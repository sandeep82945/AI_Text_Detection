{
    "abstractText": "Causal representation learning aims to unveil latent high-level causal representations from observed low-level data. One of its primary tasks is to provide reliable assurance of identifying these latent causal models, known as identifiability. A recent breakthrough explores identifiability by leveraging the change of causal influences among latent causal variables across multiple environments (Liu et al., 2022). However, this progress rests on the assumption that the causal relationships among latent causal variables adhere strictly to linear Gaussian models. In this paper, we extend the scope of latent causal models to involve nonlinear causal relationships, represented by polynomial models, and general noise distributions conforming to the exponential family. Additionally, we investigate the necessity of imposing changes on all causal parameters and present partial identifiability results when part of them remains unchanged. Further, we propose a novel empirical estimation method, grounded in our theoretical finding, that enables learning consistent latent causal representations. Our experimental results, obtained from both synthetic and real-world data, validate our theoretical contributions concerning identifiability and consistency.",
    "authors": [],
    "id": "SP:dd6694d4ee126292475e53bada844ebdcacfa778",
    "references": [
        {
            "authors": [
                "Jeffrey Adams",
                "Niels Hansen",
                "Kun Zhang"
            ],
            "title": "Identification of partially observed linear causal models: Graphical conditions for the non-gaussian and heterogeneous cases",
            "venue": "NeurIPS,",
            "year": 2021
        },
        {
            "authors": [
                "Kartik Ahuja",
                "Divyat Mahajan",
                "Yixin Wang",
                "Yoshua Bengio"
            ],
            "title": "Interventional causal representation learning",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Animashree Anandkumar",
                "Daniel Hsu",
                "Adel Javanmard",
                "Sham Kakade"
            ],
            "title": "Learning linear bayesian networks with latent variables",
            "venue": "In ICML, pp",
            "year": 2013
        },
        {
            "authors": [
                "Johann Brehmer",
                "Pim De Haan",
                "Phillip Lippe",
                "Taco Cohen"
            ],
            "title": "Weakly supervised causal representation learning",
            "venue": "arXiv preprint arXiv:2203.16437,",
            "year": 2022
        },
        {
            "authors": [
                "Simon Buchholz",
                "Goutham Rajendran",
                "Elan Rosenfeld",
                "Bryon Aragam",
                "Bernhard Sch\u00f6lkopf",
                "Pradeep Ravikumar"
            ],
            "title": "Learning linear causal representations from interventions under general nonlinear mixing",
            "venue": "arXiv preprint arXiv:2306.02235,",
            "year": 2023
        },
        {
            "authors": [
                "Ruichu Cai",
                "Feng Xie",
                "Clark Glymour",
                "Zhifeng Hao",
                "Kun Zhang"
            ],
            "title": "Triad constraints for learning causal structure of latent variables",
            "venue": "NeurIPS,",
            "year": 2019
        },
        {
            "authors": [
                "Carlos M Carvalho",
                "Nicholas G Polson",
                "James G Scott"
            ],
            "title": "Handling sparsity via the horseshoe",
            "venue": "In Artificial intelligence and statistics,",
            "year": 2009
        },
        {
            "authors": [
                "Srinivas Niranj Chandrasekaran",
                "Hugo Ceulemans",
                "Justin D Boyd",
                "Anne E Carpenter"
            ],
            "title": "Imagebased profiling for drug discovery: due for a machine-learning upgrade",
            "venue": "Nature Reviews Drug Discovery,",
            "year": 2021
        },
        {
            "authors": [
                "Miriam K Forbes",
                "Robert F Krueger"
            ],
            "title": "The great recession and mental health in the united states",
            "venue": "Clinical Psychological Science,",
            "year": 2019
        },
        {
            "authors": [
                "Benjamin Frot",
                "Preetam Nandy",
                "Marloes H Maathuis"
            ],
            "title": "Robust causal structure learning with some hidden variables",
            "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
            "year": 2019
        },
        {
            "authors": [
                "Howard Frumkin"
            ],
            "title": "Environmental health: from global to local",
            "year": 2016
        },
        {
            "authors": [
                "I. Higgins",
                "Lo\u0131\u0308c Matthey",
                "A. Pal",
                "Christopher P. Burgess",
                "Xavier Glorot",
                "M. Botvinick",
                "S. Mohamed",
                "Alexander Lerchner"
            ],
            "title": "beta-vae: Learning basic visual concepts with a constrained variational framework",
            "venue": "In ICLR,",
            "year": 2017
        },
        {
            "authors": [
                "Patrik O Hoyer",
                "Dominik Janzing",
                "Joris M Mooij",
                "Jonas Peters",
                "Bernhard Sch\u00f6lkopf"
            ],
            "title": "Nonlinear causal discovery with additive noise models",
            "venue": "In NeurIPS,",
            "year": 2008
        },
        {
            "authors": [
                "Biwei Huang",
                "Charles Jia Han Low",
                "Feng Xie",
                "Clark Glymour",
                "Kun Zhang"
            ],
            "title": "Latent hierarchical causal structure discovery with rank constraints",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Aapo Hyvarinen",
                "Hiroaki Sasaki",
                "Richard Turner"
            ],
            "title": "Nonlinear ica using auxiliary variables and generalized contrastive learning",
            "venue": "In The 22nd International Conference on Artificial Intelligence and Statistics,",
            "year": 2019
        },
        {
            "authors": [
                "Martin Jankowiak",
                "Fritz Obermeyer"
            ],
            "title": "Pathwise derivatives beyond the reparameterization trick",
            "venue": "In International conference on machine learning,",
            "year": 2018
        },
        {
            "authors": [
                "Samil Karahan",
                "Merve Kilinc Yildirum",
                "Kadir Kirtac",
                "Ferhat Sukru Rende",
                "Gultekin Butun",
                "Hazim Kemal Ekenel"
            ],
            "title": "How image degradations affect deep cnn-based face recognition? In 2016 international conference of the biometrics special interest group (BIOSIG)",
            "year": 2016
        },
        {
            "authors": [
                "Nan Rosemary Ke",
                "Aniket Didolkar",
                "Sarthak Mittal",
                "Anirudh Goyal",
                "Guillaume Lajoie",
                "Stefan Bauer",
                "Danilo Rezende",
                "Yoshua Bengio",
                "Michael Mozer",
                "Christopher Pal"
            ],
            "title": "Systematic evaluation of causal discovery in visual model based reinforcement learning",
            "venue": "arXiv preprint arXiv:2107.00848,",
            "year": 2021
        },
        {
            "authors": [
                "Ilyes Khemakhem",
                "Diederik Kingma",
                "Ricardo Monti",
                "Aapo Hyvarinen"
            ],
            "title": "Variational autoencoders and nonlinear ica: A unifying framework",
            "venue": "In AISTAS,",
            "year": 2020
        },
        {
            "authors": [
                "Diederik P Kingma",
                "Max Welling"
            ],
            "title": "Auto-encoding variational bayes",
            "venue": "arXiv preprint arXiv:1312.6114,",
            "year": 2013
        },
        {
            "authors": [
                "Murat Kocaoglu",
                "Christopher Snyder",
                "Alexandros G Dimakis",
                "Sriram Vishwanath"
            ],
            "title": "Causalgan: Learning causal implicit generative models with adversarial training",
            "venue": "In ICLR,",
            "year": 2018
        },
        {
            "authors": [
                "S\u00e9bastien Lachapelle",
                "Pau Rodr\u0131\u0301guez L\u00f3pez",
                "Yash Sharma",
                "Katie Everett",
                "R\u00e9mi Le Priol",
                "Alexandre Lacoste",
                "Simon Lacoste-Julien"
            ],
            "title": "Disentanglement via mechanism sparsity regularization: A new principle for nonlinear ica",
            "venue": "arXiv preprint arXiv:2107.10098,",
            "year": 2021
        },
        {
            "authors": [
                "Timothy O. Laumann",
                "Russell A. Poldrack"
            ],
            "title": "URL https://openfmri.org/ dataset/ds000031",
            "year": 2015
        },
        {
            "authors": [
                "Phillip Lippe",
                "Sara Magliacane",
                "Sindy L\u00f6we",
                "Yuki M Asano",
                "Taco Cohen",
                "Stratis Gavves"
            ],
            "title": "Citris: Causal identifiability from temporal intervened sequences",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Yuhang Liu",
                "Wenyong Dong",
                "Lei Zhang",
                "Dong Gong",
                "Qinfeng Shi"
            ],
            "title": "Variational bayesian dropout with a hierarchical prior",
            "year": 2019
        },
        {
            "authors": [
                "Yuhang Liu",
                "Zhen Zhang",
                "Dong Gong",
                "Mingming Gong",
                "Biwei Huang",
                "Anton van den Hengel",
                "Kun Zhang",
                "Javen Qinfeng Shi"
            ],
            "title": "Identifying weight-variant latent causal models",
            "venue": "arXiv preprint arXiv:2208.14153,",
            "year": 2022
        },
        {
            "authors": [
                "Adam Paszke",
                "Sam Gross",
                "Soumith Chintala",
                "Gregory Chanan",
                "Edward Yang",
                "Zachary DeVito",
                "Zeming Lin",
                "Alban Desmaison",
                "Luca Antiga",
                "Adam Lerer"
            ],
            "title": "Automatic differentiation in pytorch",
            "venue": "In NeurIPS workshop,",
            "year": 2017
        },
        {
            "authors": [
                "Judea Pearl",
                "Madelyn Glymour",
                "Nicholas P Jewell"
            ],
            "title": "Causal inference in statistics: A primer",
            "year": 2016
        },
        {
            "authors": [
                "Jonas Peters",
                "Joris M. Mooij",
                "Dominik Janzing",
                "Bernhard Sch\u00f6lkopf"
            ],
            "title": "Causal discovery with continuous additive noise models",
            "year": 2009
        },
        {
            "authors": [
                "Bernhard Sch\u00f6lkopf"
            ],
            "title": "Learning to see and act",
            "venue": "Nature, 518(7540):486\u2013487,",
            "year": 2015
        },
        {
            "authors": [
                "Bernhard Sch\u00f6lkopf",
                "Francesco Locatello",
                "Stefan Bauer",
                "Nan Rosemary Ke",
                "Nal Kalchbrenner",
                "Anirudh Goyal",
                "Yoshua Bengio"
            ],
            "title": "Toward causal representation learning",
            "venue": "Proceedings of the IEEE,",
            "year": 2021
        },
        {
            "authors": [
                "Anna Seigal",
                "Chandler Squires",
                "Caroline Uhler"
            ],
            "title": "Linear causal disentanglement via interventions",
            "venue": "arXiv preprint arXiv:2211.16467,",
            "year": 2022
        },
        {
            "authors": [
                "Shohei Shimizu",
                "Patrik O Hoyer",
                "Aapo Hyv\u00e4rinen"
            ],
            "title": "Estimation of linear non-gaussian acyclic models for latent factors",
            "year": 2024
        },
        {
            "authors": [
                "Ricardo Silva",
                "Richard Scheines",
                "Clark Glymour",
                "Peter Spirtes",
                "David Maxwell Chickering"
            ],
            "title": "Learning the structure of linear latent variable models",
            "year": 2006
        },
        {
            "authors": [
                "Peter Sorrenson",
                "Carsten Rother",
                "Ullrich K\u00f6the"
            ],
            "title": "Disentanglement by nonlinear ica with general incompressible-flow networks (gin)",
            "venue": "arXiv preprint arXiv:2001.04872,",
            "year": 2020
        },
        {
            "authors": [
                "Stefan G Stark",
                "Joanna Ficek",
                "Francesco Locatello",
                "Ximena Bonilla",
                "St\u00e9phane Chevrier",
                "Franziska Singer",
                "Tumor Profiler Consortium",
                "Gunnar R\u00e4tsch",
                "Kjong-Van Lehmann"
            ],
            "title": "Scim: universal single-cell matching with unpaired feature",
            "venue": "sets. Bioinformatics,",
            "year": 2020
        },
        {
            "authors": [
                "Burak Varici",
                "Emre Acarturk",
                "Karthikeyan Shanmugam",
                "Abhishek Kumar",
                "Ali Tajer"
            ],
            "title": "Scorebased causal representation learning with interventions",
            "venue": "arXiv preprint arXiv:2301.08230,",
            "year": 2023
        },
        {
            "authors": [
                "Julius Von K\u00fcgelgen",
                "Yash Sharma",
                "Luigi Gresele",
                "Wieland Brendel",
                "Bernhard Sch\u00f6lkopf",
                "Michel Besserve",
                "Francesco Locatello"
            ],
            "title": "Self-supervised learning with data augmentations provably isolates content from style",
            "venue": "In Advances in neural information processing systems,",
            "year": 2021
        },
        {
            "authors": [
                "Feng Xie",
                "Ruichu Cai",
                "Biwei Huang",
                "Clark Glymour",
                "Zhifeng Hao",
                "Kun Zhang"
            ],
            "title": "Generalized independent noise condition for estimating latent variable causal graphs",
            "venue": "NeurIPS,",
            "year": 2020
        },
        {
            "authors": [
                "Feng Xie",
                "Biwei Huang",
                "Zhengming Chen",
                "Yangbo He",
                "Zhi Geng",
                "Kun Zhang"
            ],
            "title": "Identification of linear non-gaussian latent hierarchical structure",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Mengyue Yang",
                "Furui Liu",
                "Zhitang Chen",
                "Xinwei Shen",
                "Jianye Hao",
                "Jun Wang"
            ],
            "title": "Causalvae: Structured causal disentanglement in variational autoencoder",
            "year": 2021
        },
        {
            "authors": [
                "Weiran Yao",
                "Yuewen Sun",
                "Alex Ho",
                "Changyin Sun",
                "Kun Zhang"
            ],
            "title": "Learning temporally causal latent processes from general temporal data",
            "venue": "arXiv preprint arXiv:2110.05428,",
            "year": 2021
        },
        {
            "authors": [
                "Weiran Yao",
                "Guangyi Chen",
                "Kun Zhang"
            ],
            "title": "Learning latent causal dynamics",
            "venue": "arXiv preprint arXiv:2202.04828,",
            "year": 2022
        },
        {
            "authors": [
                "Xun Zheng",
                "Bryon Aragam",
                "Pradeep Ravikumar",
                "Eric P Xing"
            ],
            "title": "Dags with no tears: Continuous optimization for structure learning",
            "venue": "NeurIPS,",
            "year": 2018
        },
        {
            "authors": [
                "Sorrenson"
            ],
            "title": "2020) holds in our setting, i.e., the latent noise variables n can be identified up",
            "year": 2020
        },
        {
            "authors": [
                "Liu"
            ],
            "title": "UNDERSTANDING ASSUMPTIONS IN THEOREM Assumptions (i)-(iii) are motivated by the nonlinear ICA literature (Khemakhem et al., 2020), which is to provide a guarantee that we can recover latent noise variables n up to a permutation and scaling transformation. The main Assumption (iii) essentially requires sufficient changes in latent noise variables",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Causal representation learning, aiming to discover high-level latent causal variables and causal structures among them from unstructured observed data, provides a prospective way to compensate for drawbacks in traditional machine learning paradigms, e.g., the most fundamental limitations that data, driving and promoting the machine learning methods, needs to be independent and identically distributed (i.i.d.) (Scho\u0308lkopf, 2015). From the perspective of causal representations, the changes in data distribution, arising from various real-world data collection pipelines (Karahan et al., 2016; Frumkin, 2016; Pearl et al., 2016; Chandrasekaran et al., 2021), can be attributed to the changes of causal influences among causal variables (Scho\u0308lkopf et al., 2021). These changes are observable across a multitude of fields. For instance, these could appear in the analysis of imaging data of cells, where the contexts involve batches of cells exposed to various small-molecule compounds. In this context, each latent variable represents the concentration level of a group of proteins (Chandrasekaran et al., 2021). An inherent challenge with small molecules is their variability in mechanisms of action, which can lead to differences in selectivity (Forbes & Krueger, 2019). In addition, the causal influences of a particular medical treatment on a patient outcome may vary depending on the patient profiles (Pearl et al., 2016). Moreover, causal influences from pollution to health outcomes, such as respiratory illnesses, can vary across different urban and rural environments (Frumkin, 2016).\nDespite the above desirable advantages, the fundamental theories underpinning causal representation learning, the issue of identifiability (i.e., uniqueness) of causal representations, remain a significant challenge. One key factor leading to non-identifiability results is that the causal influences among latent space could be assimilated by the causal influences from latent space to observed space, resulting in multiple feasible solutions (Liu et al., 2022; Adams et al., 2021). To illustrate this, consider two latent causal variables case, and suppose that ground truth is depicted in Figure 1 (a). The causal influence from the latent causal variable z1 to z2 in Figure 1 (a) could be assimilated by the causal influence from z to x, resulting in the non-identifiability result, as depicted in Figure 1 (b). Efforts to address the transitivity to achieve the identifiability for causal representation learning primarily fall into two categories: 1) enforcing special graph structures (Silva et al., 2006; Cai et al., 2019; Xie\net al., 2020; 2022; Adams et al., 2021; Lachapelle et al., 2021), and 2) utilizing the change of causal influences among latent causal variables (Liu et al., 2022; Brehmer et al., 2022; Ahuja et al., 2023; Seigal et al., 2022; Buchholz et al., 2023; Varici et al., 2023). The first approach usually requires special graph structures, i.e., there are two pure child nodes at least for each latent causal variable, as depicted in Figure 1 (c). These pure child nodes essentially prevent the transitivity problem, by the fact that if there is an alternative solution to generate the same observational data, the pure child would not be \u2019pure\u2019 anymore. For example, if the edge from z1 to z2 in Figure 1 (c) is replaced by two new edges (one from z1 to x2, the other from z1 to x3), x2 and x3 are not \u2019pure\u2019 child of z2 anymore. For more details please refer to recent works in Xie et al. (2020; 2022); Huang et al. (2022). However, many causal graphs in reality may be more or less arbitrary, beyond the special graph structures. The second research approach permits any graph structures by utilizing the change of causal influences, as demonstrated in Figure 1 (d). To characterize the change, a surrogate variable u is introduced into the causal system. Essentially, the success of this approach lies in that the change of causal influences in latent space can not be \u2018absorbed\u2019 by the unchanged mapping from latent space to observed space across u (Liu et al., 2022), effectively preventing the transitivity problem. Some methods within this research line require paired interventional data (Brehmer et al., 2022), which may be restricted in some applications such as biology (Stark et al., 2020). Some works require hard interventions or more restricted single-node hard interventions (Ahuja et al., 2023; Seigal et al., 2022; Buchholz et al., 2023; Varici et al., 2023), which could only model specific types of changes. By contrast, the work presented in Liu et al. (2022) studies unpaired data, and employs soft interventions to model a broader range of possible changes, which could be easier to achieve for latent variables than hard interventions.\nThe work in Liu et al. (2022) compresses the solution space of latent causal variables up to identifiable solutions, particularly from the perspective of observed data. This process leverages nonlinear identifiability results from nonlinear ICA (Hyvarinen et al., 2019; Khemakhem et al., 2020; Sorrenson et al., 2020). Most importantly, it relies on some strong assumptions, including 1) causal relations among latent causal variables to be linear Gaussian models, and 2) requiring `+ (`(`+ 1))/2 environments where ` is the number of latent causal variables. By contrast, this work is driven by the realization that we can narrow the solution space of latent causal variables from the perspective of latent noise variables, with the identifiability results from nonlinear ICA. This perspective enables us to more effectively utilize model assumptions among latent causal variables, leading to two significant generalizations: 1) Causal relations among latent causal variables can be generalized to be polynomial models with exponential family noise, and 2) The requisite number of environments can be relaxed to 2`+1 environments, a much more practical number. These two advancements narrow the gap between fundamental theory and practice. Besides, we deeply investigate the assumption of requiring all coefficients within polynomial models to change. We show complete identifiability results if all coefficients change across environments, and partial identifiability results if only part of the coefficients change. The partial identifiability result implies that the whole latent space can be theoretically divided into two subspaces, one relates to invariant latent variables, while the other involves variant variables. This may be potentially valuable for applications that focus on learning invariant latent variables to adapt to varying environments, such as domain adaptation or generalization. To verify our findings, we design a novel method to learn polynomial causal representations in the contexts of Gaussian and non-Gaussian noises. Experiments verify our identifiability results and the efficacy of the proposed approach on synthetic data, modified image data based on Ke et al. (2021), and real fMRI data."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "Due to the challenges of identifiability in causal representation learning, early works focus on learning causal representations in a supervised setting where prior knowledge of the structure of the causal graph of latent variables may be required (Kocaoglu et al., 2018), or additional labels are required to supervise the learning of latent variables (Yang et al., 2021). However, obtaining prior knowledge of the structure of the latent causal graph is non-trivial in practice, and manual labeling can be costly and error-prone. Some works consider temporal constraint that the effect cannot precede the cause has been used repeatedly in latent causal representation learning (Yao et al., 2021; Lippe et al., 2022; Yao et al., 2022), while this work aims to learn instantaneous causal relations among latent variables. Besides, there are two primary approaches to address the transitivity problem, including imposing special graph structures and using the change of causal influences.\nSpecial graph structures Special graphical structure constraints have been introduced in recent progress in identifiability (Silva et al., 2006; Shimizu et al., 2009; Anandkumar et al., 2013; Frot et al., 2019; Cai et al., 2019; Xie et al., 2020; 2022; Lachapelle et al., 2021). One of representative graph structures is that there are 2 pure children for each latent causal variables (Xie et al., 2020; 2022; Huang et al., 2022). These special graph structures are highly related to sparsity, which implies that a sparser model that fits the observation is preferred (Adams et al., 2021). However, many latent causal graphs in reality may be more or less arbitrary, beyond a purely sparse graph structure. Differing from special graph structures, this work does not restrict graph structures among latent causal variables, by exploring the change of causal influence among latent causal variables.\nThe change of causal influence Very recently, there have been some works exploring the change of causal influence (Von Ku\u0308gelgen et al., 2021; Liu et al., 2022; Brehmer et al., 2022; Ahuja et al., 2023; Seigal et al., 2022; Buchholz et al., 2023; Varici et al., 2023). Roughly speaking, these changes of causal influences could be categorized as hard interventions or soft interventions. Most of them consider hard intervention or more restricted single-node hard interventions (Ahuja et al., 2023; Seigal et al., 2022; Buchholz et al., 2023; Varici et al., 2023), which can only capture some special changes of causal influences. In contrast, soft interventions could model more possible types of change (Liu et al., 2022; Von Ku\u0308gelgen et al., 2021), which could be easier to achieve in latent space. Differing from the work in Von Ku\u0308gelgen et al. (2021) that identifies two coarse-grained latent subspaces, e.g., style and content, the work in Liu et al. (2022) aims to identify fine-grained latent variables. In this work, we generalize the identifiability results in Liu et al. (2022), and relax the requirement of the number of environments. Moreover, we discuss the necessity of requiring all causal influences to change, and partial identifiability results when part of causal influences changes."
        },
        {
            "heading": "3 IDENTIFIABLE CAUSAL REPRESENTATIONS WITH VARYING POLYNOMIAL CAUSAL MODELS",
            "text": "In this section, we show that by leveraging changes, latent causal representations are identifiable (including both latent causal variables and the causal model), for general nonlinear models and noise distributions are sampled from two-parameter exponential family members. Specifically, we start by introducing our defined varying latent polynomial causal models in Section 3.1, aiming to facilitate comprehension of the problem setting and highlight our contributions. Following this, in Section 3.2, we present our identifiability results under the varying latent polynomial causal model. This constitutes a substantial extension beyond previous findings within the domain of varying linear Gaussian models (Liu et al., 2022). Furthermore, we delve into a thorough discussion about the necessity of requiring changes in all causal influences among the latent causal variables. We, additionally, show partial identifiability results in cases where only a subset of causal influences changes in Section 3.3, further solidifying our identifiability findings."
        },
        {
            "heading": "3.1 VARYING LATENT POLYNOMIAL CAUSAL MODELS",
            "text": "We explore causal generative models where the observed data x is generated by the latent causal variables z 2 R`, allowing for any potential graph structures among z. In addition, there exist latent noise variables n 2 R`, known as exogenous variables in causal systems, corresponding to latent\ncausal variables. We introduce a surrogate variable u characterizing the changes in the distribution of n, as well as the causal influences among latent causal variables z. Here u could be environment, domain, or time index. More specifically, we parameterize the causal generative models by assuming n follows an exponential family given u, and assuming z and x are generated as follows:\np(T,\u2318)(n|u) := Y\ni\n1\nZi(u) exp[\nX\nj\n(Ti,j(ni)\u2318i,j(u))], (1)\nzi := gi(pai,u) + ni, (2) x := f(z) + \", (3)\nwith\ngi(z,u) = T i (u)[z, z\u2326\u0304z, ..., z\u2326\u0304...\u2326\u0304z| {z }], (4)\nwhere\n\u2022 in Eq. 1, Zi(u) denotes the normalizing constant, and Ti,j(ni) denotes the sufficient statistic for ni, whose the natural parameter \u2318i,j(u) depends on u. Here we focus on twoparameter (e.g., j 2 {1, 2}) exponential family members, which include not only Gaussian, but also inverse Gaussian, Gamma, inverse Gamma, and beta distributions.\n\u2022 In Eq. 2, pai denotes the set of parents of zi.\n\u2022 In Eq. 3, f denotes a nonlinear mapping, and \" is independent noise with probability density function p\"(\").\n\u2022 In Eq. 4, where i(u) = [ 1,i(u), 2,i(u), ...)], \u2326\u0304 represents the Kronecker product with all distinct entries, e.g., for 2-dimension case, z1\u2326\u0304z2 = [z21 , z22 , z1z2]. Here i(u) adheres to common Directed Acyclic Graphs (DAG) constraints.\nThe models defined above represent polynomial models and two-parameter exponential family distributions, which include not only Gaussian, but also inverse Gaussian, Gamma, inverse Gamma, and beta distributions. Clearly, the linear Gaussian models proposed in (Liu et al., 2022) can be seen as a special case in this broader framework. The proposed latent causal models, as defined in Eqs. 1 - 4, have the capacity to capture a wide range of change of causal influences among latent causal variables, including a diverse set of nonlinear functions and two-parameter exponential family noises. This expansion in scope serves to significantly bridge the divide between foundational theory and practical applications."
        },
        {
            "heading": "3.2 COMPLETE IDENTIFYABILITY RESULT",
            "text": "The crux of our identifiability analysis lies in leveraging the changes in causal influences among latent causal variables, orchestrated by u. Unlike many prior studies that constrain the changes within the specific context of hard interventions (Brehmer et al., 2022; Ahuja et al., 2023; Seigal et al., 2022; Buchholz et al., 2023; Varici et al., 2023), our approach welcomes and encourages changes. Indeed, our approach allows a wider range of potential changes which can be interpreted as soft interventions (via the causal generative model defined in Eqs. 1- 4).\nDefinition 3.1 We say that the true latent causal variables z is identifiable up to permutation and scaling, if z are related to the estimated latent causal variables z\u0302 by the following relationship: z = Pz\u0302+ c, where P denotes the permutation matrix with scaling, c denotes a constant vector.\nTheorem 3.1 Suppose latent causal variables z and the observed variable x follow the causal generative models defined in Eq. 1 - Eq. 4. Assume the following holds:\n(i) The set {x 2 X|'\"(x) = 0} has measure zero (i.e., has at the most countable number of elements), where '\" is the characteristic function of the density p\",\n(ii) The function f in Eq. 3 is bijective,\n(iii) The random vector u takes up at least 2`+ 1 distinct points, There exist 2` + 1 values of u, i.e., u0,u1, ...,u2`, such that the matrix\nL = (\u2318(u = u1) \u2318(u = u0), ...,\u2318(u = u2`) \u2318(u = u0)) (5)\nof size 2`\u21e5 2` is invertible. Here \u2318(u) = [\u2318i,j(u)]i,j ,\n(iv) The function class of i,j can be expressed by a Taylor series: for each i,j , i,j(u = 0) = 0,\nthen the true latent causal variables z are related to the estimated latent causal variables z\u0302, which are learned by matching the true marginal data distribution p(x|u), by the following relationship: z = Pz\u0302+ c, where P denotes the permutation matrix with scaling, c denotes a constant vector.the true latent causal variables z is identifiable up to permutation and scaling by matching the true marginal data distribution p(x|u).\nProof sketch First, we demonstrate that given the DAG (Directed Acyclic Graphs) constraint and the assumption of additive noise in latent causal models as in Eq. 4, the identifiability result in (Sorrenson et al., 2020) holds. Specifically, it allows us to identify the latent noise variables n up to scaling and permutation, e.g., n = Pn\u0302 + c where n\u0302 denotes the recovered latent noise variables obtained by matching the true marginal data distribution. Building upon this result, we then leverage polynomial property that the composition of polynomials is a polynomial, and additive noise assumption defined in Eq. 2, to show that the latent causal variables z can also be identified up to polynomial transformation, i.e., z = Poly(z\u0302) + c where Poly denotes a polynomial function. Finally, using the change of causal influences among z, the polynomial transformation can be further reduced to permutation and scaling, i.e., z = Pz\u0302+ c. Detailed proof can be found in A.2.\nOur model assumptions among latent causal variables is a typical additive noise model as in Eq. 4. Given this, the identifiability of latent causal variables implies that the causal graph is also identified. This arises from the fact that additive noise models are identifiable (Hoyer et al., 2008; Peters et al., 2014), regardless of the scaling on z. In addition, the proposed identifiability result in Theorem 3.1 represents a more generalized form of the previous result in (Liu et al., 2022). When the polynomial model\u2019s degree is set to 1 and the noise is sampled from Gaussian distribution, the proposed identifiability result in Theorem 3.1 converges to the earlier finding in (Liu et al., 2022). Notably, the proposed identifiability result requires only 2` + 1 environments, while the result in (Liu et al., 2022) needs the number of environments depending on the graph structure among latent causal variables. In the worst case, e.g., a full-connected causal graph over latent causal variables, i.e., `+ (`(`+ 1))/2."
        },
        {
            "heading": "3.3 COMPLETE AND PARTIAL CHANGE OF CAUSAL INFLUENCES",
            "text": "The aforementioned theoretical result necessitates that all coefficients undergo changes across various environments, as defined in Eq. 4. However, in practical applications, the assumption may not hold true. Consequently, two fundamental questions naturally arise: is the assumption necessary for identifiability, in the absence of any supplementary assumptions? Alternatively, can we obtain partial identifiability results if only part of the coefficients changes across environments? In this section, we provide answers to these two questions.\nCorollary 3.2 Suppose latent causal variables z and the observed variable x follow the causal generative models defined in Eq. 1 - Eq. 4. Under the condition that the assumptions (i)-(iv)(iii) in Theorem 3.1 are satisfied, if there is an unchanged coefficient in Eq. 4 across environments, z is unidentifiable, without additional assumptions.\nProof sketch The proof of the above corollary can be done by investigating whether we can always construct an alternative solution, different from z, to generate the same observation x, if there is an unchanged coefficient across u. The construction can be done by the following: assume that there is an unchanged coefficient in polynomial for zi, we can always construct an alternative solution z0 by removing the term involving the unchanged coefficient in polynomial gi, while keeping the other unchanged, i.e., z0j = zj for all j 6= i. Details can be found in A.3.\nInsights 1) This corollary implies the necessity of requiring all coefficients to change to obtain the complete identifyability result, without introducing additional assumptions. We acknowledge the possibility of mitigating this requirement by imposing specific graph structures, which is beyond the scope of this work. However, it is interesting to explore the connection between the change of causal influences and special graph structures for the identifiability of causal representations in the future. 2) In addition, this necessity may depend on specific model assumptions. For instance, if we use MLPs to model the causal relations of latent causal variables, it may be not necessary to require all weights in the MLPs to change.\nRequiring all coefficients to change might be challenging in real applications. In fact, when part of the coefficients change, we can still provide partial identifiability results, as outlined below:\nCorollary 3.3 Suppose latent causal variables z and the observed variable x follow the causal generative models defined in Eq. 1 - Eq. 4. Under the condition that the assumptions (i)-(iv)(iii) in Theorem 3.1 are satisfied, for each zi,\n(a) if it is a root node or all coefficients in the corresponding polynomial gi change in Eq. 4, then the true zi is related to the recovered one z\u0302j , obtained by matching the true marginal data distribution p(x|u), by the following relationship: zi = sz\u0302j + c, where s denotes scaling, c denotes a constant,\n(b) if there exists an unchanged coefficient in polynomial gi in Eq. 4, then zi is unidentifiable.\nProof sketch This can be proved by the fact that regardless of the change of the coefficients, two results hold, i.e., z = Poly(z\u0302) + c, and n = Pn\u0302 + c. Then using the change of all coefficients in the corresponding polynomial gi, we can prove (a). For (b), similar to the proof of corollary 3.2, we can construct a possible solution z0i for zi by removing the term corresponding to the unchanged coefficient, resulting in an unidentifiable result.\nInsights 1) The aforementioned partial identifiability result implies that the entire latent space can theoretically be partitioned into two distinct subspaces: one subspace pertains to invariant latent variables, while the other encompasses variant variables. This may be potentially valuable for applications that focus on learning invariant latent variables to adapt to varying environments, such as domain adaptation (or generalization). 2) In cases where there exists an unchanged coefficient in the corresponding polynomial gi, although zi is not entirely identifiable, we may still ascertain a portion of zi. To illustrate this point, for simplicity, assume that z2 = 3z1 + 1,2(u)z21 + n2. Our result (b) shows that z2 is unidentifiable due to the constant coefficient 3 on the right side of the equation. However, the component 1,2(u)z21 +n2 may still be identifiable. While we refrain from presenting a formal proof for this insight in this context, we can provide some elucidation. If we consider z2 as a composite of two variables, za = 3z1 and zb = 1,2(u)z21 + n2, according to our finding (a), zb may be identified. As a consequence, it becomes possible to disentangle zb from the invariant space."
        },
        {
            "heading": "4 LEARNING POLYNOMIAL CAUSAL REPRESENTATIONS WITH VARYING COEFFICIENTS",
            "text": "In this section, we translate our theoretical findings into a novel algorithm. Following the work in (Liu et al., 2022), due to permutation indeterminacy in latent space, we can naturally enforce a causal order z1 z2 ..., z` to impose each variable to learn the corresponding latent variables in the correct causal order. As a result, for the Gaussian noise, in which the conditional distributions p(zi|pai), where pai denote the parent nodes of zi, can be expressed as an analytic form, we formulate the prior distribution as conditional Gaussian distributions. Differing from the Gaussian noise, non-Gaussian noise does not have an analytically tractable solution, in general. Given this, we model the prior distribution of p(z|u) by p( ,n|u). As a result, we arrive at:\np(z|u) =\n8 < : p(z1|u) Q\u0300 i=2 p(zi|z<i,u) = Q\u0300 i=1 N (\u00b5zi(u), 2zi(u)), if n \u21e0 Gaussian Q`\ni=1 Q j=1 p( j,i|u) Q` i=1 p(ni|u), if n \u21e0 non-Gaussian\n(6)\nwhere N (\u00b5zi(u), 2zi(u)) denotes the Gaussian probability density function with mean \u00b5zi(u) and variance 2zi(u). Note that non-Gaussian noises typically tend to result in high-variance gradients. They often require distribution-specific variance reduction techniques to be practical, which is beyond the scope of this paper. Instead, we straightforwardly use the PyTorch (Paszke et al., 2017) implementation of the method of (Jankowiak & Obermeyer, 2018), which computes implicit reparameterization using a closed-form approximation of the probability density function derivative. In our implementation, we found that the implicit reparameterization leads to high-variance gradients for inverse Gaussian and inverse Gamma distributions. Therefore, we present the results of Gamma, and beta distributions in experiments.\nPrior on coefficients p( j,i) We enforce two constraints on the coefficients, DAG constraint and sparsity. The DAG constraint is to ensure a directed acyclic graph estimation. Current methods usually employ a relaxed DAG constraint proposed by Zheng et al. (2018) to estimate causal graphs, which may result in a cyclic graph estimation due to the inappropriate setting of the regularization hyperparameter. Following the work in (Liu et al., 2022), we can naturally ensure a directed acyclic graph estimation by enforcing the coefficients matrix (u)T to be a lower triangular matrix corresponding to a fully-connected graph structure, due to permutation property in latent space. In addition, to prune the fully connected graph structure to select true parent nodes, we enforce a sparsity constraint on each j,i(u). In our implementation, we simply impose a Laplace distribution on each j,i(u), other distributions may also be flexible, e.g, horseshoe prior (Carvalho et al., 2009) or Gaussian prior with zero mean and variance sampled from a uniform prior (Liu et al., 2019).\nVariational Posterior We employ variational posterior to approximate the true intractable posterior of p(z|x,u). The nature of the proposed prior in Eq. 6 gives rise to the posterior:\nq(z|u,x) = ( q(z1|u,x) Q` i=2 q(zi|z<i,u,x), if n \u21e0 Gaussian Q`\ni=1 Q j=1 q( j,i|x,u) Q` i=1 q(ni|u,x), if n \u21e0 non-Gaussian\n(7)\nwhere variational posteriors q(zi|z<i,u,x), q( j,i) and q(ni|u) employ the same distribution as their priors, so that an analytic form of Kullback\u2013Leibler divergence between the variational posterior and the prior can be provided. As a result, we can arrive at a simple objective:\nmaxEq(z|x,u)q( |x,u)(p(x|z,u)) DKL(q(z|x,u)||p(z|u)) DKL(q( |x,u)||p( |u)), (8)\nwhere DKL denotes the KL divergence. Implementation details can be found in Appendix A.6."
        },
        {
            "heading": "5 EXPERIMENTS",
            "text": "Synthetic Data We first conduct experiments on synthetic data, generated by the following process: we divide latent noise variables into M segments, where each segment corresponds to one value of u as the segment label. Within each segment, the location and scale parameters are respectively sampled from uniform priors. After generating latent noise variables, we randomly generate coefficients for polynomial models, and finally obtain the observed data samples by an invertible nonlinear mapping on the polynomial models. More details can be found in Appendix A.5.\nWe compare the proposed method with vanilla VAE (Kingma & Welling, 2013), -VAE (Higgins et al., 2017), identifiable VAE (iVAE) (Khemakhem et al., 2020). Among them, iVAE is able to identify the true independent noise variables up to permutation and scaling, with certain assumptions. -VAE has been widely used in various disentanglement tasks, motivated by enforcing independence among the recovered variables, but it has no theoretical support. Note that both methods assume that the latent variables are independent, and thus they cannot model the relationships among latent variables. All these methods are implemented in three different settings corresponding to linear models with Beta distributions, linear models with Gamma noise, and polynomial models with Gaussian noise, respectively. To make a fair comparison, for non-Gaussian noise, all these methods use the PyTorch (Paszke et al., 2017) implementation of the method of (Jankowiak & Obermeyer, 2018) to compute implicit reparameterization. We compute the mean of the Pearson correlation coefficient (MPC) to evaluate the performance of our proposed method. Further, we report the structural Hamming distance (SHD) of the recovered latent causal graphs by the proposed method.\nFigure 2 shows the performances of different methods on different models, in the setting where all coefficients change across u. According to MPC, the proposed method with different model assumptions obtains satisfactory performance, which verifies the proposed identifiability results. Further, Figure 3 shows the performances of the proposed method when part of coefficients change across u, for which we can see that unchanged weight leads to non-identifiability results, and changing weights contribute to the identifiability of the corresponding nodes. These empirical results are consistent with partial identifiability results in corollary 3.3.\nImage Data We further verify the proposed identifiability results and method on images from the chemistry dataset proposed in (Ke et al., 2021), which corresponds to chemical reactions where the state of an element can cause changes to another variable\u2019s state. The images consist of a number of objects whose positions are kept fixed, while the colors (states) of the objects change according to the causal graph. To meet our assumptions, we use a weight-variant linear causal model with Gamma noise to generate latent variables corresponding to the colors. The ground truth of the latent causal graph is that the \u2019diamond\u2019 (e.g., z1) causes the \u2018triangle\u2019 (e.g., z2), and the \u2018triangle\u2019 causes the \u2019square\u2019 (e.g., z3). A visualization of the observational images can be found in Figure 4. Figure 5 shows the MPC obtained by different methods. The proposed method performs better than others. The proposed method also learns the correct causal graph as verified by intervention results in Figure 6, i.e., 1) intervention on z1 (\u2019diamond\u2019) causes the change of both z2 (\u2018triangle\u2019) and z3\n(\u2019square\u2019), 2) intervention on z2 only causes the change of z3, 3) intervention on z3 can not affect both z1 and z2. These results are consistent with the correct causal graph, i.e., z1 ! z2 ! z3. Due to limited space, more traversal results on the learned latent variables by the other methods can be found in Appendix A.7. For these methods, since there is no identifiability guarantee, we found that traversing on each learned variable leads to the colors of all objects changing.\nfMRI Data Following Liu et al. (2022), we further apply the proposed method to fMRI hippocampus dataset (Laumann & Poldrack, 2015), which contains signals from six separate brain regions: perirhinal cortex (PRC), parahippocampal cortex (PHC), entorhinal cortex (ERC), subiculum (Sub), CA1, and CA3/Dentate Gyrus (DG). These signals were recorded during resting states over a span of 84 consecutive days from the same individual. Each day\u2019s data is considered a distinct instance, resulting in an 84-dimensional vector represented as u. Given our primary interest in uncovering latent causal variables, we treat the six signals as latent causal variables. To transform them into observed data, we subject them to a random nonlinear mapping. Subsequently, we apply our proposed method to the transformed observed data. We then apply the proposed method to the transformed observed data to recover the latent causal variables. Figure 7 shows the results obtained by the proposed method with different model assumptions. We can see that the polynomial models with Gaussian noise perform better than others, and the result obtained by linear models with Gaussian noise is suboptimal. This also may imply that 1) Gaussian distribution is more reasonable to model the noise in this data, 2) linear relations among these signals may be more dominant than nonlinear."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "Identifying latent causal representations is known to be generally impossible without certain assumptions. This work generalizes the previous linear Gaussian models to polynomial models with two-parameter exponential family members, including Gaussian, inverse Gaussian, Gamma, inverse Gamma, and Beta distribution. We further discuss the necessity of requiring all coefficients in polynomial models to change to obtain complete identifiability result, and analyze partial identifiability results in the setting where only part of the coefficients change. We then propose a novel method to learn polynomial causal representations with Gaussian or non-Gaussian noise. Experimental results on synthetic and real data demonstrate our findings and consistent results. Identifying causal representations by exploring the change of causal influences is still an open research line. In addition, even with the identifiability guarantees, it is still challenging to learn causal graphs in latent space."
        },
        {
            "heading": "A APPENDIX",
            "text": ""
        },
        {
            "heading": "A.1 THE RESULT IN (LIU ET AL., 2022)",
            "text": "For comparison, here we provide the main model assumptions and result in the work by (Liu et al., 2022). It considers the following causal generative models:\nni :\u21e0 N (\u2318i,1(u), \u2318i,2(u)), (9) zi := T i (u)(z) + ni, (10)\nx := f(z) + \" (11)\nTheorem A.1 Suppose latent causal variables z and the observed variable x follow the generative models defined in Eq. 9- Eq. 11, with parameters (f , ,\u2318). Assume the following holds:\n(i) The set {x 2 X|'\"(x) = 0} has measure zero (i.e., has at the most countable number of elements), where '\" is the characteristic function of the density p\".\n(ii) The function f in Eq. 11 is bijective.\n(iii) There exist 2`+ 1 distinct points un,0,un,1, ...,un,2` such that the matrix\nLn = (\u2318(un,1) \u2318(un,0), ...,\u2318(un,2`) \u2318(un,0)) (12)\nof size 2`\u21e5 2` is invertible.\n(iv) There exist k + 1 distinct points uz,0,uz,1, ...,uz,k such that the matrix\nLz = (\u2318z(uz,1) \u2318z(uz,0), ...,\u2318z(uz,k) \u2318z(uz,0)) (13)\nof size k \u21e5 k is invertible.\n(v) The function class of i,j can be expressed by a Taylor series: for each i,j , i,j(0) = 0,\nthen the recovered latent causal variables z\u0302, which are learned by matching the true marginal data distribution p(x|u), are related to the true latent causal variables z by the following relationship: z = Pz\u0302+ c, where P denotes the permutation matrix with scaling, c denotes a constant vector.\nHere \u2318 denote sufficient statistic of distribution of latent noise variables n, \u2318z denote sufficient statistic of distribution of latent causal variables z. k denotes the number of the sufficient statistic of z. Please refer to (Liu et al., 2022) for more details.\nCompared with the work in (Liu et al., 2022), this work generalizes linear Gaussian models in Eq. 10 to polynomial models with two-parameter exponential family, as defined in Eq. 1-2. In addition, this work removes the assumption (iv), which requires the number of environments highly depending on the graph structure. Moreover, both the work in (Liu et al., 2022) and this work explores the change of causal influences, in this work, we provide analysis for the necessity of requiring all causal influence to change, and also partial identifiability results when part of causal influences changes. This analysis enables the research line, allowing causal influences to change, more solid."
        },
        {
            "heading": "A.2 THE PROOF OF THEOREM 3.1",
            "text": "For convenience, we first introduce the following lemmas.\nLemma A.2 z can be expressed as a polynomial function with respect to n, i.e., z = h(n,u), where h denote a polynomial, and h 1 is also a polynomial function.\nProof can be easily shown by the following: since we have established that zi depends on its parents and ni as defined in Eqs. 2 and 4, we can recursively express zi in terms of latent noise variables relating to its parents and ni using the equations provided in Eqs. 2 and 4. Specifically, without loss of the generality, suppose that the correct causal order is z1 z2 ..., z`, we have:\nz1 = n1|{z} h1(n1) ,\nz2 = g2(z1) + n2 = g2(n1,u) + n2| {z } h2(n1,n2,u) ,\nz3 = g3(z1, g2(n1,u) + n2,u) + n3| {z } h3(n1,n2,n3,u) , (14)\n......,\nwhere h(n,u) = [h1(n1,u), h2(n1, n2,u), h3(n1, n2, n3,u)...]. By the fact that the composition of polynomials is still a polynomial, and repeating the above process for each zi can show that z can be expressed as a polynomial function with respect to n, i.e., z = h(n,u). Further, according to the additive noise models and DAG constraints, it can be shown that the Jacobi determinant of h equals 1, and thus the mapping h is invertible. Moreover, h 1 can be recursively expressed in terms of zi according to Eq. 14, as follows:\nn1 = z1|{z} h 11 (n1) ,\nn2 = z2 g2(n1,u) = z2 g2(z1,u)| {z } h 12 (z1,z2,u) ,\nn3 = z3 g3(z1, g2(n1,u) + n2,u) = z3 g3(z1, g2(z1,u) + (z2 g2(z1,u))),u)| {z } h 13 (z1,z2,z3,u) . (15)\n......,\nAgain, since the composition of polynomials is still a polynomial, the mapping h 1 is also a polynomial.\nLemma A.3 The mapping from n to x, e.g., f h, is invertible, and the Jacobi determinant | detJf h| = | detJf || detJh| = | detJf |, and thus | detJ(f h) 1 | = | detJ 1f h| = | detJ 1 f |, which do not depend on u.\nProof can be easily shown by the following: Lemma A.2 has shown that the mapping h, from n to z, is invertible. Together with the assumption that f is invertible, the mapping from n to x is invertible. In addition, due to the additive noise models and DAG constraint as defined in Eq. 14, we can obtain | detJh| = 1.\nLemma A.4 Given the assumption (iv) in Theorem 3.1, the partial derivative of hi(n1, ..., ni,u) in Eq. 14 with respect to ni0 , where i0 < i, equals 0 when u = 0, i.e.,\n@hi(n1,...,ni,u=0) @ni0 = 0.\nSince the partial derivative of the polynomial hi(n1, ..., ni,u) is still a polynomial whose coefficients are scaled by i(u), as defined in Eq. 14, and by using the assumption (iv), we can obtain the result.\nThe proof of Theorem 3.1 is done in three steps. Step I is to show that the identifiability result in (Sorrenson et al., 2020) holds in our setting, i.e., the latent noise variables n can be identified up\nto component-wise scaling and permutation, n = Pn\u0302 + c. Using this result, Step II shows that z can be identified up to polynomial transformation, i.e., z = Poly(z\u0302) + c. Step III shows that the polynomial transformation in Step II can be reduced to permutation and scaling, z = Pz\u0302 + c, by using Lemma A.4.\nStep I: Suppose we have two sets of parameters \u2713 = (f ,T, ,\u2318) and \u2713\u0302 = (f\u0302 , T\u0302, \u0302, \u2318\u0302) corresponding to the same conditional probabilities, i.e., p(f ,T, ,\u2318)(x|u) = p(f\u0302 ,T\u0302,\u0302,\u2318\u0302)(x|u) for all pairs (x,u), where T denote the sufficient statistic of latent noise variables n. Due to the assumption (i), the assumption (ii), and the fact that h is invertible (e.g., Lemma A.2), by expanding the conditional probabilities (More details can be found in Step I for proof of Theorem 1 in (Khemakhem et al., 2020)), we have:\nlog | detJ(f h) 1(x)|+ log p(T,\u2318)(n|u) = log | detJ(f\u0302 h\u0302) 1(x)|+ log p(T\u0302,\u2318\u0302)(n\u0302|u), (16)\nUsing the exponential family as defined in Eq. 1, we have:\nlog | detJ(f h) 1(x)|+TT (f h) 1(x) \u2318(u) log\nY\ni\nZi(u) = (17)\nlog | detJ(f\u0302 h\u0302) 1(x)|+ T\u0302 T (f\u0302 h\u0302) 1(x) \u2318\u0302(u) log\nY\ni\nZ\u0302i(u), (18)\nBy using Lemma A.3, Eqs. 17-18 can be reduced to:\nlog | detJf 1(x)|+TT (f h) 1(x) \u2318(u) log\nY\ni\nZi(u) =\nlog | detJf\u0302 1(x)|+ T\u0302 T (f\u0302 h\u0302) 1(x) \u2318\u0302(u) log\nY\ni\nZ\u0302i(u). (19)\nThen by expanding the above at points ul and u0, then using Eq. 19 at point ul subtract Eq. 19 at point u0, we find:\nhT(n), \u2318\u0304(u)i+ X\ni\nlog Zi(u0)\nZi(ul) = hT\u0302(n\u0302), \u00af\u0302\u2318(u)i+\nX\ni\nlog Z\u0302i(u0)\nZ\u0302i(ul) . (20)\nHere \u2318\u0304(ul) = \u2318(ul) \u2318(u0). By assumption (iii), and combining the 2` expressions into a single matrix equation, we can write this in terms of L from assumption (iii),\nLTT(n) = L\u0302T T\u0302(n\u0302) + b. (21)\nSince LT is invertible, we can multiply this expression by its inverse from the left to get:\nT (f h) 1(x) = AT\u0302 (f\u0302 h\u0302) 1(x) + c, (22)\nWhere A = (LT ) 1L\u0302T . According to lemma 3 in (Khemakhem et al., 2020) that there exist k distinct values n1i to nki such that the derivative T 0(n1i ), ..., T 0(nki ) are linearly independent, and the fact that each component of Ti,j is univariate, we can show that A is invertible.\nSince we assume the noise to be two-parameter exponential family members, Eq. 22 can be reexpressed as: \u2713\nT1(n) T2(n)\n\u25c6 = A \u2713 T\u03021(n\u0302) T\u03022(n\u0302) \u25c6 + c, (23)\nThen, we re-express T2 in term of T1, e.g., T2(ni) = t(T1(ni)) where t is a nonlinear mapping. As a result, we have from Eq. 23 that: (a) T1(ni) can be linear combination of T\u03021(n\u0302) and T\u03022(n\u0302), and (b) t(T1(ni)) can also be linear combination of T\u03021(n\u0302) and T\u03022(n\u0302). This implies the contradiction that both T1(ni) and its nonlinear transformation t(T1(ni)) can be expressed by linear combination of T\u03021(n\u0302) and T\u03022(n\u0302). This contradiction leads to that A can be reduced to permutation matrix P (See APPENDIX C in (Sorrenson et al., 2020) for more details):\nn = Pn\u0302+ c, (24)\nwhere P denote the permutation matrix with scaling, c denote a constant vector. Note that this result holds for not only Gaussian, but also inverse Gaussian, Beta, Gamma, and Inverse Gamma (See Table 1 in (Sorrenson et al., 2020)).\nStep II:By Lemma A.2, we can denote z and z\u0302 by: z = h(n), (25)\nz\u0302 = h\u0302(n\u0302), (26) where h is defined in A.2. Replacing n and n\u0302 in Eq. 24 by Eq. 25 and Eq. 26, respectively, we have:\nh 1(z) = Ph\u0302 1(z\u0302) + c, (27)\nwhere h (as well as h\u0302) are invertible supported by Lemma A.2. We can rewrite Eq. 27 as:\nz = h(Ph\u0302 1(z\u0302) + c). (28) Again, by the fact that the composition of polynomials is still a polynomial, we can show:\nz = Poly(z\u0302) + c0. (29)\nStep III Next, Replacing z and z\u0302 in Eq. 29 by Eqs. 24, 25, and 26:\nh(Pn\u0302+ c) = Poly(h\u0302(n\u0302)) + c0 (30)\nBy differentiating Eq. 30 with respect to n\u0302\nJhP = JPolyJh\u0302. (31)\nWithout loss of generality, let us consider the correct causal order z1 z2 ..., z` so that Jh and Jh\u0302 are lower triangular matrices whose the diagonal are 1, and P is a diagonal matrix with elements s1,1, s2,2, s3,3, ....\nElements above the diagonal of matrix JPoly Since Jh\u0302 are lower triangular matrices, and P is a diagonal matrix, JPoly must be a lower triangular matrix.\nThen by expanding the left side of Eq. 31, we have:\nJhP =\n0\nBB@\ns1,1 0 0 ...\ns1,1 @h2(n1,n2,u)\n@n1 s2,2 0 ...\ns1,1 @h3(n1,n2,n3,u)\n@n1 s2,2 @h3(n1,n2,n3,u) @n2\ns3,3 ... . . . ...\n1\nCCA , (32)\nby expanding the right side of Eq. 31, we have:\nJPolyJh\u0302 =\n0\nBBB@\nJPoly1,1 0 0 ...\nJPoly2,1 + JPoly2,2 @h\u03022(n1,n2,u) @n1 JPoly2,2 0 ...\nJPoly3,1 + P3 i=2 JPoly3,i @h\u0302i(n1,...,ni,u) @n1 JPoly3,2 + JPoly3,3 @h\u03023(n1,...,n3,u) @n2\nJPoly3,3 ... . . . ...\n1\nCCCA .\n(33)\nThe diagonal of matrix JPoly By comparison between Eq. 32 and Eq. 33, we have JPolyi,i = si,i\nElements below the diagonal of matrix JPoly By comparison between Eq. 32 and Eq. 33, and Lemma A.4, for all i > j we have JPolyi,j = 0.\nAs a result, the matrix JPoly in Eq. 31 equals to the permutation matrix P, which implies that the polynomial transformation Eq. 29 reduces to a permutation transformation,\nz = Pz\u0302+ c0. (34)"
        },
        {
            "heading": "A.3 THE PROOF OF COROLLARY 3.2",
            "text": "To prove the corollary, we demonstrate that it is always possible to construct an alternative solution, which is different from the true z, but capable of generating the same observations x, if there is an unchanged coefficient across u. Again, without loss of the generality, suppose that the correct causal order is z1 z2 ..., z`. Suppose that for zi, there is an unchanged coefficient j,i, related to the term of polynomial j,i across u, where denotes polynomial features created by raising the variables related to parent node to an exponent. Note that since we assume the correct causal order, the term only includes zj where j < i. Then, we can always construct new latent variables z0 as: for all k 6= i, z0k = zk, and z0i = zi j,i . Given this, we can construct a polynomial mapping M, so that\nM(z0) = z, (35)\nwhere\nM(z0) =\n0\nBBBBB@\nz01 z02 ..\nz0i + j,i z0i+1 = zi+1\n..\n1\nCCCCCA . (36)\nwhere for all k 6= i, z0k = zk in the right. It is clear the Jacobi determinant of the mapping M always equals 1, thus the mapping M is invertible. In addition, all the coefficients of the polynomial mapping M are constant and thus do not depend on u. As a result, we can construct a mapping f M as the mapping from z0 to x, which is invertible and do not depend on u, and can create the same data x generated by f(z). Therefore, the alternative solution z0 can lead to a non-identifiability result."
        },
        {
            "heading": "A.4 THE PROOF OF COROLLARY 3.3",
            "text": "Since the proof process in Steps I and II in A.2 do not depend on the assumption of change of causal influence, the results in both Eq. 32 and Eq. 33 hold. Then consider the following two cases.\n\u2022 For the case where zi is a root node or all coefficients on all paths from parent nodes to zi change across u, by using Lemma A.4, i.e., @hi(n1,...,ni,u=0)@n0i = 0 and @h\u0302i(n1,...,ni,u=0) @n0i =\n0 for all i0 < i, and by comparison between Eq. 32 and Eq. 33, we have: for all i > j we have JPolyi,j = 0, which implies that we can obtain that zi = Ai,iz\u0302i + c 0 i.\n\u2022 If there exists an unchanged coefficient in all paths from parent nodes to zi across u, then by the proof of corollary 3.2, i.e., z0i can be constructed as a new possible solution to replace zi by removing the unchanged coefficient j,i, resulting in the non-identifiability result. This is also can be proved in another way, e.g., a comparison between Eq. 32 and Eq. 33. Suppose that the coefficient is j,i related to the parent node with the index k. Given that, we have: @h\u0302i(n1,...,ni 1,u)@nk include a constant term j,i. Again, by using the Lemma A.4, and by comparison between Eq. 32 and Eq. 33, we can only arrive that sk,k j,i = JPolyi,k . As a result, zi will be expressed as a combination of z\u0302k and z\u0302i."
        },
        {
            "heading": "A.5 SYNTHETIC DATA",
            "text": "Data For experimental results on synthetic data, the number of segments is 30, and for each segment, the sample size is 1000, while the number (e.g., dimension) of latent causal or noise variables is 2,3,4,5 respectively. Specifically, for latent linear causal models, we consider the following structural causal model:\nni :\u21e0 \u21e2 B(\u21b5, ), if n \u21e0 Beta G(\u21b5, ), , if n \u21e0 Gamma (37)\nz1 := n1 (38) z2 := 1,2(u)z1 + n2 (39) z3 := 2,3(u)z2 + n3 (40) z4 := 3,4(u)z3 + n4 (41) z5 := 3,5(u)z3 + n5, (42)\n(43)\nwhere both \u21b5 and , for both Beta and Gamma distributions, are sampled from a uniform distribution [0.1, 2.0], and i,j(u) are sampled from a uniform distribution [ 1.0, 0.5] [ [0.5, 1.0]. For latent polynomial causal models with Gaussian noise, we consider the following structural causal model:\nni :\u21e0 N (\u21b5, ), (44) z1 := n1 (45)\nz2 := 1,2(u)z 2 1 + n2 (46)\nz3 := 2,3(u)z2 + n3 (47) z4 := 3,4(u)z2z3 + n4 (48)\nz5 := 3,5(u)z 2 3 + n5. (49)\n(50)\nwhere both \u21b5 and for Gaussian noise are sampled from uniform distributions [ 2.0, 2.0] and [0.1, 2.0], respectively. i,j(u) are sampled from a uniform distribution [ 1.0, 0.5] [ [0.5, 1.0].\nA.6 IMPLEMENTATION FRAMEWORK\nFigure 8 depicts the proposed method to learn polynomial causal representations with non-Gaussian noise. Figure 9 depicts the proposed method to learn polynomial causal representations with Gaussian noise. For non-Gaussian noise, since there is generally no analytic form for the joint distribution of latent causal variables, we here assume that p(z|u) = p( (u))p(n|u) as defined in Eq. 6. Note that this assumption may be not true in general, since it destroys independent causal mechanisms generating effects in causal systems. For experiments on the synthetic data and fMRI data, the encoder, decoder, MLP for , and MLP for prior are implemented by using 3-layer fully connected networks and Leaky-ReLU activation functions. For optimization, we use Adam optimizer with learning rate 0.001. For experiments on the image data, we also use 3-layer fully connected network and Leaky-ReLU activation functions for and the prior model. The encoder and decoder can be found in Table 1 and Table 2, respectively."
        },
        {
            "heading": "A.7 TRAVERSALS ON THE LEARNED VARIABLES BY IVAE, -VAE, AND VAE",
            "text": "Since there is no theoretical support for both -VAE and VAE, these two methods can not disentangle latent causal variables. This can be demonstrated by Figure 10 and Figure 11, which shows that traversal on each learned variable leads to the change of colors of all objects. It is interesting to note that iVAE has the theoretical guarantee of learning latent noise variables. And since we assume additive noise models, e.g., z1 = n1, iVAE is able to identify z1. This can be verified from the result obtained by iVAE shown in Figure 5, which shows that the MPC between recovered z1 and the true one is 0.963. However, iVAE can not identify z2 and z3, since these are causal relations among the latent causal variables. We can see from Figure 12, the changes of z2 and z3 lead to the change of colors of all objects."
        },
        {
            "heading": "A.8 FURTHER DISCUSSION ON THE PARTIAL IDENTIFIABILITY IN COROLLARY 3.3.",
            "text": "While demanding a change in all coefficients may pose challenges in practical applications, Corollary 3.3 introduces partial identifiability results. The entire latent space can theoretically be partitioned into two distinct subspaces: an invariant latent subspace and a variant latent subspace. This partitioning holds potential value for applications emphasizing the learning of invariant latent variables to adapt to changing environments, such as domain adaptation (or generalization), as discussed\nin the main paper. However, the impact of partial identifiability results on the latent causal graph structure remains unclear.\nWe posit that if there are no interactions (edges) between the two latent subspaces in the ground truth graph structure, the latent causal structure in the latent variant space can be recovered. This recovery is possible since the values of these variant latent variables can be restored up to component-wise permutation and scaling. In contrast, when no interactions exist between the two latent subspaces in the ground truth graph structure, recovering (part of) the latent causal structure becomes highly challenging. We believe that the unidentifiable variables in the invariant latent subspace may influence the latent causal structure in the variant latent subspace.\nWe hope this discussion can inspire further research to explore this intriguing problem in the future."
        },
        {
            "heading": "A.9 FURTHER DISCUSSION ON MODEL ASSUMPTIONS IN LATENT SPACE.",
            "text": "In our approach, we selected polynomial models for their approximation capabilities and straightforward expressions, streamlining analysis and facilitating the formulation of sufficient changes. While advantageous, this choice is not without recognized limitations, notably the challenges introduced by high-order terms in polynomials during optimization. Overall, we think that model assumptions can be extended to a broader scope than polynomials, including non-parametric models. This extension is contingent on deeming changes in causal influences as sufficient. The crucial question in moving towards more general model assumptions revolves around defining what constitutes sufficient changes in causal influences."
        },
        {
            "heading": "A.10 UNDERSTANDING ASSUMPTIONS IN THEOREM",
            "text": "Assumptions (i)-(iii) are motivated by the nonlinear ICA literature (Khemakhem et al., 2020), which is to provide a guarantee that we can recover latent noise variables n up to a permutation and scaling transformation. The main Assumption (iii) essentially requires sufficient changes in latent noise variables to facilitate their identification. Assumption (iv) is derived from the work by Liu et al. (2022) and is introduced to avoid a specific case: i,j(u) = 0i,j(u) + b, where b is a non-zero constant. To illustrate, if z2 = ( 01,2(u) + b)z1 + n2, the term bz1 remains unchanged across all u, resulting in non-identifiability according to Corollary 3.3. While assumption (iv) is sufficient for handling this specific case, it may not be necessary. We anticipate the proposal of a sufficient and necessary condition in the future to address the mentioned special case."
        },
        {
            "heading": "A.11 THE UNKNOWN NUMBER OF LATENT CAUSAL/NOISE VARIABLES",
            "text": "It is worth noting that most existing works require knowledge of the number of latent variables. However, this is not a theoretical hurdle in our work. It is due to a crucial step in our results leveraging the identifiability findings from Sorrenson et al. (2020) to idenitify latent noise variables. The key insight in Sorrenson et al. (2020) demonstrates that the dimension of the generating latent space can be recovered if latent noises are sampled from the two-parameter exponential family members. This assumption is consistent with our assumption on latent noise, as defined in Eq. 1. In other words, if the estimated latent space has a higher dimension than the generating latent space, some estimated latent variables may not be related to any generating latent variables and therefore encode only noise. More details can be found in Sorrenson et al. (2020)."
        }
    ],
    "year": 2023
}