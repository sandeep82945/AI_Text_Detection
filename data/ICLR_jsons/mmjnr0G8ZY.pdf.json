{
    "abstractText": "The diffusion model has been successfully used in many computer vision applications, such as text-guided image generation and image-to-image translation. Recently, there have been attempts on extending the diffusion model for time series data. However, these extensions are fairly straightforward and do not utilize the unique properties of time series data. As different patterns are usually exhibited at multiple scales of a time series, we in this paper leverage this multi-resolution temporal structure and propose the multi-resolution diffusion model (mr-Diff). By using the seasonal-trend decomposition, we sequentially extract fine-to-coarse trends from the time series for forward diffusion. The denoising process then proceeds in an easy-to-hard non-autoregressive manner. The coarsest trend is generated first. Finer details are progressively added, using the predicted coarser trends as condition variables. Experimental results on nine real-world time series datasets demonstrate that mr-Diff outperforms state-of-the-art time series diffusion models. It is also better than or comparable across a wide variety of advanced time series prediction models.",
    "authors": [],
    "id": "SP:1702c5b345c1b52298387e255c21408f87f1d084",
    "references": [
        {
            "authors": [
                "Juan Miguel Lopez Alcaraz",
                "Nils Strodthoff"
            ],
            "title": "Diffusion-based time series imputation and forecasting with structured state space models",
            "venue": "Technical report,",
            "year": 2022
        },
        {
            "authors": [
                "O. Anderson",
                "M. Kendall"
            ],
            "title": "Time-series. 2nd edn",
            "venue": "Journal of the Royal Statistical Society (Series D),",
            "year": 1976
        },
        {
            "authors": [
                "D. Bahdanau",
                "K. Cho",
                "Y. Bengio"
            ],
            "title": "Neural machine translation by jointly learning to align and translate",
            "venue": "In International Conference on Learning Representations,",
            "year": 2015
        },
        {
            "authors": [
                "Yaniv Benny",
                "Lior Wolf"
            ],
            "title": "Dynamic dual-output diffusion models",
            "venue": "In IEEE/CVF Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Andreas Blattmann",
                "Robin Rombach",
                "Huan Ling",
                "Tim Dockhorn",
                "Seung Wook Kim",
                "Sanja Fidler",
                "Karsten Kreis"
            ],
            "title": "Align your latents: High-resolution video synthesis with latent diffusion models",
            "venue": "In CVPR,",
            "year": 2023
        },
        {
            "authors": [
                "Cristian Challu",
                "Kin G Olivares",
                "Boris N Oreshkin",
                "Federico Garza",
                "Max Mergenthaler-Canseco",
                "Artur Dubrawski"
            ],
            "title": "N-hits: Neural hierarchical interpolation for time series forecasting",
            "venue": "In AAAI,",
            "year": 2023
        },
        {
            "authors": [
                "Ashesh Chattopadhyay",
                "Adam Subel",
                "Pedram Hassanzadeh"
            ],
            "title": "Data-driven super-parameterization using deep learning: Experimentation with multiscale lorenz 96 systems and transfer learning",
            "venue": "Journal of Advances in Modeling Earth Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Prafulla Dhariwal",
                "Alexander Nichol"
            ],
            "title": "Diffusion models beat gans on image synthesis",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Alexey Dosovitskiy",
                "Lucas Beyer",
                "Alexander Kolesnikov",
                "Dirk Weissenborn",
                "Xiaohua Zhai",
                "Thomas Unterthiner",
                "Mostafa Dehghani",
                "Matthias Minderer",
                "Georg Heigold",
                "Sylvain Gelly"
            ],
            "title": "An image is worth 16x16 words: Transformers for image recognition at scale",
            "venue": "In International Conference on Learning Representations,",
            "year": 2020
        },
        {
            "authors": [
                "Stefan Elfwing",
                "Eiji Uchibe",
                "Kenji Doya"
            ],
            "title": "Sigmoid-weighted linear units for neural network function approximation in reinforcement learning",
            "venue": "Technical report,",
            "year": 2017
        },
        {
            "authors": [
                "Wei Fan",
                "Shun Zheng",
                "Xiaohan Yi",
                "Wei Cao",
                "Yanjie Fu",
                "Jiang Bian",
                "Tie-Yan Liu"
            ],
            "title": "DEPTS: Deep expansion learning for periodic time series forecasting",
            "venue": "In International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "William Harvey",
                "Saeid Naderiparizi",
                "Vaden Masrani",
                "Christian Weilbach",
                "Frank Wood"
            ],
            "title": "Flexible diffusion modeling of long videos",
            "year": 2022
        },
        {
            "authors": [
                "Hansika Hewamalage",
                "Christoph Bergmeir",
                "Kasun Bandara"
            ],
            "title": "Recurrent neural networks for time series forecasting: Current status and future directions",
            "venue": "International Journal of Forecasting,",
            "year": 2021
        },
        {
            "authors": [
                "Jonathan Ho",
                "Ajay Jain",
                "Pieter Abbeel"
            ],
            "title": "Denoising diffusion probabilistic models",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Jonathan Ho",
                "Chitwan Saharia",
                "William Chan",
                "David J. Fleet",
                "Mohammad Norouzi",
                "Tim Salimans"
            ],
            "title": "Cascaded diffusion models for high fidelity image generation",
            "venue": "Journal of Machine Learning Research,",
            "year": 2022
        },
        {
            "authors": [
                "Sepp Hochreiter",
                "J\u00fcrgen Schmidhuber"
            ],
            "title": "Long short-term memory",
            "venue": "Neural Computation,",
            "year": 1997
        },
        {
            "authors": [
                "Paul Jeha",
                "Michael Bohlke-Schneider",
                "Pedro Mercado",
                "Shubham Kapoor",
                "Rajbir Singh Nirwan",
                "Valentin Flunkert",
                "Jan Gasthaus",
                "Tim Januschowski"
            ],
            "title": "PSA-GAN: Progressive self attention GANs for synthetic time series",
            "venue": "In ICLR,",
            "year": 2022
        },
        {
            "authors": [
                "Taesung Kim",
                "Jinhee Kim",
                "Yunwon Tae",
                "Cheonbok Park",
                "Jang-Ho Choi",
                "Jaegul Choo"
            ],
            "title": "Reversible instance normalization for accurate time-series forecasting against distribution shift",
            "venue": "In International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Zhifeng Kong",
                "Wei Ping",
                "Jiaji Huang",
                "Kexin Zhao",
                "Bryan Catanzaro"
            ],
            "title": "Diffwave: A versatile diffusion model for audio synthesis",
            "venue": "In International Conference on Learning Representations,",
            "year": 2020
        },
        {
            "authors": [
                "Guokun Lai",
                "Wei-Cheng Chang",
                "Yiming Yang",
                "Hanxiao Liu"
            ],
            "title": "Modeling long-and short-term temporal patterns with deep neural networks",
            "venue": "In The 41st international ACM SIGIR conference on research & development in information retrieval,",
            "year": 2018
        },
        {
            "authors": [
                "Yan Li",
                "Xinjiang Lu",
                "Yaqing Wang",
                "Dejing Dou"
            ],
            "title": "Generative time series forecasting with diffusion, denoise, and disentanglement",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Minhao Liu",
                "Ailing Zeng",
                "Muxi Chen",
                "Zhijian Xu",
                "Qiuxia Lai",
                "Lingna Ma",
                "Qiang Xu"
            ],
            "title": "Scinet: Time series modeling and forecasting with sample convolution and interaction",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Shizhan Liu",
                "Hang Yu",
                "Cong Liao",
                "Jianguo Li",
                "Weiyao Lin",
                "Alex X Liu",
                "Schahram Dustdar"
            ],
            "title": "Pyraformer: Low-complexity pyramidal attention for long-range time series modeling and forecasting",
            "venue": "In International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Cheng Lu",
                "Yuhao Zhou",
                "Fan Bao",
                "Jianfei Chen",
                "Chongxuan Li",
                "Jun Zhu"
            ],
            "title": "DPM-solver: A fast ODE solver for diffusion probabilistic model sampling in around 10 steps",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Andreas Lugmayr",
                "Martin Danelljan",
                "Andres Romero",
                "Fisher Yu",
                "Radu Timofte",
                "Luc Van Gool"
            ],
            "title": "Repaint: Inpainting using denoising diffusion probabilistic models",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Kiran Madhusudhanan",
                "Johannes Burchert",
                "Nghia Duong-Trung",
                "Stefan Born",
                "Lars"
            ],
            "title": "SchmidtThieme. Yformer: U-net inspired transformer architecture for far horizon time series forecasting",
            "venue": "Technical report,",
            "year": 2021
        },
        {
            "authors": [
                "Yuqi Nie",
                "Nam H Nguyen",
                "Phanwadee Sinthong",
                "Jayant Kalagnanam"
            ],
            "title": "A time series is worth 64 words: long-term forecasting with transformers",
            "venue": "Technical report,",
            "year": 2022
        },
        {
            "authors": [
                "Hao Niu",
                "Chuizheng Meng",
                "Defu Cao",
                "Guillaume Habault",
                "Roberto Legaspi",
                "Shinya Wada",
                "Chihiro Ono",
                "Yan Liu"
            ],
            "title": "Mu2rest: Multi-resolution recursive spatio-temporal transformer for long-term prediction",
            "venue": "In Advances in Knowledge Discovery and Data Mining,",
            "year": 2022
        },
        {
            "authors": [
                "Boris N Oreshkin",
                "Dmitri Carpov",
                "Nicolas Chapados",
                "Yoshua Bengio"
            ],
            "title": "N-beats: Neural basis expansion analysis for interpretable time series forecasting",
            "venue": "In International Conference on Learning Representations,",
            "year": 2019
        },
        {
            "authors": [
                "Syama Sundar Rangapuram",
                "Shubham Kapoor",
                "Rajbir Singh Nirwan",
                "Pedro Mercado",
                "Tim Januschowski",
                "Yuyang Wang",
                "Michael Bohlke-Schneider"
            ],
            "title": "Coherent probabilistic forecasting of temporal hierarchies",
            "venue": "In Proceedings of The 26th International Conference on Artificial Intelligence and Statistics,",
            "year": 2023
        },
        {
            "authors": [
                "Kashif Rasul",
                "Calvin Seward",
                "Ingmar Schuster",
                "Roland Vollgraf"
            ],
            "title": "Autoregressive denoising diffusion models for multivariate probabilistic time series forecasting",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Cleveland Robert",
                "C William",
                "Terpenning Irma"
            ],
            "title": "STL: A seasonal-trend decomposition procedure based on loess",
            "venue": "Journal of official Statistics,",
            "year": 1990
        },
        {
            "authors": [
                "Robin Rombach",
                "Andreas Blattmann",
                "Dominik Lorenz",
                "Patrick Esser",
                "Bj\u00f6rn Ommer"
            ],
            "title": "Highresolution image synthesis with latent diffusion models",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Olaf Ronneberger",
                "Philipp Fischer",
                "Thomas Brox"
            ],
            "title": "U-net: Convolutional networks for biomedical image segmentation",
            "venue": "18th International Conference,",
            "year": 2015
        },
        {
            "authors": [
                "Chitwan Saharia",
                "William Chan",
                "Saurabh Saxena",
                "Lala Li",
                "Jay Whang",
                "Emily L Denton",
                "Kamyar Ghasemipour",
                "Raphael Gontijo Lopes",
                "Burcu Karagol Ayan",
                "Tim Salimans"
            ],
            "title": "Photorealistic text-to-image diffusion models with deep language understanding",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Mohammad Amin Shabani",
                "Amir H. Abdi",
                "Lili Meng",
                "Tristan Sylvain"
            ],
            "title": "Scaleformer: Iterative multi-scale refining transformers for time series forecasting",
            "venue": "In ICLR,",
            "year": 2023
        },
        {
            "authors": [
                "Lifeng Shen",
                "James Kwok"
            ],
            "title": "Non-autoregressive conditional diffusion models for time series prediction",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Yusuke Tashiro",
                "Jiaming Song",
                "Yang Song",
                "Stefano Ermon"
            ],
            "title": "CSDI: Conditional score-based diffusion models for probabilistic time series imputation",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2017
        },
        {
            "authors": [
                "Ronald J Williams",
                "David Zipser"
            ],
            "title": "A learning algorithm for continually running fully recurrent neural networks",
            "venue": "Neural computation,",
            "year": 1989
        },
        {
            "authors": [
                "Haixu Wu",
                "Jiehui Xu",
                "Jianmin Wang",
                "Mingsheng Long"
            ],
            "title": "Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Bing Yu",
                "Haoteng Yin",
                "Zhanxing Zhu"
            ],
            "title": "St-unet: A spatio-temporal u-network for graph-structured time series modeling",
            "venue": "Technical report,",
            "year": 2021
        },
        {
            "authors": [
                "Zhihan Yue",
                "Yujing Wang",
                "Juanyong Duan",
                "Tianmeng Yang",
                "Congrui Huang",
                "Yunhai Tong",
                "Bixiong Xu"
            ],
            "title": "Ts2vec: Towards universal representation of time series",
            "venue": "In AAAI,",
            "year": 2022
        },
        {
            "authors": [
                "Ailing Zeng",
                "Muxi Chen",
                "Lei Zhang",
                "Qiang Xu"
            ],
            "title": "Are transformers effective for time series forecasting",
            "venue": "In AAAI,",
            "year": 2023
        },
        {
            "authors": [
                "Hongyi Zhang",
                "Moustapha Cisse",
                "Yann N Dauphin",
                "David Lopez-Paz"
            ],
            "title": "mixup: Beyond empirical risk minimization",
            "venue": "In International Conference on Learning Representations,",
            "year": 2018
        },
        {
            "authors": [
                "Haoyi Zhou",
                "Shanghang Zhang",
                "Jieqi Peng",
                "Shuai Zhang",
                "Jianxin Li",
                "Hui Xiong",
                "Wancai Zhang"
            ],
            "title": "Informer: Beyond efficient transformer for long sequence time-series forecasting",
            "venue": "In AAAI,",
            "year": 2021
        },
        {
            "authors": [
                "Tian Zhou",
                "Ziqing Ma",
                "Qingsong Wen",
                "Liang Sun",
                "Tao Yao",
                "Rong Jin"
            ],
            "title": "Film: Frequency improved legendre memory model for long-term time series forecasting",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Tian Zhou",
                "Ziqing Ma",
                "Qingsong Wen",
                "Xue Wang",
                "Liang Sun",
                "Rong Jin"
            ],
            "title": "FEDformer: frequency enhanced decomposed transformer for long-term series forecasting",
            "venue": "In Proceedings of the 39th International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "2022a Zhou et al",
                "2022 Liu et al",
                "Zeng"
            ],
            "title": "2023), it is often useful to normalize the scales of the time series in each window. In the proposed method, we use instance normalization, which has also been used in RevIN (Kim et al., 2021) (which is referred to as reversible instance normalization) and FiLM (Zhou et al., 2022a). Specifically, we subtract the time series value in each window by its lookback window mean, and then divide by the lookback",
            "year": 2022
        },
        {
            "authors": [
                "Hits (Challu"
            ],
            "title": "2023), frequency improved Legendre memory model (FiLM) (Zhou et al., 2022a), Depts (Fan et al., 2022) and NBeats (Oreshkin et al., 2019); (iv) time series transformers",
            "year": 2019
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Time series data are prevalent in many real-world applications. In particular, time series forecasting facilitates users to identify patterns and make predictions based on historical data. Examples include stock price prediction in finance, patient health monitoring in healthcare, machine monitoring in manufacturing, and traffic flow optimization in transportation. Over the years, significant advancements in time series analysis have been made through the development of various deep neural networks, including recurrent neural networks (Hewamalage et al., 2021), convolutional neural networks (Yue et al., 2022), and transformers (Vaswani et al., 2017).\nBesides these prominent deep neural networks, the diffusion model has recently emerged as a strong generative modeling tool. It has outperformed many other generative models in areas such as image synthesis (Ho et al., 2020; Dhariwal & Nichol, 2021), video generation (Harvey et al., 2022; Blattmann et al., 2023), and multi-modal applications (Rombach et al., 2022; Saharia et al., 2022). Very recently, researchers have sought to leverage its strong generative capacity in the time-series domain. A number of time-series diffusion models have been developed (Rasul et al., 2021; Tashiro et al., 2021; Alcaraz & Strodthoff, 2022; Shen & Kwok, 2023). For example, TimeGrad (Rasul et al., 2021) integrates the standard diffusion model with recurrent neural network\u2019s hidden states. CSDI (Tashiro et al., 2021) uses self-supervised masking to guide an non-autoregressive denoising process. While these time series diffusion models have demonstrated their efficacy, they do not fully utilize the unique structural properties in time series data and are still constrained to generate the time series directly from random vectors (Figure 1(a)). This can pose a significant challenge when working with real-world time series that are non-stationary and noisy.\nAs time series usually exhibit complex patterns over multiple scales, using the underlying multiresolution temporal structure has been a cornerstone in traditional time series analysis. In particular, the seasonal-trend decomposition (Anderson & Kendall, 1976; Robert et al., 1990) can extract the seasonal and trend components, and the coarser temporal patterns can be used to help modeling the finer patterns. Recently, some deep time series prediction models (Oreshkin et al., 2019; Wu et al., 2021; Zeng et al., 2023) have also incorporated multi-resolution analysis techniques. For example, NBeats (Oreshkin et al., 2019) uses the Fourier and polynomial basis to approximate the seasonal\nand trend components in multiple layers, respectively. Autoformer (Wu et al., 2021) uses average pooling to extract seasonal components in various transformer layers. DLinear (Zeng et al., 2023) introduces an MLP with seasonal-trend branches. N-Hits (Challu et al., 2023) uses hierarchical interpolation to better leverage the multiscale temporal patterns. Fedformer (Zhou et al., 2022b) improves Autoformer by using mixture-of-experts decomposition in the frequency domain. While these recent transformer and MLP models demonstrate the effectiveness of multi-resolution analysis in deep time series modeling, the use of multi-resolution analysis in time series diffusion models has yet to be explored.\nIn this paper, we bridge this gap by proposing the multi-resolution diffusion (mr-Diff) model for time series forecasting. Unlike existing time series diffusion models that directly denoises from random vectors (Figure 1(a)), mr-Diff decomposes the denoising objective into several sub-objectives (Figure 1(b)), each of which corresponds to a trend extracted from a sequence of fine-to-coarse seasonal-trend decompositions. This encourages the denoising process to proceed in an easy-to-hard manner. The coarser trends are generated first and the finer details are then progressively added. By better exploiting the seasonal-trend structure and different temporal resolutions, this leads to a more accurate generation of the time series.\nThe contributions of this paper can be summarized as follows: (i) We propose the multi-resolution diffusion (mr-Diff) model, which is the first to integrate the seasonal-trend decomposition-based multi-resolution analysis into time series diffusion models. (ii) We perform progressive denoising in an easy-to-hard manner, generating coarser signals first and then finer details. This allows a more accurate prediction of time series. (iii) Extensive experiments show that mr-Diff outperforms state-of-the-art time series diffusion models. It is also better than or comparable across a wide variety of advanced time series prediction models."
        },
        {
            "heading": "2 RELATED WORKS: DEEP TIME SERIES MODELS",
            "text": "Recently, a number of deep time series models have been proposed that use the transformer (Vaswani et al., 2017) to capture temporal dependencies. Informer (Zhou et al., 2021) improves the vanilla transformer by avoiding its quadratic time complexity with sparse attention, and improves the inference speed by decoding in a non-autoregressive manner. Autoformer (Wu et al., 2021) replaces the transformer\u2019s self-attention block with an auto-correlation layer. Fedformer (Zhou et al., 2022b) uses a frequency-enhanced module to capture important temporal structures by frequency domain mapping. Pyraformer (Liu et al., 2021) uses a pyramidal attention module for multi-resolution representation of the time series. Scaleformer (Shabani et al., 2023) generates the forecast progressively, starting from the coarser level and then progressing to the finer levels. PatchTST (Nie et al., 2022) is similar to the vision transformer (ViT) (Dosovitskiy et al., 2020), and performs time series prediction by patching the time series and self-supervised pre-training to extract local semantic information. It also replaces the transformer\u2019s decoder with a linear mapping and uses a channel-independence strategy to achieve good performance in multivariate time series prediction.\nBesides the transformer-based models, some recent models leverage basis expansion to decompose the time series. FiLM (Zhou et al., 2022a) uses Legendre Polynomials projections to approximate historical information and Fourier projections to remove noise. NBeats (Oreshkin et al., 2019) represents the trends in the time series by polynomial coefficients and the seasonal patterns by Fourier coefficients. Depts (Fan et al., 2022) improves NBeats by using a periodicity module to model periodic time series. N-Hits (Challu et al., 2023) uses multi-scale hierarchical interpolations to further improve NBeats. In general, these models are easier to train than transformer-based models, though their performance can vary depending on the choice of the basis.\nBesides these two types of deep learning models, other recent models are also very competitive. SCINet (Liu et al., 2022) uses a recursive downsample-convolve-interact architecture to extract\ntemporal features from the downsampled sub-sequences or features. NLinear (Zeng et al., 2023) normalizes the time series and uses a linear layer for prediction. DLinear (Zeng et al., 2023) follows the Autoformer and uses seasonal-trend decomposition.\nVery recently, diffusion models have also been developed for time series data. TimeGrad (Rasul et al., 2021) is a conditional diffusion model which predicts in an autoregressive manner, with the denoising process guided by the hidden state of a recurrent neural network. However, it suffers from slow inference on long time series because of the use of autoregressive decoding. To alleviate this problem, CSDI (Tashiro et al., 2021) uses non-autoregressive generation, and uses self-supervised masking to guide the denoising process. However, it needs two transformers to capture dependencies in the channel and time dimensions. Morevoer, its complexity is quadratic in the number of variables and length of time series as in other transformer models. Besides, masking-based conditioning is similar to the task of image inpainting, and can cause disharmony at the boundaries between the masked and observed regions (Lugmayr et al., 2022; Shen & Kwok, 2023). SSSD (Alcaraz & Strodthoff, 2022) reduces the computational complexity of CSDI by replacing the transformers with a structured state space model. However, it uses the same masking-based conditioning as in CSDI, and thus still suffers from the problem of boundary disharmony. To alleviate this problem, the non-autoregressive diffusion model TimeDiff (Shen & Kwok, 2023) uses future mixup and autoregressive initialization for conditioning. However, all these time series diffusion models do not leverage the multi-resolution temporal structures and denoise directly from random vectors as in standard diffusion models.\nIn this paper, we propose to decompose the time series into multiple resolutions using seasonaltrend decomposition, and use the fine-to-coarse trends as intermediate latent variables to guide the denoising process. Recently, other multiresolution analysis techniques besides using seasonaltrend decomposition have also been used for time series modeling. For example, Yu et al. (2021) propose a U-Net (Ronneberger et al., 2015) for graph-structured time series, and leverage temporal information from different resolutions by pooling and unpooling. Mu2ReST (Niu et al., 2022) works on spatio-temporal data and recursively outputs predictions from coarser to finer resolutions. Yformer (Madhusudhanan et al., 2021) captures temporal dependencies by combining downscaling/upsampling with sparse attention. PSA-GAN (Jeha et al., 2022) trains a growing U-Net, and captures multiresolution patterns by progressively adding trainable modules at different levels. However, all these methods need to design very specific U-Net structures."
        },
        {
            "heading": "3 BACKGROUND",
            "text": ""
        },
        {
            "heading": "3.1 DENOISING DIFFUSION PROBABILISTIC MODELS",
            "text": "A well-known diffusion model is the denoising diffusion probabilistic model (DDPM) (Ho et al., 2020). It is a latent variable model with forward diffusion and backward denoising processes. During forward diffusion, an input x0 is gradually corrupted to a Gaussian noise vector. Specifically, at the kth step, xk is generated by corrupting the previous iterate xk\u22121 (scaled by \u221a 1\u2212 \u03b2k) with zero-mean Gaussian noise (with variance \u03b2k \u2208 [0, 1]):\nq(xk|xk\u22121) = N (xk; \u221a 1\u2212 \u03b2kxk\u22121, \u03b2kI), k = 1, . . . ,K.\nIt can be shown that this can also be rewritten as q(xk|x0) = N (xk; \u221a \u03b1\u0304kx\n0, (1 \u2212 \u03b1\u0304k)I), where \u03b1\u0304k = \u03a0 k s=1\u03b1s, and \u03b1k = 1\u2212 \u03b2k. Thus, xk can be simply obtained as\nxk = \u221a \u03b1\u0304kx 0 + \u221a 1\u2212 \u03b1\u0304k\u03f5, (1)\nwhere \u03f5 is a noise from N (0, I). This equation also allows x0 to be easily recovered from xk. In DDPM, backward denoising is defined as a Markovian process. Specifically, at the kth denoising step, xk\u22121 is generated from xk by sampling from the following normal distribution:\np\u03b8(x k\u22121|xk) = N (xk\u22121;\u00b5\u03b8(xk, k),\u03a3\u03b8(xk, k)). (2)\nHere, the variance \u03a3\u03b8(xk, k) is usually fixed as \u03c32kI, while the mean \u00b5\u03b8(x k, k) is defined by a neural network (parameterized by \u03b8). This is usually formulated as a noise estimation or data prediction problem (Benny & Wolf, 2022). For noise estimation, a network \u03f5\u03b8 predicts the noise of the diffused input xk, and then obtains \u00b5\u03b8(xk, k) as 1\u221a\u03b1kx k \u2212 1\u2212\u03b1k\u221a 1\u2212\u03b1\u0304k \u221a \u03b1k \u03f5\u03b8(x k, k). Parameter \u03b8 is learned by\nminimizing the loss L\u03f5 = Ek,x0,\u03f5 [ \u2225\u03f5\u2212 \u03f5\u03b8(xk, k)\u22252 ] . Alternatively, the data prediction strategy uses a denoising network x\u03b8 to obtain an estimate x\u03b8(xk, k) of the clean data x0 given xk, and then set\n\u00b5\u03b8(x k, k)=\n\u221a \u03b1k(1\u2212 \u03b1\u0304k\u22121)\n1\u2212 \u03b1\u0304k xk+ \u221a \u03b1\u0304k\u22121\u03b2k 1\u2212 \u03b1\u0304k x\u03b8(x k, k). (3)\nParameter \u03b8 is learned by minimizing the loss\nLx = Ex0,\u03f5,k\u2225x0 \u2212 x\u03b8(xk, k)\u22252. (4)"
        },
        {
            "heading": "3.2 CONDITIONAL DIFFUSION MODELS FOR TIME SERIES PREDICTION",
            "text": "In time series forecasting, one aims to predict the future values x01:H \u2208 Rd\u00d7H given the past observations x0\u2212L+1:0 \u2208 Rd\u00d7L of the time series. Here, d is the number of variables, H is the length of the forecast window, and L is the length of the lookback window. When using conditional diffusion models for time series prediction, the following distribution is considered (Rasul et al., 2021; Tashiro et al., 2021; Shen & Kwok, 2023)\np\u03b8(x 0:K 1:H |c)=p\u03b8(xK1:H) K\u220f k=1 p\u03b8(x k\u22121 1:H |x k 1:H , c), c = F(x0\u2212L+1:0), (5)\nwhere xK1:H \u223c N (0, I), c is the condition, and F is a conditioning network that takes the past observations x0\u2212L+1:0 as input. Correspondingly, the denoising process at step k is given by\np\u03b8(x k\u22121 1:H |x k 1:H , c) = N (xk\u221211:H ;\u00b5\u03b8(x k 1:H , k|c), \u03c32kI), k = K,K \u2212 1, . . . , 1. (6)\nDuring inference, xK1:H is initialized as x\u0302 K 1:H , a noise vector from N (0, I). By repeatedly running the denoising step in (6) till k = 1, x\u030201:H is obtained as the prediction of x 0 1:H ."
        },
        {
            "heading": "4 MR-DIFF: MULTI-RESOLUTION DIFFUSION MODEL",
            "text": "As discussed in Section 1, recent transformer and MLP models demonstrate the effectiveness of seasonal-trend decomposition-based multi-resolution analysis in deep time series modeling. However, the use of multi-resolution temporal patterns in the diffusion model has yet to be explored. In this paper, we address this gap by proposing the multi-resolution diffusion (mr-Diff) model. An overview of the proposed model is shown in Figure 2.\nThe proposed mr-Diff can be viewed as a cascaded diffusion model (Ho et al., 2022), and proceeds in S stages, with the resolution getting coarser as the stage proceeds (Section 4.1). This allows capturing the temporal dynamics at multiple temporal resolutions. In each stage, the diffusion process is interleaved with seasonal-trend decomposition. For simplicity of notations, we use X = x\u2212L+1:0 and Y = x1:H for the time series segments in the lookback and forecast windows, respectively. Let the trend component of the lookback (resp. forecast) segment at stage s+ 1 be Xs (resp. Ys). The trend gets coarser as s increases, and with X0 = X and Y0 = Y. In each stage s+ 1, a conditional diffusion model is learned to reconstruct the trend component Ys extracted from the forecast window (Section 4.2). The reconstruction at stage 1 then corresponds to the target time series forecast.\nWhile the forward diffusion process in this diffusion model is straightforward and similar to existing diffusion models, design of the denoising process, particularly on the denoising conditions and denoising network, are less trivial. During training, to guide the reconstruction of Ys, the proposed model takes the lookback segment Xs (which has the same resolution as Ys) and the coarser trend Ys+1 (which provides an overall picture of the finer Ys) as denoising condition. On inference, the ground-truth Ys+1 is not available, and is replaced by its estimate Y\u03020s+1 produced by the denoising process at stage s + 1. By combining the diffusion model and seasonal-trend decomposition in a multi-resolution manner, the proposed model encourages a better modeling of real-world time series."
        },
        {
            "heading": "4.1 EXTRACTING FINE-TO-COARSE TRENDS",
            "text": "For the given time series segment X0 in the lookback window, its trend components are successively extracted by the TrendExtraction module as:\nXs = AvgPool(Padding(Xs\u22121), \u03c4s), s = 1, . . . , S \u2212 1,\nwhere AvgPool is the average pooling operation (Wu et al., 2021), Padding keeps the lengths of Xs\u22121 and Xs the same, and \u03c4s is the smoothing kernel size which increases with s so as to generate fine-to-coarse trends. Processing for the segment Y0 in the forecast window is analogous, and its trend components {Ys}s=1,...,S\u22121 are extracted. Note that while the seasonal-trend decomposition obtains both the seasonal and trend components, the focus here is on the trend. On the other hand, models such as the Autoformer (Wu et al., 2021) and Fedformer (Zhou et al., 2022b) focus on progressively decomposing the seasonal component. As we use the diffusion model for time series reconstruction at various stages/resolutions (Section 4.2), intuitively, it is easier to predict a finer trend from a coarser trend. On the other hand, reconstruction of a finer seasonal component from a coarser seasonal component may be difficult, especially as the seasonal component may not present clear patterns."
        },
        {
            "heading": "4.2 TEMPORAL MULTI-RESOLUTION RECONSTRUCTION",
            "text": "In each stage s+ 1, we use a conditional diffusion model to reconstruct the future trend Ys extracted in Section 4.1. As in the standard diffusion model, it consists of a forward diffusion process and a backward denoising process. Forward diffusion does not involve learnable parameters, while the training procedure of the backward denoising process needs optimization as shown in Algorithm 1.\nAn d\u2032-dimensional embedding pk of the diffusion step k is used in both the forward and backward denoising processes. As in (Rasul et al., 2021; Tashiro et al., 2021; Kong et al., 2020), this is obtained by first taking the sinusoidal position embedding (Vaswani et al., 2017): kembedding =[ sin(10 0\u00d74 w\u22121 t), . . . , sin(10 w\u00d74 w\u22121 t), cos(10 0\u00d74 w\u22121 t), . . . , cos(10 w\u00d74 w\u22121 t) ] where w = d \u2032\n2 , and then passing it through two fully-connected (FC) layers to obtain\npk = SiLU(FC(SiLU(FC(kembedding)))), (7)\nwhere SiLU is the sigmoid-weighted linear unit (Elfwing et al., 2017). By default, d\u2032 is set to 128."
        },
        {
            "heading": "4.2.1 FORWARD DIFFUSION",
            "text": "Forward diffusion is straightforward. Analogous to (1), with Y0s = Ys, we obtain at step k,\nYks = \u221a \u03b1\u0304kY 0 s + \u221a 1\u2212 \u03b1\u0304k\u03f5, k = 1, . . . ,K, (8)\nwhere the noise matrix \u03f5 is sampled from N (0, I) with the same sizes as Ys."
        },
        {
            "heading": "4.2.2 BACKWARD DENOISING",
            "text": "Standard diffusion models perform one-stage denoising directly from random vectors. In this section, we decompose the denoising objective of mr-Diff, into S sub-objectives, one for each stage. As will be seen, this encourages the denoising process to proceed in an easy-to-hard manner, such that the coarser trends are generated first and the finer details are then progressively added.\nConditioning network. The conditioning network (Figure 3, top) constructs a condition to guide the denoising network (to be discussed). Existing time series diffusion models (Rasul et al., 2021; Tashiro et al., 2021) simply use the original time series\u2019 lookback segment X0 as condition c in (5). With the proposed multi-resolution seasonal-trend decomposition, we instead use the lookback segment Xs at the same decomposition stage s. This allows better and easier reconstruction, as Xs has the same resolution as Ys to be reconstructed. On the other hand, when X0 is used as in existing time series diffusion models, the denoising network may overfit temporal details at the finer level.\nA linear mapping is applied on Xs to produce a tensor zhistory \u2208 Rd\u00d7H . For better denoising performance, during training we use future-mixup (Shen & Kwok, 2023) to enhance zhistory. It combines zhistory and the (ground-truth) future observation Y0s with mixup (Zhang et al., 2018):\nzmix = m\u2299 zhistory + (1\u2212m)\u2299Y0s , (9) where \u2299 denotes the Hadamard product, and m \u2208 [0, 1)d\u00d7H is a mixing matrix in which each element is randomly sampled from the uniform distribution on [0, 1). Future-mixup is similar to teacher forcing (Williams & Zipser, 1989), which mixes the ground truth with previous prediction output at each decoding step of autoregressive decoding.\nBesides using Xs on training, the coarser trend Ys+1 (= Y0s+1) can provide an overall picture of the finer trend Ys and is thus also useful for conditioning. Hence, zmix in (9) is concatenated with Y0s+1 along the channel dimension to produce the condition cs (a 2d\u00d7H tensor). For s = S (the last stage), there is no coarser trend and cs is simply equal to zmix.\nOn inference, the ground-truth Y0s is no longer available. hence, future-mixup in (9) is not used, and we simply set zmix = zhistory. moreover, the coarser trend Ys+1 is also not available, and we concatenate zmix with the estimate Y\u03020s+1 generated from stage s+ 2 instead.\nDenoising network. Analogous to (6), the denoising process at step k of stage s+ 1 is given by p\u03b8s(Y k\u22121 s |Yks , cs) = N (Yk\u22121s ;\u00b5\u03b8s(Yks , k|cs, \u03c32kI)), k = K, . . . , 1, (10)\nwhere \u03b8s includes all parameters in the conditional network and denoising network at stage s+1, and\n\u00b5\u03b8s(Y k s , k|cs, \u03c32kI)= \u221a \u03b1k(1\u2212\u03b1\u0304k\u22121) 1\u2212\u03b1\u0304k Yks+ \u221a \u03b1\u0304k\u22121\u03b2k 1\u2212\u03b1\u0304k Y\u03b8s(Y k s , k|cs). (11)\nAs in (3), an Y\u03b8s(Y k s , k|cs) is an estimate of Y0s .\nThe denoising network (also shown in Figure 3) outputs Y\u03b8s(Y k s , k|cs) with guidance from the condition cs (output by the conditioning network). Specifically, it first maps Yks to the embedding z\u0304k \u2208 Rd\u2032\u00d7H by an input projection block consisting of several convolutional layers. This z\u0304k, together with the diffusion-step k\u2019s embedding pk \u2208 Rd\u2032 in (7), is fed to an encoder (which is a convolution network) to obtain the representation zk \u2208 Rd\u2032\u2032\u00d7H . Next, we concatenate zk and cs along the variable dimension to form a tensor of size (2d+ d\u2032\u2032)\u00d7H . This is then fed to a decoder, which is also a convolution network, and outputs Y\u03b8s(Y k s , k|cs). Finally, analogous to (4), \u03b8s is obtained by minimizing the folllowing denoising objective\nmin \u03b8s Ls(\u03b8s) = min \u03b8s\nEY0s\u223cq(Ys),\u03f5\u223cN (0,I),k \u2225\u2225Y0s \u2212Y\u03b8s(Yks , k|cs)\u2225\u22252 . (12)\nOn inference, for each s = S, . . . , 1, we start from Y\u0302Ks \u223c N (0, I) (step 9 in Algorithm 2). Based on the data prediction strategy in (11), each denoising step from Y\u0302ks (an estimate of Y k s ) to Y\u0302 k\u22121 s is:\nY\u0302k\u22121s = \u221a \u03b1k(1\u2212\u03b1\u0304k\u22121) 1\u2212\u03b1\u0304k Y\u0302ks+ \u221a \u03b1\u0304k\u22121\u03b2k 1\u2212\u03b1\u0304k Y\u03b8s(Y\u0302 k s , k|cs) + \u03c3k\u03f5, (13)\nwhere \u03f5 \u223c N (0, I) when k > 1, and \u03f5 = 0 otherwise. The pseudocode for the training and inference procedure of the backward denoising process can be found in Appendix A.\nDiscussion. The proposed mr-Diff is related to the Scaleformer (Shabani et al., 2023), which also generates the forecast progressively from the coarser level to the finer ones. However, besides the obvious difference that Scaleformer is based on the transformer while mr-Diff is based on the diffusion model, Scaleformer uses one single forecasting module (a transformer) at all resolutions. However, as the time series patterns at different resolutions may be different, in mr-Diff, each resolution has its own denoising network and is thus more flexible. Moreover, in moving from a lower resolution to a higher resolution during both training and inference, Scaleformer needs linear interpolation and an additional cross-scale normalization mechanism. On the other hand, in mr-Diff, the lower-resolution prediction is fed into the conditioning network as a condition. The conditioning network can learn a more flexible nonlinear mapping to fuse the cross-scale trends. Coherent probabilistic forecasting (Rangapuram et al., 2023) also uses a temporal hierarchy to produce forecasts at multiple resolutions. However, it is more stringent than mr-Diff and requires the model to produce consistent forecasts at all resolutions. As will be shown in Section 5, this enables mr-Diff to have better empirical performance."
        },
        {
            "heading": "5 EXPERIMENTS",
            "text": "In this section, we conduct time series prediction experiments by comparing 22 recent strong prediction models on 9 popular real-world time series datasets. Additionally, we investigate the inference efficiency in Section 5.2. Due to space constraints, detailed introductions about the datasets and selected baselines can be found in Appendix B and Appendix C respectively. Furthermore, we provide further studies on important hyperparameters in the proposed mr-Diff in Appendix F.\nPerformance Measures. For performance evaluation, we use the mean absolute error (MAE) and mean squared error (MSE) averaged over ten randomly sampled trajectories. Because of the lack of space, results on MSE are in Appendix K.\nImplementation Details. We train the proposed model using Adam with a learning rate of 10\u22123. The batch size is 64, and training with early stopping for a maximum of 100 epochs. K = 100 diffusion steps are used, with a linear variance schedule (Rasul et al., 2021) starting from \u03b21 = 10\u22124 to \u03b2K = 10\n\u22121. S = 5 stages are used. The history length (in {96, 192, 336, 720, 1440}) is selected by using the validation set. All experiments are run on an Nvidia RTX A6000 GPU with 48GB memory. More details can be found in Appendix D.\nTable 1: Univariate prediction MAEs on the real-world time series datasets (subscript is the rank). Results of all baselines (except NLinear, SCINet, and N-Hits) are from (Shen & Kwok, 2023).\nNorPool Caiso Traffic Electricity Weather Exchange ETTh1 ETTm1 Wind avg rank\nmr-Diff 0.609(2) 0.212(4) 0.197(2) 0.332(1) 0.032(1) 0.094(1) 0.196(1) 0.149(1) 1.168(2) 1.7\nTimeDiff 0.613(3) 0.209(3) 0.207(3) 0.341(3) 0.035(4) 0.102(7) 0.202(2) 0.154(6) 1.209(5) 4.0 TimeGrad 0.841(23) 0.386(22) 0.894(23) 0.898(23) 0.036(6) 0.155(21) 0.212(8) 0.167(12) 1.239(11) 16.6\nCSDI 0.763(20) 0.282(14) 0.468(20) 0.540(19) 0.037(7) 0.200(23) 0.221(12) 0.170(14) 1.218(7) 15.1 SSSD 0.770(21) 0.263(12) 0.226(6) 0.403(8) 0.041(11) 0.118(16) 0.250(20) 0.169(13) 1.356(22) 14.3\nD3VAE 0.774(22) 0.613(23) 0.237(9) 0.539(18) 0.039(9) 0.107(13) 0.221(12) 0.160(9) 1.321(19) 14.9 CPF 0.710(15) 0.338(18) 0.385(19) 0.592(21) 0.035(4) 0.094(1) 0.221(12) 0.153(5) 1.256(12) 11.9 PSA-GAN 0.623(5) 0.250(8) 0.355(17) 0.373(6) 0.139(22) 0.109(14) 0.225(16) 0.174(16) 1.287(16) 13.3\nN-Hits 0.646(7) 0.276(13) 0.232(7) 0.419(9) 0.033(2) 0.100(5) 0.228(17) 0.157(8) 1.256(12) 8.9 FiLM 0.654(9) 0.290(15) 0.315(14) 0.362(5) 0.069(14) 0.104(10) 0.210(6) 0.149(1) 1.189(3) 8.6 Depts 0.616(4) 0.205(1) 0.241(10) 0.434(12) 0.102(19) 0.106(12) 0.202(2) 0.165(10) 1.472(23) 10.3 NBeats 0.671(10) 0.228(5) 0.225(5) 0.439(13) 0.130(21) 0.096(3) 0.242(18) 0.165(10) 1.236(9) 10.4\nScaleformer 0.687(12) 0.320(16) 0.375(18) 0.430(10) 0.083(17) 0.148(19) 0.302(22) 0.210(22) 1.348(21) 17.4 PatchTST 0.590(1) 0.260(11) 0.269(11) 0.478(17) 0.098(18) 0.111(15) 0.260(21) 0.174(16) 1.338(20) 14.4 FedFormer 0.725(17) 0.254(9) 0.278(12) 0.453(14) 0.057(13) 0.168(22) 0.212(8) 0.195(20) 1.271(14) 14.3 Autoformer 0.755(19) 0.339(19) 0.495(21) 0.623(22) 0.040(10) 0.152(20) 0.220(11) 0.174(16) 1.319(18) 17.3 Pyraformer 0.747(18) 0.257(10) 0.215(4) 0.455(15) 0.107(20) 0.104(10) 0.211(7) 0.179(19) 1.284(15) 13.1 Informer 0.698(13) 0.345(20) 0.308(13) 0.433(11) 0.069(14) 0.118(16) 0.212(8) 0.172(15) 1.236(9) 13.2 Transformer 0.723(16) 0.345(20) 0.336(16) 0.469(16) 0.071(16) 0.103(9) 0.247(19) 0.196(21) 1.212(6) 15.4\nSCINet 0.653(8) 0.244(7) 0.322(15) 0.377(7) 0.037(7) 0.101(6) 0.205(5) 0.150(4) 1.167(1) 6.7 NLinear 0.637(6) 0.238(6) 0.192(1) 0.334(2) 0.033(2) 0.097(4) 0.203(4) 0.149(1) 1.197(4) 3.3 DLinear 0.671(10) 0.206(2) 0.236(8) 0.348(4) 0.310(23) 0.102(7) 0.222(15) 0.155(7) 1.221(8) 9.3 LSTMa 0.707(14) 0.333(17) 0.757(22) 0.557(20) 0.053(12) 0.136(18) 0.332(23) 0.239(23) 1.298(17) 18.4"
        },
        {
            "heading": "5.1 MAIN RESULTS",
            "text": "Table 1 shows the MAEs on the univariate time series. As can be seen, the proposed mr-Diff is the best in 5 of the 9 datasets. The improvement is particularly significant on the more complicated datasets, such as Exchange and ETTh1. On the remaining 4 datasets, mr-Diff ranks second in 3 of them. Overall, its average ranking is better than all other baselines (which include the most recent diffusion models). Note that there is no improvement on datasets such as Caiso. This is because there is no complex trend information on this dataset that can be leveraged (as shown in Figure 5 (b) in Appendix B).\nFigure 4 shows example prediction results on ETTh1 by mr-Diff and three competitive models: SCINet, NLinear and the recent diffusion model TimeDiff. As can be seen, mr-Diff produces higher-quality predictions than the others.\n(a) SCINet. (b) NLinear. (c) TimeDiff. (d) mr-Diff.\nFigure 4: Visualizations on ETTh1 by (a) SCINet (Liu et al., 2022), (b) NLinear (Zeng et al., 2023), (c) TimeDiff (Shen & Kwok, 2023) and (d) the proposed mr-Diff.\nTable 2 shows the MAEs on the multivariate time series. Baselines N-Hits, FiLM and SCINet have strong performance because they also leverage multiresolution information in prediction. However, the proposed mr-Diff is still very competitive compared to these strong baselines. It ranks among the top-2 methods on 5 of the 9 datasets, and is the best overall. This is then followed by the recent diffusion-based model TimeDiff."
        },
        {
            "heading": "5.2 INFERENCE EFFICIENCY",
            "text": "In this experiment, we compare the inference efficiency of mr-Diff (with 1-4 stages) with the other time series diffusion model baselines (TimeDiff, TimeGrad, CSDI, SSSD) on the univariate ETTh1 dataset. Besides using a prediction horizon of H = 168 as in the previous experiment, we also use\nH = 96, 192, 336 and 720 as in (Wu et al., 2021; Zhou et al., 2022b). Table 3 shows the inference time. As can be seen, mr-Diff (even with S = 3 or 4 stages) is more efficient than SSSD, CSDI, and TimeGrad. When S = 3 (the setting used in the previous experiments), mr-Diff is even faster than TimeDiff. The inference efficiency of mr-Diff over existing diffusion models is due to: (i) it is non-autoregressive, which avoids autoregressive decoding in each time step as in TimeGrad (Rasul et al., 2021). (ii) it uses convolution layers. This avoids the scaling problem in CSDI (Tashiro et al., 2021) whose complexity is quadratic with the number of variables and time series length. (iii) use of the acceleration technique DPM-Solver (Lu et al., 2022), which further reduces the number of denoising steps in each stage."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "In this paper, we propose the mutli-resolution diffusion model mr-Diff. Different from the existing time series diffusion model, mr-Diff incorporates seasonal-trend decomposition and uses multiple temporal resolutions in both the diffusion and denoising processes. By progressively denoising the time series in a coarse-to-fine manner, mr-Diff is able to produce more reliable predictions. Experiments on a number of real-world univariate and multivariate time series datasets show that mr-Diff outperforms the state-of-the-art time series diffusion models. It also achieves very competitive performance even when compared to various different families of non-diffusionbased time series prediction models."
        },
        {
            "heading": "A PSEUDOCODE",
            "text": "Algorithm 1 Training procedure of the backward denoising process 1: repeat 2: (X0,Y0) \u223c q(X,Y) 3: {Xs}s=1,...,S\u22121 = TrendExtraction(X0) 4: {Ys}s=1,...,S\u22121 = TrendExtraction(Y0) 5: for s = S \u2212 1, . . . , 0 do 6: k \u223c Uniform({1, 2, . . . ,K}) 7: \u03f5 \u223c N (0, I) 8: Generate diffused sample Yks by Yks = \u221a \u03b1\u0304kY 0 s+ \u221a 1\u2212 \u03b1\u0304k\u03f5\n9: Obtain diffusion step k\u2019s embedding pk using (7) 10: Randomly generate a matrix m in (9) 11: Obtain zhistory using linear mapping on Xs 12: Obtain zmix using (9) 13: if s < S \u2212 1 then 14: Obtain condition cs by concatenating zhistory and Y0s+1 15: else 16: Obtain condition cs = zhistory 17: end if 18: Calculate the loss Lks (\u03b8s) in (12) 19: Take a gradient descent step based on \u2207\u03b8sLk(\u03b8s) 20: end for 21: until converged\nAlgorithm 2 Inference procedure 1: {Xs}s=1,...,S\u22121 = TrendExtraction(X0) 2: for s = S \u2212 1, . . . , 0 do 3: Obtain zhistory using linear mapping on Xs 4: if s < S \u2212 1 then 5: Obtain condition cs by concatenating zhistory and Y0s+1 6: else 7: Obtain condition cs = zhistory 8: end if 9: Initialization: Y\u0302Ks \u223c N (0, I) 10: for k = K, . . . , 1 do 11: \u03f5 \u223c N (0, I), if k > 1, else \u03f5 = 0 12: Obtain diffusion step k\u2019s embedding pk using (7) 13: Obtain the denoised output Y\u0302k\u22121s by (13) 14: end for 15: end for 16: return Y\u030200"
        },
        {
            "heading": "B DATASET INFORMATION",
            "text": "Experiments are performed on nine commonly-used real-world time series datasets (Zhou et al., 2021; Wu et al., 2021; Fan et al., 2022): (i) NorPool, which includes eight years of hourly energy production volume series in multiple European countries; (ii) Caiso, which contains eight years of hourly actual electricity load series in different zones of California; (iii) Traffic, which records the hourly road occupancy rates generated by sensors in the San Francisco Bay area freeways; (iv) Electricity, which includes the hourly electricity consumption of 321 clients over two years; (v) Weather, which records 21 meteorological indicators at 10-minute intervals from 2020 to 2021; (vi) Exchange (Lai et al., 2018), which describes the daily exchange rates of eight countries (Australia, British, Canada, Switzerland, China, Japan, New Zealand, and Singapore); (vii)-(viii) ETTh1 and ETTm1, which contain two years of electricity transformer temperature data (Zhou et al., 2021) collected in China, at 1-hour and 15-minute intervals, respectively; (ix) Wind, which contains wind power records from 2020-2021 at 15-minute intervals (Li et al., 2022). Table 4 shows the dataset information. As different datasets have different sampling interval lengths, we follow (Shen & Kwok, 2023) and consider prediction tasks with more reasonable prediction lengths.\nWe use the following publicly available datasets, and they are from the following links: i) NorPool: https://www.nordpoolgroup.com/Market-data1/Power-system-data\nii) Caiso: http://www.energyonline.com/Data\niii) Traffic: http://pems.dot.ca.gov iv) Electricity: https://archive.ics.uci.edu/ ml/datasets/ElectricityLoadDiagrams20112014\nv) Weather: https://www.bgc-jena.mpg.de/wetter/\nvi) Exchange: https://github.com/laiguokun/multivariate-time-series-data\nvii) ETTh1 and ETTm1: https://github.com/zhouhaoyi/ETDataset\nviii) Wind: https://github.com/PaddlePaddle/PaddleSpatial/tree/main/ paddlespatial/datasets/WindPower\nBesides running directly on these multivariate datasets, we also convert them to univariate time series for performance comparison. For NorPool and Caiso, the univariate time series are extracted from all variables as in (Fan et al., 2022). For the other datasets, we follow (Wu et al., 2021; Zhou et al., 2021) and extract the univariate time series by using the last variable only.\nFigure 5 shows examples of the time series data used in the experiments. Since all of them are multivariate, we only show the last variate. As can be seen, these datasets are representative in exhibiting various temporal characteristics (different stationary states, periodicities, and sampling rates). For example, Electricity contains obvious periodic patterns, while ETTh1 and ETTm1 exhibit non-stationary trends.\nReal-world time series often have irregular dynamics over time or across variables. As in many deep time series models (Kim et al., 2021; Zhou et al., 2022a; Liu et al., 2022; Zeng et al., 2023), it is often useful to normalize the scales of the time series in each window. In the proposed method, we use instance normalization, which has also been used in RevIN (Kim et al., 2021) (which is referred to as reversible instance normalization) and FiLM (Zhou et al., 2022a). Specifically, we subtract the time series value in each window by its lookback window mean, and then divide by the lookback window\u2019s standard deviation. During inference, the mean and standard deviation are added back to the prediction."
        },
        {
            "heading": "C BASELINE IN THE MAIN EXPERIMENTS.",
            "text": "We compare with several types of baselines, including: (i) recent time series diffusion models: non-autoregressive diffusion model TimeDiff (Shen & Kwok, 2023), TimeGrad (Rasul et al., 2021), conditional score-based diffusion model for imputation (CSDI) (Tashiro et al., 2021), structured state space model-based diffusion (SSSD) (Alcaraz & Strodthoff, 2022); (ii) recent generative models for time series prediction: variational autoencoder with diffusion, denoise and disentanglement (D3VAE) (Li et al., 2022), coherent probabilistic forecasting (CPF) (Rangapuram et al., 2023), and PSA-GAN (Jeha et al., 2022); (iii) recent prediction models based on basis expansion: NHits (Challu et al., 2023), frequency improved Legendre memory model (FiLM) (Zhou et al., 2022a), Depts (Fan et al., 2022) and NBeats (Oreshkin et al., 2019); (iv) time series transformers:\nScaleformer (Shabani et al., 2023), PatchTST (Nie et al., 2022), Fedformer (Zhou et al., 2022b), Autoformer (Wu et al., 2021), Pyraformer (Liu et al., 2021), Informer (Zhou et al., 2021) and the standard Transformer (Vaswani et al., 2017); and (v) other competitive baselines: SCINet (Liu et al., 2022) that introduces sample convolution and interaction for time series prediction, NLinear (Zeng et al., 2023), DLinear (Zeng et al., 2023) LSTMa (Bahdanau et al., 2015), and an attention-based LSTM (Hochreiter & Schmidhuber, 1997). We do not compare with (Yu et al., 2021; Niu et al., 2022; Madhusudhanan et al., 2021) because their codes are not publicly available."
        },
        {
            "heading": "D MORE IMPLEMENTATION DETAILS.",
            "text": "In the proposed mr-Diff, the conditioning network, the denoising network\u2019s encoder/decoder are built by stacking a number of convolutional blocks. The default configuration of each convolutional block is shown in Table 5.\nThe number of S is selected from {2, 3, 4, 5} (the number of stages is greater than the number of decompositions by 1). When S = 2, the kernel size \u03c41 is selected from {5, 25}; When S = 3, the kernel size (\u03c41, \u03c42) is selected from {(5, 25), (25, 51), (51, 201)}; When S = 4, the kernel size (\u03c41, \u03c42, \u03c43) is selected from {(5, 25, 51), (25, 51, 201)}. When S = 5, the kernel size (\u03c41, \u03c42, \u03c43, \u03c44) is selected from {(5, 25, 51, 201)}. In practice, we run a grid search over S for each dataset. This is not expensive, as the number of choices is small (as can be seen from above). Usually, S = 2 and the combinations (5,25) and (25,51) can achieve promising performance.\nE DETAILS OF MR-DIFF VARIANTS\nFigure 6 illustrates the architecture of the mr-Diff Variant without seasonal-trend decomposition blocks (in the case of direct denoising from random vectors and S = 1).\nforecast window\nlookback window\nY0\nX0\nc0 denoising network\nYk0\nrandom noise\ninference only\ntraining only\nfinal prediction L0 Y\u030200\u0302\nconditioning network\nforward diffusion\nFigure 6: The baseline without seasonal-trend decomposition blocks.\nFigure 7 shows the mr-Diff Variant of replacing the trend component from seasonal-trend decompsition by down-sampling."
        },
        {
            "heading": "F ABLATION STUDIES",
            "text": "In this section, we perform a number of ablation experiments on mr-Diff using the Electricity, ETTh1 and ETTm1 datasets. These datasets are representative in exhibiting various temporal characteristics (different stationary states, periodicities, and sampling rates). For example, Electricity contains obvious periodic patterns, while ETTh1 and ETTm1 exhibit non-stationary trends.\nLength of lookback window L. Table 6 shows the prediction MAE of mr-Diff with different lengths (L) of the lookback window. We consider L = {96, 192, 336, 720, 1440} as used in (Shen & Kwok, 2023; Zeng et al., 2023; Wu et al., 2021). As can be seen, on Electricity, ETTh1 and ETTm1 (corresponding to 168/168/192-step-ahead prediction, respectively), good performance can be obtained when L is 336 or above.\nNumber of stages S. In this experiment, we vary the number of stages S. The kernel size \u03c4s is set to increase with the stage number s, so as to generate fine-to-coarse trends. We also compare with a variant that does not perform seasonal-trend decomposition. This variant directly generates the forecast window from a random noise vector without using the coarser trend Y0s+1. The resultant simplified model is shown in Figure 6 in Appendix E. Table 8 shows the prediction errors. As can be seen, using multiple stages improves performance, and not using the seasonal-trend decomposition"
        },
        {
            "heading": "96 0.449 0.210 0.165",
            "text": ""
        },
        {
            "heading": "50 0.348 0.199 0.151",
            "text": "leads to the worst performance. However, using a large number of stages is usually not necessary, as the performance improvement becomes marginal and the training time gets longer.\nSeasonal-trend decompsition versus downsampling/upsampling. In this experiment, we replace the trend component from seasonal-trend decompsition by downsampling. Using three stages as in previous experiments, the downsampled time series segments have lengths that are 75%, 50%, 25% of the original time series, respectively. Similarly, the coarser estimation Y\u03020s at stage s + 1\nis upsampled by linear interpolation back to the same size as Y0s before feeding into stage s. The resultant model is shown in Figure 7 of Appendix E.\nResults are shown in Table 9. As can be seen, this variant has inferior performance. We speculate that this is because downsampling can only obtain uniformly-spaced samples, while the trend component from seasonal-trend decompsition can better preserve the shape of the time series segment.\nNumber of diffusion steps K. Table 7 shows the prediction error of mr-Diff with K, the number of diffusion steps. As can be seen, setting K = 100 leads to stable performance across all four datasets. This also agrees with (Li et al., 2022) in that a small K may lead to incomplete diffusion, while a K too large may involve unncessary computations.\nGaussian noise variance \u03b2k. Recall from Section 5 that \u03b2k is generated by a linear variance schedule (Rasul et al., 2021). In this experiment, we vary \u03b2K in {0.001,0.01,0.1,0.9}, with \u03b21 fixed to 10\u22124. As can be seen from table 10, setting \u03b2K = 0.1 always has the best performance. Li et al. (2022) has a similar conclusion that a \u03b2K too small can lead to a unsatisfactory diffusion, while a \u03b2K too large can make the diffusion out of control.\nFuture mixup. Recall that each element of the future mixup matrix m in (9) is randomly sampled from the uniform distribution on [0; 1). In this experiment, we study the effect of m by sampling each of its elements from the Beta distribution Beta(\u03b3, \u03b3) where \u03b3 \u2208 {0.1, 1, 2}. Note that Beta(1, 1) reduces to the uniform distribution. Also, we include a mr-Diff variant that does not use future mixup (by replacing (9) with zmix = zhistory). Table 11 shows the prediction results. As can be seen, the uniform distribution (with \u03b3 = 1) as used in mr-Diff has the best performance."
        },
        {
            "heading": "G EXPERIMENTS ON MULTISCALE LORENZ-96 TIME SERIES",
            "text": "In this section, we conduct experiments on synthetic time series data generated by a multi-scale Lorenz 96 system. The precise equation of the system is given by\ndXk dt = Xk\u22121 (Xk+1 \u2212Xk\u22122) + F \u2212 hc b \u03a3jYj,k, (14)\ndYj,k dt = \u2212cbYj+1,k (Yj+2,k \u2212 Yj\u22121,k)\u2212 cYj,k + hc b Xk \u2212 he d \u03a3iZi,j,k, (15)\ndZi,j,k dt = edZi\u22121,j,k (Zi+1,j,k \u2212 Zi\u22122,j,k)\u2212 geZi,j,k + he d Yj,k. (16)\nFollowing (Chattopadhyay et al., 2020), the values of the parameters are set as follows: F = 20, b = c = e = d = g = 10, and h = 1. F is a large-scale forcing that makes the system highly chaotic. Additionally, other parameters are adjusted to generate suitable spatio-temporal variability in the three variables. The indices i, j, k range from 1 to 8, resulting in X having 8 dimensions, while Y and Z have 64 and 512 dimensions, respectively. We utilize the time series data of variable X for evaluation.\nTable 12 summarizes results for different horizons (H in {24, 96, 168, 336, 720}). As can be seen, mr-Diff consistently outperforms other baselines across different values of H ."
        },
        {
            "heading": "H EXPERIMENTS ON MONASH DATASETS",
            "text": "In the main experiments, we tested the proposed model in nine real-world datasets that exhibit diverse temporal characteristics (such as different stationary states, periodicities, and sampling rates). Apart from these nine commonly used datasets, we further consider 12 datasets from the Monash benchmark. Table 13 shows the prediction results. As can be seen, mr-Diff continues to outperform other baselines. It achieves the best results in 10 out of the 12 datasets, and the second-best in the remaining 2 datasets."
        },
        {
            "heading": "I ERROR BARS EVALUATION",
            "text": "Since deep models for time series forecasting may be influenced by different random initializations,\nTable 14-15 show results on 5 random runs. As can be seen, the largest standard deviation is 0.0042 indicating that the proposed model is robust towards different initializations."
        },
        {
            "heading": "J TRAINING EFFICIENCY",
            "text": "In Section 5.2, we have discussed the inference efficiency. In this section, we further compare the number of trainable parameters and the training efficiency of mr-Diff with the other time series diffusion model baselines (TimeDiff, TimeGrad, CSDI, SSSD) on the univariate ETTh1 dataset.\nAs can be seen, the number of trainable parameters is smaller than those of TimeGrad, CSDI and SSSD. This is because mr-Diff uses convolution layers in its denoising networks, which eliminates the need for large modules like residual blocks (in TimeGrad and SSSD) and self-attention layers (in CSDI). Moreover, it is also faster than TimeDiff, thanks to its use of a linear mapping for future mixup instead of employing additional deep layers for this purpose."
        },
        {
            "heading": "K SUPPLEMENTARY OF MAIN RESULTS",
            "text": "Tables 17 and 18 show the MSE results on the univariate and multivarate time series, respectively."
        }
    ],
    "year": 2023
}