{
    "abstractText": "Generative models trained on internet data are capable of generating novel texts and images. A natural question is whether these models can advance science (e.g., generate novel stable materials). Traditionally, models with explicit structures (e.g., graphs) have been used in modeling structural relationships (e.g., atoms and bonds in crystals), but have faced challenges scaling to large and complex systems. Another challenge in generating materials is the mismatch between standard generative modeling metrics and downstream applications. For instance, common metrics such as the reconstruction error do not correlate well with the downstream goal of discovering novel stable materials. In this work, we tackle the scalability challenge by developing a unified crystal representation that can represent any crystal structure (UniMat), followed by training a diffusion probabilistic model on the UniMat representations. Despite the lack of explicit structure modeling, UniMat can generate high fidelity crystals from larger and more complex chemical systems, outperforming previous approaches. To better connect generation quality to downstream applications, we propose additional metrics for evaluating generative models of materials, including per-composition formation energy and stability with respect to convex hulls from Density Function Theory (DFT). Lastly, we show that conditional generation with UniMat can scale to up to millions of crystal structures, outperforming random structure search (the current leading method) in discovering new stable materials.",
    "authors": [],
    "id": "SP:67d5b22f7f2a2c268a9b087bf9e4716ddc2f3898",
    "references": [
        {
            "authors": [
                "Rohan Anil",
                "Andrew M Dai",
                "Orhan Firat",
                "Melvin Johnson",
                "Dmitry Lepikhin",
                "Alexandre Passos",
                "Siamak Shakeri",
                "Emanuel Taropa",
                "Paige Bailey",
                "Zhifeng Chen"
            ],
            "title": "Palm 2 technical report",
            "venue": "arXiv preprint arXiv:2305.10403,",
            "year": 2023
        },
        {
            "authors": [
                "Luis M Antunes",
                "Keith T Butler",
                "Ricardo Grau-Crespo"
            ],
            "title": "Crystal structure generation with autoregressive large language modeling",
            "venue": "arXiv preprint arXiv:2307.04340,",
            "year": 2023
        },
        {
            "authors": [
                "Jacob Austin",
                "Daniel D Johnson",
                "Jonathan Ho",
                "Daniel Tarlow",
                "Rianne Van Den Berg"
            ],
            "title": "Structured denoising diffusion models in discrete state-spaces",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Christopher J Bartel"
            ],
            "title": "Review of computational approaches to predict the thermodynamic stability of inorganic solids",
            "venue": "Journal of Materials Science,",
            "year": 2022
        },
        {
            "authors": [
                "Christopher J Bartel",
                "Amalie Trewartha",
                "Qi Wang",
                "Alexander Dunn",
                "Anubhav Jain",
                "Gerbrand Ceder"
            ],
            "title": "A critical examination of compound stability predictions from machine-learned formation",
            "venue": "energies. npj computational materials,",
            "year": 2020
        },
        {
            "authors": [
                "Simon Batzner",
                "Albert Musaelian",
                "Lixin Sun",
                "Mario Geiger",
                "Jonathan P Mailoa",
                "Mordechai Kornbluth",
                "Nicola Molinari",
                "Tess E Smidt",
                "Boris"
            ],
            "title": "Kozinsky. E (3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials",
            "venue": "Nature communications,",
            "year": 2022
        },
        {
            "authors": [
                "J George Bednorz",
                "K Alex M\u00fcller"
            ],
            "title": "Possible high t c superconductivity in the ba- la- cu- o system",
            "venue": "Zeitschrift fu\u0308r Physik B Condensed Matter,",
            "year": 1986
        },
        {
            "authors": [
                "Peter E Bl\u00f6chl"
            ],
            "title": "Projector augmented-wave method",
            "venue": "Physical review B,",
            "year": 1994
        },
        {
            "authors": [
                "Gowoon Cheon",
                "Lusann Yang",
                "Kevin McCloskey",
                "Evan J Reed",
                "Ekin D Cubuk"
            ],
            "title": "Crystal structure search with random relaxations using graph networks",
            "venue": "arXiv preprint arXiv:2012.02920,",
            "year": 2020
        },
        {
            "authors": [
                "Hitarth Choubisa",
                "Mikhail Askerka",
                "Kevin Ryczko",
                "Oleksandr Voznyy",
                "Kyle Mills",
                "Isaac Tamblyn",
                "Edward H Sargent"
            ],
            "title": "Crystal site feature embedding enables exploration of large chemical spaces",
            "year": 2020
        },
        {
            "authors": [
                "\u00d6zg\u00fcn \u00c7i\u00e7ek",
                "Ahmed Abdulkadir",
                "Soeren S Lienkamp",
                "Thomas Brox",
                "Olaf Ronneberger"
            ],
            "title": "3d u-net: learning dense volumetric segmentation from sparse annotation",
            "venue": "19th International Conference,",
            "year": 2016
        },
        {
            "authors": [
                "Callum J Court",
                "Batuhan Yildirim",
                "Apoorv Jain",
                "Jacqueline M Cole"
            ],
            "title": "3-d inorganic crystal structure generation and property prediction via representation learning",
            "venue": "Journal of Chemical Information and Modeling,",
            "year": 2020
        },
        {
            "authors": [
                "Yabo Dan",
                "Yong Zhao",
                "Xiang Li",
                "Shaobo Li",
                "Ming Hu",
                "Jianjun Hu"
            ],
            "title": "Generative adversarial networks (gan) based efficient sampling of chemical composition space for inverse design of inorganic materials",
            "venue": "npj Computational Materials,",
            "year": 2020
        },
        {
            "authors": [
                "Daniel W Davies",
                "Keith T Butler",
                "Adam J Jackson",
                "Jonathan M Skelton",
                "Kazuki Morita",
                "Aron Walsh"
            ],
            "title": "Smact: Semiconducting materials by analogy and chemical theory",
            "venue": "Journal of Open Source Software,",
            "year": 2019
        },
        {
            "authors": [
                "Prafulla Dhariwal",
                "Alexander Nichol"
            ],
            "title": "Diffusion models beat gans on image synthesis",
            "venue": "Advances in neural information processing systems,",
            "year": 2021
        },
        {
            "authors": [
                "Daniel Flam-Shepherd",
                "Al\u00e1n Aspuru-Guzik"
            ],
            "title": "Language models can generate molecules, materials, and protein binding sites directly in three dimensions as xyz, cif, and pdb files",
            "venue": "arXiv preprint arXiv:2305.05708,",
            "year": 2023
        },
        {
            "authors": [
                "Octavian Ganea",
                "Lagnajit Pattanaik",
                "Connor Coley",
                "Regina Barzilay",
                "Klavs Jensen",
                "William Green",
                "Tommi Jaakkola"
            ],
            "title": "Geomol: Torsional geometric generation of molecular 3d conformer ensembles",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Francesco Giuliari",
                "Gianluca Scarpellini",
                "Stuart James",
                "Yiming Wang",
                "Alessio Del Bue"
            ],
            "title": "Positional diffusion: Ordering unordered sets with diffusion probabilistic models",
            "venue": "arXiv preprint arXiv:2303.11120,",
            "year": 2023
        },
        {
            "authors": [
                "Martin A Green",
                "Anita Ho-Baillie",
                "Henry J Snaith"
            ],
            "title": "The emergence of perovskite solar cells",
            "venue": "Nature photonics,",
            "year": 2014
        },
        {
            "authors": [
                "J\u00fcrgen Hafner"
            ],
            "title": "Ab-initio simulations of materials using vasp: Density-functional theory and beyond",
            "venue": "Journal of computational chemistry,",
            "year": 2008
        },
        {
            "authors": [
                "Paul Z Hanakata",
                "Ekin D Cubuk",
                "David K Campbell",
                "Harold S Park"
            ],
            "title": "Forward and inverse design of kirigami via supervised autoencoder",
            "venue": "Physical Review Research,",
            "year": 2006
        },
        {
            "authors": [
                "Jonathan Ho",
                "Tim Salimans"
            ],
            "title": "Classifier-free diffusion guidance",
            "venue": "arXiv preprint arXiv:2207.12598,",
            "year": 2022
        },
        {
            "authors": [
                "Jonathan Ho",
                "Ajay Jain",
                "Pieter Abbeel"
            ],
            "title": "Denoising diffusion probabilistic models",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Jonathan Ho",
                "William Chan",
                "Chitwan Saharia",
                "Jay Whang",
                "Ruiqi Gao",
                "Alexey Gritsenko",
                "Diederik P Kingma",
                "Ben Poole",
                "Mohammad Norouzi",
                "David J Fleet"
            ],
            "title": "Imagen video: High definition video generation with diffusion models",
            "venue": "arXiv preprint arXiv:2210.02303,",
            "year": 2022
        },
        {
            "authors": [
                "Jonathan Ho",
                "Tim Salimans",
                "Alexey Gritsenko",
                "William Chan",
                "Mohammad Norouzi",
                "David J. Fleet"
            ],
            "title": "Video diffusion models, 2022b",
            "year": 2022
        },
        {
            "authors": [
                "Jordan Hoffmann",
                "Louis Maestrati",
                "Yoshihide Sawada",
                "Jian Tang",
                "Jean Michel Sellier",
                "Yoshua Bengio"
            ],
            "title": "Data-driven approach to encoding and decoding 3-d crystal structures",
            "year": 1909
        },
        {
            "authors": [
                "Pierre Hohenberg",
                "Walter Kohn"
            ],
            "title": "Inhomogeneous electron gas",
            "venue": "Physical review,",
            "year": 1964
        },
        {
            "authors": [
                "Anubhav Jain",
                "Shyue Ping Ong",
                "Geoffroy Hautier",
                "Wei Chen",
                "William Davidson Richards",
                "Stephen Dacek",
                "Shreyas Cholia",
                "Dan Gunter",
                "David Skinner",
                "Gerbrand Ceder"
            ],
            "title": "Commentary: The materials project: A materials genome approach to accelerating materials innovation",
            "venue": "APL materials,",
            "year": 2013
        },
        {
            "authors": [
                "Jaehyeong Jo",
                "Seul Lee",
                "Sung Ju Hwang"
            ],
            "title": "Score-based generative modeling of graphs via the system of stochastic differential equations",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Sungwon Kim",
                "Juhwan Noh",
                "Geun Ho Gu",
                "Alan Aspuru-Guzik",
                "Yousung Jung"
            ],
            "title": "Generative adversarial networks for crystal structure prediction",
            "venue": "ACS central science,",
            "year": 2020
        },
        {
            "authors": [
                "Diederik Kingma",
                "Tim Salimans",
                "Ben Poole",
                "Jonathan Ho"
            ],
            "title": "Variational diffusion models",
            "venue": "Advances in neural information processing systems,",
            "year": 2021
        },
        {
            "authors": [
                "Vadim Korolev",
                "Artem Mitrofanov",
                "Artem Eliseev",
                "Valery Tkachenko"
            ],
            "title": "Machine-learningassisted search for functional materials over extended chemical space",
            "venue": "Materials Horizons,",
            "year": 2020
        },
        {
            "authors": [
                "Georg Kresse",
                "J\u00fcrgen Furthm\u00fcller"
            ],
            "title": "Efficiency of ab-initio total energy calculations for metals and semiconductors using a plane-wave basis set",
            "venue": "Computational materials science,",
            "year": 1996
        },
        {
            "authors": [
                "Georg Kresse",
                "J\u00fcrgen Furthm\u00fcller"
            ],
            "title": "Efficient iterative schemes for ab initio total-energy calculations using a plane-wave basis set",
            "venue": "Physical review B,",
            "year": 1996
        },
        {
            "authors": [
                "Georg Kresse",
                "Daniel Joubert"
            ],
            "title": "From ultrasoft pseudopotentials to the projector augmented-wave method",
            "venue": "Physical review b,",
            "year": 1999
        },
        {
            "authors": [
                "Teng Long",
                "Nuno M Fortunato",
                "Ingo Opahle",
                "Yixuan Zhang",
                "Ilias Samathrakis",
                "Chen Shen",
                "Oliver Gutfleisch",
                "Hongbin Zhang"
            ],
            "title": "Constrained crystals deep convolutional generative adversarial network for the inverse design of crystal structures",
            "venue": "npj Computational Materials,",
            "year": 2021
        },
        {
            "authors": [
                "James Lucas",
                "George Tucker",
                "Roger Grosse",
                "Mohammad Norouzi"
            ],
            "title": "Understanding posterior collapse in generative latent variable models",
            "year": 2019
        },
        {
            "authors": [
                "Shitong Luo",
                "Wei Hu"
            ],
            "title": "Diffusion probabilistic models for 3d point cloud generation",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Zhaoyang Lyu",
                "Zhifeng Kong",
                "Xudong Xu",
                "Liang Pan",
                "Dahua Lin"
            ],
            "title": "A conditional point diffusion-refinement paradigm for 3d point cloud completion",
            "venue": "arXiv preprint arXiv:2112.03530,",
            "year": 2021
        },
        {
            "authors": [
                "Kiran Mathew",
                "Joseph H Montoya",
                "Alireza Faghaninia",
                "Shyam Dwarakanath",
                "Muratahan Aykol",
                "Hanmei Tang",
                "Iek-heng Chu",
                "Tess Smidt",
                "Brandon Bocklund",
                "Matthew Horton"
            ],
            "title": "Atomate: A high-level interface to generate, execute, and analyze computational materials science workflows",
            "venue": "Computational Materials Science,",
            "year": 2017
        },
        {
            "authors": [
                "Amil Merchant",
                "Simon Batzner",
                "Samuel S. Schoenholz",
                "Muratahan Aykol",
                "Gowoon Cheon",
                "Ekin Dogus Cubuk"
            ],
            "title": "Scaling deep learning for materials",
            "year": 2023
        },
        {
            "authors": [
                "KJPC Mizushima",
                "PC Jones",
                "PJ Wiseman",
                "John B Goodenough"
            ],
            "title": "x\u00a1-1): A new cathode material for batteries of high energy density",
            "venue": "Materials Research Bulletin,",
            "year": 1980
        },
        {
            "authors": [
                "Koichi Momma",
                "Fujio Izumi"
            ],
            "title": "Vesta 3 for three-dimensional visualization of crystal, volumetric and morphology data",
            "venue": "Journal of applied crystallography,",
            "year": 2011
        },
        {
            "authors": [
                "Shuji Nakamura"
            ],
            "title": "The roles of structural imperfections in ingan-based blue light-emitting diodes and laser",
            "venue": "diodes. Science,",
            "year": 1998
        },
        {
            "authors": [
                "J\u00f6rg Neugebauer",
                "Tilmann Hickel"
            ],
            "title": "Density functional theory in materials science",
            "venue": "Wiley Interdisciplinary Reviews: Computational Molecular Science,",
            "year": 2013
        },
        {
            "authors": [
                "Chenhao Niu",
                "Yang Song",
                "Jiaming Song",
                "Shengjia Zhao",
                "Aditya Grover",
                "Stefano Ermon"
            ],
            "title": "Permutation invariant graph generation via score-based generative modeling",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2020
        },
        {
            "authors": [
                "Juhwan Noh",
                "Jaehoon Kim",
                "Helge S Stein",
                "Benjamin Sanchez-Lengeling",
                "John M Gregoire",
                "Alan Aspuru-Guzik",
                "Yousung Jung"
            ],
            "title": "Inverse design of solid-state materials via a continuous representation",
            "year": 2019
        },
        {
            "authors": [
                "Jens Kehlet N\u00f8rskov",
                "Thomas Bligaard",
                "Jan Rossmeisl",
                "Claus Hviid Christensen"
            ],
            "title": "Towards the computational design of solid catalysts",
            "venue": "Nature chemistry,",
            "year": 2009
        },
        {
            "authors": [
                "Asma Nouira",
                "Nataliya Sokolovska",
                "Jean-Claude Crivello"
            ],
            "title": "Crystalgan: learning to discover crystallographic structures with generative adversarial networks",
            "venue": "arXiv preprint arXiv:1810.11203,",
            "year": 2018
        },
        {
            "authors": [
                "Shyue Ping Ong",
                "William Davidson Richards",
                "Anubhav Jain",
                "Geoffroy Hautier",
                "Michael Kocher",
                "Shreyas Cholia",
                "Dan Gunter",
                "Vincent L Chevrier",
                "Kristin A Persson",
                "Gerbrand Ceder"
            ],
            "title": "Python materials genomics (pymatgen): A robust, open-source python library for materials analysis",
            "venue": "Computational Materials Science,",
            "year": 2013
        },
        {
            "authors": [
                "Teerachote Pakornchote",
                "Natthaphon Choomphon-anomakhun",
                "Sorrjit Arrerut",
                "Chayanon Atthapak",
                "Sakarn Khamkaeo",
                "Thiparat Chotibut",
                "Thiti Bovornratanaraks"
            ],
            "title": "Diffusion probabilistic models enhance variational autoencoder for crystal structure generative modeling",
            "venue": "arXiv preprint arXiv:2308.02165,",
            "year": 2023
        },
        {
            "authors": [
                "John P Perdew",
                "Matthias Ernzerhof",
                "Kieron Burke"
            ],
            "title": "Rationale for mixing exact exchange with density functional approximations",
            "venue": "The Journal of chemical physics,",
            "year": 1996
        },
        {
            "authors": [
                "Chris J Pickard",
                "RJ Needs"
            ],
            "title": "Ab initio random structure searching",
            "venue": "Journal of Physics: Condensed Matter,",
            "year": 2011
        },
        {
            "authors": [
                "Charles R Qi",
                "Hao Su",
                "Kaichun Mo",
                "Leonidas J Guibas"
            ],
            "title": "Pointnet: Deep learning on point sets for 3d classification and segmentation",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2017
        },
        {
            "authors": [
                "Aditya Ramesh",
                "Mikhail Pavlov",
                "Gabriel Goh",
                "Scott Gray",
                "Chelsea Voss",
                "Alec Radford",
                "Mark Chen",
                "Ilya Sutskever"
            ],
            "title": "Zero-shot text-to-image generation",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Zekun Ren",
                "Juhwan Noh",
                "Siyu Tian",
                "Felipe Oviedo",
                "Guangzong Xing",
                "Qiaohao Liang",
                "Armin Aberle",
                "Yi Liu",
                "Qianxiao Li",
                "Senthilnath Jayavelu"
            ],
            "title": "Inverse design of crystals using generalized invertible crystallographic representation",
            "venue": "arXiv preprint arXiv:2005.07609,",
            "year": 2005
        },
        {
            "authors": [
                "Zekun Ren",
                "Siyu Isaac Parker Tian",
                "Juhwan Noh",
                "Felipe Oviedo",
                "Guangzong Xing",
                "Jiali Li",
                "Qiaohao Liang",
                "Ruiming Zhu",
                "Armin G Aberle",
                "Shijing Sun"
            ],
            "title": "An invertible crystallographic representation for general inverse design of inorganic crystals with targeted properties",
            "year": 2022
        },
        {
            "authors": [
                "Chitwan Saharia",
                "William Chan",
                "Saurabh Saxena",
                "Lala Li",
                "Jay Whang",
                "Emily L Denton",
                "Kamyar Ghasemipour",
                "Raphael Gontijo Lopes",
                "Burcu Karagol Ayan",
                "Tim Salimans"
            ],
            "title": "Photorealistic text-to-image diffusion models with deep language understanding",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Kristof Sch\u00fctt",
                "Pieter-Jan Kindermans",
                "Huziel Enoc Sauceda Felix",
                "Stefan Chmiela",
                "Alexandre Tkatchenko",
                "Klaus-Robert M\u00fcller"
            ],
            "title": "Schnet: A continuous-filter convolutional neural network for modeling quantum interactions",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Uriel Singer",
                "Adam Polyak",
                "Thomas Hayes",
                "Xi Yin",
                "Jie An",
                "Songyang Zhang",
                "Qiyuan Hu",
                "Harry Yang",
                "Oron Ashual",
                "Oran Gafni"
            ],
            "title": "Make-a-video: Text-to-video generation without text-video data",
            "venue": "arXiv preprint arXiv:2209.14792,",
            "year": 2022
        },
        {
            "authors": [
                "Jascha Sohl-Dickstein",
                "Eric Weiss",
                "Niru Maheswaranathan",
                "Surya Ganguli"
            ],
            "title": "Deep unsupervised learning using nonequilibrium thermodynamics",
            "venue": "In International Conference on Machine Learning,",
            "year": 2015
        },
        {
            "authors": [
                "Yang Song",
                "Stefano Ermon"
            ],
            "title": "Generative modeling by estimating gradients of the data distribution",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "Akash Srivastava",
                "Lazar Valkov",
                "Chris Russell",
                "Michael U Gutmann",
                "Charles Sutton"
            ],
            "title": "Veegan: Reducing mode collapse in gans using implicit variational learning",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Andrij Vasylenko",
                "Jacinthe Gamon",
                "Benjamin B Duff",
                "Vladimir V Gusev",
                "Luke M Daniels",
                "Marco Zanella",
                "J Felix Shin",
                "Paul M Sharp",
                "Alexandra Morscher",
                "Ruiyong Chen"
            ],
            "title": "Element selection for crystalline inorganic solid discovery guided by unsupervised machine learning of experimentally explored chemistry",
            "venue": "Nature communications,",
            "year": 2021
        },
        {
            "authors": [
                "Clement Vignac",
                "Igor Krawczuk",
                "Antoine Siraudin",
                "Bohan Wang",
                "Volkan Cevher",
                "Pascal Frossard"
            ],
            "title": "Digress: Discrete denoising diffusion for graph generation",
            "venue": "arXiv preprint arXiv:2209.14734,",
            "year": 2022
        },
        {
            "authors": [
                "Logan Ward",
                "Ankit Agrawal",
                "Alok Choudhary",
                "Christopher Wolverton"
            ],
            "title": "A general-purpose machine learning framework for predicting properties of inorganic materials",
            "venue": "npj Computational Materials,",
            "year": 2016
        },
        {
            "authors": [
                "Tian Xie",
                "Jeffrey C Grossman"
            ],
            "title": "Crystal graph convolutional neural networks for an accurate and interpretable prediction of material properties",
            "venue": "Physical review letters,",
            "year": 2018
        },
        {
            "authors": [
                "Tian Xie",
                "Xiang Fu",
                "Octavian-Eugen Ganea",
                "Regina Barzilay",
                "Tommi Jaakkola"
            ],
            "title": "Crystal diffusion variational autoencoder for periodic material generation",
            "venue": "arXiv preprint arXiv:2110.06197,",
            "year": 2021
        },
        {
            "authors": [
                "Minkai Xu",
                "Lantao Yu",
                "Yang Song",
                "Chence Shi",
                "Stefano Ermon",
                "Jian Tang"
            ],
            "title": "Geodiff: A geometric diffusion model for molecular conformation generation",
            "venue": "arXiv preprint arXiv:2203.02923,",
            "year": 2022
        },
        {
            "authors": [
                "Jason Yim",
                "Brian L Trippe",
                "Valentin De Bortoli",
                "Emile Mathieu",
                "Arnaud Doucet",
                "Regina Barzilay",
                "Tommi Jaakkola"
            ],
            "title": "Se (3) diffusion model with application to protein backbone generation",
            "venue": "arXiv preprint arXiv:2302.02277,",
            "year": 2023
        },
        {
            "authors": [
                "Jiahui Yu",
                "Yuanzhong Xu",
                "Jing Yu Koh",
                "Thang Luong",
                "Gunjan Baid",
                "Zirui Wang",
                "Vijay Vasudevan",
                "Alexander Ku",
                "Yinfei Yang",
                "Burcu Karagol Ayan"
            ],
            "title": "Scaling autoregressive models for contentrich text-to-image generation",
            "venue": "arXiv preprint arXiv:2206.10789,",
            "year": 2022
        },
        {
            "authors": [
                "Nils ER Zimmermann",
                "Anubhav Jain"
            ],
            "title": "Local structure order parameters and site fingerprints for quantification of coordination environment and crystal structure similarity",
            "venue": "RSC advances,",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Large generative models trained on internet-scale vision and language data have demonstrated exceptional abilities in synthesizing highly realistic texts (OpenAI, 2023; Anil et al., 2023), images (Ramesh et al., 2021; Yu et al., 2022), and videos (Ho et al., 2022a; Singer et al., 2022). The need for novel synthesis, however, goes far beyond conversational agents or generative media, which mostly impact the digital world. In the physical world, technological applications such as catalysis (N\u00f8rskov et al., 2009), solar cells (Green et al., 2014), and lithium batteries (Mizushima et al., 1980) are enabled by the discovery of novel materials. The traditional trial-and-error approach that discovered these materials can be highly inefficient and take decades (e.g., blue LEDs (Nakamura, 1998) and high-Tc superconductors (Bednorz & Mu\u0308ller, 1986)). Generative models have the potential to dramatically accelerate materials discovery by generating and evaluating material candidates with desirable properties more efficiently in silico. One of the difficulties in materials generation lies in characterizing the structural relationships between atoms, which scales quadratically with the number of atoms. While representations with explicit structures such as graphs have been extensively studied (Schu\u0308tt et al., 2017; Xie & Grossman, 2018; Batzner et al., 2022; Xie et al., 2021), explicit characterization of inter-atomic relationships becomes increasingly challenging as the number of atoms increases, which can prevent these methods from scaling to large materials datasets with complex chemical systems. On the other hand, given that generative models are designed to discover patterns from data, it is natural to wonder if material structures can automatically arise from data through generative modeling, similar to how natural language structures arise from language modeling, so that large system sizes becomes more of a benefit than a roadblock. Existing generative models that directly model atoms without explicit structures are largely inspired by generative models for computer vision, such as learning VAEs or GANs on voxel images (Noh et al., 2019; Hanakata et al., 2020) or point cloud representations of materials (Kim et al., 2020). VAEs and GANs have known drawbacks such as posterior collapse (Lucas et al., 2019) and mode collapse (Srivastava et al., 2017), potentially making scaling difficult (Dhariwal & Nichol, 2021).\nMore recently, diffusion models (Song & Ermon, 2019; Ho et al., 2020) have been found particularly effective in generating diverse yet high fidelity image and videos, and have been applied to data at internet scale (Saharia et al., 2022; Ho et al., 2022a). However, it is unclear whether diffusion models are also effective in modeling structural relationships between atoms in crystals that are neither images nor videos. In this work, we investigate whether diffusion models can capture inter-atomic relationships effectively by directly modeling atom locations, and whether such an approach can be scaled to complex chemical systems with a larger number of atoms. Specifically, we propose a unified representation of materials (UniMat) that can capture any crystal structure. As shown in Figure 1, UniMat represents atoms in a material\u2019s unit cell (the smallest repeating unit) by storing the continuous value x, y, z atom locations at the corresponding element entry in the periodic table. This representation overcomes the difficulty around joint modeling of discrete atom types and continuous atom locations, while introducing prior knowledge from the periodic table (e.g., elements in the same group have similar chemical properties). With such a unified representation of materials, we train diffusion probabilistic models by treating the UniMat representation as a 4-dimensional tensor and applying interleaved attention and convolution layers, similar to Saharia et al. (2022), across periods and groups of the periodic table. This allows UniMat to capture inter-atom relationships while preserving any inductive bias from the periodic table, such as elements in the same group having similar chemical properties. We first evaluate UniMat on a set of proxy metrics proposed by Xie et al. (2021), and show that UniMat generally works better than the previous state-of-the-art graph based approach and a recent language model (Flam-Shepherd & Aspuru-Guzik, 2023) and diffusion model (Pakornchote et al., 2023) baseline. However, we are ultimately interested in whether the generated materials are physically valid and can be synthesized in a laboratory (e.g., low-energy materials). We found proxy metrics based on learning a separate energy network either saturate or fall short in evaluating generated materials reliably under the context of material discovery (i.e., generating materials that have not been seen by the energy prediction network). In answering this question, we run DFT relaxations (Hafner, 2008) to compute the formation energy of the generated materials, which is more widely accepted in material science than learned proxy metrics in Bartel et al. (2020). We then use per-composition formation energy and stability with respect to convex hull through decomposition energy as more reliable metrics for evaluating generative models for materials. UniMat drastically outperforms previous state-of-the-art according to these DFT based metrics. Lastly, we scale UniMat to train on all experimentally verified stable materials as well as additional stable / semi-stable materials found through search and substitution (over 2 million structures in total). We show that predicting material structures conditioned on element type can generalize (in a zero-shot manner) to predicting more difficult structures that are not a neighboring structure to the training set, achieving better efficiency than the predominant random structure search. This allows for the possibility of discovering new materials with desired properties effectively. In summary, our work contributes the following: \u2022 We develop a novel representation of materials that enables diffusion models to scale to large and\ncomplex materials datasets, outperforming previous methods on previous proxy metrics.\n\u2022 We conduct DFT calculations to rigorously verify the stability of generated materials, and propose to use per-composition formation energy and stability with respect to convex hull for evaluating generative models for materials. \u2022 We scale conditional generation to all known stable materials and additional materials found by search and substitution, and observe zero-shot generalization to generating harder structures, achieving better efficiency than random structure search in discovering new materials."
        },
        {
            "heading": "2 SCALABLE DIFFUSION FOR MATERIALS GENERATION",
            "text": "We start by proposing a novel crystal representation that can represent any material with a finite number of atoms in a unit cell (the smallest repeating unit of a material). We then illustrate how to learn both unconditional and conditional denoising diffusion models on the proposed crystal representations. Lastly, we explain how we can verify generated materials rigorously using quantum mechanical methods."
        },
        {
            "heading": "2.1 SCALABLE REPRESENTATION OF CRYSTAL STRUCTURES",
            "text": "An ideal representation for crystal structures should not introduce any intrinsic errors (unlike voxel images), and should be able to support both up scaling to large sets of materials on the internet and down scaling to a single compound system that a particular group of scientists care about (e.g., silicon carbide). We develop such a scalable and flexible representation below. Periodic Table Based Material Representation. We first observe that periodic table captures rich knowledge of chemical properties. To introduce such prior knowledge to a generative model as an inductive bias, we define a 4-dimensional material space, M := RL\u00d7H\u00d7W\u00d7C , where H = 9 and W = 18 correspond to the number of periods and groups in the periodic table, L corresponds to the maximum number of atoms per element in the periodic table, and C = 3 corresponds to the x,y,z locations of each atoms in a unit cell. We define a null location using special values such as x = y = z = \u22121 to represent the absence of this atom. A visualization of this representation is shown in Figure 1. To account for invariances in order, rotation, translation, and periodicity, we incorporate data augmentation through random shuffling and rotations similar to Hoffmann et al. (2019); Kim et al. (2020); Court et al. (2020). We also include unit cell parameters (a, b, c) \u2208 R3 and (\u03b1, \u03b2, \u03b3) \u2208 R3 as shown in Figure 1. We denote this representation UniMat, as it is a unified representation of crystals, and has the potential to represent broader chemical structures (e.g., drugs, molecules, and proteins). Flexibility for Smaller Systems. While UniMat can represent any crystal structure, sometimes one might only be interested in generating structures with one specific element (e.g., carbon in graphene) or two-chemical compounds (e.g., silicon carbide). Instead of setting H and W to the full periods and groups of the periodic table, one can set H = 1,W = 1 (for one specific element) or H = 9,W = 2 (for elements from two groups) to model specific chemical systems of interest. L can also be adjusted according to the number of elements expected to exist in the system."
        },
        {
            "heading": "2.2 LEARNING DIFFUSION MODELS WITH UNIMAT REPRESENTATION",
            "text": "With the UniMat representation above, we now illustrate how effective training of diffusion models (Sohl-Dickstein et al., 2015; Ho et al., 2020) on crystal structures can be enabled, followed by how to generate crystal structures conditioned on compositions or other types of material properties. Details of the model architecture and training procedure can be found in Appendix A. Diffusion Model Background. Denoising diffusion probablistic models (DDPM) are a class of probabilistic generative models initially designed for images where the generation of an image x \u2208 Rd is formed by iterative denoising. That is, given an image x sampled from a distribution of images p(x), a randomly sampled Gaussian noise variable \u03f5 \u223c N (0, Id), and a set of T different noise levels \u03b2t \u2208 R, a denoising model \u03f5\u03b8 is trained to denoise the noise corrupted image x at each specified noise level t \u2208 [1, T ] by minimizing:\nLMSE = \u2225\u03f5\u2212 \u03f5\u03b8( \u221a 1\u2212 \u03b2tx+ \u221a \u03b2t\u03f5, t))\u22252.\nGiven this learned denoising function, new images may be generated from the diffusion model by initializing an image sample xT at noise level T from a Gaussian N (0, Id). This sample xT is then iteratively denoised by following the expression:\nxt\u22121 = \u03b1t(xt \u2212 \u03b3t\u03f5\u03b8(xt, t)) + \u03be, \u03be \u223c N ( 0, \u03c32t Id ) , (1)\nwhere \u03b3t is the step size of denoising, \u03b1t is a linear decay on the currently denoised sample, and \u03c3t is some time varying noise level that depends on \u03b1t and \u03b2t. The final sample x0 after T rounds of denoising corresponds to the final generated image.\nUnconditional Diffusion with UniMat. Now instead of an image x \u2208 Rd, we have a material x \u2208 Rd with d = L\u00d7H\u00d7W\u00d73 tensor as described in Section 2.1, where the inner-most dimension of x represents the atom locations (x,y,z). The denoising process in Equation 1 now corresponds to the process of moving atoms from random locations back to their original locations in a unit cell as shown in Figure 2. Note that the set of null atoms (i.e., atoms that do not exist in a crystal) will have random locations initially (left-most structure in Figure 2), and are gradually moved to the special null location during the denoising process. The null atoms are then filtered when the final crystals are extracted. The inclusion of null atoms in the representation enables UniMat to generate crystals with an arbitrary number of atoms (up to a maximum size). Since the denoising process of a DDPM nicely corresponds to the process of gradually moving atoms in space until they reach their target location, we choose DDPM over other diffusion models (e.g., denoising score matching). We parametrize \u03f5\u03b8(xt, t) using interleaved convolution and attention operations across the L,H,W dimensions of xt similar to Saharia et al. (2022), which can capture inter-atom relationships in a crystal structure. When atom locations are represented using fractional coordinates, we treat unit cell parameters as additional inputs to the diffusion process by concatenating the unit cell parameters with the crystal locations. Conditioned Diffusion with UniMat. While the unconditional generation procedure described above allows generation of materials from random noise, na\u0131\u0308vely sampling from the unconditional model can lead to samples that largely overlap with the training set. This is undesirable in the context of materials discovery, where the goal is to discover novel materials that do not exist in the training set. Futhermore, practical applications such as material synthesis often focus on specific types of materials, but one do not have much control over what compound gets generated during an unconditional denoising process. This suggests that conditional generation may be more relevant for materials discovery. We consider conditioning generation on compositions (types and ratios of chemical elements) c \u2208 RH\u00d7W when only the composition types are specified (e.g., carbon and silicon), or on c \u2208 RL\u00d7H\u00d7W when the exact composition (number of atoms per element) is given (e.g., Si4C4). We denote the conditional denoising model as \u03f5\u03b8(xt, t|c). Since the input to the unconditional denoising model \u03f5\u03b8(xt, t) is a noisy material of dimensions (L,H,W, 3), we concatenate the conditioning variable c with the noisy material along the last dimension before inputting the noisy material into the denoising model, so that the denoising model can easily condition on compositions as desired. To condition on auxiliary information such as energy, we can leverage classifier-free guidance (Ho & Salimans, 2022) and use\n\u03f5\u0302\u03b8(xt, t|c,aux) = (1 + \u03c9)\u03f5\u03b8(xt, t|c,aux)\u2212 \u03c9\u03f5\u03b8(xt, t|c) (2) as the denoising model in the reverse process for sampling materials conditioned on auxiliary information aux, where \u03c9 controls the strength of auxiliary information conditioning."
        },
        {
            "heading": "2.3 EVALUATING GENERATED MATERIALS",
            "text": "Different from generative models for vision and language where the quality of generation can be easily assessed by humans, evaluating generated crystals rigorously requires calculations from Density Functional Theory (DFT) (Hohenberg & Kohn, 1964), which we elaborate in detail below. Drawbacks of Learning Based Evaluations. One way to evaluate generative models for materials is to compare the distributions of formation energy Ef between a generated and reference set, D(p(Egenf ), p(E ref f )), where D is a distance measure over distributions, such as earth mover\u2019s distance (Xie et al., 2021). Since using DFT to compute Ef is computationally demanding, previous work has relied on a learned network to predict Ef from generated materials (Xie et al., 2021). However, predicting Ef can have intrinsic errors, particularly in the context of materials discovery\nwhere the goal is to generate novel materials beyond the training manifold of the energy prediction network. Even when Ef can be predicted with reasonable accuracy, a low Ef does not necessarily reflect ground-truth (DFT) stability. For example, Bartel et al. (2020) reported that a model that can predict Ef with an error of 60 meV/atom (a 16-fold reduction from random-guessing) does not provide any predictive improvement over random guessing for stable material discovery. This is because most variations in Ef are between different chemical systems, whereas for stability assessment, the important comparison is between compounds in a single chemical system. When materials generated by two different models contain different compounds, the model that generated materials with a lower Ef could have simply generated compounds from a lower Ef system without enabling efficient discovery (Merchant et al., 2023). The property that captures relative stabilities between different compositions is known as decomposition energy (Ed). Since Ed depends on the formation energy of other compounds from the same system, predicting Ed directly using machine learning models has been found difficult (Bartel et al., 2020). Evaluating via Per-Composition Formation Energy. Different from learned energy predictors, DFT calculations provide more accurate and reliable Ef values. When two models each generate a structure of the same composition, we can directly compare which structure has a lower DFT computed Ef (and is hence more stable). We call this the per-composition formation energy comparison. We define average difference in per-composition formation energy between two sets of materials A and B as\n\u2206Ef (A,B) = 1 |C| \u2211\n(x,x\u2032)\u2208C\n( EAf,x \u2212 EBf,x\u2032 ) , (3)\nwhere C = {(x, x\u2032) | x \u2208 A, x\u2032 \u2208 B, comp(x) = comp(x\u2032)} denotes the set of structures from A and B that have the same composition. We also define the Ef Reduction Rate between set A and B as the rate where structures in A have a lower Ef than the structures in B of the corresponding compositions, i.e.,\nEf Reduction Rate(A,B) = 1\n|C| |{(x, x\u2032) | (x, x\u2032) \u2208 C \u2227 EAf,x < EBf,x\u2032}|, (4)\nwhere C is the same as in Equation 3. We can then use \u2206Ef and the Ef Reduction Rate to compare a generated set of structures to some reference set, or to compare two generated sets. \u2206Ef (A,B) measures how much lower in Ef (on average) the structures in a set A are compared to the structures of correponding compositions in a set B, while Ef Reduction Rate(A,B) reflects how many structures in A have lower Ef than the corresponding structures in B. We use these metrics to evaluate generated materials in Section 3.2.1. Evaluating Stability via Decomposition Energy We also want to compare generated materials that differ in composition. To do so, we can use DFT to compute decomposition energy Ed. Ed measures a compound\u2019s thermodynamic decomposition enthalpy into its most stable compositions on a convex hull phase diagram, where the convex hull is formed by linear combinations of the most stable (lowest energy) phases for each known composition (Jain et al., 2013). As a result, decomposition energy allows us to compare compounds from two generative models that differ in composition by separately computing their decomposition energy with respect to the convex hull formed by a larger materials database. The distribution of decomposition energies will reflect a generative model\u2019s ability to generate relatively stable materials. We can further compute the number of novel stable (Ed < 0) materials from set A with respect to convex hull as # Stable(A) = |{x \u2208 A | EAd,x < 0}|, (5) and compare this quantity to some other set B. We apply this metric to evaluate generative models for materials in Section 3.2. Evaluating against Random Search Baseline. For structure prediction given compositions, one popular non-learning based approach is Ab initio random structure search (AIRSS) (Pickard & Needs, 2011). AIRSS works by initializing a set of sensible structures given the composition and a target volume, relaxing randomly initialized structures via soft-sphere potentials, followed by DFT relaxations to minimize the total energy of the system. However, discovering structures (especially if done in a high-throughput framework) requires a large number of initializations and relaxations which can often fail to converge (Cheon et al., 2020; Merchant et al., 2023).\nOne practical use of conditional UniMat is to propose initial structures given compositions, with the hope that the generated structures will result in a higher convergence rate for DFT calculations compared to structures proposed by AIRSS, which are based on manual heuristics and random guessing of initial volumes."
        },
        {
            "heading": "3 EXPERIMENTAL EVALUATION",
            "text": "We now evaluate UniMat using previous proxy metrics from Xie et al. (2021) and metrics derived from DFT calculations from Section 2.3. UniMat is able to generate orders of magnitude more stable materials verified by DFT calculations compared to the previous state-of-the-art generative model. We further demonstrate UniMat\u2019s ability in accelerating random structure search through conditional generation."
        },
        {
            "heading": "3.1 EVALUATING UNCONDITIONAL GENERATION USING PROXY METRICS",
            "text": "Datasets, Metrics, and Baselines. We begin the evaluation following the same setup as CDVAE Xie et al. (2021) using Perov-5, Carbon-24, and MP-20 materials datasets. We report metrics on structural and composition validity determined by atom distances and SMACT, coverage metrics based on CrystalNN fingerprint distances, and property distributions in density, learned formation energy, and number of atoms (e.g., earth mover\u2019s distance between the distribution of number of elements in generated materials versus test materials.). We include a recent language model baseline (FlamShepherd & Aspuru-Guzik, 2023) and a diffusion baseline (Pakornchote et al., 2023). Results. Evaluation results on UniMat and baselines are shown in Table 5. All four models perform similarly in terms of structure and composition validity on the Perov-5 dataset due to its simplicity. UniMat performs slightly worse on the coverage based metrics on Perov-5, but achieves better distributions in energy and number of unique elements. On Carbon-24, UniMat outperforms CDVAE in all metrics. On the more realistic MP-20 dataset, UniMat achieves the best property statistics, coverage, and composition validity, but worse structure validity than CDVAE. Results on full coverage\nFigure 5: Difference in Ef for each composition generated by UniMat and CDVAE, i.e., EAf,x \u2212EBf,x\u2032 , where A and B are sets of structures generated by UniMat and CDVAE, respectively. UniMat generates more structures with lower Ef .\nA, B \u2206Ef (eV/atom) Ef Reduc. Rate\nCDVAE, MP-20 test 0.279 0.083\nUniMat, MP-20 test 0.061 0.254 UniMat, CDVAE -0.216 0.863\nTable 2: \u2206Ef (Equation 3) and Ef Reduction Rate (Equation 4) between CDVAE and MP-20 test, between UniMat and MP-20 test, and between UniMat and CDVAE. UniMat generates structures with an average of -0.216 eV/atom lower Ef than CDVAE. 86.3% of the overlapping (in composition) structures generated by UniMat and CDVAE has a lower energy in UniMat.\nmetrics from CDVAE are in Appendix D. We note that some of these metrics have been saturated with close to 100% performance. We defer more rigorous evaluations with DFT calculations to Section 3.2. In addition, we qualitatively evaluate the generated materials from training on MP-20 in Figure 3. We select generated materials that have the same composition as the test set from MP-20, and use the VESTA crystal visualization tool (Momma & Izumi, 2011) to plot both the test set materials and the generated materials. The range of fractional coordinates in the VESTA settings were set from -0.1 to 1.1 for all coordinates to represent all fractional atoms adjacent to the unit cell. In general, we found that UniMat generates materials that are visually more aligned with the test set materials than CDVAE.\nAblation on Model Size. In training on larger datasets with more diverse materials such as MP-20, we found benefits in scaling up the model as shown in Table 4, which suggests that the UniMat representation and the UniMat training objective can be further scaled to systems larger than MP-20, which we elaborate more in Section 3.3."
        },
        {
            "heading": "3.2 EVALUATING UNCONDITIONAL GENERATION USING DFT CALCULATIONS",
            "text": "As discussed in Section 2.3, proxy-based evaluation in Section 3.1 should be backed by DFT verifications similar to Noh et al. (2019). In this section, we evaluate stability of generated materials using metrics derived from DFT calculations in Section 2.3."
        },
        {
            "heading": "3.2.1 PER-COMPOSITION FORMATION ENERGY",
            "text": "Setup. We start by running DFT relaxations using the VASP software (Hafner, 2008) to relax both atomic positions and unit cell parameters on generated materials from models trained on MP20 to compute their formation energy Ef (see details of DFT in Appendix B). We then compare average difference in per-composition formation energy (\u2206Ef in Equation 3) and the formation energy reduction rate (Ef Reduction Rate in Equation 4) between materials generated by CDVAE and the MP-20 test set, between UniMat and the test set, and between UniMat and CDVAE. Results. We plot the difference in formation energy for each pair of generated structures from UniMat and CDVAE with the same composition in Figure 5. We see the majority of the generated compositions from UniMat have a lower formation energy. We further report \u2206Ef and the Ef Reduction Rate in Table 2. We see that among the set of materials generated by UniMat and CDVAE with overlapping compositions, 86% of them have a lower energy when generated by UniMat. Furthermore, materials generated by UniMat have an average of -0.21 eV/atom lower Ef than CDVAE. Comparing the generated set against the MP-20 test set also favors UniMat."
        },
        {
            "heading": "3.2.2 STABILITY ANALYSIS THROUGH DECOMPOSITION ENERGY",
            "text": "As discussed in Section 2.3, generated structures relaxed by DFT can be compared against the convex hull of a larger materials database in order to analyze their stability through decomposition energy. Specifically, we downloaded the full Materials Project database (Jain et al., 2013) from July 2021, and used this to form the convex hull. We then compute the decomposition energy for materials generated by UniMat and CDVAE individually against the convex hull.\nResults. We plot the distributions of the decomposition energies after DFT relaxation for the generated materials from both models in Figure 6. Note that only the set of generated materials that converged after DFT calculations are plotted. We see that UniMat generates materials that are lower in decomposition energy after DFT relaxation compared to CDVAE. We further report the number of newly discovered stable / metastable materials (with Ed < 25meV/atom) from both UniMat and CDVAE in Table 3. In addition to using the convex hull from Materials Project 2021, we also use another dataset (GNoME) with 2.2 million materials constructed via structure search to construct a more challenging convex hull (Merchant et al., 2023). We see that UniMat is able to discover an order of magnitude more stable materials than CDVAE with respect to convex hulls constructed from both datasets. We visualize examples of newly discovered stable materials by UniMat in Figure 7."
        },
        {
            "heading": "3.3 EVALUATING COMPOSITION CONDITIONED GENERATION",
            "text": "We have verified that some of the unconditionally generated materials from UniMat are indeed novel and stable through DFT calculations. We now assess composition conditioned generation which is often more practical for downstream synthesis applications. Setup. We use AIRSS to randomly initialize 100 structures per composition followed by relaxation via soft-sphere potentials. We then run DFT relaxations on these AIRSS structures. For conditional generation using UniMat, we train composition conditioned UniMat on the GNoME dataset consisting of 2.2 million stable materials. We then sample 100 structures per composition for the same compositions used by AIRSS. We evaluate the rate of compositions for which at least 1 out of 100 structures converged during DFT calculations. In addition to convergence rate, we also evaluate the \u2206Ef (UniMat,AIRSS) and the Ef Reduction Rate (UniMat,AIRSS) on the DFT relaxed structures. Since none of the test compositions exist in the training set, we are evaluating the ability of UniMat to generalize to more difficult structures in a zero-shot manner. See details of AIRSS in Appendix C.\nResults. We first observe that AIRSS has an overall convergence rate of 0.55, whereas UniMat has an overall convergence rate of 0.81. We note that both AIRSS and UniMat can be further optimized for convergence rate, so these results are only initial signals on how conditional generative models compare to structure search. Next, we take the relaxed structure with the lowest Ef from both UniMat and AIRSS for each composition, and plot the percomposition Ef difference in Figure 8, and\n\u2206Ef (UniMat,AIRSS) = \u22120.68eV/atom, and Ef Reduction Rate(UniMat, AIRSS) = 0.8, which suggests that UniMat is indeed effective in initializing structures that lead to lower Ef than AIRSS."
        },
        {
            "heading": "4 RELATED WORK",
            "text": "Diffusion Models for Structured Data Diffusion models (Song & Ermon, 2019; Ho et al., 2020; Kingma et al., 2021) were initially proposed for generating images from noise of the same dimension through a Markov chain of Gaussian transitions, and have been adopted to structured data such as graphs (Niu et al., 2020; Vignac et al., 2022; Jo et al., 2022; Yim et al., 2023), sets (Giuliari et al., 2023) and point clouds (Qi et al., 2017; Luo & Hu, 2021; Lyu et al., 2021). Diffusion modeling for materials requires joint modeling of continuous atom locations and discrete atom types. Previous approaches either embed discrete quantities into a continuous latent space, risking information loss (Xie et al., 2021), or directly learn discrete-space transformations (Vignac et al., 2022; Austin et al., 2021) on graphs represented by adjacency matrices that scale quadratically in the number of atoms. Generative Models for Materials Discovery. Generative models originally designed for images have been applied to generating material structures, such as GANs (Nouira et al., 2018; Kim et al., 2020; Long et al., 2021), VAEs (Hoffmann et al., 2019; Noh et al., 2019; Ren et al., 2020; Court et al., 2020), and diffusion models (Xie et al., 2021). These methods were developed to work with different materials representations as voxel images (Hoffmann et al., 2019; Noh et al., 2019; Court et al., 2020), graphs (Xie et al., 2021), point clouds (Kim et al., 2020), and phase fields or electron density maps (Vasylenko et al., 2021; Court et al., 2020). However, existing work has mostly focused on simpler materials in binry compounds (Noh et al., 2019; Long et al., 2021), ternary compounds (Nouira et al., 2018; Kim et al., 2020), or cubic systems (Hoffmann et al., 2019). Xie et al. (2021) show that graph neural networks with latent space diffusion guided by gradient of formation energy can scale to Materials Project (Jain et al., 2013). However, the quality of generated materials seems to decrease drastically on complex datasets. Recently, large language models have been applied to generate crystal files (Antunes et al., 2023; Flam-Shepherd & Aspuru-Guzik, 2023). However, the ability of language models to generate files with structural information requires further confirmation, and the generated materials require further DFT verification. Pakornchote et al. (2023) is the closest to our work in using diffusion models to model atom locations, but Pakornchote et al. (2023) uses a separate VAE to predict lattice parameters and number of atoms, limiting modeling flexibility. Evaluation of Materials Discovery The most reliable verification of generated materials is through Density Function Theory (DFT) calculations (Neugebauer & Hickel, 2013), which uses quantum mechanics to calculate thermodynamic properties such as formation energy and energy above the hull, thereby determining the stability of generated structures (Noh et al., 2019; Long et al., 2021; Choubisa et al., 2020; Dan et al., 2020; Korolev et al., 2020; Ren et al., 2022; Long et al., 2021; Kim et al., 2020). However, DFT calculations require extensive computational resources. Alternative proxy metrics such as pairwise atom distances and charge neutrality (Davies et al., 2019) were developed as a sanity check of generated materials (Xie et al., 2021; Flam-Shepherd & AspuruGuzik, 2023). Fingerprint distances (Zimmermann & Jain, 2020; Ward et al., 2016) have also been used to measure precision and recall between the generated set and some held-out test set (Ganea et al., 2021; Xu et al., 2022; Xie & Grossman, 2018; Flam-Shepherd & Aspuru-Guzik, 2023). To evaluate properties of generated materials, previous work learns a separate graph neural network, which has intrinsic errors. Furthermore, Bartel (2022) has shown that learned formation energies do not reproduce DFT-calculated relative stabilities, bringing the value of learned property based evaluation into question."
        },
        {
            "heading": "5 LIMITATIONS AND CONCLUSION",
            "text": "We have presented the first diffusion model for materials generation that can scale to datasets with millions of materials. To enable effective scaling, we developed a novel representation, UniMat, based on the periodic table, which enables any crystal structure to be effectively represented. The advantage of UniMat lies in modeling flexibility which enables scalability and computational efficiency compared to traditional search methods. UniMat has a few limitations. It does not achieve 100% validity on complex datasets (e.g., MP-20). The UniMat representation is sparse when the chemical system is small, which incurs additional computational cost (e.g., 99% atoms might be null atoms). Despite these limitations, UniMat enables training of diffusion models that results in better generation quality than previous state-of-the-art learned materials generators. We further advocate for using DFT calculations to perform rigorous stability analysis of materials generated by generative models. Expanding UniMat to other materials (e.g., non-crystalline or amorphous) and broader scientific data is an exciting direction of future work."
        },
        {
            "heading": "A ARCHITECTURE AND TRAINING",
            "text": "We repurpose the 3D U-Net architecture (C\u0327ic\u0327ek et al., 2016; Ho et al., 2022b) which originally models the spatial and time dimensions of videos into modeling periods and groups of the periodic table as well as the number of atoms dimension, which can be seen as the time dimension in videos. We apply the spatial downsampling pass followed by the spatial upsampling pass with skip connections to the downsampling pass activations with interleaved 3D convolution and attention layers as in standard 3D U-Net. The hyperparamters in training the UniMat diffusion model are summarized in Table 4."
        },
        {
            "heading": "B DETAILS OF DFT CALCULATIONS",
            "text": "We use the Vienna ab initio simulation package (VASP) (Kresse & Furthmu\u0308ller, 1996b;a) with the Perdew-Burke-Ernzerhof (PBE) (Perdew et al., 1996) functional and projector-augmented wave (PAW) (Blo\u0308chl, 1994; Kresse & Joubert, 1999) potentials in all DFT calculations. Our DFT settings are consistent with Materials Project workflows as encoded in pymatgen (Ong et al., 2013) and atomate (Mathew et al., 2017). We use consistent settings with the Materials Project workflow including the Hubbard U parameter applied to a subset of transition metals in DFT+U, 520 eV plane-wave basis cutoff, magnetization settings and the choice of PBE pseudopotentials, except for Li, Na, Mg, Ge, and Ga. For Li, Na, Mg, Ge, and Ga, we use more recent versions of the respective potentials with the same number of valence electrons. For all structures, we use the standard protocol of two stage relaxation of all geometric degrees of freedom, followed by a final static calculation along with the custodian package (Ong et al., 2013) to handle any VASP related errors that arise and adjust appropriate simulations. For the choice of KPOINTS, we also force gamma centered kpoint generation for hexagonal cells rather than the more traditional Monkhorst-Pack. We assume ferromagnetic spin initialization with finite magnetic moments, as preliminary attempts to incorporate different spin orderings showed computational costs prohibitive to sustain at the scale presented. In AIMD simulations, we turn off spin-polarization and use the NVT ensemble with a 2 fs time step, except for simulations including hydrogen, where we reduce the time step to 0.5 fs."
        },
        {
            "heading": "C DETAILS OF AIRSS AND CONDITIONAL EVALUATION",
            "text": "Random structures for conditional evaluation of UniMat are generated through Ab initio random structure search (Pickard & Needs, 2011). Random structures are initialized as \u201csensible\u201d structures (obeying certain symmetry requirements) to a target volume then relaxed via soft-sphere potentials.\nFor this paper, we always generate 100 AIRSS structures for every composition, many of which failed to converge as detailed in Section 3.3. We try a range of initial volumes spanning 0.4 to 1.2 times a volume estimated by considering relevant atomic radii, finding that the DFT relaxation fails or does not converge for the whole range for each composition. Note that these settings could be further finetuned to optimize AIRSS for convergence rate. To compute the convergence rate for AIRSS, we use a total of 57,655 compositions from previous AIRSS runs(Merchant et al., 2023), for which 31,917 converged, and hence the AIRSS convergence is 0.55. When we run conditional generation, we randomly sampled 157 compounds from the 31,917 AIRSS-converged compounds, and 309 compounds from the 25,738 compounds where AIRSS had no structure that converged. Among the 157 compounds where AIRSS converged, 137 from UniMat converged, and among the 309 compounds that AIRSS did not converge, 231 from UniMat converged, resulting in an overall convergence rate 137/157 \u2217 31917/(31917 + 25738) + 231/309 \u2217 25738/(31917 + 25738) = 0.817 for UniMat."
        },
        {
            "heading": "D ADDITIONAL RESULTS",
            "text": ""
        }
    ],
    "year": 2023
}