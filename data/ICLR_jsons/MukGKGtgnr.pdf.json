{
    "abstractText": "Traditional causal discovery approaches typically assume the absence of latent variables, a simplification that often does not align with real-world situations. Recently, there has been a surge of causal discovery methods that explicitly consider latent variables. While some works aim to reveal causal relations between observed variables in the presence of latent variables, others seek to identify latent variables and recover the causal structure over them. The latter typically entail strong distributional and graphical assumptions, such as the non-Gaussianity, purity, and two-pure-children assumption. In this paper, we endeavor to recover the whole causal structure involving both latent and observed variables under milder assumptions. We formulate two cases, one allows entirely arbitrary distribution and requires only one pure child per latent variable, and the other requires no pure child and imposes the non-Gaussianity requirement on only a subset of variables, and they both avoid the purity assumption. We prove the identifiability of linear latent variable models in both cases, and our constructive proof leads to theoretically sound and computationally efficient algorithms.",
    "authors": [
        {
            "affiliations": [],
            "name": "MILDER DISTRIBUTIONAL"
        },
        {
            "affiliations": [],
            "name": "GRAPHICAL ASSUMPTIONS"
        },
        {
            "affiliations": [],
            "name": "Xiu-Chuan Li"
        },
        {
            "affiliations": [],
            "name": "Kun Zhang"
        },
        {
            "affiliations": [],
            "name": "Tongliang Liu"
        }
    ],
    "id": "SP:164e92549259744a4f75e88a80b3615e53081acd",
    "references": [
        {
            "authors": [
                "Jeffrey Adams",
                "Niels Hansen",
                "Kun Zhang"
            ],
            "title": "Identification of partially observed linear causal models: Graphical conditions for the non-gaussian and heterogeneous cases",
            "venue": "In Conference on Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Kartik Ahuja",
                "Jason S Hartford",
                "Yoshua Bengio"
            ],
            "title": "Weakly supervised representation learning with sparse perturbations",
            "venue": "In Conference on Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Kartik Ahuja",
                "Divyat Mahajan",
                "Yixin Wang",
                "Yoshua Bengio"
            ],
            "title": "Interventional causal representation learning",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Animashree Anandkumar",
                "Daniel Hsu",
                "Adel Javanmard",
                "Sham Kakade"
            ],
            "title": "Learning linear bayesian networks with latent variables",
            "venue": "In International Conference on Machine Learning,",
            "year": 2013
        },
        {
            "authors": [
                "Johann Brehmer",
                "Pim De Haan",
                "Phillip Lippe",
                "Taco S Cohen"
            ],
            "title": "Weakly supervised causal representation learning",
            "venue": "In Conference on Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Barbara M Byrne"
            ],
            "title": "Structural equation modeling with Mplus: Basic concepts, applications, and programming",
            "venue": "routledge,",
            "year": 2013
        },
        {
            "authors": [
                "Ruichu Cai",
                "Feng Xie",
                "Clark Glymour",
                "Zhifeng Hao",
                "Kun Zhang"
            ],
            "title": "Triad constraints for learning causal structure of latent variables",
            "venue": "In Conference on Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Ruichu Cai",
                "Zhiyi Huang",
                "Wei Chen",
                "Zhifeng Hao",
                "Kun Zhang"
            ],
            "title": "Causal discovery with latent confounders based on higher-order cumulants",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Zhengming Chen",
                "Feng Xie",
                "Jie Qiao",
                "Zhifeng Hao",
                "Kun Zhang",
                "Ruichu Cai"
            ],
            "title": "Identification of linear latent variable model with arbitrary distribution",
            "venue": "In AAAI Conference on Artificial Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Zhengming Chen",
                "Feng Xie",
                "Jie Qiao",
                "Zhifeng Hao",
                "Ruichu Cai"
            ],
            "title": "Some general identification results for linear latent hierarchical causal structure",
            "venue": "In International Joint Conferences on Artificial Intelligence,",
            "year": 2023
        },
        {
            "authors": [
                "David Maxwell Chickering"
            ],
            "title": "Optimal structure identification with greedy search",
            "venue": "Journal of Machine Learning Research,",
            "year": 2002
        },
        {
            "authors": [
                "Tom Claassen",
                "Ioan G Bucur"
            ],
            "title": "Greedy equivalence search in the presence of latent confounders",
            "venue": "In Uncertainty in Artificial Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Ziming Hong",
                "Zhenyi Wang",
                "Li Shen",
                "Yu Yao",
                "Zhuo Huang",
                "Shiming Chen",
                "Chuanwu Yang",
                "Mingming Gong",
                "Tongliang Liu"
            ],
            "title": "Improving non-transferable representation learning by harnessing content and style",
            "venue": "In International Conference on Learning Representations,",
            "year": 2024
        },
        {
            "authors": [
                "Patrik Hoyer",
                "Dominik Janzing",
                "Joris M Mooij",
                "Jonas Peters",
                "Bernhard Sch\u00f6lkopf"
            ],
            "title": "Nonlinear causal discovery with additive noise models",
            "venue": "In Conference on Neural Information Processing Systems,",
            "year": 2008
        },
        {
            "authors": [
                "Patrik O Hoyer",
                "Shohei Shimizu",
                "Antti J Kerminen",
                "Markus Palviainen"
            ],
            "title": "Estimation of causal effects using linear non-gaussian causal models with hidden variables",
            "venue": "International Journal of Approximate Reasoning,",
            "year": 2008
        },
        {
            "authors": [
                "Biwei Huang",
                "Charles Jia Han Low",
                "Feng Xie",
                "Clark Glymour",
                "Kun Zhang"
            ],
            "title": "Latent hierarchical causal structure discovery with rank constraints",
            "venue": "In Conference on Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Zhuo Huang",
                "Xiaobo Xia",
                "Li Shen",
                "Bo Han",
                "Mingming Gong",
                "Chen Gong",
                "Tongliang Liu"
            ],
            "title": "Harnessing out-of-distribution examples via augmenting content and style",
            "venue": "In International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "AM Kagan"
            ],
            "title": "New classes of dependent random variables and a generalization of the darmois\u2013 skitovich theorem to several forms",
            "venue": "Theory of Probability & Its Applications,",
            "year": 1989
        },
        {
            "authors": [
                "David Kaltenpoth",
                "Jilles Vreeken"
            ],
            "title": "Nonlinear causal discovery with latent confounders",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Bohdan Kivva",
                "Goutham Rajendran",
                "Pradeep Ravikumar",
                "Bryon Aragam"
            ],
            "title": "Learning latent causal graphs via mixture oracles",
            "venue": "In Conference on Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Erich Kummerfeld",
                "Joseph Ramsey"
            ],
            "title": "Causal clustering for 1-factor measurement models",
            "venue": "In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,",
            "year": 2016
        },
        {
            "authors": [
                "Chenxi Liu",
                "Kun Kuang"
            ],
            "title": "Causal structure learning for latent intervened non-stationary data",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Aidan Lyon"
            ],
            "title": "Why are normal distributions normal",
            "venue": "The British Journal for the Philosophy of Science,",
            "year": 2014
        },
        {
            "authors": [
                "Christopher Meek"
            ],
            "title": "Causal inference and causal explanation with background knowledge",
            "venue": "In Uncertainty in Artificial Intelligence,",
            "year": 1995
        },
        {
            "authors": [
                "Joris M Mooij",
                "Jonas Peters",
                "Dominik Janzing",
                "Jakob Zscheischler",
                "Bernhard Sch\u00f6lkopf"
            ],
            "title": "Distinguishing cause from effect using observational data: methods and benchmarks",
            "venue": "Journal of Machine Learning Research,",
            "year": 2016
        },
        {
            "authors": [
                "Jonas Peters",
                "Joris M Mooij",
                "Dominik Janzing",
                "Bernhard Sch\u00f6lkopf"
            ],
            "title": "Causal discovery with continuous additive noise models",
            "venue": "Journal of Machine Learning Research,",
            "year": 2014
        },
        {
            "authors": [
                "Jonas Peters",
                "Dominik Janzing",
                "Bernhard Sch\u00f6lkopf"
            ],
            "title": "Elements of causal inference: foundations and learning algorithms",
            "year": 2017
        },
        {
            "authors": [
                "Joseph D Ramsey",
                "Kun Zhang",
                "Madelyn Glymour",
                "Ruben Sanchez Romero",
                "Biwei Huang",
                "Imme Ebert-Uphoff",
                "Savini Samarasinghe",
                "Elizabeth A Barnes",
                "Clark Glymour"
            ],
            "title": "Tetrad\u2014a toolbox for causal discovery",
            "venue": "In International Workshop on Climate Informatics,",
            "year": 2018
        },
        {
            "authors": [
                "Yves Rosseel"
            ],
            "title": "lavaan: An r package for structural equation modeling",
            "venue": "Journal of Statistical Software,",
            "year": 2012
        },
        {
            "authors": [
                "Saber Salehkaleybar",
                "AmirEmad Ghassami",
                "Negar Kiyavash",
                "Kun Zhang"
            ],
            "title": "Learning linear nongaussian causal models in the presence of latent variables",
            "venue": "Journal of Machine Learning Research,",
            "year": 2020
        },
        {
            "authors": [
                "Bernhard Sch\u00f6lkopf",
                "Francesco Locatello",
                "Stefan Bauer",
                "Nan Rosemary Ke",
                "Nal Kalchbrenner",
                "Anirudh Goyal",
                "Yoshua Bengio"
            ],
            "title": "Toward causal representation learning",
            "venue": "Proceedings of the IEEE,",
            "year": 2021
        },
        {
            "authors": [
                "Lukas Schott",
                "Jonas Rauber",
                "Matthias Bethge",
                "Wieland Brendel"
            ],
            "title": "Towards the first adversarially robust neural network model on mnist",
            "venue": "In International Conference on Learning Representations,",
            "year": 2018
        },
        {
            "authors": [
                "Anna Seigal",
                "Chandler Squires",
                "Caroline Uhler"
            ],
            "title": "Linear causal disentanglement via interventions",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Muralikrishnna G Sethuraman",
                "Romain Lopez",
                "Rahul Mohan",
                "Faramarz Fekri",
                "Tommaso Biancalani",
                "Jan-Christian H\u00fctter"
            ],
            "title": "Nodags-flow: Nonlinear cyclic causal structure learning",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2023
        },
        {
            "authors": [
                "Shohei Shimizu",
                "Patrik O Hoyer",
                "Aapo Hyv\u00e4rinen",
                "Antti Kerminen",
                "Michael Jordan"
            ],
            "title": "A linear non-gaussian acyclic model for causal discovery",
            "venue": "Journal of Machine Learning Research,",
            "year": 2003
        },
        {
            "authors": [
                "Shohei Shimizu",
                "Takanori Inazumi",
                "Yasuhiro Sogawa",
                "Aapo Hyvarinen",
                "Yoshinobu Kawahara",
                "Takashi Washio",
                "Patrik O Hoyer",
                "Kenneth Bollen",
                "Patrik Hoyer"
            ],
            "title": "Directlingam: A direct method for learning a linear non-gaussian structural equation model",
            "venue": "Journal of Machine Learning Research,",
            "year": 2011
        },
        {
            "authors": [
                "Ricardo Silva",
                "Richard Scheines",
                "Clark Glymour",
                "Peter Spirtes",
                "David Maxwell Chickering"
            ],
            "title": "Learning the structure of linear latent variable models",
            "venue": "Journal of Machine Learning Research,",
            "year": 2006
        },
        {
            "authors": [
                "Peter Spirtes"
            ],
            "title": "Calculation of entailed rank constraints in partially non-linear and cyclic models",
            "venue": "In Uncertainty in Artificial Intelligence,",
            "year": 2013
        },
        {
            "authors": [
                "Peter Spirtes",
                "Christopher Meek",
                "Thomas Richardson"
            ],
            "title": "Causal inference in the presence of latent variables and selection bias",
            "venue": "In Uncertainty in Artificial Intelligence,",
            "year": 1995
        },
        {
            "authors": [
                "S Sullivant",
                "K Talaska",
                "J Draisma"
            ],
            "title": "Trek separation for gaussian graphical models",
            "venue": "The Annals of Statistics,",
            "year": 2010
        },
        {
            "authors": [
                "Lingxiao Wang",
                "Zhuoran Yang",
                "Zhaoran Wang"
            ],
            "title": "Provably efficient causal reinforcement learning with confounded observational data",
            "venue": "In Conference on Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Feng Xie",
                "Ruichu Cai",
                "Biwei Huang",
                "Clark Glymour",
                "Zeng Hao",
                "Kun Zhang"
            ],
            "title": "Generalized independent noise condition for estimating latent variable causal graphs",
            "venue": "In Conference on Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Feng Xie",
                "Biwei Huang",
                "Zhengming Chen",
                "Yangbo He",
                "Zhi Geng",
                "Kun Zhang"
            ],
            "title": "Identification of linear non-gaussian latent hierarchical structure",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Feng Xie",
                "Biwei Huang",
                "Zhengming Chen",
                "Ruichu Cai",
                "Clark Glymour",
                "Zhi Geng",
                "Kun Zhang"
            ],
            "title": "Generalized independent noise condition for estimating causal structure with latent variables",
            "venue": "arXiv preprint arXiv:2308.06718,",
            "year": 2023
        },
        {
            "authors": [
                "Feng Xie",
                "Yan Zeng",
                "Zhengming Chen",
                "Yangbo He",
                "Zhi Geng",
                "Kun Zhang"
            ],
            "title": "Causal discovery of 1-factor measurement models in linear latent variable models with arbitrary noise",
            "venue": "distributions. Neurocomputing,",
            "year": 2023
        },
        {
            "authors": [
                "Yu Yao",
                "Tongliang Liu",
                "Mingming Gong",
                "Bo Han",
                "Gang Niu",
                "Kun Zhang"
            ],
            "title": "Instance-dependent label-noise learning under a structural causal model",
            "venue": "In Conference on Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Yan Zeng",
                "Shohei Shimizu",
                "Ruichu Cai",
                "Feng Xie",
                "Michio Yamamoto",
                "Zhifeng Hao"
            ],
            "title": "Causal discovery with multi-domain lingam for latent factors",
            "venue": "In International Joint Conferences on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Kun Zhang",
                "Aapo Hyvarinen"
            ],
            "title": "On the identifiability of the post-nonlinear causal model",
            "venue": "In Uncertainty in Artificial Intelligence,",
            "year": 2009
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Understanding causal relations is a fundamental element of artificial intelligence (Scho\u0308lkopf et al., 2021; Schott et al., 2018; Wang et al., 2021; Yao et al., 2021; Huang et al., 2023; Hong et al., 2024). The gold standard is to use randomized experiments, but this is usually too expensive or even impractical. Therefore, there has been significant attention towards the analysis of observational data to reveal causal relations, commonly known as causal discovery. Most traditional approaches focus on the situation without latent variables, such as constraint-based PC algorithm (Spirtes et al., 2000), score-based Greedy Equivalence Search (GES) (Chickering, 2002), and some Functional Causal Model-(FCM-)based algorithms (Shimizu et al., 2006; 2011; Hoyer et al., 2008a; Zhang & Hyvarinen, 2009; Peters et al., 2014; Mooij et al., 2016). However, in complex systems, we typically fail to collect and measure all task-relevant variables. Many algorithms have been proposed to handle the situation with latent variables, such as constraint-based Fast Causal Inference (FCI) (Spirtes et al., 1995), score-based Greedy PAG Search (GPS) (Claassen & Bucur, 2022), and also some FCM-based algorithms (Hoyer et al., 2008b; Salehkaleybar et al., 2020; Cai et al., 2023).\nWhile the above approaches can reveal causal relations between observed variables with or without latent variables, they cannot identify latent variables, let alone infer their causal relations. However, researchers may care more about the causal structure over latent variables in many cases (Silva et al., 2006). Assuming linear causal relations and no observed variable being the parent of any latent one in the underlying causal graph, many existing works employed sparsity of causal edges to facilitate latent causal structure learning. For instance, some early works (Silva et al., 2006; Kummerfeld & Ramsey, 2016) have proven that latent causal structure can be recovered under the three-purechildren assumption that each latent variable has at least three pure children (an observed variable \ud835\udc42 is called a pure child of a latent variable \ud835\udc3f if \ud835\udc42 has no child and only one parent \ud835\udc3f, see Definition 2.). Others (Cai et al., 2019; Xie et al., 2020; 2022) have relaxed the three-pure-children assumption to the two-pure-children assumption that each latent variable has at least two pure children. However,\nthey entailed two additional assumptions: the purity assumption that there is no causal edge between observed variables and the non-Gaussianity assumption that noises of all variables are non-Gaussian. On this basis, Xie et al. (2023b) made a further step by eliminating the purity assumption.\nIn the real world, since some variables might have nearly Gaussian distributions (Lyon, 2014), the non-Gaussianity assumption might not hold. Besides, some observed variables may directly influence others, violating the purity assumption, e.g., in financial markets, while stock returns may be confounded by some economic or political factors, they may also be causally related (Adams et al., 2021). Moreover, the occurrence of pure children will become less frequent without the purity assumption. Finally, when observed variables are also causally related, we usually want the whole causal structure involving both latent and observed variables rather than only the latent causal structure. Therefore, we endeavor to recover the whole causal structure in the case where none of the non-Gaussianity, purity, and two-pure-children assumption holds.\nRecovery of the whole causal structure requires us to first identify latent variables and then infer causal relations between any two variables. Existing works typically identify a latent variable by detecting its pure children from observed variables, which can be achieved under strong graphical and distributional assumptions. We notice that previously used assumptions are sufficient but not necessary for detecting the pure children, and some special impure children can play a similar role as pure ones. Based on this, we formulate two sets of assumptions which are milder than previous ones. They both allow causal edges between observed variables, one allows entirely arbitrary distribution and requires only one pure child per latent variable, and the other requires no pure child and imposes the non-Gaussianity requirement on only a subset of variables, two illustrative examples are shown in Figure 1. We prove identifiability of latent variables under either set of assumptions, and corresponding algorithms directly derive from our constructive proof. After this, we perform some pre-processing procedures and then modify the PC-MIMBuild (Silva et al., 2006) which has already been proved asymptotically correct to infer causal relations between any two variables.\nIn summary, our main contributions are three-fold. First, we introduce two sets of milder assumptions, both of which avoid the non-Gaussianity, purity, and two-pure-children assumption simultaneously. Second, we prove that the whole causal structure of linear latent variable models can be recovered under either set of assumptions. Third, from our constructive proof, we derive algorithms to recover the whole causal structure from purely observational data, which are both theoretically sound and computationally efficient."
        },
        {
            "heading": "2 PRELIMINARIES",
            "text": "In this paper, we focus on linear latent variable models with graph structure G = (V,E) which is a directed acyclic graph (DAG). V = L \u222a O where L = {\ud835\udc3f\ud835\udc56}\ud835\udc56 and O = {\ud835\udc42\ud835\udc56}\ud835\udc56 respectively denote the set of latent and observed variables. In the causal graph G, each variable follows:\n\ud835\udc3f\ud835\udc56 = \u2211\ufe01\n\ud835\udc3f \ud835\udc57 \u2208PaGL (\ud835\udc3f\ud835\udc56 )\n\ud835\udc4f \ud835\udc57\ud835\udc56\ud835\udc3f \ud835\udc57 + \ud835\udf16\ud835\udc3f\ud835\udc56 , \ud835\udc42\ud835\udc56 = \u2211\ufe01\n\ud835\udc3f \ud835\udc57 \u2208PaGL (\ud835\udc42\ud835\udc56 )\n\ud835\udc50 \ud835\udc57\ud835\udc56\ud835\udc3f \ud835\udc57 + \u2211\ufe01\n\ud835\udc42 \ud835\udc57 \u2208PaGO (\ud835\udc42\ud835\udc56 )\n\ud835\udc51 \ud835\udc57\ud835\udc56\ud835\udc42 \ud835\udc57 + \ud835\udf16\ud835\udc42\ud835\udc56 , (1)\nwhere PaGL (\ud835\udc49), Pa G O (\ud835\udc49) respectively denote the set of latent parents and observed parents of \ud835\udc49 in G. Moreover, PaG (\ud835\udc49) = PaGL (\ud835\udc49) \u222a Pa G O (\ud835\udc49), Pa\nG (V) = \u222a\ud835\udc49\u2208VPaG (\ud835\udc49), and ChG (\u00b7),NeiG (\u00b7) respectively denote children and neighbors. \ud835\udc4f \ud835\udc57\ud835\udc56 , \ud835\udc50 \ud835\udc57\ud835\udc56 , \ud835\udc51 \ud835\udc57\ud835\udc56 respectively denote the causal strength from \ud835\udc3f \ud835\udc57 to \ud835\udc3f\ud835\udc56 , from \ud835\udc3f \ud835\udc57 to \ud835\udc42\ud835\udc56 , from \ud835\udc42 \ud835\udc57 to \ud835\udc42\ud835\udc56 . \ud835\udf16\ud835\udc3f\ud835\udc56 and \ud835\udf16\ud835\udc42\ud835\udc56 refer to noises, which are continuous and independent of any other noise. Without loss of generality, we suppose that each variable has zero mean.\nDefinition 1. (linear latent variable model) A causal model with graph structure G = (V,E) where G is a DAG and V = L \u222aO is called a linear latent variable model if\n1. each variable follows Equation (1); 2. the distribution over V is both Markov and faithful to G;\nEquation (1) implies that all causal relations are linear and no observed variable is a parent of any latent one, both of which have almost become standard assumptions of latent causal structure learning since proposed by the seminal work (Silva et al., 2006), although very few works avoid them at the expense of other significant limitations. For instance, Kivva et al. (2021) allow non-linearity, but they assume that all latent variables are discrete. By the way, some of out theoretical results can still generalize to certain special nonlinear cases, please see Appendix C.1 for more details. Definition 2. (Pure child) An observed variable \ud835\udc42 \u2208 O is called a pure child of a latent variable \ud835\udc3f \u2208 L if PaG (\ud835\udc42) = {\ud835\udc3f} and ChG (\ud835\udc42) = \u2205.1 Example 1. In Figure 1(a), \ud835\udc3f1 has 3 pure children: \ud835\udc421, \ud835\udc422, \ud835\udc423; \ud835\udc3f2 has 2 pure children: \ud835\udc424, \ud835\udc425; \ud835\udc3f3 has only 1 pure child \ud835\udc4210. Definition 3. (Pure pair) An observed pair {\ud835\udc421, \ud835\udc422} \u2282 O is called a pure pair if \u2203\ud835\udc3f \u2208 L s.t. both \ud835\udc421 and \ud835\udc422 are pure children of \ud835\udc3f. Definition 4. (Pseudo-pure pair) An observed pair {\ud835\udc421, \ud835\udc422} \u2282 O is called a pseudo-pure pair if \u2203\ud835\udc3f \u2208 L s.t. (a) PaG (\ud835\udc421) = {\ud835\udc3f},ChG (\ud835\udc421) = {\ud835\udc422}, PaG (\ud835\udc422) = {\ud835\udc3f,\ud835\udc421},ChG (\ud835\udc422) = \u2205 or (b) PaG (\ud835\udc422) = {\ud835\udc3f},ChG (\ud835\udc422) = {\ud835\udc421}, PaG (\ud835\udc421) = {\ud835\udc3f,\ud835\udc422} and ChG (\ud835\udc421) = \u2205. Definition 5. (Generalized pure pair) An observed pair {\ud835\udc421, \ud835\udc422} \u2282 O is called a generalized pure pair if it is either a pure pair or a pseudo-pure pair. Example 2. In Figure 1(a), there are 4 pure pairs: {\ud835\udc421, \ud835\udc422}, {\ud835\udc421, \ud835\udc423}, {\ud835\udc422, \ud835\udc423}, {\ud835\udc424, \ud835\udc425}, 3 pseudo-pure pairs: {\ud835\udc426, \ud835\udc427}, {\ud835\udc428, \ud835\udc429}, {\ud835\udc4211, \ud835\udc4212}, and hence 7 generalized pure pairs.\nXie et al. (2023b) suggest that with only the two-pure-children assumption, latent variables cannot be fully identified. The problem is that a pseudo-pure pair may be falsely identified as a pure pair, once this happens, a single latent variable will be split into multiple ones, an example is shown in Figure 2. In fact, pseudopure pairs are not uncommon in the real world, e.g., in psychometric questionnaires, \u201cinsomnia\u201d and \u201cconcentration\u201d might be a pseudo-\npure pair because the former directly influences the latter and they are also confounded by a latent variable \u201cdepression\u201d. To handle this problem, they further introduce the non-Gaussianity assumption which enables discrimination between pure and pseudo-pure pairs, while such ambiguity can also be avoided with the previously used three-pure-children assumption (Kummerfeld & Ramsey, 2016). However, both the non-Gaussianity and three-pure-children assumption are only sufficient but not necessary conditions. Besides, we find that pseudo-pure pairs may even benefit causal discovery because they can play a similar role as pure pairs. This motivates us to investigate the case where none of the non-Gaussianity, purity, and two-pure-children assumption holds."
        },
        {
            "heading": "3 IDENTIFYING LATENT VARIABLES",
            "text": "To recover the whole causal structure, the first step is to identify latent variables. To this end, we formulate Assumption 1, 2, 3 at the outset of Section 3.1, 3.2, 3.3 respectively. Assumption 1 is a preliminary assumption enabling partial identification of latent variables, which can be achieved by Algorithm 1. On this basis, if Assumption 2 or Assumption 3 is also satisfied, latent variables can be fully identified. Taking the output of Algorithm 1 as the input, Algorithm 2 and 3 can accomplish this goal under Assumption 2 and 3 respectively."
        },
        {
            "heading": "3.1 PARTIALLY IDENTIFYING LATENT VARIABLES",
            "text": "Assumption 1. (a) \u2200\ud835\udc3f \u2208 L, \ud835\udc3f has at least one generalized pure pair as children, (b) \u2200\ud835\udc3f \u2208 L, NeiGL (\ud835\udc3f) \u2260 \u2205, and (c) \u2200\ud835\udc42 \u2208 O, if Pa\nG (\ud835\udc42) = \u2205, then |ChG (\ud835\udc42) | \u2265 3. 1Some recent works such as Xie et al. (2022) focused on the scenario where pure children may still be latent,\nwhich is out of our scope. We discuss the relation between these works and ours in Section 5.\nAlgorithm 1: Partially identifying latent variables. Input: Observed variable O Output: Candidate variables OC, generalized pure pairs S, purity indicator function 1pure (\u00b7)\n1 Find all candidate variables based on Definition 6. 2 Find all generalized pure pairs based on Theorem 1. 3 Identify as many pure pairs as possible based on Lemma 1.\nAssumption 1(a) indicates that a latent variable with a pseudo-pure pair as children can have no pure child. Assumption 1(b) has already been used by previous works like Kummerfeld & Ramsey (2016), which can be replaced by a much weaker assumption, please see Appendix C.2 for more details. Assumption 1(c) means that each root observed variable has a sufficient number of children. Definition 6. (Candidate variable) Given an observed variable \ud835\udc421 \u2208 O, we call \ud835\udc421 is a candidate variable if \u2200{\ud835\udc42\ud835\udc56 , \ud835\udc42 \ud835\udc57 } \u2282 O\\{\ud835\udc421}, \u2203\ud835\udc422 \u2208 O\\{\ud835\udc421, \ud835\udc42\ud835\udc56 , \ud835\udc42 \ud835\udc57 } s.t. \ud835\udc421 \u2aeb\u2215 \ud835\udc422, \ud835\udc421 \u2aeb\u2215 \ud835\udc422 |{\ud835\udc42\ud835\udc56}, \ud835\udc421 \u2aeb\u2215 \ud835\udc422 |{\ud835\udc42 \ud835\udc57 }, and \ud835\udc421 \u2aeb\u2215 \ud835\udc422 |{\ud835\udc42\ud835\udc56 , \ud835\udc42 \ud835\udc57 }.\nWe denote the set of candidate variables by OC. Definition 7. (Tetrad constraint) Given an observed pair {\ud835\udc421, \ud835\udc422} \u2282 O and a set of observed variables O\u2032 \u2282 O\\{\ud835\udc421, \ud835\udc422} s.t. |O\u2032 | \u2265 2, we call ({\ud835\udc421, \ud835\udc422},O\u2032) satisfies the tetrad constraint if \u2200{\ud835\udc42\ud835\udc56 , \ud835\udc42 \ud835\udc57 } \u2282 O\u2032,Cov(\ud835\udc421, \ud835\udc42 \ud835\udc57 )Cov(\ud835\udc422, \ud835\udc42\ud835\udc56) = Cov(\ud835\udc421, \ud835\udc42\ud835\udc56)Cov(\ud835\udc422, \ud835\udc42 \ud835\udc57 ). Theorem 1. Suppose the underlying linear latent variable model satisfies Assumption 1 and {\ud835\udc421, \ud835\udc422} \u2282 O. Then {\ud835\udc421, \ud835\udc422} \u2282 OC and ({\ud835\udc421, \ud835\udc422},O\\{\ud835\udc421, \ud835\udc422}) satisfies the tetrad constraint if and only if {\ud835\udc421, \ud835\udc422} is a generalized pure pair.\nBased on Theorem 1, we can detect all generalized pure pairs, the set of which is denoted by S. Since each latent variable has at least one generalized pure pair as children according to Assumption 1(a), every latent variable can be detected at least once. The soundness of Theorem 1 heavily relies on Assumption 1. Roughly speaking, Assumption 1(a) and 1(b) guarantees that if \ud835\udc421 and \ud835\udc422 both have latent parents, they are always candidate variables, and the tetrad constraint is satisfied if and only if {\ud835\udc421, \ud835\udc422} is a generalized pure pair. Assumption 1(c) guarantees that if \ud835\udc421 or \ud835\udc422 has no latent parent, they are not both candidate variables or the tetrad constraint is not satisfied. Lemma 1. Suppose S \u2208 S. Then S is a pure pair if (but not only if) \u2203S\u2032 \u2208 S s.t. S \u2229 S\u2032 \u2260 \u2205.\nTo fully identify latent variables, we still need to determine whether any two generalized pure pairs share a common latent parent, which requires us to first discriminate pure pairs against pseudo-pure pairs. Unfortunately, this issue can only be partially addressed based on Lemma 1 at this point, so latent variables can only be partially identified. We define a purity indicator function 1pure (\u00b7) on S. If S \u2208 S is identified as a pure pair, 1pure (S) = 1; if S is identified as a pseudo-pure pair, 1pure (S) = 0; otherwise, if S \u2208 S is unidentifiable temporarily, 1pure (S) = \u22121. The algorithm is summarized in Algorithm 1, which has O(|O|4) complexity. A detailed version can be found in Appendix D."
        },
        {
            "heading": "3.2 FULLY IDENTIFYING LATENT VARIABLES: CASE I",
            "text": "Assumption 2. (a) \u2200\ud835\udc3f \u2208 L, \ud835\udc3f has at least one pure child, (b) \u2200\ud835\udc3f \u2208 L, |NeiG (\ud835\udc3f) | \u2265 4. Furthermore, if |NeiG (\ud835\udc3f) | = 4, NeiGL (\ud835\udc3f) = {\ud835\udc3f\n\u2032}, and ChGO (\ud835\udc3f) = {\ud835\udc421, \ud835\udc422, \ud835\udc423} where {\ud835\udc421, \ud835\udc422} is a pure pair, then NeiG (\ud835\udc423) \u2260 {\ud835\udc3f, \ud835\udc3f\u2032}.\nAssumption 2(a) requires only one pure child per latent variable. On the basis of Assumption 1 and 2(a), given an \ud835\udc3f \u2208 L, there are only two cases where Assumption 2(b) is violated.\n1. \ud835\udc3f has one latent neighbor \ud835\udc3f\u2032, two pure children {\ud835\udc421, \ud835\udc422}, and no other neighbor; 2. \ud835\udc3f has one latent neighbor \ud835\udc3f\u2032, three observed children {\ud835\udc421, \ud835\udc422, \ud835\udc423}, and no other neighbor,\nwhere {\ud835\udc421, \ud835\udc422} is a pure pair, \ud835\udc423 has two latent parents {\ud835\udc3f, \ud835\udc3f\u2032} and no other neighbor. In other words, Assumption 2(b) can be satisfied in various forms, including but not limited to |NeiGL (\ud835\udc3f) | \u2265 2, or |Nei G O (\ud835\udc3f) | \u2265 4, or \u2203\ud835\udc42 \u2208 Ch G O (\ud835\udc3f) s.t. Nei G O (\ud835\udc42) \u2260 \u2205, etc. In particular, if the three-pure-children assumption is satisfied, Assumption 2 holds, so we say our assumption is milder. Lemma 2. Suppose the underlying linear latent variable model satisfies Assumption 1 and 2, S = {\ud835\udc421, \ud835\udc422} \u2208 S and 1pure (S) = \u22121. Then S is a pseudo-pure pair if and only if \u2203\ud835\udc423 \u2208 OC\\{\ud835\udc421, \ud835\udc422} s.t. ({\ud835\udc421, \ud835\udc423},O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423}) satisfies the tetrad constraint.\nAlgorithm 2: Fully identifying latent variables in Case I. Input: Observed variables O, candidate variables OC, generalized pure pairs S, purity indicator function 1pure (\u00b7) Output: Updated purity indicator function 1pure (\u00b7), sibling indicator function 1sib (\u00b7, \u00b7). 1 Discriminate pure pairs against pseudo-pure pairs based on Lemma 2. 2 Check whether two generalized pure pairs share a common latent parent based on Proposition 1.\nGiven a pseudo-pure pair S = {\ud835\udc421, \ud835\udc422}, we denote by Ref (S) any (not all) auxiliary variable \ud835\udc423 that satisfies the condition in Lemma 2. Corollary 1. Suppose S is a pseudo-pure pair. Then Ref (S) is a pure child of PaGL (S).\nBased on Lemma 2, we can completely discriminate pure pairs against pseudo-pure pairs. Besides, Corollary 1 indicates that Ref (S) is not an ordinary variable but a pure child of PaGL (S). The soundness of Lemma 2 heavily relies on Assumption 2. With Assumption 2(a), for any pseudopure pair, its latent parent has at least one pure child, which can serve as the auxiliary variable that makes the tetrad constraint in Lemma 2 hold; Without Assumption 2(b), given a pure pair, the tetrad constraint in Lemma 2 may still hold, an example is shown in Figure 2(b): for a pure pair {\ud835\udc424, \ud835\udc425}, ({\ud835\udc424, \ud835\udc421},O\\{\ud835\udc421, \ud835\udc424, \ud835\udc425}) satisfies the tetrad constraint, where O\\{\ud835\udc421, \ud835\udc424, \ud835\udc425} = {\ud835\udc422, \ud835\udc423}. Proposition 1. Let {S1,S2} \u2282 S.\n1. SupposeS1 andS2 are two pure pairs. Then PaGL (S1) = Pa G L (S2) if and only if (1)S1\u2229S2 \u2260\n\u2205, or (2) \u2203S3 \u2208 S s.t. S1 \u2229 S3 \u2260 \u2205 and S2 \u2229 S3 \u2260 \u2205. 2. Suppose S1 is a pure pair and S2 is a pseudo-pure pair. Then PaGL (S1) = Pa G L (S2) if and\nonly if (1) Ref (S2) \u2208 S1, or (2) \u2203S3 \u2208 S s.t. Ref (S2) \u2208 S3 and S1 \u2229 S3 \u2260 \u2205. 3. Suppose S1 and S2 are two pseudo-pure pairs. Then PaGL (S1) = Pa G L (S2) if and only if (1)\nRef (S1) = Ref (S2), or (2) \u2203S3 \u2208 S s.t. Ref (S1) \u2208 S3 and Ref (S2) \u2208 S3. Based on Proposition 1, we can determine whether any two generalized pure pairs share a common latent parent. We define a sibling indicator function 1sib (\u00b7, \u00b7) on S \u00d7 S. If {S1,S2} \u2282 S share a common latent parent, 1sib (S1,S2) = 1; otherwise, 1sib (S1,S2) = 0. The algorithm for fully identifying latent variables is summarized in Algorithm 2, which has O(|O|4) complexity. A detailed version can be found in Appendix D. With its output, we assign each S\ud835\udc56 \u2208 S with a latent variable \ud835\udc3f\ud835\udc56 , and let \ud835\udc3f\ud835\udc56 = \ud835\udc3f \ud835\udc57 if 1sib (S\ud835\udc56 ,S \ud835\udc57 ) = 1, such that latent variables are fully identified. Theorem 2. Suppose the underlying linear latent variable model satisfies Assumption 1 and 2. Then latent variables can be fully identified."
        },
        {
            "heading": "3.3 FULLY IDENTIFYING LATENT VARIABLES: CASE II",
            "text": "Assumption 3. (a) \u2200S\ud835\udc56 = {\ud835\udc42\ud835\udc561 , \ud835\udc42\ud835\udc562 } \u2208 S s.t. \u2200S \ud835\udc57 \u2208 S\\{S\ud835\udc56},S\ud835\udc56 \u2229 S \ud835\udc57 = \u2205, \ud835\udf16\ud835\udc42\ud835\udc561 and \ud835\udf16\ud835\udc42\ud835\udc562 are both non-Gaussian. (b) \u2200S \u2208 S with PaGL (S) = {\ud835\udc3f}, if S is a pseudo-pure pair, then \u2203\ud835\udc491 \u2208 Ch\nG (\ud835\udc3f)\\S s.t. \ud835\udc3f \u2aeb PaG (\ud835\udc491)\\{\ud835\udc3f}. Furthermore, if PaG (\ud835\udc3f) = \u2205, then \u2203\ud835\udc492 \u2208 ChG (\ud835\udc3f)\\S s.t. \ud835\udc3f \u2aeb PaG (\ud835\udc492)\\{\ud835\udc3f} and \ud835\udc491 \u2aeb \ud835\udc492 |\ud835\udc3f.\nAssumption 3(a) imposes the non-Gaussianity requirement on only some generalized pure pairs, which are exactly those on which 1pure (\u00b7) is -1. Assumption 3(b) is a bit complicated. Specifically, for any pseudo-pure pair S with latent parent \ud835\udc3f,\n1. if \ud835\udc3f is a non-root node, Assumption 3(b) requires that \u2203\ud835\udc49 \u2208 ChG (\ud835\udc3f)\\S s.t. there is no mediator or confounder between \ud835\udc3f and \ud835\udc49 , where \ud835\udc49 is not necessarily an observed variable and \ud835\udc49 may have other parent besides \ud835\udc3f; 2. if \ud835\udc3f is a root node, Assumption 3(b) requires that \u2203{\ud835\udc491, \ud835\udc492} \u2282 ChG (\ud835\udc3f)\\S s.t. there is no mediator between \ud835\udc3f and \ud835\udc491, no mediator between \ud835\udc3f and \ud835\udc492, and no confounder between \ud835\udc491 and \ud835\udc492 besides \ud835\udc3f.\nClearly, if the non-Gaussianity assumption holds, Assumption 3(a) is satisfied; if the two-purechildren assumption holds, Assumption 3(b) is satisfied, so we say our assumption is milder. By the way, it is obvious that if Assumption 2 holds, Assumption 3(b) is satisfied. Lemma 3. Suppose the underlying linear latent variable model satisfies Assumption 1 and 3, S = {\ud835\udc421, \ud835\udc422} and 1pure (S) = \u22121. Then S is a pseudo-pure pair if and only if \u2203(\ud835\udc423, \ud835\udc424) \u2282 O\\{\ud835\udc421, \ud835\udc422}\nAlgorithm 3: Fully identifying latent variables in Case II. Input: Observed variables O, generalized pure pairs S, purity indicator function 1pure (\u00b7) Output: Updated indicator function 1pure (\u00b7), sibling indicator function 1sib (\u00b7, \u00b7)\n1 Discriminate pure pairs against pseudo-pure pairs based on Lemma 3. 2 Check whether two generalized pure pairs share a common latent parent based on Proposition 2.\nwhich is an ordered pair s.t. \ud835\udc421 + \ud835\udefc\ud835\udc422 + \ud835\udefd\ud835\udc423 \u2aeb \ud835\udc421 where \ud835\udefc, \ud835\udefd satisfy\nVar(\ud835\udc421) + \ud835\udefcCov(\ud835\udc421, \ud835\udc422) + \ud835\udefdCov(\ud835\udc421, \ud835\udc423) = 0, (2) Cov(\ud835\udc421, \ud835\udc424) + \ud835\udefcCov(\ud835\udc422, \ud835\udc424) + \ud835\udefdCov(\ud835\udc423, \ud835\udc424) = 0; (3)\nor \ud835\udc422 + \ud835\udefc\ud835\udc421 + \ud835\udefd\ud835\udc423 \u2aeb \ud835\udc422 where \ud835\udefc, \ud835\udefd satisfy\nVar(\ud835\udc422) + \ud835\udefcCov(\ud835\udc422, \ud835\udc421) + \ud835\udefdCov(\ud835\udc422, \ud835\udc423) = 0, (4) Cov(\ud835\udc422, \ud835\udc424) + \ud835\udefcCov(\ud835\udc421, \ud835\udc424) + \ud835\udefdCov(\ud835\udc423, \ud835\udc424) = 0. (5)\nCorollary 2. Suppose S = {\ud835\udc421, \ud835\udc422} \u2208 S and \u2203(\ud835\udc423, \ud835\udc424) \u2282 O\\{\ud835\udc421, \ud835\udc422} which is an ordered pair s.t. \ud835\udc421 + \ud835\udefc\ud835\udc422 + \ud835\udefd\ud835\udc423 \u2aeb \ud835\udc421 where \ud835\udefc, \ud835\udefd satisfy Equation (2) and (3). Then S\u0303 = {?\u0303?1, ?\u0303?2} is a pure pair with latent parent PaGL (S) where ?\u0303?1 = \ud835\udc421 and ?\u0303?2 = \ud835\udc422 + 1 \ud835\udefc \ud835\udc421.\nBased on Lemma 3, we can completely discriminate pure pairs against pseudo-pure pairs. Besides, each pseudo-pure pair S can be converted into a pure one S\u0303 based on Corollary 2. The soundness of Lemma 3 heavily relies on Assumption 3. Without Assumption 3(a), \ud835\udc421 + \ud835\udefc\ud835\udc422 + \ud835\udefd\ud835\udc423 \u2aeb \ud835\udc421 in Lemma 3 may hold even if {\ud835\udc421, \ud835\udc422} is a pure pair since if \ud835\udc421, \ud835\udc422, \ud835\udc423 are all Gaussian, Equation (2) entails \ud835\udc421 + \ud835\udefc\ud835\udc422 + \ud835\udefd\ud835\udc423 \u2aeb \ud835\udc421. Assumption 3(b) ensures that for any pseudo-pure pair S with latent parent \ud835\udc3f, we can find two auxiliary variables {\ud835\udc423, \ud835\udc424} which makes the condition in Lemma 3 hold. If \ud835\udc3f is not a root node, \ud835\udc423 can be \ud835\udc491 (or its child) in Assumption 3(b), \ud835\udc424 can be an observed child of \ud835\udc3f\u2019s any parent; if \ud835\udc3f is a root node, \ud835\udc423, \ud835\udc424 can be \ud835\udc491, \ud835\udc492 (or their children) in Assumption 3(b). Proposition 2. Let {S1,S2} \u2282 S where S1 = {\ud835\udc421, \ud835\udc422} and S2 = {\ud835\udc423, \ud835\udc424}. Then\n1. SupposeS1 andS2 are two pure pairs. Then PaGL (S1) = Pa G L (S2) if and only if (1)S1\u2229S2 \u2260\n\u2205, or (2) \u2203S3 \u2208 S s.t. S1 \u2229 S3 \u2260 \u2205 and S2 \u2229 S3 \u2260 \u2205. 2. Suppose S1 is a pure pair and S2 is a pseudo-pure pair. Then PaGL (S1) = Pa G L (S2) if and\nonly if ({\ud835\udc422, ?\u0303?3}, {\ud835\udc421, ?\u0303?4}) satisfies the tetrad constraint. 3. Suppose S1 and S2 are two pseudo-pure pairs. Then PaGL (S1) = Pa G L (S2) if and only if\n({?\u0303?2, ?\u0303?3}, {?\u0303?1, ?\u0303?4}) satisfies the tetrad constraint. Based on Proposition 2, we can determine whether two generalized pure pairs share a common latent parent. The algorithm for fully identifying latent variables is summarized in Algorithm 3, which has O(|O|3) complexity. A detailed version can be found in Appendix D. With its output, we assign each S\ud835\udc56 \u2208 S with a latent variable \ud835\udc3f\ud835\udc56 , and let \ud835\udc3f\ud835\udc56 = \ud835\udc3f \ud835\udc57 if 1sib (S\ud835\udc56 ,S \ud835\udc57 ) = 1, such that latent variables are fully identified. Theorem 3. Suppose the underlying linear latent variable model satisfies Assumption 1 and 3. Then latent variables can be fully identified."
        },
        {
            "heading": "3.4 DISCUSSION",
            "text": "In Section 3.2 and 3.3, we respectively formulate two cases where none of the non-Gaussianity, purity, and two-pure-children assumption holds but latent variable can still be fully identified. These two cases make different trade-offs between graphical and distributional assumption. In terms of the graphical assumption, Case II requiring no pure child is more general than Case I entailing one pure child per latent variable; in terms of the distributional assumption, Case I allowing entirely arbitrary distribution is more general than Case II requiring partial non-Gaussianity.\nAlgorithm 2 and 3 are proposed to handle Case I and Case II respectively. Without sufficient prior knowledge about the underlying causal model, it is a non-trivial problem to choose between them. We design an expedient to handle this issue. We first run Algorithm 1. After that, if \u2200S \u2208 S, 1pure (S) \u2260 \u22121, latent variables can be fully identified; otherwise, \u2200{\ud835\udc42\ud835\udc56 , \ud835\udc42 \ud835\udc57 } \u2208 S s.t. 1pure ({\ud835\udc42\ud835\udc56 , \ud835\udc42 \ud835\udc57 }) = \u22121, we find an \ud835\udc42 \u2208 O\\{\ud835\udc42\ud835\udc56 , \ud835\udc42 \ud835\udc57 } s.t. Cov(\ud835\udc42\ud835\udc56 , \ud835\udc42)Cov(\ud835\udc42 \ud835\udc57 , \ud835\udc42) \u2260 0, if one of \ud835\udc42\ud835\udc56 , \ud835\udc42 \ud835\udc57 , \ud835\udc42\ud835\udc56 \u2212 Cov(\ud835\udc42\ud835\udc56 ,\ud835\udc42)Cov(\ud835\udc42 \ud835\udc57 ,\ud835\udc42)\ud835\udc42 \ud835\udc57 is Gaussian, then \ud835\udf16\ud835\udc42\ud835\udc56 or \ud835\udf16\ud835\udc42 \ud835\udc57 is Gaussian, violating Assumption 3(a), in\nAlgorithm 4: PC-MIMBuild Input: Variables V = L \u222aOD \u222aOU, and each variable in L \u222aOU has at least two indicators Output: A partially directed acyclic graph G\u0302 over V\n1 Find separation set for variables in L \u222aOU based on Theorem 19 in Silva et al. (2006) to recover the skeleton over L \u222aOU, which is denoted by G\u0302. 2 Orient v-structures in G\u0302 based on the separation sets. 3 Orient each undirected edge between a latent variable and an observed variable in G\u0302. 4 Orient as many undirected edges in G\u0302 as possible by Meek\u2019s rules (Meek, 1995). 5 Add variables in OD and corresponding causal edges to G\u0302.\nwhich case we choose Algorithm 2, otherwise we choose Algorithm 3. Although this is not a perfect method, it is much better than making a random choice. In fact, most previous works about latent causal structure learning just assumed some properties of the underlying causal models and circumvented the procedure of testing these assumptions."
        },
        {
            "heading": "4 INFERRING CAUSAL RELATIONS BETWEEN ANY TWO VARIABLES",
            "text": "After identifying latent variables, the next step is to infer causal relations between any two variables. In Section 4.1, we describe some pre-processing procedures. In Section 4.2, we present the modified PC-MIMBuild for inferring causal relations. No extra assumption is introduced in this section."
        },
        {
            "heading": "4.1 PRE-PROCESSING",
            "text": "Given an observed variable \ud835\udc42, if \u2203S \u2208 S s.t. \ud835\udc42 \u2208 S in Case I or Case II, or \u2203S \u2208 S s.t. \ud835\udc42 = Ref (S) in Case I, its causal relations with any other variable is determined. Specifically, if \ud835\udc42 \u2208 S and S is a pure pair in Case I or Case II, it has no other neighbor except a latent parent; if \ud835\udc42 \u2208 S and S is a pseudo-pure pair in Case I or Case II, it has no other neighbor except a latent parent and an observed neighbor; if \ud835\udc42 = Ref (S) in Case I, it has no other neighbor except a latent parent based on Corollary 1. Such observed variables are called determined observed variables otherwise undetermined observed variables, the set of which are denoted by OD and OU respectively. To recover the whole causal structure, we only need to focus on variables in L \u222aOU. Proposition 3. No variable in OD is a parent of any variable in L \u222aOU.\nTo recover the causal structure over latent variables, PC-MIMBuild requires that each latent variable has at least two measured indicators that can be represented as its linear function plus an independent noise. Given a latent variable \ud835\udc3f, if \ud835\udc3f has multiple pure children, these pure children can be detected and serve as the indicators of \ud835\udc3f, otherwise, \ud835\udc3f must has a pseudo-pure pair {\ud835\udc421, \ud835\udc422} as children according to Assumption 1(a). In Case I, \ud835\udc421 and Ref ({\ud835\udc421, \ud835\udc422}) can serve as indicators of \ud835\udc3f; in Case II, {?\u0303?1, ?\u0303?2} derived by Corollary 2 can serve as indicators of \ud835\udc3f. Furthermore, our objective is to recover the whole causal structure involving both latent and observed variables. Since L \u222a OU is causally sufficient based on Proposition 3, if we create two auxiliary indicators for each undetermined observed variable by adding independent noises to it, causal relations between any two variables in L \u222aOU can be revealed by PC-MIMBuild."
        },
        {
            "heading": "4.2 PC-MIMBUILD",
            "text": "An overview of PC-MIMBuild are summarized in Algorithm 4. Since no observed variable is a parent of any latent one in linear latent variable models, when searching for the separation set of any two latent variables in line 1, we limit the search space to L to reduce computational cost. For the same reason, we can orient each undirected edge between a latent variable and an observed one in line 3, which allows more undirected edges to be oriented by Meek\u2019s rules (Meek, 1995) in line 4.\nTheorem 4. Suppose the underlying linear latent variable model satisfies Assumption 1 and 2 or Assumption 1 and 3, in the limit of infinite data, G\u0302 satisfies that (1) G\u0302 has the same skeleton and v-structures as G; (2) \u2200{\ud835\udc42\ud835\udc56 , \ud835\udc42 \ud835\udc57 } \u2282 O s.t. \ud835\udc42\ud835\udc56 \u2208 PaG (\ud835\udc42 \ud835\udc57 ) and PaGL (\ud835\udc42\ud835\udc56) \u2260 Pa G L (\ud835\udc42 \ud835\udc57 ), \ud835\udc42\ud835\udc56 \u2208 Pa G\u0302 (\ud835\udc42 \ud835\udc57 ).\nIt is not surprising that without further assumptions, the causal structure can only be identified up to Markov equivalence. Fortunately, Chen et al. (2022) have proposed additional distributional\nconditions under which the causal structure can be identified completely and also a corresponding algorithm, which could apply to G\u0302 directly if their proposed conditions hold."
        },
        {
            "heading": "5 RELATION TO EXISTING WORK",
            "text": "Most traditional causal discovery approaches typically assume the absence of latent variables, but they usually yield unreliable results in situations involving latent variables which may cause spurious correlations. This has inspired extensive researches into causal discovery with latent variables. While some works aim to reveal causal relations between observed variables in the presence of latent variables, others attempt to identify latent variables and recover the latent causal structure. An important line of works employs sparsity of causal edges to facilitate latent causal structure learning for linear latent variable models. The seminal work (Silva et al., 2006) suggested that the latent causal structure can be identified under the three-pure-children assumption. On this basis, Kummerfeld & Ramsey (2016) proposed a more efficient algorithm which allows partial non-linearity based on the work of Spirtes (2013). Cai et al. (2019) first showed that two-pure-children assumption could also enable identification of latent causal structure. Subsequently, Xie et al. (2020) and Zeng et al. (2021) attempted to generalize the results of Cai et al. (2019) to more challenging scenarios. The former could address the scenario where observed variables have multiple latent parents while the latter could recover the latent causal structure shared by multiple domains. Although the requirement for pure children has been relaxed, they additionally entailed the non-Gaussianity and purity assumption. Xie et al. (2023b) made a further step by eliminating the purity assumption. Instead, we formulate two more general cases where none of the non-Gaussianity, purity, and two-pure-children assumption holds. By the way, the purity assumption is also required by some other works which utilized matrix decomposition (Anandkumar et al., 2013) or mixture oracle (Kivva et al., 2021) for latent causal structure learning, so our work is also more general than theirs in this regard.\nRecently, latent hierarchical causal structure learning has drawn significant attention, where \u201chierarchical\u201d means that some latent variables may lack observed children. The seminal work (Xie et al., 2022) relied on the non-Gaussianity, purity, and generalized two-pure-children (pure children could be either latent or observed) assumption. Huang et al. (2022) used more general assumptions that allow arbitrary distribution. Chen et al. (2023) highlighted that the assumptions in Huang et al. (2022) may not hold if there exist three mutually adjacent variables, they overcome this limitation by requiring more pure children. At a high level, each of these works decomposes the hierarchical structure into multiple layers, and then infers latent variables and their causal relations from lower to higher levels recursively. Since most algorithms used within a single level originate from those designed for conventional linear latent variable models, our results can be potentially generalized to this scenario. Some recent works leveraged counterfactual data (Brehmer et al., 2022; Ahuja et al., 2022) or interventional data (Ahuja et al., 2023; Seigal et al., 2023) rather than purely observational data for latent causal structure learning. Although they have avoided many distributional and graphical assumptions, interventional or counterfactual data is not always available in practice.\nInstead of the causal structure over only latent variables, we attempt to recover the whole causal structure involving both latent and observed variables. Previously, Adams et al. (2021) have introduced much weaker graphical assumptions for recovery of the whole causal structure, but they still required the non-Gaussianity assumption and their proposed algorithms are computationally intractable. A contemporaneous work (Xie et al., 2023a) proposed efficient algorithms to recover the whole causal structure of n-factor causal models with latent hierarchical structure, which are beyond our ability. However, they still required the non-Gaussianity and (generalized) two-pure-children assumption, and only allowed edges between particular observed variables.\nIn this paper, we decompose the recovery of the whole causal structure into two sub-problems: identification of latent variables and inference of causal relations between any two variables. In Section 3, we provide main theoretical results about the first sub-problem, the proofs of which heavily rely on the Tetrad Representation Theorem (Spirtes et al., 2000) and Darmois-Skitovich Theorem (Kagan, 1989), which are presented in Appendix B.1 and B.7. The former builds a connection between the structure of underlying causal model and the covariance of variables that can be calculated from samples. The latter means that as long as two variables share any non-Gaussian component, they cannot be statistically independent. Although many existing works (Silva et al., 2006; Xie et al., 2020; 2023b) also used them as cornerstones, their results cannot be directly involved in our framework where their required assumptions are mostly not satisfied. In Section 4, we\npresent algorithms for the second sub-problem, which are mostly based on the PC-MIMBuild (Silva et al., 2006). To make it more adaptable to our framework, we design pre-processing procedures in Section 4.1 and also make some modifications to itself in Section 4.2."
        },
        {
            "heading": "6 EXPERIMENTAL RESULTS",
            "text": "We apply our proposed algorithms to both synthetic and real-world data to demonstrate their effectiveness. Due to the space limit, we only present experimental results on synthetic data derived by causal models with structure G1 and G2 as shown in Figure 1 in the main text and provide more details in Appendix A. For each graph, we draw 10 sample sets of size \ud835\udc41=500, 1000, 2000 respectively. Each causal strength is sampled from a uniform distribution over [\u22122.0,\u22120.5]\u222a [0.5, 2.0]. Noises of causal models with structure G1 are Gaussian variables with mean 0 and standard error drawn from uniform(0.5,1), those of causal models with structure G2 are the seventh power of uniform(-1,1) variables, which are then normalized to have a standard error also drawn from uniform(0.5,1).\nWe compare our proposed methods with BPC (Silva et al., 2006), FOFC (Kummerfeld & Ramsey, 2016), and GIN (Xie et al., 2020). We use Latent Omission (LO), Latent Commission (LC), Wrong Indicator (WI) as the evaluation metrics. LO and LC are respectively the number of omitted and redundant latent variables divided by the total number of latent variables in ground truth graph. WI is the number of wrong indicators divided by the total number of observed variables in the ground truth graph, where an indicator is called wrong if it measures at least one wrong latent variable or it is still dependent of some other indicators given the latent variable it measures. Besides, we also report the Error Rate (Err) which is the number of sample sets on which LO, LC, and WI are not all 0 divided by the total number of sample sets.\nThe experimental results are summarized in Table 1. No previous approach can yield correct results since their required assumptions are not satisfied. For instance, FOFC requires the three-purechildren assumption, and its implementation in TETRAD (Ramsey et al., 2018) actually prefers at least four pure children per latent variable, so it cannot detect latent variables, leading to high LO. Using the expedient proposed in Section 3.4, we choose Algorithm 1 plus 2 to recover G1 and Algorithm 1 plus 3 to recover G2. Because causal models with structure G1 and G2 both satisfy Assumption 1 and respectively satisfy Assumption 2 and 3, our algorithms can return correct results."
        },
        {
            "heading": "7 CONCLUSION AND FUTURE WORK",
            "text": "In this paper, we endeavor to recover the whole causal structure of linear latent variable models under milder graphical and distributional assumptions. Firstly, we formulate two cases where none of the non-Gaussianity, purity, and two-pure-children assumption holds. Secondly, we prove that the whole causal structure involving both latent and observed variables is identifiable in either case. Thirdly, we also provide efficient algorithms for causal structure recovery.\nAlthough we prove identifiability under milder assumptions, they may still not hold in practice. For instance, an observed variable might be the cause of some latent variables (Adams et al., 2021), some causal relations might be non-linear (Kaltenpoth & Vreeken, 2023) or non-stationary (Liu & Kuang, 2023), and the underlying causal graph may be cyclic because feedback loops are not uncommon (Sethuraman et al., 2023). Actually, some causal questions might be answered even without a fully identified causal graph, so it is useful to investigate to which extent the causal structure can be recovered under less restrictive assumptions. Finally, to guarantee a trustworthy result, we need special algorithms to test whether the required assumptions are satisfied, for which we only propose an imperfect expedient in Section 3.4 while most existing works directly circumvent this procedure."
        },
        {
            "heading": "ACKNOWLEDGEMENT",
            "text": "XL is partially supported by the JD Technology Scholarship for Postgraduate Research in Artificial Intelligence. KZ would like to acknowledge the support from NSF Grant 2229881, the National Institutes of Health (NIH) under Contract R01HL159805, and grants from Apple Inc., KDDI Research Inc., Quris AI, and Infinite Brain Technology. TL is partially supported by the following Australian Research Council projects: FT220100318, DP220102121, LP220100527, LP220200949, IC190100031."
        },
        {
            "heading": "A MORE EXPERIMENTAL RESULTS",
            "text": "First, we compare Algorithm 1 plus 2 to existing algorithms on more causal models with structure G3,G4,G5 as shown in Figure 3(a,b,c). For each graph, we draw 10 sample sets of size \ud835\udc41=1000. Each causal strength is sampled from a uniform distribution over [\u22122.0,\u22120.5] \u222a [0.5, 2.0]. All noises are Gaussian variables generated following Section 6. Experimental results are summarized in Table 2.\nSecond, we compare Algorithm 1 plus 3 to existing algorithms on more causal models with structure G6,G7,G8 as shown in Figure 3(d,e,f). For each graph, we draw 10 sample sets of size \ud835\udc41=1000. Each causal strength is sampled from a uniform distribution over [\u22122.0,\u22120.5] \u222a [0.5, 2.0]. All noises of causal models with structure G6 and G8 are non-Gaussian variables generated following Section 6. For causal models with structure G7, noises of {\ud835\udc422, \ud835\udc424, \ud835\udc426, \ud835\udc428} are non-Gaussian while other noises are Gaussian. Experimental results are summarized in Table 3.\n1. Since causal models with structure G6 satisfy the non-Gaussianity, purity, and two-purechildren assumption, GIN can yield correct results. In this case, Assumption 1 and 3 are also satisfied, so our algorithms can also return correct results. Furthermore, because algorithms use both second-order and high-order statistics while GIN purely relies on highorder statistics, our Err is remarkably lower than GIN. Since the three-pure-children assumption is not satisfied, both BPC and FOFC always produce wrong results.\n2. Since S = {{\ud835\udc421, \ud835\udc422}, {\ud835\udc423, \ud835\udc424}, {\ud835\udc425, \ud835\udc426}, {\ud835\udc427, \ud835\udc428}} in G7 and noises of {\ud835\udc422, \ud835\udc424, \ud835\udc426, \ud835\udc428} in causal models with structure G7 are all Gaussian, Assumption 3(a) is not satisfied. In this case, our algorithm may falsely identify pure pairs as pseudo-pure ones and pseudopure pairs cannot be converted into pure ones correctly. It is possible that a single latent variable is split into multiple ones or multiple latent variables are merged into a signle one. Therefore, our algorithms cannot yield correct results. Any other algorithm also fails.\n3. Since the \ud835\udc3f3 in G8 has a pseudo-pure pair {\ud835\udc427, \ud835\udc428} as children but has no other child, Assumption 3(b) is not satisfied. In this case, our algorithm will falsely identify {\ud835\udc427, \ud835\udc428} as a pure one, and both of them will serve as the indicators of \ud835\udc3f3, leading to high WI. Therefore, our algorithms cannot yield correct results. Any other algorithm also fails.\nMoreover, we investigate the behavior of different algorithms on causal models with structure G9, G10, and G11 as shown in Figure 3(g,h,i), where there is no latent variable. For each graph, we draw 10 sample sets of size \ud835\udc41=1000. Each causal strength is sampled from a uniform distribution over [\u22122.0,\u22120.5] \u222a [0.5, 2.0]. All noises are non-Gaussian variables generated following Section 6. Overall, our algorithms return no generalized pure pair in G9,G10, and G11, indicating that there exists no latent variable. This is because no tetrad constraint is satisfied in G9 and there exists only one candidate variable \ud835\udc421 and \ud835\udc422 in G10 and G11 respectively. However, all other algorithms introduce a latent variable being the parent of all observed ones in G10 and G11. Note that in G10, the\nroot variable \ud835\udc421 has only one child \ud835\udc422, violating Assumption 1(c), but our algorithms can still yield correct results. In the case without latent variable, PC-MIMBuild can be replaced by the vanilla PC.\nFinally, we compare our algorithms with others on two real-world datasets: HolzingerSwineford1939 (HS1939) (Rosseel, 2012) and Teacher Burnout (TB) (Byrne, 2013). The experimental results are summarized in Table 4."
        },
        {
            "heading": "B PROOFS",
            "text": ""
        },
        {
            "heading": "B.1 PROOF OF THEOREM 1",
            "text": "We begin with the Tetrad Representation Theorem (Spirtes et al., 2000) which is essential for our proof. Theorem 5. (Tetrad Representation Theorem) In a linear latent variable model with graph structure G, let \ud835\udc3c1, \ud835\udc3c2, \ud835\udc3d1, \ud835\udc3d2 be four variables in G. Then ({\ud835\udc3c1, \ud835\udc3c2}, {\ud835\udc3d1, \ud835\udc3d2}) satisfies the tetrad constraint if and only if there is a choke point between {\ud835\udc3c1, \ud835\udc3c2} and {\ud835\udc3d1, \ud835\udc3d2}.\nTheorem 5 entails some graphical definitions. Specifically, in a directed acyclic (DAG) graph,\n1. a path is a sequence of distinct variables \ud835\udc491, ..., \ud835\udc49\ud835\udc5a, such that \ud835\udc49\ud835\udc58 is adjacent to \ud835\udc49\ud835\udc58+1 for all \ud835\udc58 = 1, ..., \ud835\udc5a \u2212 1. In particular, a single variable is also a path.\n2. a collider on a path \ud835\udc491, ..., \ud835\udc49\ud835\udc5a is a variable \ud835\udc49\ud835\udc56 , 1 < \ud835\udc56 < \ud835\udc5b, such that \ud835\udc49\ud835\udc56\u22121 and \ud835\udc49\ud835\udc56+1 are both parents of \ud835\udc49\ud835\udc56;\n3. a trek is a path that does not contain any collider; 4. the source of a trek is the unique node in the trek to which no arrows are directed. 5. the \ud835\udc3c side of a trek between \ud835\udc3c and \ud835\udc3d with source \ud835\udc46 is the subpath directed from \ud835\udc46 to \ud835\udc3c. In\nparticular, it is possible that \ud835\udc46 = \ud835\udc3c; 6. a choke point between two set of variables I and J is a variable \ud835\udc49 that lies on every trek\nbetween any element of I and any element of J, and \ud835\udc49 is either on the I side of every such trek or on the J side of every such trek.\nThen we further define pseudo-pure child and generalized pure child for ease of exposition. Definition 8. (Pseudo-pure child) An observed variable \ud835\udc421 \u2208 O is called a pseudo-pure child of a latent variable \ud835\udc3f \u2208 L if \ud835\udc421 \u2208 ChGO (\ud835\udc3f) and \u2203\ud835\udc422 s.t. {\ud835\udc421, \ud835\udc422} is a pseudo-pure pair. Furthermore, if \ud835\udc421 \u2208 PaG (\ud835\udc422), \ud835\udc421 is called a type-I pseudo-pure child of \ud835\udc3f; otherwise, \ud835\udc421 is called a type-II pseudo-pure child of \ud835\udc3f.\nDefinition 9. (Generalized pure child) An observed variable \ud835\udc42 \u2208 O is called a generalized pure child of a latent variable \ud835\udc3f \u2208 L if \ud835\udc42 is a pure child or a pseudo-pure child of \ud835\udc3f.\nAssumption 1. (a) \u2200\ud835\udc3f \u2208 L, \ud835\udc3f has at least one generalized pure pair as children, (b) \u2200\ud835\udc3f \u2208 L, NeiGL (\ud835\udc3f) \u2260 \u2205, and (c) \u2200\ud835\udc42 \u2208 O, if Pa\nG (\ud835\udc42) = \u2205, then |ChG (\ud835\udc42) | \u2265 3. Assumption 1(a) indicates that each latent variable has at least two generalized pure children.\nBefore proving Theorem 1, we present three lemmas about candidate variables under Assumption 1.\nLemma 4. Suppose \ud835\udc421 \u2208 O and PaGL (\ud835\udc421) \u2260 \u2205. Then \ud835\udc421 \u2208 O C.\nProof. Let \ud835\udc3f1 \u2208 PaGL (\ud835\udc421). According to Assumption 1(a), \ud835\udc3f1 has a generalized pure child \ud835\udc422 \u2260 \ud835\udc421. Besides, \ud835\udc3f1 has a latent neighbor \ud835\udc3f2 according to Assumption 1(b) and \ud835\udc3f2 has two generalized pure children {\ud835\udc423, \ud835\udc424} \u2282 O\\{\ud835\udc421, \ud835\udc422} according to Assumption 1(a). Therefore, there are 3 treks \ud835\udc421 \u2190 \ud835\udc3f1 \u2192 \ud835\udc422, \ud835\udc421 \u2190 \ud835\udc3f1 \u2212 \ud835\udc3f2 \u2192 \ud835\udc423, \ud835\udc421 \u2190 \ud835\udc3f1 \u2212 \ud835\udc3f2 \u2192 \ud835\udc424. That is, \u2200{\ud835\udc42\ud835\udc56 , \ud835\udc42 \ud835\udc57 } \u2282 O\\{\ud835\udc421}, let \ud835\udc42\ud835\udc58 \u2208 {\ud835\udc422, \ud835\udc423, \ud835\udc424}\\{\ud835\udc42\ud835\udc56 , \ud835\udc42 \ud835\udc57 }, we have \ud835\udc421 \u2aeb\u2215 \ud835\udc42\ud835\udc58 , \ud835\udc421 \u2aeb\u2215 \ud835\udc42\ud835\udc58 |{\ud835\udc42\ud835\udc56}, \ud835\udc421 \u2aeb\u2215 \ud835\udc42\ud835\udc58 |{\ud835\udc42 \ud835\udc57 }, and \ud835\udc421 \u2aeb\u2215 \ud835\udc42\ud835\udc58 |{\ud835\udc42\ud835\udc56 , \ud835\udc42 \ud835\udc57 }, so \ud835\udc421 \u2208 OC. \u25a1\nLemma 5. Suppose \ud835\udc421 \u2208 O and PaGL (\ud835\udc421) = \u2205. If \ud835\udc421 \u2208 O C, |NeiGO (\ud835\udc421) | \u2265 2.\nProof. This lemma is proved by contradiction. Suppose |NeiGO (\ud835\udc421) | < 2, combined with Assumption 1(c), \ud835\udc421 is a leaf node which has no other neighbor besides an observed parent \ud835\udc422. Based on the local Markov property (Peters et al., 2017), \ud835\udc421 \u2aeb O\\{\ud835\udc421, \ud835\udc422}|{\ud835\udc422}, so \ud835\udc421 \u2209 OC, which leads to contradiction. \u25a1\nLemma 6. Suppose {\ud835\udc421 \ud835\udc422} \u2208 O and PaGL (\ud835\udc421) = Pa G L (\ud835\udc422) = \u2205. If {\ud835\udc421, \ud835\udc422} \u2282 O C, then |NeiGO (\ud835\udc421) \u222a Nei G O (\ud835\udc422)\\{\ud835\udc421, \ud835\udc422}| \u2265 2.\nProof. This lemma is proved by contradiction. Suppose |NeiGO (\ud835\udc421) \u222a Nei G O (\ud835\udc422)\\{\ud835\udc421, \ud835\udc422}| \u2264 1. There are two possible cases.\n1. Suppose \ud835\udc422 \u2209 NeiGO (\ud835\udc421), then |Nei G O (\ud835\udc421) \u222a Nei G O (\ud835\udc422)\\{\ud835\udc421, \ud835\udc422}| \u2264 1 implies that\n|NeiGO (\ud835\udc421) | \u2264 1, based on Lemma 5, \ud835\udc421 \u2209 O C, which leads to contradiction.\n2. Suppose \ud835\udc422 \u2208 NeiGO (\ud835\udc421). If |Nei G O (\ud835\udc421) \u222a Nei G O (\ud835\udc422)\\{\ud835\udc421, \ud835\udc422}| = 0, then Nei G O (\ud835\udc422) =\n{\ud835\udc421}, based on Lemma 5, \ud835\udc421 \u2209 OC, which leads to contradiction. If |NeiGO (\ud835\udc421) \u222a NeiGO (\ud835\udc422)\\{\ud835\udc421, \ud835\udc422}| = 1, since |Nei G O (\ud835\udc421) | \u2265 2 and |Nei G O (\ud835\udc422) | \u2265 2, there exists \ud835\udc423 \u2208 O\\{\ud835\udc421, \ud835\udc422} s.t. NeiGO (\ud835\udc421) = {\ud835\udc422, \ud835\udc423} and Nei G O (\ud835\udc422) = {\ud835\udc421, \ud835\udc423}. According to Assumption 1(c), neither \ud835\udc421 nor \ud835\udc422 is a root node, so either \ud835\udc421 or \ud835\udc422 is a leaf node. Without loss of generality, let \ud835\udc421 be a leaf node, then \ud835\udc421 has no other neighbor besides two observed parents \ud835\udc422, \ud835\udc423. Based on the local Markov property, \ud835\udc421 \u2aeb O\\{\ud835\udc422, \ud835\udc423}, that is, \ud835\udc421 \u2209 OC, which leads to contradiction.\n\u25a1\nTheorem 1. Suppose the underlying linear latent variable model satisfies Assumption 1 and {\ud835\udc421, \ud835\udc422} \u2282 O. Then {\ud835\udc421, \ud835\udc422} \u2282 OC and ({\ud835\udc421, \ud835\udc422},O\\{\ud835\udc421, \ud835\udc422}) satisfies the tetrad constraint if and only if {\ud835\udc421, \ud835\udc422} is a generalized pure pair.\nProof. (i) \u201cIf\u201d. Suppose {\ud835\udc421, \ud835\udc422} is a generalized pure pair, then PaGL (\ud835\udc421) \u2260 \u2205 and Pa G L (\ud835\udc422) \u2260 \u2205, based on Lemma 4, {\ud835\udc421, \ud835\udc422} \u2282 OC. Let PaGL ({\ud835\udc421, \ud835\udc422}) = {\ud835\udc3f}, then \u2200\ud835\udc42 \u2208 O\\{\ud835\udc421, \ud835\udc422}, \ud835\udc3f lies in each trek between \ud835\udc421 and \ud835\udc42 and is on the \ud835\udc421 side of every such trek. This also holds for each trek between \ud835\udc422 and \ud835\udc42. Therefore, \ud835\udc3f is a choke point between {\ud835\udc421, \ud835\udc422} and O\\{\ud835\udc421, \ud835\udc422}. Based on Theorem 5, we reach the conclusion that ({\ud835\udc421, \ud835\udc422},O\\{\ud835\udc421, \ud835\udc422}) satisfies the tetrad constraint.\n(ii) \u201cOnly if\u201d. This part is proved by contradiction. Suppose {\ud835\udc421, \ud835\udc422} is not a generalized pure pair, there are 4 possible cases w.r.t. PaGL (\ud835\udc421) and Pa G L (\ud835\udc422).\n1. Suppose ones of PaGL (\ud835\udc421) and Pa G L (\ud835\udc422) is an empty set. Without loss of generality,\nwe suppose PaGL (\ud835\udc421) = \u2205 and Pa G L (\ud835\udc422) \u2260 \u2205. Based on Lemma 5, \ud835\udc421 has an observed neighbor \ud835\udc423 \u2208 O\\{\ud835\udc422}. Let \ud835\udc3f \u2208 PaGL (\ud835\udc422), then \ud835\udc3f has a generalized pure child \ud835\udc424 \u2208 O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423} according to Assumption 1(a). Clearly, there are two nonintersecting treks \ud835\udc421 \u2212\ud835\udc423 and \ud835\udc422 \u2190 \ud835\udc3f \u2192 \ud835\udc424. Therefore, there is no choke point between {\ud835\udc421, \ud835\udc422} and {\ud835\udc423, \ud835\udc424}. An illustrative example is shown in Figure 4(a).\n2. Suppose PaGL (\ud835\udc421) = \u2205 and Pa G L (\ud835\udc422) = \u2205. Based on Lemma 5 and 6, \u2203{\ud835\udc423, \ud835\udc424} \u2208\nO\\{\ud835\udc421, \ud835\udc422} s.t. \ud835\udc423 \u2208 NeiGO (\ud835\udc421) and \ud835\udc424 \u2208 Nei G O (\ud835\udc422). Clearly, there are two nonintersecting treks\ud835\udc421\u2212\ud835\udc423 and\ud835\udc422\u2212\ud835\udc424. Therefore, there is no choke point between {\ud835\udc421, \ud835\udc422} and {\ud835\udc423, \ud835\udc424}. An illustrative example is shown in Figure 4(b).\n3. Suppose PaGL (\ud835\udc421) \u2260 \u2205, Pa G L (\ud835\udc422) \u2260 \u2205 and |Pa G L ({\ud835\udc421, \ud835\udc422}) | > 1. That is, there exist\n\ud835\udc3f1 \u2208 PaGL (\ud835\udc421), \ud835\udc3f2 \u2208 Pa G L (\ud835\udc422) s.t. \ud835\udc3f1 \u2260 \ud835\udc3f2. According to Assumption 1(a), \ud835\udc3f1 has a generalized pure child \ud835\udc423 \u2208 O\\{\ud835\udc421, \ud835\udc422}. Similarly, \ud835\udc3f2 has a generalized pure child \ud835\udc424 \u2208 O\\{\ud835\udc421, \ud835\udc422} and \ud835\udc423 \u2260 \ud835\udc424. Clearly, there are two non-intersecting treks \ud835\udc421 \u2190 \ud835\udc3f1 \u2192 \ud835\udc423 and \ud835\udc422 \u2190 \ud835\udc3f2 \u2192 \ud835\udc424. Therefore, there is no choke point between {\ud835\udc421, \ud835\udc422} and {\ud835\udc423, \ud835\udc424}. An illustrative example is shown in Figure 4(c).\n4. Suppose PaGL (\ud835\udc421) \u2260 \u2205, Pa G L (\ud835\udc422) \u2260 \u2205 and |Pa G L ({\ud835\udc421, \ud835\udc422}) | = 1. Since {\ud835\udc421, \ud835\udc422} is not a\ngeneralized pure pair, there is NeiGO (\ud835\udc421)\\{\ud835\udc422} \u2260 \u2205 or Nei G O (\ud835\udc422)\\{\ud835\udc421} \u2260 \u2205. Without loss of generality, we suppose PaGL ({\ud835\udc421, \ud835\udc422}) = {\ud835\udc3f1}, \ud835\udc423 \u2208 Nei G O (\ud835\udc422)\\{\ud835\udc421}. Then \ud835\udc3f1 has a latent neighbor \ud835\udc3f2 according to Assumption 1(b) and \ud835\udc3f2 has a generalized pure child \ud835\udc424 \u2208 O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423} according to Assumption 1(a). Clearly, there are two non-intersecting treks \ud835\udc422 \u2212 \ud835\udc423 and \ud835\udc421 \u2190 \ud835\udc3f1 \u2212 \ud835\udc3f2 \u2192 \ud835\udc424. Therefore, there is no choke point between {\ud835\udc421, \ud835\udc422} and {\ud835\udc423, \ud835\udc424}. An illustrative example is shown in Figure 4(d).\nBased on Theorem 5, we reach the conclusion that ({\ud835\udc421, \ud835\udc422},O\\{\ud835\udc421, \ud835\udc422}) does not satisfy the tetrad constraint, which leads to contradiction. \u25a1"
        },
        {
            "heading": "B.2 PROOF OF LEMMA 1",
            "text": "Lemma 1. Suppose S \u2208 S. Then S is a pure pair if (but not only if) \u2203S\u2032 \u2208 S s.t. S \u2229 S\u2032 \u2260 \u2205.\nProof. (i) \u201cIf\u201d. This can be easily derived from the Definition 3, 4, and 5.\n(ii) \u201cNot only if\u201d. If a latent variable \ud835\udc3f has no pure child except \ud835\udc421 and \ud835\udc422, then {\ud835\udc421, \ud835\udc422} is a pure pair but it does not overlap with any other generalized pure pair. \u25a1"
        },
        {
            "heading": "B.3 PROOF OF LEMMA 2",
            "text": "Assumption 2. (a) \u2200\ud835\udc3f \u2208 L, \ud835\udc3f has at least one pure child, (b) \u2200\ud835\udc3f \u2208 L, |NeiG (\ud835\udc3f) | \u2265 4. Furthermore, if |NeiG (\ud835\udc3f) | = 4, NeiGL (\ud835\udc3f) = {\ud835\udc3f\n\u2032}, and ChGO (\ud835\udc3f) = {\ud835\udc421, \ud835\udc422, \ud835\udc423} where {\ud835\udc421, \ud835\udc422} is a pure pair, then NeiG (\ud835\udc423) \u2260 {\ud835\udc3f, \ud835\udc3f\u2032}. Lemma 2. Suppose the underlying linear latent variable model satisfies Assumption 1 and 2, S = {\ud835\udc421, \ud835\udc422} \u2208 S and 1pure (S) = \u22121. Then S is a pseudo-pure pair if and only if \u2203\ud835\udc423 \u2208 OC\\{\ud835\udc421, \ud835\udc422} s.t. ({\ud835\udc421, \ud835\udc423},O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423}) satisfies the tetrad constraint.\nProof. (i) \u201cOnly if\u201d. Suppose S = {\ud835\udc421, \ud835\udc422} is a pseudo-pure pair and let PaGL (S) = {\ud835\udc3f}. According to Assumption 2(a), \ud835\udc3f has a pure child \ud835\udc423 \u2208 O\\{\ud835\udc421, \ud835\udc422}. Based on Lemma 4, \ud835\udc423 \u2208 OC. Besides, \u2200\ud835\udc42 \u2208 O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423}, \ud835\udc3f lies in each trek between \ud835\udc421 and \ud835\udc42 and is on the \ud835\udc421 side of every such trek. This also holds for each trek between \ud835\udc423 and \ud835\udc42. Therefore, \ud835\udc3f is a choke point between {\ud835\udc421, \ud835\udc423} and O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423}. Based on Theorem 5, we reach the conclusion that ({\ud835\udc421, \ud835\udc423},O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423}) satisfies the tetrad constraint.\n(ii) \u201cIf\u201d. This part is proved by contradiction. Suppose S = {\ud835\udc421, \ud835\udc422} is a pure pair and let PaGL (S) = {\ud835\udc3f1}. Because 1pure (S) = \u22121, \ud835\udc3f1 has no pure child except \ud835\udc421 and \ud835\udc422, otherwise we can derive 1pure (S) = 1 based on Lemma 1. There are 5 possible cases w.r.t. PaGL (\ud835\udc423).\n1. Suppose PaGL (\ud835\udc423) = \u2205. Based on Lemma 5, \ud835\udc423 has an observed children \ud835\udc424 \u2208 O\\{\ud835\udc421, \ud835\udc422}. Besides, \ud835\udc3f1 has a latent neighbor \ud835\udc3f2 according to Assumption 1(b) and \ud835\udc3f2 has a generalized pure child \ud835\udc425 \u2208 O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423, \ud835\udc424} according to Assumption 1(a). Clearly, there are two non-intersecting treks \ud835\udc423 \u2212 \ud835\udc424 and \ud835\udc421 \u2190 \ud835\udc3f1 \u2212 \ud835\udc3f2 \u2192 \ud835\udc425. Therefore, there is no choke point between {\ud835\udc421, \ud835\udc423} and {\ud835\udc424, \ud835\udc425}. An illustrative example is shown in Figure 5(a).\n2. Suppose PaGL (\ud835\udc423) = {\ud835\udc3f1}. Since \ud835\udc423 is not a pure child of \ud835\udc3f1, \ud835\udc423 has an observed neighbor \ud835\udc424 \u2208 O\\{\ud835\udc421, \ud835\udc422}. Besides, \ud835\udc3f1 has a latent neighbor \ud835\udc3f2 according to Assumption 1(b) and \ud835\udc3f2 has a generalized pure child \ud835\udc425 \u2208 O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423, \ud835\udc424} according to Assumption 1(a). Clearly, there are two non-intersecting treks \ud835\udc423 \u2212\ud835\udc424 and \ud835\udc421 \u2190 \ud835\udc3f1 \u2212 \ud835\udc3f2 \u2192 \ud835\udc425. Therefore, there is no choke point between {\ud835\udc421, \ud835\udc423} and {\ud835\udc424, \ud835\udc425}. An illustrative example is shown in Figure 5(b).\n3. Suppose PaGL (\ud835\udc423) \u2260 {\ud835\udc3f1} and \u2203\ud835\udc3f2 \u2208 Pa G L (\ud835\udc423)\\{\ud835\udc3f1} s.t. \ud835\udc3f2 \u2209 Nei G L (\ud835\udc3f1). Then \ud835\udc3f2 has a\ngeneralized pure child \ud835\udc424 \u2208 O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423} according to Assumption 1(a). Besides, \ud835\udc3f1 has a latent neighbor \ud835\udc3f3 \u2260 \ud835\udc3f2 according to Assumption 1(b) and \ud835\udc3f3 has a generalized pure child \ud835\udc425 \u2208 O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423, \ud835\udc424} according to Assumption 1(a). Clearly, there are two nonintersecting treks \ud835\udc423 \u2190 \ud835\udc3f2 \u2192 \ud835\udc424 and \ud835\udc421 \u2190 \ud835\udc3f1 \u2212 \ud835\udc3f3 \u2192 \ud835\udc425. Therefore, there is no choke point between {\ud835\udc421, \ud835\udc423} and {\ud835\udc424, \ud835\udc425}. An illustrative example is shown in Figure 5(c).\n4. Suppose PaGL (\ud835\udc423) \u2260 {\ud835\udc3f1}, \u2200\ud835\udc3f \u2208 Pa G L (\ud835\udc423)\\{\ud835\udc3f1}, \ud835\udc3f \u2208 Nei G L (\ud835\udc3f1) and \ud835\udc3f1 \u2209 Pa G L (\ud835\udc423). Let\n\ud835\udc3f2 \u2208 PaGL (\ud835\udc423)\\{\ud835\udc3f1}, then \ud835\udc3f2 has a generalized pure child \ud835\udc424 \u2208 O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423} according to Assumption 1(a). Furthermore, there are two possible sub-cases w.r.t. NeiGL (\ud835\udc3f1).\n(a) Suppose |NeiGL (\ud835\udc3f1) | \u2265 2. Then \ud835\udc3f1 has a latent neighbor \ud835\udc3f3 \u2260 \ud835\udc3f2. The remaining proof is the same as Case 3.\n(b) Suppose |NeiGL (\ud835\udc3f1) | = 1. According to Assumption 2(b) that |Nei G (\ud835\udc3f1) | \u2265 4, \u2203\ud835\udc425 \u2208\nChGO (\ud835\udc3f1)\\{\ud835\udc421, \ud835\udc422}. Since \ud835\udc3f1 \u2209 Pa G L (\ud835\udc423) and \ud835\udc424 is a generalized pure child of \ud835\udc3f2, we have \ud835\udc425 \u2260 \ud835\udc423 and \ud835\udc425 \u2260 \ud835\udc424. Clearly, there are two non-intersecting treks \ud835\udc423 \u2190 \ud835\udc3f2 \u2192 \ud835\udc424 and \ud835\udc421 \u2190 \ud835\udc3f1 \u2192 \ud835\udc425. Therefore, there is no choke point between {\ud835\udc421, \ud835\udc423} and {\ud835\udc424, \ud835\udc425}. An illustrative example is shown in Figure 5(d).\nAccording to Assumption 1(b), NeiGL (\ud835\udc3f1) \u2260 \u2205, so there is no other possible sub-case.\n5. Suppose PaGL (\ud835\udc423) \u2260 {\ud835\udc3f1}, \u2200\ud835\udc3f \u2208 Pa G L (\ud835\udc423)\\{\ud835\udc3f1}, \ud835\udc3f \u2208 Nei G L (\ud835\udc3f1) and \ud835\udc3f1 \u2208 Pa G L (\ud835\udc423). Let\n\ud835\udc3f2 \u2208 PaGL (\ud835\udc423)\\{\ud835\udc3f1}, then \ud835\udc3f2 has a generalized pure child \ud835\udc424 \u2208 O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423} according to Assumption 1(a). Furthermore, there are three possible sub-cases w.r.t. NeiGL (\ud835\udc3f1).\n(a) Suppose |NeiGL (\ud835\udc3f1) | \u2265 2. The remaining proof is the same as Case 4(a). (b) Suppose |NeiGL (\ud835\udc3f1) | = 1 and |Nei\nG (\ud835\udc3f1) | > 4, let \ud835\udc425 \u2208 ChGO (\ud835\udc3f1)\\{\ud835\udc421, \ud835\udc422, \ud835\udc423}. Since \ud835\udc424 is a generalized pure child of \ud835\udc3f2, \ud835\udc425 \u2260 \ud835\udc424. The remaining proof is the same as Case 4(b).\n(c) Suppose |NeiGL (\ud835\udc3f1) | = 1 and |Nei G (\ud835\udc3f1) | = 4, considering the supposition at the be-\nginning of Case 5, we have NeiGL (\ud835\udc3f1) = {\ud835\udc3f2},Ch G O (\ud835\udc3f1) = {\ud835\udc421, \ud835\udc422, \ud835\udc423}, Pa G L (\ud835\udc423) = {\ud835\udc3f1, \ud835\udc3f2}. According to Assumption 2(b) that NeiG (\ud835\udc423) \u2260 {\ud835\udc3f1, \ud835\udc3f2}, there is NeiGO (\ud835\udc423) \u2260 \u2205. Let \ud835\udc425 \u2208 Nei G O (\ud835\udc423). Since \ud835\udc424 is a generalized pure child of \ud835\udc3f2, \ud835\udc425 \u2260 \ud835\udc424. Clearly, there are two non-intersecting treks \ud835\udc423 \u2212\ud835\udc425 and \ud835\udc421 \u2190 \ud835\udc3f1 \u2212 \ud835\udc3f2 \u2192 \ud835\udc424. Therefore, there is no choke point between {\ud835\udc421, \ud835\udc423} and {\ud835\udc424, \ud835\udc425}. An illustrative example is shown in Figure 5(e).\nAccording to Assumption 1(b) and Assumption 2(b), NeiGL (\ud835\udc3f1) \u2260 \u2205 and |Nei G (\ud835\udc3f1) | \u2265 4, there is no other possible sub-case.\nBased on Theorem 5, we reach the conclusion that \u2200\ud835\udc423 \u2208 OC\\{\ud835\udc421, \ud835\udc422}, ({\ud835\udc421, \ud835\udc423},O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423}) does not satisfy the tetrad constraint, which leads to contradiction.\n\u25a1"
        },
        {
            "heading": "B.4 PROOF OF COROLLARY 1",
            "text": "Corollary 1. Suppose S is a pseudo-pure pair. Then Ref (S) is a pure child of PaGL (S).\nProof. This corollary is proved by contradiction. Suppose Ref (S) is not a pure child of PaGL (S), let S = {\ud835\udc421, \ud835\udc422},Ref (S) = \ud835\udc423 and PaGL (S) = {\ud835\udc3f1}. According to Assumption 2(a), \ud835\udc3f1 has a pure child \ud835\udc424 \u2208 O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423}. Then there are three possible cases w.r.t. PaGL (\ud835\udc423).\n1. Suppose PaGL (\ud835\udc423) = \u2205. Based on Lemma 2 and Lemma 5, \ud835\udc423 has an observed neighbor \ud835\udc425 \u2208 O\\{\ud835\udc421, \ud835\udc422, \ud835\udc424}. Clearly, there are two non-intersecting treks \ud835\udc421 \u2190 \ud835\udc3f1 \u2192 \ud835\udc424 and \ud835\udc423 \u2212\ud835\udc425. Therefore, there is no choke point between {\ud835\udc421, \ud835\udc423} and {\ud835\udc424, \ud835\udc425}.\n2. Suppose PaGL (\ud835\udc423) \u2260 \u2205 and Pa G L (\ud835\udc423) \u2260 {\ud835\udc3f1}. Let \ud835\udc3f2 \u2208 Pa G L (\ud835\udc423)\\{\ud835\udc3f1}. Then \ud835\udc3f2 has a\ngeneralized pure child \ud835\udc425 \u2208 O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423, \ud835\udc424}. Clearly, there are two non-intersecting treks \ud835\udc421 \u2190 \ud835\udc3f1 \u2192 \ud835\udc424 and \ud835\udc423 \u2190 \ud835\udc3f2 \u2192 \ud835\udc425. Therefore, there is no choke point between {\ud835\udc421, \ud835\udc423} and {\ud835\udc424, \ud835\udc425}.\n3. Suppose PaGL (\ud835\udc423) = {\ud835\udc3f1}. Since \ud835\udc423 is not a pure child of \ud835\udc3f1, it has an observed neighbor \ud835\udc425 \u2208 O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423, \ud835\udc424}. Clearly, there are two non-intersecting treks \ud835\udc421 \u2190 \ud835\udc3f1 \u2192 \ud835\udc424 and \ud835\udc423 \u2212\ud835\udc425. Therefore, there is no choke point between {\ud835\udc421, \ud835\udc423} and {\ud835\udc424, \ud835\udc425}.\nBased on Theorem 5, we reach the conclusion that ({\ud835\udc421, \ud835\udc423},O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423}) does not satisfy the tetrad constraint, which leads to contradiction. \u25a1"
        },
        {
            "heading": "B.5 PROOF OF PROPOSITION 1",
            "text": "Proposition 1. Let {S1,S2} \u2282 S.\n1. SupposeS1 andS2 are two pure pairs. Then PaGL (S1) = Pa G L (S2) if and only if (1)S1\u2229S2 \u2260\n\u2205, or (2) \u2203S3 \u2208 S s.t. S1 \u2229 S3 \u2260 \u2205 and S2 \u2229 S3 \u2260 \u2205. 2. Suppose S1 is a pure pair and S2 is a pseudo-pure pair. Then PaGL (S1) = Pa G L (S2) if and\nonly if (1) Ref (S2) \u2208 S1, or (2) \u2203S3 \u2208 S s.t. Ref (S2) \u2208 S3 and S1 \u2229 S3 \u2260 \u2205. 3. Suppose S1 and S2 are two pseudo-pure pairs. Then PaGL (S1) = Pa G L (S2) if and only if (1)\nRef (S1) = Ref (S2), or (2) \u2203S3 \u2208 S s.t. Ref (S1) \u2208 S3 and Ref (S2) \u2208 S3.\nProof. (i) \u201cIf\u201d.\n1. Suppose S1 and S2 are two pure pairs. (1) Suppose S1 \u2229 S2 \u2260 \u2205. Then PaGL (S1) = PaGL (S1 \u2229 S2) = Pa G L (S2). (2) Suppose \u2203S3 \u2208 S s.t. S1 \u2229 S3 \u2260 \u2205 and S2 \u2229 S3 \u2260 \u2205. Then\nPaGL (S1) = Pa G L (S3) = Pa G L (S2).\n2. Suppose S1 is a pure pair and S2 is a pseudo-pure pair. (1) Suppose Ref (S2) \u2208 S1. Then based on Corollary 1, PaGL (S1) = Pa G L (Ref (S2)) = Pa G L (S2). (2) Suppose \u2203S3 \u2208 S s.t.\nRef (S2) \u2208 S3 and S1 \u2229 S3 \u2260 \u2205. Then based on Corollary 1, PaGL (S1) = Pa G L (S3) = PaGL (Ref (S2)) = Pa G L (S2).\n3. Suppose S1 and S2 are two pseudo-pure pairs. (1) Suppose Ref (S1) = Ref (S2). Then based on Corollary 1, PaGL (S1) = Pa G L (Ref (S1)) = Pa G L (Ref (S2)) = Pa G L (S2). (2) Suppose\n\u2203S3 \u2208 S s.t. Ref (S1) \u2208 S3 and Ref (S2) \u2208 S3. Then based on Corollary 1, PaGL (S1) = PaGL (Ref (S1)) = Pa G L (S3) = Pa G L (Ref (S2)) = Pa G L (S2).\n(ii) \u201cOnly if\u201d.\n1. Suppose S1 and S2 are two pure pairs and PaGL (S1) = Pa G L (S2) = {\ud835\udc3f}. Then \u2200\ud835\udc42 \u2208 S1\u222aS2,\n\ud835\udc42 is a pure child of \ud835\udc3f. It is obviously possible that S1 \u2229 S2 \u2260 \u2205; otherwise, \u2200\ud835\udc421 \u2208 S1 and \u2200\ud835\udc422 \u2208 S2, S3 = {\ud835\udc421, \ud835\udc422} is also a pure pair, that is, S3 \u2208 S.\n2. Suppose S1 is a pure pair, S2 is a pseudo-pure pair, and PaGL (S1) = Pa G L (S2) = {\ud835\udc3f}. Then\nbased on Corollary 1, \u2200\ud835\udc42 \u2208 S1\u222a{Ref (S2)}, \ud835\udc42 is a pure child of \ud835\udc3f. It is obviously possible that Ref (S2) \u2208 S1; otherwise, \u2200\ud835\udc42 \u2208 S1, S3 = {\ud835\udc42,Ref (S2)} is also a pure pair, that is, S3 \u2208 S.\n3. Suppose S1 and S2 are two pure pairs and PaGL (S1) = Pa G L (S2) = {\ud835\udc3f}. Then based on\nCorollary 1, both Ref (S1) and Ref (S2) are pure children of \ud835\udc3f. It is obviously possible that Ref (S1) = Ref (S2); otherwise S3 = {Ref (S1),Ref (S2)} is also a pure pair, that is, S3 \u2208 S.\n\u25a1"
        },
        {
            "heading": "B.6 PROOF OF THEOREM 2",
            "text": "Theorem 2. Suppose the underlying linear latent variable model satisfies Assumption 1 and 2. Then latent variables can be fully identified.\nProof. Theorem 1 ensures no latent omission under Assumption 1 while Proposition 1 ensures no latent commission under Assumption 1 and 2. Therefore, latent variables can be fully identified. \u25a1"
        },
        {
            "heading": "B.7 PROOF OF LEMMA 3",
            "text": "We begin with Darmois-Skitovitch Theorem (Kagan, 1989) which is essential for our proof. Theorem 6. (Darmois-Skitovitch Theorem) Suppose two random variables \ud835\udc491 and \ud835\udc492 can be represented as linear combinations of independent random variables {\ud835\udc52\ud835\udc56}\ud835\udc56 ,\n\ud835\udc491 = \u2211\ufe01 \ud835\udc56 \ud835\udefc\ud835\udc56\ud835\udc52\ud835\udc56 , \ud835\udc492 = \u2211\ufe01 \ud835\udc56 \ud835\udefd\ud835\udc56\ud835\udc52\ud835\udc56 . (6)\nThen, if \ud835\udc491 and \ud835\udc492 are independent, all variables \ud835\udc52 \ud835\udc57 for which \ud835\udefc \ud835\udc57 \ud835\udefd \ud835\udc57 \u2260 0 are Gaussian. In other words, if there exists a non-Gaussian \ud835\udc52 \ud835\udc57 for which \ud835\udefc \ud835\udc57 \ud835\udefd \ud835\udc57 \u2260 0, \ud835\udc491 and \ud835\udc492 are dependent.\nAssumption 3. (a) \u2200S\ud835\udc56 = {\ud835\udc42\ud835\udc561 , \ud835\udc42\ud835\udc562 } \u2208 S s.t. \u2200S \ud835\udc57 \u2208 S\\{S\ud835\udc56},S\ud835\udc56 \u2229 S \ud835\udc57 = \u2205, \ud835\udf16\ud835\udc42\ud835\udc561 and \ud835\udf16\ud835\udc42\ud835\udc562 are both non-Gaussian. (b) \u2200S \u2208 S with PaGL (S) = {\ud835\udc3f}, if S is a pseudo-pure pair, then \u2203\ud835\udc491 \u2208 Ch\nG (\ud835\udc3f)\\S s.t. \ud835\udc3f \u2aeb PaG (\ud835\udc491)\\{\ud835\udc3f}. Furthermore, if PaG (\ud835\udc3f) = \u2205, then \u2203\ud835\udc492 \u2208 ChG (\ud835\udc3f)\\S s.t. \ud835\udc3f \u2aeb PaG (\ud835\udc492)\\{\ud835\udc3f} and \ud835\udc491 \u2aeb \ud835\udc492 |\ud835\udc3f."
        },
        {
            "heading": "B.8 PROOF OF LEMMA 3",
            "text": "Lemma 3. Suppose the underlying linear latent variable model satisfies Assumption 1 and 3, S = {\ud835\udc421, \ud835\udc422} and 1pure (S) = \u22121. Then S is a pseudo-pure pair if and only if \u2203(\ud835\udc423, \ud835\udc424) \u2282 O\\{\ud835\udc421, \ud835\udc422} which is an ordered pair s.t. \ud835\udc421 + \ud835\udefc\ud835\udc422 + \ud835\udefd\ud835\udc423 \u2aeb \ud835\udc421 where \ud835\udefc, \ud835\udefd satisfy\nVar(\ud835\udc421) + \ud835\udefcCov(\ud835\udc421, \ud835\udc422) + \ud835\udefdCov(\ud835\udc421, \ud835\udc423) = 0, (7) Cov(\ud835\udc421, \ud835\udc424) + \ud835\udefcCov(\ud835\udc422, \ud835\udc424) + \ud835\udefdCov(\ud835\udc423, \ud835\udc424) = 0, (8)\nor \ud835\udc422 + \ud835\udefc\ud835\udc421 + \ud835\udefd\ud835\udc423 \u2aeb \ud835\udc422 where \ud835\udefc, \ud835\udefd satisfy\nVar(\ud835\udc422) + \ud835\udefcCov(\ud835\udc422, \ud835\udc421) + \ud835\udefdCov(\ud835\udc422, \ud835\udc423) = 0 (9) Cov(\ud835\udc422, \ud835\udc424) + \ud835\udefcCov(\ud835\udc421, \ud835\udc424) + \ud835\udefdCov(\ud835\udc423, \ud835\udc424) = 0. (10)\nProof. (i) \u201cIf\u201d. This part is proved by contradiction. Suppose S = {\ud835\udc421, \ud835\udc422} is a pure pair. Then \ud835\udc421 contains \ud835\udf16\ud835\udc421 while \u2200\ud835\udc42 \u2209 O\\{\ud835\udc421}, \ud835\udc42 does not contain \ud835\udf16\ud835\udc421 . Therefore, \u2200\ud835\udefc, \ud835\udefd, \ud835\udc421 + \ud835\udefc\ud835\udc422 + \ud835\udefd\ud835\udc423 contains \ud835\udf16\ud835\udc421 . Because \ud835\udf16\ud835\udc421 is non-Gaussian based on Assumption 3(a), \ud835\udc421 + \ud835\udefc\ud835\udc422 + \ud835\udefd\ud835\udc423 \u2aeb\u2215 \ud835\udc421. Similarly, \u2200\ud835\udefc, \ud835\udefd, \ud835\udc422 + \ud835\udefc\ud835\udc421 + \ud835\udefd\ud835\udc423 \u2aeb\u2215 \ud835\udc422, which leads to contradiction.\n(ii) \u201cOnly if\u201d. Suppose S is a pseudo-pure pair and \ud835\udc421 \u2208 PaG (\ud835\udc422) without loss of generality. Let PaGL ({\ud835\udc421, \ud835\udc422}) = {\ud835\udc3f1}, then \ud835\udc421, \ud835\udc422 can be represented as\n\ud835\udc421 = \ud835\udc5011\ud835\udc3f1 + \ud835\udf16\ud835\udc421 , (11) \ud835\udc422 = \ud835\udc5012\ud835\udc3f1 + \ud835\udc5112\ud835\udc421 + \ud835\udf16\ud835\udc422 = (\ud835\udc5011\ud835\udc5112 + \ud835\udc5012)\ud835\udc3f1 + \ud835\udc5112\ud835\udf16\ud835\udc421 + \ud835\udf16\ud835\udc422 . (12)\nThere are two possible cases w.r.t \ud835\udc3f1.\n1. Suppose \ud835\udc3f1 is not a root node. According to Assumption 3(b), \u2203\ud835\udc491 \u2208 ChG (\ud835\udc3f1)\\{\ud835\udc421, \ud835\udc422} s.t. \ud835\udc3f1 \u2aeb PaG (\ud835\udc491)\\{\ud835\udc3f1}. If \ud835\udc491 \u2208 O, we let \ud835\udc423 = \ud835\udc491; otherwise we let \ud835\udc3f2 = \ud835\udc491 and \ud835\udc423 be a pure child or a type-I pseudo-pure child of \ud835\udc3f2. Therefore, \ud835\udc423 can be represented as\n\ud835\udc423 = \ud835\udc5013\ud835\udc3f1 + \ud835\udf16 \u2032\ud835\udc423 or \ud835\udc423 = \ud835\udc5023\ud835\udc3f2 + \ud835\udf16\ud835\udc423 = \ud835\udc4f12\ud835\udc5023\ud835\udc3f1 + \ud835\udc5023\ud835\udf16 \u2032 \ud835\udc3f2 + \ud835\udf16\ud835\udc423 , (13)\nwhere {\ud835\udf16 \u2032 \ud835\udc423 , \ud835\udf16 \u2032 \ud835\udc3f2 } \u2aeb \ud835\udc3f1. Let \ud835\udc3f3 \u2208 PaGL (\ud835\udc3f1) and \ud835\udc424 be a pure child or a type-I pseudo-pure child of \ud835\udc3f3 which can be represented as\n\ud835\udc424 = \ud835\udc5034\ud835\udc3f3 + \ud835\udf16\ud835\udc424 . (14)\nSince \ud835\udc3f1 \u2aeb PaG (\ud835\udc491)\\{\ud835\udc3f1} and \ud835\udc3f3 \u2208 PaGL (\ud835\udc3f1), we have \ud835\udc3f3 \u2aeb Pa G (\ud835\udc491)\\{\ud835\udc3f1}, indicating that {\ud835\udf16 \u2032 \ud835\udc423 , \ud835\udf16 \u2032 \ud835\udc3f2 } \u2aeb \ud835\udc3f3.\n2. Suppose \ud835\udc3f1 is a root node. According to Assumption 3(b), \u2203{\ud835\udc491, \ud835\udc492} \u2282 ChG (\ud835\udc3f)\\S s.t. \ud835\udc3f \u2aeb PaG (\ud835\udc491)\\{\ud835\udc3f}, \ud835\udc3f \u2aeb PaG (\ud835\udc492)\\{\ud835\udc3f} and \ud835\udc491 \u2aeb \ud835\udc492 |\ud835\udc3f. If \ud835\udc491 \u2208 O, we let \ud835\udc423 = \ud835\udc491; otherwise we let \ud835\udc3f2 = \ud835\udc491 and \ud835\udc423 be a pure child or a type-I pseudo-pure child of \ud835\udc3f2. If \ud835\udc492 \u2208 O, we let \ud835\udc492 = \ud835\udc424; otherwise we let \ud835\udc492 = \ud835\udc3f3 and \ud835\udc424 be a pure child or a type-I pseudo-pure child of \ud835\udc3f3. Therefore, \ud835\udc423, \ud835\udc424 can be represented as\n\ud835\udc423 = \ud835\udc5013\ud835\udc3f1 + \ud835\udf16 \u2032\ud835\udc423 or \ud835\udc423 = \ud835\udc5023\ud835\udc3f2 + \ud835\udf16\ud835\udc423 = \ud835\udc4f12\ud835\udc5023\ud835\udc3f1 + \ud835\udc5023\ud835\udf16 \u2032 \ud835\udc3f2 + \ud835\udf16\ud835\udc423 , (15) \ud835\udc424 = \ud835\udc5014\ud835\udc3f1 + \ud835\udf16 \u2032\ud835\udc424 or \ud835\udc424 = \ud835\udc5034\ud835\udc3f3 + \ud835\udf16\ud835\udc424 = \ud835\udc4f13\ud835\udc5034\ud835\udc3f1 + \ud835\udc5034\ud835\udf16 \u2032 \ud835\udc3f3 + \ud835\udf16\ud835\udc424 , (16)\nwhere {\ud835\udf16 \u2032 \ud835\udc423 , \ud835\udf16 \u2032 \ud835\udc3f2 , \ud835\udf16 \u2032 \ud835\udc424 , \ud835\udf16 \u2032 \ud835\udc3f3 } \u2aeb \ud835\udc3f1 and {\ud835\udf16 \u2032\ud835\udc423 , \ud835\udf16 \u2032 \ud835\udc3f2 } \u2aeb {\ud835\udf16 \u2032 \ud835\udc424 , \ud835\udf16 \u2032 \ud835\udc3f3 }.\nClearly, if \ud835\udc3f1 is a non-root node, there are two possible cases w.r.t. {\ud835\udc423, \ud835\udc424}; otherwise, there are four possible cases w.r.t. {\ud835\udc423, \ud835\udc424}. We show all six possible cases in Figure 7. In each case, we can rewrite \ud835\udc421, \ud835\udc422, \ud835\udc423, \ud835\udc424 as\n\ud835\udc421 = \ud835\udf061\ud835\udc3f + \ud835\udf16\ud835\udc421 , (17) \ud835\udc422 = \ud835\udf062\ud835\udc3f + \ud835\udf142\ud835\udf16\ud835\udc421 + \ud835\udf16\ud835\udc422 , (18)\n\ud835\udc423 = \ud835\udf063\ud835\udc3f + \ud835\udf16 \u2032\u2032\ud835\udc423 , (19) \ud835\udc424 = \ud835\udf064\ud835\udc3f \u2032 + \ud835\udf16 \u2032\u2032\ud835\udc424 , (20)\nwhere \ud835\udf16\ud835\udc421 , \ud835\udf16\ud835\udc422 , \ud835\udf16 \u2032\u2032 \ud835\udc423 , \ud835\udf16 \u2032\u2032 \ud835\udc424 are independent of each other, each of them is independent of \ud835\udc3f and \ud835\udc3f\u2032, and Cov(\ud835\udc3f, \ud835\udc3f\u2032) \u2260 0. We substitute Equation (17)\u223c(20) into Equation (7) and (8),\n\ud835\udf061 (\ud835\udf061 + \ud835\udefc\ud835\udf062 + \ud835\udefd\ud835\udf063)Var(\ud835\udc3f) + (1 + \ud835\udefc\ud835\udf142)Var(\ud835\udf16\ud835\udc421 ) = 0, (21) \ud835\udf064 (\ud835\udf061 + \ud835\udefc\ud835\udf062 + \ud835\udefd\ud835\udf063)Cov(\ud835\udc3f, \ud835\udc3f\u2032) = 0, (22)\nwhich yield that \ud835\udf061 + \ud835\udefc\ud835\udf062 + \ud835\udefd\ud835\udf063 = 0 and 1 + \ud835\udefc\ud835\udf142 = 0. (23)\nTherefore, we can reach the conclusion that\n\ud835\udc421 + \ud835\udefc\ud835\udc422 + \ud835\udefd\ud835\udc423 = (\ud835\udf061 + \ud835\udefc\ud835\udf062 + \ud835\udefd\ud835\udf063)\ud835\udc3f + (1 + \ud835\udefc\ud835\udf142)\ud835\udf16\ud835\udc421 + \ud835\udefc\ud835\udf16\ud835\udc422 + \ud835\udefd\ud835\udf16 \u2032\u2032\ud835\udc423 = \ud835\udefc\ud835\udf16\ud835\udc422 + \ud835\udefd\ud835\udf16 \u2032\u2032 \ud835\udc423 \u2aeb \ud835\udc421. (24)\n\u25a1"
        },
        {
            "heading": "B.9 PROOF OF COROLLARY 2",
            "text": "Corollary 2. Suppose S = {\ud835\udc421, \ud835\udc422} \u2208 S and \u2203(\ud835\udc423, \ud835\udc424) \u2282 O\\{\ud835\udc421, \ud835\udc422} which is an ordered pair s.t. \ud835\udc421 + \ud835\udefc\ud835\udc422 + \ud835\udefd\ud835\udc423 \u2aeb \ud835\udc421 where \ud835\udefc, \ud835\udefd satisfy Equation (2) and (3). Then S\u0303 = {?\u0303?1, ?\u0303?2} is a pure pair with latent parent PaGL (S) where ?\u0303?1 = \ud835\udc421 and ?\u0303?2 = \ud835\udc422 + 1 \ud835\udefc \ud835\udc421.\nProof. Based on Lemma 3, S = {\ud835\udc421, \ud835\udc422} is a pseudo-pure pair. Suppose \ud835\udc422 \u2208 PaG (\ud835\udc421), then \ud835\udc421 contains \ud835\udf16\ud835\udc421 while \u2200\ud835\udc42 \u2209 O\\{\ud835\udc421}, \ud835\udc42 does not contain \ud835\udf16\ud835\udc421 , so \u2200\ud835\udefc, \ud835\udefd, \ud835\udc421 + \ud835\udefc\ud835\udc422 + \ud835\udefd\ud835\udc423 contains \ud835\udf16\ud835\udc421 . As \ud835\udf16\ud835\udc421 is non-Gaussian based on Assumption 3(a), \ud835\udc421 + \ud835\udefc\ud835\udc422 + \ud835\udefd\ud835\udc423 \u2aeb\u2215 \ud835\udc421, which leads to contradiction. Therefore, we can conclude \ud835\udc421 \u2208 PaG (\ud835\udc422). Let PaGL (S) = {\ud835\udc3f}, then \ud835\udc421, \ud835\udc422 can be represented as\n\ud835\udc421 = \ud835\udc5011\ud835\udc3f + \ud835\udf16\ud835\udc421 , (25) \ud835\udc422 = \ud835\udc5012\ud835\udc3f + \ud835\udc5112\ud835\udc421 + \ud835\udf16\ud835\udc422 = (\ud835\udc5011\ud835\udc5112 + \ud835\udc5012)\ud835\udc3f + \ud835\udc5112\ud835\udf16\ud835\udc421 + \ud835\udf16\ud835\udc422 . (26)\nWe can easily obtain \ud835\udefc = \u2212 1 \ud835\udc5112 , because if \ud835\udefc \u2260 \u2212 1 \ud835\udc5112 , both \ud835\udc421 and \ud835\udc421 + \ud835\udefc\ud835\udc422 + \ud835\udefd\ud835\udc423 contain nonGaussian \ud835\udf16\ud835\udc421 , i.e., \ud835\udc421 + \ud835\udefc\ud835\udc422 + \ud835\udefd\ud835\udc423 \u2aeb\u2215 \ud835\udc421. Therefore, we can represent ?\u0303?1, ?\u0303?2 as\n?\u0303?1 = \ud835\udc5011\ud835\udc3f + \ud835\udf16\ud835\udc421 , ?\u0303?2 = \ud835\udc5012\ud835\udc3f + \ud835\udf16\ud835\udc422 . (27) Clearly, {?\u0303?1, ?\u0303?2} is a pure pair with latent parent \ud835\udc3f. \u25a1"
        },
        {
            "heading": "B.10 PROOF OF PROPOSITION 2",
            "text": "Proposition 2. Let {S1,S2} \u2282 S where S1 = {\ud835\udc421, \ud835\udc422} and S2 = {\ud835\udc423, \ud835\udc424}. Then\n1. Suppose S1 and S2 are two pure pairs. PaGL (S1) = Pa G L (S2) if and only if (1) S1 \u2229 S2 \u2260 \u2205,\nor (2) \u2203S3 \u2208 S s.t. S1 \u2229 S3 \u2260 \u2205 and S2 \u2229 S3 \u2260 \u2205. 2. Suppose S1 is a pure pair and S2 is a pseudo-pure pair. Then PaGL (S1) = Pa G L (S2) if and\nonly if ({\ud835\udc422, ?\u0303?3}, {\ud835\udc421, ?\u0303?4}) satisfies the tetrad constraint. 3. Suppose S1 and S2 are two pseudo-pure pairs. Then PaGL (S1) = Pa G L (S2) if and only if\n({?\u0303?2, ?\u0303?3}, {?\u0303?1, ?\u0303?4}) satisfies the tetrad constraint.\nProof. (i) \u201cIf\u201d.\n1. Suppose S1 and S2 are two pure pairs. The proof is the same as that of the first subproposition of Proposition 1.\n2. Suppose S1 is a pure pair and S2 is a pseudo-pure pair. Clearly, S1 \u2229 S2 = \u2205. Based on Corollary 2, {?\u0303?3, ?\u0303?4} is a pure pair with latent parent PaGL (S2). This part can be proved by contradiction. Suppose PaGL (S1) \u2260 Pa G L (S2), let Pa G L (S1) = {\ud835\udc3f1} and Pa G L (S2) = {\ud835\udc3f2}.\nThen there are two non-intersecting treks \ud835\udc421 \u2190 \ud835\udc3f1 \u2192 \ud835\udc422 and ?\u0303?3 \u2190 \ud835\udc3f2 \u2192 ?\u0303?4, so there is no choke point between {\ud835\udc422, ?\u0303?3} and {\ud835\udc421, ?\u0303?4}. Therefore, ({\ud835\udc422, ?\u0303?3}, {\ud835\udc421, ?\u0303?4}) does not satisfy the tetrad constraint, which leads to contradiction.\n3. Suppose S1 and S2 are two pseudo-pure pairs. The remaining proof is similar to that of the second sub-proposition above.\n(ii) \u201cOnly if\u201d.\n1. Suppose S1 and S2 are two pure pairs. The proof is the same as that of the first subproposition of Proposition 1.\n2. Suppose S1 is a pure pair and S2 is a pseudo-pure pair. Clearly, S1 \u2229 S2 = \u2205. Based on Corollary 2, {?\u0303?3, ?\u0303?4} is a pure pair with latent parent PaGL (S2). Suppose Pa G L (S1) =\nPaGL (S2), let Pa G L (S1) = {\ud835\udc3f}. Since \ud835\udc421, \ud835\udc422, ?\u0303?3, ?\u0303?4 are all pure children of \ud835\udc3f, \ud835\udc3f is a choke point between {\ud835\udc422, ?\u0303?3} and {\ud835\udc421, ?\u0303?4}. Therefore, ({\ud835\udc422, ?\u0303?3}, {\ud835\udc421, ?\u0303?4}) satisfies the tetrad constraint.\n3. Suppose S1 and S2 are two pseudo-pure pairs. The remaining proof is similar to that of the second sub-proposition above.\n\u25a1"
        },
        {
            "heading": "B.11 PROOF OF THEOREM 3",
            "text": "Theorem 3. Suppose the underlying linear latent variable model satisfies Assumption 1 and 3. Then latent variables can be fully identified.\nProof. Theorem 1 ensures no latent omission under Assumption 1 while Proposition 2 ensures no latent commission under Assumption 1 and 3. Therefore, latent variables can be fully identified. \u25a1"
        },
        {
            "heading": "B.12 PROOF OF PROPOSITION 3",
            "text": "Proposition 3. No variable in OD is a parent of any variable in L \u222aOU.\nProof. We prove this proposition in Case I (where Assumption 1 and 2 hold) and Case II (where Assumption 1 and 3 hold) respectively.\n1. In Case I, \ud835\udc421 \u2208 OD if and only if (1) \u2203\ud835\udc422 \u2208 O s.t. {\ud835\udc421, \ud835\udc422} \u2208 S, or (2) \u2203S \u2208 S s.t. \ud835\udc421 = Ref (S). Based on Corollary 1, the latter means that \ud835\udc421 is a pure child of some latent variable. Therefore, we can easily reach the conclusion that no variable in OD is a parent of any variable in L \u222aOU.\n2. In Case II, \ud835\udc421 \u2208 OD if and only if \u2203\ud835\udc422 \u2208 O s.t. {\ud835\udc421, \ud835\udc422} \u2208 S, so no variable in OD is a parent of any variable in L \u222aOU.\n\u25a1"
        },
        {
            "heading": "B.13 PROOF OF THEOREM 4",
            "text": "Theorem 4. Suppose the underlying linear latent variable model satisfies Assumption 1 and 2 or Assumption 1 and 3, in the limit of infinite data, G\u0302 satisfies that (1) G\u0302 has the same skeleton and v-structures as G; (2) \u2200{\ud835\udc42\ud835\udc56 , \ud835\udc42 \ud835\udc57 } \u2282 O s.t. \ud835\udc42\ud835\udc56 \u2208 PaG (\ud835\udc42 \ud835\udc57 ) and PaGL (\ud835\udc42\ud835\udc56) \u2260 Pa G L (\ud835\udc42 \ud835\udc57 ), \ud835\udc42\ud835\udc56 \u2208 Pa G\u0302 (\ud835\udc42 \ud835\udc57 ).\nProof. Based on Theorem 2 and Theorem 3, latent variables can be fully identified. After preprocessing, each latent variable has multiple indicators of which each can be represented as its linear function plus an independent noise.\n(1) This is derived by the soundness of PC algorithm.\n(2) Without loss of generality, suppose \ud835\udc42\ud835\udc56 \u2208 PaG (\ud835\udc42 \ud835\udc57 ), there are two possible cases w.r.t. PaGL (\ud835\udc42 \ud835\udc57 ).\n1. Suppose \u2203\ud835\udc3f \u2208 PaGL (\ud835\udc42 \ud835\udc57 ) s.t. \ud835\udc3f \u2209 Pa G L (\ud835\udc42\ud835\udc56). Then there exists a v-structure \ud835\udc42\ud835\udc56 \u2192 \ud835\udc42 \ud835\udc57 \u2190 \ud835\udc3f\nin G, which can be discovered by line 2 of Algorithm 4.\n2. Suppose \u2200\ud835\udc3f \u2208 PaGL (\ud835\udc42 \ud835\udc57 ), \ud835\udc3f \u2208 Pa G L (\ud835\udc42\ud835\udc56). Since Pa G L (\ud835\udc42\ud835\udc56) \u2260 Pa G L (\ud835\udc42 \ud835\udc57 ), \u2203\ud835\udc3f \u2032 \u2208 PaGL (\ud835\udc42\ud835\udc56) s.t. \ud835\udc3f\u2032 \u2209 PaGL (\ud835\udc42 \ud835\udc57 ). After line 3 of Algorithm 4, there is \ud835\udc3f\n\u2032 \u2192 \ud835\udc42\ud835\udc56 \u2212\ud835\udc42 \ud835\udc57 and \ud835\udc3f\u2032 is not adjacent to \ud835\udc42 \ud835\udc57 in G\u0302. Based on Meek\u2019s rule 1 shown as Figure 8, \ud835\udc42\ud835\udc56 \u2212\ud835\udc42 \ud835\udc57 can be oriented as \ud835\udc42\ud835\udc56 \u2192 \ud835\udc42 \ud835\udc57 .\n\u25a1"
        },
        {
            "heading": "C MORE THEORETICAL RESULTS",
            "text": ""
        },
        {
            "heading": "C.1 NON-LINEARITY",
            "text": "All theoretical results in Section 3.1 and 3.2 are derived by the Tetrad Representation Theorem (Spirtes et al., 2000), which is a special form of the Trek Separation Theorem (Sullivant et al., 2010). Furthermore, Spirtes (2013) has extended the Trek Separation Theorem to partially nonlinear cases. An exact formulation of the Extended Trek Separation Theorem entails many concepts not previously introduced, here we only need to know\n1. If there is a choke point \ud835\udc36 between {\ud835\udc3c1, \ud835\udc3c2} and {\ud835\udc3d1, \ud835\udc3d2}, \ud835\udc36 is on the {\ud835\udc3c1, \ud835\udc3c2} side, and for each directed path \ud835\udf0b from \ud835\udc36 to {\ud835\udc3c1, \ud835\udc3c2}, any vertex \ud835\udc49 on \ud835\udf0b is a linear function of its parents along \ud835\udf0b plus an arbitrary function of the parents not along \ud835\udf0b, then ({\ud835\udc3c1, \ud835\udc3c2}, {\ud835\udc3d1, \ud835\udc3d2}) satisfies the tetrad constraint.\n2. If there is no choke point between {\ud835\udc3c1, \ud835\udc3c2} and {\ud835\udc3d1, \ud835\udc3d2}, under faithfulness assumption, ({\ud835\udc3c1, \ud835\udc3c2}, {\ud835\udc3d1, \ud835\udc3d2}) does not satisfy the tetrad constraint.\nBased on these two propositions, we can conclude that all theoretical results in Section 3.1 and 3.2 are still valid as long as all causal relations involving generalized pure children (see Definition 9) are linear. More specifically, any causal relation between \ud835\udc491 and \ud835\udc492 can be nonlinear as long as neither \ud835\udc491 nor \ud835\udc492 is a generalized pure child of some latent variable. Any tetrad constraint in this case holds if and only if it holds in the linear case. Furthermore, if only causal relations between observed variables that are not pseudo-pure children (see Definition 8) of some latent variable are nonlinear while others are all linear, all theoretical results in Section 3.3 also hold, because our proofs do not rely on linearity of these causal relations."
        },
        {
            "heading": "C.2 WEAKENING ASSUMPTION 1(B)",
            "text": "Assumption 1(b) requires that \u2200\ud835\udc3f \u2208 L,NeiGL (\ud835\udc3f) \u2260 \u2205. It is used only in the proof of Theorem 1 and Lemma 2. In fact, even if \u2203\ud835\udc3f \u2208 L s.t. NeiGL (\ud835\udc3f) = \u2205, Theorem 1 still holds if for every such \ud835\udc3f, |ChGO (\ud835\udc3f) | \u2265 4; and Lemma 2 still holds if for every such \ud835\udc3f, |Ch G O (\ud835\udc3f) | \u2265 5. Taking Lemma 2 as an example, we prove that it still holds if \u2200\ud835\udc3f \u2208 L s.t. NeiGL (\ud835\udc3f) = \u2205, |Ch G O (\ud835\udc3f) | \u2265 5.\nProof. In the proof of Lemma 2 given in Appendix B.3, Assumption 1(b) is only used to prove that \u2200\ud835\udc42 \u2208 OC\\{\ud835\udc421, \ud835\udc422}, ({\ud835\udc421, \ud835\udc42},O\\{\ud835\udc421, \ud835\udc422, \ud835\udc42}) does not satisfy the tetrad constraint if S = {\ud835\udc421, \ud835\udc422} is a pure pair and 1pure (S) = \u22121. We only need to prove this part. Let PaGL (S) = {\ud835\udc3f1}, \ud835\udc3f1 has no pure child except \ud835\udc421 and \ud835\udc422 since 1pure (S) = \u22121. Given an \ud835\udc423 \u2208 OC\\{\ud835\udc421, \ud835\udc422}, there are three possible cases w.r.t. PaGL (\ud835\udc423).\n1. Suppose PaGL (\ud835\udc423) = \u2205. Based on Lemma 5, \ud835\udc423 has an observed children \ud835\udc424 \u2208 O\\{\ud835\udc421, \ud835\udc422}. If NeiGL (\ud835\udc3f1) \u2260 \u2205, the proof is the same as the original one; otherwise, there is |ChGO (\ud835\udc3f1) | \u2265 5 according to our new assumption, so \u2203\ud835\udc425 \u2208 Ch G O (\ud835\udc3f1)\\{\ud835\udc421, \ud835\udc422, \ud835\udc423, \ud835\udc424}.\nClearly, there are two non-intersecting treks \ud835\udc423 \u2212 \ud835\udc424 and \ud835\udc421 \u2190 \ud835\udc3f1 \u2192 \ud835\udc425. Therefore, there is no choke point between {\ud835\udc421, \ud835\udc423} and {\ud835\udc424, \ud835\udc425}.\n2. Suppose PaGL (\ud835\udc423) = {\ud835\udc3f1}. Since \ud835\udc423 is not a pure child of \ud835\udc3f1, \u2203\ud835\udc424 \u2208 Nei G O (\ud835\udc423) where\n\ud835\udc424 \u2209 {\ud835\udc421, \ud835\udc422}. If NeiGL (\ud835\udc3f1) \u2260 \u2205, the proof is the same as the original one; otherwise, there is |ChGO (\ud835\udc3f1) | \u2265 5 according to our new assumption, so \u2203\ud835\udc425 \u2208 Ch G O (\ud835\udc3f1)\\{\ud835\udc421, \ud835\udc422, \ud835\udc423, \ud835\udc424}.\nClearly, there are two non-intersecting treks \ud835\udc423 \u2212 \ud835\udc424 and \ud835\udc421 \u2190 \ud835\udc3f1 \u2192 \ud835\udc425. Therefore, there is no choke point between {\ud835\udc421, \ud835\udc423} and {\ud835\udc424, \ud835\udc425}.\n3. Suppose PaGL (\ud835\udc423) \u2260 \u2205 and Pa G L (\ud835\udc423) \u2260 {\ud835\udc3f1}, that is, \u2203\ud835\udc3f2 \u2208 Pa G L (\ud835\udc423)\\{\ud835\udc3f1}. Then \ud835\udc3f2 has a\ngeneralized pure child \ud835\udc424 \u2208 O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423} according to Assumption 1(a). If NeiGL (\ud835\udc3f1) \u2260 \u2205, the proof is the same as the original one; otherwise, there is |ChGO (\ud835\udc3f1) | \u2265 5 according to our new assumption, so \u2203\ud835\udc425 \u2208 ChGO (\ud835\udc3f1)\\{\ud835\udc421, \ud835\udc422, \ud835\udc423, \ud835\udc424}. Clearly, there are two nonintersecting treks \ud835\udc423 \u2190 \ud835\udc3f2 \u2192 \ud835\udc424 and \ud835\udc421 \u2190 \ud835\udc3f1 \u2192 \ud835\udc425. Therefore, there is no choke point between {\ud835\udc421, \ud835\udc423} and {\ud835\udc424, \ud835\udc425}.\nBased on Theorem 5, we reach the conclusion that \u2200\ud835\udc42 \u2208 OC\\{\ud835\udc421, \ud835\udc422}, ({\ud835\udc421, \ud835\udc42},O\\{\ud835\udc421, \ud835\udc422, \ud835\udc42}) does not satisfy the tetrad constraint. \u25a1"
        },
        {
            "heading": "D DETAILS OF ALGORITHMS",
            "text": "The detailed versions of Algorithm 1, 2, and 3 are shown as Algorithm 5, 6, and 7. Besides, we also provide two illustrative examples to show how each step proceeds.\n\ud835\udc3f3\n\ud835\udc429 \ud835\udc4210 \ud835\udc4211 \ud835\udc4212\ud835\udc428\n\ud835\udc3f1\n\ud835\udc421 \ud835\udc422 \ud835\udc423\n\ud835\udc3f2\n\ud835\udc424 \ud835\udc425 \ud835\udc426\n\ud835\udc4213 \ud835\udc4214\n\ud835\udc427\n(a) G1\n\ud835\udc3f3\n\ud835\udc422 \ud835\udc423\n\ud835\udc3f1 \ud835\udc3f2\n\ud835\udc427 \ud835\udc428\n\ud835\udc4211 \ud835\udc4210\n\ud835\udc424\ud835\udc421 \ud835\udc425 \ud835\udc426 \ud835\udc429\n\ud835\udc4212\n(b) G2\nTaking the causal model with structure G1 as an example of Case I, we show the procedures of recovering the whole causal graph as follows.\n1. Line 1 of Algorithm 1: find all candidate variables. Here OC = O. 2. Line 2 of Algorithm 1: find all generalized pure pairs. Here S = {{\ud835\udc421, \ud835\udc422}, {\ud835\udc421, \ud835\udc423}, {\ud835\udc422, \ud835\udc423}, {\ud835\udc424, \ud835\udc425}, {\ud835\udc426, \ud835\udc427}, {\ud835\udc428, \ud835\udc429}, {\ud835\udc4211, \ud835\udc4212}}.\n3. Line 3 of Algorithm 1: identify as many pure pairs as possible. Since {\ud835\udc421, \ud835\udc422} \u2229 {\ud835\udc421, \ud835\udc423} \u2260 \u2205 and {\ud835\udc421, \ud835\udc422} \u2229 {\ud835\udc422, \ud835\udc423} \u2260 \u2205, 1pure ({\ud835\udc421, \ud835\udc422}) = 1pure ({\ud835\udc421, \ud835\udc423}) = 1pure ({\ud835\udc422, \ud835\udc423}) = 1, for any other generalized pure pair 1pure (\u00b7) is -1.\n4. Line 1 of Algorithm 2: discriminate pure pairs against pseudo-pure ones. Since ({\ud835\udc426, \ud835\udc424},O\\{\ud835\udc424, \ud835\udc426, \ud835\udc427}) satisfies the tetrad constraint, 1pure ({\ud835\udc426, \ud835\udc427}) = 0 and Ref ({\ud835\udc426, \ud835\udc427}) = \ud835\udc424. Similarly, we have 1pure ({\ud835\udc428, \ud835\udc429}) = 0,1pure ({\ud835\udc4211, \ud835\udc4212}) = 0 and Ref ({\ud835\udc428, \ud835\udc429}) = \ud835\udc4210,Ref ({\ud835\udc4211, \ud835\udc4212}) = \ud835\udc4210. Besides, 1pure ({\ud835\udc424, \ud835\udc425}) = 1\n5. Line 2 of Algorithm 2: check whether any two generalized pure pairs share a common latent parent. Clearly, PaGL ({\ud835\udc421, \ud835\udc422}) = Pa G L ({\ud835\udc421, \ud835\udc423}) = Pa G L ({\ud835\udc422, \ud835\udc423}) = {\ud835\udc3f1},\nPaGL ({\ud835\udc424, \ud835\udc425}) = Pa G L (\ud835\udc424) = Pa G L ({\ud835\udc426, \ud835\udc427}) = {\ud835\udc3f2}, and Pa G L ({\ud835\udc428, \ud835\udc429}) = Pa G L (\ud835\udc4210) =\nPaGL ({\ud835\udc4211, \ud835\udc4212}) = {\ud835\udc3f3}. 6. Pre-processing in Section 4.1: L = {\ud835\udc3f1, \ud835\udc3f2, \ud835\udc3f3}, OD = {\ud835\udc42\ud835\udc56}12\ud835\udc56=1, O\nU = {\ud835\udc4213, \ud835\udc4214}. The measured indicators of \ud835\udc3f1, \ud835\udc3f2 and \ud835\udc3f3 can be respectively {\ud835\udc421, \ud835\udc422}, {\ud835\udc424, \ud835\udc425} and {\ud835\udc428, \ud835\udc4210}. Furthermore, we also create two auxiliary measured indicators for each variable in OU.\n7. Run Algorithm 4 to reveal causal relations between any two variables.\nTaking the causal model with structure G2 as an example of Case II, we show the procedures of recovering the whole causal graph as follows.\n1. Line 1 of Algorithm 1: find all candidate variables OC. Here OC = O.\n2. Line 2 of Algorithm 1: find all generalized pure pairs S. Here S = {{\ud835\udc421, \ud835\udc422}, {\ud835\udc423, \ud835\udc424}, {\ud835\udc425, \ud835\udc426}, {\ud835\udc427, \ud835\udc428}, {\ud835\udc427, \ud835\udc429}, {\ud835\udc428, \ud835\udc429}}.\n3. Line 3 of Algorithm 1: identify as many pure pairs as possible. Since {\ud835\udc427, \ud835\udc428} \u2229 {\ud835\udc427, \ud835\udc429} \u2260 \u2205 and {\ud835\udc427, \ud835\udc428} \u2229 {\ud835\udc428, \ud835\udc429} \u2260 \u2205, 1pure ({\ud835\udc427, \ud835\udc428}) = 1pure ({\ud835\udc427, \ud835\udc429}) = 1pure ({\ud835\udc428, \ud835\udc429}) = 1, for any other generalized pure pair 1pure (\u00b7) is -1.\n4. Line 1 of Algorithm 3: discriminate pure pairs against pseudo-pure ones and convert each pseudo-pure ones into a pure one. Since (\ud835\udc421, \ud835\udc422) can make \ud835\udc423 + \ud835\udefc\ud835\udc424 + \ud835\udefd\ud835\udc421 \u2aeb \ud835\udc423 hold and (\ud835\udc427, \ud835\udc421) can make \ud835\udc425 + \ud835\udefc\ud835\udc426 + \ud835\udefd\ud835\udc427 \u2aeb \ud835\udc425 hold, we have 1pure ({\ud835\udc423, \ud835\udc424}) = 0 and 1pure ({\ud835\udc425, \ud835\udc426}) = 0. Besides, we also have 1pure ({\ud835\udc421, \ud835\udc422}) = 1. Then we convert {\ud835\udc423, \ud835\udc424} into {?\u0303?3, ?\u0303?4} and {\ud835\udc425, \ud835\udc426} into {?\u0303?5, ?\u0303?6}\n5. Line 2 of Algorithm 3: check whether two generalized pure pairs share a common latent parent. We have PaGL ({\ud835\udc421, \ud835\udc422}) = Pa G L ({\ud835\udc423, \ud835\udc424}) = {\ud835\udc3f1} since\n({\ud835\udc421, ?\u0303?3}, {\ud835\udc422, ?\u0303?4}) satisfies the tetrad constraint, PaGL ({\ud835\udc425, \ud835\udc426}) = {\ud835\udc3f2}, and PaGL ({\ud835\udc427, \ud835\udc428}) = Pa G L ({\ud835\udc427, \ud835\udc429}) = Pa G L ({\ud835\udc428, \ud835\udc429}) = {\ud835\udc3f3}. 6. Pre-processing in Section 4.1: L = {\ud835\udc3f1, \ud835\udc3f2, \ud835\udc3f3}, OD = {\ud835\udc42\ud835\udc56}9\ud835\udc56=1, O U = {\ud835\udc4210, \ud835\udc4211, \ud835\udc4212}.\nThe measured indicators of \ud835\udc3f1, \ud835\udc3f2 and \ud835\udc3f3 can be respectively {\ud835\udc421, \ud835\udc422}, {?\u0303?5, ?\u0303?6} and {\ud835\udc427, \ud835\udc428}. Furthermore, we also create two auxiliary measured indicators for each variable in OU.\n7. Run Algorithm 4 to reveal causal relations between any two variables.\nAlgorithm 5: Partially identifying latent variables under Assumption 1 (a detailed version). Input: Observed variable O. Output: Candidate variables OC, generalized pure pairs S, purity indicator function 1pure (\u00b7).\n1 // Find all candidate variables. 2 OC := \u2205; 3 for \ud835\udc421 \u2208 O do 4 flag := 1. 5 for {\ud835\udc422, \ud835\udc423} \u2282 O\\{\ud835\udc421} do 6 if \u2200\ud835\udc424 \u2208 O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423} s.t. \ud835\udc421 \u2aeb \ud835\udc424 given some subset of {\ud835\udc422, \ud835\udc423} then 7 flag := 0; 8 break 9 end\n10 end 11 if flag = 1 then 12 OC := OC \u222a {\ud835\udc421}; 13 end 14 end 15 // Find all generalized pure pairs. 16 S = \u2205; 17 for {\ud835\udc421, \ud835\udc422} \u2282 OC do 18 if \u2200{\ud835\udc423, \ud835\udc424} \u2282 O\\{\ud835\udc421, \ud835\udc422},Cov(\ud835\udc421, \ud835\udc424)Cov(\ud835\udc422, \ud835\udc423) = Cov(\ud835\udc421, \ud835\udc423)Cov(\ud835\udc422, \ud835\udc424) then 19 S := S \u222a {{\ud835\udc421, \ud835\udc422}} 20 end 21 end 22 // Identify as many pure pairs as possible; 23 for S \u2208 S do 24 1pure (S) := \u22121; 25 end 26 for S \u2208 S do 27 if \u2203S\u2032 \u2208 S\\{S} s.t. S \u2229 S\u2032 \u2260 \u2205 then 28 1pure (S) := 1 29 end 30 end\nAlgorithm 6: Fully identifying latent variables in Case I (a detailed version). Input: Observed variables O, candidate variables OC, generalized pure pairs S, purity indicator function 1pure (\u00b7) Output: Updated purity indicator function 1pure (\u00b7), sibling indicator function 1sib (\u00b7, \u00b7).\n1 // Discriminate pure pairs against pseudo-pure pairs. 2 for S = {\ud835\udc421, \ud835\udc422} \u2282 S s.t. 1pure (S) = \u22121 do 3 for \ud835\udc423 \u2208 OC\\{\ud835\udc421, \ud835\udc422} do 4 if \u2200{\ud835\udc424, \ud835\udc425} \u2282O\\{\ud835\udc421, \ud835\udc422, \ud835\udc423},Cov(\ud835\udc421, \ud835\udc425)Cov(\ud835\udc423, \ud835\udc424)=Cov(\ud835\udc421, \ud835\udc424)Cov(\ud835\udc423, \ud835\udc425) then 5 1pure (S) := 0; 6 Ref (S) := \ud835\udc423; 7 else 8 1pure (S) := 1; 9 end\n10 end 11 end 12 // Check whether two generalized pure pairs share a common latent parent. 13 for {S1,S2} \u2282 S do 14 1sib (S1,S2) := 0; 15 end 16 for {S1,S2} \u2282 S do 17 if 1pure (S1) = 1 and 1pure (S2) = 1 then 18 if S1 \u2229 S2 \u2260 \u2205 or \u2203S3 \u2208 S\\{S1,S2} s.t. S1 \u2229 S3 \u2260 \u2205 and S2 \u2229 S3 \u2260 \u2205 then 19 1sib (S1,S2) := 1; 20 end 21 else if 1pure (S1) = 0 and 1pure (S2) = 1 then 22 if Ref (S1) \u2208 S2 or \u2203S3 \u2208 S\\{S1,S2} s.t. Ref (S1) \u2208 S3 and S2 \u2229 S3 \u2260 \u2205 then 23 1sib (S1,S2) := 1; 24 end 25 else if 1pure (S1) = 1 and 1pure (S2) = 0 then 26 if Ref (S2) \u2208 S1 or \u2203S3 \u2208 S\\{S1,S2} s.t. Ref (S2) \u2208 S3 and S1 \u2229 S3 \u2260 \u2205 then 27 1sib (S1,S2) := 1; 28 end 29 else 30 if Ref (S1) \u2208 Ref (S2) or \u2203S3 \u2208 S\\{S1,S2} s.t. Ref (S1) \u2208 S3 and Ref (S2) \u2208 S3 then 31 1sib (S1,S2) := 1; 32 end 33 end 34 end\nAlgorithm 7: Fully identifying latent variables in Case II (a detailed version). Input: Observed variables O, generalized pure pairs S, purity indicator function 1pure (\u00b7) Output: Updated purity indicator function 1pure (\u00b7), sibling indicator function 1sib (\u00b7, \u00b7).\n1 // Discriminate pure pairs against pseudo-pure pairs. 2 for S = {\ud835\udc421, \ud835\udc422} \u2282 S s.t. 1pure (S) = \u22121 do 3 for (\ud835\udc423, \ud835\udc424) \u2282 O\\{\ud835\udc421, \ud835\udc422} do 4 if \ud835\udc421 + \ud835\udefc\ud835\udc422 + \ud835\udefd\ud835\udc423 \u2aeb \ud835\udc421 where \ud835\udefc, \ud835\udefd satisfy Equation (2) and (3) then 5 1pure (S) =: 0, ?\u0303?1 := \ud835\udc421, ?\u0303?2 := \ud835\udc422 + 1\ud835\udefc\ud835\udc421; 6 else if \ud835\udc422 + \ud835\udefc\ud835\udc421 + \ud835\udefd\ud835\udc423 \u2aeb \ud835\udc422 where \ud835\udefc, \ud835\udefd satisfy Equation (4) and (5) then 7 1pure (S) =: 0, ?\u0303?1 := \ud835\udc421 + 1\ud835\udefc\ud835\udc422, ?\u0303?2 := \ud835\udc422; 8 else 9 1pure (S) =: 1;\n10 end 11 end 12 end 13 // Check whether two generalized pure pairs share a common latent parent. 14 for {S1,S2} \u2282 S do 15 1sib (S1,S2) := 0; 16 end 17 for {S1,S2} \u2282 S do 18 if 1pure (S1) = 1 and 1pure (S2) = 1 then 19 if S1 \u2229 S2 \u2260 \u2205 or \u2203S3 \u2208 S\\{S1,S2} s.t. S1 \u2229 S3 \u2260 \u2205 and S2 \u2229 S3 \u2260 \u2205 then 20 1sib (S1,S2) := 1; 21 end 22 else if 1pure (S1) = 0 and 1pure (S2) = 1 then 23 if Cov(?\u0303?1, \ud835\udc424)Cov(?\u0303?2, \ud835\udc423) = Cov(?\u0303?1, \ud835\udc423)Cov(?\u0303?2, \ud835\udc424) then 24 1sib (S1,S2) := 1; 25 end 26 else if 1pure (S1) = 1 and 1pure (S2) = 0 then 27 if Cov(\ud835\udc421, ?\u0303?4)Cov(\ud835\udc422, ?\u0303?3) = Cov(\ud835\udc421, ?\u0303?3)Cov(\ud835\udc422, ?\u0303?4) then 28 1sib (S1,S2) := 1; 29 end 30 else 31 if Cov(?\u0303?1, ?\u0303?4)Cov(?\u0303?2, ?\u0303?3) = Cov(?\u0303?1, ?\u0303?3)Cov(?\u0303?2, ?\u0303?4) then 32 1sib (S1,S2) := 1; 33 end 34 end 35 end"
        }
    ],
    "year": 2024
}