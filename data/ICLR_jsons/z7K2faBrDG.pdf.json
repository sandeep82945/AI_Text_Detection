{
    "abstractText": "Perception is often viewed as a process that transforms physical variables, external to an observer, into internal psychological variables. Such a process can be modeled by a function coined perceptual scale. The perceptual scale can be deduced from psychophysical measurements that consist in comparing the relative differences between stimuli (i.e. difference scaling experiments). However, this approach is often overlooked by the modeling and experimentation communities. Here, we demonstrate the value of measuring the perceptual scale of classical (spatial frequency, orientation) and less classical physical variables (interpolation between textures) by embedding it in recent probabilistic modeling of perception. First, we show that the assumption that an observer has an internal representation of univariate parameters such as spatial frequency or orientation while stimuli are high-dimensional does not lead to contradictory predictions when following the theoretical framework. Second, we show that the measured perceptual scale corresponds to the transduction function hypothesized in this framework. In particular, we demonstrate that it is related to the Fisher information of the generative model that underlies perception and we test the predictions given by the generative model of different stimuli in a set a of difference scaling experiments. Our main conclusion is that the perceptual scale is mostly driven by the stimulus power spectrum. Finally, we propose that this measure of perceptual scale is a way to push further the notion of perceptual distances by estimating the perceptual geometry of images i.e. the path between images instead of simply the distance between those.",
    "authors": [],
    "id": "SP:0b80f0759b0787dabee7ca2f6114c3d6b44323b5",
    "references": [
        {
            "authors": [
                "Guillermo Aguilar",
                "Marianne Maertens"
            ],
            "title": "Toward reliable measurements of perceptual scales in multiple contexts",
            "venue": "Journal of Vision,",
            "year": 2020
        },
        {
            "authors": [
                "Guillermo Aguilar",
                "Felix A Wichmann",
                "Marianne Maertens"
            ],
            "title": "Comparing sensitivity estimates from mlds and forced-choice methods in a slant-from-texture experiment",
            "venue": "Journal of Vision,",
            "year": 2017
        },
        {
            "authors": [
                "Dan Amir",
                "Yair Weiss"
            ],
            "title": "Understanding and simplifying perceptual distances",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Fred Attneave"
            ],
            "title": "Some informational aspects of visual perception",
            "venue": "Psychological review,",
            "year": 1954
        },
        {
            "authors": [
                "Horace B Barlow"
            ],
            "title": "Possible principles underlying the transformation of sensory messages",
            "venue": "Sensory communication,",
            "year": 1961
        },
        {
            "authors": [
                "Pouya Bashivan",
                "Kohitij Kar",
                "James J DiCarlo"
            ],
            "title": "Neural population control via deep image synthesis",
            "venue": "Science, 364(6439):eaav9436,",
            "year": 2019
        },
        {
            "authors": [
                "Philipp Berens",
                "Alexander S Ecker",
                "Sebastian Gerwinn",
                "Andreas S Tolias",
                "Matthias Bethge"
            ],
            "title": "Reassessing optimal neural population codes with neurometric functions",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 2011
        },
        {
            "authors": [
                "Matthias Bethge",
                "David Rotermund",
                "Klaus Pawelzik"
            ],
            "title": "Optimal short-term population coding: When fisher information fails",
            "venue": "Neural computation,",
            "year": 2002
        },
        {
            "authors": [
                "Nicolas Brunel",
                "Jean-Pierre Nadal"
            ],
            "title": "Mutual information, fisher information, and population coding",
            "venue": "Neural computation,",
            "year": 1998
        },
        {
            "authors": [
                "Fr\u00e9d\u00e9ric Devinck",
                "Kenneth Knoblauch"
            ],
            "title": "A common signal detection model accounts for both perception and discrimination of the watercolor effect",
            "venue": "Journal of Vision,",
            "year": 2012
        },
        {
            "authors": [
                "Khemraj Emrith",
                "MJ Chantler",
                "PR Green",
                "LT Maloney",
                "ADF Clarke"
            ],
            "title": "Measuring perceived differences in surface texture due to changes in higher order statistics",
            "venue": "JOSA A,",
            "year": 2010
        },
        {
            "authors": [
                "Bruno Galerne"
            ],
            "title": "Stochastic image models and texture synthesis",
            "venue": "PhD thesis, E\u0301cole normale supe\u0301rieure de Cachan-ENS Cachan,",
            "year": 2010
        },
        {
            "authors": [
                "Leon Gatys",
                "Alexander S Ecker",
                "Matthias Bethge"
            ],
            "title": "Texture synthesis using convolutional neural networks",
            "venue": "Advances in neural information processing systems,",
            "year": 2015
        },
        {
            "authors": [
                "Ahna R Girshick",
                "Michael S Landy",
                "Eero P Simoncelli"
            ],
            "title": "Cardinal rules: visual orientation perception reflects knowledge of environmental statistics",
            "venue": "Nature neuroscience,",
            "year": 2011
        },
        {
            "authors": [
                "Alexander Hepburn",
                "Valero Laparra",
                "Raul Santos-Rodriguez",
                "Johannes Ball\u00e9",
                "Jesus Malo"
            ],
            "title": "On the relation between statistical learning and perceptual distances",
            "venue": "In 10th International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Martin Heusel",
                "Hubert Ramsauer",
                "Thomas Unterthiner",
                "Bernhard Nessler",
                "Sepp Hochreiter"
            ],
            "title": "Gans trained by a two time-scale update rule converge to a local nash equilibrium",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Ingmar Kanitscheider",
                "Ruben Coen-Cagli",
                "Alexandre Pouget"
            ],
            "title": "Origin of information-limiting noise correlations",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 2015
        },
        {
            "authors": [
                "Eric Kee",
                "Hany Farid"
            ],
            "title": "A perceptual metric for photo retouching",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 1990
        },
        {
            "authors": [
                "David C Knill",
                "Whitman Richards"
            ],
            "title": "Perception as Bayesian inference",
            "year": 1996
        },
        {
            "authors": [
                "Kenneth Knoblauch",
                "Laurence T Maloney"
            ],
            "title": "Mlds: Maximum likelihood difference scaling in r",
            "venue": "Journal of Statistical Software,",
            "year": 2008
        },
        {
            "authors": [
                "Andrey Kolmogoroff"
            ],
            "title": "Grundbegriffe der wahrscheinlichkeitsrechnung",
            "year": 1933
        },
        {
            "authors": [
                "Tuomas Kynk\u00e4\u00e4nniemi",
                "Tero Karras",
                "Miika Aittala",
                "Timo Aila",
                "Jaakko Lehtinen"
            ],
            "title": "The role of imagenet classes in fr\u00e9chet inception distance",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Laurence T Maloney",
                "Joong Nam Yang"
            ],
            "title": "Maximum likelihood difference scaling",
            "venue": "Journal of Vision,",
            "year": 2003
        },
        {
            "authors": [
                "Tyler S Manning",
                "Benjamin N Naecker",
                "Iona R McLean",
                "Bas Rokers",
                "Jonathan W Pillow",
                "Emily A Cooper"
            ],
            "title": "A general framework for inferring bayesian ideal observer models from psychophysical data",
            "year": 2023
        },
        {
            "authors": [
                "William T Newsome",
                "Kenneth H Britten",
                "J Anthony Movshon"
            ],
            "title": "Neuronal correlates of a perceptual decision",
            "venue": "Nature, 341(6237):52\u201354,",
            "year": 1989
        },
        {
            "authors": [
                "Gouki Okazawa",
                "Satohiro Tajima",
                "Hidehiko Komatsu"
            ],
            "title": "Image statistics underlying natural texture selectivity of neurons in macaque v4",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 2015
        },
        {
            "authors": [
                "Bruno A Olshausen",
                "David J Field"
            ],
            "title": "How close are we to understanding v1",
            "venue": "Neural computation,",
            "year": 2005
        },
        {
            "authors": [
                "Javier Portilla",
                "Eero P Simoncelli"
            ],
            "title": "A parametric texture model based on joint statistics of complex wavelet coefficients",
            "venue": "International journal of computer vision,",
            "year": 2000
        },
        {
            "authors": [
                "Tim Salimans",
                "Ian Goodfellow",
                "Wojciech Zaremba",
                "Vicki Cheung",
                "Alec Radford",
                "Xi Chen"
            ],
            "title": "Improved techniques for training gans",
            "venue": "Advances in neural information processing systems,",
            "year": 2016
        },
        {
            "authors": [
                "Alan A Stocker",
                "Eero P Simoncelli"
            ],
            "title": "Noise characteristics and prior expectations in human visual speed perception",
            "venue": "Nature neuroscience,",
            "year": 2006
        },
        {
            "authors": [
                "L Louis"
            ],
            "title": "Thurstone. A law of comparative judgment",
            "venue": "Psychological review,",
            "year": 1927
        },
        {
            "authors": [
                "Jonathan Vacher",
                "Thibaud Briand"
            ],
            "title": "The Portilla-Simoncelli Texture Model: towards Understanding the Early Visual Cortex",
            "venue": "Image Processing On Line,",
            "year": 2021
        },
        {
            "authors": [
                "Jonathan Vacher",
                "Andrew Isaac Meso",
                "Laurent U Perrinet",
                "Gabriel Peyr\u00e9"
            ],
            "title": "Bayesian modeling of motion perception using dynamical stochastic textures",
            "venue": "Neural computation,",
            "year": 2018
        },
        {
            "authors": [
                "Jonathan Vacher",
                "Aida Davila",
                "Adam Kohn",
                "Ruben Coen-Cagli"
            ],
            "title": "Texture interpolation for probing visual perception",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Jonathan D Victor",
                "Mary M Conte",
                "Charles F Chubb"
            ],
            "title": "Textures as probes of visual processing",
            "venue": "Annual review of vision science,",
            "year": 2017
        },
        {
            "authors": [
                "Martin J Wainwright"
            ],
            "title": "Visual adaptation as optimal information transmission",
            "venue": "Vision research,",
            "year": 1999
        },
        {
            "authors": [
                "Zhou Wang",
                "Alan C Bovik",
                "Hamid R Sheikh",
                "Eero P Simoncelli"
            ],
            "title": "Image quality assessment: from error visibility to structural similarity",
            "venue": "IEEE transactions on image processing,",
            "year": 2004
        },
        {
            "authors": [
                "Xue-Xin Wei",
                "Alan A Stocker"
            ],
            "title": "Mutual information, fisher information, and efficient coding",
            "venue": "Neural computation,",
            "year": 2016
        },
        {
            "authors": [
                "Xue-Xin Wei",
                "Alan A Stocker"
            ],
            "title": "Lawful relation between perceptual bias and discriminability",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 2017
        },
        {
            "authors": [
                "Peter Whittle"
            ],
            "title": "The analysis of multiple stationary time series",
            "venue": "Journal of the Royal Statistical Society: Series B (Methodological),",
            "year": 1953
        },
        {
            "authors": [
                "Stuart Yarrow",
                "Edward Challis",
                "Peggy Seri\u00e8s"
            ],
            "title": "Fisher and shannon information in finite neural populations",
            "venue": "Neural computation,",
            "year": 2012
        },
        {
            "authors": [
                "Hang Zhang",
                "Xiangjuan Ren",
                "Laurence T Maloney"
            ],
            "title": "The bounded rationality of probability distortion",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 2020
        },
        {
            "authors": [
                "Richard Zhang",
                "Phillip Isola",
                "Alexei A Efros",
                "Eli Shechtman",
                "Oliver Wang"
            ],
            "title": "The unreasonable effectiveness of deep features as a perceptual metric",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "Perception is often viewed as a process that transforms physical variables, external to an observer, into internal psychological variables. Such a process can be modeled by a function coined perceptual scale. The perceptual scale can be deduced from psychophysical measurements that consist in comparing the relative differences between stimuli (i.e. difference scaling experiments). However, this approach is often overlooked by the modeling and experimentation communities. Here, we demonstrate the value of measuring the perceptual scale of classical (spatial frequency, orientation) and less classical physical variables (interpolation between textures) by embedding it in recent probabilistic modeling of perception. First, we show that the assumption that an observer has an internal representation of univariate parameters such as spatial frequency or orientation while stimuli are high-dimensional does not lead to contradictory predictions when following the theoretical framework. Second, we show that the measured perceptual scale corresponds to the transduction function hypothesized in this framework. In particular, we demonstrate that it is related to the Fisher information of the generative model that underlies perception and we test the predictions given by the generative model of different stimuli in a set a of difference scaling experiments. Our main conclusion is that the perceptual scale is mostly driven by the stimulus power spectrum. Finally, we propose that this measure of perceptual scale is a way to push further the notion of perceptual distances by estimating the perceptual geometry of images i.e. the path between images instead of simply the distance between those."
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "Difference Scaling Difference scaling methods allow us to measure the relative perceptual differences of multiple stimuli in human observers. Such methods have been used as early as in the 1960s to measure the relative differences of perceived color, contrast or loudness (see Maloney & Yang (2003) and references therein). This is only at the beginning of our century that a fitting method, called Maximum Likelihood Difference Scaling (MLDS), was developed (Maloney & Yang, 2003; Knoblauch & Maloney, 2008) to infer the function that maps the physical to the perceptual space. This function is called perceptual scale. The critical assumption behind the fitting methods dates back to Thurstone\u2019s law of comparative judgment (see case V Thurstone (1927)): the difference between two values along a psychological dimension is corrupted by noise that has a constant variance. The perceptual scale informs us about how a stimulus is perceived when modified along a continuous physical scale (e.g. color, contrast, . . . ). When the slope of the perceptual scale is steep, perception changes rapidly with small physical changes i.e. the observer is highly sensitive to physical variations. When the slope is shallow, perception is stable even for large physical variations i.e. the observer is weakly sensitive to physical variations. Recently, the MLDS method has been used to measure the perceptual scales of surface texture (Emrith et al., 2010), watercolor effect (Devinck & Knoblauch, 2012), slant-from-texture (Aguilar et al., 2017), lightness (Aguilar & Maertens, 2020) or probabilities (Zhang et al., 2020). However, perceptual scales of more fundamental physical variables such as orientation and spatial frequency have not been measured nor related to existing probabilistic theory of perception. Additionally, while relations between standard Two-alternative Forced Choice (2AFC) measurements and perceptual scales have been studied (Aguilar et al., 2017), it was a theory of perception that was previously described (Wei & Stocker, 2017) that has been used to derive predictions.\nProbabilistic modeling of perception Thurstone\u2019s law of comparative judgment is a first brick in the history of probabilistic modeling of perception (Thurstone, 1927). Indeed, it introduced the incipient concept of random variable (Chebyshev, 1867; Kolmogoroff, 1933) in psychophysics. Then, the development of computer science and information theory had major impact in perception studies, bringing concepts such as redundancy reduction and information maximization (Attneave, 1954; Barlow et al., 1961). More specifically, when applied to texture perception, these concepts led to Julesz\u2019 hypothesis that perception of textures is statistical (Victor et al., 2017) i.e. textures with similar statistics are indistinguishable. Later on, together with advances in image processing, Julesz\u2019 hypothesis led to modern texture synthesis algorithms (Portilla & Simoncelli, 2000; Gatys et al., 2015). In parallel, a core theorem of probabilities, namely Bayes rule, was found to efficiently predicts human perceptual behaviors (Knill & Richards, 1996). Further works have been dedicated to solve the inverse problem of identifying observers\u2019 prior that best explain their perception (Stocker & Simoncelli, 2006; Girshick et al., 2011; Vacher et al., 2018; Manning et al., 2023). Inspired by neural population coding models, an optimal observer theory is now described in details by Wei & Stocker (2017). The main consequence of this theory is the existence of a simple relation between perceptual bias and sensitivity. Yet, the theory is limited to a hypothesized scalar perceptual variable while it is established that only part of the neurons of the primary visual cortex is tuned to scalar variables such as spatial and temporal frequencies or orientation (Olshausen & Field, 2005). In higher visual areas, it is more and more difficult to identify scalar variables that uniquely drive single neurons as they respond to increasingly complex patterns (Bashivan et al., 2019). In some previous work, Wainwright (Wainwright, 1999) have used higher dimensional natural image statistics (auto-correlation and power spectrum) to explain various psychophysical observations. Though, it is unclear how this approach relates to the univariate Bayesian framework.\nFisher information in neural populations The theory behind the work of Wei & Stocker (2017) is largely inspired by previous work on neural population coding (Brunel & Nadal, 1998). In this and subsequent works (Yarrow et al., 2012; Kanitscheider et al., 2015; Bethge et al., 2002; Wei & Stocker, 2016), it is often ultimately assumed that neurons are Poisson firing neurons parameterized by the tuning curve of a scalar variable. As stated previously, it is a quite restrictive framework as all neurons are not tuned to a scalar variable (Olshausen & Field, 2005). By applying this framework to perception, Wei and Stocker remove these unnecessary assumptions. They derive the relation between perceptual bias and sensitivity which at its core comes from the relation between Fisher information and prior under the optimal coding assumption (Brunel & Nadal, 1998)\nPS(s) \u221d \u221a\nI(s) (1) where S is a stimulus variable. Fisher information is used to quantify the variance of a stimulus estimator from a neural population encoding (Cramer-Rao lower bound). In contrast, priors are introduced in observer models to explain perceptual biases. Therefore, Equation (1) links neural population models and perceptual models. However, less attention is dedicated to the underlying encoding model, where a stimulus variable S is non-linearly related to an internal measurement M through a function \u03c8 plus an additive Gaussian noise N with constant variance,\nM = \u03c8(S) +N. (2)\nInterestingly, such an encoding model is very similar to the assumptions behind the observer model underlying the MLDS method. However, the precise nature of these internal measurements has so far remained abstract.\nPerceptual distance A perceptual distance is a score of image quality used to quantify and to compare the performances of image restoration or generation methods. Perceptual distances have been introduced to overcome the limitation of the Signal-to-Noise Ratio (also known as SNR). Indeed, images with similar SNR could vary subjectively in quality when presented to human observers (Wang et al., 2004). The Structural SIMilarity index (SSIM) is a score that is popular to provide a better account of perceptual similarity as compared to SNR. Since then, variations of SSIM have been proposed to more specific purposes such as estimating photo retouching (Kee & Farid, 2011). However, these scores require to compare the image to be rated to a reference image. In recent years, the success of deep generative modeling have led to the emergence of new scores such as the Inception score (Salimans et al., 2016) or the Fr\u00e9chet Inception Distance (FID) (Heusel et al., 2017). These scores have in common that they compare the generated image distribution to the true empirical image distribution instead of a generated image to a reference image. In addition, they are based on Deep Neural Network (DNN) features. Overall, it has been shown that such DNN features-based\nscores are better aligned with human perception than SSIM or SNR for example (Zhang et al., 2018). One possible explanation is that DNN are able to capture high-order image statistics and that as hypothesized in vision, our perception is deeply related to image statistics (see Hepburn et al. (2022) and references in previous paragraphs). Yet, these coined perceptual distances are not exempt of limitations as they could be subject to bias when classes specific features are present or not (Kynk\u00e4\u00e4nniemi et al., 2023). Overcoming these biases will likely require to move away from training by measuring higher-order statistics on the image directly without relying on some learned or random filters (Amir & Weiss, 2021). One other limitation of perceptual distances is that they do not provide any information about how well a model has captured the perceptual geometry of images. Providing a full account of perceptual geometry is more demanding, it requires to compare the path when moving from one image to another and not only their distance along this path.\nContributions Our work brings several contributions to overcome the limitations introduced above. First, we explain that a convergence theorem of discrete spot noises is a way to resolve the tension between univariate Bayesian theories of perception (Wei & Stocker, 2017) and the high dimensionality of images (Wainwright, 1999). More precisely, the hypothesis that an observer has a univariate representation of the distribution of the parameter of interest (e.g. spatial frequency), is compatible with the assumption that an observer is measuring the spectral energy distribution of the image in that both assumptions leads to similar predictions. Second, we show that the function \u03c8, introduced in Equation 2, can be interpreted as the perceptual scale as measured by a difference scaling experiment. Then, we demonstrate again that this function \u03c8 can be predicted from the Fisher information of the stimulus when using the true distribution of the noisy internal stimulus representation knowing the presented stimulus i.e. the distribution of the measurements M that we give explicitly. Therefore, we provide a clear link between theory and experiment. Third, we propose to go further in exploring perceptual distances by estimating how well the geometry of natural images captured by models matches the perceptual geometry. For this purpose, we empirically test the prediction given by the Fisher information of Gaussian vectors and processes in a series of experiments (code and data, texture interpolation code1) involving stochastic stimuli characterized by their power spectrum or their higher-order statistics captured by VGG-19 (Gatys et al., 2015). In particular, we collapse the high dimensionality of these statistics by interpolating between single textures (Vacher et al., 2020) and we measure the corresponding perceptual scale when going from one texture to another. Finally, we propose the Area Matching Score (AMS) score to quantify the mismatch between the predicted and the measured perceptual scales providing a clear method to evaluate the perceptual alignment between generative image models and human vision.\nNotations Unless stated differently, upper case letters (e.g. X) are random variables and lower case letters (e.g. x) are samples or realizations of those random variables. The probability density at X = x is denoted PX(x). Similarly, the conditional probability density at X = x knowing Y = y is donoted PX|Y (x, y). The set S = [sinit, sfinal] is the stimulus segment."
        },
        {
            "heading": "2 METHODS",
            "text": ""
        },
        {
            "heading": "2.1 STOCHASTIC VISUAL STIMULATION",
            "text": "We recall some theoretical results about the artificial textures we use in the current work. Firstly, we use textures that are stationary Gaussian Random Fields (GRFs) fully characterized by their scalar mean and their auto-correlation function (or equivalently their power spectrum i.e. the autocorrelation Fourier transform). Interestingly, such GRFs can be seen as the limit of high intensity discrete spot noises. This result allows one to relate the densities of local image features such as orientation and scales to the power spectrum of the image (seen as a GRF). In summary, it provides a link between scalar densities and the high-dimensional Gaussian distribution of the image. We will see in later sections that this result leads both approach to similar predictions for perceptual scales. Secondly, we use naturalistic textures that are obtained by imposing high-order and high-dimensional statistics obtained using VGG-19. However, the result mentioned above and detailed below does not hold for naturalistic textures. It is unknown at this stage if similar results could be obtained with some feature under some (non-linear) transformation.\n1,\nAsymptotic Discrete Spot Noise Let \u03be0 = (1, 0). Let g\u03c3 be a Gabor function defined for all \u03c3 > 0 and for all x \u2208 R2 by\ng\u03c3(x) = 1\n2\u03c0 cos(x \u00b7 \u03be0)e\u2212\n\u03c32\n2 ||x|| 2\n.\nIn addition, let \u03c6z,\u03b8 be a scaled rotation defined for all (z, \u03b8) \u2208 R+ \u00d7 [0, \u03c0] by \u03c6z,\u03b8(x) = zR\u2212\u03b8(x)\nwhere R\u03b8 is the rotation of angle \u03b8. Now, let F\u03bb,\u03c3 be a discrete spot noise of intensity \u03bb > 0 defined as the following random field for all x \u2208 R2\nF\u03bb,\u03c3(x) = 1\u221a \u03bb \u2211 k\u2208N g\u03c3(\u03c6Zk,\u0398k(x\u2212Xk))\nwhere (Xk, Zk,\u0398k)k\u2208N are iid random variables. Specifically (Xk)k\u2208N is a 2-D Poisson process of intensity \u03bb > 0 and (Zk,\u0398k)k\u2208N have densities (PZ ,P\u0398). Proposition 1 (Convergence and Power Spectrum). In the limit of infinite intensity (\u03bb \u2212\u2192 +\u221e) and pure wave (\u03c3 \u2212\u2192 0), F\u03bb,\u03c3 converges towards a Gaussian field F with the following power spectrum for all \u03be \u2208 R2,\n\u03b3\u0302(\u03be) = 1\n||\u03be||2 PZ(||\u03be||)P\u0398(\u2220\u03be)\nwhere \u03be = (||\u03be|| cos(\u2220\u03be), ||\u03be|| sin(\u2220\u03be)).\nProof. This is a special case of Proposition 2 in Vacher et al. (2018). The general result is Theorem 3.1 in Galerne (2010).\nIn practice, the distribution PZ and P\u0398 are parametrized by (Z0,\u03a3Z) and (\u03980,\u03a3\u0398) respectively.\nBy providing a relation between local feature statistics (orientation and scale) and the image power spectrum, Proposition 1 will allow us to justify the common assumption made when modeling psychophysical data that is, the feature of interest is directly used by the observer instead of the image (Knill & Richards, 1996; Stocker & Simoncelli, 2006; Girshick et al., 2011). See Section 2.3.\nInterpolation of Naturalistic Textures Even though for experimental purposes the GRFs described above can be parameterized by just a few scalar variables (Vacher et al., 2018), naturalistic textures depend on the statistics of high-dimensional features extracted at different layers of VGG-19 (Gatys et al., 2015; Vacher et al., 2020). Previous algorithms widely used in vision studies (Portilla & Simoncelli, 2000; Vacher & Briand, 2021) were using fewer parameters, but the number was still too large to derive clear and interpretable results (Okazawa et al., 2015). One way to efficiently collapse the dimension parameterizing those textures is to use interpolation (Vacher et al., 2020). As a consequence the texture features of an interpolation of textures extracted at layers k are interpreted as realizations of a random variable Ak(s) with mean \u00b5W (s) and covariance \u03a3W (s) (see Appendix C). Assuming Gaussiannity, it will become possible to derive predictions for the perceptual scale measured along the interpolation path."
        },
        {
            "heading": "2.2 THURSTONE SCALE, FISHER INFORMATION AND MLDS",
            "text": "First, we define more precisely the encoding model given in Equation 2 as follows\nM = R+N where R = \u03c8(S) with \u03c8 : S \u2192 S. (3) We use the above description to highlight the fact that M , R and N are random variables that are internal to the observer while S is external to them, it is an environment variable, an external stimulus. In practice, the noise N is often assumed to be Gaussian with variance \u03c32. It corrupts the internal representation of the stimulus R to give what we call the internal measurement M . Then, we define Fisher information for two abstracts unidimensional random variables. Definition 1 (One-dimensional Fisher information). Let X and Y be two random variables defined respectively on two abstract spaces X and Y and let PX|Y be the conditional density of X knowing Y . The Fisher information carried by X about Y is a function I : Y \u2212\u2192 R defined for all y \u2208 Y by\nIY (y) = EX|Y\n(( \u2202 log(PX|Y )\n\u2202y (X, y)\n)2) . (4)\nIn statistics, Fisher information is used as a upper bound of the precision of an estimation (see Cram\u00e9r-Rao bound). This is also how we interpret it for an observer, namely the maximal precision of their estimation of a stimulus S.\nThe precise definition given above is helpful to realize that the Fisher information carried by M about S (IS) is different from the one carried by M about R (IR). We can go one step further though, and establish the following relation between those two\nIS(s) = \u03c8\u2032(s)2IR(\u03c8(s)). (5)\nA reformulation of Thurstone law of comparative judgment (Thurstone, 1927) is to assume that the Fisher information of an observer\u2019s internal representation IR is constant. It is not so obvious to understand why this assumption is relevant. The idea is that an observer has only access to her internal states, she never observes any realization of an external stimulus S. Every external variable is transformed to an internal one through the psychological function \u03c8. Therefore, without any knowledge about the external world, a fair assumption is to allocate equal resources to every possible internal state in order to be equally precise in our estimates of different states (without knowing to what they correspond to in the external world). This assumption is also equivalent to assuming that internal observer\u2019s noise (a common notion used in psychophysics) is constant. If the internal Fisher information is constant we can now express the psychological function simply in terms of external Fisher information. This is summarized in the following proposition.\nProposition 2. Assume Equation (3), the internal Fisher information IR is constant if and only if for all s \u2208 S the psychological function \u03c8 verifies\n\u03c8(s) \u221d \u222b s sinit \u221a IS(t)dt. (6)\nProof. See Appendix D.\nRelation to the MLDS observer model. In the MLDS framework, an observer has to judge which pair of stimuli is more similar to another. Assuming three stimuli (si, sj , sk), those are transformed through the psychological scale \u03c8 and the observer responds by comparing the difference of differences between the pairs di,j,k = |\u03c8(si)\u2212 \u03c8(sj)| \u2212 |\u03c8(sj)\u2212 \u03c8(sk)|. This difference is assumed to be corrupted by an internal noise Nmlds of constant variance \u03c32mlds i.e. \u2206i,j,k = di,j,k +Nmlds. Those assumptions are sufficient to recover an estimate of \u03c8 (Knoblauch & Maloney, 2008). In addition, it is often assumed that there is no specific internal ordering of the variables so that the difference di,j,k can be written without absolute value. In that case, assuming the encoding model (3) is enough to recover the MLDS observer model, we have the following relation between the noise variances \u03c32mlds = 4\u03c3 2.\n2.3 FISHER INFORMATION CARRIED BY THE IMAGE vs BY THE LOCAL FEATURES\nIn the previous section, we have introduce an observer model based on an abstract random internal measurement M . It is often unclear what those measurements are. Ideally inspired by neurophysiology, the measurements are responses of neurons to the image often modeled by Linear/Non-linear operations, even though those modeling stages are often dropped in perceptual studies. In the case of GRFs parameterized by spatial frequency (or scale) and orientation distributions, it is often accepted to assume that the measurements are samples of an appropriate distribution e.g. a Log-Normal distribution for the spatial frequency or a Von-Mises distribution for the orientation. Using the notation of the previous section, these cases correspond to measurement M = Z with stimulus S = Z0 and measurement M = \u0398 with stimuli S = \u03980. We will see that in both cases this is equivalent to consider that measurements are the image itself M = F with S = Z0 or S = \u03980. This is because Fisher information is given in closed-form and that perceptual scale can be predicted using Proposition 2. Similar results hold for S = BZ and S = \u03a3\u03b8 (note that (Z0, BZ) and (\u03980,\u03a3\u0398) are parameters of PZ and P\u0398 introduced in Section 2.1). The predictions are given in Figure 1.\nFisher Information of Log-Normal and Von-Mises Distributions We give the precise parametrization and the corresponding Fisher information of the Log-Normal and Von-Mises distributions in Appendix A.\nFisher Information of Parametric GRFs Now, we consider a GRF texture F with mean \u00b5 \u2208 R and autocorrelation function \u03b3 (or equivalently power spectrum \u03b3\u0302) parameterized by s \u2208 S. Mathematically, the texture can be expressed for all x \u2208 R2 and s \u2208 S, as\nF (x, s) = \u00b5+ \u222b R2 k(x\u2212 y, s)dW (y) (7)\nwhere k(\u00b7, s) = F\u22121( \u221a \u03b3\u0302(\u00b7, s)) and W is a classical Wiener process.\nProposition 3. The Fisher Information carried by F about S is\nI(s) = 1 2 \u222b R2\n1\n|\u03b3\u0302(\u03be, s)|2 \u2223\u2223\u2223\u2223\u2202\u03b3\u0302(\u03be, s)\u2202s \u2223\u2223\u2223\u22232 d\u03be = 12 \u222b R2 \u2223\u2223\u2223\u2223\u2202 log(\u03b3\u0302(\u03be, s))\u2202s \u2223\u2223\u2223\u22232 d\u03be.\nProof. This is a specific case of Whittle formula (Whittle, 1953, Theorem 9).\nWe combine Proposition 3 with Proposition 1 using the Log-normal and the Von-Mises distributions to express the power spectrum \u03b3\u0302 parameterized by S = Z0, S = BZ , S = \u03980 or S = \u03a3\u03b8. Therefore, the Fisher information carried by measurements M = F comes down to the Fisher information carried by measurements M = Z (spatial frequency) or M = \u0398 (orientation) as described above up to a multiplicative constant of 1/2. As a consequence both approaches lead to similar predictions about the perceptual scales measured for these parameters.\nFisher Information of Parametric Gaussian Vectors In the case of interpolation between naturalistic textures, we do not have a direct generative model of the texture conditionally on the interpolation parameter s. Instead, the texture is generated using a gradient descent to impose the statistics of VGG-19 features at multiples layers for which we have a generative model. Therefore, at layer k and for s \u2208 S the activation Ak(s) of texture Fk(s) is\nAk(s) = \u00b5k(s) + \u03a3k(s)N with \u00b5k \u2208 C1 ( S,Rdk ) and \u03a3k \u2208 C1 ( S,R dk\u00d7dk )\n(8)\nwhere N \u223c N (0, Idk) is a standard normal random vector and dk is the feature dimension of layer k. Proposition 4. The Fisher Information carried by Ak about S is\nI(s) = \u00b5\u2032k(s)\u03a3k(s)\u22121\u00b5\u2032k(s) + 1 2 Tr ( \u03a3k(s) \u22121\u03a3\u2032k(s)\u03a3k(s) \u22121\u03a3\u2032k(s) ) .\nProof. See Appendix B.\n0.0 0.5 1.0 0.0\n0.5\n1.0 spatial freq.\nhuman theory\n0.0 0.5 1.0\nspatial freq. bandwidth\n0.0 0.5 1.0\nori. bandwidth\nFigure 3: Measured and predicted perceptual scales for the spatial frequency mode (left), the spatial frequency bandwidth (middle) and the orientation bandwidth (right).\nAs stated earlier in the manuscript, no link can be made with interpretable feature distributions as it is the case for GRFs. Though, precise expressions for \u00b5k and \u03a3k are available in close forms in the Gaussian case as assumed here (see Appendix C). In practice, the feature activations are not Gaussian (Vacher et al., 2020)."
        },
        {
            "heading": "2.4 PREDICTIONS AND EXPERIMENTAL METHODS",
            "text": "The calculated Fisher informations together with Proposition 2 allows us to predict the perceptual scales corresponding to the parameters described in the previous section. These predictions hold under the assumed generative models for measurements.\nPredictions In the case of GRFs textures, we recall that assuming that spatial frequency or orientation are directly measured or that the image as a whole is measured makes no differences in the prediction (see bottom-right of Figure 1). In the case of naturalistic textures, the measurements are assumed to be the feature activations of the texture in VGG-19 at layer 2 to 5 (see bottom-right of Figure 2). For the naturalistic, we alternatively propose that measurements are the single pixel gray levels, the image itself (i.e. the power spectrum as for GRFs) or the wavelet activations.\nExperimental Methods The experiment consists of trials where participants have to make a similarity judgment. Participants are presented with 3 stimuli with parameters s1 < s2 < s3 and are required to choose which of the two pairs with parameters (s1, s2) and (s2, s3) is the most similar. We used four sets of textures (see Figure 1 and 2): (i) the first set consists of parameterized artificial textures where we measured the perceptual scales of spatial frequency, spatial frequency bandwidth and orientation bandwidth (see Appendix E for details); (ii) the other three sets consist of interpolations between arbitrary textures. A set of textures for which the perceptual scale corresponds to an early sensitivity (i.e. steep-to-shallow slope, see top-left of Figure 2). Another one for which the perceptual scale corresponds to late sensitivity (i.e. shallow-to-steep slope, see top-right of Figure 2). And a last set for which the predictions are inconsistent from one layer of VGG-19 to another (bottom-left of Figure 2). All stimuli had an average luminance of 128 (range [0, 255]) and an RMS contrast of 39.7. For each texture pair, we use 13 equally spaced (\u03b4s = 0.083) interpolation weights. To ensure that stimulus comparisons are around the discrimination threshold we only use triplets such that |s1,3 \u2212 s2| \u2264 3\u03b4s. For each texture pair, a group of 5 naive participants performed the experiment. Participants were recruited through the platform prolific (https://www.prolific.com), performed the\nexperiments online, and were paid 9\u00a3/hr. Monitor gamma was measured using a psychometric estimation and corrected to 1. The MLDS model is described at the end of Section 2.2. The protocol was approved by the XXX."
        },
        {
            "heading": "3 RESULTS",
            "text": "3.1 ORIENTATION AND SPATIAL FREQUENCY\nThe perception of spatial frequencies is well-known in vision studies, its perceptual scale is expected to be logarithmic. Such a scale is also predicted by Fisher information as integrating the square-root (Proposition 2) of a squared inverse (Proposition 1) leads to a logarithm. The measured perceptual scale of the spatial frequency mode matches correctly this prediction (left of Figure 3). The spatial frequency and orientation bandwidths are less studied, the predictions are qualitatively the same as for the spatial frequency mode (Proposition 2 and Appendix Proposition 2). The Fisher information of the orientation bandwidth\nis more complex but leads to a similar curve. The measured perceptual scale is more variable for the orientation bandwidth (larger error bars) but is still in line with the prediction (predicted offset from linear behavior is exaggerated, see right of Figure 3). In contrast, the measured perceptual scales of spatial frequency bandwidth is approximately linear for low values while its gets supra-linear at intermediate values and even saturate for the highest values (center of Figure 3)."
        },
        {
            "heading": "3.2 INTERPOLATION BETWEEN NATURALISTIC TEXTURES",
            "text": "We present the perceptual scales measured for the different groups of natural textures in Figure 4 and 5. On these figures, the prediction given by the auto-correlation (i.e. when considering the textures as GRFs) is shown. Predictions assuming alternative measurements (pixel, wavelet, and VGG-19) are quantitatively compared in Figure 6 using the following Area Matching Score : AMS =\u222b 1 0\nsign(fm(x)\u2212x)(fth(x)\u2212x)/|fm(x)\u2212x|dx where fm and fth are respectively the measured and predicted scales. Intuition about score values is given in Figure 6a.\nEarly and Late Sensitivity For the set of early sensitivity texture pairs, measured perceptual scales are inline with the predictions (Figure 4) in the sense that a linear (pair01, pair04-05) or a supra-linear (pair02-03) perceptual scale is measured in all texture pairs. The same hold for the set of late sensitivity texture pairs (Figure 4), but this time in the sense that a linear (pair06 and pair08) or a sub-linear (pair07 and pair09-10) perceptual scale is measured in all texture\npairs. Such a result is also valid for the predictions based on alternative measurement assumptions as shown in Figure 6 by the fact that all scores are positive for pair01-10.\nConflicting predictions For the set of textures with conflicting predictions (Figure 5), for both texture pairs, we observe that the GRF measurement assumption predicts a late sensitivity while the measured perceptual scale corresponds to an early sensitivity with a late saturation. Other measurement assumptions are not providing better prediction as their score is either close to 0 or negative. However, there is one exception for pair11 under the wavelet measurement assumption which has a ideal score, close to 1 (up to score limitation, see Section 4).\nMeasurement Assumption Scores As previously stated, all assumptions predict correctly whether the scale corresponds to late or early sensitivity (positive scores) except for the conflicting prediction texture pairs. Note that pair05 has also a score close to 0 under all assumptions (though this might be due to score limitation, see Section 4). On average, the GRF assumption is the best with an average score (\u00b199.7% CI) close to 1 (0.92\u00b1 0.69). The single pixel distribution assumption only predicts a linear behavior and has therefore a score close to 0. In contrast, the wavelet and VGG-19 assumptions often overestimate the early or late sensitivity (average scores above 1)."
        },
        {
            "heading": "4 DISCUSSION AND CONCLUSION",
            "text": "In the case of GRFs, we have shown that the univariate assumption behind the Bayesian theories of perception and the absence of this assumption (i.e. the observer is using all the information in the image) lead to the same prediction for the perceptual scales of spatial frequencies, orientations and their bandwidths. Such a result is due to the fact that these local feature distributions directly appear in the power spectrum (the Fourier transform of the auto-correlation) of GRFs (Proposition 1) and to our second result that is the perceptual scale is related to the Fisher information of the feature distribution (Proposition 2). In the case of naturalistic textures, it is unknown if such a result relating a (non-linear) transform and some feature distribution holds. Therefore, it is necessary to make new hypotheses about the measurements in order to predict the perceptual scale of an observer. We tested this issue in a series of difference scaling experiments involving GRF and naturalistic textures. Our main result is that the perceptual scale is mainly driven by the auto-correlation (or the power spectrum). However, it does not perfectly explain the measured perceptual scales, and in particular, the perceptual scale of pair11 appears to be driven by the wavelet representation. In addition, exploring those assumptions would require to be able to interpolate between textures while maintaining some measurements constant (e.g. interpolating between deep feature representations while maintaining a constant power spectrum). Another highly interesting future directions is to compare the perceptual scale to a neurometric scale, an equivalent scale but deduced from neurophysiological recordings as the equivalent exists for the psychometric function (Newsome et al., 1989; Berens et al., 2011). Other limitations lie in the MLDS method. Usually, running a difference scaling experiment requires to know ahead of time an approximation of the observer\u2019s sensitivity to the parameter that one would like to test. Here, we have not estimated the sensitivity of each participant and, therefore, have not adapted the stimuli accordingly. Instead, we have only tested the experiment ourselves and judged that it was feasible. Yet, it seems that we were near the participants sensitivity because the raw data do not show responses with very high or very low probabilities. All these questions demonstrate the ambition of our approach and the work that remains to be done to understand, beyond perceptual distance, perceptual metrics.\nREPRODUCIBILITY STATEMENT The reproducibility of our work will be ensured by the links provided to the data and code. Theoretical results are supported by proofs or references to proof."
        }
    ],
    "year": 2023
}