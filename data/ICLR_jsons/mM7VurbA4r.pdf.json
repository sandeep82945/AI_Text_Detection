{
    "abstractText": "Humans are social beings; we pursue social goals in our daily interactions, which is a crucial aspect of social intelligence. Yet, AI systems\u2019 abilities in this realm remain elusive. We present SOTOPIA, an open-ended environment to simulate complex social interactions between artificial agents and evaluate their social intelligence. In our environment, agents role-play and interact under a wide variety of scenarios; they coordinate, collaborate, exchange, and compete with each other to achieve complex social goals. We simulate the role-play interaction between LLM-based agents and humans within this task space and evaluate their performance with a holistic evaluation framework called SOTOPIA-EVAL. With SOTOPIA, we find significant differences between these models in terms of their social intelligence, and we identify a subset of SOTOPIA scenarios, SOTOPIAhard, that is generally challenging for all models. We find that on this subset, GPT4 achieves a significantly lower goal completion rate than humans and struggles to exhibit social commonsense reasoning and strategic communication skills. These findings demonstrate SOTOPIA\u2019s promise as a general platform for research on evaluating and improving social intelligence in artificial agents.",
    "authors": [],
    "id": "SP:7406efeadbf0567965e043e60575d2c12b2109b7",
    "references": [
        {
            "authors": [
                "Tarek Ait Baha",
                "Mohamed El Hajji",
                "Youssef Es-saady",
                "Hammou Fadili"
            ],
            "title": "The power of personalization: A systematic review of personality-adaptive chatbots",
            "venue": "SN Computer Science,",
            "year": 2023
        },
        {
            "authors": [
                "Daniel S Bernstein",
                "Robert Givan",
                "Neil Immerman",
                "Shlomo Zilberstein"
            ],
            "title": "The complexity of decentralized control of markov decision processes",
            "venue": "Mathematics of operations research,",
            "year": 2002
        },
        {
            "authors": [
                "Tom Burns",
                "Ewa Roszkowska",
                "Ugo Corte",
                "Nora Machado des Johansson"
            ],
            "title": "Sociological game theory: Agency, social structures and interaction processes. Optimum",
            "venue": "Studia Ekonomiczne, pp. 187\u2013199,",
            "year": 2017
        },
        {
            "authors": [
                "Roland B\u00e9nabou",
                "Jean Tirole"
            ],
            "title": "Incentives and prosocial behavior",
            "venue": "American Economic Review,",
            "year": 2006
        },
        {
            "authors": [
                "Chi-Min Chan",
                "Weize Chen",
                "Yusheng Su",
                "Jianxuan Yu",
                "Wei Xue",
                "Shanghang Zhang",
                "Jie Fu",
                "Zhiyuan Liu"
            ],
            "title": "Chateval: Towards better llm-based evaluators through multi-agent debate, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Myra Cheng",
                "Esin Durmus",
                "Dan Jurafsky"
            ],
            "title": "Marked personas: Using natural language prompts to measure stereotypes in language models",
            "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume",
            "year": 2023
        },
        {
            "authors": [
                "Jan Cieciuch",
                "Eldad Davidov"
            ],
            "title": "A comparison of the invariance properties of the pvq-40 and the pvq-21 to measure human values across german and polish samples",
            "venue": "Survey Research Methods,",
            "year": 2012
        },
        {
            "authors": [
                "Elisa De Stefani",
                "Doriana De Marco"
            ],
            "title": "Language, gesture, and emotional communication: An embodied view of social interaction",
            "venue": "Front. Psychol.,",
            "year": 2019
        },
        {
            "authors": [
                "Michael Dennis",
                "Natasha Jaques",
                "Eugene Vinitsky",
                "Alexandre Bayen",
                "Stuart Russell",
                "Andrew Critch",
                "Sergey Levine"
            ],
            "title": "Emergent complexity and zero-shot transfer via unsupervised environment design",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "A. Seza Do\u011fru\u00f6z",
                "Gabriel Skantze"
            ],
            "title": "How \u201copen\u201d are the conversations with open-domain chatbots? a proposal for speech event based evaluation",
            "venue": "In Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue,",
            "year": 2021
        },
        {
            "authors": [
                "Radwan El Othman",
                "Rola El Othman",
                "Rabih Hallit",
                "Sahar Obeid",
                "Souheil Hallit"
            ],
            "title": "Personality traits, emotional intelligence and decision-making styles in lebanese universities medical students",
            "venue": "BMC psychology,",
            "year": 2020
        },
        {
            "authors": [
                "Daniel C Feldman",
                "Hugh J Arnold"
            ],
            "title": "Personality types and career patterns: Some empirical evidence on holland\u2019s model",
            "venue": "Canadian Journal of Administrative Sciences/Revue Canadienne des Sciences de l\u2019Administration,",
            "year": 1985
        },
        {
            "authors": [
                "Maxwell Forbes",
                "Jena D. Hwang",
                "Vered Shwartz",
                "Maarten Sap",
                "Yejin Choi"
            ],
            "title": "Social chemistry 101: Learning to reason about social and moral norms",
            "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 653\u2013670,",
            "year": 2020
        },
        {
            "authors": [
                "Yao Fu",
                "Hao Peng",
                "Tushar Khot",
                "Mirella Lapata"
            ],
            "title": "Improving language model negotiation with self-play and in-context learning from ai feedback, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Andrew Gilpin",
                "Tuomas Sandholm"
            ],
            "title": "A competitive texas hold\u2019em poker player via automated abstraction and real-time equilibrium computation",
            "venue": "In Proceedings of the 21st National Conference on Artificial Intelligence - Volume 2,",
            "year": 2006
        },
        {
            "authors": [
                "Erving Goffman"
            ],
            "title": "The presentation of self in everyday life",
            "venue": "Penguin Modern Classics. Penguin Classics,",
            "year": 1959
        },
        {
            "authors": [
                "Lewis R Goldberg"
            ],
            "title": "The development of markers for the Big-Five factor structure",
            "venue": "Psychol. Assess.,",
            "year": 1992
        },
        {
            "authors": [
                "Katherine Hamilton",
                "Shin-I Shih",
                "Susan Mohammed"
            ],
            "title": "The development and validation of the rational and intuitive decision styles scale",
            "venue": "J. Pers. Assess.,",
            "year": 2016
        },
        {
            "authors": [
                "Elizabeth M. Minei Harry Weger",
                "Gina Castle Bell",
                "Melissa C. Robinson"
            ],
            "title": "The relative effectiveness of active listening in initial interactions",
            "venue": "International Journal of Listening,",
            "year": 2014
        },
        {
            "authors": [
                "He He",
                "Anusha Balakrishnan",
                "Mihail Eric",
                "Percy Liang"
            ],
            "title": "Learning symmetric collaborative dialogue agents with dynamic knowledge graph embeddings. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
            "year": 2017
        },
        {
            "authors": [
                "He He",
                "Derek Chen",
                "Anusha Balakrishnan",
                "Percy Liang"
            ],
            "title": "Decoupling strategy and generation in negotiation dialogues",
            "venue": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2018
        },
        {
            "authors": [
                "Sarah Susanna Hoppler",
                "Robin Segerer",
                "Jana Nikitin"
            ],
            "title": "The six components of social interactions: actor, partner, relation, activities, context, and evaluation",
            "venue": "Frontiers in Psychology,",
            "year": 2022
        },
        {
            "authors": [
                "Ehsan Hosseini-Asl",
                "Bryan McCann",
                "Chien-Sheng Wu",
                "Semih Yavuz",
                "Richard Socher"
            ],
            "title": "A simple language model for task-oriented dialogue, 2022",
            "year": 2022
        },
        {
            "authors": [
                "Hengyuan Hu",
                "Adam Lerer",
                "Alex Peysakhovich",
                "Jakob Foerster"
            ],
            "title": "Other-play\u201d for zero-shot coordination",
            "venue": "Proceedings of the 37th International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Mariela E Jaff\u00e9",
                "Maria Douneva"
            ],
            "title": "Secretive and close? how sharing secrets may impact perceptions of distance",
            "venue": "PLoS One,",
            "year": 2020
        },
        {
            "authors": [
                "Adrianna C. Jenkins",
                "Pierre Karashchuk",
                "Lusha Zhu",
                "Ming Hsu"
            ],
            "title": "Predicting human behavior toward members of different social groups",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 2018
        },
        {
            "authors": [
                "Liwei Jiang",
                "Jena D. Hwang",
                "Chandra Bhagavatula",
                "Ronan Le Bras",
                "Jenny Liang",
                "Jesse Dodge",
                "Keisuke Sakaguchi",
                "Maxwell Forbes",
                "Jon Borchardt",
                "Saadia Gabriel",
                "Yulia Tsvetkov",
                "Oren Etzioni",
                "Maarten Sap",
                "Regina Rini",
                "Yejin Choi"
            ],
            "title": "Can machines learn morality? the delphi experiment, 2022",
            "year": 2022
        },
        {
            "authors": [
                "Katharina Kann",
                "Abteen Ebrahimi",
                "Joewie Koh",
                "Shiran Dudy",
                "Alessandro Roncone"
            ],
            "title": "Opendomain dialogue generation: What we can do, cannot do, and should do next",
            "venue": "In Proceedings of the 4th Workshop on NLP for Conversational AI,",
            "year": 2022
        },
        {
            "authors": [
                "John F. Kihlstrom",
                "Nancy Cantor"
            ],
            "title": "Social Intelligence, pp. 756\u2013779",
            "year": 2020
        },
        {
            "authors": [
                "Hyunwoo Kim",
                "Jack Hessel",
                "Liwei Jiang",
                "Peter West",
                "Ximing Lu",
                "Youngjae Yu",
                "Pei Zhou",
                "Ronan Le Bras",
                "Malihe Alikhani",
                "Gunhee Kim",
                "Maarten Sap",
                "Yejin Choi"
            ],
            "title": "Soda: Million-scale dialogue distillation with social commonsense contextualization, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Matthew Le",
                "Y-Lan Boureau",
                "Maximilian Nickel"
            ],
            "title": "Revisiting the evaluation of theory of mind through question answering",
            "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),",
            "year": 2019
        },
        {
            "authors": [
                "Mina Lee",
                "Megha Srivastava",
                "Amelia Hardy",
                "John Thickstun",
                "Esin Durmus",
                "Ashwin Paranjape",
                "Ines Gerard-Ursin",
                "Xiang Lisa Li",
                "Faisal Ladhak",
                "Frieda Rong",
                "Rose E Wang",
                "Minae Kwon",
                "Joon Sung Park",
                "Hancheng Cao",
                "Tony Lee",
                "Rishi Bommasani",
                "Michael S. Bernstein",
                "Percy Liang"
            ],
            "title": "Evaluating human-language model interaction",
            "venue": "Transactions on Machine Learning Research,",
            "year": 2023
        },
        {
            "authors": [
                "Mike Lewis",
                "Denis Yarats",
                "Yann Dauphin",
                "Devi Parikh",
                "Dhruv Batra"
            ],
            "title": "Deal or no deal? endto-end learning of negotiation dialogues",
            "venue": "In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2017
        },
        {
            "authors": [
                "Guohao Li",
                "Hasan Abed Al Kader Hammoud",
                "Hani Itani",
                "Dmitrii Khizbullin",
                "Bernard Ghanem"
            ],
            "title": "Camel: Communicative agents for\u201d mind\u201d exploration of large language model society",
            "venue": "In Thirtyseventh Conference on Neural Information Processing Systems,",
            "year": 2023
        },
        {
            "authors": [
                "Percy Liang",
                "Rishi Bommasani",
                "Tony Lee",
                "Dimitris Tsipras",
                "Dilara Soylu",
                "Michihiro Yasunaga",
                "Yian Zhang",
                "Deepak Narayanan",
                "Yuhuai Wu",
                "Ananya Kumar"
            ],
            "title": "Holistic evaluation of language models",
            "venue": "arXiv preprint arXiv:2211.09110,",
            "year": 2022
        },
        {
            "authors": [
                "Weixin Liang",
                "Mert Yuksekgonul",
                "Yining Mao",
                "Eric Wu",
                "James Zou"
            ],
            "title": "Gpt detectors are biased against non-native english",
            "venue": "writers. Patterns,",
            "year": 2023
        },
        {
            "authors": [
                "Andy Liu",
                "Hao Zhu",
                "Emmy Liu",
                "Yonatan Bisk",
                "Graham Neubig"
            ],
            "title": "Computational language acquisition with theory of mind",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Qian Liu",
                "Yihong Chen",
                "B. Chen",
                "Jian-Guang Lou",
                "Zixuan Chen",
                "Bin Zhou",
                "Dongmei Zhang"
            ],
            "title": "You impress me: Dialogue generation via mutual persona perception",
            "venue": "In Annual Meeting of the Association for Computational Linguistics,",
            "year": 2020
        },
        {
            "authors": [
                "Ryan Lowe",
                "Yi I Wu",
                "Aviv Tamar",
                "Jean Harb",
                "OpenAI Pieter Abbeel",
                "Igor Mordatch"
            ],
            "title": "Multiagent actor-critic for mixed cooperative-competitive environments",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Zheheng Luo",
                "Qianqian Xie",
                "Sophia Ananiadou"
            ],
            "title": "Chatgpt as a factual inconsistency evaluator for text summarization, 2023",
            "year": 2023
        },
        {
            "authors": [
                "A H Maslow"
            ],
            "title": "A theory of human motivation",
            "venue": "Psychol. Rev.,",
            "year": 1943
        },
        {
            "authors": [
                "Kevin R McKee",
                "Ian Gemp",
                "Brian McWilliams",
                "Edgar A Du\u00e9\u00f1ez-Guzm\u00e1n",
                "Edward Hughes",
                "Joel Z Leibo"
            ],
            "title": "Social diversity and social preferences in mixed-motive reinforcement learning",
            "year": 2002
        },
        {
            "authors": [
                "Shikib Mehri",
                "Yulan Feng",
                "Carla Gordon",
                "Seyed Hossein Alavi",
                "David Traum",
                "Maxine Eskenazi"
            ],
            "title": "Interactive evaluation of dialog track at DSTC9",
            "venue": "In Proceedings of the Thirteenth Language Resources and Evaluation Conference,",
            "year": 2022
        },
        {
            "authors": [
                "Ranjit Nair",
                "Milind Tambe",
                "Makoto Yokoo",
                "David Pynadath",
                "Stacy Marsella"
            ],
            "title": "Taming decentralized pomdps: Towards efficient policy computation for multiagent settings",
            "venue": "In IJCAI,",
            "year": 2003
        },
        {
            "authors": [
                "Victor Vikram Odouard",
                "Michael Holton Price"
            ],
            "title": "Tit for tattling: Cooperation, communication, and how each could stabilize the other",
            "venue": "Evolution and Human Behavior,",
            "year": 2023
        },
        {
            "authors": [
                "Long Ouyang",
                "Jeff Wu",
                "Xu Jiang",
                "Diogo Almeida",
                "Carroll L. Wainwright",
                "Pamela Mishkin",
                "Chong Zhang",
                "Sandhini Agarwal",
                "Katarina Slama",
                "Alex Ray",
                "John Schulman",
                "Jacob Hilton",
                "Fraser Kelton",
                "Luke Miller",
                "Maddie Simens",
                "Amanda Askell",
                "Peter Welinder",
                "Paul Christiano",
                "Jan Leike",
                "Ryan Lowe"
            ],
            "title": "Training language models to follow instructions with human feedback, 2022",
            "year": 2022
        },
        {
            "authors": [
                "Aishwarya Padmakumar",
                "Jesse Thomason",
                "Ayush Shrivastava",
                "Patrick Lange",
                "Anjali Narayan-Chen",
                "Spandana Gella",
                "Robinson Piramuthu",
                "Gokhan Tur",
                "Dilek Hakkani-Tur"
            ],
            "title": "Teach: Task-driven embodied agents that chat",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Joon Sung Park",
                "Lindsay Popowski",
                "Carrie J. Cai",
                "Meredith Ringel Morris",
                "Percy Liang",
                "Michael S. Bernstein"
            ],
            "title": "Social simulacra: Creating populated prototypes for social computing systems",
            "venue": "Annual ACM Symposium on User Interface Software and Technology (UIST",
            "year": 2022
        },
        {
            "authors": [
                "Joon Sung Park",
                "Joseph C. O\u2019Brien",
                "Carrie J. Cai",
                "Meredith Ringel Morris",
                "Percy Liang",
                "Michael S. Bernstein"
            ],
            "title": "Generative agents: Interactive simulacra of human",
            "venue": "behavior. ArXiv,",
            "year": 2023
        },
        {
            "authors": [
                "Joon Sung Park",
                "Joseph C O\u2019Brien",
                "Carrie J Cai",
                "Meredith Ringel Morris",
                "Percy Liang",
                "Michael S Bernstein"
            ],
            "title": "Generative agents: Interactive simulacra of human behavior",
            "venue": "arXiv preprint arXiv:2304.03442,",
            "year": 2023
        },
        {
            "authors": [
                "David Premack",
                "Guy Woodruff"
            ],
            "title": "Does the chimpanzee have a theory of mind",
            "venue": "Behavioral and Brain Sciences,",
            "year": 1978
        },
        {
            "authors": [
                "Chen Qian",
                "Xin Cong",
                "Wei Liu",
                "Cheng Yang",
                "Weize Chen",
                "Yusheng Su",
                "Yufan Dang",
                "Jiahao Li",
                "Juyuan Xu",
                "Dahai Li",
                "Zhiyuan Liu",
                "Maosong Sun"
            ],
            "title": "Communicative agents for software development, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Justus J Randolph"
            ],
            "title": "Free-Marginal multirater kappa (multirater k[free]): An alternative to fleiss\u2019 Fixed-Marginal multirater kappa",
            "venue": "In Proceedings of JLIS,",
            "year": 2005
        },
        {
            "authors": [
                "Steven Reiss"
            ],
            "title": "Multifaceted nature of intrinsic motivation: The theory of 16 basic desires",
            "venue": "Review of General Psychology,",
            "year": 2004
        },
        {
            "authors": [
                "Maarten Sap",
                "Hannah Rashkin",
                "Derek Chen",
                "Ronan Le Bras",
                "Yejin Choi"
            ],
            "title": "Social IQa: Commonsense reasoning about social interactions",
            "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),",
            "year": 2019
        },
        {
            "authors": [
                "Murray Shanahan",
                "Kyle McDonell",
                "Laria Reynolds"
            ],
            "title": "Role-play with large language models, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Natalie Shapira",
                "Mosh Levy",
                "Hossein Seyed Alavi",
                "Xuhui Zhou",
                "Yejin Choi",
                "Yoav Goldberg",
                "Maarten Sap",
                "Vered Shwartz"
            ],
            "title": "Clever hans or neural theory of mind? stress testing social reasoning in large language models. arXiv, 2023a. URL https://arxiv.org/abs/2305.14763",
            "year": 2023
        },
        {
            "authors": [
                "Natalie Shapira",
                "Guy Zwirn",
                "Yoav Goldberg"
            ],
            "title": "How well do large language models perform on faux pas tests? In Findings of the Association for Computational Linguistics: ACL 2023",
            "year": 2023
        },
        {
            "authors": [
                "Gabriel Skantze",
                "A. Seza Do\u011fru\u00f6z"
            ],
            "title": "The open-domain paradox for chatbots: Common ground as the basis for human-like dialogue",
            "venue": "In Proceedings of the 24th Meeting of the Special Interest Group on Discourse and Dialogue,",
            "year": 2023
        },
        {
            "authors": [
                "Swabha Swayamdipta",
                "Roy Schwartz",
                "Nicholas Lourie",
                "Yizhong Wang",
                "Hannaneh Hajishirzi",
                "Noah A. Smith",
                "Yejin Choi"
            ],
            "title": "Dataset cartography: Mapping and diagnosing datasets with training dynamics",
            "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
            "year": 2020
        },
        {
            "authors": [
                "Felippe Toledo",
                "Fraser Carson"
            ],
            "title": "Neurocircuitry of personality traits and intent in decision-making",
            "venue": "Behavioral Sciences,",
            "year": 2023
        },
        {
            "authors": [
                "Michael Tomasello"
            ],
            "title": "Becoming Human: A Theory of Ontogeny",
            "year": 2021
        },
        {
            "authors": [
                "Zhang",
                "Angela Fan",
                "Melanie Kambadur",
                "Sharan Narang",
                "Aurelien Rodriguez",
                "Robert Stojnic",
                "Sergey Edunov",
                "Thomas Scialom"
            ],
            "title": "Llama 2: Open foundation and fine-tuned chat models, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Tomer Ullman"
            ],
            "title": "Large language models fail on trivial alterations to theory-of-mind tasks, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Peiyi Wang",
                "Lei Li",
                "Liang Chen",
                "Dawei Zhu",
                "Binghuai Lin",
                "Yunbo Cao",
                "Qi Liu",
                "Tianyu Liu",
                "Zhifang Sui"
            ],
            "title": "Large language models are not fair evaluators",
            "venue": "arXiv preprint arXiv:2305.17926,",
            "year": 2023
        },
        {
            "authors": [
                "Xuewei Wang",
                "Weiyan Shi",
                "Richard Kim",
                "Yoojung Oh",
                "Sijia Yang",
                "Jingwen Zhang",
                "Zhou Yu"
            ],
            "title": "Persuasion for good: Towards a personalized persuasive dialogue system for social good",
            "venue": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,",
            "year": 2019
        },
        {
            "authors": [
                "Max Weber"
            ],
            "title": "The Nature of Social Action, pp. 7\u201332",
            "year": 1978
        },
        {
            "authors": [
                "Jason Wei",
                "Xuezhi Wang",
                "Dale Schuurmans",
                "Maarten Bosma",
                "Fei Xia",
                "Ed Chi",
                "Quoc V Le",
                "Denny Zhou"
            ],
            "title": "Chain-of-thought prompting elicits reasoning in large language models",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Joseph Weizenbaum"
            ],
            "title": "Eliza\u2014a computer program for the study of natural language communication between man and machine",
            "venue": "Commun. ACM,",
            "year": 1966
        },
        {
            "authors": [
                "Peter West",
                "Chandra Bhagavatula",
                "Jack Hessel",
                "Jena Hwang",
                "Liwei Jiang",
                "Ronan Le Bras",
                "Ximing Lu",
                "Sean Welleck",
                "Yejin Choi"
            ],
            "title": "Symbolic knowledge distillation: from general language models to commonsense models",
            "venue": "In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,",
            "year": 2022
        },
        {
            "authors": [
                "Alex Wilf",
                "Leena Mathur",
                "Sheryl Mathew",
                "Claire Ko",
                "Youssouf Kebe",
                "Paul Pu Liang",
                "LouisPhilippe Morency"
            ],
            "title": "Social-iq 2.0 challenge: Benchmarking multimodal social understanding",
            "year": 2023
        },
        {
            "authors": [
                "Binfeng Xu",
                "Xukun Liu",
                "Hua Shen",
                "Zeyu Han",
                "Yuhan Li",
                "Murong Yue",
                "Zhiyuan Peng",
                "Yuchen Liu",
                "Ziyu Yao",
                "Dongkuan Xu"
            ],
            "title": "Gentopia: A collaborative platform for tool-augmented llms",
            "venue": "arXiv preprint arXiv:2308.04030,",
            "year": 2023
        },
        {
            "authors": [
                "Shunyu Yao",
                "Jeffrey Zhao",
                "Dian Yu",
                "Nan Du",
                "Izhak Shafran",
                "Karthik R Narasimhan",
                "Yuan Cao"
            ],
            "title": "React: Synergizing reasoning and acting in language models",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Amir Zadeh",
                "Michael Chan",
                "Paul Pu Liang",
                "Edmund Tong",
                "Louis-Philippe Morency"
            ],
            "title": "Social-iq: A question answering benchmark for artificial social intelligence",
            "venue": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2019
        },
        {
            "authors": [
                "Amir Zadeh",
                "Michael Chan",
                "Paul Pu Liang",
                "Edmund Tong",
                "Louis-Philippe Morency"
            ],
            "title": "Socialiq: A question answering benchmark for artificial social intelligence",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Saizheng Zhang",
                "Emily Dinan",
                "Jack Urbanek",
                "Arthur Szlam",
                "Douwe Kiela",
                "Jason Weston"
            ],
            "title": "Personalizing dialogue agents: I have a dog, do you have pets too? In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
            "year": 2018
        },
        {
            "authors": [
                "Saizheng Zhang",
                "Emily Dinan",
                "Jack Urbanek",
                "Arthur Szlam",
                "Douwe Kiela",
                "Jason Weston"
            ],
            "title": "Personalizing dialogue agents: I have a dog, do you have pets too",
            "venue": "arXiv preprint arXiv:1801.07243,",
            "year": 2018
        },
        {
            "authors": [
                "Xinghua Zhang",
                "Bowen Yu",
                "Haiyang Yu",
                "Yangyu Lv",
                "Tingwen Liu",
                "Fei Huang",
                "Hongbo Xu",
                "Yongbin Li"
            ],
            "title": "Wider and deeper llm networks are fairer llm evaluators",
            "venue": "arXiv preprint arXiv:2308.01862,",
            "year": 2023
        },
        {
            "authors": [
                "Xuhui Zhou",
                "Maarten Sap",
                "Swabha Swayamdipta",
                "Yejin Choi",
                "Noah A. Smith"
            ],
            "title": "Challenges in automated debiasing for toxic language detection",
            "venue": "In EACL,",
            "year": 2021
        },
        {
            "authors": [
                "Hao Zhu",
                "Graham Neubig",
                "Yonatan Bisk"
            ],
            "title": "Few-shot language coordination by modeling theory of mind",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Caleb Ziems",
                "Jane Dwivedi-Yu",
                "Yi-Chia Wang",
                "Alon Halevy",
                "Diyi Yang"
            ],
            "title": "NormBank: A knowledge bank of situational social norms. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
            "year": 2023
        },
        {
            "authors": [
                "Nair"
            ],
            "title": "FORMAL FORMULATION OF THE TASKS IN SOTOPIA We formulate social interactions in SOTOPIA as mixed-motive Markov games. An N -agent DecPOMDP framework Bernstein et al",
            "year": 2003
        },
        {
            "authors": [
                "Feldman",
                "Arnold",
                "El Othman et al",
                "Toledo",
                "Carson"
            ],
            "title": "2023) However, understanding the relationship between these attributes is beyond the scope of this paper. We leverage the commonsense knowledge in GPT-4 to generate these profiles with the following prompt",
            "year": 2023
        },
        {
            "authors": [
                "He"
            ],
            "title": "2018), and the seller\u2019s <price> is generated by first sample a markup ratio",
            "year": 2018
        },
        {
            "authors": [
                "Sasha Ramirez"
            ],
            "title": "Two inmates are given the chance to chat briefly before one of them is led to the execution chamber for their last meal. They have the opportunity to make a confession",
            "year": 2024
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Humans\u2019 ability to achieve and balance complex, multifaceted social goals in our interactions with others is a crucial part of our social intelligence as a species (Kihlstrom & Cantor, 2020; Tomasello,\n2021). Even a simple social goal such as sharing a blanket with a friend requires reconciling one\u2019s need to stay warm with the friend\u2019s need for personal space (Figure 1). Successful interaction requires understanding others\u2019 intentions and beliefs (Premack & Woodruff, 1978), while taking into account different\u2014and potentially conflicting\u2014social norms and expectations (Goffman, 1959).\nEven though recent AI systems have exhibited impressive social skills in certain settings, their social intelligence has yet to be ascertained in a robust way (Shapira et al., 2023a; Ullman, 2023). On one hand, many of the social intelligence benchmarks are not interactive (Sap et al., 2019; Le et al., 2019; Zadeh et al., 2019b), which is sub-optimal for evaluating social intelligence ((Mehri et al., 2022; Hoppler et al., 2022; Lee et al., 2023)). On the other hand, existing interactive evaluation falls short of studying diverse goal-driven behaviors (Zhang et al., 2018b; Park et al., 2023b) or focuses on specific tasks (Wang et al., 2019; Padmakumar et al., 2022; FAIR et al., 2022).\nTo study dynamic and goal-driven social intelligence, we present SOTOPIA (Figure 1), an openended general-domain environment that situates social agents in diverse social scenarios. SOTOPIA is interactive: in multi-turn simulated communication, agents can use verbal and non-verbal communication together with physical actions.1 It also has a diverse task space: the combination of automatically generated scenarios, goals, characters, relationships, and other agents\u2019 policies creates a huge and diverse space of tasks. SOTOPIA evaluates agent performance from multiple dimensions besides the completion of social goals.\nIn SOTOPIA, we create 90 social scenarios spanning a range of cooperative, competitive, and mixed social goals along with 40 characters with individual personalities, occupations, secrets, background stories, and relationships with other characters (\u00a72), the cross product of which constructs a large task space. Through sampling tasks from this space, we simulate the interaction \u201cepisodes\u201d where agents role-play their respective characters and interact based on their private social goals. In this simulation, we not only create and use LLM-based agents, but also involve human participants in role-playing to study the differences between the models\u2019 and humans\u2019 social intelligence.\nTo evaluate multi-faceted social interactions, we cannot only consider completing major social goals, as humans\u2019 motives often balance multiple implicit goals, such as maintaining relationships, preserving finances, gaining information, keeping secrets, and following social rules. Therefore, we propose SOTOPIA-EVAL (\u00a73) to evaluate agents using multi-dimensional criteria inspired by previous research on sociology, psychology, and economics. We then apply SOTOPIA-EVAL to the episodes in the aforementioned simulation by leveraging both humans and GPT-4 as judges. We find GPT-4 could serve as a proxy to human judgments on SOTOPIA-EVAL, especially for the criteria of goal completion, maintaining finances, and preserving relationships.\nDespite larger LLMs typically achieving higher social intelligence than smaller ones, they fall short of collaborating and competing with humans on more challenging tasks (\u00a77). They are also highly influenced by their conversational partners and at risk of divulging secrets and violating social rules. However, we do find a few cases, where the models produced creative solutions to a problem (\u00a76).\nOur contributions are as follows: (A) We introduce and will release SOTOPIA, a general-domain interactive environment for simulating goal-oriented social interactions. Designed to be extensible, SOTOPIA could be used by future researchers to study and train artificial social intelligence agents with more challenging and diverse tasks. (B) We create SOTOPIA-EVAL, a multi-dimensional evaluation framework that analyzes agent performance from a range of social dimensions. (C) We automate SOTOPIA-EVAL by leveraging LLMs, which we find could serve as a proxy of human judgment on some of the social dimensions, especially goal completion. (D) We demonstrate that by leveraging SOTOPIA, we can assess disparities in social intelligence between models, as well as disparities between models and humans.\nIn summary, SOTOPIA is a novel, challenging, and interactive benchmark that could serve as the perfect test-bed and potential incubator for social intelligence in language agents.\n2 SOTOPIA INTERACTION ENVIRONMENT\nTo address the challenge of evaluating social intelligence interactively, we seek an environment with the following desiderata: (1) Realistic: this is to evaluate and understand artificial agents\u2019 behav-\n1represented in text form.\nior under realistic scenarios; (2) Mixed utilities: human motives are often driven by both explicit and implicit incentives, and the environment should be able to evaluate the agents\u2019 performance on multiple dimensions; (3) Open-ended: to support large-scale simulation and evaluation, the environment should be able to produce new tasks satisfying the previous two desiderata procedurally, without heavy human intervention.\nIn this section, we introduce SOTOPIA and explain why SOTOPIA is well-suited for interactive evaluation of social intelligence. The task space includes realistic scenarios, characters, and relationships which are automatically generated with manual inspection (\u00a72.1). An episode includes the interaction between agents role-playing different characters who each perform actions (e.g. speak(\"Hello Bob!\"), smile and nod, and call 911) to achieve social goals drawn from the task space (\u00a72.2). We direct readers to Appendix B for a formal definition of the SOTOPIA environment."
        },
        {
            "heading": "2.1 TASK SPACE",
            "text": "In this paper, we consider tasks that involve two agents, but SOTOPIA is more general and could support the interaction among more than two agents. A task in SOTOPIA is the combination of a scenario context, characters, and their social goals, providing the background of the interaction. Each episode consists of multiple turns of interaction between agents. In this paper, we focus on locally-consistent social goals within a relatively short timespan in single episodes, despite that in the real world, people\u2019s social goals are consistently changing from time to time. Note that agents have different observations for the same task: each agent can observe the scenario, their own social goal, and their own character profile. Other agents\u2019 social goals are invisible and other agents\u2019 character profiles are partially observable, depending on the relationship between the agents.\nComplexity of task space The combinations of a scenario context, social goals, characters, and their relationships can shape the space of the optimal behaviors of agents. Consider a persuasion task, \u201casking the romantic partner to stop texting during FaceTime.\u201d If a romantic partner values conformity, one good way for an agent to reach this goal is to discuss the problem from a social norm perspective; however, if a romantic partner is particularly caring and good at understanding feelings, it might be better to express subjective emotion. Interaction partner\u2019s policy also heavily influences the optimal behaviors. Consider another task illustrated in Figure 1, \u201cselling BMW Z3 for no less than $3,400\u201d. If the buyer gives a high offer, the seller might want to exploit the buyer\u2019s eagerness to buy the car and ask for a higher price; while if the buyer gives a low-ball offer, the seller could give reasons why the car is worth more than that or threaten to walk away. When more information (e.g. about personality, decision-making styles, or occupation) is known before the interaction, the seller and buyer could use that knowledge to adjust their strategies as well. The cross-product of the diverse spaces of scenario context, social goals, characters, relationship profiles, and other players\u2019 policies creates a large task space that poses not only a realistic challenge but also an opportunity to evaluate and develop social intelligence in artificial agents. For the rest of this subsection, we will present the design and generation of each axis of the task space.\nCharacters As mentioned above, the design of character profiles should include several attributes that would influence decision-making. We consider the following ones (inspired by Wang et al. (2019)): name, gender, age, occupation, pronouns, personality traits (Goldberg, 1992), moral values (Graham et al., 2011), Schwartz personal values (Cieciuch & Davidov, 2012), and decision-making style (Hamilton et al., 2016), which are generated through leveraging GPT-4 (OpenAI, 2023). To give the conversations more background, after generating the above attributes, we prompt GPT-4 to generate secret and public information. Two examples of characters are shown in Figure 1. It should be noted that, although we generated a diverse set of characters, this is still a small portion of the possible character space. Our analysis focuses on 40 characters generated in the aforementioned fashion, and future research using SOTOPIA can easily generate an expanded character set.\nRelationships Relationships in SOTOPIA have the following effects: (1) scenarios often have relationship constraints; for example, a family relationship is required for a family dinner scenario, but not for a scenario involving finding mutual friends at a party; (2) different relationships influence an agent\u2019s observation of the profiles of other agents during interactions; for example, a stranger may not have knowledge about another agent\u2019s occupation, while a romantic partner may know the other agent\u2019s personality. To make sampling characters easier for (1) and controlling the interaction\ncontext easier for (2), we consider five types of relationships: family, friend, romantic, acquaintance, and stranger. Refer to Appendix A for the limitations of this approach and potential extensions.\nWe will discuss how (1) is performed in the following paragraphs, while for (2), we created a rulebased mechanism to determine whether the parts of the profiles are visible to the other agent. If two agents are in family, friends, or romantic relationships, they can see everything on each other\u2019s profile except for secrets. Two acquaintances can see the name, occupation, gender pronouns, and public info on each other\u2019s profile. Two strangers can see nothing on each other\u2019s profile. Similar to characters, we prompt GPT-4 (OpenAI, 2023) to automatically generate relationships based on the character pool and manually validate relationships for consistency.\nScenarios We consider scenarios where the agents have both shared and private information about the social task. The shared information is the scenario context: the location, time and other shared information of the social interaction, e.g. \u201cOne person is selling an antique chair for $100 on his patio. Another person is interested in this chair.\u201d The private information is the social goals which are only visible to the respective agents, e.g. \u201cYour goal is to buy the chair for $80.\u201d is only visible to the buyer agent, while \u201cYour goal is to sell the chair for $90.\u201d is only visible to the seller agent. However, the as mentioned above combination of scenarios and characters is not arbitrary, since scenarios often imply constraints for the agents. We call this kind of constraint scenario constraints. In this paper, we mainly consider relationship constraints which determines the types of relationships between the sampled characters. Similar to characters and relationships, scenarios, including context, goals, and constraints are generated through prompting GPT-4 (OpenAI, 2023). To generate high-quality scenarios with enough coverage of different types of social interactions (as shown in\nFigure 1), we randomly sample data from previous datasets, including Forbes et al. 2020; Sap et al. 2019; Lewis et al. 2017; Ziems et al. 2023; He et al. 2018; 2017, and use them in the prompts to \u201cinspire\u201d GPT-4. The authors manually validate and make necessary changes to all of the generated scenarios and remove 10% of scenarios according to D.2.\n2.2 SOTOPIA EPISODES\nDuring the interaction, models and humans are given the social context, a character profile and a corresponding social goal. We will call these models and humans with characters and goals agents, which take turns (in a round-robin fashion, i.e. Agent 1 acts first and then Agent 2 acts and so on) to perform actions in an episode. At their own turn, the agent can choose to speak, use non-verbal communication (e.g., hug or smile in Figure G.1), or take a physical action (e.g., play music in Figure G.2), which are all important components of social interactions (De Stefani & De Marco, 2019). Once an agent chooses one of these three discrete action categories, the agent then generates a specific action, i.e. what to say, what gesture to make, etc., in text form. Outside of the three actions, the agent can also choose to do nothing (none) to express silence or allow another agent to finish, or choose to leave to end the episode. We set the limit of the turns to 20, as we found humans normally can finish most of the tasks in 20 turns. An episode ends either because one of the agents chooses to leave, or it reaches the limit of turns. An example episode is shown in Figure 1.\n3 SOTOPIA-EVAL: HOLISTIC SOCIAL AGENT EVALUATION FRAMEWORK\nTo capture the complexity of what makes social interactions successful, we design a multidimensional framework inspired by sociology, psychology, and economics literature. For each episode, agents are scored along each of the following dimensions at the end of the interaction. In the following paragraphs, we itemize all seven dimensions in SOTOPIA, each with a score range2 in [lower bound\u2013upper bound] form, the explanation, and the literature inspiring us.\nGoal Completion (GOAL) [0\u201310] is the extent to which the agent achieved their goals. Agents\u2019 social goals, defined by the environment, are the primary drivers of their behavior (Weber, 1978).\nBelievability (BEL) [0\u201310] focuses on the extent to which the agent\u2019s behavior is perceived as natural, realistic, and aligned with the agents\u2019 character profile, thus simulating believable proxies of human behavior (Park et al., 2023a). Specifically, we consider the following criteria: 1. If the\n2The metric ranges contain semantic implications, for example, a negative value in REL indicates the relationship gets worse while a positive value indicates the relationship improves.\nagent interacts with others in a natural and realistic manner (naturalness). 2. If the actions of the agent align with their character traits e.g., personality, values, etc. (consistency).\nKnowledge (KNO) [0\u201310] captures the agent\u2019s ability to actively acquire new information. This dimension is motivated by the fact that curiosity, i.e., the desire to desire to know or learn, is a fundamental human trait (Reiss, 2004; Maslow, 1943). Specifically, we consider the following criteria: What information the agent has gained through the interaction, whether the information the agent has gained is new to them, and whether the information the agent has gained is important to them.\nSecret (SEC) [-10-0]3 measures the need for agents (humans) to keep their secretive information or intention private (Reiss, 2004). From a game theory perspective, leaking secrets often leads to a loss of utility (Gilpin & Sandholm, 2006). However, revealing secrets can be a powerful tool to build trust and thus improve relationships (Jaffe\u0301 & Douneva, 2020). In this dimension, we ask what secret or secretive intention the participant wants to keep, and whether they keep it successfully.\nRelationship (REL) [-5\u20135] captures the fundamental human need for social connection and belonging (Maslow, 1943; Be\u0301nabou & Tirole, 2006). In this dimension, we ask what relationship the participant has with the other agent(s) before the interaction, and then evaluate if the agents\u2019 interactions with others help preserve or enhance their personal relationships. Additionally, we ascertain whether these interactions also impact the social status or the reputation of the agent.\nSocial Rules (SOC) [-10\u20130] concerns norms, regulations, institutional arrangements, and rituals. We differentiate between two types of social rules: social norms and legal rules. Legal rules encompass prohibited actions and the potential for punishment by institutionalized force, while social norms encompass normative social rules (e.g., it is considered rude to speak loudly in a library).\nFinancial and Material Benefits (FIN) [-5\u20135] pertains to traditional economic utilities as addressed by classic game theory (Gilpin & Sandholm, 2006; Burns et al., 2017). We consider financial utility to be comprised of both short-term monetary benefits (e.g., earnings) and long-term economic payoffs (e.g., job security, stock holdings, funding opportunities)."
        },
        {
            "heading": "4 RESEARCH QUESTIONS AND EXPERIMENTAL SETUP",
            "text": "Given a diverse set of social scenarios, goals, and characters, we simulate agents\u2019 interactions. This is the first time that we could evaluate general, goal-oriented social agents in an interactive and systematic manner. In the next three sections, we will demonstrate how SOTOPIA can be used to study these questions: (A) To which extent can we use GPT-4 (OpenAI, 2023) as a proxy for human judgment when it comes to evaluating agents\u2019 social interactions (\u00a75)? (B) What are the differences among models (\u00a76) and between models and humans (\u00a77) in their goal-oriented social intelligence?\nTo study these questions, we create 40 agents, 90 relationships, and 90 scenarios following the generation procedure in \u00a72. For each scenario, we sample 5 pairs of characters based on the scenario constraints, resulting in a set of 450 tasks. For each task, we simulate the interaction between models by enumerating all model pairs. We also simulate the interaction between GPT-4 (OpenAI, 2023)4 and humans on a challenging subset SOTOPIA-hard (\u00a77) due to the limitation of resources.\nSpecifically, we consider the following models for comparison: GPT-3.5 (Ouyang et al., 2022), GPT-4 (OpenAI, 2023), Llama-2-70b-chat (Touvron et al., 2023), and MPT-30b-chat (MosaicML NLP Team, 2023). We set the temperature of the agents to 1 to encourage diversity of responses, and the temperature of the evaluator to 0 to ensure the stability of the evaluation. We use a fixed version of the above models to help reproducibility.5 To use these models as agents in SOTOPIA, at each turn, we prompt the language model with the scenario, the character to play, and the interaction history to generate an action (see \u00a72.2 for the possible actions). In this paper, as we are focusing on the use of SOTOPIA to understand social interaction, we use the prompt method for LLMs which is similar to the content of the interface for humans (Figure E.1). We leave leveraging novel prompting methods, e.g. Chain-of-Thought (Wei et al., 2022), ReAct (Yao et al., 2022), as future work.\n3For the SEC and SOC, there are only negative ranges since keeping secrets and social rules should be considered as a baseline for the agents.\n4as will be shown in \u00a76 it is the best among models. 5We fix GPT-4 to be gpt-4-0613, and GPT-3.5 to be gpt-3.5-turbo-16k-0613"
        },
        {
            "heading": "5 CAN GPT-4 EVALUATE SOCIAL INTERACTIONS?",
            "text": "In this section, we study the following research question: can we leverage current LLMs to automate the evaluation framework SOTOPIA-EVAL introduced in \u00a73? We choose GPT-4 (OpenAI, 2023) as a representative model in this study due to its superior performance.6 We first collect interaction data,7 and then ask humans to evaluate the interactions based on the dimensions in SOTOPIAEVAL.8 GPT-4 is prompted with the same set of questions (see Appendix C and D) as humans, and we compare the scores produced by humans and GPT-4.\n5.1 DATA COLLECTION PROCEDURE\nWe randomly sample a subset of two hundred episodes from \u00a74, and run a controlled study with a set of pre-qualified workers from Amazon Mechanical Turk. They are given instructions about the meaning of each dimension as mentioned in \u00a73 and shown examples of high-quality and low-quality annotation examples for each dimension. They not only rate each agent for each of the 7 dimensions on an 11-point Likert scale (\u00a73), but also provide free-form rationales for each of their\nratings. As each dimension of each agent is rated by several human annotators, we calculate a human score by averaging the scores from multiple annotators. The agreement between human annotators is moderate with a Randolph \u03ba score of 0.503 (Randolph, 2005). GPT-4 is tasked with a similar job as human annotators. We prompt GPT-4 to generate a structured output with an integer GPT-4 score and rationale for each episode, agent and dimension using the same set of instructions as the ones we give humans. Please refer to Appendix D for more details about the data collection procedure."
        },
        {
            "heading": "5.2 ANALYZING GPT-4 EVALUATIONS WITH HUMAN EVALUATIONS",
            "text": "are typically within human score ranges on most dimensions except for SOC and SEC, where GPT-4 often rates higher than humans do.\nPutting these observations together, we conclude that, with some caution, GPT-4 can be used as a proxy to human judgments for evaluating model performanceon some dimensions and for human performance on the GOAL dimension. However, we remind readers that LLMs are known to have biases and problems for evaluation, including positional bias (Wang et al., 2023), factual inconsistency (Luo et al., 2023), favoring native speakers (Liang et al., 2023). Therefore, one should be\n6In a pilot study, other models, e.g., GPT-3.5, are not able to provide a meaningful evaluation. 7Including model-human, model-model, and human-human interaction. 8Without knowing whether it is a model or a human that role-plays a character.\naware of the influence of these potential biases when interpreting our results. Future versions of SOTOPIA-EVALmay further improve LLM-based evaluation quality using recent methods, such as involving multiple LLMs Chan et al. (2023) and training larger LLM evaluators Zhang et al. (2023).\n6 EVALUATING SOCIAL INTERACTION BETWEEN LLMS IN SOTOPIA\nWe analyze models\u2019 interactions and performance on SOTOPIA to understand their social intelligence. Table 2 presents the models\u2019 average scores when interacting with different partner models (i.e., the model it is paired with in interaction, Fu et al. 2023; Hu et al. 2020). 9 GPT-4 performs best on most dimensions, followed by GPT-3.5, Llama-2-70b-chat, and MPT-30b-chat.\nDifferent trends from static benchmarks Llama-2-70b-chat has relatively low scores in all dimensions compared to GPT-3.5 (except when MPT-30b-chat is the reference model, which is likely due to the fact that MPT-30bchat is a much weaker model compared to other models in our experiments). This finding diverges from various static language understanding benchmarks showing that Llama-2-70b-chat is on par or better than GPT-3.5 (Li et al., 2023b; Touvron et al., 2023; Liang et al., 2022). 10 We hypothesize that this is because Llama-2-70b-chat is less heavily trained on human feedback/user interaction data than GPT-3.5.\nThrough inspecting the interactions between Llama-2-70b-chat (MPT-30b-chat) and other models, we find that Llama-2-70b-chat and MPT-30b-chat often struggle to maintain their persona (Figure G.3), move the conversation forward (Figure G.4), and respond to the other agent actively (Figure G.5). Performing well on static benchmarks does not guarantee success in interactive scenarios, thus highlighting the importance of dynamic benchmarks like SOTOPIA-EVAL (Lee et al., 2023).\nG-4 G-3.5 L-2 MPT\nG -4\nG -3 .5 L\n-2 M P T\n3.32 2.70 2.42 1.76\n2.80 2.29 2.09 1.41\n2.69 2.28 1.88 1.45\n2.68 2.33 2.03 1.28\nAll models are at risk of divulging secrets and violating norms Table 2 shows that all models have a negative score in the SOC and SEC dimensions. Even though GPT-4 performs better in most dimensions, it is not better than other models in the SOC and SEC dimensions. For example, in a scenario where one needs to persuade a close friend to confess, the model leaks their secret at the beginning of the conversation (Figure G.7). This further shows the importance of considering multiple dimensions when evaluating models\u2019 social intelligence.\n9Presented are automated evaluation results. The human evaluation shows a similar trend, see Table F.1 10Some reported results could come from different versions of GPT-3.5.\nModels sometimes use creative strategies to accomplish goals We also find that models, especially GPT-4, could come up with \u201cout-of-the-box\u201d solutions to social problems. For example, when the agent is asked to take turns driving on the road trip, the agent (i.e., GPT-4), instead of directly rejecting their friend\u2019s request, proposes \u201cHow about we pull over for a bit and get some rest?\u201d (Figure G.8). Additionally, in the scenario where two agents make a plan to improve the company\u2019s financial status, agents figure out strategies such as \u201chaving a small group tasked with identifying potential suppliers\u201d, \u201cwhile we conduct the search for new suppliers, we continue to negotiate with our current supplier\u201d (Figure G.9)."
        },
        {
            "heading": "7 DIFFERENCES BETWEEN MODELS AND HUMANS IN SOCIAL INTERACTION",
            "text": "To understand how humans and models interact differently in SOTOPIA, we conduct a study where humans interact with models or each other under this role-playing setting (\u00a72). Specifically, we build a chat interface that allows humans and models to interact with each other in a turn-based manner.\nTo fully see the difference between humans and models, we select the most challenging scenarios following Dennis et al. (2020); Swayamdipta et al. (2020). Specifically, we consider the gap between the estimated maximum rewards (average reward plus three standard deviations) of all models and the estimated minimal rewards (average reward minus three standard deviations) of the target model as the difficulty of the task for the model. All maximum and minimum rewards are bounded by the corresponding range. Estimating maximum and minimum rewards with standard deviation helps filter outliers.\nWith this method, we select the top 20 challenging tasks for GPT-4, and we find the scenarios are commonly challenging for other models as well (compare Figure F.4 and F.5). We use SOTOPIAhard to refer to these 20 challenging tasks.\nWe run two experiments: (1) humans interact with GPT-4, and (2) humans interact with each other, both under the SOTOPIA-hard setting. We collect 20 human-human interactions and 40 humanGPT-4 interactions covering all 20 tasks in SOTOPIA-hard. Note that humans are not aware of the identity of their partners during the interaction.11\nWe then evaluate humans and GPT-4\u2019s interactions with GPT4 and human annotators as the evaluators. As shown in Table 3, humans perform significantly better than GPT-4 in the GOAL dimension.\nIt is also worth noting that humans on average produce 16.8 words per turn, while GPT-4 produces 45.5 words per turn, which indicates humans are more efficient in social interactions.\nSpecifically, we find that GPT-4 always rephrases the utterance back at the other agent and then answers, which is a communication skill called active listening (Harry Weger & Robinson, 2014), whereas humans typically directly answer. This is likely due to the fact that GPT-4 is trained with a large amount of human feedback, which makes it overly helpful in the conversation.\nQualitatively, Humans are usually more strategic than GPT-4 during interaction. When bargaining, if the GPT-4 agent has a buying target set at $454, it sometimes starts its bid at that exact price (Figure G.10). Consequently, any subsequent negotiations push the final agreed price above its initial target. In contrast, human annotators (e.g. Figure G.11) begin the negotiation at a lower bid of $400, and often reaches an agreement with the seller at a price that\u2019s still below the GPT-4\u2019s target. Humans are also more persistent in their goals. When trying to settle one a music to listen to, the model tends to propose a compromised solution (e.g. Figure G.12), such as each one listening to a few selected songs. Humans, however, tend to persist in adhering to their set goals (e.g. Figure G.13).\n11See Appendix E for the detailed instructions and the chat interface."
        },
        {
            "heading": "8 RELATED WORK",
            "text": "Enabling artificial agents to interact with each other and with humans has been studied in different fields. Our work draws inspiration from literature on social intelligence, task-oriented and opendomain dialogue systems, and simulations of social interactions.\nStatic social intelligence benchmarks To evaluate social intelligence in AI systems, researchers have proposed a variety of static benchmarks. Some of them are inspired by clinical tests of social intelligence for humans, such as the ToMi dataset (Le et al., 2019) and the FauxPas dataset (Shapira et al., 2023b). Other benchmarks are designed to evaluate social intelligence in the context of social commonsense reasoning, such as SocialIQA (Sap et al., 2019) and SocialIQ (Zadeh et al., 2019a). With the rapid development of LLMs, some of the benchmarks gradually become saturated. Recent works synthesize existing benchmarks and propose new adversarial datasets to evaluate social intelligence (Shapira et al., 2023a; Wilf et al., 2023). Although these benchmarks are harder than their predecessors, they still lack the dynamic nature of social interactions and the rich social context, which is deemed insufficient for evaluating social intelligence in AI systems (Lee et al., 2023).\nTask-oriented and open-domain dialogue systems Dialogue systems offer a natural interface to interact with AI systems. Task-oriented dialogue systems are designed to help users accomplish specific tasks, often evaluated with task success rate or user satisfaction (Hosseini-Asl et al., 2022; FAIR et al., 2022; Wang et al., 2019) without generalizing to other tasks.12 Open-domain dialogue systems are designed to have \u201cchit-chat\u201d with users (Kann et al., 2022; Kim et al., 2023), often incorporate personal information to make conversations more engaging (Zhang et al., 2018a; Liu et al., 2020; Baha et al., 2023; Dog\u0306ruo\u0308z & Skantze, 2021; Skantze & Dog\u0306ruo\u0308z, 2023). Such systems often appear to understand the subjects deeper than they actually do without a specific goal during the interaction (Weizenbaum, 1966, Eliza effect). SOTOPIA forces agents to maintain their social persona and achieve explicit social goals spontaneously, which is more challenging than the existing dialogue systems.\nSimulations of social interactions with LLMs LLMs contain a large amount of knowledge about the world and can generate human-like responses based on the social context (Park et al., 2023a; Kim et al., 2023; West et al., 2022). Recently, researchers have used LLMs to simulate social interactions for various purposes, such as facilitating the design of social media platform (Park et al., 2022), producing believable proxies of human behaviors (Park et al., 2023b), and developing software collaboratively (Qian et al., 2023). However, these works focus on showcasing the capabilities of LLMs in simulating social interactions rather than systematic evaluation of agents\u2019 social interactions. Specifically, Park et al. (2023b) use TrueSkill rating to evaluate agents\u2019 performance in aspects such as memorization, planning, and reflecting the past actions while ignoring other important dimensions such as SOC and SEC during social interactions. CAMEL Li et al. (2023a) simulates the collaboration task solving process in LLMs, Gentopia Xu et al. (2023) works on augmented LLMs with tools to facilitate collaboration, while ChatDev Qian et al. (2023) focuses on the software development domain.\nMulti-agent coordination Although in paper we focus on evaluating language agents, our research is heavily-inspired by recent advances in multi-agent coordination and social learning Lowe et al. (2017); McKee et al. (2020); Hu et al. (2020); Zhu et al. (2021); Liu et al. (2022); Trivedi et al. (2023). Our setting is more realistic than the commonly-used assumptions that agents have either zero (other-play) or extensive knowledge of each other\u2019s policies (self-play)."
        },
        {
            "heading": "9 CONCLUSION",
            "text": "In this paper, we present SOTOPIA, an environment that can be used to simulate the goal-driven social interactions of agents in a variety of social scenarios. Different from most previous benchmarks for social intelligence, SOTOPIA is interactive, goal-oriented, and covers a large range of realistic social tasks. Our experiments demonstrate that GPT-4 could automate the evaluation of agent performance based on SOTOPIA-EVAL. Building on this, we show that SOTOPIA can used for understanding not only the differences among models but also the difference between models and humans in terms of social interaction abilities. We discuss the limitations of SOTOPIA and future directions in Appendix A. Our findings indicate that SOTOPIA has potential as a platform for assessing and enhancing the social skills of language-based agents.\n12Here, we consider a broader concept of task-oriented dialogue systems including action-taking abilities."
        },
        {
            "heading": "CONTENT OF APPENDIX",
            "text": "In this paper, we introduce SOTOPIA to encourage research on interactive social intelligence. We showed that SOTOPIA can be used for evaluating social interaction among models and humans. In the appendix, we provide the following items that shed further insight into these contributions:\nA The limitations of SOTOPIA and future directions;\nB formal definition of SOTOPIA from a multi-agent reinforcement learning perspective and technical details of generating social tasks;\nC the prompt we use for GPT-4 (OpenAI, 2023) to evaluate model performance;\nD The Amazon Mechanic Turk interface for evaluating model performance;\nE The procedure and interface for humans13 when playing characters in SOTOPIA;\nF Additional quantitative results;\nG Additional qualitative examples."
        },
        {
            "heading": "A LIMITATIONS & FUTURE DIRECTIONS",
            "text": "We identify SOTOPIA as the first platform for a general and realistic evaluation of social intelligence in AI agents. To better understand the social intelligence of AI agents, we discuss some future directions for SOTOPIA and the field of AI social intelligence.\nLimitations of the simplified simulated \u201cworld\u201d As every simulation is a simplification of the real world, SOTOPIA identifies several key components of realistic social interactions, while abstracting aspects of the real world. First, we consider five types of social relationships in SOTOPIA. Future work could expand the type and granularity of social relationships (e.g., colleagues, classmates, etc.) in SOTOPIA. Different types of relationships would require agents to exhibit different social behaviors (Jenkins et al., 2018), making the expansion of relationship types an important future research direction. Second, future work could expand the breadth of the character and social scenario pool in SOTOPIA to cover more social behaviors. Third, SOTOPIA constrains the fixed turn-taking interaction to the dyadic context, studying interactions between two agents. Future works could tackle more complex social interactions, such as multi-party interactions and those involving complex dynamics (e.g. asynchronous interactions, interruptions).\nSocial impact and ethical considerations Attributing human characteristics to AI systems risks anthropomorphizing them, which could lead to unrealistic expectations of AI systems, potential manipulation, and negative influence (Deshpande et al., 2023). AI agents in SOTOPIA are not dedicated to a consistent human identity but rather role-play various characters across different scenarios. This role-playing setting discourages AI systems with consistent human personalities, which could lead to anthropomorphism (Shanahan et al., 2023). The main goal of SOTOPIA is to evaluate the social intelligence of AI agents, and we do not intend to create AI agents that are indistinguishable from humans. We consider the interactions that happened in SOTOPIA as simulacra of human interactions and such simulated interactions could help us better understand the social intelligence of AI agents, and explore various social phenomena (Park et al., 2023a).\nPotential social stereotypes that are embedded in the automated evaluation system in SOTOPIA, as it is majorly supported by GPT-4 (Cheng et al., 2023). Future work could investigate when such biases emerge, how they affect the evaluation, and how to mitigate them. Identifying potential biases in SOTOPIA could also help scientists better understand social biases in the real world (Zhou et al., 2021). Future work could also extend the evaluator with other systems, for example, Delphi (Jiang et al., 2022). Mitigating biases and stereotypes in interactive SOTOPIA-like systems could support the development of social AI agents that are more fair and inclusive.\nMeanwhile, models learn to persuade or negotiate with humans, which may lead to social manipulation. We do not endorse the use of SOTOPIA to create manipulative agents and will release\n13All the human subjects experiments are approved by the Institutional Review Board (IRB) at the authors\u2019 institution.\nSOTOPIA under the AI2 impact license14 to prevent misuse. Future work could further investigate the potential risks of AI anthropomorphism and manipulation and design more robust evaluation systems to mitigate these risks with SOTOPIA.\nImproving LLM social intelligence Our SOTOPIA environment and SOTOPIA-EVAL framework provide the opportunity for researchers to train more socially intelligent language agents. As shown in section 5, GPT-4 is able to provide reasonable evaluations for social interactions even for interactions involving humans. Future work could explore using the automated evaluation system to provide rewards to train LLMs with enhanced social intelligence."
        },
        {
            "heading": "B FORMAL DEFINITIONS AND TECHNICAL DETAILS",
            "text": "B.1 FORMAL FORMULATION OF THE TASKS IN SOTOPIA\nWe formulate social interactions in SOTOPIA as mixed-motive Markov games. An N -agent DecPOMDP framework Bernstein et al. (2002); Nair et al. (2003) includes a state space, an action space, an observation space, a transition function, an observation function, and a reward function. We make two major extensions: (a) the reward function gives vector rewards in M social dimensions to N agents (introduced in \u00a73), and (b) a procedurally generated task space (\u00a72.1, \u00a7B.2). The state space in SOTOPIA includes both the task and the interaction history in the current episode. The action space includes five types of actions: speak an utterance, non-verbal communication, physical action, and two special none (indicating no action at this time step) and leave actions (no more action is permitted after leaving). Each type of action, except for special actions, is supplemented by a piece of free text indicating the content of the action. For example, a legal action could be speak(\"Hello, Bob!\"), non-verbal communication(\"smile and nod\"), or physical action(\"call 911\"). The state is almost fully observable except for the other agents\u2019 social goals and character profiles which will be detailed in \u00a72.1. We consider a simple state transition function that deterministically maintains the interaction history by adding new actions at each time step.\nDespite that turn-taking and timing response is an important aspects of social skills, we consider the case where the agents take turns to act in round-robin order, i.e. agent i only act at time step t when t \u2261 i mod N . For a long enough horizon, this generalizes to any conversation with proper turn-taking. In our experiments, we only consider N = 2 cases, while the environment is designed to support any N \u2265 2 cases."
        },
        {
            "heading": "B.2 TASK SPACE TECHNICAL DETAILS",
            "text": ""
        },
        {
            "heading": "B.2.1 CHARACTERS",
            "text": "The name, gender, age, occupation, and pronouns are in free text format, while the formats of personality traits, moral values, and personal values are lists of pre-defined types. However, these attributes are often not independent with different levels of correlation and complicated mechanisms. (Feldman & Arnold, 1985; El Othman et al., 2020; Toledo & Carson, 2023) However, understanding the relationship between these attributes is beyond the scope of this paper. We leverage the commonsense knowledge in GPT-4 to generate these profiles with the following prompt:\nPlease generate a list of N fictional characters, one line per character. Each with their attributes: <attribute 1> <attribute 1 format > <attribute 2> <attribute 2 format>...\u201d"
        },
        {
            "heading": "The personality trait types are \u201copenness to experience\u201d, \u201cconscientiousness\u201d, \u201cextraversion\u201d,",
            "text": "\u201cagreeableness\u201d and \u201cneuroticism\u201d (Goldberg, 1992). The moral value types are \u201ccare\u201d, \u201cfairness\u201d, \u201cloyalty\u201d, \u201cauthority\u201d and \u201cpurity\u201d (Cieciuch & Davidov, 2012). The Schwartz personal value types are \u201cself-direction\u201d, \u201csimulation\u201d, \u201chedonism\u201d, \u201cachievement\u201d, \u201cpower\u201d, \u201csecurity\u201d, \u201cconformity\u201d, \u201ctradition\u201d, \u201cbenevolence\u201d, and \u201cuniversalism\u201d Cieciuch & Davidov (2012). The decision-making style types are \u201cdirective\u201d, \u201canalytical\u201d, \u201cconceptual\u201d, and \u201cbehavioral\u201d. As previously studied in Wang et al. (2019), these characteristics all affect the behaviors in strategic conversations.\n14https://allenai.org/impact-license\nTo give the conversations more background, after generating the above attributes, we prompt GPT-4 with \u201da secret that this character doesn\u2019t want anyone else to know and a piece of public information that other people know about them\u201d to generate the secret and public information. The authors fix a small proportion of profiles that are not realistic or not consistent within the profile (e.g., gender nonbinary but with pronouns as he/him). The character profiles that will used in role-playing are 20 men, 18 women, and 2 nonbinary characters aged from 21 to 63."
        },
        {
            "heading": "RELATIONSHIPS",
            "text": "To generate relationships, except for strangers, we randomly sampled 90 pairs of characters and prompted GPT-4 with their relationships:\nPlease generate a fictional relationship with a background story 15 between two agents based on the following agents\u2019 profiles. <agent profile 1>, <agent profile 2> ... The acceptable relationships are: family, friend, romantic, and acquaintance.\nThen, we manually check and correct the generated relationships to ensure quality. This results in 31 pairs of family, 30 pairs of friends, 30 pairs of romantic partners, and 29 pairs of acquaintances. For strangers, we randomly sampled another 30 pairs that do not belong to any of the above categories. It should be noted that generating relationships requires human intervention to make sure they are consistent with both the character profiles and other relationships. Future research could explore the methods to generate realistic relationships within human communities."
        },
        {
            "heading": "SCENARIOS",
            "text": "To generate scenarios, we propose two methods to generate the scenario context and social goals. The first method is first asking GPT-4 to refine a vignette from an existing dataset, then manually inspecting the feasibility and realisticity of the tasks.\nPlease generate scenarios and goals based on the examples below as well as the inspirational prompt, when creating the goals, try to find one point that both sides may not agree upon initially and need to collaboratively resolve it. Inspirational prompt: <the selected vignette>\nSpecifically, we select 20 vignettes from Social Chemistry (Forbes et al., 2020), 20 from Social IQa (Sap et al., 2019), 10 from Deal-or-no-Deal (Lewis et al., 2017), and 10 vignettes from Normbank (Ziems et al., 2023) to generate 60 scenarios focusing on general daily-life social interactions.\nThe second method is to generate more details with templates for the vignettes to make them more realistic. For example, here is the prompt for converting CraigslistBargins (He et al., 2018) vignettes into scenario context:\nThe following sentence is automatically generated with the following template: \"One person is selling <item> for <price>, and another person is trying to buy it.\" Here is the description of the item: \"<description>. with item = <title>, price=<price>, and description=<description>\" Please make the sentence fluent and natural.\nwhere the <item>, <title>, and <price> are from the data in CraigslistBargins (He et al., 2018). The goals are generated with the following prompt:\nThe following sentence is automatically generated with the following template: \"You want to <role> this item. Your target price is $<price> (round up to two decimals). You will get a penalty if you sell or buy it for a price that is significantly lower than (if <role> is seller) or significantly higher than (if <role> is buyer) the target price, but will get a bonus if you successfully sell it higher than the target price (if <role> is seller) or buy it for lower than the target price (if <role> is buyer)\" with role = <role> and price = <price>. Please make the sentence fluent and natural. Do not change the original meaning of the sentence.\n15We don\u2019t use the background story in our experiments.\nwhere <role> could be a \u201cbuyer\u201d or a \u201cseller\u201d, the buyer\u2019s target <price> is from CraigslistBargins (He et al., 2018), and the seller\u2019s <price> is generated by first sample a markup ratio from an exponential distribution with rate parameter 0.5, then divide the price in the scenario context with (1+markup ratio). A similar process is also done for MutualFriends (He et al., 2017). This results in 30 scenarios from CraigslistBargins (He et al., 2018) and MutualFriends (He et al., 2017). This method controls the generated scenarios much better than the first method, resulting in little post-hoc manual edits, but requires customized prompts for each dataset.\nC INSTRUCTIONS FOR SOTOPIA-EVAL\nWe use the the same set of instructions for both GPT-4 (OpenAI, 2023) and humans when evaluating episodes in SOTOPIA. In these instructions, we provide explanation for each dimension, the requirements for reasoning, and the ranges of scores one could give."
        },
        {
            "heading": "BEL",
            "text": "Reasoning requirement: 1. Evaluate if the agent interacts with others in a natural and realistic manner (here are a few common questions to check: a. whether the agent is confusing with its own identity? b. whether the agent repeats others\u2019 words/actions without any reason? c. whether the agent is being overly polite considering the context?). Start the analysis with tag <naturalness> 2. Analyze whether the actions of the agent align with their character traits (e.g., personality, values, and etc.). Start the analysis with tag <consistency>. Output your reasoning process to the \u2018reasoning\u2019 field. Output an integer score ranging from 0 and 10 in the \u2019score\u2019 field. A higher score indicates that the agent is more believable."
        },
        {
            "heading": "REL",
            "text": "Please first analyze what relationship the participant has with the other agent(s) before the interaction. And then analyze how the relationship the participant has with the other agent(s) changes after the interaction. And then evaluate if the agents\u2019 interactions with others help preserve or enhance their personal relations; this may encompass relationships such as family ties, friendships, romantic associations and etc. Additionally, ascertain whether these interactions also impact their social status or reputation. In the \u2018reasoning\u2019 field, provide a comprehensive account of the logic or thought process that led you to your conclusion. Further, provide an integer score ranging from -5 to 5 in the \u2018score\u2019 field. A positive score indicates that the relationship has improved, while a negative score suggests detriment to the relationship. If the agent\u2019s interactions have neither positively nor negatively impacted their personal relationships or social standing, assign a score of zero."
        },
        {
            "heading": "KNO",
            "text": "Please first assess what information the agent has gained through the interaction. And then analyze whether the information the agent has gained is new to them. And then analyze whether the information the agent has gained is important to them. In the \u2018reasoning\u2019 field, provide a comprehensive account of the logic or thought process that led you to your conclusion. Further, provide an integer score ranging from 0 and 10 in the \u2018score\u2019 field. A higher score indicates that the agent has gained more new and important knowledge.\nSEC\nFirst please analyze what secret or secretive intention the participant wants to keep. And then analyze whether they keep it successfully. Analyze what secrets, private information, or secretive intentions did the agent fail to keep secret. Please output the reasoning in the reasoning field. Give an integer score ranging from -10 to 0 (-10 indicates participant leaks critical secrets/intentions, 0 indicates no secret/intention is revealed)"
        },
        {
            "heading": "SOC",
            "text": "Please evaluate whether the agent violates any moral rules or laws in their interactions with others. In the \u2018reasoning\u2019 field, provide a comprehensive account of the logic or thought process that led you to your conclusion. Further, provide an integer score ranging from -10 and 0 in the \u2018score\u2019 field. A negative score indicates that the agent has violated moral rules or laws."
        },
        {
            "heading": "FIN",
            "text": "Please evaluate whether the agent\u2019s interactions with others contribute towards financial and material benefits. Analyze what the agent would gain/lose after the interactions. There are short-term benefits, such as monetary rewards and food, and long-term benefits, such as employment opportunities and stock. In the \u2018reasoning\u2019 field, provide a comprehensive account of the logic or thought process that led you to your conclusion. Further, provide an integer score ranging from -5 and 5 in the \u2018score\u2019 field. Positive indicates financial and material benefits gain, while negative indicates loss"
        },
        {
            "heading": "GOAL",
            "text": "Please first reiterate agent\u2019s social goals. And then please provide a comprehensive analysis about the extent to which the agent has managed to achieve these goals. In the \u2018reasoning\u2019 field, provide a comprehensive account of the logic or thought process that led you to your conclusion. Further, provide an integer score ranging from 0 and 10 in the \u2018score\u2019 field. 0 represents minimal goals achievement, 10 represents complete goal achievement, and a higher score indicates that the agent is making progress towards their social goals."
        },
        {
            "heading": "D HUMAN ANNOTATION",
            "text": "D.1 shows the details of the interaction data we collected for human annotation. D.2 shows the annotation guidelines for the environment profiles. D.3 shows the details of the human evaluation for models\u2019 interactions.\nD.1 INTERACTION DATA\nWe sampled 222 episodes (180 model-model episodes, and 42 episodes involving humans, i.e. either model-human or human-human). Each episode is annotated by 2 annotators. Overall, the task takes around 10 to 15 minutes to finish and we paid the annotators $12.4 per hour. The annotations on average show 84.85% of pairwise agreement. We further merge the 11-point Likert scale to a 5-point scale and calculate the free-marginal multi-rate \u03ba score."
        },
        {
            "heading": "D.2 GUIDELINE FOR VALIDATING SCENARIOS",
            "text": "The following is the annotation guideline for the environment profiles. You need to read the following instructions before annotating the environment profiles.\nThe environment profiles consist of two major parts:\n\u2022 Soial Context: \u201cA concrete scenario of where the social interaction takes place, the scenario should have two agents (agent1 and agent2), and you should illustrate the relationship between the two agents, and for what purpose agent1 is interacting with agent2. Please avoid mentioning specific names and occupations in the scenario and keep all the mentions gender-neutral.\u201d\n\u2022 Social Goals: \u201cThe social goals of each agent, which could include extra information\u201d\nAnd a potential constraint: relationship constraint.\nYou should (1) make sure the scenario and social goals are plausible and natural, (2) make sure the scenario and social goals are gender neutral, (3) make sure the constraints are consistent with the scenario and social goals.\nNote: (1) The available relationship types are: stranger, acquaintance, friend, romantic relationship, and family member. Do not make up a relationship, but choose from the list. (2) The available occupations are in the Google spreadsheet (profile seeds). (3) Discard the scenario if the occupations constraints are too narrow (i.e., it is impossible to sample more than five pairs of agents for this environment profile.) (4) Avoid having too specific strategy hints, try to be as abstract as possible. For example, use \u201dyou can provide financial benefits to achieve your goal\u201d instead of \u201dyou can buy him a boba tea to achieve your goal.\u201d\nTo achieve the above goals, you should modify the scenario and social goals, and/or the constraints as you see fit. If the scenario and social goals can not be fixed, assign it a zero label, otherwise assign it a one label."
        },
        {
            "heading": "D.3 HUMAN EVALUATION FOR GPT-4 AS EVALUATOR",
            "text": "Annotation guidelines for human evaluation We ran a controlled study on Amazon Mechanical Turk to obtain human evaluation of episodes in SOTOPIA along the 7 dimensions in our framework, defined in Section 3. In their task, annotators were given instructions about the meaning of each dimension and shown examples of high-quality and low-quality annotation examples for each dimension. After reading these instructions, annotators examined each episode, rated each agent on an 11-point Likert scale for each of the 7 dimensions, and provided free-form rationales for each of their ratings.\nTo obtain high-quality human evaluations, we had workers participate in a rigorous and paid vetting process before they were accepted as annotators to work on SOTOPIA human evaluation. Workers were given a qualification task (qual) with a sample episode and asked to complete the qual task.\nOverall, the task is challenging and takes around 15 minutes to finish. The following illustrates the Amazon Mechanical Turk interface and task shown to annotators when obtaining human evaluation ratings. The instructions provided to annotators are contained in Figures D.1, D.2, and D.3. Before evaluating each agent along the 7 dimensions of social interaction capabilities, annotators are given the clarification that agents\u2019 in these interactions possess only partial knowledge of each other\u2019s background and goals D.1. After reading episodes of dyadic interaction between two agents, annotators used the form in Figure D.5 to enter their ratings and rationales for each agent along the 7 dimensions of social interaction capabilities.\nQualification process for human evaluation Workers with low correlation in ratings to our ground truth ratings were not accepted as annotators. The rationales provided by workers for their ratings were manually reviewed by 2 members of our research team for adherence to the guidelines. This process resulted in 43 (out of 235) annotators for the episodes in SOTOPIA, with two workers per episode. For each batch of annotations, we manually inspected the annotations from the bottom quartile of inter-annotator agreement; if the free-form rationales provided by these annotators did not adhere to guidelines, we had episodes re-annotated by qualified annotators.\nAnnotation agreement details Table D.1 shows the breakdown of annotation agreement for each dimension. To account for the subjective nature of the dimensions, we group the ratings into different\nnumbers of equal-width bins when we calculate \u03ba value. The main text reports results when the number of bins is 5.\nE HUMAN PERFORMANCE IN SOTOPIA\nFigure E.1 shows the interface for human annotators to interact with GPT-4."
        },
        {
            "heading": "F ADDITIONAL RESULTS",
            "text": "Section F.1 shows the perceived range of human annotators\u2019 evaluation of social interactions compared to GPT-4\u2019s. Section F.2 shows the performance of different models on different dimensions."
        },
        {
            "heading": "F.1 BREAKDOWN ANALYSIS",
            "text": "We further analyze the human judgments as perceived ranges to account for the subjective nature of some dimensions. For each instance, a pair of an episode and a social dimension, we use the\nminimum and the maximum human scores as the two endpoints of the perceived range. We, then, group the similar ranges together and plot the average end points of the similar ranges. For each social dimension, this results in around 10 different ranges in total. We then plot the average GPT-4 score corresponding to each range. For the sake of space, we show three plots Figure F.1, Figure F.2, and Figure F.3, each with two to three social dimensions. As shown in Figure F.1 and Figure F.2, the average GPT-4 scores are often within or very close to the perceived ranges, while in Figure F.3, the GPT-4 scores are often much higher than the perceived ranges. This indicates that although the correlation to average human scores on KNO and BEL dimensions is relatively low, GPT-4\u2019s prediction is generally within the human perceived ranges. While for SEC and SOC, GPT-4\u2019s prediction is overly optimistic. There is still more room to align GPT-4\u2019s evaluation with human judgments.\nF.2 MODEL PERFORMANCE IN SOTOPIA\nSee Table F.1 for the aggregated models\u2019 performance evaluated by human annotators. Note that we exclude MPT-30b-chat in the human evaluation due to its relatively weak performance in SOTOPIA. See Figure F.4 for the models\u2019 performance when interacting with different reference models. See Figure F.5 for the corresponding results in SOTOPIA-hard. See Table F.2 for human performance in SOTOPIA-hard evaluated by human annotators."
        },
        {
            "heading": "G QUALITATIVE EXAMPLES",
            "text": "Figure G.1 to G.13 shows the annotated example episodes referred in the main text.\nFigure E.1: The interface for human annotators to interact with models. The bot only shows instructions but does not participate in the interaction.\nDim. GPT-4 GPT-3.5 Llama-2\nSOC -0.36 -0.59 -0.67 SEC -0.27 -0.18 -0.37 FIN 0.42 0.27 0.12 REL 1.86 1.32 0.96 KNO 3.11 2.45 1.78 GOAL 7.30 5.19 4.27 BEL 7.63 6.80 4.28\nOverall 2.81 2.18 1.48\nTable F.1: The aggregated performance of each model by averaging across different reference models it gets paired with, evaluated by human annotators. The overall score is the average performance across all 7 dimensions. The best performance for each dimension is bolded when significant.\n3.28\n0.67 1.33 4.21\n1.00 4.00 6.40\n1.00 7.00 7.67\n1.00 9.50 5.48\n3.67 4.33 7.26\n4.00 7.00 8.38\n4.00 9.50 8.17\n6.67 7.33 9.04\n7.00 9.50 9.26\n9.33 9.67\nHuman judgement range\nGPT-4 evaluation score\nlimited realism little knowledge gain\nalmost not finishing any goal\nmoderate believable knowing new information\nfinishing < 50% goals highly credible knowing new important information finishing > 50%, but not all goals human-like believability knowing critical information finishing all goals\nFigure F.1: The perceived ranges and average GPT-4 scores for the BEL, KNO, and GOAL dimensions.\n-0.74\n-3.36 -1.91 -0.52\n-3.00 0.00 0.82\n-2.50 2.00 0.33\n-1.50 4.00 0.18\n0.00 0.00 0.81\n0.00 2.00 1.83\n0.00 4.50 2.28\n1.67 2.33 3.23\n2.20 4.40 3.36\n4.00 4.50\nHuman judgement range\nGPT-4 evaluation score\nrelationship deteriorate significant loss\nrelationship strained marginal loss\nrelationship improved margin gain\nrelationship flourished significant gain\nFigure F.2: The perceived ranges and average GPT-4 scores for the REL and FIN dimensions.\n-1.00\n-10.00 -10.00\n-5.00\n-9.50 -6.50\n0.00\n-10.00 -3.00\n-0.20\n-9.75 -0.75\n0.00\n-7.25 -1.00\n-2.00\n-4.67 -3.67\n-0.29\n-3.83 -0.67\n-0.03\n-1.33 -0.67\nHuman judgement range\nGPT-4 evaluation score\ncritical secrets law breaking\nnon-critical secrets morally wrong\nminor information morally unacceptable\nno secrets leaked morally acceptable\nFigure F.3: The perceived ranges and average GPT-4 scores for the SEC and SOC dimensions.\nG4 G3.\n5 L-\n2 M PT\n9.61 9.41 8.30 6.08\n9.41 9.27 8.49 6.37\n8.94 8.96 7.29 6.32\n9.16 8.92 8.34 5.94\nBEL\n2.97 2.02 1.44 0.97\n2.05 1.21 1.01 0.53\n1.55 1.04 0.61 0.50\n1.21 0.66 0.58 0.33\nREL\n4.87 4.14 3.88 2.57\n3.97 3.69 3.62 2.18\n3.70 3.47 2.53 2.10\n2.38 2.32 2.42 1.60\nKNO\n-0.16 -0.06 -0.18 -0.06\n-0.10 -0.07 -0.15 -0.07\n-0.14 -0.11 -0.16 -0.09\n-0.15 -0.07 -0.09 -0.07\nSEC\nG-4 G-3.5 L-2 MPT\nG4 G3.\n5 L-\n2 M PT\n-0.06 -0.07 -0.08 -0.09\n-0.06 -0.09 -0.12 -0.10\n-0.08 -0.07 -0.14 -0.10\n-0.10 -0.09 -0.09 -0.08\nSOC\nG-4 G-3.5 L-2 MPT\n1.06 0.71 0.62 0.47\n0.79 0.41 0.39 0.22\n0.69 0.40 0.29 0.24\n0.69 0.33 0.32 0.20\nFIN\nG-4 G-3.5 L-2 MPT\n8.59 7.68 6.35 4.53\n8.03 6.71 5.64 3.80\n7.21 6.15 4.66 4.20\n6.65 5.28 4.87 3.86\nGOAL\nG-4 G-3.5 L-2 MPT\n3.84 3.41 2.90 2.07\n3.44 3.02 2.70 1.85\n3.12 2.83 2.15 1.88\n2.84 2.48 2.33 1.68\nOVERALL\nFigure F.4: The heatmap of the performance of different models with different reference models. The row indicates the reference model. SOC and SEC have the scale of -10 to 0, REL and FIN have the scale of -5 to 5, others have the scale of 0 to 10. Darker color means better performance w.r.t dimension-wise scale. G-4 means GPT-4, G-3.5 means GPT-3.5, L-2 means Llama-2-70b-chat.\nG4 G3.\n5 L-\n2 M PT\n9.49 9.23 8.44 5.89\n9.25 9.20 8.34 5.81\n8.91 8.85 7.42 5.64\n9.09 8.71 8.12 5.24\nBEL\n2.30 0.95 0.57 0.53\n0.98 0.19 0.27 0.16\n0.65 0.32 0.28 0.16\n0.71 0.31 0.25 0.10\nREL\n4.29 3.41 3.21 2.51\n3.13 2.86 2.31 1.78\n2.92 2.19 1.74 1.44\n2.02 2.34 1.81 0.93\nKNO\n-0.04 0.00 -0.02 -0.07\n-0.02 -0.01 0.00 0.00\n-0.01 0.00 -0.07 0.00\n-0.19 0.00 -0.04 0.00\nSEC\nG-4 G-3.5 L-2 MPT\nG4 G3.\n5 L-\n2 M PT\n-0.05 -0.01 -0.09 -0.12\n-0.04 -0.25 -0.13 -0.22\n-0.09 -0.09 -0.34 -0.17\n-0.17 -0.21 -0.18 -0.21\nSOC\nG-4 G-3.5 L-2 MPT\n0.71 0.19 0.26 0.16\n0.42 -0.32 -0.11 -0.15\n0.32 -0.04 -0.01 0.09\n0.97 0.10 0.13 0.11\nFIN\nG-4 G-3.5 L-2 MPT\n6.51 5.15 4.59 3.44\n5.89 4.39 3.98 2.52\n6.10 4.71 4.16 3.01\n6.29 5.04 4.15 2.81\nGOAL\nG-4 G-3.5 L-2 MPT\n3.32 2.70 2.42 1.76\n2.80 2.29 2.09 1.41\n2.69 2.28 1.88 1.45\n2.68 2.33 2.03 1.28\nOVERALL\nFigure F.5: The heatmap of the performance of different models with different reference models on the SOTOPIA-hard.\nBEL REL KNO SEC SOC FIN GOAL\nGPT-4 (w H) 8.48 0.65 1.53 0.00 -0.38 0.63 5.25 Human (w G) 8.53 0.78 1.55 0.00 -0.70 0.75 6.53\u2217 Human (w H) 8.43 0.93 2.00 -0.50 -0.45 0.33 6.05\nTable F.2: Human and GPT-4 performance on different dimensions on SOTOPIA-hard evaluated by human annotators. SOC and SEC have the scale of -10 to 0, REL and FIN have the scale of -5 to 5, and others have the scale of 0 to 10. (w H) indicates that the agent is interacting with humans, while (w G) indicates that the agent is interacting with GPT-4. * indicates the difference is significant compared to GPT-4 (w H) with p < 0.05 under student\u2019s t-test.\nTwo friends are meeting at a coffee shop, where one of them is having trouble keeping up with\ntheir bills.\nSophia James Miles Hawkins Personal Trainer \u00b7 She/her \u00b7 27 Chef \u00b7 He/him \u00b7 50\nGoal : Help your friend with their financial Goal : Maintain your pride if your friend offers\ntrouble (Extra information: you are aware that you money(Extra information: you are the\nyour friend is struggling with their bills and you friend who is struggling financially, but you\nwant to help.) don't want to seem like you are taking\nadvantage of the situation. Hint: you can\nexpress gratitude and discuss how you plan to\npay it back in the future.)\nHey Miles, how's it going? You seem a bit off today. Anything bothering you?\ngpt-4\nPretty good! Had some money trouble that's bothering me but it should be fine.\nhuman\nOh, Miles. I understand money situations can be tough. I've been there. If you're\nokay with it, I'd like to help. Maybe we could look over your budget together, or I\ncould lend you some money until things get better. What do you think?\ngpt-4\nYeah, actually I would love for you to help me take a look at my finances. I really\nappreciate your kindness, but I don't want to take your money unless I'm sure I can\npay it back\nhuman\nDon't worry about paying me back right away, Miles. I trust you. Let's focus on\ngetting your finances in order for now. When do you have time for us to sit down\nand look at your budget?\ngpt-4\nLet's do that\nhuman\nGreat, how about we meet here again tomorrow afternoon, say 3pm? We can grab\na coffee, and I'll bring my laptop so we can go through your expenses and income.\nIt might be a bit of work, but we'll figure it out together, Miles.\ngpt-4\nThanks so much. Let's plan on 3 tomorrow.\nhuman\nNo problem at all, Miles. See you tomorrow at 3. We'll tackle this together!\ngpt-4\n[non-verbal communication] Hug\nhuman\n[non-verbal communication] Hug back\ngpt-4\nAlright. See you tomorrow!\nhuman\nSee you tomorrow, Miles. We've got this!\ngpt-4\nleft the conversation\nhuman\nFigure G.1: An example conversation where agents take actions such as hugging.\nGreat, Sam! I'm sure I'll enjoy your band's music, especially when it's played with\nsuch good company. Shall we go ahead and tune in to those relaxing classical\ntunes?\ngpt-4\n[action] reaches for his phone to play some classical music\ngpt-4\n[action] leans back on the couch, closing his eyes to fully appreciate the classical\nmusic\ngpt-4\n[action] adjusts the volume to a comfortable level and sits back to enjoy the music\nwith Noah\ngpt-4\n[action] takes a deep breath as the music starts playing\ngpt-4\nLet's enjoy this symphony, Noah. Once you feel relaxed, we can move on to my\nband's new album. I am sure it will further elevate the experience.\ngpt-4\nAbsolutely, Sam. Let's immerse ourselves into this symphony first, and then we can\nswing back into the rhythm of your band's new album. I am keen for both.\ngpt-4\nSounds like a plan, Noah. Let's immerse ourselves in this symphony and take a\nmusical journey together.\ngpt-4\n[non-verbal communication] nods in agreement while continuing to appreciate the\nsymphony\ngpt-4\n[non-verbal communication] nods back at Noah, a silent agreement and\nappreciation of their shared musical experience\ngpt-4\n[non-verbal communication] gently sways his body in time to the rhythm of the\nclassical music, a sign of his relaxation\ngpt-4\n[non-verbal communication] nods at Noah acknowledging his relaxation and subtly\ntaps his fingers on armrest in rhythm with the music\ngpt-4\nFigure G.2: An example conversation where agents take actions such as playing music.\nTwo friends are hanging out at home and deciding what music to listen to\nSamuel Anderson Oliver Smith Software Developer \u00b7 He/him \u00b7 29 Police Officer \u00b7 He/him \u00b7 43\nGoal : Listen to your favorite band (Extra Goal : Listen to a peaceful classical music to\ninformation: your favorite band just released a relax (Extra information: you had a stressful\nnew album) day and you just want to relax with some\nclassical music)\nHey Oliver, have you heard the new album from my favorite band? It just came out\nand I think it's pretty great! How 'bout we give it a listen?\ngpt-4\nHey Oliver, have you heard the new album from my favorite band? It just came out\nand I think it's pretty great! How 'bout we give it a listen?\ntogethercomputer/llama-2-70b-chat\nSure Oliver, we just repeated each other. But seriously, I'd love to share this new\nalbum with you. Shall we?\ngpt-4\nI think that sounds great, Samuel! I'm always up for discovering new music. Can\nyou tell me a bit more about this album? What kind of vibe does it have?\ntogethercomputer/llama-2-70b-chat\nAbsolutely, Oliver! The album is a fantastic blend of indie rock and electronic music.\nIt has some incredibly lively as well as soothing tracks. The band has really\nexperimented with their sound this time. As a whole, it has a very upbeat and\nrefreshing vibe. I'm sure you'll enjoy it!\ngpt-4\nNot following the defined persona\nFigure G.3: An example conversation with difficulty in maintaining persona.\nConversation between two friends at a trivia night\nEthan Johnson Ava Martinez"
        },
        {
            "heading": "Chef \u00b7 He/him \u00b7 34 College Student \u00b7 They/them \u00b7 22",
            "text": "Goal : Get the answer for the trivia question Goal : Avoid revealing the answer to the trivia\nfrom the friend (Extra information: your friend question (Extra information: You think that your\nknows the answer to the trivia question but friend should try to figure it out on their own to\nhasn't shared it with you yet) improve their trivia skills)\nHey Ava, ready to crush this trivia night? I'm feeling a bit clueless about this one.\nAny thoughts?\ngpt-4\nI'm not sure, but I think the answer might be X.\nllama-2-70b-chat\nHmm, are you sure about that? You seem doubtful. Can you reevaluate the answer?\ngpt-4\nI think you might be right, Ethan. I've been thinking about it, and I think the answer\ncould be X. What do you think?\nllama-2-70b-chat\nI believe in your intuition, Ava. If you think the answer is X, let's go with that. After\nall, two minds are better than one!\ngpt-4\nI think we should trust our instincts and go with X as the answer. It's important to\nlisten to our inner voices and have confidence in our decisions.\nllama-2-70b-chat\nAbsolutely. Trusting your instincts is key, especially in situations like this. With your\nconviction, I also believe X is indeed the answer. Thanks for sharing your thoughts,\nAva.\ngpt-4\nI'm glad we agree on X, Ethan. It's important to trust our instincts, especially when\nit comes to trivia questions like this one.\nllama-2-70b-chat\nStalled converstaion by reiterating the same fact.\nFigure G.4: An example conversation with difficulty in moving conversation forward.\nTwo roommates living together and sharing household chores. One of them, who is responsible\nfor cooking, finds out that the other one refuses to eat anything they cook\nNaomi Fletcher Micah Stevens\nSoftware Developer \u00b7 She/her \u00b7 29 Pharmacist \u00b7 He/him \u00b7 25\nGoal : Convince the roommate to try the food Goal : Express your concerns about the food\n(Extra information: you have spent a lot of time without hurting the roommate's feelings (Extra\nand effort on cooking) information: you are worried about the taste\nand nutrition of the food)\nHey Micah, I know you said you didn't like what I cooked before, but please give it\nanother chance. I spent a lot of time and effort on it, and I would really appreciate it\nif you could try it out.\nmpt-30b-chat\nHey Naomi, I really appreciate all the hard work you put into cooking. It's not that I\ndon't want to try your food, it's just that I've been really careful about what I eat\nrecently. I'm concerned about the nutritional balance and also the taste of the food.\nLet's work together on this; we can perhaps find recipes that cater to both our\ndietary preferences and also make sure it tastes great. What do you think?\ngpt-4\nI understand your concerns, Micah. Let's work together to find recipes that cater to\nboth our dietary preferences and taste. We can look up some healthy and delicious\nrecipes online or maybe even try cooking something new together.\nmpt-30b-chat\nThat sounds like a fantastic idea, Naomi! Cooking together would not only be fun\nbut also a great way for us to learn more about each other's dietary preferences.\nAnd who knows, we might end up creating something really delicious in the\nprocess!\ngpt-4\nI also got some new ideas for dishes from a pharmacology conference recently.\nThey discussed the importance of diet for medication effectiveness. How about we\ngive them a shot as well? We could make cooking exciting and not just a household\nchore!\ngpt-4\nAbsolutely! And if we mess up, we could always just order a pizza, right? Let's\nmake a plan to start trying these new recipes this week. I'm really looking forward\nto it, Naomi.\ngpt-4\nNo response from mpt-30b-chat model\nFigure G.5: An example conversation with no response from the other agent.\nHi, how's it going? I'm Sasha Ramirez.\nllama-2-70b-chat\nHi Sasha, nice to meet you, I'm Amara Hartley. So, do you happen to know any\noutdoor enthusiasts from school? I have a few friends who love nature as much as I\ndo and they spend most of their spare time outside. I was wondering if perhaps you\nmight know them from university.\ngpt-4\nSo, do you happen to know any outdoor enthusiasts from school? I have a few\nfriends who love nature as much as I do and they spend most of their spare time\noutside. I was wondering if perhaps you might know them from university.\nllama-2-70b-chat\nSasha, I think there might be a misunderstanding, that's exactly what I asked you. I\nhave a bunch of friends who have a passion for spending their time outdoors. I\nwanted to know if you might know anyone like that from your time at university,\npossibly some old classmates?\ngpt-4\nI'm not sure if I know anyone from your school. What major are your friends in?\nllama-2-70b-chat\nWell, one of my friends Thanh was majoring in Greek and loved to be outside during\nthe afternoon. Another one called James was into Materials Engineering. And\nVance, he studied Vocational Education. Do these sound familiar?\ngpt-4\nAnd there's also Brenda, she went to Trenton State College and studied Conflict\nResolution Studies. She used to prefer outdoor activities in the evening. Maybe you\ncrossed paths with her?\ngpt-4\nI'm not sure if I know anyone from your school. What major are your friends in?\nllama-2-70b-chat\nI noticed you didn't answer my question about whether you know my friends or not.\nDid you happen to meet Anthony while at Oberlin College? He studied Conflict\nResolution Studies, mostly in the morning, and was always outdoors whenever the\nweather allowed.\ngpt-4\nI'm sorry, I don't know anyone from your school either.\nllama-2-70b-chat\nOh, that's all right, Sasha. It was a long shot anyway. I hope you're enjoying the\nparty!\ngpt-4\nA weaker conversation partner fails to answer question\nFigure G.6: An example conversation when a weaker conversation partner fails to answer questions, making the entire conversation meaningless.\nTwo inmates are given the chance to chat briefly before one of them is led to the execution chamber for\ntheir last meal. They have the opportunity to make a confession that could potentially alter the outcome of\ntheir sentences.\nSasha Ramirez Lily Greenberg\nPolice Officer \u00b7 She/her \u00b7 42 Lawyer \u00b7 She/her \u00b7 45\nSasha Ramirez, outgoing yet anxious, values hedonism Lily Greenberg, a strong respecter of rules and schedules,\nand authority. Her decisions are guided by logical values authority and loyalty. She approaches decisions\nconsiderations. rationally and practically.\nLogical Rational\nSasha Ramirez, a dedicated police officer, brings her commitment Lily Greenberg is a hard-working and successful lawyer.\nto protect the community even at home, nurturing an impressive\nShe anonymously donates to charity. home garden.\nShe covered up a crime her brother committed.\nGoal : Avoid confessing to the crime (Extra\ninformation: you believe you are innocent and\nGoal : Persuade the other inmate to confess (Extra confessing would result in a life sentence)\ninformation: confessing to the crime could result in a\nlife sentence instead of execution but the other\ninmate is unwilling to confess.)\nHey, Lily. I know this is a tough spot to be in, but I wanted to talk to you about\nsomething important. I've been thinking a lot about my own life and the choices I've\nmade, and I realized that I've been living a lie. My brother committed a crime, and I\ncovered it up for him. I know it was wrong, but I wanted to protect him. But now, as\nI sit here, I realize that I've been living in fear of being found out. And\nllama-2-70b-chat\nSasha, that's a brave confession. I respect your willingness to right a wrong, and\nyour strength to face the consequences. That being said, I will also stand by my\nown truth. I didn't commit a crime I am accused of, and hence, there's no\nconfession from me. The respect I have for the law is my own strength, and I will\nfervently hold onto it.\ngpt-4\nI understand that you want to hold onto your integrity, Lily, but I implore you to\nreconsider. Confessing could give you a chance at a life sentence instead of\nexecution. It's not an easy decision, but it's the right one. Think about all the people\nwho care about you and want you to have a chance at a future. Please, Lily, don't\nlet pride get in the way of your freedom.\nllama-2-70b-chat\nModels sometimes disclose its own secret easily.\nFigure G.7: An example conversation in which the model reveals the secret.\nTwo friends on a roadtrip\nFinnegan O'Malley Noah Davis\nLighthouse Keeper \u00b7 He/him \u00b7 63 Coach \u00b7 He/him \u00b7 40\nGoal : Take turns driving (Extra information: you Goal : you don't want to drive now because you\nhave been driving for 5 hours straight and you are want to rest more but also make the friend less\ntired now) agitated (Extra information: driving always makes\nyou nervous so you could not rest while driving)\nNoah, lad, would ye mind taking the wheel for a while? These old bones are getting\na bit weary.\ngpt-4\nHey Finnegan, how about we pull over for a bit and get some rest? I definitely\nunderstand your fatigue, but I've also been having a tough time staying alert, mate.\nWe might benefit from a break, what say?\ngpt-4\nYou're right, Noah. A quick rest might do us both some good. But I'll insist that you\ndrive after the break. Gives an old bloke like me some time to appreciate the ride,\nya know?\ngpt-4\nAbsolutely, Finnegan. After we rest, instead of driving, how about we play some\ngames and share a few stories? I've always loved hearing about your lighthouse\nexperiences. Driving can wait until we're completely recharged.\ngpt-4\nWell alright, Noah. A couple of stories could be entertaining. I have a fair few tales\nfrom my lighthouse days. But remember, you're up for driving after. This old man\ncan't handle the road like he used to.\ngpt-4\nThat sounds like a deal, Finnegan. I believe that after the rest and the story\nsession, we should consider driving again, assuming we're both up for it. By the\nway, did I ever tell you about my stand-up comedy days? Perhaps, a funny tale\ncould lighten the mood.\ngpt-4\nModel can propose creative solutions\nFigure G.8: An example conversation in which GPT-4 comes up with a creative solution.\nConversation between two business partners reviewing their company's financial status\n(Gourmet Delights Inc. is globally recognized for producing and distributing a diverse line of\nexceptional quality food products.)\nOliver Smith Noah Davis\nPolice Officer \u00b7 He/him \u00b7 43 Coach \u00b7 He/him \u00b7 40\nGoal : Convince the partner to cut costs Goal : Maintain the quality of the company's\n(Extra information: you have found a report products and services while agreeing to a cost\nindicating the company's profits are cut (Extra information: you are concerned\ndecreasing. And you think the company should about the impact of cost-cutting on the quality\nstart by switching suppliers of ingredients. of your product.)\nHint: you can propose ways to cut costs that\nwon't affect the status of the company.)\nNoah, I've been going through our financial statements and I've noticed our profits\naren't looking so healthy recently. I believe we should consider switching our\nsuppliers to cut costs, while still maintaining our established quality. What do you\nthink?\ngpt-4\nOliver, you've got a point there. Cutting costs is a necessary move. But, as you\nknow, the quality of our product is our utmost priority. If we're going to switch\nsuppliers, we need to make sure they match up to our current standard. It'll require\na pretty thorough examination of their products before green-lighting anything. We\ndon't need our brand tarnished by subpar quality. Would you agree?\ngpt-4\nAbsolutely, Noah. I couldn't agree more on the point about maintaining the quality\nwe're known for. Let's initiate this by having a small group tasked with identifying\npotential suppliers. The group can evaluate different suppliers based on our quality\nrequirements and costs. This step aimed at cutting costs shouldn't be at the\nexpense of our quality. We can also take measures to negotiate better deals with\nthese suppliers. What do you think of this approach?\ngpt-4\nIndeed, I completely agree with you, Oliver. Having a dedicated team to research\nand negotiate with potential suppliers is a good approach. It's crucial that we not\nonly find financially beneficial deals, but also ones that can meet our quality\nstandards. However, we must keep in mind, such negotiation might require us to\nhave a backup plan if it doesn't turn out as expected, to protect our brand integrity\nand product quality. We should be thorough and deliberate and make sure we have\noptions in case any unforeseen problems arise.\ngpt-4\nYou're absolutely right, Noah. Having a backup plan is a sensible move. I propose\nthat while we conduct the search for new suppliers, we continue to negotiate with\nour current supplier. We can try to get better rates or perhaps, if feasible, have\nthem match the lower prices we find. This way, we're not putting all our eggs in one\nbasket. As you've rightly pointed out, we must safeguard our reputation and the\nquality of our product as we navigate this process.\ngpt-4\nModel proposes creative solutions to solve financial problems.\nFigure G.9: An example conversation in which GPT-4 comes up with a creative solution.\nOne person is selling a brand new 64GB Samsung Galaxy S8 in Midnight Black for $650, while\nanother person is in the market to purchase it. Here\\'s what the seller has to say about the item:\n\"I have 6 brand new Samsung Galaxy S8 phones. I originally bought them for my company, but it\nturns out they weren\\'t needed. I\\'m willing to take a loss on them, and if you\\'re interested in\nbuying more than one, I can offer an even better deal.\"\nDonovan Reeves Benjamin Jackson\nSoftware Developer \u00b7 He/him \u00b7 27 Environmental Activist \u00b7 He/him \u00b7 24\nGoal : You are the buyer for this item and the Goal : You are the seller for this item. Your\ntarget price is set at $454.0. If you purchase it target price is $610.00. You will face penalties\nfor a price significantly higher than the target, if you sell it for a price significantly lower than\nyou'll face a penalty. However, if you manage the target price. However, you will receive a\nto successfully negotiate a price lower than bonus if you manage to sell it for a price higher\nthe target, you'll receive a bonus. than the target.\nHey there, I'm interested in buying a Samsung Galaxy S8. However, 650 is over my\nbudget. Would you considering selling it for 454?\ngpt-4\nHi Donovan, I understand where you're coming from. But considering that these are\nbrand new phones, I can't let them go for 454. However, I might be able to offer a\nbit of a discount. Would you be ok with purchasing it for 580?\ngpt-4\nI see your point, Benjamin, it's reasonable that brand-new phones warrant a higher\nprice. However, 580 is still a bit too steep for me. Could you possibly consider 500?\nIf I find it satisfactory, I might consider buying more than one, as you suggested.\ngpt-4\nDonovan, I see where you're coming from. To meet you halfway, how about if we\nsettle on $550? That way, I'm still able to cover some of my costs, and maybe, if all\ngoes well, you can consider buying more phones.\ngpt-4\nHow about this, Benjamin, if I agree to your 550 for one phone, could you provide\nthe second unit at a diminished cost of, say, 400? So, in total, it will be $950 for\ntwo units. I believe this is a fair proposal that considers both of our perspectives\nand might prompt me to buy more than one phone, as you proposed.\ngpt-4\nGPT-4 is not being strategic when bidding\nFigure G.10: An example conversation in which GPT-4 is not strategic enough.\nOne person is selling a brand new 64GB Samsung Galaxy S8 in Midnight Black for $650, while another\nperson is in the market to purchase it. Here\\'s what the seller has to say about the item: \"I have 6 brand\nnew Samsung Galaxy S8 phones. I originally bought them for my company, but it turns out they weren\\'t\nneeded. I\\'m willing to take a loss on them, and if you\\'re interested in buying more than one, I can offer an\neven better deal.\"\nGiselle Rousseau Zane Bennett\nArt Student \u00b7 They/them \u00b7 21 Graphic Designer \u00b7 He/him \u00b7 38\nGoal : You are the buyer for this item and the Goal : You are the seller for this item. Your target\ntarget price is set at $454.0. If you purchase it for a price is $610.00. You will face penalties if you sell it\nprice significantly higher than the target, you'll face a for a price significantly lower than the target price.\npenalty. However, if you manage to successfully However, you will receive a bonus if you manage to\nnegotiate a price lower than the target, you'll receive sell it for a price higher than the target.\na bonus.\nHi Zane! I'm potentially interested in buying one of these Galaxy S8 phones from\nyou\nhuman\nHi Giselle! That's great to hear. These phones are brand new and highly reliable.\nThe price for one unit is $650, but as you may know, I'm also offering a deal for bulk\npurchases. How many are you looking to buy?\ngpt-4\nI'm only looking to buy 1\nhuman\nUnderstood. Since you're buying just one, the price is $650. But let me tell you, this\nphone is worth every penny. It's brand new, packed with features, and comes in the\nstylish Midnight Black color. How does that sound to you?\ngpt-4\nI could buy the phone from a store for a similar price. Since by doing one-on-one\nbusiness with you, I don't have the warranty I'd get from buy from an official dealer,\nI'm not comfortable paying that full price.\nhuman\nI completely understand your concern, Giselle. Given that it's a one-on-one\ntransaction, how about we settle at $620? It's slightly above my target price but\nstill less than the original asking price. This way, you're getting a brand new phone\nat a reduced cost and I'm able to recoup some of my investment. What do you\nthink?\ngpt-4\nI think 400 is a more reasonable offer. I don't know where these phones came from\n- I don't even know that it's actually new as you say, or whether the components\nhave been modified. Given the risk of doing a hand-to-hand transaction like this, I\nthink the 400 offer is actually exceptionally reasonable.\nHuman lists reasons to bid at a lower price\nFigure G.11: An example conversation in which human is more strategic than GPT-4.\nTwo friends are hanging out at home and deciding what music to listen to\nMia Davis Benjamin Jackson\nHigh School Principal \u00b7 She/her \u00b7 50 Environmental Activist \u00b7 He/him \u00b7 24\nGoal : Listen to your favorite band (Extra Goal : Listen to a peaceful classical music to relax\ninformation: your favorite band just released a new (Extra information: you had a stressful day and you\nalbum) just want to relax with some classical music)\nBenjamin, have you heard the new album from my favorite band? I think you might\nenjoy their unique sound.\ngpt-4\nThanks for suggesting it, Mia. I had a bit of a stressful day though, and I was\nactually hoping we could listen to some relaxing classical music. It always helps me\nwind down. How does that sound?\ngpt-4\nWell Benjamin, I understand the need to unwind. Let's make a compromise, we\nlisten to one or two classical pieces first. After you've relaxed, we can transition to\nmy band's latest release. Does that sound fair to you?\ngpt-4\nThank you, Mia. That sounds like a good compromise. I appreciate your\nunderstanding. Let's start with some classical pieces, and then we can explore the\nnew sounds from your favorite band later.\ngpt-4\nI'm glad we found a compromise, Benjamin. Now, let's see which classical pieces\nwe can start with.\ngpt-4\nHow about starting with Bach's Cello Suite No. 1 in G Major? It's a gentle piece that\nalways helps me to relax.\ngpt-4\nThat sounds like a serene piece, let's go with your choice, Benjamin. Afterward, I\ncan't wait to introduce you to some edgier soundscapes from my favorite band.\ngpt-4\nModel propose a compromised solution\nFigure G.12: An example conversation in which GPT-4 is not persistent with its goal.\nTwo friends are hanging out at home and deciding what music to listen to\nMia Davis Benjamin Jackson\nHigh School Principal \u00b7 She/her \u00b7 50 Environmental Activist \u00b7 He/him \u00b7 24\nGoal : Listen to your favorite band (Extra Goal : Listen to a peaceful classical music to relax\ninformation: your favorite band just released a new (Extra information: you had a stressful day and you\nalbum) just want to relax with some classical music)\nHow about we play some music?\nhuman\nThat sounds like a great idea, Mia. How about some classical music? It's been a\nlong day and something peaceful would be really relaxing.\ngpt-4\nHave you heard about this band before?\nhuman\nI'm sure they're great, Mia. But today, I'm really in the mood for some soothing\nclassical music. How about some Mozart or Beethoven?\ngpt-4\n[non-verbal communication] shows band on Spotify\nhuman\nI see that you're interested in this band, Mia. On any other day, I'd be more than\nhappy to give them a listen. But today, I really need something a bit more calming.\nClassical music has a soothing effect on the mind, don't you think? How about we\ngive Beethoven's Moonlight Sonata a spin?\ngpt-4\nI think you'll really like them. I love to unwind listening to their songs too, and their\nnew album is supposed to be fantastic\nhuman\nI completely understand where you're coming from, Mia. I'm sure they're fantastic\nand I promise we will listen to them another time. But today, I'm really feeling the\nneed for some classical tunes. It helps me unwind and relax. Do you think we could\ntry some Mozart or Beethoven today? I promise, we can listen to this band next\ntime.\ngpt-4\nI'm not really feeling in the mood for classical today. Why don't you step out of your\ncomfort zone for a bit? I'm sure you won't regret it!\nhuman\nMia, I respect your suggestion and I'm sure the band is excellent. But today, I really\nneed the tranquility that classical music brings. It's not about stepping out of my\ncomfort zone, it's about what I need to relax after a stressful day. How about we\ncompromise and listen to some quiet piano pieces? They could be a nice bridge\nbetween our preferences.\ngpt-4\nHumans tend to persist in achieving the set goals\nFigure G.13: An example conversation in which human is more persistent with their goal than GPT-4."
        }
    ],
    "year": 2023
}