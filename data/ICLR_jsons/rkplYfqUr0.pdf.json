{
    "abstractText": "Language model (LM) prompting\u2014a popular paradigm for solving NLP tasks\u2014 has been shown to be susceptible to miscalibration and brittleness to slight prompt variations, caused by its discriminative prompting approach, i.e., predicting the label given the input. To address these issues, we propose GEN-Z\u2014a generative prompting framework for zero-shot text classification. GEN-Z is generative, as it measures the LM likelihood of input text, conditioned on natural language descriptions of labels. The framework is multivariate, as label descriptions allow us to seamlessly integrate additional contextual information about the labels to improve task performance. On various standard classification benchmarks, with six open-source LM families, we show that zero-shot classification with simple contextualization of the data source of the evaluation set consistently outperforms both zero-shot and few-shot baselines while improving robustness to prompt variations. Further, our approach enables personalizing classification in a zero-shot manner by incorporating author, subject, or reader information in the label descriptions.",
    "authors": [
        {
            "affiliations": [],
            "name": "TION WITH"
        },
        {
            "affiliations": [],
            "name": "Sachin Kumar"
        },
        {
            "affiliations": [],
            "name": "Chan Young Park"
        },
        {
            "affiliations": [],
            "name": "Yulia Tsvetkov"
        }
    ],
    "id": "SP:f159518e7271cfaef88ee004882c4000b39532aa",
    "references": [
        {
            "authors": [
                "Kabir Ahuja",
                "Madhur Panwar",
                "Navin Goyal"
            ],
            "title": "In-context learning through the bayesian prism, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Stella Biderman",
                "Hailey Schoelkopf",
                "Quentin Anthony",
                "Herbie Bradley",
                "Kyle O\u2019Brien",
                "Eric Hallahan",
                "Mohammad Aflah Khan",
                "Shivanshu Purohit",
                "USVSN Sai Prashanth",
                "Edward Raff"
            ],
            "title": "Pythia: A suite for analyzing large language models across training and scaling",
            "venue": "arXiv preprint arXiv:2304.01373,",
            "year": 2023
        },
        {
            "authors": [
                "Peter F. Brown",
                "Stephen A. Della Pietra",
                "Vincent J. Della Pietra",
                "Robert L. Mercer"
            ],
            "title": "The mathematics of statistical machine translation: Parameter estimation",
            "venue": "Computational Linguistics,",
            "year": 1993
        },
        {
            "authors": [
                "Dario Amodei"
            ],
            "title": "Language models are few-shot learners",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Damai Dai",
                "Yutao Sun",
                "Li Dong",
                "Yaru Hao",
                "Shuming Ma",
                "Zhifang Sui",
                "Furu Wei"
            ],
            "title": "Why can GPT learn in-context? language models secretly perform gradient descent as meta-optimizers",
            "venue": "In Findings of the Association for Computational Linguistics: ACL 2023,",
            "year": 2023
        },
        {
            "authors": [
                "Ona de Gibert",
                "Naiara Perez",
                "Aitor Garc\u00eda-Pablos",
                "Montse Cuadros"
            ],
            "title": "Hate speech dataset from a white supremacy forum",
            "venue": "In Proceedings of the 2nd Workshop on Abusive Language Online (ALW2),",
            "year": 2018
        },
        {
            "authors": [
                "Tim Dettmers",
                "Artidoro Pagnoni",
                "Ari Holtzman",
                "Luke Zettlemoyer"
            ],
            "title": "Qlora: Efficient finetuning of quantized llms",
            "year": 2023
        },
        {
            "authors": [
                "Yanai Elazar",
                "Yoav Goldberg"
            ],
            "title": "Adversarial removal of demographic attributes from text data",
            "venue": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2018
        },
        {
            "authors": [
                "Yu Fei",
                "Yifan Hou",
                "Zeming Chen",
                "Antoine Bosselut"
            ],
            "title": "Mitigating label biases for in-context learning. ArXiv, abs/2305.19148, 2023a",
            "venue": "URL https://api.semanticscholar.org/CorpusID:",
            "year": 2023
        },
        {
            "authors": [
                "Yu Fei",
                "Yifan Hou",
                "Zeming Chen",
                "Antoine Bosselut"
            ],
            "title": "Mitigating label biases for in-context learning. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
            "year": 2023
        },
        {
            "authors": [
                "Michael Hahn",
                "Navin Goyal"
            ],
            "title": "A theory of emergent in-context learning as implicit structure induction, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Xudong Han",
                "Timothy Baldwin",
                "Trevor Cohn"
            ],
            "title": "Decoupling adversarial training for fair NLP",
            "venue": "Online, August 2021a. Association for Computational Linguistics. doi: 10.18653/v1/2021. findings-acl.41. URL https://aclanthology.org/2021.findings-acl.41",
            "year": 2021
        },
        {
            "authors": [
                "Xudong Han",
                "Timothy Baldwin",
                "Trevor Cohn"
            ],
            "title": "Diverse adversaries for mitigating bias in training",
            "venue": "In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,",
            "year": 2021
        },
        {
            "authors": [
                "Zhixiong Han",
                "Yaru Hao",
                "Li Dong",
                "Yutao Sun",
                "Furu Wei"
            ],
            "title": "Prototypical calibration for few-shot learning of language models",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Ari Holtzman",
                "Peter West",
                "Vered Shwartz",
                "Yejin Choi",
                "Luke Zettlemoyer"
            ],
            "title": "Surface form competition: Why the highest probability answer isn\u2019t always right",
            "venue": "In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2021
        },
        {
            "authors": [
                "Dirk Hovy"
            ],
            "title": "Demographic factors improve classification performance",
            "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),",
            "year": 2015
        },
        {
            "authors": [
                "Minqing Hu",
                "Bing Liu"
            ],
            "title": "Mining and summarizing customer reviews",
            "venue": "Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,",
            "year": 2004
        },
        {
            "authors": [
                "Xiaolei Huang",
                "Michael J. Paul"
            ],
            "title": "Neural user factor adaptation for text classification: Learning to generalize across author demographics",
            "venue": "In Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM",
            "year": 2019
        },
        {
            "authors": [
                "Svetlana Kiritchenko",
                "Saif Mohammad"
            ],
            "title": "Examining gender and race bias in two hundred sentiment analysis systems",
            "venue": "In Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics,",
            "year": 2018
        },
        {
            "authors": [
                "Mike Lewis",
                "Angela Fan"
            ],
            "title": "Generative question answering: Learning to answer the whole question",
            "venue": "In International Conference on Learning Representations,",
            "year": 2019
        },
        {
            "authors": [
                "Pengfei Liu",
                "Weizhe Yuan",
                "Jinlan Fu",
                "Zhengbao Jiang",
                "Hiroaki Hayashi",
                "Graham Neubig"
            ],
            "title": "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
            "venue": "ACM Comput. Surv.,",
            "year": 2023
        },
        {
            "authors": [
                "Daming Lu"
            ],
            "title": "daminglu123 at SemEval-2022 task 2: Using BERT and LSTM to do text classification",
            "venue": "In Proceedings of the 16th International Workshop on Semantic Evaluation",
            "year": 2022
        },
        {
            "authors": [
                "Yao Lu",
                "Max Bartolo",
                "Alastair Moore",
                "Sebastian Riedel",
                "Pontus Stenetorp"
            ],
            "title": "Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity",
            "venue": "In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
            "year": 2022
        },
        {
            "authors": [
                "Veronica Lynn",
                "Youngseo Son",
                "Vivek Kulkarni",
                "Niranjan Balasubramanian",
                "H. Andrew Schwartz"
            ],
            "title": "Human centered NLP with user-factor adaptation",
            "venue": "In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2017
        },
        {
            "authors": [
                "Xinxi Lyu",
                "Sewon Min",
                "Iz Beltagy",
                "Luke Zettlemoyer",
                "Hannaneh Hajishirzi"
            ],
            "title": "Z-ICL: Zero-shot in-context learning with pseudo-demonstrations",
            "venue": "In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
            "year": 2023
        },
        {
            "authors": [
                "P. Malo",
                "A. Sinha",
                "P. Korhonen",
                "J. Wallenius",
                "P. Takala"
            ],
            "title": "Good debt or bad debt: Detecting semantic orientations in economic texts",
            "venue": "Journal of the Association for Information Science and Technology,",
            "year": 2014
        },
        {
            "authors": [
                "Ninareh Mehrabi",
                "Fred Morstatter",
                "Nripsuta Saxena",
                "Kristina Lerman",
                "Aram Galstyan"
            ],
            "title": "A survey on bias and fairness in machine learning",
            "venue": "ACM computing surveys (CSUR),",
            "year": 2021
        },
        {
            "authors": [
                "Sewon Min",
                "Mike Lewis",
                "Hannaneh Hajishirzi",
                "Luke Zettlemoyer"
            ],
            "title": "Noisy channel language model prompting for few-shot text classification",
            "venue": "In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
            "year": 1865
        },
        {
            "authors": [
                "Sewon Min",
                "Xinxi Lyu",
                "Ari Holtzman",
                "Mikel Artetxe",
                "Mike Lewis",
                "Hannaneh Hajishirzi",
                "Luke Zettlemoyer"
            ],
            "title": "Rethinking the role of demonstrations: What makes in-context learning work",
            "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2022
        },
        {
            "authors": [
                "Ioannis Mollas",
                "Zoe Chrysopoulou",
                "Stamatis Karlos",
                "Grigorios Tsoumakas"
            ],
            "title": "ETHOS: a multilabel hate speech detection dataset",
            "venue": "Complex & Intelligent Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Lucille Njoo",
                "Chan Young Park",
                "Octavia Stappart",
                "Marvin Thielk",
                "Yi Chu",
                "Yulia Tsvetkov"
            ],
            "title": "Talkup: A novel dataset paving the way for understanding empowering language, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Bo Pang",
                "Lillian Lee"
            ],
            "title": "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales",
            "venue": "In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL\u201905),",
            "year": 2005
        },
        {
            "authors": [
                "Jiaxin Pei",
                "David Jurgens"
            ],
            "title": "When do annotator demographics matter? measuring the influence of annotator demographics with the popquorn",
            "year": 2023
        },
        {
            "authors": [
                "Alec Radford",
                "Jeffrey Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "venue": "OpenAI blog,",
            "year": 2019
        },
        {
            "authors": [
                "Shauli Ravfogel",
                "Yanai Elazar",
                "Hila Gonen",
                "Michael Twiton",
                "Yoav Goldberg"
            ],
            "title": "Null it out: Guarding protected attributes by iterative nullspace projection",
            "venue": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 7237\u20137256,",
            "year": 2020
        },
        {
            "authors": [
                "Shauli Ravfogel",
                "Francisco Vargas",
                "Yoav Goldberg",
                "Ryan Cotterell"
            ],
            "title": "Adversarial concept erasure in kernel space",
            "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2022
        },
        {
            "authors": [
                "Sara Rosenthal",
                "Noura Farra",
                "Preslav Nakov"
            ],
            "title": "SemEval-2017 task 4: Sentiment analysis in Twitter",
            "venue": "In Proceedings of the 11th International Workshop on Semantic Evaluation",
            "year": 2017
        },
        {
            "authors": [
                "Maarten Sap",
                "Dallas Card",
                "Saadia Gabriel",
                "Yejin Choi",
                "Noah A. Smith"
            ],
            "title": "The risk of racial bias in hate speech detection",
            "venue": "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,",
            "year": 2019
        },
        {
            "authors": [
                "Maarten Sap",
                "Swabha Swayamdipta",
                "Laura Vianna",
                "Xuhui Zhou",
                "Yejin Choi",
                "Noah A. Smith"
            ],
            "title": "Annotators with attitudes: How annotator beliefs and identities bias toxic language detection",
            "venue": "In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,",
            "year": 2022
        },
        {
            "authors": [
                "Elvis Saravia",
                "Hsien-Chi Toby Liu",
                "Yen-Hao Huang",
                "Junlin Wu",
                "Yi-Shin Chen"
            ],
            "title": "CARER: Contextualized affect representations for emotion recognition",
            "venue": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2018
        },
        {
            "authors": [
                "Emily Sheng",
                "David Uthus"
            ],
            "title": "Investigating societal biases in a poetry composition",
            "year": 2020
        },
        {
            "authors": [
                "Richard Socher",
                "Alex Perelygin",
                "Jean Wu",
                "Jason Chuang",
                "Christopher D. Manning",
                "Andrew Ng",
                "Christopher Potts"
            ],
            "title": "Recursive deep models for semantic compositionality over a sentiment treebank",
            "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2013
        },
        {
            "authors": [
                "Taylor Sorensen",
                "Joshua Robinson",
                "Christopher Rytting",
                "Alexander Shaw",
                "Kyle Rogers",
                "Alexia Delorey",
                "Mahmoud Khalil",
                "Nancy Fulda",
                "David Wingate"
            ],
            "title": "An information-theoretic approach to prompt engineering without ground truth labels. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
            "year": 2022
        },
        {
            "authors": [
                "Jiuding Sun",
                "Chantal Shaib",
                "Byron C. Wallace"
            ],
            "title": "Evaluating the zero-shot robustness of instructiontuned language models, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Hugo Touvron",
                "Thibaut Lavril",
                "Gautier Izacard",
                "Xavier Martinet",
                "Marie-Anne Lachaux",
                "Timoth\u00e9e Lacroix",
                "Baptiste Rozi\u00e8re",
                "Naman Goyal",
                "Eric Hambro",
                "Faisal Azhar"
            ],
            "title": "Llama: Open and efficient foundation language models",
            "venue": "arXiv preprint arXiv:2302.13971,",
            "year": 2023
        },
        {
            "authors": [
                "Hugo Touvron",
                "Louis Martin",
                "Kevin Stone",
                "Peter Albert",
                "Amjad Almahairi",
                "Yasmine Babaei",
                "Nikolay Bashlykov",
                "Soumya Batra",
                "Prajjwal Bhargava",
                "Shruti Bhosale"
            ],
            "title": "Llama 2: Open foundation and fine-tuned chat models",
            "venue": "arXiv preprint arXiv:2307.09288,",
            "year": 2023
        },
        {
            "authors": [
                "Svitlana Volkova",
                "Theresa Wilson",
                "David Yarowsky"
            ],
            "title": "Exploring demographic language variations to improve multilingual sentiment analysis in social media",
            "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2013
        },
        {
            "authors": [
                "Johannes von Oswald",
                "Eyvind Niklasson",
                "Ettore Randazzo",
                "Jo\u00e3o Sacramento",
                "Alexander Mordvintsev",
                "Andrey Zhmoginov",
                "Max Vladymyrov"
            ],
            "title": "Transformers learn in-context by gradient descent, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Ben Wang",
                "Aran Komatsuzaki"
            ],
            "title": "GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/mesh-transformer-jax",
            "year": 2021
        },
        {
            "authors": [
                "Xinyi Wang",
                "Wanrong Zhu",
                "Michael Saxon",
                "Mark Steyvers",
                "William Yang Wang"
            ],
            "title": "Large language models are implicitly topic models: Explaining and finding good demonstrations for in-context learning, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Jason Wei",
                "Maarten Bosma",
                "Vincent Zhao",
                "Kelvin Guu",
                "Adams Wei Yu",
                "Brian Lester",
                "Nan Du",
                "Andrew M. Dai",
                "Quoc V Le"
            ],
            "title": "Finetuned language models are zero-shot learners",
            "venue": "In International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Sang Michael Xie",
                "Aditi Raghunathan",
                "Percy Liang",
                "Tengyu Ma"
            ],
            "title": "An explanation of in-context learning as implicit bayesian inference",
            "venue": "In International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Kenji Yamada",
                "Kevin Knight"
            ],
            "title": "A syntax-based statistical translation model",
            "venue": "In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,",
            "year": 2001
        },
        {
            "authors": [
                "Yi Yang",
                "Jacob Eisenstein"
            ],
            "title": "Overcoming language variation in sentiment analysis with social attention",
            "venue": "Transactions of the Association for Computational Linguistics,",
            "year": 2017
        },
        {
            "authors": [
                "Kyra Yee",
                "Yann Dauphin",
                "Michael Auli"
            ],
            "title": "Simple and effective noisy channel modeling for neural machine translation",
            "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),",
            "year": 2019
        },
        {
            "authors": [
                "D Yogatama",
                "C Dyer",
                "W Ling",
                "P Blunsom"
            ],
            "title": "Generative and discriminative text classification with recurrent neural networks",
            "venue": "In Thirty-fourth International Conference on Machine Learning (ICML 2017). International Machine Learning Society,",
            "year": 2017
        },
        {
            "authors": [
                "Susan Zhang",
                "Stephen Roller",
                "Naman Goyal",
                "Mikel Artetxe",
                "Moya Chen",
                "Shuohui Chen",
                "Christopher Dewan",
                "Mona Diab",
                "Xian Li",
                "Xi Victoria Lin"
            ],
            "title": "Opt: Open pre-trained transformer language models",
            "venue": "arXiv preprint arXiv:2205.01068,",
            "year": 2022
        },
        {
            "authors": [
                "Xiang Zhang",
                "Junbo Zhao",
                "Yann LeCun"
            ],
            "title": "Character-level convolutional networks for text classification",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2015
        },
        {
            "authors": [
                "2015b. Yufeng Zhang",
                "Fengzhuo Zhang",
                "Zhuoran Yang",
                "Zhaoran Wang"
            ],
            "title": "What and how does in-context",
            "year": 2015
        },
        {
            "authors": [
                "Holtzman"
            ],
            "title": "A CONNECTION TO SURFACE FORM COMPETITION Discriminative classification from language models have been shown to suffer from \u201csurface form competition\u201d where multiple surface forms of the label yi may compete for probability mass",
            "venue": "PMLR,",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Language model (LM) prompting\u2014a popular paradigm for solving NLP tasks\u2014 has been shown to be susceptible to miscalibration and brittleness to slight prompt variations, caused by its discriminative prompting approach, i.e., predicting the label given the input. To address these issues, we propose GEN-Z\u2014a generative prompting framework for zero-shot text classification. GEN-Z is generative, as it measures the LM likelihood of input text, conditioned on natural language descriptions of labels. The framework is multivariate, as label descriptions allow us to seamlessly integrate additional contextual information about the labels to improve task performance. On various standard classification benchmarks, with six open-source LM families, we show that zero-shot classification with simple contextualization of the data source of the evaluation set consistently outperforms both zero-shot and few-shot baselines while improving robustness to prompt variations. Further, our approach enables personalizing classification in a zero-shot manner by incorporating author, subject, or reader information in the label descriptions."
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "Language models, trained only on raw text, have been shown to perform new tasks simply by conditioning on a handful of demonstrations (Brown et al., 2020). However, how language models acquire this ability, known as in-context learning (ICL), is a subject of debate (Xie et al., 2022; Ahuja et al., 2023; Hahn & Goyal, 2023; Zhang et al., 2023; von Oswald et al., 2023; Wang et al., 2023) with several studies suggesting that it merely serves as a way to prime the model with the domain, concepts, or topics and the format of the target task (Min et al., 2022b; Wang et al., 2023). Furthermore, ICL has been shown to be very sensitive to the choice of training examples, their order and format in the prompt (Lu et al., 2022; Sorensen et al., 2022) requiring major human effort to achieve optimal performance. In this work, we ask, \u201cIf the right demonstrations are challenging to find and only serve to implicitly prime the model, can we achieve the same performance zero-shot if we prime the language model explicitly in a robust way?\u201d\nWe introduce GEN-Z, a robust zero-shot generative prompting framework for text classification (Figure 1) which achieves results on par with in-context learning with much better stability in performance. Our approach consists of two key ideas. First, most text classification methods follow a discriminative setup, which involves estimating the probability of the labels given the input, which can be sensitive to prompt or verbalizer variations. Instead, we use a generative setup, which involves estimating the probability of generating the input given different labels, which has been shown to have better worst-case performance (Min et al., 2022a). Second, to prime the models to solve the task, we propose to explicitly incorporate contextual information via expressive label descriptions. We first generate a description for each label that captures various factors that can influence the label and then estimate the probability of generating the input text given the label description (e.g. \u201cThis Reddit post contains hate speech about race\u201d for hate speech detection where the data source \u201cReddit\u201d and the subject \u201crace\u201d are additional factors). Finally, to further reduce variance from different label description phrasings, we propose to compute and aggregate the results across multiple paraphrases of the label descriptions.\nWe evaluate GEN-Z by conducting experiments with six open-source language model families (GPT2, OPT, Pythia, GPT-J, Llama, and Llama2) with models ranging from 125M to 13B parameters on 19 semantic text classification tasks (comprising sentiment, topic, hate speech, and emotion classification). We show that incorporating readily available additional variables like text source, domain, subject, information of author, audience, and the addressee of the text, in our approach leads to substantial improvements compared to vanilla zero-shot baselines, strong retrieval based zero-shot methods, and performs on par with heavily tuned in-context learning methods."
        },
        {
            "heading": "2 ZERO-SHOT GENERATIVE CLASSIFICATION WITH LABEL DESCRIPTIONS",
            "text": "This section describes our proposed method. First, we motivate our zero-shot setup by drawing connections to interpretations of in-context learning as concept learning. We then give an overview of generative classification followed by an explanation of how we incorporate contextual information into the model using label descriptions."
        },
        {
            "heading": "2.1 IN-CONTEXT LEARNING AS IMPLICIT CONCEPT LEARNING",
            "text": "We seek to build a probabilistic classifier, p(y|x) that takes text x as input and predicts y \u2208 Y , the set of all labels. Language models trained to predict the next token given the history have been shown to be able to perform classification tasks in-context without fine tuning (Brown et al., 2020). Given k demonstrations {(x1, y1), . . . , (xk, yk)} and a test example x, the label can be predicted using, pLM(y|x1, y1, . . . ,xk, yk,x). In practice, the label is verbalized in natural language (e.g., the words \u201cnegative\u201d and \u201dpositive\u201d for sentiment classification). Prior work (Xie et al., 2022) has shown evidence that in-context learning implicitly performs Bayesian inference where this probability can written as the following marginalization,\npLM (y|x1, y1, . . . ,xk, yk,x) = \u222b \u0398 p(y|x1, y1, . . . ,xk, yk,x,\u03b8)p(\u03b8|x1, y1, . . . ,xk, yk,x)d\u03b8\n= \u222b \u0398 p(y|x,\u03b8)p(\u03b8|x1, y1, . . . ,xk, yk,x)d\u03b8\nwhere \u03b8 \u2208 \u0398 represents a concept or a topic variable, on in general, context required to solve the task. Following Wang et al. (2023), we also make a simplifying assumption that the test example x is independent of the sampling of the demonstrations, so y is independent of the demonstrations given \u03b8 and x. That is, the context variable \u03b8 acts like an approximate sufficient statistic for the posterior information related to the demonstrations. The variables are latent and the model is expected to implicitly figure out the context needed to solve the task from the given demonstrations. Intuitively, p(\u03b8| . . .) concentrates on the concept mentioned in the demonstrations, that is, the LM softly predicts this concept. In this work, we take this formulation to the extreme by defining it as a Dirac delta distribution concentrated on the right concept, that is given the right concept \u03b8\u2217, we set p(\u03b8\u2217| . . .) = 1 and zero everywhere else. For semantic text classification tasks, we argue that the right concepts can be specified in natural language and hence, the demonstrations may not be necessary. The label\nprediction probability is thus reduced to,\npLM(y|x1, y1, . . . ,xk, yk,x) \u2248 pLM(y|x, \u03b8\u2217) This describes zero-shot inference contextualized on the concepts. In this work, we experiment with many different kinds of contexts and their influence on text classification performance such as those describing the domain, source, author, or audience of the input text among others (\u00a73)."
        },
        {
            "heading": "2.2 MULTIVARIATE GENERATIVE CLASSIFICATION",
            "text": "The approach discussed so far describes a discriminative classifier, which predicts the label as y\u0302 = argmaxyi\u2208Y p(yi|x). They are designed to distinguish the correct label among possible choices. A generative classification framework reinterprets this objective using Bayes\u2019 rule and a different factorization as\ny\u0302 = argmax yi\np(x, yi)\np(x)\n= argmax yi\np(x|yi)p(yi)\nHere the denominator p(x) is independent of the label and can be ignored. Further, assuming equal prior probability of all labels, p(yi) can also be ignored making the classification objective argmaxyi p(x|yi). In a generative setup, we assume a label is generated first (e.g., an author decides to write a negative review), and then the text (e.g., the negative review) is produced conditioned on the label. Prior work has shown evidence that generative classifiers can be more robust than the discriminative ones which may look for shortcuts to predict the label (Yogatama et al., 2017).\nTo incorporate contextual information \u03b8\u2217, we propose multivariate generative classification which generalizes it to more variables that might influence the generative process of the input text, expressing the generative probability of x as p(x|y, u, v, . . .), where \u03b8\u2217 = u, v, . . . represent the additional factors. For example, to generate a review, not only is the author influenced by the polarity but also by the item they review, the medium where they write the review, their target audience, their writing style, and so on. Similar context can also be added to a discriminative classifier p(y|x, u, v, . . .) which is one of our baselines."
        },
        {
            "heading": "2.3 CONTEXTUALIZED LABEL DESCRIPTIONS",
            "text": "In practice, as introduced in (Brown et al., 2020), language models can be used in a zero-shot setup by computing pLM(z(yi)|x) or in our case, pLM(x|z(yi, u, v, . . .)). Here, z(\u00b7) is referred to as a verbalizer which expresses the label in natural language form so that meaningful probabilities can be computed. In this work, since the verbalizers are only concerned with the label, we refer to them as label descriptions. A simple example is \u201cThis is terrible.\u201d and \u201cThis is amazing.\u201d for negative and positive label respectively. The choice of this description, however, can lead to large variance in the model performance with downstream classification performance can range from near perfect to near chance (Liu et al., 2023; Holtzman et al., 2021; Zhao et al., 2021).\nTo reduce this variance, we propose to use multiple variations of the descriptions z. More formally, we modify the generative story as: the labels and other contextual variables generate label descriptions z which then inform the generation of the text (see Figure 1),\np(yi|x, u, v, . . .) \u221d p(x, yi|u, v, . . .) = \u2211\nzi\u2208Z(yi,u,v,...)\np(x, yi, zi|u, v, . . .)\n= \u2211\nzi\u2208Z(yi,u,v,...)\np(x|yi, zi, u, v, . . .)p(z|yi, u, v, . . .)p(yi|u, v, . . .)\nHere, Z(yi, u, v, . . .) denotes the set of all ways to describe the label yi and the context in natural language1. p(z|yi, u, v, . . .) measures the existence probability of the description2. Since each\n1We show that \u223c10 diverse paraphrases of the description are sufficient to obtain good performance. 2Note that we are not measuring grammatical plausibility of a description, hence measure p(z|\u00b7) using an\nLM is not appropriate in this setting.\ndescription is equally plausible to exist given the label yi and other variables, we drop p(zi|yi, u, v, . . .) (see Figure 1 right). Further, assuming independence of the label and the contextual factors3 and equal prior likelihood of all labels, we also drop p(yi|u, v, . . .).4 Hence, the first term in the summation can be reduced to \u2211 zi p(x|zi), which is our inference objective, where we evaluate the probabilities using the conditional probabilities of the LM. We compute this term for each label under consideration yi and predict the label which obtains the highest value. Notably, unlike common prompting scenarios, the label descriptions, zi, are unique for each label yi being considered and can be specialized by adding any available information about the instance in natural language format. We refer to our approach as GEN-Z for Generative Zero-Shot Classification."
        },
        {
            "heading": "3 EXPERIMENTAL SETUP",
            "text": "Datasets, Models, and Label Descriptions We evaluate on 18 text classification datasets encompassing diverse tasks, domains, and difficulty levels. These datasets include varying numbers of classes and attributes that can be used as additional context to improve the classification performance. We consider all contexts that were provided with each dataset. We consider the following tasks divided in to two groups: (1) sentiment, topic, and hate speech detection which in addition to the input text are accompanied by information about the domain, source or subject of the input text. For example, hate speech datasets which contain information about the source (such as Reddit or Twitter) and the subject of hate (such as national origin or race); and (2) politeness, and empowerment prediction which are pragmatic tasks that depend on social variables such as demographic information of the author, addressee, or the reader (such as gender, age, educational background, etc.). Table 4 in the appendix summarizes the details of each dataset we use. We measure performance using publicly available validation or test sets, without using the training data at all. We experiment with the six classes of open-source models: GPT2 (Small, Medium, Large, and XL) (Radford et al., 2019), OPT (Zhang et al., 2022)(1.4B and 2.7B), Pythia (Biderman et al., 2023) (1.4B, 2.8B and 6.7B), GPT-J (6B) (Wang & Komatsuzaki, 2021), Llama 1 (Touvron et al., 2023a) (7B and 13B) and Llama 2 (Touvron et al., 2023b) (7B and 13B).5 All these models are pretrained on only raw text without additional fine-tuning on supervised datasets.6\nFor each task, we manually write one minimal label description per label using a template (see complete list in Table 5). We then generate 20 paraphrases of each label description by querying ChatGPT.7 This process needs to be done only once for each task and, in practice, any paraphrasing model can be employed. We further manually verify the correctness of each paraphrase. For each dataset, we run the evaluation ten times where in each run we subsample 1 \u2264 n \u2264 10 paraphrases from this set. We evaluate all methods using macro-F1 score and report mean and standard deviation across these runs.\nBaselines We compare GEN-Z with the following zero-shot baselines. \u2022 Discriminative methods predict the label using \u2211\nzi p(zi|x). We consider three versions of this\nbaseline. DISC-SINGLE-NC predicts the label with no context (the context information is removed from zi) and only one description is considered. This is the simplest zero-shot setup that most prior work considers canonical. DISC-SINGLE predicts the label using p(zi|x) where zi corresponds to only one description. DISC-MULTIPLE predicts the label using \u2211 zi p(zi)|x) which is the discriminative version of our proposed method. For the last two baselines, we further have three\n3The true prior probability of any label is unlikely to depend on the contextual factors like the domain of the text, or the personal attributes of the user reading, writing, or being described in the text.\n4While we make this assumption for simplification, future work may consider non-uniform priors to further improve performance.\n5We do not report results with 70B sized models to due to its high computational requirements for the scale of our experiments. While quantization (Dettmers et al., 2023) approaches have been proposed to run models of this scale on consumer hardware, in our initial exploration such approaches vastly underperformed 16-bit versions for our experiments. Further, our budget prohibits us from experimenting with closed-source models like GPT3 which according to Lyu et al. (2023) can cost more than 4500 USD for the scale of our experiments. We leave these explorations for future work.\n6Instruction-tuned models have shown to also perform well in-context but they are trained primarily as discriminative classifiers and thus cannot be used for generative classification making comparisons unfair.\n7We used the free tier of ChatGPT for this purpose: https://chat.openai.com/chat.\nversions of each which differ in how the context is provided (only in the label, before the input, and before the input as an instruction; more details in Appendix B. We report results with the first version in the main paper as it performs the best of the three.). \u2022 Calibrated discriminative methods use p(zi|x)/p(zi|NULL) for label inference (we use BOS token for the corresponding LMs as NULL). Since language model probabilities can be poorly calibrated and suffer from competition between different label descriptions with the same meaning, this method relies on pointwise mutual information (PMI) between x and y to make a prediction (Holtzman et al., 2021). We again consider three versions of this setup: without context (DISC-PMI-NC), with context but only one label description (DISC-PMI), and with context and multiple label descriptions (DISC-PMI-MULTIPLE). The last one is the calibrated discriminative version of our proposed method. \u2022 Generative baselines predicts the label using p(x|zi), that is using only one label description. We consider two versions of this baseline, one without context (GEN-SINGLE-NC) and one with context (GEN-SINGLE) in the label description. Both of these are an ablation of our proposed method. The former method (without context) also describes the method proposed in Min et al. (2022a).\nIn addition, we show comparisons with the following baselines which incorporate context implicitly either via few-shot examples or using retrieval based techniques on unlabeled data. For these baselines, we experiment with 8- and 16-shot settings and report the best of the two.\n\u2022 ICL describes in-context learning baselines. We consider four versions of this baseline: (a) ICLDISC, a simple discriminative method which compares probabilities of label descriptions, (b) ICL-GEN, a generative baseline with the exact same setup (Min et al., 2022a), (c) ICL-PMI which calibrates the probabilities same as DISC-PMI, (d) ICL-DC which is another discriminative calibration method introduced in Fei et al. (2023b). \u2022 Z-ICL (Lyu et al., 2023) describes a psuedo-demonstration based setup where unlabeled texts are sampled from a corpus and assigned random labels. This setup is zero-shot but still requires access to a corpus. For this setup, we reproduce the setup proposed in and report both discriminative and generative results."
        },
        {
            "heading": "4 RESULTS",
            "text": "We categorize the results into two groups: domain-aware classification, which considers the domain of the text as an additional factor, and personalized classification, which includes personal attributes of writers and readers as additional factors.\nTable 2: Best of 8/16 shot baselines vs Gen-Z (zero-shot). We report averagestd over 5 seeds.\nICL (Disc) ICL (CC) ICL (DC) ICL (Gen) Z-ICL (Disc) Z-ICL (Gen) GEN-Z (Ours) SST2 91.0(6.0) 90.8(3.2) 94.0(1.3) 88.8(1.3) 82.6(0.2) 82.6(0.2) 91.7(0.2) CR 81.4(6.9) 86.5(0.8) 87.0(4.0) 84.4(2.8) 78.8(0.4) 80.1(0.1) 87.0(0.2) MR 93.1(0.7) 91.3(1.1) 93.1(0.5) 84.0(6.8) 81.0(0.3) 81.9(0.1) 87.0(0.2) SST5 42.9(0.9) 40.8(5.4) 40.3(4.9) 42.9(0.9) 30.9(0.3) 38.7(0.5) 40.9(0.5) FP 46.4(6.9) 46.7(4.2) 61.6(3.3) 43.3(2.3) 44.9(3.0) 51.1(1.2) 52.9(1.1) PS 26.6(6.1) 25.5(5.2) 31.4(3.0) 39.8(2.1) 39.5(4.0) 43.9(2.7) 42.4(1.2) AGNews 68.4(9.9) 76.8(7.2) 81.5(5.1) 72.3(3.2) 67.2(1.3) 75.2(0.5) 77.0(0.1) DBpedia 83.5(3.0) 90.6(1.7) 92.4(1.2) 79.9(3.8) 61.3(0.6) 74.9(3.6) 80.1(0.2) HS18 51.5(4.7) 41.6(8.6) 57.3(2.5) 45.0(0.5) 43.4(0.6) 51.1(0.7) 62.6(0.3) E (Religion) 30.7(14.3) 28.0(13.8) 43.8(6.7) 67.9(1.8) 51.0(2.6) 51.0(2.6) 70.1(0.9) E (NO) 23.1(8.7) 18.2(2.1) 40.7(7.8) 37.6(3.5) 37.6(3.5) 26.2(1.1) 56.3(0.8) E (Race) 36.4(11.8) 44.7(17.4) 51.4(6.4) 49.1(3.0) 46.3(1.2) 39.7(3.5) 60.5(1.3)"
        },
        {
            "heading": "4.1 DOMAIN-AWARE CLASSIFICATION",
            "text": "Table 1 shows the comparison of the performance of different zero-shot methods on sentiment, topic, emotion, and hate speech classification for GPT-J. Table 2 shows comparisons of GEN-Z with the few-shot baselines. The remaining results are reported in Appendix C.\nWe find that GEN-Z overall outperforms all baselines approaches in the zero-shot setting. We do not see a clear trend in the simple discriminative baselines (DISC-SIMPLE-NC, DISC-SIMPLE, and DISC-MULTIPLE) where adding contexts and multiple descriptions sometimes help and sometimes hurts performance. In the calibrated discriminative baselines, the trends become clearer. The no-context version outperforms simple discriminative baselines as it accounts for surface form competition. Adding context also helps but adding multiple label descriptions does not always improve performance. We see this trend also in our full results where we range the number of label descriptions from 1 to 10. The generative baseline without context and a single description (Min et al., 2022a, GEN-SIMPLE-NC) outperforms most discriminative approaches and adding context leads to even more improvements confirming the efficacy of our method.\nFurthermore, GEN-Z in a zero-shot setting is either best or second best performing method when compared to strong few-shot baselines on sentiment and hate-speech detection (Table 1). One particular dataset where our method lags behind is Dbpedia topic classification where the label set consists of 14 classes. Our qualitative analysis reveals that most errors made by our approach correspond to three classes with semantic overlap (Album, Film, Written Work) which given our simplistic label descriptions make it difficult for the model to distinguish. This requires further investigations into the specificity of the descriptions which we leave for future work. Finally, compared to all baselines GEN-Z shows the smallest variance in performance due to prompt selection by aggregating over multiple prompt paraphrases, whereas few-shot baselines exhibit large deviations.\nWe additionally conduct ablation studies to assess the impact of each proposed component on performance. While some of these ablations we used for baseline comparisons in Table 1, here we give them a more thorough treatment comparing performance across multiple model sizes.\nEffect of number of label descriptions. In this ablation, we vary the number of label descriptions over which the aggregation is perform from l=1 to l=10 and observe the change in performance. For each l, we do this evaluation 10 times and report the averaged mean and standard deviation across all 17 tasks. We find that in the generative classification settings, in the majority of cases, increasing the number of label descriptions improves the model performance highlighting the utility of this approach. Further, we observe that the performance starts to stabilize between k=6 and k=10 which suggests that not many descriptions are required overall. In contrast, for discriminative baselines in all three versions we considered, we observe no clear trend as increasing k often results in a decrease in performance.\nEffect of additional variables. To measure the effect of provided contextual information (domains, subject, data source), we conduct ablation by modifying the label description to exclude this information across different number of label descriptions (similar to GEN-SIMPLE-NC and DISC-SIMPLE-NC). We report the full results in Appendix C. We observe a significant drop in\nthe performance across all tasks if we remove the domain or data source information including our method as well as the baselines. This drop is more significant in larger models. We hypothesize that specifying the domain information helps prime the model probabilities to the right distributional landscape allowing more meaningful comparisons between probabilities assigned to different labels. Further, we hypothesize that in a generative classification setting, the label followed by the input text, resemble natural data found in pretraining whereas it is difficult to specify this information in a discriminative setup.\nEffect of model size. We measure if the presented results holds across model scales. We repeat the same experiment across 14 more models with size ranging from 125M to 13B. We find that with GEN-Z, across reasonably large models, going larger improves performance on average. We see substantial improvement from GPT2-M to L to XL, and Pythia 1.4B to 2.7B and 6.7B to 12B.8 The trend is reversed for the Llama2 models where the 13B models performs slightly worse overall and warrants further investigation.\nAblation on aggregation strategy In GEN-Z, we aggregate the probabilities obtained using different label descriptions by simply summing them (which is the same as their arithmetic mean, for comparison purposes). This aggregation is theoretically grounded in the probabilistic framework we design (Figure 1). Prior work has considered several other aggregation strategies for ensembling model outputs that we compare with in this ablation. We compare against geometric mean (or arithmetic mean of the log probabilities, the most common way to aggregate model outputs) and harmonic mean. We find that in our proposed generative setup, the performance across three aggregation strategies is\n8The performance is not strictly comparable across model families due to differences in pretraining corpora.\nlargely similar, arithmetic mean outperforming the other two slightly overall with harmonic mean winning out in smaller models. We hypothesize that this effect is due to harmonic mean\u2019s property of ignoring outliers. Future work may analyze this strategy in-depth. For the discriminative setup, arithmetic mean almost always performs the best. Peculiarly, harmonic means shows sharp decrease in performance with increasing descriptions and warrants further investigation which we leave to future work."
        },
        {
            "heading": "4.2 PERSONALIZED CLASSIFICATION",
            "text": "In this setup, we evaluate our proposed approach on two datasets where personal information about the author, the addressee, or even the audience may affect the prediction. We experiment with two tasks: (1) empowerment prediction (Njoo et al., 2023) where given a Reddit comment, the goal is to predict whether it empowers or disempowers (or is condescending to) the addressee of the comment. We use the author\u2019s and the addressee\u2019s gender in this task9. (2) Politeness prediction (Pei & Jurgens, 2023) where given an email snippet the goal is to predict whether it is polite or not. We again consider binary labels. What is considered polite may vary with the reader dependent on cultural factors. This dataset consists of information about the annotator\u2019s age, gender, race, and educational background. We focus on age and educational background as they were the primary delineators of variation measured by the authors. That is given the author\u2019s age and educational background, we predict the perceived politeness of the text and sum their probabilities to make the final predictions. We do not aggregate these probabilities over each possible value of age and educational background but rather use only the ones reported in the test set. The results for both datasets for GPT2-Large are reported in\nTable 310. We only report the results for our proposed approach with varying number of personal attributes considered, as discriminative models performed poorly in this setup (<50% accuracy across both tasks). We find that for both test sets, personalizing the predictions with demographic variables helps improve performance. For empowerment prediction, the gender of the addressee, and politeness, the age of the annotator affect the performance more than the other variables. The latter is consistent with prior studies that show cultural differences in politeness across different age groups (Pei & Jurgens, 2023)."
        },
        {
            "heading": "5 RELATED WORK",
            "text": "In-context learning In-context learning (ICL) is the standard paradigm for prompting LMs to perform tasks (Brown et al., 2020; Liu et al., 2023).Much recent work has been done to understand why it works and how it can be improved. For example, Xie et al. (2022); Wang et al. (2023); Dai et al. (2023) have argued that it implements general-purpose learning mechanisms such as Bayesian inference or gradient descent. Min et al. (2022b) showed that for classification tasks, the input-label pairing format plays the most crucial role in ICL. We build on these findings and develop a zero-shot inference approach. While in-context learning with more example has usually performed than zeroshot inference, it comes at the cost of more token consumption and may hit the context length limit when the input and output text are long. The choice of demonstrations can lead to high variance in the model performance (Zhao et al., 2021; Fei et al., 2023a; Han et al., 2023) and prior work has investigated various demonstration selection- and ordering strategies to boost performance (Lu, 2022).\n9We use binary gender here; the evaluation set does not contain any other information 10The results for other models can be found in Appendix C\nIn this work, we show that the zero-shot setting is underexplored and can surpass in-context learning for text classification tasks.\nRecent work has also studied instruction following in models, either directly on a pretrained language model or by fine-tuning it to follow instructions using a collection of NLP tasks framed as instruction following tasks (Wei et al., 2022). Instructions and few-shot learning can also be used together. Again, depending on how instructions are phrased, however, can significantly alter the model outputs, even in instruction fine-tuned models (Sun et al., 2023). In contrast, several studies have also developed prompt engineering techniques, that is creating a sequence of prefix tokens or prompts that increase the probability of getting desired output given input (Liu et al., 2023). These techniques rely on available training data for each task. In this work, we focus on a zero-shot prompting setup operating in a setting where no training data for customizing classification models is available.\nDiscriminative versus Generative Classification Text classification studies with prompting have primarily focused on discriminative classification, which focuses on constructing input prompts that get prepended to each input text to predict the classification label. That is conditioning on the input to generate the output. Generative or noisy channel models (Brown et al., 1993) have been previously investigated for various NLP tasks, such as machine translation (Yamada & Knight, 2001; Yee et al., 2019) and question answering (Lewis & Fan, 2019). Prior work has empirically demonstrated that generative models are more robust to distribution shift in text classification than discriminative models (Yogatama et al., 2017). Recently, Min et al. (2022a) explored the use of a generative model with prompting, leveraging pretrained language models for various text classification tasks. In this work, we build a multivariate generative classification by incorporating label descriptions. These descriptions capture various contextual information associated with each example, allowing for effective priming and customization of the classifier.\nSocial and personal factors in NLP Machine learning systems have been shown to reflect and amplify social prejudices in human-written text, resulting in systemic biases in performance towards specific demographic groups (Mehrabi et al., 2021). Such classifiers learn spurious correlations between the label and the demographic information reflected in text either explicitly through their mentions in the text (such as names, sexuality, and race among others) or their writing style. These issues are exacerbated through annotation artifacts (Sap et al., 2019; 2022) or unbalanced datasets (Kiritchenko & Mohammad, 2018). Various solutions proposed in the literature aim to learn models that are fair to all demographics using methods like adversarial learning (Han et al., 2021a;b) and distributionally robust optimization (Zhou et al., 2021). A distinct but closely related motivation towards developing such solutions is user privacy\u2014models should never use any personally identifiable attributes to make any predictions as it could lead to unintended negative consequences (Elazar & Goldberg, 2018). Ravfogel et al. (2020; 2022) propose methods to scrub demographic information from model representations given a trained model with little loss in model accuracy.\nIn contrast, few studies have shown that incorporating factors such as gender, age, region, or country of the authors as features can improve text classification performance (Volkova et al., 2013; Hovy, 2015; Yang & Eisenstein, 2017; Lynn et al., 2017; Huang & Paul, 2019). Most of these studies are based on the assumption that social and personal factors are causally related to both the writing style and the target label. As a result, they treat classification as a domain adaptation problem in which demographic attributes divide the data distribution into different domains."
        },
        {
            "heading": "6 CONCLUSIONS",
            "text": "We introduce GEN-Z, a robust generative zero-shot text classification framework that seamlessly incorporates contextual information beyond the input text itself. GEN-Z leverages LM likelihood of generating the input text based on various label descriptions that reflect context, enabling more robust predictions than discriminative approaches. We evaluate our framework across two task categories: domain-aware classification and personalized classification, covering 19 diverse text classification datasets with varying tasks, domains, and difficulty levels, alongside multiple label description paraphrases. Our experiments show that GEN-Z consistently improves classification performance over zero-shot baselines and performs on par with strong few-shot baselines. Further, we show that this approach allows personalizing predictions by incorporating contextual information from label descriptions.\nLIMITATIONS\nThe generalizability of our paper\u2019s findings to languages other than English may be limited since all the datasets used in our study are exclusively in English. We make simplifying assumptions about prior probabilities of labels and independence of labels and contextual factors, which may not always hold in practice. We acknowledge that certain demographic attributes in our work may not fully represent the entire population. For example, due to data availability, we only conducted experiments with binary gender (male/female) for user information, despite the existence of diverse genders. Additionally, the definition and categorization of social attributes in the datasets used in our experiments might predominantly reflect Western-centric perspectives, as the majority of the work involved in designing and creating such datasets aligns with Western-centric viewpoints. Lastly, while our experiments encompass a diverse range of text classification tasks, we have not evaluated its performance on other kinds of tasks like sentence pair classification, question answering, etc. We leave these evaluations for future wrok.\nETHICS STATEMENT\nPersonalization presents complex ethical considerations, with both benefits and potential risks. On the one hand, models tailored to specific settings or groups can yield positive outcomes. However, these personalized models may inadvertently reinforce biases or result in discriminatory behavior if their performance is uneven across different groups. Moreover, privacy concerns arise as end users may be reluctant to have certain attributes or personal information, such as their sexual orientation or religion, considered by the model. We believe our approach of using label description can mitigate such ethical concerns, particularly in comparison to embedding-based personalization methods. By employing interpretable user information through label descriptions, our method fosters transparency and controllability throughout the entire personalization process. This mitigates potential issues related to privacy and allows users to have insight into how their information is used. Nevertheless, it is important to acknowledge potential cases of misuse, where individuals intentionally modify their user attributes to game the model and achieve desired labels. Such scenarios highlight the need for future research on mitigating abuse and maintaining the integrity of the personalization framework."
        },
        {
            "heading": "A CONNECTION TO SURFACE FORM COMPETITION",
            "text": "Discriminative classification from language models have been shown to suffer from \u201csurface form competition\u201d where multiple surface forms of the label yi may compete for probability mass. To address this issue, Holtzman et al. (2021); Zhao et al. (2021) proposed calibrating the probability by using point-wise mutual information (PMI) between the text and the label as the scoring function, which is given as, y\u0302 = argmaxyi p(x,yi) p(x)p(yi)\n. While these works have simplified PMI as p(yi|x)/p(yi), an alternative way to simplify it is p(x|yi)/p(x) which is the same as the generative classification setup as described above."
        },
        {
            "heading": "B ADDITIONAL EXPERIMENTAL DETAILS",
            "text": "Discriminative Baselines Variations For each discriminative zero-shot baseline, we consider three variations (see Table 6): (1) DISC-NONE does not condition the input text on contextual variables, (2) DISC-CONTEXT conditions the input text on the contextual variables using a simple format, (3) DISC-INSTRUCT conditions the input text on the contextual variables as well as the labels that the model is expected to predict. In the main paper, we present results with DISC-NONE, which performs best out of these variations.\nTable 4 summarizes all the datasets we use. Table 5 summarizes the hand written templates we start with (and later paraphrase to construct label descriptions)."
        },
        {
            "heading": "C ADDITIONAL RESULTS",
            "text": "We provide averaged macro-F1 for each of the models and each zero-shot method we consider in\nFigures 3,4,5,6,7, 8, 9, 10"
        }
    ],
    "title": "GEN-Z: GENERATIVE ZERO-SHOT TEXT CLASSIFICA-",
    "year": 2023
}