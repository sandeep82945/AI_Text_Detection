{
    "abstractText": "We study both stream-based and pool-based active learning with neural network approximations. A recent line of works proposed bandit-based approaches that transformed active learning into a bandit problem, achieving both theoretical and empirical success. However, the performance and computational costs of these methods may be susceptible to the number of classes, denoted as K, due to this transformation. Therefore, this paper seeks to answer the question: \"How can we mitigate the adverse impacts of K while retaining the advantages of principled exploration and provable performance guarantees in active learning?\" To tackle this challenge, we propose two algorithms based on the newly designed exploitation and exploration neural networks for stream-based and pool-based active learning. Subsequently, we provide theoretical performance guarantees for both algorithms in a non-parametric setting, demonstrating a slower error-growth rate concerning K for the proposed approaches. We use extensive experiments to evaluate the proposed algorithms, which consistently outperform state-of-the-art baselines.",
    "authors": [],
    "id": "SP:22b01ecce91e8af8549beec02ebce36aa1dac078",
    "references": [
        {
            "authors": [
                "Yasin Abbasi-Yadkori",
                "D\u00e1vid P\u00e1l",
                "Csaba Szepesv\u00e1ri"
            ],
            "title": "Improved algorithms for linear stochastic bandits",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2011
        },
        {
            "authors": [
                "Naoki Abe",
                "Philip M Long"
            ],
            "title": "Associative reinforcement learning using linear probabilistic concepts",
            "venue": "In ICML, pp. 3\u201311. Citeseer,",
            "year": 1999
        },
        {
            "authors": [
                "Zeyuan Allen-Zhu",
                "Yuanzhi Li",
                "Zhao Song"
            ],
            "title": "A convergence theory for deep learning via over-parameterization",
            "venue": "In International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "Sanjeev Arora",
                "Simon S Du",
                "Wei Hu",
                "Zhiyuan Li",
                "Russ R Salakhutdinov",
                "Ruosong Wang"
            ],
            "title": "On exact computation with an infinitely wide neural net",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Jordan Ash",
                "Surbhi Goel",
                "Akshay Krishnamurthy",
                "Sham Kakade"
            ],
            "title": "Gone fishing: Neural active learning with fisher embeddings",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Jordan T Ash",
                "Chicheng Zhang",
                "Akshay Krishnamurthy",
                "John Langford",
                "Alekh Agarwal"
            ],
            "title": "Deep batch active learning by diverse, uncertain gradient lower bounds",
            "year": 1906
        },
        {
            "authors": [
                "Pranjal Awasthi",
                "Maria Florina Balcan",
                "Philip M Long"
            ],
            "title": "The power of localization for efficiently learning linear separators with noise",
            "venue": "In Proceedings of the forty-sixth annual ACM symposium on Theory of computing,",
            "year": 2014
        },
        {
            "authors": [
                "Maria-Florina Balcan",
                "Phil Long"
            ],
            "title": "Active and passive learning of linear separators under log-concave distributions",
            "venue": "In Conference on Learning Theory,",
            "year": 2013
        },
        {
            "authors": [
                "Yikun Ban",
                "Yunzhe Qi",
                "Tianxin Wei",
                "Jingrui He"
            ],
            "title": "Neural collaborative filtering bandits via meta learning",
            "venue": "ArXiv abs/2201.13395,",
            "year": 2022
        },
        {
            "authors": [
                "Yikun Ban",
                "Yuchen Yan",
                "Arindam Banerjee",
                "Jingrui He"
            ],
            "title": "EE-net: Exploitation-exploration neural networks in contextual bandits",
            "venue": "In International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Yikun Ban",
                "Yuheng Zhang",
                "Hanghang Tong",
                "Arindam Banerjee",
                "Jingrui He"
            ],
            "title": "Improved algorithms for neural active learning",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Yuan Cao",
                "Quanquan Gu"
            ],
            "title": "Generalization bounds of stochastic gradient descent for wide and deep neural networks",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Rui M Castro",
                "Robert D Nowak"
            ],
            "title": "Minimax bounds for active learning",
            "venue": "IEEE Transactions on Information Theory,",
            "year": 2008
        },
        {
            "authors": [
                "Gui Citovsky",
                "Giulia DeSalvo",
                "Claudio Gentile",
                "Lazaros Karydas",
                "Anand Rajagopalan",
                "Afshin Rostamizadeh",
                "Sanjiv Kumar"
            ],
            "title": "Batch active learning at scale",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Gregory Cohen",
                "Saeed Afshar",
                "Jonathan Tapson",
                "Andre Van Schaik"
            ],
            "title": "Emnist: Extending mnist to handwritten letters",
            "venue": "In 2017 international joint conference on neural networks (IJCNN),",
            "year": 2017
        },
        {
            "authors": [
                "David A Cohn",
                "Zoubin Ghahramani",
                "Michael I Jordan"
            ],
            "title": "Active learning with statistical models",
            "venue": "Journal of artificial intelligence research,",
            "year": 1996
        },
        {
            "authors": [
                "Sanjoy Dasgupta",
                "Daniel J Hsu",
                "Claire Monteleoni"
            ],
            "title": "A general agnostic active learning algorithm",
            "venue": "Advances in neural information processing systems,",
            "year": 2007
        },
        {
            "authors": [
                "Ofer Dekel",
                "Claudio Gentile",
                "Karthik Sridharan"
            ],
            "title": "Selective sampling and active learning from single and multiple teachers",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2012
        },
        {
            "authors": [
                "Giulia DeSalvo",
                "Claudio Gentile",
                "Tobias Sommer Thune"
            ],
            "title": "Online active learning with surrogate loss functions",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Bo Du",
                "Zengmao Wang",
                "Lefei Zhang",
                "Liangpei Zhang",
                "Wei Liu",
                "Jialie Shen",
                "Dacheng Tao"
            ],
            "title": "Exploring representativeness and informativeness for active learning",
            "venue": "IEEE transactions on cybernetics,",
            "year": 2015
        },
        {
            "authors": [
                "Dylan Foster",
                "Alexander Rakhlin"
            ],
            "title": "Beyond ucb: Optimal and efficient contextual bandits with regression oracles",
            "venue": "In International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Claudio Gentile",
                "Zhilei Wang",
                "Tong Zhang"
            ],
            "title": "Achieving minimax rates in pool-based batch active learning",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Steve Hanneke"
            ],
            "title": "A bound on the label complexity of agnostic active learning",
            "venue": "In Proceedings of the 24th international conference on Machine learning,",
            "year": 2007
        },
        {
            "authors": [
                "Steve Hanneke"
            ],
            "title": "Adaptive rates of convergence in active learning",
            "venue": "In COLT. Citeseer,",
            "year": 2009
        },
        {
            "authors": [
                "Steve Hanneke"
            ],
            "title": "Theory of disagreement-based active learning",
            "venue": "Foundations and Trends\u00ae in Machine Learning,",
            "year": 2014
        },
        {
            "authors": [
                "Wei-Ning Hsu",
                "Hsuan-Tien Lin"
            ],
            "title": "Active learning by learning",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2015
        },
        {
            "authors": [
                "Arthur Jacot",
                "Franck Gabriel",
                "Cl\u00e9ment Hongler"
            ],
            "title": "Neural tangent kernel: Convergence and generalization in neural networks",
            "venue": "In Advances in neural information processing systems,",
            "year": 2018
        },
        {
            "authors": [
                "Yoon-Yeong Kim",
                "Kyungwoo Song",
                "JoonHo Jang",
                "Il-chul Moon"
            ],
            "title": "Lada: Look-ahead data acquisition via augmentation for deep active learning",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Vladimir Koltchinskii"
            ],
            "title": "Rademacher complexities and bounding the excess risk in active learning",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2010
        },
        {
            "authors": [
                "Aryeh Kontorovich",
                "Sivan Sabato",
                "Ruth Urner"
            ],
            "title": "Active nearest-neighbor learning in metric spaces",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2016
        },
        {
            "authors": [
                "Lihong Li",
                "Wei Chu",
                "John Langford",
                "Robert E Schapire"
            ],
            "title": "A contextual-bandit approach to personalized news article recommendation",
            "venue": "In Proceedings of the 19th international conference on World wide web,",
            "year": 2010
        },
        {
            "authors": [
                "Zhuoming Liu",
                "Hao Ding",
                "Huaping Zhong",
                "Weijia Li",
                "Jifeng Dai",
                "Conghui He"
            ],
            "title": "Influence selection for active learning",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Andrea Locatelli",
                "Alexandra Carpentier",
                "Samory Kpotufe"
            ],
            "title": "Adaptivity to noise parameters in nonparametric active learning",
            "venue": "In Proceedings of the 2017 Conference on Learning Theory, PMLR,",
            "year": 2017
        },
        {
            "authors": [
                "Enno Mammen",
                "Alexandre B Tsybakov"
            ],
            "title": "Smooth discrimination analysis",
            "venue": "The Annals of Statistics,",
            "year": 1999
        },
        {
            "authors": [
                "Stanislav Minsker"
            ],
            "title": "Plug-in approach to active learning",
            "venue": "Journal of Machine Learning Research,",
            "year": 2012
        },
        {
            "authors": [
                "Jooyoung Moon",
                "Jihyo Kim",
                "Younghak Shin",
                "Sangheum Hwang"
            ],
            "title": "Confidence-aware learning for deep neural networks",
            "venue": "In international conference on machine learning,",
            "year": 2020
        },
        {
            "authors": [
                "Eliya Nachmani",
                "Yair Be\u2019ery",
                "David Burshtein"
            ],
            "title": "Learning to decode linear codes using deep learning",
            "venue": "In 2016 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton),",
            "year": 2016
        },
        {
            "authors": [
                "Aldo Pacchiano",
                "My Phan",
                "Yasin Abbasi Yadkori",
                "Anup Rao",
                "Julian Zimmert",
                "Tor Lattimore",
                "Csaba"
            ],
            "title": "Szepesvari. Model selection in contextual stochastic bandit problems",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Remus Pop",
                "Patric Fulop"
            ],
            "title": "Deep ensemble bayesian active learning: Addressing the mode collapse issue in monte carlo dropout via ensembles",
            "venue": "arXiv preprint arXiv:1811.03897,",
            "year": 2018
        },
        {
            "authors": [
                "Pengzhen Ren",
                "Yun Xiao",
                "Xiaojun Chang",
                "Po-Yao Huang",
                "Zhihui Li",
                "Brij B Gupta",
                "Xiaojiang Chen",
                "Xin Wang"
            ],
            "title": "A survey of deep active learning",
            "venue": "ACM computing surveys (CSUR),",
            "year": 2021
        },
        {
            "authors": [
                "Ozan Sener",
                "Silvio Savarese"
            ],
            "title": "Active learning for convolutional neural networks: A core-set approach",
            "venue": "arXiv preprint arXiv:1708.00489,",
            "year": 2017
        },
        {
            "authors": [
                "Burr Settles"
            ],
            "title": "Active learning literature survey",
            "year": 2009
        },
        {
            "authors": [
                "Wei Tan",
                "Lan Du",
                "Wray Buntine"
            ],
            "title": "Diversity enhanced active learning with strictly proper scoring rules",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Dan Wang",
                "Yi Shang"
            ],
            "title": "A new active labeling method for deep learning",
            "venue": "In 2014 International joint conference on neural networks (IJCNN),",
            "year": 2014
        },
        {
            "authors": [
                "Haonan Wang",
                "Wei Huang",
                "Andrew Margenot",
                "Hanghang Tong",
                "Jingrui He"
            ],
            "title": "Deep active learning by leveraging training dynamics",
            "venue": "arXiv preprint arXiv:2110.08611,",
            "year": 2021
        },
        {
            "authors": [
                "Haonan Wang",
                "Wei Huang",
                "Ziwei Wu",
                "Hanghang Tong",
                "Andrew J Margenot",
                "Jingrui He"
            ],
            "title": "Deep active learning by leveraging training dynamics",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Zhilei Wang",
                "Pranjal Awasthi",
                "Christoph Dann",
                "Ayush Sekhari",
                "Claudio Gentile"
            ],
            "title": "Neural active learning with performance guarantees",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Han Xiao",
                "Kashif Rasul",
                "Roland Vollgraf"
            ],
            "title": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms, 2017",
            "year": 2017
        },
        {
            "authors": [
                "Donggeun Yoo",
                "In So Kweon"
            ],
            "title": "Learning loss for active learning",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Chicheng Zhang"
            ],
            "title": "Efficient active learning of sparse halfspaces",
            "venue": "In Conference on Learning Theory, pp. 1856\u20131880",
            "year": 2018
        },
        {
            "authors": [
                "Chicheng Zhang",
                "Yinan Li"
            ],
            "title": "Improved algorithms for efficient active learning halfspaces with massart and tsybakov noise",
            "venue": "In Conference on Learning Theory,",
            "year": 2021
        },
        {
            "authors": [
                "Chicheng Zhang",
                "Jie Shen",
                "Pranjal Awasthi"
            ],
            "title": "Efficient active learning of sparse halfspaces with arbitrary bounded noise",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Yuheng Zhang",
                "Hanghang Tong",
                "Yinglong Xia",
                "Yan Zhu",
                "Yuejie Chi",
                "Lei Ying"
            ],
            "title": "Batch active learning with graph neural networks via multi-agent deep reinforcement learning",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Fedor Zhdanov"
            ],
            "title": "Diverse mini-batch active learning",
            "venue": "arXiv preprint arXiv:1901.05954,",
            "year": 2024
        },
        {
            "authors": [
                "Dongruo Zhou",
                "Lihong Li",
                "Quanquan Gu"
            ],
            "title": "Neural contextual bandits with ucb-based exploration",
            "venue": "In International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Jingbo Zhu",
                "Matthew Ma"
            ],
            "title": "Uncertainty-based active learning with instability estimation for text classification",
            "venue": "ACM Transactions on Speech and Language Processing (TSLP),",
            "year": 2012
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Active learning is one of the primary areas in machine learning to investigate the learning technique on a small subset of labeled data while acquiring good generalization performance compared to passive learning [16]. There are mainly two settings of active learning: stream-based and pool-based settings. For the stream-based setting, the learner is presented with an instance drawn from some distribution in each round and is required to decide on-the-fly whether or not to query the label from the oracle. For the pool-based setting, the learner aims to select one or multiple instances from the unlabeled pool and hand them over to the oracle for labeling. It repeats this process until the label budget is exhausted [41]. The essence of active learning is to exploit the knowledge extracted from labeled instances and explore the unlabeled data to maximize information acquisition for long-term benefits.\nUsing neural networks (NNs) to perform active learning has been explored extensively in recent works [40; 42; 46; 6]. However, they often lack a provable performance guarantee despite strong empirical performance. To address this issue, a recent line of works [48; 11] proposed the banditbased approaches to solve the active learning problem, which are equipped with principled exploration and theoretical performance guarantee. In contextual bandits [32; 56], the learner is presented with K arms (context vectors) and required to select one arm in each round. Then, the associated reward is observed. [48; 11] transformed the online K-class classification into a bandit problem. Specifically, in one round of stream-based active learning, a data instance xt \u2208 Rd is transformed into K long vectors corresponding to K arms, matching K classes: xt,1 = [x\u22a4t ,0\n\u22a4, \u00b7 \u00b7 \u00b7 ,0\u22a4]\u22a4, . . . ,xt,K = [0\u22a4, \u00b7 \u00b7 \u00b7 ,0\u22a4,x\u22a4t ]\u22a4, where xt,k \u2208 RdK , k \u2208 [K]. Then, the learner uses an NN model to calculate a score for each arm and selects an arm based on these scores. The index of the selected arm represents the index of the predicted class. This design enables researchers to utilize the exploration strategy and analysis in contextual bandits to solve the active learning problem. Note [48; 11] can only handle the stream-based setting of active learning.\nHowever, bandit-based approaches bear the following two limitations. First, as the instance xt is transformed into K arms, it is required to calculate a score for all K arms respectively, producing a cost of K times forward-propagation computation of neural networks. This computation cost is scaled by K. Second, the transformed long vector (arm) has (Kd) dimensions, in contrast to the d dimensions of the original instance as the input of the NN model. This potentially amplifies the effects of K on an active learning algorithm\u2019s performance. We empirically evaluate [48; 11] as\nshown in Table 1. The results indicate a noticeable degradation in both test accuracy and running time as K increases.\nIn response, in this paper, we aim to mitigate the adverse effects of K on the bandit-based approach in active learning. Our methods are built upon and beyond [11]. [11] adopted the idea of [10] to employ two neural networks, one for exploitation and another for exploration. As previously mentioned, these two neural networks take the transformed Kd-dimension arm as input. Moreover, in each round, [11] decomposed the label vector yt \u2208 {0, 1}K into K rewards (scalars), necessitating the training of two neural networks K times for each arm. Next, we summarize our key ideas and contributions to reduce the input dimension back to d and the number of forward propagations to 1 in each round while preserving the essence of exploitation and exploration of neural networks.\nMethodology. (1) We extend the loss function in active learning from 0-1 loss to Bounded loss, which is more flexible and general. Instead, [48; 11] restricted the loss to be 0-1 loss, because they had to define the reward of each class (arm) due to their bandit-based methodology. (2) We re-designed the input and output exploitation and exploration neural networks to directly take the d-dimension instance as input and output the predicted probabilities for K classes synchronously, mitigating the curse of K. The connection between exploitation and exploration neural networks is also reconstructed beyond the standard bandit setting. In other words, we avoid the transformation of active learning to the standard bandit setting. This is the first main contribution of this paper. (3) To facilitate efficient and effective exploration, we introduce the end-to-end embedding (Definition 4.1) as the input of the exploration neural network, which removes the dependence of the input dimension while preserving the essential information. (4) In addition to our proposed stream-based algorithm, referred to NEURONAL-S, we also propose a pool-based active learning algorithm, NEURONAL-P. We bring the redesigned exploitation and exploration network into pool-based setting and propose a novel gap-inverse-based selection strategy tailored for pool-based active learning. This is our second main contribution. Note that the stream-based algorithms cannot be directly converted into the pool-based setting, as discussed in Appendix B.\nTheoretical analysis. (1) We provide the regret upper bounds for the proposed stream-based algorithm under low-noise conditions on the data distribution. Our results indicate the cumulative regret of NEURONAL-S grows slower than that of [48] concerning K by a multiplicative factor at least O( \u221a T log(1 + \u03bb0)) and up to O\u0303( \u221a md), where \u03bb0 is the smallest eigenvalue of Neural Tangent Kernel (NTK) and m is the width of the neural network. This finding helps explain why our algorithms outperform the bandit-based algorithms, particularly when K is large, as shown in Table 1. In the binary classification task, our regret bounds directly remove the dependence of effective dimension d\u0303, which measures the actual underlying dimension in the RKHS space spanned by NTK, discussed in Sec. 5. (2) We also provide a performance guarantee for the proposed pool-based algorithm in the non-parametric setting, tailored for neural network models. In contrast, previous works focus on the regime either in parametric settings that require a finite VC dimension [26] or a linear mapping function assumption [8; 52; 23]. The performance guarantee matches the SOTA minimax active learning rate with a linear separator [23]. The above theoretical results are our third main contribution.\nEmpirical evaluation. In the end, we perform extensive experiments to evaluate the proposed algorithms for both stream-based and pool-based algorithms compared to state-of-the-art baselines. Our evaluation encompasses various metrics, including test accuracy and running time, and we have carried out ablation studies to investigate the impact of hyper-parameters and label budgets. This is our fourth main contribution."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "Active learning has been studied for decades and adapted to many real-world applications [43]. There are several strategies in active learning to smartly query labels, such as diversity sampling [20; 55], and uncertainty sampling [57; 50; 33]. Works that use neural networks to perform active learning, according to the model structure, can be classified into online-learning-based [37; 6] and banditbased [48; 11] methods. For most of the methods, their neural models take the instance as input and calculate the predicted scores for each class synchronously. For example, [37; 6; 14; 29; 44; 46; 54; 5] exploit the neural networks for active learning to improve the empirical performance. As mentioned before, this type of related work often lacks the principled exploration and provable guarantee in a non-parametric setting.\nThe primary focus of theoretical research in active learning is to determine the convergence rate of the population loss (regret) of the hypothesis produced by the algorithm in relation to the number of queried labels N . In the parametric setting, the convergence rates of the regret are of the form \u03bdN1/2 + e\u2212 \u221a N , where \u03bd is the population loss of the best function in the class with finite VCdimension, e.g., [24; 17; 39; 51; 7; 53]. With the realizable assumption (i.e., when the Bayes optimal classifier lies in the function class), minimax active learning rates of the form N\u2212 \u03b1+1 2 are shown in [25; 30] to hold for adaptive algorithms that do not know beforehand the noise exponent \u03b1 (Defined in Sec. 5). In non-parametric settings, [36; 34; 58] worked under smoothness (Holder continuity/smoothness) assumptions, implying more restrictive assumptions on the marginal data distribution. [34; 58] achieved the minimax active learning rate N\u2212 \u03b2(\u03b1+1) 2\u03b2+d for \u03b2-Holder classes, where exponent \u03b2 plays the role of the complexity of the class of functions to learn. [8; 52; 23] focused on the pool-based setting and achieve the ( dN )\n\u03b1+1/\u03b1+2 minimax rate, but their analysis are built on the linear mapping function. [31] investigated active learning with nearest-neighbor classifiers and provided a data-dependent minimax rate based on the noisy-margin properties of the random sample. [48] and [11] represent the closest works related to the analysis of neural networks in active learning. Both [48] and our work utilized the theory of NTK, making their results directly comparable. [11] established a connection between their regret upper bound and the training error of a neural network function class. However, they did not provide a clear trade-off between the training error and the function class radius, making it challenging to compare [11] with our theoretical results."
        },
        {
            "heading": "3 PROBLEM DEFINITION",
            "text": "In this paper, we consider the K-class classification problem for both stream-based and pool-based active learning.\nLet X denote the input space over Rd and Y represent the label space over {0, 1}K . D is some unknown distribution over X \u00d7 Y . For any round t \u2208 [T ] = {1, 2, . . . , T}, an instance xt is drawn from the marginal distribution DX . Accordingly, the associated label yt is drawn from the conditional distribution DY|xt , in which the dimension with value 1 indicates the ground-truth class of xt. For the clarity of presentation, we use yt,k, k \u2208 [K] to represent the K possible predictions, i.e., yt,1 = [1, 0, . . . , 0]\u22a4, . . . ,yt,K = [0, 0, . . . , 1]\u22a4.\nGiven an instance xt \u223c DX , the learner is required to make a prediction yt,k\u0302, k\u0302 \u2208 [K] based on some function. Then, the label yt is observed. A loss function \u2113 : Y \u00d7 Y \u2192 [0, 1], represented by \u2113(yt,k\u0302,yt), reflects the quality of this prediction. We investigate the non-parametric setting of active learning. Specifically, we make the following assumption for the conditional distribution of the loss.\nAssumption 3.1. The conditional distribution of the loss given xt is defined by some unknown function h : X \u2192 [0, 1]K , such that\n\u2200k \u2208 [K],Eyt\u223cDY|xt [\u2113(yt,k,yt)|xt] = h(xt)[k], (3.1)\nwhere h(xt)[k] represents the value of the kth dimension of h(xt).\nAssumption 3.1 is the standard formulation in [48; 11]. Related works [11; 48] restricted \u2113 to be 0-1 loss. In contrast, we only assume \u2113 is bounded for the sake of generality.\nStream-based. For stream-based active learning, at each round t \u2208 [T ], the learner receives an instance xt \u223c DX . Then, the learner is compelled to make a prediction yt,k\u0302, and at the same time, decides on-the-fly whether or not to observe the label yt.\nThen, the goal of active learning is to minimize the Population Cumulative Regret. Given the data distribution D and the number of rounds T , the Population Cumulative Regret is defined as:\nRstream(T ) := T\u2211 t=1 [ E (xt,yt)\u223cD [\u2113(yt,k\u0302,yt)]\u2212 E(xt,yt)\u223cD [\u2113(yt,k\u2217 ,yt)] ] , (3.2)\nwhere yt,k\u2217 is the prediction induced by the Bayes-optimal classifier with respect to xt in round t, i.e., k\u2217 = argmink\u2208[K] h(xt)[k]. The Population Regret reflects the generalization performance of a model in T rounds of stream-based active learning. At the same time, the goal of the learner is to minimize the expected label query cost: N(T ) :=\u2211T t=1 Ext\u223cDX\n[It|xt], where It is an indicator of the query decision in round t such that It = 1 if yt is observed; It = 0, otherwise.\nPool-based. The goal pool-based active learning is to maximize the performance of a model with a limited label budget given the pool of instances. In a round, assume there is an instance pool Pt = {x1,x2, . . . ,xB} with B instances, which are drawn from DX . Then, for any xt \u2208 Pt, the learner is able to request a label from the conditional distribution yt \u223c DY|xt with one unit of budget cost. The total number of queries is set as Q. Let yt,k\u0302 be the prediction of xt \u2208 Pt by some hypothesis. Then, the Population Cumulative Regret for pool-based active learning is defined as:\nRpool(Q) := Q\u2211 t=1 [ E (xt,yt)\u223cD [\u2113(yt,k\u0302,yt)]\u2212 E(xt,yt)\u223cD [\u2113(yt,k\u2217 ,yt)] ] , (3.3)\nwhere k\u2217 = argmink\u2208[K] h(xt)[k]. Rpool(Q) reflects the generalization performance of a model in Q rounds of pool-based active learning."
        },
        {
            "heading": "4 PROPOSED ALGORITHMS",
            "text": "In this section, we present the proposed algorithms for both stream-based and pool-based active learning. The proposed NN models incorporate two neural networks for exploitation and exploration. The exploitation network directly takes the instance as input and outputs the predicted probabilities for K classes synchronously, instead of taking the transformed K long vectors as input and computing the probabilities sequentially. The exploration network has a novel embedding as input to incorporate the information of K classes in the exploitation network simultaneously instead of calculating K embeddings for K arms sequentially as in bandit-based approaches.\nExploitation Network f1. The exploitation network f1 is a neural network which learns the mapping from input space X to the loss space [0, 1]K . In round t \u2208 [T ], we denote the network by f1(\u00b7;\u03b81t ), where the superscript of \u03b81t indicates the network and the subscript indicates the index of the round after updates for inference. f1 is defined as a fully-connected neural network with L-depth and m-width:\nf1(xt;\u03b8 1) := \u221a mW1L\u03c3(W 1 L\u22121 . . . \u03c3(W 1 1xt))) \u2208 RK , (4.1)\nwhere W11 \u2208 Rm\u00d7d,W1l \u2208 Rm\u00d7m, for 2 \u2264 l \u2264 L \u2212 1, W1L \u2208 RK\u00d7m, \u03b8 1 = [vec(W11) \u22a4, . . . , vec(W1L)\n\u22a4]\u22a4 \u2208 Rp1 , and \u03c3 is the ReLU activation function \u03c3(x) = max{0,x}. We randomly initialize \u03b81 denoted by \u03b811, where each entry is drawn from normal distribution N(0, 2/m) for W1l , l \u2208 [L\u2212 1], and each entry is drawn from N(0, 1/(Km)) for W1L. Note that we take the basic fully-connected network as an example for the sake of analysis in overparameterized networks, and f1 can be easily replaced with other advanced models depending on the tasks. Given an instance xt, f1(xt;\u03b81t ) can be considered as the estimation for \u2113(yt,k,yt), k \u2208 [K].\nIn round t, after receiving the label yt, we conduct stochastic gradient descent to update \u03b81, based on the loss function Lt,1(\u03b81t ), such as Lt,1(\u03b8 1 t ) = \u2211 k\u2208[K] ( f1(xt;\u03b8 1 t )[k]\u2212 \u2113(yt,k,yt) )2 /2, where f1(xt;\u03b8 1 t )[k] represents the value of the k th dimension of f1(xt;\u03b81t ).\nAlgorithm 1 NEURONAL-S Input: T,K, f1, f2, \u03b71, \u03b72 (learning rate), \u03b3 (exploration para.), \u03b4 (confidence para.), S (norm para.)\n1: Initialize \u03b811,\u03b8 2 1; \u03b8\u0302\n1 1 = \u03b8 1 1; \u03b8\u0302 2 1 = \u03b8 2 1,\u21261 = {(\u03b8\u0302 1 1, \u03b8\u0302 2\n1)} 2: for t = 1, 2, . . . , T do 3: Receive an instance xt \u223c DX 4: f(xt;\u03b8t) = f1(xt;\u03b8 1 t ) + f2(\u03d5(xt);\u03b8 2 t ) 5: k\u0302 = argmink\u2208[K] f(xt;\u03b8t)[k] 6: k\u25e6 = argmink\u2208([K]\\{ k\u0302 }) f(xt;\u03b8t)[k] 7: Predict yt,k\u0302\n8: It = 1{|f(xt;\u03b8t)[k\u0302]\u2212 f(xt;\u03b8t)[k\u25e6]| < 2\u03b3\u03b2t} \u2208 {0, 1}; \u03b2t = \u221a KS2 t + \u221a 2 log(3T/\u03b4) t 9: Observe yt and \u2113, if It = 1; yt = yt,k\u0302, otherwise\n10: \u03b8\u0302 1 t+1 = \u03b8\u0302 1 t \u2212 \u03b71\u25bd\u03b8\u03021Lt,1(\u03b8\u0302 1 t ) 11: \u03b8\u0302 2 t+1 = \u03b8\u0302 2 t \u2212 \u03b72\u25bd\u03b8\u03022Lt,2(\u03b8\u0302 2 t ) 12: \u2126t+1 = \u2126t \u222a {(\u03b8\u0302 1 t+1, \u03b8\u0302 2\nt+1)} 13: Draw (\u03b81t+1,\u03b8 2 t+1) uniformly from \u2126t+1 14: end for 15: return \u03b8T\nExploration Network f2. The exploration network f2 learns the uncertainty of estimating f1(\u00b7;\u03b81). In round t \u2208 [T ], given an instance xt and the estimation f1(xt;\u03b81t ), the input of f2 is a mapping or embedding \u03d5(xt) that incorporates the information of both xt and the discriminative information of \u03b81t . We introduce the following embedding \u03d5(xt):\nDefinition 4.1 (End-to-end Embedding). Given the exploitation network f1(\u00b7;\u03b81t ) and an input context xt, its end-to-end embedding is defined as\n\u03d5(xt) \u22a4 = ( \u03c3(W11xt) \u22a4, vec(\u2207W1Lf1(xt;\u03b8 1 t )) \u22a4 ) \u2208 Rm+Km, (4.2)\nwhere the first term is the output of the first layer of f1 and the second term is the partial derivative of f1 with respect to the parameters of the last layer. \u03d5(xt) is usually normalized.\nThe first term \u03c3(W11xt) \u22a4 can be thought of as an embedding to transform xt \u2208 Rd into another space in Rm, as the input dimension d can be a very large number. Thus, we leverage the representation power of f1 and minimize the dependence on d for f2. The last layer might play the more important role in terms of classification ability [38] and hence we only take the gradient of the last layer which incorporates the discriminative information of \u03b81t , to reduce the computation cost.\nThen, specifically, given an embedding \u03d5(xt), f2 is defined as:\nf2(\u03d5(xt);\u03b8 2) := \u221a mW2L\u03c3(W 2 L\u22121 . . . \u03c3(W 2 1\u03d5(xt))) \u2208 RK , (4.3)\nwhere W21 \u2208 Rm\u00d7(m+Km),W2l \u2208 Rm\u00d7m, for 2 \u2264 l \u2264 L \u2212 1, W2L \u2208 RK\u00d7m, \u03b8 2 = [vec(W21) \u22a4, . . . , vec(W2L)\n\u22a4]\u22a4 \u2208 Rp2 , and \u03c3 is the ReLU activation function \u03c3(x) = max{0,x}. Similarly, we randomly initialize \u03b82 denoted by \u03b821, where each entry is drawn from Normal distribution N(0, 2/m) for W2l , l \u2208 [L\u2212 1], and each entry is drawn from N(0, 1/Km) for W2L.\nIn round t, after receiving yt, the label for training f2 is the estimated error of f1(\u00b7;\u03b81)[k], represented by (\u2113(yt,k,yt) \u2212 f1(xt;\u03b81t )[k]). Therefore, we conduct stochastic gradient descent to update \u03b82, based on the loss Lt,2(\u03b82t ), such as Lt,2(\u03b8 2 t ) = \u2211 k\u2208[K] ( f2(\u03d5(xt);\u03b8\n2 t )[k] \u2212( \u2113(yt,k,yt) \u2212 f1(xt;\u03b81t )[k] ))2 /2, where f2(\u03d5(xt);\u03b82t )[k] represents the value of the k th dimen-\nsion of f2(\u03d5(xt);\u03b82t ).\nStream-based Algorithm. Our proposed stream-based active learning algorithm is described in Algorithm 1. In a round, when receiving a data instance, we calculate its exploitation-exploration\nAlgorithm 2 NEURONAL-P Input: Q,B,K, f1, f2, \u03b71, \u03b72, \u00b5, \u03b3\n1: Initialize \u03b811,\u03b8 2 1 2: for t = 1, 2, . . . , Q do 3: Draw B instances, Pt, from DX 4: for xi \u2208 Pt do 5: f(xi;\u03b8t) = f1(xi;\u03b8 1 t ) + f2(\u03d5(xi);\u03b8 2 t ) 6: k\u0302 = argmink\u2208[K] f(xi;\u03b8t)[k] 7: k\u25e6 = argmink\u2208([K]\\{ k\u0302 }) f(xi;\u03b8t)[k] 8: wi = f(xi;\u03b8t)[k\u0302]\u2212 f(xi;\u03b8t)[k\u25e6] 9: end for"
        },
        {
            "heading": "10: wi\u0302 = mini\u2208[B] wi",
            "text": "11: For each i \u0338= i\u0302, pi =\nwi\u0302 \u00b5wi\u0302+\u03b3(wi\u2212wi\u0302) 12: pi\u0302 = 1\u2212 \u2211\ni=i\u0302 pi 13: Draw one instance xt from Pt according to probability distribution P formed by pi 14: Query xt, Predict yt,k\u0302, and observe yt 15: Update \u03b81,\u03b82 as Lines 11-12 in Algorithm 1 16: end for 17: return \u03b8Q\nscore and then make a prediction (Lines 3-7), where k\u25e6 is used in the decision-maker (Line 8). When It = 1, which indicates that the uncertainty of this instance is high, we query the label of this data instance to attain new information; otherwise, we treat our prediction as the pseudo label (Line 9). Finally, we use the SGD to train and update the parameters of NN models (Lines 10-13). Here, we draw the parameters from the pool \u2126t for the sake of analysis to bound the expected approximation error of one round. One can use the mini-batch SGD to avoid this issue in implementation.\nPool-based Algorithm. Our proposed pool-based active learning algorithm is described in Algorithm 2. In each round, we calculate the exploitation and exploration scores, and then calculate the prediction gap w for each data instance (Lines 4-9). Then, we form a distribution of data instances (Lines 10-13), P , where Lines 11-12 are inspired by the selection scheme in [2]. The intuition behind this is as follows. The prediction gap wi reflects the uncertainty of this data instance. Smaller wi shows the larger uncertainty of xi. Thus, the smaller wi, the higher the drawing probability pi (Line 11). Finally, we draw a data instance according to the sampling probability P and conduct SGD to update the neural networks."
        },
        {
            "heading": "5 REGRET ANALYSIS",
            "text": "In this section, we provide the regret analysis for both the proposed stream-based and pool-based active learning algorithms.\nExisting works such as [48; 34; 58] studied active learning in binary classification, where the label space Y \u2208 [0, 1] can be parametrized by the Mammen-Tsybakov low noise condition [35]: There exist absolute constants c > 0 and \u03b1 \u2265 0, such that for all 0 < \u03f5 < 1/2,x \u2208 X , k \u2208 {0, 1}, P(|h(x)[k] \u2212 12 | \u2264 \u03f5) \u2264 c\u03f5\n\u03b1. For simplicity, we are interested in the two extremes: \u03b1 = 0 results in no assumption whatsoever on D while \u03b1 = \u221e gives the hard-margin condition on D. These two conditions can be directly extended to the K-class classification task. Next, we will provide the regret analysis and comparison with [48].\nOur analysis is associated with the NTK matrix as follows: Definition 5.1 (NTK [28; 48]). Let N denote the normal distribution. Given the data instances {xt}Tt=1, for all i, j \u2208 [T ], define\nH0i,j = \u03a3 0 i,j = \u27e8xi,xj\u27e9, Ali,j =\n( \u03a3li,i \u03a3 l i,j\n\u03a3lj,i \u03a3 l j,j ) \u03a3li,j = 2Ea,b\u223cN (0,Al\u22121i,j )[\u03c3(a)\u03c3(b)], H l i,j = 2H l\u22121 i,j Ea,b\u223cN (0,Al\u22121i,j )[\u03c3 \u2032(a)\u03c3\u2032(b)] + \u03a3li,j .\nThen, the Neural Tangent Kernel matrix is defined as H = (HL +\u03a3L)/2.\nThere are two complexity terms in [48] as well as in Neural Bandits [56; 9]. The assumption H \u2ab0 \u03bb0I is generally held in this literature to guarantee that there exists a solution for NTK regression. The first complexity term is S = \u221a h\u22a4H\u22121h where h = [h(x1)[1],h(x1)[2], . . . ,h(xT )[K]]\u22a4 \u2208 RTK . S is to bound the optimal parameters in NTK regression: there exists \u03b8\u2217 \u2208 Rp such that h(xt)[k] = \u27e8\u2207\u03b8f(xt;\u03b8\u2217)[k],\u03b8\u2217 \u2212 \u03b81\u27e9 and \u2225\u03b8\u2217 \u2212 \u03b81\u22252 \u2264 S. The second complexity term is the effective dimension d\u0303, defined as d\u0303 = log det(I+H)log(1+TK) , which describes the actual underlying\ndimension in the RKHS space spanned by NTK. [48] used the term LH to represent d\u0303: LH = log det(I+H) = d\u0303 log(1 + TK). We provide the upper bound and lower bound of LH in Appendix C: TK log(1 + \u03bb0) \u2264 LH \u2264 O\u0303(mdK). Next, we show the regret bound for the stream-based active learning algorithm (Algorithm 1) without any assumption on the distribution D (Tsybakov noise \u03b1 = 0). Theorem 5.1. [Stream-based]. Given T , for any \u03b4 \u2208 (0, 1), \u03bb0 > 0, suppose \u2225xt\u22252 = 1, t \u2208 [T ], H \u2ab0 \u03bb0I, m \u2265 \u2126\u0303(poly(T,K,L, S) \u00b7 log(1/\u03b4)), \u03b71 = \u03b72 = \u0398( Sm\u221aTK ). Then, with probability at least 1\u2212 \u03b4 over the initialization of \u03b811,\u03b8 2 1, Algorithm 1 achieves the following regret bound:\nRstream(T ) \u2264 O( \u221a T ) \u00b7 (\u221a KS + \u221a 2 log(3T/\u03b4) ) where N(T ) \u2264 O(T ).\nTheorem 5.1 shows that NEURONAL-S achieves a regret upper bound of O\u0303( \u221a TKS). Under the same condition (\u03b1 = 0), [48] obtains the regret upper bound: Rstream(T ) \u2264 O\u0303 (\u221a TLHS + \u221a TLH ) .\nThis core term is further bounded by O\u0303( \u221a T \u00b7 \u221a TK log(1 + \u03bb0)S) \u2264 O\u0303 (\u221a TLHS ) \u2264 O\u0303( \u221a TmdKS). Concerning K, Theorem 5.1 results in regret-growth rate \u221a K \u00b7 O\u0303( \u221a TS) in contrast with \u221a K \u00b7 O\u0303( \u221a TmdS) at most in [48]. Therefore, our regret bound has a slower growth rate concerning K\ncompared to [48] by a multiplicative factor at least O( \u221a T log(1 + \u03bb0)) and up to O\u0303( \u221a md). In binary classification, we reduce the regret bound by O\u0303( \u221a TLH), i.e., remove the dependency of d\u0303,\nand further improve the regret bound by a multiplicative factor at least O( \u221a T log(1 + \u03bb0)). The regret analysis of [11] introduced two other forms of complexity terms: O\u0303( \u221a T \u00b7 (\u221a\u00b5+ \u03bd)). \u00b5 is the data-dependent term interpreted as the minimal training error of a function class on the data, while \u03bd is the function class radius. [3] had implied that when \u03bd has the order of O\u0303(poly(T )), \u00b5 can decrease to O\u0303(1). But, their regret bounds also depend on O(\u03bd). This indicates that their regret analysis is invalid when \u03bd has O(T ). Since [11] did not provide the upper bound and trade-off of \u00b5 and \u03bd or build the connection with NTK, their results are not readily comparable to ours.\nFor the label complexity, Theorem 5.1 has the trivial O(T ) complexity which is the same as [48; 11]. This turns into the active learning minimax rate of N(T )\u22121/2, which is indeed the best rate under \u03b1 = 0 [13; 25; 30; 18]. Next, we provide the analysis under the following margin assumption. Assumption 5.1 ([11]). Given an instance xt and the label yt, xt has a unique optimal class if there exists \u03f5 > 0 such that \u2200t \u2208 [T ],h(xt)[k\u2217]\u2212 h(xt)[k\u25e6] \u2265 \u03f5, (5.1) where k\u2217 = argmink\u2208[K] h(xt)[k] and k\u25e6 = argmink\u2208([K]\\{k\u2217}) h(xt)[k].\nAssumption 5.1 describes that there exists a unique Bayes-optimal class for each input instance. Then, we have the following theorem. Theorem 5.2. [Stream-based]. Given T , for any \u03b4 \u2208 (0, 1), \u03b3 > 1, \u03bb0 > 0, suppose \u2225xt\u22252 = 1, t \u2208 [T ], H \u2ab0 \u03bb0I, m \u2265 \u2126\u0303(poly(T,K,L, S) \u00b7 log(1/\u03b4)), \u03b71 = \u03b72 = \u0398( Sm\u221aTK ), and Assumption 5.1 holds. Then, with probability at least 1\u2212 \u03b4 over the initialization of \u03b811,\u03b8 2 1, Algorithm 1 achieves the following regret bound and label complexity: Rstream(T ) \u2264O((KS2 + log(3T/\u03b4))/\u03f5)\nN(T ) \u2264O((KS2 + log(3T/\u03b4))/\u03f52).\nTheorem 5.2 provides the regret upper bound and label complexity of O\u0303(KS2) for NEURONAL-S under margin assumption. With \u03b1 \u2192 \u221e, [48] obtained O\u0303(LH(LH+S2)) \u2264 O\u0303(mdK(mdK+S2)). Therefore, with margin assumption, the regret of NEURONAL-S grows slower than [48] by a multiplicative factor up to O(md) with respect to K. In the binary classification task, Theorem 5.2 turns into O\u0303(S2) in contrast with O\u0303(LH(LH+S2)) of [48]. [11] achieved O\u0303(\u03bd2+\u00b5), but the results are not directly comparable to ours, as discussed before.\nNow, we provide the regret analysis for the pool-based active learning algorithm (Algorithm 2). Theorem 5.3 (Pool-based). For any 1 > \u03b4 > 0, \u03bb0 > 0, by setting \u00b5 = Q and \u03b3 = \u221a Q/(KS2), suppose \u2225xt\u22252 = 1 for all instances, H \u2ab0 \u03bb0I, m \u2265 \u2126\u0303(poly(Q,K,L,R) \u00b7 log(1/\u03b4)), \u03b71 = \u03b72 = \u0398( 1mLK ). Then, with probability at least 1\u2212 \u03b4 over the initilization of \u03b8 1 1,\u03b8 2 1, Algorithm 2 achieves:\nRpool(Q) \u2264 O( \u221a QKS) +O\n(\u221a Q\nKS2\n) \u00b7 log(2\u03b4\u22121) +O( \u221a Q log(3\u03b4\u22121)).\nTheorem 5.3 provides a performance guarantee of O\u0303( \u221a QKS) for NEURONAL-P in the nonparametric setting with neural network approximator. This result shows that the pool-based algorithm can achieve a regret bound of the same complexity as the stream-based algorithm (Theorem 5.1) with respect to the number of labels. Meanwhile, Theorem 5.3 indicates the O\u0303( \u221a 1/Q) minimax rate in the pool-based setting which matches the rate (\u03b1 = 0) in [8; 52; 23]. However, the results in [8; 52; 23] only work with the linear separator, i.e., they assume h as the linear function with respect to the data instance x. Note that [48; 11] only work on stream-based active learning."
        },
        {
            "heading": "6 EXPERIMENTS",
            "text": "In this section, we extensively evaluate NEURONAL for both stream-based and pool-based settings on the following six public classification datasets: Adult, Covertype (CT), MagicTelescope (MT), Shuttle [21], Fashion [49], and Letter [15]. For all NN models, we use the same width m = 100 and depth L = 2. Due to the space limit, we move the description of baselines and additional results (figures) to Appendix A.\nStream-based Setups. We use two metrics to evaluate the performance of each method: (1) test accuracy and (2) cumulative regret. We set T = 10, 000. After T rounds of active learning, we evaluate all the methods on another 10, 000 unseen data points and report the accuracy. As Adult does not have enough data points, we use 5, 000 data points for the evaluation. In each iteration, one instance is randomly chosen and the model predicts a label. If the predicted label is wrong, the regret is 1; otherwise 0. The algorithm can choose to observe the label, which will reduce the query budget by one. We restrict the query budget to avoid the situation of the algorithm querying every data point in the dataset, following [11]. The default label budget is 30%\u00d7T . We run each experiment 10 times and report the mean and std of results. We use three baselines for comparison in the stream-based setting: (1) NeurAL-NTK [48], (2) I-NeurAL [11], and (3) ALPS [19]. Due to the space limit, we reported the cumulative regret and more details in Appendix A.1.\nStream-based Results. To evaluate the effectiveness of NEURONAL-S, first, we report the test accuracy of bandit-based methods in Table 1, which shows the generalization performance of each method. From this table, we can see that the proposed NEURONAL-S consistently trains the best model compared to all the baselines for each dataset, where NEURONAL-S achieves non-trivial improvements under the same label budget with the same width and depth of NN models. Compared to bandit-based approaches, NeurAL-NTK and I-NeurAL, NEURONAL-S has new input and output, which enable us to better exploit the full feedback in active learning instead of bandit feedback and to explore more effectively. The results of ALPS are placed in Table 3. ALPS manages to select the best pre-trained hypotheses for the data. However, the model parameters are fixed before the online active learning process. Hence, ALPS is not able to take the new knowledge obtained by queries into account and its performance is highly limited by the hypothesis class. Table 1 shows the running time of NEURONAL-S compared to bandit-based approaches. NEURONAL-S achieves the best empirical performance and significantly saves the time cost. The speed-up is boosted when K is large. This is because of NEURONAL-S\u2019s new NN model structure to calculate the predicted score synchronously. In contrast, bandit-based approaches calculate the score sequentially, of which the computational cost\nis scaled by K. We also conduct the ablation study for different label budgets in the active learning setting placed in Appendix A.\nPool-based Setups. We use the test accuracy to evaluate the performance of each method. Following [47], we use batch active learning. In each active learning round, we select and query 100 points for labels. After 10 rounds of active learning, we evaluate all the methods on another 10, 000 unseen data points and report the accuracy. We run each experiment 10 times and report the mean and standard deviation of results. The four SOTA baselines are: (1) CoreSet [42], (2) BADGE [6], (3) DynamicAL [47], and (4) ALBL [27].\nPool-based results. To evaluate the effectiveness of NEURONAL-P, we report the test accuracy of all methods in Table 2. Our method, NEURONAL-P, can consistently outperform other baselines across all datasets. This indicates that these baselines without explicit exploration are easier to be trapped in sub-optimal solutions. Our method has a more effective network structure (including the principled exploration network), allowing us to exploit the full feedback and explore new knowledge simultaneously in active learning. Moreover, we use the inverse gap strategy to draw samples, which further balances exploitation and exploration. CoreSet always chooses the maximal distance based on the embeddings derived by the last layer of the exploitation neural network, which is prone to be affected by outlier samples. BADGE also works on the last layer of the exploitation network using the seed-based clustering method, and it is not adaptive to the state of the exploitation network. DynamicAL relies on the training dynamics of the Neural Tangent Kernel, but the rules it uses might only work on the over-parameterized neural networks based on the analysis. ALBL is a hybrid active learning algorithm that combines Coreset and Conf [45]. ALBL shows a stronger performance but still is outperformed by our algorithm. As mentioned before, these baselines do not provide a theoretical performance guarantee. For the running time, as there are B samples in a pool in each round, NEURONAL-P takes O(2B) to make a selection. For other baselines, CoreSet takes O(2B). In addition to O(2B) cost, BADGE and DynamicAL need to calculate the gradient for each sample, which is scaled by O(B). Thus, BADGE and DynamicAL are slow. ALBA is slow because it contains another algorithm, and thus, it has two computational costs in addition to neural models. We also conduct the hyper-parameter sensitivity study for different label budgets in the active learning setting placed in Appendix A.2."
        },
        {
            "heading": "7 CONCLUSION",
            "text": "In this paper, we propose two algorithms for both stream-based and pool-based active learning. The proposed algorithms mitigate the adverse effects of K in terms of computational cost and performance. The proposed algorithms build on the newly designed exploitation and exploration neural networks, which enjoy a tighter provable performance guarantee in the non-parametric setting. Ultimately, we use extensive experiments to demonstrate the improved empirical performance in stream- and pool-based settings."
        },
        {
            "heading": "A EXPERIMENTS DETAILS",
            "text": "In this section, we provide more experiments and details for both stream-based and pool-based settings.\nA.1 STREAM-BASED\nBaselines. Given an instance, NeurAL-NTK is a method that predicts K scores for K classes sequentially, only based on the exploitation NN classifier with an Upper-Confidence-Bound (UCB). On the contrary, I-NeurAL predicts K scores for K classes sequentially, based on both the exploitation and exploration NN classifiers. NeurAL-NTK and I-NeurAL query for a label when the model cannot differentiate the Bayes-optimal class from other classes. Finally, ALPS makes a prediction by choosing a hypothesis (from a set of pre-trained hypotheses) that minimizes the loss of labeled and pseudo-labeled data, and queries based on the difference between hypotheses.\nImplementation Details. We perform hyperparameter tuning on the training set. Each method has a couple of hyperparameters: the learning rate, number of epochs, batch size, label budget percentage, and threshold (if applicable). During hyperparameter tuning for all methods, we perform a grid search over the values {0.0001, 0.0005, 0.001} for the learning rate, {10, 20, 30, 40, 50, 60, 70, 80, 90} for the number of epochs, {32, 64, 128, 256} for the batch size, {0.1, 0.3, 0.5, 0.7, 0.9} for the label budget percentage and {1, 2, 3, 4, 5, 6, 7, 8, 9} for the threshold (exploration) parameter. Here are the final hyperparameters in the form {learning rate, number of epochs, batch size, label budget percentage, and the turning hyperparameter}: NeurAL-NTK and ALPS use {0.001, 40, 64, 0.3, 3}, and I-NeurAL uses {0.001, 40, 32, 0.3, 6}. For NEURONAL-S, we set \u00b5 = 1 for all experiments and conduct the grid search for \u03b3 over {1, 2, 3, 4, 5, 6, 7, 8, 9}. In the end, NEURONAL-S uses {0.0001, 40, 64, 0.3, 6} for all datasets. We set S = 1 as the norm parameter for NEURONAL-S all the time.\nCumulative Regret. Figure 1 shows the regret comparison for each of the six datasets in 10,000 rounds of stream-based active learning. NEURONAL-S outperforms baselines on most datasets. This\ndemonstrates that our designed NN model attains effectiveness in the active learning process, which is consistent with the best performance achieved by NEURONAL-S in testing accuracy.\nAblation study for label budget. Tables 4 to 6 show the NEURONAL-S in active learning with different budget percentages: 3%, 10%, 50 %. NEURONAL-S achieves the best performance in most of the experiments. With 3% label budget, almost all NN models are not well trained. Thus, NEURONAL does not perform stably. With 10% and 50% label budget, NEURONAL achieves better performance, because the advantages of NN models can better exploit and explore this label information.\nBaselines. BADGE uses gradient embeddings to model uncertainty - if the gradient in the last neural network layer is large, the uncertainty is also large. They pick random points to query using the k-meanss++ algorithm and repeat this process. DynamicAL introduces the concept of training dynamics into active learning. Given an instance, they assign it a pseudo-label and monitor how much the model changes. They query for the label of the point with the biggest change in the training dynamics. CoreSet has a simple but powerful approach. The algorithm chooses points to query based on the loss over the labeled points and the loss over the unlabelled points, i.e., the core-set loss. ALBL is a hybrid active learning algorithm that combines Coreset and Conf [45].\nImplementation details. For all methods, we conduct the same grid search as the stream-based setting for the learning rate and number of epochs. For NEURONAL-P, we perform a grid search over \u00b5, \u03b3 \u2208 {500, 1000, 2000}. Testing accuracy. Figure 2 shows the average test accuracy at each round. NEURONAL-P can outperform baselines in a few query rounds. Our method utilizes a highly effective network structure, including the principled exploration network and inverse-weight-based selection strategy. Unlike CoreSet, which solely relies on the embeddings derived from the last layer of exploitation neural networks to select samples based on maximum distance, our approach avoids susceptibility to outlier samples. Similarly, BADGE also operates on the last layer of the exploitation network using the seedbased clustering method, lacking adaptability to the state of the exploitation network. DynamicAL\u2019s approach relies on the training dynamics of the Neural Tangent Kernel that usually requires very wide neural networks. ALBL is a blending approach, but it still suffers from the limitation of CoreSet.\nAblation study for \u00b5 and \u03b3. Table 7 shows NEURONAL-P with varying \u00b5 and \u03b3 values (500, 1000, 2000) on four datasets. Intuitively, if \u03b3 and \u00b5 is too small, NEURONAL-P will place more weights on the tail of the distribution of P . Otherwise, NEURONAL-P will focus more on the head of the distribution of P . From the results in the table, it seems that different datasets respond to different values of \u00b5 and \u03b3. This sensitivity study roughly shows good values for \u00b5, \u03b3."
        },
        {
            "heading": "B STREAM-BASED VS POOL-BASED",
            "text": "To answer the question \"Can one directly convert the stream-based algorithm to the pool-based setting?\", we implemented the idea that one uniformly samples data from the pool to feed it to the stream-based active learner. Denote the new algorithm by Neu-UniS, described as follows.\nNeu-UniS: In a round of pool-based active learning, we uniformly draw a sample from the pool and feed it to the stream-based learner. If the stream-based learner decides to query the label, it costs one unit of the label budget; otherwise, we keep uniformly drawing a sample until the stream-based learner decides to query the label. Once the label is queried, we train the neural model based on the sample and label. We keep doing this process until we run out of the label budget. In this algorithm, the stream-based learner is set as NEURONAL-S (Algorithm 1 in the manuscript).\nUnder the same setting used in our pool-based experiments, the testing accuracy of Neu-UniS compared to our pool-based algorithm NEURONAL-P is reported in Table 8.\nWhy does NEURONAL-P outperform Neu-UniS? Because Neu-UniS does not rank data instances and only randomly chooses the data instances that satisfy the query criterion. All the stream-based algorithms have one criterion to determine whether to query the label for this data point, such as Lines 8-9 in Algorithm 1. Suppose there are 200 data points. If the 100 data points among them satisfy the criterion, then Neu-UniS will randomly choose one from the 100 data points, because we uniformly draw a data point and feed it to stream-based learner in each round.\nOn the contrary, NEURONAL-P has a novel component (Lines 10-12 in Algorithm 2) to rank all the data points, and then draw a sample from the newly formed distribution, to balance exploitation and exploration. To the best of our knowledge, this is the first inverse-gap weighting strategy in active learning. Thus, its analysis is also novel.\nIn summary, stream-based algorithms cannot directly convert into pool-based algorithms, because they do not have the ranking component which is necessary in the pool-based setting. Existing works [48; 19; 11] only focus on the stream-based setting and [42] [6] [47] only focus on pool-based setting. We could hardly find existing works that incorporate both stream-based and pool-based settings."
        },
        {
            "heading": "C UPPER BOUND AND LOWER BOUND FOR LH",
            "text": "Then, we define the following gram matrix G. Let g(x;\u03b80) = \u25bd\u03b8f(x;\u03b80) \u2208 Rp and G = [g(x1,1;\u03b80)/ \u221a m, . . . , g(xT,K ;\u03b80)/ \u221a m] \u2208 Rp\u00d7TK where p = m+mKd+m2(L\u22122). Therefore, we have G = G\u22a4G. Based on Theorem 3.1 in [4], when m \u2265 \u2126(T 4K6 log(2TK/\u03b4)/\u03f54), with probability at least 1\u2212 \u03b4, we have \u2225G\u2212H\u2225F \u2264 \u03f5. Then, we have the following bound:\nlog det(I+H) = log det (I+G+ (H\u2212G)) (e1)\n\u2264 log det(I+G) + \u27e8(I+G)\u22121, (H\u2212G)\u27e9 \u2264 log det(I+G) + \u2225(I+G)\u22121\u2225F \u2225H\u2212G\u2225F (e2)\n\u2264 log det(I+G) + \u221a T\u2225H\u2212G\u2225F\n(e3)\n\u2264 log det(I+G) + 1\n(C.1)\nwhere (e1) is because of the concavity of log det(\u00b7), (e2) is by Lemma B.1 in [56] with the choice of m, and (e3) is by the proper choice of \u03f5. Then, LH can be bounded by:\nlog det(I+H) \u2264 log det(I+G) + 1 (e1) = log det(I+GG\u22a4) + 1\n= log det ( I+\nTK\u2211 i=1 g(xi;\u03b80)g(xi;\u03b80) \u22a4/m\n) + 1\n(e2)\n\u2264 p \u00b7 log(1 +O(TK)/p) + 1\nwhere (e1) is because of det(I+G\u22a4G) = det(I+GG\u22a4) and (e2) is an application of Lemma 10 in [1] and \u2225g(xi;\u03b80)\u22252 \u2264 O( \u221a mL) with L = 2. Because p = m+mKd+m2 \u00d7 (L\u2212 2), we have\nLH = log det(I+H) \u2264 O\u0303(mKd). (C.2)\nFor the lower bound of LH, we have LH = log det(I+H) \u2265 log ( \u03bbmin (I+H) TK ) = TK log(1 + \u03bb0). (C.3)"
        },
        {
            "heading": "D PROOF OF THEOREM 5.1 AND THEOREM 5.2",
            "text": "First, define the general neural structure:\nf(xt;\u03b8) := \u221a mWL\u03c3(WL\u22121 . . . \u03c3(W1xt))) \u2208 RK , (D.1)\nwhere \u03b8 = [vec(W1)\u22a4, . . . , vec(WL)\u22a4]\u22a4 \u2208 Rp. Following [3; 12], given an instance x, we define the outputs of hidden layers of the neural network:\ngt,0 = xt,gt,l = \u03c3(Wlgt,l\u22121), l \u2208 [L\u2212 1]. Then, we define the binary diagonal matrix functioning as ReLU:\nDt,l = diag(1{(Wlgt,l\u22121)1}, . . . ,1{(Wlgt,l\u22121)m}), l \u2208 [L\u2212 1]. Accordingly, the neural network is represented by\nf(xt;\u03b8) = \u221a mWL( L\u22121\u220f l=1 Dt,lWl)xt,\nand we have the following gradient form:\n\u2207Wlf(xt;\u03b8) =\n{\u221a m \u00b7 [gt,l\u22121WL( \u220fL\u22121 \u03c4=l+1 Dt,\u03c4W\u03c4 )]\n\u22a4, l \u2208 [L\u2212 1]\u221a m \u00b7 g\u22a4t,L\u22121, l = L.\nLet \u03b81 be the random initialization of parameters of neural networks. Then, we define the following neural network function class: Given a constant R > 0, the function class is defined as\nB(\u03b81, R) = {\u03b8 \u2208 Rp : \u2225\u03b8 \u2212 \u03b81\u22252 \u2264 R/m1/2}. (D.2)\nLemma D.1 ([3]). With probability at least 1 \u2212 O(TL) \u00b7 exp[\u2212\u2126(m\u03c92/3L)], given \u03c9 \u2264 O(L\u22129/2[log(m)]\u22123/2), for all \u03b8,\u03b8\u2032 \u2208 B(\u03b81, R), i \u2208 [T ], l \u2208 [L\u2212 1]\n\u2225gt,l\u2225 \u2264 O(1) \u2225Di,l \u2212D\u2032i,l\u22252 \u2264 O(L\u03c92/3m).\nLemma D.2. With probability at least 1\u2212O(TL2)\u00b7exp[\u2212\u2126(m\u03c92/3L)], uniformly over any diagonal matrices D\u2032\u2032i,1, . . . ,D \u2032\u2032 i,L\u22121 \u2208 [\u22121, 1]m\u00d7m with at most O(m\u03c92/3L) non-zero entries, for any \u03b8,\u03b8\n\u2032 \u2208 B(\u03b81;\u03c9) with \u03c9 \u2264 O(L\u22126[log(m)]\u22123/2), we have the following results:\n(1)\u2225 \u220f \u03c4\u2208l (Di,\u03c4 +D \u2032\u2032 i,\u03c4 )W\u03c4\u22252 \u2264 O( \u221a L) (D.3)\n(2)\u2225WL L\u22121\u220f \u03c4=l1 (Di,\u03c4 +D \u2032\u2032 i,\u03c4 )W\u03c4\u2225F \u2264 O ( 1\u221a K ) (D.4)\n(3) \u2225\u2225\u2225\u2225\u2225W\u2032L L\u22121\u220f \u03c4=l1 (D\u2032i,\u03c4 +D \u2032\u2032 i,\u03c4 )W \u2032 \u03c4 \u2212WL L\u22121\u220f \u03c4=l1 Di,\u03c4W\u03c4 \u2225\u2225\u2225\u2225\u2225 F \u2264 O ( \u03c91/3L2 \u221a log(m)\u221a K ) . (D.5)\nProof. Based on Lemma D.1, with high probability at least 1\u2212O(nL) \u00b7exp(\u2212\u2126(L\u03c92/3m)), \u2225D\u2032i,l+ D\u2032\u2032i,l \u2212D (1) i,l \u22250 \u2264 O(L\u03c92/3m)\u22250. Applying Lemma 8.6 in [3] proves D.3. Then, by lemma 8.7 in [3] with s = O(m\u03c92/3L) to W and W\u2032, the results hold:\n\u221a m \u2225\u2225\u2225\u2225\u2225W(1)L L\u22121\u220f \u03c4=l1 (D\u2032i,\u03c4 +D \u2032\u2032 i,\u03c4 )W \u2032 \u03c4 \u2212W (1) L L\u22121\u220f r=l1 D (1) i,\u03c4W (1) \u03c4 \u2225\u2225\u2225\u2225\u2225 2 \u2264 O ( \u03c91/3L2 \u221a m log(m)\u221a K ) \u221a m\n\u2225\u2225\u2225\u2225\u2225W(1)L L\u22121\u220f \u03c4=l1 Di,\u03c4W\u03c4 \u2212W(1)L \u220f \u03c4=l1 D (1) i,\u03c4W (1) \u03c4 \u2225\u2225\u2225\u2225\u2225 \u2264 O ( \u03c91/3L2 \u221a m log(m)\u221a K ) .\n(D.6)\nMoreover, using Lemma D.1 gain, we have\u2225\u2225\u2225\u2225\u2225(W\u2032L \u2212W(1)L ) L\u22121\u220f \u03c4=l1 (D\u2032i,\u03c4 +D \u2032\u2032 i,\u03c4 )W \u2032 \u03c4 \u2225\u2225\u2225\u2225\u2225 2 \u2264 O( \u221a L\u03c9) \u2264 O ( \u03c91/3L2 \u221a m log(m)\u221a K ) \u2225\u2225\u2225\u2225\u2225(WL \u2212W(1)L ) L\u22121\u220f \u03c4=l1 Di,\u03c4W\u03c4 \u2225\u2225\u2225\u2225\u2225 2 \u2264 O( \u221a L\u03c9) \u2264 O ( \u03c91/3L2 \u221a m log(m)\u221a K\n) (D.7) Then, combining (D.6) and (D.7) leads the result. For, it has\u2225\u2225\u2225\u2225\u2225WL L\u22121\u220f \u03c4=l1 (Di,\u03c4 +D \u2032\u2032 i,\u03c4 )W\u03c4 \u2225\u2225\u2225\u2225\u2225 2 \u2264 \u2225\u2225\u2225\u2225\u2225WL L\u22121\u220f \u03c4=l1 (Di,\u03c4 +D \u2032\u2032 i,\u03c4 )W\u03c4 \u2212W (1) L L\u22121\u220f \u03c4=l1 D(1)i,\u03c4W (1) \u03c4 \u2225\u2225\u2225\u2225\u2225 2\n+ \u2225W(1)L L\u22121\u220f \u03c4=l1 D (1) i,\u03c4W (1) \u03c4 \u22252\n(a) \u2264 O\n( \u03c91/3L2 \u221a m log(m)\u221a K ) +O( 1\u221a K ) = O( 1\u221a K )\nwhere (a) is applying the and Lemma 7.4 in [3]. The proof is completed.\nLemma D.3. Suppose the derivative of loss function L\u2032 \u2264 O(1). With probability at least 1 \u2212 O(TKL2) \u00b7 exp[\u2212\u2126(m\u03c92/3L)], for all t \u2208 [T ], \u2225\u03b8 \u2212 \u03b81\u2225 \u2264 \u03c9 and \u03c9 \u2264 O(L\u22126[log(m)]\u22123), suppose \u2225Lt(\u03b8)\u2032\u22252 \u2264 \u221a K, it holds uniformly that\n\u2225\u2207\u03b8f(xt;\u03b8)\u22252 \u2264 O( \u221a Lm) (D.8) \u2225\u2207\u03b8f(xt;\u03b8)[k]\u2225 \u2264 O( \u221a Lm) (D.9)\n\u2225\u2207\u03b8Lt(\u03b8)\u22252 \u2264 O (\u221a (K + L\u2212 1)m )\n(D.10)\nProof. By Lemma D.1, the result holds:\n\u2225\u2207WLf(xt;\u03b8)\u2225F = \u2225 \u221a mgt,L\u22121\u22252 \u2264 O( \u221a m).\nFor l \u2208 [L\u2212 1], the results hold:\n\u2225\u2207Wlf(xt;\u03b8)\u2225F = \u221a m\u2225gt,l\u22121WL( L\u22121\u220f \u03c4=l+1 Dt,\u03c4W\u03c4 )\u2225\n= \u221a m \u00b7 \u2225gt,l\u22121\u22252 \u00b7 \u2225WL( L\u22121\u220f \u03c4=l+1 Dt,\u03c4W\u03c4 )\u2225F\n\u2264 O (\u221a\nm\u221a K ) Thus, applying the union bound, for l \u2208 [L], t \u2208 [T ], k \u2208 [K] it holds uniformly that\n\u2225\u2207\u03b8f(xt;\u03b8)\u22252 \u2264 \u221a\u221a\u221a\u221a L\u2211 l\u22121 \u2225\u2207Wlf(xi;\u03b8)\u22252F \u2264 O (\u221a K + L K m ) = O( \u221a Lm).\nLet ek be the k-th basis vector. Then, we have\n\u2225\u2207\u03b8f(xt;\u03b8)[k]\u22252 \u2264 \u221a\u221a\u221a\u221a L\u2211 l\u22121 \u2225ek\u222522\u2225\u2207Wlf(xi;\u03b8)\u22252F \u2264 O( \u221a Lm).\nThese prove (D.8) and (D.9). For WL, the result holds:\n\u2225\u2207WLLt(\u03b8)\u2225F = \u2225Lt(\u03b8)\u2032\u22252 \u00b7 \u2225\u2207WLf(xt;\u03b8)\u2225F \u2264 O( \u221a Km).\nFor l \u2208 [L\u2212 1], the results hold:\n\u2225\u2207WlLt(\u03b8)\u2225F = \u2225Lt(\u03b8)\u2032\u22252 \u00b7 \u2225\u2207Wlf(xt;\u03b8)\u2225F \u2264 O( \u221a m).\nTherefore, \u2225\u2207\u03b8Lt(\u03b8)\u22252 = \u221a\u2211L l=1 \u2225\u2207WlLt(\u03b8)\u22252F \u2264 \u221a (K + L\u2212 1)m.\nLemma D.4. With probability at least 1 \u2212 O(TL2K) exp[\u2212\u2126(m\u03c92/3L)] over random initialization, for all t \u2208 [T ], and \u03b8,\u03b8\u2032 satisfying \u2225\u03b8 \u2212 \u03b81\u22252 \u2264 w and \u2225\u03b8\u2032 \u2212 \u03b81\u22252 \u2264 w with \u03c9 \u2264 O(L\u22126[logm]\u22123/2), , it holds uniformly that\n|f(xt;\u03b8\u2032)[k]\u2212 f(xt;\u03b8)[k]\u2212 \u27e8\u2207\u03b8f(xt;\u03b8)[k],\u03b8\u2032 \u2212 \u03b8\u27e9| \u2264 O\n( \u03c91/3L3 \u221a m log(m)\u221a K ) \u2225\u03b8 \u2212 \u03b8\u2032\u22252.\nProof. Let F (xt;\u03b8\u2032)[k] = f(xt;\u03b8)[k] \u2212 \u27e8\u2207\u03b8f(xt;\u03b8)[k],\u03b8\u2032 \u2212 \u03b8\u27e9 and ek \u2208 RK be the k-th basis vector. Then, we have\nf(xt;\u03b8 \u2032)[k]\u2212 F (xt;\u03b8\u2032)[k] = \u2212 \u221a m L\u22121\u2211 l\u22121 e\u22a4k WL( L\u22121\u2211 \u03c4=l+1 Dt,\u03c4W\u03c4 )Dt,\u03c4 (W \u2032 l \u2212Wl)gi,l=1\n+ \u221a me\u22a4k W \u2032 L(g \u2032 t,L\u22121 \u2212 gt,L\u22121).\nUsing Claim 8.2 in [3], there exist diagonal matrices D\u2032\u2032t,l \u2208 Rm\u00d7m with entries in [\u22121, 1] such that \u2225D\u2032\u2032t,l\u22250 \u2264 O(m\u03c92/3) and\ngt,L\u22121 \u2212 g\u2032t,L\u22121 = L\u22121\u2211 l=1\n[ L\u22121\u220f\n\u03c4=l+1\n(D\u2032t,\u03c4 +D \u2032\u2032 t,\u03c4 )W \u2032 \u03c4 ] (D\u2032t,l +D \u2032\u2032 t,l)(Wl \u2212W\u2032l)gt,l\u22121.\nThus, we have\n|f(xt;\u03b8\u2032)[k]\u2212 F (xt;\u03b8\u2032)[k]| = \u221a m L\u22121\u2211 l=1 e\u22a4k W \u2032 L [ (D\u2032t,\u03c4 +D \u2032\u2032 t,\u03c4 )W \u2032 \u03c4 (D \u2032 t,l +D \u2032\u2032 t,l)(Wl \u2212W\u2032l)gt,l\u22121 ] \u2212 \u221a m\nL\u22121\u2211 l\u22121 e\u22a4k WL( L\u22121\u2211 \u03c4=l+1 Dt,\u03c4W\u03c4 )Dt,l(W \u2032 l \u2212Wl)gi,l\u22121\n(a) \u2264\n( \u03c91/3L2 \u221a m log(m)\u221a K ) \u00b7 L\u22121\u2211 l=1 \u2225gt,l\u22121 \u00b7W\u2032l \u2212Wl\u22252\n(b) \u2264\n( \u03c91/3L3 \u221a m log(m)\u221a K ) \u2225\u03b8 \u2212 \u03b8\u2032\u22252\nwhere (a) is applying (D.5) and (b) is based on Lemma D.1. The proof is completed.\nDefine Lt(\u03b8) = \u2225f(xt;\u03b8) \u2212 lt\u22252 and Lt,k = |f(xt;\u03b8)[k] \u2212 lt[k]|, where lt \u2208 RK represents the corresponding label to train.\nLemma D.5 (Almost Convexity). With probability at least 1\u2212O(TL2K) exp[\u2212\u2126(m\u03c92/3L)] over random initialization, for any \u03f5 > 0 and all t \u2208 [T ], and \u03b8,\u03b8\u2032 satisfying \u2225\u03b8 \u2212 \u03b81\u22252 \u2264 \u03c9 and \u2225\u03b8\u2032 \u2212 \u03b81\u22252 \u2264 \u03c9 with \u03c9 \u2264 O ( \u03f53/4L\u22129/4(Km[logm])\u22123/8 ) \u2227O(L\u22126[logm]\u22123/2), it holds uniformly that\nLt(\u03b8\u2032) \u2265 Lt(\u03b8) + K\u2211\nk=1\n\u27e8\u2207\u03b8Lt,k(\u03b8),\u03b8\u2032 \u2212 \u03b8\u27e9 \u2212 \u03f5.\nProof. Let Lt,k(\u03b8) be the loss function with respect to f(xt;\u03b8\u2032)[k]. By convexity of L, it holds uniformly that\nLt(\u03b8\u2032)\u2212 Lt(\u03b8) (a)\n\u2265 K\u2211\nk=1\nL\u2032t,k(\u03b8) ( f(xt;\u03b8 \u2032)[k]\u2212 f(xt;\u03b8)[k] )\n(b) \u2265 K\u2211\nk=1\nL\u2032t,k(\u03b8)\u27e8\u2207f(xt;\u03b8)[k],\u03b8 \u2032 \u2212 \u03b8\u27e9\n\u2212 K\u2211\nk=1 \u2223\u2223L\u2032t,k(\u03b8) \u00b7 [f(xt;\u03b8\u2032)[k]\u2212 f(xt;\u03b8)[k]\u2212 \u27e8\u2207f(xt;\u03b8)[k],\u03b8\u2032 \u2212 \u03b8\u27e9]\u2223\u2223 (c)\n\u2265 K\u2211\nk=1\n\u27e8\u2207\u03b8Lt,k(\u03b8),\u03b8\u2032 \u2212 \u03b8\u27e9 \u2212 K\u2211\nk=1\n|f(xt;\u03b8\u2032)[k]\u2212 f(xt;\u03b8)[k]\u2212 \u27e8\u2207f(xt;\u03b8)[k],\u03b8\u2032 \u2212 \u03b8\u27e9|\n(d) \u2265 K\u2211\nk=1\n\u27e8\u2207\u03b8Lt,k(\u03b8),\u03b8\u2032 \u2212 \u03b8\u27e9 \u2212K \u00b7 O ( \u03c94/3L3\n\u221a m logm)\u221a K ) (e)\n\u2265 K\u2211\nk=1\n\u27e8\u2207\u03b8Lt,k(\u03b8),\u03b8\u2032 \u2212 \u03b8\u27e9 \u2212 \u03f5\nwhere (a) is due to the convexity of Lt, (b) is an application of triangle inequality, (c) is because of the Cauchy\u2013Schwarz inequality, (d) is the application of Lemma D.4, and (e) is by the choice of \u03c9. The proof is completed.\nLemma D.6 (Loss Bound). With probability at least 1\u2212O(TL2K) exp[\u2212\u2126(m\u03c92/3L)] over random initialization and suppose R, \u03b7,m satisfy the condition in Theorem 5.1, the result holds that\nT\u2211 t=1 Lt(\u03b8t) \u2264 T\u2211 t=1 Lt(\u03b8\u2217) +O( \u221a TKR). (D.11)\nwhere \u03b8\u2217 = arg inf\u03b8\u2208B(\u03b81,R) \u2211T t=1 Lt(\u03b8). Proof. Let w = O ( \u03f53/4L\u22126(Km)\u22123/8[logm]\u22123/2 ) such that the conditions of Lemma D.5 are satisfied. Next, we aim to show \u2225\u03b8t \u2212 \u03b81\u22252 \u2264 \u03c9, for any t \u2208 [T ]. The proof follows a simple induction. Obviously, \u03b81 is in B(\u03b81, R). Suppose that \u03b81,\u03b82, . . . ,\u03b8T \u2208 B(\u03b81, R). We have, for any t \u2208 [T ],\n\u2225\u03b8T \u2212 \u03b81\u22252 \u2264 T\u2211\nt=1\n\u2225\u03b8t+1 \u2212 \u03b8t\u22252 \u2264 T\u2211\nt=1\n\u03b7\u2225\u2207Lt(\u03b8t)\u22252 \u2264 T\u2211\nt=1\n\u03b7O( \u221a L\u03bam)\n\u2264 T \u00b7 O( \u221a L\u03bam) \u00b7 R\nm \u221a TK \u2264 \u03c9\nwhen m > \u2126\u0303(T 4L52KR8\u03f5\u22126). This also leads to R\u221a m \u2264 \u03c9.\nIn round t, therefore, based on Lemma D.5, for any \u2225\u03b8t \u2212 \u03b8\u2032\u22252 \u2264 \u03c9, it holds uniformly\nLt(\u03b8t)\u2212 Lt(\u03b8\u2032) \u2264 K\u2211\nk\u22121\n\u27e8\u2207\u03b8Lt,k(\u03b8t),\u03b8t \u2212 \u03b8\u2032\u27e9+ \u03f5,\nThen, it holds uniformly\nLt(\u03b8t)\u2212 Lt(\u03b8\u2032t) (a) \u2264 \u27e8\u03b8t \u2212 \u03b8t+1,\u03b8t \u2212 \u03b8 \u2032\u27e9\n\u03b7 + \u03f5\n(b) = \u2225\u03b8t \u2212 \u03b8\u2032\u222522 + \u2225\u03b8t \u2212 \u03b8t+1\u222522 \u2212 \u2225\u03b8t+1 \u2212 \u03b8 \u2032\u222522 2\u03b7 + \u03f5 \u2264\u2225\u03b8t \u2212 \u03b8 \u2032\u222522 \u2212 \u2225\u03b8t+1 \u2212 \u03b8\n\u2032\u222522 2\u03b7 + 2\u03b7\u2225\u2207\u03b8Lt(\u03b8t)\u222522 + \u03f5\n(c) \u2264 \u2225\u03b8t \u2212 \u03b8 \u2032\u222522 \u2212 \u2225\u03b8t+1 \u2212 \u03b8 \u2032\u222522 2\u03b7 + \u03b7(K + L\u2212 1)m+ \u03f5\nwhere (a) is because of the definition of gradient descent, (b) is due to the fact 2\u27e8A,B\u27e9 = \u2225A\u22252F + \u2225B\u22252F \u2212 \u2225A\u2212B\u22252F , (c) is by \u2225\u03b8t \u2212 \u03b8t+1\u222522 = \u2225\u03b7\u2207\u03b8Lt(\u03b8t)\u222522 \u2264 O(\u03b72(K + L\u2212 1)m). Then, for T rounds, we have\nT\u2211 t=1 Lt(\u03b8t)\u2212 T\u2211 t=1 Lt(\u03b8\u2032t)\n(a) \u2264 \u2225\u03b81 \u2212 \u03b8 \u2032\u222522\n2\u03b7 + T\u2211 t=2 \u2225\u03b8t \u2212 \u03b8\u2032\u222522( 1 2\u03b7 \u2212 1 2\u03b7 ) + T\u2211 t=1 (L+K \u2212 1)\u03b7m+ T\u03f5\n\u2264\u2225\u03b81 \u2212 \u03b8 \u2032\u222522\n2\u03b7 + T\u2211 t=1 (L+K \u2212 1)\u03b7m+ T\u03f5\n\u2264 R 2\n2m\u03b7 + T (K + L\u2212 1)\u03b7m+ T\u03f5\n(b) \u2264O (\u221a TKR )\nwhere (a) is by simply discarding the last term and (b) is setting by \u03b7 = R m \u221a TK , L \u2264 K, and \u03f5 =\n\u221a KR\u221a T . The proof is completed.\nLemma D.7. Let G = [\u2207\u03b80f(x1;\u03b80)[1],\u2207\u03b80f(x1;\u03b80)[2], . . . ,\u2207\u03b80f(xT ;\u03b80)[K]]/ \u221a m \u2208 Rp\u00d7TK . Let H be the NTK defined in. Then, for any 0 < \u03b4 \u2264 1, suppose m = \u2126(T 4K4L6 log(TKL/\u03b4)\n\u03bb40 ), then\nwith probability at least 1\u2212 \u03b4, we have\n\u2225G\u22a4G\u2212H\u2225F \u2264 \u03bb0/2; G\u22a4G \u2ab0 H/2.\nProof. Using Theorem 3.1 in [4], for any \u03f5 > 0 and \u03b4 \u2208 (0, 1), suppose m = \u2126(L 6 log(L/\u03b4)\n\u03f54 ), for any i, j \u2208 [T ], k, k\u2032 \u2208 [K], with probability at least 1\u2212 \u03b4, the result holds;\n|\u27e8\u2207\u03b80f(xi;\u03b80)[k],\u2207\u03b80f(xj ;\u03b80)[k\u2032]\u27e9/m\u2212Hik,jk\u2032 | \u2264 \u03f5.\nThen, take the union bound over [T ] and [K] and set \u03f5 = \u03bb02TK , with probability at least 1\u2212 \u03b4, the result hold\n\u2225G\u22a4G\u2212H\u2225F = \u221a\u221a\u221a\u221a T\u2211 i=1 K\u2211 k=1 T\u2211 j=1 K\u2211 k\u2032=1 |\u27e8\u2207\u03b80f(xi;\u03b80)[k],\u2207\u03b80f(xi;\u03b80)[k\u2032]\u27e9/m\u2212Hik,jk\u2032 |2\n\u2264 TK\u03f5 = \u03bb0 2\nwhere m = \u2126(L 6T 4K4 log(T 2K2L/\u03b4)\n\u03bb0 ).\nLemma D.8. Define u = [\u2113(y1,1,y1), \u00b7 \u00b7 \u00b7 , \u2113(yT,K ,yT )] \u2208 RTK and S\u2032 = \u221a u\u22a4H\u22121u. With probability at least 1\u2212 \u03b4, the result holds:\ninf \u03b8\u2208B(\u03b80;S\u2032) T\u2211 t=1 Lt(\u03b8) \u2264 \u221a TKS\u2032\nProof. Suppose the singular value decomposition of G is PAQ\u22a4,P \u2208 Rp\u00d7TK ,A \u2208 RTK\u00d7TK ,Q \u2208 RTK\u00d7TK , then, A \u2ab0 0. Define \u03b8\u0302 \u2217 = \u03b80 +PA \u22121Q\u22a4u/ \u221a m. Then, we have\n\u221a mG\u22a4(\u03b8\u2217 \u2212 \u03b80) = QAP\u22a4PA\u22121Q\u22a4u = u.\nwhich leads to T\u2211\nt=1 K\u2211 k=1 |\u2113(yt,k,yt)\u2212 \u27e8\u2207\u03b80f(xt;\u03b80)[k], \u03b8\u0302 \u2217 \u2212 \u03b80\u27e9| = 0.\nTherefore, the result holds:\n\u2225\u03b8\u2217 \u2212 \u03b80\u222522 = u\u22a4QA \u22122Q\u22a4u/m = u\u22a4(G\u22a4G)\u22121u/m \u2264 u\u22a4H\u22121u/m (D.12)\nBased on Lemma D.4, given \u03c9 = R m1/2 and initialize f(xt;\u03b80) \u2192 0, we have T\u2211\nt=1\nLt(\u03b8) \u2264 T\u2211\nt=1 K\u2211 k=1 |yt[k]\u2212 \u27e8\u2207\u03b80f(xt;\u03b80)[k],\u03b8 \u2217 \u2212 \u03b80)|+ TK \u00b7 O ( \u03c91/3L3 \u221a m log(m) ) \u00b7 \u2225\u03b8 \u2212 \u03b80\u22252\n\u2264 T\u2211\nt=1 K\u2211 k=1 |yt[k]\u2212 \u27e8\u2207\u03b80f(xt;\u03b80)[k],\u03b8 \u2217 \u2212 \u03b80)|+ TK \u00b7 O ( \u03c94/3L3 \u221a m log(m) ) \u2264\nT\u2211 t=1 K\u2211 k=1 |yt[k]\u2212 \u27e8\u2207\u03b80f(xt;\u03b80)[k],\u03b8 \u2217 \u2212 \u03b80)|+ TK \u00b7 O ( (R/m1/2)4/3L3 \u221a m log(m) ) (a\n\u2264 T\u2211\nt=1 K\u2211 k=1 |yt[k]\u2212 \u27e8\u2207\u03b80f(xt;\u03b80)[k],\u03b8 \u2217 \u2212 \u03b80)|+ \u221a TKR\nwhere (a) is by the choice of m : m \u2265 \u2126\u0303(T 3K3R2). Therefore, by putting them together, we have\ninf \u03b8\u2208B(\u03b80;R) T\u2211 t=1 Lt(\u03b8) \u2264 \u221a TKS\u2032.\nwhere R = S\u2032 = \u221a u\u22a4H\u22121u.\nD.1 MAIN LEMMAS\nLemma D.9. Suppose m, \u03b71, \u03b72 satisfy the conditions in Theorem 5.2. For any \u03b4 \u2208 (0, 1), with probability at least 1\u2212 \u03b4 over the initialization, it holds uniformly that\n1\nT T\u2211 t=1 E yt\u223cDX|xt [\u2225\u2225\u2225f1(xt; \u03b8\u03021t )\u2212 (ut \u2212 f2(\u03d5(xt); \u03b8\u03022t ))\u2225\u2225\u2225 2 \u2227 1|Ht\u22121 ] \u2264 O (\u221a K\nT \u00b7 S\n) + 2 \u221a 2 log(3/\u03b4)\nT ,\nwhere ut = [\u2113(yt,1,yt), . . . , \u2113(yt,K ,yt)]\u22a4, Ht\u22121 = {x\u03c4 ,y\u03c4}t\u22121\u03c4=1 is historical data.\nProof. This lemma is inspired by Lemma 5.1 in [10]. For any round t \u2208 [T ], define\nVt =E ut\n[ \u2225f2(\u03d5(xt); \u03b8\u0302 2 t )\u2212 (ut \u2212 f1(xt; \u03b8\u0302 1 t ))\u22252 \u2227 1 ]\n\u2212 \u2225f2(\u03d5(xt); \u03b8\u0302 2 t )\u2212 (ut \u2212 f1(xt; \u03b8\u0302 1 t ))\u22252 \u2227 1 (D.13)\nThen, we have\nE[Vt|Ft\u22121] =E ut\n[ \u2225f2(\u03d5(xt); \u03b8\u0302 2 t )\u2212 (ut \u2212 f1(xt; \u03b8\u0302 1 t ))\u22252 \u2227 1 ]\n\u2212 E ut\n[ \u2225f2(\u03d5(xt); \u03b8\u0302 2 t )\u2212 (ut \u2212 f1(xt; \u03b8\u0302 1 t ))\u22252 \u2227 1|Ft\u22121 ]\n=0\n(D.14)\nwhere Ft\u22121 denotes the \u03c3-algebra generated by the history H1t\u22121. Therefore, {Vt}tt=1 are the martingale difference sequence. Then, applying the Hoeffding-Azuma inequality and union bound, we have\nP  1T T\u2211\nt=1\nVt \u2212 1\nT T\u2211 t=1\nE[Vt|Ft\u22121]\ufe38 \ufe37\ufe37 \ufe38 I1 >\n\u221a 2 log(1/\u03b4)\nT  \u2264 \u03b4 (D.15) As I1 is equal to 0, with probability at least 1\u2212 \u03b4, we have\n1\nT T\u2211 t=1 E ut [ \u2225f2(\u03d5(xt); \u03b8\u0302 2 t )\u2212 (ut \u2212 f1(xt; \u03b8\u0302 1 t ))\u22252 \u2227 1 ]\n\u2264 1 T T\u2211 t=1 \u2225f2(\u03d5(xt); \u03b8\u0302 2 t )\u2212 (ut \u2212 f1(xt; \u03b8\u0302 1\nt ))\u22252\ufe38 \ufe37\ufe37 \ufe38 I2 +\n\u221a 2 log(1/\u03b4)\nT\n(D.16)\nFor I2, applying the Lemma D.6 and Lemma D.8 to \u03b82, we have\nI2 \u2264 O( \u221a TKS\u2032). (D.17)\nCombining the above inequalities together and applying the union bound, with probability at least 1\u2212 \u03b4, we have\n1\nT T\u2211 t=1 E ut [ \u2225f2(\u03d5(xt); \u03b8\u0302 2 t )\u2212 (ut \u2212 f1(xt; \u03b8\u0302 1 t ))\u22252 \u2227 1 ]\n\u2264O\n(\u221a K T \u00b7 S\u2032 ) + \u221a 2 log(2/\u03b4) T .\n(D.18)\nApply the Hoeffding-Azuma inequality again on S\u2032, due to E[S\u2032] = S, the result holds:\n1\nT T\u2211 t=1 E ut [ \u2225f2(\u03d5(xt); \u03b8\u0302 2 t )\u2212 (ut \u2212 f1(xt; \u03b8\u0302 1 t ))\u22252 \u2227 1 ]\n\u2264O\n(\u221a K\nT \u00b7 S\n) + 2 \u221a 2 log(3/\u03b4)\nT ,\nwhere the union bound is applied. The proof is completed.\nLemma D.10 is an variance of Lemma D.9 Lemma D.10. Suppose m, \u03b71, \u03b72 satisfy the conditions in Theorem 5.2. For any \u03b4 \u2208 (0, 1), with probability at least 1\u2212 \u03b4 over the random initialization, for all t \u2208 [T ], it holds uniformly that\nE (xt,yt)\u223cD [\u2225\u2225f1(xt;\u03b81t )\u2212 (ut \u2212 f2(\u03d5(xt);\u03b82t ))\u2225\u22252 \u2227 1|H1t\u22121] \u2264 O (\u221a K\nt \u00b7 S\n) + 2 \u221a 2 log(3T/\u03b4)\nt ,\n(D.19)\nwhere ut = (\u2113(yt,1,yt), . . . , \u2113(yt,K ,yt))\u22a4, Ht\u22121 = {x\u03c4 ,y\u03c4}t\u22121\u03c4=1 is historical data, and the expectation is also taken over (\u03b81t ,\u03b8 2 t ).\nProof. For any round \u03c4 \u2208 [t], define\nV\u03c4 = E (x\u03c4 ,y\u03c4 )\u223cD\n[ \u2225f2(\u03d5(x\u03c4 ); \u03b8\u0302 2 \u03c4 )\u2212 (u\u03c4 \u2212 f1(x\u03c4 ; \u03b8\u0302 1 \u03c4 ))\u22252 \u2227 1 ]\n\u2212 \u2225f2(\u03d5(x\u03c4 ); \u03b8\u0302 2 \u03c4 )\u2212 (u\u03c4 \u2212 f1(x\u03c4 ; \u03b8\u0302 1 \u03c4 ))\u22252 \u2227 1 (D.20)\nThen, we have\nE[V\u03c4 |F\u03c4\u22121] = E (x\u03c4 ,y\u03c4 )\u223cD\n[ \u2225f2(\u03d5(x\u03c4 ); \u03b8\u0302 2 \u03c4 )\u2212 (u\u03c4 \u2212 f1(x\u03c4 ; \u03b8\u0302 1 \u03c4 ))\u22252 \u2227 1 ]\n\u2212 E (x\u03c4 ,y\u03c4 )\u223cD\n[ \u2225f2(\u03d5(x\u03c4 ); \u03b8\u0302 2 \u03c4 )\u2212 (u\u03c4 \u2212 f1(x\u03c4 ; \u03b8\u0302 1 \u03c4 ))\u22252 \u2227 1|F\u03c4\u22121 ]\n=0\n(D.21)\nwhere F\u03c4\u22121 denotes the \u03c3-algebra generated by the history H1\u03c4\u22121. Therefore, {V\u03c4}t\u03c4=1 are the martingale difference sequence. Then, applying the Hoeffding-Azuma inequality and union bound, we have\nP 1t t\u2211\n\u03c4=1\nV\u03c4 \u2212 1\nt t\u2211 \u03c4=1\nE[V\u03c4 |F\u03c4\u22121]\ufe38 \ufe37\ufe37 \ufe38 I1 >\n\u221a 2 log(1/\u03b4)\nt  \u2264 \u03b4 (D.22) As I1 is equal to 0, with probability at least 1\u2212 \u03b4, we have\n1\nt t\u2211 \u03c4=1 E (x\u03c4 ,y\u03c4 )\u223cD [ \u2225f2(\u03d5(x\u03c4 ); \u03b8\u0302 2 \u03c4 )\u2212 (u\u03c4 \u2212 f1(x\u03c4 ; \u03b8\u0302 1 \u03c4 ))\u22252 \u2227 1 ]\n\u22641 t t\u2211 \u03c4=1 \u2225f2(\u03d5(x\u03c4 ); \u03b8\u0302 2 \u03c4 )\u2212 (u\u03c4 \u2212 f1(x\u03c4 ; \u03b8\u0302 1 \u03c4 ))\u22252 + \u221a 2 log(1/\u03b4) t\n(D.23)\nBased on the the definition of \u03b81t\u22121,\u03b8 2 t\u22121 in Algorithm 1, we have\nE (xt,yt)\u223cD E (\u03b81,\u03b82)\n[ \u2225f1(xt;\u03b81t )\u2212 (ut \u2212 f2(xt;\u03b8 2 t ))\u22252 \u2227 1 ] = 1\nt t\u2211 \u03c4=1 E (x\u03c4 ,y\u03c4 )\u223cD [ \u2225f1(x\u03c4 ; \u03b8\u0302 1 \u03c4 )\u2212 (u\u03c4 \u2212 f2(x\u03c4 ; \u03b8\u0302 2 \u03c4 ))\u22252 \u2227 1 ] .\n(D.24)\nTherefore, putting them together, we have\nE (xt,yt)\u223cD E (\u03b81,\u03b82)\n[ \u2225f1(xt;\u03b81t\u22121)\u2212 (ut \u2212 f2(xt;\u03b8 2 t ))\u22252 \u2227 1 ] \u22641 t t\u2211 \u03c4=1 \u2225f2(x\u03c4 ; \u03b8\u0302 2 \u03c4 )\u2212 (u\u03c4 \u2212 f1(x\u03c4 ; \u03b8\u0302 1\n\u03c4 ))\u22252\ufe38 \ufe37\ufe37 \ufe38 I2 +\n\u221a 2 log(1/\u03b4)\nt . (D.25)\nFor I2, which is an application of Lemma D.6 and Lemma D.8, we have\nI2 \u2264 O( \u221a tKS\u2032) (D.26)\nwhere (a) is because of the choice of m.\nCombining above inequalities together, with probability at least 1\u2212 \u03b4, we have\nE (xt,yt)\u223cD [\u2223\u2223f1(xt;\u03b81t\u22121) + f2(\u03d5(xt);\u03b82t\u22121)\u2212 ut\u2223\u2223] \u2264 O (\u221a K t \u00b7 S\u2032 ) + \u221a 2 log(2T/\u03b4) t .\n(D.27)\nwhere we apply union bound over \u03b4 to make the above events occur concurrently for all T rounds. Apply the Hoeffding-Azuma inequality again on S\u2032 completes the proof.\nLemma D.11. Suppose m, \u03b71, \u03b72 satisfy the conditions in Theorem 5.2. For any \u03b4 \u2208 (0, 1), \u03b3 > 1, with probability at least 1\u2212 \u03b4 over the random initialization, for all t \u2208 [T ], when It = 0, it holds uniformly that\nE xt\u223cDX [h(xt)[k\u0302]] = E xt\u223cDX\n[h(xt)[k \u2217]],\nProof. As It = 0, we have\n|f(xt;\u03b8t)[k\u0302]\u2212 f(xt;\u03b8t)[k\u25e6]| = f(xt;\u03b8t)[k\u0302]\u2212 f(xt;\u03b8t)[k\u25e6] \u2265 2\u03b3\u03b2t. In round t, based on Lemma D.10, with probability at least 1\u2212 \u03b4, the following event happens:\nE\u03020 = { \u03c4 \u2208 [t], k \u2208 [K], E\nx\u03c4\u223cDX\n[ |f(x\u03c4 ;\u03b8\u03c4 )[k]\u2212 h(x\u03c4 )[k]| ] \u2264 \u03b2\u03c4 } . (D.28)\nWhen E\u03020 happens with probability at least 1\u2212 \u03b4, we have Ext\u223cDX [f(xt;\u03b8t)[k\u0302]]\u2212 \u03b2t \u2264 Ext\u223cDX [h(xt)[k\u0302]] \u2264 Ext\u223cDX [f(xt;\u03b8t)[k\u0302]] + \u03b2tE xt\u223cDX [f(xt;\u03b8t)[k \u25e6]]\u2212 \u03b2t \u2264 E xt\u223cDX [h(xt)[k \u25e6]] \u2264 E xt\u223cDX [f(xt;\u03b8t)[k \u25e6]] + \u03b2t\n(D.29)\nThen, with probability at least 1\u2212 \u03b4,we have\nE xt\u223cDX [h(xt)[k\u0302]\u2212 h(xt)[k\u25e6]] \u2265 E xt\u223cDX [f(xt;\u03b8t)[k\u0302]\u2212 f(xt;\u03b8t)[k\u25e6]]\u2212 2\u03b2t\n\u2265 2\u03b3\u03b2t \u2212 2\u03b2t > 0\n(D.30)\nwhere the last inequality is because of \u03b3 > 1. Then, similarly, for any k\u2032 \u2208 ([K] \\ {k\u0302, k\u25e6}), we have E\nxt\u223cDX [h(xt)[k\u0302] \u2212 h(xt)] \u2265 0. Thus, based on the definition of h(xt)[k\u2217], we have\nE xt\u223cDX [h(xt)[k\u0302]] = E xt\u223cDX [h(xt)[k \u2217]]. The proof is completed.\nLemma D.12. When t \u2265 T\u0304 = O\u0303(\u03b3 2(KS2)\n\u03f52 ), it holds that 2(\u03b3 + 1)\u03b2t \u2264 \u03f5.\nProof. To achieve 2(\u03b3 + 1)\u03b2t \u2264 \u03f5, there exist constants C1, C2, such that\nt \u2265 4(\u03b3 + 1)2 \u00b7\n[ KS2 + log(3T/\u03b4) ] \u03f52\n\u21d2 \u221a KS2\nt +\n\u221a 2 log(3T/\u03b4)\nt ) \u2264 \u03f5 2(\u03b3 + 1)\nThe proof is completed.\nLemma D.13. Suppose m, \u03b71, \u03b72 satisfy the conditions in Theorem 5.2. Under Assumption 5.1, for any \u03b4 \u2208 (0, 1), \u03b3 > 1, with probability at least 1\u2212 \u03b4 over the random initialization, when t \u2265 T\u0304 , it holds uniformly:\nE xt\u223cDX [It] = 0,\nE xt\u223cDX\n[h(xt)[k \u2217]] = E\nxt\u223cDX [h(xt)[k\u0302]].\nProof. Define the events\nE1 = { t \u2265 T\u0304 , E\nxt\u223cDX [h(xt)[k\n\u2217]\u2212 h(xt)[k\u0302]] = 0 } ,\nE2 = { t \u2265 T\u0304 , E\nxt\u223cDX [f(xt;\u03b8t)[k\n\u2217]\u2212 f(xt;\u03b8t)[k\u0302]] = 0 } ,\nE\u03021 = { t \u2265 T\u0304 , E\nxt\u223cDX [f(xt;\u03b8t)[k\n\u2217]\u2212 f(xt;\u03b8t)[k\u25e6]] < 2\u03b3\u03b2t } .\n(D.31)\nThe proof is to prove that E\u03021 will not happen. When E\u03020 Eq. (D.28) happens with probability at least 1\u2212 \u03b4, we have Ext\u223cDX [f(xt;\u03b8t)[k \u2217]]\u2212 \u03b2t \u2264 E xt\u223cDX [h(xt)[k \u2217]] \u2264 E xt\u223cDX [f(xt;\u03b8t)[k \u2217]] + \u03b2t\nE xt\u223cDX [f(xt;\u03b8t)[k \u25e6]]\u2212 \u03b2t \u2264 E xt\u223cDX [h(xt)[k \u25e6]] \u2264 E xt\u223cDX [f(xt;\u03b8t)[k \u25e6]] + \u03b2t\n(D.32)\nTherefore, we have\nE xt\u223cDX\n[h(xt)[k \u2217]\u2212 h(xt)[k\u25e6]] \u2264 E\nxt\u223cDX [f(xt;\u03b8t)[k\n\u2217]] + \u03b2t \u2212 (\nE xt\u223cDX [f(xt;\u03b8t)[k \u25e6]]\u2212 \u03b2t ) \u2264 E\nxt\u223cDX [f(xt;\u03b8t)[k\n\u2217]\u2212 f(xt;\u03b8t)[k\u25e6]] + 2\u03b2t.\nSuppose E\u03021 happens, we have E\nxt\u223cDX [h(xt)[k\n\u2217]\u2212 h(xt)[k\u25e6]] \u2264 2(\u03b3 + 1)\u03b2t.\nThen, based on Lemma D.12, when t > T\u0304 , 2(\u03b3 + 1)\u03b2t \u2264 \u03f5. Therefore, we have E\nxt\u223cDX [h(xt)[k\n\u2217]\u2212 h(xt)[k\u25e6]] \u2264 2(\u03b3 + 1)\u03b2t \u2264 \u03f5.\nThis contradicts Assumption 5.1, i.e., h(xt)[k\u2217]\u2212 h(xt)[k\u25e6] \u2265 \u03f5. Hence, E\u03021 will not happen. Accordingly, with probability at least 1\u2212 \u03b4, the following event will happen\nE\u03022 = { t \u2265 T\u0304 , E\nxt\u223cDX [f(xt;\u03b8t)[k\n\u2217]\u2212 f(xt;\u03b8t)[k\u25e6]] \u2265 2\u03b3\u03b2t } . (D.33)\nTherefore, we have E[f(xt;\u03b8t)[k\u2217]] > E[f(xt;\u03b8t)[k\u25e6]].\nRecall that k\u2217 = argmaxk\u2208[K] h(xt)[k] and k\u0302 = argmaxk\u2208[K] f(xt;\u03b8t)[k]. As\n\u2200k \u2208 ([K] \\ {k\u0302}), f(xt;\u03b8t)[k] \u2264 f(xt;\u03b8t)[k\u25e6]\n\u21d2 \u2200k \u2208 ([K] \\ {k\u0302}), E xt\u223cDX [f(xt;\u03b8t)[k]] \u2264 E xt\u223cDX [f(xt;\u03b8t)[k \u25e6]],\nwe have \u2200k \u2208 ([K] \\ {k\u0302}), E\nxt\u223cDX [f(xt;\u03b8t)[k \u2217]] > E xt\u223cDX [f(xt;\u03b8t)[k]].\nBased on the definition of k\u0302, we have E\nxt\u223cDX [f(xt;\u03b8t)[k \u2217]] = E xt\u223cDX [f(xt;\u03b8t)[k\u0302]] = E xt\u223cDX [max i\u2208[k] f(xt;\u03b8t)[k]]. (D.34)\nThis indicates E2 happens with probability at least 1\u2212 \u03b4.\nTherefore, based on E\u03022 and (D.34), the following inferred event E\u03023 happens with probability at least 1\u2212 \u03b4: E\u03023 = { t \u2265 T\u0304 , E\nxt\u223cDX [f(xt;\u03b8t)[k\u0302]\u2212 f(xt;\u03b8t)[k\u25e6]] \u2265 2\u03b3\u03b2t\n} .\nThen, based on Eq. D.32, we have\nE[h(xt)[k\u0302]\u2212 h(xt)[k\u25e6]] \u2265 E[f(xt;\u03b8t)[k\u0302]]\u2212 \u03b2t \u2212 (E[f(xt;\u03b8t)[k\u25e6]] + \u03b2t)\n= E[f(xt;\u03b8t)[k\u0302]\u2212 f(xt;\u03b8t)[k\u25e6]]\u2212 2\u03b2t E1 \u2265 2(\u03b3 \u2212 1)\u03b2t > 0\n(D.35)\nwhere E1 is because E\u03023 happened with probability at least 1\u2212 \u03b4. Therefore, we have E\nxt\u223cDX [h(xt)[k\u0302]]\u2212 E xt\u223cDX [h(xt)[k\n\u25e6]] > 0.\nSimilarly, we can prove that\n\u21d2 \u2200k \u2208 ([K] \\ {k\u0302}), E xt\u223cDX [h(xt)[k\u0302]]\u2212 E xt\u223cDX [h(xt)[k]] > 0.\nThen, based on the definition of k\u2217, we have E\nxt\u223cDX [h(xt)[k\u0302]] = E xt\u223cDX [h(xt)[k \u2217]] = E xt\u223cDX [max k\u2208[K] h(xt)[k]].\nThus, the event E1 happens with probability at least 1\u2212 \u03b4.\nD.2 LABEL COMPLEXITY\nLemma D.14 (Label Complexity Analysis). For any \u03b4 \u2208 (0, 1), \u03b3 \u2265 1, suppose m satisfies the conditions in Theorem 5.1. Then, with probability at least 1\u2212 \u03b4, we have\nNT \u2264 T\u0304 . (D.36)\nProof. Recall that xt,\u0302i = maxxt,i,i\u2208[k] f(xt;\u03b8t)[k], and xt,i\u25e6 = maxxt,i,i\u2208([k]/{xt,i\u0302}) f(xt;\u03b8t)[k]. With probability at least 1\u2212 \u03b4, according to Eq. (D.28) the event\nE\u03020 = { \u03c4 \u2208 [t], k \u2208 [K], E\nx\u03c4\u223cDX [|f(x\u03c4 ;\u03b8\u03c4 )[k]\u2212 h(x\u03c4 )[k]|] \u2264 \u03b2\u03c4 } happens. Therefore, we have Ext\u223cDX [h(xt)[k\u0302]]\u2212 \u03b2t \u2264 Ext\u223cDX [f(xt;\u03b8t)[k\u0302]] \u2264 Ext\u223cDX [h(xt)[k\u0302]] + \u03b2tE\nxt\u223cDX [h(xt)[k \u25e6]]\u2212 \u03b2t \u2264 E xt\u223cDX [f(xt;\u03b8t)[k \u25e6]] \u2264 E xt\u223cDX [h(xt)[k \u25e6]] + \u03b2t.\nThen, we have Ext\u223cDX [f(xt;\u03b8t)[k\u0302]\u2212 f(xt;\u03b8t)[k \u25e6]] \u2264 E xt\u223cDX [h(xt)[k\u0302]]\u2212 E xt\u223cDX [h(xt)[k \u25e6]] + 2\u03b2t\nE xt\u223cDX [f(xt;\u03b8t)[k\u0302]\u2212 f(xt;\u03b8t)[k\u25e6]] \u2265 E xt\u223cDX [h(xt)[k\u0302]]\u2212 E xt\u223cDX [h(xt)[k \u25e6]]\u2212 2\u03b2t.\n(D.37)\nLet \u03f5t = | E xt\u223cDX [h(xt)[k\u0302]] \u2212 E xt\u223cDX [h(xt)[k \u25e6]]|. Then, based on Lemma D.12 and Lemma D.13, when t \u2265 T\u0304 , we have 2(\u03b3 + 1)\u03b2t \u2264 \u03f5 \u2264 \u03f5t \u2264 1. (D.38) For any t \u2208 [T ] and t < T\u0304 , we have E xt\u223cDX [It] \u2264 1.\nFor the round t > T\u0304 , based on Lemma D.13, it holds uniformly E xt\u223cDX [h(xt)[k\u0302]] \u2212 E\nxt\u223cDX [h(xt)[k\n\u25e6]] = \u03f5t. Then, based on (D.37), we have\nE xt\u223cDX\n[f(xt;\u03b8t)[k\u0302]\u2212 f(xt;\u03b8t)[k\u25e6]] \u2265 \u03f5t \u2212 2\u03b2t E2 \u2265 2\u03b3\u03b2t, (D.39)\nwhere E2 is because of Eq. (D.38).\nAccording to Lemma D.13, when t > T\u0304 , E xt\u223cDX [f(xt;\u03b8t)[k \u2217]] = E xt\u223cDX [f(xt;\u03b8t)[k\u0302]]. Thus, it holds uniformly f(xt;\u03b8t)[k\u0302]\u2212 f(xt;\u03b8t)[k\u25e6] \u2265 2\u03b3\u03b2t, t > T\u0304 .\nThen, for the round t > T\u0304 , we have E xt\u223cDX [It] = 0.\nThen, assume T > T\u0304 , we have\nNT = T\u2211 t=1 E xt\u223cDX [ 1{f(xt;\u03b8t)[k\u0302]\u2212 f(xt;\u03b8t)[k\u25e6] < 2\u03b3\u03b2t} ]\n\u2264 T\u0304\u2211 t=1 1 + T\u2211 t=T\u0304 +1 E xt\u223cDX [ 1{f(xt;\u03b8t)[k\u0302]\u2212 f(xt;\u03b8t)[k\u25e6] < 2\u03b3\u03b2t} ] = T\u0304 + 0.\n(D.40)\nTherefore, we have NT \u2264 T\u0304 .\nTheorem 5.1. [Stream-based]. Given T , for any \u03b4 \u2208 (0, 1), \u03bb0 > 0, suppose \u2225xt\u22252 = 1, t \u2208 [T ], H \u2ab0 \u03bb0I, m \u2265 \u2126\u0303(poly(T,K,L, S) \u00b7 log(1/\u03b4)), \u03b71 = \u03b72 = \u0398( Sm\u221aTK ). Then, with probability at least 1\u2212 \u03b4 over the initialization of \u03b811,\u03b8 2 1, Algorithm 1 achieves the following regret bound:\nRstream(T ) \u2264 O( \u221a T ) \u00b7 (\u221a KS + \u221a 2 log(3T/\u03b4) ) where N(T ) \u2264 O(T ).\nProof. Define Rt = E xt\u223cDX\n[ h(xt)[k\u0302]\u2212 h(xt)[k\u2217] ] .\nRstream(T ) = T\u2211 t=1 Rt(It = 1 \u2228 It = 0)\n\u2264 T\u2211\nt=1\nmax{Rt(It = 1), Rt(It = 0)}\n(a) \u2264 T\u2211\nt=1\nE (xt,yt)\u223cD [\u2225f(xt;\u03b8t\u22121)\u2212 ut\u22252]\n\u2264 T\u2211\nt=1\nO\n(\u221a K\nt \u00b7 S\n) +O (\u221a 2 log(3T/\u03b4)\nt ) \u2264O( \u221a TKS) +O (\u221a 2T log(3T/\u03b4) ) ,\nwhere (a) is based on Lemma D.11: Rt(It = 0) = 0 . The proof is completed.\nTheorem 5.2. [Stream-based]. Given T , for any \u03b4 \u2208 (0, 1), \u03b3 > 1, \u03bb0 > 0, suppose \u2225xt\u22252 = 1, t \u2208 [T ], H \u2ab0 \u03bb0I, m \u2265 \u2126\u0303(poly(T,K,L, S) \u00b7 log(1/\u03b4)), \u03b71 = \u03b72 = \u0398( Sm\u221aTK ), and Assumption 5.1 holds. Then, with probability at least 1\u2212 \u03b4 over the initialization of \u03b811,\u03b8 2 1, Algorithm 1 achieves the following regret bound and label complexity:\nRstream(T ) \u2264O((KS2 + log(3T/\u03b4))/\u03f5) N(T ) \u2264O((KS2 + log(3T/\u03b4))/\u03f52).\nProof. Given T\u0304 , we divide rounds into the follow two pars. Then, it holds that\nRstream(T ) = T\u2211 t=1 Rt(It = 1 \u2228 It = 0)\n= T\u0304\u2211 t=1 Rt(It = 1) + T\u2211 t=T\u0304 +1 Rt(It = 0) = T\u0304\u2211 t=1 E xt\u223cDX\n[h(xt)[k\u0302]\u2212 h(xt)[k\u2217]\ufe38 \ufe37\ufe37 \ufe38 I1 +\nT\u2211 t=T\u0304 +1 E xt\u223cDX\n[h(xt)[k\u0302]\u2212 h(xt)[k\u2217]\ufe38 \ufe37\ufe37 \ufe38 I2\n(D.41)\nFor I1, it holds that\nRt(It = 1) = E xt\u223cDX\n[ h(xt)[k\u0302]\u2212 h(xt)[k\u2217] ] = E\nxt\u223cDX\n[ h(xt)[k\u0302]\u2212 f(xt;\u03b8t)[k\u0302] + f(xt;\u03b8t)[k\u0302]\u2212 h(xt)[k\u2217] ] (a) \u2264 E xt\u223cDX [ h(xt)[k\u0302]\u2212 f(xt;\u03b8t)[k\u0302] + f(xt;\u03b8t)[k\u2217]\u2212 h(xt)[k\u2217]\n] \u2264 E\nxt\u223cDX [|h(xt)[k\u0302]\u2212 f(xt;\u03b8t)[k\u0302]|] + E xt\u223cDX [|f(xt;\u03b8t)[k\u2217]\u2212 h(xt)[k\u2217]|]\n\u2264 2 E xt\u223cDX [\u2225h(xt)\u2212 f(xt;\u03b8t)\u2225\u221e]\n\u2264 2 E (xt,yt)\u223cD [\u2225f(xt;\u03b8t\u22121)\u2212 ut\u22252]\n(b) \u2264 O\n(\u221a K\nT \u00b7 S\n) +O (\u221a 2 log(3T/\u03b4)\nt\n) ,\nwhere (a) is duo the selection criterion of NEURONAL and (b) is an application of D.10. Then,\nI1 \u2264 T\u0304\u2211 t=1 O\n(\u221a K\nT \u00b7 S\n) +O (\u221a 2 log(3T/\u03b4)\nt ) \u2264 (2 \u221a T\u0304 \u2212 1) [\u221a KS + \u221a 2 log(3T/\u03b4)\n] For I2, we have Rt|(It = 0) = E\nxt\u223cDX [h(xt)[k\u0302]\u2212 h(xt)[k\u2217]] = 0 based on Lemma D.13.\nTherefore, it holds that: Rstream(T ) \u2264 (2 \u221a T\u0304 \u2212 1) [\u221a KS + \u221a 2 log(3T/\u03b4) ] .\nThe proof is completed."
        },
        {
            "heading": "E PROOF OF THEOREM 5.3",
            "text": "Define Lt(\u03b8t) = \u2225f(xt;\u03b8t) \u2212 ut\u222522/2, Lt,k(\u03b8t) = (f(xt;\u03b8t)[k] \u2212 ut[k])2/2, and ut = [\u2113(yt,1,yt), . . . , l(yt,K ,yt)].\nLemma E.1 (Almost Convexity). With probability at least 1\u2212O(TL2K) exp[\u2212\u2126(m\u03c92/3L)] over random initialization, for all t \u2208 [T ], and \u03b8,\u03b8\u2032 satisfying \u2225\u03b8 \u2212 \u03b81\u22252 \u2264 \u03c9 and \u2225\u03b8\u2032 \u2212 \u03b81\u22252 \u2264 \u03c9 with \u03c9 \u2264 O(L\u22126[logm]\u22123/2), it holds uniformly that\nLt(\u03b8\u2032) \u2265 Lt(\u03b8)/2 + K\u2211\nk=1\n\u27e8\u2207\u03b8Lt,k(\u03b8),\u03b8\u2032 \u2212 \u03b8\u27e9 \u2212 \u03f5.\nwhere \u03c9 \u2264 O ( (Km logm)\u22123/8L\u22129/4\u03f53/4 ) .\nProof. Let Lt,k(\u03b8) be the loss function with respect to f(xt;\u03b8\u2032)[k]. By convexity of Lt, it holds uniformly that\n\u2225f(xt;\u03b8\u2032)\u2212 ut\u222522/2\u2212 \u2225f(xt;\u03b8)\u2212 ut\u222522/2\n\u2265 K\u2211\nk=1\nL\u2032t,k(\u03b8) ( f(xt;\u03b8 \u2032)[k]\u2212 f(xt;\u03b8)[k] )\n(b) \u2265 K\u2211\nk=1\nL\u2032t,k(\u03b8)\u27e8\u2207f(xt;\u03b8)[k],\u03b8 \u2032 \u2212 \u03b8\u27e9\n\u2212 K\u2211\nk=1 \u2223\u2223L\u2032t,k(\u03b8) \u00b7 [f(xt;\u03b8\u2032)[k]\u2212 f(xt;\u03b8)[k]\u2212 \u27e8\u2207f(xt;\u03b8)[k],\u03b8\u2032 \u2212 \u03b8\u27e9]\u2223\u2223 (c)\n\u2265 K\u2211\nk=1\n\u27e8\u2207\u03b8Lt,k(\u03b8),\u03b8\u2032 \u2212 \u03b8\u27e9\n\u2212 K\u2211\nk=1\n( |f(xt;\u03b8)[k]\u2212 ut[k]| \u00b7 |f(xt;\u03b8\u2032)[k]\u2212 f(xt;\u03b8)[k]\u2212 \u27e8\u2207f(xt;\u03b8)[k],\u03b8\u2032 \u2212 \u03b8\u27e9| ) (d)\n\u2265 K\u2211\nk=1\n\u27e8\u2207\u03b8Lt,k(\u03b8),\u03b8\u2032 \u2212 \u03b8\u27e9 \u2212 O ( \u03c94/3L3\n\u221a m logm)\u221a K\n) \u00b7 K\u2211 k=1 |f(xt;\u03b8)[k]\u2212 ut[k]|\n(e) \u2265 K\u2211\nk=1\n\u27e8\u2207\u03b8Lt,k(\u03b8),\u03b8\u2032 \u2212 \u03b8\u27e9 \u2212 O ( \u03c94/3L3\n\u221a m logm)\u221a K\n) \u00b7 K\u2211 k=1 ( |f(xt;\u03b8)[k]\u2212 ut[k]|2 + 1 4 ) where (a) is due to the convexity of Lt, (b) is an application of triangle inequality, (c) is because of the Cauchy\u2013Schwarz inequality, and (d) is the application of Lemma D.4 and Lemma D.3, (e) is by\nthe fact x \u2264 x2 + 14 . Therefore, the results hold \u2225f(xt;\u03b8\u2032)\u2212 ut\u222522/2\u2212 \u2225f(xt;\u03b8)\u2212 ut\u222522/2\n\u2264 K\u2211\nk=1\n\u27e8\u2207\u03b8Lt,k(\u03b8),\u03b8\u2032 \u2212 \u03b8\u27e9 \u2212 O ( \u03c94/3L3\n\u221a m logm)\u221a K ) \u00b7 \u2225f(xt;\u03b8)\u2212 ut\u222522\n\u2212 ( \u03c94/3L3\n\u221a m logm)\u221a K ) \u00b7 K 4\n(a) \u2264 K\u2211\nk=1\n\u27e8\u2207\u03b8Lt,k(\u03b8),\u03b8\u2032 \u2212 \u03b8\u27e9 \u2212 1\n4 \u00b7 \u2225f(xt;\u03b8)\u2212 ut\u222522\n\u2212 ( \u03c94/3L3\n\u221a m logm)\u221a K ) \u00b7 K 4\nwhere (a) holds when \u03c9 \u2264 O ( 4\u22123/4K3/8(m logm)\u22123/8L\u22129/4 ) .\nIn the end, when \u03c9 \u2264 O ( 4\u22123/4(Km logm)\u22123/8L\u22129/4\u03f53/4 ) , the result hold:\n\u2225f(xt;\u03b8\u2032)\u2212 ut\u222522/2\u2212 \u2225f(xt;\u03b8)\u2212 ut\u222522/4\n\u2264 K\u2211\nk=1\n\u27e8\u2207\u03b8Lt,k(\u03b8),\u03b8\u2032 \u2212 \u03b8\u27e9 \u2212 \u03f5.\nThe proof is completed.\nLemma E.2. With the probability at least 1\u2212O(TL2K) exp[\u2212\u2126(m\u03c92/3L)] over random initialization, for all t \u2208 [T ], \u2225\u03b8\u2032 \u2212 \u03b81\u2225 \u2264 \u03c9, and\u03c9 \u2264 O(L\u22129/2[logm]\u22123), the results hold:\nf(xt;\u03b8 \u2032) \u2264 logm\nProof. Using Lemma 7.1 in [3], we have gt,L\u22121 \u2264 O(1), Then, Based on the randomness of WL, the result hold: f(xt;\u03b8\u2032) \u2264 logm (analogical analysis as Lemma 7.1). Using Lemma 8.2 in [3], we have g\u2032t,L\u22121 \u2264 O(1), and thus f(xt;\u03b8 \u2032) \u2264 logm\nLemma E.3 (Loss Bound). With probability at least 1\u2212O(TL2K) exp[\u2212\u2126(m\u03c92/3L)] over random initialization, it holds that\nT\u2211 t=1 \u2225f(xt;\u03b8t)\u2212 ut\u222522/2 \u2264 inf \u03b8\u2032\u2208B(\u03b80;) T\u2211 t=1 \u2225f(xt;\u03b8\u2032)\u2212 ut\u222522 + 4LKR2 (E.1)\nwhere \u03b8\u2217 = arg inf\u03b8\u2208B(\u03b81,R) \u2211T t=1 Lt(\u03b8). Proof. Let \u03c9 \u2264 O ( (Km logm)\u22123/8L\u22129/4\u03f53/4 ) , such that the conditions of Lemma D.5 are satisfied.\nThe proof follows a simple induction. Obviously, \u03b81 is in B(\u03b81, R). Suppose that \u03b81,\u03b82, . . . ,\u03b8T \u2208 B(\u03b81, R). We have, for any t \u2208 [T ],\n\u2225\u03b8T \u2212 \u03b81\u22252 \u2264 T\u2211\nt=1\n\u2225\u03b8t+1 \u2212 \u03b8t\u22252 \u2264 T\u2211\nt=1\n\u03b7\u2225\u2207Lt(\u03b8t)\u22252\n\u2264 \u03b7 \u00b7 T\u2211\nt=1\n\u2225f(xt;\u03b8t)\u2212 ut\u22252 \u00b7 \u2225\u2207\u03b8tf(xt;\u03b8t)\u22252\n\u2264 \u03b7 \u00b7 \u221a Lm T\u2211 t=1 \u2225f(xt;\u03b8t)\u2212 ut\u22252\n(a) \u2264 \u03b7 \u00b7 \u221a LmT \u00b7 logm\n(b) \u2264 \u03c9\nwhere (a) is applying Lemma E.2 and (b) holds when m \u2265 \u2126\u0303(T 8K\u22121L14\u03f5\u22126).\nMoreover, when m > \u2126\u0303(R8T 8K3L18\u03f5\u22126), it leads to R\u221a m \u2264 \u03c9. In round t, based on Lemma D.5, for any \u2225\u03b8t \u2212 \u03b8\u2032\u22252/2 \u2264 \u03c9, it holds uniformly\n\u2225f(xt;\u03b8t)\u2212 ut\u222522/4\u2212 \u2225f(xt;\u03b8 \u2032)\u2212 ut\u222522/2 \u2264 K\u2211 k=1 \u27e8\u2207\u03b8Lt,k(\u03b8t),\u03b8t \u2212 \u03b8\u2032\u27e9+ \u03f5.\nThen, it holds uniformly\n\u2225f(xt;\u03b8t)\u2212 ut\u222522/4\u2212 \u2225f(xt;\u03b8 \u2032)\u2212 ut\u222522/2\n(a) \u2264 \u27e8\u03b8t \u2212 \u03b8t+1,\u03b8t \u2212 \u03b8 \u2032\u27e9\n\u03b7 + \u03f5\n(b) = \u2225\u03b8t \u2212 \u03b8\u2032\u222522 + \u2225\u03b8t \u2212 \u03b8t+1\u222522 \u2212 \u2225\u03b8t+1 \u2212 \u03b8 \u2032\u222522 2\u03b7 + \u03f5\n(c) \u2264 \u2225\u03b8t \u2212 \u03b8 \u2032\u222522 \u2212 \u2225\u03b8t+1 \u2212 \u03b8 \u2032\u222522 2\u03b7\n+ \u03b7\u2225 K\u2211\nk=1\n\u2207\u03b8tLt,k(\u03b8t)\u22252F + \u03f5\n\u2264\u2225\u03b8t \u2212 \u03b8 \u2032\u222522 \u2212 \u2225\u03b8t+1 \u2212 \u03b8 \u2032\u222522 2\u03b7\n+ \u03b7\u2225 K\u2211\nk=1\n(f(xt;\u03b8t)[k]\u2212 ut[k]) \u00b7 \u2207\u03b8tf(xt;\u03b8t)[k]\u222522 + \u03f5\n\u2264\u2225\u03b8t \u2212 \u03b8 \u2032\u222522 \u2212 \u2225\u03b8t+1 \u2212 \u03b8 \u2032\u222522 2\u03b7 + \u03b7mL K\u2211 k=1 |(f(xt;\u03b8t)[k]\u2212 ut[k])|2 + \u03f5 \u2264\u2225\u03b8t \u2212 \u03b8 \u2032\u222522 \u2212 \u2225\u03b8t+1 \u2212 \u03b8\n\u2032\u222522 2\u03b7 + \u03b7mLK\u2225f(xt;\u03b8t)\u2212 ut\u222522 + \u03f5\nwhere (a) is because of the definition of gradient descent, (b) is due to the fact 2\u27e8A,B\u27e9 = \u2225A\u22252F + \u2225B\u22252F \u2212 \u2225A\u2212B\u22252F , (c) is by \u2225\u03b8t \u2212 \u03b8t+1\u222522 = \u2225\u03b7\u2207\u03b8Lt(\u03b8t)\u222522 \u2264 O(\u03b72KLm). Then, for T rounds, we have\nT\u2211 t=1 \u2225f(xt;\u03b8t)\u2212 ut\u222522/4\u2212 T\u2211 t=1 \u2225f(xt;\u03b8\u2032)\u2212 ut\u222522/2\n(a) \u2264 \u2225\u03b81 \u2212 \u03b8 \u2032\u222522\n2\u03b7 + T\u2211 t=2 \u2225\u03b8t \u2212 \u03b8\u2032\u222522( 1 2\u03b7 \u2212 1 2\u03b7 ) + T\u2211 t=1 \u03b7mLK\u2225f(xt;\u03b8t)\u2212 ut\u222522 + T\u03f5\n\u2264\u2225\u03b81 \u2212 \u03b8 \u2032\u222522\n2\u03b7 + T\u2211 t=1 \u03b7mLK\u2225f(xt;\u03b8t)\u2212 ut\u222522 + T\u03f5\n\u2264 R 2\n2m\u03b7 + \u03b7mLK T\u2211 t=1 \u2225f(xt;\u03b8t)\u2212 ut\u222522 + T\u03f5\n\u22645R2LK + T\u2211\nt=1\n\u2225f(xt;\u03b8t)\u2212 ut\u222522/8\nwhere (a) is by simply discarding the last term and (b) is setting by \u03b7 = 1mLK and \u03f5 = KR2L\nT . Based on the above inequality, taking the infimum over \u03b8\u2032 \u2208 B(\u03b8\u221e,R), the results hold :\nT\u2211 t=1 \u2225f(xt;\u03b8t)\u2212 ut\u222522/8 \u2264 inf \u03b8\u2032\u2208B(\u03b8\u221e,R) T\u2211 t=1 \u2225f(xt;\u03b8\u2032)\u2212 ut\u222522/2 + 5LKR2.\nThe proof is completed.\nLemma E.4. Let R = S\u2032 = \u221a u\u22a4h\u22121u. With probability at least 1\u2212O(TL2K) exp[\u2212\u2126(m\u03c92/3L)] , the result holds that\ninf \u03b8\u2208B(\u03b80;R) T\u2211 t=1 Lt(\u03b8) \u2264 O(LK)\nProof. Let G = [\u2207\u03b80f(x1;\u03b80)[1],\u2207\u03b80f(x1;\u03b80)[2], . . . ,\u2207\u03b80f(xT ;\u03b80)[K]]/ \u221a m \u2208 Rp\u00d7TK . Suppose the singular value decomposition of G is PAQ\u22a4,P \u2208 Rp\u00d7TK ,A \u2208 RTK\u00d7TK ,Q \u2208 RTK\u00d7TK , then, A \u2ab0 0. Define \u03b8\u2217 = \u03b80 +PA\u22121Q\u22a4u/ \u221a m. Then, we have\n\u221a mG\u22a4(\u03b8\u2217 \u2212 \u03b80) = QAP\u22a4PA\u22121Q\u22a4u = u.\nThis leads to\nT\u2211 t=1 K\u2211 k=1 |ut[k]\u2212 \u27e8\u2207\u03b80f(xt;\u03b80)[k],\u03b8 \u2217 \u2212 \u03b80\u27e9| = 0.\nTherefore, the result holds:\n\u2225\u03b8\u2217 \u2212 \u03b80\u222522 = u\u22a4QA \u22122Q\u22a4u/m = u\u22a4(G\u22a4G)\u22121u/m \u2264 2u\u22a4H\u22121u/m (E.2)\nBased on Lemma D.4 and initialize (xt;\u03b80) = 0, t \u2208 [T], we have\nT\u2211 t=1 Lt(\u03b8\u2217) \u2264 T\u2211 t=1 K\u2211 k=1 ( ut[k]\u2212 \u27e8\u2207\u03b80f(xt;\u03b80)[k],\u03b8 \u2217 \u2212 \u03b80\u27e9 \u2212 O(\u03c94/3L3 \u221a m log(m)) )2 \u2264\nT\u2211 t=1 K\u2211 k=1 (ut[k]\u2212 \u27e8\u2207\u03b80f(xt;\u03b80)[k],\u03b8 \u2217 \u2212 \u03b80\u27e9)2 + TK \u00b7 O(\u03c98/3L6m log(m))\n\u2264 T\u2211\nt=1 K\u2211 k=1 (ut[k]\u2212 \u27e8\u2207\u03b80f(xt;\u03b80)[k],\u03b8 \u2217 \u2212 \u03b80\u27e9)2 + TK \u00b7 O((S\u2032/m1/2)8/3L6m log(m))\n\u2264 T\u2211\nt=1 K\u2211 k=1 (ut[k]\u2212 \u27e8\u2207\u03b80f(xt;\u03b80)[k],\u03b8 \u2217 \u2212 \u03b80\u27e9)2 +O(LK)\n\u2264 O(LK)\nBecause \u03b8\u2217 \u2208 B(\u03b80, S\u2032), the proof is completed.\nLemma E.5. Suppose m, \u03b71, \u03b72 satisfy the conditions in Theorem 5.3. With probability at least 1\u2212 \u03b4, for all t \u2208 [Q], it holds uniformly that\n1\nt t\u2211 \u03c4=1 [ \u2225f2(\u03d5(x\u03c4 );\u03b82\u03c4 )\u2212 (h(x\u03c4 )\u2212 f1(x\u03c4 ;\u03b8 1 \u03c4 ))\u22252 \u2227 1 ] \u2264 \u221a O(LKS2) t + 2 \u221a 2 log(1/\u03b4) t (E.3)\nut = (\u2113(yt,1,yt), . . . , \u2113(yt,K ,yt)) \u22a4, Ht\u22121 = {x\u03c4 ,y\u03c4}t\u22121\u03c4=1 is historical data, and the expectation is also taken over (\u03b81t ,\u03b8 2 t ).\nProof. Then, applying the Hoeffding-Azuma inequality as same as in Lemma D.6, we have\n1\nt t\u2211 \u03c4=1 [ \u2225f2(\u03d5(x\u03c4 );\u03b82\u03c4 )\u2212 (h(x\u03c4 )\u2212 f1(x\u03c4 ;\u03b8 1 \u03c4 ))\u22252 \u2227 1 ] \u22641 t t\u2211 \u03c4=1 \u2225f2(\u03d5(x\u03c4 );\u03b82\u03c4 )\u2212 (u\u03c4 \u2212 f1(x\u03c4 ;\u03b8 1 \u03c4 ))\u22252 + \u221a 2 log(1/\u03b4) t\n\u22641 t \u221a\u221a\u221a\u221at t\u2211 \u03c4=1 \u2225f2(\u03d5(x\u03c4 );\u03b82\u03c4 )\u2212 (u\u03c4 \u2212 f1(x\u03c4 ;\u03b8 1 \u03c4 ))\u222522 + \u221a 2 log(1/\u03b4) t\n(a) \u2264 \u221a\nO(LKS\u20322) t +\n\u221a 2 log(1/\u03b4)\nt (b) \u2264 \u221a\nO(LKS2) t + 2\n\u221a 2 log(1/\u03b4)\nt\n(E.4)\nwhere (a) is an application of Lemma E.3 and Lemma E.4 and (b) is applying the Hoeffding-Azuma inequality again on S\u2032. The proof is complete.\nLemma E.6. Suppose m, \u03b71, \u03b72 satisfy the conditions in Theorem 5.3. With probability at least 1\u2212 \u03b4, the result holds:\nQ\u2211 t=1 \u2211 xi\u2208Pt pi(h(xi)[k\u0302]\u2212 h(xi)[k\u2217]) \u2264 \u03b3 4 Q\u2211 t=1 \u2211 xi\u2208Pt pi(f(xi;\u03b8t)[k \u2217]\u2212 h(xi)[k\u2217])2 + Q \u03b3\n+ \u221a QKS2 +O(log(1/\u03b4))\nProof. For some \u03b7 > 0, we have\nQ\u2211 t=1 \u2211 xi\u2208Pt pi(h(xi)[k\u0302]\u2212 h(xi)[k\u2217])\u2212 \u03b7 Q\u2211 t=1 \u2211 xi\u2208Pt pi(f(xi;\u03b8t)[k \u2217]\u2212 h(xi)[k\u2217])2\n= Q\u2211 t=1 \u2211 xi\u2208Pt pi[(h(xi)[k\u0302]\u2212 h(xi)[k\u2217])\u2212 \u03b7(f(xi;\u03b8t)[k\u2217]\u2212 h(xi)[k\u2217])2]\n= Q\u2211 t=1 \u2211 xi\u2208Pt pi[(h(xi)[k\u0302]\u2212 f(xi;\u03b8t)[k\u0302]) + (f(xi;\u03b8t)[k\u0302]\u2212 h(xi)[k\u2217])\u2212 \u03b7(f(xi;\u03b8t)[k\u2217]\u2212 h(xi)[k\u2217])2]\n\u2264 Q\u2211 t=1 \u2211 xi\u2208Pt pi[(h(xi)[k\u0302]\u2212 f(xi;\u03b8t)[k\u0302]) + (f(xi;\u03b8t)[k\u2217]\u2212 h(xi)[k\u2217])\u2212 \u03b7(f(xi;\u03b8t)[k\u2217]\u2212 h(xi)[k\u2217])2]\n(a) \u2264 Q\u2211 t=1 \u2211 xi\u2208Pt pi(h(xi)[k\u0302]\u2212 f(xi;\u03b8t)[k\u0302]) + Q 4\u03b7\n(b) \u2264 Q\u2211 t=1 \u2225ut \u2212 f(xt;\u03b8t)\u22252 +O(log(1/\u03b4)) + Q 4\u03b7\n(c) \u2264 \u221a QKS2 +O(log(1/\u03b4)) + Q\n4\u03b7\nwhere (a) is an application of AM-GM: x \u2212 \u03b7x2 \u2264 1\u03b7 and (b) is application of Lemma E.7. (c) is based on Lemma E.5. Then, replacing \u03b7 by \u03b34 completes the proof.\nLemma E.7. (Lemma 2, [22]) With probability 1\u2212 \u03b4, the result holds: Q\u2211 t=1 \u2211 xi\u2208Pt pi\u2225f(xi;\u03b8t)\u2212 h(xi)\u222522 \u2264 2 Q\u2211 t=1 \u2225f(xt;\u03b8t)\u2212 ut\u222522 +O(log(1/\u03b4)).\nFinally, we show the proof of Theorem 5.3.\nProof. Assume the event in E.7 holds. We have\nRpool(Q) = Q\u2211 t=1 [ E (xt,yt)\u223cD [\u2113(yt,k\u0302,yt)]\u2212 E(xt,yt)\u223cD [\u2113(yt,k\u2217 ,yt)] ]\n= Q\u2211 t=1 [ E xt\u223cDX [h(xt)[k\u0302]]\u2212 E xt\u223cDX [h(xt)[k \u2217]] ]\n(a) \u2264 Q\u2211 t=1 E[h(xt)[k\u0302]\u2212 h(xt)[k\u2217]] + \u221a 2Q log(2/\u03b4)\n\u2264 Q\u2211 t=1 \u2211 xi\u2208Pt pi(h(xi)[k\u0302]\u2212 h(xi)[k\u2217]) + \u221a 2Q log(2/\u03b4)\nwhere (a) is an application of Azuma-Hoeffding inequality. Next, applying Lemma E.6 and Letting \u03be = \u221a QKS2 +O(log(1/\u03b4)), we have\nRpool(Q) (a) \u2264 \u03b3 4 Q\u2211 t=1 \u2211 xi\u2208Pt pi(f(xi;\u03b8t)[k \u2217]\u2212 h(xi)[k\u2217])2 + Q \u03b3 + \u221a 2Q log(2/\u03b4) + \u03be\n\u2264 \u03b3 4 Q\u2211 t=1 \u2211 xi\u2208Pt pi\u2225f(xi;\u03b8t)\u2212 h(xi)\u222522 + Q \u03b3 + \u221a 2Q log(2/\u03b4) + \u03be\n(b) \u2264 \u03b3 2 Q\u2211 t=1 \u2225f(xi;\u03b8t)\u2212 ut)\u22252 + \u03b3 log(\u03b4\u22121)/4 + Q \u03b3 + \u221a 2Q log(2/\u03b4) + \u03be\n(c) \u2264 \u03b3 2 KS2 + \u03b3 log(2\u03b4\u22121)/4 + Q \u03b3 + \u221a 2Q log(2/\u03b4) + \u221a QKS2 +O(log(1/\u03b4))\n\u2264 \u221a O(QKS2) +\n\u221a Q\nKS2 \u00b7 O(log(\u03b4\u22121)) +O(\n\u221a 2Q log(3/\u03b4))\nwhere (a) follows from E.6, (b) follows from E.7, (c) is based on Lemma E.5, and we apply the union bound to the last inequality and choose \u03b3 = \u221a\nQ KS2 . Therefore:\nRpool(Q) \u2264 O( \u221a QKS) +O\n(\u221a Q\nKS2\n) \u00b7 log(\u03b4\u22121) +O( \u221a 2Q log(3/\u03b4))\nThe proof is complete."
        },
        {
            "heading": "F ANALYSIS IN BINARY CLASSIFICATION",
            "text": "First, we provide the noise condition used in [48].\nAssumption F.1 ( Mammen-Tsybakov low noise [35; 48]). There exist absolute constants c > 0 and \u03b1 \u2265 0, such that for all 0 < \u03f5 < 1/2,x \u2208 X , k \u2208 {0, 1}, P(|h(x)[k]\u2212 12 | \u2264 \u03f5) \u2264 c\u03f5 \u03b1.\nThen, we provide the following theorem.\nTheorem F.1. Given T , for any \u03b4 \u2208 (0, 1), \u03bb0 > 0, suppose K = 2, \u2225xt\u22252 = 1, t \u2208 [T ], H \u2ab0 \u03bb0I, m \u2265 \u2126\u0303(poly(T, L, S) \u00b7 log(1/\u03b4)), \u03b71 = \u03b72 = \u0398( Sm\u221a2T ). Then, with probability at least 1\u2212 \u03b4 over\nthe initialization of \u03b811,\u03b8 2 1, Algorithm 1 achieves the following regret bound:\nRstream(T ) \u2264 O\u0303((S2) \u03b1+1 \u03b1+2T 1 \u03b1+2 ),\nN(T ) \u2264 O\u0303((S2) \u03b1 \u03b1+2T 2 \u03b1+2 ).\nIn comparison, with assumption F.1, [48] achieves the following results: Rstream(T ) \u2264 O\u0303 ( LH 2(\u03b1+1) \u03b1+2 T 1 \u03b1+2 ) + O\u0303 ( LH \u03b1+1 \u03b1+2 (S2) \u03b1+1 \u03b1+2T 1 \u03b1+2 ) ,\nN(T ) \u2264 O\u0303 ( LH 2\u03b1 \u03b1+2T 2 \u03b1+2 ) + O\u0303 ( LH \u03b1 \u03b1+2 (S2) \u03b1 \u03b1+2T 2 \u03b1+2 ) .\nFor the regret Rstream(T ), compared to [48], Theorem F.1 removes the term O\u0303 ( LH 2(\u03b1+1) \u03b1+2 T 1 \u03b1+2 ) and further improve the regret upper bound by a multiplicative factor LH \u03b1+1 \u03b1+2 . For the label complexity\nN(T ), compared to [48], Theorem F.1 removes the term O\u0303 ( LH 2\u03b1 \u03b1+2T 2 \u03b1+2 ) and further improve the\nregret upper bound by a multiplicative factor LH \u03b1\n\u03b1+2 . It is noteworthy that LH grows linearly with respect to T , i.e., LH \u2265 T log(1 + \u03bb0).\nProof. First, we define \u2206t = h(xt)[k\u0302]\u2212 h(xt)[k\u25e6]\n\u2206\u0302t = f(xt;\u03b8t)[k\u0302]\u2212 f(xt;\u03b8t)[k\u25e6] + 2\u03b2t\nT\u03f5 = T\u2211 t=1 Ext\u223cDX [1{\u22062t \u2264 \u03f52}].\n(F.1)\nLemma F.1. Suppose the conditions of Theorem F.1 are satisfied. With probability at least 1\u2212 \u03b4, the following result holds: NT \u2264 O ( T\u03f5 + 1\n\u03f52 (S2 + log(3T/\u03b4))\n) .\nProof. First, based on Lemma D.11, with probability at least 1\u2212 \u03b4, we have 0 \u2264 \u2206\u0302t \u2212\u2206t \u2264 4\u03b2t. Because \u2206\u0302t \u2265 0, then \u2206\u0302t \u2264 4\u03b2t implies \u2206t \u2264 4\u03b2t. Then, we have\nIt = It1{\u2206\u0302t \u2264 4\u03b2t} \u2264 It1{\u2206\u0302t \u2264 4\u03b2t, 4\u03b2t \u2265 \u03f5}+ It1{\u2206\u0302t \u2264 4\u03b2t, 4\u03b2t < \u03f5}\n\u2264 16It\u03b2 2 t\n\u03f52 \u2227 1 + 1{\u22062t \u2264 \u03f52}.\nThus, we have\nNT = T\u2211 t=1 Ext\u223cDX [It1{\u2206\u0302t \u2264 4\u03b2t}]\n\u2264 1 \u03f52 T\u2211 t=1 (16It\u03b2 2 t \u2227 \u03f52) + T\u03f5\n\u2264 1 \u03f52 T\u2211 t=1 (16It\u03b2 2 t \u2227 1 4 ) + T\u03f5\n\u2264 16 \u03f52 (2S2 + 2 log(3T/\u03b4)) + T\u03f5 = O( 1 \u03f52 (2S2 + 2 log(3T/\u03b4))) + T\u03f5.\nThe proof is completed.\nLemma F.2. Suppose the conditions of Theorem F.1 are satisfied. With probability at least 1\u2212 \u03b4, the following result holds: RT \u2264 O ( \u03f5T\u03f5 + 1\n\u03f5 (S2 + log(3T/\u03b4)) ) Proof.\nRT = T\u2211 t=1 E xt\u223cDX [ h(xt)[k\u0302]\u2212 h(xt)[k\u2217] ] \u2264\nT\u2211 t=1 E xt\u223cDX [|\u2206t|]\n= T\u2211 t=1 E xt\u223cDX [|\u2206t|1{|\u2206t| > \u03f5}] + T\u2211 t=1 E xt\u223cDX [|\u2206t|1{|\u2206t| \u2264 \u03f5}]\nwhere the second term is upper bounded by \u03f5T\u03f5. For the first term, we have\nT\u2211 t=1 E xt\u223cDX [|\u2206t|1{|\u2206t| > \u03f5}]\n\u22641 \u03f5 T\u2211 t=1 E xt\u223cDX [|\u2206t|2] \u2227 \u03f5\n(a) \u2264 1 \u03f5 T\u2211 t=1 E xt\u223cDX [|\u2206t|21{\u2206t \u2264 2\u03b2t}] \u2227 \u03f5+ 1 \u03f5 T\u2211 t=1 E xt\u223cDX [|\u2206t|21{\u2206t > 2\u03b2t}] \u2227 \u03f5\n\u22641 \u03f5 T\u2211 t=1 4\u03b22t \u2227 1 2\n\u2264O ( 1\n\u03f5 (2S2 + 2 log(3T/\u03b4)) ) where the second term in (a) is zero based on the Lemma D.13. The proof is completed.\nThen, because x1, ...,xT are generated i.i.d. with Assumption F.1. Then, applying Lemma 23 in [48], with probability at least 1\u2212 \u03b4, the result holds:\nT\u03f5 \u2264 3T\u03f5\u03b1 +O(log log T\n\u03b4 ).\nUsing the above bound of T\u03f5 back into both Lemma F.1 and Lemma F.2, and then optimizing over \u03f5 in the two bounds separately complete the proof:\nRT \u2264 O((S2 + log(3T/\u03b4)) \u03b1+1 \u03b1+2T 1 \u03b1+2 ),\nNT \u2264 O((S2 + log(3T/\u03b4)) \u03b1 \u03b1+2T 2 \u03b1+2 )."
        }
    ],
    "title": "NEURAL ACTIVE LEARNING BEYOND BANDITS",
    "year": 2023
}