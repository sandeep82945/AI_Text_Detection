{
    "abstractText": "Known for their impressive performance in generative modeling, diffusion models are attractive candidates for density-based anomaly detection. This paper investigates different variations of diffusion modeling for unsupervised and semisupervised anomaly detection. In particular, we find that Denoising Diffusion Probability Models (DDPM) are performant on anomaly detection benchmarks yet computationally expensive. By simplifying DDPM in application to anomaly detection, we are naturally led to an alternative approach called Diffusion Time Estimation (DTE). DTE estimates the distribution over diffusion time for a given input and uses the mode or mean of this distribution as the anomaly score. We derive an analytical form for this density and leverage a deep neural network to improve inference efficiency. Through empirical evaluations on the ADBench benchmark, we demonstrate that all diffusion-based anomaly detection methods perform competitively for both semi-supervised and unsupervised settings. Notably, DTE achieves orders of magnitude faster inference time than DDPM, while outperforming it on this benchmark. These results establish diffusion-based anomaly detection as a scalable alternative to traditional methods and recent deep-learning techniques for standard unsupervised and semi-supervised anomaly detection settings.",
    "authors": [
        {
            "affiliations": [],
            "name": "ANOMALY DETEC"
        }
    ],
    "id": "SP:a2261d1eaa7512a06d8dedc8028ddfae3c7dd495",
    "references": [],
    "sections": [
        {
            "text": "Known for their impressive performance in generative modeling, diffusion models are attractive candidates for density-based anomaly detection. This paper investigates different variations of diffusion modeling for unsupervised and semisupervised anomaly detection. In particular, we find that Denoising Diffusion Probability Models (DDPM) are performant on anomaly detection benchmarks yet computationally expensive. By simplifying DDPM in application to anomaly detection, we are naturally led to an alternative approach called Diffusion Time Estimation (DTE). DTE estimates the distribution over diffusion time for a given input and uses the mode or mean of this distribution as the anomaly score. We derive an analytical form for this density and leverage a deep neural network to improve inference efficiency. Through empirical evaluations on the ADBench benchmark, we demonstrate that all diffusion-based anomaly detection methods perform competitively for both semi-supervised and unsupervised settings. Notably, DTE achieves orders of magnitude faster inference time than DDPM, while outperforming it on this benchmark. These results establish diffusion-based anomaly detection as a scalable alternative to traditional methods and recent deep-learning techniques for standard unsupervised and semi-supervised anomaly detection settings."
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "Anomaly detection seeks to identify observations that differ from the others to such a large extent that they are likely generated by a different mechanism (Hawkins, 1980). This is a longstanding research problem in machine learning with applications in various fields ranging from medicine (Pachauri & Sharma, 2015; Salem et al., 2013), finance (Ahmed et al., 2016b), security (Ahmed et al., 2016a), manufacturing (Susto et al., 2017), particle physics (Fraser et al., 2022) and geospatial data (Yairi et al., 2006). Despite its significance and potential for impact (e.g., leading to the discovery of new phenomena), to this day traditional anomaly detection methods, such as nearest neighbours, reportedly outperform deep learning techniques on various benchmarks (Han et al., 2022) by a significant margin. This is true for unsupervised, semi-supervised, and supervised anomaly detection tasks. However, the growing number of applications involving high-dimensional data and massive datasets are beginning to challenge the classical, and in particular non-parametric, techniques, and there is a need for scalable, interpretable, and expressive deep learning techniques for anomaly detection.\nIn recent years, denoising diffusion probabilistic models (DDPMs) (Ho et al., 2020) have received much attention as a powerful class of generative models. While these models have been successfully utilized for anomaly detection in domain-specific image datasets (Wolleb et al., 2022; Zhang et al., 2023a; Wyatt et al., 2022), a comprehensive exploration of their applicability for general-purpose anomaly detection across diverse tabular, image, and natural language datasets is notably absent.\nOur starting point is the observation that DDPM exhibits competitive performance compared to previous approaches for unsupervised and semi-supervised anomaly detection. These are some of the most challenging settings, where either an unlabelled mix of normal and anomalous samples are available for training or, at best, the training data only includes normal samples. However, the expressivity and interpretability of DDPM come with a considerable computational cost. This\ncomputational complexity poses challenges for anomaly detection tasks involving large datasets or data streams.\nIn anomaly detection using DDPM, we deterministically \u201cdenoise\u201d the input and measure the distance to its denoised reconstruction; a large distance indicates an anomaly. Since we only use this distance for outlier identification, in order to reduce the complexity of the diffusion-based approach, we propose to directly estimate this distance, which is correlated with diffusion time.\nMore precisely, we estimate the posterior distribution of diffusion time (or noise variance) for a given input. This estimated distribution serves as a guide for identifying anomalies, as they are anticipated to exhibit higher posterior density at larger time steps compared to normal samples. In particular, we use the mode or mean of this distribution as the anomaly score. We derive an analytical form for this posterior distribution, enabling its non-parametric estimation. We see that the non-parametric approximation produces a ranking for anomalies that is identical to k-Nearest Neighbours (kNN) for anomaly detection. We then propose a parametric model, a deep neural network, allowing us to leverage the generalization capability and efficient inference time of deep learning.\nWe provide an extensive evaluation compared to classical and other deep models for different anomaly detection settings on more than 57 datasets from ADBench (Han et al., 2022). Our empirical results suggest that using a sin-\ngle deep neural network architecture across all datasets and settings makes the diffusion model competitive with classical and other deep models. Figure 1 shows the efficiency and effectiveness of different anomaly detection algorithms across all datasets in ADBench. Notably, our proposed method surpasses the direct application of DDPMs, achieving substantial improvements in inference time.\nThe contributions of our work are summarized as follows:\n\u2022 Evaluation of denoising diffusion probabilistic models on various anomaly detection tasks encompassing tabular data and embeddings of images and natural language datasets.\n\u2022 Development of a simplified approach that models the posterior distribution over diffusion time as a proxy for anomaly detection.\n\u2022 Derivation of an analytical form of the posterior distribution of diffusion time and development of a non-parametric estimator that leads us to kNN.\n\u2022 Introduction of a parametric approach utilizing a deep neural network for improved generalization and scalability.\n\u2022 Implementation of additional baselines and extensive evaluation on 57 datasets from ADBench, showcasing competitive performance compared to classical and existing deeplearning-based anomaly detection algorithms.\n\u2022 Investigation into the interpretability of diffusion-based methods, including our novel approach, highlighting their strengths and limitations.\n\u2022 Exploration of optimal representation selections for image datasets with diffusion methods."
        },
        {
            "heading": "2 PRELIMINARIES",
            "text": "A classification of anomaly detection methods is based on the availability of labelled data. Supervised setting is similar to binary classification with unbalanced classes since the number of anomalies\nin the data is generally a small fraction of the total number of samples. This setup is limited to the identification of known anomalies. The more challenging unsupervised setting assumes that the data is a mix of normal and anomalies, without access to labels. Methods in this category often make assumptions about the data-generation process. Therefore, embedding techniques and deep generative models are prime candidates. However, a challenge for deep models is the fact that they tend to model the anomalies within the input data more easily, making the task of identifying them harder. A middle ground between supervised and unsupervised is semi-supervised or one-class classification setting, where one has access to purely normal samples during training, yet anomalies of unknown nature can exist at inference time. Perhaps confusingly, the term semi-supervised is also used when partial labelling of anomalies is available during the training. In this work, we are interested in identifying anomalies with an unknown distribution and therefore do not assume access to any label information for outliers. That is we consider both unsupervised and the one-class classification version of semi-supervised anomaly detection."
        },
        {
            "heading": "2.1 DIFFUSION PROBABILISTIC MODELS",
            "text": "A diffusion process is a stochastic process characterized by a probability distribution that evolves over time, governed by the diffusion equation. Diffusion probabilistic models (Sohl-Dickstein et al., 2015; Ho et al., 2020) are latent variable probabilistic models where the state at time steps larger than zero are considered latent variables. Let x0 \u223c q(x0) denote the data and x1, . . . ,xT denote the corresponding latent variables. The forward diffusion process is generally fixed to add Gaussian noise at each timestep according to a variance schedule \u03b21, . . . , \u03b2T . The approximate posterior q(x1:T | x0) is given by,\nq(x1:T |x0) := T\u220f\nt=1\nq(xt|xt\u22121), q(xt|xt\u22121) := N (xt; \u221a 1\u2212 \u03b2txt\u22121, \u03b2tI) (1)\nChoosing the transitions as Gaussian distributions enables sampling xt at any time in closed form. Let \u03b1t := 1\u2212 \u03b2t and \u03b1\u0304t := \u220ft s=1 \u03b1s, then,\nq(xt|x0) := N (xt; \u221a \u03b1\u0304tx0, (1\u2212 \u03b1\u0304t)I). (2)\nDiffusion probabilistic models then learn transitions that reverse the forward diffusion process. Starting at p(xT ) = N (xT ; 0, I), the joint distribution of the reverse process p\u03b8(x0:T ) is given by,\np\u03b8(x0:T ) := p(xT ) T\u220f t=1 p\u03b8(xt\u22121|xt), p\u03b8(xt\u22121|xt) := N (xt\u22121;\u00b5\u03b8(xt, t),\u03a3\u03b8(xt, t)) (3)\nThis parameterized Markov chain also called the reverse process, can produce samples matching the data distribution after a finite number of transition steps."
        },
        {
            "heading": "3 DIFFUSION TIME ESTIMATION",
            "text": "Denoising diffusion probabilistic models (DDPM), as introduced in (Ho et al., 2020), can be used to generate samples matching the data distribution even in high-dimensional spaces. The reverse diffusion process implicitly learns the score function of the data distribution and can be used for the likelihood-based identification of anomalies. A common approach used in prior works on anomaly detection using diffusion models (Wolleb et al., 2022; Zhang et al., 2023a; Wyatt et al., 2022) is to reconstruct input samples by simulating the reverse diffusion chain and then using the reconstruction distance to identify anomalies. This is particularly useful where anomalies are localized in the image, and the difference between the input and its reconstruction identifies this localized anomaly. While all previous works focus on this scenario in image data, we consider the broader problem of identification of anomalous samples without assumptions on data type or the nature of the anomaly.\nToward this objective, we evaluate the reconstruction-based approach using DDPMs on the ADBench benchmark, which comprises 57 datasets, including tabular, image, and natural language data. We observe that the choice of timestep at the start of reverse diffusion is arbitrary, yet it can significantly affect the anomaly detection performance. We found that using 25% of the maximum timestep globally leads to good results; see the Appendix A for an ablation.\nAs anticipated, the expressivity of these models allows them to perform competitively compared to prior work. However, inference for a single data point involves simulating the reverse diffusion chain in its entirety, making this approach computationally expensive. By quantifying the disparity between the reconstructed output and the original input, the objective is to effectively capture the deviations of anomalous samples from the underlying data manifold. We contend that modeling the score function by learning the reverse process is unnecessary if the objective is only the identification of anomalies.\nBuilding upon this idea, we propose a much simpler approach that does not require modeling the reverse diffusion process but instead models the distribution over diffusion time corresponding to noisy input samples. Assuming anomalies are distanced from the data manifold, the density for larger timesteps should have a higher value for anomalies, enabling their probabilistic identification. This can be seen as a direct estimation of reconstruction error.\nMore concretely, we simulate anomalous samples using a diffusion process and train a neural network to predict the diffusion time corresponding to the noisy samples. Provided that the noisy samples cover the entire feature space, this procedure should also capture potential anomalies. Figure 2 contrasts DDPM and DTE on a toy dataset. The success of our method in using diffusion for anomaly detection is due to the space-filling property of the diffusion process; different regions of the space are sampled at different rates, depending on their proximity to the data manifold. To our knowledge, this is the first setting that uses this property of diffusion beyond its application in learning time-dependent score functions for generative modelling. While in that setting, the estimated score is able to meaningfully approximate the true score over the entire space, we show that we are able to approximate the diffusion time for arbitrary points, including normal or anomalous points."
        },
        {
            "heading": "3.1 POSTERIOR DISTRIBUTION OF DIFFUSION TIME",
            "text": "Assuming xs \u2208 Rd is produced through a diffusion process, starting from the data manifold, our goal in this section is to identify the distribution over its diffusion time, as a surrogate for its distance from the manifold. The diffusion process described by Equation (2) specifies a distribution corresponding to each timestep. First, let us assume the dataset consists of a single data point at the\norigin. Denote the variance at time t as \u03c32t = 1 \u2212 \u03b1\u0304t, and consider the d-dimensional zero mean Gaussian distribution at each timestep N (0, \u03c32t ). The posterior distribution over \u03c32t given xs is:\np(\u03c32t |xs) \u221d p(xs|\u03c32t ) p(\u03c32t ) = N (xs;0, \u03c32t ) \u221d \u03c3\u2212dt exp ( \u2212\u2225xs\u2225 2\n2\u03c32t\n)\nThis is an inverse Gamma distribution p(\u03c32t ; a, b) = ba\n\u0393(a) ( 1 \u03c32t )a+1 exp ( \u2212 b \u03c32t ) with parameter\nvalues a = d/2\u2212 1 and b = \u2225xs\u22252/2.\nIf instead of a single data point at the origin, we have a dataset D, with the corresponding data distribution p(x), we have\np(\u03c32t |xs) \u221d p(xs|\u03c32t )p(\u03c32t ) = \u2211 x0 p(xs|x0, \u03c32t )p(x0) = \u2211 x0\u2208D N (xs;x0, \u03c32t I). (4)\nWe refer to Equation (4) as the analytic estimator in subsequent sections since it is the exact posterior distribution. The posterior distribution can be interpreted as adding the likelihoods of Gaussian distributions centered around data points x0 \u2208 D with different (time-dependent) variances. Substituting the Gaussian density function and simplifying, we get\np(\u03c32t |xs) \u221d \u2211 x0\u2208D \u03c3\u2212dt exp ( \u2212\u2225xs \u2212 x0\u2225 2 2\u03c32t ) = \u03c3\u2212dt exp ( log (\u2211 x0\u2208D exp ( \u2212\u2225xs \u2212 x0\u2225 2 2\u03c32t ))) .\nWe can approximate the log-sum-exp term using max function:\np(\u03c32t |xs) \u221d\u223c \u03c3 \u2212d t exp ( max x0\u2208D \u2212\u2225xs \u2212 x0\u2225 2 2\u03c32t ) = \u03c3\u2212dt exp ( \u2212 1 \u03c32t min x0\u2208D \u2225xs \u2212 x0\u22252 2 ) (5)\nThe posterior over diffusion time approximately has the form of an inverse Gamma distribution with the shape parameter a = d/2 \u2212 1 depending only on the dimensionality of the data and the scale parameter b = minx0\u2208D \u2225xs\u2212x0\u22252 2 depending on the distance of the input point to the closest point in the dataset. Note that, as a > 0 =\u21d2 d > 2, this analysis is only valid for three or higher dimensions."
        },
        {
            "heading": "3.2 NON-PARAMETRIC MODEL",
            "text": "The posterior over diffusion time given by Equation (5) can potentially be used as a non-parametric approach to anomaly detection. The approximation of log-sum-exp using the maximum value (nearest neighbour) becomes less accurate for larger timesteps, in which a point has a comparable distance to several points in the dataset. We found that instead of setting the scale parameter b based on the distance to the closest point, approximating log-sum-exp using the average distance to k-nearest neighbours of the input point works better in practice. The non-parametric estimator is then:\np(\u03c32t |xs) \u221d\u223c \u03c3 \u2212d t exp \u2212 1 \u03c32t \u00b7 1 K \u2211 x0\u2208kNN(xs) \u2225xs \u2212 x0\u22252 2  (6) Figure 3 shows the analytical posterior distribution obtained using Equation (4) and the nonparametric estimator given in Equation (6) for a real dataset.\nThe upshot is that, given a point xs, this method approximates the scale parameter of the inverse Gamma distribution using the average distance to its k-nearest neighbours. The anomaly score is the mean of this distribution over diffusion time. As seen in Figure 3, points xs that are produced using diffusion with larger time-steps also have a higher posterior mean, on average, enabling us to identify them as points that are far from the manifold. Interestingly, this method closely resembles the classical k-nearest neighbours (kNN). In fact, the anomaly rankings given by these methods are identical. In our experiments, the difference in score comes from the distance calculation: for DTE non-parametric, we take the mean distance from the k-nearest neighbours as opposed to (a variation of) kNN that takes the distance from the kth-nearest neighbour."
        },
        {
            "heading": "3.3 PARAMETRIC MODEL",
            "text": "The non-parametric estimator of diffusion time becomes compute and memory-intensive when dealing with large datasets due to the need to find the k-nearest neighbours for each input sample in the entire dataset. To tackle the scalability problem, we employ deep neural networks to estimate the posterior distribution, which also enhances generalization capabilities. The full training procedure for both parametric models is available in Appendix C.2.\nInverse Gamma model In Section 3.1 we saw that the posterior distribution over time-dependent variance has the form of an inverse Gamma distribution. We train a deep neural network parameterized by \u03b8, which we denote by f\u03b8, to predict the scale parameter b of the inverse Gamma distribution, given the noisy sample xt. Since the shape parameter a depends only on the dimensionality of the data, it is a known fixed parameter. We minimize the negative log-likelihood given by:\nL(\u03b8) := \u2212Et,x0 [ a log f\u03b8(xt)\u2212 (a+ 1) log \u03c32t \u2212 f\u03b8(xt)/\u03c32t ] (7)\nThe expectation is over data samples x0 \u223c p(x) and timesteps t \u223c U [1, T ]. The mode of the distribution is used as anomaly score.\nFigure 4 shows the predicted timestep for the inverse Gamma model applied to different datasets, with the length of Markov chain T = 300. Compared to standard \u21132 regression which assumes that the output variable is Gaussian distributed, the inverse Gamma model has a much lower bias for diffusion time prediction for smaller timesteps, which empirically validates our analysis. However, this model suffers from high bias and high variance for larger timesteps. The high bias can be attributed to the approximation error of log-sum-exp using k-nearest neighbours, which becomes inaccurate for larger timesteps. The high variance is a consequence of the shape of the inverse Gamma distribution, which becomes flat for large values of the scale parameter (see Figure 3).\nCategorical model The inverse Gamma model while analytically accurate, can restrict the expressivity of the neural network. In order to provide more flexibility in learning the diffusion time distribution, we can model it as a categorical distribution over T classes, where T is the length of the Markov chain associated with the diffusion process. This approach does not assume any parametric distribution over diffusion time and requires the model to accurately predict the full distribution. Let yt \u2208 {0, 1}T denote the one-hot vector with one at coordinate t, and f\u03b8 denote the deep neural network that predicts the class probabilities, f\u03b8 : X \u2192 [0, 1]T . We minimize the cross-entropy loss function, which is equivalent to maximizing the log-likelihood of the categorical distribution:\nL(\u03b8) := Et,x0\n[ \u2212\nK\u2211 k=0 y (k) t log ( f\u03b8(xt) (k) )]\n(8)\nIn practice, we simplify the learning task by combining timesteps into bins and training a model to predict the correct bin. If B denotes the number of bins, then the corresponding bin for a timestep t would be \u230a t\u00b7BT \u230b. Figure 4 shows the predicted timestep for the categorical model on different datasets. Compared to the inverse Gamma model, it suffers from significantly less bias across the entire range of timesteps. The score calculation is described in Appendix C.3 with the training algorithm in Appendix C.2."
        },
        {
            "heading": "4 EXPERIMENTS",
            "text": "Setting We perform experiments on the ADBench benchmark (Han et al., 2022), which comprises a set of popular tabular anomaly detection datasets as well as newly created tabular datasets made from images and natural language tasks, all described in Appendix C.1. The implementation details are provided in Appendix C, with the training algorithm, model architecture, hyperparameters, and comparison of the run-time. Some ablation studies are in Appendix A. We implement and compare the results of the various approaches proposed in Section 3: the non-parametric, the parametric inverse Gamma, and the parametric categorical DTE.\nBaselines We compare against all the unsupervised learning methods included in ADBench. These include classical methods, namely CBLOF (He et al., 2003), COPOD (Li et al., 2020), ECOD (Li et al., 2022), FeatureBagging (Lazarevic & Kumar, 2005), HBOS (Goldstein & Dengel, 2012), IForest (Liu et al., 2008), kNN (Ramaswamy et al., 2000), LODA (Pevny\u0301, 2016), LOF (Breunig et al., 2000), MCD (Fauconnier & Haesbroeck, 2009), OCSVM (Scho\u0308lkopf et al., 1999), and PCA (Shyu et al., 2003). The deep learning-based methods include DeepSVDD (Ruff et al., 2018), and DAGMM (Zong et al., 2018). Outside of ADBench, we also compare against some more recently proposed deep learning-based approaches such as DROCC (Goyal et al., 2020), GOAD (Bergman & Hoshen, 2020), ICL (Shenkar & Wolf, 2022), SLAD (Xu et al., 2023b) and DIF (Xu et al., 2023a); see Section 5 for a brief overview. For each method, we picked the best-performing set of hyperparameters given in their original paper. We also have four additional generative baselines: normalizing flows with planar flows (Rezende & Mohamed, 2015) to identify anomalies based on the log-likelihood, DDPM, VAE (Kingma & Welling, 2013) and GAN (Goodfellow et al., 2014) to reconstruct the input and compare it with the original input to identify anomalies.\nResults Figure 5 shows the overall performance of these different methods on 57 tasks in ADBench, each limited to 50,000 data points. The results for each individual dataset are provided in Appendix E. We report the mean AUC ROC and its standard deviation over five different seeds for each method. For the unsupervised setting, we used bootstrapping over the whole dataset for training, while inference is made on the full dataset. For the semi-supervised setting, we used 50% of\nthe normal samples for training, while the test set contains the rest of the normal samples and all anomalous samples. The proposed method is among the few competitive in both semi-supervised and unsupervised settings. In particular, our method outperforms all previous deep learning-based approaches in both settings significantly and also outperforms the DDPM model. Unsurprisingly, deep learning methods have a higher variance than non-parametric methods. Using bagging can be a way to help reduce the variance at the cost of more training and inference time.\nFigure 1 compares our method\u2019s performance and inference time with the other baselines. In some applications, such as medical and network monitoring, fast inference time is crucial as the algorithm must detect anomalies in real time. Our method uses a forward pass through a simple neural network for predictions, which gives it the shortest inference time over all the methods considered here. Training time, inference time and compute amounts are available in Appendix C.4.\nChoice of representation ADBench\u2019s image datasets use vector representation derived from pretrained ImageNet embeddings. We investigated the impact of representation quality for semisupervised anomaly detection across several datasets: VisA (Zou et al., 2022), CIFAR-10, and MNIST. We observe that different methods, including DDPM, kNN and DTE, perform better when applied to image embeddings rather than raw images. In particular, embeddings produced through self-supervision are generally of higher quality when compared to those produced for classification, and the embeddings that are specialized or fined-tuned to the target dataset produce the best results. The results are reported in Appendix D.\nWe also observe that kNN remains a top-performing algorithm for anomaly detection, where its only disadvantage remains its scalability. As explained in Section 3.2, the non-parametric method gives the same anomaly ranking as kNN. DTE can thus be approximately interpreted as a parametric knearest neighbours algorithm which can be beneficial for large datasets that require smaller inference time. To understand the anomalies, both DDPM and DTE are able to identify a \u201cdenoised\u201d data point; DDPM depends on an initial time step hyper-parameter, whereas DTE does not, by using deterministic ODE flow. However, DDPM outperforms in denoising, being explicitly trained for it. Further interpretability discussion, illustrated with a toy example, is in Appendix B."
        },
        {
            "heading": "5 RELATED WORK",
            "text": "We refer the reader to the following surveys for a comprehensive review (Pang et al., 2021; Chandola et al., 2009; Ruff et al., 2021; Hodge & Austin, 2004). Although recently, the spotlight has shifted towards deep learning methodologies, classical techniques such as kNN (Ramaswamy et al., 2000)\npersistently exhibit strong performance. We compared our method with some of these techniques in Section 4. Clustering and nearest neighbour algorithms use the distance to score instances, making them easily interpretable. Clustering algorithms, such as CBLOF (He et al., 2003) and k-means (MacQueen, 1967), assume that anomalies are either not part of cluster, are part of smaller clusters than normal instances, or lie further away from the cluster centroid. In contrast, nearest neighbour algorithms use the distance between points or relative density with respect to their neighbourhood.\nAs anomalies can be more difficult to detect in high-dimensional spaces and complex data distributions (Pang et al., 2021), the development of deep anomaly detection algorithms has been increasing over the past few years (Ruff et al., 2021). In particular, several works combine autoencoders with other classical techniques (Zhou & Paffenroth, 2017; Kim et al., 2020; An & Cho, 2015; Erfani et al., 2016; Sakurada & Yairi, 2014; Xia et al., 2015). Other notable methods include DeepSVDD (Ruff et al., 2018), DAGMM (Zong et al., 2018); Lunar (Goodge et al., 2022), DROCC (Goyal et al., 2020), GOAD (Bergman & Hoshen, 2020), SO-GAAL and MO-GAAL (Liu et al., 2019), SLAD (Xu et al., 2023b) and DIF (Xu et al., 2023a). Deep kNN methods (Pang et al., 2018; Sun et al., 2022) learn representations to apply kNN. ICL (Shenkar & Wolf, 2022), which uses contrastive representation learning reported competitive results for ODDS datasets, for the semi-supervised setting.\nDiffusion-based Techniques While diffusion models have been previously used for anomaly detection in image and video (Yan et al., 2023; Flaborea et al., 2023; Tur et al., 2023) data for a oneclass setting (semi-supervised), their application in the context of tabular data and the unsupervised setting was unexplored. Wolleb et al. (2022) proposed an encoding method using a diffusion process followed by a denoising procedure guided by a classifier. Zhang et al. (2023a) synthesizes anomaly samples to train the denoising network for anomaly repair. AnoDDPM employs a specific diffusion noise to train a denoising network for normal image reconstruction (Wyatt et al., 2022). Similarly, Graham et al. (2023) utilized a DDPM to reconstructs an image for multiple different timesteps combined together to make anomaly scores. Liu et al. (2023) introduced a diffusion method that reconstruct an image by in-painting the input masked by a checkerboard pattern. Lastly, Zhang et al. (2023b) used a latent diffusion model trained with simulated anomalous samples on images."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "This paper investigates the applicability of diffusion modelling for unsupervised and semisupervised anomaly detection. We observe that specific design choices in DDPMs, although somewhat arbitrary, significantly influence their performance. Despite the expressivity and interpretability of DDPMs, they come with notable computational overhead compared to existing parametric techniques. For anomaly detection, DDPM essentially estimates the distance between the input and its \u201cdenoised reconstruction\u201d; we observe that one could directly produce this estimate, or equivalently estimate the diffusion time. We first observe that the distribution of diffusion time given a noisy input, follows an inverse Gamma distribution. This forms the basis for our non-parametric approach that accurately predicts the diffusion time and turns out to create the same anomaly score ranking as kNN. A subsequent parametric strategy leverages a deep neural network, harnessing its generalization and rapid inference capabilities for large datasets. We evaluate the effectiveness of DTE on ADBench, a benchmark comprising popular anomaly detection datasets. Our results demonstrate competitive performance compared to prior work while improving the inference time by several orders of magnitude. Furthermore, we find that using pre-trained embeddings for images considerably improves the performance of diffusion-based methods, showing the potential advantage of using latent space diffusion."
        },
        {
            "heading": "7 LIMITATIONS AND FUTURE WORK",
            "text": "While our approach, DTE, achieves excellent performance with low inference time, it is important to acknowledge that in terms of interpretability, DTE falls behind DDPM as we explain in Appendix B and Section 4. This may pose challenges for practitioners seeking to understand the underlying mechanisms and behaviours of the data. Evaluating DTE in handling larger and more complex real-world datasets remains an avenue for future exploration. While here, we only address point anomalies, applications of diffusion modelling for group and contextual anomalies remain a highimpact unexplored area that we plan to investigate in the future."
        },
        {
            "heading": "8 REPRODUCIBILITY STATEMENT",
            "text": "We have made efforts to ensure that our method is reproducible. Appendix C.1 provides a description of all datasets included in ADBench, along with the preprocessing steps. Appendix C.2 presents a formal algorithm for parametric DTE and Appendix C.3 provides a detailed description of the network architecture and hyperparameters. We provide full results for both the unsupervised and semi-supervised settings with additional metrics, for all individual datasets and baselines in Appendix E as a reference for researchers to reproduce our experimental results. We are releasing the code as part of the supplemental material with detailed explanations to run the experiments."
        },
        {
            "heading": "A ABLATION STUDIES",
            "text": "We perform several ablation studies to understand DDPM and the proposed DTE method.\nReconstruction timestep in DDPM When using DDPMs for anomaly detection based on the reconstruction distance, the denoising model requires an input timestep to create the reconstruction. We found that this somewhat arbitrary hyperparameter choice can significantly affect performance as shown in Figure 6.\nFor the unsupervised setting, we found that a value close to 50% of the maximum timestep results in the highest AUC ROC score on average. For the semi-supervised, the AUC ROC decreases as we increase the reconstruction timestep. Since the model is trained only on normal samples, the anomalies are sufficiently distanced from the learned data manifold for minor changes to result in a large reconstruction error while a larger timestep decreases the precision on normal samples.\nNumber of bins in categorical DTE As discussed in Section 3.3, we implement categorical DTE by combining multiple timesteps into bins. This turns out to be an important hyperparameter as it affects the final performance significantly. Figure 7 shows that a low number of bins leads to better performance. This can be attributed to the fact that we calculate the mean of the predicted timestep distribution rather than the mode to calculate anomaly scores and that adding more bins increases the complexity of the learning task.\nMaximum timestep in DTE We study the effect of changing the maximum timestep in the noising diffusion process. As seen in Figure 8, the maximum timestep affects performance until roughly T = 250, since for very low values of T , the noisy samples might not resemble standard Gaussian noise and might not cover all potential anomalies in the dataset. We also note categorical DTE is more robust to the value of T than the inverse Gamma DTE.\nFigure 9 shows the value of standard deviation versus timestep as we increase the maximum timestep T . We observe that for values of T \u2265 250, the final timestep corresponds to a standard deviation close enough to 1.0 that the data resembles samples drawn from a standard Gaussian distribution.\nB INTERPRETABILITY\nIn certain applications, the mere identification of anomalies in the dataset is insufficient; it is imperative to understand the underlying reasons for flagging specific data points as anomalies. Both DDPM and DTE can provide interpretability by identifying a corresponding \u201cdenoised\u201d or normal data point. In DDPM this is achieved using the deterministic ODE flow, which is (rather arbitrarily) initialized at some large time step. We found the initial time step to be an important hyper-parameter, which impacts both anomaly detection and interpretability for DDPM. In practice, T \u2032 = .25 \u00d7 T performs well as the initial time-step. DTE has the benefit of avoiding such hyper-parameters, where one could use the gradient flow associated with the mode of the posterior to denoise a given input; see Figure 2 (d, e, and f).\nFigure 10 shows another example, this time using the categorical likelihood on the MNIST dataset. We artificially introduce a gray patch as an anomaly (Figure 10 (a)) and perform the gradient descent procedure reducing the mean\nof the posterior density. We observe that this procedure indeed partially eliminates the patch (Figure 10 (b)). We also note that since it is explicitly trained to remove the noise from a noisy input, DDPM performs better in removing the patch.\nAs detailed in Section 3.2, the non-parametric DTE yields the same anomaly score as kNN. Thus, the parametric DTE can be viewed as an approximate parametric kNN algorithm. This perspective enhances DTE\u2019s interpretability: the neural network\u2019s score represents the estimated distance of a point to the manifold. Although we can\u2019t pinpoint which training set instance most closely matches an input, interpreting the score as a distance to a certain neighbourhood offers a straightforward insight into the method\u2019s functioning.\nC IMPLEMENTATION DETAILS\nC.1 DATASETS AND PREPROCESSING\nDatasets description We show the results from our methods and baselines over multiple datasets from ADBench (Han et al., 2022) described in Table 1. There are 47 tabular datasets ranging from multiple different applications. There are also five datasets composed of extracted representations of images after the last average polling layer from a Resnet-18 (He et al., 2015) model pre-trained on ImageNet. Similarly, there are five datasets composed of extracted embedding of NLP tasks from BERT (Devlin et al., 2019). We also show results on VisA (Zou et al., 2022), which is a dataset composed of images of 12 different objects where the anomalies are various flaws on the objects.\nTraining and test data configuration For ADBench, the semi-supervised setting, we use half of the normal data in the training set, and the other half is in the test set with all the anomalies. For the unsupervised setting, we sample the whole dataset with replacement for the training data, while the test data is the whole dataset. This bootstrapping method allows us to test the variance over the training dataset for each method.\nPreprocessing We standardize the input samples based on the mean and standard deviation calculated over the training data, to ensure consistency across the input values and mitigate the impact of potential outliers or scale variations. For VisA, 90% of the normal instances are making the training data, while the anomalies and the remaining 10% are in the test set. For CIFAR-10 and MNIST, One class is set as the anomaly while the others are part of the training data. 80% of the normal instances are in the training data while the remaining 20% and the anomalies are in the test data. For ADBench, CIFAR-10, MNIST-C, SVHN, and FashionMNIST are made up of one class for the normal sample, while the anomalies are the rest of the classes downsampled to make up 5% of the total data.\nOn the importance of standardization for diffusion models Throughout the course of our investigations, we discovered the critical importance of standardization. This is due to the fact that the incorporated Gaussian noise operates under the assumption that each feature is centered at zero with unit standard deviation. Consequently, implementing standard scaling facilitates the comprehensive coverage of the anomaly detection space by the noise. This proved to be an essential component of the proposed anomaly detection method.\nC.2 ALGORITHM\nAlgorithm 1 Training Process for parametric DTE Parameters: T : maximum timestep, \u03bb : learning rate Input: Training data D\n1: \u03b8 \u2190 \u03b80 \u25b7 Initialize weights of the model 2: \u03b20, \u03b21, ..., \u03b2T\u22121 \u2190 linear(0, 0.01) \u25b7 Define the \u03b2 schedule for forward diffusion 3: for all t < T do 4: \u03b1\u0304t \u2190 \u220ft s=1(1\u2212 \u03b2s) \u25b7 Compute the \u03b1\u0304\n5: \u03c3t \u2190 \u221a 1\u2212 \u03b1\u0304t \u25b7 Set standard deviation for each timestep 6: end for 7: for num epochs do 8: for all x0 in D do 9: t \u223c U(0, T \u2212 1) \u25b7 Sample timestep t uniformly 10: \u03f5 \u223c N (0, 1) \u25b7 Sample standard Gaussian noise 11: xt \u2190 x0 + \u03c3t \u03f5 \u25b7 Compute noisy sample of x at timestep t 12: L \u2190 loss(f\u03b8(xt)) \u25b7 Equation (8) for inverse Gamma or Equation (9) for categorical 13: \u03b8 \u2190 \u03b8 \u2212 \u03bb\u2207\u03b8L \u25b7 Update model parameters 14: end for 15: end for\nC.3 MODEL ARCHITECTURE AND HYPERPARAMETERS\nWe first found the hyperparameters using different training splits for the semi-supervised setting on the shuttle and thyroid datasets (network architecture, maximum timestep, batch size, number of\nepochs). We then tuned some of them over all the datasets using different training seeds than the ones used for the final results (number of bins and learning rate). This is the case for the diffusion methods and the normalizing flow method. For the other baselines, we picked the set of hyperparameters from the original papers that provided the best results over the whole benchmark.\nDTE For the non-parametric DTE, the score is calculated based on the approximate posterior distribution in Equation (6) with k = 5 for the semi-supervised setting and k = 32 for the unsupervised setting. The anomaly score is the mean of the posterior to avoid having an anomaly score that is restricted by the maximum variance using the mode. The be consistent, we selected the same k for the kNN baseline.\nFor the DTE parametric approach, we employ a multi-layer perceptron (MLP) neural network. We use a common architecture and set of hyperparameters across all datasets. When training on images, we used a ResNet-50 architecture.\nFor the categorical model, we found that using the mean over each output probability bin provided the best results. That is, the anomaly score for each individual x is computed as follow:\nscore = f\u03b8(x)  0 1 2 ...\nB \u2212 1  (9) where B is the number of bins and f\u03b8(xt) is the output probability vector of the network using a softmax, which is an N \u00d7 B matrix, where the sum across each row equates to one and N is the batch size. The score for each instance will be a value between 0 and B \u2212 1. The higher the score is, the more anomalous an instance is.\nEmploying the mode as a measurement metric proved suboptimal given the disproportionate representation of the first bin, a pattern that remained consistent even among anomalous instances. Consequently, it was observed that while the probabilities could be diffusely distributed across the remaining bins, the mode predominantly remained in the first bin. In contrast, utilizing the mean allowed us to effectively account for this distribution characteristic, enabling an inclusive weighting scheme across all bins. Additionally, the mean offered a continuous scoring system as opposed to the integer values provided by the mode, thereby affording a more nuanced understanding of the anomalous data.\nDDPM For the DDPM model, we used a modified ResNet for tabular data (Gorishniy et al., 2021) with added time embedding before each block, inspired by the work done for TabDDPM (Kotelnikov et al., 2022). Recognizing that learning noise at each timestep presents a considerably complex task, the necessity for a more sophisticated model than a simple MLP became evident to optimize the efficacy of our method. Furthermore, the lack of research on diffusion models for tabular data has constrained our ability to apply a model of comparable strength to the U-net model typically used for images, to our benchmark datasets. This presents an interesting direction for further research, with the potential to significantly enhance the performance of machine learning models on tabular\ndatasets. In contrast to prior work (Wyatt et al., 2022; Wolleb et al., 2022), we do not add noise to the data point before reconstructing it as we found that it leads to overall slightly better results. This is a minor change, one intuition for the boost of performance could be that adding noise can modify the images toward anomalous data, thus increasing the amount of false positives.\nNormalizing Flows Baseline We compare our diffusion methods with a normalizing flows baseline that uses planar flows (Rezende & Mohamed, 2015). Normalizing flows allow to compute the exact likelihoods of data point, which allow to easily assign anomaly scores. Once trained, the model can estimate the density of any data point in the input space. This is done by passing the data point through the inverse of the learned transformation and then computing the density of the transformed point under the simple target distribution. The density of the original point under the complex data distribution can be computed from this using the change-of-variables formula.\nThe total amount of compute required to reproduce our experiments with five seeds, including all of the baselines and the proposed DTE model amounts to 473 GPU-hours for the unsupervised setting and 225 GPU-hours for the semi-supervised setting on an RTX8000 GPU with 48 gigabytes of memory for running the ADBench datasets.\nFigure 11 shows the training and inference times averaged over all datasets in ADBench over five seeds for all methods discussed in Section 4. As expected, deep learning-based methods have significantly higher training times compared to classical methods but comparable inference times. In particular, the inference time for the parametric DTEs is orders of magnitude lower than all other methods. The non-parametric variant of DTE has no training phase, so we show the inference time in both plots."
        },
        {
            "heading": "D CHOICE OF REPRESENTATION FOR IMAGES",
            "text": "In this section, we compare the effect of choice of representation on the performance of diffusionbased anomaly detection techniques. Three choices considered are 1) pixel space representation, 2) self-supervised embedding, and 3) embedding produced by a classifier. Results for three image datasets are reported in Table 5. The datasets and preprocessing are described in Appendix C.1 and the full results are in Appendix E. As expected, using pre-trained embeddings leads to better results than pixel space for all methods considered. Tables 9 to 12 report other experiments that lead to a similar conclusion.\nIn particular, using self-supervised embedding for CIFAR-10, significantly improved the anomaly detection performance as the pre-training was done on CIFAR-10 itself. Note that all the other pre-training were supervised classification using ResNet-34 on ImageNet and not directly on the datasets. Overall, pre-training improves the results for all methods and all datasets with the exception of kNN and the non-parametric DTE (DTE-NP) on MNIST. This result can be attributed to the simplicity of the MNIST dataset when adapted to anomaly detection tasks. As a reminder, DTE-NP is equivalent to kNN, but corresponds to the variation that uses the mean distance of the k-nearest neighbours instead of the distance to the kth-nearest neighbour.\nZou et al. (2022) highlighted the advantages of tailoring specialized self-supervised learning techniques to specific datasets, exemplified by their method for VisA. As our methods are not explicitly designed for these datasets, our results for all diffusion-based methods reported here lag behind those of methods specialized to this dataset. In particular, VisA dataset contains images that are quite similar with the exception of highly localized anomalies."
        },
        {
            "heading": "E FULL RESULTS",
            "text": "We provide the full table of results corresponding to the AUC ROC box-plots in Section 4. We report additional metrics including F1 score and area under the precision-recall curve (AUC PR) along with the corresponding box-plots. All results are shown averaged across five seeds along with standard deviations in brackets for all 57 datasets in ADBench. In the subsequent tables, DTE-NP refers to the non-parametric DTE estimator, DTE-IG refers to the parametric inverse Gamma model, and DTE-C refers to the parametric categorical model. Tables 9 to 12 show the results for three methods when using pre-trained embeddings on CIFAR-10 and SVHN compared to trained directly on the images, as it is set up in ADBench. The difference with Table 5 is that instead of having one class as an anomaly, here we have one class as normal while the rest of the classes are downsampled to produce the anomalies.\nE.1 SEMI-SUPERVISED SETTING\nTa bl\ne 13\n:A ve\nra ge\nA U\nC R\nO C\nan d\nst an\nda rd\nde vi\nat io\nns ov\ner fiv\ne se\ned s\nfo rt\nhe se\nm i-\nsu pe\nrv is\ned se\ntti ng\non A\nD B\nen ch\n.\nC B\nL O\nF C\nO PO\nD E\nC O\nD Fe\nat ur\neB ag\ngi ng\nH B\nO S\nIF or\nes t\nkN N\nL O\nD A\nL O\nF M\nC D\nO C\nSV M\nPC A\nD A\nG M\nM D\nee pS\nV D\nD D\nR O\nC C\nG O\nA D\nIC L\nPl an\nar Fl\now VA\nE G\nA N\nom al\ny SL\nA D\nD IF\nD D\nPM D\nT E\n-N P\nD T\nE -I\nG D\nT E\n-C\nal oi\n53 .6\n9( 0.\n15 )\n49 .5\n1( 0.\n0) 51\n.7 3(\n0. 0)\n49 .0\n7( 0.\n53 )\n52 .2\n3( 0.\n0) 50\n.7 4(\n0. 68\n) 51\n.0 4(\n0. 0)\n49 .2\n4( 2.\n75 )\n48 .7\n6( 0.\n0) 48\n.5 4(\n0. 35\n) 54\n.2 9(\n0. 0)\n54 .0\n4( 0.\n0) 50\n.8 4(\n2. 97\n) 50\n.8 9(\n2. 05\n) 50\n.0 (0\n.0 )\n48 .0\n1( 0.\n92 )\n47 .5\n(0 .9\n8) 48\n.5 2(\n2. 34\n) 54\n.0 4(\n0. 0)\n53 .9\n4( 1.\n65 )\n50 .7\n6( 0.\n29 )\n51 .1\n(0 .0\n) 49\n.9 1(\n0. 35\n) 51\n.1 9(\n0. 46\n) 50\n.8 7(\n1. 17\n) 50\n.4 4(\n0. 19 ) am az on 58 .1 7( 0. 12 ) 56 .7 8( 0. 0) 53 .7 9( 0. 0) 57 .9 4( 0. 04 ) 56 .3 2( 0. 0) 56 .4 (0 .9 5) 60 .5 8( 0. 0) 52 .2 3( 2. 84 ) 57 .8 8( 0. 0) 60 .3 6( 0. 09 ) 56 .4 8( 0. 0) 54 .9 (0 .0 ) 50 .4 7( 2. 01 ) 51 .2 (4 .4 2) 50 .0 (0 .0 ) 56 .0 7( 0. 9) 54 .2 1( 0. 22 ) 49 .9 4( 2. 12 ) 54 .9 (0 .0 ) 53 .4 2( 0. 94 ) 52 .0 1( 0. 06 ) 51 .4 3( 0. 34 ) 55 .0 9( 0. 1) 60 .8 2( 0. 0) 51 .9 3( 3. 5) 56 .7 1( 2. 15 ) an nt hy ro id 90 .1 4( 1. 08 ) 76 .7 7( 0. 0) 78 .4 5( 0. 0) 88 .9 5( 1. 61 ) 66 .0 2( 0. 0) 90 .2 8( 1. 52 ) 92 .8 1( 0. 0) 77 .3 5( 7. 51 ) 88 .6 3( 0. 0) 90 .1 9( 0. 02 ) 88 .4 5( 0. 0) 85 .1 9( 0. 0) 72 .2 3( 15 .1 3) 55 .0 1( 3. 62 ) 88 .9 (2 .3 1) 81 .0 1( 5. 16 ) 81 .1 1( 1. 07 ) 93 .1 9( 2. 14 ) 85 .4 4( 0. 0) 67 .5 2( 5. 54 ) 93 .3 4( 0. 36 ) 88 .3 6( 0. 0) 88 .8 2( 1. 34 ) 92 .9 (0 .2 5) 87 .6 (4 .4 6) 97 .5 2( 0. 15 ) ba ck do or 69 .6 5( 5. 23 ) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 94 .8 3( 0. 62 ) 70 .8 1( 0. 89 ) 74 .8 9( 2. 67 ) 93 .7 5( 0. 53 ) 47 .6 2( 22 .6 3) 95 .3 3( 0. 25 ) 85 .1 3( 8. 87 ) 62 .5 2( 0. 64 ) 64 .5 7( 0. 65 ) 54 .3 6( 19 .9 1) 91 .1 4( 2. 62 ) 94 .2 5( 0. 73 ) 52 .9 (1 4. 48 ) 93 .6 2( 0. 69 ) 76 .0 3( 11 .5 6) 64 .6 7( 0. 74 ) 87 .1 7( 1. 43 ) 50 .0 (0 .0 ) 83 .7 3( 0. 76 ) 80 .9 3( 0. 56 ) 93 .3 1( 1. 7) 94 .0 2( 1. 46 ) 91 .6 5( 1. 73 ) br ea st w 99 .1 1( 0. 23 ) 99 .4 6( 0. 09 ) 99 .1 4( 0. 22 ) 59 .0 7( 15 .4 4) 99 .2 3( 0. 17 ) 99 .5 (0 .0 8) 99 .0 5( 0. 26 ) 98 .1 3( 0. 35 ) 88 .9 1( 6. 8) 98 .6 6( 0. 65 ) 99 .3 9( 0. 16 ) 99 .2 1( 0. 17 ) 89 .5 3( 10 .2 ) 96 .9 6( 0. 92 ) 47 .3 2( 31 .9 5) 98 .8 6( 0. 33 ) 98 .2 8( 0. 45 ) 97 .9 3( 0. 82 ) 99 .2 2( 0. 18 ) 94 .7 5( 2. 73 ) 99 .5 3( 0. 13 ) 56 .3 4( 11 .9 ) 98 .7 (0 .4 3) 99 .2 8( 0. 12 ) 78 .6 5( 11 .1 ) 92 .7 8( 1. 75 ) ca m pa ig n 77 .0 5( 0. 31 ) 78 .1 5( 0. 0) 76 .8 6( 0. 0) 69 .1 (3 .8 5) 77 .0 6( 0. 0) 73 .6 4( 1. 48 ) 78 .4 8( 0. 0) 58 .8 8( 4. 48 ) 70 .5 5( 0. 0) 78 .5 1( 0. 81 ) 77 .6 7( 0. 0) 77 .0 7( 0. 0) 61 .4 7( 2. 73 ) 62 .2 1( 12 .8 8) 50 .0 (0 .0 ) 47 .8 9( 12 .3 2) 80 .9 2( 0. 79 ) 69 .7 5( 3. 75 ) 77 .0 7( 0. 0) 69 .2 1( 3. 28 ) 76 .7 5( 0. 16 ) 57 .8 7( 0. 0) 74 .5 1( 0. 42 ) 78 .7 9( 0. 25 ) 74 .8 1( 1. 69 ) 77 .9 5( 1. 11 ) ca rd io 93 .4 9( 1. 47 ) 93 .1 6( 0. 0) 94 .9 5( 0. 0) 92 .1 2( 0. 56 ) 80 .7 (0 .0 ) 93 .3 2( 1. 43 ) 92 .0 (0 .0 ) 91 .3 4( 2. 93 ) 92 .2 1( 0. 0) 82 .8 2( 0. 85 ) 95 .6 1( 0. 0) 96 .5 4( 0. 01 ) 77 .9 2( 8. 85 ) 65 .4 3( 4. 37 ) 62 .1 4( 23 .7 6) 96 .0 1( 0. 27 ) 80 .0 1( 2. 12 ) 88 .9 (0 .9 3) 96 .5 5( 0. 0) 86 .0 6( 4. 31 ) 83 .0 5( 1. 1) 68 .2 5( 0. 0) 86 .9 4( 1. 96 ) 91 .8 (0 .5 9) 73 .7 9( 14 .0 9) 87 .2 6( 1. 0) ca rd io to co gr ap hy 67 .6 1( 2. 21 ) 66 .3 5( 0. 0) 79 .3 (0 .0 ) 63 .6 4( 2. 4) 61 .2 4( 0. 0) 74 .2 4( 2. 88 ) 62 .1 1( 0. 0) 72 .7 9( 7. 6) 64 .4 9( 0. 0) 57 .1 1( 1. 41 ) 75 .2 2( 0. 0) 78 .8 9( 0. 0) 67 .1 1( 9. 03 ) 47 .7 5( 8. 59 ) 45 .9 8( 16 .7 5) 76 .0 6( 1. 4) 54 .2 (1 .8 ) 69 .8 8( 5. 65 ) 78 .9 (0 .0 ) 62 .7 7( 8. 62 ) 47 .3 2( 0. 31 ) 41 .7 9( 0. 0) 54 .5 4( 2. 96 ) 63 .7 6( 1. 88 ) 52 .4 4( 3. 67 ) 60 .1 3( 2. 59 ) ce le ba 79 .2 8( 1. 3) 75 .7 2( 0. 59 ) 76 .3 3( 0. 63 ) 46 .8 9( 1. 8) 76 .6 8( 0. 66 ) 71 .2 3( 2. 27 ) 73 .1 4( 0. 72 ) 62 .4 6( 13 .1 7) 43 .7 3( 0. 75 ) 84 .3 7( 2. 34 ) 79 .7 9( 0. 77 ) 80 .5 3( 0. 7) 63 .8 1( 4. 28 ) 56 .1 7( 22 .4 6) 68 .8 9( 1. 11 ) 43 .8 (1 0. 49 ) 72 .2 1( 0. 82 ) 71 .6 4( 7. 91 ) 80 .3 2( 0. 48 ) 52 .2 5( 11 .7 9) 67 .4 3( 1. 64 ) 66 .6 9( 3. 55 ) 78 .5 6( 1. 99 ) 70 .4 (0 .3 7) 74 .5 1( 2. 39 ) 82 .1 8( 2. 38 ) ce ns us 70 .8 4( 0. 28 ) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 55 .9 2( 1. 0) 62 .5 (0 .4 7) 62 .5 5( 2. 38 ) 72 .2 6( 0. 29 ) 51 .1 2( 11 .1 9) 58 .4 6( 1. 06 ) 74 .1 4( 1. 94 ) 70 .0 2( 0. 21 ) 70 .5 1( 0. 21 ) 52 .2 4( 1. 19 ) 54 .1 6( 4. 33 ) 55 .3 6( 3. 62 ) 35 .2 4( 4. 19 ) 70 .5 6( 0. 35 ) 59 .3 3( 2. 89 ) 70 .5 2( 0. 22 ) 68 .0 7( 3. 66 ) 57 .9 1( 10 .8 4) 61 .4 5( 2. 04 ) 70 .1 5( 0. 23 ) 72 .1 (0 .4 ) 61 .7 9( 4. 94 ) 69 .6 2( 0. 91 ) co ve r 94 .0 4( 0. 28 ) 88 .2 (0 .2 7) 91 .8 6( 0. 21 ) 99 .1 6( 0. 63 ) 71 .1 1( 0. 82 ) 86 .3 1( 2. 07 ) 97 .5 4( 0. 15 ) 94 .9 3( 3. 07 ) 99 .1 8( 0. 1) 70 .0 2( 0. 66 ) 96 .1 7( 0. 11 ) 94 .4 1( 0. 14 ) 75 .9 4( 14 .0 6) 49 .1 2( 14 .7 4) 95 .7 9( 0. 69 ) 13 .8 3( 13 .3 4) 89 .3 4( 4. 02 ) 47 .5 2( 8. 02 ) 94 .3 5( 0. 15 ) 76 .3 5( 19 .1 1) 73 .9 7( 13 .8 ) 57 .6 9( 5. 24 ) 98 .3 5( 0. 66 ) 97 .7 3( 0. 55 ) 95 .8 3( 1. 55 ) 97 .7 6( 1. 28 ) do no rs 93 .4 7( 0. 23 ) 81 .5 (0 .2 1) 88 .7 4( 0. 38 ) 95 .2 1( 1. 72 ) 81 .1 9( 0. 61 ) 89 .4 4( 2. 22 ) 99 .4 9( 0. 06 ) 63 .5 2( 27 .2 7) 96 .9 7( 0. 24 ) 81 .9 3( 10 .7 8) 92 .0 9( 0. 22 ) 88 .1 2( 0. 57 ) 62 .1 5( 16 .1 9) 72 .9 5( 17 .8 1) 74 .1 8( 22 .0 9) 33 .5 7( 16 .0 ) 99 .9 (0 .0 5) 91 .6 4( 3. 52 ) 88 .6 (0 .2 5) 75 .3 4( 11 .6 9) 88 .5 1( 5. 51 ) 90 .0 4( 1. 79 ) 82 .5 (1 .8 3) 99 .2 6( 0. 29 ) 99 .2 5( 0. 6) 98 .1 5( 0. 37 ) fa ul t 59 .0 (1 .2 9) 49 .1 4( 0. 0) 50 .3 7( 0. 0) 48 .3 2( 0. 95 ) 53 .0 6( 0. 0) 55 .8 6( 2. 03 ) 58 .7 3( 0. 0) 50 .2 7( 1. 88 ) 47 .4 2( 0. 0) 59 .4 4( 3. 79 ) 57 .2 1( 0. 0) 55 .8 7( 0. 0) 52 .8 5( 7. 19 ) 54 .3 1( 1. 62 ) 55 .7 3( 5. 33 ) 58 .8 9( 0. 61 ) 60 .6 3( 0. 5) 57 .5 1( 5. 15 ) 55 .8 7( 0. 0) 59 .5 (5 .1 4) 63 .9 3( 0. 19 ) 62 .3 1( 0. 0) 61 .0 9( 1. 16 ) 58 .6 4( 0. 65 ) 59 .4 2( 1. 46 ) 59 .4 6( 1. 45 ) fr au d 94 .9 1( 1. 08 ) 94 .3 (1 .4 1) 94 .8 9( 1. 27 ) 94 .8 3( 1. 56 ) 95 .0 2( 0. 67 ) 94 .7 3( 1. 23 ) 95 .4 3( 1. 04 ) 89 .0 5( 8. 12 ) 94 .3 5( 1. 41 ) 91 .1 (1 .7 9) 95 .6 1( 0. 69 ) 95 .3 8( 0. 68 ) 85 .3 3( 6. 76 ) 83 .1 3( 6. 6) 50 .0 (0 .0 ) 69 .7 5( 21 .3 ) 92 .7 8( 1. 46 ) 90 .7 2( 2. 26 ) 95 .4 7( 0. 75 ) 93 .2 5( 2. 85 ) 94 .5 8( 1. 01 ) 82 .5 8( 2. 27 ) 93 .6 5( 0. 92 ) 95 .6 4( 1. 05 ) 90 .7 9( 3. 24 ) 93 .5 2( 1. 53 ) gl as s 89 .3 5( 1. 48 ) 76 .0 (1 .9 4) 71 .1 4( 3. 54 ) 88 .4 9( 1. 71 ) 82 .5 9( 3. 23 ) 81 .0 9( 2. 56 ) 92 .0 4( 1. 12 ) 67 .3 4( 5. 39 ) 88 .8 2( 1. 98 ) 79 .7 1( 1. 37 ) 69 .7 3( 5. 89 ) 73 .4 4( 2. 22 ) 65 .3 3( 15 .5 3) 83 .6 7( 16 .2 ) 64 .8 9( 23 .6 4) 59 .0 3( 12 .6 4) 99 .4 4( 0. 58 ) 85 .3 3( 6. 2) 72 .5 5( 1. 66 ) 79 .7 7( 8. 72 ) 86 .0 4( 5. 69 ) 96 .4 5( 1. 39 ) 66 .6 7( 13 .6 3) 89 .6 4( 3. 54 ) 98 .5 3( 0. 86 ) 92 .4 2( 2. 3) he pa tit is 86 .2 6( 2. 35 ) 80 .9 (1 .2 2) 73 .8 4( 1. 99 ) 67 .7 6( 6. 5) 84 .8 4( 0. 78 ) 82 .6 9( 2. 75 ) 96 .4 6( 1. 46 ) 68 .9 8( 3. 97 ) 66 .9 2( 7. 01 ) 80 .6 4( 4. 23 ) 90 .5 8( 1. 79 ) 84 .4 8( 2. 29 ) 70 .2 2( 6. 66 ) 99 .5 7( 0. 24 ) 51 .8 (1 7. 93 ) 84 .5 (3 .2 5) 99 .9 4( 0. 13 ) 95 .8 (1 .6 7) 84 .8 4( 2. 27 ) 87 .3 9( 7. 55 ) 99 .9 3( 0. 15 ) 96 .0 7( 2. 32 ) 97 .7 4( 1. 18 ) 93 .2 2( 3. 9) 99 .9 3( 0. 15 ) 98 .7 8( 0. 88 ) ht tp 99 .9 3( 0. 01 ) 99 .1 9( 0. 09 ) 97 .9 5( 0. 12 ) 92 .1 (0 .5 7) 98 .5 8( 1. 04 ) 99 .3 5( 0. 29 ) 10 0. 0( 0. 0) 47 .7 2( 45 .4 9) 99 .9 8( 0. 03 ) 99 .9 5( 0. 01 ) 10 0. 0( 0. 0) 99 .9 5( 0. 01 ) 91 .7 8( 17 .9 1) 61 .3 1( 51 .4 9) 50 .0 (0 .0 ) 99 .6 8( 0. 13 ) 98 .2 4( 3. 45 ) 99 .3 8( 0. 08 ) 99 .9 4( 0. 01 ) 50 .1 4( 34 .8 5) 99 .9 1( 0. 08 ) 99 .3 6( 0. 07 ) 10 0. 0( 0. 0) 99 .9 8( 0. 03 ) 80 .7 2( 43 .0 8) 99 .4 5( 0. 1) im db 49 .9 4( 0. 01 ) 51 .0 5( 0. 0) 46 .8 8( 0. 0) 49 .5 3( 0. 1) 49 .9 4( 0. 0) 49 .5 3( 0. 78 ) 50 .0 8( 0. 0) 47 .2 3( 2. 24 ) 49 .5 7( 0. 0) 51 .2 4( 0. 18 ) 48 .7 2( 0. 0) 47 .9 7( 0. 0) 48 .6 (0 .3 8) 49 .9 7( 5. 71 ) 51 .3 5( 2. 05 ) 48 .4 6( 0. 65 ) 52 .3 4( 0. 49 ) 49 .2 3( 2. 75 ) 47 .9 7( 0. 0) 51 .5 8( 0. 71 ) 51 .2 6( 0. 1) 51 .4 (0 .4 9) 47 .9 1( 0. 1) 50 .4 3( 0. 0) 50 .9 7( 3. 41 ) 48 .0 5( 2. 22 ) in te rn et ad s 65 .1 6( 0. 08 ) 65 .9 4( 0. 0) 66 .0 1( 0. 0) 71 .3 8( 2. 32 ) 49 .1 8( 0. 0) 47 .8 7( 2. 11 ) 68 .0 8( 0. 0) 58 .7 3( 3. 84 ) 71 .7 2( 0. 0) 47 .7 3( 0. 01 ) 65 .6 3( 0. 0) 65 .1 2( 0. 0) 49 .4 7( 5. 05 ) 72 .9 6( 3. 24 ) 53 .4 (7 .5 5) 65 .6 5( 0. 21 ) 72 .2 (0 .5 5) 70 .8 7( 0. 84 ) 65 .1 2( 0. 0) 69 .8 6( 0. 23 ) 75 .9 4( 0. 11 ) 49 .3 3( 0. 34 ) 65 .7 6( 0. 06 ) 69 .9 6( 2. 22 ) 71 .5 2( 3. 89 ) 77 .5 7( 1. 54 ) io no sp he re 96 .7 8( 1. 5) 78 .3 2( 2. 13 ) 71 .7 7( 1. 43 ) 94 .4 7( 2. 1) 70 .6 8( 2. 85 ) 91 .2 1( 1. 37 ) 97 .4 4( 0. 98 ) 85 .5 6( 3. 59 ) 94 .2 9( 2. 2) 95 .4 (0 .6 4) 96 .3 2( 0. 93 ) 89 .1 1( 1. 31 ) 73 .9 5( 5. 98 ) 97 .2 (1 .2 6) 61 .1 4( 28 .5 4) 91 .5 4( 3. 05 ) 98 .9 8( 0. 32 ) 96 .8 6( 1. 21 ) 89 .7 6( 1. 2) 93 .8 9( 2. 03 ) 98 .2 1( 0. 6) 93 .5 9( 2. 06 ) 94 .6 (0 .8 5) 97 .7 7( 1. 39 ) 95 .1 5( 3. 6) 95 .4 2( 0. 58 ) la nd sa t 57 .2 1( 0. 26 ) 49 .2 9( 0. 0) 42 .0 1( 0. 0) 66 .3 8( 0. 17 ) 73 .2 1( 0. 0) 58 .8 (2 .2 1) 68 .2 5( 0. 0) 44 .6 5( 3. 3) 66 .5 8( 0. 0) 56 .7 8( 6. 08 ) 47 .9 8( 0. 0) 43 .9 (0 .0 ) 56 .2 7( 3. 46 ) 59 .4 4( 1. 41 ) 53 .8 6( 2. 57 ) 40 .5 2( 2. 32 ) 65 .1 3( 0. 44 ) 50 .8 5( 2. 13 ) 54 .2 2( 9. 45 ) 55 .3 4( 10 .0 3) 65 .0 3( 0. 18 ) 56 .5 6( 0. 0) 51 .3 7( 1. 0) 68 .2 (1 .7 5) 44 .7 2( 5. 52 ) 52 .7 9( 1. 63 ) le tte r 33 .2 4( 0. 66 ) 36 .5 3( 0. 0) 45 .3 7( 0. 0) 44 .8 4( 1. 0) 35 .9 1( 0. 0) 32 .0 4( 1. 64 ) 35 .4 3( 0. 0) 30 .2 (0 .9 4) 44 .8 3( 0. 0) 31 .4 7( 4. 16 ) 32 .1 7( 0. 0) 30 .3 (0 .0 ) 38 .9 7( 8. 38 ) 36 .4 (3 .0 5) 55 .2 6( 11 .0 4) 31 .0 8( 0. 55 ) 42 .6 8( 1. 17 ) 38 .7 3( 3. 53 ) 30 .2 3( 0. 0) 34 .0 2( 0. 74 ) 36 .8 (0 .4 1) 74 .0 7( 0. 0) 38 .0 5( 1. 12 ) 34 .3 8( 0. 98 ) 39 .8 6( 2. 29 ) 36 .7 2( 0. 95 ) ly m ph og ra ph y 99 .8 3( 0. 02 ) 99 .5 3( 0. 2) 99 .5 2( 0. 15 ) 96 .6 1( 2. 84 ) 99 .6 9( 0. 17 ) 99 .4 5( 0. 32 ) 99 .9 3( 0. 08 ) 67 .0 4( 13 .8 7) 98 .2 1( 0. 75 ) 98 .8 8( 0. 55 ) 10 0. 0( 0. 0) 99 .8 6( 0. 05 ) 94 .9 4( 3. 85 ) 99 .7 3( 0. 3) 32 .4 2( 37 .7 5) 99 .8 9( 0. 08 ) 10 0. 0( 0. 0) 99 .5 8( 0. 51 ) 99 .8 8( 0. 09 ) 99 .0 9( 0. 86 ) 10 0. 0( 0. 01 ) 99 .8 4( 0. 22 ) 99 .9 4( 0. 09 ) 99 .9 3( 0. 09 ) 99 .9 8( 0. 05 ) 98 .9 9( 0. 4) m ag ic .g am m a 75 .8 1( 0. 0) 68 .0 (0 .0 ) 63 .5 8( 0. 0) 84 .1 9( 0. 72 ) 74 .5 3( 0. 0) 77 .0 9( 1. 29 ) 83 .2 7( 0. 0) 70 .5 3( 1. 36 ) 83 .4 (0 .0 ) 73 .6 7( 0. 12 ) 74 .2 5( 0. 0) 70 .6 4( 0. 0) 59 .2 3( 4. 32 ) 62 .9 7( 1. 07 ) 78 .8 3( 0. 66 ) 69 .4 6( 2. 39 ) 75 .5 6( 0. 42 ) 74 .1 2( 2. 75 ) 70 .6 4( 0. 0) 59 .1 8( 1. 6) 72 .0 (0 .0 1) 63 .8 6( 0. 0) 85 .9 7( 1. 08 ) 83 .5 7( 0. 76 ) 86 .4 6( 1. 12 ) 87 .5 (0 .9 ) m am m og ra ph y 84 .7 4( 0. 02 ) 90 .5 9( 0. 0) 90 .6 7( 0. 0) 86 .3 1( 0. 35 ) 85 .0 1( 0. 0) 88 .0 2( 0. 3) 87 .5 8( 0. 0) 89 .6 2( 0. 87 ) 85 .5 2( 0. 0) 72 .8 7( 0. 64 ) 88 .6 3( 0. 0) 89 .9 3( 0. 0) 76 .0 3( 14 .6 5) 71 .5 (7 .4 ) 81 .8 2( 1. 94 ) 69 .9 4( 8. 59 ) 71 .8 7( 9. 11 ) 78 .9 3( 5. 71 ) 89 .5 8( 0. 17 ) 85 .5 4( 7. 43 ) 74 .5 1( 0. 67 ) 73 .8 7( 0. 2) 81 .0 1( 2. 04 ) 87 .6 2( 0. 09 ) 84 .6 4( 3. 47 ) 86 .4 2( 1. 72 ) m ni st 91 .1 (0 .2 3) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 92 .5 5( 0. 4) 62 .3 4( 0. 0) 86 .6 (1 .9 9) 93 .8 5( 0. 0) 64 .7 4( 7. 74 ) 92 .9 3( 0. 0) 88 .3 (1 .0 3) 90 .5 6( 0. 0) 90 .2 1( 0. 0) 72 .1 9( 7. 16 ) 66 .3 7( 11 .0 3) 83 .1 3( 1. 64 ) 90 .0 7( 0. 35 ) 90 .1 1( 1. 13 ) 81 .9 (2 .6 7) 90 .2 1( 0. 0) 77 .9 (6 .4 4) 89 .7 3( 0. 44 ) 50 .2 1( 0. 0) 87 .2 7( 3. 22 ) 94 .0 2( 0. 42 ) 80 .7 8( 5. 91 ) 87 .4 3( 2. 48 ) m us k 10 0. 0( 0. 0) 99 .7 1( 0. 0) 99 .8 7( 0. 0) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 90 .5 8( 6. 2) 10 0. 0( 0. 0) 99 .6 7( 0. 35 ) 10 0. 0( 0. 0) 93 .9 1( 2. 55 ) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 95 .0 1( 4. 27 ) 99 .9 9( 0. 01 ) 32 .9 9( 33 .1 8) 10 0. 0( 0. 0) 99 .3 7( 0. 63 ) 76 .6 5( 18 .7 2) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 97 .7 6( 0. 0) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 94 .2 2( 12 .9 3) 10 0. 0( 0. 0) op td ig its 83 .5 2( 1. 69 ) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 96 .2 7( 0. 49 ) 89 .9 2( 0. 0) 81 .0 7( 3. 28 ) 93 .7 2( 0. 0) 32 .7 7( 8. 62 ) 96 .6 5( 0. 0) 64 .8 6( 0. 92 ) 63 .3 8( 0. 0) 58 .1 7( 0. 0) 40 .0 4( 20 .4 5) 39 .4 5( 18 .6 5) 85 .2 5( 2. 9) 67 .4 6( 4. 94 ) 97 .1 8( 0. 8) 34 .1 2( 8. 29 ) 58 .1 7( 0. 0) 74 .3 (1 2. 58 ) 95 .2 8( 0. 17 ) 48 .6 4( 0. 0) 90 .7 6( 2. 12 ) 94 .2 8( 1. 67 ) 79 .8 1( 9. 35 ) 82 .3 8( 2. 68 ) pa ge bl oc ks 91 .2 3( 0. 11 ) 80 .8 5( 0. 0) 87 .9 5( 0. 0) 91 .1 1( 0. 3) 65 .6 2( 0. 0) 82 .6 4( 0. 89 ) 89 .6 5( 0. 0) 83 .6 2( 2. 6) 91 .3 (0 .0 ) 87 .0 7( 0. 02 ) 88 .5 8( 0. 0) 86 .1 2( 0. 0) 82 .8 (1 0. 44 ) 78 .3 9( 1. 53 ) 92 .3 3( 1. 18 ) 88 .0 5( 1. 19 ) 88 .3 9( 0. 77 ) 84 .8 5( 1. 19 ) 86 .1 6( 0. 0) 72 .8 3( 9. 94 ) 87 .8 6( 0. 01 ) 87 .3 9( 0. 0) 86 .9 3( 0. 42 ) 89 .3 2( 0. 26 ) 85 .6 6( 1. 77 ) 89 .8 9( 0. 55 ) pe nd ig its 96 .6 7( 0. 07 ) 90 .7 4( 0. 0) 92 .9 5( 0. 0) 99 .5 (0 .1 1) 93 .5 5( 0. 0) 97 .2 2( 0. 48 ) 99 .8 7( 0. 0) 92 .1 3( 1. 02 ) 99 .0 5( 0. 0) 83 .6 9( 0. 09 ) 96 .3 6( 0. 0) 94 .3 7( 0. 0) 56 .4 9( 21 .8 3) 46 .2 9( 11 .3 5) 75 .9 1( 13 .3 8) 89 .9 7( 2. 03 ) 96 .7 1( 0. 83 ) 83 .4 5( 6. 13 ) 94 .5 (0 .0 ) 67 .9 3( 21 .6 ) 94 .6 1( 0. 41 ) 89 .7 1( 0. 0) 98 .1 1( 0. 23 ) 99 .6 1( 0. 17 ) 96 .9 6( 1. 63 ) 97 .7 9( 0. 68 ) pi m a 72 .9 4( 1. 07 ) 66 .5 9( 1. 32 ) 60 .5 6( 1. 57 ) 71 .9 3( 2. 22 ) 74 .7 6( 1. 6) 74 .2 6( 1. 63 ) 76 .9 4( 1. 87 ) 62 .6 8( 7. 55 ) 70 .5 3( 2. 19 ) 73 .6 4( 1. 37 ) 71 .5 3( 1. 79 ) 72 .2 8( 1. 99 ) 54 .5 4( 6. 0) 57 .9 9( 2. 85 ) 47 .5 3( 16 .5 2) 62 .3 1( 13 .7 ) 79 .6 8( 3. 06 ) 72 .1 7( 2. 71 ) 73 .1 8( 1. 93 ) 60 .4 5( 3. 01 ) 60 .6 2( 4. 21 ) 55 .1 9( 6. 92 ) 70 .2 7( 2. 28 ) 81 .5 (2 .5 7) 68 .5 9( 3. 93 ) 69 .8 8( 1. 95 ) sa te lli te 73 .2 (0 .9 2) 68 .3 4( 0. 0) 62 .2 2( 0. 0) 80 .1 1( 0. 11 ) 85 .5 (0 .0 ) 77 .4 6( 1. 48 ) 82 .2 4( 0. 0) 69 .7 3( 1. 15 ) 80 .3 (0 .0 ) 72 .7 6( 3. 68 ) 73 .9 1( 0. 0) 66 .6 3( 0. 0) 72 .7 9( 2. 01 ) 76 .1 9( 2. 66 ) 73 .3 8( 4. 44 ) 68 .7 6( 0. 92 ) 85 .1 5( 0. 48 ) 72 .3 (1 .7 3) 74 .1 4( 0. 25 ) 79 .8 7( 0. 56 ) 87 .4 9( 0. 1) 66 .9 1( 0. 0) 77 .7 (0 .5 3) 82 .1 1( 0. 67 ) 76 .5 2( 2. 68 ) 78 .6 1( 0. 7) sa tim ag e2 99 .4 2( 0. 01 ) 97 .9 2( 0. 0) 97 .0 9( 0. 0) 99 .4 7( 0. 03 ) 97 .9 5( 0. 0) 99 .1 2( 0. 21 ) 99 .7 1( 0. 0) 98 .6 7( 0. 52 ) 99 .3 8( 0. 0) 99 .9 2( 0. 0) 99 .6 1( 0. 0) 98 .1 7( 0. 0) 91 .8 2( 4. 43 ) 92 .9 4( 2. 84 ) 99 .2 2( 0. 42 ) 98 .9 9( 0. 06 ) 99 .4 8( 0. 22 ) 96 .6 7( 0. 57 ) 98 .9 8( 0. 04 ) 97 .5 7( 1. 19 ) 99 .7 7( 0. 0) 86 .9 (0 .0 ) 99 .6 2( 0. 16 ) 99 .6 7( 0. 0) 95 .3 4( 1. 84 ) 99 .3 4( 0. 07 ) sh ut tle 99 .7 2( 0. 02 ) 99 .4 7( 0. 0) 99 .3 3( 0. 0) 86 .8 9( 8. 22 ) 98 .6 4( 0. 0) 99 .6 5( 0. 07 ) 99 .9 1( 0. 0) 71 .6 8( 33 .8 8) 99 .9 8( 0. 0) 98 .9 8( 0. 0) 99 .6 2( 0. 0) 99 .3 6( 0. 0) 84 .5 8( 18 .6 8) 99 .7 9( 0. 07 ) 50 .0 (0 .0 ) 70 .4 4( 16 .2 8) 99 .9 2( 0. 04 ) 86 .5 (5 .6 8) 99 .3 5( 0. 0) 97 .5 3( 0. 74 ) 99 .9 (0 .0 1) 99 .7 6( 0. 0) 99 .9 1( 0. 01 ) 99 .9 3( 0. 02 ) 99 .8 6( 0. 12 ) 99 .7 5( 0. 0) sk in 91 .8 2( 0. 21 ) 47 .2 1( 0. 18 ) 49 .1 4( 0. 18 ) 78 .3 9( 0. 91 ) 76 .9 2( 0. 35 ) 89 .4 2( 0. 58 ) 99 .4 9( 0. 08 ) 75 .5 1( 5. 43 ) 86 .3 4( 1. 77 ) 88 .3 7( 0. 26 ) 90 .2 5( 0. 24 ) 59 .7 3( 0. 31 ) 67 .9 1( 30 .0 2) 59 .9 5( 4. 47 ) 89 .4 8( 1. 07 ) 64 .9 5( 2. 25 ) 6. 58 (0 .6 3) 91 .2 7( 7. 09 ) 66 .0 5( 0. 19 ) 48 .4 8( 2. 87 ) 91 .0 5( 2. 61 ) 87 .5 5( 0. 76 ) 88 .7 4( 4. 4) 98 .8 6( 0. 46 ) 98 .7 1( 1. 13 ) 91 .7 7( 0. 22 ) sm tp 87 .2 8( 5. 65 ) 91 .1 5( 1. 58 ) 88 .2 6( 2. 46 ) 84 .8 1( 3. 66 ) 82 .7 5( 5. 31 ) 90 .3 6( 2. 13 ) 92 .4 3( 2. 7) 73 .0 3( 6. 65 ) 93 .4 2( 2. 48 ) 94 .8 7( 0. 84 ) 84 .6 5( 4. 49 ) 81 .8 1( 7. 32 ) 87 .0 8( 5. 31 ) 85 .2 4( 6. 6) 57 .1 3( 15 .9 3) 78 .7 8( 13 .1 2) 74 .3 6( 7. 07 ) 84 .2 2( 6. 88 ) 81 .9 3( 5. 67 ) 54 .5 5( 5. 98 ) 92 .1 5( 1. 87 ) 95 .5 1( 1. 36 ) 95 .4 3( 1. 26 ) 92 .9 8( 2. 91 ) 81 .6 4( 9. 87 ) 95 .2 7( 1. 28 ) sp am ba se 81 .5 2( 0. 55 ) 72 .0 9( 0. 0) 68 .8 3( 0. 0) 69 .6 4( 2. 09 ) 77 .8 8( 0. 0) 85 .1 8( 1. 69 ) 83 .3 6( 0. 0) 72 .3 9( 6. 9) 73 .2 3( 0. 0) 80 .6 9( 3. 02 ) 81 .7 (0 .0 ) 81 .4 (0 .0 ) 69 .4 1( 4. 42 ) 70 .2 4( 5. 02 ) 75 .3 7( 4. 45 ) 81 .7 8( 0. 36 ) 83 .5 3( 0. 45 ) 82 .2 6( 3. 35 ) 81 .4 (0 .0 ) 82 .5 7( 1. 34 ) 84 .8 6( 0. 2) 41 .3 1( 0. 0) 64 .5 4( 0. 8) 83 .7 4( 0. 69 ) 77 .5 (3 .3 7) 83 .0 1( 0. 41 ) sp ee ch 35 .8 8( 0. 15 ) 37 .0 3( 0. 0) 35 .9 6( 0. 0) 37 .4 8( 0. 37 ) 36 .6 6( 0. 0) 37 .7 (1 .7 2) 36 .3 6( 0. 0) 38 .0 2( 2. 67 ) 37 .5 3( 0. 0) 38 .8 1( 0. 36 ) 36 .5 7( 0. 0) 36 .3 8( 0. 0) 50 .6 6( 3. 9) 48 .8 8( 2. 88 ) 48 .9 6( 2. 21 ) 36 .6 3( 1. 14 ) 48 .8 6( 2. 72 ) 48 .5 6( 4. 54 ) 36 .3 8( 0. 0) 38 .7 (3 .4 3) 41 .3 7( 0. 94 ) 52 .2 9( 3. 42 ) 36 .9 6( 0. 86 ) 41 .3 7( 0. 0) 39 .5 7( 1. 54 ) 38 .1 7( 0. 57 ) st am ps 93 .4 1( 1. 66 ) 93 .1 4( 0. 4) 87 .6 2( 0. 91 ) 94 .2 1( 2. 26 ) 91 .8 (1 .0 ) 93 .4 7( 1. 42 ) 95 .8 9( 1. 44 ) 91 .9 3( 3. 55 ) 93 .7 4( 2. 36 ) 84 .9 3( 2. 01 ) 93 .7 2( 1. 74 ) 92 .7 (1 .6 8) 80 .1 1( 11 .5 6) 71 .0 9( 3. 68 ) 50 .1 5( 22 .9 3) 81 .4 6( 15 .3 6) 96 .6 8( 1. 09 ) 87 .3 (1 0. 69 ) 93 .2 8( 1. 28 ) 66 .2 (7 .8 4) 81 .9 7( 8. 29 ) 84 .9 2( 4. 03 ) 91 .8 4( 4. 15 ) 97 .8 7( 0. 37 ) 93 .3 8( 3. 31 ) 91 .6 (2 .0 4) th yr oi d 98 .5 4( 0. 06 ) 93 .8 1( 0. 0) 97 .5 5( 0. 0) 93 .1 5( 1. 52 ) 98 .6 5( 0. 0) 98 .9 6( 0. 2) 98 .6 8( 0. 0) 96 .0 6( 1. 65 ) 92 .7 2( 0. 0) 98 .4 9( 0. 01 ) 98 .5 6( 0. 0) 98 .5 5( 0. 0) 91 .0 8( 6. 68 ) 88 .7 7( 3. 69 ) 94 .9 6( 1. 55 ) 95 .1 5( 0. 85 ) 95 .4 (0 .9 8) 98 .4 2( 0. 51 ) 98 .5 5( 0. 0) 94 .7 8( 3. 22 ) 95 .2 7( 0. 24 ) 96 .2 9( 0. 0) 97 .9 5( 0. 22 ) 98 .6 3( 0. 04 ) 89 .4 3( 11 .7 3) 98 .7 4( 0. 14 ) ve rt eb ra l 54 .4 3( 1. 97 ) 26 .3 4( 2. 49 ) 41 .9 5( 4. 78 ) 64 .1 3( 2. 15 ) 40 .0 9( 3. 97 ) 45 .6 4( 3. 83 ) 57 .6 7( 3. 58 ) 31 .6 6( 5. 28 ) 64 .3 (1 .3 1) 47 .1 (1 .8 2) 50 .4 7( 2. 23 ) 42 .0 8( 3. 49 ) 50 .6 (1 1. 93 ) 44 .7 9( 1. 71 ) 43 .8 4( 24 .2 8) 46 .7 3( 8. 74 ) 79 .1 9( 5. 06 ) 49 .7 8( 7. 82 ) 42 .6 3( 2. 75 ) 50 .6 7( 10 .7 1) 44 .9 6( 9. 25 ) 57 .2 1( 3. 04 ) 70 .6 7( 6. 28 ) 54 .3 (1 5. 47 ) 74 .6 3( 7. 58 ) 66 .4 1( 1. 9) vo w el s 78 .7 2( 4. 01 ) 52 .8 2( 0. 0) 61 .4 7( 0. 0) 85 .3 2( 1. 16 ) 53 .3 1( 0. 0) 61 .8 3( 0. 62 ) 82 .2 1( 0. 0) 55 .5 2( 8. 1) 86 .3 (0 .0 ) 27 .6 6( 0. 28 ) 75 .9 1( 0. 0) 52 .2 9( 0. 0) 42 .5 5( 11 .5 6) 55 .7 3( 4. 43 ) 54 .7 4( 21 .3 2) 68 .4 9( 3. 71 ) 85 .1 (2 .1 3) 54 .5 9( 10 .5 5) 52 .1 2( 0. 02 ) 63 .1 1( 9. 82 ) 85 .0 2( 0. 02 ) 88 .4 8( 0. 0) 86 .3 8( 1. 94 ) 81 .4 2( 1. 44 ) 85 .6 8( 3. 16 ) 86 .9 3( 2. 25 ) w av ef or m 72 .9 3( 0. 9) 72 .3 6( 0. 0) 59 .4 4( 0. 0) 76 .9 5( 1. 07 ) 69 .2 8( 0. 0) 72 .2 9( 1. 52 ) 75 .2 1( 0. 0) 60 .9 6( 5. 08 ) 76 .0 (0 .0 ) 58 .3 9( 0. 03 ) 70 .4 4( 0. 0) 64 .6 8( 0. 0) 51 .8 9( 7. 39 ) 59 .9 4( 2. 58 ) 67 .7 (5 .0 ) 64 .9 9( 3. 1) 68 .6 8( 3. 66 ) 64 .8 (2 .4 2) 64 .8 4( 0. 0) 75 .9 5( 7. 58 ) 48 .9 2( 0. 08 ) 50 .6 3( 0. 0) 62 .1 7( 2. 64 ) 74 .4 8( 0. 0) 73 .6 8( 2. 68 ) 65 .2 1( 1. 05 ) w bc 98 .3 1( 1. 31 ) 99 .4 (0 .2 5) 99 .3 9( 0. 25 ) 58 .0 5( 18 .0 8) 99 .0 (0 .4 1) 99 .4 1( 0. 37 ) 99 .1 2( 0. 19 ) 97 .8 6( 1. 59 ) 80 .5 2( 4. 47 ) 98 .8 8( 1. 02 ) 99 .6 3( 0. 19 ) 99 .3 5( 0. 13 ) 86 .7 6( 15 .3 3) 91 .4 4( 3. 64 ) 44 .2 4( 28 .2 1) 99 .1 4( 0. 2) 99 .6 6( 0. 36 ) 95 .9 7( 0. 81 ) 99 .2 5( 0. 27 ) 95 .9 1( 3. 0) 99 .7 8( 0. 18 ) 97 .4 6( 1. 82 ) 99 .2 (0 .3 9) 99 .5 4( 0. 28 ) 90 .9 8( 11 .6 4) 80 .5 3( 7. 15 ) w db c 98 .7 3( 0. 43 ) 99 .1 8( 0. 21 ) 96 .7 2( 0. 71 ) 99 .6 3( 0. 18 ) 98 .5 5( 0. 28 ) 98 .7 3( 0. 64 ) 99 .0 5( 0. 27 ) 96 .9 8( 2. 04 ) 99 .6 2( 0. 21 ) 97 .0 3( 0. 47 ) 99 .3 4( 0. 23 ) 99 .1 4( 0. 22 ) 73 .7 8( 25 .2 7) 99 .3 1( 0. 4) 40 .0 8( 33 .9 7) 98 .9 6( 0. 25 ) 99 .7 8( 0. 27 ) 98 .8 6( 0. 76 ) 99 .1 4( 0. 36 ) 96 .2 2( 3. 1) 99 .4 9( 0. 25 ) 68 .0 3( 7. 24 ) 99 .3 (0 .1 7) 99 .5 2( 0. 38 ) 99 .6 (0 .3 1) 98 .4 8( 0. 77 ) w ilt 42 .9 (1 .1 4) 32 .0 9( 0. 0) 37 .4 8( 0. 0) 73 .3 5( 10 .5 ) 39 .1 (0 .0 ) 47 .9 7( 3. 12 ) 63 .6 6( 0. 0) 41 .1 (7 .0 ) 68 .8 1( 0. 0) 81 .7 2( 0. 01 ) 34 .8 1( 0. 0) 26 .0 7( 0. 0) 41 .8 1( 7. 29 ) 34 .4 1( 1. 7) 49 .4 9( 12 .6 2) 51 .3 8( 5. 33 ) 76 .4 2( 3. 46 ) 74 .6 2( 4. 18 ) 35 .4 1( 0. 0) 44 .0 1( 5. 48 ) 61 .7 6( 0. 11 ) 55 .0 2( 0. 0) 71 .6 6( 0. 81 ) 62 .9 1( 5. 59 ) 93 .7 5( 3. 23 ) 85 .1 (1 .1 3) w in e 97 .7 5( 0. 59 ) 86 .3 7( 4. 37 ) 73 .8 6( 5. 42 ) 97 .9 3( 0. 87 ) 95 .6 3( 2. 63 ) 93 .9 2( 1. 79 ) 99 .1 9( 0. 22 ) 90 .9 4( 4. 75 ) 98 .3 6( 0. 38 ) 97 .2 8( 1. 8) 97 .8 2( 0. 45 ) 93 .7 9( 1. 58 ) 66 .1 7( 39 .6 1) 92 .1 6( 4. 34 ) 43 .8 (3 2. 33 ) 94 .1 1( 1. 86 ) 99 .8 7( 0. 29 ) 95 .3 8( 2. 4) 94 .2 5( 1. 47 ) 74 .3 2( 28 .6 4) 10 0. 0( 0. 0) 91 .0 9( 2. 25 ) 99 .6 1( 0. 09 ) 99 .4 4( 0. 97 ) 99 .9 5( 0. 11 ) 99 .9 7( 0. 04 ) w pb c 59 .5 7( 1. 98 ) 52 .3 3( 2. 93 ) 49 .5 (2 .4 7) 56 .7 9( 1. 86 ) 60 .9 1( 2. 67 ) 56 .3 3( 2. 72 ) 63 .6 7( 2. 34 ) 51 .3 2( 3. 74 ) 57 .3 6( 2. 01 ) 63 .3 6( 0. 93 ) 53 .3 7( 2. 44 ) 52 .5 4( 2. 3) 46 .9 9( 2. 56 ) 82 .6 7( 5. 47 ) 43 .7 8( 4. 34 ) 51 .3 9( 5. 74 ) 96 .6 1( 1. 17 ) 57 .4 6( 2. 93 ) 54 .4 2( 2. 76 ) 60 .1 1( 5. 48 ) 95 .5 3( 2. 21 ) 82 .5 1( 3. 26 ) 66 .4 9( 3. 17 ) 83 .1 6( 13 .4 6) 70 .7 1( 9. 06 ) 68 .8 8( 2. 7) ye as t 50 .4 (0 .0 8) 38 .8 8( 0. 0) 44 .6 4( 0. 0) 46 .4 (1 .3 3) 42 .8 8( 0. 0) 41 .8 (0 .7 5) 44 .7 4( 0. 0) 46 .5 1( 5. 8) 45 .7 9( 0. 0) 43 .0 5( 0. 1) 44 .8 4( 0. 0) 43 .2 4( 0. 0) 51 .0 3( 3. 92 ) 47 .6 2( 5. 96 ) 48 .4 2( 5. 46 ) 52 .5 3( 3. 88 ) 48 .9 8( 2. 39 ) 45 .0 7( 3. 33 ) 42 .3 9( 0. 01 ) 47 .6 4( 6. 7) 48 .6 9( 0. 11 ) 38 .4 4( 0. 0) 49 .1 3( 2. 85 ) 44 .5 8( 0. 33 ) 48 .5 8( 2. 89 ) 47 .0 8( 1. 1) ye lp 63 .8 (0 .0 7) 60 .2 1( 0. 0) 57 .3 9( 0. 0) 67 .0 6( 0. 12 ) 59 .9 5( 0. 0) 61 .0 7( 0. 53 ) 68 .0 7( 0. 0) 56 .2 6( 3. 78 ) 67 .2 (0 .0 ) 66 .1 5( 0. 04 ) 62 .0 8( 0. 0) 59 .1 6( 0. 0) 49 .8 7( 1. 25 ) 49 .9 (3 .3 ) 50 .6 7( 1. 15 ) 61 .0 7( 0. 98 ) 55 .7 9( 0. 5) 53 .6 (2 .0 3) 59 .1 4( 0. 04 ) 56 .1 1( 1. 6) 54 .8 8( 0. 19 ) 48 .3 6( 0. 23 ) 59 .3 (0 .0 9) 68 .6 6( 0. 0) 57 .3 2( 4. 3) 59 .9 4( 5. 32 ) M N IS TC 81 .1 1( 0. 09 ) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 87 .3 3( 0. 15 ) 70 .4 3( 0. 0) 76 .7 5( 1. 45 ) 84 .1 1( 0. 0) 69 .3 9( 5. 31 ) 87 .2 1( 0. 0) 75 .2 6( 1. 24 ) 79 .5 5( 0. 0) 78 .3 5( 0. 0) 63 .7 1( 6. 37 ) 64 .7 (4 .6 ) 57 .2 (1 1. 1) 79 .3 4( 0. 41 ) 85 .6 2( 0. 52 ) 71 .2 1( 1. 5) 78 .3 5( 0. 01 ) 80 .0 8( 1. 16 ) 83 .5 1( 0. 11 ) 54 .0 5( 2. 27 ) 80 .1 2( 0. 14 ) 84 .7 4( 0. 0) 79 .9 2( 3. 93 ) 86 .1 (0 .8 4) Fa sh io nM N IS T 89 .1 (0 .1 5) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 91 .6 7( 0. 11 ) 75 .4 2( 0. 0) 84 .1 5( 1. 07 ) 89 .8 7( 0. 0) 79 .2 8( 4. 1) 91 .6 (0 .0 ) 84 .3 7( 1. 11 ) 88 .1 6( 0. 0) 87 .6 (0 .0 ) 70 .8 (4 .8 9) 75 .4 5( 2. 22 ) 51 .5 8( 14 .4 4) 88 .0 3( 0. 24 ) 90 .5 6( 0. 27 ) 82 .1 9( 0. 96 ) 87 .6 (0 .0 ) 89 .4 3( 0. 52 ) 89 .9 4( 0. 04 ) 65 .5 3( 1. 77 ) 88 .5 2( 0. 07 ) 90 .1 4( 0. 0) 84 .3 2( 2. 44 ) 90 .2 1( 0. 55 ) C IF A R 10 67 .8 7( 0. 21 ) 54 .9 8( 0. 0) 56 .8 8( 0. 0) 70 .3 1( 0. 21 ) 57 .8 9( 0. 0) 64 .0 4( 0. 93 ) 67 .5 3( 0. 0) 61 .6 2( 4. 35 ) 70 .3 (0 .0 ) 65 .1 5( 0. 58 ) 67 .7 9( 0. 0) 67 .4 2( 0. 0) 53 .9 7( 2. 96 ) 56 .1 2( 2. 2) 49 .6 3( 3. 46 ) 67 .5 3( 0. 72 ) 63 .6 (0 .8 3) 62 .7 5( 1. 09 ) 67 .4 2( 0. 0) 67 .1 9( 0. 84 ) 66 .6 (0 .1 ) 52 .0 6( 1. 59 ) 67 .9 1( 0. 13 ) 67 .8 2( 0. 0) 62 .4 (3 .3 3) 68 .5 3( 1. 59 ) SV H N 60 .9 7( 0. 17 ) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 63 .9 3( 0. 14 ) 54 .6 5( 0. 0) 58 .9 9( 0. 88 ) 61 .6 9( 0. 0) 54 .5 (4 .0 2) 63 .8 2( 0. 0) 58 .8 7( 0. 65 ) 61 .2 5( 0. 0) 60 .7 9( 0. 0) 53 .3 6( 2. 12 ) 53 .9 2( 3. 05 ) 49 .9 9( 2. 47 ) 60 .7 5( 0. 49 ) 61 .7 (0 .5 ) 58 .8 7( 0. 87 ) 60 .7 9( 0. 0) 61 .2 5( 0. 77 ) 60 .8 7( 0. 07 ) 52 .9 8( 0. 67 ) 61 .3 7( 0. 08 ) 62 .1 3( 0. 0) 59 .1 9( 2. 5) 62 .9 1( 1. 1) M V Te cA D 79 .9 6( 2. 02 ) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 80 .4 5( 2. 2) 75 .9 7( 1. 84 ) 77 .3 8( 1. 95 ) 81 .5 1( 1. 82 ) 72 .3 1( 3. 37 ) 80 .3 6( 2. 14 ) 86 .7 5( 2. 12 ) 77 .4 4( 2. 03 ) 76 .3 7( 1. 91 ) 64 .6 9( 5. 63 ) 89 .5 5( 2. 19 ) 60 .5 2( 11 .4 2) 77 .0 6( 2. 1) 94 .7 5( 0. 84 ) 72 .8 (2 .3 9) 76 .2 1( 1. 81 ) 81 .1 (1 .8 ) 93 .2 4( 1. 09 ) 81 .9 9( 2. 78 ) 78 .0 (1 .9 9) 89 .6 6( 1. 51 ) 85 .8 8( 3. 63 ) 89 .3 9( 2. 0) 20 ne w s 57 .1 (1 .2 3) 52 .9 2( 0. 43 ) 54 .1 1( 0. 24 ) 60 .2 5( 0. 7) 53 .5 7( 0. 35 ) 54 .9 1( 1. 17 ) 57 .3 6( 0. 66 ) 53 .4 5( 4. 0) 60 .1 9( 0. 62 ) 62 .8 5( 1. 63 ) 56 .2 5( 0. 62 ) 54 .3 9( 0. 41 ) 51 .4 8( 4. 08 ) 55 .6 4( 4. 17 ) 52 .7 7( 4. 09 ) 54 .9 2( 1. 04 ) 61 .3 (1 .0 5) 51 .5 9( 3. 0) 54 .5 9( 0. 74 ) 59 .6 8( 1. 87 ) 59 .4 7( 0. 8) 53 .1 8( 2. 56 ) 54 .8 8( 0. 52 ) 59 .9 7( 0. 74 ) 58 .2 8( 6. 15 ) 64 .3 (3 .1 7) ag ne w s 62 .8 2( 0. 08 ) 55 .0 5( 0. 0) 55 .1 1( 0. 0) 74 .6 4( 0. 09 ) 55 .6 9( 0. 0) 58 .4 3( 1. 09 ) 67 .0 5( 0. 0) 56 .9 5( 3. 54 ) 74 .5 8( 0. 0) 67 .9 8( 0. 25 ) 60 .6 4( 0. 0) 56 .9 (0 .0 ) 51 .0 3( 3. 6) 49 .8 3( 5. 63 ) 49 .6 5( 0. 76 ) 59 .8 7( 0. 86 ) 62 .5 5( 0. 47 ) 50 .1 5( 1. 19 ) 56 .9 (0 .0 ) 58 .6 3( 1. 14 ) 58 .4 3( 0. 07 ) 52 .0 2( 0. 89 ) 57 .8 2( 0. 12 ) 67 .9 8( 0. 0) 56 .5 5( 4. 15 ) 68 .1 6( 3. 22 )\nTa bl\ne 14\n:A ve\nra ge\nF1 sc\nor e\nan d\nst an\nda rd\nde vi\nat io\nns ov\ner fiv\ne se\ned s\nfo rt\nhe se\nm i-\nsu pe\nrv is\ned se\ntti ng\non A\nD B\nen ch\n.\nC B\nL O\nF C\nO PO\nD E\nC O\nD Fe\nat ur\neB ag\ngi ng\nH B\nO S\nIF or\nes t\nkN N\nL O\nD A\nL O\nF M\nC D\nO C\nSV M\nPC A\nD A\nG M\nM D\nee pS\nV D\nD D\nR O\nC C\nG O\nA D\nIC L\nPl an\nar Fl\now VA\nE G\nA N\nom al\ny SL\nA D\nD IF\nD D\nPM D\nT E\n-N P\nD T\nE -I\nG D\nT E\n-C\nal oi\n53 .6\n9( 0.\n15 )\n49 .5\nal oi\n6. 74\n(0 .0\n8) 4.\n58 (0\n.0 )\n4. 44\n(0 .0\n) 8.\n93 (0\n.5 7)\n7. 43\n(0 .0\n) 4.\n2( 0.\n26 )\n5. 9(\n0. 0)\n6. 6(\n1. 58\n) 8.\n16 (0\n.0 )\n3. 41\n(0 .1\n4) 7.\n29 (0\n.0 )\n7. 63\n(0 .0\n) 5.\n98 (1\n.6 7)\n5. 17\n(0 .9\n2) 0.\n0( 0.\n0) 5.\n73 (1\n.4 5)\n4. 91\n(0 .5\n6) 3.\n83 (0\n.7 2)\n7. 63\n(0 .0\n) 9.\n35 (2\n.2 7)\n5. 32\n(0 .1\n1) 3.\n91 (0\n.0 )\n6. 76\n(0 .1\n9) 5.\n82 (0\n.0 7)\n5. 12\n(0 .6\n8) 4.\n2( 0. 2) am az on 11 .5 2( 0.\n5) 11\n.4 (0\n.0 )\n10 .0\n(0 .0\n) 10\n.0 (0\n.1 4)\n10 .6\n(0 .0\n) 11\n.2 8(\n0. 64\n) 11\n.4 (0\n.0 )\n10 .6\n4( 1.\n18 )\n10 .0\n(0 .0\n) 11\n.3 2(\n0. 23\n) 12\n.0 (0\n.0 )\n11 .0\n(0 .0\n) 9.\n48 (1\n.2 3)\n11 .7\n6( 2.\n19 )\n0. 0(\n0. 0)\n11 .5\n6( 0.\n26 )\n9. 4(\n0. 32\n) 9.\n48 (1\n.6 2)\n11 .0\n(0 .0\n) 8.\n96 (0\n.7 4)\n10 .1\n6( 0.\n22 )\n9. 32\n(0 .6\n6) 11\n.0 8(\n0. 11\n) 10\n.8 (0\n.0 )\n10 .4\n8( 2.\n37 )\n11 .8\n(1 .5 3) an nt hy ro id 56 .7 (3 .3 ) 31 .6 5( 0. 0) 38 .3 9( 0. 0) 50 .6 7( 5. 76 ) 35 .9 6( 0. 0) 55 .0 2( 4. 22 ) 61 .9 9( 0. 0) 46 .7 8( 5. 94 ) 49 .6 3( 0. 0) 50 .3 7( 0. 0) 53 .5 6( 0. 0) 50 .0 (0 .0 ) 45 .6 6( 16 .4 4) 23 .3 3( 5. 12 ) 57 .4 2( 2. 53 ) 55 .7 7( 4. 62 ) 49 .4 4( 3. 88 ) 60 .0 (7 .7 6) 50 .1 9( 0. 0) 34 .4 2( 7. 48 ) 65 .9 9( 0. 62 ) 58 .9 9( 0. 0) 57 .2 3( 2. 96 ) 61 .8 4( 1. 59 ) 48 .8 (7 .0 4) 77 .7 2( 0. 5) ba ck do or 7. 74 (1 .1 ) 0. 0( 0. 0) 0. 0( 0. 0) 58 .5 3( 7. 63 ) 6. 93 (0 .6 1) 4. 07 (2 .4 ) 52 .0 1( 1. 92 ) 4. 64 (4 .1 5) 72 .4 2( 2. 18 ) 19 .4 9( 27 .3 6) 7. 94 (0 .8 5) 8. 3( 1. 0) 5. 25 (3 .9 4) 82 .9 6( 3. 28 ) 85 .4 4( 1. 14 ) 4. 79 (3 .4 7) 87 .1 5( 1. 1) 36 .7 3( 22 .1 7) 8. 5( 1. 27 ) 21 .9 2( 20 .4 1) 0. 0( 0. 0) 20 .2 8( 2. 02 ) 9. 6( 0. 62 ) 51 .4 8( 17 .2 6) 84 .4 5( 2. 16 ) 82 .5 8( 2.\n44 )\nbr ea\nst w\n95 .7\n8( 0.\n27 )\n96 .4\n1( 0.\n34 )\n94 .6\n3( 0.\n53 )\n60 .9\n9( 14\n.7 )\n96 .9\n3( 0.\n34 )\n96 .9\n4( 0.\n46 )\n95 .7\n7( 0.\n19 )\n95 .6\n7( 0.\n47 )\n85 .4\n(5 .9\n3) 95\n.8 4(\n0. 67\n) 96\n.6 6(\n1. 1)\n95 .7\n8( 0.\n45 )\n83 .5\n2( 11\n.1 )\n91 .8\n5( 0.\n77 )\n48 .2\n7( 26\n.5 5)\n95 .6\n6( 0.\n34 )\n95 .9\n1( 0.\n68 )\n94 .0\n9( 1.\n69 )\n96 .1\n2( 0.\n47 )\n90 .0\n5( 3.\n37 )\n96 .8\n7( 0.\n65 )\n56 .8\n1( 4.\n58 )\n95 .0\n4( 0.\n75 )\n96 .6\n6( 0.\n71 )\n74 .0\n3( 10\n.3 2)\n88 .1\n8( 2.\n86 )\nca m\npa ig\nn 49\n.2 9(\n0. 2)\n49 .2\n7( 0.\n0) 48\n.3 8(\n0. 0)\n37 .1\n5( 6.\n73 )\n47 .9\n1( 0.\n0) 43\n.7 (0\n.9 1)\n50 .3\n7( 0.\n0) 30\n.7 4(\n5. 47\n) 42\n.2 4(\n0. 0)\n48 .3\n3( 1.\n62 )\n49 .5\n9( 0.\n0) 48\n.8 4(\n0. 0)\n34 .1\n3( 3.\n43 )\n37 .8\n9( 12\n.9 )\n0. 0(\n0. 0)\n22 .6\n2( 9.\n05 )\n51 .0\n3( 0.\n73 )\n42 .1\n1( 2.\n88 )\n48 .8\n4( 0.\n0) 40\n.9 2(\n4. 2)\n49 .8\n3( 0.\n0) 27\n.1 1(\n0. 0)\n50 .4\n(0 .6\n8) 50\n.9 8(\n0. 61\n) 47\n.8 5(\n2. 0)\n52 .1\n2( 0.\n62 )\nca rd\nio 70\n.0 (5\n.0 4)\n70 .4\n5( 0.\n0) 73\n.8 6(\n0. 0)\n62 .9\n5( 3.\n04 )\n56 .2\n5( 0.\n0) 67\n.5 (3\n.3 2)\n61 .9\n3( 0.\n0) 63\n.4 1(\n3. 82\n) 62\n.5 (0\n.0 )\n59 .0\n9( 0.\n0) 70\n.4 5(\n0. 0)\n76 .1\n4( 0.\n0) 53\n.0 7(\n6. 55\n) 38\n.4 1(\n4. 19\n) 46\n.9 3(\n23 .4\n1) 74\n.8 9(\n0. 93\n) 52\n.1 6(\n5. 49\n) 59\n.7 7(\n1. 94\n) 76\n.1 4(\n0. 0)\n58 .7\n5( 3.\n47 )\n60 .8\n(0 .0\n) 27\n.2 7(\n0. 0)\n61 .7\n(1 .7\n3) 63\n.0 7(\n0. 0)\n36 .8\n2( 14\n.2 9)\n58 .3\n(0 .7 6) ca rd io to co gr ap hy 51 .4 2( 3. 49 ) 48 .2 8( 0. 0) 62 .8 8( 0. 0) 48 .4 1( 1. 57 ) 41 .4 2( 0. 0) 56 .1 4( 2. 75 ) 46 .3 5( 0. 0) 55 .1 1( 7. 7) 48 .2 8( 0. 0) 36 .4 8( 1. 78 ) 57 .9 4( 0. 0) 61 .5 9( 0. 0) 52 .3 2( 9. 99 ) 37 .0 8( 5. 46 ) 33 .9 5( 12 .3 7) 59 .9 6( 1. 08 ) 38 .9 3( 2. 89 ) 49 .4 (6 .5 3) 61 .5 9( 0. 0) 46 .3 5( 9. 46 ) 33 .8 2( 0. 47 ) 31 .3 3( 0. 0) 38 .8 4( 2. 75 ) 46 .7 8( 1. 44 ) 31 .6 7( 2. 63 ) 38 .3 7( 2.\n23 )\nce le\nba 25\n.3 2(\n7. 14\n) 22\n.7 8(\n0. 91\n) 22\n.8 1(\n0. 78\n) 2.\n92 (0\n.8 9)\n22 .6\n8( 0.\n93 )\n17 .3\n3( 2.\n29 )\n17 .1\n9( 0.\n83 )\n13 .2\n6( 8.\n39 )\n1. 91\n(0 .4\n7) 25\n.1 2(\n4. 44\n) 27\n.3 7(\n0. 74\n) 27\n.1 7(\n0. 49\n) 14\n.1 9(\n5. 61\n) 8.\n43 (5\n.5 )\n8. 62\n(0 .8\n4) 3.\n98 (2\n.9 8)\n12 .6\n9( 1.\n83 )\n17 .9\n1( 7.\n49 )\n27 .0\n4( 0.\n41 )\n11 .0\n7( 7.\n99 )\n13 .6\n9( 1.\n66 )\n10 .7\n9( 1.\n42 )\n26 .0\n2( 2.\n89 )\n15 .8\n1( 0.\n69 )\n19 .1\n1( 5.\n61 )\n17 .3\n5( 3.\n48 )\nce ns\nus 21\n.4 6(\n0. 28\n) 0.\n0( 0.\n0) 0.\n0( 0.\n0) 3.\n47 (1\n.3 )\n10 .7\n7( 0.\n62 )\n10 .5\n4( 1.\n4) 22\n.5 2(\n0. 51\n) 14\n.1 5(\n8. 41\n) 13\n.0 9(\n0. 42\n) 29\n.4 5(\n3. 37\n) 20\n.6 7(\n0. 38\n) 20\n.8 2(\n0. 33\n) 14\n.4 6(\n2. 49\n) 19\n.2 8(\n1. 44\n) 15\n.5 5(\n1. 44\n) 4.\n96 (2\n.1 3)\n23 .9\n6( 0.\n54 )\n13 .8\n6( 2.\n4) 20\n.7 6(\n0. 27\n) 18\n.2 7(\n3. 91\n) 8.\n65 (1\n1. 85\n) 14\n.4 4(\n1. 82\n) 20\n.2 7(\n0. 48\n) 22\n.2 1(\n0. 6)\n17 .4\n7( 2.\n81 )\n17 .4\n3( 2.\n38 )\nco ve\nr 13\n.9 9(\n1. 06\n) 18\n.8 2(\n0. 81\n) 24\n.4 6(\n1. 11\n) 79\n.4 1(\n10 .6\n) 10\n.7 5(\n1. 26\n) 11\n.6 1(\n1. 24\n) 65\n.1 (2\n.1 5)\n24 .1\n9( 12\n.2 6)\n82 .4\n(2 .1\n6) 3.\n44 (0\n.3 1)\n24 .5\n5( 1.\n58 )\n16 .2\n4( 1.\n53 )\n12 .1\n6( 11\n.5 6)\n3. 43\n(3 .4\n4) 41\n.8 7(\n7. 55\n) 0.\n0( 0.\n0) 39\n.9 6(\n12 .7\n1) 2.\n59 (2\n.4 8)\n16 .2\n1( 1.\n68 )\n25 .6\n9( 34\n.3 7)\n9. 14\n(8 .1\n3) 1.\n19 (0\n.8 5)\n76 .8\n6( 1.\n33 )\n66 .8\n4( 7.\n4) 77\n.7 9(\n3. 91\n) 71\n.0 4(\n9. 46 ) do no rs 48 .4 8( 1. 33 ) 41 .3 7( 0. 99 ) 44 .6 (1 .0 4) 56 .1 1( 14 .4 ) 24 .3 6( 3. 68 ) 43 .4 6( 3. 54 ) 94 .9 1( 0. 67 ) 21 .0 4( 27 .8 1) 74 .4 7( 2. 04 ) 33 .3 2( 14 .2 1) 39 .5 2( 1. 55 ) 37 .3 (1 .8 ) 21 .9 4( 14 .5 4) 41 .4 4( 30 .4 ) 29 .3 7( 27 .5 4) 4. 29 (4 .1 3) 97 .2 2( 1. 04 ) 47 .8 4( 14 .5 8) 37 .7 5( 0. 93 ) 18 .9 8( 16 .4 7) 55 .8 6( 8. 74 ) 37 .4 (5 .8 3) 25 .0 1( 7. 13 ) 92 .9 (2 .8 3) 93 .1 1( 3. 02 ) 82 .1 7( 2. 54 ) fa ul t 56 .4 (0 .8 7) 50 .8 2( 0. 0) 51 .5 6( 0. 0) 50 .4 (0 .8 5) 53 .6 4( 0. 0) 53 .6 4( 1. 34 ) 55 .5 7( 0. 0) 51 .5 9( 1. 84 ) 50 .6 7( 0. 0) 56 .3 7( 1. 62 ) 55 .1 3( 0. 0) 55 .2 7( 0. 0) 53 .2 2( 4. 51 ) 54 .9 2( 1. 38 ) 56 .7 (4 .7 2) 55 .9 6( 0. 68 ) 57 .5 9( 0. 56 ) 57 .6 5( 4. 55 ) 55 .2 2( 0. 08 ) 56 .7 6( 4. 09 ) 60 .0 6( 0. 24 ) 61 .9 6( 0. 0) 58 .4 5( 1. 15 ) 56 .2 (0 .4 ) 55 .8 1( 0. 56 ) 56 .2 3( 1. 73 ) fr au d 34 .3 9( 0. 6) 46 .1 6( 3. 48 ) 37 .8 1( 2. 09 ) 67 .6 5( 4. 19 ) 41 .5 1( 4. 73 ) 28 .0 3( 4. 09 ) 45 .2 2( 4. 87 ) 45 .0 6( 11 .5 9) 59 .4 7( 4. 5) 56 .1 9( 3. 88 ) 41 .5 2( 5. 56 ) 33 .2 6( 1. 7) 20 .8 8( 22 .3 2) 58 .1 1( 14 .7 7) 0. 0( 0. 0) 37 .2 8( 25 .8 ) 57 .4 3( 5. 97 ) 66 .5 5( 9. 18 ) 34 .4 6( 3. 22 ) 61 .1 7( 11 .0 7) 47 .3 9( 4. 57 ) 4. 59 (3 .7 3) 73 .1 6( 2. 29 ) 48 .3 6( 5. 41 ) 55 .6 1( 10 .9 6) 68 .2 3( 13 .1 1) gl as s 23 .7 5( 14 .3 1) 19 .0 6( 8. 56 ) 15 .7 7( 8. 65 ) 22 .4 5( 7. 76 ) 27 .6 8( 10 .3 9) 16 .1 8( 7. 01 ) 25 .8 7( 13 .7 6) 14 .6 (4 .7 1) 20 .4 6( 8. 79 ) 16 .2 5( 9. 09 ) 14 .9 7( 7. 84 ) 15 .7 7( 8. 65 ) 13 .7 2( 16 .1 ) 45 .3 9( 21 .8 7) 15 .4 8( 13 .1 4) 20 .1 5( 11 .0 ) 87 .8 3( 9. 1) 19 .5 6( 11 .2 ) 18 .0 3( 5. 11 ) 24 .8 3( 10 .9 9) 35 .0 3( 7. 61 ) 60 .4 1( 14 .5 5) 32 .8 1( 13 .3 6) 24 .5 8( 16 .8 3) 78 .4 (1 3. 6) 37 .4 6( 6. 39 ) he pa tit is 66 .9 3( 8. 55 ) 53 .7 8( 0. 81 ) 37 .6 (3 .8 8) 41 .2 7( 12 .6 ) 58 .0 8( 1. 24 ) 54 .0 (5 .5 4) 81 .2 9( 5. 04 ) 46 .7 6( 9. 9) 41 .9 5( 10 .6 2) 49 .4 9( 11 .0 4) 66 .6 1( 4. 93 ) 60 .5 6( 7. 59 ) 47 .5 1( 7. 54 ) 93 .8 2( 1. 29 ) 29 .2 9( 17 .2 8) 57 .8 6( 7. 77 ) 99 .6 4( 0. 79 ) 79 .7 5( 3. 37 ) 60 .5 1( 6. 9) 65 .5 1( 10 .6 6) 99 .6 4( 0. 79 ) 81 .1 (4 .4 3) 86 .6 9( 4. 26 ) 79 .0 3( 11 .9 5) 99 .6 4( 0. 79 ) 92 .8 (3 .3 2) ht tp 91 .2 9( 1. 52 ) 2. 16 (1 .1 5) 2. 05 (1 .2 9) 0. 0( 0. 0) 3. 64 (3 .6 5) 25 .8 (2 2. 46 ) 10 0. 0( 0. 0) 1. 05 (0 .9 6) 96 .7 8( 3. 13 ) 93 .0 5( 1. 51 ) 99 .7 8( 0. 3) 92 .7 1( 1. 43 ) 48 .9 5( 34 .3 7) 25 .0 (2 2. 46 ) 0. 0( 0. 0) 56 .3 9( 17 .6 1) 60 .7 (5 3. 56 ) 14 .4 3( 12 .3 1) 91 .9 4( 1. 25 ) 18 .9 9( 41 .3 ) 88 .4 9( 9. 31 ) 14 .1 8( 12 .0 7) 99 .6 8( 0. 3) 97 .4 3( 3. 53 ) 78 .8 2( 42 .9 4) 24 .5 9( 15 .3 ) im db 6. 96 (0 .0 9) 6. 6( 0. 0) 5. 0( 0. 0) 6. 56 (0 .3 ) 6. 4( 0. 0) 6. 2( 0. 49 ) 5. 4( 0. 0) 7. 04 (1 .0 8) 6. 4( 0. 0) 7. 44 (0 .2 2) 5. 8( 0. 0) 5. 6( 0. 0) 8. 92 (1 .3 7) 9. 96 (2 .7 1) 4. 4( 6. 03 ) 5. 64 (0 .6 5) 10 .5 6( 0. 54 ) 9. 24 (1 .4 5) 5. 6( 0. 0) 6. 96 (0 .5 5) 10 .2 4( 0. 22 ) 11 .4 4( 0. 77 ) 5. 56 (0 .0 9) 5. 2( 0. 0) 10 .3 6( 5. 13 ) 7. 24 (1 .6 2) in te rn et ad s 45 .7 6( 0. 24 ) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 54 .3 5( 3. 71 ) 27 .1 7( 0. 0) 26 .4 1( 4. 44 ) 51 .9 (0 .0 ) 41 .3 6( 2. 56 ) 54 .6 2( 0. 0) 33 .4 2( 0. 0) 46 .2 (0 .0 ) 45 .6 5( 0. 0) 31 .8 5( 5. 57 ) 54 .2 9( 5. 92 ) 38 .4 2( 6. 06 ) 46 .1 4( 0. 52 ) 55 .8 7( 0. 91 ) 55 .8 2( 1. 78 ) 45 .6 5( 0. 0) 52 .7 2( 0. 54 ) 57 .8 3( 0. 3) 31 .1 4( 0. 15 ) 45 .8 7( 0. 35 ) 53 .2 1( 3. 77 ) 54 .9 5( 5. 79 ) 64 .7 8( 2. 48 ) io no sp he re 91 .9 6( 2. 14 ) 69 .5 3( 2. 51 ) 64 .5 (2 .1 1) 87 .6 5( 2. 26 ) 69 .4 9( 1. 68 ) 83 .4 3( 3. 5) 90 .4 7( 2. 17 ) 77 .3 4( 4. 54 ) 87 .5 3( 2. 54 ) 88 .6 4( 1. 2) 92 .6 2( 1. 51 ) 78 .9 9( 2. 57 ) 69 .3 3( 4. 23 ) 93 .0 7( 1. 23 ) 60 .1 9( 21 .5 7) 83 .4 2( 5. 88 ) 94 .1 8( 1. 62 ) 90 .8 3( 1. 6) 79 .8 (2 .2 6) 86 .1 7( 2. 5) 92 .6 5( 1. 26 ) 85 .8 6( 1. 47 ) 88 .6 4( 1. 58 ) 91 .5 1( 2. 09 ) 89 .6 8( 4. 23 ) 89 .5 8( 0. 9) la nd sa t 38 .3 3( 0. 19 ) 33 .8 3( 0. 0) 30 .7 6( 0. 0) 53 .9 7( 0. 17 ) 52 .1 4( 0. 0) 43 .2 7( 1. 34 ) 51 .4 6( 0. 0) 36 .8 9( 4. 89 ) 53 .6 4( 0. 0) 47 .7 (9 .5 4) 38 .5 6( 0. 0) 33 .9 8( 0. 0) 40 .9 5( 4. 11 ) 42 .1 8( 2. 53 ) 40 .8 (3 .6 1) 32 .9 6( 1. 19 ) 53 .8 2( 0. 35 ) 35 .7 7( 1. 67 ) 38 .7 7( 4. 59 ) 35 .1 2( 11 .1 6) 46 .9 3( 0. 04 ) 34 .4 3( 0. 0) 40 .2 3( 1. 02 ) 51 .2 2( 2. 55 ) 30 .2 6( 4. 37 ) 38 .2 9( 2. 94 ) le tte r 1. 0( 0. 0) 4. 0( 0. 0) 9. 0( 0. 0) 8. 6( 1. 34 ) 6. 0( 0. 0) 3. 8( 1. 1) 1. 0( 0. 0) 1. 2( 0. 45 ) 10 .0 (0 .0 ) 2. 4( 0. 89 ) 1. 0( 0. 0) 1. 0( 0. 0) 8. 6( 4. 39 ) 5. 0( 1. 58 ) 13 .6 (8 .6 2) 1. 2( 0. 45 ) 7. 2( 0. 84 ) 3. 8( 2. 39 ) 1. 0( 0. 0) 1. 2( 0. 84 ) 1. 6( 0. 55 ) 28 .0 (0 .0 ) 3. 6( 0. 89 ) 1. 0( 0. 0) 3. 4( 0. 55 ) 2. 4( 1. 67 ) ly m ph og ra ph y 89 .2 8( 1. 85 ) 88 .4 7( 4. 27 ) 86 .6 7( 6. 42 ) 65 .3 4( 17 .1 6) 88 .4 9( 3. 88 ) 85 .0 5( 4. 72 ) 94 .5 (6 .4 7) 24 .0 5( 20 .7 9) 74 .8 7( 7. 44 ) 83 .7 3( 4. 92 ) 10 0. 0( 0. 0) 90 .8 6( 4. 08 ) 67 .5 8( 11 .6 3) 89 .8 2( 9. 49 ) 26 .1 5( 35 .8 2) 93 .1 3( 5. 46 ) 10 0. 0( 0. 0) 91 .0 7( 9. 32 ) 92 .9 6( 5. 55 ) 83 .3 1( 12 .4 3) 99 .4 7( 1. 18 ) 94 .4 (7 .7 7) 95 .1 9( 6. 67 ) 95 .7 8( 5. 81 ) 97 .8 9( 4. 71 ) 82 .0 1( 3. 83 ) m ag ic .g am m a 69 .2 4( 0. 01 ) 62 .8 6( 0. 0) 59 .7 2( 0. 0) 76 .8 5( 0. 77 ) 67 .1 9( 0. 0) 69 .6 4( 1. 25 ) 76 .1 7( 0. 0) 65 .4 8( 1. 31 ) 76 .0 8( 0. 0) 67 .8 9( 0. 12 ) 68 .3 8( 0. 0) 65 .1 9( 0. 0) 57 .3 5( 2. 82 ) 59 .8 8( 0. 89 ) 72 .6 1( 0. 67 ) 62 .7 2( 1. 48 ) 69 .5 5( 0. 47 ) 67 .8 2( 1. 62 ) 65 .2 5( 0. 0) 56 .9 5( 1. 27 ) 65 .9 5( 0. 02 ) 62 .0 2( 0. 0) 78 .8 8( 0. 95 ) 76 .4 6( 0. 81 ) 79 .3 1( 1. 11 ) 80 .7 8( 0. 8) m am m og ra ph y 49 .2 3( 0. 0) 52 .6 9( 0. 0) 53 .0 8( 0. 0) 39 .3 8( 0. 97 ) 16 .9 2( 0. 0) 39 .2 3( 2. 48 ) 40 .3 8( 0. 0) 47 .9 2( 2. 01 ) 38 .4 6( 0. 0) 2. 62 (0 .6 3) 41 .9 2( 0. 0) 44 .6 2( 0. 0) 26 .8 5( 20 .2 ) 31 .6 2( 10 .2 1) 32 .6 9( 2. 68 ) 35 .6 2( 5. 7) 17 .3 8( 3. 62 ) 22 .0 (1 0. 88 ) 45 .0 (0 .0 ) 36 .8 5( 22 .7 8) 22 .1 5( 1. 26 ) 16 .8 5( 0. 42 ) 24 .6 2( 4. 04 ) 42 .3 8( 1. 03 ) 35 .3 1( 7. 05 ) 37 .3 1( 3. 91 ) m ni st 65 .9 4( 0. 44 ) 0. 0( 0. 0) 0. 0( 0. 0) 68 .8 9( 1. 44 ) 24 .1 4( 0. 0) 52 .6 (4 .6 4) 71 .8 6( 0. 0) 33 .8 (7 .6 8) 71 .4 3( 0. 0) 55 .9 7( 2. 61 ) 64 .2 9( 0. 0) 63 .8 6( 0. 0) 44 .6 6( 8. 53 ) 43 .3 1( 11 .2 1) 57 .2 9( 2. 09 ) 63 .9 1( 1. 13 ) 64 .8 9( 1. 95 ) 52 .1 4( 4. 56 ) 63 .8 6( 0. 0) 41 .8 3( 5. 0) 67 .0 (0 .3 9) 21 .2 9( 0. 0) 60 .3 7( 3. 89 ) 72 .6 (1 .2 1) 50 .4 3( 8. 41 ) 58 .4 6( 2. 88 ) m us k 10 0. 0( 0. 0) 87 .6 3( 0. 0) 92 .7 8( 0. 0) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 35 .8 8( 24 .7 8) 10 0. 0( 0. 0) 90 .7 2( 5. 41 ) 10 0. 0( 0. 0) 53 .6 1( 14 .3 ) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 70 .7 2( 21 .5 3) 99 .1 8( 1. 13 ) 12 .1 6( 17 .4 4) 10 0. 0( 0. 0) 83 .3 (8 .9 7) 35 .0 5( 28 .1 7) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 70 .1 (0 .0 ) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 88 .6 6( 25 .3 6) 10 0. 0( 0. 0) op td ig its 1. 6( 0. 37 ) 0. 0( 0. 0) 0. 0( 0. 0) 47 .3 3( 4. 45 ) 40 .6 7( 0. 0) 12 .8 (6 .2 8) 21 .3 3( 0. 0) 1. 07 (1 .6 7) 53 .3 3( 0. 0) 0. 0( 0. 0) 0. 67 (0 .0 ) 0. 67 (0 .0 ) 0. 27 (0 .6 ) 0. 0( 0. 0) 20 .1 3( 7. 2) 0. 4( 0. 37 ) 57 .7 3( 8. 41 ) 0. 0( 0. 0) 0. 67 (0 .0 ) 4. 93 (4 .0 7) 39 .8 7( 0. 73 ) 0. 67 (0 .0 ) 28 .4 (7 .0 5) 27 .2 (1 0. 73 ) 27 .0 7( 18 .5 7) 10 .9 3( 3. 39 ) pa ge bl oc ks 65 .2 9( 0. 28 ) 36 .6 7( 0. 0) 49 .2 2( 0. 0) 63 .4 5( 1. 67 ) 12 .3 5( 0. 0) 42 .6 3( 2. 29 ) 59 .0 2( 0. 0) 46 .8 2( 3. 32 ) 65 .8 8( 0. 0) 57 .5 7( 0. 11 ) 55 .6 9( 0. 0) 46 .8 6( 0. 0) 57 .9 2( 11 .7 7) 54 .7 1( 3. 06 ) 68 .4 3( 1. 73 ) 50 .2 4( 1. 07 ) 64 .9 (1 .2 9) 54 .3 5( 2. 08 ) 46 .8 6( 0. 0) 39 .8 (1 6. 8) 60 .2 (0 .0 ) 61 .9 6( 0. 0) 50 .3 1( 0. 73 ) 59 .2 9( 0. 26 ) 54 .5 9( 2. 54 ) 62 .1 2( 0. 47 ) pe nd ig its 49 .2 3( 0. 7) 35 .2 6( 0. 0) 43 .5 9( 0. 0) 83 .3 3( 3. 51 ) 41 .0 3( 0. 0) 57 .9 5( 4. 75 ) 90 .3 8( 0. 0) 42 .0 5( 6. 31 ) 76 .2 8( 0. 0) 14 .3 6( 0. 35 ) 53 .2 1( 0. 0) 44 .2 3( 0. 0) 13 .9 7( 16 .5 6) 12 .3 1( 12 .2 ) 19 .2 3( 5. 21 ) 41 .5 4( 3. 49 ) 61 .1 5( 5. 82 ) 14 .2 3( 6. 24 ) 44 .2 3( 0. 0) 15 .5 1( 20 .4 8) 44 .3 6( 1. 05 ) 26 .9 2( 0. 0) 64 .6 2( 2. 62 ) 83 .4 6( 6. 02 ) 59 .7 4( 9. 95 ) 56 .0 3( 8. 28 ) pi m a 68 .7 8( 2. 76 ) 63 .1 6( 2. 25 ) 58 .5 4( 1. 89 ) 68 .4 3( 3. 04 ) 69 .6 (2 .7 6) 69 .5 7( 2. 68 ) 70 .5 6( 2. 49 ) 61 .1 4( 5. 31 ) 66 .7 5( 3. 0) 70 .8 6( 2. 2) 68 .5 9( 2. 02 ) 69 .3 (2 .9 2) 54 .0 5( 5. 38 ) 55 .9 5( 2. 36 ) 50 .0 1( 13 .5 7) 59 .1 9( 11 .7 7) 73 .5 4( 2. 63 ) 67 .9 2( 2. 87 ) 70 .4 5( 2. 76 ) 58 .9 3( 5. 42 ) 58 .8 7( 2. 87 ) 54 .4 7( 4. 52 ) 66 .6 2( 2. 63 ) 74 .6 9( 2. 25 ) 65 .1 7( 3. 7) 65 .2 5( 3. 25 ) sa te lli te 64 .0 2( 0. 07 ) 60 .7 1( 0. 0) 56 .6 3( 0. 0) 72 .6 (0 .0 8) 75 .9 8( 0. 0) 67 .1 2( 0. 64 ) 71 .8 1( 0. 0) 65 .0 1( 1. 17 ) 72 .6 4( 0. 0) 63 .1 5( 5. 11 ) 67 .3 4( 0. 0) 62 .6 7( 0. 0) 65 .1 3( 1. 63 ) 67 .7 6( 2. 88 ) 67 .5 2( 3. 93 ) 63 .5 8( 0. 48 ) 74 .9 9( 0. 46 ) 66 .0 1( 1. 44 ) 66 .1 7( 0. 11 ) 69 .9 8( 0. 81 ) 78 .2 4( 0. 13 ) 63 .8 5( 0. 0) 73 .7 4( 0. 27 ) 71 .9 1( 0. 99 ) 70 .5 7( 3. 05 ) 72 .3 3( 0. 63 ) sa tim ag e2 92 .9 6( 0. 0) 80 .2 8( 0. 0) 78 .8 7( 0. 0) 84 .5 1( 1. 0) 83 .1 (0 .0 ) 89 .5 8( 1. 61 ) 90 .1 4( 0. 0) 88 .7 3( 1. 0) 81 .6 9( 0. 0) 95 .7 7( 0. 0) 91 .5 5( 0. 0) 87 .3 2( 0. 0) 50 .4 2( 33 .8 8) 73 .2 4( 6. 68 ) 76 .3 4( 13 .4 5) 90 .7 (0 .7 7) 88 .4 5( 1. 54 ) 62 .2 5( 5. 49 ) 88 .1 7( 0. 77 ) 76 .6 2( 15 .8 3) 88 .7 3( 0. 0) 0. 0( 0. 0) 78 .5 9( 5. 12 ) 90 .1 4( 0. 0) 78 .3 1( 5. 23 ) 66 .4 8( 2. 71 ) sh ut tle 96 .3 1( 0. 16 ) 96 .0 7( 0. 0) 91 .8 (0 .0 ) 30 .9 1( 41 .5 2) 95 .0 7( 0. 0) 96 .7 1( 0. 53 ) 98 .2 3( 0. 0) 53 .1 1( 44 .5 5) 98 .4 1( 0. 0) 84 .6 2( 0. 0) 96 .5 (0 .0 ) 95 .7 8( 0. 0) 67 .9 (2 4. 09 ) 98 .1 1( 0. 09 ) 0. 0( 0. 0) 56 .2 6( 30 .2 ) 98 .8 2( 0. 16 ) 46 .1 5( 11 .4 3) 95 .7 8( 0. 0) 91 .1 5( 8. 04 ) 98 .4 7( 0. 05 ) 97 .8 6( 0. 0) 98 .3 (0 .0 8) 98 .3 (0 .1 ) 98 .7 8( 0. 09 ) 97 .9 9( 0. 02 ) sk in 81 .3 9( 0. 38 ) 20 .2 (0 .5 8) 22 .0 (0 .3 6) 59 .0 2( 1. 62 ) 58 .3 (0 .2 9) 78 .0 6( 0. 72 ) 96 .3 5( 0. 62 ) 55 .7 7( 10 .1 4) 70 .8 (2 .0 9) 76 .7 6( 0. 35 ) 80 .0 2( 0. 42 ) 37 .9 1( 0. 84 ) 55 .7 1( 28 .6 7) 43 .2 6( 2. 59 ) 78 .4 4( 1. 35 ) 52 .0 5( 1. 57 ) 1. 09 (0 .9 7) 78 .5 9( 11 .2 3) 44 .7 3( 0. 84 ) 31 .3 (2 .7 9) 74 .5 5( 2. 88 ) 72 .6 7( 0. 95 ) 73 .4 2( 5. 35 ) 95 .0 8( 1. 16 ) 93 .3 6( 2. 92 ) 82 .2 3( 0. 43 ) sm tp 69 .5 (4 .4 3) 0. 0( 0. 0) 69 .5 (4 .4 3) 0. 0( 0. 0) 0. 0( 0. 0) 0. 0( 0. 0) 69 .5 (4 .4 3) 8. 76 (5 .0 5) 65 .8 2( 5. 88 ) 0. 0( 0. 0) 69 .5 (4 .4 3) 69 .5 (4 .4 3) 26 .3 2( 34 .3 ) 34 .0 (2 3. 28 ) 13 .7 5( 30 .7 5) 48 .5 6( 12 .4 3) 6. 96 (1 2. 38 ) 0. 0( 0. 0) 69 .5 9( 4. 42 ) 0. 0( 0. 0) 69 .5 9( 4. 42 ) 68 .0 5( 5. 72 ) 56 .1 9( 11 .7 7) 69 .5 9( 4. 42 ) 37 .9 1( 24 .5 3) 69 .5 (4 .4 3) sp am ba se 78 .7 8( 0. 49 ) 71 .5 9( 0. 0) 69 .5 1( 0. 0) 71 .5 2( 1. 85 ) 74 .9 3( 0. 0) 80 .4 9( 1. 34 ) 80 .5 2( 0. 0) 71 .0 3( 5. 1) 73 .9 7( 0. 0) 77 .7 (2 .0 9) 78 .5 6( 0. 0) 78 .5 (0 .0 ) 68 .4 5( 3. 55 ) 69 .5 5( 3. 79 ) 73 .9 4( 3. 09 ) 78 .8 1( 0. 63 ) 79 .2 7( 0. 49 ) 77 .6 2( 3. 62 ) 78 .4 9( 0. 03 ) 79 .3 3( 1. 09 ) 81 .5 (0 .1 3) 50 .9 8( 0. 0) 63 .5 5( 0. 95 ) 80 .6 7( 0. 48 ) 75 .1 8( 2. 65 ) 80 .0 2( 0. 23 ) sp ee ch 1. 64 (0 .0 ) 3. 28 (0 .0 ) 3. 28 (0 .0 ) 2. 95 (0 .7 3) 4. 92 (0 .0 ) 3. 93 (2 .4 9) 3. 28 (0 .0 ) 2. 3( 1. 87 ) 3. 28 (0 .0 ) 2. 62 (1 .4 7) 3. 28 (0 .0 ) 3. 28 (0 .0 ) 3. 28 (1 .1 6) 1. 31 (1 .3 7) 2. 95 (2 .1 4) 2. 95 (1 .3 7) 2. 62 (1 .8 7) 1. 64 (1 .1 6) 3. 28 (0 .0 ) 1. 97 (1 .3 7) 6. 23 (2 .6 9) 4. 59 (1 .8 ) 2. 95 (1 .3 7) 4. 92 (0 .0 ) 1. 97 (1 .8 ) 3. 93 (1 .4 7) st am ps 64 .3 9( 11 .8 6) 67 .2 3( 4. 51 ) 49 .4 8( 5. 09 ) 64 .7 (1 2. 55 ) 57 .5 5( 6. 45 ) 63 .6 2( 8. 81 ) 75 .4 7( 9. 45 ) 60 .1 6( 12 .6 4) 63 .5 2( 13 .2 ) 30 .9 7( 8. 32 ) 63 .4 4( 9. 99 ) 57 .8 6( 9. 09 ) 47 .0 2( 25 .2 1) 37 .0 7( 9. 74 ) 28 .0 3( 26 .4 2) 52 .7 2( 15 .8 ) 77 .1 7( 7. 83 ) 51 .8 2( 17 .6 9) 61 .4 4( 6. 81 ) 32 .2 7( 14 .5 ) 50 .9 9( 12 .7 7) 43 .7 2( 9. 88 ) 62 .9 8( 12 .0 9) 85 .9 3( 2. 97 ) 70 .2 3( 11 .3 5) 57 .9 7( 11 .6 ) th yr oi d 74 .1 9( 1. 08 ) 30 .1 1( 0. 0) 59 .1 4( 0. 0) 40 .2 2( 11 .5 7) 77 .4 2( 0. 0) 80 .4 3( 3. 08 ) 75 .2 7( 0. 0) 70 .7 5( 5. 18 ) 52 .6 9( 0. 0) 73 .1 2( 0. 0) 75 .2 7( 0. 0) 74 .1 9( 0. 0) 65 .3 8( 11 .8 6) 65 .5 9( 8. 6) 69 .0 3( 3. 68 ) 74 .1 9( 1. 32 ) 56 .1 3( 8. 72 ) 69 .8 9( 3. 72 ) 74 .1 9( 0. 0) 52 .9 (2 0. 51 ) 71 .1 8( 1. 18 ) 51 .6 1( 0. 0) 75 .4 8( 2. 07 ) 74 .8 4( 0. 96 ) 47 .7 4( 10 .6 6) 75 .4 8( 0. 9) ve rt eb ra l 25 .7 3( 3. 79 ) 0. 28 (0 .6 3) 12 .6 1( 2. 46 ) 33 .3 3( 8. 67 ) 9. 53 (5 .4 6) 15 .8 4( 2. 0) 23 .8 2( 5. 02 ) 8. 42 (4 .4 6) 33 .6 8( 6. 21 ) 17 .3 2( 5. 22 ) 20 .3 7( 3. 6) 13 .9 3( 1. 31 ) 21 .1 9( 13 .5 ) 16 .7 1( 5. 9) 16 .9 9( 21 .4 1) 18 .2 5( 10 .6 4) 63 .3 9( 5. 17 ) 21 .5 3( 8. 46 ) 14 .0 7( 1. 08 ) 19 .7 6( 4. 38 ) 14 .2 (1 0. 67 ) 36 .3 7( 4. 21 ) 37 .5 4( 12 .5 2) 21 .5 6( 14 .7 8) 46 .5 8( 10 .2 4) 42 .1 3( 11 .4 9) vo w el s 19 .6 (2 .6 1) 6. 0( 0. 0) 22 .0 (0 .0 ) 35 .2 (4 .1 5) 8. 0( 0. 0) 15 .2 (3 .6 3) 26 .0 (0 .0 ) 10 .4 (3 .2 9) 34 .0 (0 .0 ) 0. 0( 0. 0) 28 .0 (0 .0 ) 12 .0 (0 .0 ) 5. 6( 6. 69 ) 20 .8 (4 .1 5) 13 .6 (1 2. 2) 23 .6 (2 .1 9) 24 .4 (8 .2 9) 14 .4 (5 .1 8) 12 .0 (0 .0 ) 22 .8 (1 5. 4) 38 .8 (4 .3 8) 50 .0 (0 .0 ) 41 .6 (5 .3 7) 29 .6 (0 .8 9) 36 .0 (2 .4 5) 37 .2 (4 .1 5) w av ef or m 26 .4 (1 .5 2) 9. 0( 0. 0) 7. 0( 0. 0) 29 .6 (2 .1 9) 8. 0( 0. 0) 10 .2 (2 .1 7) 27 .0 (0 .0 ) 7. 4( 2. 79 ) 28 .0 (0 .0 ) 9. 0( 0. 0) 13 .0 (0 .0 ) 9. 0( 0. 0) 4. 6( 1. 67 ) 14 .6 (3 .5 8) 26 .6 (6 .1 1) 9. 8( 2. 39 ) 26 .8 (5 .8 1) 28 .6 (4 .3 9) 8. 0( 0. 0) 12 .0 (7 .2 1) 2. 2( 1. 1) 5. 0( 0. 0) 12 .0 (1 .2 2) 26 .0 (0 .0 ) 24 .8 (4 .2 7) 12 .2 (2 .7 7) w bc 80 .6 8( 9. 87 ) 82 .4 (5 .6 5) 82 .4 (5 .6 5) 6. 29 (1 4. 06 ) 80 .4 1( 7. 38 ) 88 .2 5( 2. 41 ) 86 .4 1( 3. 23 ) 68 .8 (1 6. 05 ) 20 .2 7( 9. 64 ) 79 .1 3( 14 .0 6) 89 .8 4( 2. 99 ) 87 .2 8( 5. 1) 46 .1 6( 26 .6 1) 54 .1 7( 11 .2 8) 26 .6 1( 27 .5 7) 86 .4 5( 4. 97 ) 92 .8 8( 4. 57 ) 55 .6 8( 15 .8 3) 88 .4 2( 3. 21 ) 64 .1 1( 13 .6 1) 92 .2 (4 .4 8) 71 .7 7( 11 .9 ) 86 .0 3( 5. 16 ) 89 .3 5( 3. 45 ) 62 .6 4( 10 .3 1) 32 .4 9( 10 .2 8) w db c 69 .6 5( 7. 72 ) 79 .5 5( 3. 91 ) 51 .1 3( 9. 94 ) 87 .1 1( 5. 67 ) 67 .9 5( 6. 63 ) 70 .9 1( 11 .0 5) 78 .7 (2 .3 2) 52 .6 5( 20 .7 9) 85 .6 3( 6. 59 ) 58 .7 3( 7. 26 ) 80 .3 4( 2. 47 ) 78 .7 8( 1. 28 ) 32 .5 (2 9. 05 ) 83 .3 4( 7. 3) 8. 7( 19 .4 4) 75 .8 2( 5. 69 ) 90 .5 2( 9. 27 ) 75 .0 8( 11 .7 3) 78 .6 9( 6. 98 ) 57 .8 9( 10 .7 2) 85 .2 3( 6. 41 ) 3. 3( 5. 65 ) 79 .2 8( 7. 36 ) 85 .0 5( 6. 83 ) 89 .4 7( 7. 99 ) 68 .0 8( 14 .3 ) w ilt 1. 09 (0 .4 3) 1. 56 (0 .0 ) 4. 28 (0 .0 ) 19 .1 4( 13 .2 8) 0. 0( 0. 0) 2. 02 (0 .3 3) 2. 33 (0 .0 ) 0. 86 (0 .5 8) 16 .7 3( 0. 0) 7. 78 (0 .0 ) 1. 17 (0 .0 ) 1. 56 (0 .0 ) 5. 68 (3 .3 3) 0. 62 (0 .3 5) 1. 48 (1 .3 9) 12 .4 5( 2. 0) 35 .1 8( 2. 59 ) 3. 27 (4 .5 9) 1. 95 (0 .0 ) 6. 15 (5 .1 1) 7. 0( 0. 0) 10 .5 1( 0. 0) 20 .2 3( 0. 91 ) 2. 41 (1 .4 9) 64 .7 5( 4. 54 ) 17 .5 9( 2. 54 ) w in e 75 .7 3( 7. 02 ) 56 .1 3( 3. 76 ) 39 .2 7( 8. 98 ) 82 .7 (5 .2 6) 77 .6 7( 8. 64 ) 71 .0 5( 4. 25 ) 87 .1 6( 5. 61 ) 55 .3 3( 13 .2 8) 80 .8 4( 3. 22 ) 74 .6 7( 15 .1 3) 78 .2 8( 3. 76 ) 66 .0 1( 5. 57 ) 48 .5 4( 37 .4 9) 69 .8 1( 9. 29 ) 12 .7 8( 16 .9 5) 65 .5 2( 5. 99 ) 99 .3 2( 1. 52 ) 68 .3 1( 14 .3 9) 67 .9 (6 .3 1) 42 .7 2( 36 .2 2) 10 0. 0( 0. 0) 48 .5 8( 10 .3 4) 90 .3 1( 3. 17 ) 92 .1 3( 11 .8 5) 99 .3 2( 1. 52 ) 98 .2 9( 2. 42 ) w pb c 44 .4 5( 2. 96 ) 33 .5 2( 3. 96 ) 36 .2 1( 1. 91 ) 38 .8 6( 5. 39 ) 44 .5 9( 3. 59 ) 36 .6 3( 1. 93 ) 49 .0 9( 2. 1) 37 .2 8( 3. 79 ) 41 .2 6( 4. 76 ) 41 .2 8( 3. 93 ) 35 .7 9( 1. 33 ) 33 .6 2( 3. 01 ) 33 .1 8( 3. 98 ) 70 .2 2( 6. 11 ) 31 .9 (5 .2 2) 34 .2 2( 3. 42 ) 90 .5 5( 0. 97 ) 42 .8 4( 4. 39 ) 36 .4 8( 3. 41 ) 45 .6 1( 5. 66 ) 87 .9 1( 3. 64 ) 67 .9 9( 4. 49 ) 50 .7 1( 4. 98 ) 68 .1 6( 14 .0 2) 59 .5 1( 9. 36 ) 57 .7 6( 6. 44 ) ye as t 51 .3 6( 0. 11 ) 42 .6 (0 .0 ) 46 .3 5( 0. 0) 47 .5 (1 .5 1) 44 .3 8( 0. 0) 44 .4 6( 0. 86 ) 46 .7 5( 0. 0) 48 .0 5( 3. 25 ) 47 .7 3( 0. 0) 46 .2 7( 0. 18 ) 46 .5 5( 0. 0) 43 .3 9( 0. 0) 51 .9 9( 3. 47 ) 49 .4 7( 5. 66 ) 48 .8 (3 .7 7) 53 .2 1( 2. 43 ) 50 .2 6( 1. 38 ) 47 .7 7( 2. 46 ) 44 .2 6( 0. 18 ) 49 .5 1( 4. 78 ) 49 .2 7( 0. 22 ) 43 .7 9( 0. 0) 50 .8 5( 2. 02 ) 46 .1 5( 0. 44 ) 49 .6 6( 2. 28 ) 49 .2 3( 1. 12 ) ye lp 13 .4 (0 .2 ) 16 .0 (0 .0 ) 13 .4 (0 .0 ) 20 .7 2( 0. 23 ) 16 .2 (0 .0 ) 15 .8 (0 .6 2) 18 .8 (0 .0 ) 13 .8 (2 .1 7) 20 .6 (0 .0 ) 12 .5 2( 0. 3) 15 .2 (0 .0 ) 16 .2 (0 .0 ) 8. 2( 2. 18 ) 10 .4 (1 .7 7) 6. 88 (6 .4 1) 15 .3 6( 0. 38 ) 8. 88 (0 .7 3) 11 .1 2( 1. 38 ) 16 .2 (0 .0 ) 13 .3 6( 1. 31 ) 7. 12 (0 .1 1) 8. 16 (0 .3 3) 16 .0 8( 0. 18 ) 19 .6 (0 .0 ) 14 .6 (2 .1 7) 14 .7 2( 1. 51 ) M N IS TC 42 .9 4( 0. 16 ) 0. 0( 0. 0) 0. 0( 0. 0) 53 .2 1( 0. 6) 23 .2 4( 0. 0) 34 .7 (2 .5 9) 46 .3 (0 .0 ) 34 .4 8( 5. 52 ) 52 .9 6( 0. 0) 25 .6 9( 4. 92 ) 42 .3 2( 0. 0) 41 .1 1( 0. 0) 25 .1 7( 8. 13 ) 34 .4 5( 3. 0) 30 .5 4( 9. 37 ) 42 .1 1( 0. 45 ) 52 .0 7( 1. 25 ) 34 .6 7( 1. 69 ) 41 .1 1( 0. 01 ) 44 .5 (1 .7 6) 47 .6 6( 0. 22 ) 12 .0 (1 .5 9) 42 .4 4( 0. 25 ) 47 .5 1( 0. 0) 46 .2 1( 5. 11 ) 48 .6 8( 1. 5) Fa sh io nM N IS T 57 .1 4( 0. 32 ) 0. 0( 0. 0) 0. 0( 0. 0) 63 .7 8( 0. 56 ) 33 .6 5( 0. 0) 45 .3 3( 2. 4) 59 .0 5( 0. 0) 48 .9 (3 .8 9) 63 .3 (0 .0 ) 37 .3 5( 5. 77 ) 56 .4 4( 0. 0) 55 .6 2( 0. 0) 33 .4 3( 6. 11 ) 47 .9 6( 2. 33 ) 32 .2 1( 12 .8 3) 56 .2 5( 0. 6) 62 .9 (1 .0 7) 48 .0 5( 1. 55 ) 55 .6 2( 0. 0) 59 .4 5( 1. 3) 59 .7 7( 0. 26 ) 18 .3 7( 2. 0) 56 .6 7( 0. 27 ) 59 .6 8( 0. 0) 54 .6 6( 2. 68 ) 59 .2 2( 0. 99 ) C IF A R 10 23 .4 8( 0. 53 ) 9. 7( 0. 0) 10 .1 9( 0. 0) 27 .2 2( 0. 71 ) 14 .9 (0 .0 ) 18 .1 9( 1. 18 ) 22 .8 5( 0. 0) 20 .4 2( 3. 07 ) 27 .0 7( 0. 0) 17 .9 1( 2. 06 ) 22 .8 1( 0. 0) 22 .6 2( 0. 0) 13 .3 5( 2. 59 ) 16 .4 6( 1. 96 ) 14 .9 7( 2. 42 ) 22 .8 8( 0. 89 ) 20 .5 9( 1. 37 ) 17 .6 (1 .3 1) 22 .6 2( 0. 0) 24 .2 7( 1. 43 ) 24 .6 7( 0. 48 ) 10 .3 3( 1. 42 ) 22 .9 8( 0. 41 ) 23 .1 9( 0. 0) 19 .9 7( 2. 49 ) 23 .7 9( 1. 09 ) SV H N 18 .6 5( 0. 37 ) 0. 0( 0. 0) 0. 0( 0. 0) 19 .6 6( 0. 45 ) 13 .1 (0 .0 ) 16 .4 5( 1. 06 ) 18 .9 5( 0. 0) 15 .3 (2 .3 4) 19 .2 3( 0. 0) 14 .3 4( 1. 94 ) 18 .4 3( 0. 0) 18 .2 7( 0. 0) 12 .9 9( 2. 1) 15 .2 (1 .6 6) 13 .1 8( 1. 68 ) 18 .4 9( 0. 42 ) 19 .5 5( 0. 99 ) 17 .5 3( 0. 97 ) 18 .2 7( 0. 0) 19 .1 9( 0. 89 ) 19 .1 8( 0. 24 ) 11 .3 7( 0. 78 ) 18 .7 3( 0. 23 ) 19 .2 1( 0. 0) 17 .5 9( 1. 78 ) 19 .4 9( 0. 61 ) M V Te cA D 66 .4 8( 3. 06 ) 62 .9 2( 4. 9) 62 .9 2( 4. 9) 67 .4 8( 3. 26 ) 62 .6 5( 2. 52 ) 64 .6 (2 .6 5) 67 .3 7( 3. 1) 60 .3 8( 3. 87 ) 67 .2 9( 3. 16 ) 72 .3 5( 3. 2) 64 .6 (2 .6 7) 63 .4 1( 2. 78 ) 51 .8 8( 5. 78 ) 76 .7 8( 3. 79 ) 51 .1 5( 10 .0 3) 63 .8 3( 3. 2) 82 .6 3( 2. 26 ) 60 .3 8( 3. 19 ) 63 .1 1( 2. 64 ) 67 .2 8( 2. 76 ) 81 .7 7( 2. 71 ) 66 .3 4( 4. 21 ) 65 .0 2( 2. 84 ) 75 .6 9( 2. 88 ) 75 .8 7( 4. 33 ) 78 .9 8( 3. 08 ) 20 ne w s 12 .8 3( 2. 11 ) 10 .8 9( 0. 77 ) 10 .7 6( 1. 05 ) 16 .6 4( 1. 39 ) 9. 38 (0 .7 8) 10 .4 9( 1. 66 ) 14 .6 1( 1. 48 ) 9. 95 (1 .9 7) 16 .7 7( 1. 37 ) 14 .7 2( 1. 95 ) 11 .3 1( 1. 1) 10 .5 (1 .2 4) 9. 61 (2 .5 2) 13 .6 4( 3. 63 ) 12 .5 5( 3. 73 ) 10 .7 (1 .0 3) 16 .4 3( 1. 74 ) 9. 08 (3 .3 3) 10 .7 9( 1. 83 ) 14 .5 4( 2. 93 ) 14 .0 9( 1. 43 ) 10 .1 2( 2. 67 ) 10 .5 5( 1. 27 ) 17 .8 3( 1. 58 ) 14 .3 3( 4. 65 ) 18 .9 5( 4. 69 ) ag ne w s 15 .3 5( 0. 25 ) 11 .5 5( 0. 0) 11 .4 5( 0. 0) 30 .5 3( 0. 37 ) 11 .4 5( 0. 0) 12 .4 8( 0. 65 ) 20 .1 (0 .0 ) 13 .5 2( 1. 55 ) 30 .6 (0 .0 ) 13 .0 8( 0. 32 ) 13 .7 (0 .0 ) 12 .2 5( 0. 0) 10 .7 7( 3. 43 ) 10 .6 6( 3. 57 ) 3. 72 (4 .1 6) 13 .1 5( 0. 69 ) 17 .7 9( 0. 72 ) 9. 78 (1 .2 ) 12 .2 5( 0. 0) 14 .4 4( 0. 8) 13 .3 3( 0. 14 ) 10 .7 1( 1. 01 ) 12 .5 2( 0. 18 ) 20 .7 (0 .0 ) 14 .1 1( 3. 85 ) 23 .9 3( 3. 44 )\nTa bl\ne 15\n:A ve\nra ge\nA U\nC PR\nan d\nst an\nda rd\nde vi\nat io\nns ov\ner fiv\ne se\ned s\nfo rt\nhe se\nm i-\nsu pe\nrv is\ned se\ntti ng\non A\nD B\nen ch\n.\nC B\nL O\nF C\nO PO\nD E\nC O\nD Fe\nat ur\neB ag\ngi ng\nH B\nO S\nIF or\nes t\nkN N\nL O\nD A\nL O\nF M\nC D\nO C\nSV M\nPC A\nD A\nG M\nM D\nee pS\nV D\nD D\nR O\nC C\nG O\nA D\nIC L\nPl an\nar Fl\now VA\nE G\nA N\nom al\ny SL\nA D\nD IF\nD D\nPM D\nT E\n-N P\nD T\nE -I\nG D\nT E\n-C\nal oi\n6. 4(\n0. 02\n) 5.\n72 (0\n.0 )\n6. 06\n(0 .0\n) 6.\n8( 0.\n19 )\n6. 42\n(0 .0\n) 5.\n82 (0\n.1 )\n6. 02\n(0 .0\n) 5.\n93 (0\n.5 )\n6. 54\n(0 .0\n) 5.\n55 (0\n.0 7)\n6. 52\n(0 .0\n) 6.\n54 (0\n.0 )\n6. 07\n(0 .5\n5) 6.\n23 (0\n.3 5)\n5. 91\n(0 .0\n) 5.\n7( 0.\n24 )\n5. 5(\n0. 13\n) 5.\n48 (0\n.3 )\n6. 54\n(0 .0\n) 8.\n09 (1\n.2 7)\n5. 99\n(0 .0\n4) 5.\n8( 0.\n0) 5.\n97 (0\n.0 6)\n6. 05\n(0 .0\n6) 5.\n98 (0\n.1 4)\n5. 76\n(0 .0 4) am az on 11 .4 6( 0. 08 ) 11 .1 5( 0. 0) 10 .4 (0 .0 ) 11 .0 6( 0. 02 ) 11 .1 (0 .0 ) 11 .0 7( 0. 19 ) 11 .6 9( 0. 0) 10 .1 8( 0. 78 ) 11 .0 4( 0. 0) 11 .7 (0 .0 3) 11 .0 6( 0. 0) 10 .7 2( 0. 0) 9. 53 (0 .4 6) 10 .2 4( 1. 27 ) 9. 52 (0 .0 ) 10 .9 4( 0. 21 ) 10 .1 9( 0. 08 ) 9. 56 (0 .5 9) 10 .7 2( 0. 0) 9. 93 (0 .1 9) 9. 74 (0 .0 2) 9. 89 (0 .4 1) 10 .7 6( 0. 02 ) 11 .7 3( 0. 0) 10 .1 6( 1. 08 ) 11 .1 5( 0.\n65 )\nan nt\nhy ro\nid 63\n.6 2(\n4. 4)\n29 .6\n1( 0.\n0) 40\n.0 2(\n0. 0)\n48 .4\n9( 8.\n07 )\n39 .0\n3( 0.\n0) 59\n.0 2(\n5. 39\n) 68\n.0 7(\n0. 0)\n49 .0\n1( 6.\n73 )\n53 .5\n3( 0.\n0) 59\n.7 (0\n.0 5)\n60 .1\n1( 0.\n0) 56\n.5 7(\n0. 0)\n48 .0\n3( 17\n.5 6)\n27 .8\n3( 5.\n93 )\n63 .7\n2( 3.\n08 )\n58 .7\n4( 5.\n0) 45\n.8 3(\n2. 16\n) 65\n.1 5(\n8. 63\n) 56\n.7 4(\n0. 0)\n34 .3\n(1 0.\n62 )\n70 .5\n8( 0.\n92 )\n61 .1\n2( 0.\n0) 62\n.8 8(\n2. 59\n) 68\n.1 5(\n0. 38\n) 49\n.8 7(\n9. 05\n) 82\n.8 8(\n0. 59 ) ba ck do or 9. 07 (1 .3 7) 4. 84 (0 .1 ) 4. 84 (0 .1 ) 49 .5 2( 8. 43 ) 8. 56 (0 .2 6) 9. 37 (1 .4 8) 46 .5 4( 1. 41 ) 5. 96 (3 .8 4) 53 .4 7( 2. 6) 22 .1 6( 13 .7 3) 7. 66 (0 .0 6) 7. 9( 0. 13 ) 7. 5( 3. 45 ) 84 .7 7( 2. 79 ) 84 .5 9( 1. 93 ) 6. 31 (1 .9 4) 89 .1 8( 1. 04 ) 32 .1 5( 23 .7 8) 7. 97 (0 .2 4) 27 .8 7( 6. 63 ) 4. 83 (0 .1 ) 17 .8 1( 1. 03 ) 14 .2 (0 .6 3) 45 .7 (1 2. 5) 81 .9 9( 4. 24 ) 62 .4 4( 2. 39 ) br ea st w 99 .0 6( 0. 24 ) 99 .4 4( 0. 12 ) 99 .1 6( 0. 2) 52 .3 9( 10 .9 ) 99 .0 8( 0. 27 ) 99 .4 9( 0. 12 ) 98 .9 2( 0. 32 ) 96 .7 6( 0. 62 ) 80 .0 1( 10 .0 9) 98 .2 7( 1. 23 ) 99 .3 5( 0. 21 ) 99 .1 9( 0. 15 ) 90 .9 5( 8. 37 ) 96 .0 1( 1. 28 ) 63 .1 9( 22 .3 5) 98 .7 7( 0. 37 ) 96 .7 9( 1. 61 ) 97 .4 7( 1. 08 ) 99 .1 7( 0. 17 ) 93 .7 8( 2. 46 ) 99 .4 7( 0. 21 ) 52 .0 5( 5. 33 ) 98 .6 (0 .5 1) 99 .1 9( 0. 14 ) 81 .4 1( 7. 86 ) 88 .2 5( 1. 06 ) ca m pa ig n 48 .5 6( 0. 59 ) 51 .0 5( 0. 0) 49 .5 1( 0. 0) 33 .3 1( 6. 99 ) 49 .6 9( 0. 0) 45 .7 3( 1. 85 ) 49 .0 4( 0. 0) 29 .7 5( 5. 8) 40 .2 4( 0. 0) 47 .9 1( 1. 49 ) 49 .4 3( 0. 0) 48 .8 4( 0. 0) 32 .3 5( 4. 69 ) 36 .9 5( 12 .7 ) 20 .2 5( 0. 0) 23 .0 9( 7. 18 ) 48 .9 (0 .9 8) 42 .7 7( 2. 92 ) 48 .8 4( 0. 0) 39 .1 7( 4. 25 ) 48 .1 1( 0. 12 ) 24 .9 9( 0. 0) 48 .8 7( 0. 29 ) 49 .9 5( 0. 67 ) 46 .1 7( 2. 19 ) 46 .9 (0 .7 1) ca rd io 80 .9 4( 2. 89 ) 74 .8 8( 0. 0) 78 .5 5( 0. 0) 71 .5 5( 3. 14 ) 58 .8 7( 0. 0) 78 .6 3( 2. 69 ) 77 .2 2( 0. 0) 72 .4 7( 5. 87 ) 70 .1 5( 0. 0) 67 .0 7( 0. 62 ) 83 .5 9( 0. 0) 86 .1 7( 0. 06 ) 55 .8 6( 7. 98 ) 38 .8 9( 5. 52 ) 51 .1 5( 24 .5 5) 84 .7 9( 0. 57 ) 47 .9 1( 11 .4 7) 68 .9 2( 1. 77 ) 86 .2 5( 0. 0) 67 .7 1( 4. 44 ) 69 .9 4( 0. 98 ) 29 .2 6( 0. 0) 69 .2 8( 0. 91 ) 77 .4 1( 0. 85 ) 41 .0 7( 13 .1 8) 69 .2 9( 1. 27 ) ca rd io to co gr ap hy 61 .7 1( 1. 92 ) 56 .0 7( 0. 0) 68 .9 8( 0. 0) 57 .0 4( 2. 15 ) 50 .7 (0 .0 ) 62 .8 5( 3. 42 ) 57 .4 3( 0. 0) 60 .5 6( 7. 01 ) 57 .3 2( 0. 0) 52 .8 3( 0. 7) 66 .1 9( 0. 0) 69 .6 8( 0. 0) 59 .7 (7 .6 3) 45 .7 8( 5. 1) 43 .9 1( 12 .5 5) 67 .5 2( 0. 82 ) 48 .6 6( 3. 84 ) 59 .2 7( 4. 03 ) 69 .6 9( 0. 0) 54 .9 4( 3. 83 ) 49 .3 7( 0. 19 ) 33 .5 1( 0. 0) 51 .3 1( 1. 98 ) 58 .6 8( 1. 14 ) 39 .5 9( 5. 95 ) 53 .3 4( 1. 26 ) ce le ba 18 .5 (4 .4 3) 16 .4 8( 0. 82 ) 16 .9 (0 .7 9) 3. 87 (0 .2 6) 16 .7 7( 0. 78 ) 11 .7 (1 .3 5) 11 .9 2( 0. 5) 9. 46 (6 .7 5) 3. 61 (0 .1 5) 19 .0 2( 3. 4) 20 .2 7( 0. 9) 20 .9 5( 1. 06 ) 9. 04 (2 .7 3) 7. 09 (4 .3 2) 7. 65 (0 .1 6) 4. 01 (1 .2 1) 9. 74 (0 .6 8) 12 .8 5( 4. 44 ) 20 .9 5( 1. 11 ) 7. 47 (5 .6 1) 9. 29 (0 .9 2) 7. 99 (1 .0 6) 18 .0 3( 2. 6) 10 .6 5( 0. 49 ) 13 .4 (2 .3 7) 14 .1 9( 2. 31 ) ce ns us 20 .3 4( 0. 62 ) 11 .7 3( 0. 29 ) 11 .7 3( 0. 29 ) 12 .0 2( 0. 38 ) 14 .0 1( 0. 32 ) 14 .1 9( 0. 73 ) 21 .6 8( 0. 63 ) 13 .4 2( 3. 92 ) 13 .7 1( 0. 42 ) 28 .9 8( 1. 47 ) 20 .3 2( 0. 66 ) 20 .0 3( 0. 59 ) 13 .1 7( 0. 9) 15 .3 5( 1. 07 ) 14 .2 5( 1. 1) 8. 69 (0 .9 9) 21 .2 (0 .6 1) 14 .6 8( 1. 56 ) 19 .8 2( 0. 55 ) 17 .4 9( 2. 11 ) 14 .9 6( 4. 41 ) 14 .6 6( 1. 25 ) 19 .6 7( 0. 6) 21 .0 5( 0. 67 ) 16 .3 (1 .7 7) 17 .9 4( 1. 09 ) co ve r 15 .9 6( 0. 8) 12 .2 6( 0. 85 ) 19 .2 2( 1. 54 ) 78 .1 (1 3. 95 ) 5. 42 (0 .6 1) 8. 66 (1 .5 3) 55 .7 9( 3. 74 ) 22 .5 6( 9. 16 ) 82 .9 2( 2. 19 ) 3. 14 (0 .1 8) 22 .2 8( 1. 01 ) 16 .1 7( 0. 86 ) 9. 84 (9 .9 8) 2. 69 (1 .5 3) 31 .3 3( 5. 85 ) 1. 09 (0 .1 8) 34 .4 8( 16 .3 9) 1. 98 (0 .6 ) 16 .0 5( 0. 88 ) 25 .0 3( 38 .2 4) 6. 96 (5 .1 8) 2. 23 (0 .3 2) 73 .2 7( 3. 36 ) 59 .9 7( 10 .5 7) 80 .4 3( 4. 6) 63 .7 3( 12\n.3 3)\ndo no\nrs 46\n.4 6(\n1. 12\n) 33\n.5 (0\n.8 )\n41 .2\n7( 0.\n97 )\n65 .2\n5( 10\n.2 5)\n36 .3\n3( 1.\n85 )\n40 .5\n1( 3.\n59 )\n89 .0\n9( 0.\n94 )\n25 .3\n9( 21\n.3 3)\n63 .3\n9( 1.\n89 )\n31 .2\n4( 13\n.6 2)\n42 .7\n1( 0.\n86 )\n35 .2\n2( 1.\n21 )\n19 .5\n4( 11\n.0 2)\n42 .7\n5( 27\n.4 8)\n30 .2\n(1 7.\n77 )\n9. 0(\n1. 93\n) 98\n.3 5(\n0. 87\n) 49\n.3 1(\n14 .8\n2) 36\n.0 1(\n0. 72\n) 23\n.9 (1\n1. 25\n) 46\n.1 8(\n9. 8)\n37 .2\n6( 4.\n14 )\n26 .6\n6( 2.\n91 )\n85 .5\n5( 4.\n56 )\n95 .7\n7( 2.\n6) 71\n.3 3(\n3. 89 ) fa ul t 61 .2 9( 1. 82 ) 53 .1 9( 0. 0) 51 .7 1( 0. 0) 50 .8 4( 0. 82 ) 53 .8 9( 0. 0) 59 .1 9( 2. 02 ) 61 .9 8( 0. 0) 54 .4 9( 2. 63 ) 50 .4 4( 0. 0) 63 .3 7( 5. 99 ) 61 .1 2( 0. 0) 60 .3 5( 0. 0) 56 .7 5( 6. 65 ) 55 .4 6( 1. 48 ) 57 .8 1( 4. 16 ) 62 .1 4( 0. 82 ) 63 .1 8( 0. 7) 60 .3 5( 2. 93 ) 60 .3 5( 0. 0) 62 .4 7( 4. 52 ) 66 .6 9( 0. 19 ) 60 .8 (0 .0 ) 64 .7 5( 0. 69 ) 62 .1 7( 0. 14 ) 63 .8 3( 1. 23 ) 63 .9 3( 0. 72 ) fr au d 27 .7 7( 2. 14 ) 38 .4 3( 3. 99 ) 33 .2 (4 .6 8) 63 .1 1( 6. 38 ) 32 .2 5( 5. 42 ) 18 .2 2( 3. 66 ) 38 .6 8( 7. 19 ) 36 .5 9( 15 .1 7) 55 .0 9( 8. 19 ) 60 .0 6( 3. 89 ) 29 .6 4( 5. 04 ) 26 .9 3( 1. 91 ) 15 .5 7( 20 .1 1) 48 .3 3( 17 .1 3) 0. 33 (0 .0 3) 29 .4 4( 24 .6 6) 53 .8 8( 8. 78 ) 62 .8 1( 9. 37 ) 28 .7 (4 .5 4) 60 .2 4( 11 .1 5) 44 .9 7( 5. 43 ) 2. 08 (0 .8 2) 69 .2 1( 3. 46 ) 42 .1 (7 .6 3) 51 .1 4( 8. 64 ) 62 .1 4( 10\n.9 2)\ngl as\ns 31\n.7 (2\n.7 4)\n20 .0\n9( 4.\n04 )\n25 .0\n2( 6.\n94 )\n36 .0\n9( 8.\n99 )\n27 .6\n1( 6.\n5) 21\n.3 7(\n3. 58\n) 42\n.3 2(\n8. 47\n) 15\n.5 5(\n2. 58\n) 38\n.1 2(\n9. 91\n) 20\n.2 9(\n3. 22\n) 26\n.7 6(\n7. 68\n) 20\n.9 6(\n5. 76\n) 18\n.6 2(\n12 .4\n3) 52\n.3 5(\n21 .0\n4) 23\n.1 4(\n13 .9\n8) 18\n.3 3(\n7. 23\n) 92\n.3 5(\n8. 32\n) 30\n.9 3(\n6. 56\n) 18\n.5 1(\n3. 73\n) 26\n.0 4(\n10 .3\n) 41\n.1 5(\n3. 98\n) 67\n.0 2(\n13 .2\n) 31\n.2 1(\n11 .3\n) 37\n.3 8(\n15 .5\n1) 80\n.5 7(\n12 .8\n3) 41\n.5 1(\n5. 91 ) he pa tit is 63 .3 6( 6. 81 ) 56 .0 8( 3. 5) 45 .8 4( 3. 47 ) 44 .6 (9 .5 5) 63 .4 9( 5. 99 ) 55 .3 6( 6. 09 ) 90 .3 1( 4. 36 ) 50 .1 5( 7. 4) 43 .6 7( 10 .7 9) 56 .8 (8 .0 ) 77 .6 3( 3. 49 ) 64 .8 5( 5. 06 ) 54 .3 7( 8. 05 ) 98 .7 3( 1. 05 ) 34 .9 1( 13 .1 5) 65 .7 7( 5. 43 ) 99 .8 3( 0. 38 ) 89 .6 3( 3. 08 ) 64 .4 8( 5. 1) 73 .2 5( 17 .1 5) 99 .7 9( 0. 47 ) 89 .1 6( 5. 91 ) 95 .1 4( 1. 34 ) 82 .3 2( 10 .2 6) 99 .8 (0 .4 5) 95 .8 2( 3. 85 ) ht tp 90 .3 1( 1. 45 ) 46 .3 1( 2. 11 ) 25 .1 8( 0. 82 ) 8. 21 (1 .1 5) 38 .9 5( 12 .1 6) 53 .4 3( 12 .0 8) 10 0. 0( 0. 0) 7. 46 (9 .7 9) 97 .1 2( 3. 92 ) 92 .1 6( 1. 88 ) 99 .8 8( 0. 26 ) 91 .6 9( 1. 53 ) 57 .5 3( 32 .6 1) 36 .0 9( 31 .8 5) 0. 73 (0 .0 6) 68 .3 8( 8. 01 ) 70 .8 2( 42 .0 6) 52 .2 3( 4. 21 ) 90 .4 2( 1. 67 ) 19 .2 9( 40 .3 3) 88 .0 9( 7. 46 ) 50 .5 4( 3. 34 ) 99 .9 6( 0. 06 ) 97 .1 (4 .0 4) 78 .8 (4 2. 53 ) 55 .4 5( 5. 61 ) im db 8. 95 (0 .0 ) 9. 3( 0. 0) 8. 48 (0 .0 ) 9. 03 (0 .0 2) 9. 01 (0 .0 ) 8. 97 (0 .1 7) 8. 92 (0 .0 ) 8. 73 (0 .3 9) 9. 03 (0 .0 ) 9. 45 (0 .0 4) 8. 85 (0 .0 ) 8. 71 (0 .0 ) 9. 22 (0 .3 ) 9. 68 (1 .4 7) 9. 89 (0 .5 2) 8. 8( 0. 11 ) 10 .2 4( 0. 13 ) 9. 5( 0. 67 ) 8. 71 (0 .0 ) 9. 41 (0 .1 6) 9. 79 (0 .0 3) 10 .3 (0 .4 6) 8. 7( 0. 02 ) 8. 97 (0 .0 ) 10 .0 6( 1. 49 ) 8. 9( 0. 52 ) in te rn et ad s 47 .0 4( 0. 08 ) 61 .7 4( 0. 0) 61 .8 7( 0. 0) 49 .2 6( 1. 85 ) 30 .7 9( 0. 0) 29 .2 (1 .7 4) 49 .2 2( 0. 0) 39 .3 2( 2. 28 ) 50 .4 3( 0. 0) 34 .3 6( 0. 0) 48 .1 5( 0. 0) 46 .9 7( 0. 0) 31 .7 8( 3. 63 ) 51 .5 6( 4. 75 ) 43 .0 8( 5. 72 ) 47 .4 3( 0. 86 ) 60 .0 3( 1. 39 ) 47 .5 7( 1. 08 ) 46 .9 7( 0. 0) 52 .8 9( 1. 61 ) 60 .5 2( 1. 05 ) 30 .5 6( 0. 37 ) 47 .7 (0 .1 6) 51 .3 (2 .0 2) 58 .6 8( 6. 22 ) 55 .2 2( 3. 65 ) io no sp he re 97 .2 6( 1. 05 ) 78 .4 9( 3. 06 ) 75 .6 4( 1. 71 ) 94 .9 4( 1. 4) 64 .6 3( 3. 76 ) 91 .7 (1 .8 9) 97 .9 5( 0. 69 ) 85 .1 5( 3. 63 ) 94 .5 8( 1. 57 ) 96 .6 6( 0. 39 ) 97 .4 5( 0. 53 ) 90 .9 4( 1. 25 ) 77 .5 (4 .9 4) 98 .0 9( 0. 81 ) 71 .7 2( 21 .8 8) 93 .1 7( 2. 64 ) 99 .0 6( 0. 32 ) 97 .6 4( 0. 86 ) 91 .4 2( 1. 37 ) 95 .3 8( 1. 33 ) 98 .5 5( 0. 51 ) 94 .4 4( 1. 96 ) 96 .4 3( 0. 5) 98 .2 2( 1. 02 ) 96 .9 1( 2. 1) 96 .8 3( 0. 38 ) la nd sa t 36 .8 9( 0. 24 ) 33 .8 2( 0. 0) 31 .0 9( 0. 0) 61 .4 9( 0. 23 ) 60 .1 2( 0. 0) 47 .3 1( 3. 5) 54 .8 5( 0. 0) 35 .7 (5 .7 7) 61 .3 7( 0. 0) 39 .6 8( 4. 51 ) 37 .0 1( 0. 0) 32 .7 2( 0. 0) 40 .2 8( 2. 2) 49 .4 3( 2. 4) 37 .5 5( 1. 93 ) 31 .2 1( 0. 8) 53 .1 2( 1. 57 ) 34 .1 9( 0. 94 ) 40 .2 9( 7. 81 ) 37 .1 4( 8. 33 ) 45 .1 (0 .1 7) 37 .3 7( 0. 0) 34 .8 3( 0. 91 ) 54 .5 2( 4. 05 ) 32 .6 5( 2. 84 ) 36 .7 5( 1. 23 ) le tte r 8. 33 (0 .0 8) 8. 85 (0 .0 ) 10 .6 5( 0. 0) 11 .6 6( 0. 51 ) 8. 73 (0 .0 ) 8. 22 (0 .2 5) 8. 7( 0. 0) 8. 03 (0 .2 5) 11 .2 6( 0. 0) 8. 1( 0. 41 ) 8. 26 (0 .0 ) 8. 01 (0 .0 ) 10 .3 7( 1. 67 ) 8. 93 (0 .5 2) 15 .7 4( 6. 69 ) 8. 13 (0 .0 5) 12 .8 (1 .1 7) 9. 19 (0 .8 1) 8. 0( 0. 0) 8. 45 (0 .0 9) 8. 93 (0 .0 5) 24 .7 (0 .0 ) 9. 53 (0 .5 1) 8. 57 (0 .1 3) 10 .2 3( 1. 12 ) 8. 95 (0 .1 3) ly m ph og ra ph y 98 .2 6( 0. 34 ) 93 .9 (2 .8 5) 94 .3 8( 1. 43 ) 72 .7 3( 15 .5 ) 96 .5 5( 2. 11 ) 94 .3 8( 3. 28 ) 99 .1 7( 0. 94 ) 24 .1 3( 13 .2 9) 84 .1 6( 4. 27 ) 86 .7 6( 6. 31 ) 10 0. 0( 0. 0) 98 .4 9( 0. 55 ) 73 .4 7( 15 .8 8) 96 .8 2( 3. 69 ) 30 .8 7( 35 .6 3) 98 .7 6( 0. 88 ) 10 0. 0( 0. 0) 96 .2 4( 4. 22 ) 98 .5 9( 1. 01 ) 90 .5 3( 7. 4) 99 .9 4( 0. 12 ) 98 .1 (2 .6 4) 99 .3 (1 .0 2) 99 .3 4( 0. 93 ) 99 .7 6( 0. 55 ) 86 .7 7( 9. 24 ) m ag ic .g am m a 80 .2 4( 0. 0) 72 .2 2( 0. 0) 67 .9 2( 0. 0) 86 .8 9( 0. 56 ) 77 .1 5( 0. 0) 80 .2 7( 1. 07 ) 85 .8 6( 0. 0) 75 .7 8( 1. 08 ) 86 .3 6( 0. 0) 77 .2 1( 0. 09 ) 79 .1 6( 0. 0) 75 .2 (0 .0 ) 64 .5 (4 .6 2) 69 .5 4( 0. 73 ) 83 .1 9( 0. 66 ) 76 .1 3( 2. 42 ) 81 .3 3( 0. 57 ) 78 .5 1( 2. 91 ) 75 .2 7( 0. 0) 65 .8 3( 2. 36 ) 77 .3 4( 0. 01 ) 65 .7 6( 0. 0) 87 .9 7( 0. 84 ) 86 .1 5( 0. 74 ) 88 .7 3( 0. 78 ) 89 .6 8( 0. 5) m am m og ra ph y 41 .0 8( 0. 13 ) 54 .6 3( 0. 0) 55 .2 (0 .0 ) 29 .3 4( 1. 55 ) 21 .3 2( 0. 0) 37 .9 4( 3. 21 ) 41 .2 7( 0. 0) 43 .2 1( 2. 04 ) 34 .0 7( 0. 0) 7. 96 (0 .2 ) 40 .5 2( 0. 0) 41 .6 5( 0. 0) 22 .0 (1 7. 15 ) 27 .5 4( 11 .4 ) 27 .2 4( 2. 23 ) 27 .8 2( 3. 84 ) 17 .1 1( 3. 75 ) 18 .5 2( 9. 52 ) 41 .7 6( 0. 02 ) 37 .0 8( 23 .8 9) 18 .9 8( 1. 05 ) 11 .1 7( 0. 01 ) 19 .9 3( 3. 92 ) 42 .0 9( 0. 86 ) 33 .3 6( 9. 9) 39 .8 (4 .2 6) m ni st 66 .4 9( 0. 36 ) 16 .8 6( 0. 0) 16 .8 6( 0. 0) 69 .2 9( 1. 07 ) 22 .2 1( 0. 0) 54 .1 5( 6. 53 ) 72 .7 2( 0. 0) 34 .0 7( 7. 67 ) 70 .9 7( 0. 0) 55 .7 5( 6. 4) 66 .2 (0 .0 ) 64 .9 9( 0. 0) 46 .0 6( 7. 88 ) 46 .0 (9 .5 5) 59 .7 2( 1. 98 ) 65 .0 9( 0. 57 ) 68 .4 5( 1. 63 ) 55 .2 2( 3. 33 ) 64 .9 9( 0. 0) 47 .9 7( 4. 73 ) 68 .3 9( 0. 46 ) 20 .1 9( 0. 0) 62 .4 2( 4. 39 ) 73 .6 8( 1. 31 ) 56 .1 (8 .0 7) 56 .2 6( 3. 26 ) m us k 10 0. 0( 0. 0) 96 .1 3( 0. 0) 98 .2 (0 .0 ) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 40 .3 9( 26 .1 ) 10 0. 0( 0. 0) 90 .8 (1 0. 84 ) 10 0. 0( 0. 0) 66 .3 2( 12 .0 8) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 70 .6 1( 23 .9 4) 99 .9 1( 0. 17 ) 15 .6 5( 19 .6 1) 10 0. 0( 0. 0) 92 .2 1( 6. 32 ) 32 .6 8( 33 .4 8) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 72 .2 1( 0. 0) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 88 .8 7( 24 .8 8) 10 0. 0( 0. 0) op td ig its 13 .9 7( 1. 21 ) 5. 59 (0 .0 ) 5. 59 (0 .0 ) 41 .2 3( 2. 99 ) 42 .3 8( 0. 0) 15 .4 1( 3. 21 ) 29 .1 1( 0. 0) 3. 93 (0 .4 5) 43 .6 3( 0. 0) 7. 1( 0. 17 ) 6. 92 (0 .0 ) 6. 02 (0 .0 ) 4. 95 (2 .3 9) 4. 53 (1 .0 4) 19 .1 5( 3. 94 ) 7. 76 (1 .1 5) 50 .9 4( 8. 59 ) 3. 93 (0 .4 7) 6. 01 (0 .0 ) 11 .5 7( 3. 94 ) 36 .3 (0 .9 4) 5. 14 (0 .0 ) 25 .5 6( 4. 25 ) 31 .7 5( 4. 86 ) 22 .0 6( 15 .0 9) 15 .3 4( 2. 17 ) pa ge bl oc ks 70 .6 (0 .1 1) 41 .5 1( 0. 0) 58 .5 4( 0. 0) 70 .1 6( 1. 16 ) 22 .4 8( 0. 0) 43 .4 2( 2. 0) 67 .6 (0 .0 ) 48 .5 7( 3. 88 ) 71 .0 7( 0. 0) 63 .1 7( 0. 04 ) 64 .2 5( 0. 0) 59 .3 5( 0. 0) 60 .2 6( 12 .8 4) 52 .0 5( 3. 89 ) 73 .4 6( 2. 81 ) 63 .5 (1 .1 7) 68 .1 1( 2. 3) 58 .2 6( 5. 01 ) 59 .3 9( 0. 0) 46 .0 8( 16 .7 7) 64 .7 (0 .7 9) 59 .1 (0 .0 ) 62 .1 (0 .9 5) 67 .4 5( 0. 1) 57 .4 6( 2. 99 ) 66 .4 2( 1. 23 ) pe nd ig its 51 .2 4( 0. 47 ) 30 .8 6( 0. 0) 41 .4 5( 0. 0) 85 .6 7( 2. 53 ) 42 .3 3( 0. 0) 58 .7 9( 5. 21 ) 96 .9 9( 0. 0) 37 .2 3( 7. 94 ) 78 .5 5( 0. 0) 13 .2 (0 .0 7) 51 .7 8( 0. 0) 38 .6 3( 0. 0) 11 .7 1( 9. 8) 9. 34 (7 .7 8) 14 .5 7( 3. 43 ) 33 .3 5( 2. 85 ) 66 .4 1( 7. 58 ) 14 .4 7( 4. 88 ) 39 .1 4( 0. 0) 14 .6 5( 15 .3 9) 35 .3 5( 0. 15 ) 22 .3 6( 0. 0) 61 .1 4( 4. 73 ) 91 .8 9( 3. 3) 59 .2 (1 0. 53 ) 48 .4 4( 5. 92 ) pi m a 72 .0 8( 2. 78 ) 69 .0 7( 2. 47 ) 64 .7 7( 2. 3) 69 .5 4( 3. 79 ) 75 .8 8( 2. 36 ) 73 .6 5( 2. 07 ) 75 .3 7( 2. 99 ) 59 .3 6( 7. 6) 68 .4 (3 .7 9) 68 .6 4( 3. 1) 71 .9 8( 3. 41 ) 71 .1 8( 3. 39 ) 56 .4 8( 5. 33 ) 59 .7 5( 1. 75 ) 53 .4 2( 13 .5 3) 65 .1 5( 8. 8) 78 .6 3( 1. 94 ) 71 .2 3( 2. 96 ) 71 .4 9( 3. 69 ) 61 .6 6( 4. 66 ) 63 .0 3( 4. 45 ) 56 .7 8( 3. 69 ) 71 .1 8( 2. 06 ) 79 .7 (2 .4 4) 69 .6 4( 4. 28 ) 67 .9 8( 2. 86 ) sa te lli te 77 .2 8( 0. 33 ) 73 .3 3( 0. 0) 69 .5 7( 0. 0) 85 .8 2( 0. 05 ) 86 .4 9( 0. 0) 82 .3 5( 0. 88 ) 86 .0 1( 0. 0) 79 .7 7( 0. 93 ) 85 .8 6( 0. 0) 79 .9 3( 2. 95 ) 80 .9 (0 .0 ) 77 .7 9( 0. 0) 75 .9 8( 3. 34 ) 81 .1 (1 .9 7) 77 .4 6( 6. 34 ) 78 .9 6( 0. 46 ) 87 .6 2( 0. 24 ) 77 .8 6( 2. 47 ) 81 .0 4( 0. 11 ) 81 .8 3( 0. 75 ) 88 .6 4( 0. 07 ) 63 .2 5( 0. 0) 85 .0 9( 0. 18 ) 85 .8 3( 0. 72 ) 81 .7 1( 1. 91 ) 84 .7 9( 0. 35 ) sa tim ag e2 96 .7 6( 0. 01 ) 85 .2 7( 0. 0) 79 .6 6( 0. 0) 90 .6 5( 0. 96 ) 87 .6 8( 0. 0) 94 .5 3( 0. 55 ) 96 .6 9( 0. 0) 93 .7 2( 0. 69 ) 88 .4 6( 0. 0) 98 .3 1( 0. 0) 96 .9 2( 0. 0) 91 .9 2( 0. 0) 47 .4 8( 30 .1 4) 76 .2 8( 8. 21 ) 79 .3 2( 13 .4 8) 95 .8 9( 0. 1) 94 .7 (1 .1 9) 62 .4 7( 5. 18 ) 92 .9 4( 0. 28 ) 80 .2 5( 15 .9 5) 95 .4 4( 0. 23 ) 8. 0( 0. 0) 88 .0 5( 5. 1) 96 .1 6( 0. 0) 83 .3 (4 .5 2) 68 .2 1( 3. 15 ) sh ut tle 96 .7 7( 0. 12 ) 98 .0 5( 0. 0) 95 .2 (0 .0 ) 46 .3 5( 25 .9 7) 97 .4 9( 0. 0) 98 .6 1( 0. 34 ) 97 .8 6( 0. 0) 55 .7 4( 40 .6 6) 99 .7 5( 0. 0) 90 .9 (0 .0 ) 97 .6 7( 0. 0) 96 .2 7( 0. 0) 65 .9 8( 23 .6 8) 98 .0 3( 0. 13 ) 13 .3 5( 0. 0) 60 .1 6( 26 .9 2) 99 .7 2( 0. 14 ) 51 .6 6( 12 .9 3) 96 .2 7( 0. 0) 93 .9 3( 4. 7) 98 .0 4( 0. 01 ) 94 .8 7( 0. 01 ) 97 .9 1( 0. 26 ) 98 .1 4( 0. 48 ) 99 .3 5( 0. 09 ) 94 .0 3( 0. 11 ) sk in 69 .4 7( 0. 5) 29 .6 9( 0. 18 ) 30 .4 9( 0. 2) 49 .2 1( 1. 1) 53 .3 7( 0. 59 ) 64 .5 8( 1. 09 ) 98 .2 4( 0. 41 ) 53 .0 4( 7. 11 ) 61 .6 8( 1. 85 ) 62 .3 9( 0. 42 ) 66 .3 1( 0. 51 ) 36 .3 9( 0. 33 ) 50 .3 7( 21 .7 9) 42 .9 9( 3. 28 ) 65 .6 2( 1. 8) 42 .1 8( 1. 84 ) 32 .4 6( 1. 0) 74 .7 4( 17 .4 ) 40 .1 4( 0. 33 ) 31 .8 8( 2. 2) 78 .7 3( 7. 88 ) 63 .0 1( 1. 72 ) 76 .3 7( 5. 79 ) 94 .7 8( 2. 33 ) 96 .8 5( 2. 54 ) 69 .0 8( 0. 5) sm tp 49 .7 (6 .0 4) 0. 99 (0 .0 5) 68 .0 1( 5. 66 ) 0. 38 (0 .2 5) 1. 15 (0 .1 ) 1. 1( 0. 12 ) 50 .5 3( 5. 92 ) 8. 16 (5 .4 7) 48 .0 9( 7. 38 ) 1. 18 (0 .0 8) 64 .5 1( 11 .8 8) 49 .5 (6 .1 ) 20 .9 2( 26 .9 3) 30 .7 3( 22 .8 2) 8. 69 (1 9. 27 ) 32 .4 (8 .4 8) 3. 81 (3 .8 3) 0. 77 (0 .4 ) 49 .3 8( 6. 44 ) 0. 1( 0. 02 ) 50 .0 (6 .3 ) 49 .4 (6 .6 4) 40 .8 1( 13 .3 6) 50 .2 (6 .3 9) 33 .6 (2 3. 33 ) 50 .3 7( 6. 15 ) sp am ba se 82 .0 3( 0. 41 ) 73 .5 8( 0. 0) 71 .2 6( 0. 0) 68 .4 (2 .5 8) 78 .4 2( 0. 0) 88 .2 6( 1. 32 ) 83 .3 2( 0. 0) 80 .1 6( 4. 45 ) 72 .7 1( 0. 0) 81 .7 8( 2. 94 ) 82 .1 9( 0. 0) 81 .8 4( 0. 0) 74 .2 2( 2. 55 ) 75 .2 6( 2. 44 ) 79 .0 7( 3. 1) 82 .0 9( 0. 21 ) 86 .7 8( 0. 59 ) 85 .3 6( 2. 63 ) 81 .8 4( 0. 0) 83 .6 3( 1. 4) 85 .6 4( 0. 14 ) 50 .5 (0 .0 ) 72 .8 9( 0. 42 ) 83 .6 5( 0. 58 ) 80 .9 9( 2. 36 ) 83 .8 (0 .5 2) sp ee ch 2. 7( 0. 02 ) 2. 79 (0 .0 ) 2. 87 (0 .0 ) 2. 98 (0 .1 ) 3. 21 (0 .0 ) 3. 25 (1 .0 ) 2. 8( 0. 0) 2. 97 (0 .9 6) 3. 15 (0 .0 ) 2. 83 (0 .0 7) 2. 78 (0 .0 ) 2. 77 (0 .0 ) 3. 95 (0 .7 5) 3. 38 (0 .3 8) 3. 57 (0 .7 3) 2. 81 (0 .3 1) 3. 38 (0 .5 ) 3. 26 (0 .5 7) 2. 77 (0 .0 ) 2. 76 (0 .2 1) 3. 1( 0. 06 ) 3. 9( 0. 35 ) 3. 0( 0. 29 ) 3. 17 (0 .0 ) 2. 88 (0 .4 8) 2. 85 (0 .1 2) st am ps 62 .1 9( 8. 71 ) 56 .4 3( 3. 1) 49 .0 (3 .8 6) 65 .5 9( 8. 71 ) 52 .2 8( 4. 56 ) 58 .8 4( 6. 84 ) 71 .6 8( 8. 35 ) 57 .1 7( 11 .2 1) 64 .8 4( 8. 17 ) 41 .7 (6 .1 6) 64 .9 1( 7. 95 ) 58 .8 1( 7. 82 ) 46 .5 4( 22 .1 1) 42 .6 2( 9. 94 ) 28 .4 8( 21 .9 4) 49 .5 7( 17 .7 2) 79 .5 4( 5. 44 ) 52 .4 1( 12 .5 6) 59 .9 2( 7. 99 ) 33 .4 7( 10 .3 6) 50 .6 1( 13 .2 6) 49 .1 3( 8. 19 ) 64 .7 4( 12 .8 7) 82 .4 7( 4. 08 ) 72 .8 (1 0. 03 ) 57 .6 5( 8. 4) th yr oi d 81 .5 1( 0. 16 ) 30 .1 9( 0. 0) 64 .0 3( 0. 0) 36 .4 9( 17 .3 3) 76 .9 5( 0. 0) 79 .6 6( 5. 62 ) 80 .9 4( 0. 0) 64 .2 6( 6. 24 ) 60 .5 7( 0. 0) 80 .0 8( 0. 13 ) 78 .9 2( 0. 0) 81 .3 4( 0. 0) 63 .0 8( 15 .7 7) 69 .0 6( 8. 1) 74 .3 5( 3. 86 ) 80 .0 9( 0. 89 ) 51 .5 1( 12 .7 5) 75 .7 9( 6. 78 ) 81 .3 3( 0. 0) 53 .6 1( 24 .5 1) 74 .0 7( 0. 84 ) 60 .9 1( 0. 0) 82 .2 2( 0. 87 ) 81 .0 3( 0. 31 ) 45 .6 7( 16 .2 8) 81 .6 7( 0. 97 ) ve rt eb ra l 25 .2 4( 3. 76 ) 15 .4 8( 1. 84 ) 19 .9 3( 0. 83 ) 32 .8 9( 4. 98 ) 18 .8 6( 2. 45 ) 20 .7 5( 1. 98 ) 26 .1 1( 2. 49 ) 16 .7 2( 1. 76 ) 33 .8 7( 4. 3) 20 .9 6( 2. 2) 22 .2 3( 2. 01 ) 19 .2 6( 1. 41 ) 25 .0 6( 8. 54 ) 23 .4 2( 3. 17 ) 23 .3 5( 10 .4 ) 21 .3 9( 4. 98 ) 58 .7 5( 7. 3) 22 .9 7( 3. 46 ) 17 .8 5( 1. 85 ) 23 .3 6( 3. 83 ) 19 .8 7( 4. 37 ) 28 .6 4( 2. 59 ) 35 .8 4( 9. 27 ) 25 .2 1( 8. 9) 51 .5 (1 0. 55 ) 35 .1 4( 5. 39 ) vo w el s 23 .8 5( 4. 53 ) 7. 06 (0 .0 ) 17 .7 2( 0. 0) 32 .7 3( 5. 31 ) 7. 88 (0 .0 ) 11 .9 7( 1. 05 ) 30 .2 1( 0. 0) 10 .4 3( 2. 54 ) 33 .0 9( 0. 0) 4. 36 (0 .0 1) 27 .4 3( 0. 0) 10 .5 1( 0. 0) 7. 32 (3 .2 1) 16 .8 8( 1. 93 ) 13 .1 9( 9. 94 ) 20 .9 4( 2. 43 ) 27 .3 9( 5. 75 ) 9. 67 (2 .5 2) 10 .1 (0 .0 1) 21 .6 3( 14 .9 7) 39 .2 3( 1. 65 ) 43 .2 6( 0. 0) 42 .7 2( 4. 8) 31 .5 9( 1. 59 ) 33 .6 3( 6. 25 ) 38 .1 (4 .8 9) w av ef or m 22 .4 9( 1. 47 ) 9. 88 (0 .0 ) 7. 35 (0 .0 ) 28 .7 3( 3. 91 ) 9. 0( 0. 0) 10 .5 3( 0. 76 ) 27 .0 (0 .0 ) 7. 8( 1. 04 ) 30 .6 6( 0. 0) 7. 83 (0 .0 2) 10 .9 1( 0. 0) 8. 41 (0 .0 ) 6. 07 (0 .8 9) 11 .5 2( 3. 39 ) 20 .0 7( 6. 96 ) 8. 86 (0 .6 4) 18 .6 3( 4. 08 ) 25 .0 8( 5. 76 ) 8. 4( 0. 0) 13 .3 3( 5. 54 ) 5. 31 (0 .0 1) 5. 7( 0. 0) 9. 31 (1 .0 5) 27 .8 7( 0. 0) 19 .6 1( 4. 09 ) 9. 99 (1 .1 3) w bc 86 .8 3( 6. 29 ) 93 .1 6( 2. 9) 93 .1 1( 2. 88 ) 12 .6 8( 7. 89 ) 87 .7 3( 5. 11 ) 94 .2 4( 3. 95 ) 92 .0 1( 3. 96 ) 75 .7 4( 17 .2 ) 24 .8 9( 3. 49 ) 90 .1 6( 7. 96 ) 97 .1 5( 0. 77 ) 94 .3 (1 .8 7) 56 .8 (2 9. 54 ) 56 .5 1( 11 .1 2) 23 .9 5( 26 .8 6) 91 .9 5( 3. 26 ) 95 .1 2( 5. 14 ) 70 .9 9( 10 .4 9) 93 .2 2( 2. 73 ) 73 .8 7( 14 .2 4) 98 .1 4( 1. 35 ) 79 .2 4( 11 .8 8) 93 .8 4( 2. 45 ) 96 .1 (2 .1 7) 72 .3 7( 12 .6 1) 29 .9 7( 3. 1) w db c 75 .6 7( 6. 52 ) 83 .7 8( 3. 4) 61 .0 4( 3. 15 ) 93 .6 7( 2. 48 ) 77 .8 4( 2. 61 ) 71 .9 8( 8. 57 ) 82 .0 3( 3. 28 ) 54 .8 4( 16 .7 5) 93 .6 4( 3. 06 ) 55 .2 6( 4. 5) 87 .4 4( 5. 59 ) 82 .0 5( 4. 51 ) 30 .9 2( 26 .0 2) 84 .3 2( 8. 89 ) 12 .2 3( 18 .0 4) 78 .7 7( 4. 26 ) 95 .6 (6 .1 2) 77 .4 6( 13 .2 8) 83 .6 2( 6. 58 ) 58 .9 8( 15 .4 6) 89 .0 8( 6. 97 ) 9. 88 (2 .9 ) 84 .3 (4 .4 4) 90 .4 7( 7. 91 ) 92 .0 7( 6. 84 ) 68 .8 2( 12\n.4 2)\nw ilt\n8. 09\n(0 .1\n6) 6.\n87 (0\n.0 )\n7. 68\n(0 .0\n) 19\n.2 1(\n7. 52\n) 7.\n87 (0\n.0 )\n8. 81\n(0 .5\n1) 12\n.2 5(\n0. 0)\n7. 96\n(0 .9\n2) 15\n.7 4(\n0. 0)\n21 .4\n9( 0.\n01 )\n7. 12\n(0 .0\n) 6.\n41 (0\n.0 )\n8. 43\n(1 .1\n2) 7.\n08 (0\n.1 7)\n9. 61\n(2 .4\n) 10\n.8 6(\n1. 37\n) 28\n.9 4(\n3. 31\n) 17\n.0 7(\n2. 4)\n7. 25\n(0 .0\n) 8.\n85 (1\n.2 6)\n12 .1\n7( 0.\n04 )\n11 .0\n8( 0.\n0) 17\n.2 4(\n0. 46\n) 12\n.2 (1\n.6 )\n52 .1\n(7 .6\n9) 25\n.4 1(\n1. 36 ) w in e 86 .7 7( 2. 55 ) 52 .3 4( 5. 29 ) 32 .5 6( 4. 25 ) 88 .6 8( 3. 76 ) 77 .7 1( 9. 93 ) 67 .1 2( 7. 62 ) 95 .1 1( 1. 81 ) 57 .8 5( 15 .7 6) 89 .9 5( 2. 64 ) 83 .1 3( 9. 43 ) 88 .6 8( 2. 29 ) 69 .2 2( 6. 18 ) 50 .9 2( 36 .7 4) 78 .5 6( 9. 59 ) 18 .5 (1 4. 36 ) 70 .1 (6 .2 9) 98 .2 6( 3. 89 ) 78 .8 5( 9. 76 ) 69 .4 7( 6. 95 ) 47 .6 3( 29 .5 3) 10 0. 0( 0. 0) 53 .4 8( 10 .4 7) 97 .6 5( 0. 72 ) 96 .8 (5 .5 8) 99 .7 1( 0. 65 ) 99 .8 5( 0. 23 ) w pb c 44 .8 (1 .4 7) 38 .1 7( 2. 2) 35 .7 8( 1. 83 ) 40 .9 7( 2. 44 ) 42 .6 1( 2. 22 ) 40 .7 3( 3. 15 ) 46 .1 1( 2. 74 ) 38 .3 (3 .2 7) 41 .2 (2 .6 2) 45 .1 6( 1. 42 ) 40 .8 8( 3. 04 ) 40 .0 3( 2. 79 ) 37 .1 9( 3. 38 ) 74 .8 8( 5. 58 ) 35 .9 9( 4. 15 ) 38 .8 8( 3. 82 ) 89 .3 1( 5. 37 ) 45 .4 5( 2. 24 ) 40 .2 6( 2. 88 ) 46 .9 3( 5. 57 ) 87 .4 5( 6. 21 ) 70 .5 7( 6. 66 ) 54 .6 1( 3. 75 ) 69 .0 2( 13 .9 1) 65 .7 8( 8. 55 ) 60 .3 5( 4. 88 ) ye as t 50 .7 4( 0. 02 ) 46 .8 2( 0. 0) 49 .4 3( 0. 0) 49 .8 9( 0. 68 ) 49 .7 8( 0. 0) 46 .7 8( 0. 37 ) 48 .2 6( 0. 0) 48 .9 5( 3. 57 ) 48 .9 4( 0. 0) 45 .6 7( 0. 08 ) 47 .9 5( 0. 0) 46 .7 8( 0. 0) 51 .8 1( 3. 07 ) 49 .2 1( 3. 88 ) 49 .7 6( 4. 94 ) 50 .7 7( 2. 18 ) 49 .5 5( 1. 36 ) 47 .0 4( 1. 92 ) 46 .4 6( 0. 0) 49 .0 4( 4. 46 ) 50 .5 6( 0. 08 ) 43 .9 6( 0. 0) 51 .0 5( 1. 65 ) 48 .1 2( 0. 49 ) 51 .1 1( 1. 33 ) 49 .7 4( 0. 72 ) ye lp 13 .7 2( 0. 03 ) 13 .2 5( 0. 0) 11 .8 9( 0. 0) 16 .0 8( 0. 07 ) 13 .0 4( 0. 0) 13 .1 5( 0. 29 ) 16 .0 3( 0. 0) 11 .7 7( 1. 34 ) 16 .1 4( 0. 0) 13 .8 1( 0. 02 ) 13 .4 2( 0. 0) 12 .7 7( 0. 0) 9. 31 (0 .4 4) 10 .0 2( 1. 01 ) 10 .1 (0 .5 9) 13 .1 3( 0. 39 ) 10 .4 (0 .0 9) 10 .6 9( 0. 61 ) 12 .7 6( 0. 01 ) 11 .3 8( 0. 24 ) 9. 96 (0 .0 5) 9. 05 (0 .1 4) 12 .8 (0 .0 2) 16 .3 5( 0. 0) 12 .2 5( 1. 58 ) 13 .0 (1 .5 7) M N IS TC 42 .5 4( 0. 12 ) 9. 52 (0 .0 ) 9. 52 (0 .0 ) 52 .1 5( 0. 36 ) 21 .6 (0 .0 ) 32 .8 (2 .4 3) 46 .2 (0 .0 ) 32 .6 4( 5. 25 ) 51 .8 9( 0. 0) 25 .8 1( 4. 48 ) 41 .5 7( 0. 0) 40 .3 3( 0. 0) 23 .4 1( 9. 02 ) 31 .4 4( 3. 04 ) 26 .9 2( 8. 88 ) 41 .2 3( 0. 35 ) 51 .4 7( 1. 1) 34 .1 (1 .2 8) 40 .3 4( 0. 0) 43 .4 4( 1. 57 ) 46 .8 9( 0. 14 ) 11 .2 (0 .8 4) 41 .7 8( 0. 12 ) 47 .4 2( 0. 0) 44 .0 8( 4. 87 ) 47 .1 6( 1. 36 ) Fa sh io nM N IS T 57 .7 5( 0. 25 ) 9. 5( 0. 0) 9. 5( 0. 0) 63 .9 4( 0. 43 ) 34 .8 6( 0. 0) 44 .7 3( 1. 88 ) 59 .1 5( 0. 0) 46 .9 1( 3. 85 ) 63 .6 1( 0. 0) 37 .4 1( 6. 46 ) 56 .5 3( 0. 0) 56 .1 6( 0. 0) 29 .6 6( 7. 59 ) 45 .1 (2 .0 4) 29 .6 3( 12 .7 3) 56 .5 9( 0. 4) 63 .0 8( 0. 96 ) 46 .7 8( 1. 12 ) 56 .1 6( 0. 0) 59 .7 7( 1. 03 ) 59 .6 (0 .1 7) 16 .1 5( 1. 44 ) 57 .1 4( 0. 12 ) 59 .7 9( 0. 0) 53 .7 3( 2. 28 ) 55 .0 1( 1. 04 ) C IF A R 10 19 .7 3( 0. 18 ) 12 .1 (0 .0 ) 12 .6 3( 0. 0) 22 .2 (0 .3 4) 13 .9 7( 0. 0) 16 .4 6( 0. 64 ) 19 .6 2( 0. 0) 16 .8 8( 1. 96 ) 22 .1 7( 0. 0) 15 .9 2( 1. 04 ) 19 .4 2( 0. 0) 19 .2 3( 0. 0) 12 .0 4( 1. 54 ) 14 .0 3( 1. 08 ) 12 .3 6( 1. 69 ) 19 .4 (0 .4 ) 17 .3 9( 0. 59 ) 15 .9 1( 0. 52 ) 19 .2 3( 0. 0) 19 .9 9( 0. 79 ) 19 .9 8( 0. 07 ) 10 .4 4( 0. 55 ) 19 .5 5( 0. 08 ) 19 .9 1( 0. 0) 16 .6 9( 1. 63 ) 19 .6 8( 0. 86 ) SV H N 15 .0 6( 0. 1) 9. 52 (0 .0 ) 9. 52 (0 .0 ) 16 .0 8( 0. 12 ) 11 .9 6( 0. 0) 13 .8 5( 0. 49 ) 15 .3 4( 0. 0) 12 .7 1( 1. 55 ) 15 .9 7( 0. 0) 12 .8 2( 0. 93 ) 15 .0 (0 .0 ) 14 .8 6( 0. 0) 11 .4 3( 0. 99 ) 12 .4 (0 .9 5) 11 .1 7( 1. 04 ) 14 .9 3( 0. 18 ) 15 .6 (0 .3 1) 14 .2 4( 0. 4) 14 .8 6( 0. 0) 15 .2 7( 0. 36 ) 15 .4 (0 .0 6) 10 .7 5( 0. 28 ) 15 .0 8( 0. 04 ) 15 .5 3( 0. 0) 14 .2 1( 0. 95 ) 15 .4 7( 0. 47 ) M V Te cA D 74 .8 8( 2. 84 ) 37 .8 3( 1. 63 ) 37 .8 3( 1. 63 ) 75 .7 7( 3. 0) 67 .6 2( 2. 71 ) 70 .0 (3 .0 7) 75 .7 6( 2. 71 ) 65 .7 1( 3. 94 ) 75 .7 9( 2. 95 ) 80 .5 1( 2. 92 ) 73 .0 3( 2. 82 ) 72 .0 5( 2. 65 ) 58 .1 3( 6. 28 ) 83 .7 8( 3. 32 ) 59 .2 8( 10 .9 ) 72 .6 2( 2. 74 ) 89 .4 6( 2. 23 ) 67 .8 5( 3. 06 ) 71 .6 1( 2. 31 ) 75 .5 6( 2. 55 ) 87 .9 1( 2. 31 ) 69 .1 7( 3. 68 ) 73 .6 6( 2. 72 ) 82 .9 4( 2. 68 ) 82 .8 5( 3. 49 ) 85 .1 1( 2. 96 ) 20 ne w s 12 .6 3( 0. 64 ) 11 .0 9( 0. 32 ) 11 .2 7( 0. 12 ) 15 .0 2( 0. 68 ) 11 .1 4( 0. 27 ) 11 .5 6( 0. 43 ) 13 .4 7( 0. 52 ) 11 .2 3( 1. 35 ) 15 .0 4( 0. 67 ) 15 .4 5( 1. 06 ) 11 .8 3( 0. 52 ) 11 .3 4( 0. 4) 10 .1 7( 1. 17 ) 12 .9 (1 .9 ) 12 .0 1( 2. 09 ) 11 .4 9( 0. 51 ) 14 .6 2( 0. 88 ) 10 .5 7( 1. 52 ) 11 .4 9( 0. 65 ) 13 .7 8( 1. 19 ) 13 .5 9( 0. 34 ) 10 .4 4( 1. 03 ) 11 .4 8( 0. 44 ) 15 .6 1( 1. 35 ) 14 .0 7( 2. 82 ) 17 .3 3( 2. 36 ) ag ne w s 13 .7 8( 0. 01 ) 11 .0 7( 0. 0) 10 .9 3( 0. 0) 25 .9 (0 .1 3) 11 .1 6( 0. 0) 11 .9 4( 0. 32 ) 16 .6 8( 0. 0) 12 .0 8( 0. 99 ) 25 .8 6( 0. 0) 14 .6 2( 0. 14 ) 12 .8 2( 0. 0) 11 .6 2( 0. 0) 10 .1 7( 1. 33 ) 10 .2 2( 1. 85 ) 9. 74 (0 .3 4) 12 .4 2( 0. 31 ) 15 .4 2( 0. 38 ) 9. 72 (0 .3 7) 11 .6 2( 0. 0) 12 .6 8( 0. 53 ) 12 .3 (0 .0 6) 10 .1 7( 0. 32 ) 11 .8 5( 0. 03 ) 17 .3 5( 0. 0) 12 .8 1( 2. 31 ) 19 .2 2( 2. 97 )\nE.2 UNSUPERVISED SETTING\nTa bl\ne 16\n:A ve\nra ge\nA U\nC R\nO C\nan d\nst an\nda rd\nde vi\nat io\nns ov\ner fiv\ne se\ned s\nfo rt\nhe un\nsu pe\nrv is\ned se\ntti ng\non A\nD B\nen ch\n.\nC B\nL O\nF C\nO PO\nD E\nC O\nD Fe\nat ur\neB ag\ngi ng\nH B\nO S\nIF or\nes t\nkN N\nL O\nD A\nL O\nF M\nC D\nO C\nSV M\nPC A\nD A\nG M\nM D\nee pS\nV D\nD D\nR O\nC C\nG O\nA D\nIC L\nPl an\nar Fl\now VA\nE G\nA N\nom al\ny SL\nA D\nD IF\nD D\nPM D\nT E\n-N P\nD T\nE -I\nG D\nT E\n-C\nal oi\n55 .5\n8( 0.\n2) 51\n.5 3(\n0. 01\n) 53\n.0 6(\n0. 01\n) 79\n.1 5(\n0. 56\n) 53\n.1 1(\n0. 21\n) 54\n.2 2(\n0. 39\n) 61\n.3 2(\n0. 04\n) 49\n.5 2(\n1. 02\n) 76\n.6 6(\n0. 35\n) 52\n.0 4(\n0. 17\n) 54\n.8 6(\n0. 01\n) 54\n.9 (0\n.0 8)\n51 .6\n9( 2.\n13 )\n51 .4\n2( 2.\n92 )\n50 .0\n(0 .0\n) 49\n.6 9(\n0. 64\n) 54\n.8 4(\n0. 62\n) 52\n.0 1(\n1. 37\n) 54\n.8 5(\n0. 0)\n54 .7\n5( 1.\n09 )\n54 .2\n4( 0.\n68 )\n49 .7\n7( 1.\n14 )\n53 .2\n2( 0.\n25 )\n64 .5\n(0 .0\n9) 54\n.1 (0\n.9 9)\n52 .4\n8( 0.\n31 )\nam az\non 57\n.9 2(\n0. 24\n) 57\n.0 5(\n0. 06\n) 54\n.1 (0\n.0 5)\n57 .1\n8( 0.\n49 )\n56 .3\n(0 .0\n8) 55\n.7 6(\n0. 65\n) 60\n.2 7(\n0. 04\n) 52\n.6 3(\n3. 04\n) 57\n.0 9(\n0. 56\n) 59\n.7 3(\n0. 42\n) 56\n.4 7(\n0. 1)\n54 .9\n5( 0.\n1) 50\n.1 2(\n1. 97\n) 46\n.3 8(\n2. 16\n) 50\n.0 (0\n.0 )\n55 .9\n7( 2.\n07 )\n52 .8\n4( 0.\n7) 49\n.4 9(\n0. 97\n) 54\n.9 8(\n0. 0)\n55 .1\n2( 1.\n1) 51\n.8 (0\n.3 4)\n50 .9\n1( 1.\n39 )\n55 .1\n3( 0.\n09 )\n60 .3\n(0 .4\n) 53\n.4 5(\n1. 61\n) 55\n.6 4(\n2. 54 ) an nt hy ro id 67 .5 7( 0. 98 ) 77 .6 7( 0. 17 ) 78 .9 1( 0. 11 ) 78 .7 7( 2. 68 ) 60 .8 4( 2. 38 ) 81 .6 3( 1. 18 ) 76 .0 5( 0. 14 ) 45 .3 3( 12 .8 1) 70 .9 5( 1. 05 ) 91 .8 (0 .3 5) 68 .1 7( 0. 21 ) 67 .5 6( 0. 39 ) 54 .8 1( 7. 26 ) 73 .9 (1 .5 7) 63 .0 7( 2. 69 ) 45 .2 5( 10 .0 3) 59 .9 4( 3. 53 ) 96 .5 8( 1. 49 ) 67 .4 4( 0. 01 ) 61 .9 1( 1. 12 ) 57 .2 6( 6. 06 ) 49 .5 (0 .8 5) 81 .3 7( 1. 37 ) 78 .1 1( 0. 22 ) 92 .3 2( 2. 08 ) 96 .3 6( 0. 52 ) ba ck do or 89 .7 1( 0. 72 ) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 79 .0 3( 3. 04 ) 74 .0 4( 0. 77 ) 72 .4 6( 3. 35 ) 82 .6 4( 0. 5) 51 .5 (1 6. 4) 76 .4 2( 2. 72 ) 84 .7 8( 9. 77 ) 88 .8 6( 0. 77 ) 88 .7 5( 0. 73 ) 75 .2 4( 8. 88 ) 73 .4 9( 2. 66 ) 50 .0 (0 .0 ) 58 .6 8( 10 .7 4) 93 .6 2( 0. 75 ) 78 .6 6( 7. 09 ) 88 .7 9( 0. 76 ) 90 .7 5( 3. 52 ) 50 .0 (0 .0 ) 50 .2 1( 0. 9) 89 .1 8( 0. 62 ) 80 .5 6( 0. 48 ) 75 .3 4( 11 .8 2) 87 .5 2( 1. 0) br ea st w 96 .0 8( 0. 93 ) 99 .4 4( 0. 16 ) 99 .0 4( 0. 25 ) 40 .8 3( 2. 6) 98 .4 4( 0. 3) 98 .3 2( 0. 46 ) 98 .0 2( 0. 53 ) 96 .9 7( 3. 27 ) 44 .6 1( 3. 25 ) 98 .5 2( 0. 45 ) 93 .4 9( 2. 12 ) 94 .6 3( 1. 2) 81 .1 (6 .3 3) 62 .5 4( 12 .5 9) 84 .7 3( 6. 24 ) 84 .5 4( 9. 29 ) 80 .7 3( 3. 93 ) 96 .4 8( 1. 43 ) 92 .8 (4 .0 7) 94 .2 7( 3. 9) 81 .7 4( 1. 91 ) 51 .1 4( 2. 06 ) 76 .6 4( 4. 22 ) 97 .6 2( 0. 47 ) 90 .4 5( 2. 0) 89 .0 7( 2. 24 ) ca m pa ig n 73 .7 8( 0. 3) 78 .2 8( 0. 04 ) 76 .9 4( 0. 05 ) 59 .3 7( 4. 19 ) 76 .8 1( 0. 27 ) 70 .3 7( 1. 81 ) 74 .9 5( 0. 14 ) 49 .2 7( 8. 77 ) 61 .4 4( 0. 34 ) 77 .4 7( 0. 94 ) 73 .6 5( 0. 07 ) 73 .4 (0 .1 2) 58 .0 7( 2. 76 ) 50 .7 9( 8. 34 ) 50 .0 (0 .0 ) 44 .2 8( 5. 98 ) 76 .6 1( 0. 5) 56 .6 1( 2. 97 ) 73 .4 2( 0. 0) 65 .1 9( 5. 23 ) 70 .4 1( 0. 71 ) 49 .8 7( 0. 72 ) 72 .3 8( 0. 77 ) 74 .5 9( 0. 16 ) 65 .9 9( 6. 09 ) 78 .9 1( 0. 61 ) ca rd io 83 .1 6( 1. 77 ) 92 .0 8( 0. 3) 93 .4 9( 0. 12 ) 57 .8 9( 2. 77 ) 83 .9 4( 1. 23 ) 92 .2 1( 1. 22 ) 83 .0 2( 1. 85 ) 85 .5 9( 7. 1) 55 .1 2( 2. 42 ) 81 .4 8( 1. 65 ) 93 .4 2( 0. 35 ) 94 .9 (0 .1 8) 62 .4 7( 10 .8 9) 49 .7 8( 16 .0 6) 65 .5 4( 4. 78 ) 90 .7 7( 3. 72 ) 46 .0 7( 4. 06 ) 79 .5 9( 4. 61 ) 95 .0 (0 .0 4) 77 .0 1( 18 .8 ) 49 .5 (4 .1 3) 49 .5 2( 2. 41 ) 72 .3 3( 5. 93 ) 77 .6 7( 2. 16 ) 63 .1 1( 10 .5 2) 72 .1 3( 3. 16 ) ca rd io to co gr ap hy 56 .0 9( 2. 47 ) 66 .4 2( 3. 42 ) 78 .4 (0 .2 2) 53 .7 9( 1. 73 ) 59 .5 (1 .0 9) 68 .0 9( 2. 61 ) 50 .3 (0 .4 9) 70 .8 (1 3. 23 ) 52 .6 7( 2. 09 ) 49 .9 9( 0. 49 ) 69 .1 3( 0. 43 ) 74 .6 6( 0. 68 ) 54 .6 (6 .5 8) 48 .8 (5 .2 5) 44 .9 (4 .6 7) 62 .4 2( 12 .7 1) 37 .2 (2 .0 7) 64 .2 5( 6. 21 ) 75 .2 5( 0. 08 ) 66 .5 7( 10 .4 5) 38 .2 7( 3. 61 ) 50 .4 2( 0. 97 ) 57 .8 6( 4. 27 ) 49 .2 8( 0. 7) 50 .6 2( 6. 64 ) 51 .0 3( 2. 7) ce le ba 75 .3 4( 1. 76 ) 75 .7 (0 .6 2) 76 .3 1( 0. 65 ) 51 .3 9( 2. 7) 75 .4 1( 0. 65 ) 70 .7 2( 1. 27 ) 73 .5 8( 0. 38 ) 59 .9 7( 11 .9 1) 43 .2 1( 1. 22 ) 80 .2 5( 3. 67 ) 78 .1 1( 0. 7) 79 .2 3( 0. 61 ) 62 .6 6( 3. 98 ) 49 .1 2( 17 .5 3) 72 .5 7( 0. 97 ) 43 .2 (1 2. 41 ) 68 .3 5( 2. 27 ) 70 .3 2( 11 .8 6) 78 .9 7( 0. 39 ) 43 .6 7( 19 .1 6) 60 .4 9( 1. 66 ) 49 .9 3( 0. 99 ) 79 .5 8( 1. 88 ) 69 .8 7( 0. 51 ) 69 .9 6( 4. 42 ) 81 .2 2( 1. 54 ) ce ns us 66 .4 (0 .1 8) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 53 .7 5( 0. 31 ) 61 .0 9( 0. 34 ) 60 .7 3( 2. 15 ) 67 .0 8( 0. 26 ) 45 .4 4( 13 .1 1) 56 .2 (0 .6 1) 73 .1 2( 2. 05 ) 65 .4 6( 0. 18 ) 66 .1 5( 0. 16 ) 49 .0 7( 0. 64 ) 52 .7 (5 .1 2) 44 .3 1( 2. 74 ) 48 .8 (5 .0 6) 66 .7 6( 0. 69 ) 60 .3 6( 1. 36 ) 66 .0 7( 0. 13 ) 64 .9 9( 5. 58 ) 62 .5 (6 .9 9) 50 .1 3( 1. 0) 65 .8 7( 0. 14 ) 67 .2 (0 .2 7) 62 .8 7( 3. 68 ) 64 .6 4( 1. 14 ) co ve r 92 .2 4( 0. 17 ) 88 .2 (0 .3 2) 91 .8 5( 0. 2) 57 .1 4( 2. 15 ) 70 .6 8( 1. 16 ) 87 .3 2( 2. 69 ) 86 .5 7( 2. 41 ) 92 .1 8( 3. 85 ) 56 .7 5( 1. 89 ) 69 .5 8( 0. 9) 95 .2 (0 .1 6) 93 .3 9( 0. 25 ) 74 .1 5( 14 .1 5) 58 .0 4( 22 .3 9) 74 .6 9( 22 .5 9) 12 .3 7( 7. 08 ) 68 .0 7( 5. 04 ) 41 .6 8( 7. 76 ) 93 .2 5( 0. 23 ) 70 .1 3( 19 .1 ) 72 .3 4( 1. 89 ) 50 .4 1( 1. 34 ) 80 .7 6( 1. 65 ) 83 .8 1( 2. 71 ) 63 .5 2( 7. 37 ) 69 .6 8( 4. 69 ) do no rs 80 .7 7( 0. 71 ) 81 .5 3( 0. 27 ) 88 .8 3( 0. 32 ) 69 .0 6( 1. 74 ) 74 .3 1( 0. 63 ) 77 .0 8( 1. 5) 82 .9 (0 .4 2) 56 .6 2( 38 .0 2) 62 .8 9( 1. 35 ) 76 .4 8( 7. 46 ) 77 .0 2( 0. 67 ) 82 .5 (0 .9 4) 55 .7 6( 15 .6 3) 51 .1 1( 24 .7 3) 74 .6 6( 13 .8 9) 22 .4 5( 11 .5 3) 73 .9 2( 4. 79 ) 89 .8 9( 1. 85 ) 82 .0 1( 0. 45 ) 63 .8 7( 15 .5 1) 62 .7 2( 1. 88 ) 49 .7 6( 0. 41 ) 80 .6 3( 1. 88 ) 83 .2 3( 0. 45 ) 79 .5 5( 10 .7 5) 78 .4 9( 7. 9) fa ul t 66 .5 (2 .5 1) 45 .4 9( 0. 16 ) 46 .8 1( 0. 19 ) 59 .1 (1 .1 6) 50 .6 2( 6. 66 ) 54 .3 9( 1. 01 ) 71 .5 2( 0. 62 ) 47 .7 8( 2. 34 ) 57 .8 8( 1. 35 ) 50 .5 (1 .2 ) 53 .6 9( 0. 3) 47 .9 7( 0. 55 ) 49 .5 4( 5. 92 ) 52 .2 2( 2. 87 ) 66 .8 4( 2. 7) 54 .6 3( 4. 8) 66 .0 5( 1. 1) 46 .8 7( 3. 43 ) 48 .4 6( 0. 08 ) 48 .9 2( 6. 42 ) 70 .4 8( 0. 88 ) 50 .6 9( 0. 61 ) 56 .2 2( 0. 95 ) 72 .5 5( 0. 3) 57 .7 4( 5. 42 ) 58 .9 5( 3. 36 ) fr au d 95 .3 9( 0. 81 ) 94 .2 9( 1. 42 ) 94 .8 9( 1. 27 ) 61 .5 9( 7. 15 ) 94 .5 1( 1. 22 ) 94 .9 5( 1. 15 ) 95 .5 (1 .1 3) 85 .5 5( 5. 41 ) 54 .7 7( 7. 3) 91 .1 3( 1. 91 ) 95 .3 7( 0. 72 ) 95 .2 3( 0. 72 ) 85 .7 1( 5. 32 ) 76 .9 1( 6. 34 ) 50 .0 (0 .0 ) 72 .4 (2 2. 06 ) 93 .0 9( 1. 05 ) 89 .4 8( 2. 1) 95 .2 4( 0. 76 ) 84 .9 3( 5. 45 ) 93 .7 9( 1. 88 ) 50 .2 2( 3. 43 ) 92 .3 7( 1. 37 ) 95 .6 (1 .1 8) 94 .1 8( 1. 16 ) 93 .7 8( 1. 29 ) gl as s 85 .5 (4 .1 8) 75 .9 5( 1. 51 ) 71 .0 4( 3. 41 ) 65 .8 6( 12 .4 7) 82 .0 2( 1. 77 ) 78 .9 5( 3. 72 ) 87 .0 3( 1. 1) 62 .4 3( 12 .7 5) 61 .7 6( 12 .4 2) 79 .4 7( 1. 22 ) 66 .0 7( 6. 69 ) 71 .5 1( 2. 1) 62 .9 9( 16 .2 7) 51 .6 9( 18 .7 5) 74 .2 9( 16 .1 9) 54 .4 6( 20 .9 7) 72 .8 5( 5. 65 ) 76 .6 2( 8. 46 ) 69 .9 5( 1. 81 ) 80 .8 1( 13 .8 3) 74 .8 7( 2. 69 ) 50 .0 5( 5. 2) 56 .0 4( 9. 11 ) 88 .1 3( 1. 24 ) 68 .0 5( 23 .1 ) 86 .3 9( 4. 15 ) he pa tit is 63 .4 7( 14 .6 1) 80 .7 4( 0. 93 ) 73 .7 (1 .7 3) 46 .9 4( 11 .1 4) 76 .7 7( 1. 57 ) 68 .2 9( 1. 42 ) 66 .9 4( 7. 9) 55 .7 4( 15 .7 3) 46 .7 7( 8. 48 ) 72 .0 5( 2. 95 ) 70 .3 8( 1. 52 ) 74 .7 8( 2. 64 ) 60 .0 (9 .7 1) 36 .0 8( 22 .0 7) 58 .1 8( 4. 23 ) 63 .6 5( 22 .9 4) 61 .6 4( 3. 75 ) 65 .4 2( 7. 96 ) 74 .8 4( 1. 89 ) 65 .5 1( 6. 12 ) 43 .0 6( 10 .0 4) 49 .2 8( 3. 43 ) 46 .1 2( 8. 03 ) 63 .1 (2 .7 9) 45 .1 4( 13 .8 8) 57 .6 9( 9. 3) ht tp 99 .6 1( 0. 03 ) 99 .0 7( 0. 26 ) 97 .9 6( 0. 1) 28 .8 2( 1. 45 ) 99 .1 1( 0. 16 ) 99 .9 5( 0. 08 ) 5. 05 (1 .9 8) 5. 95 (9 .3 5) 33 .7 5( 1. 07 ) 99 .9 5( 0. 01 ) 99 .3 6( 0. 05 ) 99 .6 6( 0. 03 ) 83 .8 1( 35 .3 ) 24 .8 9( 42 .3 5) 50 .0 (0 .0 ) 99 .5 6( 0. 04 ) 92 .1 1( 7. 15 ) 99 .3 8( 0. 05 ) 99 .6 2( 0. 02 ) 77 .9 1( 18 .0 4) 99 .4 3( 0. 1) 49 .6 6( 2. 23 ) 99 .7 6( 0. 16 ) 5. 06 (1 .9 9) 97 .3 3( 4. 05 ) 99 .5 1( 0. 21 ) im db 49 .5 6( 0. 21 ) 51 .2 (0 .0 4) 47 .0 5( 0. 03 ) 49 .8 9( 0. 54 ) 49 .8 6( 0. 08 ) 48 .9 3( 0. 66 ) 49 .4 4( 0. 14 ) 46 .6 (2 .5 2) 50 .0 2( 0. 55 ) 50 .3 6( 0. 21 ) 48 .3 9( 0. 13 ) 47 .8 2( 0. 06 ) 48 .6 8( 0. 29 ) 52 .5 6( 4. 11 ) 49 .9 5( 0. 12 ) 48 .5 8( 1. 58 ) 52 .0 7( 0. 36 ) 49 .2 9( 0. 76 ) 47 .8 3( 0. 0) 48 .9 6( 1. 32 ) 50 .5 4( 0. 4) 49 .8 8( 0. 83 ) 47 .7 9( 0. 11 ) 49 .4 9( 0. 3) 48 .6 1( 4. 27 ) 48 .4 4( 2. 75 ) in te rn et ad s 61 .5 5( 0. 12 ) 67 .6 1( 0. 07 ) 67 .6 6( 0. 06 ) 49 .4 2( 4. 74 ) 69 .5 6( 0. 04 ) 68 .6 1( 1. 81 ) 61 .6 2( 0. 08 ) 54 .0 6( 5. 45 ) 58 .7 3( 1. 53 ) 65 .9 6( 4. 33 ) 61 .5 2( 0. 07 ) 60 .9 1( 0. 22 ) 51 .4 8( 2. 63 ) 58 .3 (4 .5 ) 50 .0 (1 .4 ) 61 .4 1( 0. 35 ) 59 .2 1( 1. 26 ) 60 .7 8( 0. 48 ) 61 .4 7( 0. 0) 68 .7 5( 1. 0) 60 .0 8( 2. 14 ) 49 .3 8( 1. 28 ) 61 .3 7( 0. 03 ) 63 .4 2( 0. 33 ) 63 .5 3( 3. 89 ) 65 .5 8( 2. 8) io no sp he re 89 .1 9( 1. 14 ) 78 .2 7( 1. 27 ) 71 .6 5( 1. 21 ) 87 .6 4( 1. 63 ) 54 .4 4( 3. 14 ) 83 .3 (1 .3 1) 92 .1 8( 1. 24 ) 78 .8 4( 4. 28 ) 86 .3 8( 2. 12 ) 95 .1 4( 0. 75 ) 83 .7 9( 1. 44 ) 77 .6 8( 1. 24 ) 64 .1 (4 .7 7) 51 .3 7( 9. 79 ) 76 .6 (7 .8 7) 82 .9 2( 2. 69 ) 62 .9 (2 .9 6) 88 .3 7( 1. 49 ) 78 .5 5( 1. 59 ) 88 .0 7( 2. 14 ) 88 .4 (1 .0 6) 49 .4 6( 2. 76 ) 75 .7 5( 2. 41 ) 92 .4 (1 .6 3) 69 .7 2( 11 .3 9) 91 .1 4( 1. 82 ) la nd sa t 54 .7 7( 4. 28 ) 42 .1 7( 0. 12 ) 36 .8 3( 0. 13 ) 54 .0 3( 1. 15 ) 57 .5 (0 .5 8) 47 .4 (2 .3 2) 61 .4 4( 0. 32 ) 38 .2 3( 3. 78 ) 54 .8 6( 1. 33 ) 60 .7 (0 .0 7) 42 .3 3( 0. 26 ) 36 .5 5( 0. 29 ) 53 .2 5( 1. 1) 63 .1 3( 2. 62 ) 62 .5 6( 0. 47 ) 50 .5 9( 9. 05 ) 64 .8 6( 1. 86 ) 46 .4 4( 0. 89 ) 54 .8 5( 1. 48 ) 54 .4 (4 .8 ) 67 .2 7( 0. 61 ) 50 .2 3( 0. 98 ) 49 .6 2( 0. 59 ) 60 .2 (0 .3 9) 47 .3 1( 8. 29 ) 54 .4 2( 1. 2) le tte r 76 .3 2( 1. 8) 56 .0 2( 0. 07 ) 57 .2 6( 0. 13 ) 88 .5 8( 0. 51 ) 58 .8 5( 0. 59 ) 61 .5 6( 1. 17 ) 81 .2 1( 0. 3) 53 .7 1( 4. 29 ) 87 .8 1( 0. 48 ) 80 .4 3( 0. 42 ) 59 .8 1( 0. 28 ) 52 .3 5( 0. 29 ) 50 .3 1( 5. 01 ) 51 .7 4( 2. 09 ) 78 .0 3( 2. 72 ) 59 .7 7( 1. 85 ) 73 .6 5( 1. 25 ) 68 .9 2( 3. 77 ) 52 .4 5( 0. 12 ) 68 .1 5( 9. 18 ) 86 .5 2( 0. 55 ) 50 .4 5( 1. 04 ) 84 .7 3( 1. 44 ) 85 .0 (0 .5 ) 67 .6 3( 4. 86 ) 78 .1 3( 1. 49 ) ly m ph og ra ph y 99 .3 5( 0. 74 ) 99 .6 (0 .0 9) 99 .4 9( 0. 14 ) 52 .3 4( 18 .3 1) 99 .4 9( 0. 18 ) 99 .8 5( 0. 1) 99 .5 1( 0. 28 ) 90 .0 4( 11 .0 6) 63 .6 3( 18 .0 1) 98 .9 (0 .2 4) 99 .5 6( 0. 27 ) 99 .6 7( 0. 25 ) 84 .0 (4 .7 7) 68 .0 7( 30 .7 5) 87 .7 5( 8. 04 ) 99 .5 3( 0. 28 ) 88 .4 3( 4. 62 ) 94 .0 3( 5. 01 ) 99 .7 2( 0. 21 ) 86 .4 3( 20 .2 2) 96 .1 1( 1. 79 ) 51 .1 5( 6. 83 ) 95 .7 7( 4. 02 ) 98 .8 9( 0. 72 ) 85 .2 3( 7. 81 ) 83 .4 1( 11 .3 7) m ag ic .g am m a 72 .5 3( 0. 1) 68 .1 (0 .0 4) 63 .8 (0 .0 5) 69 .9 6( 0. 64 ) 70 .9 3( 0. 55 ) 72 .1 (0 .7 9) 79 .5 (0 .1 5) 65 .5 (1 .4 1) 67 .8 4( 0. 38 ) 69 .8 7( 0. 1) 67 .2 6( 0. 18 ) 66 .7 3( 0. 11 ) 58 .4 4( 3. 35 ) 60 .3 7( 1. 2) 72 .7 9( 0. 59 ) 44 .2 4( 4. 6) 67 .5 5( 1. 02 ) 74 .2 3( 4. 69 ) 66 .8 6( 0. 0) 57 .7 3( 3. 14 ) 63 .7 8( 0. 4) 50 .2 (0 .4 8) 76 .2 6( 1. 48 ) 80 .0 7( 0. 15 ) 78 .2 1( 2. 19 ) 76 .4 5( 1. 39 ) m am m og ra ph y 79 .5 (1 .8 4) 90 .5 4( 0. 03 ) 90 .6 2( 0. 03 ) 72 .6 1( 0. 51 ) 83 .7 7( 0. 9) 85 .9 6( 1. 73 ) 85 .1 7( 0. 24 ) 86 .6 9( 2. 45 ) 70 .1 5( 1. 87 ) 69 .0 2( 1. 35 ) 87 .1 1( 0. 13 ) 88 .8 4( 0. 29 ) 71 .9 1( 17 .9 5) 45 .1 3( 6. 77 ) 77 .9 2( 1. 81 ) 41 .4 1( 13 .3 1) 65 .7 6( 9. 12 ) 78 .2 2( 2. 96 ) 88 .6 7( 0. 07 ) 87 .1 2( 4. 62 ) 73 .2 3( 2. 4) 50 .1 7( 2. 0) 74 .9 4( 2. 14 ) 84 .8 6( 0. 22 ) 79 .9 4( 5. 76 ) 81 .0 2( 2. 74 ) m ni st 84 .2 6( 1. 11 ) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 66 .4 4( 1. 42 ) 57 .3 6( 0. 38 ) 81 .0 6( 2. 17 ) 86 .6 6( 0. 59 ) 56 .4 (1 1. 07 ) 65 .7 7( 1. 94 ) 85 .6 2( 1. 32 ) 84 .9 1( 0. 22 ) 84 .7 6( 0. 43 ) 63 .1 4( 6. 24 ) 60 .4 8( 14 .1 1) 61 .5 1( 1. 13 ) 69 .7 6( 8. 76 ) 69 .0 6( 1. 61 ) 64 .4 9( 15 .6 3) 85 .0 (0 .0 4) 72 .0 5( 3. 57 ) 50 .0 (0 .0 ) 49 .5 1( 1. 34 ) 81 .6 (1 .2 ) 85 .2 7( 0. 77 ) 75 .5 6( 4. 12 ) 81 .8 9( 1. 32 ) m us k 10 0. 0( 0. 0) 94 .8 1( 0. 48 ) 95 .2 8( 0. 29 ) 57 .5 4( 10 .6 7) 10 0. 0( 0. 0) 99 .7 7( 0. 38 ) 96 .4 2( 3. 15 ) 99 .3 (0 .7 7) 58 .0 7( 8. 89 ) 99 .9 6( 0. 05 ) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 91 .2 2( 7. 47 ) 53 .8 4( 15 .3 8) 57 .4 9( 5. 9) 10 0. 0( 0. 0) 79 .0 (2 .5 8) 74 .8 3( 25 .7 1) 10 0. 0( 0. 0) 10 0. 0( 0. 0) 83 .6 6( 4. 44 ) 50 .0 3( 3. 54 ) 99 .9 5( 0. 03 ) 88 .1 7( 5. 61 ) 78 .4 8( 12 .0 7) 96 .4 7( 1. 74 ) op td ig its 78 .4 8( 0. 95 ) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 53 .9 3( 5. 59 ) 86 .8 1( 0. 25 ) 69 .6 3( 4. 81 ) 39 .5 2( 2. 17 ) 49 .2 9( 9. 35 ) 53 .8 2( 5. 25 ) 41 .2 7( 5. 26 ) 50 .6 6( 1. 46 ) 51 .7 8( 0. 53 ) 40 .7 8( 19 .7 5) 51 .9 4( 25 .0 8) 56 .5 2( 3. 54 ) 65 .6 6( 7. 61 ) 53 .2 9( 6. 15 ) 49 .1 5( 13 .2 3) 51 .4 7( 0. 2) 44 .7 9( 14 .0 6) 56 .0 8( 3. 06 ) 50 .1 8( 1. 59 ) 40 .1 5( 3. 71 ) 38 .6 1( 2. 33 ) 51 .3 4( 4. 5) 50 .7 7( 6. 25 ) pa ge bl oc ks 89 .3 (2 .1 4) 87 .4 8( 0. 21 ) 91 .3 7( 0. 1) 75 .8 3( 1. 79 ) 77 .8 9( 2. 07 ) 89 .7 2( 0. 35 ) 91 .9 4( 0. 32 ) 71 .2 4( 10 .4 7) 70 .3 3( 1. 55 ) 92 .3 (0 .2 2) 91 .4 2( 0. 21 ) 90 .6 7( 0. 47 ) 75 .2 9( 4. 49 ) 59 .2 4( 11 .1 3) 91 .3 8( 1. 48 ) 60 .9 3( 7. 81 ) 76 .7 5( 1. 0) 90 .8 (2 .0 2) 90 .5 7( 0. 0) 80 .1 3( 2. 79 ) 74 .5 7( 4. 01 ) 50 .2 6( 1. 09 ) 82 .0 (0 .9 1) 90 .6 4( 0. 63 ) 85 .0 2( 8. 84 ) 92 .3 9( 0. 84 ) pe nd ig its 86 .3 8( 7. 22 ) 90 .6 (0 .4 3) 92 .6 9( 0. 15 ) 51 .8 2( 5. 22 ) 92 .4 7( 0. 38 ) 94 .6 9( 0. 78 ) 82 .8 1( 3. 01 ) 89 .5 1( 0. 85 ) 53 .4 2( 4. 61 ) 83 .4 1( 0. 94 ) 92 .8 6( 0. 48 ) 93 .5 8( 0. 12 ) 54 .8 (2 1. 37 ) 38 .2 6( 12 .3 9) 52 .0 1( 4. 93 ) 59 .2 3( 15 .6 ) 65 .0 2( 4. 5) 77 .9 9( 9. 67 ) 93 .6 6( 0. 03 ) 83 .7 5( 10 .0 3) 68 .6 3( 2. 86 ) 49 .6 5( 2. 66 ) 70 .0 3( 5. 43 ) 78 .6 4( 3. 13 ) 62 .3 9( 10 .3 9) 71 .3 3( 6. 62 ) pi m a 65 .4 9( 1. 65 ) 66 .2 (1 .2 1) 60 .3 8( 1. 54 ) 57 .3 1( 3. 88 ) 70 .3 8( 1. 21 ) 67 .3 7( 1. 88 ) 72 .3 3( 1. 74 ) 59 .5 2( 7. 09 ) 56 .3 4( 3. 89 ) 68 .6 4( 2. 09 ) 63 .1 1( 1. 82 ) 65 .1 1( 2. 53 ) 52 .1 6( 3. 2) 51 .0 1( 3. 01 ) 54 .1 8( 11 .4 9) 60 .5 7( 18 .2 5) 52 .4 (2 .5 6) 61 .5 1( 5. 6) 67 .0 3( 1. 72 ) 55 .0 5( 6. 29 ) 47 .1 1( 3. 76 ) 51 .2 4( 2. 19 ) 53 .7 4( 5. 29 ) 70 .7 1( 2. 47 ) 59 .9 2( 3. 39 ) 62 .3 7( 3. 09 ) sa te lli te 74 .1 9( 3. 23 ) 63 .3 4( 0. 04 ) 58 .3 (0 .0 5) 54 .5 4( 1. 26 ) 76 .1 8( 0. 55 ) 69 .5 (1 .0 7) 72 .0 9( 0. 14 ) 61 .3 9( 2. 92 ) 54 .9 8( 1. 29 ) 80 .3 9( 0. 07 ) 66 .2 4( 0. 21 ) 60 .1 4( 0. 07 ) 67 .4 6( 2. 21 ) 56 .2 1( 5. 85 ) 60 .8 (1 .2 3) 70 .2 1( 3. 55 ) 62 .6 5( 1. 77 ) 67 .0 5( 1. 01 ) 75 .5 5( 0. 75 ) 68 .1 3( 6. 86 ) 74 .5 6( 1. 53 ) 49 .8 4( 0. 7) 71 .5 3( 0. 52 ) 70 .1 5( 0. 19 ) 58 .1 7( 6. 67 ) 71 .0 5( 1. 82 ) sa tim ag e2 99 .8 8( 0. 01 ) 97 .4 6( 0. 04 ) 96 .5 2( 0. 05 ) 52 .5 5( 7. 36 ) 97 .6 (0 .1 2) 99 .2 8( 0. 16 ) 99 .2 4( 0. 61 ) 98 .1 4( 0. 49 ) 53 .9 1( 7. 29 ) 99 .5 3( 0. 06 ) 99 .6 7( 0. 01 ) 97 .7 2( 0. 03 ) 91 .1 3( 4. 48 ) 55 .1 2( 12 .7 7) 57 .8 6( 11 .1 2) 99 .5 6( 0. 06 ) 89 .7 6( 2. 38 ) 97 .0 3( 0. 86 ) 98 .5 1( 0. 12 ) 98 .3 6( 1. 01 ) 96 .6 5( 1. 42 ) 50 .7 7( 2. 25 ) 99 .5 5( 0. 05 ) 97 .9 5( 1. 48 ) 85 .8 1( 5. 97 ) 94 .5 6( 1. 27 ) sh ut tle 62 .0 6( 3. 96 ) 99 .5 (0 .1 ) 99 .3 (0 .0 1) 49 .2 9( 3. 4) 98 .6 3( 0. 23 ) 99 .7 1( 0. 03 ) 73 .1 6( 0. 66 ) 38 .8 7( 13 .1 6) 52 .5 5( 1. 09 ) 99 .0 1( 0. 01 ) 99 .1 8( 0. 0) 98 .9 9( 0. 03 ) 89 .7 7( 5. 59 ) 57 .5 8( 13 .2 4) 50 .0 (0 .0 ) 20 .7 8( 28 .3 5) 64 .1 7( 14 .0 5) 85 .1 6( 6. 0) 98 .9 8( 0. 0) 98 .1 1( 0. 69 ) 90 .7 2( 18 .1 2) 50 .0 8( 0. 35 ) 97 .5 (2 .2 8) 69 .8 3( 0. 34 ) 66 .8 6( 26 .5 2) 97 .6 2( 1. 2) sk in 67 .5 1( 3. 8) 47 .1 2( 0. 19 ) 48 .9 7( 0. 1) 53 .3 8( 0. 29 ) 58 .8 4( 0. 37 ) 66 .9 7( 0. 65 ) 71 .9 7( 0. 13 ) 44 .1 6( 1. 92 ) 54 .9 7( 0. 17 ) 89 .1 5( 0. 15 ) 54 .7 3( 0. 45 ) 44 .6 9( 0. 58 ) 55 .4 4( 17 .8 1) 54 .8 2( 7. 49 ) 70 .8 4( 1. 68 ) 57 .8 6( 4. 33 ) 26 .4 5( 9. 05 ) 77 .3 3( 3. 97 ) 52 .2 7( 0. 25 ) 46 .5 4( 3. 91 ) 75 .0 1( 0. 51 ) 50 .1 5( 0. 38 ) 46 .0 9( 2. 11 ) 71 .8 1( 0. 13 ) 74 .0 5( 3. 66 ) 74 .0 5( 2. 35 ) sm tp 86 .2 9( 4. 76 ) 91 .1 7( 1. 63 ) 88 .2 2( 2. 47 ) 79 .3 6( 5. 06 ) 80 .9 1( 4. 76 ) 90 .5 (2 .2 ) 93 .2 6( 1. 74 ) 81 .8 8( 3. 56 ) 89 .9 2( 5. 31 ) 94 .8 4( 0. 93 ) 84 .4 9( 4. 46 ) 85 .6 2( 4. 92 ) 86 .7 7( 5. 56 ) 89 .5 3( 5. 1) 50 .0 (0 .0 ) 91 .5 3( 1. 82 ) 65 .6 1( 12 .0 8) 78 .3 7( 11 .9 ) 81 .9 8( 5. 52 ) 59 .0 1( 16 .0 5) 92 .1 3( 1. 68 ) 54 .1 (6 .5 3) 95 .5 6( 1. 3) 92 .9 7( 1. 89 ) 76 .9 2( 14 .3 3) 95 .0 7( 1. 36 ) sp am ba se 54 .1 3( 0. 68 ) 68 .7 9( 0. 08 ) 65 .5 7( 0. 12 ) 42 .4 1( 0. 84 ) 66 .4 1( 1. 18 ) 63 .7 2( 2. 0) 56 .5 6( 0. 27 ) 47 .9 8( 10 .2 3) 45 .2 9( 0. 42 ) 44 .5 5( 3. 6) 53 .4 3( 0. 18 ) 54 .7 7( 0. 69 ) 48 .8 4( 4. 87 ) 58 .4 4( 7. 73 ) 49 .0 4( 1. 5) 49 .5 7( 9. 44 ) 45 .8 8( 1. 79 ) 52 .8 3( 6. 32 ) 54 .9 9( 0. 03 ) 55 .1 8( 2. 65 ) 49 .2 6( 0. 44 ) 49 .5 1( 0. 82 ) 51 .0 1( 1. 51 ) 54 .4 7( 0. 38 ) 50 .9 3( 4. 84 ) 51 .5 2( 1. 9) sp ee ch 47 .1 1( 0. 24 ) 48 .8 9( 0. 29 ) 46 .9 5( 0. 04 ) 50 .8 5( 0. 71 ) 47 .3 2( 0. 19 ) 47 .6 2( 0. 7) 48 .0 (0 .0 9) 46 .5 7( 1. 85 ) 51 .1 5( 0. 65 ) 49 .3 7( 1. 87 ) 46 .5 9( 0. 1) 46 .8 9( 0. 04 ) 52 .2 2( 4. 41 ) 51 .2 4( 3. 1) 48 .2 7( 1. 74 ) 45 .8 1( 1. 99 ) 51 .1 6( 2. 23 ) 49 .5 6( 3. 55 ) 46 .9 4( 0. 05 ) 50 .6 6( 2. 29 ) 50 .8 5( 2. 15 ) 48 .0 9( 2. 89 ) 46 .5 7( 1. 17 ) 48 .7 3( 1. 02 ) 48 .8 4( 4. 05 ) 49 .4 6( 1. 46 ) st am ps 66 .0 4( 2. 92 ) 92 .9 2( 0. 83 ) 87 .7 2( 1. 03 ) 50 .1 6( 7. 61 ) 90 .4 (1 .0 ) 90 .7 2( 1. 09 ) 86 .9 7( 2. 04 ) 83 .1 (9 .1 5) 51 .1 8( 9. 24 ) 83 .8 3( 3. 64 ) 88 .2 4( 1. 44 ) 90 .9 4( 1. 59 ) 71 .8 9( 9. 56 ) 46 .5 1( 7. 98 ) 76 .0 (7 .4 4) 77 .4 4( 13 .7 8) 50 .5 1( 4. 05 ) 83 .8 1( 4. 86 ) 90 .6 3( 1. 26 ) 77 .4 (1 2. 76 ) 51 .2 (3 .7 9) 50 .7 (4 .3 5) 55 .5 5( 12 .8 3) 82 .0 2( 4. 05 ) 69 .1 7( 18 .3 3) 75 .2 5( 5. 15 ) th yr oi d 90 .9 3( 1. 07 ) 93 .9 1( 0. 26 ) 97 .7 1( 0. 11 ) 70 .6 8( 1. 69 ) 94 .8 4( 1. 01 ) 97 .9 1( 0. 55 ) 96 .5 2( 0. 21 ) 81 .8 9( 12 .4 9) 65 .6 9( 3. 08 ) 98 .5 7( 0. 04 ) 95 .8 3( 0. 12 ) 95 .4 8( 0. 31 ) 71 .8 5( 12 .1 1) 50 .4 5( 2. 0) 88 .8 9( 4. 95 ) 57 .4 2( 27 .1 6) 69 .2 5( 5. 72 ) 99 .1 8( 0. 26 ) 95 .5 6( 0. 0) 81 .9 (1 7. 35 ) 80 .0 2( 3. 3) 50 .8 5( 2. 85 ) 87 .0 6( 1. 5) 96 .4 3( 0. 3) 82 .7 5( 12 .1 6) 99 .0 2( 0. 12 ) ve rt eb ra l 46 .3 4( 1. 41 ) 26 .2 8( 3. 94 ) 41 .6 7( 3. 03 ) 47 .3 2( 5. 6) 31 .7 3( 3. 46 ) 36 .1 8( 3. 44 ) 37 .9 (2 .0 3) 29 .4 4( 5. 11 ) 48 .6 8( 3. 4) 38 .9 (2 .1 6) 42 .6 1( 0. 9) 37 .8 2( 2. 71 ) 46 .9 6( 9. 72 ) 39 .4 2( 2. 69 ) 42 .4 5( 15 .8 7) 46 .8 1( 12 .6 8) 44 .9 (1 .0 8) 40 .8 6( 14 .6 6) 38 .4 (2 .5 4) 37 .6 6( 8. 85 ) 39 .7 5( 3. 09 ) 49 .2 8( 2. 03 ) 56 .3 4( 7. 41 ) 40 .0 4( 2. 58 ) 45 .0 7( 14 .4 3) 45 .7 6( 8. 79 ) vo w el s 88 .3 8( 0. 5) 49 .6 (0 .4 4) 59 .3 (0 .3 8) 93 .2 9( 1. 73 ) 67 .9 1( 0. 98 ) 76 .2 6( 3. 14 ) 95 .0 9( 0. 23 ) 70 .5 2( 4. 82 ) 93 .1 8( 1. 07 ) 73 .2 1( 8. 48 ) 77 .8 7( 0. 98 ) 60 .3 5( 0. 6) 46 .4 4( 13 .2 7) 51 .3 7( 2. 96 ) 73 .8 1( 15 .9 ) 79 .0 8( 5. 62 ) 78 .4 2( 2. 32 ) 88 .8 2( 3. 83 ) 62 .0 8( 0. 09 ) 55 .4 3( 18 .5 3) 93 .1 9( 0. 78 ) 49 .2 9( 2. 87 ) 90 .3 4( 2. 76 ) 96 .4 2( 0. 42 ) 70 .4 9( 8. 5) 91 .4 2( 5. 8) w av ef or m 70 .1 4( 0. 99 ) 73 .8 9( 0. 4) 60 .3 1( 0. 21 ) 71 .5 2( 2. 12 ) 69 .3 8( 0. 64 ) 70 .6 9( 5. 94 ) 74 .9 7( 0. 82 ) 59 .4 (6 .1 6) 69 .2 6( 1. 81 ) 57 .1 6( 0. 49 ) 66 .8 8( 0. 3) 63 .5 3( 0. 26 ) 52 .3 (7 .4 2) 60 .8 6( 7. 12 ) 67 .4 (1 .9 4) 59 .1 5( 5. 89 ) 66 .0 5( 2. 92 ) 63 .9 7( 5. 61 ) 63 .8 5( 0. 05 ) 62 .0 1( 16 .1 6) 43 .6 5( 0. 95 ) 48 .7 (3 .4 9) 61 .7 2( 3. 41 ) 72 .9 1( 1. 34 ) 52 .2 9( 6. 3) 60 .2 (3 .5 5) w bc 97 .7 1( 1. 1) 99 .4 (0 .1 ) 99 .3 8( 0. 12 ) 38 .8 3( 10 .4 ) 98 .7 (0 .1 6) 99 .5 8( 0. 15 ) 98 .2 1( 0. 47 ) 99 .1 7( 0. 13 ) 60 .6 6( 8. 68 ) 98 .7 7( 1. 03 ) 98 .7 2( 0. 54 ) 99 .2 8( 0. 25 ) 82 .0 9( 14 .3 7) 50 .3 4( 17 .7 6) 82 .0 8( 10 .3 5) 94 .8 6( 4. 74 ) 85 .3 4( 4. 73 ) 93 .3 6( 3. 36 ) 99 .1 5( 0. 18 ) 95 .7 6( 3. 23 ) 96 .0 8( 4. 57 ) 48 .0 1( 3. 85 ) 94 .8 (1 .1 6) 97 .9 4( 0. 76 ) 89 .3 8( 7. 64 ) 87 .0 6( 3. 83 ) w db c 98 .9 8( 0. 42 ) 99 .2 9( 0. 14 ) 97 .0 5( 0. 65 ) 86 .6 5( 8. 37 ) 98 .9 4( 0. 24 ) 98 .8 3( 0. 39 ) 98 .0 4( 0. 64 ) 98 .0 4( 0. 77 ) 84 .8 7( 9. 38 ) 96 .9 (1 .1 2) 98 .4 2( 0. 37 ) 98 .8 (0 .3 1) 71 .5 1( 25 .0 4) 60 .2 (2 0. 82 ) 34 .7 3( 16 .7 8) 98 .2 8( 1. 25 ) 73 .7 8( 7. 19 ) 98 .5 4( 0. 81 ) 97 .7 9( 0. 97 ) 96 .2 3( 2. 96 ) 78 .9 9( 12 .1 3) 48 .5 2( 3. 7) 96 .5 4( 0. 93 ) 97 .4 9( 1. 11 ) 56 .6 4( 26 .5 6) 83 .5 1( 6. 61 ) w ilt 39 .5 9( 1. 76 ) 34 .4 9( 0. 27 ) 39 .4 (0 .1 2) 66 .5 9( 7. 27 ) 34 .8 1( 2. 83 ) 45 .1 3( 3. 34 ) 51 .0 5( 0. 65 ) 31 .3 1( 9. 9) 67 .8 1( 1. 65 ) 85 .8 8( 0. 06 ) 31 .6 6( 0. 3) 23 .9 4( 0. 42 ) 43 .1 8( 5. 91 ) 46 .5 (1 .5 8) 39 .9 9( 3. 03 ) 55 .4 6( 8. 59 ) 64 .8 5( 3. 41 ) 79 .3 6( 2. 41 ) 33 .0 8( 0. 0) 41 .3 2( 1. 11 ) 68 .0 6( 1. 02 ) 50 .9 1( 1. 72 ) 65 .9 (3 .9 2) 55 .1 5( 0. 61 ) 83 .3 8( 7. 17 ) 85 .1 2( 1. 73 ) w in e 45 .2 7( 33 .4 ) 86 .4 6( 4. 66 ) 73 .7 7( 4. 79 ) 32 .3 4( 5. 54 ) 90 .7 2( 3. 31 ) 78 .6 1( 6. 71 ) 47 .0 4( 3. 12 ) 82 .1 7( 3. 91 ) 32 .9 7( 14 .6 3) 97 .5 4( 1. 59 ) 67 .1 4( 3. 79 ) 81 .9 1( 2. 83 ) 51 .2 7( 29 .9 4) 50 .7 2( 23 .4 1) 62 .0 5( 21 .9 9) 73 .3 7( 23 .8 1) 45 .4 7( 4. 33 ) 38 .9 9( 21 .8 9) 81 .2 2( 3. 63 ) 68 .1 7( 16 .0 1) 37 .4 2( 8. 26 ) 48 .4 5( 3. 14 ) 37 .3 9( 8. 37 ) 42 .4 5( 6. 29 ) 31 .0 1( 10 .9 8) 55 .7 1( 11 .3 9) w pb c 48 .6 8( 3. 14 ) 51 .8 7( 3. 09 ) 48 .9 1( 2. 35 ) 43 .6 1( 3. 13 ) 54 .8 1( 2. 85 ) 51 .5 5( 1. 88 ) 51 .2 2( 2. 52 ) 50 .0 7( 3. 44 ) 44 .6 6( 3. 87 ) 53 .4 1( 4. 03 ) 48 .5 1( 2. 34 ) 48 .6 2( 2. 27 ) 44 .9 4( 2. 82 ) 49 .3 4( 2. 52 ) 48 .2 6( 3. 3) 46 .6 4( 5. 66 ) 48 .7 6( 5. 04 ) 48 .3 4( 3. 69 ) 46 .7 7( 1. 77 ) 48 .8 7( 4. 0) 48 .3 3( 1. 22 ) 48 .8 2( 2. 44 ) 49 .3 1( 3. 97 ) 50 .2 2( 3. 27 ) 48 .9 1( 3. 81 ) 46 .7 9( 6. 57 ) ye as t 46 .0 6( 1. 23 ) 38 .0 3( 0. 15 ) 44 .3 1( 0. 16 ) 46 .4 5( 1. 53 ) 40 .1 7( 0. 97 ) 39 .4 2( 1. 16 ) 39 .6 2( 0. 95 ) 46 .1 3( 4. 68 ) 45 .3 (2 .1 2) 40 .6 4( 1. 1) 41 .9 5( 0. 43 ) 41 .7 5( 0. 4) 50 .3 3( 4. 55 ) 52 .0 4( 3. 8) 39 .5 7( 4. 74 ) 50 .3 1( 3. 51 ) 46 .5 9( 2. 15 ) 44 .2 (5 .9 2) 40 .0 7( 0. 01 ) 47 .6 4( 5. 98 ) 49 .5 5( 1. 21 ) 50 .0 1( 2. 19 ) 46 .3 1( 0. 72 ) 39 .9 8( 1. 1) 44 .6 1( 4. 27 ) 42 .0 3( 2. 62 ) ye lp 63 .5 3( 0. 34 ) 60 .5 2( 0. 15 ) 57 .7 8( 0. 04 ) 66 .1 (0 .4 2) 59 .9 7( 0. 11 ) 60 .1 5( 0. 34 ) 67 .0 1( 0. 17 ) 58 .1 (2 .8 9) 66 .1 1( 0. 48 ) 65 .4 9( 0. 64 ) 62 .0 8( 0. 04 ) 59 .1 9( 0. 1) 49 .8 3( 1. 27 ) 52 .4 3( 8. 88 ) 50 .3 5( 0. 54 ) 59 .0 2( 3. 78 ) 54 .5 2( 0. 49 ) 52 .6 7( 1. 98 ) 59 .2 9( 0. 08 ) 60 .5 1( 0. 91 ) 54 .3 7( 0. 27 ) 49 .1 (1 .3 4) 59 .3 8( 0. 12 ) 67 .0 8( 0. 37 ) 51 .3 7( 3. 24 ) 60 .1 6( 3. 22 ) M N IS TC 75 .7 1( 1. 0) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 70 .1 9( 1. 05 ) 68 .9 2( 0. 22 ) 73 .3 4( 1. 89 ) 78 .6 4( 0. 13 ) 59 .0 6( 9. 66 ) 69 .9 4( 0. 95 ) 73 .9 (1 .6 2) 75 .1 1( 0. 09 ) 74 .0 5( 0. 18 ) 58 .1 3( 6. 73 ) 55 .2 4( 9. 15 ) 59 .3 7( 2. 13 ) 75 .1 6( 1. 73 ) 66 .9 5( 1. 05 ) 70 .4 8( 1. 97 ) 74 .0 5( 0. 01 ) 72 .5 6( 3. 12 ) 74 .5 9( 0. 67 ) 49 .7 3( 1. 14 ) 75 .1 (0 .1 4) 78 .8 3( 0. 24 ) 70 .3 (3 .9 7) 74 .5 6( 2. 21 ) Fa sh io nM N IS T 87 .0 6( 0. 33 ) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 74 .7 8( 0. 94 ) 74 .8 2( 0. 2) 83 .0 8( 0. 94 ) 87 .5 1( 0. 14 ) 67 .2 3( 7. 64 ) 73 .8 1( 0. 86 ) 83 .9 5( 1. 2) 86 .0 3( 0. 05 ) 85 .3 2( 0. 17 ) 66 .3 7( 5. 59 ) 64 .6 6( 7. 04 ) 56 .3 9( 3. 06 ) 85 .9 9( 0. 52 ) 75 .8 (1 .2 ) 81 .8 8( 1. 33 ) 85 .3 2( 0. 01 ) 86 .6 5( 0. 97 ) 85 .8 3( 2. 38 ) 50 .3 1( 1. 74 ) 86 .1 (0 .0 8) 87 .3 1( 0. 25 ) 76 .6 7( 6. 18 ) 84 .0 5( 1. 28 ) C IF A R 10 66 .3 1( 0. 3) 54 .7 8( 0. 07 ) 56 .6 6( 0. 06 ) 68 .7 1( 0. 63 ) 57 .2 3( 0. 17 ) 62 .9 (1 .0 9) 65 .8 5( 0. 09 ) 59 .0 9( 5. 51 ) 68 .6 2( 0. 59 ) 63 .9 (0 .7 5) 66 .2 5( 0. 08 ) 65 .9 3( 0. 18 ) 53 .0 (2 .9 4) 55 .4 5( 4. 1) 50 .3 2( 2. 39 ) 65 .8 5( 1. 04 ) 55 .6 8( 1. 4) 62 .1 3( 1. 33 ) 65 .9 2( 0. 01 ) 66 .1 9( 1. 19 ) 64 .8 1( 0. 56 ) 50 .3 2( 1. 77 ) 66 .3 4( 0. 14 ) 66 .0 (0 .2 2) 59 .5 2( 2. 81 ) 62 .8 7( 1. 57 ) SV H N 60 .1 3( 0. 25 ) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 62 .9 (0 .4 ) 54 .2 2( 0. 12 ) 58 .0 3( 0. 7) 60 .3 6( 0. 08 ) 53 .4 (4 .2 9) 62 .8 (0 .4 1) 58 .3 1( 0. 84 ) 60 .3 8( 0. 08 ) 59 .9 2( 0. 17 ) 52 .7 5( 2. 11 ) 52 .0 5( 3. 23 ) 52 .1 2( 2. 09 ) 59 .7 (1 .4 4) 57 .0 6( 1. 05 ) 58 .0 4( 1. 09 ) 59 .9 1( 0. 01 ) 60 .1 7( 1. 06 ) 59 .5 7( 0. 4) 49 .6 6( 1. 16 ) 60 .4 5( 0. 13 ) 60 .6 9( 0. 2) 56 .7 3( 2. 89 ) 59 .9 6( 1. 24 ) M V Te cA D 75 .4 1( 2. 26 ) 50 .0 (0 .0 ) 50 .0 (0 .0 ) 74 .5 4( 2. 66 ) 73 .1 8( 1. 9) 74 .6 7( 1. 85 ) 76 .2 8( 1. 56 ) 64 .4 2( 5. 16 ) 74 .1 7( 2. 73 ) 61 .7 9( 4. 89 ) 73 .5 2( 1. 86 ) 72 .4 4( 1. 94 ) 59 .5 7( 4. 79 ) 60 .2 8( 6. 07 ) 54 .3 8( 4. 52 ) 72 .9 6( 2. 61 ) 68 .3 (3 .3 7) 63 .7 3( 6. 77 ) 72 .4 6( 1. 61 ) 73 .8 5( 2. 83 ) 69 .8 8( 3. 91 ) 49 .9 4( 2. 48 ) 73 .2 1( 1. 92 ) 76 .1 1( 2. 26 ) 65 .4 8( 5. 76 ) 72 .9 5( 3. 11 ) 20 ne w s 56 .3 8( 1. 44 ) 53 .2 6( 0. 59 ) 54 .4 2( 0. 42 ) 60 .9 7( 1. 63 ) 53 .6 9( 0. 62 ) 55 .0 (1 .8 1) 56 .6 5( 1. 23 ) 53 .8 5( 4. 56 ) 60 .9 8( 1. 65 ) 58 .2 9( 2. 78 ) 55 .9 2( 0. 97 ) 54 .4 8( 0. 69 ) 51 .7 8( 3. 92 ) 51 .4 9( 5. 34 ) 49 .5 8( 2. 77 ) 55 .2 8( 1. 84 ) 54 .7 3( 2. 58 ) 51 .2 7( 2. 61 ) 54 .5 9( 0. 69 ) 55 .7 4( 1. 98 ) 55 .3 1( 1. 21 ) 50 .9 9( 3. 11 ) 54 .7 4( 0. 56 ) 56 .9 8( 1. 59 ) 52 .7 2( 5. 59 ) 57 .8 7( 3. 45 ) ag ne w s 61 .9 1( 0. 31 ) 55 .1 (0 .0 4) 55 .2 4( 0. 04 ) 71 .5 (0 .6 2) 55 .4 (0 .0 8) 58 .4 3( 1. 32 ) 64 .6 5( 0. 1) 56 .8 1( 3. 57 ) 71 .3 6( 0. 64 ) 66 .5 (0 .5 ) 60 .0 9( 0. 11 ) 56 .6 1( 0. 08 ) 50 .8 (3 .4 5) 49 .3 6( 4. 46 ) 50 .0 1( 0. 55 ) 59 .1 6( 3. 06 ) 59 .0 8( 0. 61 ) 49 .6 5( 1. 27 ) 56 .6 (0 .0 ) 64 .5 3( 1. 65 ) 57 .4 4( 0. 25 ) 50 .1 7( 1. 17 ) 57 .0 6( 0. 1) 65 .2 2( 0. 31 ) 54 .4 5( 5. 22 ) 62 .6 6( 3. 75 )\nTa bl\ne 17\n:A ve\nra ge\nF1 sc\nor e\nan d\nst an\nda rd\nde vi\nat io\nns ov\ner fiv\ne se\ned s\nfo rt\nhe un\nsu pe\nrv is\ned se\ntti ng\non A\nD B\nen ch\n.\nC B\nL O\nF C\nO PO\nD E\nC O\nD Fe\nat ur\neB ag\ngi ng\nH B\nO S\nIF or\nes t\nkN N\nL O\nD A\nL O\nF M\nC D\nO C\nSV M\nPC A\nD A\nG M\nM D\nee pS\nV D\nD D\nR O\nC C\nG O\nA D\nIC L\nPl an\nar Fl\now VA\nE G\nA N\nom al\ny SL\nA D\nD IF\nD D\nPM D\nT E\n-N P\nD T\nE -I\nG D\nT E\n-C\nal oi\n4. 46\n(0 .3\n9) 2.\n39 (0\n.0 )\n2. 64\n(0 .0\n3) 14\n.9 1(\n0. 33\n) 4.\n08 (0\n.1 4)\n3. 45\n(0 .2\n1) 7.\n0( 0.\n23 )\n4. 4(\n1. 48\n) 13\n.8 3(\n0. 13\n) 2.\n4( 0.\n13 )\n4. 6(\n0. 04\n) 4.\n58 (0\n.0 7)\n3. 75\n(1 .0\n7) 3.\n74 (0\n.3 2)\n0. 0(\n0. 0)\n3. 62\n(0 .9\n7) 7.\n69 (0\n.8 8)\n3. 41\n(0 .4\n7) 4.\n51 (0\n.0 )\n6. 42\n(0 .5\n6) 4.\n85 (0\n.3 9)\n3. 04\n(0 .4\n1) 4.\n64 (0\n.3 5)\n8. 82\n(0 .2\n1) 5.\n37 (0\n.3 5)\n4. 48\n(0 .4 7) am az on 6. 5( 0. 62 ) 6. 2( 0. 0) 5. 52 (0 .1 8) 5. 24 (0 .2 6) 5. 88 (0 .1 1) 6. 36 (0 .4 1) 5. 68 (0 .1 8) 5. 6( 1. 1) 5. 28 (0 .3 6) 5. 04 (0 .1 7) 6. 04 (0 .0 9) 5. 84 (0 .1 7) 4. 4( 0. 14 ) 4. 04 (1 .8 9) 3. 6( 0. 0) 6. 0( 0. 51 ) 4. 32 (0 .8 7) 5. 0( 0. 79 ) 5. 8( 0. 0) 4. 56 (0 .6 2) 4. 08 (0 .4 4) 5. 28 (1 .2 2) 5. 8( 0. 0) 4. 84 (0 .4 3) 5. 2( 1. 89 ) 5. 12 (1 .2 7) an nt hy ro id 22 .2 8( 1. 08 ) 23 .6 (0 .4 2) 30 .6 4( 0. 21 ) 25 .0 2( 5. 33 ) 26 .6 3( 1. 11 ) 32 .4 3( 1. 56 ) 29 .4 8( 0. 21 ) 11 .6 5( 3. 16 ) 20 .0 4( 0. 48 ) 45 .6 2( 0. 57 ) 24 .4 9( 0. 08 ) 24 .0 4( 0. 34 ) 11 .9 5( 7. 71 ) 25 .9 2( 2. 39 ) 19 .7 (2 .3 8) 11 .8 (3 .4 6) 16 .6 3( 3. 02 ) 62 .9 6( 8. 09 ) 23 .7 8( 0. 0) 19 .1 4( 1. 14 ) 12 .6 2( 4. 17 ) 7. 12 (1 .0 1) 32 .4 (0 .8 4) 30 .6 4( 0. 31 ) 42 .5 1( 7. 86 ) 65 .6 2( 0.\n34 )\nba ck\ndo or\n50 .5\n6( 0.\n83 )\n2. 37\n(0 .6\n) 2.\n37 (0\n.6 )\n33 .1\n4( 15\n.3 5)\n1. 82\n(0 .6\n2) 1.\n47 (0\n.7 )\n47 .1\n2( 0.\n84 )\n12 .4\n(7 .9\n5) 44\n.9 2(\n1. 63\n) 1.\n55 (2\n.3 7)\n47 .4\n8( 1.\n47 )\n46 .7\n2( 1.\n29 )\n27 .0\n1( 7.\n12 )\n42 .8\n1( 17\n.5 3)\n2. 37\n(0 .6\n) 35\n.2 5(\n3. 99\n) 73\n.0 2(\n3. 41\n) 40\n.6 (1\n.8 2)\n46 .7\n7( 1.\n34 )\n45 .7\n1( 3.\n57 )\n2. 24\n(0 .5\n2) 2.\n5( 0.\n44 )\n47 .4\n9( 1.\n19 )\n45 .8\n6( 1.\n62 )\n44 .5\n8( 3.\n24 )\n51 .0\n(0 .6 2) br ea st w 86 .2 5( 2. 14 ) 94 .1 5( 1. 33 ) 92 .7 7( 1. 43 ) 6. 92 (4 .3 4) 93 .4 5( 1. 21 ) 90 .9 8( 1. 46 ) 92 .2 2( 0. 62 ) 91 .2 8( 4. 46 ) 19 .8 8( 6. 05 ) 92 .4 1( 1. 36 ) 88 .7 8( 1. 87 ) 91 .2 2( 1. 94 ) 66 .6 5( 7. 76 ) 51 .5 6( 9. 67 ) 74 .4 4( 3. 07 ) 78 .4 7( 7. 69 ) 62 .2 6( 6. 06 ) 86 .9 (4 .0 1) 88 .1 (5 .9 6) 84 .9 3( 7. 94 ) 60 .2 8( 3. 26 ) 33 .8 9( 1. 98 ) 56 .2 7( 5. 91 ) 90 .1 4( 0. 59 ) 78 .3 7( 1. 66 ) 70 .6 1( 4.\n17 )\nca m\npa ig\nn 37\n.0 7(\n0. 07\n) 40\n.3 8(\n0. 04\n) 39\n.3 6(\n0. 09\n) 14\n.8 1(\n6. 68\n) 38\n.1 2(\n0. 26\n) 31\n.8 8(\n0. 77\n) 35\n.0 7(\n0. 29\n) 14\n.2 6(\n6. 73\n) 19\n.7 3(\n0. 22\n) 41\n.7 2(\n2. 79\n) 36\n.6 9(\n0. 06\n) 36\n.7 5(\n0. 09\n) 19\n.1 9(\n3. 07\n) 18\n.2 4(\n3. 69\n) 10\n.5 6(\n0. 0)\n10 .6\n6( 3.\n35 )\n31 .7\n9( 0.\n89 )\n22 .0\n4( 4.\n71 )\n36 .8\n1( 0.\n0) 25\n.8 6(\n11 .7\n5) 29\n.7 9(\n0. 85\n) 11\n.1 6(\n0. 62\n) 37\n.3 5(\n1. 02\n) 33\n.7 9(\n0. 28\n) 30\n.5 7(\n3. 26\n) 40\n.4 3(\n0. 95 ) ca rd io 52 .7 (1 .6 3) 52 .9 5( 0. 25 ) 52 .6 1( 0. 65 ) 16 .7 (4 .0 7) 45 .0 (1 .0 9) 52 .0 5( 3. 7) 42 .6 1( 1. 61 ) 43 .3 (1 1. 04 ) 18 .3 (4 .0 7) 47 .1 6( 6. 31 ) 50 .4 5( 1. 02 ) 59 .8 9( 1. 54 ) 27 .2 7( 12 .7 1) 20 .6 8( 9. 22 ) 32 .1 6( 8. 77 ) 55 .2 3( 6. 18 ) 10 .3 4( 3. 1) 47 .9 5( 15 .1 ) 60 .6 8( 0. 25 ) 31 .7 (1 9. 7) 17 .1 6( 3. 27 ) 8. 41 (1 .8 6) 28 .4 1( 5. 45 ) 37 .2 7( 1. 64 ) 22 .6 1( 7. 64 ) 27 .1 6( 2. 96 ) ca rd io to co gr ap hy 31 .6 5( 3. 68 ) 35 .9 7( 3. 11 ) 49 .6 1( 0. 24 ) 27 .9 4( 1. 47 ) 31 .7 2( 0. 67 ) 40 .6 9( 2. 2) 32 .3 6( 0. 24 ) 42 .3 6( 11 .9 1) 26 .6 1( 1. 05 ) 28 .2 8( 0. 1) 38 .3 7( 0. 47 ) 44 .1 6( 0. 88 ) 27 .8 5( 6. 89 ) 24 .0 8( 1. 64 ) 26 .2 7( 3. 34 ) 38 .5 (7 .5 8) 17 .4 7( 1. 06 ) 31 .8 5( 3. 43 ) 45 .0 6( 0. 0) 38 .9 7( 11 .9 ) 20 .7 7( 2. 21 ) 21 .6 3( 1. 1) 34 .2 5( 2. 68 ) 31 .8 (0 .5 1) 26 .4 8( 4. 4) 26 .6 1( 1. 94 ) ce le ba 11 .7 5( 3. 2) 15 .0 (0 .4 6) 15 .0 3( 0. 53 ) 2. 62 (1 .5 1) 14 .1 8( 0. 52 ) 10 .2 4( 0. 4) 9. 57 (0 .4 ) 7. 77 (6 .6 1) 0. 53 (0 .2 8) 12 .1 4( 2. 95 ) 14 .8 9( 0. 62 ) 16 .4 9( 0. 69 ) 7. 51 (3 .7 9) 5. 11 (6 .1 7) 5. 01 (0 .6 5) 2. 12 (1 .8 6) 5. 69 (0 .3 5) 9. 6( 6. 98 ) 16 .7 4( 0. 85 ) 3. 8( 4. 37 ) 4. 48 (0 .7 8) 2. 7( 0. 42 ) 13 .9 2( 2. 97 ) 8. 7( 0. 56 ) 9. 37 (3 .1 7) 9. 87 (1 .0 1) ce ns us 6. 79 (0 .3 ) 6. 3( 0. 66 ) 6. 3( 0. 66 ) 1. 25 (0 .5 3) 5. 47 (0 .3 ) 5. 27 (0 .8 6) 6. 83 (0 .2 3) 7. 31 (5 .1 2) 3. 56 (0 .4 4) 15 .3 6( 3. 84 ) 6. 4( 0. 17 ) 6. 46 (0 .2 2) 6. 58 (2 .1 2) 9. 74 (2 .4 2) 6. 41 (0 .3 2) 10 .3 (2 .8 1) 10 .4 2( 0. 41 ) 5. 08 (0 .4 3) 6. 44 (0 .3 2) 8. 14 (3 .3 ) 7. 4( 0. 88 ) 6. 14 (0 .3 8) 6. 49 (0 .1 3) 8. 24 (0 .3 7) 7. 67 (1 .3 4) 5. 23 (0 .4 6) co ve r 1. 88 (0 .3 2) 11 .9 3( 1. 63 ) 17 .2 8( 1. 54 ) 5. 02 (2 .7 ) 6. 27 (1 .2 9) 7. 92 (2 .7 9) 9. 41 (1 .5 5) 9. 89 (4 .9 2) 4. 88 (1 .0 4) 1. 83 (0 .5 7) 7. 8( 1. 69 ) 7. 34 (1 .6 4) 2. 13 (2 .2 ) 9. 06 (9 .0 9) 6. 72 (5 .3 5) 0. 0( 0. 0) 3. 82 (0 .4 3) 1. 79 (1 .8 9) 7. 29 (1 .5 9) 18 .1 2( 32 .3 ) 1. 43 (0 .7 ) 0. 94 (0 .3 4) 7. 83 (1 .2 4) 9. 34 (1 .3 ) 6. 67 (2 .2 7) 3. 35 (1 .8 2) do no rs 13 .6 (1 .2 8) 26 .2 6( 0. 84 ) 28 .4 7( 0. 97 ) 9. 91 (2 .8 ) 6. 04 (1 .8 8) 9. 61 (1 .1 3) 17 .0 3( 0. 4) 20 .4 9( 30 .6 6) 10 .9 2( 1. 55 ) 18 .6 8( 3. 6) 16 .9 8( 0. 52 ) 19 .2 9( 0. 85 ) 10 .6 7( 6. 21 ) 10 .5 5( 13 .4 1) 9. 9( 2. 66 ) 1. 74 (1 .2 3) 10 .6 6( 1. 84 ) 20 .3 9( 7. 89 ) 20 .1 4( 0. 67 ) 13 .0 6( 13 .9 3) 12 .0 3( 1. 73 ) 5. 89 (0 .4 4) 11 .9 3( 3. 41 ) 18 .8 4( 0. 25 ) 16 .8 2( 7. 1) 10 .0 6( 4. 6) fa ul t 48 .3 3( 3. 24 ) 29 .9 (0 .3 4) 31 .5 (0 .3 5) 42 .2 9( 1. 55 ) 33 .4 (7 .3 3) 40 .4 8( 1. 25 ) 52 .3 6( 1. 16 ) 34 .0 (2 .0 4) 41 .1 6( 1. 87 ) 34 .8 (1 .6 1) 41 .2 5( 0. 36 ) 33 .8 5( 0. 57 ) 34 .5 (5 .6 ) 38 .1 9( 4. 34 ) 48 .5 3( 2. 68 ) 38 .7 5( 4. 26 ) 47 .8 8( 1. 31 ) 31 .2 3( 3. 9) 34 .2 9( 0. 07 ) 32 .2 7( 7. 43 ) 51 .0 (1 .1 7) 35 .2 5( 1. 51 ) 40 .9 8( 1. 12 ) 52 .9 3( 0. 74 ) 42 .4 1( 4. 08 ) 44 .1 (2 .2 3) fr au d 24 .2 2( 7. 07 ) 34 .4 3( 4. 0) 30 .7 1( 3. 36 ) 0. 0( 0. 0) 32 .5 6( 4. 67 ) 25 .2 5( 6. 56 ) 22 .9 1( 7. 37 ) 27 .1 3( 6. 03 ) 0. 0( 0. 0) 52 .0 (3 .4 2) 13 .7 7( 0. 98 ) 23 .7 2( 6. 22 ) 13 .8 3( 17 .6 1) 37 .0 6( 22 .6 8) 0. 0( 0. 0) 31 .5 3( 34 .1 9) 14 .3 4( 6. 4) 51 .2 1( 16 .9 1) 23 .7 8( 6. 62 ) 23 .4 3( 8. 04 ) 24 .8 7( 6. 91 ) 0. 0( 0. 0) 23 .9 4( 6. 15 ) 18 .8 6( 8. 76 ) 23 .1 1( 11 .9 5) 75 .5 1( 5. 1) gl as s 10 .7 4( 6. 76 ) 7. 98 (6 .5 8) 11 .7 9( 6. 31 ) 16 .6 1( 9. 8) 14 .5 9( 10 .4 2) 11 .7 9( 6. 31 ) 14 .0 5( 3. 69 ) 6. 08 (7 .3 6) 16 .6 1( 9. 8) 3. 9( 5. 35 ) 11 .7 9( 6. 31 ) 11 .7 9( 6. 31 ) 8. 81 (9 .8 7) 11 .8 4( 7. 69 ) 15 .4 8( 13 .1 4) 7. 98 (6 .5 8) 10 .6 3( 6. 85 ) 5. 28 (6 .1 2) 14 .0 5( 3. 69 ) 9. 91 (5 .6 2) 15 .9 5( 3. 2) 4. 25 (3 .6 3) 8. 27 (8 .2 2) 14 .0 5( 3. 69 ) 10 .3 9( 8. 51 ) 13 .8 5( 3. 56 ) he pa tit is 25 .9 3( 18 .1 5) 39 .7 3( 4. 96 ) 28 .8 9( 4. 2) 18 .7 9( 11 .1 6) 31 .6 7( 8. 79 ) 18 .1 8( 6. 29 ) 23 .5 8( 9. 7) 26 .1 7( 15 .0 4) 18 .0 4( 8. 25 ) 33 .8 8( 9. 47 ) 25 .6 2( 3. 91 ) 35 .0 4( 3. 78 ) 25 .2 9( 13 .5 7) 7. 06 (1 5. 78 ) 19 .6 6( 2. 71 ) 23 .0 9( 13 .0 3) 19 .5 (7 .3 4) 25 .4 5( 12 .8 3) 34 .2 3( 2. 12 ) 31 .6 2( 7. 7) 5. 97 (6 .7 ) 14 .7 8( 3. 71 ) 7. 03 (5 .0 5) 19 .9 3( 9. 87 ) 17 .9 1( 13 .2 7) 26 .9 6( 12 .4 3) ht tp 2. 79 (2 .9 ) 2. 05 (1 .2 9) 2. 05 (1 .2 9) 5. 03 (2 .0 1) 2. 05 (1 .2 9) 84 .6 1( 22 .9 2) 2. 88 (0 .9 7) 0. 64 (0 .6 7) 5. 03 (2 .0 1) 86 .3 1( 2. 44 ) 2. 48 (1 .0 1) 7. 35 (5 .4 8) 14 .8 5( 24 .3 7) 1. 84 (1 .3 6) 0. 41 (0 .6 6) 1. 77 (1 .6 7) 2. 86 (1 .3 8) 1. 85 (0 .9 1) 3. 54 (3 .0 5) 19 .7 (4 4. 04 ) 2. 49 (1 .3 1) 0. 43 (0 .5 9) 37 .7 3( 38 .6 5) 3. 1( 1. 01 ) 7. 85 (1 4. 11 ) 13 .9 (3 0. 45 ) im db 2. 0( 0. 0) 1. 0( 0. 0) 2. 6( 0. 0) 3. 88 (0 .3 ) 1. 4( 0. 0) 2. 36 (0 .2 2) 2. 04 (0 .1 7) 3. 0( 0. 82 ) 3. 92 (0 .4 1) 2. 2( 0. 37 ) 2. 04 (0 .0 9) 2. 2( 0. 0) 4. 72 (1 .0 7) 4. 04 (2 .7 2) 4. 88 (0 .6 3) 2. 48 (0 .3 ) 4. 76 (1 .1 6) 5. 12 (0 .6 3) 2. 2( 0. 0) 3. 44 (0 .3 3) 5. 76 (0 .2 6) 4. 6( 1. 01 ) 2. 2( 0. 0) 1. 84 (0 .1 7) 3. 36 (1 .1 1) 2. 8( 1. 09 ) in te rn et ad s 34 .3 1( 0. 14 ) 44 .7 3( 0. 65 ) 44 .5 1( 0. 75 ) 18 .1 (4 .1 ) 47 .0 7( 0. 12 ) 43 .5 3( 4. 34 ) 34 .0 8( 0. 36 ) 26 .0 3( 4. 53 ) 28 .4 2( 2. 62 ) 34 .4 (5 .0 8) 34 .7 8( 0. 19 ) 33 .2 6( 1. 85 ) 20 .9 8( 2. 99 ) 28 .7 5( 5. 25 ) 20 .1 6( 1. 58 ) 33 .8 6( 0. 73 ) 23 .5 3( 1. 97 ) 32 .5 (1 .7 9) 34 .2 4( 0. 0) 40 .0 (2 .1 5) 31 .4 1( 2. 66 ) 18 .2 6( 1. 43 ) 34 .4 (0 .1 5) 35 .7 1( 2. 24 ) 32 .1 2( 5. 24 ) 37 .2 3( 3. 06 ) io no sp he re 80 .9 2( 3. 94 ) 56 .7 4( 3. 96 ) 51 .3 8( 3. 13 ) 76 .4 (3 .4 1) 31 .3 1( 2. 5) 65 .4 9( 4. 15 ) 82 .6 6( 2. 03 ) 62 .2 (1 .4 2) 75 .5 (3 .0 5) 87 .1 2( 0. 77 ) 72 .5 7( 1. 34 ) 58 .5 4( 2. 0) 49 .3 7( 4. 65 ) 31 .9 4( 10 .9 9) 62 .0 9( 9. 36 ) 64 .3 5( 2. 95 ) 43 .4 9( 4. 11 ) 74 .2 6( 1. 85 ) 57 .9 4( 2. 22 ) 77 .3 (4 .4 3) 71 .2 3( 3. 21 ) 34 .9 2( 1. 74 ) 55 .7 2( 3. 28 ) 84 .0 3( 1. 62 ) 54 .9 7( 9. 47 ) 74 .6 1( 4. 29 ) la nd sa t 20 .8 4( 1. 46 ) 17 .9 3( 0. 05 ) 15 .8 7( 0. 19 ) 26 .9 3( 0. 92 ) 26 .3 3( 0. 36 ) 21 .9 8( 2. 12 ) 30 .4 4( 0. 69 ) 19 .3 8( 4. 68 ) 26 .9 8( 0. 93 ) 31 .8 8( 0. 27 ) 19 .3 2( 0. 17 ) 19 .5 9( 0. 44 ) 24 .5 5( 3. 55 ) 35 .0 (2 .7 ) 28 .3 (0 .4 3) 17 .2 1( 7. 06 ) 41 .5 3( 0. 95 ) 16 .8 (0 .8 2) 24 .4 4( 0. 29 ) 20 .3 2( 4. 46 ) 36 .8 5( 0. 68 ) 20 .9 6( 0. 62 ) 18 .8 (1 .7 ) 29 .7 1( 0. 72 ) 18 .9 5( 6. 6) 17 .9 (1 .8 8) le tte r 24 .0 (2 .9 4) 3. 8( 0. 45 ) 8. 6( 0. 55 ) 41 .8 (3 .3 5) 6. 8( 0. 45 ) 8. 0( 1. 41 ) 26 .8 (1 .4 8) 9. 4( 1. 82 ) 39 .8 (3 .4 9) 17 .4 (1 .5 2) 14 .0 (1 .2 2) 7. 6( 0. 55 ) 11 .4 (3 .3 6) 11 .4 (2 .9 7) 27 .6 (5 .5 ) 10 .6 (2 .4 1) 25 .0 (2 .9 2) 20 .0 (6 .2 ) 7. 8( 0. 45 ) 17 .0 (1 0. 3) 33 .8 (1 .9 2) 6. 4( 1. 14 ) 39 .4 (3 .0 5) 30 .8 (1 .3 ) 21 .4 (4 .8 3) 35 .2 (1 .9 2) ly m ph og ra ph y 83 .7 1( 6. 32 ) 79 .4 3( 6. 0) 79 .4 3( 6. 0) 6. 77 (1 0. 14 ) 80 .7 6( 7. 36 ) 87 .2 3( 7. 7) 81 .0 4( 7. 69 ) 42 .0 3( 41 .1 5) 10 .0 1( 10 .0 2) 79 .8 5( 4. 1) 83 .7 (7 .6 9) 83 .7 (7 .6 9) 49 .0 6( 14 .4 6) 23 .8 3( 9. 68 ) 40 .8 2( 16 .7 9) 81 .4 3( 7. 54 ) 27 .6 1( 15 .8 8) 43 .0 7( 16 .6 ) 84 .2 8( 7. 45 ) 41 .4 3( 33 .6 4) 54 .4 8( 9. 76 ) 5. 79 (2 .4 5) 63 .7 7( 17 .8 9) 75 .9 1( 9. 2) 35 .9 8( 24 .0 8) 41 .4 7( 13 .5 7) m ag ic .g am m a 56 .1 2( 0. 17 ) 49 .6 (0 .0 4) 46 .2 6( 0. 06 ) 53 .4 5( 0. 79 ) 50 .4 (0 .1 7) 54 .5 2( 0. 78 ) 62 .2 3( 0. 21 ) 49 .4 9( 1. 01 ) 51 .2 9( 0. 33 ) 49 .7 6( 0. 13 ) 52 .6 3( 0. 07 ) 48 .6 4( 0. 12 ) 43 .0 9( 2. 79 ) 45 .7 3( 1. 12 ) 57 .7 9( 0. 53 ) 28 .9 9( 3. 9) 51 .6 5( 1. 03 ) 58 .0 7( 4. 37 ) 48 .8 8( 0. 0) 42 .0 7( 3. 04 ) 47 .8 4( 0. 57 ) 35 .4 3( 0. 61 ) 59 .6 5( 1. 72 ) 63 .2 1( 0. 19 ) 62 .0 2( 2. 71 ) 62 .8 7( 1. 8) m am m og ra ph y 22 .9 8( 6. 74 ) 43 .0 (0 .1 7) 42 .8 5( 0. 34 ) 12 .6 9( 4. 54 ) 13 .1 5( 1. 47 ) 24 .6 2( 3. 43 ) 27 .3 8( 1. 4) 30 .0 8( 4. 5) 18 .0 (0 .7 4) 1. 08 (0 .4 2) 27 .3 1( 0. 0) 25 .8 5( 1. 17 ) 14 .5 4( 16 .3 9) 2. 08 (0 .8 ) 18 .3 1( 2. 15 ) 9. 08 (3 .3 2) 4. 77 (2 .2 4) 8. 08 (4 .5 3) 25 .7 7( 0. 0) 21 .1 5( 19 .4 9) 12 .7 7( 2. 31 ) 2. 31 (1 .2 2) 19 .6 9( 3. 43 ) 25 .3 1( 2. 42 ) 8. 92 (3 .0 9) 20 .1 5( 0. 84 ) m ni st 40 .5 (1 .7 3) 0. 0( 0. 0) 0. 0( 0. 0) 27 .6 3( 1. 05 ) 11 .2 9( 0. 39 ) 32 .2 (5 .2 4) 42 .2 3( 0. 48 ) 17 .8 3( 7. 37 ) 27 .0 (1 .2 6) 29 .1 4( 5. 43 ) 38 .7 7( 0. 39 ) 38 .0 3( 1. 01 ) 25 .1 4( 5. 65 ) 30 .5 1( 11 .9 3) 29 .8 3( 1. 19 ) 33 .0 6( 4. 29 ) 28 .0 (2 .2 2) 26 .4 6( 10 .7 1) 38 .6 (0 .0 6) 25 .9 1( 5. 52 ) 0. 0( 0. 0) 9. 63 (1 .3 8) 41 .0 3( 1. 46 ) 42 .1 1( 0. 42 ) 30 .4 3( 5. 92 ) 37 .7 7( 3. 14 ) m us k 10 0. 0( 0. 0) 40 .0 (3 .2 1) 47 .8 4( 2. 26 ) 15 .4 6( 7. 61 ) 97 .9 4( 0. 0) 89 .6 9( 12 .2 8) 61 .0 3( 8. 73 ) 78 .5 6( 18 .0 1) 13 .8 1( 7. 09 ) 96 .0 8( 4. 02 ) 10 0. 0( 0. 0) 98 .1 4( 0. 46 ) 49 .2 8( 25 .0 8) 11 .5 5( 13 .0 9) 24 .7 4( 4. 43 ) 99 .5 9( 0. 92 ) 10 .3 1( 3. 5) 37 .1 1( 33 .0 5) 98 .9 7( 0. 0) 10 0. 0( 0. 0) 24 .7 4( 8. 05 ) 3. 71 (1 .1 8) 94 .8 5( 3. 86 ) 40 .0 (3 .6 ) 9. 69 (5 .2 9) 50 .5 2( 19 .5 2) op td ig its 0. 0( 0. 0) 0. 0( 0. 0) 0. 0( 0. 0) 4. 13 (1 .2 8) 24 .1 3( 0. 56 ) 2. 4( 1. 21 ) 0. 0( 0. 0) 1. 07 (2 .0 3) 4. 67 (1 .2 5) 0. 0( 0. 0) 0. 0( 0. 0) 0. 0( 0. 0) 0. 13 (0 .3 ) 0. 27 (0 .3 7) 0. 4( 0. 6) 0. 0( 0. 0) 2. 0( 1. 15 ) 0. 0( 0. 0) 0. 0( 0. 0) 0. 27 (0 .6 ) 0. 0( 0. 0) 3. 33 (1 .0 5) 0. 27 (0 .3 7) 0. 0( 0. 0) 0. 93 (1 .0 1) 0. 0( 0. 0) pa ge bl oc ks 50 .5 4( 5. 8) 33 .5 7( 0. 29 ) 43 .2 5( 0. 33 ) 36 .5 5( 2. 17 ) 32 .5 9( 2. 96 ) 40 .8 6( 1. 61 ) 53 .7 6( 0. 79 ) 40 .9 (7 .5 2) 32 .1 2( 2. 58 ) 57 .3 3( 0. 51 ) 49 .2 5( 0. 61 ) 47 .4 1( 1. 28 ) 32 .1 2( 6. 85 ) 34 .2 4( 11 .3 ) 61 .7 6( 2. 81 ) 35 .9 2( 4. 9) 30 .7 8( 3. 33 ) 50 .5 5( 4. 78 ) 47 .2 5( 0. 0) 35 .9 6( 11 .1 2) 39 .9 6( 3. 56 ) 10 .5 1( 0. 79 ) 47 .9 6( 2. 99 ) 51 .1 (1 .0 6) 49 .1 4( 8. 96 ) 52 .6 3( 4. 1) pe nd ig its 24 .3 6( 8. 14 ) 26 .0 3( 2. 51 ) 35 .2 6( 0. 45 ) 8. 08 (1 .7 9) 29 .7 4( 0. 73 ) 32 .0 5( 3. 98 ) 10 .5 1( 3. 13 ) 27 .8 2( 6. 58 ) 8. 08 (1 .3 3) 8. 21 (4 .2 4) 32 .8 2( 1. 31 ) 32 .8 2( 0. 95 ) 6. 54 (1 0. 03 ) 1. 41 (1 .0 5) 2. 05 (1 .0 5) 13 .2 1( 12 .5 3) 5. 77 (0 .6 4) 4. 74 (3 .7 5) 33 .7 2( 0. 57 ) 20 .9 (1 5. 89 ) 5. 51 (2 .4 2) 2. 31 (1 .3 3) 6. 15 (1 .3 3) 11 .6 7( 1. 66 ) 5. 0( 1. 6) 4. 23 (0 .9 7) pi m a 49 .9 9( 3. 12 ) 49 .6 6( 1. 45 ) 46 .3 6( 2. 07 ) 41 .9 9( 2. 18 ) 54 .1 4( 2. 09 ) 51 .1 4( 2. 13 ) 55 .9 3( 1. 78 ) 40 .9 1( 6. 18 ) 40 .9 4( 2. 95 ) 52 .2 2( 4. 15 ) 48 .7 2( 1. 81 ) 51 .4 8( 3. 68 ) 38 .5 3( 0. 9) 35 .0 2( 3. 2) 38 .8 8( 9. 78 ) 46 .3 3( 14 .4 9) 36 .5 (3 .0 2) 45 .6 9( 5. 31 ) 53 .3 8( 2. 0) 41 .3 7( 6. 13 ) 33 .2 3( 4. 6) 36 .3 2( 3. 77 ) 40 .4 6( 3. 48 ) 54 .9 8( 2. 08 ) 43 .8 3( 4. 94 ) 44 .0 9( 2. 05 ) sa te lli te 57 .3 6( 3. 6) 48 .1 (0 .0 7) 44 .9 2( 0. 04 ) 37 .3 6( 0. 59 ) 57 .4 4( 0. 48 ) 55 .8 4( 0. 93 ) 52 .6 8( 0. 29 ) 50 .1 1( 3. 78 ) 37 .5 7( 0. 91 ) 68 .6 2( 0. 13 ) 53 .7 6( 0. 27 ) 48 .2 7( 0. 12 ) 52 .5 1( 2. 94 ) 37 .7 6( 4. 88 ) 42 .8 5( 0. 81 ) 52 .0 8( 3. 55 ) 48 .0 8( 1. 33 ) 51 .1 6( 0. 94 ) 56 .7 2( 0. 12 ) 47 .0 3( 11 .0 1) 53 .0 3( 1. 93 ) 31 .1 5( 0. 71 ) 58 .8 6( 1. 28 ) 50 .8 3( 0. 39 ) 39 .8 6( 6. 18 ) 57 .8 7( 3. 05 ) sa tim ag e2 94 .0 1( 0. 7) 74 .3 7( 0. 63 ) 61 .9 7( 0. 0) 10 .1 4( 6. 78 ) 70 .1 4( 0. 63 ) 86 .2 (1 .1 8) 59 .7 2( 13 .0 5) 80 .8 5( 9. 37 ) 10 .1 4( 5. 58 ) 61 .9 7( 3. 59 ) 92 .9 6( 0. 0) 83 .1 (0 .0 ) 32 .1 1( 29 .4 7) 6. 76 (4 .3 9) 16 .6 2( 2. 89 ) 90 .4 2( 0. 63 ) 14 .3 7( 5. 49 ) 48 .4 5( 7. 29 ) 73 .5 2( 3. 05 ) 62 .2 5( 27 .8 8) 35 .2 1( 7. 78 ) 1. 13 (0 .6 3) 70 .7 (6 .2 5) 44 .5 1( 7. 49 ) 10 .7 (6 .5 ) 16 .9 (4 .3 4) sh ut tle 28 .4 2( 4. 28 ) 95 .1 5( 0. 28 ) 86 .8 9( 0. 22 ) 9. 11 (3 .8 6) 93 .3 (0 .8 7) 94 .6 3( 1. 26 ) 19 .5 6( 0. 82 ) 15 .6 (2 1. 79 ) 12 .8 3( 0. 91 ) 74 .3 3( 0. 1) 95 .5 8( 0. 01 ) 95 .0 7( 0. 06 ) 41 .8 9( 12 .6 5) 17 .6 2( 11 .2 5) 6. 52 (0 .0 ) 14 .0 2( 26 .4 ) 14 .0 1( 4. 47 ) 37 .4 9( 13 .2 9) 95 .1 (0 .0 1) 87 .3 3( 13 .3 ) 67 .8 3( 34 .2 7) 7. 38 (0 .4 2) 84 .2 6( 9. 38 ) 21 .4 2( 0. 73 ) 28 .6 4( 15 .7 8) 68 .2 6( 12 .2 5) sk in 34 .0 1( 3. 92 ) 1. 59 (0 .1 9) 9. 54 (0 .1 6) 11 .6 5( 0. 68 ) 17 .5 9( 1. 08 ) 11 .9 4( 1. 79 ) 24 .6 1( 0. 49 ) 4. 33 (0 .6 2) 20 .7 7( 0. 42 ) 58 .8 7( 0. 39 ) 20 .6 4( 0. 57 ) 4. 04 (0 .6 2) 17 .8 9( 12 .3 6) 19 .3 7( 5. 17 ) 26 .7 3( 1. 97 ) 23 .7 5( 3. 12 ) 7. 95 (5 .4 9) 28 .4 8( 3. 24 ) 4. 85 (0 .2 8) 12 .1 (6 .5 2) 41 .8 2( 1. 72 ) 21 .0 1( 0. 35 ) 4. 58 (0 .5 8) 25 .8 4( 0. 42 ) 29 .0 8( 7. 43 ) 19 .4 9( 1. 75 ) sm tp 65 .7 (7 .6 2) 0. 0( 0. 0) 69 .5 (4 .4 3) 0. 0( 0. 0) 0. 0( 0. 0) 0. 0( 0. 0) 69 .5 9( 4. 42 ) 29 .3 5( 11 .4 8) 0. 0( 0. 0) 0. 0( 0. 0) 64 .1 6( 6. 16 ) 61 .5 6( 9. 44 ) 25 .3 7( 35 .1 ) 31 .7 5( 18 .3 4) 0. 0( 0. 0) 55 .1 7( 8. 18 ) 0. 0( 0. 0) 0. 0( 0. 0) 66 .8 8( 5. 67 ) 4. 71 (1 0. 52 ) 69 .5 9( 4. 42 ) 0. 0( 0. 0) 69 .5 (4 .4 3) 69 .5 9( 4. 42 ) 0. 0( 0. 0) 69 .5 (4 .4 3) sp am ba se 42 .3 8( 0. 79 ) 57 .4 (0 .1 4) 55 .2 6( 0. 12 ) 33 .2 7( 0. 68 ) 54 .8 4( 1. 12 ) 52 .0 2( 2. 18 ) 43 .1 4( 0. 36 ) 38 .6 3( 9. 33 ) 35 .8 4( 0. 67 ) 32 .2 (3 .3 3) 42 .5 3( 0. 18 ) 43 .0 6( 0. 94 ) 38 .7 5( 4. 74 ) 48 .7 2( 6. 76 ) 38 .2 7( 1. 59 ) 40 .3 1( 4. 87 ) 35 .2 4( 1. 82 ) 42 .9 8( 9. 33 ) 43 .6 7( 0. 03 ) 43 .5 9( 2. 82 ) 39 .0 8( 0. 97 ) 39 .5 9( 0. 83 ) 38 .9 6( 1. 34 ) 42 .0 8( 0. 75 ) 40 .9 6( 4. 31 ) 37 .9 2( 1. 84 ) sp ee ch 1. 64 (0 .0 ) 3. 28 (0 .0 ) 3. 28 (0 .0 ) 4. 92 (1 .1 6) 3. 61 (0 .7 3) 2. 95 (1 .3 7) 2. 62 (0 .9 ) 0. 98 (1 .4 7) 3. 61 (1 .8 ) 1. 97 (1 .3 7) 3. 28 (0 .0 ) 2. 95 (0 .7 3) 3. 61 (1 .8 ) 1. 64 (1 .6 4) 1. 97 (1 .3 7) 2. 3( 1. 47 ) 2. 95 (2 .9 3) 1. 31 (1 .3 7) 3. 28 (0 .0 ) 1. 97 (1 .8 ) 0. 66 (0 .9 ) 1. 64 (2 .3 2) 2. 95 (0 .7 3) 2. 95 (1 .3 7) 2. 3( 1. 87 ) 2. 62 (1 .8 7) st am ps 20 .3 8( 4. 44 ) 40 .4 1( 10 .3 7) 29 .0 2( 2. 31 ) 18 .2 5( 6. 21 ) 28 .9 7( 11 .9 1) 28 .4 9( 6. 49 ) 21 .0 3( 2. 83 ) 29 .6 2( 4. 76 ) 18 .4 8( 7. 14 ) 12 .2 4( 6. 41 ) 19 .8 7( 4. 68 ) 28 .5 5( 9. 12 ) 17 .3 1( 12 .5 9) 3. 28 (3 .8 7) 24 .7 7( 10 .9 ) 23 .6 6( 13 .5 1) 10 .1 8( 2. 55 ) 24 .3 4( 6. 13 ) 28 .7 1( 8. 69 ) 27 .6 2( 19 .0 1) 17 .5 3( 8. 05 ) 12 .2 9( 5. 74 ) 13 .9 7( 4. 72 ) 22 .6 8( 8. 21 ) 26 .2 2( 11 .6 9) 21 .1 6( 4. 12 ) th yr oi d 24 .1 9( 1. 39 ) 18 .0 6( 2. 45 ) 56 .5 6( 1. 8) 9. 03 (3 .5 3) 49 .4 6( 2. 94 ) 57 .4 2( 6. 25 ) 36 .5 6( 3. 88 ) 22 .5 8( 7. 01 ) 9. 46 (2 .0 7) 65 .5 9( 0. 0) 38 .0 6( 0. 59 ) 35 .2 7( 2. 45 ) 15 .7 (1 2. 78 ) 0. 86 (0 .9 ) 33 .7 6( 5. 25 ) 38 .9 2( 19 .7 2) 9. 89 (3 .0 8) 72 .6 9( 6. 39 ) 34 .4 1( 0. 0) 22 .5 8( 23 .2 6) 19 .1 4( 8. 31 ) 3. 01 (2 .0 7) 33 .9 8( 2. 36 ) 33 .3 3( 4. 02 ) 12 .0 4( 6. 73 ) 70 .7 5( 0. 48 ) ve rt eb ra l 4. 22 (1 .8 1) 0. 0( 0. 0) 12 .3 1( 2. 45 ) 9. 2( 5. 88 ) 3. 03 (1 .8 6) 3. 64 (1 .4 3) 4. 02 (1 .6 4) 1. 01 (2 .2 7) 9. 78 (6 .4 ) 0. 0( 0. 0) 3. 21 (1 .7 5) 0. 0( 0. 0) 8. 57 (5 .2 3) 4. 37 (3 .7 8) 6. 39 (5 .9 2) 6. 76 (5 .5 ) 7. 43 (4 .7 3) 3. 73 (4 .2 6) 0. 0( 0. 0) 1. 45 (3 .2 5) 5. 22 (2 .7 6) 11 .2 9( 3. 08 ) 8. 0( 4. 59 ) 2. 16 (2 .1 6) 9. 7( 7. 03 ) 7. 09 (3 .5 3) vo w el s 21 .5 (1 .9 1) 0. 8( 1. 79 ) 17 .2 (1 .1 ) 32 .8 (5 .7 6) 12 .4 (1 .6 7) 20 .0 (4 .6 9) 42 .4 (1 .6 7) 17 .6 (5 .3 7) 33 .6 (4 .7 7) 9. 6( 10 .8 1) 26 .4 (0 .8 9) 14 .0 (0 .0 ) 4. 0( 6. 16 ) 1. 6( 0. 89 ) 20 .8 (1 6. 47 ) 18 .4 (7 .8 ) 23 .6 (3 .5 8) 32 .4 (7 .2 7) 14 .0 (0 .0 ) 4. 8( 6. 57 ) 35 .2 (7 .4 3) 2. 8( 2. 28 ) 32 .4 (4 .3 4) 47 .6 (1 .6 7) 20 .0 (3 .4 6) 43 .6 (1 2. 2) w av ef or m 19 .2 5( 2. 22 ) 6. 0( 0. 0) 4. 0( 0. 0) 11 .8 (3 .7 7) 5. 2( 0. 84 ) 5. 2( 1. 79 ) 20 .0 (2 .5 5) 3. 4( 1. 14 ) 10 .4 (2 .0 7) 6. 4( 0. 89 ) 8. 6( 1. 34 ) 5. 2( 0. 45 ) 1. 8( 1. 1) 8. 2( 3. 56 ) 20 .2 (2 .8 6) 4. 4( 2. 7) 7. 0( 3. 16 ) 20 .2 (7 .2 9) 5. 0( 0. 0) 5. 8( 4. 92 ) 0. 4( 0. 55 ) 2. 4( 1. 14 ) 7. 8( 2. 17 ) 16 .0 (3 .9 4) 4. 4( 3. 78 ) 6. 0( 1. 0) w bc 57 .6 3( 5. 79 ) 78 .0 1( 3. 99 ) 78 .0 1( 3. 99 ) 0. 0( 0. 0) 65 .3 2( 5. 89 ) 89 .8 4( 2. 99 ) 74 .1 5( 5. 44 ) 80 .6 9( 5. 93 ) 9. 15 (6 .4 1) 70 .9 6( 16 .2 9) 75 .4 (1 3. 84 ) 89 .4 (2 .9 2) 32 .9 3( 22 .5 4) 3. 17 (4 .6 ) 36 .7 3( 4. 31 ) 63 .7 (2 .1 6) 22 .8 3( 9. 2) 43 .0 6( 11 .6 2) 86 .9 4( 4. 58 ) 61 .7 9( 11 .4 9) 60 .0 2( 20 .1 1) 2. 68 (1 .0 5) 69 .9 2( 12 .1 4) 65 .5 4( 12 .6 4) 31 .7 5( 23 .5 2) 20 .0 (9 .8 5) w db c 61 .4 6( 6. 99 ) 71 .2 6( 3. 22 ) 44 .5 6( 4. 03 ) 13 .5 7( 10 .6 6) 65 .0 9( 4. 62 ) 62 .4 9( 7. 74 ) 49 .0 9( 8. 46 ) 51 .9 (1 0. 17 ) 7. 64 (7 .1 5) 39 .5 2( 13 .6 6) 51 .5 (4 .7 4) 55 .4 1( 2. 24 ) 12 .0 9( 15 .1 5) 3. 65 (6 .4 2) 4. 68 (6 .4 8) 52 .5 6( 13 .8 8) 2. 3( 2. 13 ) 55 .2 5( 9. 82 ) 48 .3 5( 6. 06 ) 40 .6 1( 30 .1 3) 22 .1 3( 4. 93 ) 3. 23 (3 .4 7) 50 .3 7( 9. 42 ) 38 .9 3( 5. 39 ) 3. 65 (4 .5 4) 22 .4 4( 11 .8 8) w ilt 0. 39 (0 .3 2) 0. 78 (0 .0 ) 3. 11 (0 .0 ) 5. 06 (2 .9 6) 0. 23 (0 .2 1) 0. 78 (0 .3 9) 0. 39 (0 .0 ) 0. 31 (0 .3 3) 5. 99 (1 .3 4) 0. 0( 0. 0) 0. 16 (0 .2 1) 0. 31 (0 .1 7) 5. 37 (1 .9 7) 1. 32 (0 .3 5) 0. 39 (0 .0 ) 6. 23 (5 .0 8) 16 .1 9( 2. 0) 0. 0( 0. 0) 0. 39 (0 .0 ) 1. 17 (1 .1 ) 11 .6 7( 1. 83 ) 5. 45 (1 .3 2) 5. 99 (1 .4 7) 0. 31 (0 .1 7) 26 .4 6( 7. 67 ) 6. 85 (3 .3 7) w in e 11 .3 6( 22 .7 3) 35 .7 8( 11 .7 ) 11 .6 5( 4. 9) 0. 0( 0. 0) 49 .3 9( 7. 34 ) 14 .3 4( 7. 71 ) 0. 0( 0. 0) 15 .5 4( 13 .3 1) 0. 0( 0. 0) 66 .9 (1 1. 05 ) 3. 15 (4 .4 ) 22 .8 8( 16 .4 8) 5. 34 (8 .3 9) 12 .2 5( 10 .3 4) 8. 61 (8 .7 5) 20 .7 7( 22 .2 ) 2. 61 (3 .6 6) 5. 65 (8 .3 8) 24 .5 4( 10 .3 ) 11 .6 6( 15 .8 5) 0. 0( 0. 0) 7. 8( 2. 28 ) 3. 47 (7 .7 5) 0. 0( 0. 0) 0. 0( 0. 0) 4. 22 (5 .8 7) w pb c 18 .5 9( 2. 06 ) 18 .6 8( 2. 12 ) 13 .0 8( 2. 74 ) 15 .6 (3 .2 2) 22 .2 2( 4. 08 ) 17 .1 8( 4. 37 ) 17 .2 8( 4. 24 ) 19 .0 6( 5. 31 ) 15 .8 7( 3. 05 ) 23 .1 7( 4. 38 ) 17 .0 9( 1. 53 ) 15 .7 (3 .8 8) 15 .0 8( 4. 12 ) 23 .7 9( 4. 71 ) 22 .5 3( 6. 13 ) 16 .3 7( 5. 58 ) 19 .8 8( 3. 25 ) 19 .1 2( 5. 18 ) 14 .5 5( 2. 17 ) 21 .3 8( 4. 44 ) 22 .5 7( 2. 03 ) 22 .9 5( 2. 61 ) 22 .9 7( 4. 35 ) 18 .0 8( 2. 47 ) 23 .4 7( 4. 84 ) 17 .7 5( 3. 12 ) ye as t 31 .0 7( 0. 89 ) 25 .8 4( 0. 14 ) 31 .6 (0 .4 7) 31 .7 6( 1. 34 ) 28 .4 4( 1. 1) 27 .1 4( 1. 05 ) 27 .7 3( 1. 13 ) 31 .3 2( 4. 59 ) 30 .4 9( 0. 89 ) 27 .1 8( 1. 93 ) 27 .4 2( 0. 37 ) 27 .7 3( 0. 65 ) 34 .2 8( 5. 12 ) 34 .2 4( 3. 79 ) 23 .2 3( 3. 03 ) 32 .8 2( 4. 66 ) 31 .1 6( 1. 58 ) 29 .4 3( 5. 7) 26 .6 3( 0. 0) 30 .9 7( 4. 8) 33 .2 1( 1. 38 ) 34 .6 7( 2. 33 ) 32 .5 (0 .7 7) 28 .4 8( 1. 14 ) 27 .6 1( 3. 09 ) 30 .3 (2 .0 9) ye lp 8. 75 (0 .5 7) 10 .6 (0 .0 ) 8. 48 (0 .1 1) 10 .6 (0 .6 9) 9. 64 (0 .0 9) 9. 2( 0. 66 ) 9. 0( 0. 14 ) 8. 84 (1 .6 ) 10 .5 6( 0. 74 ) 6. 68 (0 .2 3) 10 .2 8( 0. 11 ) 9. 96 (0 .0 9) 3. 52 (1 .2 9) 7. 0( 2. 77 ) 4. 76 (0 .6 1) 9. 6( 0. 68 ) 4. 48 (0 .6 3) 6. 24 (0 .8 ) 9. 88 (0 .1 8) 8. 48 (1 .5 9) 2. 28 (0 .2 3) 4. 92 (0 .5 8) 10 .1 2( 0. 18 ) 10 .5 6( 0. 54 ) 5. 56 (2 .9 9) 6. 84 (2 .3 1) M N IS TC 20 .2 4( 2. 17 ) 4. 68 (0 .0 ) 4. 68 (0 .0 ) 16 .0 7( 0. 81 ) 13 .4 9( 0. 4) 20 .0 9( 2. 68 ) 21 .3 6( 0. 33 ) 13 .3 (5 .2 7) 15 .9 1( 0. 75 ) 17 .4 5( 6. 62 ) 21 .2 2( 0. 1) 20 .5 2( 0. 6) 11 .4 3( 5. 53 ) 13 .8 2( 5. 09 ) 14 .5 (1 .5 1) 20 .9 2( 0. 85 ) 11 .6 (1 .1 9) 18 .3 2( 2. 53 ) 20 .6 4( 0. 01 ) 20 .2 1( 4. 33 ) 21 .8 6( 0. 75 ) 5. 03 (0 .9 7) 20 .9 8( 0. 29 ) 21 .6 4( 0. 41 ) 16 .1 9( 4. 5) 19 .5 5( 1. 53 ) Fa sh io nM N IS T 36 .0 4( 1. 66 ) 5. 11 (0 .0 ) 5. 11 (0 .0 ) 26 .1 3( 1. 3) 27 .0 (0 .4 1) 31 .9 7( 1. 87 ) 37 .1 4( 0. 55 ) 22 .3 7( 5. 46 ) 25 .6 4( 1. 34 ) 25 .9 2( 6. 95 ) 35 .9 5( 0. 2) 34 .6 7( 0. 81 ) 18 .0 5( 5. 62 ) 25 .5 6( 4. 96 ) 15 .6 (2 .3 4) 35 .5 (1 .1 8) 19 .6 (1 .6 9) 35 .1 6( 2. 21 ) 35 .0 2( 0. 0) 36 .0 1( 4. 63 ) 35 .0 3( 3. 75 ) 5. 03 (1 .1 9) 35 .1 4( 0. 58 ) 36 .3 9( 0. 73 ) 25 .7 7( 5. 23 ) 32 .0 7( 1. 97 ) C IF A R 10 12 .6 6( 0. 41 ) 7. 0( 0. 1) 7. 32 (0 .0 5) 15 .8 5( 0. 84 ) 8. 72 (0 .2 2) 10 .6 3( 0. 93 ) 12 .4 1( 0. 15 ) 11 .8 3( 2. 46 ) 15 .8 6( 0. 95 ) 9. 66 (2 .3 7) 12 .2 3( 0. 04 ) 12 .1 7( 0. 42 ) 7. 14 (1 .7 9) 9. 86 (1 .3 3) 7. 24 (1 .4 1) 12 .4 5( 0. 6) 9. 06 (1 .6 6) 10 .5 8( 1. 18 ) 12 .0 2( 0. 0) 13 .7 3( 1. 2) 13 .7 4( 0. 72 ) 5. 03 (1 .1 8) 12 .3 6( 0. 36 ) 12 .7 9( 0. 53 ) 9. 54 (1 .5 6) 12 .7 (1 .1 1) SV H N 10 .8 8( 0. 36 ) 4. 51 (0 .0 ) 4. 51 (0 .0 ) 11 .2 5( 0. 71 ) 7. 34 (0 .1 7) 9. 58 (0 .8 4) 11 .1 5( 0. 16 ) 8. 56 (1 .8 3) 11 .1 3( 0. 68 ) 8. 13 (2 .1 9) 10 .6 7( 0. 02 ) 10 .7 7( 0. 41 ) 7. 11 (1 .6 2) 9. 01 (1 .1 7) 7. 62 (1 .2 5) 10 .8 7( 0. 37 ) 8. 74 (1 .5 ) 10 .3 3( 0. 94 ) 10 .5 7( 0. 0) 11 .2 4( 0. 98 ) 11 .1 5( 0. 51 ) 4. 55 (0 .8 9) 10 .8 4( 0. 26 ) 11 .1 8( 0. 37 ) 9. 04 (1 .4 ) 10 .9 5( 0. 93 ) M V Te cA D 52 .2 4( 3. 53 ) 23 .4 8( 2. 58 ) 23 .4 8( 2. 58 ) 50 .0 (4 .2 ) 49 .6 6( 3. 09 ) 51 .8 5( 2. 86 ) 53 .5 2( 2. 49 ) 41 .8 3( 5. 88 ) 49 .8 7( 4. 19 ) 42 .7 7( 4. 81 ) 51 .2 1( 2. 77 ) 49 .1 5( 2. 72 ) 34 .5 7( 6. 48 ) 36 .4 (6 .7 3) 29 .3 4( 5. 21 ) 49 .8 1( 3. 81 ) 41 .1 7( 3. 92 ) 41 .6 3( 7. 25 ) 48 .8 5( 2. 81 ) 50 .4 9( 3. 83 ) 47 .1 3( 4. 38 ) 23 .4 1( 2. 81 ) 49 .7 2( 2. 66 ) 53 .3 6( 3. 12 ) 42 .8 5( 6. 45 ) 48 .2 8( 4. 45 ) 20 ne w s 5. 71 (1 .1 7) 4. 96 (0 .7 7) 5. 62 (0 .4 3) 10 .8 6( 2. 81 ) 4. 9( 1. 02 ) 5. 51 (1 .2 2) 6. 17 (0 .9 ) 5. 77 (1 .3 3) 10 .9 8( 2. 48 ) 7. 56 (2 .2 2) 5. 71 (1 .2 3) 5. 51 (1 .0 6) 4. 65 (1 .5 3) 5. 85 (1 .9 3) 5. 55 (2 .8 9) 5. 82 (0 .9 6) 7. 79 (2 .2 5) 5. 2( 2. 69 ) 5. 76 (0 .6 8) 5. 95 (1 .8 1) 6. 13 (1 .4 ) 5. 86 (2 .7 8) 5. 74 (0 .8 ) 6. 66 (1 .4 ) 5. 97 (3 .0 8) 6. 99 (2 .2 3) ag ne w s 7. 48 (0 .2 1) 6. 15 (0 .1 2) 5. 61 (0 .0 7) 17 .2 7( 1. 16 ) 6. 18 (0 .1 2) 6. 57 (0 .3 8) 9. 95 (0 .3 ) 7. 7( 0. 98 ) 17 .1 4( 1. 12 ) 5. 38 (0 .1 6) 7. 03 (0 .1 ) 6. 37 (0 .1 ) 5. 46 (2 .2 6) 5. 61 (1 .6 9) 5. 82 (0 .5 8) 6. 85 (0 .6 2) 8. 11 (0 .7 8) 4. 54 (0 .8 5) 6. 4( 0. 0) 12 .1 4( 2. 36 ) 7. 51 (0 .3 6) 4. 84 (0 .9 8) 6. 49 (0 .0 8) 10 .4 2( 0. 36 ) 7. 08 (3 .0 4) 9. 02 (2 .0 5)\nTa bl\ne 18\n:A ve\nra ge\nA U\nC PR\nan d\nst an\nda rd\nde vi\nat io\nns ov\ner fiv\ne se\ned s\nfo rt\nhe un\nsu pe\nrv is\ned se\ntti ng\non A\nD B\nen ch\n.\nC B\nL O\nF C\nO PO\nD E\nC O\nD Fe\nat ur\neB ag\ngi ng\nH B\nO S\nIF or\nes t\nkN N\nL O\nD A\nL O\nF M\nC D\nO C\nSV M\nPC A\nD A\nG M\nM D\nee pS\nV D\nD D\nR O\nC C\nG O\nA D\nIC L\nPl an\nar Fl\now VA\nE G\nA N\nom al\ny SL\nA D\nD IF\nD D\nPM D\nT E\n-N P\nD T\nE -I\nG D\nT E\n-C\nal oi\n3. 74\n(0 .0\n7) 3.\n13 (0\n.0 )\n3. 29\n(0 .0\n) 10\n.3 6(\n0. 45\n) 3.\n38 (0\n.0 3)\n3. 39\n(0 .0\n3) 4.\n76 (0\n.0 2)\n3. 27\n(0 .2\n9) 9.\n69 (0\n.2 8)\n3. 22\n(0 .0\n5) 3.\n92 (0\n.1 4)\n3. 72\n(0 .0\n3) 3.\n31 (0\n.2 6)\n3. 44\n(0 .2\n7) 3.\n04 (0\n.0 )\n3. 28\n(0 .2\n3) 4.\n6( 0.\n43 )\n3. 23\n(0 .1\n) 3.\n7( 0.\n0) 4.\n38 (0\n.2 9)\n3. 65\n(0 .1\n) 3.\n06 (0\n.1 5)\n3. 59\n(0 .0\n2) 5.\n55 (0\n.0 2)\n3. 95\n(0 .1\n1) 3.\n28 (0\n.0 7)\nam az\non 6.\n06 (0\n.0 6)\n5. 96\n(0 .0\n1) 5.\n5( 0.\n01 )\n5. 8(\n0. 11\n) 5.\n87 (0\n.0 2)\n5. 83\n(0 .0\n9) 6.\n22 (0\n.0 1)\n5. 44\n(0 .4\n3) 5.\n79 (0\n.1 3)\n6. 21\n(0 .0\n4) 5.\n89 (0\n.0 1)\n5. 69\n(0 .0\n2) 4.\n94 (0\n.2 5)\n4. 6(\n0. 31\n) 5.\n0( 0.\n0) 5.\n83 (0\n.2 1)\n5. 23\n(0 .1\n6) 5.\n04 (0\n.2 )\n5. 69\n(0 .0\n) 5.\n61 (0\n.1 1)\n5. 08\n(0 .0\n4) 5.\n21 (0\n.1 8)\n5. 71\n(0 .0\n1) 6.\n22 (0\n.0 8)\n5. 49\n(0 .4\n) 5.\n72 (0\n.5 4)\nan nt\nhy ro\nid 16\n.9 4(\n0. 78\n) 17\n.4 3(\n0. 19\n) 27\n.2 1(\n0. 44\n) 20\n.5 5(\n4. 61\n) 22\n.7 9(\n0. 86\n) 31\n.2 3(\n3. 56\n) 22\n.4 1(\n0. 47\n) 9.\n8( 2.\n71 )\n16 .3\n3( 0.\n53 )\n50 .2\n6( 0.\n93 )\n18 .7\n5( 0.\n28 )\n19 .5\n5( 1.\n07 )\n10 .9\n(5 .0\n8) 19\n.2 4(\n1. 59\n) 18\n.5 5(\n2. 55\n) 13\n.1 2(\n3. 87\n) 12\n.2 9(\n1. 66\n) 65\n.4 4(\n9. 63\n) 19\n.1 6(\n0. 01\n) 12\n.4 4(\n0. 59\n) 13\n.2 1(\n3. 3)\n7. 47\n(0 .3\n) 29\n.7 4(\n2. 36\n) 22\n.8 2(\n0. 34\n) 38\n.0 3(\n6. 2)\n67 .0\n1( 0.\n84 )\nba ck\ndo or\n54 .6\n5( 1.\n42 )\n2. 48\n(0 .0\n5) 2.\n48 (0\n.0 5)\n21 .6\n8( 6.\n06 )\n5. 15\n(0 .0\n9) 4.\n54 (0\n.7 2)\n47 .9\n2( 1.\n45 )\n10 .0\n8( 7.\n77 )\n35 .8\n(2 .4\n3) 12\n.1 5(\n6. 59\n) 53\n.3 8(\n1. 03\n) 53\n.1 4(\n1. 28\n) 24\n.9 9(\n7. 1)\n37 .2\n3( 15\n.5 2)\n2. 48\n(0 .0\n5) 34\n.6 9(\n3. 95\n) 71\n.7 (1\n.3 )\n33 .6\n1( 8.\n67 )\n52 .5\n7( 1.\n21 )\n54 .0\n5( 6.\n18 )\n2. 48\n(0 .0\n5) 2.\n5( 0.\n12 )\n52 .0\n1( 0.\n96 )\n47 .2\n9( 1.\n45 )\n43 .8\n4( 3.\n25 )\n48 .0\n7( 1.\n28 )\nbr ea\nst w\n88 .9\n9( 3.\n32 )\n98 .8\n7( 0.\n33 )\n98 .2\n4( 0.\n39 )\n28 .4\n4( 1.\n29 )\n95 .4\n4( 1.\n0) 95\n.6 4(\n1. 34\n) 93\n.2 (1\n.8 5)\n95 .5\n(3 .1\n5) 29\n.6 5(\n2. 09\n) 96\n.2 3(\n1. 35\n) 89\n.6 9(\n1. 55\n) 94\n.5 5(\n0. 9)\n66 .0\n4( 8.\n57 )\n48 .2\n(9 .3\n6) 77\n.5 7(\n4. 69\n) 82\n.5 9(\n7. 94\n) 63\n.4 5(\n5. 52\n) 90\n.7 6(\n5. 05\n) 89\n.4 6(\n8. 33\n) 89\n.7 8(\n9. 83\n) 67\n.6 2(\n4. 21\n) 34\n.7 (2\n.0 )\n53 .6\n8( 5.\n28 )\n92 .0\n9( 1.\n62 )\n77 .0\n3( 2.\n76 )\n71 .5\n2( 3. 8) ca m pa ig n 28 .6 8( 0. 21 ) 36 .8 4( 0. 06 ) 35 .4 4( 0. 07 ) 14 .5 1( 2. 47 ) 35 .2 1( 0. 32 ) 27 .9 1( 1. 24 ) 28 .9 1( 0. 14 ) 13 .0 5( 4. 47 ) 15 .8 (0 .1 3) 32 .5 2( 0. 91 ) 28 .3 3( 0. 08 ) 28 .4 (0 .3 2) 16 .2 7( 2. 77 ) 14 .8 5( 2. 89 ) 11 .2 7( 0. 0) 10 .5 (1 .6 4) 26 .7 (0 .6 4) 19 .1 1( 3. 77 ) 28 .4 9( 0. 0) 21 .6 5( 8. 29 ) 24 .0 8( 0. 63 ) 11 .2 4( 0. 25 ) 29 .9 (0 .9 6) 28 .0 5( 0. 19 ) 23 .6 8( 2. 47 ) 32 .1 2( 1. 1) ca rd io 48 .2 3( 1. 68 ) 57 .5 9( 0. 51 ) 56 .6 8( 0. 74 ) 16 .0 9( 1. 04 ) 45 .8 (0 .8 6) 55 .8 8( 4. 43 ) 40 .1 7( 1. 51 ) 42 .7 8( 10 .4 7) 15 .8 9( 1. 81 ) 36 .4 4( 5. 19 ) 53 .5 7( 0. 67 ) 60 .8 7( 0. 73 ) 19 .2 8( 7. 44 ) 17 .7 2( 6. 67 ) 27 .2 1( 5. 27 ) 53 .9 6( 5. 29 ) 10 .8 4( 1. 25 ) 47 .0 7( 11 .9 5) 61 .0 (0 .1 2) 33 .4 4( 20 .1 5) 18 .4 6( 2. 5) 9. 57 (0 .6 8) 27 .8 4( 5. 61 ) 37 .6 2( 0. 74 ) 18 .3 5( 6. 15 ) 26 .8 (1 .8 7) ca rd io to co gr ap hy 33 .5 3( 5. 06 ) 40 .2 9( 2. 63 ) 50 .2 3( 0. 37 ) 27 .6 4( 0. 53 ) 36 .1 (0 .6 7) 43 .6 2( 2. 11 ) 32 .3 7( 0. 29 ) 46 .2 8( 12 .5 9) 27 .1 5( 0. 91 ) 31 .1 3( 0. 24 ) 40 .8 3( 0. 26 ) 46 .2 (1 .1 8) 27 .1 4( 3. 98 ) 25 .2 3( 2. 27 ) 25 .7 8( 2. 76 ) 40 .2 6( 7. 31 ) 18 .7 8( 0. 89 ) 34 .8 4( 3. 37 ) 47 .5 2( 0. 07 ) 39 .1 5( 9. 74 ) 23 .0 (3 .0 1) 22 .1 6( 0. 45 ) 33 .8 4( 3. 2) 31 .1 6( 0. 49 ) 25 .0 (3 .6 8) 27 .5 5( 1. 23 ) ce le ba 6. 88 (2 .0 6) 9. 28 (0 .5 9) 9. 53 (0 .5 5) 2. 37 (0 .2 8) 8. 95 (0 .5 6) 6. 26 (0 .4 1) 6. 07 (0 .2 7) 4. 65 (3 .1 9) 1. 81 (0 .0 2) 9. 17 (1 .6 8) 10 .2 8( 0. 48 ) 11 .1 9( 0. 62 ) 4. 42 (1 .2 7) 3. 11 (1 .5 1) 4. 66 (0 .2 2) 2. 09 (0 .9 1) 4. 48 (0 .3 ) 6. 55 (3 .4 5) 11 .2 (0 .7 3) 2. 9( 2. 18 ) 3. 18 (0 .2 7) 2. 25 (0 .1 ) 9. 25 (1 .4 7) 5. 19 (0 .2 3) 5. 77 (1 .5 9) 7. 68 (0 .8 3) ce ns us 8. 75 (0 .2 8) 6. 23 (0 .1 6) 6. 23 (0 .1 6) 6. 11 (0 .1 8) 7. 3( 0. 19 ) 7. 3( 0. 49 ) 8. 82 (0 .0 9) 6. 52 (2 .7 2) 6. 87 (0 .2 3) 15 .3 1( 1. 22 ) 8. 52 (0 .2 3) 8. 66 (0 .2 3) 6. 17 (0 .3 ) 7. 54 (1 .2 2) 5. 8( 0. 42 ) 7. 19 (1 .2 5) 9. 5( 0. 25 ) 7. 35 (0 .3 4) 8. 56 (0 .1 6) 8. 58 (1 .3 2) 8. 23 (1 .2 4) 6. 2( 0. 15 ) 8. 56 (0 .2 3) 9. 0( 0. 09 ) 8. 34 (0 .9 2) 8. 09 (0 .3 ) co ve r 6. 99 (0 .2 8) 6. 79 (0 .5 4) 11 .2 5( 1. 07 ) 1. 9( 0. 46 ) 2. 63 (0 .3 2) 5. 18 (1 .4 9) 5. 44 (0 .5 6) 8. 97 (3 .8 ) 1. 87 (0 .1 4) 1. 59 (0 .0 8) 9. 91 (0 .3 6) 7. 53 (0 .4 3) 4. 39 (4 .5 ) 4. 83 (6 .2 8) 5. 6( 4. 26 ) 0. 53 (0 .0 3) 2. 23 (0 .4 5) 0. 98 (0 .4 6) 7. 41 (0 .4 2) 18 .6 4( 36 .5 8) 2. 1( 0. 19 ) 1. 0( 0. 08 ) 4. 55 (0 .8 5) 4. 78 (0 .5 8) 2. 49 (0 .6 9) 2. 1( 0. 52 ) do no rs 14 .7 7( 0. 42 ) 20 .9 4( 0. 53 ) 26 .4 7( 0. 61 ) 12 .0 4( 0. 75 ) 13 .4 7( 1. 11 ) 12 .4 (0 .9 3) 18 .2 1( 0. 17 ) 25 .4 7( 32 .6 2) 10 .8 6( 0. 23 ) 14 .1 3( 4. 81 ) 13 .9 4( 0. 3) 16 .6 1( 0. 62 ) 8. 58 (3 .9 8) 11 .2 4( 7. 73 ) 12 .2 8( 3. 73 ) 3. 98 (0 .6 5) 11 .8 7( 1. 73 ) 24 .0 7( 2. 38 ) 16 .4 8( 0. 33 ) 12 .2 7( 8. 05 ) 8. 99 (0 .5 3) 5. 91 (0 .1 6) 14 .3 3( 0. 84 ) 18 .8 3( 0. 17 ) 16 .3 5( 6. 18 ) 13 .9 5( 3. 79 ) fa ul t 47 .3 (3 .1 ) 31 .2 6( 0. 16 ) 32 .5 4( 0. 17 ) 39 .5 7( 1. 22 ) 35 .9 7( 6. 41 ) 39 .4 5( 0. 61 ) 52 .2 1( 0. 73 ) 33 .6 5( 2. 46 ) 38 .7 7( 1. 09 ) 33 .3 5( 0. 73 ) 40 .0 8( 0. 34 ) 33 .1 6( 0. 61 ) 36 .1 1( 4. 21 ) 37 .5 2( 3. 2) 49 .6 2( 2. 49 ) 38 .0 8( 3. 41 ) 47 .2 7( 1. 26 ) 32 .9 2( 2. 45 ) 33 .9 8( 0. 07 ) 34 .8 (5 .3 3) 51 .5 6( 1. 42 ) 35 .4 1( 0. 41 ) 39 .2 (0 .6 5) 53 .2 3( 0. 39 ) 41 .7 (3 .5 9) 42 .1 8( 2. 19 ) fr au d 14 .5 3( 3. 21 ) 25 .1 7( 5. 67 ) 21 .5 4( 4. 92 ) 0. 34 (0 .0 7) 20 .8 8( 5. 54 ) 14 .4 9( 5. 34 ) 16 .8 6( 5. 49 ) 14 .6 2( 5. 25 ) 0. 26 (0 .0 5) 48 .7 6( 3. 53 ) 10 .9 8( 1. 28 ) 14 .9 1( 3. 13 ) 8. 44 (1 1. 9) 25 .0 2( 17 .8 5) 0. 16 (0 .0 1) 25 .7 (2 8. 34 ) 12 .6 6( 2. 66 ) 44 .7 4( 19 .7 8) 15 .6 7( 4. 11 ) 15 .6 2( 7. 69 ) 17 .9 6( 6. 53 ) 0. 18 (0 .0 3) 14 .5 8( 3. 63 ) 13 .6 8( 4. 1) 18 .8 1( 8. 21 ) 64 .7 5( 5. 97 ) gl as s 14 .3 6( 3. 18 ) 11 .0 5( 2. 35 ) 18 .3 3( 6. 17 ) 15 .0 9( 5. 9) 16 .0 7( 4. 53 ) 14 .4 1( 8. 02 ) 16 .7 4( 2. 54 ) 8. 99 (3 .1 9) 14 .4 2( 6. 7) 11 .3 3( 2. 11 ) 12 .9 8( 4. 31 ) 11 .1 8( 3. 06 ) 11 .0 6( 10 .1 5) 9. 03 (5 .3 9) 15 .9 2( 8. 84 ) 7. 55 (3 .8 ) 12 .2 3( 5. 39 ) 11 .3 3( 3. 69 ) 9. 99 (2 .5 6) 14 .8 3( 5. 17 ) 13 .3 7( 2. 61 ) 4. 61 (1 .4 1) 7. 29 (1 .1 3) 20 .5 7( 6. 59 ) 13 .5 4( 7. 27 ) 16 .8 2( 4. 63 ) he pa tit is 30 .3 6( 15 .5 7) 38 .8 8( 3. 25 ) 29 .4 7( 2. 74 ) 22 .4 9( 8. 34 ) 32 .8 (4 .3 1) 24 .3 1( 2. 23 ) 25 .1 7( 5. 46 ) 27 .4 7( 8. 72 ) 21 .3 9( 6. 04 ) 36 .3 4( 5. 03 ) 27 .7 (3 .2 5) 33 .9 1( 5. 86 ) 25 .2 9( 7. 17 ) 16 .9 9( 13 .0 8) 22 .0 9( 2. 34 ) 29 .0 9( 14 .1 5) 23 .0 6( 2. 98 ) 31 .7 2( 11 .9 3) 31 .0 4( 2. 78 ) 30 .6 9( 7. 55 ) 15 .8 6( 2. 27 ) 16 .1 8( 2. 12 ) 16 .4 9( 2. 95 ) 23 .8 2( 2. 31 ) 21 .4 9( 8. 14 ) 25 .7 3( 7. 5) ht tp 46 .4 3( 3. 33 ) 28 .0 2( 4. 37 ) 14 .4 7( 0. 73 ) 4. 69 (1 .8 3) 30 .1 9( 3. 04 ) 88 .6 3( 15 .2 6) 0. 98 (0 .6 9) 0. 41 (0 .0 7) 4. 95 (2 .1 ) 86 .4 6( 1. 79 ) 35 .5 9( 2. 55 ) 49 .9 9( 2. 19 ) 36 .8 (2 2. 99 ) 9. 34 (1 9. 72 ) 0. 37 (0 .0 3) 44 .1 3( 3. 94 ) 9. 08 (7 .2 8) 36 .2 7( 2. 48 ) 47 .6 6( 2. 57 ) 21 .1 5( 43 .9 9) 38 .1 5( 3. 94 ) 0. 4( 0. 04 ) 64 .2 2( 20 .7 5) 2. 41 (0 .9 9) 29 .5 3( 19 .6 2) 44 .0 3( 16 .1 1) im db 4. 74 (0 .0 3) 4. 96 (0 .0 3) 4. 48 (0 .0 1) 4. 87 (0 .0 4) 4. 74 (0 .0 1) 4. 68 (0 .0 4) 4. 67 (0 .0 2) 4. 58 (0 .2 8) 4. 88 (0 .0 6) 4. 88 (0 .0 8) 4. 69 (0 .0 9) 4. 59 (0 .0 1) 4. 86 (0 .1 1) 5. 31 (0 .7 7) 5. 01 (0 .0 3) 4. 68 (0 .1 5) 5. 38 (0 .0 9) 5. 06 (0 .1 5) 4. 59 (0 .0 ) 4. 79 (0 .2 2) 5. 19 (0 .0 4) 5. 12 (0 .1 5) 4. 59 (0 .0 1) 4. 69 (0 .0 3) 4. 74 (0 .5 2) 4. 67 (0 .3 2) in te rn et ad s 29 .6 5( 0. 08 ) 50 .4 7( 0. 2) 50 .5 4( 0. 2) 18 .1 9( 1. 9) 52 .2 7( 0. 3) 48 .6 2( 4. 28 ) 29 .6 4( 0. 09 ) 24 .1 8( 3. 77 ) 23 .2 (1 .2 ) 34 .3 6( 5. 4) 29 .0 9( 0. 14 ) 27 .5 6( 0. 76 ) 20 .7 3( 1. 63 ) 25 .2 1( 3. 95 ) 19 .7 3( 1. 54 ) 28 .7 8( 0. 13 ) 23 .6 9( 0. 9) 26 .1 9( 0. 59 ) 29 .5 6( 0. 0) 34 .5 2( 1. 55 ) 26 .2 6( 1. 06 ) 18 .6 (0 .8 3) 29 .4 6( 0. 05 ) 29 .0 1( 0. 46 ) 27 .5 3( 2. 43 ) 30 .1 8( 2. 54 ) io no sp he re 88 .1 (2 .9 2) 66 .2 8( 3. 2) 63 .3 4( 2. 3) 82 .0 5( 3. 0) 35 .2 6( 2. 03 ) 77 .9 2( 2. 9) 91 .0 9( 0. 79 ) 74 .0 7( 1. 71 ) 80 .6 7( 4. 01 ) 94 .6 5( 0. 24 ) 82 .9 1( 0. 84 ) 72 .0 8( 2. 42 ) 47 .3 4( 2. 7) 39 .2 4( 6. 87 ) 72 .7 7( 10 .3 3) 78 .1 (2 .2 3) 47 .1 9( 2. 28 ) 82 .3 8( 0. 99 ) 72 .0 (1 .7 4) 86 .5 9( 2. 41 ) 80 .7 3( 2. 48 ) 36 .5 2( 1. 6) 63 .2 9( 3. 49 ) 92 .0 4( 1. 18 ) 60 .9 8( 10 .6 3) 87 .9 6( 2. 24 ) la nd sa t 21 .2 3( 1. 78 ) 17 .6 (0 .0 5) 16 .3 7( 0. 05 ) 24 .6 3( 0. 49 ) 23 .0 7( 0. 25 ) 19 .3 7( 0. 64 ) 25 .7 5( 0. 22 ) 18 .2 9( 3. 54 ) 24 .9 9( 0. 55 ) 25 .3 1( 0. 07 ) 17 .5 (0 .0 5) 16 .3 3( 0. 13 ) 23 .0 1( 1. 27 ) 36 .1 5( 4. 0) 27 .2 2( 0. 36 ) 19 .8 4( 2. 96 ) 32 .9 4( 1. 69 ) 18 .6 5( 0. 43 ) 21 .9 4( 0. 43 ) 22 .0 7( 2. 21 ) 30 .5 5( 0. 31 ) 20 .8 7( 0. 34 ) 19 .9 9( 0. 35 ) 25 .4 5( 0. 27 ) 20 .2 7( 3. 23 ) 22 .3 4( 0. 89 ) le tte r 16 .6 4( 1. 01 ) 6. 84 (0 .0 3) 7. 71 (0 .0 7) 44 .5 3( 3. 22 ) 7. 79 (0 .2 1) 8. 59 (0 .1 6) 20 .3 1( 0. 72 ) 8. 26 (1 .1 7) 43 .3 2( 2. 85 ) 17 .3 8( 0. 53 ) 11 .2 7( 0. 27 ) 7. 62 (0 .1 2) 8. 27 (2 .6 6) 9. 94 (1 .3 7) 25 .2 2( 4. 92 ) 9. 85 (0 .8 8) 20 .8 (3 .3 8) 15 .2 7( 4. 23 ) 7. 71 (0 .0 1) 14 .6 4( 7. 07 ) 30 .9 6( 3. 04 ) 6. 55 (0 .2 9) 36 .6 9( 1. 64 ) 25 .5 3( 1. 41 ) 18 .0 9( 2. 29 ) 25 .6 5( 1. 6) ly m ph og ra ph y 91 .4 9( 6. 57 ) 90 .6 9( 2. 49 ) 89 .3 9( 2. 04 ) 9. 0( 7. 08 ) 91 .9 1( 3. 02 ) 97 .2 2( 1. 71 ) 89 .4 4( 6. 58 ) 49 .0 5( 38 .6 7) 13 .5 2( 9. 57 ) 76 .6 7( 5. 33 ) 88 .4 8( 6. 11 ) 93 .5 1( 4. 78 ) 45 .4 1( 15 .8 1) 25 .3 5( 18 .3 7) 46 .3 1( 19 .0 5) 89 .7 2( 6. 59 ) 26 .4 4( 9. 97 ) 41 .7 3( 13 .5 1) 93 .6 7( 4. 31 ) 48 .5 4( 32 .0 1) 66 .1 1( 8. 36 ) 4. 87 (1 .2 4) 73 .1 (2 0. 13 ) 80 .5 1( 9. 21 ) 38 .8 (1 9. 67 ) 38 .1 3( 14 .8 8) m ag ic .g am m a 66 .6 1( 0. 05 ) 58 .8 (0 .0 4) 53 .3 4( 0. 05 ) 53 .8 7( 0. 79 ) 61 .7 4( 0. 15 ) 63 .7 7( 0. 37 ) 72 .3 5( 0. 14 ) 57 .8 7( 1. 31 ) 51 .9 8( 0. 44 ) 63 .1 5( 0. 09 ) 62 .5 1( 0. 1) 58 .8 8( 0. 09 ) 45 .0 1( 3. 53 ) 49 .9 3( 1. 07 ) 62 .7 1( 0. 72 ) 32 .5 9( 4. 63 ) 54 .7 6( 1. 7) 69 .2 4( 4. 35 ) 59 .1 2( 0. 0) 41 .7 3( 4. 32 ) 50 .9 9( 1. 35 ) 35 .4 (0 .3 3) 65 .1 4( 1. 91 ) 72 .9 8( 0. 13 ) 65 .7 4( 2. 99 ) 66 .4 (0 .9 7) m am m og ra ph y 13 .9 5( 2. 79 ) 43 .0 2( 0. 41 ) 43 .5 4( 0. 39 ) 7. 01 (0 .9 9) 13 .2 4( 1. 35 ) 21 .7 8( 3. 74 ) 18 .0 6( 0. 92 ) 21 .7 6( 4. 58 ) 8. 48 (0 .7 2) 3. 58 (0 .2 5) 18 .6 9( 0. 74 ) 20 .4 4( 1. 39 ) 11 .0 6( 10 .1 2) 2. 53 (0 .4 8) 11 .4 1( 1. 7) 4. 63 (1 .6 7) 4. 56 (1 .2 ) 7. 37 (1 .4 4) 19 .8 2( 0. 03 ) 20 .1 1( 14 .6 5) 7. 91 (1 .4 7) 2. 4( 0. 28 ) 9. 89 (2 .2 6) 17 .4 5( 0. 99 ) 8. 2( 2. 52 ) 17 .0 2( 1. 42 ) m ni st 38 .6 1( 1. 75 ) 9. 21 (0 .0 ) 9. 21 (0 .0 ) 24 .1 1( 1. 05 ) 10 .9 1( 0. 12 ) 29 .0 3( 4. 81 ) 40 .8 7( 0. 5) 16 .9 7( 6. 79 ) 23 .3 4( 1. 51 ) 30 .8 4( 2. 43 ) 38 .5 4( 0. 33 ) 38 .1 4( 0. 94 ) 21 .5 2( 3. 55 ) 25 .3 4( 10 .3 6) 23 .7 3( 1. 08 ) 29 .7 2( 4. 7) 23 .1 9( 1. 41 ) 25 .9 4( 10 .6 8) 38 .3 (0 .0 4) 26 .0 3( 4. 54 ) 9. 21 (0 .0 ) 9. 33 (0 .5 2) 37 .3 8( 1. 09 ) 39 .9 9( 0. 75 ) 27 .6 3( 5. 4) 36 .7 6( 2. 05 ) m us k 10 0. 0( 0. 0) 36 .9 1( 4. 05 ) 47 .4 7( 1. 53 ) 13 .9 5( 7. 85 ) 99 .8 7( 0. 08 ) 94 .4 7( 9. 05 ) 70 .8 1( 10 .3 5) 84 .1 5( 17 .5 6) 11 .7 7( 5. 21 ) 99 .1 5( 1. 13 ) 10 0. 0( 0. 0) 99 .9 5( 0. 02 ) 50 .0 2( 29 .2 9) 10 .7 4( 13 .4 3) 19 .5 7( 7. 39 ) 99 .9 7( 0. 07 ) 12 .8 4( 4. 41 ) 39 .1 1( 37 .8 7) 99 .9 8( 0. 0) 10 0. 0( 0. 0) 26 .3 5( 7. 41 ) 3. 48 (0 .4 9) 98 .3 8( 1. 16 ) 43 .3 6( 3. 14 ) 13 .6 8( 4. 74 ) 55 .3 (2 1. 58 ) op td ig its 5. 92 (0 .2 6) 2. 88 (0 .0 ) 2. 88 (0 .0 ) 3. 62 (0 .7 8) 19 .1 8( 1. 06 ) 4. 61 (0 .8 1) 2. 18 (0 .0 9) 2. 9( 0. 95 ) 3. 53 (0 .6 9) 2. 24 (0 .2 1) 2. 65 (0 .0 8) 2. 7( 0. 03 ) 2. 6( 1. 34 ) 3. 89 (2 .5 8) 3. 16 (0 .2 8) 3. 94 (0 .9 6) 3. 02 (0 .5 6) 2. 74 (0 .6 8) 2. 68 (0 .0 1) 2. 67 (1 .1 3) 3. 04 (0 .2 4) 3. 03 (0 .2 2) 2. 24 (0 .1 4) 2. 14 (0 .0 9) 2. 82 (0 .3 5) 2. 75 (0 .3 8) pa ge bl oc ks 54 .6 7( 5. 46 ) 37 .0 3( 0. 41 ) 51 .9 6( 0. 39 ) 34 .1 (2 .7 9) 31 .8 8( 4. 58 ) 46 .3 7( 1. 42 ) 55 .5 8( 0. 65 ) 40 .9 5( 8. 6) 29 .1 6( 2. 08 ) 61 .6 9( 0. 68 ) 53 .0 7( 0. 57 ) 52 .4 6( 1. 66 ) 25 .5 2( 5. 14 ) 28 .8 3( 12 .9 7) 63 .2 1( 3. 28 ) 37 .2 9( 4. 72 ) 28 .4 9( 3. 65 ) 53 .7 6( 4. 73 ) 51 .3 2( 0. 0) 32 .5 9( 7. 06 ) 40 .3 8( 3. 46 ) 10 .0 2( 0. 42 ) 49 .2 7( 2. 07 ) 52 .9 6( 0. 97 ) 50 .7 2( 9. 01 ) 55 .4 9( 4. 05 ) pe nd ig its 19 .1 7( 10 .4 2) 17 .7 1( 1. 05 ) 26 .9 6( 0. 57 ) 4. 83 (0 .7 8) 24 .7 3( 0. 8) 26 .0 1( 4. 72 ) 9. 95 (2 .6 1) 18 .5 6( 5. 48 ) 4. 01 (0 .5 3) 6. 91 (0 .1 9) 22 .5 7( 1. 29 ) 21 .8 6( 0. 32 ) 5. 63 (4 .6 9) 2. 16 (0 .8 5) 2. 7( 0. 46 ) 7. 51 (6 .9 6) 4. 53 (1 .0 3) 6. 04 (2 .5 6) 22 .1 1( 0. 06 ) 19 .6 2( 13 .4 4) 4. 52 (1 .0 9) 2. 42 (0 .2 7) 5. 61 (0 .6 4) 8. 87 (1 .4 7) 4. 4( 0. 91 ) 4. 36 (1 .0 6) pi m a 48 .3 8( 3. 73 ) 53 .6 2( 2. 38 ) 48 .3 8( 2. 46 ) 41 .2 2( 2. 23 ) 57 .7 3( 2. 72 ) 50 .9 6( 4. 11 ) 52 .9 9( 3. 09 ) 40 .3 9( 5. 19 ) 40 .6 3( 2. 05 ) 49 .7 7( 3. 47 ) 47 .7 4( 2. 79 ) 49 .1 9( 4. 08 ) 37 .1 8( 2. 12 ) 36 .6 2( 2. 52 ) 41 .3 4( 9. 25 ) 47 .6 1( 11 .5 8) 38 .4 7( 2. 35 ) 47 .6 4( 4. 75 ) 49 .6 4( 3. 38 ) 41 .2 7( 3. 36 ) 35 .0 2( 3. 6) 37 .0 (3 .7 9) 40 .0 2( 2. 72 ) 52 .8 3( 2. 87 ) 43 .7 4( 3. 29 ) 44 .6 8( 2. 5) sa te lli te 65 .6 4( 6. 27 ) 57 .0 4( 0. 08 ) 52 .6 2( 0. 1) 37 .7 7( 0. 72 ) 68 .7 8( 0. 47 ) 64 .8 8( 1. 51 ) 58 .1 6( 0. 35 ) 61 .2 7( 4. 3) 38 .1 (0 .7 ) 76 .8 (0 .1 3) 65 .4 4( 0. 16 ) 60 .6 1( 0. 17 ) 52 .6 9( 5. 91 ) 40 .5 7( 4. 8) 46 .4 5( 0. 98 ) 65 .8 3( 2. 86 ) 45 .1 4( 1. 92 ) 59 .5 5( 0. 78 ) 70 .5 5( 0. 27 ) 51 .3 (1 3. 93 ) 52 .8 9( 1. 37 ) 31 .6 (0 .4 8) 66 .1 6( 0. 76 ) 56 .2 9( 0. 46 ) 37 .9 6( 2. 66 ) 52 .9 1( 3. 46 ) sa tim ag e2 97 .2 1( 0. 03 ) 79 .7 (0 .9 4) 66 .6 2( 1. 58 ) 4. 23 (2 .7 1) 76 .0 (1 .1 4) 91 .7 5( 0. 85 ) 68 .9 8( 15 .7 8) 85 .7 4( 7. 48 ) 4. 08 (2 .5 ) 68 .2 4( 3. 21 ) 96 .5 3( 0. 02 ) 87 .1 9( 0. 1) 28 .9 2( 20 .6 1) 5. 15 (4 .6 9) 7. 61 (2 .9 3) 94 .9 1( 0. 33 ) 10 .1 8( 2. 82 ) 48 .3 6( 8. 72 ) 81 .2 4( 2. 27 ) 61 .2 2( 32 .4 6) 34 .4 4( 6. 41 ) 1. 32 (0 .1 1) 78 .2 5( 5. 9) 50 .7 3( 8. 98 ) 9. 52 (5 .6 6) 13 .8 4( 3. 38 ) sh ut tle 18 .3 8( 2. 14 ) 96 .2 2( 0. 17 ) 90 .5 (0 .1 4) 8. 08 (1 .8 8) 96 .4 7( 0. 15 ) 97 .6 2( 0. 41 ) 19 .3 1( 0. 46 ) 16 .8 3( 19 .0 6) 10 .9 3( 0. 17 ) 84 .1 (0 .0 5) 90 .7 2( 0. 06 ) 91 .3 3( 0. 15 ) 43 .7 5( 13 .4 7) 14 .8 6( 7. 6) 7. 15 (0 .0 ) 13 .5 8( 19 .7 2) 13 .4 8( 3. 81 ) 34 .5 7( 12 .2 6) 91 .5 4( 0. 0) 90 .0 7( 8. 72 ) 63 .2 7( 30 .2 1) 7. 22 (0 .0 7) 77 .8 8( 7. 67 ) 18 .6 5( 0. 26 ) 24 .7 2( 13 .7 7) 62 .6 (9 .5 5) sk in 28 .8 6( 3. 15 ) 17 .8 6( 0. 09 ) 18 .2 7( 0. 1) 20 .6 8( 0. 24 ) 23 .2 (0 .1 9) 25 .3 6( 0. 43 ) 29 .0 (0 .1 8) 18 .0 3( 0. 48 ) 22 .1 (0 .1 7) 49 .0 1( 0. 31 ) 22 .0 1( 0. 19 ) 17 .2 4( 0. 15 ) 22 .5 5( 6. 64 ) 22 .1 4( 2. 98 ) 28 .4 7( 1. 09 ) 23 .2 2( 1. 66 ) 17 .2 9( 1. 24 ) 33 .5 3( 2. 24 ) 19 .3 3( 0. 11 ) 18 .1 7( 1. 34 ) 35 .3 5( 1. 08 ) 20 .9 2( 0. 31 ) 17 .5 4( 0. 58 ) 28 .9 9( 0. 2) 31 .5 7( 3. 14 ) 30 .2 4( 1. 74 ) sm tp 40 .3 2( 5. 33 ) 0. 5( 0. 05 ) 58 .8 5( 4. 72 ) 0. 13 (0 .0 2) 0. 5( 0. 05 ) 0. 53 (0 .0 8) 41 .5 4( 5. 59 ) 31 .2 1( 10 .4 1) 2. 23 (1 .3 9) 0. 6( 0. 06 ) 38 .2 5( 8. 36 ) 38 .2 4( 5. 87 ) 17 .8 8( 24 .4 9) 24 .0 1( 14 .7 ) 0. 04 (0 .0 ) 35 .7 6( 4. 34 ) 0. 43 (0 .5 1) 0. 56 (0 .5 4) 38 .7 3( 5. 82 ) 6. 32 (1 4. 04 ) 42 .5 4( 4. 67 ) 0. 05 (0 .0 2) 50 .2 3( 9. 75 ) 41 .0 7( 5. 45 ) 1. 16 (2 .2 ) 42 .1 5( 3. 73 ) sp am ba se 40 .2 3( 0. 63 ) 54 .3 7( 0. 16 ) 51 .8 2( 0. 17 ) 34 .3 9( 0. 6) 51 .7 7( 1. 22 ) 48 .7 5( 1. 64 ) 41 .5 3( 0. 17 ) 38 .6 5( 5. 96 ) 35 .9 5( 0. 33 ) 34 .8 9( 2. 17 ) 40 .2 1( 0. 07 ) 40 .9 3( 0. 51 ) 38 .8 7( 3. 27 ) 45 .6 (4 .6 4) 38 .3 2( 0. 91 ) 38 .7 3( 3. 86 ) 37 .0 1( 0. 74 ) 43 .3 2( 5. 7) 40 .9 5( 0. 02 ) 42 .9 4( 1. 74 ) 38 .5 1( 0. 29 ) 39 .4 (0 .7 7) 38 .3 7( 0. 71 ) 40 .6 9( 0. 22 ) 39 .8 6( 3. 19 ) 40 .0 4( 1. 52 ) sp ee ch 1. 87 (0 .0 2) 1. 88 (0 .0 7) 1. 96 (0 .0 1) 2. 18 (0 .1 5) 2. 29 (0 .1 4) 2. 05 (0 .3 4) 1. 85 (0 .0 2) 1. 61 (0 .2 ) 2. 16 (0 .1 5) 1. 91 (0 .1 1) 1. 85 (0 .0 3) 1. 84 (0 .0 ) 2. 18 (0 .4 3) 1. 8( 0. 15 ) 2. 03 (0 .7 3) 1. 93 (0 .4 2) 2. 01 (0 .3 ) 1. 75 (0 .2 ) 1. 84 (0 .0 ) 2. 22 (0 .7 4) 1. 72 (0 .1 ) 1. 74 (0 .2 7) 2. 04 (0 .4 3) 1. 88 (0 .1 5) 1. 9( 0. 21 ) 2. 0( 0. 33 ) st am ps 21 .0 6( 2. 78 ) 39 .7 8( 4. 75 ) 32 .3 5( 3. 22 ) 14 .2 6( 4. 1) 33 .1 8( 3. 9) 34 .7 2( 4. 5) 31 .6 9( 3. 92 ) 27 .9 7( 8. 26 ) 15 .2 7( 4. 4) 25 .7 3( 6. 17 ) 31 .7 6( 4. 47 ) 36 .4 (6 .1 3) 19 .7 5( 8. 33 ) 9. 87 (2 .8 ) 24 .0 9( 8. 58 ) 28 .5 3( 10 .9 ) 11 .6 6( 2. 25 ) 28 .3 6( 3. 34 ) 35 .4 1( 6. 01 ) 27 .8 3( 12 .7 2) 16 .5 2( 5. 78 ) 10 .5 1( 2. 2) 14 .2 6( 4. 14 ) 27 .2 5( 4. 34 ) 23 .4 8( 11 .0 1) 22 .6 3( 4. 68 ) th yr oi d 27 .1 7( 0. 59 ) 17 .9 4( 0. 9) 47 .1 8( 2. 25 ) 6. 93 (2 .8 8) 50 .1 2( 2. 65 ) 56 .2 2( 8. 46 ) 39 .2 2( 2. 16 ) 18 .9 (8 .9 7) 7. 73 (2 .4 7) 70 .1 5( 0. 73 ) 32 .8 9( 2. 07 ) 35 .5 7( 3. 87 ) 12 .6 (1 1. 43 ) 2. 41 (0 .2 ) 33 .8 4( 5. 52 ) 31 .7 8( 22 .4 9) 6. 56 (1 .9 4) 73 .3 7( 9. 97 ) 35 .5 8( 0. 01 ) 23 .3 8( 25 .6 6) 17 .6 6( 5. 2) 2. 66 (0 .3 7) 32 .4 8( 4. 3) 35 .9 8( 2. 15 ) 11 .8 (6 .2 6) 70 .4 9( 4. 14 ) ve rt eb ra l 12 .3 4( 0. 98 ) 8. 5( 1. 2) 10 .9 7( 0. 72 ) 12 .3 7( 3. 08 ) 9. 12 (1 .0 3) 9. 68 (1 .0 ) 9. 51 (1 .1 8) 8. 88 (1 .1 4) 12 .9 5( 3. 05 ) 10 .1 1( 1. 31 ) 10 .6 8( 1. 32 ) 9. 93 (0 .8 9) 13 .3 8( 3. 96 ) 10 .6 7( 2. 05 ) 11 .7 5( 3. 86 ) 12 .3 5( 3. 81 ) 11 .5 3( 1. 69 ) 11 .1 1( 2. 23 ) 9. 15 (0 .8 9) 9. 63 (1 .0 6) 10 .1 8( 1. 87 ) 12 .1 8( 1. 93 ) 14 .9 7( 4. 55 ) 9. 82 (1 .0 3) 13 .3 1( 5. 54 ) 11 .9 2( 1. 7) vo w el s 16 .6 1( 1. 03 ) 3. 43 (0 .0 5) 8. 28 (0 .5 4) 31 .4 2( 8. 14 ) 7. 83 (0 .8 9) 16 .2 3( 6. 18 ) 44 .3 2( 0. 55 ) 12 .7 2( 3. 85 ) 32 .5 8( 5. 97 ) 8. 54 (6 .4 5) 19 .5 8( 1. 16 ) 6. 87 (0 .2 6) 4. 07 (1 .9 8) 3. 71 (0 .3 9) 17 .8 1( 14 .3 3) 15 .4 2( 7. 74 ) 21 .9 2( 3. 39 ) 29 .5 3( 8. 97 ) 6. 96 (0 .0 8) 5. 56 (3 .3 1) 32 .7 4( 3. 42 ) 3. 59 (0 .3 4) 31 .0 6( 4. 37 ) 50 .4 4( 3. 18 ) 16 .5 7( 4. 43 ) 41 .7 (1 2. 32 ) w av ef or m 12 .2 3( 1. 76 ) 5. 69 (0 .1 4) 4. 04 (0 .0 3) 7. 84 (1 .4 3) 4. 83 (0 .1 1) 5. 63 (0 .9 2) 13 .2 8( 0. 76 ) 4. 02 (0 .7 8) 7. 09 (0 .9 ) 3. 95 (0 .1 2) 5. 23 (0 .1 1) 4. 41 (0 .0 2) 3. 16 (0 .5 1) 6. 1( 1. 96 ) 14 .9 6( 3. 18 ) 4. 24 (0 .8 2) 6. 29 (1 .2 1) 15 .0 4( 8. 49 ) 4. 46 (0 .0 1) 5. 78 (4 .5 3) 2. 38 (0 .0 4) 2. 91 (0 .2 7) 4. 98 (0 .6 1) 10 .9 3( 1. 18 ) 3. 73 (0 .9 6) 4. 28 (0 .5 9) w bc 69 .0 7( 11 .7 9) 88 .3 3( 2. 34 ) 88 .1 9( 2. 42 ) 3. 72 (0 .4 8) 72 .8 3( 6. 35 ) 94 .8 4( 2. 02 ) 74 .2 7( 6. 66 ) 89 .7 6( 2. 29 ) 7. 72 (1 .4 7) 83 .9 2( 11 .3 6) 81 .2 7( 11 .5 ) 91 .3 3( 4. 96 ) 32 .6 7( 25 .3 3) 6. 93 (2 .6 1) 35 .8 4( 8. 07 ) 73 .6 4( 8. 88 ) 21 .0 6( 4. 43 ) 43 .0 6( 12 .6 9) 89 .2 3( 4. 82 ) 70 .1 8( 14 .0 1) 70 .5 9( 20 .1 6) 4. 87 (1 .2 ) 75 .7 8( 9. 25 ) 72 .1 7( 13 .6 ) 34 .8 4( 17 .7 9) 19 .3 5( 3. 2) w db c 68 .8 1( 9. 09 ) 76 .0 4( 3. 54 ) 49 .2 7( 4. 01 ) 15 .4 5( 9. 61 ) 76 .1 4( 4. 83 ) 70 .1 8( 4. 66 ) 52 .1 3( 4. 05 ) 52 .6 9( 13 .2 2) 12 .8 (7 .8 9) 39 .4 6( 8. 71 ) 53 .8 9( 7. 79 ) 61 .2 8( 3. 38 ) 15 .1 6( 13 .9 ) 6. 26 (3 .3 4) 3. 94 (2 .5 7) 58 .8 7( 13 .6 6) 6. 48 (1 .5 9) 56 .8 (1 2. 62 ) 50 .3 1( 4. 11 ) 46 .9 6( 30 .3 8) 18 .3 2( 5. 3) 3. 09 (0 .9 6) 48 .2 7( 10 .8 ) 46 .5 1( 7. 89 ) 7. 41 (7 .0 3) 15 .6 5( 7. 73 ) w ilt 4. 01 (0 .1 2) 3. 7( 0. 01 ) 4. 17 (0 .0 ) 8. 05 (2 .1 6) 3. 94 (0 .1 5) 4. 4( 0. 25 ) 4. 92 (0 .0 7) 3. 6( 0. 48 ) 8. 31 (0 .3 4) 15 .3 4( 0. 06 ) 3. 54 (0 .0 1) 3. 22 (0 .0 1) 4. 73 (0 .6 2) 4. 64 (0 .1 7) 4. 05 (0 .2 3) 6. 47 (1 .5 1) 10 .8 8( 1. 46 ) 11 .5 3( 1. 08 ) 3. 64 (0 .0 ) 4. 19 (0 .0 8) 10 .3 6( 0. 49 ) 5. 7( 0. 22 ) 7. 62 (0 .8 5) 5. 35 (0 .0 7) 21 .1 4( 6. 69 ) 16 .2 9( 1. 47 ) w in e 17 .0 4( 22 .7 2) 36 .3 9( 6. 24 ) 19 .4 5( 3. 2) 6. 06 (0 .5 ) 41 .2 1( 10 .0 1) 20 .6 9( 4. 89 ) 8. 05 (0 .8 9) 24 .9 9( 9. 9) 6. 42 (1 .6 6) 73 .7 4( 14 .7 7) 13 .4 8( 2. 11 ) 26 .3 9( 5. 02 ) 12 .0 4( 7. 37 ) 11 .6 (5 .7 7) 12 .6 (4 .7 4) 22 .9 (1 4. 04 ) 8. 67 (1 .1 8) 8. 6( 4. 64 ) 23 .6 5( 3. 65 ) 17 .6 3( 13 .8 8) 6. 77 (1 .1 7) 8. 18 (1 .0 ) 7. 45 (2 .1 4) 7. 37 (1 .2 1) 6. 39 (1 .9 3) 10 .2 7( 3. 41 ) w pb c 22 .7 4( 2. 24 ) 23 .3 7( 1. 68 ) 21 .6 6( 1. 22 ) 20 .5 7( 1. 44 ) 24 .1 (1 .6 6) 23 .7 3( 1. 92 ) 23 .4 4( 1. 4) 22 .6 5( 1. 74 ) 20 .9 8( 1. 73 ) 25 .6 6( 2. 17 ) 22 .1 5( 1. 31 ) 22 .8 6( 1. 58 ) 21 .4 (1 .9 5) 24 .0 2( 1. 97 ) 23 .3 8( 2. 93 ) 21 .4 4( 2. 8) 23 .4 4( 1. 73 ) 23 .6 4( 0. 84 ) 21 .2 3( 1. 24 ) 23 .9 7( 1. 24 ) 23 .5 5( 0. 58 ) 23 .2 (1 .3 6) 23 .8 (3 .1 1) 22 .7 2( 1. 72 ) 23 .8 (2 .0 7) 23 .1 4( 3. 11 ) ye as t 31 .3 9( 0. 56 ) 30 .7 9( 0. 15 ) 33 .1 9( 0. 18 ) 32 .5 5( 0. 99 ) 32 .7 9( 0. 5) 30 .3 9( 0. 49 ) 29 .3 6( 0. 48 ) 33 .0 1( 2. 79 ) 31 .5 1( 0. 78 ) 29 .7 6( 0. 48 ) 30 .3 3( 0. 38 ) 30 .1 7( 0. 2) 35 .2 7( 2. 8) 35 .0 3( 2. 67 ) 28 .3 5( 1. 8) 33 .2 3( 2. 68 ) 31 .8 4( 1. 18 ) 30 .9 2( 3. 18 ) 29 .6 4( 0. 0) 33 .5 9( 3. 64 ) 34 .0 4( 1. 07 ) 34 .4 8( 1. 53 ) 32 .0 4( 0. 49 ) 29 .4 5( 0. 66 ) 30 .6 4( 1. 82 ) 30 .6 1( 1. 7) ye lp 7. 31 (0 .1 7) 7. 24 (0 .0 3) 6. 47 (0 .0 1) 8. 52 (0 .1 9) 7. 04 (0 .0 1) 6. 96 (0 .0 5) 8. 27 (0 .0 5) 6. 67 (0 .6 ) 8. 52 (0 .1 8) 7. 49 (0 .1 2) 7. 29 (0 .0 1) 6. 88 (0 .0 3) 4. 89 (0 .2 5) 5. 8( 1. 45 ) 5. 08 (0 .1 1) 6. 78 (0 .6 4) 5. 36 (0 .0 7) 5. 57 (0 .2 4) 6. 91 (0 .0 2) 6. 95 (0 .3 5) 5. 2( 0. 04 ) 4. 99 (0 .1 1) 6. 92 (0 .0 1) 8. 5( 0. 13 ) 5. 42 (0 .9 3) 6. 59 (0 .7 8) M N IS TC 17 .2 6( 2. 17 ) 5. 0( 0. 0) 5. 0( 0. 0) 12 .8 (0 .3 8) 12 .6 2( 0. 22 ) 17 .7 9( 2. 47 ) 19 .0 6( 0. 11 ) 10 .1 3( 3. 68 ) 12 .6 5( 0. 33 ) 16 .6 4( 4. 96 ) 17 .9 3( 0. 17 ) 16 .9 7( 0. 5) 9. 22 (4 .1 5) 9. 7( 3. 62 ) 9. 63 (0 .9 2) 17 .6 9( 0. 93 ) 9. 78 (0 .5 8) 15 .4 3( 1. 59 ) 17 .2 1( 0. 01 ) 17 .0 7( 3. 82 ) 17 .2 4( 0. 46 ) 5. 04 (0 .2 2) 17 .7 5( 0. 19 ) 19 .2 2( 0. 15 ) 14 .0 5( 3. 08 ) 15 .6 7( 1. 38 ) Fa sh io nM N IS T 32 .8 9( 1. 4) 4. 99 (0 .0 ) 4. 99 (0 .0 ) 19 .4 (0 .8 ) 26 .9 3( 0. 21 ) 31 .9 5( 1. 42 ) 34 .6 2( 0. 26 ) 18 .0 (4 .4 ) 18 .8 (0 .7 6) 24 .5 (5 .8 2) 32 .8 7( 0. 33 ) 31 .8 8( 0. 91 ) 13 .8 2( 4. 52 ) 18 .0 9( 3. 66 ) 10 .6 1( 1. 48 ) 32 .7 6( 0. 93 ) 15 .8 1( 1. 16 ) 29 .7 3( 1. 53 ) 32 .2 8( 0. 01 ) 30 .6 8( 3. 51 ) 32 .3 7( 3. 59 ) 5. 14 (0 .3 3) 32 .4 5( 0. 24 ) 33 .8 6( 0. 37 ) 21 .2 5( 4. 22 ) 26 .7 4( 1. 66 ) C IF A R 10 10 .3 4( 0. 16 ) 6. 45 (0 .0 2) 6. 74 (0 .0 3) 11 .5 1( 0. 41 ) 7. 49 (0 .0 7) 8. 9( 0. 51 ) 10 .2 3( 0. 03 ) 8. 57 (1 .4 8) 11 .4 5( 0. 36 ) 8. 41 (0 .6 9) 10 .1 9( 0. 24 ) 10 .1 2( 0. 23 ) 6. 17 (0 .8 2) 7. 29 (0 .9 8) 6. 01 (0 .6 9) 10 .1 6( 0. 33 ) 6. 98 (0 .6 2) 8. 48 (0 .4 ) 10 .0 7( 0. 0) 10 .4 8( 0. 56 ) 10 .3 8( 0. 27 ) 5. 24 (0 .3 1) 10 .1 7( 0. 09 ) 10 .3 6( 0. 09 ) 7. 77 (0 .6 6) 9. 17 (0 .5 1) SV H N 7. 87 (0 .1 ) 5. 0( 0. 0) 5. 0( 0. 0) 8. 35 (0 .1 7) 6. 35 (0 .0 3) 7. 29 (0 .2 8) 7. 94 (0 .0 2) 6. 4( 0. 88 ) 8. 26 (0 .1 4) 6. 82 (0 .5 4) 7. 81 (0 .1 6) 7. 8( 0. 24 ) 5. 9( 0. 57 ) 6. 25 (0 .5 4) 6. 03 (0 .4 7) 7. 8( 0. 26 ) 6. 84 (0 .5 3) 7. 44 (0 .3 3) 7. 76 (0 .0 ) 7. 96 (0 .3 2) 7. 91 (0 .1 4) 5. 0( 0. 21 ) 7. 84 (0 .0 9) 8. 01 (0 .0 4) 6. 89 (0 .6 2) 7. 73 (0 .3 4) M V Te cA D 56 .9 6( 2. 98 ) 23 .6 3( 1. 25 ) 23 .6 3( 1. 25 ) 53 .6 (3 .7 4) 54 .5 6( 2. 72 ) 57 .0 (2 .4 8) 58 .0 2( 2. 12 ) 46 .4 2( 5. 61 ) 53 .2 (3 .6 7) 45 .1 1( 4. 53 ) 55 .4 5( 2. 18 ) 53 .9 7( 2. 29 ) 36 .1 8( 5. 29 ) 38 .6 6( 5. 26 ) 31 .7 2( 4. 41 ) 54 .6 (3 .1 2) 40 .3 6( 2. 79 ) 45 .3 8( 7. 19 ) 53 .8 3( 2. 13 ) 54 .2 6( 3. 28 ) 50 .9 4( 3. 8) 24 .0 8( 1. 86 ) 54 .6 (2 .2 4) 57 .7 5( 2. 44 ) 43 .9 1( 6. 01 ) 51 .7 3( 3. 6) 20 ne w s 6. 66 (0 .4 2) 6. 09 (0 .2 9) 6. 17 (0 .1 2) 8. 71 (0 .8 7) 6. 05 (0 .2 1) 6. 24 (0 .3 6) 6. 9( 0. 36 ) 6. 23 (1 .0 7) 8. 75 (0 .8 8) 7. 15 (0 .6 2) 6. 38 (0 .4 4) 6. 24 (0 .2 3) 5. 43 (0 .6 6) 5. 8( 0. 74 ) 5. 53 (0 .7 4) 6. 28 (0 .3 ) 6. 3( 0. 86 ) 5. 63 (0 .6 8) 6. 27 (0 .3 ) 6. 55 (0 .7 1) 6. 42 (0 .4 1) 5. 77 (1 .0 5) 6. 25 (0 .2 1) 7. 16 (0 .4 9) 6. 01 (1 .3 8) 6. 84 (0 .8 7) ag ne w s 7. 24 (0 .0 7) 5. 85 (0 .0 1) 5. 76 (0 .0 1) 12 .5 1( 0. 62 ) 5. 87 (0 .0 1) 6. 36 (0 .2 2) 8. 16 (0 .0 3) 6. 42 (0 .5 8) 12 .4 7( 0. 61 ) 7. 7( 0. 1) 6. 78 (0 .0 7) 6. 11 (0 .0 2) 5. 31 (0 .6 9) 5. 27 (0 .7 2) 5. 1( 0. 21 ) 6. 63 (0 .4 9) 6. 89 (0 .2 4) 5. 0( 0. 2) 6. 11 (0 .0 ) 8. 81 (0 .7 9) 6. 3( 0. 08 ) 5. 07 (0 .2 3) 6. 17 (0 .0 1) 8. 45 (0 .0 6) 6. 26 (1 .2 8) 7. 55 (1 .0 4)"
        }
    ],
    "year": 2023
}