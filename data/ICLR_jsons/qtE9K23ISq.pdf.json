{
    "abstractText": "In Self-Supervised Learning (SSL), models are typically pretrained, fine-tuned, and evaluated on the same domains. However, they tend to perform poorly when evaluated on unseen domains, a challenge that Unsupervised Domain Generalization (UDG) seeks to address. Current UDG methods rely on domain labels, which are often challenging to collect, and domain-specific architectures that lack scalability when confronted with numerous domains, making the current methodology impractical and rigid. Inspired by contrastive-based UDG methods that mitigate spurious correlations by restricting comparisons to examples from the same domain, we hypothesize that eliminating style variability within a batch could provide a more convenient and flexible way to reduce spurious correlations without requiring domain labels. To verify this hypothesis, we introduce Batch Styles Standardization (BSS), a relatively simple yet powerful Fourier-based method to standardize the style of images in a batch specifically designed for integration with SSL methods to tackle UDG. Combining BSS with existing SSL methods offers serious advantages over prior UDG methods: (1) It eliminates the need for domain labels or domain-specific network components to enhance domain-invariance in SSL representations, and (2) offers flexibility as BSS can be seamlessly integrated with diverse contrastive-based but also non-contrastive-based SSL methods. Experiments on several UDG datasets demonstrate that it significantly improves downstream task performances on unseen domains, often outperforming or rivaling UDG methods. Finally, this work clarifies the underlying mechanisms contributing to BSS\u2019s effectiveness in improving domain-invariance in SSL representations and performances on unseen domains. Implementations of the extended SSL methods and BSS are provided at this url.",
    "authors": [
        {
            "affiliations": [],
            "name": "BATCH STYLES STANDARDIZATION"
        },
        {
            "affiliations": [],
            "name": "Marin Scalbert"
        },
        {
            "affiliations": [],
            "name": "Maria Vakalopoulou"
        }
    ],
    "id": "SP:1ca1183061a24fbb6af32b31fee696c6d7712385",
    "references": [
        {
            "authors": [
                "Mahmoud Assran",
                "Mathilde Caron",
                "Ishan Misra",
                "Piotr Bojanowski",
                "Florian Bordes",
                "Pascal Vincent",
                "Armand Joulin",
                "Mike Rabbat",
                "Nicolas Ballas"
            ],
            "title": "Masked siamese networks for label-efficient learning",
            "venue": "In European Conference on Computer Vision,",
            "year": 2022
        },
        {
            "authors": [
                "Adrien Bardes",
                "Jean Ponce",
                "Yann LeCun"
            ],
            "title": "Vicreg: Variance-invariance-covariance regularization for selfsupervised learning",
            "venue": "arXiv preprint arXiv:2105.04906,",
            "year": 2021
        },
        {
            "authors": [
                "Mathilde Caron",
                "Piotr Bojanowski",
                "Armand Joulin",
                "Matthijs Douze"
            ],
            "title": "Deep clustering for unsupervised learning of visual features",
            "venue": "In Proceedings of the European conference on computer vision (ECCV),",
            "year": 2018
        },
        {
            "authors": [
                "Mathilde Caron",
                "Ishan Misra",
                "Julien Mairal",
                "Priya Goyal",
                "Piotr Bojanowski",
                "Armand Joulin"
            ],
            "title": "Unsupervised learning of visual features by contrasting cluster assignments",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Mathilde Caron",
                "Hugo Touvron",
                "Ishan Misra",
                "Herv\u00e9 J\u00e9gou",
                "Julien Mairal",
                "Piotr Bojanowski",
                "Armand Joulin"
            ],
            "title": "Emerging properties in self-supervised vision transformers",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Ting Chen",
                "Simon Kornblith",
                "Mohammad Norouzi",
                "Geoffrey Hinton"
            ],
            "title": "A simple framework for contrastive learning of visual representations",
            "venue": "In International conference on machine learning,",
            "year": 2020
        },
        {
            "authors": [
                "Ting Chen",
                "Simon Kornblith",
                "Kevin Swersky",
                "Mohammad Norouzi",
                "Geoffrey E Hinton"
            ],
            "title": "Big self-supervised models are strong semi-supervised learners",
            "venue": "Advances in neural information proces202sing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Xinlei Chen",
                "Kaiming He"
            ],
            "title": "Exploring simple siamese representation learning",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Xinlei Chen",
                "Haoqi Fan",
                "Ross Girshick",
                "Kaiming He"
            ],
            "title": "Improved baselines with momentum contrastive learning",
            "venue": "arXiv preprint arXiv:2003.04297,",
            "year": 2020
        },
        {
            "authors": [
                "Marco Cuturi"
            ],
            "title": "Sinkhorn distances: Lightspeed computation of optimal transport",
            "venue": "Advances in neural information processing systems,",
            "year": 2013
        },
        {
            "authors": [
                "Jia Deng",
                "Wei Dong",
                "Richard Socher",
                "Li-Jia Li",
                "Kai Li",
                "Li Fei-Fei"
            ],
            "title": "Imagenet: A large-scale hierarchical image database",
            "venue": "IEEE conference on computer vision and pattern recognition,",
            "year": 2009
        },
        {
            "authors": [
                "Yaroslav Ganin",
                "Evgeniya Ustinova",
                "Hana Ajakan",
                "Pascal Germain",
                "Hugo Larochelle",
                "Fran\u00e7ois Laviolette",
                "Mario Marchand",
                "Victor Lempitsky"
            ],
            "title": "Domain-adversarial training of neural networks. The journal of machine learning",
            "year": 2030
        },
        {
            "authors": [
                "Jean-Bastien Grill",
                "Florian Strub",
                "Florent Altch\u00e9",
                "Corentin Tallec",
                "Pierre Richemond",
                "Elena Buchatskaya",
                "Carl Doersch",
                "Bernardo Avila Pires",
                "Zhaohan Guo",
                "Mohammad Gheshlaghi Azar"
            ],
            "title": "Bootstrap your own latent-a new approach to self-supervised learning",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Sivan Harary",
                "Eli Schwartz",
                "Assaf Arbelle",
                "Peter Staar",
                "Shady Abu-Hussein",
                "Elad Amrani",
                "Roei Herzig",
                "Amit Alfassy",
                "Raja Giryes",
                "Hilde Kuehne"
            ],
            "title": "Unsupervised domain generalization by learning a bridge across domains",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Kaiming He",
                "Xinlei Chen",
                "Saining Xie",
                "Yanghao Li",
                "Piotr Doll\u00e1r",
                "Ross Girshick"
            ],
            "title": "Masked autoencoders are scalable vision learners",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Judy Hoffman",
                "Eric Tzeng",
                "Taesung Park",
                "Jun-Yan Zhu",
                "Phillip Isola",
                "Kate Saenko",
                "Alexei Efros",
                "Trevor Darrell"
            ],
            "title": "Cycada: Cycle-consistent adversarial domain adaptation",
            "venue": "In International conference on machine learning,",
            "year": 2018
        },
        {
            "authors": [
                "Qianjiang Hu",
                "Xiao Wang",
                "Wei Hu",
                "Guo-Jun Qi"
            ],
            "title": "Adco: Adversarial contrast for efficient learning of unsupervised representations from self-trained negative adversaries",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Yannis Kalantidis",
                "Mert Bulent Sariyildiz",
                "Noe Pion",
                "Philippe Weinzaepfel",
                "Diane Larlus"
            ],
            "title": "Hard negative mixing for contrastive learning",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Guoliang Kang",
                "Lu Jiang",
                "Yi Yang",
                "Alexander G Hauptmann"
            ],
            "title": "Contrastive adaptation network for unsupervised domain adaptation",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Juwon Kang",
                "Sohyun Lee",
                "Namyup Kim",
                "Suha Kwak"
            ],
            "title": "Style neophile: Constantly seeking novel styles for domain generalization",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Pang Wei Koh",
                "Shiori Sagawa",
                "Henrik Marklund",
                "Sang Michael Xie",
                "Marvin Zhang",
                "Akshay Balsubramani",
                "Weihua Hu",
                "Michihiro Yasunaga",
                "Richard Lanas Phillips",
                "Irena Gao"
            ],
            "title": "Wilds: A benchmark of in-thewild distribution shifts",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Da Li",
                "Yongxin Yang",
                "Yi-Zhe Song",
                "Timothy M Hospedales"
            ],
            "title": "Deeper, broader and artier domain generalization",
            "venue": "In Proceedings of the IEEE international conference on computer vision,",
            "year": 2017
        },
        {
            "authors": [
                "Haoliang Li",
                "Sinno Jialin Pan",
                "Shiqi Wang",
                "Alex C Kot"
            ],
            "title": "Domain generalization with adversarial feature learning",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2018
        },
        {
            "authors": [
                "Pan Li",
                "Da Li",
                "Wei Li",
                "Shaogang Gong",
                "Yanwei Fu",
                "Timothy M Hospedales"
            ],
            "title": "A simple feature augmentation for domain generalization",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Ya Li",
                "Xinmei Tian",
                "Mingming Gong",
                "Yajing Liu",
                "Tongliang Liu",
                "Kun Zhang",
                "Dacheng Tao"
            ],
            "title": "Deep domain generalization via conditional invariant adversarial networks",
            "venue": "In Proceedings of the European Conference on Computer Vision (ECCV),",
            "year": 2018
        },
        {
            "authors": [
                "Xingchao Peng",
                "Qinxun Bai",
                "Xide Xia",
                "Zijun Huang",
                "Kate Saenko",
                "Bo Wang"
            ],
            "title": "Moment matching for multisource domain adaptation",
            "venue": "In Proceedings of the IEEE/CVF international conference on computer vision,",
            "year": 2019
        },
        {
            "authors": [
                "Joshua Robinson",
                "Ching-Yao Chuang",
                "Suvrit Sra",
                "Stefanie Jegelka"
            ],
            "title": "Contrastive learning with hard negative samples",
            "venue": "arXiv preprint arXiv:2010.04592,",
            "year": 2020
        },
        {
            "authors": [
                "Marin Scalbert",
                "Maria Vakalopoulou",
                "Florent Couzini\u00e9-Devy"
            ],
            "title": "Multi-source domain adaptation via supervised contrastive learning and confident consistency regularization",
            "venue": "arXiv preprint arXiv:2106.16093,",
            "year": 2021
        },
        {
            "authors": [
                "Marin Scalbert",
                "Maria Vakalopoulou",
                "Florent"
            ],
            "title": "Couzini\u00e9-Devy. Test-time image-to-image translation ensembling improves out-of-distribution generalization in histopathology",
            "venue": "In International Conference on Medical Image Computing and Computer-Assisted Intervention,",
            "year": 2022
        },
        {
            "authors": [
                "Kihyuk Sohn",
                "David Berthelot",
                "Nicholas Carlini",
                "Zizhao Zhang",
                "Han Zhang",
                "Colin A Raffel",
                "Ekin Dogus Cubuk",
                "Alexey Kurakin",
                "Chun-Liang Li"
            ],
            "title": "Fixmatch: Simplifying semi-supervised learning with consistency and confidence",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Qinwei Xu",
                "Ruipeng Zhang",
                "Ya Zhang",
                "Yanfeng Wang",
                "Qi Tian"
            ],
            "title": "A fourier-based framework for domain generalization",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Haiyang Yang",
                "Xiaotong Li",
                "Shixiang Tang",
                "Feng Zhu",
                "Yizhou Wang",
                "Meilin Chen",
                "Lei Bai",
                "Rui Zhao",
                "Wanli Ouyang"
            ],
            "title": "Cycle-consistent masked autoencoder for unsupervised domain generalization",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Haiyang Yang",
                "Shixiang Tang",
                "Meilin Chen",
                "Yizhou Wang",
                "Feng Zhu",
                "Lei Bai",
                "Rui Zhao",
                "Wanli Ouyang"
            ],
            "title": "Domain invariant masked autoencoders for self-supervised learning from multi-domains",
            "venue": "In European Conference on Computer Vision,",
            "year": 2022
        },
        {
            "authors": [
                "Yanchao Yang",
                "Stefano Soatto"
            ],
            "title": "Fda: Fourier domain adaptation for semantic segmentation",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Xingxuan Zhang",
                "Linjun Zhou",
                "Renzhe Xu",
                "Peng Cui",
                "Zheyan Shen",
                "Haoxin Liu"
            ],
            "title": "Towards unsupervised domain generalization",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Shanshan Zhao",
                "Mingming Gong",
                "Tongliang Liu",
                "Huan Fu",
                "Dacheng Tao"
            ],
            "title": "Domain generalization via entropy regularization",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Kaiyang Zhou",
                "Yongxin Yang",
                "Timothy Hospedales",
                "Tao Xiang"
            ],
            "title": "Deep domain-adversarial image generation for domain generalisation",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "Kaiyang Zhou",
                "Yongxin Yang",
                "Timothy Hospedales",
                "Tao Xiang"
            ],
            "title": "Learning to generate novel domains for domain generalization",
            "venue": "In European conference on computer vision,",
            "year": 2020
        },
        {
            "authors": [
                "Kaiyang Zhou",
                "Yongxin Yang",
                "Yu Qiao",
                "Tao Xiang"
            ],
            "title": "Domain generalization with mixstyle",
            "venue": "arXiv preprint arXiv:2104.02008,",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Motivations. In recent years, Self-Supervised Learning (SSL), has seen significant growth and success (Chen et al., 2020a; Grill et al., 2020; Caron et al., 2020; 2021; Assran et al., 2022; Bardes et al., 2021; He et al., 2022). However, SSL generally assumes that pretraining, fine-tuning and testing data come from the same domains, an assumption which does not hold true in practice and thereby limits its real-life applications. The distribution shifts between pretraining/fine-tuning domains (sources domains) and testing domains (targets domains) usually lead to poor generalization on testing domains.\nUnsupervised Domain Generalization (UDG) (Zhang et al., 2022), aims to tackle this issue by evaluating how well fine-tuned SSL models generalize to unseen target domains. In UDG, models are first pretrained on unlabeled data, fine-tuned on labeled data and finally evaluated on data from unseen domains. This work focuses on the all-correlated UDG setting which is the most standard and studied one (Zhang et al., 2022; Harary et al., 2022; Yang et al., 2022b). In this setting, unlabeled and labeled data come from the same source domains, testing data come from unseen target domains, while all cover the same classes.\nCurrent UDG methods suffer from the same drawbacks: (1) They require domain labels to reinforce domain-invariance in SSL representations, while in practice these labels may be challenging\nto obtain or even unavailable and (2) they all rely on domain-specific architectures, such as domainspecific negative queues or domain-specific decoders, that lack scalability when confronted to numerous domains. These limitations highlight the need for more practical and flexible UDG methods.\nTaking inspiration from contrastive-based UDG methods that reduce spurious correlations by restraining comparisons to examples from the same domain, we believe that removing style variability within a batch through style standardization may provide a more practical and flexible way to mitigate spurious correlations and achieve domain-invariant SSL representations without requiring any domain labels.\nContributions. To investigate the effectiveness of style standardization in mitigating spurious correlations within SSL representations with the aim of proposing more convenient and flexible UDG approaches, we introduce Batch Styles Standardization (BSS). BSS is a simple yet powerful Fourierbased method for standardizing image styles within a batch purposefully designed for integration with existing SSL methods to reinforce domain-invariance. Style standardization is performed by transferring the style of a randomly selected image to all images in the batch.\nIntegrated with existing SSL methods, it confers significant advantages over prior UDG works: (1) it reinforces domain-invariance without requiring any domain labels or domain-specific architecture, and (2) it offers simplicity and flexibility, integrating easily with contrastive-based (SimCLR (Chen et al., 2020a), SWaV (Caron et al., 2020)) but also non-contrastive-based SSL methods (MSN (Assran et al., 2022)).\nExperiments conducted on UDG datasets indicate that BSS combined with the different SSL methods yields significant performance gains on unseen domains while outperforming or competing with established UDG methods. Finally, extensive experiments have been conducted to clarify the underlying mechanisms driving BSS\u2019s effectiveness in enhancing domain-invariance in SSL representations and performances on unseen domains."
        },
        {
            "heading": "2 RELATED WORKS",
            "text": "Domain Generalization. DG aims to learn a model from multiple source domains with distinct distributions to generalize well to unseen target domains. Former DG methods have focused on aligning source features distributions using a large panel of techniques (Ganin et al., 2016; Kang et al., 2019; Li et al., 2018a;b; Peng et al., 2019; Scalbert et al., 2021; Zhao et al., 2020). Recently, the trend has shifted towards improving cross-domain generalization by refining data augmentation strategies. These strategies can be applied at either the image level (Scalbert et al., 2022; Xu et al., 2021; Yang & Soatto, 2020; Zhou et al., 2020a;b) or the feature representation level (Kang et al., 2022; Li et al., 2021; Zhou et al., 2021), and can be non-parametric (Xu et al., 2021; Zhou et al., 2021), trained adversarially during the DG task (Hoffman et al., 2018; Kang et al., 2022; Zhou et al., 2020a;b), or pretrained beforehand on source domains (Scalbert et al., 2022). Among these methods, Fourier-based Augmentations (FA) (Xu et al., 2021; Yang & Soatto, 2020) stand out as a simple and promising approach to instill domain-invariance into the representations and, thereby, enhance generalization. In this work, the proposed BSS extends FA\u2019s style transfer ability to standardize the style of images within a batch so as to strengthen domain-invariance in SSL methods.\nSelf-Supervised Learning. SSL has gained a lot of attention for its ability to efficiently pretrain models on abundant unlabeled data and subsequently fine-tune them for downstream tasks with limited labeled data. Contrastive and non-contrastive-based methods have emerged as successful approaches. The former focuses on making representations of similar examples (positives) closer while pushing apart representations of dissimilar examples (negatives). Similar examples are usually built by generating several augmented views of the same image. These methods operate either at the instance-level (Chen et al., 2020a;c; Hu et al., 2021) or cluster-level (Caron et al., 2018; 2020). Given their reliance on a large number of negatives, non-contrastive-based methods have attempted to eliminate the use of negative examples but require additional tricks to avoid collapse (Grill et al., 2020; Chen & He, 2021; Caron et al., 2021). In this work, harnessing FA and the proposed BSS, we extend both contrastive-based (SimCLR, SWaV) and non-contrastive-based (MSN) methods to strengthen domain-invariance and address UDG.\nUnsupervised Domain Generalization. Contrastive-based UDG methods (DARLING (Zhang et al., 2022), BrAD (Harary et al., 2022)) improve domain-invariance by ensuring that positive\nand negative examples share the same domain. This constraint mitigates spurious correlations within SSL representations when repelling negative examples from positive ones. To respect this constraint, DARLING exploits domain-specific adversarial negative queues while BrAD maintains domain-specific negative queues containing past representations of a momentum encoder. Additionally, BrAD learns image-to-image mappings from the different domains to a shared space and compares representations of raw and projected images. As an alternative, DiMAE (Yang et al., 2022b) and CycleMAE (Yang et al., 2022a) rely on Masked Auto-Encoder (He et al., 2022) (MAE) with domain-specific decoders to solve a cross-domain reconstruction task. However, these methods rely on domain labels and complex domain-specific architectures, limiting scalability and adaptability. Inspired by UDG contrastive methods, we propose removing style variability within a batch and without domain labels to reduce spurious correlations in SSL methods resulting in simpler and more flexible UDG approaches."
        },
        {
            "heading": "3 METHOD",
            "text": ""
        },
        {
            "heading": "3.1 PROBLEM FORMULATION",
            "text": "In the all-correlated UDG setting, an unlabeled dataset, a labeled dataset and a test dataset are provided. Unlabeled and labeled training data are drawn from the same source domains DS while testing data are drawn from unseen target domains DT . All data share the same class labels space Y . The goal of UDG is to pretrain a model on the unlabeled data, fine-tune it on the labeled data and achieve good generalization on the test dataset."
        },
        {
            "heading": "3.2 BATCH STYLES STANDARDIZATION",
            "text": ""
        },
        {
            "heading": "3.2.1 PRELIMINARIES ON FOURIER-BASED AUGMENTATIONS",
            "text": "Fourier-based Augmentations (Xu et al., 2021; Yang & Soatto, 2020) are motivated by a property of the Fourier transform: phase components tend to retain semantic information while amplitude components the style information such as intensity and textures. Therefore, to make the network prioritize semantics over style, FA randomly alters the amplitudes of images during training.\nMore formally, given an image X \u2208 RH\u00d7W , its Fourier transform F(X) along with the corresponding amplitude A(X) and phase P(X) are computed as follows:\nF(X)(u, v) = H\u2211\nh=1 W\u2211 w=1 Xh,we \u2212i2\u03c0\n h H u+ w W v  (1)\n= A(X)(u, v)e\u2212iP(X)(u,v) (2)\nwhere A(X) = \u221a Re (F(X))2 + Im (F(X))2 and P(X) = arctan ( Im (F(X)) Re (F(X)) ) (3)\nThe amplitude A(X) is then altered by substituting its low-frequency components with those of a randomly selected image A(X \u2032) resulting in the altered amplitude A\u0302(X):\nA\u0302(X)(u, v) = { A(X \u2032)(u, v) if u \u2264 r \u2217H and v \u2264 r \u2217W, A(X)(u, v) if u > r \u2217H and v > r \u2217W, (4)\nThe strength of the augmentation is controlled by the hyperparameter r \u223c U(rmin, rmax) representing the ratio between the substituted amplitude area and the entire amplitude area, where rmin and rmax stand for the minimum and maximum possible ratios. Finally, an augmented image X\u0302 with the same content as the original image X and style as the randomly chosen image X \u2032 can be built by applying the inverse Fourier transform F\u22121 onto the altered amplitude A\u0302(X) and unmodified phase P(X):\nX\u0302 = F\u22121 ( A\u0302(X)e\u2212iP(X) ) (5)"
        },
        {
            "heading": "3.2.2 EXTEND FOURIER-BASED AUGMENTATIONS FOR BATCH STYLES STANDARDIZATION",
            "text": "Drawing inspiration from contrastive-based UDG methods, we believe that removing style variability within a batch might reduce spurious correlations in SSL methods without requiring domain labels resulting in simpler and more flexible UDG approaches. Since FA possess a style transferlike ability, they can be extended to perform styles standardization/harmonization. Concretely, it can be accomplished by transferring the style of a randomly chosen image within the batch to all other images in that batch. Hence, the proposed method is referred to as Batch Styles Standardization.\nThe process of applying BSS is illustrated on Figure 1a. Specifically, given a batch of images and their corresponding Fourier transforms, we manipulate the different amplitudes by substituting their low-frequency components with those of a single randomly chosen image. Finally, after applying the inverse Fourier transform to the different modified Fourier transforms, the style of the randomly chosen image is transferred to all images, effectively standardizing/harmonizing the style. A pseudocode along with a PyTorch implementation of BSS are provided in Appendix A.\nTo highlight batch-level differences between standard FA and the proposed BSS, we display in Figure 1b and Figure 1c, a N \u00d7 V grid of augmented images generated by applying FA or BSS V times on a batch of N images. For a specific view index (column index), it is clear that augmented images produced by FA exhibit different styles whereas in the case of BSS, a unique style prevails. It is important to notice that standardized images can undergo independent geometric augmentations, but color augmentations must be batch-wise to preserve the unique style.\nAs opposed to UDG methods exploiting domain labels to restrict comparisons to examples from the same domain, standardizing the style of examples using a random style simulates as if they were drawn from the same \u201dpseudo-domain\u201d, thereby eliminating the need for domain labels. Moreover, BSS\u2019s seamless integration into existing SSL methods removes the need for UDG domain-specific components, such as domain-specific negative queues (DARLING, BRaD) or domain-specific decoders (DiMAE). Collectively, these characteristics position BSS as a simpler and more versatile solution to enhance domain-invariance within SSL methods and address UDG."
        },
        {
            "heading": "3.3 HOW TO INTEGRATE BATCH STYLES STANDARDIZATION INTO SSL METHODS?",
            "text": "Both contrastive and non-contrastive methods aim to distribute batch examples over the embedding space. This distribution can be driven by explicit contrastive loss (SimCLR) or methods preventing representation collapse like the Sinkhorn-Knopp algorithm (SWaV, MSN), centering (DINO), or variance regularization (VicReg). However, when dealing with diverse domains/styles within a batch, distributing examples may unintentionally group them by domains/styles, resulting in spuri-\nous correlations. To mitigate this, we propose applying BSS to examples undergoing this distribution. Removing style information through standardization should encourage the distribution to focus more on example semantics. In the following sections, we extend three existing SSL methods (SimCLR, SWaV and MSN) and detail where and how BSS should be integrated. For further technical details about the regular SSL methods, readers may refer to Appendix B or the original papers.\nSIMCLR aims to bring representations of several views of the same image closer (positives) while repelling all other images representations (negatives). In standard SimCLR, each image in a batch of N images is augmented V times resulting in V positive examples. However, this can result in positive examples with domains/styles that differ from those of the negatives (see Figure 1b), risking unintentional exploitation of this style/domain discrepancy to solve the contrastive task and causing spurious correlations. To address this, we suggest independently applying BSS V times to the initial batch, ensuring that positive and negative examples share the same styles (see Figure 1c).\nSWAV computes representations of several views of the same image and clusters them using an online algorithm. Given that representations should capture similar information, SWaV enforces consistency between representations and cluster assignments produced from different views. To obtain these cluster assignments, the Sinkhorn-Klopp (SK) algorithm (Cuturi, 2013) is performed on the representations. Concretely, SK solves an optimal transport problem whose constraints are to assign representations to the most similar centroids/prototypes while keeping a uniform assignment distribution over centroids/prototypes. However, if several domains/styles are present within views subject to SK, there is a risk of assigning and grouping the corresponding representations using domain/style information resulting in spurious correlations. To address this, we propose to standardize the style of views subject to SK using BSS. In practice, SWaV employs a multi-crop strategy, generating 2 global views (large crops) and V local views (small crops) for each image. In this setting, cluster assignments are computed only from the global views while representations are derived from all views. Therefore, we suggest applying BSS only on the global views and augmenting the local views using FA. As this results in two batches of global views, each with its own style, SK is performed on each batch separately.\nMSN aims to match the representations of masked views of the same image with that of an unmasked view. To derive a view\u2019s representation, MSN computes similarities between its embedding and a set of learnable cluster centroids/prototypes and subsequently transforms them into a probability distribution. Since direct matching between masked and unmasked views\u2019 representations can lead to representation collapse, MSN simultaneously optimizes a cross-entropy term along with an entropy regularization term on the mean representation of the masked views. This regularization term encourages the model to use the entire set of centroids/prototypes. Additionally, MSN employs SK on the representations of the unmasked views to avoid tuning the hyperparameter weighting the entropy regularization term. Similarly to SWaV, if several domains/styles are present within unmasked views, assigning the corresponding representations using SK may group examples using domain/style information. To address this, we propose to standardize the style of unmasked views using BSS while we recommend augmenting masked views using FA."
        },
        {
            "heading": "4 RESULTS",
            "text": ""
        },
        {
            "heading": "4.1 DATASETS",
            "text": "To evaluate the extended SSL methods, experiments were conducted on 3 datasets commonly used for benchmarking DG / UDG methods, namely PACS, DomainNet and Camelyon17 WILDS.\nPACS (Li et al., 2017) contains 4 domains (photo, art painting, cartoon, sketch) and 7 classes. DomainNet (Peng et al., 2019) contains 6 different domains (clipart, infograph, quickdraw, painting, real and sketch) and covers 345 classes. Following prior UDG works (Harary et al., 2022; Yang et al., 2022b; Zhang et al., 2022), a subset of DomainNet including 20 classes out of the 345 available classes is considered. Camelyon17 WILDS (Koh et al., 2021) includes images covering 2 classes (tumor, no tumor) from 5 domains (hospitals). It is split into train, val, and test subsets comprising respectively 3, 1, and 1 distinct domains."
        },
        {
            "heading": "4.2 EXPERIMENTAL SETUP",
            "text": "Following the standard UDG evaluation protocol (Zhang et al., 2022), models were pretrained on source data in an unsupervised way, fine-tuned on a fraction of the source data and finally evaluated on the target data. For the pretraining step, all our models were trained using FA or BSS without Imagenet (Deng et al., 2009) transfer learning, except on DomainNet to allow fair comparisons with prior UDG works. In Appendix D.1, the choice of using transfer learning within a DG/UDG context is further discussed while additional experiments on PACS reveal that SSL methods tend to benefit unfairly from ImageNet transfer learning. For the fine-tuning step, following BrAD, on PACS and DomainNet, all the models were fine-tuned via linear probing except when considering the entire PACS dataset where full fine-tuning was performed like DARLING and DiMAE. On Camelyon17 WILDS, linear probing was performed for each fraction of labeled data. Pretraining and fine-tuning implementation details are provided in Appendix C."
        },
        {
            "heading": "4.3 EXPERIMENTAL RESULTS",
            "text": "In the following experiments, the proposed extended SSL methods are compared to regular SSL methods (MoCo V2 (Chen et al., 2020c), SimCLR V2 (Chen et al., 2020b), BYOL (Grill et al., 2020), AdCo (Hu et al., 2021), MAE (He et al., 2022)) and UDG methods (DARLING, DiMAE, BRaD, CycleMAE). For Camelyon17 WILDS, the extended SSL methods are compared to reimplemented UDG methods (DARLING, DiMAE) but also to the Semi-Supervised Learning method FixMatch (Sohn et al., 2020) and SSL method SWaV trained with additional data from the target.\nPACS. For each combination of (sources, target) domains, each fraction of labeled data and each of our SSL models, averaged accuracy over 3 independent runs are reported on Table 1. Compared to FA, integrating BSS to SimCLR or SWaV, significantly improves the overall accuracy (avg.): SimCLR \u2192 (+2.96%,+4.55%,+3.61%,+3.6%); SWaV \u2192 (+5.3%,+5.9%,+5.46%,+1.52%) for the fractions of labeled data 1%, 5%, 10% and 100%, respectively. Extended SSL methods with BSS outperform most of the time other methods, except for the target domain photo (BrAD, DiMAE, CycleMAE) or in the 10% (DiMAE) and 100% (DiMAE, CycleMAE) labeled data settings. For the target domain photo, one possible explanation is that other methods benefit from transfer learning on ImageNet while for the 10% and 100% labeled data settings, DiMAE and CycleMAE consider different experimental settings (ViT-base architecture, full fine-tuning on 10%.)\nDomainNet. Following prior UDG methods, painting, real and sketch were selected as source domains and others as target domains. The reversed domains combination was also considered. For these two combinations, for each fraction of labeled data (1%, 5% and 10%) and each of our SSL models, we report on Table 2, the accuracy on each target domain, the per-domain averaged accuracy and the overall accuracy. The presented results are averaged over 3 independent runs. When inte-\ngrating BSS, almost all target domain accuracies increase while per-domain-averaged accuracy always improves: SimCLR \u2192 (+1.51%,+1.16%,+1.33%); SWaV \u2192 (+2.08%,+1.61%,+1.11%) for the labeled data fractions 1%, 5% and 10%, respectively.\nCamelyon17 WILDS. Averaged accuracy over 10 independent runs, for different fractions of labeled data, on the test split are reported on Table 3. To ensure fair comparisons, the reimplemented methods DARLING and DiMAE used identical pretraining and fine-tuning hyperparameters as extended SSL methods. For each extended SSL method, BSS leads to substantial performance gains\nranging from +1.45% to +4.49% resulting in state-of-the-art performances. Extended SSL methods with BSS even surpass methods trained with additional unlabeled target data."
        },
        {
            "heading": "5 ABLATION STUDIES AND ADDITIONAL EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "5.1 AUGMENTATION STRATEGY ABLATION STUDY",
            "text": "To evaluate the benefits of each component in our augmentation strategy (BSS + additional augmentations) on performances, we pretrained a model on Camelyon17 WILDS using SimCLR and different combinations of components. For each combination and each fraction of labeled data, averaged accuracy over 10 independent runs are reported in Table 4. Sample-wise color jittering and\nno FA or BSS, resulting in the regular SimCLR, leads to poor performance for the different fractions of labeled data. Changing the color-jittering from sample-wise to batch-wise slightly improves performances suggesting that even reducing the styles variability of augmented images helps for generalization. FA leads to drastic performance gains compared to the regular SimCLR which is not surprising given their prior success in DG tasks. Combining SimCLR with BSS and batch-wise color-jitter yields even greater performance improvements and non-negligible gains compared to FA. This observation is also supported by results from Tables 1, 2, 3."
        },
        {
            "heading": "5.2 UNDERLYING MECHANISMS INVOLVED IN BSS EFFICIENCY",
            "text": "Spurious correlations reduction, harder negatives creation and reduced batch size requirement (SimCLR). We hypothesized that BSS should help reduce the emergence of spurious correlations when repelling negatives from positives. Additionally, standardizing styles among positives and negatives should also facilitate the creation of harder negatives, a known factor contributing to robust performance (Kalantidis et al., 2020; Robinson et al., 2020), while also reducing the demand for large batch sizes. To validate these hypotheses, we conducted 3 comprehensive experiments employing SimCLR with standard augmentation, FA, or BSS on Camelyon17 WILDS: (1) To validate BSS\u2019s effectiveness in reducing spurious correlations, we computed the averaged domain purity for representations of unseen source and target examples after pretraining. This metric, which quantifies the degree to which each example and its nearest neighbors share the same domain label, serves as an indicator of the domain-invariance within SSL representations (refer to Figure 2a). (2) To assess the impact of BSS on encouraging the presence of harder negatives, we computed representations for several augmented batches and calculated cosine similarities across all possible (anchor, negative) pairs, reporting the values in a histogram (refer to Figure 2b). (3) Lastly, to assess BSS\u2019s ability to mitigate the demand for large batch sizes, we pretrained SimCLR varying batch sizes and assessed performance using linear probing (refer to Figure 2c). Figure 2a demonstrates that SimCLR with FA exhibits slightly lower average domain purity than standard SimCLR while SimCLR with BSS results in much lower average domain purity. This observation affirms BSS\u2019s effectiveness in attenuating spurious correlations and enhancing domain-invariance. Figure 2b indicates that standard SimCLR tends to produce negatives that are dissimilar to the anchors. SimCLR with FA produces negatives more similar to the anchors but not to the same extent as SimCLR with BSS which confirms BSS\u2019s role in creating harder negatives. Finally, Figure 2c reveals that standard SimCLR yields considerably lower performances compared to SimCLR with FA or with BSS. FA and BSS lead to improved performances for any batch size. As batch size increases, performances augment until a plateau is reached. However, when using BSS, this plateau is reached for a lower batch size supporting BSS\u2019s efficacy in reducing the need for large batches.\n(a) Average domain purity varying number of nearest neighbors (b) (Anchor, negative) cosine similarities (c) Linear-probing accuracy varying batch size N\nFigure 2: SimCLR experiments with standard augmentation, FA or BSS on Camelyon17 WILDS.\nBetter domain heterogeneity and class homogeneity for examples assigned to the same prototype (SWaV, MSN). We postulated that the coexistence of multiple domains/styles within views used for cluster assignments computation (i.e.: global views for SWaV and unmasked views for MSN) could introduce correlations between the assignments and domains/styles. To investigate the effectiveness of BSS in mitigating these correlations and shed light on why BSS yields superior representations compared to FA, we conducted the following experiment: We pretrained a backbone with SWaV using FA or BSS on DomainNet (sources: painting \u222a real \u222a sketch, targets: clipart \u222a infograph \u222a quickdraw). During training, at every 1K optimization step, we computed representations from unseen source and target examples along with their hard assignments resulting from SK. Subsequently, we evaluated the homogeneity of representations assigned to each prototype in terms of domain or class labels and averaged the homogeneity scores over all prototypes. The evolution of the averaged homogeneity score with respect to domain or class labels are respectively reported in Figure 3a and Figure 3b. Figure 3a reveals that employing BSS instead of\nFA tends to reduce domain homogeneity (or improve domain heterogeneity) among representations assigned to the same prototype. This observation confirms BSS\u2019s role in reducing correlations between assignments and domains. Conversely, Figure 3b illustrates that BSS results in higher class label homogeneity attesting that BSS helps to produce assignments more semantically coherent."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "This work introduces Batch Styles Standardization, an image style standardization technique to be combined with existing SSL methods to address UDG. Extending existing SSL methods with BSS offers serious advantages over prior UDG methods, including the elimination of domain labels and domain-specific network components dependencies to enhance domain-invariance while offering versatility for integration. Leveraging BSS, the extended SSL methods exhibit improved generalization capabilities, often surpassing or competing with alternative UDG strategies. Comprehensive experiments provide insights into the underlying mechanisms involved in BSS\u2019s efficiency. Other style transfer techniques, like GAN-based methods or AdaIN, could standardize image style to reduce spurious correlations in SSL. However, we leave this exploration for future research."
        },
        {
            "heading": "7 ACKNOWLEDGEMENTS",
            "text": "This project was provided with computer and storage resources by GENCI at IDRIS thanks to the grant 2022-AD011013424R1 on the supercomputer Jean Zay\u2019s V100 partition. This work was also partially supported by ANR-21-CE45-0007 (Hagnodice). We would like to express our sincere gratitude to Spyros Gidaris and Enzo Ferrante for their valuable feedback and comments, which greatly contributed to the improvement of this research."
        }
    ],
    "year": 2024
}