{
    "abstractText": "In the past several years, the last-iterate convergence of the Stochastic Gradient Descent (SGD) algorithm has triggered people\u2019s interest due to its good performance in practice but lack of theoretical understanding. For Lipschitz convex functions, different works have established the optimal O(log(1/\u03b4) log T/ \u221a T ) or O( \u221a log(1/\u03b4)/T ) high-probability convergence rates for the final iterate, where T is the time horizon and \u03b4 is the failure probability. However, to prove these bounds, all the existing works are either limited to compact domains or require almost surely bounded noises. It is natural to ask whether the last iterate of SGD can still guarantee the optimal convergence rate but without these two restrictive assumptions. Besides this important question, there are still lots of theoretical problems lacking an answer. For example, compared with the last-iterate convergence of SGD for non-smooth problems, only few results for smooth optimization have yet been developed. Additionally, the existing results are all limited to a non-composite objective and the standard Euclidean norm. It still remains unclear whether the last-iterate convergence can be provably extended to wider composite optimization and non-Euclidean norms. In this work, to address the issues mentioned above, we revisit the last-iterate convergence of stochastic gradient methods and provide the first unified way to prove the convergence rates both in expectation and in high probability to accommodate general domains, composite objectives, non-Euclidean norms, Lipschitz conditions, smoothness, and (strong) convexity simultaneously.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zijian Liu"
        },
        {
            "affiliations": [],
            "name": "Zhengyuan Zhou"
        }
    ],
    "id": "SP:431310e5f71650138a5700ee074b6af229a9f380",
    "references": [
        {
            "authors": [
                "Amir Beck",
                "Marc Teboulle"
            ],
            "title": "Mirror descent and nonlinear projected subgradient methods for convex optimization",
            "venue": "Operations Research Letters,",
            "year": 2003
        },
        {
            "authors": [
                "Damek Davis",
                "Dmitriy Drusvyatskiy"
            ],
            "title": "High probability guarantees for stochastic convex optimization",
            "venue": "In Conference on Learning Theory,",
            "year": 2020
        },
        {
            "authors": [
                "John Duchi",
                "Elad Hazan",
                "Yoram Singer"
            ],
            "title": "Adaptive subgradient methods for online learning and stochastic optimization",
            "venue": "Journal of machine learning research,",
            "year": 2011
        },
        {
            "authors": [
                "John C Duchi",
                "Shai Shalev-Shwartz",
                "Yoram Singer",
                "Ambuj Tewari"
            ],
            "title": "Composite objective mirror descent",
            "venue": "In COLT,",
            "year": 2010
        },
        {
            "authors": [
                "Rong Ge",
                "Sham M Kakade",
                "Rahul Kidambi",
                "Praneeth Netrapalli"
            ],
            "title": "The step decay schedule: A near optimal, geometrically decaying learning rate procedure for least squares",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "Eduard Gorbunov",
                "Marina Danilova",
                "Alexander Gasnikov"
            ],
            "title": "Stochastic optimization with heavytailed noise via accelerated gradient clipping",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Robert Gower",
                "Othmane Sebbouh",
                "Nicolas Loizou"
            ],
            "title": "Sgd for structured nonconvex functions: Learning rates, minibatching and interpolation",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2021
        },
        {
            "authors": [
                "Nicholas JA Harvey",
                "Christopher Liaw",
                "Yaniv Plan",
                "Sikander Randhawa"
            ],
            "title": "Tight analyses for nonsmooth stochastic gradient descent",
            "venue": "In Conference on Learning Theory,",
            "year": 2019
        },
        {
            "authors": [
                "Nicholas JA Harvey",
                "Christopher Liaw",
                "Sikander Randhawa"
            ],
            "title": "Simple and optimal high-probability bounds for strongly-convex stochastic gradient descent",
            "venue": "arXiv preprint arXiv:1909.00843,",
            "year": 2019
        },
        {
            "authors": [
                "Elad Hazan",
                "Satyen Kale"
            ],
            "title": "Beyond the regret minimization barrier: optimal algorithms for stochastic strongly-convex optimization",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2014
        },
        {
            "authors": [
                "Prateek Jain",
                "Dheeraj M. Nagaraj",
                "Praneeth Netrapalli"
            ],
            "title": "Making the last iterate of sgd information theoretically optimal",
            "venue": "SIAM Journal on Optimization,",
            "year": 2021
        },
        {
            "authors": [
                "Ahmed Khaled",
                "Peter Richt\u00e1rik"
            ],
            "title": "Better theory for SGD in the nonconvex world",
            "venue": "Transactions on Machine Learning Research,",
            "year": 2023
        },
        {
            "authors": [
                "Simon Lacoste-Julien",
                "Mark Schmidt",
                "Francis Bach"
            ],
            "title": "A simpler approach to obtaining an o (1/t) convergence rate for the projected stochastic subgradient method",
            "venue": "arXiv preprint arXiv:1212.2002,",
            "year": 2012
        },
        {
            "authors": [
                "Guanghui Lan"
            ],
            "title": "First-order and stochastic optimization methods for machine",
            "year": 2020
        },
        {
            "authors": [
                "Yunwen Lei",
                "Ding-Xuan Zhou"
            ],
            "title": "Analysis of online composite mirror descent algorithm",
            "venue": "Neural computation,",
            "year": 2017
        },
        {
            "authors": [
                "Daogao Liu",
                "Zhou Lu"
            ],
            "title": "The convergence rate of sgd\u2019s final iterate: Analysis on dimension dependence",
            "venue": "arXiv preprint arXiv:2106.14588,",
            "year": 2021
        },
        {
            "authors": [
                "Zijian Liu",
                "Ta Duy Nguyen",
                "Thien Hang Nguyen",
                "Alina Ene",
                "Huy Nguyen"
            ],
            "title": "High probability convergence of stochastic gradient methods",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Haihao Lu",
                "Robert M Freund",
                "Yurii Nesterov"
            ],
            "title": "Relatively smooth convex optimization by firstorder methods, and applications",
            "venue": "SIAM Journal on Optimization,",
            "year": 2018
        },
        {
            "authors": [
                "H. Brendan McMahan",
                "Matthew J. Streeter"
            ],
            "title": "Adaptive bound optimization for online convex optimization",
            "venue": "In Conference on Learning Theory (COLT),",
            "year": 2010
        },
        {
            "authors": [
                "Eric Moulines",
                "Francis Bach"
            ],
            "title": "Non-asymptotic analysis of stochastic approximation algorithms for machine learning",
            "venue": "Advances in neural information processing systems,",
            "year": 2011
        },
        {
            "authors": [
                "Arkadi Nemirovski",
                "David Yudin"
            ],
            "title": "Problem complexity and method efficiency in optimization",
            "year": 1983
        },
        {
            "authors": [
                "Yu Nesterov",
                "Vladimir Shikhman"
            ],
            "title": "Quasi-monotone subgradient methods for nonsmooth convex minimization",
            "venue": "Journal of Optimization Theory and Applications,",
            "year": 2015
        },
        {
            "authors": [
                "Francesco Orabona",
                "D\u00e1vid P\u00e1l"
            ],
            "title": "Parameter-free stochastic optimization of variationally coherent functions",
            "venue": "arXiv preprint arXiv:2102.00236,",
            "year": 2021
        },
        {
            "authors": [
                "Rui Pan",
                "Haishan Ye",
                "Tong Zhang"
            ],
            "title": "Eigencurve: Optimal learning rate schedule for SGD on quadratic objectives with skewed hessian spectrums",
            "venue": "In International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Alexander Rakhlin",
                "Ohad Shamir",
                "Karthik Sridharan"
            ],
            "title": "Making gradient descent optimal for strongly convex stochastic optimization",
            "venue": "arXiv preprint arXiv:1109.5647,",
            "year": 2011
        },
        {
            "authors": [
                "Herbert Robbins",
                "Sutton Monro"
            ],
            "title": "A stochastic approximation method",
            "venue": "The annals of mathematical statistics,",
            "year": 1951
        },
        {
            "authors": [
                "Abdurakhmon Sadiev",
                "Marina Danilova",
                "Eduard Gorbunov",
                "Samuel Horv\u00e1th",
                "Gauthier Gidel",
                "Pavel Dvurechensky",
                "Alexander Gasnikov",
                "Peter Richt\u00e1rik"
            ],
            "title": "High-probability bounds for stochastic optimization and variational inequalities: the case of unbounded variance",
            "venue": "arXiv preprint arXiv:2302.00999,",
            "year": 2023
        },
        {
            "authors": [
                "Shai Shalev-Shwartz",
                "Yoram Singer",
                "Nathan Srebro"
            ],
            "title": "Pegasos: Primal estimated sub-gradient solver for svm",
            "venue": "In Proceedings of the 24th international conference on Machine learning,",
            "year": 2007
        },
        {
            "authors": [
                "Ohad Shamir",
                "Tong Zhang"
            ],
            "title": "Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes",
            "venue": "In International conference on machine learning,",
            "year": 2013
        },
        {
            "authors": [
                "Aditya Vardhan Varre",
                "Loucas Pillaud-Vivien",
                "Nicolas"
            ],
            "title": "Flammarion. Last iterate convergence of sgd for least-squares in the interpolation regime",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Roman Vershynin"
            ],
            "title": "High-dimensional probability: An introduction with applications in data science, volume 47",
            "year": 2018
        },
        {
            "authors": [
                "Jingfeng Wu",
                "Difan Zou",
                "Vladimir Braverman",
                "Quanquan Gu",
                "Sham Kakade"
            ],
            "title": "Last iterate risk bounds of sgd with decaying stepsize for overparameterized linear regression",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Moslem Zamani",
                "Fran\u00e7ois Glineur"
            ],
            "title": "Exact convergence rate of the last iterate in subgradient methods",
            "venue": "arXiv preprint arXiv:2307.11134,",
            "year": 2023
        }
    ],
    "sections": [
        {
            "text": "\u221a T ) or O( \u221a log(1/\u03b4)/T ) high-probability convergence rates for the final iterate, where T is the time horizon and \u03b4 is the failure probability. However, to prove these bounds, all the existing works are either limited to compact domains or require almost surely bounded noises. It is natural to ask whether the last iterate of SGD can still guarantee the optimal convergence rate but without these two restrictive assumptions. Besides this important question, there are still lots of theoretical problems lacking an answer. For example, compared with the last-iterate convergence of SGD for non-smooth problems, only few results for smooth optimization have yet been developed. Additionally, the existing results are all limited to a non-composite objective and the standard Euclidean norm. It still remains unclear whether the last-iterate convergence can be provably extended to wider composite optimization and non-Euclidean norms. In this work, to address the issues mentioned above, we revisit the last-iterate convergence of stochastic gradient methods and provide the first unified way to prove the convergence rates both in expectation and in high probability to accommodate general domains, composite objectives, non-Euclidean norms, Lipschitz conditions, smoothness, and (strong) convexity simultaneously.\n1 INTRODUCTION\nIn this paper, we consider the constrained composite optimization problem minx\u2208X F (x) := f(x)+ h(x) where both f(x) and h(x) are convex (but possibly satisfying additional conditions such as strong convexity, smoothness, etc.) and X \u2286 Rd is a nonempty closed convex set. Since a true gradient is computationally prohibitive to obtain (e.g., large-scale machine learning tasks) or even infeasible to access (e.g., streaming data), the classic Stochastic Gradient Descent (SGD) (Robbins & Monro, 1951) algorithm has emerged to be the gold standard for a light-weight yet effective computational procedure commonly adopted in production for the majority of machine learning tasks: SGD only requires a stochastic first-order oracle \u2202\u0302f(x) satisfying E[\u2202\u0302f(x) | x] \u2208 \u2202f(x) where \u2202f(x) denotes the set of subgradients at x and guarantees provable convergence under certain conditions (e.g., Lipschitz condition for f(x) and finite variance on the stochastic oracle).\nA particularly important problem in this area is to understand the last-iterate convergence of SGD, which has been motivated by experimental studies suggesting that returning the final iterate of SGD (or sometimes the average of the last few iterates) \u2013 rather than a running average \u2013 often yields a solution that works well in practice (e.g., Shalev-Shwartz et al. (2007)). As such, a fruitful line of literature (Rakhlin et al., 2011; Shamir & Zhang, 2013; Harvey et al., 2019a; Orabona, 2020; Jain et al., 2021) developed an extensive theoretical understanding of the non-asymptotic last-iterate convergence rate. Loosely speaking, two optimal upper bounds, O\u0303(1/ \u221a T ) for Lipschitz convex functions\n\u2217An extended version including more results is available at https://arxiv.org/abs/2312.08531. \u2020Corresponding author.\nand O\u0303(1/T ) for Lipschitz strongly convex functions, have been established for both expected and high-probability convergence when h(x) = 0 (see Subsection 1.2 for a detailed discussion). However, to prove the high-probability rates, the existing works rely on restrictive assumptions: compact domains or almost surely bounded noises (or both), which can simplify the analysis but are unrealistic in lots of problems. Until today, whether these two assumptions can be relaxed simultaneously or not still remains unclear. Naturally, we want to ask the following question:\nQ1: Is it possible to prove the high-probability last-iterate convergence of SGD for Lipschitz (strongly) convex functions without the compact domain assumption and beyond bounded noises?\nCompared with the fast development of non-smooth problems, the understanding of the last-iterate convergence of SGD for smooth problems (i.e., the gradients of f(x) are Lipschitz) is much slower. The best expected bound for smooth convex optimization under X = Rd until now is stillO(1/ 3 \u221a T ) due to Moulines & Bach (2011), which is far from the optimal rate O(1/ \u221a T ) of the averaging output (Theorem 4.2 in Lan (2020)). However, temporarily suppose the domain is compact, one can immediately improve the rate from O(1/ 3 \u221a T ) to O\u0303(1/ \u221a T ) by noticing that we can reduce the smooth problem to the Lipschitz problem1 and use the known bounds from non-smooth convex optimization. Hence, one may expect the last-iterate convergence rate of SGD for smooth convex optimization should still be O(1/ \u221a T ) for any kind of domain. If one further considers smooth and strongly convex problems, as far as we know, no formal result has been established for the final iterate of SGD in a general domain except for the expected O(1/T ) rate when X = Rd under the PL-condition (which is known as a relaxation for strong convexity) (Gower et al., 2021; Khaled & Richt\u00e1rik, 2023). The above discussion thereby leads us to the second main question:\nQ2: Does the last iterate of SGD provably converge in the rate of O(1/ \u221a T ) for smooth and convex\nfunctions and O(1/T ) for smooth and strongly convex functions in a general domain?\nBesides the two aforementioned questions, there are still several important missing parts. First, recalling that our original goal is to optimize the composite objective F (x) = f(x) + h(x), it is still unclear whether \u2013 and if so, how \u2013 the last-iterate convergence of this harder problem can be proved. Moreover, the previous works are limited to the standard Euclidean norm. Whereas, in lots of specialized tasks, it may be beneficial to employ a general norm instead of the \u21132 norm to capture the non-Euclidean structure. However, whether this extension can be done remains open. Additionally, the proof techniques in the existing works vary in different settings, which builds a barrier for researchers to better understand the convergence of the last iterate of SGD. Motivated by these challenges, we would like to ask the final question:\nQ3: Is there a unified way to analyze the last-iterate convergence of stochastic gradient methods both in expectation and in high probability to accommodate general domains, composite\nobjectives, non-Euclidean norms, Lipschitz conditions, smoothness, and (strong) convexity at once?\n1.1 OUR CONTRIBUTIONS\nWe provide affirmative answers to the above three questions and establish several new results by revisiting a simple algorithm, Composite Stochastic Mirror Descent (CSMD) (Duchi et al., 2010), which is based on the famous Mirror Descent (MD) algorithm (Nemirovski & Yudin, 1983; Beck & Teboulle, 2003) and includes SGD as a special case. Specifically, our contributions are as follows.\n\u2022 We establish the first high-probability convergence result for the last iterate of CSMD in general domains under sub-Gaussian noises to answer Q1 affirmatively. \u2022 We prove the last iterate of CSMD can converge in the rate of O\u0303(1/ \u221a T ) for smooth convex\noptimization and O\u0303(1/T ) for smooth strongly convex problems both in expectation and in high probability for any general domain X , hence resolving Q2.\n\u2022 We present a simple unified analysis that differs from the prior works and can be directly applied to various scenarios simultaneously, thus leading to a positive answer to Q3.\n1To see why gradients are bounded in this case, we first fix a point x0 in the domain. Then by smoothness, there is \u2225\u2207f(x)\u2212\u2207f(x0)\u22252 = O(\u2225x\u2212x0\u22252) for any other point x, which immediately implies \u2225\u2207f(x)\u22252 = O(\u2225x\u2212 x0\u22252 + \u2225\u2207f(x0)\u22252) = O(D + \u2225\u2207f(x0)\u22252) where D is the domain diameter.\n1.2 RELATED WORK\nWe review the literature related to the last-iterate convergence of plain stochastic gradient methods2 measured by the function value gap (see Subsection 2.1 for why we use this criterion) for both Lipschitz and smooth (strongly) convex optimization. We only focus on the algorithms without momentum or averaging since it is already known that, without further special assumptions, both operations cannot help to improve the lower order term O(1/ \u221a T ) for general convex functions and O(1/T ) for strongly convex functions. For the last iterate of accelerated or averaging based stochastic gradient methods, we refer the reader to Nesterov & Shikhman (2015); Lan (2020); Orabona & P\u00e1l (2021) for in-expectation rates and Davis & Drusvyatskiy (2020); Gorbunov et al. (2020); Liu et al. (2023); Sadiev et al. (2023) for high-probability bounds. As for the last iterate of stochastic gradient methods for structured problems (e.g., linear regression), the reader can refer to Lei & Zhou (2017); Ge et al. (2019); Varre et al. (2021); Pan et al. (2022); Wu et al. (2022) for recent progress.\nLast iterate for Lipschitz (strongly) convex functions: Rakhlin et al. (2011) is the first to show an expected O(1/T ) convergence for strongly convex functions. But such a bound is obtained under the additional assumption, smoothness with respect to optimum3, meaning their result does not hold in general. Later on, Shamir & Zhang (2013) proves the first expected last-iterate rates O(log T/ \u221a T ) and O(log T/T ) for convex and strongly convex objectives, respectively. The highprobability bounds turn out to be much harder than the expected rates. After several years, Harvey et al. (2019a) is the first to establish a high-probability bound in the rate of O(log(1/\u03b4) log T/ \u221a T ) and O(log(1/\u03b4) log T/T ) for convex and strongly convex problems where \u03b4 is the probability of failure. Afterward, Jain et al. (2021) improves the previous two rates to O( \u221a log(1/\u03b4)/T ) and O(log(1/\u03b4)/T ) but with a non-standard step size schedule. They also prove the expected rates O(1/ \u221a T ) and O(1/T ) under the new step size.\nHowever, a main drawback for the general convex case in all the above papers is requiring a compact domain. To our best knowledge, Orabona (2020) is the first and the only work showing how to shave off this restriction, and thereby obtains an expected O(log T/ \u221a T ) rate for general domains yet it is unclear whether his proof can be extended to the high-probability case or not. Until recently, Zamani & Glineur (2023) exhibits a new proof on how to obtain the convergence rate for the last iterate but only for the deterministic case. Lastly, we would like to mention that all of these prior results are built for a non-composite objective f(x) with the standard Euclidean norm.\nLast iterate for smooth (strongly) convex functions: Compared with Lipschitz problems, much less work is done for smooth optimization. As far as we know, the only result showing a nonasymptotic rate for smooth convex functions dates back to Moulines & Bach (2011), in which the authors prove that the last iterate of SGD on Rd enjoys the expected rate O(1/ 3 \u221a T ) under additional restrictive assumptions (e.g., mean squared smoothness). As for the strongly convex case, the expected rate O(1/T ) under the PL-condition (which is known as a relaxation for strong convexity) has been established but only for non-composite optimization under the Euclidean norm on the domain X = Rd (Gower et al., 2021; Khaled & Richt\u00e1rik, 2023). Lower bounds for last iterate: Under the requirement d = T where d is the dimension of the problem, Harvey et al. (2019a) is the first to provide lower bounds \u2126(log T/ \u221a T ) under the step size \u0398(1/ \u221a t) for non-smooth convex functions and \u2126(log T/T ) under the step size \u0398(1/t) when strong convexity is additionally assumed. Note that these two rates are both proved for deterministic optimization meaning that they can be also applied to the expected lower bounds. Subsequently, when d < T holds, Liu & Lu (2021) extends the above two lower bounds to \u2126(log d/ \u221a T ) (this bound is also true for the step size \u0398(1/ \u221a T )) and \u2126(log d/T ) under the same step size in Harvey et al. (2019a). As a consequence, lower bounds \u2126(log(d\u2227T )/T ) and \u2126(log(d\u2227T )/ \u221a T ) have been established for both convex and strongly convex problems under the Lipschitz condition. For the high-probability bounds, Harvey et al. (2019a) shows their two deterministic bounds will incur an extra multiplicative factor \u2126(log(1/\u03b4)), namely, \u2126(log(1/\u03b4) log T/ \u221a T ) and \u2126(log(1/\u03b4) log T/T ). However, under more sophisticated designed step sizes, better upper bounds without the \u2126(log T ) factor are possible, for example, see Jain et al. (2021) as mentioned above.\n2To clarify, we mean the algorithm does not contain momentum or averaging operations. 3This means \u2203L > 0 such that f(x)\u2212 f(x\u2217) \u2264 L\n2 \u2225x\u2212 x\u2217\u22252,\u2200x \u2208 X where x\u2217 \u2208 argminx\u2208X f(x).\nAnother highly related work is Liu et al. (2023), which presents a generic approach to establish the high-probability convergence of the average iterate under sub-Gaussian noises. We will show that their idea can be further used to prove the high-probability convergence for the last iterate.\n2 PRELIMINARIES\nNotations: N is the set of natural numbers (excluding 0). [d] := {1, 2, \u00b7 \u00b7 \u00b7 , d} for any d \u2208 N. a \u2228 b and a\u2227b are defined as max {a, b} and min {a, b}, respectively. \u27e8\u00b7, \u00b7\u27e9 is the standard Euclidean inner product on Rd. \u2225 \u00b7\u2225 represents a general norm on Rd and \u2225 \u00b7\u2225\u2217 is its dual norm. Given a setA \u2286 Rd, int(A) stands for its interior points. For a function f , \u2202f(x) denotes the set of subgradients at x.\nWe focus on the following optimization problem in this work min x\u2208X F (x) := f(x) + h(x),\nwhere f and h are both convex. X \u2286 int(dom(f)) \u2286 Rd is a closed convex set. The requirement of X \u2286 int(dom(f)) is only to guarantee the existence of \u2202f(x) for every point x in X with no special reason. We emphasize that there is no compactness requirement on X . Additionally, given \u03c8 being a differentiable and 1-strongly convex function with respect to \u2225 \u00b7 \u2225 on X (i.e., \u03c8(x) \u2265 \u03c8(y) + \u27e8\u2207\u03c8(y), x \u2212 y\u27e9 + 12\u2225x \u2212 y\u2225\n2,\u2200x, y \u2208 X 4), the Bregman divergence with respect to \u03c8 is defined as D\u03c8(x, y) := \u03c8(x) \u2212 \u03c8(y) \u2212 \u27e8\u2207\u03c8(y), x \u2212 y\u27e9. Throughout this paper, we assume that argminx\u2208Xh(x) + \u27e8g, x\u2212 y\u27e9+ D\u03c8(x,y) \u03b7 can be solved efficiently for any g \u2208 R d, y \u2208 X , \u03b7 > 0.\nNext, we list the assumptions used in our analysis:\n1. Existence of a local minimizer: \u2203x\u2217 \u2208 argminx\u2208X F (x) satisfying F (x\u2217) > \u2212\u221e. 2. (\u00b5f , \u00b5h)-strongly convex: For k = f and k = h, \u2203\u00b5k \u2265 0 such that \u00b5kD\u03c8(x, y) \u2264 k(x) \u2212 k(y)\u2212 \u27e8g, x\u2212 y\u27e9,\u2200x, y \u2208 X , g \u2208 \u2202k(y). Moreover, we assume at least one of (\u00b5f , \u00b5h) is zero.\n3. General (L,M)-smooth: \u2203L \u2265 0,M \u2265 0 such that f(x)\u2212 f(y)\u2212 \u27e8g, x\u2212 y\u27e9 \u2264 L2 \u2225x\u2212 y\u2225 2 + M\u2225x\u2212 y\u2225,\u2200x, y \u2208 X , g \u2208 \u2202f(y). 4. Unbiased gradient estimator: For a given xt \u2208 X in the t-th iterate, we can access an unbiased gradient estimator g\u0302t, i.e., E [ g\u0302t | F t\u22121 ] \u2208 \u2202f(xt), where F t := \u03c3(g\u0302s, s \u2208 [t]) is the \u03c3-algebra.\n5A. Finite variance: \u2203\u03c3 \u2265 0 such that E [ \u2225\u03bet\u22252\u2217 | F t\u22121 ] \u2264 \u03c32 where \u03bet := g\u0302t \u2212 E [ g\u0302t | F t\u22121 ] .\n5B. Sub-Gaussian noises: \u2203\u03c3 \u2265 0 such that E [ exp(\u03bb\u2225\u03bet\u22252\u2217) | F t\u22121 ] \u2264 exp(\u03bb\u03c32),\u2200\u03bb \u2208 [ 0, \u03c3\u22122 ] .\nWe briefly discuss the assumptions here. Assumptions 1, 4, and 5A are standard in the stochastic optimization literature. Assumption 2 is known as relative strong convexity appeared in previous works (Hazan & Kale, 2014; Lu et al., 2018). We use it here since the last-iterate convergence rate will be derived for the CSMD algorithm, which employs Bregman divergence to exploit the nonEuclidean geometry. In particular, when \u2225 \u00b7 \u2225 is the standard \u21132 norm, we can take \u03c8(x) = 12\u2225x\u2225 2 to recover the common definition of strong convexity. Assumption 3 is borrowed from Section 4.2 in Lan (2020). Note that both L-smooth functions (by taking M = 0) and G-Lipschitz functions (by taking L = 0 and M = 2G) are subclasses of Assumption 3. Additionally, we remark that Assumption 3 can be further relaxed to the following inequality\nf(x)\u2212 f(y)\u2212 \u27e8g, x\u2212 y\u27e9 \u2264 LD\u03c8(x, y) +M \u221a 2D\u03c8(x, y),\u2200x, y \u2208 X , g \u2208 \u2202f(y),\nbut without changing the convergence results proved in this paper (see (1) and (5) in the proof of Lemma 4.1). Lastly, Assumption 5B is used for the high-probability convergence bound.\nOur proofs for the high-probability convergence rely on the following simple fact for the centered sub-Gaussian random vector. Similar results have been proved in prior works (Vershynin, 2018; Liu et al., 2023). For completeness, we include the proof in Appendix A. Lemma 2.1. Given a \u03c3-algebra F and a random vector Z \u2208 Rd that is F-measurable, if \u03be \u2208 Rd is a random vector satisfying E [\u03be | F ] = 0 and E [ exp(\u03bb\u2225\u03be\u22252\u2217) | F ] \u2264 exp(\u03bb\u03c32),\u2200\u03bb \u2208 [ 0, \u03c3\u22122 ] , then E [exp (\u27e8\u03be, Z\u27e9) | F ] \u2264 exp ( \u03c32\u2225Z\u22252 ) .\n4Rigorously speaking, y should be in int(X ). But one can think X \u2286 int(dom(\u03c8)) to avoid this issue.\n2.1 CONVERGENCE CRITERION\nWe always measure the convergence via the function value gap, i.e., F (x) \u2212 F (x\u2217). There are several reasons to stick to this criterion. First, for the general convex case, the function value gap is the standard metric. Next, for strongly convex functions, the function value gap is always a stronger measurement than the squared distance to the optimal solution since \u2225x\u2212x\u2217\u22252 = O(F (x)\u2212F (x\u2217)) holds by strong convexity. Even if F (x) is additionally assumed to be (L, 0)-smooth (e.g., f(x) is (L, 0)-smooth and h(x) = 0), the bound on \u2225x \u2212 x\u2217\u22252 cannot be converted to the bound on F (x) \u2212 F (x\u2217) since F (x) \u2212 F (x\u2217) \u2264 \u27e8\u2207F (x\u2217), x \u2212 x\u2217\u27e9 + L2 \u2225x \u2212 x\n\u2217\u22252 = O(\u2225\u2207F (x\u2217)\u2225\u2217\u2225x \u2212 x\u2217\u2225 + \u2225x \u2212 x\u2217\u22252), which is probably worse than O(\u2225x \u2212 x\u2217\u22252) as x\u2217 is only a local minimizer meaning \u2225\u2207F (x\u2217)\u2225\u2217 possibly to be non-zero. Moreover, the function value gap is important in both the theoretical and practical sides of modern machine learning (e.g., the generalization error).\n3 LAST-ITERATE CONVERGENCE OF STOCHASTIC GRADIENT METHODS\nAlgorithm 1 Composite Stochastic Mirror Descent (CSMD) Input: x1 \u2208 X , \u03b7t > 0,\u2200t \u2208 [T ]. for t = 1 to T do xt+1 = argminx\u2208Xh(x) + \u27e8g\u0302t, x\u2212 xt\u27e9+ D\u03c8(x,x t)\n\u03b7t\nReturn xT+1\nThe algorithm, Composite Stochastic Mirror Descent, is presented in Algorithm 1. When h(x) = 0, Algorithm 1 degenerates to the standard Stochastic Mirror Descent algorithm. If we further consider the case \u2225\u00b7\u2225 = \u2225\u00b7\u22252, Algorithm 1 can recover the standard projected SGD by taking \u03c8(x) = 12\u2225x\u2225 2 2. We assume T \u2265 2 throughout the following paper to avoid some algebraic issues in the proof. The full version of every following theorem with its proof is deferred into the appendix.\n3.1 GENERAL CONVEX FUNCTIONS\nIn this section, we focus on the last-iterate convergence of Algorithm 1 for general convex functions (i.e., \u00b5f = \u00b5h = 0). First, the in-expectation convergence rates are shown in Theorem 3.1.\nTheorem 3.1. Under Assumptions 1-4 and 5A with \u00b5f = \u00b5h = 0:\nIf T is unknown, by taking \u03b7t = 12L \u2227 \u03b7\u221a t ,\u2200t \u2208 [T ] with \u03b7 = \u0398 (\u221a D\u03c8(x\u2217,x1) M2+\u03c32 ) , there is\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 O ( LD\u03c8(x \u2217, x1)\nT + (M + \u03c3) \u221a D\u03c8(x\u2217, x1) log T\u221a T ) .\nIf T is known, by taking \u03b7t = 12L \u2227 \u03b7\u221a T ,\u2200t \u2208 [T ] with \u03b7 = \u0398\n(\u221a D\u03c8(x\u2217,x1)\n(M2+\u03c32) log T\n) , there is\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 O ( LD\u03c8(x \u2217, x1)\nT + (M + \u03c3) \u221a D\u03c8(x\u2217, x1) log T\u221a T ) .\nBefore moving on to the high-probability bounds, we would like to talk more about these inexpectation convergence results. First, the constant \u03b7 here is optimized to obtain the best dependence on the parameters M,\u03c3 and D\u03c8(x\u2217, x1). Indeed, the last iterate provably converges for arbitrary \u03b7 > 0 but with a worse dependence on M,\u03c3 and D\u03c8(x\u2217, x1). We refer the reader to Theorem C.1 in the appendix for a full version of Theorem 3.1 with any \u03b7 > 0. Next, by taking L = 0, we immediately get the (nearly) optimal O\u0303(1/ \u221a T ) convergence rate of the last iterate for non-smooth functions. Note that our bounds are better than Shamir & Zhang (2013) since it only works for bounded domains and non-composite optimization. Besides, when considering smooth problems (taking M = 0), to our best knowledge, our O\u0303(L/T + \u03c3/ \u221a T ) bound\nis the first improvement since the O(1/ 3 \u221a T ) rate by Moulines & Bach (2011). Moreover, compared to Moulines & Bach (2011), Theorem 3.1 does not rely on some restrictive assumptions like bounded stochastic gradients or x\u2217 being a global optimal point but is able to be used for the more general composite problems. Additionally, it is worth remarking that the O\u0303(L/T +\u03c3/ \u221a T ) rate matches the optimal O(L/T + \u03c3/ \u221a T ) rate for the averaged output xT+1avg = ( \u2211T+1 t=2 x\nt)/T (Lan, 2020) up to an extra logarithmic factor. Notably, our bounds are also adaptive to the noise \u03c3 in this case. In other words, we can recover the well-known O(L/T ) rate for the last iterate of the GD algorithm in the noiseless case. Last but most importantly, our proof is unified and thus can be applied to different settings (e.g., general domains, (L,M )-smoothness, non-Euclidean norms, etc.) simultaneously. Remark 3.2. Orabona (2020) exhibited a circuitous method based on comparing the last iterate with the averaged output to show the expected last-iterate convergence for non-composite non-smooth convex optimization in general domains. However, it did not explicitly generalize to the broader problems considered in this paper. Moreover, our method is done in a direct manner (see Section 4). Theorem 3.3. Under Assumptions 1-4 and 5B with \u00b5f = \u00b5h = 0 and let \u03b4 \u2208 (0, 1):\nIf T is unknown, by taking \u03b7t = 12L \u2227 \u03b7\u221a t ,\u2200t \u2208 [T ] with \u03b7 = \u0398\n(\u221a D\u03c8(x\u2217,x1)\nM2+\u03c32 log 1\u03b4\n) , then with\nprobability at least 1\u2212 \u03b4, there is\nF (xT+1)\u2212 F (x\u2217) \u2264 O LD\u03c8(x\u2217, x1) T + (M + \u03c3 \u221a log 1\u03b4 ) \u221a D\u03c8(x\u2217, x1) log T \u221a T  . If T is known, by taking \u03b7t = 12L \u2227 \u03b7\u221a T ,\u2200t \u2208 [T ] with \u03b7 = \u0398 (\u221a D\u03c8(x\u2217,x1)\n(M2+\u03c32 log 1\u03b4 ) log T\n) , then with\nprobability at least 1\u2212 \u03b4, there is\nF (xT+1)\u2212 F (x\u2217) \u2264 O LD\u03c8(x\u2217, x1) T + (M + \u03c3 \u221a log 1\u03b4 ) \u221a D\u03c8(x\u2217, x1) log T \u221a T  . In Theorem 3.3, we present the high-probability bounds for (L,M)-smooth functions. Again, the constant \u03b7 is picked to get the best dependence on the parameters M,\u03c3,D\u03c8(x\u2217, x1) and log(1/\u03b4). The full version of Theorem 3.3 with arbitrary \u03b7, Theorem C.2, is deferred into the appendix. Compared with Theorem 3.1, the high-probability rates only incur an extra O( \u221a log(1/\u03b4)) factor (or O(log(1/\u03b4)) for arbitrary \u03b7, which is known to be optimal for L = 0 (Harvey et al., 2019a)).\nIn contrast to the previous bounds (Harvey et al., 2019a; Jain et al., 2021) that only work for Lipschitz functions in a compact domain, our results are the first to describe the high-probability behavior of Algorithm 1 for the wider (L,M)-smooth function class in a general domain even with sub-Gaussian noises, not to mention composite objectives and non-Euclidean norms. Even in the special smooth case (setting M = 0), as far as we know, this is also the first last-iterate high-probability bound being adaptive to the noise \u03c3 at the same time for plain stochastic gradient methods. Unlike the previous proofs employing some new probability tools (e.g., the generalized Freedman\u2019s inequality in Harvey et al. (2019a)), our high-probability argument is simple and only based on the basic property of sub-Gaussian random vectors (see Lemma 2.1). Therefore, we believe our work can bring some new insights to researchers to gain a better understanding of the convergence for the last iterate of stochastic gradient methods.\n3.2 STRONGLY CONVEX FUNCTIONS\nNow we turn our attention to strongly convex functions. Due to the space limitation, we only provide the results for the case of \u00b5f > 0 and \u00b5h = 0. The other case, \u00b5f = 0 and \u00b5h > 0, will be delivered in Appendix D.2. Theorem 3.4. Under Assumptions 1-4 and 5A with \u00b5f > 0 and \u00b5h = 0, let \u03baf := L\u00b5f \u2265 0:\nIf T is unknown, by taking either \u03b7t = 1\u00b5f (t+2\u03baf ) ,\u2200t \u2208 [T ] or \u03b7t = 2 \u00b5f (t+1+4\u03baf ) ,\u2200t \u2208 [T ], there is E [ F (xT+1)\u2212 F (x\u2217) ] \u2264 O ( LD\u03c8(x \u2217,x1) T + (M2+\u03c32) log T \u00b5f (T+\u03baf ) ) \u03b7t = 1 \u00b5f (t+2\u03baf ) ,\u2200t \u2208 [T ] O ( L(1+\u03baf )D\u03c8(x\n\u2217,x1) T (T+\u03baf ) + (M 2+\u03c32) log T \u00b5f (T+\u03baf ) ) \u03b7t = 2 \u00b5f (t+1+4\u03baf ) ,\u2200t \u2208 [T ] .\nIf T is known, by taking \u03b7t =  1 \u00b5f (1+2\u03baf ) t = 1 1 \u00b5f (\u03b7+2\u03baf ) 2 \u2264 t \u2264 \u03c4 2\n\u00b5f (t\u2212\u03c4+2+4\u03baf ) t \u2265 \u03c4 + 1 ,\u2200t \u2208 [T ] with \u03b7 := 1.5 and \u03c4 :=\n\u2308 T 2 \u2309 ,\nthere is\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 O LD\u03c8(x\u2217, x1) exp ( T\n3+4\u03baf\n) + (M2 + \u03c32) log T \u00b5f (T + \u03baf )  . The in-expectation rates are stated in Theorem 3.4 where the constant \u03b7 = 1.5 is chosen without any special reason. Generally speaking, it can be any non-negative number satisfying \u03b7 + \u03baf > 1. The interested reader could refer to Theorem D.1 in the appendix for a completed version of Theorem 3.4. We would like to remind that \u03baf \u2265 1 is not necessary as we are considering the general (L,M)-smooth functions. Hence, it can be zero.\nAs before, we first take L = 0 to consider the special Lipschitz case. Due to \u03baf = 0 now, all bounds will degenerate to O(log T/T ), which is known to be optimal for the step size 1/\u00b5f t (Harvey et al., 2019a) and only incurs an extra O(log T ) factor compared with the best O(1/T ) bound when T is known (Jain et al., 2021). We would also like to mention that Theorem 3.4 is the first to give the in-expectation last-iterate bound for the step size 2/\u00b5f (t+1). Interestingly, the extra O(log T ) factor appears again compared to the known O(1/T ) bound on the function value gap for the non-uniform averaging strategy under this step size (Lacoste-Julien et al., 2012). Besides, Lacoste-Julien et al. (2012) also shows E [ \u2225xT+1 \u2212 x\u2217\u222522 ] = O(1/T ). Whereas, it is currently unknown whether our\nE [ F (xT+1)\u2212 F (x\u2217) ] = O(log T/T ) bound can be improved to match the O(1/T ) rate or not.\nFor the general (L,M)-smooth case (even for (L, 0)-smoothness), our bounds are the first convergence results for the last iterate of stochastic gradient methods with respect to the function value gap5. Remarkably, all of these rates do not require prior knowledge of M or \u03c3 to set the step size. In particular, the bound for known T is adaptive to \u03c3 when M = 0, i.e., it can recover the well-known linear convergence rate O(exp(\u2212T/\u03baf )) when \u03c3 = 0. Theorem 3.5. Under Assumptions 1-4 and 5B with \u00b5f > 0 and \u00b5h = 0, let \u03baf := L\u00b5f \u2265 0 and \u03b4 \u2208 (0, 1): If T is unknown, by taking either \u03b7t = 1\u00b5f (t+2\u03baf ) ,\u2200t \u2208 [T ] or \u03b7t = 2 \u00b5f (t+1+4\u03baf )\n,\u2200t \u2208 [T ], then with probability at least 1\u2212 \u03b4, there is\nF (xT+1)\u2212F (x\u2217) \u2264 O ( \u00b5f (1+\u03baf )D\u03c8(x \u2217,x1) T + (M2+\u03c32 log 1\u03b4 ) log T \u00b5f (T+\u03baf ) ) \u03b7t = 1 \u00b5f (t+2\u03baf ) ,\u2200t \u2208 [T ] O ( \u00b5f (1+\u03baf ) 2D\u03c8(x \u2217,x1)\nT (T+\u03baf ) +\n(M2+\u03c32 log 1\u03b4 ) log T\n\u00b5f (T+\u03baf )\n) \u03b7t =\n2 \u00b5f (t+1+4\u03baf )\n,\u2200t \u2208 [T ] .\nIf T is known, by taking \u03b7t =  1 \u00b5f (1+2\u03baf ) t = 1 1 \u00b5f (\u03b7+2\u03baf ) 2 \u2264 t \u2264 \u03c4 2\n\u00b5f (t\u2212\u03c4+2+4\u03baf ) t \u2265 \u03c4 + 1 ,\u2200t \u2208 [T ] with \u03b7 := 1.5 and \u03c4 :=\n\u2308 T 2 \u2309 ,\nthen with probability at least 1\u2212 \u03b4, there is\nF (xT+1)\u2212 F (x\u2217) \u2264 O \u00b5f (1 + \u03baf )D\u03c8(x\u2217, x1) exp ( T\n3+4\u03baf\n) + (M2 + \u03c32 log 1\u03b4 ) log T \u00b5f (T + \u03baf )  . To finish this section, we provide the high-probability convergence results in Theorem 3.5. Again, the constant \u03b7 = 1.5 is set without any particular reason. The full statement with general \u03b7, Theorem D.2, can be found in the appendix. Besides, \u03baf is possible to be zero as mentioned above. Compared with Theorem 3.4, only an additional O(log(1/\u03b4)) factor appears. Such extra loss is known to be inevitable for L = 0 due to Harvey et al. (2019a).\n5Note that the rates under the PL-condition (e.g., Gower et al. (2021); Khaled & Richt\u00e1rik (2023)) are incompatible with our settings since they can be only applied to non-constrained, non-composite and (L, 0)- smooth optimization problems with the Euclidean norm.\nFor the Lipschitz case (i.e., L = \u03baf = 0), by noticing D\u03c8(x\u2217, x1) = O(M2/\u00b52f ) 6, all of these bounds will degenerate to O(log(1/\u03b4) log T/T ) matching the best-known last-iterate bound proved by Harvey et al. (2019a) for the step size 1/\u00b5f t. For the step size 2/\u00b5f (t+1), Harvey et al. (2019b) has proved the high-probability bound O(log(1/\u03b4)/T ) for the non-uniform averaging output instead of the last iterate. Hence, as far as we know, our high-probability rate for the step size 2/\u00b5f (t+1) is new. However, we would like to mention that our bound for known T is worse by a logarithmic factor than Jain et al. (2021), though, which assumes bounded noises.\nFinally, let us go back to the general (L,M)-smooth case. To our best knowledge, our results are first to prove the last iterate of plain stochastic gradient methods enjoying the provable high-probability convergence even for the smooth case (M = 0). Hence, we believe our work closes the gap between the lack of theoretical understanding and good performance of the last iterate of SGD for smooth and strongly convex functions. Lastly, the same as the in-expectation bound for known T in Theorem 3.4, our high-probability bound is also adaptive to \u03c3 when M = 0.\n4 UNIFIED THEORETICAL ANALYSIS\nIn this section, we introduce the ideas in our analysis and present three important lemmas, all the missing proofs of which are deferred into Appendix B.\nThe key insight in our proofs is to utilize the convexity of F (x), which is highly inspired by the recent work (Zamani & Glineur, 2023). To be more precise, using the classic convergence analysis for non-composite Lipschitz convex problems as an example, people always consider to upper bound the function value gap f(xt) \u2212 f(x\u2217) (probably with some weight before it) then sum them over time to obtain the ergodic rate. Whereas, in such an argument, convexity is not necessary in fact (except if one wants to bound the average iterate in the last step). Hence, if the convexity of f can be utilized somewhere, it is reasonable to expect a last-iterate convergence guarantee. Actually, this thought is possible as shown by Zamani & Glineur (2023), in which the authors upper bound the quantity f(xt) \u2212 f(zt) where zt is a carefully chosen convex combination of other points and finally obtain the last-iterate rate by lower bounding \u2212f(zt) via convexity. More precisely, suppose zt := \u03b1t0x \u2217 + \u2211t s=1 \u03b1 t sx t where \u03b1ts \u2265 0,\u2200s \u2208 {0} \u222a [t] ,\u2200t \u2208 [T ] satisfy \u2211t s=0 \u03b1 t s = 1,\u2200t \u2208 [T ],\nthen there is \u2212f(zt) \u2265 \u2212\u03b1t0f(x\u2217)\u2212 \u2211t s=1 \u03b1 t sf(x\nt) by the convexity of f . By properly picking \u03b1ts, one can finally bound f(xT )\u2212 f(x\u2217) as proved by Zamani & Glineur (2023). Though Zamani & Glineur (2023) only shows how to prove the last-iterate convergence for deterministic non-composite Lipschitz convex optimization under the Euclidean norm, we can catch the most important message conveyed by their paper and apply it to our settings. Formally speaking, we will upper bound the term F (xt+1) \u2212 F (zt) for a well-designed zt rather than directly bound the function value gap F (xt+1)\u2212F (x\u2217). This idea can finally help us construct a unified proof and obtain several novel results without prior restrictive assumptions. By careful calculations, the new analysis leads us to the following most important and unified result, Lemma 4.1. Lemma 4.1. Under Assumptions 1-3, suppose \u03b7t \u2264 12L\u2228\u00b5f ,\u2200t \u2208 [T ] and let \u03b3t := \u03b7t \u220ft s=2 1+\u00b5h\u03b7s\u22121 1\u2212\u00b5f\u03b7s ,\u2200t \u2208 [T ], if wt \u2265 0,\u2200t \u2208 [T ] is a non-increasing sequence and vt > 0 is\ndefined as vt := wT \u03b3T\u2211T s=t ws\u03b3s ,\u2200t \u2208 [T ] and v0 := v1, then we have\nwT \u03b3T vT ( F (xT+1)\u2212 F (x\u2217) ) \u2264w1(1\u2212 \u00b5f\u03b71)v0D\u03c8(x\u2217, x1) +\nT\u2211 t=1 2wt\u03b3t\u03b7tvt(M 2 + \u2225\u03bet\u22252\u2217)\n+ T\u2211 t=1 wt\u03b3tvt\u22121\u27e8\u03bet, zt\u22121 \u2212 xt\u27e9+ T\u2211 t=2 (wt \u2212 wt\u22121)\u03b3t(\u03b7\u22121t \u2212 \u00b5f )vt\u22121D\u03c8(zt\u22121, xt),\nwhere \u03bet := g\u0302t \u2212 E [ g\u0302t | F t\u22121 ] ,\u2200t \u2208 [T ] and zt := v0vt x \u2217 + \u2211t s=1 vs\u2212vs\u22121 vt xs,\u2200t \u2208 {0} \u222a [T ].\nLet us discuss Lemma 4.1 more here. The requirement of the step size \u03b7t having an upper bound 1/2L\u2228\u00b5f is common in the optimization literature. \u03b3t is used to ensure we can telescope sum some\n6This holds now due to \u00b5f\u2225x\u2217 \u2212 x1\u22252/2 \u2264 \u00b5fD\u03c8(x\u2217, x1) \u2264M\u2225x\u2217 \u2212 x1\u2225.\nterms. For the special case \u00b5f = \u00b5h = 0, it degenerates to \u03b7t. \u03bet naturally shows up as we are considering stochastic optimization. The most important sequences are wt, vt and zt. As mentioned above, the appearance of zt is to make sure to get the last-iterate convergence. For how to find such a sequence, we refer the reader to our proofs in Appendix B for details.\nWe would like to say more about the sequence wt before moving on. Suppose we are in the deterministic case temporarily, i.e., \u03bet = 0, then a natural choice is to set wt = 1,\u2200t \u2208 [T ] to remove the last residual summation. It turns out this is the correct choice even for the following in-expectation bound in Lemma 4.2. So why do we still need this redundant wt? The reason is that setting wt to be one is not enough for the high-probability bound. More precisely, if we still choose wt = 1,\u2200t \u2208 [T ], then there will be some extra positive terms after the concentration argument in the R.H.S. of the inequality in Lemma 4.1. To deal with this issue, we borrow the idea recently developed by Liu et al. (2023), in which the authors employ an extra sequence wt to give a clear proof for the high-probability bound for stochastic gradient methods. We refer the reader to Liu et al. (2023) for a detailed explanation of this technique. Lemma 4.2. Under Assumptions 1-4 and 5A, suppose \u03b7t \u2264 12L\u2228\u00b5f ,\u2200t \u2208 [T ] and let \u03b3t := \u03b7t \u220ft s=2 1+\u00b5h\u03b7s\u22121 1\u2212\u00b5f\u03b7s ,\u2200t \u2208 [T ], then we have\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 (1\u2212 \u00b5f\u03b71)D\u03c8(x\n\u2217, x1)\u2211T t=1 \u03b3t + 2(M2 + \u03c32) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s .\nSuppose Lemma 4.1 holds, Lemma 4.2 is immediately obtained by setting wt = 1,\u2200t \u2208 [T ] and using Assumptions 4 and 5A. This unified result for the expected last-iterate convergence can be applied to many different settings like composite optimization and non-Euclidean norms without any restrictive assumptions. Lemma 4.3. Under Assumptions 1-4 and 5B, suppose \u03b7t \u2264 12L\u2228\u00b5f ,\u2200t \u2208 [T ] and let \u03b3t := \u03b7t \u220ft s=2 1+\u00b5h\u03b7s\u22121 1\u2212\u00b5f\u03b7s ,\u2200t \u2208 [T ], then for any \u03b4 \u2208 (0, 1), with probability at least 1\u2212 \u03b4, we have\nF (xT+1)\u2212 F (x\u2217) \u22642 ( 1 + max\n2\u2264t\u2264T\n1\n1\u2212 \u00b5f\u03b7t ) \u00d7 [ D\u03c8(x\n\u2217, x1)\u2211T t=1 \u03b3t +\n( M2 + \u03c32 ( 1 + 2 log 2\n\u03b4 )) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s ] .\nTo get Lemma 4.3, we need some extra effort to find the correct wt and invoke a simple property of sub-Gaussian random vectors (Lemma 2.1). The details can be found in Appendix B. Compared with prior works, this unified high-probability bound can be applied to various scenarios including general domains and sub-Gaussian noises.\nEquipped with Lemma 4.2 and Lemma 4.3, we can prove all theorems provided in Section 3 by plugging in different step sizes for different cases.\n5 CONCLUSION\nIn this work, we present a unified analysis for the last-iterate convergence of stochastic gradient methods and obtain several new results. More specifically, we establish the (nearly) optimal convergence of the last iterate of the CSMD algorithm both in expectation and in high probability. Our proofs can not only handle different function classes simultaneously but also be applied to composite problems with non-Euclidean norms on general domains. We believe our work develops a deeper understanding of stochastic gradient methods. However, there still remain many directions worth exploring. For example, it could be interesting to see whether our proof can be extended to adaptive gradient methods like AdaGrad (McMahan & Streeter, 2010; Duchi et al., 2011). We leave this important question as future work and expect it to be addressed.\nACKNOWLEDGMENTS\nThis work is generously supported by the National Science Foundation grant CCF-2106508. Zhengyuan Zhou would also like to thank the 2024-2025 NYU Center for Global Economy and Business faculty grant and the NYU Research Catalyst Prize. We also thank the anonymous reviewers for their constructive comments and suggestions.\nEthics Statement: This is a theory work. Hence, there are no potential ethics concerns.\nReproducibility Statement: We include the full proofs of all theorems in the appendix.\nREFERENCES Amir Beck and Marc Teboulle. Mirror descent and nonlinear projected subgradient methods for\nconvex optimization. Operations Research Letters, 31(3):167\u2013175, 2003.\nDamek Davis and Dmitriy Drusvyatskiy. High probability guarantees for stochastic convex optimization. In Conference on Learning Theory, pp. 1411\u20131427. PMLR, 2020.\nJohn Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of machine learning research, 12(7), 2011.\nJohn C Duchi, Shai Shalev-Shwartz, Yoram Singer, and Ambuj Tewari. Composite objective mirror descent. In COLT, volume 10, pp. 14\u201326. Citeseer, 2010.\nRong Ge, Sham M Kakade, Rahul Kidambi, and Praneeth Netrapalli. The step decay schedule: A near optimal, geometrically decaying learning rate procedure for least squares. Advances in neural information processing systems, 32, 2019.\nEduard Gorbunov, Marina Danilova, and Alexander Gasnikov. Stochastic optimization with heavytailed noise via accelerated gradient clipping. Advances in Neural Information Processing Systems, 33:15042\u201315053, 2020.\nRobert Gower, Othmane Sebbouh, and Nicolas Loizou. Sgd for structured nonconvex functions: Learning rates, minibatching and interpolation. In International Conference on Artificial Intelligence and Statistics, pp. 1315\u20131323. PMLR, 2021.\nNicholas JA Harvey, Christopher Liaw, Yaniv Plan, and Sikander Randhawa. Tight analyses for nonsmooth stochastic gradient descent. In Conference on Learning Theory, pp. 1579\u20131613. PMLR, 2019a.\nNicholas JA Harvey, Christopher Liaw, and Sikander Randhawa. Simple and optimal high-probability bounds for strongly-convex stochastic gradient descent. arXiv preprint arXiv:1909.00843, 2019b.\nElad Hazan and Satyen Kale. Beyond the regret minimization barrier: optimal algorithms for stochastic strongly-convex optimization. The Journal of Machine Learning Research, 15(1): 2489\u20132512, 2014.\nPrateek Jain, Dheeraj M. Nagaraj, and Praneeth Netrapalli. Making the last iterate of sgd information theoretically optimal. SIAM Journal on Optimization, 31(2):1108\u20131130, 2021. doi: 10.1137/ 19M128908X. URL https://doi.org/10.1137/19M128908X.\nAhmed Khaled and Peter Richt\u00e1rik. Better theory for SGD in the nonconvex world. Transactions on Machine Learning Research, 2023. ISSN 2835-8856. URL https://openreview.net/ forum?id=AU4qHN2VkS. Survey Certification.\nSimon Lacoste-Julien, Mark Schmidt, and Francis Bach. A simpler approach to obtaining an o (1/t) convergence rate for the projected stochastic subgradient method. arXiv preprint arXiv:1212.2002, 2012.\nGuanghui Lan. First-order and stochastic optimization methods for machine learning. Springer, 2020.\nYunwen Lei and Ding-Xuan Zhou. Analysis of online composite mirror descent algorithm. Neural computation, 29(3):825\u2013860, 2017.\nDaogao Liu and Zhou Lu. The convergence rate of sgd\u2019s final iterate: Analysis on dimension dependence. arXiv preprint arXiv:2106.14588, 2021.\nZijian Liu, Ta Duy Nguyen, Thien Hang Nguyen, Alina Ene, and Huy Nguyen. High probability convergence of stochastic gradient methods. In International Conference on Machine Learning, pp. 21884\u201321914. PMLR, 2023.\nHaihao Lu, Robert M Freund, and Yurii Nesterov. Relatively smooth convex optimization by firstorder methods, and applications. SIAM Journal on Optimization, 28(1):333\u2013354, 2018.\nH. Brendan McMahan and Matthew J. Streeter. Adaptive bound optimization for online convex optimization. In Conference on Learning Theory (COLT), pp. 244\u2013256. Omnipress, 2010.\nEric Moulines and Francis Bach. Non-asymptotic analysis of stochastic approximation algorithms for machine learning. Advances in neural information processing systems, 24, 2011.\nArkadi Nemirovski and David Yudin. Problem complexity and method efficiency in optimization. Wiley-Interscience, 1983.\nYu Nesterov and Vladimir Shikhman. Quasi-monotone subgradient methods for nonsmooth convex minimization. Journal of Optimization Theory and Applications, 165(3):917\u2013940, 2015.\nFrancesco Orabona. Last iterate of sgd converges (even in unbounded domains). 2020. URL https://parameterfree.com/2020/08/07/ last-iterate-of-sgd-converges-even-in-unbounded-domains/.\nFrancesco Orabona and D\u00e1vid P\u00e1l. Parameter-free stochastic optimization of variationally coherent functions. arXiv preprint arXiv:2102.00236, 2021.\nRui Pan, Haishan Ye, and Tong Zhang. Eigencurve: Optimal learning rate schedule for SGD on quadratic objectives with skewed hessian spectrums. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=rTAclwH46Tb.\nAlexander Rakhlin, Ohad Shamir, and Karthik Sridharan. Making gradient descent optimal for strongly convex stochastic optimization. arXiv preprint arXiv:1109.5647, 2011.\nHerbert Robbins and Sutton Monro. A stochastic approximation method. The annals of mathematical statistics, pp. 400\u2013407, 1951.\nAbdurakhmon Sadiev, Marina Danilova, Eduard Gorbunov, Samuel Horv\u00e1th, Gauthier Gidel, Pavel Dvurechensky, Alexander Gasnikov, and Peter Richt\u00e1rik. High-probability bounds for stochastic optimization and variational inequalities: the case of unbounded variance. arXiv preprint arXiv:2302.00999, 2023.\nShai Shalev-Shwartz, Yoram Singer, and Nathan Srebro. Pegasos: Primal estimated sub-gradient solver for svm. In Proceedings of the 24th international conference on Machine learning, pp. 807\u2013814, 2007.\nOhad Shamir and Tong Zhang. Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes. In International conference on machine learning, pp. 71\u201379. PMLR, 2013.\nAditya Vardhan Varre, Loucas Pillaud-Vivien, and Nicolas Flammarion. Last iterate convergence of sgd for least-squares in the interpolation regime. Advances in Neural Information Processing Systems, 34:21581\u201321591, 2021.\nRoman Vershynin. High-dimensional probability: An introduction with applications in data science, volume 47. Cambridge university press, 2018.\nJingfeng Wu, Difan Zou, Vladimir Braverman, Quanquan Gu, and Sham Kakade. Last iterate risk bounds of sgd with decaying stepsize for overparameterized linear regression. In International Conference on Machine Learning, pp. 24280\u201324314. PMLR, 2022.\nMoslem Zamani and Fran\u00e7ois Glineur. Exact convergence rate of the last iterate in subgradient methods. arXiv preprint arXiv:2307.11134, 2023.\nA PROOF OF LEMMA 2.1\nBefore giving the proof of Lemma 2.1, we need the following property of sub-Gaussian vectors. This result is already known before (see Vershynin (2018)). We provide a proof here to make the paper self-consistent. Lemma A.1. Given a \u03c3-algebra F , if \u03be \u2208 Rd is a random vector satisfying E [ exp(\u03bb\u2225\u03be\u22252\u2217) | F ] \u2264\nexp(\u03bb\u03c32),\u2200\u03bb \u2208 [ 0, \u03c3\u22122 ] , then for any integer k \u2265 1 we have\nE [ \u2225\u03be\u22252k\u2217 | F ] \u2264 { \u03c32 k = 1\ne(k!)\u03c32k k \u2265 2 .\nProof. For the case k = 1, given any \u03bb \u2208 [ 0, \u03c3\u22122 ] , there is\nexp ( E [ \u03bb\u2225\u03be\u22252\u2217 | F ]) \u2264 E [ exp ( \u03bb\u2225\u03be\u22252\u2217 ) | F ] \u2264 exp(\u03bb\u03c32) \u21d2 E [ \u2225\u03be\u22252\u2217 | F ] \u2264 \u03c32.\nFor k \u2265 2, we have E [ \u2225\u03be\u22252k\u2217 | F ] = E [\u222b \u221e 0 2kt2k\u221211 [\u2225\u03be\u2225\u2217 \u2265 t] dt | F ] = \u222b \u221e 0 2kt2k\u22121E [1 [\u2225\u03be\u2225\u2217 \u2265 t] | F ] dt\n\u2264 \u222b \u221e 0 2kt2k\u22121E [ exp(\u03c3\u22122\u2225\u03be\u22252\u2217) exp(\u03c3\u22122t2) | F ] dt (a) \u2264 \u222b \u221e 0 2ekt2k\u22121 exp(\u2212\u03c3\u22122t2)dt\n(b) = \u222b \u221e 0 ek\u03c32ksk\u22121 exp(\u2212s)ds = ek\u03c32k\u0393(k) = e(k!)\u03c32k,\nwhere (a) is by E [ exp(\u03c3\u22122\u2225\u03be\u22252\u2217) | F ] \u2264 exp(\u03c3\u22122\u03c32) = e and (b) is by the change of variable t = \u03c3 \u221a s.\nNow we are ready to prove Lemma 2.1.\nProof of Lemma 2.1. Note that E [exp (\u27e8\u03be, Z\u27e9) | F ]\n=E [ 1 + \u27e8\u03be, Z\u27e9+\n\u221e\u2211 k=2 (\u27e8\u03be, Z\u27e9)k k! | F\n] \u2264 E [\u27e8\u03be, Z\u27e9 | F ] + E [ 1 +\n\u221e\u2211 k=2 \u2225\u03be\u2225k\u2217\u2225Z\u2225k k! | F ] (a) =E [ 1 +\n\u221e\u2211 k=1 \u2225\u03be\u22252k\u2217 \u2225Z\u22252k (2k)! + \u221e\u2211 k=1 \u2225\u03be\u22252k+1\u2217 \u2225Z\u22252k+1 (2k + 1)! | F ] (b) \u2264E [ 1 +\n\u221e\u2211 k=1 \u2225\u03be\u22252k\u2217 \u2225Z\u22252k (2k)! + \u221e\u2211 k=1 \u2225\u03be\u22252k\u2217 \u2225Z\u22252k + \u2225\u03be\u22252k+2\u2217 \u2225Z\u22252k+2/4 (2k + 1)! | F\n]\n=E [ 1 + 2\u2225\u03be\u22252\u2217\u2225Z\u22252\n3 + \u221e\u2211 k=2 \u2225\u03be\u22252k\u2217 \u2225Z\u22252k (\n1\n4(2k \u2212 1)! +\n1\n(2k)! +\n1\n(2k + 1)!\n) | F ]\n=E [ 1 + 2\u2225\u03be\u22252\u2217\u2225Z\u22252\n3 + \u221e\u2211 k=2 \u2225\u03be\u22252k\u2217 \u2225Z\u22252k 1 + k/2 + 1/(2k + 1) (2k)! | F ] (c)\n\u22641 + 2\u03c3 2\u2225Z\u22252\n3 + \u221e\u2211 k=2 \u03c32k\u2225Z\u22252k k! \u00b7 e(1 + k/2 + 1/(2k + 1))( 2k k\n) (d)\n\u22641 + \u03c32\u2225Z\u22252 + \u221e\u2211 k=2 \u03c32k\u2225Z\u22252k k! = exp ( \u03c32\u2225Z\u22252 ) ,\nwhere (a) is by E [\u27e8\u03be, Z\u27e9 | F ] = \u27e8E [\u03be | F ] , Z\u27e9 = 0, (b) holds due to AM-GM inequality, (c) is by applying Lemma A.1 to E [ \u2225\u03be\u22252k\u2217 \u2225Z\u22252k | F ] = \u2225Z\u22252kE [ \u2225\u03be\u22252k\u2217 | F ] and (d) is by 2/3 < 1 and\nmax k\u22652,k\u2208N e(1 + k/2 + 1/(2k + 1))( 2k k ) = e(1 + 1 + 1/5) 6 < 1.\nB MISSING PROOFS IN SECTION 4\nIn this section, we provide the missing proofs of the most important three lemmas.\nB.1 PROOF OF LEMMA 4.1\nProof of Lemma 4.1. Inspired by Zamani & Glineur (2023), we first introduce the following auxiliary sequence\nzt :=\n{( 1\u2212 vt\u22121vt ) xt + vt\u22121vt z\nt\u22121 t \u2208 [T ] x\u2217 t = 0 \u21d4 zt := v0 vt x\u2217 + t\u2211 s=1 vs \u2212 vs\u22121 vt xs,\u2200t \u2208 {0} \u222a [T ] ,\nwhere we recall that vt = wT \u03b3T\u2211T s=t ws\u03b3s \u2265 0,\u2200t \u2208 [T ] and v0 = v1 are non-decreasing. Note that zt always falls in the domain X because it is a convex combination of x\u2217, x1, \u00b7 \u00b7 \u00b7 , xt that are in X . Now, we start the proof from the (L,M)-smoothness of f ,\nf(xt+1)\u2212 f(xt) \u2264\u27e8gt, xt+1 \u2212 xt\u27e9+ L 2 \u2225xt+1 \u2212 xt\u22252 +M\u2225xt+1 \u2212 xt\u2225\n=\u27e8\u03bet, zt \u2212 xt\u27e9+ \u27e8\u03bet, xt \u2212 xt+1\u27e9\ufe38 \ufe37\ufe37 \ufe38 I + \u27e8g\u0302t, xt+1 \u2212 zt\u27e9\ufe38 \ufe37\ufe37 \ufe38 II\n+ \u27e8gt, zt \u2212 xt\u27e9\ufe38 \ufe37\ufe37 \ufe38 III + L 2 \u2225xt+1 \u2212 xt\u22252 +M\u2225xt+1 \u2212 xt\u2225\ufe38 \ufe37\ufe37 \ufe38\nIV\n, (1)\nwhere gt := E [ g\u0302t|F t\u22121 ] \u2208 \u2202f(xt) and \u03bet := g\u0302t\u2212gt. Next, we bound these four terms respectively.\n\u2022 For term I, by applying Cauchy-Schwarz inequality, the 1-strong convexity of \u03c8 and AMGM inequality, we can get the following upper bound\nI \u2264 \u2225\u03bet\u2225\u2217\u2225xt \u2212 xt+1\u2225 \u2264 \u2225\u03bet\u2225\u2217 \u221a 2D\u03c8(xt+1, xt) \u2264 2\u03b7t\u2225\u03bet\u22252\u2217 + D\u03c8(x t+1, xt)\n4\u03b7t . (2)\n\u2022 For term II, we recall that the update rule is xt+1 = argminx\u2208Xh(x) + \u27e8g\u0302t, x \u2212 xt\u27e9 + D\u03c8(x,x\nt) \u03b7t\n. Hence, by the optimality condition of xt+1, there exists ht+1 \u2208 \u2202h(xt+1) such that for any y \u2208 X\n\u27e8ht+1 + g\u0302t + \u2207\u03c8(x t+1)\u2212\u2207\u03c8(xt)\n\u03b7t , xt+1 \u2212 y\u27e9 \u2264 0,\nwhich implies\n\u27e8g\u0302t, xt+1 \u2212 y\u27e9 \u2264\u27e8\u2207\u03c8(x t)\u2212\u2207\u03c8(xt+1), xt+1 \u2212 y\u27e9\n\u03b7t + \u27e8ht+1, y \u2212 xt+1\u27e9\n\u2264D\u03c8(y, x t)\u2212D\u03c8(y, xt+1)\u2212D\u03c8(xt+1, xt)\n\u03b7t + h(y)\u2212 h(xt+1)\u2212 \u00b5hD\u03c8(y, xt+1)\nwhere the last inequality holds due to \u27e8\u2207\u03c8(xt) \u2212 \u2207\u03c8(xt+1), xt+1 \u2212 y\u27e9 = D\u03c8(y, xt) \u2212 D\u03c8(y, x\nt+1) \u2212D\u03c8(xt+1, xt) and \u27e8ht+1, y \u2212 xt+1\u27e9 \u2264 h(y) \u2212 h(xt+1) \u2212 \u00b5hD\u03c8(y, xt+1) by the \u00b5h-strong convexity of h. We substitute y with zt to obtain\nII \u2264 D\u03c8(z t, xt)\u2212D\u03c8(zt, xt+1)\u2212D\u03c8(xt+1, xt)\n\u03b7t + h(zt)\u2212 h(xt+1)\u2212 \u00b5hD\u03c8(zt, xt+1).\n(3)\n\u2022 For term III, we simply use the \u00b5f -strong convexity of f to get\nIII \u2264 f(zt)\u2212 f(xt)\u2212 \u00b5fD\u03c8(zt, xt). (4)\n\u2022 For term IV, we have\nIV \u2264 LD\u03c8(xt+1, xt) +M \u221a 2D\u03c8(xt+1, xt)\n\u2264 LD\u03c8(xt+1, xt) + 2\u03b7tM2 + D\u03c8(x\nt+1, xt)\n4\u03b7t , (5)\nwhere the first inequality holds by the 1-strong convexity of \u03c8 again and the second one is due to AM-GM inequality.\nBy plugging the bounds (2), (3), (4) and (5) into (1), we obtain\nf(xt+1)\u2212 f(xt)\n\u2264\u27e8\u03bet, zt \u2212 xt\u27e9+ 2\u03b7t\u2225\u03bet\u22252\u2217 + D\u03c8(x\nt+1, xt)\n4\u03b7t\n+ D\u03c8(z t, xt)\u2212D\u03c8(zt, xt+1)\u2212D\u03c8(xt+1, xt) \u03b7t + h(zt)\u2212 h(xt+1)\u2212 \u00b5hD\u03c8(zt, xt+1)\n+ f(zt)\u2212 f(xt)\u2212 \u00b5fD\u03c8(zt, xt) + LD\u03c8(xt+1, xt) + 2\u03b7tM2 + D\u03c8(x\nt+1, xt)\n4\u03b7t .\nRearranging the terms to get\nF (xt+1)\u2212 F (zt) \u2264\u27e8\u03bet, zt \u2212 xt\u27e9+ (\u03b7\u22121t \u2212 \u00b5f )D\u03c8(zt, xt)\u2212 (\u03b7\u22121t + \u00b5h)D\u03c8(zt, xt+1)\n+ ( L\u2212 1\n2\u03b7t\n) D\u03c8(x t+1, xt) + 2\u03b7t(M 2 + \u2225\u03bet\u22252\u2217)\n(a) \u2264\u27e8\u03bet, zt \u2212 xt\u27e9+ (\u03b7\u22121t \u2212 \u00b5f )D\u03c8(zt, xt)\u2212 (\u03b7\u22121t + \u00b5h)D\u03c8(zt, xt+1) + 2\u03b7t(M2 + \u2225\u03bet\u22252\u2217) (b) = vt\u22121 vt \u27e8\u03bet, zt\u22121 \u2212 xt\u27e9+ (\u03b7\u22121t \u2212 \u00b5f )D\u03c8(zt, xt)\u2212 (\u03b7\u22121t + \u00b5h)D\u03c8(zt, xt+1) + 2\u03b7t(M2 + \u2225\u03bet\u22252\u2217)\n(c) \u2264 vt\u22121 vt \u27e8\u03bet, zt\u22121 \u2212 xt\u27e9+ (\u03b7\u22121t \u2212 \u00b5f ) vt\u22121 vt D\u03c8(z t\u22121, xt)\u2212 (\u03b7\u22121t + \u00b5h)D\u03c8(zt, xt+1) + 2\u03b7t(M2 + \u2225\u03bet\u22252\u2217),\n(6)\nwhere (a) is by \u03b7t \u2264 12L\u2228\u00b5f \u2264 1 2L ,\u2200t \u2208 [T ] \u21d2 L \u2212 1 2\u03b7t \u2264 0, (b) holds due to the definition of zt = ( 1\u2212 vt\u22121vt ) xt + vt\u22121vt z t\u22121 implying zt \u2212 xt = vt\u22121vt ( zt\u22121 \u2212 xt ) , (c) is by noticing \u03b7t \u2264\n1 2L\u2228\u00b5f \u2264 1 \u00b5f ,\u2200t \u2208 [T ] \u21d2 \u03b7\u22121t \u2212 \u00b5f \u2265 0 and\nD\u03c8(z t, xt)\n(d) \u2264 ( 1\u2212 vt\u22121\nvt\n) D\u03c8(x\nt, xt) + vt\u22121 vt D\u03c8(z t\u22121, xt) = vt\u22121 vt D\u03c8(z t\u22121, xt)\nwhere (d) is by the convexity of the first argument in D\u03c8(\u00b7, \u00b7).\nMultiplying both sides of (6) by wt\u03b3tvt (all of these three terms are non-negative) and summing up from t = 1 to T , we obtain\nT\u2211 t=1 wt\u03b3tvt ( F (xt+1)\u2212 F (zt) ) \u2264\nT\u2211 t=1 wt\u03b3tvt\u22121\u27e8\u03bet, zt\u22121 \u2212 xt\u27e9+ T\u2211 t=1 2wt\u03b3t\u03b7tvt(M 2 + \u2225\u03bet\u22252\u2217)\n+ T\u2211 t=1 wt\u03b3t(\u03b7 \u22121 t \u2212 \u00b5f )vt\u22121D\u03c8(zt\u22121, xt)\u2212 wt\u03b3t(\u03b7\u22121t + \u00b5h)vtD\u03c8(zt, xt+1)\n=w1\u03b31(\u03b7 \u22121 1 \u2212 \u00b5f )v0D\u03c8(z0, x1)\u2212 wT \u03b3T (\u03b7 \u22121 T + \u00b5h)vTD\u03c8(z T , xT+1) + T\u2211 t=1 2wt\u03b3t\u03b7tvt(M 2 + \u2225\u03bet\u22252\u2217)\n+ T\u2211 t=1 wt\u03b3tvt\u22121\u27e8\u03bet, zt\u22121 \u2212 xt\u27e9+ T\u2211 t=2 ( wt\u03b3t(\u03b7 \u22121 t \u2212 \u00b5f )\u2212 wt\u22121\u03b3t\u22121(\u03b7\u22121t\u22121 + \u00b5h) ) vt\u22121D\u03c8(z t\u22121, xt)\n(e) =w1(1\u2212 \u00b5f\u03b71)v0D\u03c8(x\u2217, x1)\u2212 wT \u03b3T (\u03b7\u22121T + \u00b5h)vTD\u03c8(z T , xT+1) + T\u2211 t=1 2wt\u03b3t\u03b7tvt(M 2 + \u2225\u03bet\u22252\u2217)\n+ T\u2211 t=1 wt\u03b3tvt\u22121\u27e8\u03bet, zt\u22121 \u2212 xt\u27e9+ T\u2211 t=2 (wt \u2212 wt\u22121)\u03b3t(\u03b7\u22121t \u2212 \u00b5f )vt\u22121D\u03c8(zt\u22121, xt), (7)\nwhere (e) holds due to \u03b31(\u03b7\u221211 \u2212 \u00b5f ) = \u03b71(\u03b7 \u22121 1 \u2212 \u00b5f ) = 1\u2212 \u00b5f\u03b71, z0 = x\u2217 and \u03b3t(\u03b7 \u22121 t \u2212 \u00b5f ) = \u03b7t(\u03b7 \u22121 t \u2212 \u00b5f ) \u220ft s=2 1+\u00b5h\u03b7s\u22121 1\u2212\u00b5f\u03b7s = (\u03b7 \u22121 t\u22121 + \u00b5h)\u03b7t\u22121 \u220ft\u22121 s=2 1+\u00b5h\u03b7s\u22121 1\u2212\u00b5f\u03b7s = \u03b3t\u22121(\u03b7 \u22121 t\u22121 + \u00b5h),\u2200t \u2265 2.\nBy the convexity of F and the definition of zt = v0vt x \u2217+ \u2211t s=1 vs\u2212vs\u22121 vt\nxs (which means zt is a convex combination of x\u2217, x1, \u00b7 \u00b7 \u00b7 , xt by noticing that the weights are summed up to 1 and nonnegative since vt,\u2200t \u2208 {0} \u222a [T ] is non-decreasing), we have\nF (zt) \u2264 t\u2211\ns=1\nvs \u2212 vs\u22121 vt F (xs) + v0 vt F (x\u2217),\nwhich implies\nT\u2211 t=1 wt\u03b3tvt ( F (xt+1)\u2212 F (zt) ) \u2265\nT\u2211 t=1\n[ wt\u03b3tvtF (x t+1)\u2212 wt\u03b3t ( t\u2211\ns=1\n(vs \u2212 vs\u22121)F (xs) + v0F (x\u2217)\n)]\n= T\u2211 t=1\n[ wt\u03b3tvt ( F (xt+1)\u2212 F (x\u2217) ) \u2212 wt\u03b3t\nt\u2211 s=1 (vs \u2212 vs\u22121) (F (xs)\u2212 F (x\u2217))\n]\n=wT \u03b3T vT ( F (xT+1)\u2212 F (x\u2217) ) \u2212 ( T\u2211 t=1 wt\u03b3t ) (v1 \u2212 v0) ( F (x1)\u2212 F (x\u2217) ) +\nT\u2211 t=2\n[ wt\u22121\u03b3t\u22121vt\u22121 \u2212 ( T\u2211 s=t ws\u03b3s ) (vt \u2212 vt\u22121) ] ( F (xt)\u2212 F (x\u2217) ) .\nNow by the definition of vt = wT \u03b3T\u2211T s=t ws\u03b3s\n,\u2200t \u2208 [T ] and v0 = v1, we observe that( T\u2211 t=1 wt\u03b3t ) (v1 \u2212 v0) = 0,\nand for 2 \u2264 t \u2264 T ,\nwt\u22121\u03b3t\u22121vt\u22121 \u2212 ( T\u2211 s=t ws\u03b3s ) (vt \u2212 vt\u22121)\n=\n( T\u2211\ns=t\u22121 ws\u03b3s\n) vt\u22121 \u2212 ( T\u2211 s=t ws\u03b3s ) vt\n=\n( T\u2211\ns=t\u22121 ws\u03b3s\n) wT \u03b3T\u2211T\ns=t\u22121 ws\u03b3s \u2212 ( T\u2211 s=t ws\u03b3s ) wT \u03b3T\u2211T s=t ws\u03b3s\n=0.\nThese two equations immediately imply\nT\u2211 t=1 wt\u03b3tvt ( F (xt+1)\u2212 F (zt) ) \u2265 wT \u03b3T vT ( F (xT+1)\u2212 F (x\u2217) ) . (8)\nPlugging (8) into (7), we finally get wT \u03b3T vT ( F (xT+1)\u2212 F (x\u2217) ) \u2264w1(1\u2212 \u00b5f\u03b71)v0D\u03c8(x\u2217, x1)\u2212 wT \u03b3T (\u03b7\u22121T + \u00b5h)vTD\u03c8(z T , xT+1) +\nT\u2211 t=1 2wt\u03b3t\u03b7tvt(M 2 + \u2225\u03bet\u22252\u2217)\n+ T\u2211 t=1 wt\u03b3tvt\u22121\u27e8\u03bet, zt\u22121 \u2212 xt\u27e9+ T\u2211 t=2 (wt \u2212 wt\u22121)\u03b3t(\u03b7\u22121t \u2212 \u00b5f )vt\u22121D\u03c8(zt\u22121, xt)\n\u2264w1(1\u2212 \u00b5f\u03b71)v0D\u03c8(x\u2217, x1) + T\u2211 t=1 2wt\u03b3t\u03b7tvt(M 2 + \u2225\u03bet\u22252\u2217)\n+ T\u2211 t=1 wt\u03b3tvt\u22121\u27e8\u03bet, zt\u22121 \u2212 xt\u27e9+ T\u2211 t=2 (wt \u2212 wt\u22121)\u03b3t(\u03b7\u22121t \u2212 \u00b5f )vt\u22121D\u03c8(zt\u22121, xt).\nB.2 PROOF OF LEMMA 4.2\nProof of Lemma 4.2. We invoke Lemma 4.1 with wt = 1,\u2200t \u2208 [T ] to get \u03b3T vT ( F (xT+1)\u2212 F (x\u2217) ) \u2264(1\u2212 \u00b5f\u03b71)v0D\u03c8(x\u2217, x1) +\nT\u2211 t=1 2\u03b3t\u03b7tvt(M 2 + \u2225\u03bet\u22252\u2217) + T\u2211 t=1 \u03b3tvt\u22121\u27e8\u03bet, zt\u22121 \u2212 xt\u27e9.\nTaking expectations on both sides to obtain \u03b3T vTE [ F (xT+1)\u2212 F (x\u2217) ] \u2264(1\u2212 \u00b5f\u03b71)v0D\u03c8(x\u2217, x1) +\nT\u2211 t=1 2\u03b3t\u03b7tvt(M 2 + E [ \u2225\u03bet\u22252\u2217 ] ) + T\u2211 t=1 \u03b3tvt\u22121E [ \u27e8\u03bet, zt\u22121 \u2212 xt\u27e9 ] \u2264(1\u2212 \u00b5f\u03b71)v0D\u03c8(x\u2217, x1) +\nT\u2211 t=1 2\u03b3t\u03b7tvt(M 2 + \u03c32),\nwhere the last line is due to E [ \u2225\u03bet\u22252\u2217 ] = E [ E [ \u2225\u03bet\u22252\u2217 | F t\u22121 ]] \u2264 \u03c32 (Assumption 5A) and\nE [ \u27e8\u03bet, zt\u22121 \u2212 xt\u27e9 ] = E [ \u27e8E [ \u03bet|F t\u22121 ] , zt\u22121 \u2212 xt\u27e9 ] = 0 (zt\u22121 \u2212 xt \u2208 F t\u22121 = \u03c3(g\u0302s, s \u2208 [t\u2212 1]) and Assumption 4). Finally, we divide both sides by \u03b3T vT and plug in vt = wT \u03b3T\u2211T s=t ws\u03b3s\n= \u03b3T\u2211T s=t \u03b3s ,\u2200t \u2208 [T ] and v0 = v1 to finish the proof.\nB.3 PROOF OF LEMMA 4.3\nProof of Lemma 4.3. We invoke Lemma 4.1 to get wT \u03b3T vT ( F (xT+1)\u2212 F (x\u2217) ) \u2264w1(1\u2212 \u00b5f\u03b71)v0D\u03c8(x\u2217, x1) +\nT\u2211 t=1 2wt\u03b3t\u03b7tvt(M 2 + \u2225\u03bet\u22252\u2217)\n+ T\u2211 t=1 wt\u03b3tvt\u22121\u27e8\u03bet, zt\u22121 \u2212 xt\u27e9+ T\u2211 t=2 (wt \u2212 wt\u22121)\u03b3t(\u03b7\u22121t \u2212 \u00b5f )vt\u22121D\u03c8(zt\u22121, xt). (9)\nLet wt,\u2200t \u2208 [T ] be defined as follows (note that w1 is also well-defined as w1 = 1\u2211T s=1 2\u03b3s\u03b7sv\u0304s\u03c3 2 )\nwt := 1\u2211t\ns=2 2\u03b3s\u03b7sv\u0304s\u03c32 1\u2212\u00b5f\u03b7s + \u2211T s=1 2\u03b3s\u03b7sv\u0304s\u03c3 2 ,\u2200t \u2208 [T ] , (10)\nwhere v\u0304t := \u03b3T\u2211T s=t \u03b3s ,\u2200t \u2208 [T ] and v\u03041 := v\u03040. (11) Note that wt \u2265 0,\u2200t \u2208 [T ] is non-increasing, from the definition of vt := wT \u03b3T\u2211T s=t ws\u03b3s\n,\u2200t \u2208 [T ] and v0 := v1, there are always\nvt = wT \u03b3T\u2211T s=t ws\u03b3s \u2264 \u03b3T\u2211T s=t \u03b3s = v\u0304t,\u2200t \u2208 [T ] and v0 \u2264 v\u03040. (12)\nNow we consider the following non-negative sequence with U0 := 1 and\nUs := exp ( s\u2211 t=1 2wt\u03b3t\u03b7tvt\u2225\u03bet\u22252\u2217 \u2212 2wt\u03b3t\u03b7tvt\u03c32 ) \u2208 Fs,\u2200s \u2208 [T ] .\nWe claim Ut is a supermartingale by observing that E [ Ut | F t\u22121 ] = Ut\u22121E [ exp ( 2wt\u03b3t\u03b7tvt\u2225\u03bet\u22252\u2217 \u2212 2wt\u03b3t\u03b7tvt\u03c32 ) | F t\u22121 ] (a)\n\u2264 Ut\u22121 exp ( 2wt\u03b3t\u03b7tvt\u03c3 2 \u2212 2wt\u03b3t\u03b7tvt\u03c32 ) = Ut\u22121,\nwhere (a) holds due to Assumption 5B by noticing\n2wt\u03b3t\u03b7tvt (10) = 2\u03b3t\u03b7tvt\u2211t s=2 2\u03b3s\u03b7sv\u0304s\u03c32 1\u2212\u00b5f\u03b7s + \u2211T s=1 2\u03b3s\u03b7sv\u0304s\u03c3 2 \u2264 vt v\u0304t\u03c32 (12) \u2264 1 \u03c32 .\nHence, we know E [UT ] \u2264 U0 = 1. Thus, there is\nPr [ UT > 2\n\u03b4\n] (b)\n\u2264 \u03b4 2 E [UT ] \u2264 \u03b4 2\n\u21d2Pr [ T\u2211 t=1 2wt\u03b3t\u03b7tvt\u2225\u03bet\u22252\u2217 \u2264 T\u2211 t=1 2wt\u03b3t\u03b7tvt\u03c3 2 + log 2 \u03b4 ] \u2265 1\u2212 \u03b4 2 , (13)\nwhere we use Markov\u2019s inequality in (b).\nNext, we consider another non-negative sequence with R0 := 1 and\nRs := exp ( s\u2211 t=1 wt\u03b3tvt\u22121\u27e8\u03bet, zt\u22121 \u2212 xt\u27e9 \u2212 w2t \u03b32t v2t\u22121\u03c32\u2225zt\u22121 \u2212 xt\u22252 ) \u2208 Fs,\u2200s \u2208 [T ] .\nWe prove that Rt is also a supermartingale by E [ Rt | F t\u22121 ] = Rt\u22121E [ exp ( wt\u03b3tvt\u22121\u27e8\u03bet, zt\u22121 \u2212 xt\u27e9 \u2212 w2t \u03b32t v2t\u22121\u03c32\u2225zt\u22121 \u2212 xt\u22252 ) | F t\u22121 ] (c)\n\u2264 Rt\u22121 exp ( w2t \u03b3 2 t v 2 t\u22121\u03c3 2\u2225zt\u22121 \u2212 xt\u22252 \u2212 w2t \u03b32t v2t\u22121\u03c32\u2225zt\u22121 \u2212 xt\u22252 ) = Rt\u22121,\nwhere (c) is by applying Lemma 2.1 (note that zt\u22121 \u2212 xt \u2208 F t\u22121 = \u03c3(g\u0302s, s \u2208 [t\u2212 1])). Hence, we have E [RT ] \u2264 R0 = 1, which immediately implies\nPr [ RT > 2\n\u03b4\n] (d)\n\u2264 \u03b4 2 E [RT ] \u2264 \u03b4 2\n\u21d2Pr [ T\u2211 t=1 wt\u03b3tvt\u22121\u27e8\u03bet, zt\u22121 \u2212 xt\u27e9 \u2264 T\u2211 t=1 w2t \u03b3 2 t v 2 t\u22121\u03c3 2\u2225zt\u22121 \u2212 xt\u22252 + log 2 \u03b4 ] \u2265 1\u2212 \u03b4 2\n\u21d2Pr [ T\u2211 t=1 wt\u03b3tvt\u22121\u27e8\u03bet, zt\u22121 \u2212 xt\u27e9 \u2264 T\u2211 t=1 2w2t \u03b3 2 t v 2 t\u22121\u03c3 2D\u03c8(z t\u22121, xt) + log 2 \u03b4 ] \u2265 1\u2212 \u03b4 2 , (14)\nwhere (d) is by Markov\u2019s inequality and the last line is due to \u2225zt\u22121 \u2212 xt\u22252 \u2264 2D\u03c8(zt\u22121, xt) from the 1-strong convexity of \u03c8.\nCombining (9), (13) and (14), with probability at least 1\u2212 \u03b4, there is\nwT \u03b3T vT ( F (xT+1)\u2212 F (x\u2217) ) \u2264w1(1\u2212 \u00b5f\u03b71)v0D\u03c8(x\u2217, x1) + 2 log 2\n\u03b4 + T\u2211 t=1 2wt\u03b3t\u03b7tvt(M 2 + \u03c32)\n+ T\u2211 t=1 2w2t \u03b3 2 t v 2 t\u22121\u03c3 2D\u03c8(z t\u22121, xt) + T\u2211 t=2 (wt \u2212 wt\u22121)\u03b3t(\u03b7\u22121t \u2212 \u00b5f )vt\u22121D\u03c8(zt\u22121, xt)\n= [ w1(1\u2212 \u00b5f\u03b71)v0 + 2w21\u03b321v20\u03c32 ] D\u03c8(x \u2217, x1) + 2 log 2\n\u03b4 + T\u2211 t=1 2wt\u03b3t\u03b7tvt(M 2 + \u03c32)\n+ T\u2211 t=2 [ (wt \u2212 wt\u22121)(\u03b7\u22121t \u2212 \u00b5f ) + 2w2t \u03b3tvt\u22121\u03c32 ] \u03b3tvt\u22121D\u03c8(z t\u22121, xt).\nObserving that for t \u2265 2\n(wt \u2212 wt\u22121)(\u03b7\u22121t \u2212 \u00b5f ) + 2w2t \u03b3tvt\u22121\u03c32\n=2w2t \u03b3tvt\u22121\u03c3 2\n\u2212  1\u2211t\u22121 s=2 2\u03b3s\u03b7sv\u0304s\u03c32 1\u2212\u00b5f\u03b7s + \u2211T s=1 2\u03b3s\u03b7sv\u0304s\u03c3 2 \u2212 1\u2211t s=2 2\u03b3s\u03b7sv\u0304s\u03c32 1\u2212\u00b5f\u03b7s + \u2211T s=1 2\u03b3s\u03b7sv\u0304s\u03c3 2  (\u03b7\u22121t \u2212 \u00b5f ) =2w2t \u03b3tvt\u22121\u03c3 2 \u2212 wtwt\u22121 \u00d7 2\u03b3t\u03b7tv\u0304t\u03c3 2\n1\u2212 \u00b5f\u03b7t \u00d7 (\u03b7\u22121t \u2212 \u00b5f )\n=2wt(wtvt\u22121 \u2212 wt\u22121v\u0304t)\u03b3t\u03c32 \u2264 0,\nwhere the last line holds due to wt \u2264 wt\u22121 and vt\u22121 \u2264 vt \u2264 v\u0304t. So we know\nwT \u03b3T vT ( F (xT+1)\u2212 F (x\u2217) ) \u2264 [ w1(1\u2212 \u00b5f\u03b71)v0 + 2w21\u03b321v20\u03c32 ] D\u03c8(x \u2217, x1) + 2 log 2\n\u03b4 + T\u2211 t=1 2wt\u03b3t\u03b7tvt(M 2 + \u03c32)\n(e) \u2264w1 ( 1\u2212 \u00b5f\u03b71 + 2w1\u03b321v0\u03c32 ) v0D\u03c8(x \u2217, x1) + 2 log 2\n\u03b4 + w1 T\u2211 t=1 2\u03b3t\u03b7tvt(M 2 + \u03c32),\nwhere (e) is by wt \u2264 w1,\u2200t \u2208 [T ]. Dividing both sides by wT \u03b3T vT , we get\nF (xT+1)\u2212 F (x\u2217)\n\u2264w1 wT\n[ (1\u2212 \u00b5f\u03b71 + 2w1\u03b321v0\u03c32)\nv0 \u03b3T vT D\u03c8(x \u2217, x1) +\n2\nw1\u03b3T vT log\n2 \u03b4 + 2 T\u2211 t=1 \u03b3t\u03b7tvt \u03b3T vT (M2 + \u03c32) ] (f)\n\u2264 ( 1 + max\n2\u2264t\u2264T\n1\n1\u2212 \u00b5f\u03b7t\n)[ (2\u2212 \u00b5f\u03b71)D\u03c8(x\u2217, x1)\u2211T\nt=1 \u03b3t + 2\n( M2 + \u03c32 ( 1 + 2 log 2\n\u03b4 )) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s ]\n\u22642 ( 1 + max\n2\u2264t\u2264T\n1\n1\u2212 \u00b5f\u03b7t\n)[ D\u03c8(x\n\u2217, x1)\u2211T t=1 \u03b3t +\n( M2 + \u03c32 ( 1 + 2 log 2\n\u03b4 )) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s ] ,\nwhere (f) holds due to the following calculations\nw1 wT =\n\u2211T s=1 2\u03b3s\u03b7sv\u0304s\u03c3 2 + \u2211T s=2 2\u03b3s\u03b7sv\u0304s\u03c3 2\n1\u2212\u00b5f\u03b7s\u2211T s=1 2\u03b3s\u03b7sv\u0304s\u03c3 2 \u2264 1 + max 2\u2264t\u2264T\n1\n1\u2212 \u00b5f\u03b7t ;\n2w1\u03b3 2 1v0\u03c3\n2 = 2\u03b321v0\u03c3 2\u2211T s=1 2\u03b3s\u03b7sv\u0304s\u03c3 2 = 2\u03b31\u03b71v1\u03c3 2\u2211T s=1 2\u03b3s\u03b7sv\u0304s\u03c3 2 \u2264 1;\nv0 \u03b3T vT \u2264 v\u03040 \u03b3T vT = 1\u2211T t=1 \u03b3t ;\n2\nw1\u03b3T vT log\n2 \u03b4 = 4\u03c32 log 2 \u03b4 T\u2211 t=1 \u03b3t\u03b7tv\u0304t \u03b3T vT = 4\u03c32 log 2 \u03b4 T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s ;\n2 T\u2211 t=1 \u03b3t\u03b7tvt \u03b3T vT (M2 + \u03c32) \u2264 2(M2 + \u03c32) T\u2211 t=1 \u03b3t\u03b7tv\u0304t \u03b3T vT = 2(M2 + \u03c32) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s .\nHence, the proof is completed.\nC GENERAL CONVEX FUNCTIONS\nIn this section, we present the full version of theorems for general convex functions (i.e., \u00b5f = \u00b5h = 0) with their proofs. Theorem C.1. Under Assumptions 1-4 and 5A with \u00b5f = \u00b5h = 0:\nIf T is unknown, by taking \u03b7t = 12L \u2227 \u03b7\u221a t ,\u2200t \u2208 [T ], there is\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 O ( LD\u03c8(x \u2217, x1)\nT + 1\u221a T\n[ D\u03c8(x \u2217, x1)\n\u03b7 + \u03b7(M2 + \u03c32) log T\n]) .\nIn particular, by choosing \u03b7 = \u0398 (\u221a\nD\u03c8(x\u2217,x1) M2+\u03c32\n) , there is\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 O ( LD\u03c8(x \u2217, x1)\nT + (M + \u03c3) \u221a D\u03c8(x\u2217, x1) log T\u221a T ) .\nIf T is known, by taking \u03b7t = 12L \u2227 \u03b7\u221a T ,\u2200t \u2208 [T ], there is\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 O ( LD\u03c8(x \u2217, x1)\nT + 1\u221a T\n[ D\u03c8(x \u2217, x1)\n\u03b7 + \u03b7(M2 + \u03c32) log T\n]) .\nIn particular, by choosing \u03b7 = \u0398 (\u221a\nD\u03c8(x\u2217,x1) (M2+\u03c32) log T\n) , there is\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 O ( LD\u03c8(x \u2217, x1)\nT + (M + \u03c3) \u221a D\u03c8(x\u2217, x1) log T\u221a T ) .\nProof. From Lemma 4.2, if \u03b7t \u2264 12L\u2228\u00b5f ,\u2200t \u2208 [T ], there is\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 (1\u2212 \u00b5f\u03b71)D\u03c8(x\n\u2217, x1)\u2211T t=1 \u03b3t + 2(M2 + \u03c32) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s , (15)\nwhere \u03b3t := \u03b7t \u220ft s=2 1+\u00b5h\u03b7s\u22121 1\u2212\u00b5f\u03b7s ,\u2200t \u2208 [T ]. Note that \u00b5f = \u00b5h = 0 now, so both \u03b7t = 1 2L \u2227 \u03b7\u221a t ,\u2200t \u2208 [T ] and \u03b7t = 12L \u2227 \u03b7\u221a T ,\u2200t \u2208 [T ] satisfy \u03b7t \u2264 12L\u2228\u00b5f = 1 2L ,\u2200t \u2208 [T ]. Besides, \u03b3t will degenerate to \u03b7t. Therefore, (15) can be simplified into\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 D\u03c8(x\n\u2217, x1)\u2211T t=1 \u03b7t + 2(M2 + \u03c32) T\u2211 t=1 \u03b72t\u2211T s=t \u03b7s . (16)\nBefore proving convergence rates for these two different step sizes, we first recall some standard results.\nT\u2211 t=1 1\u221a t = T\u2211 t=1 \u221a t\u2212 t\u2212 1\u221a t = \u221a T + T\u22121\u2211 t=1 \u221a t\u2212 t\u221a t+ 1 \u2265 \u221a T ; (17)\nT\u2211 s=t 1\u221a s \u2265 \u222b T+1 t 1\u221a s ds = 2( \u221a T + 1\u2212 \u221a t),\u2200t \u2208 [T ] ; (18)\nT\u2211 t=1 1 t \u2264 1 + \u222b T 1 1 t dt = 1 + log T. (19)\nIf \u03b7t = 12L \u2227 \u03b7\u221a t ,\u2200t \u2208 [T ], we consider the following three cases:\n\u2022 \u03b7 < 12L : In this case, we have \u03b7t = \u03b7\u221a t ,\u2200t \u2208 [T ] and\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 D\u03c8(x \u2217, x1)\n\u03b7 \u2211T t=1 1/ \u221a t + 2\u03b7(M2 + \u03c32) T\u2211 t=1\n1 t \u2211T s=t 1/ \u221a s\n(17),(18) \u2264 D\u03c8(x\n\u2217, x1)\n\u03b7 \u221a T\n+ \u03b7(M2 + \u03c32) T\u2211 t=1\n1\nt( \u221a T + 1\u2212 \u221a t)\n(a) \u2264 D\u03c8(x \u2217, x1)\n\u03b7 \u221a T\n+ 4\u03b7(M2 + \u03c32)(1 + log T )\u221a\nT\n= 1\u221a T\n[ D\u03c8(x \u2217, x1)\n\u03b7 + 4\u03b7(M2 + \u03c32)(1 + log T )\n] , (20)\nwhere (a) is by\nT\u2211 t=1\n1\nt( \u221a T + 1\u2212 \u221a t) = T\u2211 t=1 \u221a T + 1 + \u221a t t(T + 1\u2212 t) \u2264 T\u2211 t=1 2 \u221a T + 1 t(T + 1\u2212 t)\n= T\u2211 t=1 2\u221a T + 1 ( 1 t +\n1\nT + 1\u2212 t\n) =\n4\u221a T + 1 T\u2211 t=1 1 t\n(19) \u2264 4(1 + log T )\u221a\nT .\n\u2022 \u03b7 \u2265 \u221a T\n2L : In this case, we have \u03b7t = 1 2L ,\u2200t \u2208 [T ] and\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 D\u03c8(x \u2217, x1)\nT/2L + M2 + \u03c32 L T\u2211 t=1\n1\nT \u2212 t+ 1\n= 2LD\u03c8(x\n\u2217, x1) T + M2 + \u03c32 L T\u2211 t=1 1 t\n(19) \u2264 2LD\u03c8(x\n\u2217, x1)\nT +\n(M2 + \u03c32)(1 + log T )\nL (b)\n\u2264 2LD\u03c8(x \u2217, x1)\nT + 2\u03b7(M2 + \u03c32)(1 + log T )\u221a T , (21)\nwhere (b) is by 1L \u2264 2\u03b7\u221a T .\n\u2022 \u03b7 \u2208 [ 12L , \u221a T 2L ): In this case, we define \u03c4 = \u230a4\u03b7 2L2\u230b where \u230a\u00b7\u230b is the floor function. Note\nthat 4\u03b72L2 \u2208 [1, T ) \u21d2 \u03c4 = \u230a4\u03b72L2\u230b \u2208 [T \u2212 1] .\nBy observing \u03b7\u221a t \u2265 12L \u21d4 t \u2208 [1, \u03c4 ], we can calculate E [ F (xT+1)\u2212 F (x\u2217) ] \u2264 D\u03c8(x\n\u2217, x1)\u2211T t=1 \u03b7t + 2(M2 + \u03c32) T\u2211 t=1 \u03b72t\u2211T s=t \u03b7s\n(c) \u2264 D\u03c8(x \u2217, x1)\nT 2\nT\u2211 t=1 1\n\u03b7t\ufe38 \ufe37\ufe37 \ufe38 I\n+2(M2 + \u03c32)  \u03c4\u2211 t=1 \u03b72t\u2211T s=t \u03b7s\ufe38 \ufe37\ufe37 \ufe38\nII\n+ T\u2211 t=\u03c4+1 \u03b72t\u2211T s=t \u03b7s\ufe38 \ufe37\ufe37 \ufe38\nIII\n ,\nwhere (c) is by T 2 \u2264 (\u2211T\nt=1 \u03b7t )(\u2211T t=1 1 \u03b7t ) . Now we bound terms I, II and III as follows\nI = T\u2211 t=1 2L \u2228 \u221a t \u03b7 \u2264 T\u2211 t=1 2L+ \u221a t \u03b7 \u2264 2LT + \u221a T + \u222b T 1 \u221a tdt \u03b7\n= 2LT +\n\u221a T + 23 (T 3 2 \u2212 1)\n\u03b7 \u2264 2LT + 5T\n3 2\n3\u03b7 ;\nII = \u03c4\u2211 t=1 \u03b72t\u2211\u03c4 s=t \u03b7s + \u2211T s=\u03c4+1 \u03b7s = \u03c4\u2211 t=1\n1/(4L2) (\u03c4 \u2212 t+ 1)/2L+ \u2211T s=\u03c4+1 \u03b7/ \u221a s\n= 1\n2L \u03c4\u2211 t=1\n1 \u03c4 \u2212 t+ 1 + \u2211T s=\u03c4+1 2\u03b7L/ \u221a s\n(18) \u2264 1\n2L \u03c4\u2211 t=1\n1\n\u03c4 \u2212 t+ 1 + 4\u03b7L( \u221a T + 1\u2212 \u221a \u03c4 + 1)\n\u2264  1 2L \u2211\u03c4 t=1 1 \u03c4\u2212t+1 \u2264 1 2L ( 1 + \u222b \u03c4 1 1 t dt ) = 1+log \u03c42L (d) \u2264 \u03b7(1+log T )\u221a \u03c4\n1 2L \u2211\u03c4 t=1 1 4\u03b7L( \u221a T+1\u2212 \u221a \u03c4+1) = \u03c4 8\u03b7L2( \u221a T+1\u2212 \u221a \u03c4+1) (e) \u2264 \u03b7 2( \u221a T+1\u2212 \u221a \u03c4+1)\n\u21d2 II \u2264 \u03b7(1 + log T ) (\n1\u221a \u03c4 \u2227 1 2( \u221a T + 1\u2212 \u221a \u03c4 + 1) ) \u2264 2\u03b7(1 + log T )\u221a\n\u03c4 + 2( \u221a T + 1\u2212 \u221a \u03c4 + 1)\n(f) \u2264 2\u03b7(1 + log T )\u221a T ,\nwhere (d) is due to \u03c4 \u2264 T and \u221a \u03c4 \u2264 2\u03b7L, (e) holds by \u03c4 \u2264 4\u03b72L2 and (f) is by, for \u03c4 \u2208 [T \u2212 1] and T \u2265 2, \u221a \u03c4 + 2( \u221a T + 1\u2212 \u221a \u03c4 + 1) \u2265 \u221a T \u2212 1 + 2 \u221a T + 1\u2212 2 \u221a T \u2265 \u221a T .\nIII = \u03b7 T\u2211\nt=\u03c4+1\n1 t \u2211T s=t 1/ \u221a s (18) \u2264 \u03b7 T\u2211 t=\u03c4+1\n1\n2t( \u221a T + 1\u2212 \u221a t)\n= \u03b7 T\u2211 t=\u03c4+1 \u221a T + 1 + \u221a t 2t(T + 1\u2212 t) \u2264 \u03b7 T\u2211 t=\u03c4+1 \u221a T + 1 t(T + 1\u2212 t)\n= \u03b7 T\u2211 t=\u03c4+1 1\u221a T + 1 ( 1 t +\n1\nT + 1\u2212 t\n) \u2264 2\u03b7\u221a\nT + 1 T\u2211 t=1 1 t\n(19) \u2264 2\u03b7(1 + log T )\u221a\nT .\nThus, we have E [ F (xT+1)\u2212 F (x\u2217) ] \u2264D\u03c8(x \u2217, x1)\nT 2\n( 2LT + 5T 3 2\n3\u03b7\n) + 2(M2 + \u03c32) [ 2\u03b7(1 + log T )\u221a\nT + 2\u03b7(1 + log T )\u221a T ] \u22642LD\u03c8(x \u2217, x1)\nT + 1\u221a T\n( 5D\u03c8(x \u2217, x1)\n3\u03b7 + 8\u03b7(M2 + \u03c32)(1 + log T )\n) . (22)\nCombining (20), (21) and (22), we know\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 1\u221a\nT\n[ D\u03c8(x \u2217, x1)\n\u03b7 + 4\u03b7(M2 + \u03c32)(1 + log T ) ] \u2228 [ 2LD\u03c8(x \u2217, x1)\nT + 2\u03b7(M2 + \u03c32)(1 + log T )\u221a T ] \u2228 [ 2LD\u03c8(x \u2217, x1)\nT + 1\u221a T\n( 5D\u03c8(x \u2217, x1)\n3\u03b7 + 8\u03b7(M2 + \u03c32)(1 + log T ) )] \u22642LD\u03c8(x \u2217, x1)\nT + 1\u221a T\n( 5D\u03c8(x \u2217, x1)\n3\u03b7 + 8\u03b7(M2 + \u03c32)(1 + log T ) ) =O ( LD\u03c8(x \u2217, x1)\nT + 1\u221a T\n[ D\u03c8(x \u2217, x1)\n\u03b7 + \u03b7(M2 + \u03c32) log T\n]) . (23)\nBy plugging in \u03b7 = \u0398 (\u221a\nD\u03c8(x\u2217,x1) M2+\u03c32\n) , we get the desired bound.\nIf \u03b7t = 12L \u2227 \u03b7\u221a T ,\u2200t \u2208 [T ], we will obtain\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 D\u03c8(x \u2217, x1)\nT\n( 2L \u2228 \u221a T\n\u03b7\n) + 2 ( 1\n2L \u2227 \u03b7\u221a\nT\n) (M2 + \u03c32) T\u2211 t=1\n1\nT \u2212 t+ 1\n= D\u03c8(x\n\u2217, x1)\nT\n( 2L \u2228 \u221a T\n\u03b7\n) + 2 ( 1\n2L \u2227 \u03b7\u221a\nT\n) (M2 + \u03c32) T\u2211 t=1 1 t\n(19) \u2264 D\u03c8(x\n\u2217, x1)\nT\n( 2L \u2228 \u221a T\n\u03b7\n) + 2 ( 1\n2L \u2227 \u03b7\u221a\nT\n) (M2 + \u03c32)(1 + log T )\n\u2264 2LD\u03c8(x \u2217, x1)\nT + 1\u221a T\n[ D\u03c8(x \u2217, x1)\n\u03b7 + 2\u03b7(M2 + \u03c32)(1 + log T ) ] = O ( LD\u03c8(x \u2217, x1)\nT + 1\u221a T\n[ D\u03c8(x \u2217, x1)\n\u03b7 + \u03b7(M2 + \u03c32) log T\n]) . (24)\nBy plugging in \u03b7 = \u0398 (\u221a\nD\u03c8(x\u2217,x1) (M2+\u03c32) log T\n) , we get the desired bound.\nTheorem C.2. Under Assumptions 1-4 and 5B with \u00b5f = \u00b5h = 0 and let \u03b4 \u2208 (0, 1):\nIf T is unknown, by taking \u03b7t = 12L \u2227 \u03b7\u221a t ,\u2200t \u2208 [T ], then with probability at least 1\u2212 \u03b4, there is\nF (xT+1)\u2212 F (x\u2217) \u2264 O ( LD\u03c8(x \u2217, x1)\nT + 1\u221a T\n[ D\u03c8(x \u2217, x1)\n\u03b7 + \u03b7\n( M2 + \u03c32 log 1\n\u03b4\n) log T ]) .\nIn particular, by choosing \u03b7 = \u0398 (\u221a D\u03c8(x\u2217,x1)\nM2+\u03c32 log 1\u03b4\n) , there is\nF (xT+1)\u2212 F (x\u2217) \u2264 O LD\u03c8(x\u2217, x1) T + (M + \u03c3 \u221a log 1\u03b4 ) \u221a D\u03c8(x\u2217, x1) log T \u221a T  . If T is known, by taking \u03b7t = 12L \u2227 \u03b7\u221a T ,\u2200t \u2208 [T ], then with probability at least 1\u2212 \u03b4, there is\nF (xT+1)\u2212 F (x\u2217) \u2264 O ( LD\u03c8(x \u2217, x1)\nT + 1\u221a T\n[ D\u03c8(x \u2217, x1)\n\u03b7 + \u03b7\n( M2 + \u03c32 log 1\n\u03b4\n) log T ]) .\nIn particular, by choosing \u03b7 = \u0398 (\u221a\nD\u03c8(x\u2217,x1)\n(M2+\u03c32 log 1\u03b4 ) log T\n) , there is\nF (xT+1)\u2212 F (x\u2217) \u2264 O LD\u03c8(x\u2217, x1) T + (M + \u03c3 \u221a log 1\u03b4 ) \u221a D\u03c8(x\u2217, x1) log T \u221a T  . Proof. From Lemma 4.3, if \u03b7t \u2264 12L\u2228\u00b5f ,\u2200t \u2208 [T ], with probability at least 1\u2212 \u03b4, there is\nF (xT+1)\u2212 F (x\u2217) \u22642 ( 1 + max\n2\u2264t\u2264T\n1\n1\u2212 \u00b5f\u03b7t ) \u00d7 [ D\u03c8(x\n\u2217, x1)\u2211T t=1 \u03b3t +\n( M2 + \u03c32 ( 1 + 2 log 2\n\u03b4 )) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s ] , (25)\nwhere \u03b3t := \u03b7t \u220ft s=2 1+\u00b5h\u03b7s\u22121 1\u2212\u00b5f\u03b7s ,\u2200t \u2208 [T ]. Note that \u00b5f = \u00b5h = 0 now, so both \u03b7t = 1 2L \u2227 \u03b7\u221a t ,\u2200t \u2208 [T ] and \u03b7t = 12L \u2227 \u03b7\u221a T ,\u2200t \u2208 [T ] satisfy \u03b7t \u2264 12L\u2228\u00b5f = 1 2L ,\u2200t \u2208 [T ]. Besides, \u03b3t will degenerate to \u03b7t. Then we can simplify (25) into\nF (xT+1)\u2212 F (x\u2217) \u2264 4D\u03c8(x \u2217, x1)\u2211T\nt=1 \u03b7t + 4\n( M2 + \u03c32 ( 1 + 2 log 2\n\u03b4 )) T\u2211 t=1 \u03b72t\u2211T s=t \u03b7s . (26)\nIf \u03b7t = 12L \u2227 \u03b7\u221a t ,\u2200t \u2208 [T ], similar to (23), we will have\nF (xT+1)\u2212 F (x\u2217) \u2264 O ( LD\u03c8(x \u2217, x1)\nT + 1\u221a T\n[ D\u03c8(x \u2217, x1)\n\u03b7 + \u03b7\n( M2 + \u03c32 log 1\n\u03b4\n) log T ]) .\nBy plugging in \u03b7 = \u0398 (\u221a D\u03c8(x\u2217,x1)\nM2+\u03c32 log 1\u03b4\n) , we get the desired bound.\nIf \u03b7t = 12L \u2227 \u03b7\u221a T ,\u2200t \u2208 [T ], similar to (24), we will get\nF (xT+1)\u2212 F (x\u2217) \u2264 O ( LD\u03c8(x \u2217, x1)\nT + 1\u221a T\n[ D\u03c8(x \u2217, x1)\n\u03b7 + \u03b7\n( M2 + \u03c32 log 1\n\u03b4\n) log T ]) .\nBy plugging in \u03b7 = \u0398 (\u221a\nD\u03c8(x\u2217,x1)\n(M2+\u03c32 log 1\u03b4 ) log T\n) , we get the desired bound.\nD STRONGLY CONVEX FUNCTIONS\nIn this section, we present the full version of theorems for strongly convex functions with their proofs.\nD.1 THE CASE OF \u00b5f > 0\nTheorem D.1. Under Assumptions 1-4 and 5A with \u00b5f > 0 and \u00b5h = 0, let \u03baf := L\u00b5f \u2265 0:\nIf T is unknown, by taking either \u03b7t = 1\u00b5f (t+2\u03baf ) ,\u2200t \u2208 [T ] or \u03b7t = 2 \u00b5f (t+1+4\u03baf ) ,\u2200t \u2208 [T ], there is E [ F (xT+1)\u2212 F (x\u2217) ] \u2264 O ( LD\u03c8(x \u2217,x1) T + (M2+\u03c32) log T \u00b5f (T+\u03baf ) ) \u03b7t = 1 \u00b5f (t+2\u03baf ) ,\u2200t \u2208 [T ] O ( L(1+\u03baf )D\u03c8(x\n\u2217,x1) T (T+\u03baf ) + (M 2+\u03c32) log T \u00b5f (T+\u03baf ) ) \u03b7t = 2 \u00b5f (t+1+4\u03baf ) ,\u2200t \u2208 [T ] .\nIf T is known, by taking \u03b7t =  1 \u00b5f (1+2\u03baf ) t = 1 1 \u00b5f (\u03b7+2\u03baf ) 2 \u2264 t \u2264 \u03c4 2\n\u00b5f (t\u2212\u03c4+2+4\u03baf ) t \u2265 \u03c4 + 1 ,\u2200t \u2208 [T ] where \u03b7 \u2265 0 can be any\nnumber satisfying \u03b7 + \u03baf > 1 and \u03c4 := \u2308 T 2 \u2309 , there is\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 O  LD\u03c8(x\u2217, x1) exp ( T\n2\u03b7+4\u03baf\n) + (M2 + \u03c32) log T \u00b5f (T + \u03baf )  . Proof. When \u00b5f > 0 and \u00b5h = 0, suppose the condition of \u03b7t \u2264 12L\u2228\u00b5f ,\u2200t \u2208 [T ] in Lemma 4.2 holds, we have\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 (1\u2212 \u00b5f\u03b71)D\u03c8(x\n\u2217, x1)\u2211T t=1 \u03b3t + 2(M2 + \u03c32) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s . (27)\nNow observing that for any t \u2208 [T ]\n\u03b3t := \u03b7t t\u220f s=2 1 + \u00b5h\u03b7s\u22121 1\u2212 \u00b5f\u03b7s = \u03b7t t\u220f s=2\n1\n1\u2212 \u00b5f\u03b7s = \u03b7t\u0393t =\n{ \u0393t\u2212\u0393t\u22121\n\u00b5f t \u2265 2\n\u03b71 t = 1 ,\nwhere \u0393t := \u220ft s=2 1 1\u2212\u00b5f\u03b7s ,\u2200t \u2208 [T ]. Hence, (27) can be rewritten as\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 (1\u2212 \u00b5f\u03b71)D\u03c8(x \u2217, x1)\n\u03b71 + \u0393T\u22121 \u00b5f\n+ 2(M2 + \u03c32)\n[ \u03b721\n\u03b71 + \u0393T\u22121 \u00b5f\n+ T\u2211 t=2\n\u00b5f\u03b7 2 t\n(\u0393T /\u0393t\u22121 \u2212 1)(1\u2212 \u00b5f\u03b7t)\n] . (28)\nNow let us check the condition of \u03b7t \u2264 12L\u2228\u00b5f ,\u2200t \u2208 [T ] for our three choices respectively:\n\u03b7t = 1 \u00b5f (t+ 2\u03baf ) \u2264 1 \u00b5f + 2L \u2264 1 2L \u2228 \u00b5f ,\u2200t \u2208 [T ] ;\n\u03b7t = 2 \u00b5f (t+ 1 + 4\u03baf ) \u2264 1 \u00b5f + 2L \u2264 1 2L \u2228 \u00b5f ,\u2200t \u2208 [T ] ;\n\u03b7t =  1 \u00b5f (1+2\u03baf ) = 1\u00b5f+2L \u2264 1 2L\u2228\u00b5f t = 1 1 \u00b5f (\u03b7+2\u03baf ) \u2264 1\u00b5f (2\u03baf\u2228(\u03b7+\u03baf )) \u2264 1 2L\u2228\u00b5f 2 \u2264 t \u2264 \u03c4 2\n\u00b5f (t\u2212\u03c4+2+4\u03baf ) \u2264 1 \u00b5f+2L \u2264 12L\u2228\u00b5f t \u2265 \u03c4 + 1\n.\nTherefore, (28) holds for all cases.\nFirst, we consider \u03b7t = 1\u00b5f (t+2\u03baf ) ,\u2200t \u2208 [T ]. We can calculate \u03b71 = 1 \u00b5f (1+2\u03baf ) and\n\u0393t = t\u220f s=2\n1\n1\u2212 \u00b5f\u03b7s = t\u220f s=2 s+ 2\u03baf s\u2212 1 + 2\u03baf = t+ 2\u03baf 1 + 2\u03baf ,\u2200t \u2208 [T ] .\nHence, using (28), we have\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 (1\u2212 11+2\u03baf )D\u03c8(x \u2217, x1)\n1 \u00b5f (1+2\u03baf ) + \u0393T\u22121\u00b5f + 2(M2 + \u03c32)\n 1\u00b52f (1+2\u03baf )2 1\n\u00b5f (1+2\u03baf ) + \u0393T\u22121\u00b5f\n+ T\u2211 t=2 \u00b5f \u00b7 1\u00b52f (t+2\u03baf )2 (\u0393T /\u0393t\u22121 \u2212 1)(1\u2212 \u00b5f \u00b7 1\u00b5f (t+2\u03baf ) )  = 2LD\u03c8(x \u2217, x1)\n(1 + 2\u03baf )\u0393T \u2212 2\u03baf +\n2(M2 + \u03c32)\n\u00b5f\n[ 1\n(1 + 2\u03baf )((1 + 2\u03baf )\u0393T \u2212 2\u03baf )\n+ T\u2211 t=2\n1\n(\u0393T /\u0393t\u22121 \u2212 1)(t\u2212 1 + 2\u03baf )(t+ 2\u03baf )\n]\n= 2LD\u03c8(x\n\u2217, x1)\nT +\n2(M2 + \u03c32)\n\u00b5f\n[ 1\n(1 + 2\u03baf )T + T\u2211 t=2\n1\n(T \u2212 t+ 1)(t+ 2\u03baf )\n]\n= 2LD\u03c8(x\n\u2217, x1)\nT +\n2(M2 + \u03c32)\n\u00b5f\nT\u2211 t=1\n1\n(T \u2212 t+ 1)(t+ 2\u03baf )\n= 2LD\u03c8(x\n\u2217, x1)\nT +\n2(M2 + \u03c32)\n\u00b5f\nT\u2211 t=1\n1\nT + 1 + 2\u03baf\n( 1\nT \u2212 t+ 1 +\n1\nt+ 2\u03baf\n)\n\u22642LD\u03c8(x \u2217, x1)\nT +\n2(M2 + \u03c32) \u00b5f \u00b7 1 + log T + 11+2\u03baf + log T+2\u03baf 1+2\u03baf T + 1 + 2\u03baf\n\u22642LD\u03c8(x \u2217, x1)\nT +\n4(M2 + \u03c32)(1 + log T )\n\u00b5f (T + 2\u03baf )\n=O\n( LD\u03c8(x \u2217, x1)\nT +\n(M2 + \u03c32) log T\n\u00b5f (T + \u03baf )\n) . (29)\nNext, for the case of \u03b7t = 2\u00b5f (t+1+4\u03baf ) ,\u2200t \u2208 [T ], there are \u03b71 = 1 \u00b5f (1+2\u03baf ) and\n\u0393t = t\u220f s=2\n1\n1\u2212 \u00b5f\u03b7s = t\u220f s=2 s+ 1 + 4\u03baf s\u2212 1 + 4\u03baf = (t+ 4\u03baf )(t+ 1 + 4\u03baf ) (1 + 4\u03baf )(2 + 4\u03baf ) ,\u2200t \u2208 [T ] .\nThus, we have E [ F (xT+1)\u2212 F (x\u2217) ] \u2264 (1\u2212 11+2\u03baf )D\u03c8(x \u2217, x1)\n1 \u00b5f (1+2\u03baf ) + \u0393T\u22121\u00b5f + 2(M2 + \u03c32)\n 1\u00b52f (1+2\u03baf )2 1\n\u00b5f (1+2\u03baf ) + \u0393T\u22121\u00b5f\n+ T\u2211 t=2 \u00b5f \u00b7 4\u00b52f (t+1+4\u03baf )2 (\u0393T /\u0393t\u22121 \u2212 1)(1\u2212 \u00b5f \u00b7 2\u00b5f (t+1+4\u03baf ) )  = 2LD\u03c8(x \u2217, x1)\n(1 + 2\u03baf )\u0393T \u2212 2\u03baf +\n2(M2 + \u03c32)\n\u00b5f\n[ 1\n(1 + 2\u03baf )((1 + 2\u03baf )\u0393T \u2212 2\u03baf )\n+ T\u2211 t=2\n4\n(\u0393T /\u0393t\u22121 \u2212 1)(t\u2212 1 + 4\u03baf )(t+ 1 + 4\u03baf )\n]\n= 4(1 + 4\u03baf )LD\u03c8(x\n\u2217, x1)\nT (T + 1 + 8\u03baf )\n+ 2(M2 + \u03c32)\n\u00b5f\n[ 2(1 + 4\u03baf )\n(1 + 2\u03baf )T (T + 1 + 8\u03baf ) + T\u2211 t=2\n4(t+ 4\u03baf )\n(T + 1\u2212 t)(T + t+ 8\u03baf )(t+ 1 + 4\u03baf )\n]\n= 4(1 + 4\u03baf )LD\u03c8(x\n\u2217, x1)\nT (T + 1 + 8\u03baf ) +\n2(M2 + \u03c32)\n\u00b5f\nT\u2211 t=1\n4(t+ 4\u03baf )\n(T + 1\u2212 t)(T + t+ 8\u03baf )(t+ 1 + 4\u03baf )\n\u22644(1 + 4\u03baf )LD\u03c8(x \u2217, x1)\nT (T + 1 + 8\u03baf ) +\n2(M2 + \u03c32)\n\u00b5f\nT\u2211 t=1\n4\n2T + 1 + 8\u03baf\n( 1\nT + 1\u2212 t +\n1\nT + t+ 8\u03baf\n)\n\u22644(1 + 4\u03baf )LD\u03c8(x \u2217, x1)\nT (T + 1 + 8\u03baf ) +\n2(M2 + \u03c32) \u00b5f \u00b7 4(1 + log T + log\n2T+8\u03baf T+8\u03baf )\n2T + 1 + 8\u03baf\n\u22644(1 + 4\u03baf )LD\u03c8(x \u2217, x1)\nT (T + 1 + 8\u03baf ) +\n8(M2 + \u03c32)(1 + log 2T )\n\u00b5f (2T + 1 + 8\u03baf )\n=O\n( L(1 + \u03baf )D\u03c8(x \u2217, x1)\nT (T + \u03baf ) +\n(M2 + \u03c32) log T\n\u00b5f (T + \u03baf )\n) . (30)\nFinally, if T is known, recall that we choose for any t \u2208 [T ]\n\u03b7t =  1 \u00b5f (1+2\u03baf ) t = 1 1 \u00b5f (\u03b7+2\u03baf ) 2 \u2264 t \u2264 \u03c4 2\n\u00b5f (t\u2212\u03c4+2+4\u03baf ) t \u2265 \u03c4 + 1 .\nNote that we have \u03b71 = 1\u00b5f (1+2\u03baf ) and for any t \u2208 [T ]\n\u0393t = t\u220f s=2\n1\n1\u2212 \u00b5f\u03b7s =  ( \u03b7+2\u03baf \u03b7+2\u03baf\u22121 )t\u22121 t \u2264 \u03c4(\n\u03b7+2\u03baf \u03b7+2\u03baf\u22121\n)\u03c4\u22121 (t\u2212\u03c4+1+4\u03baf )(t\u2212\u03c4+2+4\u03baf )\n(1+4\u03baf )(2+4\u03baf ) t \u2265 \u03c4 + 1\n.\nSo we know E [ F (xT+1)\u2212 F (x\u2217) ] \u2264 (1\u2212 \u00b5f\u03b71)D\u03c8(x \u2217, x1)\n\u03b71 + \u0393T\u22121 \u00b5f\n+ 2(M2 + \u03c32)\n[ \u03b721\n\u03b71 + \u0393T\u22121 \u00b5f\n+ T\u2211 t=2\n\u00b5f\u03b7 2 t\n(\u0393T /\u0393t\u22121 \u2212 1)(1\u2212 \u00b5f\u03b7t)\n]\n= 2LD\u03c8(x\n\u2217, x1)\n(1 + 2\u03baf )\u0393T \u2212 2\u03baf +\n2(M2 + \u03c32)\n\u00b5f \u00b7 1 (1 + 2\u03baf )((1 + 2\u03baf )\u0393T \u2212 2\u03baf )\n+ 2\u00b5f (M 2 + \u03c32)  \u03c4\u2211 t=2 \u03b72t (\u0393T /\u0393t\u22121 \u2212 1)(1\u2212 \u00b5f\u03b7t)\ufe38 \ufe37\ufe37 \ufe38\nI\n+ T\u2211 t=\u03c4+1 \u03b72t (\u0393T /\u0393t\u22121 \u2212 1)(1\u2212 \u00b5f\u03b7t)\ufe38 \ufe37\ufe37 \ufe38\nII\n . (31)\nNote that we can bound\n1\n(1 + 2\u03baf )\u0393T \u2212 2\u03baf\n= 1(\n\u03b7+2\u03baf \u03b7+2\u03baf\u22121\n)\u03c4\u22121 (T\u2212\u03c4+1+4\u03baf )(T\u2212\u03c4+2+4\u03baf )\n2(1+4\u03baf ) \u2212 2\u03baf\n(a) \u2264 1( \u03b7+2\u03baf \u03b7+2\u03baf\u22121 )\u03c4\u22121 (1 + 2\u03baf )\u2212 2\u03baf = 1 2\u03baf [( \u03b7+2\u03baf \u03b7+2\u03baf\u22121 )\u03c4\u22121 \u2212 1 ] + ( \u03b7+2\u03baf \u03b7+2\u03baf\u22121 )\u03c4\u22121 (b)\n\u2264 ( 1\u2212 1\n\u03b7 + 2\u03baf\n)\u03c4\u22121 \u2264 exp ( \u2212 \u03c4 \u2212 1 \u03b7 + 2\u03baf ) = exp ( \u2212\u03c4 \u03b7 + 2\u03baf +\n1\n\u03b7 + 2\u03baf ) (c)\n\u2264 exp ( \u2212 T 2(\u03b7 + 2\u03baf ) + 1 ) , (32)\nwhere (a) holds due to T \u2212 \u03c4 \u2265 0, (b) is by \u03baf \u2265 0 and (\n\u03b7+2\u03baf \u03b7+2\u03baf\u22121 )\u03c4\u22121 \u2265 1, (c) is from \u03c4 \u2265 T2 ,\n\u03b7 + \u03baf > 1 and \u03baf \u2265 0. We can also bound\n1\n(1 + 2\u03baf )((1 + 2\u03baf )\u0393T \u2212 2\u03baf )\n= 1\n(1 + 2\u03baf ) [( \u03b7+2\u03baf \u03b7+2\u03baf\u22121 )\u03c4\u22121 (T\u2212\u03c4+1+4\u03baf )(T\u2212\u03c4+2+4\u03baf ) 2(1+4\u03baf ) \u2212 2\u03baf ] \u2264 1\n(1 + 2\u03baf ) [ (T\u2212\u03c4+1+4\u03baf )(T\u2212\u03c4+2+4\u03baf )\n2(1+4\u03baf ) \u2212 2\u03baf ] = 2(1 + 4\u03baf )\n(1 + 2\u03baf )(T \u2212 \u03c4 + 1)(T \u2212 \u03c4 + 2 + 8\u03baf ) (d) \u2264 2(1 + 4\u03baf ) (1 + 2\u03baf )(T \u2212 T+12 + 1)(T \u2212 T+1 2 + 2 + 8\u03baf )\n= 8(1 + 4\u03baf )\n(1 + 2\u03baf )(T + 1)(T + 3 + 16\u03baf )\n(e) \u2264 8 T + 3 + 16\u03baf , (33)\nwhere (d) is by \u03c4 \u2264 T+12 and (e) is by T \u2265 1. Besides, there is\nI = 1\n\u00b52f (\u03b7 + 2\u03baf )(\u03b7 + 2\u03baf \u2212 1) \u03c4\u2211 t=2 1( \u03b7+2\u03baf \u03b7+2\u03baf\u22121 )\u03c4\u2212t+1 (T\u2212\u03c4+1+4\u03baf )(T\u2212\u03c4+2+4\u03baf ) (1+4\u03baf )(2+4\u03baf ) \u2212 1\n(f) \u2264 1 \u00b52f (\u03b7 + 2\u03baf )(\u03b7 + 2\u03baf \u2212 1) \u03b7+2\u03baf \u03b7+2\u03baf\u22121 \u03c4\u2211 t=2 1 (T\u2212\u03c4+1+4\u03baf )(T\u2212\u03c4+2+4\u03baf ) (1+4\u03baf )(2+4\u03baf ) \u2212 1\n= 1\n\u00b52f (\u03b7 + 2\u03baf ) 2 \u03c4\u2211 t=2\n(1 + 4\u03baf )(2 + 4\u03baf )\n(T \u2212 \u03c4)(T \u2212 \u03c4 + 3 + 8\u03baf ) =\n(1 + 4\u03baf )(2 + 4\u03baf )\n\u00b52f (\u03b7 + 2\u03baf ) 2\n\u00b7 \u03c4 \u2212 1 (T \u2212 \u03c4)(T \u2212 \u03c4 + 3 + 8\u03baf )\n(g) \u2264 (1 + 4\u03baf )(2 + 4\u03baf ) \u00b52f (\u03b7 + 2\u03baf ) 2 \u00b7\nT+1 2 \u2212 1\n(T \u2212 T+12 )(T \u2212 T+1 2 + 3 + 8\u03baf )\n= (1 + 4\u03baf )(2 + 4\u03baf )\n\u00b52f (\u03b7 + 2\u03baf ) 2\n\u00b7 2 T + 5 + 16\u03baf\n(h) \u2264 32 \u00b52f (T + 5 + 16\u03baf ) , (34)\nwhere (f) is by \u03c4\u2212t \u2265 0 (w.l.o.g., we can assume \u03c4 \u2265 2, otherwise, there is I= 0 \u2264 8 \u00b52f (T+5+16\u03baf ) ) and \u03b7+2\u03baf\u03b7+2\u03baf\u22121 \u2265 1, (g) is due to \u03c4 \u2264 T+1 2 and (h) is by \u03b7 + \u03baf > 1. We also have\nII = 4\n\u00b52f T\u2211 t=\u03c4+1 1[ (T\u2212\u03c4+1+4\u03baf )(T\u2212\u03c4+2+4\u03baf ) (t\u2212\u03c4+4\u03baf )(t\u2212\u03c4+1+4\u03baf ) \u2212 1 ] (t\u2212 \u03c4 + 2 + 4\u03baf )(t\u2212 \u03c4 + 4\u03baf )\n= 4\n\u00b52f T\u2212\u03c4\u2211 t=1 1[ (T\u2212\u03c4+1+4\u03baf )(T\u2212\u03c4+2+4\u03baf ) (t+4\u03baf )(t+1+4\u03baf ) \u2212 1 ] (t+ 2 + 4\u03baf )(t+ 4\u03baf )\n= 4\n\u00b52f T\u2212\u03c4\u2211 t=1 t+ 1 + 4\u03baf [(T \u2212 \u03c4 + 1 + 4\u03baf )(T \u2212 \u03c4 + 2 + 4\u03baf )\u2212 (t+ 4\u03baf )(t+ 1 + 4\u03baf )] (t+ 2 + 4\u03baf )\n\u2264 4 \u00b52f T\u2212\u03c4\u2211 t=1\n1\n(T \u2212 \u03c4 + 1 + 4\u03baf )(T \u2212 \u03c4 + 2 + 4\u03baf )\u2212 (t+ 4\u03baf )(t+ 1 + 4\u03baf )\n= 4\n\u00b52f T\u2212\u03c4\u2211 t=1\n1\n(T \u2212 \u03c4 + 1\u2212 t)(T \u2212 \u03c4 + 2 + 8\u03baf + t)\n= 4\n\u00b52f T\u2212\u03c4\u2211 t=1\n1\n2T \u2212 2\u03c4 + 3 + 8\u03baf\n( 1\nT \u2212 \u03c4 + 1\u2212 t +\n1\nT \u2212 \u03c4 + 2 + 8\u03baf + t\n)\n\u2264 4(1 + log(T \u2212 \u03c4) + log 2T\u22122\u03c4+2+8\u03bafT\u2212\u03c4+2+8\u03baf )\n\u00b52f (2T \u2212 2\u03c4 + 3 + 8\u03baf ) \u2264 4(1 + log T ) \u00b52f (T + 2 + 8\u03baf ) , (35)\nwhere we use T2 \u2264 \u03c4 \u2264 T+1 2 in the last inequality. Plugging (32), (33), (34) and (35) into (31), we have E [ F (xT+1)\u2212 F (x\u2217)\n] \u22642LD\u03c8(x\u2217, x1) exp ( \u2212 T 2(\u03b7 + 2\u03baf ) + 1 ) + 2(M2 + \u03c32) \u00b5f \u00b7 8 T + 3 + 16\u03baf\n+ 2\u00b5f (M 2 + \u03c32)\n[ 32\n\u00b52f (T + 5 + 16\u03baf ) +\n4(1 + log T )\n\u00b52f (T + 2 + 8\u03baf )\n]\n=O  LD\u03c8(x\u2217, x1) exp ( T\n2\u03b7+4\u03baf\n) + (M2 + \u03c32) log T \u00b5f (T + \u03baf )  . (36) Theorem D.2. Under Assumptions 1-4 and 5B with \u00b5f > 0 and \u00b5h = 0, let \u03baf := L\u00b5f \u2265 0 and \u03b4 \u2208 (0, 1): If T is unknown, by taking either \u03b7t = 1\u00b5f (t+2\u03baf ) ,\u2200t \u2208 [T ] or \u03b7t = 2 \u00b5f (t+1+4\u03baf )\n,\u2200t \u2208 [T ], then with probability at least 1\u2212 \u03b4, there is\nF (xT+1)\u2212F (x\u2217) \u2264 O ( \u00b5f (1+\u03baf )D\u03c8(x \u2217,x1) T + (M2+\u03c32 log 1\u03b4 ) log T \u00b5f (T+\u03baf ) ) \u03b7t = 1 \u00b5f (t+2\u03baf ) ,\u2200t \u2208 [T ] O ( \u00b5f (1+\u03baf ) 2D\u03c8(x \u2217,x1)\nT (T+\u03baf ) +\n(M2+\u03c32 log 1\u03b4 ) log T\n\u00b5f (T+\u03baf )\n) \u03b7t =\n2 \u00b5f (t+1+4\u03baf )\n,\u2200t \u2208 [T ] .\nIf T is known, by taking \u03b7t =  1 \u00b5f (1+2\u03baf ) t = 1 1 \u00b5f (\u03b7+2\u03baf ) 2 \u2264 t \u2264 \u03c4 2\n\u00b5f (t\u2212\u03c4+2+4\u03baf ) t \u2265 \u03c4 + 1 ,\u2200t \u2208 [T ] where \u03b7 \u2265 0 can be any\nnumber satisfying \u03b7 + \u03baf > 1 and \u03c4 := \u2308 T 2 \u2309 , then with probability at least 1\u2212 \u03b4, there is\nF (xT+1)\u2212F (x\u2217) \u2264 O (1 \u2228 1 \u03b7 + 2\u03baf \u2212 1 )\u00b5f (1 + \u03baf )D\u03c8(x\u2217, x1) exp ( T\n2\u03b7+4\u03baf\n) + (M2 + \u03c32 log 1\u03b4 ) log T \u00b5f (T + \u03baf )\n .\nProof. When \u00b5f > 0 and \u00b5h = 0, suppose the condition of \u03b7t \u2264 12L\u2228\u00b5f ,\u2200t \u2208 [T ] in Lemma 4.3 holds, we will have with probability at least 1\u2212 \u03b4\nF (xT+1)\u2212 F (x\u2217) \u22642 ( 1 + max\n2\u2264t\u2264T\n1\n1\u2212 \u00b5f\u03b7t ) \u00d7 [ D\u03c8(x\n\u2217, x1)\u2211T t=1 \u03b3t +\n( M2 + \u03c32 ( 1 + 2 log 2\n\u03b4 )) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s ] . (37)\nNow observing that for any t \u2208 [T ]\n\u03b3t := \u03b7t t\u220f s=2 1 + \u00b5h\u03b7s\u22121 1\u2212 \u00b5f\u03b7s = \u03b7t t\u220f s=2\n1\n1\u2212 \u00b5f\u03b7s = \u03b7t\u0393t =\n{ \u0393t\u2212\u0393t\u22121\n\u00b5f t \u2265 2\n\u03b71 t = 1 ,\nwhere \u0393t := \u220ft s=2 1 1\u2212\u00b5f\u03b7s ,\u2200t \u2208 [T ]. Hence, (37) can be rewritten as\nF (xT+1)\u2212 F (x\u2217) \u22642 ( 1 + max\n2\u2264t\u2264T\n1\n1\u2212 \u00b5f\u03b7t ) \u00d7 ( D\u03c8(x \u2217, x1)\n\u03b71 + \u0393T\u22121 \u00b5f\n+ ( M2 + \u03c32 ( 1 + 2 log 2\n\u03b4 )) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s ) . (38)\nNow let us check the condition of \u03b7t \u2264 12L\u2228\u00b5f ,\u2200t \u2208 [T ] for our three choices respectively:\n\u03b7t = 1 \u00b5f (t+ 2\u03baf ) \u2264 1 \u00b5f + 2L \u2264 1 2L \u2228 \u00b5f ,\u2200t \u2208 [T ] ;\n\u03b7t = 2 \u00b5f (t+ 1 + 4\u03baf ) \u2264 1 \u00b5f + 2L \u2264 1 2L \u2228 \u00b5f ,\u2200t \u2208 [T ] ;\n\u03b7t =  1 \u00b5f (1+2\u03baf ) = 1\u00b5f+2L \u2264 1 2L\u2228\u00b5f t = 1 1 \u00b5f (\u03b7+2\u03baf ) \u2264 1\u00b5f (2\u03baf\u2228(\u03b7+\u03baf )) \u2264 1 2L\u2228\u00b5f 2 \u2264 t \u2264 \u03c4 2\n\u00b5f (t\u2212\u03c4+2+4\u03baf ) \u2264 1 \u00b5f+2L \u2264 12L\u2228\u00b5f t \u2265 \u03c4 + 1\n.\nTherefore, (38) holds for all cases.\nFirst, we consider \u03b7t = 1\u00b5f (t+2\u03baf ) ,\u2200t \u2208 [T ]. We can find 1+max2\u2264t\u2264T 1 1\u2212\u00b5f\u03b7t = 1+ 1 1\u2212\u00b5f\u03b72 \u2264 3, \u03b71 =\n1 \u00b5f (1+2\u03baf ) and\n\u0393t = t\u220f s=2\n1\n1\u2212 \u00b5f\u03b7s = t\u220f s=2 s+ 2\u03baf s\u2212 1 + 2\u03baf = t+ 2\u03baf 1 + 2\u03baf ,\u2200t \u2208 [T ] .\nHence, using (38), we have\nF (xT+1)\u2212 F (x\u2217) \u2264 6\n( D\u03c8(x \u2217, x1)\n\u03b71 + \u0393T\u22121 \u00b5f\n+ ( M2 + \u03c32 ( 1 + 2 log 2\n\u03b4 )) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s ) .\nFollowing similar steps in the proof of (29), we can get F (xT+1)\u2212 F (x\u2217) \u2264 O ( \u00b5f (1 + \u03baf )D\u03c8(x \u2217, x1)\nT +\n(M2 + \u03c32 log 1\u03b4 ) log T\n\u00b5f (T + \u03baf )\n) .\nNext, for the case of \u03b7t = 2\u00b5f (t+1+4\u03baf ) ,\u2200t \u2208 [T ], there are 1+max2\u2264t\u2264T 1 1\u2212\u00b5f\u03b7t = 1+ 1 1\u2212\u00b5f\u03b72 \u2264 4, \u03b71 = 1\u00b5f (1+2\u03baf ) and\n\u0393t = t\u220f s=2\n1\n1\u2212 \u00b5f\u03b7s = t\u220f s=2 s+ 1 + 4\u03baf s\u2212 1 + 4\u03baf = (t+ 4\u03baf )(t+ 1 + 4\u03baf ) 2(1 + 4\u03baf )(1 + 2\u03baf ) ,\u2200t \u2208 [T ] .\nThus, we have\nF (xT+1)\u2212 F (x\u2217) \u2264 8\n( D\u03c8(x \u2217, x1)\n\u03b71 + \u0393T\u22121 \u00b5f\n+ ( M2 + \u03c32 ( 1 + 2 log 2\n\u03b4 )) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s ) .\nFollowing similar steps in the proof of (30), we can get F (xT+1)\u2212 F (x\u2217) \u2264 O ( \u00b5f (1 + \u03baf ) 2D\u03c8(x \u2217, x1)\nT (T + \u03baf ) +\n(M2 + \u03c32 log 1\u03b4 ) log T\n\u00b5f (T + \u03baf )\n) .\nFinally, if T is known, we recall the current choice is for any t \u2208 [T ]\n\u03b7t =  1 \u00b5f (1+2\u03baf ) t = 1 1 \u00b5f (\u03b7+2\u03baf ) 2 \u2264 t \u2264 \u03c4 2\n\u00b5f (t\u2212\u03c4+2+4\u03baf ) t \u2265 \u03c4 + 1 ,\nwhere \u03b7 > 1 and \u03c4 = \u2308 T 2 \u2309 . Note that we have\n1 + max 2\u2264t\u2264T\n1\n1\u2212 \u00b5f\u03b7t = 1 +\n1\n1\u2212 \u00b5f (\u03b72 \u2228 \u03b7\u03c4+1) = 2 +\n1\n\u03b7 \u2227 1.5 + 2\u03baf \u2212 1\n= 2 + 1 \u03b7 + 2\u03baf \u2212 1 \u2228 1 0.5 + 2\u03baf\n\u2264 4 + 1 \u03b7 + 2\u03baf \u2212 1 ,\n\u03b71 = 1 \u00b5f (1+2\u03baf ) and for any t \u2208 [T ]\n\u0393t = t\u220f s=2\n1\n1\u2212 \u00b5f\u03b7s =  ( \u03b7+2\u03baf \u03b7+2\u03baf\u22121 )t\u22121 t \u2264 \u03c4(\n\u03b7+2\u03baf \u03b7+2\u03baf\u22121\n)\u03c4\u22121 (t\u2212\u03c4+1+4\u03baf )(t\u2212\u03c4+2+4\u03baf )\n(1+4\u03baf )(2+4\u03baf ) t \u2265 \u03c4 + 1\n.\nThus, we have F (xT+1)\u2212 F (x\u2217)\n\u2264 ( 8 +\n2\n\u03b7 + 2\u03baf \u2212 1\n)( D\u03c8(x \u2217, x1)\n\u03b71 + \u0393T\u22121 \u00b5f\n+ ( M2 + \u03c32 ( 1 + 2 log 2\n\u03b4 )) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s ) .\nFollowing similar steps in the proof of (36), we can get F (xT+1)\u2212 F (x\u2217)\n\u2264O (1 \u2228 1 \u03b7 + 2\u03baf \u2212 1 )\u00b5f (1 + \u03baf )D\u03c8(x\u2217, x1) exp ( T\n2\u03b7+4\u03baf\n) + (M2 + \u03c32 log 1\u03b4 ) log T \u00b5f (T + \u03baf )\n .\nD.2 THE CASE OF \u00b5h > 0\nTheorem D.3. Under Assumptions 1-4 and 5A with \u00b5f = 0 and \u00b5h > 0, let \u03bah := L\u00b5h \u2265 0:\nIf T is unknown, by taking \u03b7t = 2\u00b5h(t+4\u03bah) ,\u2200t \u2208 [T ], there is\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 O ( \u00b5h(1 + \u03bah) 2D\u03c8(x \u2217, x1)\nT (T + \u03bah) +\n(M2 + \u03c32) log T\n\u00b5h(T + \u03bah)\n) .\nIf T is known, by taking \u03b7t =\n{ 1\n\u00b5h(\u03b7+2\u03bah) t \u2264 \u03c4 2 \u00b5h(t\u2212\u03c4+4\u03bah) t \u2265 \u03c4 + 1 ,\u2200t \u2208 [T ] where \u03b7 \u2265 0 can be any number\nsatisfying \u03b7 + \u03bah > 0 and \u03c4 := \u2308 T 2 \u2309 , there is\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 O  \u00b5hD\u03c8(x\u2217, x1) exp ( T\n2(1+\u03b7+2\u03bah)\n) \u2212 1 +\n( 1 \u2228 1\n\u03b7 + 2\u03bah\n) (M2 + \u03c32) log T\n\u00b5h(T + \u03bah)\n .\nProof. When \u00b5f = 0 and \u00b5h > 0, suppose the condition of \u03b7t \u2264 12L\u2228\u00b5f = 1 2L ,\u2200t \u2208 [T ] in Lemma 4.2 holds, we will have\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 (1\u2212 \u00b5f\u03b71)D\u03c8(x\n\u2217, x1)\u2211T t=1 \u03b3t + 2(M2 + \u03c32) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s\n= D\u03c8(x \u2217, x1)\u2211T t=1 \u03b3t + 2(M2 + \u03c32) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s . (39)\nObserving that\n\u03b3t := \u03b7t t\u220f s=2 1 + \u00b5h\u03b7s\u22121 1\u2212 \u00b5f\u03b7s = \u03b7t t\u220f s=2 (1 + \u00b5h\u03b7s\u22121) = \u03b7t\u0393t\u22121 = \u0393t \u2212 \u0393t\u22121 \u00b5h ,\u2200t \u2208 [T ] ,\nwhere \u0393t := \u220ft s=1(1 + \u00b5h\u03b7s),\u2200t \u2208 {0} \u222a [T ]. So (39) can be rewritten as\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264 \u00b5hD\u03c8(x \u2217, x1)\n\u0393T \u2212 1 + 2\u00b5h(M\n2 + \u03c32) T\u2211 t=1 \u03b72t \u0393T /\u0393t\u22121 \u2212 1 . (40)\nWe can check that\n\u03b7t = 2 \u00b5h(t+ 4\u03bah) \u2264 1 2\u03bah\u00b5h = 1 2L ,\u2200t \u2208 [T ] ;\n\u03b7t =\n{ 1\n\u00b5h(\u03b7+2\u03bah) \u2264 12\u03bah\u00b5h = 1 2L t \u2264 \u03c4 2 \u00b5h(t\u2212\u03c4+4\u03bah) \u2264 1 2\u03bah\u00b5h = 12L t \u2265 \u03c4 + 1 .\nTherefore, (40) is true for all cases.\nIf \u03b7t = 2\u00b5h(t+4\u03bah) ,\u2200t \u2208 [T ], we have\n\u0393t = t\u220f s=1 (1 + \u00b5h\u03b7s) = (t+ 1 + 4\u03bah)(t+ 2 + 4\u03bah) (1 + 4\u03bah)(2 + 4\u03bah) ,\u2200t \u2208 {0} \u222a [T ] .\nHence, by (40), E [ F (xT+1)\u2212 F (x\u2217) ] \u2264 \u00b5hD\u03c8(x\n\u2217, x1) (T+1+4\u03bah)(T+2+4\u03bah)\n(1+4\u03bah)(2+4\u03bah) \u2212 1\n+ 8(M2 + \u03c32)\n\u00b5h\nT\u2211 t=1\n1 (t+4\u03bah)2\n(T+1+4\u03bah)(T+2+4\u03bah) (t+4\u03bah)(t+1+4\u03bah) \u2212 1\n= (1 + 4\u03bah)(2 + 4\u03bah)\u00b5hD\u03c8(x\n\u2217, x1)\nT (T + 3 + 8\u03bah) +\n8(M2 + \u03c32)\n\u00b5h\nT\u2211 t=1 t+ 1 + 4\u03bah t+ 4\u03bah \u00b7 1 (T + 1\u2212 t)(T + 2 + 8\u03bah + t)\n\u2264 (1 + 4\u03bah)(2 + 4\u03bah)\u00b5hD\u03c8(x \u2217, x1)\nT (T + 3 + 8\u03bah) +\n16(M2 + \u03c32)\n\u00b5h\nT\u2211 t=1\n1\n2T + 3 + 8\u03bah\n( 1\nT + 1\u2212 t +\n1\nT + 2 + 8\u03bah + t\n)\n\u2264 (1 + 4\u03bah)(2 + 4\u03bah)\u00b5hD\u03c8(x \u2217, x1)\nT (T + 3 + 8\u03bah) +\n16(M2 + \u03c32) \u00b5h \u00b7 1 + log T + log 2T+2+8\u03bahT+2+8\u03bah 2T + 3 + 8\u03bah\n\u2264 (1 + 4\u03bah)(2 + 4\u03bah)\u00b5hD\u03c8(x \u2217, x1)\nT (T + 3 + 8\u03bah) +\n16(M2 + \u03c32)(1 + log 2T )\n\u00b5h(2T + 3 + 8\u03bah)\n=O\n( \u00b5h(1 + \u03bah) 2D\u03c8(x \u2217, x1)\nT (T + \u03bah) +\n(M2 + \u03c32) log T\n\u00b5h(T + \u03bah)\n) . (41)\nIf \u03b7t =\n{ 1\n\u00b5h(\u03b7+2\u03bah) t \u2264 \u03c4 2 \u00b5h(t\u2212\u03c4+4\u03bah) t \u2265 \u03c4 + 1 ,\u2200t \u2208 [T ], we know for any t \u2208 {0} \u222a [T ]\n\u0393t = t\u220f s=1 (1 + \u00b5h\u03b7s) =  ( 1 + 1\u03b7+2\u03bah )t t \u2264 \u03c4(\n1 + 1\u03b7+2\u03bah\n)\u03c4 (t\u2212\u03c4+1+4\u03bah)(t\u2212\u03c4+2+4\u03bah)\n(1+4\u03bah)(2+4\u03bah) t \u2265 \u03c4 + 1\n.\nSo we can obtain\nE [ F (xT+1)\u2212 F (x\u2217) ] \u2264\u00b5hD\u03c8(x \u2217, x1)\n\u0393T \u2212 1 + 2\u00b5h(M\n2 + \u03c32) T\u2211 t=1 \u03b72t \u0393T /\u0393t\u22121 \u2212 1\n= \u00b5hD\u03c8(x \u2217, x1)( 1 + 1\u03b7+2\u03bah )\u03c4 (T\u2212\u03c4+1+4\u03bah)(T\u2212\u03c4+2+4\u03bah) (1+4\u03bah)(2+4\u03bah) \u2212 1 + 2\u00b5h(M 2 + \u03c32) T\u2211 t=1 \u03b72t \u0393T /\u0393t\u22121 \u2212 1\n(a) \u2264 \u00b5hD\u03c8(x \u2217, x1)(\n1 + 1\u03b7+2\u03bah\n)T/2 \u2212 1 + 2\u00b5h(M 2 + \u03c32) T\u2211 t=1 \u03b72t \u0393T /\u0393t\u22121 \u2212 1\n(b) \u2264 \u00b5hD\u03c8(x \u2217, x1) exp (\nT 2(1+\u03b7+2\u03bah)\n) \u2212 1 + 2\u00b5h(M 2 + \u03c32) T\u2211 t=1 \u03b72t \u0393T /\u0393t\u22121 \u2212 1\n= \u00b5hD\u03c8(x\n\u2217, x1) exp (\nT 2(1+\u03b7+2\u03bah)\n) \u2212 1 + 2\u00b5h(M 2 + \u03c32)  \u03c4\u2211 t=1 \u03b72t \u0393T /\u0393t\u22121 \u2212 1\ufe38 \ufe37\ufe37 \ufe38\nI\n+ T\u2211 t=\u03c4+1 \u03b72t \u0393T /\u0393t\u22121 \u2212 1\ufe38 \ufe37\ufe37 \ufe38\nII\n , (42)\nwhere (a) is by T \u2212 \u03c4 \u2265 0 and \u03c4 \u2265 T2 , (b) is due to\n( 1 +\n1\n\u03b7 + 2\u03bah\n)T/2 = exp ( T\n2 log\n( 1 +\n1\n\u03b7 + 2\u03bah\n)) \u2265 exp ( T\n2(1 + \u03b7 + 2\u03bah)\n) .\nNow we bound\nI = 1\n\u00b52h(\u03b7 + 2\u03bah) 2 \u03c4\u2211 t=1 1( 1 + 1\u03b7+2\u03bah )\u03c4\u2212t+1 (T\u2212\u03c4+1+4\u03bah)(T\u2212\u03c4+2+4\u03bah) (1+4\u03bah)(2+4\u03bah) \u2212 1\n(c) \u2264 1 \u00b52h(\u03b7 + 2\u03bah) 2 ( 1 + 1\u03b7+2\u03bah ) \u03c4\u2211 t=1 1 (T\u2212\u03c4+1+4\u03bah)(T\u2212\u03c4+2+4\u03bah) (1+4\u03bah)(2+4\u03bah) \u2212 1\n= 1\n\u00b52h(\u03b7 + 2\u03bah)(\u03b7 + 1 + 2\u03bah) \u03c4\u2211 t=1\n(1 + 4\u03bah)(2 + 4\u03bah)\n(T \u2212 \u03c4)(T \u2212 \u03c4 + 8\u03bah + 3)\n= (1 + 4\u03bah)(2 + 4\u03bah) \u00b52h(\u03b7 + 2\u03bah)(\u03b7 + 1 + 2\u03bah) \u00b7 \u03c4 (T \u2212 \u03c4)(T \u2212 \u03c4 + 8\u03bah + 3)\n(d) \u2264 2(1 + 4\u03bah) \u00b52h(\u03b7 + 2\u03bah) \u00b7 2(T + 1) (T \u2212 1)(T + 5 + 16\u03bah)\n(e) \u2264 2 ( 2 + 1\u03b7+2\u03bah ) \u00b52h \u00b7 6 T + 5 + 16\u03bah) = 12 ( 2 + 1\u03b7+2\u03bah ) \u00b52h(T + 5 + 16\u03bah) , (43)\nwhere (c) is by \u03c4 \u2212 t \u2265 0 and 1 + 1\u03b7+2\u03bah \u2265 1. We use \u03b7 \u2265 0, \u03c4 \u2264 T+1 2 in (d) and T \u2265 2 in (e). Next, there is\nII = 4\n\u00b52h T\u2211 t=\u03c4+1\n1 (t\u2212 \u03c4 + 4\u03bah)2 (\n(T\u2212\u03c4+1+4\u03bah)(T\u2212\u03c4+2+4\u03bah) (t\u2212\u03c4+4\u03bah)(t\u2212\u03c4+1+4\u03bah) \u2212 1 ) = 4\n\u00b52h T\u2212\u03c4\u2211 t=1\n1 (t+ 4\u03bah)2 (\n(T\u2212\u03c4+1+4\u03bah)(T\u2212\u03c4+2+4\u03bah) (t+4\u03bah)(t+1+4\u03bah)\n\u2212 1 )\n= 4\n\u00b52h T\u2212\u03c4\u2211 t=1 t+ 1 + 4\u03bah (t+ 4\u03bah) ((T \u2212 \u03c4 + 1 + 4\u03bah)(T \u2212 \u03c4 + 2 + 4\u03bah)\u2212 (t+ 4\u03bah)(t+ 1 + 4\u03bah))\n\u2264 8 \u00b52h T\u2212\u03c4\u2211 t=1\n1\n(T \u2212 \u03c4 + 1 + 4\u03bah)(T \u2212 \u03c4 + 2 + 4\u03bah)\u2212 (t+ 4\u03bah)(t+ 1 + 4\u03bah)\n= 8\n\u00b52h T\u2212\u03c4\u2211 t=1\n1\n(T \u2212 \u03c4 + 1\u2212 t)(T \u2212 \u03c4 + 2 + 8\u03bah + t)\n= 8\n\u00b52h T\u2212\u03c4\u2211 t=1\n1\n2T \u2212 2\u03c4 + 3 + 8\u03bah\n( 1\nT \u2212 \u03c4 + 1\u2212 t +\n1\nT \u2212 \u03c4 + 2 + 8\u03bah + t ) \u2264 8 \u00b52h(2T \u2212 2\u03c4 + 3 + 8\u03bah) ( 1 + log(T \u2212 \u03c4) + log 2T \u2212 2\u03c4 + 2 + 8\u03bah T \u2212 \u03c4 + 2 + 8\u03bah\n) \u2264 8(1 + log T ) \u00b52h(T + 2 + 8\u03bah) , (44)\nwhere we use T2 \u2264 \u03c4 \u2264 T+1 2 in the last inequality.\nPlugging (43) and (44) into (42) to get E [ F (xT+1)\u2212 F (x\u2217) ] \u2264 \u00b5hD\u03c8(x \u2217, x1)\nexp (\nT 2(1+\u03b7+2\u03bah)\n) \u2212 1 + 2(M2 + \u03c32) \u00b5h\n12 ( 2 + 1\u03b7+2\u03bah ) T + 5 + 16\u03bah + 8(1 + log T ) T + 2 + 8\u03bah  =O\n \u00b5hD\u03c8(x\u2217, x1) exp ( T\n2(1+\u03b7+2\u03bah)\n) \u2212 1 +\n( 1 \u2228 1\n\u03b7 + 2\u03bah\n) (M2 + \u03c32) log T\n\u00b5h(T + \u03bah)\n . (45)\nTheorem D.4. Under Assumptions 1-4 and 5B with \u00b5f = 0 and \u00b5h > 0, let \u03bah := L\u00b5h \u2265 0 and \u03b4 \u2208 (0, 1): If T is unknown, by taking \u03b7t = 2\u00b5h(t+4\u03bah) ,\u2200t \u2208 [T ], then with probability at least 1\u2212 \u03b4, there is\nF (xT+1)\u2212 F (x\u2217) \u2264 O ( \u00b5h(1 + \u03bah) 2D\u03c8(x \u2217, x1)\nT (T + \u03bah) +\n(M2 + \u03c32 log 1\u03b4 ) log T\n\u00b5h(T + \u03bah)\n) .\nIf T is known, by taking \u03b7t =\n{ 1\n\u00b5h(\u03b7+2\u03bah) t \u2264 \u03c4 2 \u00b5h(t\u2212\u03c4+4\u03bah) t \u2265 \u03c4 + 1 ,\u2200t \u2208 [T ] where \u03b7 \u2265 0 can be any number\nsatisfying \u03b7 + \u03bah > 0 and \u03c4 := \u2308 T 2 \u2309 , then with probability at least 1\u2212 \u03b4, there is\nF (xT+1)\u2212 F (x\u2217) \u2264 O  \u00b5hD\u03c8(x\u2217, x1) exp ( T\n2(1+\u03b7+2\u03bah)\n) \u2212 1 +\n( 1 \u2228 1\n\u03b7 + 2\u03bah\n) (M2 + \u03c32 log 1\u03b4 ) log T\n\u00b5h(T + \u03bah)\n .\nProof. When \u00b5f = 0 and \u00b5h > 0, suppose the condition of \u03b7t \u2264 12L\u2228\u00b5f = 1 2L ,\u2200t \u2208 [T ] in Lemma 4.3 holds, we will have with probability at least 1\u2212 \u03b4\nF (xT+1)\u2212 F (x\u2217) \u22642 ( 1 + max\n2\u2264t\u2264T\n1\n1\u2212 \u00b5f\u03b7t\n)[ D\u03c8(x\n\u2217, x1)\u2211T t=1 \u03b3t +\n( M2 + \u03c32 ( 1 + 2 log 2\n\u03b4 )) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s ]\n= 4D\u03c8(x \u2217, x1)\u2211T t=1 \u03b3t + 4\n( M2 + \u03c32 ( 1 + 2 log 2\n\u03b4 )) T\u2211 t=1 \u03b3t\u03b7t\u2211T s=t \u03b3s . (46)\nObserving that\n\u03b3t := \u03b7t t\u220f s=2 1 + \u00b5h\u03b7s\u22121 1\u2212 \u00b5f\u03b7s = \u03b7t t\u220f s=2 (1 + \u00b5h\u03b7s\u22121) = \u03b7t\u0393t\u22121 = \u0393t \u2212 \u0393t\u22121 \u00b5h ,\u2200t \u2208 [T ] ,\nwhere \u0393t := \u220ft s=1(1 + \u00b5h\u03b7s),\u2200t \u2208 {0} \u222a [T ]. So (46) can be rewritten as\nF (xT+1)\u2212F (x\u2217) \u2264 4\u00b5hD\u03c8(x \u2217, x1)\n\u0393T \u2212 1 +4\u00b5h\n( M2 + \u03c32 ( 1 + 2 log 2\n\u03b4 )) T\u2211 t=1 \u03b72t \u0393T /\u0393t\u22121 \u2212 1 . (47)\nWe can check that\n\u03b7t = 2 \u00b5h(t+ 4\u03bah) \u2264 1 2\u03bah\u00b5h = 1 2L ,\u2200t \u2208 [T ] ;\n\u03b7t =\n{ 1\n\u00b5h(\u03b7+2\u03bah) \u2264 12\u03bah\u00b5h = 1 2L t \u2264 \u03c4 2 \u00b5h(t\u2212\u03c4+4\u03bah) \u2264 1 2\u03bah\u00b5h = 12L t \u2265 \u03c4 + 1 .\nTherefore, (47) is true for all cases.\nIf \u03b7t = 2\u00b5h(t+4\u03bah) ,\u2200t \u2208 [T ], following the similar steps in the proof of (41), we can finally get\nF (xT+1)\u2212 F (x\u2217) \u2264 O ( \u00b5h(1 + \u03bah) 2D\u03c8(x \u2217, x1)\nT (T + \u03bah) +\n(M2 + \u03c32 log 1\u03b4 ) log T\n\u00b5h(T + \u03bah)\n) .\nIf \u03b7t =\n{ 1\n\u00b5h(\u03b7+2\u03bah) t \u2264 \u03c4 2 \u00b5h(t\u2212\u03c4+4\u03bah) t \u2265 \u03c4 + 1 ,\u2200t \u2208 [T ], following the similar steps in the proof of (45), we\ncan finally get\nF (xT+1)\u2212 F (x\u2217) \u2264 O  \u00b5hD\u03c8(x\u2217, x1) exp ( T\n2(1+\u03b7+2\u03bah)\n) \u2212 1 +\n( 1 \u2228 1\n\u03b7 + 2\u03bah\n) (M2 + \u03c32 log 1\u03b4 ) log T\n\u00b5h(T + \u03bah)\n ."
        }
    ],
    "year": 2024
}