{
    "abstractText": "Accurate blind docking has the potential to lead to new biological breakthroughs, but for this promise to be realized, docking methods must generalize well across the proteome. Existing benchmarks, however, fail to rigorously assess generalizability. Therefore, we develop DOCKGEN, a new benchmark based on the ligandbinding domains of proteins, and we show that existing machine learning-based docking models have very weak generalization abilities. We carefully analyze the scaling laws of ML-based docking and show that, by scaling data and model size, as well as integrating synthetic data strategies, we are able to significantly increase the generalization capacity and set new state-of-the-art performance across benchmarks. Further, we propose CONFIDENCE BOOTSTRAPPING, a new training paradigm that solely relies on the interaction between diffusion and confidence models and exploits the multi-resolution generation process of diffusion models. We demonstrate that CONFIDENCE BOOTSTRAPPING significantly improves the ability of ML-based docking methods to dock to unseen protein classes, edging closer to accurate and generalizable blind docking methods.",
    "authors": [
        {
            "affiliations": [],
            "name": "DOCKING GENERALIZATION"
        },
        {
            "affiliations": [],
            "name": "Gabriele Corso"
        },
        {
            "affiliations": [],
            "name": "Arthur Deng"
        },
        {
            "affiliations": [],
            "name": "Nicholas Polizzi"
        },
        {
            "affiliations": [],
            "name": "Regina Barzilay"
        },
        {
            "affiliations": [],
            "name": "Tommi Jaakkola"
        }
    ],
    "id": "SP:cf4768b734966206a6439b40ee8f578ddc0f4807",
    "references": [
        {
            "authors": [
                "Tunde Aderinwale",
                "Charles Christoffer",
                "Daisuke Kihara"
            ],
            "title": "Rl-mlzerd: Multimeric protein docking using reinforcement learning",
            "venue": "Frontiers in Molecular Biosciences,",
            "year": 2022
        },
        {
            "authors": [
                "Amr Alhossary",
                "Stephanus Daniel Handoko",
                "Yuguang Mu",
                "Chee-Keong Kwoh"
            ],
            "title": "Fast, accurate, and reliable molecular docking with QuickVina",
            "venue": "2. Bioinformatics,",
            "year": 2015
        },
        {
            "authors": [
                "Mikhail Belkin",
                "Daniel Hsu",
                "Siyuan Ma",
                "Soumik Mandal"
            ],
            "title": "Reconciling modern machinelearning practice and the classical bias\u2013variance trade-off",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 2019
        },
        {
            "authors": [
                "H. Berman",
                "K. Henrick",
                "H. Nakamura"
            ],
            "title": "Announcing the worldwide Protein Data Bank",
            "venue": "Nat Struct Biol,",
            "year": 2003
        },
        {
            "authors": [
                "Martin Buttenschoen",
                "Garrett M Morris",
                "Charlotte M Deane"
            ],
            "title": "Posebusters: Ai-based docking methods fail to generate physically valid poses or generalise to novel sequences",
            "venue": "Chemical Science,",
            "year": 2024
        },
        {
            "authors": [
                "Hua Cheng",
                "R Dustin Schaeffer",
                "Yuxing Liao",
                "Lisa N Kinch",
                "Jimin Pei",
                "Shuoyong Shi",
                "Bong-Hyun Kim",
                "Nick V Grishin"
            ],
            "title": "Ecod: an evolutionary classification of protein domains",
            "venue": "PLoS computational biology,",
            "year": 2014
        },
        {
            "authors": [
                "UniProt Consortium"
            ],
            "title": "Uniprot: a hub for protein information",
            "venue": "Nucleic acids research,",
            "year": 2015
        },
        {
            "authors": [
                "Gabriele Corso"
            ],
            "title": "Modeling molecular structures with intrinsic diffusion models",
            "venue": "arXiv preprint arXiv:2302.12255,",
            "year": 2023
        },
        {
            "authors": [
                "Gabriele Corso",
                "Hannes St\u00e4rk",
                "Bowen Jing",
                "Regina Barzilay",
                "Tommi Jaakkola"
            ],
            "title": "Diffdock: Diffusion steps, twists, and turns for molecular docking",
            "venue": "arXiv preprint arXiv:2210.01776,",
            "year": 2022
        },
        {
            "authors": [
                "Justas Dauparas",
                "Ivan Anishchenko",
                "Nathaniel Bennett",
                "Hua Bai",
                "Robert J Ragotte",
                "Lukas F Milles",
                "Basile IM Wicky",
                "Alexis Courbet",
                "Rob J de Haas",
                "Neville Bethel"
            ],
            "title": "Robust deep learning\u2013 based protein sequence design using proteinmpnn",
            "venue": "Science,",
            "year": 2022
        },
        {
            "authors": [
                "Valentin De Bortoli",
                "Emile Mathieu",
                "Michael Hutchinson",
                "James Thornton",
                "Yee Whye Teh",
                "Arnaud Doucet"
            ],
            "title": "Riemannian score-based generative modeling",
            "venue": "arXiv preprint arXiv:2202.02763,",
            "year": 2022
        },
        {
            "authors": [
                "Stefano Forli",
                "Ruth Huey",
                "Michael E Pique",
                "Michel F Sanner",
                "David S Goodsell",
                "Arthur J Olson"
            ],
            "title": "Computational protein\u2013ligand docking and virtual drug screening with the autodock suite",
            "venue": "Nature protocols,",
            "year": 2016
        },
        {
            "authors": [
                "Ian Goodfellow",
                "Jean Pouget-Abadie",
                "Mehdi Mirza",
                "Bing Xu",
                "David Warde-Farley",
                "Sherjil Ozair",
                "Aaron Courville",
                "Yoshua Bengio"
            ],
            "title": "Generative adversarial nets",
            "venue": "Advances in neural information processing systems,",
            "year": 2014
        },
        {
            "authors": [
                "Christoph Gorgulla",
                "Andras Boeszoermenyi",
                "Zi-Fu Wang",
                "Patrick D Fischer",
                "Paul W Coote",
                "Krishna M Padmanabha Das",
                "Yehor S Malets",
                "Dmytro S Radchenko",
                "Yurii S Moroz",
                "David A Scott"
            ],
            "title": "An open-source drug discovery platform enables ultra-large virtual screens",
            "venue": "Nature,",
            "year": 2020
        },
        {
            "authors": [
                "Thomas A Halgren",
                "Robert B Murphy",
                "Richard A Friesner",
                "Hege S Beard",
                "Leah L Frye",
                "W Thomas Pollard",
                "Jay L Banks"
            ],
            "title": "Glide: a new approach for rapid, accurate docking and scoring. 2. enrichment factors in database screening",
            "venue": "Journal of medicinal chemistry,",
            "year": 2004
        },
        {
            "authors": [
                "Nafisa M. Hassan",
                "Amr A. Alhossary",
                "Yuguang Mu",
                "Chee-Keong Kwoh"
            ],
            "title": "Protein-ligand blind docking using quickvina-w with inter-process spatio-temporal integration",
            "venue": "Scientific Reports,",
            "year": 2017
        },
        {
            "authors": [
                "Liegi Hu",
                "Mark L Benson",
                "Richard D Smith",
                "Michael G Lerner",
                "Heather A Carlson"
            ],
            "title": "Binding moad (mother of all databases)",
            "venue": "Proteins: Structure, Function, and Bioinformatics,",
            "year": 2005
        },
        {
            "authors": [
                "Ajay N Jain"
            ],
            "title": "Surflex: fully automatic flexible molecular docking using a molecular similarity-based search engine",
            "venue": "Journal of medicinal chemistry,",
            "year": 2003
        },
        {
            "authors": [
                "Wengong Jin",
                "Jeremy Wohlwend",
                "Regina Barzilay",
                "Tommi Jaakkola"
            ],
            "title": "Iterative refinement graph neural network for antibody sequence-structure co-design",
            "venue": "arXiv preprint arXiv:2110.04624,",
            "year": 2021
        },
        {
            "authors": [
                "Bowen Jing",
                "Gabriele Corso",
                "Jeffrey Chang",
                "Regina Barzilay",
                "Tommi Jaakkola"
            ],
            "title": "Torsional diffusion for molecular conformer generation",
            "venue": "arXiv preprint arXiv:2206.01729,",
            "year": 2022
        },
        {
            "authors": [
                "Gareth Jones",
                "Peter Willett",
                "Robert C Glen",
                "Andrew R Leach",
                "Robin Taylor"
            ],
            "title": "Development and validation of a genetic algorithm for flexible docking",
            "venue": "Journal of molecular biology,",
            "year": 1997
        },
        {
            "authors": [
                "John Jumper",
                "Richard Evans",
                "Alexander Pritzel",
                "Tim Green",
                "Michael Figurnov",
                "Olaf Ronneberger",
                "Kathryn Tunyasuvunakool",
                "Russ Bates",
                "Augustin \u017d\u0131\u0301dek",
                "Anna Potapenko"
            ],
            "title": "Highly accurate protein structure prediction with alphafold",
            "year": 2021
        },
        {
            "authors": [
                "David Ryan Koes",
                "Matthew P Baumgartner",
                "Carlos J Camacho"
            ],
            "title": "Lessons learned in empirical scoring with smina from the csar 2011 benchmarking exercise",
            "venue": "Journal of chemical information and modeling,",
            "year": 2013
        },
        {
            "authors": [
                "Rohith Krishna",
                "Jue Wang",
                "Woody Ahern",
                "Pascal Sturmfels",
                "Preetham Venkatesh",
                "Indrek Kalvet",
                "Gyu Rie Lee",
                "Felix S Morey-Burrows",
                "Ivan Anishchenko",
                "Ian R Humphreys"
            ],
            "title": "Generalized biomolecular modeling and design with rosettafold all-atom",
            "year": 2023
        },
        {
            "authors": [
                "Radoslav Kriv\u00e1k",
                "David Hoksza"
            ],
            "title": "P2rank: machine learning based tool for rapid and accurate prediction of ligand binding sites from protein structure",
            "venue": "Journal of cheminformatics,",
            "year": 2018
        },
        {
            "authors": [
                "Zeming Lin",
                "Halil Akin",
                "Roshan Rao",
                "Brian Hie",
                "Zhongkai Zhu",
                "Wenting Lu",
                "Allan dos Santos Costa",
                "Maryam Fazel-Zarandi",
                "Tom Sercu",
                "Sal Candido",
                "Alexander Rives"
            ],
            "title": "Language models of protein sequences at the scale of evolution enable accurate structure prediction",
            "year": 2022
        },
        {
            "authors": [
                "Tiqing Liu",
                "Yuhmei Lin",
                "Xin Wen",
                "Robert N Jorissen",
                "Michael K Gilson"
            ],
            "title": "Bindingdb: a webaccessible database of experimentally determined protein\u2013ligand binding affinities",
            "venue": "Nucleic acids research,",
            "year": 2007
        },
        {
            "authors": [
                "Zhihai Liu",
                "Minyi Su",
                "Li Han",
                "Jie Liu",
                "Qifan Yang",
                "Yan Li",
                "Renxiao Wang"
            ],
            "title": "Forging the basis for developing protein\u2013ligand interaction scoring functions",
            "venue": "Accounts of Chemical Research,",
            "year": 2017
        },
        {
            "authors": [
                "Wei Lu",
                "Qifeng Wu",
                "Jixian Zhang",
                "Jiahua Rao",
                "Chengtao Li",
                "Shuangjia Zheng"
            ],
            "title": "Tankbind: Trigonometry-aware neural networks for drug-protein binding structure prediction",
            "venue": "Advances in neural information processing systems,",
            "year": 2022
        },
        {
            "authors": [
                "Heng Luo",
                "Achille Fokoue-Nkoutche",
                "Nalini Singh",
                "Lun Yang",
                "Jianying Hu",
                "Ping Zhang"
            ],
            "title": "Molecular docking for prediction and interpretation of adverse drug reactions",
            "venue": "Combinatorial Chemistry & High Throughput Screening,",
            "year": 2018
        },
        {
            "authors": [
                "Matthew R Masters",
                "Amr H Mahmoud",
                "Markus A Lill"
            ],
            "title": "Fusiondock: Physics-informed diffusion model for molecular docking",
            "year": 2023
        },
        {
            "authors": [
                "David McClosky",
                "Eugene Charniak",
                "Mark Johnson"
            ],
            "title": "Effective self-training for parsing",
            "venue": "In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,",
            "year": 2006
        },
        {
            "authors": [
                "Andrew T McNutt",
                "Paul Francoeur",
                "Rishal Aggarwal",
                "Tomohide Masuda",
                "Rocco Meli",
                "Matthew Ragoza",
                "Jocelyn Sunseri",
                "David Ryan Koes"
            ],
            "title": "Gnina 1.0: molecular docking with deep learning",
            "venue": "Journal of cheminformatics,",
            "year": 2021
        },
        {
            "authors": [
                "Rocco Meli",
                "Philip C. Biggin"
            ],
            "title": "spyrmsd: symmetry-corrected rmsd calculations in python",
            "venue": "Journal of Cheminformatics,",
            "year": 2020
        },
        {
            "authors": [
                "Oscar M\u00e9ndez-Lucio",
                "Mazen Ahmad",
                "Ehecatl Antonio del Rio-Chanona",
                "J\u00f6rg Kurt Wegner"
            ],
            "title": "A geometric deep learning approach to predict binding conformations of bioactive molecules",
            "venue": "Nature Machine Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Mayukh Mukhopadhyay"
            ],
            "title": "A brief survey on bio inspired optimization algorithms for molecular docking",
            "venue": "International Journal of Advances in Engineering & Technology,",
            "year": 2014
        },
        {
            "authors": [
                "Nicholas F Polizzi",
                "William F DeGrado"
            ],
            "title": "A defined structural unit enables de novo design of small-molecule\u2013binding proteins",
            "year": 2020
        },
        {
            "authors": [
                "Gustavo Schottlender",
                "Juan Manuel Prieto",
                "Miranda Clara Palumbo",
                "Florencia A Castello",
                "Federico Serral",
                "Ezequiel J Sosa",
                "Adri\u00e1n G Turjanski",
                "Marcelo A Mart\u0131",
                "Dar\u0131\u0301o Fern\u00e1ndez Do Porto"
            ],
            "title": "From drugs to targets: Reverse engineering the virtual screening process on a proteomic scale",
            "venue": "Frontiers in Drug Discovery,",
            "year": 2022
        },
        {
            "authors": [
                "David Silver",
                "Aja Huang",
                "Chris J Maddison",
                "Arthur Guez",
                "Laurent Sifre",
                "George Van Den Driessche",
                "Julian Schrittwieser",
                "Ioannis Antonoglou",
                "Veda Panneershelvam",
                "Marc Lanctot"
            ],
            "title": "Mastering the game of go with deep neural networks and tree search",
            "year": 2016
        },
        {
            "authors": [
                "Yang Song",
                "Stefano Ermon"
            ],
            "title": "Generative modeling by estimating gradients of the data distribution",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Yang Song",
                "Jascha Sohl-Dickstein",
                "Diederik P Kingma",
                "Abhishek Kumar",
                "Stefano Ermon",
                "Ben Poole"
            ],
            "title": "Score-based generative modeling through stochastic differential equations",
            "venue": "In International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Hannes St\u00e4rk",
                "Octavian Ganea",
                "Lagnajit Pattanaik",
                "Regina Barzilay",
                "Tommi Jaakkola"
            ],
            "title": "Equibind: Geometric deep learning for drug binding structure prediction",
            "venue": "In International Conference on Machine Learning",
            "year": 2022
        },
        {
            "authors": [
                "Ren\u00e9 Thomsen"
            ],
            "title": "Protein\u2013ligand docking with evolutionary algorithms",
            "venue": "Computational Intelligence in Bioinformatics,",
            "year": 2007
        },
        {
            "authors": [
                "Ren\u00e9 Thomsen",
                "Mikael H Christensen"
            ],
            "title": "Moldock: a new technique for high-accuracy molecular docking",
            "venue": "Journal of medicinal chemistry,",
            "year": 2006
        },
        {
            "authors": [
                "Chenran Wang",
                "Yang Chen",
                "Yuan Zhang",
                "Keqiao Li",
                "Menghan Lin",
                "Feng Pan",
                "Wei Wu",
                "Jinfeng Zhang"
            ],
            "title": "A reinforcement learning approach for protein\u2013ligand binding pose prediction",
            "venue": "BMC bioinformatics,",
            "year": 2022
        },
        {
            "authors": [
                "Joseph L Watson",
                "David Juergens",
                "Nathaniel R Bennett",
                "Brian L Trippe",
                "Jason Yim",
                "Helen E Eisenach",
                "Woody Ahern",
                "Andrew J Borst",
                "Robert J Ragotte",
                "Lukas F Milles"
            ],
            "title": "De novo design of protein structure and function with rfdiffusion",
            "venue": "Nature,",
            "year": 2023
        },
        {
            "authors": [
                "Qizhe Xie",
                "Minh-Thang Luong",
                "Eduard Hovy",
                "Quoc V Le"
            ],
            "title": "Self-training with noisy student improves imagenet classification",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Xin Yi",
                "Yanbo Zhang",
                "Peidan Wang",
                "Jiangwei Qi",
                "Meiying Hu",
                "Guohua Zhong"
            ],
            "title": "Ligands binding and molecular simulation: the potential investigation of a biosensor based on an insect odorant binding protein",
            "venue": "International journal of biological sciences,",
            "year": 2015
        },
        {
            "authors": [
                "Gengmo Zhou",
                "Zhifeng Gao",
                "Qiankun Ding",
                "Hang Zheng",
                "Hongteng Xu",
                "Zhewei Wei",
                "Linfeng Zhang",
                "Guolin Ke"
            ],
            "title": "Uni-mol: a universal 3d molecular representation learning",
            "year": 2023
        },
        {
            "authors": [
                "Corso"
            ],
            "title": "2022] to stabilize the inference over different training epochs. We add the sampled poses with a confidence score c\u03c6(x, d) > k, where k is the confidence cutoff, to the buffer: B = B",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Understanding how small molecules and proteins interact, a task known as molecular docking, is at the heart of drug discovery. The conventional use of docking in the industry has led the field to focus on finding binding conformations when restricting the search to predefined pockets and evaluating these on a relatively limited set of protein families of commercial interest. However, solving the general blind docking task (i.e. without pocket knowledge) would have profound biological implications. For example, it would help us understand the mechanism of action of new drugs to accelerate their development [Schottlender et al., 2022], predict adverse side-effects of drugs before clinical trials [Luo et al., 2018], and discover the function of the vast number of enzymes and membrane proteins whose biology we do not yet know [Yi et al., 2015]. All these tasks critically require the docking methods to generalize beyond the relatively small class of well-studied proteins for which we have many available structures.\nExisting docking benchmarks are largely built on collections of similar binding modes and fail to rigorously assess the ability of docking methods to generalize across the proteome. Gathering diverse data for protein-ligand interactions is challenging because binding pockets tend to be evolutionarily well-conserved due to their critical biological functions. Therefore, a large proportion of known interactions fall into a relatively small set of common binding modes. Moreover, human biases in the collection of binding conformational data further compromise the representativeness of existing benchmarks. To address these problems, we propose DOCKGEN, a new benchmark that aims to test a method\u2019s ability to generalize across protein domains. With DOCKGEN, we show that existing machine learning-based docking methods poorly predict binding poses on unseen binding pockets.\nWith this new benchmark, we analyze the scaling laws of DIFFDOCK, the state-of-the-art MLbased blind docking method, with respect to the size of both its architecture and its training data. The results show that increasing both data and model can give significant generalization improvements. Further, we devised and integrated a synthetic data generation strategy based on extracting side chains as ligands from real protein structures. Putting these together, our new DIFFDOCK-L\n\u2217Equal contribution. Correspondence to gcorso@mit.edu\nincreases the top ML-based DOCKGEN performance from 7.1% to 22.6% setting a new state-of-theart. However, with the current data and computing resources available today, this trend alone might not be sufficient to fully bridge this generalization gap.\nTo move beyond this challenge, we propose CONFIDENCE BOOTSTRAPPING, a novel self-training scheme inspired by Monte Carlo tree-search methods, where we fine-tune directly on protein-ligand complexes from unseen domains without access to their structural data. The fine-tuning is enabled by the interaction between a diffusion model rolling out the sampling process and a confidence model assigning confidence scores to the final sampled poses. These confidence scores are then fed back into the early steps of the generation process (see Figure 1 for a visual representation). This process is iterated to improve the diffusion model\u2019s performance on unseen targets, effectively closing the generalization gap between the diffusion model and the confidence model.\nWe test CONFIDENCE BOOTSTRAPPING on the new DOCKGEN benchmark by fine-tuning a small and efficient version of DIFFDOCK on individual protein clusters. In each of these clusters, within the first few iterations of bootstrapping, the diffusion model is pushed to generate docked poses with increasingly high confidence. This increased confidence also translates into significantly higher accuracy with the fine-tuned models improving from 9.8% to 24.0% success rate overall, and above 30% in half of the protein domains."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "Search-based docking Due to its importance in biological research and drug discovery, molecular docking has for decades been a central challenge for the computational science community [Halgren et al., 2004; Jain, 2003; Thomsen & Christensen, 2006]. Originally, most techniques followed the search-based paradigm, which is still prevalent today. These methods consist of a scoring function and an optimization algorithm. The latter searches over thousands or millions of different conformations, which are passed to the scoring function that determines their likelihood/goodness. While these methods tend to show relatively robust generalization across protein classes, they are significantly affected by the size of the search space, which grows exponentially as the ligand gets larger or as assumptions are removed (e.g. receptor rigidity).\nML-based docking Researchers have recently tried to move beyond the search-based paradigm and directly generate poses with deep learning models. The first attempts [Sta\u0308rk et al., 2022; Lu et al., 2022] framed the docking task as a regression problem; this showed significant improvements in runtime but did not reach the accuracy of search-based methods. Corso et al. [2022] proposed DIFFDOCK, a generative model based on the diffusion modeling framework that is trained to sample\ndocked ligand poses. In particular, DIFFDOCK uses a diffusion model to sample a small number of possible poses that are then passed to a confidence model that ranks and assigns a score to each.\nBlind docking benchmarks The majority of previous ML-based methods used the PDBBind dataset [Liu et al., 2017], a curated set of protein-ligand crystallographic structures from PDB [Berman et al., 2003], to train and test models. In particular, they adopted a time-based split of the dataset where structures that were resolved before 2019 went into training and validation, and those from 2019 formed the test set. Sta\u0308rk et al. [2022] and others also evaluate the performance on a reduced set of proteins with different UniProt-ID [Consortium, 2015] compared to those in the training set. Here, while ML methods show a drop in performance, they remain in line with search-based techniques [Corso et al., 2022]. Similarly, concurrent works [Masters et al., 2023; Buttenschoen et al., 2024] define new splits or benchmarks based on global sequence similarity."
        },
        {
            "heading": "3 THE DOCKGEN BENCHMARK",
            "text": "We argue that the existing approaches used to evaluate the ML docking methods fall short in analyzing their generalization capacity to different parts of the proteome. Binding pockets, due to their importance to many biological mechanisms, are often among the most well-conserved regions in proteins. Therefore, just looking at the UniProt-ID of a protein or its global sequence similarity often leads to proteins in the train and test sets that have the same underlying pocket. Figure 2-A shows an example of such failures, where two proteins, even with only 22% sequence similarity (30% is often used as cutoff), share very similar binding pockets.\nTo better detect these cases we delve one level deeper into the organization of proteins and look at protein domains. Protein domains are the structural and functional units that compose proteins. Very similar domains can appear in different sequences but have similar local structural characteristics. Therefore, by looking at the protein domains where ligands bind, we can form a more granular classification of the protein-ligand interactions.\nTo classify each domain, we used the ECOD [Cheng et al., 2014] classification. This clustering divides the 17k complexes from PDBBind before 2019, which have been used for training and validation of previous ML models, into 487 clusters. The remaining data from 2019, from which the test set was generated, presents only 8 additional clusters composed of a total of 15 complexes. This clustering approach is very different from that taken by other methods based on global sequence similarity.\nTo obtain a more sizable test set without retraining the models on a reduced set, we turn to the Binding MOAD dataset [Hu et al., 2005]. Similar to PDBBind, Binding MOAD is a curated collection of protein-ligand complexes from the PDB. However, due to its different filtering and requirements (e.g. no requirement for known affinity), it contains a set of 41k complexes partially disjoint from PDBBind. These come from 525 ECOD clusters, 346 of which are in common with PDBBind, and 179 of which are not present in PDBBind.\nTo generate the validation and test datasets of the new benchmark, we randomly divide these remaining clusters in two and then apply a number of further filtering steps (more details in Appendix A). In particular, we exclude protein-ligand complexes with multiple ligands interacting in the same pocket (i.e. no additional bound cofactors). We also remove metals, crystal additives, and large molecules with more than 60 heavy atoms. To maintain a chemical balance we only keep up to 5 complexes with the same ligand in the validation and test datasets. This leaves us with 141 complexes in the validation and 189 complexes in the test set. A careful analysis of the binding-site similarity of the different datasets highlights the vast improvement brought by DOCKGEN in terms of binding site generalization (Figure 2.B and Appendix A.2).\nWe then run a number of baselines considered to be the state-of-the-art open-source or open-access models: for search-based methods, SMINA [Koes et al., 2013] and GNINA [McNutt et al., 2021], while for ML methods, EQUIBIND [Sta\u0308rk et al., 2022], TANKBIND [Lu et al., 2022] and DIFFDOCK [Corso et al., 2022]. Since search-based methods have been shown to improve their blind docking performance by first selecting a pocket with a pocket finder method like P2RANK [Kriva\u0301k & Hoksza, 2018], we also report these performances.\nPrevious ML methods significantly underperform in this new benchmark (Table 1), and their performances are only a fraction of those that they have in the time-split complexes from the PDBBind test set, with regression methods having nearly no success. On the other hand, search-based methods have a significantly lower drop in performance, but even when increasing the exhaustiveness of their search, they are not able to find the true pose in the vast majority of cases, motivating the need for the development of more accurate methods."
        },
        {
            "heading": "4 CONFIDENCE BOOTSTRAPPING",
            "text": "Docking, along with other structural biology problems like protein folding, has been commonly treated as an NP-hard combinatorial optimization problem [Thomsen, 2007; Mukhopadhyay, 2014]. Although the success of ML methods such as AlphaFold2 [Jumper et al., 2021] has demonstrated that deep learning methods can significantly shorten the search in practice. The NP perspective suggests a useful insight into the problem: it is easier to check that a pose is good than to generate a good pose. This perspective points towards the exploration of new self-training-based strategies where feedback from a discriminative model is used to update the generative model exploring the\nspace of conformations and help the latter generalize to protein domains where we have no data for ground truth poses."
        },
        {
            "heading": "4.1 BACKGROUND",
            "text": "Diffusion models Let p(x) be some data distribution of interest. Score-based diffusion generative models [Song et al., 2021] are trained to sample from p by defining a continuous diffusion process dx = f(x, t)dt + g(t)dw, where w represents the Wiener process that transforms the data distribution in a simple prior, and learns to reverse such a process. This is enabled by the existence of a corresponding reverse diffusion process which can be expressed by the SDE dx = [f(x, t)\u2212 g(t)2 \u2207x log pt(x)]dt+ g(t)dw where pt(x) is the likelihood of the evolving data distribution. To run this reverse diffusion equation, we need to learn to approximate the score of the evolving data distribution s\u03b8(x, t) \u2248 \u2207x log pt(x). This is achieved by optimizing the parameters \u03b8 via the denoising score matching loss:\n\u03b8\u2217 = argmin \u03b8\n[ Et\u223cU [0,T ] { \u03bb(t)Ex(0)\u223cptrainEx(t)|x(0) [ \u2225s\u03b8(x(t), t)\u2212\u2207x(t) log p0t(x(t)|x(0))\u222522 ]} ] where U refers to the uniform distribution, \u03bb(t) is a positive weighting function and p0t the transition kernel of the forward diffusion process. One view of diffusion models is via the lens of their iterative denoising generation ladder which, at every step, exponentially reduces the size of candidate poses\u2019 posterior distribution (progressively higher resolution), a perspective we will use to motivate our approach. Diffusion models were also generalized to compact Riemannian manifolds [De Bortoli et al., 2022], a formulation that is particularly well suited for scientific applications where the main degrees of freedom can be well represented by actions on a low-dimensional Riemannian manifold [Corso, 2023]. This idea underlies DIFFDOCK and other recent advances in computational sciences [Jing et al., 2022; Watson et al., 2023].\nSelf-training methods Self-training refers to a range of techniques that have been employed in several different ML application domains where labels predicted by some model on unlabelled data are used for training. For example, in the setting of image classification, Xie et al. [2020] used unlabelled images to improve a classifier by first generating labels from the clean image with the current classifier version, and then training the classifier to make the same prediction on noisy versions of the same image. This method was taken as inspiration for the self-distillation technique used by AlphaFold2 [Jumper et al., 2021], where after a first training iteration, predicted structures satisfying a certain residue pairwise distance distribution were used for a second iteration of model training.\nIn the realm of generative models, McClosky et al. [2006] used the labels predicted by a discriminative reranker to select the best parses generated by a generative parser and add them to the training set. Jin et al. [2021] took a similar approach for antibody optimization via the feedback of a neutralization predictor. Finally, Generative Adversarial Networks (GANs) [Goodfellow et al., 2014] also use the feedback from a discriminator to train a generative model. However, in GANs one relies on having in-distribution data to jointly train the discriminator."
        },
        {
            "heading": "4.2 METHOD",
            "text": "These existing self-training methods do not, however, directly exploit the structure of the generative process they optimize. Moreover, they often fail if the initial generator has a low signal-to-noise ratio. Iterating on such generators amplifies the initial errors [McClosky et al., 2006]. We argue that diffusion models, because of their multi-resolution structure, offer a unique opportunity to more precisely target the effect of self-training and avoid error amplification.\nA large challenge for the diffusion model is that in the first steps of the reverse diffusion process, the model needs to determine both the pocket and approximate pose of the ligand, without having a clear view of how well that pose will fit in the pocket. If the model finds that the pocket does not fit the ligand adequately after the ligand has been partially docked, the model can not backtrack its decisions1 or learn from its mistakes.\n1Note that in theory at every step the conditional distribution learned by the diffusion model spans the whole search space; however, in practice the model learns, based on the prior, to not to look for a conformation beyond a distance that is much larger than the current noise level.\nWe introduce CONFIDENCE BOOTSTRAPPING, a training mechanism that refines a diffusion generator based on feedback from a confidence model. The diffusion model is used to \u201croll out\u201d the reverse diffusion process, generating poses that are then scored with the confidence model. These scores are used to inform how to update the parameters of the early steps of the diffusion process so that the model will generate more poses close to those with high confidence (see a graphical representation in Figure 1). This process is then repeated for several steps.\nThere are several reasons why we hypothesize that the diffusion model would be able to learn from the feedback of the confidence model. As discussed above, while generating a ligand pose for a new protein is difficult, testing whether a pose is satisfactory is a local and simpler task that, we believe, can more easily generalize to unseen targets. Intuitively, the more difficult the underlying task the more a model is likely to overfit, capturing some spurious correlations in the data instead of the underlying signal. Similarly, early steps of the reverse diffusion process that have to decide the most likely among the different pockets and poses will struggle more than the late steps where the remaining posterior is significantly more localized. Training the early steps of the reverse diffusion based on the confidence outcomes of the rollouts, CONFIDENCE BOOTSTRAPPING is able to exploit the multi-resolution structure of diffusion models and close the generalization gap between the different diffusion steps.\nFrom this perspective, our procedure of (1) rolling out the steps of the generation process, (2) evaluating the success at the end, and (3) feeding back information from the end to the initial steps resembles the Reinforcement Learning (RL) algorithm used to master games such as Go [Silver et al., 2016]. Instead of score and confidence models, they use policy and value networks, and the diffusion process is replaced by a Monte Carlo tree-search. More generally, our problem can be loosely seen as an RL problem, where confidence is the reward. We discuss this connection in more detail in Appendix D.\nAlthough it adds complexity to the training process, CONFIDENCE BOOTSTRAPPING is particularly well suited for the molecular docking task. Firstly, as discussed in Section 3, the limited amount of training data and its lack of diversity make alternative training methods critical for the success of blind docking. Furthermore, CONFIDENCE BOOTSTRAPPING can leverage information from very large affinity datasets such as BindingDB [Liu et al., 2007]. Exploiting this binding data is largely unexplored for the docking task. Finally, docking screens are usually run on a very large number of complexes (up to tens of billions [Gorgulla et al., 2020]) using a restricted set of proteins. Therefore, any time that one would spend fine-tuning the docking algorithm for the restricted set would be largely amortized throughout the screen."
        },
        {
            "heading": "4.3 FORMALIZATION",
            "text": "We now formalize the CONFIDENCE BOOTSTRAPPING training routine. For simplicity, we will present it based on the diffusion model formulation in Euclidean space. However, note that this directly applies to the Riemannian diffusion formulation [De Bortoli et al., 2022] used by DIFFDOCK.\nLet p\u03b8(x; d) be the probability distribution of poses learned by the diffusion model with score s\u03b8(x\n(t), t; d) where d is the known information about the complex (e.g, protein and molecule identity). Let c\u03d5(x, d) be the output of the confidence model, and let D = {d1, d2, ...} be a set of known binders (e.g. from BindingDB) for the target distribution of interest.\nCONFIDENCE BOOTSTRAPPING consists of K iterations where at each iteration i the score model weights \u03b8 are updated based as following optimization:\n\u03b8i+1 = argmin \u03b8\n[ Et\u223cU [0,T ] { \u03bb(t) Ex(0),d\u223cptrainEx(t)|x(0) [ \u2225s\u03b8(x(t), t; d)\u2212\u2207x(t) log p0t(x(t)|x(0))\u222522 ] + \u03bb\u2032(t) Ex(0),d\u223cp\u03b8i,\u03d5Ex(t)|x(0) [ \u2225s\u03b8(x(t), t; d)\u2212\u2207x(t) log p0t(x(t)|x(0))\u222522\n]}] where \u03b80 are the weights of the pretrained diffusion model (if not trained from scratch), and p\u03b8,\u03d5(x, d) \u221d p\u03b8(x; d) exp[c\u03d5(x, d)]. Each of these iterations i \u2208 [0,K) is achieved by performing a rollout stage, followed by an update stage. During the rollout stage, we first sample d from D, then sample points from p\u03b8i(\u00b7, d), forming a buffer B = [(x1, d1), ...]. During the update stage, a fixed number of stochastic gradient descent steps are performed where half of the fine-tuning complexes are taken from the training dataset (first\nhalf of the objective) and half are taken from the buffer B (second half). In particular, to approximate samples from p\u03b8i,\u03d5(x, d), the elements (x, d) of B are sampled with probabilities proportional to exp[c\u03d5(x, d)].\nUsing different \u03bb and \u03bb\u2032 allows us to take advantage of the multiresolution decomposition of diffusion models and direct the bootstrapping feedback principally to update the initial steps of the reverse diffusion. The samples taken from the combination of diffusion and confidence models are likely to be too noisy to provide fine-grained guidance for small t. To prevent the model from forgetting how to perform the final steps, we still take samples from the training dataset and give them a larger weight for small t. Further details on the implementation and optimization of this routine can be found in Appendix C."
        },
        {
            "heading": "5 EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "5.1 ANALYZING DOCKING SCALING LAWS",
            "text": "Empirically, we first analyze the effect that scaling the training data and the model size has on the generalization capacity of DIFFDOCK. This analysis is important to evaluate the potential impact of community efforts to increase the amount of available high-quality training data and develop large-scale ML docking models.\nIncreasing the training data We investigate how much the addition of more data, within the protein domains that the model already sees, can help with generalization outside of those domains. This is an important question because in recent years there has been a call from the research community for pharmaceutical companies to release the large number of crystallography structures they possess. We test this question by including in the training data all MOAD complexes from the same binding protein domains as those seen in PDBBind training and validation sets and released before 2019 (to maintain the validity of the benchmarks). After filtering out duplicates and non-conformant ligands, this increases the number of training data points by approximately 52%.\nVan der Mer-inspired docking augmentation Additional training data from MOAD contributes modestly to pocket diversity, as the extra data points lie within the same protein domain clusters. To increase pocket diversity, we design a novel auxiliary training task based on the generation of synthetic docked poses using protein sidechains as surrogate ligands. We take inspiration from the concept of a van der Mer (vdM), which has been used successfully in the design of proteins that bind target ligands [Polizzi & DeGrado, 2020]. A van der Mer is an amino acid that interacts with another amino acid that is distant in the 1D protein sequence, which can closely approximate a noncovalent protein-ligand interaction. In a given protein crystal structure, we select a sidechain with a large number of protein contacts distant in sequence. The interacting amino acids are assigned as the \u201cbinding pocket\u201d for the chosen sidechain. We remove the coordinates of the \u201cligand\u201d residue and its sequence-local neighbors from the protein to generate the new target complex (more details on how exactly these are chosen can be found in Appendix B.2).\nThe advantage of these synthetic protein-ligand complexes is that they are myriad and easy to compute, since any (even unliganded) protein structure can be used to generate such examples. Thus, we can potentially dramatically increase the structural and chemical diversity of binding domains and pockets. This diversity could help the model understand the chemical and geometrical environments of different pockets. The drawbacks are that these synthetic complexes are of unknown affinity (many could be weak binders), and the chemical diversity of ligands is limited to the 20 amino acids.\nIncreasing the model size Further, we evaluate how the generalization ability of the docking models changes when scaling their capacity. The relationship between model capacity and generalization has been a topic of significant study in the machine learning community. On one hand, the traditional learning theory perspective suggests that once the model overfits to some amount of training data increasing the model size will only likely make the overfitting worse. On the other hand, recent evidence for deep learning models has shown the opposite behavior with \u201coverparameterized\u201d models increasing their ability to generalize when given more capacity [Belkin et al., 2019]. We compare score models of the size of the original DIFFDOCK (\u223c20M parameters) with others of smaller (\u223c4M) and larger ones (\u223c30M).\nExperimental results The results of these experiments, shown in Figure 3, highlight a clear trend of improvement both when increasing the training data and when increasing the size of the model. The vdM augmentation strategy also seems to provide some improvements when scaling to larger model sizes. Combining these components we develop DIFFDOCK-L, which we release publicly2. DIFFDOCK-L improves the ML-docking performance on DOCKGEN from 7.1% to 22.6%, even outperforming the best search-based method (17.5%). DIFFDOCK-L also achieves state-of-the-art blind docking performance on both PDBBind (see Table 1) and PoseBusters test sets (see Appendix E.1). Overall we believe that the analysis of these trends may prove useful for many practitioners and to support the effort of the community in developing even larger open-source datasets and models."
        },
        {
            "heading": "5.2 CONFIDENCE BOOTSTRAPPING",
            "text": "We test3 CONFIDENCE BOOTSTRAPPING on the new DOCKGEN benchmark, where we fine-tune a model on each protein domain cluster. In particular, we use DIFFDOCK-S, the 4M parameters version of DIFFDOCK introduced in Appendix C.2. For computational feasibility, we use clusters with at least 6 complexes and restrict the test set to 8 separate clusters (5 for validation) for a total of 85 complexes, which compose the DOCKGEN-clusters subset.\nAs can be seen from Figure 4-A, for most of the clusters, the median confidence of the predicted structures increases along the fine-tuning. Critically, Figure 4-B and 4-C show that also the accuracy of most clusters significantly improves over the course of the bootstrapping process. In Figure 4-D, we plot the average performance across all clusters in comparison to that of the baselines. From this, we see that, in DOCKGEN-clusters, CONFIDENCE BOOTSTRAPPING considerably raises the baseline DIFFDOCK-S\u2019s performance going from 9.8% to 24.0% and doubles that of the traditional search-based methods even when run with high exhaustiveness.\nThe analysis becomes even more interesting when looking into the evolution of the performance in the individual clusters. In half of the clusters, the model is able to reach top-1 RMSD < 2A\u030a performance above 30%. These clusters mostly constitute those in which the original model has non-zero accuracy with an initial performance varying from around 2% to 20%. Then we have one cluster where the accuracy is improved to only \u223c10% and three clusters where the model never selects good poses neither before nor after the bootstrapping. These results, further supported by the performance when run using an oracle confidence model in Appendix E.2, suggest that future\n2We release data, instructions, code, and weights at https://github.com/gcorso/DiffDock. 3Code for these experiments can be found at https://github.com/LDeng0205/\nconfidence-bootstrapping.\nimprovements to either the score or confidence models will lead to even further gains when finetuned with CONFIDENCE BOOTSTRAPPING."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "Given the potential utility of high-accuracy blind docking in biology and drug discovery, it is important to track the progress of ML-based methods to generalize to unseen pockets. To this end, we have proposed DOCKGEN, a new benchmark for blind docking generalization based on the classification of binding protein domains. Evaluating existing ML methods on the DOCKGEN benchmark highlights how overfitting training data prevents generalization to unseen binding modes. By scaling the training data and model size as well as integrating a novel synthetic data generation technique, we were able to significantly improve the generalization ability and developed and released DIFFDOCKL, a new state-of-the-art docking method.\nTo improve generalization even further, we proposed CONFIDENCE BOOTSTRAPPING, a selftraining method that only relies on the interaction between a diffusion and a confidence model and exploits the multi-resolution structure of the sampling process. This allows the direct fine-tuning of the docking model on classes of proteins where binding structural data is not available. Empirically, the method shows significant improvements on the DOCKGEN benchmark, going from 10% to 24% success rate for efficient and fast models. Finally, we believe this opens up the possibility of training even larger-scale docking models that have so far been obstructed by the size and diversity of the available data, bringing us one step closer to a generalizable solution to the docking challenge."
        },
        {
            "heading": "ACKNOWLEDGEMENTS",
            "text": "We thank Bowen Jing, Hannes Stark, Rachel Wu, Peter Holderrieth, Jody Mou, and Saro Passaro for their helpful discussions and feedback. We thank Jacob Silterra for his help in the code deployment.\nThis work was supported by the NSF Expeditions grant (award 1918839: Collaborative Research: Understanding the World Through Code), the Machine Learning for Pharmaceutical Discovery and Synthesis (MLPDS) consortium, the Abdul Latif Jameel Clinic for Machine Learning in Health, the DTRA Discovery of Medical Countermeasures Against New and Emerging (DOMANE) Threats program, the DARPA Accelerated Molecular Discovery program, the NSF AI Institute CCF2112665, the NSF Award 2134795, and the GIST-MIT Research Collaboration grant. N.P. acknowledges support from NIH grant R00GM135519 and from the Innovation Research Fund of the Dana-Farber Cancer Institute."
        },
        {
            "heading": "A DOCKGEN BENCHMARK DETAILS",
            "text": ""
        },
        {
            "heading": "A.1 DATASET CREATION",
            "text": "In this section, we specify the details of how the Binding MOAD dataset was parsed and filtered to obtain the DOCKGEN benchmark validation and test sets. The benchmark was created following these steps:\n1. We perform the ECOD-based clustering. Each ligand in a protein is classified by the ECOD domain (t group) of the chain that is making the most contacts with the ligand. The t-group of the ligand is assigned using the consensus of per-residue t-group assignments of each contacting amino acid (4.8A\u030a heavy atom distance) in the dominant chain. We use this approach to classify both the complexes in PDBBind and MOAD. There are 179 clusters in MOAD that do not appear in PDBBind. These 179 are randomly and equally divided between validation and test datasets.\n2. Within these clusters, since most docking tools do not support the simultaneous docking of multiple ligands, we discard ligands that are within 4.8A\u030a from the heavy atoms of another ligand.\n3. We discard the ligands labeled by MOAD as \u201cpart of proteins\u201d as these are constituted mostly by metals and covalent binders.\n4. We discard very large ligands formed by more than 60 heavy atoms. 5. Ligands with equal chemical composition that are bound to the same protein are also clus-\ntered together forming a single ligand with multiple correct poses. 6. To ensure diversity in the benchmark, if the same ligand appears bound to different biolog-\nical assemblies of the same PDB entry we only select one of these at random. 7. To avoid overrepresentation of certain ligand classes, we limit the maximum number of\nligands to 5 of the same molecule separately in the validation and test sets. This avoids, for example, the presence of a large number of NAD ligands when considering the \u201dNADbinding domain\u201d cluster.\n8. To follow the convention that has been used to train previous ML-based blind docking algorithms, we select only the protein chains that have a C-alpha atom within 10A\u030a of a ligand\u2019s heavy atom. In the cases of multiple equal ligands bound to the same complex, one was selected as a reference for the filtering.\nAfter these steps we are left with a validation set composed by 141 unique complexes from 70 different clusters and a test set formed by 189 complexes from 63 clusters."
        },
        {
            "heading": "A.2 DATASET ANALYSIS",
            "text": "In this section, we compare the test set of the newly generated DOCKGEN benchmark and the one of PDBBind.\nReceptor and ligand dimension In Figure 5 we plot the distribution of the sizes of the receptors and ligands in the two sets. These are not too different, but on average DOCKGEN seems to present slightly smaller ligands but larger protein receptors. The latter might be one of the explanations for why even traditional search-based docking methods that are often considered to generalize relatively well (even though they also present a number of parameters fitted to experimental data) do worse in the DOCKGEN test set.\nBinding site similarity analysis To evaluate binding site similarity between datasets, we extract residues in contact with the ligand (defined as protein\u2019s heavy atoms within 5A\u030a of ligand heavy atoms) and merge them into a single chain to handle binding sites at protein-protein interfaces. We then TMalign every extracted binding site in the training set to every extracted binding site in the test set for both the PDBbind and DOCKGEN datasets. We parse the TMalign output for any aligned residues and record their amino acid identities for both the target and query binding sites. We then compute the fraction of the target and query matched by the alignment and take the harmonic mean of those fractions as a first metric for binding site similarity. We then use the BLOSUM62 amino acid\nsubstitution matrix to quantify similarity in the case that two amino acids are structurally aligned but not exact sequence matches. Amino acids that are more similar have larger values in this matrix. We normalize the BLOSUM matrix to values between 0 and 1 and then take the average of these normalized values across all structurally matched residues as a second similarity metric.\nWe compare these metrics across the PDBBind and DOCKGEN test sets when compared to PDBBind training set in Figure 2 and show that binding sites in PDBBind tend to be more similar to those in the test set compared to the same comparison for the DOCKGEN dataset: the density in the top right corner indicates significant binding site overlap in PDBBind and little in the case of DOCKGEN."
        },
        {
            "heading": "B DATA AUGMENTATION STRATEGIES DETAILS",
            "text": "B.1 INCREASING THE TRAINING DATA\nTo increase the training data using the clusters of Binding MOAD that did not go into the validation or test set, we first take the clusters that remained after applying step 1 above. We also remove all complexes resolved in 2019 or later to maintain the validity of the PDBBind test set. Then, we again discard all ligands that are close to other ligands and those with a single heavy atom.\nWe take the remaining complexes, forming a dataset with 20,012 ligand poses bound to 14,214 different biological units, and use them for training. For ligands that are bound to the same biological unit, at every epoch we select a single ligand at random for training. At training time, we simply concatenate this dataset to PDBBind\u2019s training set. One should note that the two datasets are not disjoint and many complexes will appear in both. We avoid removing the redundancy to give more weight to complexes that passed both filtering processes of MOAD and PDBBind and are therefore more likely to be of higher quality.\nB.2 VAN DER MER-INSPIRED TRAINING\nTo extract van der Mer-like amino-acid ligands, we start from a large collection of protein structures that comprise the ProteinMPNN [Dauparas et al., 2022] training set. At preprocessing time, for every sidechain s in the protein, we compute ns the number of other amino acids that have heavy atoms within 5A\u030a and are not local in primary sequence (within 10 residues). This determines the extent to which the remaining part of the protein forms a pocket around the selected sidechain, once the adjacent sequence on each side is removed.\nAt training time, we iterate over the clusters of proteins in the dataset. We use the same clusters adopted by ProteinMPNN that were generated with a sequence similarity cutoff of 30%. For each cluster, we take one protein at random, and within this, we select a sidechain s at random with\nprobability proportional to max(0, ns \u2212 5) sampling buried residues with a higher likelihood. If no sidechain has more than 5 contacts then the protein is skipped.\nOnce a sidechain is selected, the sequence-local segment of the protein chain, consisting of 21 residues centered at the selected sidechain (i.e. 10 residues on either side), is removed from the protein structure. The sidechain and its backbone atoms are then used as the ligand that the model is trained to dock. An example of such resulting complex is represented in Figure 6.\nNote that for computational efficiency, instead of re-computing the embedding each time we truncate a protein structure, we compute the ESM embeddings [Lin et al., 2022] used by DiffDock only once with the full sequence and then simply crop the removed sequence out (even though the embedding of the remaining residues might be affected by the residues that were removed)."
        },
        {
            "heading": "C CONFIDENCE BOOTSTRAPPING DETAILS",
            "text": "In this section, we discuss the CONFIDENCE BOOTSTRAPPING procedure and our experimental setup. We demonstrate that CONFIDENCE BOOTSTRAPPING improves blind docking performance of the pretrained score model on a previously unseen cluster without knowing the ground-truth poses of that cluster. This is achieved by iteratively sampling from the score model (the rollout process), evaluating these samples with the confidence model, and updating the score model treating highquality samples as ground-truth poses. Our procedure assumes a DIFFDOCK score model and a confidence model both pretrained. We use the procedure outlined in Corso et al. [2022] to train and sample from the score model."
        },
        {
            "heading": "C.1 TRAINING PROCEDURE",
            "text": "The training procedure takes as input ligand/receptor pairs D = {d1, d2, ...} from a cluster of interest, a pretrained diffusion model parametrized by \u03b8 with learned distribution over poses p\u03b8(x; d) and score s\u03b8(x(t), t; d), and a pretrained confidence model c\u03d5(x, d). At each step, we sample complexes from the score model through the reverse diffusion process, score these complexes with the confidence model, and use high-confidence samples to update the score model. More specifically, we start with the buffer B that is initially empty; at step i, we sample q candidate poses (xj , di) for j \u2208 {1, \u00b7 \u00b7 \u00b7 , q} for each di \u2208 D from p\u03b8iema(x; d) and evalute these candidate poses with c\u03d5. We use the exponential moving averaged version of model weights \u03b8iema as in Corso et al. [2022] to stabilize the inference over different training epochs. We add the sampled poses with a confidence score c\u03d5(x, d) > k, where k is the confidence cutoff, to the buffer: B = B \u222a {(xj , di) | c\u03d5(xj , di) > k}.\nThen, we update the score model \u03b8i by treating complexes in B as ground truth poses and performing a fixed number of SGD update steps on the diffusion objective to obtain \u03b8i+1.\nTo train the original model we use the denoising score matching loss presented in Section 4.1 with a weighting \u03bb(t) = t/\u00b52t where \u00b5t is the expected score magnitude at time t. During fine-tuning we use \u03bb\u2032(t) = 1/2\u00b52t and \u03bb\n\u2032(t) = t/\u00b52t , to give more emphasis to the bootstrapping examples at high noise levels. Note that these different weightings can also be seen as sampling t from different beta distributions while always normalizing by the expected score.\nThere are a few nuances to building and using the buffer B. First, we resample a constant m complexes from B to train the score model at every step. Motivated by the intuition that higher-score poses should be sampled more frequently, the poses are sampled from the distribution p(x, d) \u223c 1 Z exp[c\u03d5(x, d)] where Z is a normalization constant. Additionally, we enforce an upperbound on the number of samples per complex to encourage diversity across complexes in B by only keeping the n highest scoring poses per protein/ligand pair. Moreover, as alluded to in 4.3, updating the score model with samples from the buffer may cause it to lose information about how to perform steps with t < tmin and/or learn to sample from pathological spaces of the confidence model, where the confidence model assigns high scores to poses distant from the ground truth. Therefore, at each training step, we also include p randomly sampled complexes from MOAD training set in addition to complexes sampled from B. In our scheme, k, p, q, m, and n are hyperparameters selected through testing the method on the validation dataset."
        },
        {
            "heading": "C.2 MODEL ARCHITECTURE",
            "text": "To enable the efficient execution of the CONFIDENCE BOOTSTRAPPING iterative training routine, we make a number of changes to the architecture of DIFFDOCK\u2019s score (obtaining what we refer to as DIFFDOCK-S) and confidence models.\nScore model We speed up the architecture and execution of DIFFDOCK\u2019s score model in a number of ways. First, we add a number of embedding message-passing layers which, unlike the crossattentional interaction layers of DIFFDOCK, independently process the protein and ligand structures. This allows us to increase the depth of the architecture with very little added runtime. In fact, due to the significantly higher number of nodes, the main complexity of the embedding layer lies in the protein component. However, under the rigid protein assumption, the structure is the same across all the different samples and diffusion steps. Therefore, the protein embedding can be computed only once resulting in minor computational overhead. Further, we limit the order of the spherical harmonics used to represent the edges to one (with minor loss in accuracy), and we batch and move the whole reverse diffusion process to GPU to improve parallelization and memory transfers.\nConfidence model We also change a number of design choices in the confidence model to make it more efficient and better suited for CONFIDENCE BOOTSTRAPPING. The first choice is to force the model to reason about local interactions, as the affinity of a ligand to a particular pose is largely a local property. We achieve this by simply feeding to the model the receptor structures of only the amino acids whose C-alpha is within 20A\u030a of any of the predicted ligand atoms\u2019 positions.\nFurther, during the binary classification training of the confidence model, we try to remove the bias of the model against hard targets by balancing the proportion of positive and negative examples the model is trained over. When not possible with sampled poses (because the model only samples negatives), we use the so-called conformer-matched ligand poses [Jing et al., 2022] as positive examples. Moreover, to make the transition smoother and reduce the perceived variance in the labels, we separate the positive (poses with RMSD<2A\u030a) and negative classes (>4A\u030a)4. Finally, we supervise the model not only to predict the label of the whole ligand but also that of each individual atom (supervised on their individual distance to the ground truth pose)."
        },
        {
            "heading": "C.3 EXPERIMENTAL DETAILS",
            "text": "Setup. We tested CONFIDENCE BOOTSTRAPPING on DOCKGEN-clusters, a subset of DOCKGEN containing 8 clusters with at least 6 complexes each. For every cluster in DOCKGEN-clusters, we\n4We note that concurrent work Masters et al. [2023] also applies this strategy.\nstarted with the same pretrained diffusion and confidence models, and ran 60 iterations of CONFIDENCE BOOTSTRAPPING, where each iteration contained a rollout step and an update step with 200 SGD updates. We did two evaluation runs with the same hyperparameters and reported the averaged results. To evaluate the generated complexes, we computed the symmetric-corrected RMSD of sPyRMSD [Meli & Biggin, 2020] between the predicted and the crystal ligand atoms. We reported the percentage of top-ranked predictions that have an RMSD less than 2A\u030a, a metric generally considered to be representative of getting the correct pose [Alhossary et al., 2015; Hassan et al., 2017; McNutt et al., 2021; Corso et al., 2022].\nHyperparameters. In our experiments, we chose confidence cutoff k = \u22124, number of complexes sampled from PDBBind p = 100, number of complexes sampled from the buffer m = 100, number of inference samples q = 32, and maximum samples per protein/ligand pair n = 20. At the rollout step, we ran 4 inference steps each with 8 samples and compute the RMSD less than 2A\u030a metric with the top-ranked pose from each inference step to reduce variance in the reported metric. Additionally, we set number of inference samples to 80 for the first bootstrapping inference step to fill the initially empty buffer. These parameters were selected by testing the method on the 5 DOCKGEN validation clusters."
        },
        {
            "heading": "C.4 COMPUTATIONAL COST",
            "text": "The runtime cost of our fine-tuning approach depends on the number of complexes sampled and the number of gradient update steps. In our experiment, on average we sample 320 complexes in the cluster for every 200 gradient update steps (with batch size of 5). We interleave these two operations 60 times. With these parameters and training on one NVIDIA A6000 GPU, the average run time is 8 hours.\nOne can try compare this cost with for example running GNINA (here we assume the default version without extra search exhaustiveness), which generalizes better without retraining but it is considerably slower and cannot be finetuned on specific domains. Assuming the methods (GNINA and DiffDock w/ confidence bootstrapping) work similarly, then one can ask in which setting would it be faster to run either one of them. It takes 232 inference complexes for DiffDock to ammortize the cost of the finetuning and from then onwards it can provide significant runtime improvements. As many screening campaigns require significantly more than 232 complexes, we believe that the idea of finetuning a docking model to the specific target class of interest may prove a useful feature in the future."
        },
        {
            "heading": "D CONFIDENCE BOOTSTRAPPING AND REINFORCEMENT LEARNING",
            "text": "In the section we discuss the connection of CONFIDENCE BOOTSTRAPPING to Reinforcement Learning (RL). Our objective can be approximately formulated as finding some score model parameters \u03b8\u2217 to maximize the confidence conditioned on a cluster, and can be written as\n\u03b8\u2217 = argmax \u03b8 J\u03b8\nwhere J\u03b8 := Ep\u03b8(x;d)[c\u03d5(x; d)]. (1)\nThis objective can be directly formulated as the RL objective, where the reward function is the confidence model c\u03d5 and the policy is the diffusion model p\u03b8(x; d). Then, our method can be seen as loosely related to the policy gradient method, where the gradient of Equation 1 can be written as\n\u2207\u03b8J\u03b8 = \u2207\u03b8Ep\u03b8(x;d)[c\u03d5(x; d)] = Ep\u03b8(x;d)[\u2207\u03b8 log p\u03b8(x; d)c\u03d5(x; d)]\n\u2248 1 n n\u2211 i=1 \u2207\u03b8 log p\u03b8(xi; d)c\u03d5(xi; d)\nIn the policy gradient method, n samples are collected to approximate the expected value, which corresponds to the number of poses we sample per complex during training. However, computing \u2207 log p\u03b8(xi; d) is intractable for diffusion models. Instead, we modify the reward to exp(c\u03d5(x; d)) and the objective to:\n\u03b8\u2217 = argmax \u03b8 Ep\u03b8(x;d)[exp(c\u03d5(x; d)) log p\u03b8(x)]\n= argmin \u03b8 Ep\u03b8(x;d) exp(c\u03d5(x;d))[\u2212 log p\u03b8(x)]\n= argmin \u03b8 Ep\u03b8i,\u03d5(x,d)[\u2212 log p\u03b8(x)]\nAgain this cannot be estimated directly but we can use the denoising score matching loss with p\u03b8i,\u03d5(x, d) as our data distribution to derive an upper bound that can be optimized [Song & Ermon, 2019]:\nEp\u03b8i,\u03d5(x,d)[\u2212 log p\u03b8(x)] \u2264 JDSM (\u03b8) + C\nwhere C is a constant that does not depend on \u03b8 and JDSM (\u03b8) is the denoising score matching loss.\nAvoiding overoptimization Note that unlike traditional RL problems we not only have the (denoising score matching) loss based on the reward from our confidence model, but we also keep the loss component that came from our training set optimization. While the RL objective is to directly maximize reward/confidence, we also want to prevent the model from overfitting into pathological spaces of the confidence model (where the confidence model gives high confidence for bad poses), aka \u201coveroptimization\u201d, which is why we included the real samples from training set.\nRL in docking Reinforcement learning has been applied in the past for the docking task, for example, Wang et al. [2022] uses it for protein-ligand docking while Aderinwale et al. [2022] applies it to multimeric protein docking. These works have two strong differences with our approach: (1) RL is used to optimize the pose at inference time for a specific complex not to train/fine-tune a model (2) the specific methodologies used are very different from the idea of CONFIDENCE BOOTSTRAPPING."
        },
        {
            "heading": "E ADDITIONAL EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "E.1 POSEBUSTERS BENCHMARK",
            "text": "We report in Table 2 the results of DIFFDOCK-L on the PoseBusters benchmark test set compared to the recent ROSETTAFOLD-ALLATOM [Krishna et al., 2023] and all the methods reported by Buttenschoen et al. [2024]: GOLD [Jones et al., 1997], VINA [Forli et al., 2016], DEEPDOCK [Me\u0301ndezLucio et al., 2021], UNI-MOL [Zhou et al., 2023], EQUIBIND [Sta\u0308rk et al., 2022], TANKBIND [Lu et al., 2022] and DIFFDOCK [Corso et al., 2022]. Even on this benchmark DIFFDOCK-L performs best among blind docking methods."
        },
        {
            "heading": "E.2 CONFIDENCE BOOTSTRAPPING ORACLE EXPERIMENTS",
            "text": "In a separate experiment, we tested CONFIDENCE BOOTSTRAPPING with \u201coracle\u201d confidence predictions. The oracle confidence predictor is a monotonic transformation of the true RMSD between the ground truth pose and the predicted pose: c\u03d5(x, d) = \u22124 tanh ( 2 3RMSD(x,x \u2217)\u2212 2 ) . Note that this is not a practical setting as we would not have access to the ground truth poses x\u2217 in real applications. However, this is an illustrative experiment establishing an upperbound on the performance gains achievable through CONFIDENCE BOOTSTRAPPING with a \u201cperfect\u201d confidence model (Figure 7)."
        },
        {
            "heading": "E.3 CONFIDENCE BOOTSTRAPPING ABLATION STUDIES",
            "text": "To better understand the benefits of different components of CONFIDENCE BOOTSTRAPPING, we conducted ablation experiments and report the ablation results (Figure 8) on the DOCKGEN validation dataset. This validation dataset is selected by choosing all clusters with four or more complexes in DOCKGEN, excluding those in DOCKGEN-clusters. We further exclude one cluster where DIFFDOCK-L already achieves higher than 80% RMSD less than 2, and another where an insufficient number of samples pass the confidence threshold, resulting in 7 clusters. Here, we provide a description of each ablation experiment.\nTemperature = 0 Instead of sampling from the buffer with p \u221d exp[c\u03d5(x, d)], which can be interpreted as p \u221d exp[kc\u03d5(x, d)] with temperature k = 1, we investigate the effects of drawing buffer samples with uniform probability (t = 0).\nt sampling We change the distribution of t \u2208 [0, 1], the amount of noise added to each sample during training time. Heuristically, we would prefer to sample higher values of t more often to finetune the earlier stages of the reverse diffusion process, guiding the model into finding the right pocket. t is sampled from a beta distribution Beta(\u03b1, \u03b2). In addition, samples from ptrain use a different value of \u03b1 and \u03b2 from buffer samples. In CONFIDENCE BOOTSTRAPPING, we have \u03b1 = 2, \u03b2 = 1 for buffer samples, and \u03b1 = 1, \u03b2 = 1 for ptrain samples, with tmin = 0. We experiment with different variations of these default parameters (Figure 8).\nRemoving samples from ptrain In this experiment, we remove ptrain complexes (real samples) from the update steps of the diffusion model, using only samples from the buffer. These complexes were initially added to avoid the overoptimization problem as discussed previously, and removing them, unsurprisingly, decreases the performance of our method (though our method still significantly outperforms the baseline DiffDock)."
        }
    ],
    "year": 2024
}