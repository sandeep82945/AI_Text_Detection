{
    "abstractText": "Federated optimization studies the problem of collaborative function optimization among multiple clients (e.g. mobile devices or organizations) under the coordination of a central server. Since the data is collected separately by each client and always remains decentralized, federated optimization preserves data privacy and allows for large-scale computing, which makes it a promising decentralized machine learning paradigm. Though it is often deployed for tasks that are online in nature, e.g., next-word prediction on keyboard apps, most works formulate it as an offline problem. The few exceptions that consider federated bandit optimization are limited to very simplistic function classes, e.g., linear, generalized linear, or non-parametric function class with bounded RKHS norm, which severely hinders its practical usage. In this paper, we propose a new algorithm, named Fed-GOUCB, for federated bandit optimization with generic non-linear objective function. Under some mild conditions, we rigorously prove that Fed-GO-UCB is able to achieve sub-linear rate for both cumulative regret and communication cost. At the heart of our theoretical analysis are distributed regression oracle and individual confidence set construction, which can be of independent interests. Empirical evaluations also demonstrate the effectiveness of the proposed algorithm.",
    "authors": [],
    "id": "SP:a15359742864d40de3ba255a05dd0cc00b88613f",
    "references": [
        {
            "authors": [
                "Yasin Abbasi-yadkori",
                "D\u00e1vid P\u00e1l",
                "Csaba Szepesv\u00e1ri"
            ],
            "title": "Improved algorithms for linear stochastic bandits",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2011
        },
        {
            "authors": [
                "Zhongxiang Dai",
                "Yao Shu",
                "Arun Verma",
                "Flint Xiaofeng Fan",
                "Bryan Kian Hsiang Low",
                "Patrick Jaillet"
            ],
            "title": "Federated neural bandit",
            "venue": "arXiv preprint arXiv:2205.14309,",
            "year": 2022
        },
        {
            "authors": [
                "Yihan Du",
                "Wei Chen",
                "Yuko Yuroki",
                "Longbo Huang"
            ],
            "title": "Collaborative pure exploration in kernel bandit",
            "venue": "arXiv preprint arXiv:2110.15771,",
            "year": 2021
        },
        {
            "authors": [
                "Dheeru Dua",
                "Casey Graff"
            ],
            "title": "UCI machine learning repository, 2017",
            "venue": "URL http://archive. ics.uci.edu/ml",
            "year": 2017
        },
        {
            "authors": [
                "Abhimanyu Dubey",
                "Alex Pentland"
            ],
            "title": "Provably efficient cooperative multi-agent reinforcement learning with function approximation",
            "venue": "arXiv preprint arXiv:2103.04972,",
            "year": 2021
        },
        {
            "authors": [
                "Abhimanyu Dubey",
                "AlexSandy\u2019 Pentland"
            ],
            "title": "Differentially-private federated linear bandits",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "David Eriksson",
                "Michael Pearce",
                "Jacob Gardner",
                "Ryan D Turner",
                "Matthias Poloczek"
            ],
            "title": "Scalable global optimization via local bayesian optimization. In Advances in neural information processing systems",
            "year": 2019
        },
        {
            "authors": [
                "Sarah Filippi",
                "Olivier Cappe",
                "Aur\u00e9lien Garivier",
                "Csaba Szepesv\u00e1ri"
            ],
            "title": "Parametric bandits: The generalized linear case",
            "venue": "In Advances in Neural Information Processing Systems",
            "year": 2010
        },
        {
            "authors": [
                "Dylan Foster",
                "Alexander Rakhlin"
            ],
            "title": "Beyond ucb: Optimal and efficient contextual bandits with regression oracles",
            "venue": "In International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Peter I Frazier"
            ],
            "title": "A tutorial on bayesian optimization",
            "venue": "arXiv preprint arXiv:1807.02811,",
            "year": 2018
        },
        {
            "authors": [
                "Peter I Frazier",
                "Jialei Wang"
            ],
            "title": "Bayesian optimization for materials design",
            "venue": "In Information science for materials discovery and design,",
            "year": 2016
        },
        {
            "authors": [
                "Jemin George",
                "Prudhvi Gurram"
            ],
            "title": "Distributed stochastic gradient descent with event-triggered communication",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "Elad Hazan",
                "Adam Klivans",
                "Yang Yuan"
            ],
            "title": "Hyperparameter optimization: a spectral approach",
            "venue": "In International Conference on Learning Representations,",
            "year": 2018
        },
        {
            "authors": [
                "Jiafan He",
                "Tianhao Wang",
                "Yifei Min",
                "Quanquan Gu"
            ],
            "title": "A simple and provably efficient algorithm for asynchronous federated contextual linear bandits",
            "venue": "arXiv preprint arXiv:2207.03106,",
            "year": 2022
        },
        {
            "authors": [
                "Eshcar Hillel",
                "Zohar S Karnin",
                "Tomer Koren",
                "Ronny Lempel",
                "Oren Somekh"
            ],
            "title": "Distributed exploration in multi-armed bandits",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2013
        },
        {
            "authors": [
                "Ruiquan Huang",
                "Weiqiang Wu",
                "Jing Yang",
                "Cong Shen"
            ],
            "title": "Federated linear contextual bandits",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Donald R Jones",
                "Matthias Schonlau",
                "William J Welch"
            ],
            "title": "Efficient global optimization of expensive black-box functions",
            "venue": "Journal of Global Optimization,",
            "year": 1998
        },
        {
            "authors": [
                "Peter Kairouz",
                "H Brendan McMahan",
                "Brendan Avent",
                "Aur\u00e9lien Bellet",
                "Mehdi Bennis",
                "Arjun Nitin Bhagoji",
                "Keith Bonawitz",
                "Zachary Charles",
                "Graham Cormode",
                "Rachel Cummings"
            ],
            "title": "Advances and open problems in federated learning",
            "venue": "arXiv preprint arXiv:1912.04977,",
            "year": 2019
        },
        {
            "authors": [
                "Kirthevasan Kandasamy",
                "Karun Raju Vysyaraju",
                "Willie Neiswanger",
                "Biswajit Paria",
                "Christopher R. Collins",
                "Jeff Schneider",
                "Barnabas Poczos",
                "Eric P. Xing"
            ],
            "title": "Tuning hyperparameters without grad students: Scalable and robust bayesian optimisation with dragonfly",
            "venue": "Journal of Machine Learning Research,",
            "year": 2020
        },
        {
            "authors": [
                "Sai Praneeth Karimireddy",
                "Satyen Kale",
                "Mehryar Mohri",
                "Sashank Reddi",
                "Sebastian Stich",
                "Ananda Theertha Suresh"
            ],
            "title": "Scaffold: Stochastic controlled averaging for federated learning",
            "venue": "In International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Solmaz S Kia",
                "Jorge Cort\u00e9s",
                "Sonia"
            ],
            "title": "Mart\u0131\u0301nez. Distributed convex optimization via continuoustime coordination algorithms with discrete-time communication",
            "year": 2015
        },
        {
            "authors": [
                "Nathan Korda",
                "Balazs Szorenyi",
                "Shuai Li"
            ],
            "title": "Distributed clustering of linear bandits in peer to peer networks",
            "venue": "In International Conference on Machine Learning,",
            "year": 2016
        },
        {
            "authors": [
                "Harold J Kushner"
            ],
            "title": "A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise",
            "venue": "Journal of Basic Engineering,",
            "year": 1964
        },
        {
            "authors": [
                "Chuanhao Li",
                "Hongning Wang"
            ],
            "title": "Asynchronous upper confidence bound algorithms for federated linear bandits",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2022
        },
        {
            "authors": [
                "Chuanhao Li",
                "Hongning Wang"
            ],
            "title": "Communication efficient federated learning for generalized linear bandits",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Chuanhao Li",
                "Huazheng Wang",
                "Mengdi Wang",
                "Hongning Wang"
            ],
            "title": "Communication efficient distributed learning for kernelized contextual bandits",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Chuanhao Li",
                "Huazheng Wang",
                "Mengdi Wang",
                "Hongning Wang"
            ],
            "title": "Learning kernelized contextual bandits in a distributed and asynchronous environment",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Chuanhao Li",
                "Huazheng Wang",
                "Mengdi Wang",
                "Hongning Wang"
            ],
            "title": "Learning kernelized contextual bandits in a distributed and asynchronous environment",
            "venue": "In International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Lihong Li",
                "Wei Chu",
                "John Langford",
                "Robert E Schapire"
            ],
            "title": "A contextual-bandit approach to personalized news article recommendation",
            "venue": "In Proceedings of the 19th international conference on World wide web,",
            "year": 2010
        },
        {
            "authors": [
                "Xiang Li",
                "Kaixuan Huang",
                "Wenhao Yang",
                "Shusen Wang",
                "Zhihua Zhang"
            ],
            "title": "On the convergence of fedavg on non-iid data",
            "venue": "arXiv preprint arXiv:1907.02189,",
            "year": 2019
        },
        {
            "authors": [
                "Yingkai Li",
                "Yining Wang",
                "Yuan Zhou"
            ],
            "title": "Nearly minimax-optimal regret for linearly parameterized bandits",
            "venue": "In Annual Conference on Learning Theory,",
            "year": 2019
        },
        {
            "authors": [
                "Chong Liu",
                "Yu-Xiang Wang"
            ],
            "title": "Global optimization with parametric function approximation",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Kanak Mahadik",
                "Qingyun Wu",
                "Shuai Li",
                "Amit Sabne"
            ],
            "title": "Fast distributed bandits for online recommendation systems",
            "venue": "In Proceedings of the 34th ACM international conference on supercomputing,",
            "year": 2020
        },
        {
            "authors": [
                "Brendan McMahan",
                "Eider Moore",
                "Daniel Ramage",
                "Seth Hampson",
                "Blaise Aguera y Arcas"
            ],
            "title": "Communication-efficient learning of deep networks from decentralized data",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2017
        },
        {
            "authors": [
                "Aritra Mitra",
                "Rayana Jaafar",
                "George J Pappas",
                "Hamed Hassani"
            ],
            "title": "Achieving linear convergence in federated learning under objective and systems heterogeneity",
            "venue": "arXiv preprint arXiv:2102.07053,",
            "year": 2021
        },
        {
            "authors": [
                "Nathan Nakamura",
                "Jason Seepaul",
                "Joseph B Kadane",
                "B Reeja-Jayan"
            ],
            "title": "Design for lowtemperature microwave-assisted crystallization of ceramic thin films",
            "venue": "Applied Stochastic Models in Business and Industry,",
            "year": 2017
        },
        {
            "authors": [
                "Reese Pathak",
                "Martin J Wainwright"
            ],
            "title": "Fedsplit: an algorithmic framework for fast federated optimization",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Maxim Raginsky",
                "Alexander Rakhlin",
                "Matus Telgarsky"
            ],
            "title": "Non-convex learning via stochastic gradient langevin dynamics: a nonasymptotic analysis",
            "venue": "In Conference on Learning Theory,",
            "year": 2017
        },
        {
            "authors": [
                "Johannes Schmidt-Hieber"
            ],
            "title": "Nonparametric regression using deep neural networks with relu activation function",
            "venue": "Annals of Statistics,",
            "year": 2020
        },
        {
            "authors": [
                "Bobak Shahriari",
                "Kevin Swersky",
                "Ziyu Wang",
                "Ryan P Adams",
                "Nando De Freitas"
            ],
            "title": "Taking the human out of the loop: A review of bayesian optimization",
            "venue": "Proceedings of the IEEE,",
            "year": 2015
        },
        {
            "authors": [
                "Weiwei Shen",
                "Jun Wang",
                "Yu-Gang Jiang",
                "Hongyuan Zha"
            ],
            "title": "Portfolio choices with orthogonal bandit learning",
            "venue": "In Twenty-fourth international joint conference on artificial intelligence,",
            "year": 2015
        },
        {
            "authors": [
                "Niranjan Srinivas",
                "Andreas Krause",
                "Sham Kakade",
                "Matthias Seeger"
            ],
            "title": "Gaussian process optimization in the bandit setting: no regret and experimental design",
            "venue": "In International Conference on Machine Learning,",
            "year": 2010
        },
        {
            "authors": [
                "Chao Tao",
                "Qin Zhang",
                "Yuan Zhou"
            ],
            "title": "Collaborative learning with limited interaction: Tight bounds for distributed exploration in multi-armed bandits",
            "venue": "In Annual Symposium on Foundations of Computer Science,",
            "year": 2019
        },
        {
            "authors": [
                "Sof\u0131\u0301a S Villar",
                "Jack Bowden",
                "James Wason"
            ],
            "title": "Multi-armed bandit models for the optimal design of clinical trials: benefits and challenges",
            "venue": "Statistical science: a review journal of the Institute of Mathematical Statistics,",
            "year": 2015
        },
        {
            "authors": [
                "Yuanhao Wang",
                "Jiachen Hu",
                "Xiaoyu Chen",
                "Liwei Wang"
            ],
            "title": "Distributed bandit learning: Nearoptimal regret with efficient communication",
            "venue": "In International Conference on Learning Representations,",
            "year": 2020
        },
        {
            "authors": [
                "Pan Xu",
                "Jinghui Chen",
                "Difan Zou",
                "Quanquan Gu"
            ],
            "title": "Global convergence of langevin dynamics based algorithms for nonconvex optimization",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2018
        },
        {
            "authors": [
                "Qiang Yang",
                "Yang Liu",
                "Tianjian Chen",
                "Yongxin Tong"
            ],
            "title": "Federated machine learning: Concept and applications",
            "venue": "ACM Transactions on Intelligent Systems and Technology,",
            "year": 2019
        },
        {
            "authors": [
                "Xinlei Yi",
                "Lisha Yao",
                "Tao Yang",
                "Jemin George",
                "Karl H Johansson"
            ],
            "title": "Distributed optimization for second-order multi-agent systems with dynamic event-triggered communication",
            "venue": "IEEE Conference on Decision and Control (CDC),",
            "year": 2018
        },
        {
            "authors": [
                "Yuchen Zhang",
                "Percy Liang",
                "Moses Charikar"
            ],
            "title": "A hitting time analysis of stochastic gradient langevin dynamics",
            "venue": "In Conference on Learning Theory,",
            "year": 2017
        },
        {
            "authors": [
                "Korda"
            ],
            "title": "However, both works only tried to reduce per-round communication, and thus the communication cost is still linear over time. Two follow-up studies considered the setting where all clients solve a common linear bandit problem with time-varying arm set and interact with the environment in a round-robin fashion",
            "venue": "(Wang et al.,",
            "year": 2016
        },
        {
            "authors": [
                "Wang"
            ],
            "title": "2020) considered a star-shaped network and proposed a synchronous communication protocol for all clients to exchange their sufficient statistics via the central server. Dubey & Pentland (2020) extended this synchronous protocol to differentially private LinUCB algorithms under both star-shaped and P2P network",
            "year": 2021
        },
        {
            "authors": [
                "Kia et al",
                "Yi et al",
                "George",
                "Gurram"
            ],
            "title": "2020), while for federated bandit learning, triggering event needs to measure change in the volume of the confidence set, i.e., uncertainty in the problem space (Wang et al., 2020; Li & Wang, 2022a). B.2 SUMMARY OF EXISTING FEDERATED BANDIT ALGORITHMS Here we provide a summary of existing works in federated bandit optimization",
            "year": 2022
        },
        {
            "authors": [
                "C T"
            ],
            "title": "Set \u03a3t,it as in equation 6 and suppose Assumptions",
            "year": 2023
        },
        {
            "authors": [
                "Dubey",
                "Pentland"
            ],
            "title": "2020), while allowing for a much wider choices of models. The main difference is that, the regret of their work depends on the matrix constructed using context vectors xs for s",
            "year": 2020
        },
        {
            "authors": [
                "Liu",
                "Wang"
            ],
            "title": "2023), we are using a different way of constructing the confidence ellipsoid, which is given in Lemma 8. Their Lemma 5.4, which is given below, still holds, because it only requires Ballt\u22121,it to be a valid confidence set, and that Assumption 2 holds. Lemma 14 (Instantaneous regret bound [Lemma 5.4 of Liu & Wang (2023)). Under the same condition as Lemma 8,in Phase II of Algorithm 1, for all t \u2208 [NT",
            "year": 2023
        },
        {
            "authors": [
                "Wang"
            ],
            "title": "2022b), for the cumulative regret analysis in Phase II, we decompose P epochs into good and bad epochs, and then analyze them separately. Specifically, consider an imaginary centralized agent",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Federated optimization is a machine learning method that enables collaborative model estimation over decentralized dataset without data sharing (McMahan et al., 2017; Kairouz et al., 2019). It allows the creation of a shared global model with personal data remaining in local sites instead of being transferred to a central location, and thus reduces the risks of personal data breaches. While the main focus of the state-of-the-art federated optimization is on the offline setting, where the objective is to obtain a good model estimation based on fixed dataset (Li et al., 2019a; Mitra et al., 2021), several recent research efforts have been made to extend federated optimization to the online setting, i.e., federated bandit optimization (Wang et al., 2020; Li & Wang, 2022b; Li et al., 2022a).\nCompared with its offline counterpart, federated bandit optimization is characterized by its online interactions with the environment, which continuously provides new data points to the clients over time. The objective of the clients is to collaboratively minimize cumulative regret, which measures how fast they can find the optimal decision, as well as the quality of decisions made during the trialand-error learning process. This new paradigm greatly improves sample efficiency, as the clients not only collaborate on model estimation, but also actively select informative data points to evaluate in a coordinated manner. Moreover, compared with the standard Bayesian optimization approach (Shahriari et al., 2015), the improved data protection of federated bandit optimization makes it a better choice for applications involving sensitive data, such as recommender systems (Li et al., 2010), clinical trials (Villar et al., 2015) and sequential portfolio selection (Shen et al., 2015). For example, medical data such as disease symptoms and medical reports are very sensitive and private, and are typically stored in isolated medical centers and hospitals (Yang et al., 2019). Federated bandit optimization offers a principled way for different medical institutions to jointly solve optimization problems for smart healthcare applications, while ensuring privacy and communication efficiency.\nHowever, despite these potential benefits and the compelling theoretical guarantees, prior works in this direction are limited to very restrictive function classes, e.g., linear (Wang et al., 2020; Li & Wang, 2022a; He et al., 2022), generalized linear (Li & Wang, 2022b), and non-parametric function\nclass with bounded RKHS norm (Li et al., 2022a; 2023; Du et al., 2021), which limits their potential in practical scenarios that typically require more powerful tools in nonlinear modeling, e.g. neural networks. The main challenges in bridging this gap come from two aspects. First, different from offline federated optimization, federated bandit optimization needs to efficiently explore the decision space by actively picking data points to evaluate. This requires a careful construction of confidence sets for the unknown optimal model parameter (Abbasi-yadkori et al., 2011), which is challenging for generic nonlinear functions. Second, for clients to collaboratively estimate confidence sets, occasional communications are required to aggregate their local learning parameters as new data points are collected over time. Prior works consider simple function classes (Wang et al., 2020; Li & Wang, 2022a), so efficient communication can be realized by directly aggregating local sufficient statistics for the closed-form model estimation. However, generic non-linear function places a much higher burden on the communication cost, as iterative optimization procedure is required.\nTo address these challenges, we propose the Federated Global Optimization with Upper Confidence Bound (Fed-GO-UCB) algorithm, as illustrated in Figure 1. Specifically, Fed-GO-UCB has two phases: Phase I does uniform exploration to sufficiently explore the unknown function; and Phase II does optimistic exploration to let N clients jointly optimize the function. All clients separately choose which points to evaluate, and only share statistics summarizing their local data points with the central server. Details of Fed-GO-UCB are presented in Section 4.1.\nTechnical novelties. Our core technique to address the aforementioned challenges is a novel confidence sets construction that works for generic nonlinear functions, and more importantly, can be updated communication efficiently during federated bandit optimization. Our construction is motivated by Liu & Wang (2023), with non-trivial extensions tailored to federated bandit setting. Specifically, the statistics used for function approximation in Liu & Wang (2023) is computed based on a single sequence of continuously updated models, but in federated bandits, each client has a different sequence of locally updated models. Direct aggregation of such local statistics does not necessarily lead to valid confidence sets. Instead, we propose a new approximation procedure, such that all statistics are computed based on the same fixed model shared by all clients, which is denoted by w\u03020. With improved analysis, we show that valid confidence sets can still be constructed. More importantly, this allows direct aggregation of statistics from different clients, so that communication strategies proposed in linear settings can be utilized to reduce frequency of communications. Over the entire horizon, only the estimation of w\u03020 at the end of Phase I requires iterative optimization. To further control the communication cost it incurs, we show that w\u03020 only needs to be an O(1/ \u221a NT )- approximation to the empirical risk minimizer that is required in the analysis of Liu & Wang (2023), and adopt a distributed implementation of Gradient Langevin Dynamics (GLD) for its optimization.\nContributions. Our main contributions can be summarized as follows.\n1. To the best of our knowledge, Fed-GO-UCB is the first federated bandit algorithm for generic non-linear function optimization with provable communication efficiency, making it highly deployment-efficient.\n2. Under realizable assumption and some other mild conditions, we prove that cumulative regret of Fed-GO-UCB is O\u0303( \u221a NT ) and its communication cost is O\u0303(N1.5 \u221a T ). Both of\ntwo results are sublinear in time horizon T . 3. Our empirical evaluations show Fed-GO-UCB outperforms existing federated bandit algo-\nrithms, which demonstrates the effectiveness of generic non-linear function optimization,"
        },
        {
            "heading": "2 RELATED WORK",
            "text": "Centralized global optimization Most work on global optimization studies the centralized setting where all data points are available on a single machine. Its applications include hyperparameter tuning for deep neural networks (Hazan et al., 2018; Kandasamy et al., 2020) and materials design (Nakamura et al., 2017; Frazier & Wang, 2016). The most popular approach to this problem is Bayesian optimization (BO) (Shahriari et al., 2015; Frazier, 2018), which is closely related to bandit problems (Li et al., 2019b; Foster & Rakhlin, 2020). BO typically assumes the unknown objective function is drawn from some Gaussian Processes (GP). The learner sequentially choose points to evaluate and then improve its estimation via posterior update. Classical BO algorithms include GPUCB (Srinivas et al., 2010), GP-EI (Jones et al., 1998), and GP-PI (Kushner, 1964). To improve heterogeneous modeling of the objective function and mitigate over-exploration, Trust region BO (Eriksson et al., 2019) that uses multiple local optimization runs is proposed. In this line of research, the closes work to ours is Liu & Wang (2023), which also considers global approximation of generic nonlinear functions, though it\u2019s not suitable for federated setting as discussed in Section 1.\nFederated bandit optimization Another closely related line of research is federated/distributed bandits, where multiple agents collaborate in pure exploration (Hillel et al., 2013; Tao et al., 2019; Du et al., 2021), or regret minimization (Wang et al., 2020; Li & Wang, 2022a;b). However, most of these works make linear model assumptions, and thus the clients can efficiently collaborate by transferring the O(d2x) sufficient statistics for closed-form model estimation, where dx is input data dimension. The closest works to ours are Wang et al. (2020); Dubey & Pentland (2020); Li & Wang (2022a;b), which uses event-triggered communication strategies to obtain sub-linear communication cost over time, i.e., communication only happens when sufficient amount of new data has been collected. There is also recent work by Dai et al. (2022) that studies federated bandits with neural function approximation, but it still relies on GP with a Neural Tangent Kernel in their analysis, which is intrinsically linear. More importantly, this analysis assumes the width of the neural network is much larger than the number of samples, while our results do not require such over-parameterization."
        },
        {
            "heading": "3 PRELIMINARIES",
            "text": "We consider the problem of finding a global maximum solution to an unknown non-linear black-box function f , i.e.,\nx\u2217 = argmax x\u2208X f(x).\nDifferent from previous works, we consider a decentralized system of 1) N clients that selects data points to evaluate, and 2) a central server that coordinates the communication among the clients. The clients cannot directly communicate with each other, but only with the central server, i.e., a star-shaped communication network as shown in Figure 1. In each round, N clients interact with the unknown function f in a round-robin manner, for a total number of T rounds, so the total number of interactions is NT . Let [N ] denote the integer set {1, 2, ..., N}. Specifically, at round l \u2208 [T ], each client i \u2208 [N ] selects a point xt from the set X , and has a zeroth-order noisy function observation:\nyt = f(xt) + \u03b7t \u2208 R, (1) where the subscript t := N(l \u2212 1) + i indicates this is the t-th interaction between the system and the function f , i.e., the t-th time function f is evaluated at a selected point xt, and \u03b7t is independent, zero-mean, \u03c3-sub-Gaussian noise, for t \u2208 [NT ].\nWe adopt the classical definition of cumulative regret to evaluate the algorithm performance. It is defined as RNT = \u2211NT t=1 f(x\n\u2217) \u2212 f(xt) for NT interactions. Following Wang et al. (2020), we define the communication cost CNT as the total amount of real numbers being transferred across the system during the NT interactions with function f .\nLet U denote uniform distribution. W.l.o.g., let X \u2286 [0, 1]dx and Y \u2282 R denote the domain and range of unknown function f . We are working with a parametric function class F := {fw : X \u2192 Y|w \u2208 W} to approximate f where the parametric function class is controlled by the parameter space W . For a parametric function fw(x), let \u2207fw(x) denote the gradient taken w.r.t. x and \u2207fx(w) denote the gradient taken w.r.t. w. We use it \u2208 [N ] as the index of the client that evaluates point xt at time step t. We denote the sequence of time steps corresponding to data points that have been evaluated by client i up to time t as Dlt,i = {1 \u2264 s \u2264 t : is = i} for t = 1, 2, . . . , NT . In addition, we denote the sequence of time steps corresponding to the data points that have been used to update client i\u2019s local model as Dt,i, which include both data points collected locally and those received from the server. If client i never receives any communication from the server, Dt,i = Dlt,i; otherwise, Dlt,i \u2282 Dt,i \u2286 [t]. Moreover, when each new data point evaluated by any client in the system is readily communicated to all the other clients, we recover the centralized setting, i.e., Dt,i = [t],\u2200i, t. For completeness, we list all notations in Appendix A. Here we list all assumptions that we use throughout this paper. The first two assumptions are pretty standard and the last assumption comes from previous works. Assumption 1 (Realizabilty). There exists w\u22c6 \u2208 W such that the unknown objective function f = fw\u22c6 . Also, assume W \u2282 [0, 1]dw . This is w.l.o.g. for any compact W . Assumption 2 (Bounded, differentiable and smooth function approximation). There exist constants F,Cg, Ch > 0, s.t. |fx(w)| \u2264 F , \u2225\u2207fx(w)\u22252 \u2264 Cg , and \u2225\u22072fx(w)\u2225op \u2264 Ch, \u2200x \u2208 X , w \u2208 W . Assumption 3 (Geometric conditions on the loss function (Liu & Wang, 2023; Xu et al., 2018)). L(w) = Ex\u223cU (fx(w) \u2212 fx(w\u22c6))2 satisfies (\u03c4, \u03b3)-growth condition or local \u00b5-strong convexity at w\u22c6, i.e., \u2200w \u2208 W ,\nmin {\u00b5 2 \u2225w \u2212 w\u22c6\u222522, \u03c4 2 \u2225w \u2212 w\u22c6\u2225\u03b32 } \u2264 L(w)\u2212 L(w\u22c6),\nfor constants \u00b5, \u03c4 > 0, \u00b5 < dw, 0 < \u03b3 < 2. L(w) satisfies dissipative assumption, i.e., \u2207L(w)\u22a4w \u2265 Ci\u2225w\u222522\u2212Cj for some constants Ci, Cj > 0, and a c-local self-concordance assumption at w\u22c6, i.e., (1\u2212c)2\u22072L(w\u22c6) \u2aaf \u22072L(w\u22c6) \u2aaf (1\u2212c)\u22122\u22072L(w\u22c6), \u2200w s.t. \u2225w\u2212w\u22c6\u2225\u22072L(w) \u2264 c.\nAssumption 2 implies there exists a constant \u03b6 > 0, such that \u2225\u22072L(w\u22c6)\u2225op \u2264 \u03b6. For example, it suffices to take \u03b6 = 2C2g . Assumption 3 is made on the expected loss function L w.r.t. parameter w rather than function f , and is strictly weaker than strong convexity as it only requires strong convexity in the small neighboring region around w\u2217. For w far away from w\u2217, L(w) can be highly non-convex since only growth condition needs to be satisfied. The dissipative assumption is typical for stochastic differential equation and diffusion approximation (Raginsky et al., 2017; Zhang et al., 2017). In our paper, it is only needed for the convergence analysis of Algorithm 2, and may be relaxed by adopting other non-convex optimization methods with global convergence guarantee."
        },
        {
            "heading": "4 METHODOLOGY",
            "text": ""
        },
        {
            "heading": "4.1 FED-GO-UCB ALGORITHM",
            "text": "In this paper, we develop an algorithm that allows Bayesian optimization style active queries to work for general supervised learning-based function approximation under federated optimization scheme.\nPhase I In Step 1 of Phase I, the algorithm evaluates the unknown function f at uniformly sampled points for a total number of T0 times, where T0 is chosen to be large enough such that function f can be sufficiently explored. By the end of time step T0, each client i \u2208 [N ] has collected a local dataset {(xs, ys)}s\u2208DlT0,i (by definition \u222ai\u2208[N ]D l T0,i\n= [T0]). In Step 2, we call the distributed regression oracle, denoted as Oracle, to jointly learn model parameter w\u03020, by optimizing equation 2 below.\nmin w\u2208W\nL\u0302T0(w) := 1\nT0 N\u2211 i=1 L\u0302T0,i(w), (2)\nAlgorithm 1 Fed-GO-UCB Input: Phase I length T0, Time horizon (Phase II length) NT , Oracle, number of iterations n to execute Oracle, communication threshold \u03b3, regularization weight \u03bb. Phase I (Uniform exploration)\n1: for t = 1, 2, . . . , T0 do client it \u2208 [N ] evaluates point xt \u223c U(X ), and observe yt 2: Execute Oracle (e.g., Algorithm 2) over N clients to obtain w\u03020\nPhase II (Optimistic exploration) 1: Initialize w\u0302T0,i = w\u03020, \u03a3T0,i = \u03bbI, bT0,i = 0, DT0,i = \u2205, for each client i \u2208 [N ] 2: for t = 1, . . . , NT do 3: Client it evaluates point xt = argmaxx\u2208X maxw\u2208Ballt\u22121,it fx(w) and observe yt 4: Client it updates \u03a3t,it = \u03a3t\u22121,it + \u2207fxt(w\u03020)\u2207fxt(w\u03020)\u22a4, bt,it = bt\u22121,it +\n\u2207fxt(w\u03020)(\u2207fxt(w\u03020)\u22a4w\u03020 + yt \u2212 fxt), and \u2206\u03a3t,it = \u2206\u03a3t\u22121,it + \u2207fxt(w\u03020)\u2207fxt(w\u03020)\u22a4, \u2206bt,it = \u2206bt\u22121,it +\u2207fxt(w\u03020)\u2207fxt(w\u03020)\u22a4w\u03020 + yt \u2212 fxt\n5: Client it updates w\u0302t,it by equation 5 and Ballt,it by equation 4; sets index set Dt,it = Dt\u22121,it \u222a {t} # Check whether global synchronization is triggered\n6: if ( |Dt,it | \u2212 |Dtlast,it | ) log\ndet(\u03a3t,it )\ndet(\u03a3t,it\u2212\u2206\u03a3t,it ) > \u03b3 then\n7: All clients upload {\u2206\u03a3t,i,\u2206bt,i}, and reset \u2206\u03a3t,i = 0,\u2206bt,i = 0 for i = 1, . . . , N 8: Server aggregates \u03a3t,g = \u03a3tlast,g + \u2211N i=1 \u2206\u03a3t,i, bt,g = btlast,g + \u2211N i=1 \u2206bt,i\n9: All clients download {\u03a3t,g, bt,g}, and update \u03a3t,i = \u03a3t,g, bt,i = bt,g for i = 1, . . . , N 10: Set tlast = t Output: x\u0302 \u223c U({x1, ..., xT }).\nwhere L\u0302T0,i(w) = \u2211\ns\u2208DlT0,i\n[ ys\u2212fw(x\u22a4s ) ]2 is the squared error loss on client i\u2019s local dataset. It is\nworth noting that, executing Oracle to compute the exact minimizer w\u0302\u22c60 := argminw\u2208W L\u0302T0(w) as in the prior work by Liu & Wang (2023) is unreasonable in our case, since it requires infinite number of iterations, which leads to infinite communication cost. Instead, we need to relax the requirement by allowing for an approximation error \u03f5, such that Oracle only need to output w\u03020 that satisfies\n|L\u0302T0(w\u03020)\u2212 L\u0302T0(w\u0302\u22c60)| \u2264 \u03f5. (3) Oracle can be any distributed non-convex optimization method with global convergence guarantee, i.e., we can upper bound the number of iterations required, denoted as n, to attain \u03f5, for some \u03f5 \u2265 0. Remark 4. In this paper we adopt Gradient Langevin Dynamics (GLD) based methods to optimize equation 2, which are known to have global convergence guarantee to the minimizer of non-convex objectives under smooth and dissipative assumption (Assumption 2 and Assumption 3). GLD based methods work by introducing a properly scaled isotropic Gaussian noise to the gradient descent update at each iteration, which allows them to escape local minima. Specifically, we use a distributed implementation of GLD, which is given in Algorithm 2. It requires n = O(dx\u03f5\u03bd \u00b7 log( 1 \u03f5 )) iterations to attain \u03f5 approximation (with step size set to \u03c41 \u2264 \u03f5), where \u03bd = O(e\u2212O\u0303(dx)) denotes the spectral gap of the discrete-time Markov chain generated by GLD (Theorem 3.3 of Xu et al. (2018)).\nAlgorithm 2 Distributed-GLD-Update 1: Input: total iterations n; step size \u03c41 > 0; inverse temperature parameter \u03c42 > 0; w(0) = 0 2: for k = 0, 1, . . . , n\u2212 1 do 3: Server sends w(k) to all clients, and receives local gradients \u2207L\u0302T0,i(w(k)) for i \u2208 [N ] back 4: Server aggregates local gradients \u2207L\u0302T0(w(k)) = 1T0 \u2211N i=1 \u2207L\u0302T0,i(w(k))\n5: Server randomly draws zk \u223c N (0, Id\u00d7d) 6: Server computes update w(k+1) = w(k) \u2212 \u03c41\u2207L\u0302T0(w(k)) + \u221a 2\u03c41/\u03c42zk 7: Output: w\u03020 = w(K)\nPhase II At the beginning of Phase II, the estimator w\u03020 obtained in Phase I is sent to each client, which will be used to construct the confidence sets about the unknown parameter w\u22c6. Specifically,\nat each time step t = 1, 2, . . . , NT , the confidence set constructed by client it is a ball defined as\nBallt,it := {w : \u2225w \u2212 w\u0302t,it\u22252\u03a3t,it \u2264 \u03b2t,it}, (4)\nsuch that with the choice of \u03b2t,it in Lemma 8, w \u22c6 \u2208 Ballt,it ,\u2200t with probability at least 1\u2212 \u03b4. The center of this ball is defined as\nw\u0302t,it := \u03a3 \u22121 t,it bt,it + \u03bb\u03a3 \u22121 t,it w\u03020, (5)\nwhere the matrix\n\u03a3t,it := \u03bbI+ \u2211\ns\u2208Dt,it\n\u2207fxs(w\u03020)\u2207fxs(w\u03020)\u22a4, (6)\nand vector bt,it := \u2211\ns\u2208Dt,it \u2207fxs(w\u03020)\n[ \u2207fxs(w\u03020)\u22a4w\u03020 + ys \u2212 fxs(w\u03020) ] . Note \u2207fxs(w\u03020) is the\ngradient of our parametric function taken w.r.t parameter w\u03020, rather than the gradient of the unknown objective function. The statistics \u03a3t,i, bt,i for all client i and time t are constructed using gradients w.r.t. the same model w\u03020. This is essential in federated bandit optimization, as it allows the clients to jointly construct the confidence set by directly aggregating their local updates, denoted by \u2206\u03a3t,i,\u2206bt,i. In comparison, although the statistics used to construct the confidence sets in Liu & Wang (2023) are computed based on different models and lead to tigher results, they impede collaboration among clients and cannot be directly used in our case.\nIn Phase II, exploration is conducted following \u201cOptimism in the Face of Uncertainty (OFU)\u201d principle, i.e., at time step t, client it selects point xt \u2208 X to evaluate via joint optimization over x \u2208 X and w \u2208 Ballt\u22121,it , as shown in line 3. The newly obtained data point (xt, yt) will then be used to update client it\u2019s confidence set as shown in line 4-5. In order to ensure communication efficiency during the collaborative global optimization across N clients, an event-triggered communication protocol is adopted, as shown in line 6. Intuitively, this event measures the amount of new information collected by client it since last global synchronization. If the value of LHS exceeds threshold \u03b3, another global synchronization will be triggered, such that the confidence sets of all N clients will be synchronized as shown in line 7-9. In Section 5, we will show that with proper choice of \u03b3, the total number of synchronizations can be reduced to O\u0303( \u221a N), without degrading the performance."
        },
        {
            "heading": "4.2 THEORETICAL RESULTS",
            "text": "Theorem 5 (Cumulative regret and communication cost of Fed-GO-UCB). Suppose Assumption 1, 2, and 3 hold. Let C denote a universal constant and C\u03bb denote a constant that is independent to T . Under the condition that T \u2265 Cd 2 wF 4\u03b92 N \u00b7 max { \u00b5\u03b3/(2\u2212\u03b3) \u03c42/(2\u2212\u03b3) , \u03b6\u00b5c2 }2 , where \u03b9 is the logarithmic\nterm depending on T0, Ch, and 2/\u03b4. Algorithm 1 with parameters T0 = \u221a NT , \u03bb = C\u03bb \u221a NT , \u03b3 = dwF 4T\n\u00b52N , and \u03f5 \u2264 8 C \u221a NT , has cumulative regret\nRphase I + phase II = O\u0303 (\u221a NTF + \u221a NTd3wF 4/\u00b52 +Nd4wF 4/\u00b52 ) ,\nwith probability at least 1\u2212 \u03b4, and communication cost\nCphase I + phase II = O\u0303(N 1.5 \u221a Tdwdx exp (dx) +N 1.5d2w\u00b5/F 2).\nTheorem 5 shows that our proposed Fed-GO-UCB algorithm matches the regret upper bound of its centralized counterpart, GO-UCB algorithm by Liu & Wang (2023), while only requiring communication cost that is sub-linear in T . We should note that the O( \u221a T ) dependence in communication cost is due to the iterative optimization procedure to compute w\u03020 at the end of Phase I, which also exists for prior works in federated bandits that requires iterative optimization (Li & Wang, 2022b)."
        },
        {
            "heading": "5 PROOF OVERVIEW",
            "text": "In this section, to highlight our technical contributions, we provide a proof sketch of the theoretical results about cumulative regret and communication cost that are presented in Theorem 5. All auxiliary lemmas are given in Appendix C and complete proofs are presented in Appendix D."
        },
        {
            "heading": "5.1 PHASE I. UNIFORM EXPLORATION & DISTRIBUTED REGRESSION ORACLE",
            "text": "Cumulative Regret and Communication Cost in Phase I Recall from Section 4.1 that, N clients conduct uniform exploration in Phase I, which constitutes a total number of T0 interactions with the environment. By Assumption 2, we know that the instantaneous regret has a unform upper bound rt := f(x\n\u22c6) \u2212 f(xt) \u2264 2F , so for a total number of T0 time steps, the cumulative regret incurred in Phase I, denoted as Rphase I, can be upper bounded by Rphase I = \u2211T0 t=1 rt \u2264 2T0F . Choice of T0 value will be discussed in Section 5.2, as it controls the quality of w\u03020, which further affects the constructed confidence sets used for optimistic exploration.\nMoreover, the only communication cost in Phase I is incurred when executing Oracle, i.e., the distributed regression oracle, for n iterations. In each iteration, N clients need to upload their local gradients to the server, and then receive the updated global model back (both with dimension dw). Therefore, the communication cost incurred during Phase I is Cphase I = 2nNdw.\nDistributed Regression Oracle Guarantee At the end of Phase I, we obtain an estimate w\u03020 by optimizing equation 2 using Oracle. As we mentioned in Section 4.2, w\u03020 will be used to construct the confidence sets, and thus to prepare for our analysis of the cumulative regret in Phase II, we establish the following regression oracle lemmas. Lemma 6. There is an absolute constant C \u2032, such that after time step T0 in Phase I of Algorithm 1 and under the condition that approximation error \u03f5 \u2264 1/(C \u2032T0), with probability at least 1 \u2212 \u03b4/2, regression oracle estimated w\u03020 satisfies Ex\u223cU [(fx(w\u03020)\u2212 fx(w\u22c6))2] \u2264 C \u2032dwF 2\u03b9/T0, where \u03b9 is the logarithmic term depending on T0, Ch, 2/\u03b4.\nLemma 6 is adapted from Lemma 5.1 of Liu & Wang (2023) to account for the additional approximation error from the distributed regression oracle. Specifically, instead of proving the risk bound for the exact minimizer w\u0302\u22c60 , we consider w\u03020 that satisfies |L\u0302T0(w\u03020) \u2212 L\u0302T0(w\u0302\u22c60)| \u2264 \u03f5 for some constant \u03f5. As discussed in Section 4.1, this relaxation is essential for the communication efficiency in federated bandit optimization. And Lemma 6 shows that, by ensuring \u03f5 \u2264 1/(C \u2032T0), we can obtain the same regression oracle guarantee as in the centralized setting (Liu & Wang, 2023). As discussed in Remark 4, this condition can be satisfied with n = O(C\n\u2032dxT0 \u03bd \u00b7 log(C \u2032T0)) number of iterations. With Lemma 6, we can establish Lemma 7 below using the same arguments as Liu & Wang (2023). Lemma 7 (Regression oracle guarantee (Theorem 5.2 of Liu & Wang (2023))). Under Assumption 1, 2, and 3, and by setting \u03f5 \u2264 1/(C \u2032T0), there exists an absolute constant C such that after time step T0 in Phase I of Algorithm 1, where T0 satisfies T0 \u2265 CdwF 2\u03b9 \u00b7 max { \u00b5\u03b3/(2\u2212\u03b3) \u03c42/(2\u2212\u03b3) , \u03b6\u00b5c2 } , with probability at least 1\u2212 \u03b4/2, regression oracle estimated w\u03020 satisfies \u2225w\u03020 \u2212 w\u22c6\u222522 \u2264 CdwF 2\u03b9 \u00b5T0 ."
        },
        {
            "heading": "5.2 PHASE II. CONFIDENCE SET CONSTRUCTION & OPTIMISTIC EXPLORATION",
            "text": "Confidence Set Construction In Phase II of Algorithm 1, each client i selects its next point to evaluate based on OFU principle, which requires construction of the confidence set in equation 4. The following lemma specifies the proper choice of \u03b2t,it , such that Ballt,it contains true parameter w\u22c6 for all t \u2208 [T ] with high probability. Lemma 8. Under Assumption 1, 2, & 3 and by setting \u03b2t,it = \u0398\u0303 ( dw\u03c3 2 + dwF 2/\u00b5+ d3wF 4/\u00b52 ) ,\nT0 = \u221a NT , and \u03bb = C\u03bb \u221a NT , then \u2225w\u0302t,it \u2212 w\u2217\u22252\u03a3t,it \u2264 \u03b2t,it , with probability at least 1 \u2212 \u03b4, \u2200t \u2208 [NT ] in Phase II of Algorithm 1.\nCumulative Regret in Phase II Thanks to the confidence sets established in Lemma 8, Algorithm 1 can utlize a communication protocol similar to the ones designed for federated linear bandits (Wang et al., 2020; Dubey & Pentland, 2020) during Phase II, while providing much diverse modeling choices. Therefore, our analysis of the communication regret and communication cost incurred in Phase II follows a similar procedure as its linear counterparts.\nDenote the total number of global synchronizations (total number of times the event in line 6 of Algorithm 1 is true) over time horizon T as P \u2208 [0, NP ]. Then we use tp for p \u2208 [P ] to denote the time step when the p-th synchronization happens (define t0 = 0), and refer to the sequence of time steps in-between two consecutive synchronizations as an epoch, i.e., the p-th epoch is [tp\u22121 +1, tp].\nSimilar to Wang et al. (2020); Dubey & Pentland (2020); Li & Wang (2022b), for the cumulative regret analysis in Phase II, we decompose P epochs into good and bad epochs, and then analyze them separately. Specifically, consider an imaginary centralized agent that has immediate access to each data point in the learning system, and we let this centralized agent executes the same model update rule and arm selection rule as in line 3-5 of Algorithm 1. Then the covariance matrix maintained by this agent can be defined as \u03a3t = \u2211t s=1 \u2207fxs(w\u03020)\u2207fxs(w\u03020)\u22a4 for t \u2208 [NT ]. Then the p-th\nepoch is called a good epoch if ln ( det(\u03a3tp )\ndet(\u03a3tp\u22121 )\n) \u2264 1, otherwise it is a bad epoch. Note that based\non Lemma 9, we have ln(det(\u03a3NT )/ det(\u03bbI)) \u2264 dw log (1 + NTC2g dw\u03bb ) := R. Since ln(det(\u03a3t1 )det(\u03bbI) ) + ln( det(\u03a3t2 )\ndet(\u03a3t1 ) ) + \u00b7 \u00b7 \u00b7+ ln(det(\u03a3NT )det(\u03a3tB ) ) = ln( det(\u03a3NT ) det(\u03bbI) ) \u2264 R, and due to the pigeonhole principle, there can be at most R bad epochs. Then with standard optimistic argument (Abbasi-yadkori et al., 2011), we can show that the cumulative regret incurred in good epochs Rgood = O\u0303( d3wF 4 \u221a NT\n\u00b52 ), which matches the regret of centralized algorithm by (Liu & Wang, 2023). Moreover, by design of the event-triggered communication in line 6 of Algorithm 1, we can show that the cumulative regret incurred in any bad epoch p can be bounded by \u2211tp t=tp\u22121+1 rt \u2264 N \u221a 16\u03b2NT \u03b3 + 8\u03b22NTC 2 h/C 2 \u03bb, where \u03b2NT = O( d3wF 4\n\u00b52 ) according to Lemma 8. Since there can be at most R bad epochs, the cumulative regret incurred in bad epochs Rbad = O\u0303(Ndw \u221a d3wF 4 \u00b52 \u221a \u03b3 + Ndw d3wF 4 \u00b52 ). By setting communication threshold \u03b3 = dwF 4T\n\u00b52N , we have Rbad = O\u0303( d3wF\n4 \u221a NT\n\u00b52 + d4wF 4N \u00b52 ). Combining\ncumulative regret incurred during both good and bad epochs, we have Rphase II = Rgood +Rbad = O\u0303 (\u221a NTd3wF 4/\u00b52 +Nd4wF 4/\u00b52 ) .\nCommunication Cost in Phase II Consider some \u03b1 > 0. By pigeon-hole principle, there can be at most \u2308NT\u03b1 \u2309 epochs with length (total number of time steps) longer than \u03b1. Then we consider some epoch with less than \u03b1 time steps, similarly, we denote the first time step of this epoch as ts and the last as te, i.e., te \u2212 ts < \u03b1. Since the users appear in a round-robin manner, the number of interactions for any user i \u2208 [N ] satisfies |Dte,i| \u2212 |Dts,i| < \u03b1N . Due to the event-triggered in line 6 of Algorithm 1, we have log det(\u03a3te )det(\u03a3ts ) > \u03b3N \u03b1 . Using the pigeonhole principle again, we know that the number of epochs with less than \u03b1 time steps is at most \u2308R\u03b1\u03b3N \u2309. Therefore, the total number of synchronizations P \u2264 \u2308NT\u03b1 \u2309+ \u2308 R\u03b1 \u03b3N \u2309, and the RHS can be minimized by choosing \u03b1 = N \u221a \u03b3T/R,\nso that P \u2264 2 \u221a TR/\u03b3. With \u03b3 = dwF\n4T \u00b52N , P \u2264 2\n\u221a N log(1+NTC2g/(dw\u03bb))\u00b5 2 F 4 = O\u0303( \u221a N\u00b52/F 4). At\neach global synchronization, Algorithm 1 incurs 2N(d2w + dw) communication cost to update the statistics. Therefore, Cphase II = P \u00b7 2N(d2w + dw) = (N1.5d2w\u00b5/F 2)."
        },
        {
            "heading": "6 EXPERIMENTS",
            "text": "In order to evaluate Fed-GO-UCB\u2019s empirical performance and validate our theoretical results in Theorem 5, we conducted experiments on both synthetic and real-world datasets. Due to the space limit, here we only discuss the experiment setup and results on synthetic dataset. More discussions about the experiment setup and results on real-world datasets are presented in Appendix E.\nFor synthetic dataset, we consider two test functions, f1(x) = \u2212 \u22114 i=1 \u03b1\u0304i exp(\u2212 \u22116\nj=1 A\u0304ij(xj \u2212 P\u0304ij) 2) (see values of \u03b1\u0304, A\u0304, P\u0304 in appendix) and f2(x) = 0.1 \u22118 i=1 cos(5\u03c0xi) \u2212 \u22118 i=1 x 2 i . The decision set X is finite (with |X | = 50), and is generated by uniformly sampling from [0, 1]6 and [\u22121, 1]8, respectively. We choose F to be a neural network with two linear layers, i.e., the model f\u0302(x) = W2 \u00b7 \u03c3(W1x+ c1) + c2, where the parameters W1 \u2208 R25,dx , c1 \u2208 R25,W2 \u2208 R25, c2 \u2208 R, and \u03c3(z) = 1/(1+exp(\u2212z)). Results (averaged over 10 runs) are reported in Figure 2. We included DisLinUCB (Wang et al., 2020), Fed-GLB-UCB (Li & Wang, 2022b), ApproxDisKernelUCB (Li et al., 2022a), One-GO-UCB, and N-GO-UCB (Liu & Wang, 2023) as baselines. One-GO-UCB learns one model for all clients by immediately synchronizing every data point, and N-GO-UCB learns one model for each client with no communication. From Figure, 2, we can see that Fed-GOUCB and One-GO-UCB have much smaller regret than other baseline algorithms, demonstrating\nthe superiority of neural network approximation for the global non-linear optimization, though inevitably this comes at the expense of higher communication cost due to transferring statistics of size d2w \u2248 104 (compared with d2x \u2248 102 for the baselines). Nevertheless, we can see that the communication cost of Fed-GO-UCB is significantly lower than One-GO-UCB and it grows at a sub-linear rate over time, which conforms with our theoretical results in Theorem 5."
        },
        {
            "heading": "7 CONCLUSIONS AND FUTURE WORK",
            "text": "Despite the potential of federated optimization in high-impact applications, such as, clinical trial optimization, hyperparameter tuning, and drug discovery, there is a gap between current theoretical studies and practical usages, i.e.,, federated optimization is often needed in online tasks, like nextword prediction on keyboard apps, but most existing works formulate it as an offline problem. To bridge this gap, some recent works propose to study federated bandit optimization problem, but their objective functions are limited to simplistic classes, e.g., linear, generalized linear, or non-parametric function class with bounded RKHS norm, which limits their potential in real-world applications.\nIn this paper, we propose the first federated bandit optimization method, named Fed-GO-UCB, that works with generic non-linear objective functions. Under some mild conditions, we rigorously prove that Fed-GO-UCB is able to achieve O\u0303( \u221a NT ) cumulative regret and O\u0303(N1.5 \u221a T +N1.5) communication cost where T is time horizon and N is number of clients. Our technical analysis builds upon Xu et al. (2018); Liu & Wang (2023) and the main novelties lie in the distributed regression oracle and individual confidence set construction, which makes collaborative exploration under federated setting possible. In addition, extensive empirical evaluations are performed to validate the effectiveness of our algorithm, especially its ability in approximating nonlinear functions.\nOne interesting future direction is to generalize our work to heterogeneous clients, i.e., each client i \u2208 [N ] has a different reward function fi, that can be assumed to be close to each other as in Dubey & Pentland (2021), or have shared components as in Li & Wang (2022a). This allows us to better model the complex situations in reality, especially when personalized decisions are preferred."
        },
        {
            "heading": "A NOTATION TABLE",
            "text": ""
        },
        {
            "heading": "B ADDITIONAL DISCUSSIONS",
            "text": "B.1 MORE DETAILS ON RELATED WORKS\nMore details on distributed/federated bandits For distributed bandits (Korda et al., 2016; Mahadik et al., 2020; Wang et al., 2020; Dubey & Pentland, 2020; Huang et al., 2021), designing an efficient communication strategy is the main focus. Existing algorithms mainly differ in the relations of learning problems solved by the clients (i.e., identical vs., clustered) and the type of communication network (i.e., peer-to-peer (P2P) vs., star-shaped). Korda et al. (2016) studied two problem settings with a P2P communication network: 1) all the clients solve a common linear bandit problem, and 2) the problems are clustered. Mahadik et al. (2020) later proposed an improved algorithm on the second problem setting studied by Korda et al. (2016). However, both works only tried to reduce per-round communication, and thus the communication cost is still linear over time. Two follow-up studies considered the setting where all clients solve a common linear bandit problem with time-varying arm set and interact with the environment in a round-robin fashion (Wang et al., 2020; Dubey & Pentland, 2020). Similar to our work, they also used event-triggered communications to obtain a sub-linear communication cost over time. In particular, Wang et al. (2020) considered a star-shaped network and proposed a synchronous communication protocol for all clients to exchange their sufficient statistics via the central server. Dubey & Pentland (2020) extended this synchronous protocol to differentially private LinUCB algorithms under both star-shaped and P2P network. Huang et al. (2021) considered a similar setting but with a fixed arm set and thus proposed a phase-based elimination algorithm. Later, in order to improve robustness against possible stragglers in the system, Li & Wang (2022a); He et al. (2022) proposed asynchronous communication protocols for the federated linear bandit problems. All the works mentioned above consider linear models, where efficient communication is enabled via closed-form model update. The only existing work that studies nonlinear models with iterative optimization is by Li & Wang (2022b), who employed a combination of online and offline regression, with online regression adjusting each client\u2019s local model using its newly collected data, and offline (distributed) regression that conducts iterative gradient aggregation over all clients for joint model estimation during global synchronizations.\nOffline federated learning Another related line of research is federated learning or decentralized machine learning that considers offline supervised learning scenarios (Kairouz et al., 2019). FedAvg (McMahan et al., 2017) has been the most popular algorithm for offline federated learning. However, despite its popularity, several works (Li et al., 2019a; Karimireddy et al., 2020; Mitra et al., 2021) identified that FedAvg suffers from a client-drift problem when the clients\u2019 data are non-IID (which is an important signature of our case), i.e., local iterates in each client drift towards their local minimum. This leads to a sub-optimal convergence rate of FedAvg, i.e., a sub-linear convergence rate for strongly convex and smooth losses, though a linear convergence rate is expected in this case. To address this, Pathak & Wainwright (2020) proposed an operator splitting procedure to guarantee linear convergence to a neighborhood of the global minimum. Later, Mitra et al. (2021) introduced variance reduction techniques to guarantee exact linear convergence to the global minimum. However, due to the fundamental difference in the learning objectives, they are not suitable for our federated optimization problem: their focus is to collaboratively learn a good point estimate over a fixed dataset, i.e., convergence to the minimizer with fewer iterations, while federated bandit learning requires collaborative confidence set estimation for efficient regret reduction. This is also reflected by the difference in the design of communication triggering events. For decentralized supervised machine learning, triggering event measuring the change in the learned parameters suffices (Kia et al., 2015; Yi et al., 2018; George & Gurram, 2020), while for federated bandit learning, triggering event needs to measure change in the volume of the confidence set, i.e., uncertainty in the problem space (Wang et al., 2020; Li & Wang, 2022a).\nB.2 SUMMARY OF EXISTING FEDERATED BANDIT ALGORITHMS\nHere we provide a summary of existing works in federated bandit optimization in Table 2, which mainly differs in their modeling assumptions, type of communication protocol (synchronous vs asynchronous), as well as theoretical guarantees on regret and communication cost (in terms of N and T )."
        },
        {
            "heading": "C AUXILIARY LEMMAS",
            "text": "Lemma 9 (Lemma C.5 of Liu & Wang (2023)). Set \u03a3t,it as in equation 6 and suppose Assumptions 1, 2, & 3 hold. Then\nln ( det\u03a3t\u22121,it det\u03a30 ) \u2264 dw ln ( 1 + |Dt,it |C2g dw\u03bb ) .\nLemma 10 (Lemma C.6 of Liu & Wang (2023)). Set \u03a3t,it as in equation 6 and suppose Assumptions 1, 2, & 3 hold. Then \u2211\ns\u2208Dt,it\n\u2207fxs(w\u03020)\u22a4\u03a3\u22121s\u22121,it\u2207fxs(w\u03020) \u2264 2 ln( \u03a3t\u22121,it \u03a30 )\nLemma 11 (Self-normalized bound for vector-valued martingales (Abbasi-yadkori et al., 2011; Agarwal et al., 2021)). Let {\u03b7i}\u221ei=1 be a real-valued stochastic process with corresponding filtration {Fi}\u221ei=1 such that \u03b7i is Fi measurable, E[\u03b7i|Fi\u22121] = 0, and \u03b7i is conditionally \u03c3-sub-Gaussian with \u03c3 \u2208 R+. Let {Xi}\u221ei=1 be a stochastic process with Xi \u2208 H (some Hilbert space) and Xi being Ft measurable. Assume that a linear operator \u03a3 : H \u2192 H is positive definite, i.e., x\u22a4\u03a3x > 0 for any x \u2208 H. For any t, define the linear operator \u03a3t = \u03a30 + \u2211t i=1 XiX \u22a4 i (here xx\n\u22a4 denotes outer-product in H). With probability at least 1\u2212 \u03b4, we have for all t \u2265 1:\u2225\u2225\u2225\u2225\u2225 t\u2211 i=1 Xi\u03b7i \u2225\u2225\u2225\u2225\u2225 2\n\u03a3\u22121t\n\u2264 \u03c32 ln ( det(\u03a3t) det(\u03a30) \u22121\n\u03b42\n) . (7)\nLemma 12 (Risk Bounds for \u03f5-approximation of ERM Estimator). Given a dataset {xs, ys}ts=1 where ys is generated from equation 1, and f\u22c6 is the underlying true function. Let f\u0302t be an ERM estimator taking values in F where F is a finite set and F \u2282 {f : [0, 1]d \u2192 [\u2212F, F ]} for some"
        },
        {
            "heading": "F \u2265 1. f\u0303t \u2208 F denotes its \u03f5-approximation. Then with probability at least 1\u2212 \u03b4, f\u0303 satisfies that",
            "text": "E [ (f\u0303t \u2212 f0)2 ] \u2264 1 + \u03b1 1\u2212 \u03b1 ( inf f\u2208F E[(f \u2212 f0)2] + F 2 ln(|F|) ln(2) t\u03b1 ) + 2 ln(2/\u03b4) t\u03b1 + \u03f5\n1\u2212 \u03b1 for all \u03b1 \u2208 (0, 1] and \u03f5 \u2265 0.\nProof of Lemma 12. Define the risk and empirical risk function as\nR(f) := EX,Y [(f(X)\u2212 Y )2],\nR\u0302(f) := 1\nt t\u2211 s=1 (f(xs)\u2212 ys)2.\nBy definition,\nf\u22c6 = E[Y |X = x] = argmin f\u2208F R(f).\nDenote the excess risk and the empirical excess risk as\nE(f) := R(f)\u2212R(f\u22c6), E\u0302(f) := R\u0302(f)\u2212 R\u0302(f\u22c6).\nFollowing the same steps in Nowak [2007], we have\n(1\u2212 \u03b1)E(f) \u2264 E\u0302(f) + c(f) ln 2 + ln 1/\u03b4 \u03b1t = R\u0302(f)\u2212 R\u0302(f\u22c6) + c(f) ln 2 + ln 1/\u03b4 \u03b1t ,\nwhere penalties c(f) are positive numbers assigned to each f \u2208 F that satisfies \u2211\nf\u2208F 2 \u2212c(f) \u2264 1.\nWe set it to c(f) = F 2 ln(|F|) according to Lemma 4 of Schmidt-Hieber (2020). Now recall that, we have denoted f\u0302t as the ERM estimator, i.e., f\u0302t := argminf\u2208F R\u0302(f), and f\u0303t as its \u03f5-approximation, such that\nR\u0302(f\u0303t)\u2212 R\u0302(f\u0302t) \u2264 \u03f5.\nTherefore, we have\n(1\u2212 \u03b1)E(f\u0303t) \u2264 E\u0302(f\u0303n) + F 2 ln(|F|) ln 2 + ln 1/\u03b4\n\u03b1t\n\u2264 E\u0302(f\u0302t) + F 2 ln(|F|) ln 2 + ln 1/\u03b4\n\u03b1t + \u03f5\n\u2264 E\u0302(f\u22c6t ) + F 2 ln(|F|) ln 2 + ln 1/\u03b4\n\u03b1t + \u03f5\nDue to Craig-Bernstein inequality, we have\nE\u0302(f\u22c6t ) \u2264 E(f\u22c6t ) + \u03b1E(f\u22c6t ) + ln 1/\u03b4\n\u03b1t .\nCombining the two inequalities above, we have\nE(f\u0303t) \u2264 1 + \u03b1\n1\u2212 \u03b1 E(f\u22c6t ) +\n1 1\u2212 \u03b1 F 2 ln(|F|) ln 2 + 2 ln 1/\u03b4 \u03b1t + 1 1\u2212 \u03b1 \u03f5."
        },
        {
            "heading": "D COMPLETE PROOFS",
            "text": "D.1 PROOF OF LEMMA 6\nProof of Lemma 6. The regression oracle lemma establishes on Lemma 12 which works only for finite function class. In order to work with our continuous parameter class W, we need \u03b5-covering number argument. First, let w\u0303, W\u0303 denote the \u03f5-approximation of ERM parameter and finite parameter class after applying covering number argument on W . By Lemma 12, we find that with probability at least 1\u2212 \u03b4/2,\nEx\u223cU [(fx(w\u0303)\u2212 fx(w\u22c6))2] \u2264 1 + \u03b1 1\u2212 \u03b1 ( inf w\u2208W\u0303\u222a{w\u22c6} Ex\u223cU [(fx(w)\u2212 fx(w\u22c6))2] + F 2 ln(|W|) ln(2) T0\u03b1 ) + \u03f5\n1\u2212 \u03b1 +\n2 ln(4/\u03b4)\nT0\u03b1\n\u2264 1 + \u03b1 1\u2212 \u03b1 (F 2 ln(|W\u0303|) ln(2) T0\u03b1 ) + \u03f5 1\u2212 \u03b1 + 2 ln(4/\u03b4) T0\u03b1\nwhere the second inequality is due to Assumption 1. Our parameter class W \u2286 [0, 1]dw , so ln(|W\u0303|) = ln(1/\u03f5dw) = dw ln(1/\u03b5) and the new upper bound is that with probability at least 1\u2212 \u03b4/2,\nEx\u223cU [(fx(w\u0303)\u2212 fx(w\u22c6))2] \u2264 C \u2032\u2032 (dwF 2 ln(1/\u03b5)\nT0 +\nln(2/\u03b4) T0 + \u03f5 )\nwhere C \u2032\u2032 is a universal constant obtained by choosing \u03b1 = 1/2. Note w\u0303 is the parameter in W\u0303 after discretization, not our target parameter w\u03030 \u2208 W . By (a+ b)2 \u2264 2a2 + 2b2,\nEx\u223cU [(fx(w\u03020)\u2212 fx(w\u22c6))2] \u2264 2Ex\u223cU [(fx(w\u03020)\u2212 fx(w\u0303))2] + 2Ex\u223cU [(fx(w\u0303)\u2212 fx(w\u22c6))2]\n\u2264 2\u03b52C2h + 2C \u2032\u2032 (dwF 2 ln(1/\u03b5)\nT0 +\nln(2/\u03b4) T0 + \u03f5 )\nwhere the second line applies Lemma 12, discretization error \u03b5, and Assumption 2. By choosing \u03b5 = 1/(2 \u221a T0C2h), and \u03f5 = 1/(2C \u2032\u2032T0) we get\n(18) = 2\nT0 +\nC \u2032\u2032dwF 2 ln(T0C 2 h)\nT0 +\n2C \u2032\u2032 ln(2/\u03b4)\nT0 \u2264 C \u2032 dwF\n2 ln(T0C 2 h) + ln(2/\u03b4)\nT0\nwhere we can take C \u2032 = 2C \u2032\u2032 (assuming 2 < C \u2032\u2032dwF 2 log(T0C2h)). The proof completes by defining \u03b9 as the logarithmic term depending on T0, Ch, 2/\u03b4.\nD.2 CONFIDENCE ANALYSIS\nLemma 13 (Restatement of Lemma 8). Set w\u0302t,it ,\u03a3t,it as in eq. equation 6, equation 5. Set \u03b2t,it as\n\u03b2t,it = \u0398\u0303 ( dw\u03c3 2 + dwF 2\n\u00b5 +\nd3wF 4\n\u00b52\n) .\nSuppose Assumptions 1, 2, & 3 hold and choose T0 = \u221a NT, \u03bb = C\u03bb \u221a NT . Then \u2200t \u2208 [NT ] in Phase II of Algorithm 1, \u2225w\u0302t,it \u2212 w\u2217\u22252\u03a3t,it \u2264 \u03b2t,it , with probability at least 1\u2212 \u03b4.\nProof. The proof has two steps. First we obtain the closed form solution of w\u0302t,it . Next we prove the upper bound of \u2225w\u0302t,it \u2212 w\u2217\u22252\u03a3t,it matches our choice of \u03b2t,it .\nStep 1: Closed form solution of w\u0302t,it . Let \u2207 denote \u2207fxs(w\u03020) in this proof. Recall w\u0302t,it is estimated by solving the following optimization problem:\nw\u0302t,it = \u03a3 \u22121 t,it bt,it + \u03bb\u03a3 \u22121 t,it w\u03020\n= argmin w\n\u03bb 2 \u2225w \u2212 w\u03020\u222522 + 1 2 \u2211 s\u2208Dt(it) ((w \u2212 w\u03020)\u22a4\u2207+ fxs(w\u03020)\u2212 ys)2\nThe optimal criterion for the objective function is 0 = \u03bb(w\u0302t,it \u2212 w\u03020) + \u2211\ns\u2208Dt(it)\n((w\u0302t,it \u2212 w\u03020)\u22a4\u2207+ fxs(w\u03020)\u2212 ys)\u2207.\nRearrange the equation and we have \u03bb(w\u0302t,it \u2212 w\u03020) + \u2211\ns\u2208Dt(it)\n(w\u0302t,it \u2212 w\u03020)\u22a4\u2207\u2207 = \u2211\ns\u2208Dt(it)\n(ys \u2212 fxs(w\u03020))\u2207,\n\u03bb(w\u0302t,it \u2212 w\u03020) + \u2211\ns\u2208Dt(it)\n(w\u0302t,it \u2212 w\u03020)\u22a4\u2207\u2207 = \u2211\ns\u2208Dt(it)\n(ys \u2212 fxs(w\u2217) + fxs(w\u2217)\u2212 fxs(w\u03020))\u2207,\n\u03bb(w\u0302t,it \u2212 w\u03020) + \u2211\ns\u2208Dt(it)\nw\u0302\u22a4t,it\u2207\u2207 = \u2211\ns\u2208Dt(it)\n(w\u0302\u22a40 \u2207+ \u03b7s + fxs(w\u2217)\u2212 fxs(w\u03020))\u2207,\nw\u0302t,it \u03bbI+ \u2211 s\u2208Dt(it) \u2207\u2207\u22a4 \u2212 \u03bbw\u03020 = \u2211 s\u2208Dt(it) (w\u0302\u22a40 \u2207+ \u03b7s + fxs(w\u2217)\u2212 fxs(w\u03020))\u2207,\nw\u0302t,it\u03a3t,it = \u03bbw\u03020 + \u2211\ns\u2208Dt(it)\n(w\u0302\u22a40 \u2207+ \u03b7s + fxs(w\u2217)\u2212 fxs(w\u03020))\u2207,\nwhere the second line is by removing and adding back fxs(w \u2217), the third line is due to definition of observation noise \u03b7 and the last line is by our choice of \u03a3t,it (eq. equation 6). Now we have the closed form solution of w\u0302t,it :\nw\u0302t,it = \u03bb\u03a3 \u22121 t,it w\u03020 +\u03a3 \u22121 t,it \u2211 s\u2208Dt(it) (w\u0302\u22a40 \u2207+ \u03b7s + fxs(w\u2217)\u2212 fxs(w\u03020))\u2207,\nwhere \u2207 denotes \u2207fxs(w\u03020). Then w\u0302t,it \u2212 w\u2217 can be written as\nw\u0302t,it \u2212 w\u2217 = \u03a3\u22121t,it  \u2211 s\u2208Dt(it) \u2207(\u2207\u22a4w\u03020 + \u03b7s + fxs(w\u2217)\u2212 fxs(w\u03020)) + \u03bb\u03a3\u22121t,itw\u03020 \u2212 \u03a3\u22121t,it\u03a3t,itw\u2217 = \u03a3\u22121t,it  \u2211 s\u2208Dt(it) \u2207(\u2207\u22a4w\u03020 + \u03b7s + fxs(w\u2217)\u2212 fxs(w\u03020))\n+ \u03bb\u03a3\u22121t,it(w\u03020 \u2212 w\u2217) \u2212 \u03a3\u22121t,it  \u2211 s\u2208Dt(it) \u2207\u2207\u22a4 w\u2217\n= \u03a3\u22121t,it  \u2211 s\u2208Dt(it) \u2207(\u2207\u22a4(w\u03020 \u2212 w\u2217) + \u03b7s + fxs(w\u2217)\u2212 fxs(w\u03020)) + \u03bb\u03a3\u22121t,it(w\u03020 \u2212 w\u2217) = \u03a3\u22121t,it  \u2211 s\u2208Dt(it) \u22071 2 \u2225w\u03020 \u2212 w\u2217\u22252\u22072fxs (w\u0303) +\u03a3\u22121t,it  \u2211 s\u2208Dt(it) \u2207\u03b7s + \u03bb\u03a3\u22121t,it(w\u03020 \u2212 w\u2217), (8)\nwhere the second line is again by our choice of \u03a3t and the last equation is by the second order Taylor\u2019s theorem of fxs(w \u2217) at w\u03020 where w\u0303 lies between w\u2217 and w\u03020.\nStep 2: Upper bound of \u2225w\u0302t,it \u2212 w\u2217\u22252\u03a3t,it . Multiply both sides of eq. equation 8 by \u03a3 1 2 t,it\nand we have\n\u03a3 1 2 t,it (w\u0302t,it \u2212 w\u2217) \u2264 1\n2 \u03a3\n\u2212 12 t,it  \u2211 s\u2208Dt(it) \u2207fxs(w\u03020)\u2225w\u03020 \u2212 w\u2217\u22252\u22072fxs (w\u0303)  +\u03a3\n\u2212 12 t,it  \u2211 s\u2208Dt(it) \u2207fxs(w\u03020)\u03b7s + \u03bb\u03a3\u2212 12t,it (w\u03020 \u2212 w\u2217). Take square of both sides and by inequality (a+ b+ c)2 \u2264 4a2 + 4b2 + 4c2 we obtain\n\u2225w\u0302t,it \u2212 w\u2217\u22252\u03a3t,it \u2264 4 \u2225\u2225\u2225\u2225\u2225\u2225 \u2211\ns\u2208Dt(it)\n\u2207fxs(w\u03020)\u03b7s \u2225\u2225\u2225\u2225\u2225\u2225 2\n\u03a3\u22121t,it\n+ 4\u03bb2\u2225w\u03020 \u2212 w\u2217\u22252\u03a3\u22121t,it\n+ \u2225\u2225\u2225\u2225\u2225\u2225 \u2211\ns\u2208Dt(it)\n\u2207fxs(w\u03020)\u2225w\u03020 \u2212 w\u2217\u22252\u22072fxs (w\u0303) \u2225\u2225\u2225\u2225\u2225\u2225 2\n\u03a3\u22121t,it\n. (9)\nThe remaining job is to bound three terms in eq. equation 9 individually. The first term of eq. equation 9 can be bounded as\n4 \u2225\u2225\u2225\u2225\u2225\u2225 \u2211\ns\u2208Dt(it)\n\u2207fxs(w\u03020)\u03b7s \u2225\u2225\u2225\u2225\u2225\u2225 2\n\u03a3\u22121t,it\n\u2264 4\u03c32 log ( det(\u03a3t,it) det(\u03a30) \u22121\n\u03b42t\n)\n\u2264 4\u03c32 ( dw log ( 1 +\niC2g dw\u03bb\n) + log ( \u03c02t2\n3\u03b4 )) \u2264 4dw\u03c32\u03b9\u2032,\nwhere the second inequality is due to self-normalized bound for vector-valued martingales (Lemma 11 in Appendix C) and Lemma 7, the second inequality is by Lemma 9 and our choice of \u03b4i = 3\u03b4/(\u03c0\n2i2), and the last inequality is by defining \u03b9\u2032 as the logarithmic term depending on i, dw, Cg, 1/\u03bb, 2/\u03b4 (with probability > 1\u2212 \u03b4/2). The choice of \u03b4i guarantees the total failure probability over t rounds is no larger than \u03b4/2.\nUsing Lemma 7, the second term in eq. equation 9 is bounded as\n4\u03bb2\u2225w\u03020 \u2212 w\u2217\u22252\u03a3\u22121t,it \u2264 4\u03bbCdwF\n2\u03b9\n\u00b5T0 .\nAgain using Lemma 7 and Assumption 3, the third term of eq. equation 9 can be bounded as\u2225\u2225\u2225\u2225\u2225\u2225 \u2211\ns\u2208Dt(it)\n\u2207fxs(w\u03020)\u2225w\u03020 \u2212 w\u2217\u22252\u22072fxs (w\u0303) \u2225\u2225\u2225\u2225\u2225\u2225 2\n\u03a3\u22121t,it\n\u2264 \u2225\u2225\u2225\u2225\u2225\u2225CChdwF 2\u03b9 \u00b5T0 \u2211 s\u2208Dt(it) \u2207fxs(w\u03020) \u2225\u2225\u2225\u2225\u2225\u2225 2\n\u03a3\u22121t,it\n= C2C2hd 2 wF 4\u03b92\n\u00b52T 20\n\u2225\u2225\u2225\u2225\u2225\u2225 \u2211\ns\u2208Dt(it)\n\u2207fxs(w\u03020) \u2225\u2225\u2225\u2225\u2225\u2225 2\n\u03a3\u22121t,it\n= C2C2hd 2 wF 4\u03b92\n\u00b52T 20\n \u2211 s\u2208Dt(it) \u2207fxs(w\u03020) \u22a4 \u03a3\u22121t,it  \u2211 s\u2032\u2208Dt(it) \u2207fxs\u2032 (w\u03020)  . Rearrange the summation and we can write\nC2C2hd 2 wF 4\u03b92\n\u00b52T 20\n \u2211 s\u2208Dt(it) \u2207fxs(w\u03020) \u22a4 \u03a3\u22121t,it  \u2211 s\u2032\u2208Dt(it) \u2207fxs\u2032 (w\u03020)  = C2C2hd 2 wF 4\u03b92\n\u00b52T 20\n\u2211 s\u2208Dt(it) \u2211 s\u2032\u2208Dt(it) \u2207fxs(w\u03020)\u22a4\u03a3\u22121t,it\u2207fxs\u2032 (w\u03020)\n\u2264 C 2C2hd 2 wF 4\u03b92\n\u00b52T 20\n\u2211 s\u2208Dt(it) \u2211 s\u2032\u2208Dt(it) \u2225\u2207fxs(w\u03020)\u2225\u03a3\u22121t,it\u2225\u2207fxs\u2032 (w\u03020)\u2225\u03a3 \u22121 t,it\n= C2C2hd 2 wF 4\u03b92\n\u00b52T 20\n \u2211 s\u2208Dt(it) \u2225\u2207fxs(w\u03020)\u2225\u03a3\u22121t,it  \u2211 s\u2032\u2208Dt(it) \u2225\u2207fxs\u2032 (w\u03020)\u2225\u03a3\u22121t,it  = C2C2hd 2 wF 4\u03b92\n\u00b52T 20\n \u2211 s\u2208Dt(it) \u2225\u2207fxs(w\u03020)\u2225\u03a3\u22121t,it 2\n\u2264 C 2C2hd 2 wF 4\u03b92\n\u00b52T 20\n \u2211 s\u2208Dt(it) 1  \u2211 s\u2208Dt(it) \u2225\u2207fxs(w\u03020)\u22252\u03a3\u22121t,it  \u2264 C 2C2hd 3 wF 4t\u03b9 \u2032\u2032 \u03b92\n\u00b52T 20 ,\nwhere the second last inequality is due to Cauchy-Schwarz inequality and the last inequality is by Lemma 10.\nFinally, put three bounds together and we have\n\u2225w\u0302t,it \u2212 w\u2217\u22252\u03a3\u22121t,it \u2264 4dw\u03c32\u03b9\u2032 +\n4\u03bbCdwF 2\u03b9\n\u00b5T0 +\nC2C2hd 3 wF 4t\u03b9\u2032\u2032\u03b92\n\u00b52T 20 \u2264 O ( dw\u03c3 2\u03b9\u2032 + dwF 2\u03b9\n\u00b5 +\nd3wF 4t\u03b9\u2032\u2032\u03b92\n\u00b52NT\n) ,\nwhere the last inequality is by our choices of \u03bb = C\u03bb \u221a NT, T0 = \u221a NT . Therefore, our choice of\n\u03b2t,it = \u0398\u0303 ( dw\u03c3 2 + dwF 2\n\u00b5 +\nd3wF 4\n\u00b52 ) guarantees that w\u2217 is always contained in Ballt with probability 1\u2212 \u03b4.\nD.3 CUMULATIVE REGRET AND COMMUNICATION COST IN PHASE II\nCumulative Regret in Phase II Thanks to the confidence set established in Lemma 8, Phase II of Algorithm 1 can operate in a similar way as existing works in federated linear bandits (Wang et al., 2020; Dubey & Pentland, 2020), while allowing for a much wider choices of models. The main difference is that, the regret of their work depends on the matrix constructed using context vectors xs for s = 1, 2, . . . for the selected points, while ours rely on the matrix constructed using gradients\u2019 w.r.t. the shared model w\u03020. In the following paragraphs, we first establish the relation between instantaneous regret rt and matrix \u03a3t\u22121,it , and then analyze the regret of Algorithm 1.\nThough, compared with Liu & Wang (2023), we are using a different way of constructing the confidence ellipsoid, which is given in Lemma 8. Their Lemma 5.4, which is given below, still holds, because it only requires Ballt\u22121,it to be a valid confidence set, and that Assumption 2 holds.\nLemma 14 (Instantaneous regret bound [Lemma 5.4 of Liu & Wang (2023)). Under the same condition as Lemma 8,in Phase II of Algorithm 1, for all t \u2208 [NT ], we have\nrt \u2264 2 \u221a \u03b2t\u22121,it\u2225\u2207fxt(w\u03020)\u2225\u03a3\u22121t\u22121,it + 2\u03b2t,itCh/\u03bb,\nwith probability at least 1\u2212 \u03b4.\nDenote the total number of global synchronizations (total number of times the event in line 6 of Algorithm 1 is true) over time horizon T as P \u2208 [0, NP ]. Then we use tp for p \u2208 [P ] to denote the time step when the p-th synchronization happens (define t0 = 0), and refer to the sequence of time steps in-between two consecutive synchronizations as an epoch, i.e., the p-th epoch is [tp\u22121 +1, tp]. Similar to Wang et al. (2020); Dubey & Pentland (2020); Li & Wang (2022b), for the cumulative regret analysis in Phase II, we decompose P epochs into good and bad epochs, and then analyze them separately.\nSpecifically, consider an imaginary centralized agent that has immediate access to each data point in the learning system, and we let this centralized agent executes the same model update rule and arm selection rule as in line 3-5 of Algorithm 1. Then the covariance matrix maintained by this agent can be defined as \u03a3t = \u2211t s=1 \u2207fxs(w\u03020)\u2207fxs(w\u03020)\u22a4 for t \u2208 [NT ]. The p-th epoch is called a good epoch if\nln\n( det(\u03a3tp)\ndet(\u03a3tp\u22121)\n) \u2264 1,\notherwise it is a bad epoch. Note that based on Lemma 9, we have ln(det(\u03a3NT )/det(\u03bbI)) \u2264 dw log (1 + NTC2g dw\u03bb ) := R. Since ln(det(\u03a3t1 )det(\u03bbI) )+ln( det(\u03a3t2 ) det(\u03a3t1 ) )+\u00b7 \u00b7 \u00b7+ln(det(\u03a3NT )det(\u03a3tB ) ) = ln( det(\u03a3NT ) det(\u03bbI) ) \u2264 R, and due to the pigeonhole principle, there can be at most R bad epochs.\nNow consider some good epoch p. By definition, we have det(\u03a3t\u22121)det(\u03a3t\u22121,it ) \u2264 det(\u03a3tp ) det(\u03a3tp\u22121 ) \u2264 e, for any t \u2208 [tp\u22121+1, tp]. Therefore, if the instantaneous regret rt is incurred during a good epoch, we have\nrt \u2264 2 \u221a \u03b2t\u22121,it\u2225\u2207fxt(w\u03020)\u2225\u03a3\u22121t\u22121,it + 2\u03b2t\u22121,itCh \u03bb\n\u2264 2 \u221a \u03b2t\u22121,it\u2225\u2207fxt(w\u03020)\u2225\u03a3\u22121t\u22121 \u221a \u2225\u2207fxt(w\u03020)\u2225\u03a3\u22121t\u22121,it/\u2225\u2207fxt(w\u03020)\u2225\u03a3 \u22121 t\u22121 + 2\u03b2t\u22121,itCh \u03bb = 2 \u221a \u03b2t\u22121,it\u2225\u2207fxt(w\u03020)\u2225\u03a3\u22121t\u22121 \u221a det(\u03a3t\u22121)\ndet(\u03a3t\u22121,it) + 2\u03b2t\u22121,itCh \u03bb\n\u2264 2 \u221a e \u221a \u03b2t\u22121,it\u2225\u2207fxt(w\u03020)\u2225\u03a3\u22121t\u22121 + 2\u03b2t\u22121,itCh \u03bb\nwhere the first inequality is due to Lemma 14, and the last inequality is due to the definition of good epoch, i.e., det(\u03a3t\u22121)det(\u03a3t\u22121,it ) \u2264 det(\u03a3tp ) det(\u03a3tp\u22121 ) \u2264 e. This suggests the instantaneous regret rt incurred in a good epoch is at most \u221a e times of that incurred by the imaginary centralized agent that runs GO-UCB algorithm of Liu & Wang (2023). Therefore, the cumulative regret incurred in good epochs of Phase II, denoted as Rgood is\nRgood = P\u2211 p=1 1{ln ( det(\u03a3tp) det(\u03a3tp\u22121) ) \u2264 1} tp\u2211 t=tp\u22121 rt \u2264 NT\u2211 t=1 rt \u2264 \u221a\u221a\u221a\u221aNT NT\u2211 t=1 r2t\n\u2264 \u221a NT \u221a 16e\u03b2NT dw ln(1 +\nNTC2g dw\u03bb ) + 8\u03b22NTC 2 hNT \u03bb2\nwhere the last inequality is due to (a+b)2 \u2264 2a2+2b2, Lemma 9, and Lemma 10. Note that \u03b2NT = O( d3wF 4 \u00b52 ) according to Lemma 8. By setting \u03bb = C\u03bb \u221a NT , we have Rgood = O\u0303( d3wF 4 \u221a NT \u00b52 ).\nConsider some bad epoch p, we can upper bound the cumulative regret incurred by all N clients in this epoch p as\ntp\u2211 t=tp\u22121+1 rt = N\u2211 i=1 \u2211 t\u2208Dtp,i\\Dtp\u22121,i rt \u2264 N\u2211 i=1 \u2211 t\u2208Dtp,i\\Dtp\u22121,i ( 2 \u221a \u03b2t\u22121,it\u2225\u2207fxt(w\u03020)\u2225\u03a3\u22121t\u22121,it + 2\u03b2t\u22121,itCh \u03bb ) \u2264 N\u2211 i=1 \u221a (|Dtp,i| \u2212 |Dtp\u22121,i|)8\u03b2NT \u2211 t\u2208Dtp,i\\Dtp\u22121,i \u2225\u2207fxt(w\u03020)\u22252\u03a3\u22121t\u22121,it + 8\u03b22NTC 2 h/C 2 \u03bb \u2264 N\u2211 i=1 \u221a 16\u03b2NT \u03b3 + 8\u03b22NTC 2 h/C 2 \u03bb\nwhere the first inequality is due to Lemma 14, the second is due to Cauchy-Schwartz inequality and (a+ b)2 \u2264 2a2 + 2b2, and the last is due to Lemma 10 and event-trigger with threshold \u03b3 in line 6 of Algorithm 1.\nSince there can be at most R = dw log (1 + NTC2g dw\u03bb ) bad epochs, the cumulative regret incurred in bad epochs of Phase II, denoted as Rbad is O\u0303(Ndw \u221a d3wF 4 \u00b52 \u221a \u03b3 + Ndw d3wF 4 \u00b52 ). By setting communication threshold \u03b3 = dwF 4T\n\u00b52N , we have Rbad = O\u0303( d3wF\n4 \u221a NT\n\u00b52 + d4wF 4N \u00b52 ). Combining cumulative\nregret incurred during both good and bad epochs, we have\nRphase II = Rgood +Rbad = O\u0303\n( d3wF 4\n\u00b52\n\u221a NT + d4wF 4\n\u00b52 N\n) .\nCommunication Cost in Phase II Consider some \u03b1 > 0. By pigeon-hole principle, there can be at most \u2308NT\u03b1 \u2309 epochs with length (total number of time steps) longer than \u03b1. Then consider some epoch with less than \u03b1 time steps. We denote the first time step of this epoch as ts and\nthe last as te, i.e., te \u2212 ts < \u03b1. Since the users appear in a round-robin manner, the number of interactions for any user i \u2208 [N ] satisfies |Dte,i| \u2212 |Dts,i| < \u03b1N . Due to the event-triggered in line 6 of Algorithm 1, we have log det(\u03a3te )det(\u03a3ts ) > \u03b3N \u03b1 . Using the pigeonhole principle again, we know that the number of epochs with less than \u03b1 time steps is at most \u2308R\u03b1\u03b3N \u2309. Therefore, the total number of synchronizations P \u2264 \u2308NT\u03b1 \u2309+ \u2308 R\u03b1 \u03b3N \u2309, and the RHS can be minimized by choosing \u03b1 = N \u221a \u03b3T/R,\nso that P \u2264 2 \u221a TR/\u03b3. With \u03b3 = dwF\n4T \u00b52N , P \u2264 2\n\u221a N log(1+NTC2g/(dw\u03bb))\u00b5 2 F 4 = O\u0303( \u221a N\u00b52/F 4). At\neach global synchronization, Algorithm 1 incurs 2N(d2w + dw) communication cost to update the statistics. Therefore, Cphase II = P \u00b7 2N(d2w + dw) = (N1.5d2w\u00b5/F 2)."
        },
        {
            "heading": "E EXPERIMENT SETUP & ADDITIONAL RESULTS",
            "text": "Synthetic dataset experiment setup Here we provide more details about the experiment setup on synthetic dataset in Section 6. Specifically, we compared all the algorithms on the following two synthetic functions\nf1(x) = \u2212 4\u2211\ni=1\n\u03b1\u0304i exp(\u2212 6\u2211\nj=1\nA\u0304ij(xj \u2212 P\u0304ij)2),\nf2(x) = 0.1 8\u2211 i=1 cos(5\u03c0xi)\u2212 8\u2211 i=1 x2i .\nBoth are popular synthetic functions for Bayesian optimization benchmarking1. The 6-dimensional function f1 is called Hartmann function, where\n\u03b1\u0304 = [1.0, 1.2, 3.0, 3.2] , A\u0304 =  10, 3, 17, 3.5, 1.7, 80.05, 10, 17, 0.1, 8, 143, 3.5, 1.7, 10, 17, 8 17, 8, 0.05, 10, 0.1, 14  , P\u0304 =  1312, 1696, 5569, 124, 8283, 58862329, 4135, 8307, 3736, 1004, 99912348, 1451, 3522, 2883, 3047, 6650 4047, 8828, 8732, 5743, 1091, 381  . And the 8-dimensional function f2 is a cosine mixture test function, which is named Cosine8. To be compatible with the discrete candidate set setting assumed in prior works (Wang et al., 2020; Li & Wang, 2022b; Li et al., 2022a), we generate the decision set X for the optimization of f1 by uniformly sampling 50 data points from [0, 1]6, and similarly for the optimization of f2, 50 data points from [\u22121, 1]8. Following our problem formulation in Section 3, at each time step t \u2208 [T ] (we set T = 100), each client i \u2208 [N ] (we set N = 20) picks a data point xt,i from the candidate set X , and then observes reward yt,i generated by function f1, f2 as mentioned above. Note that the values of both functions are negated, so by maximizing reward, the algorithms are trying to find data point that minimizes the function values. We should also note that the communication cost presented in the experiment results are defined as the total number of scalars transferred in the system (Wang et al., 2020), instead of number of time communication happens (Li & Wang, 2022a).\nReal-world dataset experiment setup & results To further evaluate Fed-GO-UCB\u2019s performance in a more challenging and practical scenario, we performed experiments using real-world datasets: MagicTelescope and Shuttle from the UCI Machine Learning Repository (Dua & Graff, 2017). We pre-processed these two datasets following the steps in prior works (Filippi et al., 2010), by partitioning the dataset in to 20 clusters, and using the centroid of each cluster as feature vector for the arm and its averaged response as mean reward. Then we simulated the federated bandit learning problem introduced in Section 3 with T = 100 and N = 100. From Figure 3, we can see that Fed-GO-UCB outperforms the baselines, with relatively low communication cost.\n1We chose them from the test functions available in BoTorch package. See https://botorch.org/ api/test_functions.html for more details."
        }
    ],
    "year": 2023
}