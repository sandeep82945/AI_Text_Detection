{
    "abstractText": "Optimization layers within neural network architectures have become increasingly popular for their ability to solve a wide range of machine learning tasks and to model domain-specific knowledge. However, designing optimization layers requires careful consideration as the underlying optimization problems might be infeasible during training. Motivated by applications in learning, control and robotics, this work focuses on convex quadratic programming (QP) layers. The specific structure of this type of optimization layer can be efficiently exploited for faster computations while still allowing rich modeling capabilities. We leverage primal-dual augmented Lagrangian techniques for computing derivatives of both feasible and infeasible QP solutions. More precisely, we propose a unified approach that tackles the differentiability of the closest feasible QP solutions in a classical l2 sense. The obtained Jacobian covers for feasible QPs the traditional implicit differentiation when it is valid and a weaker notion (i.e., conservative Jacobian) when it is infeasible. We then harness this approach to enrich the expressive capabilities of existing QP layers. More precisely, we show how differentiating through infeasible QPs during training enables to drive towards feasibility at test time a new range of QP layers. These layers notably demonstrate superior predictive performance in some conventional learning tasks. Additionally, we present alternative formulations that enhance numerical robustness, speed, and accuracy for training such layers. Along with these contributions, we provide an open-source C++ software package called QPLayer for differentiating feasible and infeasible convex QPs and which can be interfaced with modern learning frameworks.",
    "authors": [],
    "id": "SP:1475469f13f8f4155d20a058fd717eba0506a08a",
    "references": [
        {
            "authors": [
                "Brandon Amos",
                "J. Zico Kolter"
            ],
            "title": "Optnet: Differentiable optimization as a layer in neural networks",
            "venue": "In ICML, volume 70 of Proceedings of Machine Learning Research,",
            "year": 2017
        },
        {
            "authors": [
                "Brandon Amos",
                "Lei Xu",
                "J. Zico Kolter"
            ],
            "title": "Input convex neural networks",
            "venue": "In ICML,",
            "year": 2017
        },
        {
            "authors": [
                "Brandon Amos",
                "Ivan Dario Jimenez Rodriguez",
                "Jacob Sacks",
                "Byron Boots",
                "J. Zico Kolter"
            ],
            "title": "Differentiable MPC for end-to-end planning and control",
            "venue": "In NeurIPS,",
            "year": 2018
        },
        {
            "authors": [
                "C.W. Anderson"
            ],
            "title": "Learning to control an inverted pendulum using neural networks",
            "venue": "IEEE Control Systems Magazine,",
            "year": 1989
        },
        {
            "authors": [
                "Shaojie Bai",
                "J. Zico Kolter",
                "Vladlen Koltun"
            ],
            "title": "Deep equilibrium models",
            "venue": "In NeurIPS,",
            "year": 2019
        },
        {
            "authors": [
                "Antoine Bambade",
                "Sarah El-Kazdadi",
                "Adrien Taylor",
                "Justin Carpentier"
            ],
            "title": "PROX-QP: Yet another Quadratic Programming Solver for Robotics and beyond",
            "venue": "In RSS 2022 - Robotics: Science and Systems,",
            "year": 2022
        },
        {
            "authors": [
                "David Belanger",
                "Andrew McCallum"
            ],
            "title": "Structured prediction energy networks",
            "venue": "In ICML,",
            "year": 2016
        },
        {
            "authors": [
                "David Belanger",
                "Bishan Yang",
                "Andrew McCallum"
            ],
            "title": "End-to-end learning for structured prediction energy networks",
            "venue": "In ICML, volume 70 of Proceedings of Machine Learning Research,",
            "year": 2017
        },
        {
            "authors": [
                "Mathieu Blondel",
                "Quentin Berthet",
                "Marco Cuturi",
                "Roy Frostig",
                "Stephan Hoyer",
                "Felipe Llinares-L\u00f3pez",
                "Fabian Pedregosa",
                "Jean-Philippe Vert"
            ],
            "title": "Efficient and modular implicit differentiation",
            "venue": "In NeurIPS,",
            "year": 2022
        },
        {
            "authors": [
                "J\u00e9r\u00f4me Bolte",
                "Edouard Pauwels"
            ],
            "title": "Conservative set valued fields, automatic differentiation, stochastic gradient method and deep learning",
            "venue": "Mathematical Programming,",
            "year": 2020
        },
        {
            "authors": [
                "J\u00e9r\u00f4me Bolte",
                "Tam Le",
                "Edouard Pauwels",
                "Antonio Silveti-Falls"
            ],
            "title": "Nonsmooth implicit differentiation for machine-learning and optimization",
            "venue": "In NeurIPS,",
            "year": 2021
        },
        {
            "authors": [
                "Oumayma Bounou",
                "Jean Ponce",
                "Justin Carpentier"
            ],
            "title": "Online learning and control of complex dynamical systems from sensory input",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Andrew Butler",
                "Roy H. Kwon"
            ],
            "title": "Efficient differentiable quadratic programming layers: an ADMM approach",
            "venue": "Comput. Optim. Appl.,",
            "year": 2023
        },
        {
            "authors": [
                "Tian Qi Chen",
                "Yulia Rubanova",
                "Jesse Bettencourt",
                "David Duvenaud"
            ],
            "title": "Neural ordinary differential equations",
            "venue": "In NeurIPS, pp",
            "year": 2018
        },
        {
            "authors": [
                "Alice Chiche",
                "Jean Charles Gilbert"
            ],
            "title": "How the augmented Lagrangian algorithm can deal with an infeasible convex quadratic optimization problem",
            "venue": "Journal of Convex Analysis,",
            "year": 2016
        },
        {
            "authors": [
                "Filipe de Avila Belbute-Peres",
                "Josh Tenenbaum",
                "J. Zico Kolter"
            ],
            "title": "End-to-end differentiable physics for learning and control",
            "venue": "In NeurIPS,",
            "year": 2018
        },
        {
            "authors": [
                "A. De Marchi"
            ],
            "title": "On a primal-dual Newton proximal method for convex quadratic programs",
            "venue": "Computational Optimization and Applications,",
            "year": 2022
        },
        {
            "authors": [
                "Justin Domke"
            ],
            "title": "Generic methods for optimization-based modeling",
            "venue": "In AISTATS,",
            "year": 2012
        },
        {
            "authors": [
                "Asen L. Dontchev",
                "R. Tyrrell Rockafellar"
            ],
            "title": "Implicit functions and solution mappings",
            "year": 2009
        },
        {
            "authors": [
                "Priya L. Donti",
                "J. Zico Kolter",
                "Brandon Amos"
            ],
            "title": "Task-based end-to-end model learning in stochastic optimization",
            "venue": "In NIPS, pp",
            "year": 2017
        },
        {
            "authors": [
                "Anthony V. Fiacco",
                "G.P. McCormick"
            ],
            "title": "Nonlinear Programming: Sequential Unconstrained Minimization Techniques",
            "year": 1968
        },
        {
            "authors": [
                "Samy Wu Fung",
                "Howard Heaton",
                "Qiuwei Li",
                "Daniel McKenzie",
                "Stanley J. Osher",
                "Wotao Yin"
            ],
            "title": "JFB: jacobian-free backpropagation for implicit networks",
            "venue": "In AAAI,",
            "year": 2022
        },
        {
            "authors": [
                "Zhenglin Geng",
                "Daniel Johnson",
                "Ronald Fedkiw"
            ],
            "title": "Coercing machine learning to output physically accurate results",
            "venue": "J. Comput. Phys.,",
            "year": 2020
        },
        {
            "authors": [
                "Zhengyang Geng",
                "Meng-Hao Guo",
                "Hongxu Chen",
                "Xia Li",
                "Ke Wei",
                "Zhouchen Lin"
            ],
            "title": "Is attention better than matrix decomposition? In ICLR",
            "venue": "OpenReview.net, 2021a. URL https://dblp. org/rec/conf/iclr/GengGCLWL21",
            "year": 2021
        },
        {
            "authors": [
                "Zhengyang Geng",
                "Xin-Yu Zhang",
                "Shaojie Bai",
                "Yisen Wang",
                "Zhouchen Lin"
            ],
            "title": "On training implicit models",
            "venue": "In NeurIPS, pp",
            "year": 2021
        },
        {
            "authors": [
                "Jean Charles Gilbert"
            ],
            "title": "Fragments d\u2019Optimisation Diff\u00e9rentiable - Th\u00e9ories et Algorithmes",
            "venue": "URL https://hal.inria.fr/hal-03347060",
            "year": 2021
        },
        {
            "authors": [
                "Stephen Gould",
                "Basura Fernando",
                "Anoop Cherian",
                "Peter Anderson",
                "Rodrigo Santa Cruz",
                "Edison Guo"
            ],
            "title": "On differentiating parameterized argmin and argmax problems with application to bi-level optimization",
            "venue": "CoRR, abs/1607.05447,",
            "year": 2016
        },
        {
            "authors": [
                "Fangda Gu",
                "Heng Chang",
                "Wenwu Zhu",
                "Somayeh Sojoudi",
                "Laurent El Ghaoui"
            ],
            "title": "Implicit graph neural networks",
            "venue": "In NeurIPS,",
            "year": 2020
        },
        {
            "authors": [
                "Osman G\u00fcler"
            ],
            "title": "On the convergence of the proximal point algorithm for convex minimization",
            "venue": "SIAM Journal on Control and Optimization,",
            "year": 1991
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Jimmy Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "CoRR, abs/1412.6980,",
            "year": 2014
        },
        {
            "authors": [
                "Quentin Le Lidec",
                "Igor Kalevatykh",
                "Ivan Laptev",
                "Cordelia Schmid",
                "Justin Carpentier"
            ],
            "title": "Differentiable simulation for physical system identification",
            "venue": "IEEE Robotics and Automation Letters,",
            "year": 2021
        },
        {
            "authors": [
                "Kwonjoon Lee",
                "Subhransu Maji",
                "Avinash Ravichandran",
                "Stefano Soatto"
            ],
            "title": "Meta-learning with differentiable convex optimization",
            "venue": "CoRR, abs/1904.03758,",
            "year": 2019
        },
        {
            "authors": [
                "Quentin Le Lidec",
                "Louis Montaut",
                "Cordelia Schmid",
                "Ivan Laptev",
                "Justin Carpentier"
            ],
            "title": "Leveraging randomized smoothing for optimal control of nonsmooth dynamical systems",
            "venue": "CoRR, abs/2203.03986,",
            "year": 2022
        },
        {
            "authors": [
                "Luke Metz",
                "Niru Maheswaranathan",
                "Jeremy Nixon",
                "C. Daniel Freeman",
                "Jascha Sohl-Dickstein"
            ],
            "title": "Understanding and correcting pathologies in the training of learned optimizers",
            "venue": "In ICML,",
            "year": 2019
        },
        {
            "authors": [
                "Mateusz Michalkiewicz",
                "Jhony Kaesemodel Pontes",
                "Dominic Jack",
                "Mahsa Baktashmotlagh",
                "Anders P. Eriksson"
            ],
            "title": "Implicit surface representations as layers in neural networks",
            "venue": "In ICCV,",
            "year": 2019
        },
        {
            "authors": [
                "Vishal Monga",
                "Yuelong Li",
                "Yonina C. Eldar"
            ],
            "title": "Algorithm unrolling: Interpretable, efficient deep learning for signal and image processing",
            "venue": "IEEE Signal Process. Mag.,",
            "year": 2021
        },
        {
            "authors": [
                "Christopher C. Paige",
                "Michael A. Saunders"
            ],
            "title": "LSQR: an algorithm for sparse linear equations and sparse least squares",
            "venue": "ACM Trans. Math. Softw.,",
            "year": 1982
        },
        {
            "authors": [
                "Neal Parikh",
                "Stephen Boyd"
            ],
            "title": "Proximal algorithms. Foundations and Trends\u00ae in Optimization, 1 (3):127\u2013239",
            "venue": "ISSN 2167-3888",
            "year": 2014
        },
        {
            "authors": [
                "Stephen M. Robinson"
            ],
            "title": "Strongly regular generalized equations",
            "venue": "Math. Oper. Res.,",
            "year": 1980
        },
        {
            "authors": [
                "R.T. Rockafellar"
            ],
            "title": "Augmented Lagrangians and Applications of the Proximal Point Algorithm in Convex Programming",
            "venue": "Mathematics of Operations Research,",
            "year": 1976
        },
        {
            "authors": [
                "Damien Scieur",
                "Gauthier Gidel",
                "Quentin Bertrand",
                "Fabian Pedregosa"
            ],
            "title": "The curse of unrolling: Rate of differentiating through optimization",
            "venue": "In NeurIPS,",
            "year": 2022
        },
        {
            "authors": [
                "Akshay Sharma",
                "Mathieu Besan\u00e7on",
                "Joaquim Dias Garcia",
                "Beno\u00eet Legat"
            ],
            "title": "Flexible differentiable optimization via model transformations",
            "venue": "CoRR, abs/2206.06135,",
            "year": 2022
        },
        {
            "authors": [
                "H.J. Terry Suh",
                "Tao Pang",
                "Russ Tedrake"
            ],
            "title": "Bundled gradients through contact via randomized smoothing",
            "venue": "CoRR, abs/2109.05143,",
            "year": 2021
        },
        {
            "authors": [
                "Defeng Sun",
                "Liqun Qi"
            ],
            "title": "On ncp-functions",
            "venue": "Comput. Optim. Appl.,",
            "year": 1999
        },
        {
            "authors": [
                "Haixiang Sun",
                "Ye Shi",
                "Jingya Wang",
                "Hoang Duong Tuan",
                "H. Vincent Poor",
                "Dacheng Tao"
            ],
            "title": "Alternating differentiation for optimization layers",
            "venue": "CoRR, abs/2210.01802,",
            "year": 2022
        },
        {
            "authors": [
                "Po-Wei Wang",
                "Priya L. Donti",
                "Bryan Wilder",
                "J. Zico Kolter"
            ],
            "title": "Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver",
            "venue": "In ICML,",
            "year": 2019
        },
        {
            "authors": [
                "Qianggong Zhang",
                "Yanyang Gu",
                "Mateusz Michalkiewicz",
                "Mahsa Baktashmotlagh",
                "Anders P. Eriksson"
            ],
            "title": "Implicitly defined layers in neural networks",
            "venue": "CoRR, abs/2003.01822,",
            "year": 2020
        },
        {
            "authors": [
                "Kolter"
            ],
            "title": "A complete description of the cart-pole swing-up task",
            "year": 2017
        }
    ],
    "sections": [
        {
            "text": "Optimization layers within neural network architectures have become increasingly popular for their ability to solve a wide range of machine learning tasks and to model domain-specific knowledge. However, designing optimization layers requires careful consideration as the underlying optimization problems might be infeasible during training. Motivated by applications in learning, control and robotics, this work focuses on convex quadratic programming (QP) layers. The specific structure of this type of optimization layer can be efficiently exploited for faster computations while still allowing rich modeling capabilities. We leverage primal-dual augmented Lagrangian techniques for computing derivatives of both feasible and infeasible QP solutions. More precisely, we propose a unified approach that tackles the differentiability of the closest feasible QP solutions in a classical \u21132 sense. The obtained Jacobian covers for feasible QPs the traditional implicit differentiation when it is valid and a weaker notion (i.e., conservative Jacobian) when it is infeasible. We then harness this approach to enrich the expressive capabilities of existing QP layers. More precisely, we show how differentiating through infeasible QPs during training enables to drive towards feasibility at test time a new range of QP layers. These layers notably demonstrate superior predictive performance in some conventional learning tasks. Additionally, we present alternative formulations that enhance numerical robustness, speed, and accuracy for training such layers. Along with these contributions, we provide an open-source C++ software package called QPLayer for differentiating feasible and infeasible convex QPs and which can be interfaced with modern learning frameworks."
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "Incorporating differentiable optimization problems as layers within neural networks has recently become practical and effective for solving certain machine learning tasks, see, for instance (Geng et al., 2020; Amos & Kolter, 2017; Lee et al., 2019; Le Lidec et al., 2021; Donti et al., 2017; de Avila Belbute-Peres et al., 2018; Amos et al., 2018; Bounou et al., 2021). Such layers allow capturing useful domain-specific knowledge or priors. Unlike conventional neural networks, where the output of each layer is provided by a simple (explicit) function of its input, the input of an optimization layer is the parameter of an optimization problem, and its output is a solution to this problem. Figure 1 and Figure 2 provide two illustrative examples of a neural network and a QP layer. Both layers have potentially fixed (in blue) and trained (in red) parameters. The main difference is that the output (i.e., y\u22c6 in Figure 1) of the feed-forward neural network has a closed-form expression, whereas the output of the QP layer is the solution of a constrained QP (i.e., y\u22c6 in Figure 2). Finally, note that extra parameters (i.e., zt and ht in red in Figure 2) are trained to ensure the quadratic program is always well-posed during training.\nIn this work, we focus on convex Quadratic Programming (QP) layers, a specific type of optimization layer that offers a rich modeling power (Amos & Kolter, 2017, Section 3.2). A convex QP\nparameterized by \u03b8 is defined as follows\nx\u22c6(\u03b8) \u2208 argmin x\u2208Rn\n{ f(x; \u03b8) := 1\n2 x\u22a4H(\u03b8)x+ x\u22a4g(\u03b8) } s.t. C(\u03b8)x \u2a7d u(\u03b8),\n(QP(\u03b8))\nwhere H(\u03b8) \u2208 Sn+(R) is a real symmetric positive semi-definite matrix of Rn\u00d7n, g(\u03b8) \u2208 Rn, C(\u03b8) \u2208 Rni\u00d7n and u(\u03b8) \u2208 Rni . n is the problem dimension, while ni is the number of inequality constraints. We will abusively denote H , g, C, and u without explicit dependence on \u03b8 when this dependence is clear from the context or does not generate any ambiguity. In order to use QP(\u03b8) as a learning tool that can be trained with standard optimization techniques, we need to be able to differentiate x\u22c6(\u03b8) w.r.t. \u03b8, which is challenging for a few reasons. First, there is usually no practical way to compute a closed-form for x\u22c6(\u03b8), even when QP(\u03b8) is well-defined. Second, even when such an x\u22c6(\u03b8) exists, there is no guarantee for it to be unique nor differentiable w.r.t. \u03b8 (see, e.g., the assumptions of the implicit function theorem (Dontchev & Rockafellar, 2009, Theorem 1B.1)). As a consequence, concurrent approaches are generally based on architectures enforcing satisfaction of some strong assumptions. In particular, to the best of our knowledge, previous approaches enforce primal feasibility of the layer during training, which generally requires additional learning variables and limits the modeling power of those layers. For instance, as in (Amos & Kolter, 2017), learning QP(\u03b8) requires imposing its feasible set to be non-empty. For imposing this while learning C, the authors also learn z \u2208 Rn and h \u2208 Rni and u of the form u = Cz + exp(h) (similarly to Figure 2), thereby preventing, among others, u from being fixed independently of the learning.\nThis work makes the following contributions:\n\u2022 We propose a unified approach to tackle the differentiability of both feasible and infeasible QPs. The main idea consists in extending the definition of x\u22c6(\u03b8) to be either a solution to QP(\u03b8) when it is feasible or a solution of the closest feasible QP (in the least-square sense) when it is not. By relying on the notion of conservative Jacobian by (Bolte et al., 2021; Bolte & Pauwels, 2020), we notably show that the KKT map G of this extended problem is path differentiable w.r.t. \u03b8 and x\u22c6 (Section 3.2). In this context, the Jacobian \u2202x\n\u22c6(\u03b8) \u2202\u03b8 is\ndefined as the least-square solution of the linear system formed by applying the implicit function theorem to G Section 3.3. We show that this definition consistently covers the differentiability of feasible QPs as with the traditional implicit differentiation (Amos & Kolter, 2017) when it is valid and with the least-square estimate proposed by (Agrawal et al., 2019, Appendix B) otherwise.\n\u2022 In Section 3.4 we provide efficient ways to compute the Jacobian \u2202x \u22c6(\u03b8) \u2202\u03b8 in forward and\nbackward automatic differentiation modes. \u2022 In Section 4 we demonstrate how the approach enables dealing with possibly infeasi-\nble QP(\u03b8) during training, while converging for test time to a feasible layer. We illustrate how it allows to train a broader range of QP layers (e.g., learning QPs that are not generically feasible). More precisely, we will show how to drive towards feasibility at test time the QP layer provided in Figure 3. Learning At (in red) is not obvious since nothing guarantees a priori that the fixed equality constraint vector (of ones) lies in the range space of At. We will see that learning such layer notably provides better predictive power for some classic learning tasks.\nBased on these developments, we provide QPLayer, an open-source implementation with efficient forward and backward passes, released upon paper acceptance. It takes advantage, among others, of recent advances in solving of QP problems to output in the forward pass the closest feasible QP solution in \u21132-sense as soon as the program is primal infeasible (Chiche & Gilbert, 2016). Section 4 highlights for different learning tasks the numerical robustness, accuracy, and speed of our approach against other state-of-the-art methods."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "Differentiation for optimization layers. Under certain regularity conditions, it is possible to implicitly differentiate the optimality conditions of convex optimization problems. (Gould et al., 2016; Gilbert, 2021; Fiacco & McCormick, 1968; Robinson, 1980) present general conditions and techniques under which it is possible to differentiate through constrained optimization problems using the implicit function theorem. (Bolte et al., 2021; Bolte & Pauwels, 2020) present extensions to nonsmooth (not necessarily differentiable) functions for machine learning and optimization applications. (Amos & Kolter, 2017) treats the specific case of QPs with a dedicated network architecture, OptNet, and a specialized batched interior-point solver, Qpth, which allows for efficient backpropagation. More recently, (Butler & Kwon, 2023) proposed an alternative approach based on the differentiation of ADMM steps, yet dealing only with equality and box inequality constraints1. For more general convex optimization, (Amos et al., 2018) proposed CvxpyLayer that differentiates through \"Disciplined Convex Programs\" using an LSQR (Paige & Saunders, 1982) solver to speed up the differentiation procedure. (Sun et al., 2022) has recently proposed an ADMM-type method, called Alt-Diff, to alternatively solving a constrained convex optimization program and obtaining approximate Jacobians at the current approximate solutions.(Blondel et al., 2022) also proposed a generic solver, JaxOpt, based on an implicit automatic differentiation mechanism leveraging the Jax framework. Finally, let us mention the work (Sharma et al., 2022), which provided a Julia library, DiffOpt.jl, for differentiable QP and conic optimization (or any model that can be reformulated into these standard forms).\nUnrolling methods. Argmin and Argmax operations can be approximated by first-order methods, which can be unrolled (Domke, 2012; Monga et al., 2021). These architectures typically introduce an\n1The associated R solver is not yet publicly available.\noptimization procedure such as gradient descent into the inference procedure (Belanger & McCallum, 2016; Belanger et al., 2017; Amos et al., 2017; Metz et al., 2019), which is usually truncated to a predefined number of iterations. Recently, (Scieur et al., 2022) highlighted the \"curse of unrolling\" by showing that for unconstrained quadratic optimization, there is a tradeoff between the convergence speed of the iterates and that of the Jacobian. Although unrolling methods are easy to implement, most of their applications are limited to unconstrained problems. Indeed, if constraints are added, the unrolling solutions have to be projected into the feasible region, significantly increasing the computational burdens.\nImplicit models. Implicit models replace explicit expressions in neural networks with layers defined by implicit functions (Zhang et al., 2020). As for optimization layers, the backward pass requires solving nonlinear Jacobian-based equations arising from the implicit function theorem. Recently, there have been a growing number of applications using them, such as neural ODE (Chen et al., 2018), deep equilibrium models (Bai et al., 2019), logical reasoning in deep neural network (using MAXSAT SDP relaxation) (Wang et al., 2019), implicit surface representation (Michalkiewicz et al., 2019), attention mechanisms (Geng et al., 2021a), graph neural networks (Gu et al., 2020). However, this method is not suitable for optimization layers with complicated constraints. Recently, (Fung et al., 2022) proposes a matrix-free approach to decrease computational costs, and (Geng et al., 2021b) proposes a phantom gradient that relies on fixed-point unrolling and a Neumann series for faster computations of approximate update directions."
        },
        {
            "heading": "3 THE EXTENDED CONSERVATIVE JACOBIAN FOR CONVEX QPS",
            "text": "This section introduces the main contribution of this work: an extended conservative Jacobian for the solutions to QP(\u03b8) allowing to simultaneously deal with feasible and infeasible QPs, as provided in Section 3.2 and Section 3.3. Section 3.4 proposes efficient algorithms for computing them in forward and backward modes. For exposition purposes, Appendix C.1 illustrates the concepts on a few simple examples."
        },
        {
            "heading": "3.1 PROBLEM FORMULATION",
            "text": "For differentiating QPs, we solve a hierarchic problem QP-H(\u03b8) which is equivalent to QP(\u03b8) when QP(\u03b8) is primal feasible (i.e., there exists x s.t. C(\u03b8)x \u2a7d u(\u03b8))\ns\u22c6(\u03b8) = arg min s\u2208Rni 1 2\u2225s\u2225 2 2\ns.t. x\u22c6(\u03b8), z\u22c6(\u03b8) \u2208 arg min x\u2208Rn max z\u2208Rni+\nL(x, z, s; \u03b8), (QP-H(\u03b8))\nwith L(x, z, s; \u03b8) := 12x \u22a4H(\u03b8)x + x\u22a4g(\u03b8) + z\u22a4(C(\u03b8)x \u2212 u(\u03b8) \u2212 s) (namely the Lagrangian of QP(\u03b8) augmented with a slack variable s). The following assumption is necessary and sufficient for guaranteeing QP-H(\u03b8) to have a solution. In this situation, QP-H(\u03b8) is therefore well-posed and s\u22c6 is referred to as the optimal shift. It provides a measure of the distance of QP(\u03b8) to be primal infeasible in \u21132-sense (hence s\u22c6 = 0 iff QP(\u03b8) is feasible). Assumption 1. H(\u03b8) is symmetric positive definite in the direction of g(\u03b8) or g(\u03b8) is orthogonal to the recession cone of QP(\u03b8), i.e., g(\u03b8) \u22a5 C\u221e(\u03b8) := {y \u2208 Rn|C(\u03b8)[x + \u03c4y] \u2a7d u(\u03b8) s.t. C(\u03b8)x \u2a7d u(\u03b8), \u03c4 \u2a7e 0}.\nThe existence of a solution (x\u22c6(\u03b8), z\u22c6(\u03b8), s\u22c6(\u03b8)) is also equivalent to the dual of QP(\u03b8) having a non-empty domain (i.e., being proper), see (Chiche & Gilbert, 2016, Assumption 2.6 and Proposition 2.5)). So, the approach proposed here allows differentiating through dual feasible convex QPs."
        },
        {
            "heading": "3.2 THE CLOSEST FEASIBLE QP",
            "text": "In what follows, we deal with QP-H(\u03b8) via a nonlinear map G:\nG(x, z, t; \u03b8) := H(\u03b8)x+ g(\u03b8) + C(\u03b8) \u22a4z\nC(\u03b8)x\u2212 u(\u03b8)\u2212 t [[t]\u2212 + z]+ \u2212 z C(\u03b8)\u22a4[t]+\n , (G)\nwhere [.]+ and [.]\u2212 respectively correspond to component-wise projections on the non-negative and non-positive orthants. The following lemma guarantees solutions to QP-H(\u03b8) to be zeros of G (see proof in Appendix A). Lemma 1. Let H(\u03b8) \u2208 Sn+(R), g(\u03b8) \u2208 Rn, C(\u03b8) \u2208 Rni\u00d7n and u(\u03b8) \u2208 Rni be satisfying Assumption 1. It holds that (x\u22c6, z\u22c6, s\u22c6) solves QP-H(\u03b8) iff there exists t\u22c6 \u2208 Rni s.t. G(x\u22c6, z\u22c6, t\u22c6; \u03b8) = 0 and s\u22c6 = [t\u22c6]+."
        },
        {
            "heading": "3.3 THE EXTENDED CONSERVATIVE JACOBIAN",
            "text": "For differentiating through G, we rely on the notion of extended conservative Jacobian (ECJ). As provided by the following lemma, the nonlinear map G(x, z, t; \u03b8) is path differentiable (see (Bolte & Pauwels, 2020, Definition 3)) w.r.t. x, z, t and also w.r.t. \u03b8 under the assumption that H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) are differentiable w.r.t. \u03b8. This lemma is proved in Appendix B. Lemma 2. G is path differentiable w.r.t. x\u22c6, z\u22c6 and t\u22c6. Furthermore, if H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) are differentiable w.r.t. \u03b8, then G is path differentiable w.r.t. \u03b8. Definition 1. Let H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) be differentiable w.r.t. \u03b8 and satisfying Assumption 1. Let v\u22c6 = (x\u22c6, z\u22c6, t\u22c6) \u2208 Rn \u00d7 Rni+ \u00d7 Rni s.t. G(x\u22c6, z\u22c6, t\u22c6; \u03b8) = 0. We refer to the ECJs of x\u22c6, z\u22c6 and t\u22c6, respectively denoted by \u2202x \u22c6\n\u2202\u03b8 , \u2202z\u22c6 \u2202\u03b8 and \u2202t\u22c6 \u2202\u03b8 , as solutions of the following problem( \u2202x\u22c6\n\u2202\u03b8 , \u2202z\u22c6 \u2202\u03b8 , \u2202t\u22c6 \u2202\u03b8\n) \u2208 argmin\nw\n\u2225\u2225\u2225\u2225\u2202G(x\u22c6, z\u22c6, t\u22c6; \u03b8)\u2202v\u22c6 w + \u2202G(x\u22c6, z\u22c6, t\u22c6; \u03b8)\u2202\u03b8 \u2225\u2225\u2225\u22252 2 . (1)\nFurthermore, we refer to an ECJ of s\u22c6 = [t\u22c6]+, denoted by \u2202s \u22c6 \u2202\u03b8 , any element satisfying \u03a0 \u2202t\u22c6 \u2202\u03b8 \u2208 \u2202s\u22c6\n\u2202\u03b8 , with \u03a0 \u2208 \u2202([.]+)(t\u22c6) a subgradient of the positive orthant evaluated in t\u22c6.\nAs shown in the next section the ECJs match the definitions of standard Jacobians under standard assumptions guaranteeing differentiability (when the QP is feasible), as provided by (Amos & Kolter, 2017; Dontchev & Rockafellar, 2009). When the QP is feasible but not differentiable, the ECJ corresponds to a least-square approximation specialized for QPs. A similar practical least-square estimate was proposed in (Agrawal et al., 2019, Appendix B) for differentiating primal solutions of second-order cones (SOCs)2. (Blondel et al., 2022, Section 2.1) proposed a similar estimate."
        },
        {
            "heading": "3.4 DERIVING AN EXTENDED CONSERVATIVE JACOBIAN",
            "text": "This section derives an ECJ and incorporates it in a backpropagation algorithm. It also shows how to efficiently compute this ECJ under primal feasibility."
        },
        {
            "heading": "3.4.1 GENERAL CASE: DEALING WITH BOTH FEASIBLE AND INFEASIBLE QPS",
            "text": "In the following, we provide forward and backward pass algorithms to compute ECJs for both feasible and infeasible QPs.\nForward pass: Let H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) be differentiable w.r.t. \u03b8 and satisfying Assumption 1, and x\u22c6, z\u22c6, t\u22c6 s.t. G(x\u22c6, z\u22c6, t\u22c6; \u03b8) = 0. We show in Appendix B.2.1.1 that we can efficiently derive ECJs of x\u22c6, z\u22c6 and t\u22c6 by solving the following QP using an augmented Lagrangian-based algorithm (Rockafellar, 1976)\n\u2202x\u22c6 \u2202\u03b8 , \u2202z\u22c6 \u2202\u03b8 , \u2202t\u22c6 \u2202\u03b8 \u2208 argmin\n\u2202x \u2202\u03b8 , \u2202z \u2202\u03b8 , \u2202t \u2202\u03b8 \u2225\u2225\u2225\u2225\u2225\u2225\u2225\u2225 H C \u22a4 0 C 0 \u2212I 0 \u03a01 \u2212 I \u03a01\u03a02 0 0 C\u22a4(I \u2212\u03a02)  \u2202x\u2202\u03b8\u2202z \u2202\u03b8 \u2202t \u2202\u03b8 +  \u2202H \u2202\u03b8 x \u22c6 + \u2202g\u2202\u03b8 + \u2202C \u2202\u03b8 \u22a4 z\u22c6 \u2202C \u2202\u03b8 x \u22c6 \u2212 \u2202u\u2202\u03b8 0 \u2202C\u22a4\n\u2202\u03b8 [t \u22c6]+\n \u2225\u2225\u2225\u2225\u2225\u2225\u2225\u2225 2\n2\n,\n(2) where \u03a01 and \u03a02 are binary diagonal matrices respectively corresponding to the subdifferentials \u2202([.]+)([t \u22c6]\u2212 + z \u22c6) and \u2202([.]\u2212)(t\u22c6), with the following specific choices in zeros\n(\u03a01)i = 1 when [t\u22c6i ]\u2212 + z \u22c6 i = 0, (\u03a02)i = 1 when t \u22c6 i = 0. (3)\n2More precisely, (Agrawal et al., 2019, Appendix B) relies on a series of assumptions allowing to simplify the computations. In particular, they assume that \u2202z \u22c6\n\u2202\u03b8 = 0 and \u2202t\n\u22c6\n\u2202\u03b8 = 0, where t\u22c6 is a slack variable.\nFurthermore, an ECJ of s\u22c6 can be obtained via (1\u2212\u03a02)\u2202t \u22c6 \u2202\u03b8 \u2208 \u2202s\u22c6 \u2202\u03b8 .\nUnder nonsingularity assumptions and infeasibility of QP(\u03b8), the next lemma provides an example case ensuring that the ECJs consistently correspond to conservative Jacobians Bolte & Pauwels (2020). Its proof is available in Appendix B.2.1. Lemma 3. Let C(\u03b8), u(\u03b8) be differentiable w.r.t. \u03b8, and H = 0, and g be fixed w.r.t. \u03b8 and satisfying Assumption 1. If s\u22c6 > 0 and z\u22c6 = 0 (i.e., it does not satisfy strict complementarity) and C is full row rank, then the ECJs of x\u22c6, z\u22c6, t\u22c6, and s\u22c6 correspond to conservative Jacobians.\nAs s\u22c6 is a direct output of an augmented Lagrangian-based algorithm (Chiche & Gilbert, 2016), in what follows, we work with s\u22c6 instead of t\u22c6.\nBackward pass: Let h : Rn \u00d7 (Rni)2 \u2192 R be a differentiable function, and let H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) be differentiable w.r.t. \u03b8 and satisfying Assumption 1. Then, denoting L(\u03b8) := h(x\u22c6(\u03b8), z\u22c6(\u03b8), s\u22c6(\u03b8)) and following the methodology provided in (Amos & Kolter, 2017, Section 3), we show in Appendix B.2.1.2 that under assumptions of Lemma 3 a conservative Jacobian \u2202L\u2202\u03b8 can be obtained from the usual chain rule: \u2202L \u2202\u03b8 = (b\u22c61) \u22a4 \u2202H \u2202\u03b8 x\u22c6 + (b\u22c61) \u22a4 \u2202g \u2202\u03b8 + (b\u22c62) \u22a4 \u2202C \u2202\u03b8 x\u22c6 + (z\u22c6)\u22a4 \u2202C \u2202\u03b8 b\u22c61 + (s \u22c6)\u22a4 \u2202C \u2202\u03b8 b\u22c64 \u2212 (b\u22c62)\u22a4 \u2202u \u2202\u03b8 , (4) where b\u22c61, b \u22c6 2, b \u22c6 3 and b\n\u22c6 4 are solutions of the linear systemH C\u22a4 0 0C 0 (I \u2212\u03a01) 0 0 \u2212I \u2212\u03a01\u03a02 (1\u2212\u03a02)C  b \u22c6 1 b\u22c62 b\u22c63 b\u22c64  = \u2212  \u2202L\u2202x\u22c6\u2202L \u2202z\u22c6 \u2202L \u2202s\u22c6  . (5) If not, the methodology proposed in (Amos & Kolter, 2017, Section 3) cannot be used. Hence, ECJs of x\u22c6, z\u22c6 and s\u22c6 are derived using forward mode and \u2202L\u2202\u03b8 is recovered from\n\u2202L \u2202\u03b8 = \u2202L \u2202x\u22c6\n\u22a4 \u2202x\u22c6\n\u2202\u03b8 + \u2202L \u2202z\u22c6\n\u22a4 \u2202z\u22c6\n\u2202\u03b8 + \u2202L \u2202s\u22c6\n\u22a4 \u2202s\u22c6\n\u2202\u03b8 . (6)\nIn practice, we provide a feasibility tolerance that can be set by the user and above which equation 5 is considered not accurate enough or infeasible. In such cases, the forward mode is used internally."
        },
        {
            "heading": "3.4.2 EXPLOITING PRIMAL FEASIBILITY OF THE QP",
            "text": "In this section, we exploit feasibility of the QP for simplifying the computations. First, for the forward pass, the QP needs only be feasible for the value of \u03b8 under consideration. For the backward pass, we exploit the standard assumption (see (Amos & Kolter, 2017)) of the QP being constructively feasible for all values of \u03b8 (which is of course restrictive, but which can be exploited for efficiency).\nForward pass: When QP(\u03b8) is feasible and H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) are differentiable w.r.t. \u03b8 and satisfy Assumption 1, we show in Appendix B.2.2.1 that ECJs can be obtained as a solution to the simpler:\n\u2202x\u22c6 \u2202\u03b8 , \u2202z\u22c6 \u2202\u03b8 \u2208 argmin\n\u2202x \u2202\u03b8 , \u2202z \u2202\u03b8\n\u2225\u2225\u2225\u2225\u2225 [ H C\u22a4 \u03a01\u221a 1+\u03a01 C \u03a01 \u2212 I ] [ \u2202x \u2202\u03b8 \u2202z \u2202\u03b8 ] + [ \u2202H \u2202\u03b8 x \u22c6 + \u2202g\u2202\u03b8 + \u2202C \u2202\u03b8 \u22a4 z\u22c6 \u03a01\u221a 1+\u03a01 ( \u2202C \u2202\u03b8 x \u22c6 \u2212 \u2202u\u2202\u03b8 )]\u2225\u2225\u2225\u2225\u2225 2\n2\n, (7)\n\u2202t\u22c6 \u2202\u03b8 = (I +\u03a01)\n\u22121 ( C \u2202x\u22c6\n\u2202\u03b8 +\n\u2202C \u2202\u03b8 x\u22c6 \u2212 \u2202u \u2202\u03b8\n) , (8)\nwhere \u03a01 is a binary diagonal matrices representing the subdifferential \u2202[.]+(Cx\u22c6 \u2212 u+ z\u22c6) with the following specific choice:\n(\u03a01)i = 1 when Cix\u22c6 \u2212 ui + z\u22c6i = 0. (9) The following lemma (see proof in Appendix B.2.1.2) guarantees that, under standard assumptions, solutions to equation 7 correspond to standard Jacobians (see, e.g., (Amos & Kolter, 2017)). Lemma 4. If QP(\u03b8) is feasible and H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) are differentiable w.r.t. \u03b8 and satisfy Assumption 1, and if the KKT matrix of active constraints is nonsingular and x\u22c6, z\u22c6 satisfy strict complementarity, then the ECJs matches the standard Jacobian, i.e., \u2202x\n\u22c6(\u03b8) \u2202\u03b8 = \u2207x\n\u22c6(\u03b8) and \u2202z\u22c6(\u03b8)\n\u2202\u03b8 = \u2207z \u22c6(\u03b8).\nBackward pass: If QP(\u03b8) is by construction primal feasible for any \u03b8, then for any \u03b8, s\u22c6(\u03b8) = 0. We can exploit this result for considering simpler losses not depending anymore of s\u22c6(\u03b8). More precisely, let h : Rn \u00d7 (Rni) \u2192 R be a differentiable function, and let H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) be differentiable w.r.t. \u03b8 and satisfying Assumption 1. Then, denoting L(\u03b8) := h(x\u22c6(\u03b8), z\u22c6(\u03b8)), we show in Appendix B.2.2.2 that when assumptions of Lemma 4 hold the backward pass can be evaluated by solving the following linear system[\nH C\u22a4J CJ 0 ] [ b\u22c6x b\u22c6zJ ] = \u2212 [ \u2202L \u2202x\u22c6 \u2202L \u2202z\u22c6J ] , b\u22c6zJc = \u2202L \u2202z\u22c6Jc , (10)\nwhere J is the set of constraints for which (\u03a01)i = 1 and Jc the one for which (\u03a01)i = 0. \u2202L\u2202\u03b8 is then retrieved from the chain rule\n\u2202L \u2202\u03b8 = (b\u22c6x) \u22a4 \u2202H \u2202\u03b8 x\u22c6 + (b\u22c6x) \u22a4 \u2202g \u2202\u03b8 + (\u03a01b \u22c6 z) \u22a4 \u2202C \u2202\u03b8 x\u22c6 + (z\u22c6)\u22a4 \u2202C \u2202\u03b8 b\u22c6x \u2212 (\u03a01b\u22c6z)\u22a4 \u2202u \u2202\u03b8 . (11)\nNote that the assumptions of Lemma 4 are not necessarily met. Therefore, if equation 10 is found to be infeasible we provide an option to use forward mode in the backward pass as in the generic case (see Section 3.4.1). Such infeasibility can be detected easily using iterative refinement (Parikh & Boyd, 2014, Section 4.1.2)) as it converges to the least-square solution of equation 10 in the infeasible case (see (G\u00fcler, 1991, Theorem 2.3))."
        },
        {
            "heading": "3.4.3 FUTURE WORK AND POTENTIAL IMPROVEMENTS",
            "text": "Before moving to the experiments, let us mention a few potential directions for future work and improvements in our approach. There remain a few gaps in the theoretical foundations of our methodology, which we believe should be handled in the future. Indeed, we have not proved that we could apply the chain rule to ECJs in the general case in the spirit of CJs (see (Bolte et al., 2021)). Also, it should be confirmed that ECJ indeed reduces to CJ under weaker assumptions than those of Lemma 3. While those problems are present in most frameworks (Agrawal et al., 2019, Section B), (Blondel et al., 2022, Section 2.1), using the least-square estimate provides good practical results when non-differentiability occurs."
        },
        {
            "heading": "4 EXPERIMENTAL RESULTS",
            "text": "Our backward mode differentiation of convex QP layers has been implemented in C++. We refer to it as QPLayer in what follows. Our code leverages the primal-dual augmented Lagrangian solver ProxQP (Bambade et al., 2022), also written in C++ as its internal QP solver. This section illustrates through a classic Sudoku learning tasks that QPLayer allows relaxing primal feasibility constraints, thereby enabling the training of simplified layers.\nBenchmark setup. QPLayer is compared to OptNet and CvxpyLayer. The experiments were conducted using all threads of an Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz. The benchmark API will be released upon acceptance of this work. It was inspired by https://github.com/ locuslab/optnet and has been extended to cover all our experiments."
        },
        {
            "heading": "4.1 LEARNING CAPABILITIES",
            "text": "Differentiable optimization for neural network layers has shown great representational power for learning problems that are fundamentally rooted in optimization. The Sudoku problem is one such problem, which can naturally be cast as a mixed integer linear program (MILP). For the Sudoku, OptNet recently showed better robustness and prediction accuracy results than traditional neural networks (Amos & Kolter, 2017, Section 4.4). This section shows that QPLayer generalizes even better by exploiting the fact that it allows learning LPs (and not only QPs). Further, the ability of QPLayer to deal with possibly primal infeasible problems during the learning process appears to be key."
        },
        {
            "heading": "4.1.1 LEARNING LINEAR PROGRAMS",
            "text": "The Sudoku problem is detailed in (Amos & Kolter, 2017, Section 4.4). We reproduce those experiments with OptNet and CvxpyLayer, while letting QPLayer learn linear programs (LPs) instead of strictly convex QPs (the layer model is detailed in Figure 12 of the appendix). In this experiment, the parameters learned in the layer are the equality constraint matrix and the associated equality constraint vector (through extra variables ensuring the structural feasibility of the layer at training and test time, see Figure 12 of the appendix). OptNet, CvxpyLayer, and QPLayer were trained using Adam with a batch of size 150 and a learning rate of 0.05 to minimize an MSE loss on the dataset created by (Amos & Kolter, 2017). The dataset contains 9000 training puzzles and 1000 held-out puzzles for testing. First, Figure 4a shows that QPLayer minimizes the training and test loss without ending up over-fitting to the training data, contrary to OptNet and CvxpyLayer which appear to saturate. Second, Figure 4b shows that QPLayer achieves significantly more accurate and robust training and test error predictions than OptNet and CvxpyLayer."
        },
        {
            "heading": "4.1.2 HANDLING PRIMAL INFEASIBILITY",
            "text": "As outlined in Section 4.1.1, forcing primal feasibility while learning is a common algorithmic strategy. For the Sudoku problems, those techniques enforcing primal feasibility typically involve neglecting a linear equality constraint Ax = 1 (we learn A) which corresponds to Sudoku rules. As shown in Figure 5b, this means that the learning procedures do not respect the Sudoku rule constraint (see green and orange dashed lines\u2014labeled \"QPLayer; Ax = 1 violation\" and \"OptNet; Ax = 1 violation\"). In the end, neglecting this constraint ultimately leads to learning a constraint matrix that is inconsistent with the Sudoku rules. Relaxing the primal feasibility imposed by differentiation procedures of previous solvers thereby appears to be key.\nBy incorporating a potential optimal shift s\u22c6 in its formulation (as exposed in Section 3.1), QPLayer allows dealing with infeasible problems during training. In order to drive towards feasibility the layer at test time (i.e., such that A forms a feasible constraint Ax = 1), we consider penalizing the optimal shift s\u22c6 in the learning loss function (see the layer architecture in Figure 13). The backward pass takes then into account the ECJ derivatives introduced in Section 3.4.1. Numerical performances are reported in Figure 5a and Figure 5b. It is apparent that the dark green curve labeled \"QPLayer-learn A; Ax = 1 violation\" converges after the end of the first epoch towards a model satisfying Sudoku rules. The respective yellow prediction and loss curves also converges slightly faster towards a regime without any prediction errors. The steeper slope observed in the graph suggests that it might be worthwhile to train a layer that more accurately adheres to the Sudoku rules, as this could potentially lead to faster puzzle-solving and more interpretable outcomes.\nFor comparison with OptNet, we have considered reformulating QP-H(\u03b8) as a convex QP (see Figure 14 in the appendix). The resulting problem considers more variables and constitutes thus a potentially harder problem to solve. As OptNet can only learn strictly convex QPs, we have also added a small quadratics over the primal variables (similarly to the structural feasible case described in Section 4.1.1). The grey curve \"OptNet learn A; test loss\" shows the result. It can be seen that it decreases slower and saturates at an earlier level, which is consistent with the fact that the problem is harder to solve. Furthermore, as expected, it displays a worse prediction error. Indeed, the dark\ndashed curves \"OptNet-learn A; Ax = 1 violation\" outputs the primal feasibility violation. It can be seen that it quickly decreases over the first epochs. Yet, at some point it does not manage to decrease further3 and saturates at some local minimum around 10\u22123.\nFinally, let us mention that the formulation developed in Section 3.4 enables a considerable speed-up over the QP reformulation of equation QP-H(\u03b8). Indeed, the forward and backward pass using QPLayer account for about 0.45\u00b1 0.07 seconds per batch, whereas OptNet takes over 8.99\u00b1 0.91 seconds per batch."
        },
        {
            "heading": "4.2 ADDITIONAL EXPERIMENTS",
            "text": "Appendix C.1 provides different simple experiments with parametric QPs to illustrate ECJs concept. Appendix C.2 contains additional timing experiments. Appendix C.3 illustrates through several experiments that QPLayer is numerically more robust and can thereby be trained with large learning rates."
        },
        {
            "heading": "5 CONCLUSION",
            "text": "In this work, we introduced an approach for differentiating both feasible and infeasible convex quadratic programs in a unified fashion. This approach is particularly relevant for learning with optimization layers through differentiable optimization.\nIn particular, by leveraging augmented Lagrangian techniques for solving QP layers that are potentially infeasible, we propose an extended conservative Jacobian formulation for differentiating convex QPs, covering both feasible and infeasible problems. For feasible problems, and when the solution is differentiable, this reduces to standard Jacobians. When the QP is infeasible, have also shown that under regularity conditions it corresponds a weaker notion (i.e., a conservative Jacobian). We further provide an open-source C++ framework, referred to as \u201cQPLayer\u201d, which implements the approach. Through a classic learning example we have shown that differentiating over infeasible QP enables more structured learning with better predicting power. We have additionally proposed in the appendix more extensive benchmarks and experiments, to evaluate QPLayer speed and numerical robustness against other alternative state-of-the-art optimization layers.\nAs for future plans, we will extend QPLayer to deal with a broader range of optimization layers that include second-order cones."
        },
        {
            "heading": "ORGANIZATION OF THE APPENDIX",
            "text": ""
        },
        {
            "heading": "A PROOF OF LEMMA 1",
            "text": "For proving Lemma 1, we first show that solutions to QP-H(\u03b8) are zeros of the map G:\nG(x, z; \u03b8) :=  H(\u03b8)x+ g(\u03b8) + C(\u03b8)\u22a4z[[C(\u03b8)x\u2212 u(\u03b8)]\u2212 + z]+ \u2212 z C(\u03b8)\u22a4[C(\u03b8)x\u2212 u(\u03b8)]+  . (12) Then, a suitable change of variable shows that finding a zero of G is equivalent to finding a zero of map G. Lemma 1. Let H(\u03b8) \u2208 Sn+(R), g(\u03b8) \u2208 Rn, C(\u03b8) \u2208 Rni\u00d7n and u(\u03b8) \u2208 Rni be satisfying Assumption 1. It holds that (x\u22c6, z\u22c6, s\u22c6) solves QP-H(\u03b8) iff there exists t\u22c6 \u2208 Rni s.t. G(x\u22c6, z\u22c6, t\u22c6; \u03b8) = 0 and s\u22c6 = [t\u22c6]+.\nProof. We first show that (x\u22c6, z\u22c6, [Cx\u22c6\u2212u]+) solves equation QP-H(\u03b8) if and only if G(x\u22c6, z\u22c6; \u03b8) = 0.\nThe optimal shift s\u22c6 (that corresponds to the closest feasible QP) is equal to [Cx\u22c6 \u2212 u]+ and is characterized by the \u21132 optimality condition (Chiche & Gilbert, 2016, Lemma 2.13):\nC\u22a4[Cx\u22c6 \u2212 u]+ = 0. Furthermore, for a feasible problem, the KKT conditions using nonlinear complementarity formulation (Sun & Qi, 1999) reads (De Marchi, 2022, Section 2.1):\nHx\u22c6 + g + C\u22a4z\u22c6 = 0, [Cx\u22c6 \u2212 u+ z\u22c6]+ \u2212 z\u22c6 = 0. (13)\nFor showing equivalence, it is thereby sufficient to show that the second line of equation 13 corresponds to:\n[[Cx\u22c6 \u2212 u]\u2212 + z\u22c6]+ \u2212 z\u22c6 = 0. (14)\nThis equivalence is straightforward when equation QP(\u03b8) is feasible, it therefore follows that we only need to handle the infeasible case. When equation QP(\u03b8) is primal infeasible, then t\u22c6 = Cx\u22c6 \u2212 u has a set of components I \u228f [1, ni] strictly positive, hence s\u22c6I = [t \u22c6 I ]+ = t \u22c6 I > 0. For these components, a solution x\u22c6 of the closest feasible QP lies on the border CIx\u22c6 = uI + t\u22c6I . The complementarity condition (De Marchi, 2022, Section 2.1) for these components reads:\n[Cx\u22c6 \u2212 uI \u2212 t\u22c6I\ufe38 \ufe37\ufe37 \ufe38 =0 +z\u22c6I ]+ \u2212 z\u22c6I = 0,\nand we thus have [z\u22c6I ]+ = z \u22c6 I . For the other set of components, which we denote by I c, we have that s\u22c6Ic = 0, and hence x \u22c6 follows the complementary conditions as in the feasible case\n[Cx\u22c6 \u2212 ucI + z\u22c6Ic ]+ \u2212 z\u22c6Ic = 0.\nTherefore, it follows that equation 14 captures the two cases (that is, both feasible and infeasible QPs), which concludes the first part of the proof.\nFinally, introducing the slack variable t\u22c6 = C(\u03b8)x\u22c6 \u2212 u(\u03b8), we have\nG(x\u22c6, z\u22c6; \u03b8) = 0 (15)\n\u21d4  H(\u03b8)x\u22c6 + g(\u03b8) + C(\u03b8)\u22a4z\u22c6[[C(\u03b8)x\u22c6 \u2212 u(\u03b8)]\u2212 + z\u22c6]+ \u2212 z\u22c6 C(\u03b8)\u22a4[C(\u03b8)x\u22c6 \u2212 u(\u03b8)]+  = 0 (16) \u21d4 H(\u03b8)x \u22c6 + g(\u03b8) + C(\u03b8)\u22a4z\u22c6\nC(\u03b8)x\u22c6 \u2212 u(\u03b8)\u2212 t\u22c6 [[t\u22c6]\u2212 + z\n\u22c6]+ \u2212 z\u22c6 C(\u03b8)\u22a4[t\u22c6]+  = 0 (17) G(x\u22c6, z\u22c6, t\u22c6; \u03b8) = 0. (18)\nHence G(x\u22c6, z\u22c6, t\u22c6) = 0 iff (x\u22c6, z\u22c6, [t\u22c6]+) solves QP-H(\u03b8), which concludes."
        },
        {
            "heading": "B ECJS AND AUTOMATIC DIFFERENTIATION",
            "text": "This section provides the proofs of the different results used in Section 3. In particular, we define ECJs and provide algorithms for computing them (both in forward and backward AD modes)."
        },
        {
            "heading": "B.1 PROOF OF LEMMA 2",
            "text": "Lemma 2. G is path differentiable w.r.t. x\u22c6, z\u22c6 and t\u22c6. Furthermore, if H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) are differentiable w.r.t. \u03b8, then G is path differentiable w.r.t. \u03b8.\nProof. We start with the first claim of the lemma. The non-negative projector [.]+ is (component-wise) convex, and hence path differentiable (Bolte & Pauwels, 2020, Proposition 2(i)). Thus, it remains to show that the third component of G is path differentiable for reaching the desired conclusion.\nTo do so, we show that the third component is Lipschitz continuous and real semialgebraic (Bolte & Pauwels, 2020, Proposition 2(iv)). Without loss of generality, we restrict ourselves to the case with 2 components (one for the dual variables, and one for the slack variables) using the following function h : R2 \u2192 R, s.t. h(z, s) := [[s]\u2212 + z]+ \u2212 z. Then, the following Lipschitzness argument applies component-wise.\nLet (s1, z1) \u2208 R2 and (s2, z2) \u2208 R2: |h(z1, s1)\u2212 h(z2, s2)| \u2a7d |[[s1]\u2212 + z1]+ \u2212 [[s2]\u2212 + z2]+|+ |z1 \u2212 z2| \u2a7d |[s1]\u2212 + z1 \u2212 [s2]\u2212 \u2212 z2|+ |z1 \u2212 z2| by monotonicity of [.]+ \u2a7d |[s1]\u2212 \u2212 [s2]\u2212|+ 2|z1 \u2212 z2| = |s1 \u2212 [s1]+ \u2212 (s2 \u2212 [s2]+)|+ 2|z1 \u2212 z2| \u2a7d |s1 \u2212 s2|+ |[s1]+ \u2212 [s2]+|+ 2|z1 \u2212 z2| \u2a7d 2|s1 \u2212 s2|+ 2|z1 \u2212 z2| by monotonicity of [.]+\n\u2a7d 2 \u221a 2\u2225 [ s1 z1 ] \u2212 [ s2 z2 ] \u22252.\nTherefore, h is Lipschitz continuous. For showing that the third component G describes a semialgebraic set, we explicitly formulate the graph of h as a finite union of base semi-algebraic sets, as follows:\ngph(h) ={(z, s, y) \u2208 R3|y = [s]\u2212 and [s]\u2212 + z > 0} \u222a {(z, s, y) \u2208 R3|y = \u2212z and [s]\u2212 + z = 0} \u222a {(z, s, y) \u2208 R3|y = \u2212z and [s]\u2212 + z < 0}\n={(z, s, y) \u2208 R3|y = s and s+ z > 0 and s < 0} \u222a {(z, s, y) \u2208 R3|y = s and s = 0} \u222a {(z, s, y) \u2208 R3|y = 0 and z > 0 and s > 0} \u222a {(z, s, y) \u2208 R3|y = \u2212z and s+ z = 0 and s < 0} \u222a {(z, s, y) \u2208 R3|y = \u2212z and z = 0 and s = 0} \u222a {(z, s, y) \u2208 R3|y = \u2212z and z = 0 and s > 0} \u222a {(z, s, y) \u2208 R3|y = \u2212z and s+ z < 0 and s < 0} \u222a {(z, s, y) \u2208 R3|y = \u2212z and z < 0 and s = 0} \u222a {(z, s, y) \u2208 R3|y = \u2212z and z < 0 and s > 0}.\nHence, gph(h) is real and semi-algebraic as it is a finite union of sets defined by polynomial equalities and inequalities. Hence h is Lipschitz continuous and real semi-algebraic, thereby reaching the target conclusion for the first part of Lemma 2.\nAs for the second part of Lemma 2. G is linear, and hence differentiable, w.r.t. H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8). Furthermore, by assumption H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) are differentiable w.r.t. \u03b8. As differentiability implies path-differentiability (Bolte & Pauwels, 2020, Remark 3b), we arrive at the desired claim by the conservativity of the chain rule for path-differentiable functions (Bolte & Pauwels, 2020, Proposition 2)."
        },
        {
            "heading": "B.2 FORWARD AND BACKWARD AD FOR COMPUTING ECJS",
            "text": "This section provides technical details for the computation of ECJs in forward and backward modes for both primal feasible and infeasible problems. We further include the proofs of Lemma 3 and Lemma 4."
        },
        {
            "heading": "B.2.1 GENERAL CASE",
            "text": "B.2.1.1 Forward pass. Let H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) be differentiable w.r.t. \u03b8 and satisfying Assumption 1, and x\u22c6, z\u22c6, t\u22c6 s.t. G(x\u22c6, z\u22c6, t\u22c6; \u03b8) = 0.\nAs G is path-differentiable w.r.t. v\u22c6 := (x\u22c6, z\u22c6, t\u22c6) (see Lemma 2), we haveH C \u22a4 0\nC 0 \u2212I 0 \u03a01 \u2212 I \u03a01\u03a02 0 0 C\u22a4\u03a03\n \u2208 \u2202G(x\u22c6, z\u22c6, t\u22c6; \u03b8) \u2202v\u22c6 ,\nfor some \u03a01 \u2208 \u2202[.]+([t\u22c6]\u2212 + z\u22c6), \u03a02 \u2208 \u2202[.]\u2212(t\u22c6) and \u03a03 \u2208 \u2202[.]+(t\u22c6).\nFurthermore, as G is linear w.r.t. H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) and H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) are differentiable w.r.t. \u03b8, the usual chain rule dictates that\n\u2202G(x\u22c6, z\u22c6, t\u22c6; \u03b8)\n\u2202\u03b8 =\n \u2202H \u2202\u03b8 x \u22c6 + \u2202g\u2202\u03b8 + \u2202C \u2202\u03b8 \u22a4 z\u22c6 \u2202C \u2202\u03b8 x \u22c6 \u2212 \u2202u\u2202\u03b8 0\n\u2202C \u2202\u03b8 \u22a4 [t\u22c6]+  . Finally, as \u2202[.]+(0) = \u2202[.]\u2212(0) = [0, 1], we make the following arbitrary choices in zeros\n\u03a01 = I when [t\u22c6]\u2212 + z\u22c6 = 0, \u03a02 = I when t\u22c6 = 0, \u03a03 = 0 when t\u22c6 = 0,\n(19)\nso that \u03a03 = I \u2212\u03a02. ECJs are thus retrieved as solutions to:\n\u2202x\u22c6 \u2202\u03b8 , \u2202z\u22c6 \u2202\u03b8 , \u2202t\u22c6 \u2202\u03b8 \u2208 argmin\n\u2202x \u2202\u03b8 , \u2202z \u2202\u03b8 , \u2202t \u2202\u03b8 \u2225\u2225\u2225\u2225\u2225\u2225\u2225\u2225 H C \u22a4 0 C 0 \u2212I 0 \u03a01 \u2212 I \u03a01\u03a02 0 0 C\u22a4(I \u2212\u03a02)  \u2202x\u2202\u03b8\u2202z \u2202\u03b8 \u2202t \u2202\u03b8 +  \u2202H \u2202\u03b8 x \u22c6 + \u2202g\u2202\u03b8 + \u2202C \u2202\u03b8 \u22a4 z\u22c6 \u2202C \u2202\u03b8 x \u22c6 \u2212 \u2202u\u2202\u03b8 0 \u2202C\u22a4\n\u2202\u03b8 [t \u22c6]+\n \u2225\u2225\u2225\u2225\u2225\u2225\u2225\u2225 2\n2\n. (20)\nIn practice, solving this problem can be done via an augmented Lagrangian-based solver for the problem:\n\u2202x\u22c6 \u2202\u03b8 , \u2202z\u22c6 \u2202\u03b8 , \u2202t\u22c6 \u2202\u03b8 \u2208 argmin\n\u2202x \u2202\u03b8 , \u2202z \u2202\u03b8 , \u2202t \u2202\u03b8\n0\ns.t. H C \u22a4 0\nC 0 \u2212I 0 \u03a01 \u2212 I \u03a01\u03a02 0 0 C\u22a4(I \u2212\u03a02)\n \u2202x\u2202\u03b8\u2202z\n\u2202\u03b8 \u2202t \u2202\u03b8\n = \u2212  \u2202H \u2202\u03b8 x \u22c6 + \u2202g\u2202\u03b8 + \u2202C \u2202\u03b8 \u22a4 z\u22c6 \u2202C \u2202\u03b8 x \u22c6 \u2212 \u2202u\u2202\u03b8 0\n\u2202C \u2202\u03b8 \u22a4 [t\u22c6]+\n (21)\nwhen this problem is feasible. When it is not feasible, the augmented Lagrangian naturally converges to the solution of the more general equation 20, see (Chiche & Gilbert, 2016, Proposition 4.2). In comparison to equation 20, a notable advantage of the formulation equation 21 is that it is naturally numerically more stable and sparse\u2013by avoiding square matrix products from the objective.\nB.2.1.2 Backward pass. The following lemma formally details the results from Section 3.4.1. Lemma 5. Let h : Rn\u00d7 (Rni)2 \u2192 R be a differentiable function, and let H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) be differentiable w.r.t. \u03b8 and satisfying Assumption 1. Then, denoting L(\u03b8) := h(x\u22c6(\u03b8), z\u22c6(\u03b8), s\u22c6(\u03b8)) and under assumptions of Lemma 3, we have that \u2202L\u2202\u03b8 can be derived as follows\n\u2202L \u2202\u03b8 = (b\u22c61) \u22a4 \u2202H \u2202\u03b8 x\u22c6 + (b\u22c61) \u22a4 \u2202g \u2202\u03b8 + (b\u22c62) \u22a4 \u2202C \u2202\u03b8 x\u22c6 + (z\u22c6)\u22a4 \u2202C \u2202\u03b8 b\u22c61 + (s \u22c6)\u22a4 \u2202C \u2202\u03b8 b\u22c64 \u2212 (b\u22c62)\u22a4 \u2202u \u2202\u03b8 ,\nwhere b\u22c61, b \u22c6 2, b \u22c6 3 and b \u22c6 4 are the solutions of the linear systemH C\u22a4 0 0C 0 (I \u2212\u03a01) 0 0 \u2212I \u2212\u03a01\u03a02 (1\u2212\u03a02)C  b \u22c6 1 b\u22c62 b\u22c63 b\u22c64  = \u2212  \u03b4L\u03b4x\u22c6\u03b4L \u03b4z\u22c6 \u03b4L \u03b4s\u22c6  .\nProof. Under the assumptions of Lemma 3, it holds that \u2202x\u22c6\u2202\u03b8\u2202z\u22c6 \u2202\u03b8 \u2202s\u22c6\n\u2202\u03b8\n is a CJ as \u2202x\u22c6\u2202\u03b8\u2202z\u22c6\n\u2202\u03b8 \u2202t\u22c6 \u2202\u03b8  and \u03a01 \u2202t\u22c6\u2202\u03b8 \u2208 \u2202s\u22c6\u2202\u03b8 are CJs ((Bolte & Pauwels, 2020, Proposition 2)). Furthermore, as L is differentiable w.r.t. x\u22c6, z\u22c6 and s\u22c6, it is path-differentiable (Bolte & Pauwels, 2020, Remark 3b) w.r.t. x\u22c6, z\u22c6, s\u22c6, so we can apply\nchain rule ((Bolte & Pauwels, 2020, Proposition 2)):\n\u2202L \u2202\u03b8 = \u2202L \u2202x\u22c6\n\u22a4 \u2202x\u22c6\n\u2202\u03b8 + \u2202L \u2202z\u22c6\n\u22a4 \u2202z\u22c6\n\u2202\u03b8 + \u2202L \u2202s\u22c6\n\u22a4 \u2202s\u22c6\n\u2202\u03b8\n= \u2212(\u2212  \u03b4L\u03b4x\u22c6\u03b4L \u03b4z\u22c6 \u03b4L \u03b4s\u22c6 )\u22a4 \u2202x\u22c6\u2202\u03b8\u2202z\u22c6 \u2202\u03b8 \u2202s\u22c6\n\u2202\u03b8\n\n= \u2212( H C \u22a4 0\nC 0 \u2212I 0 \u03a01 \u2212 I \u03a01\u03a02 0 0 C\u22a4(I \u2212\u03a02)\n b\n\u22c6 1 b\u22c62 b\u22c63 b\u22c64\n)\u22a4 \u2202x\u22c6\u2202\u03b8\u2202z\u22c6\n\u2202\u03b8 \u2202s\u22c6 \u2202\u03b8\n\n= \u2212 b \u22c6 1 b\u22c62 b\u22c63 b\u22c64  \u22a4 (\u2212  \u2202H \u2202\u03b8 x \u22c6 + \u2202g\u2202\u03b8 + \u2202C \u2202\u03b8 \u22a4 z\u22c6 \u2202C \u2202\u03b8 x \u22c6 \u2212 \u2202u\u2202\u03b8 0\n\u2202C \u2202\u03b8 \u22a4 [t\u22c6]+ ) = (b\u22c61) \u22a4( \u2202H\n\u2202\u03b8 x\u22c6 +\n\u2202g \u2202\u03b8 + \u2202C \u2202\u03b8\n\u22a4 z\u22c6)\n+ (b\u22c62) \u22a4(\n\u2202C \u2202\u03b8 x\u22c6 \u2212 \u2202u \u2202\u03b8 )\n+ (b\u22c64) \u22a4(\n\u2202C\n\u2202\u03b8\n\u22a4 [t\u22c6]+)\n= (b\u22c61) \u22a4 \u2202H\n\u2202\u03b8 x\u22c6 + (\n\u2202C \u2202\u03b8 b\u22c61) \u22a4z\u22c6 + (b1) \u22a4 \u2202g \u2202\u03b8\n+ (b\u22c62) \u22a4(\n\u2202C \u2202\u03b8 x\u22c6 \u2212 \u2202u \u2202\u03b8 )\n+ ( \u2202C\n\u2202\u03b8 b\u22c64) \u22a4[t\u22c6]+),\nwith b\u22c61, b \u22c6 2, b \u22c6 4 solution of the nonsingular system (see Lemma 3)H C\u22a4 0 0C 0 (I \u2212\u03a01) 0\n0 \u2212I \u2212\u03a01\u03a02 (1\u2212\u03a02)C\n b\n\u22c6 1 b\u22c62 b\u22c63 b\u22c64\n = \u2212  \u03b4L\u03b4x\u22c6\u03b4L\n\u03b4z\u22c6 \u03b4L \u03b4s\u22c6  , thereby reaching the desired statement with s\u22c6 = [t\u22c6]+."
        },
        {
            "heading": "B.2.2 SIMPLIFICATION OF WHEN QP IS FEASIBLE",
            "text": "B.2.2.1 Simplification of the forward pass When QP(\u03b8) is feasible and H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) are differentiable w.r.t. \u03b8 and satisfy Assumption 1, then [t\u22c6]+ = 0. Further, our choices of subgradients at zero (see equation 19) imply that \u03a02 = I and hence the following simplificationsH C\n\u22a4 0 C 0 \u2212I 0 \u03a01 \u2212 I \u03a01 0 0 0\n \u2208 \u2202G(x\u22c6, z\u22c6, t\u22c6; \u03b8) \u2202v\u22c6 ,\n \u2202H \u2202\u03b8 x \u22c6 + \u2202g\u2202\u03b8 + \u2202C \u2202\u03b8 \u22a4 z\u22c6 \u2202C \u2202\u03b8 x\n\u22c6 \u2212 \u2202u\u2202\u03b8 0 0  = \u2202G(x\u22c6, z\u22c6, t\u22c6; \u03b8)\u2202\u03b8 . Moreover, the optimality conditions of\n\u2202x\u22c6 \u2202\u03b8 , \u2202z\u22c6 \u2202\u03b8 , \u2202t\u22c6 \u2202\u03b8 \u2208 argmin\n\u2202x \u2202\u03b8 , \u2202z \u2202\u03b8 , \u2202t \u2202\u03b8 \u2225\u2225\u2225\u2225\u2225\u2225\u2225\u2225 H C \u22a4 0 C 0 \u2212I 0 \u03a01 \u2212 I \u03a01 0 0 0  \u2202x\u2202\u03b8\u2202z \u2202\u03b8 \u2202t \u2202\u03b8 +  \u2202H \u2202\u03b8 x \u22c6 + \u2202g\u2202\u03b8 + \u2202C \u2202\u03b8 \u22a4 z\u22c6 \u2202C \u2202\u03b8 x \u22c6 \u2212 \u2202u\u2202\u03b8 0 0  \u2225\u2225\u2225\u2225\u2225\u2225\u2225\u2225 2\n2\n,\nwrite down\n(H2 + C\u22a4C) \u2202x\u22c6\n\u2202\u03b8 +HC\u22a4\n\u2202z\u22c6\n\u2202\u03b8 \u2212 C\u22a4 \u2202t\n\u22c6\n\u2202\u03b8 + [H(\n\u2202H\n\u2202\u03b8 x\u22c6 +\n\u2202g \u2202\u03b8 + \u2202C \u2202\u03b8\n\u22a4 z\u22c6) + C\u22a4( \u2202C\n\u2202\u03b8 x\u22c6 \u2212 \u2202u \u2202\u03b8 )] = 0,\nCH \u2202x\u22c6\n\u2202\u03b8 + (C\u22a4C + I \u2212\u03a01)\n\u2202z\u22c6\n\u2202\u03b8 + C(\n\u2202H\n\u2202\u03b8 x\u22c6 +\n\u2202g \u2202\u03b8 + \u2202C \u2202\u03b8\n\u22a4 z\u22c6) = 0,\n\u2212C \u2202x \u22c6\n\u2202\u03b8 + (I +\u03a01)\n\u2202t\u22c6\n\u2202\u03b8 \u2212 (\u2202C \u2202\u03b8 x\u22c6 \u2212 \u2202u \u2202\u03b8 ) = 0.\n(22)\nThird equation of equation 22 leads to\n\u2202t\u22c6 \u2202\u03b8 =\n1\n1 + \u03a01 (C\n\u2202x\u22c6\n\u2202\u03b8 + (\n\u2202C \u2202\u03b8 x\u22c6 \u2212 \u2202u \u2202\u03b8 )).\nHence, optimality conditions without variable \u2202t \u22c6\n\u2202\u03b8 reduce to\n(H2 + C\u22a4 \u03a01\n1 + \u03a01 C)\n\u2202x\u22c6\n\u2202\u03b8 +HC\u22a4\n\u2202z\u22c6\n\u2202\u03b8 + C\u22a4 \u03a01 1 + \u03a01 ( \u2202C \u2202\u03b8 x\u22c6 \u2212 \u2202u \u2202\u03b8 ) +H( \u2202H \u2202\u03b8 x\u22c6 + \u2202g \u2202\u03b8 + \u2202C \u2202\u03b8\n\u22a4 z\u22c6) = 0,\nCH \u2202x\u22c6\n\u2202\u03b8 + (C\u22a4C + I \u2212\u03a01)\n\u2202z\u22c6\n\u2202\u03b8 + C(\n\u2202H\n\u2202\u03b8 x\u22c6 +\n\u2202g \u2202\u03b8 + \u2202C \u2202\u03b8\n\u22a4 z\u22c6) = 0.\n(23)\nFurthermore, the following problem\nmin \u2202x \u2202\u03b8 , \u2202z \u03b8\n\u2225\u2225\u2225\u2225\u2225 [ H C\u22a4 \u03a01\u221a 1+\u03a01 C \u03a01 \u2212 I ] [ \u2202x \u2202\u03b8 \u2202z \u2202\u03b8 ] + [ \u2202H \u2202\u03b8 x \u22c6 + \u2202g\u2202\u03b8 + \u2202C \u2202\u03b8 \u22a4 z\u22c6 \u03a01\u221a 1+\u03a01 (\u2202C\u2202\u03b8 x \u22c6 \u2212 \u2202u\u2202\u03b8 ) ]\u2225\u2225\u2225\u2225\u2225 2\n2\n,\nhave the same KKT conditions as equation 23, thereby allowing to simplify the problem as follows:\nmin \u2202x \u2202\u03b8 , \u2202z \u2202\u03b8 , \u2202t \u2202\u03b8 \u2225\u2225\u2225\u2225\u2225\u2225\u2202G(x \u22c6, z\u22c6, s\u22c6; \u03b8) \u2202v\u0302\u22c6 \u2202x\u2202\u03b8\u2202z \u2202\u03b8 \u2202t \u2202\u03b8 + \u2202G(x\u22c6, z\u22c6, s\u22c6; \u03b8) \u2202\u03b8 \u2225\u2225\u2225\u2225\u2225\u2225 2 2\n= min \u2202x \u2202\u03b8 , \u2202z \u2202\u03b8\n\u2225\u2225\u2225\u2225\u2225 [ H C\u22a4 \u03a01\u221a I+\u03a01 C \u03a01 \u2212 I ] [ \u2202x \u2202\u03b8 \u2202z \u2202\u03b8 ] + [ \u2202H \u2202\u03b8 x \u22c6 + \u2202g\u2202\u03b8 + \u2202C \u2202\u03b8 \u22a4 z\u22c6 \u03a01\u221a I+\u03a01 (\u2202C\u2202\u03b8 x \u22c6 \u2212 \u2202u\u2202\u03b8 ) ]\u2225\u2225\u2225\u2225\u2225 2\n2\n,\n(24)\nHence\n\u2202x\u22c6 \u2202\u03b8 , \u2202z\u22c6 \u2202\u03b8 , \u2202t\u22c6 \u2202\u03b8 \u2208 argmin\n\u2202x \u2202\u03b8 , \u2202z \u2202\u03b8 , \u2202t \u2202\u03b8\n\u2225\u2225\u2225\u2225\u2225\u2225\u2202G(x \u22c6, z\u22c6, s\u22c6; \u03b8) \u2202v\u0302\u22c6 \u2202x\u2202\u03b8\u2202z \u2202\u03b8 \u2202t \u2202\u03b8 + \u2202G(x\u22c6, z\u22c6, s\u22c6; \u03b8) \u2202\u03b8 \u2225\u2225\u2225\u2225\u2225\u2225 2 2\nis equivalent to\n\u2202x\u22c6 \u2202\u03b8 , \u2202z\u22c6 \u2202\u03b8 \u2208 argmin\n\u2202x \u2202\u03b8 , \u2202z \u2202\u03b8\n\u2225\u2225\u2225\u2225\u2225 [ H C\u22a4 \u03a01\u221a 1+\u03a01 C \u03a01 \u2212 I ] [ \u2202x \u2202\u03b8 \u2202z \u2202\u03b8 ] + [ \u2202H \u2202\u03b8 x \u22c6 + \u2202g\u2202\u03b8 + \u2202C \u2202\u03b8 \u22a4 z\u22c6 \u03a01\u221a 1+\u03a01 (\u2202C\u2202\u03b8 x \u22c6 \u2212 \u2202u\u2202\u03b8 ) ]\u2225\u2225\u2225\u2225\u2225 2\n2\n,\n\u03b4t\u22c6 \u03b4\u03b8 = (I +\u03a01) \u22121(C \u03b4x\u22c6 \u03b4\u03b8 + \u2202C \u2202\u03b8 x\u22c6 \u2212 \u2202u \u2202\u03b8 ).\nB.2.2.2 Simplification of the backward pass. This sections details the results from Section 3.4.2. Lemma 6. Let h : Rn \u00d7 (Rni) \u2192 R be a differentiable function, and let H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) be differentiable w.r.t. \u03b8 and satisfying Assumption 1. Then, denoting L(\u03b8) := h(x\u22c6(\u03b8), z\u22c6(\u03b8)), we have under assumptions of Lemma 4 that \u2202L\u2202\u03b8 can be derived as follows\n\u2202L \u2202\u03b8 = (b\u22c6x) \u22a4 \u2202H \u2202\u03b8 x\u22c6 + (b\u22c6x) \u22a4 \u2202g \u2202\u03b8 + (\u03a01b \u22c6 z) \u22a4 \u2202C \u2202\u03b8 x\u22c6 + (z\u22c6)\u22a4 \u2202C \u2202\u03b8 b\u22c6x \u2212 (\u03a01b\u22c6z)\u22a4 \u2202u \u2202\u03b8 ,\nwith b\u22c6x, b \u22c6 z , the solution of the following linear system[\nH C\u22a4\u03a01 C \u2212(I \u2212\u03a01) ] [ bx bz ] = \u2212 [ \u03b4L \u03b4x\u22c6 \u03b4L \u03b4z\u22c6 ] ,\nFurthermore, this latter linear system can be solved using iterative refinement.\nProof. Under the assumptions of Lemma 4, it holds that [ \u2202x\u22c6\n\u2202\u03b8 \u2202z\u22c6\n\u2202\u03b8\n] is a Jacobian. Furthermore, as L is\ndifferentiable, the chain rule implies that:\n\u2202L \u2202\u03b8 = [ \u2202L \u2202x\u22c6 \u2202L \u2202z\u22c6 ]\u22a4 [\u2202x\u22c6 \u2202\u03b8 \u2202z\u22c6 \u2202\u03b8 ] =\u2212 (\u2212\n[ \u2202L \u2202x\u22c6 \u2202L \u2202z\u22c6 ] )\u22a4 [ \u2202x\u22c6 \u2202\u03b8 \u2202z\u22c6 \u2202\u03b8 ] =\u2212 ( [ H C\u22a4\n\u03a01C \u03a01 \u2212 I ]\u22a4 [ bx bz ] )\u22a4 [ \u2202x\u22c6 \u2202\u03b8 \u2202z\u22c6\n\u2202\u03b8\n] as the matrix is nonsingular (see Lemma 4)\n=\u2212 [ bx bz ]\u22a4 (\u2212 [ \u2202H \u2202\u03b8 x \u22c6 + \u2202g\u2202\u03b8 + \u2202C \u2202\u03b8 \u22a4 z\u22c6\n\u03a01( \u2202C \u2202\u03b8 x \u22c6 \u2212 \u2202u\u2202\u03b8 )\n] )\n=(bx) \u22a4(\n\u2202H\n\u2202\u03b8 x\u22c6 +\n\u2202g \u2202\u03b8 + \u2202C \u2202\u03b8\n\u22a4 z\u22c6)\n+ (bz) \u22a4(\u03a0(dCx\u22c6 \u2212 du))\n=[(bx) \u22a4 \u2202H\n\u2202\u03b8 x\u22c6 + (\n\u2202C \u2202\u03b8 bx) \u22a4z\u22c6 + (bx) \u22a4 \u2202g \u2202\u03b8 ]\n+ (bz) \u22a4(\u03a0(\n\u2202C \u2202\u03b8 x\u22c6 \u2212 \u2202u \u2202\u03b8 )),\nwhere (bx, bz) is a solution to [ H C\u22a4\u03a01 C \u2212(I \u2212\u03a01) ] [ bx bz ] = \u2212 [ \u03b4L \u03b4x\u22c6 \u03b4L \u03b4z\u22c6 ] .\nAs detailed in the proof of Lemma 4 (see details in Appendix B.4), one can equivalently solve[ H C\u22a4J CJ 0 ] [ bx bzJ ] = \u2212 [ \u03b4L \u03b4x\u22c6 \u03b4L \u03b4z\u22c6J ] ,\nbzcJ = \u03b4L \u03b4z\u22c6Jc ,\nwith Jc the index set for which the solution is strictly feasible (i.e., i \u2208 [1, ni], (\u03a01)i = 0), and J the set of active constraints (i.e., for which (\u03a01)i = 1). Such linear systems can be solved e.g., via iterative refinement (as the matrix involved is symmetric positive semi-definite (Parikh & Boyd, 2014, Section 4.1.2))."
        },
        {
            "heading": "B.3 PROOF OF LEMMA 3",
            "text": "This section provides a proof for Lemma 3, ensuring that ECJs are CJs under some regularity assumptions.\nLemma 3. Let C(\u03b8), u(\u03b8) be differentiable w.r.t. \u03b8, and H = 0, and g be fixed w.r.t. \u03b8 and satisfying Assumption 1. If s\u22c6 > 0 and z\u22c6 = 0 (i.e., it does not satisfy strict complementarity) and C is full row rank, then the ECJs of x\u22c6, z\u22c6, t\u22c6, and s\u22c6 correspond to conservative Jacobians.\nProof. If s\u22c6 > 0, then \u03a02 = 0. Furthermore, if x\u22c6 and z\u22c6 do not satisfy strict complementarity then \u03a01 = 0. Hence, ECJs can be computed as least-square solutions to0 C\n\u22a4 0 C 0 \u2212I 0 \u2212I 0 0 0 C\u22a4\n \u2202x\u22c6\u2202\u03b8\u2202z\u22c6\n\u2202\u03b8 \u2202t\u22c6 \u2202\u03b8\n = \u2212 \n0 0\n\u2202C \u2202\u03b8 x \u22c6 \u2212 \u2202u\u2202\u03b8 \u2202C \u2202\u03b8 \u22a4 [t\u22c6]+\n .\nThus it implies \u2202z \u22c6\n\u2202\u03b8 = 0 and the system is reduced to[ C \u2212I 0 C\u22a4 ] [ \u2202x\u22c6 \u2202\u03b8 \u2202t\u22c6\n\u2202\u03b8\n] = \u2212 [ \u2202C \u2202\u03b8 x\n\u22c6 \u2212 \u2202u\u2202\u03b8 \u2202C \u2202\u03b8 \u22a4 [t\u22c6]+\n] ,\nwhich is nonsingular since C is of full row rank. Hence, \u2202x \u22c6 \u2202\u03b8 , \u2202z\u22c6 \u2202\u03b8 and \u2202t\u22c6\n\u2202\u03b8 are uniquely determined and the path-differentiable implicit function theorem (Bolte & Pauwels, 2020, Corollary 1) can be\napplied to G(x\u22c6, z\u22c6, s\u22c6; \u03b8). Hence \u2202x\u22c6\u2202\u03b8\u2202z\u22c6 \u2202\u03b8 \u2202t\u22c6\n\u2202\u03b8  corresponds to a CJ."
        },
        {
            "heading": "B.4 PROOF OF LEMMA 4",
            "text": "This section details the proof of Lemma 4, ensuring that, under some regularity assumptions, ECJs reduce to standard Jacobians. Lemma 4. If QP(\u03b8) is feasible and H(\u03b8), g(\u03b8), C(\u03b8) and u(\u03b8) are differentiable w.r.t. \u03b8 and satisfy Assumption 1, and if the KKT matrix of active constraints is nonsingular and x\u22c6, z\u22c6 satisfy strict complementarity, then the ECJs matches the standard Jacobian, i.e., \u2202x\n\u22c6(\u03b8) \u2202\u03b8 = \u2207x\n\u22c6(\u03b8) and \u2202z\u22c6(\u03b8)\n\u2202\u03b8 = \u2207z \u22c6(\u03b8).\nProof. If equation QP(\u03b8) is feasible, then the ECJs of x\u22c6 and z\u22c6 w.r.t. \u03b8 are provided by\n\u2202x\u22c6 \u2202\u03b8 , \u2202z\u22c6 \u2202\u03b8 \u2208 argmin\n\u2202x \u2202\u03b8 , \u2202z \u2202\u03b8 \u2225\u2225\u2225\u2225\u2225\u2225\u2225\u2225\u2225 [ H C\u22a4 \u03a01\u221a 1+\u03a01 C \u03a01 \u2212 I ] \ufe38 \ufe37\ufe37 \ufe38\n:=\u2206\n[ \u2202x \u2202\u03b8 \u2202z \u2202\u03b8 ] + [ \u2202H \u2202\u03b8 x \u22c6 + \u2202g\u2202\u03b8 + \u2202C \u2202\u03b8 \u22a4 z\u22c6 \u03a01\u221a 1+\u03a01 (\u2202C\u2202\u03b8 x \u22c6 \u2212 \u2202u\u2202\u03b8 ) ]\u2225\u2225\u2225\u2225\u2225\u2225\u2225\u2225\u2225 2\n2\n, (25)\nwhere \u03a01 corresponds to a binary diagonal matrix of the complementarity conditions Cx\u22c6\u2212u+z\u22c6 \u2a7e 0. Denoting by Jc the index set for which the solution is strictly feasible (i.e., i \u2208 [1, ni], (\u03a01)i = 0), and by J the index set of active constraints (i.e., for which (\u03a01)i = 1) then \u2206 can be reformulated as follows (by strict complementary)\n\u2206 =  H C\u22a4J C\u22a4Jc1\u221a 2 CJ 0 0\n0 0 \u2212I  , with I being the identity matrix of appropriate dimension. Furthermore, the right-hand side of the linear system within the \u21132 norm becomes\u2202H\u2202\u03b8 x\u22c6 + \u2202g\u2202\u03b8 + \u2202C\u2202\u03b8 \u22a4z\u22c61\u221a\n2 (\u2202CJ\u2202\u03b8 x \u22c6 \u2212 \u2202uJ\u2202\u03b8 ) 0  . [ H C\u22a4J CJ 0 ] corresponds to the KKT matrix of active constraints, and is nonsingular by assumption.\nAs it implies nonsingularity of [\nH C\u22a4J 1\u221a 2 CJ 0\n] , it follows that :\n\u2202z\u22c6Jc\n\u2202\u03b8 = 0,\nand the solution to equation 25 is uniquely determined as the solution of the following linear system (as in (Amos & Kolter, 2017, Appendix A), after multiplying second row block by \u221a 2):[\nH C\u22a4J CJ 0\n] [ \u2202x\u22c6\n\u2202\u03b8 \u2202z\u22c6\n\u2202\u03b8\n] = \u2212 [ \u2202H \u2202\u03b8 x \u22c6 + \u2202g\u2202\u03b8 + \u2202C \u2202\u03b8 \u22a4 z\u22c6\n\u2202CJ \u2202\u03b8 x \u22c6 \u2212 \u2202uJ\u2202\u03b8\n] ,\nHence, we arrive at the desired conclusion that ECJ coincides with the usual Jacobian in this case."
        },
        {
            "heading": "C ADDITIONAL EXPERIMENTAL RESULTS",
            "text": "Appendix C.1 provides a few simple experiments with parametric QPs to illustrate the concept of ECJs. Appendix C.2 contains additional benchmarks. Appendix C.3 illustrates through several experiments that QPLayer can be trained with large learning rates."
        },
        {
            "heading": "C.1 PEDAGOGICAL EXAMPLES OF PARAMETRIC QPS",
            "text": "A few numerical examples illustrate the concept of ECJ in different simple scenarios. The first example corresponds to a strictly convex parametric QP which can be either feasible or infeasible. In this example, a linear constraint depends on a parameter \u03b8. Depending on the value of this parameter, the QP can either be feasible or infeasible.\nThe second example is a strictly convex QP with a parameterized linear cost. This problem is always feasible.\nThe last example is a parametric LP with possibly multiple solutions. For appropriate values of the parameters, the LP is feasible but not differentiable."
        },
        {
            "heading": "C.1.1 STRICTLY CONVEX QP (PARAMETERIZED CONSTRAINTS)",
            "text": "Consider the following strictly convex QP parameterized by a scalar value \u03b8\nx\u22c6(\u03b8) = argmin x1,x2\u2208R2\n1 2 (x21 + x 2 2)\ns.t. \u03b8 \u2a7dx1 + x2 \u2a7d 1.55, 1.5 \u2a7d2x1 + x2 \u2a7d 1.55\n(26)\nNotice that for \u03b8 > \u03b8limit := 1.55, the QP becomes primal infeasible. We use gradient descent to minimize two scalar losses L1(\u03b8) = x\u22c61(\u03b8) and L2(\u03b8) = x\u22c62(\u03b8), starting from a predefined value \u03b80. More precisely we have launched gradient descent for 40 steps with a learning rate 5 \u00d7 10\u22124 starting from \u03b80 = 1.54. Figure 6a illustrates the results by showing the iterates of gradient descent for minimizing x\u22c61(\u03b8) (as well as the search direction\u2014minus the ECJs). By doing so \u03b8 increases and eventually becomes larger than \u03b8limit."
        },
        {
            "heading": "C.1.2 STRICTLY CONVEX QP (PARAMETERIZED OBJECTIVE)",
            "text": "Consider the following strictly convex QP parametrized by a scalar value \u03b8\nx\u22c6(\u03b8) = argmin x1,x2\u2208R2\n1\n2 \u2225\u2225\u2225\u2225[x1x2 ] + [ \u03b8 \u22122 ]\u2225\u2225\u2225\u22252 2\ns.t. \u2212 300 \u2a7d x1 + x2 \u2a7d 400, \u2212200 \u2a7d 2x1 + x2 \u2a7d 500\n(27)\nWe use gradient descent to minimize the loss L1(\u03b8) = x\u22c61(\u03b8). More precisely, we run 40 iterations of gradient descent with learning rate 5\u00d7 10\u22124 starting from \u03b80 = 1.54, as reported by Figure 7. As expected, we see that x\u22c61(\u03b8) = \u2212\u03b8, hence increasing \u03b8 decreases x\u22c61(\u03b8)."
        },
        {
            "heading": "C.1.3 PARAMETERIZED LINEAR PROGRAM",
            "text": "Consider the following LP parameterized by a scalar parameter \u03b8 > 0\nx\u22c6(\u03b8) \u2208 argmin x1,x2\u2208R2 x1 + x2\ns.t. \u03b8 \u2a7d x1 + x2, 0 \u2a7d x1 \u2a7d 1,\n0 \u2a7d x2 \u2a7d 1.\n(28)\nNote that this LP is always well-defined for any \u03b8 since the linear cost is orthogonal to the recession cone (which is empty), thereby satisfying the technical requirements from Assumption 1. We use gradient descent for minimizing two scalar losses L1(\u03b8) = x\u22c61(\u03b8) and L2(\u03b8) = x\u22c62(\u03b8).\nC.1.3.1 Feasible case (\u03b8 \u2a7d 2). For any \u03b8 \u2208]0, 2], there are infinitely many solutions to equation 28 which are defined by the segment equation\nx\u22c61 + x \u22c6 2 = \u03b8,\n0 \u2a7d x\u22c61 \u2a7d 1, 0 \u2a7d x\u22c62 \u2a7d 1.\nWe can see in Figure 8a and Figure 8b that the forward pass chooses as solution x\u22c61 = x \u22c6 2 = \u03b8 2 . Hence, only the constraint \u03b8 \u2a7d x1 + x2 is active. Following the formalism from Section 3.1 we have\nC =  \u22121 \u22121 1 0 \u22121 0 0 1 0 \u22121  , u =  \u2212\u03b8 1 0 1 0  .\nThe ECJs of L1 and L2 w.r.t \u03b8 are the solutions to[ (b\u22c6x)1 (b\u22c6x)2 b\u22c6z ] \u2208 argmin bx,bz \u2225\u2225\u2225\u2225\u2225 [ 0 0 \u22121 0 0 \u22121 \u22121 \u22121 0 ][ (bx)1 (bx)2 bz ] + [ 1 0 0 ]\u2225\u2225\u2225\u2225\u2225 2\n2\n,\n[ (d\u22c6x)1 (d\u22c6x)2 d\u22c6z ] \u2208 argmin dx,dz \u2225\u2225\u2225\u2225\u2225 [ 0 0 \u22121 0 0 \u22121 \u22121 \u22121 0 ][ (dx)1 (dx)2 dz ] + [ 0 1 0 ]\u2225\u2225\u2225\u2225\u2225 2\n2\n.\nAs the corresponding linear systems involved within the \u21132 norm are infeasible, the least square estimates do not correspond to solutions to the linear system. That is, the corresponding least-square solutions are respectively the solutions of the following projected linear systems:[\n1 1 0 1 1 0 0 0 2 ][ (b\u22c6x)1 (b\u22c6x)2 b\u22c6z ] = [ 0 0 1 ] ,\n[ 1 1 0 1 1 0 0 0 2 ][ (d\u22c6x)1 (d\u22c6x)2 d\u22c6z ] = [ 0 0 1 ] ,\nwhich leads to \u2202L1\u2202\u03b8 = \u2202L2 \u2202\u03b8 = b \u22c6 z = d \u22c6 z = 1 2 . Figure 8a and Figure 8b show that those directions allow minimizing L1 and L2 through gradient descent.\n0.690 0.692 0.694 0.696 0.698 0.700\n0.345\n0.346\n0.347\n0.348\n0.349\n0.350\nx * 1 (\n)\nx *1 ( ) dx *1 ( ) d\n(a) 40 iterations of gradient descent for minimizing x\u22c61(\u03b8) for the problem equation 28.\n0.690 0.692 0.694 0.696 0.698 0.700\n0.345\n0.346\n0.347\n0.348\n0.349\n0.350\nx * 2 (\n)\nx *2 ( ) dx *2 ( ) d\n(b) 40 iterations of gradient descent for minimizing x\u22c62(\u03b8) for the problem equation 28.\nC.1.3.2 Infeasible case (\u03b8 > 2). For any \u03b8 > 2, the LP is infeasible. The corresponding ECJs are the least-square solutions to\nargmin b1,b2,b3,b4\n\u2225 0 C\u22a4 0 0C 0 (I \u2212\u03a01) 0 0 \u2212I \u2212\u03a01\u03a02 (1\u2212\u03a02)C  b1b2b3 b4 +  \u03b4Li\u03b4x0 0  \u222522 for i \u2208 {1, 2},\nwith P1 =  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1  and P2 =  1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 . The linear system within the \u21132 norm is feasible and QPLayer outputs as ECJs \u2202L1\u2202\u03b8 = \u2202L2 \u2202\u03b8 = 1 3 . Figure 9a and Figure 9b show that following such directions allows using gradient descent for minimizing L1 and L2.\n2.193 2.194 2.195 2.196 2.197 2.198 2.199 2.200 2.201 1.0635\n1.0640\n1.0645\n1.0650\n1.0655\n1.0660\n1.0665\n1.0670\n1.0675\nx * 1 (\n)\nx *1 ( ) dx *1 ( ) d\n(a) 40 steps of gradient descent applied to minimize x\u22c61(\u03b8) starting from \u03b80 = 2.2, when considering the infeasible LP defined by equation 28.\n2.193 2.194 2.195 2.196 2.197 2.198 2.199 2.200 2.201 1.0635\n1.0640\n1.0645\n1.0650\n1.0655\n1.0660\n1.0665\n1.0670\n1.0675\nx * 2 (\n)\nx *2 ( ) dx *2 ( ) d\n(b) 40 steps of gradient descent applied to minimize x\u22c62(\u03b8) starting from \u03b80 = 2.2, when considering the infeasible LP defined by equation 28."
        },
        {
            "heading": "C.2 TIMINGS BENCHMARKS",
            "text": "In this section, we report our numerical results and compare them against state-of-the-art frameworks on a set of standard experiments. We outline detailed timings for differentiating solutions on a set of different QPs. First, Table 2 shows the results for a few randomly generated QPs. Second, Table 3 reports the average time spent in the differentiation procedure on four different learning tasks. Additional experiments are provided in Appendix C.2.\nIn the first set of experiments (see Appendix C.2.1), QPLayer is compared to OptNet, CvxpyLayer, JaxOpt, and Alt-Diff. For all the other experiments, QPLayer is benchmarked only against approaches available within the PyTorch framework (i.e., OptNet and CvxpyLayer4)."
        },
        {
            "heading": "C.2.1 RANDOM QPS",
            "text": "In this first set of experiments, we generated random QPs with 100 variables, 50 equality, and 50 inequality constraints. We solve and backpropagate through all those QPs for different forward pass accuracies. We then average the results over 5 trails and report the timings in the spirit of (Sun et al., 2022).\nFor a batch size of 100, Table 2 shows that QPLayer is almost 4 times faster than OptNet (the second fastest approach). We can see similar performance for a batch size of 1 (see Table 4, QPLayer is about 4 times faster than OptNet (the second fastest approach) for all target accuracies). We observe that the speed gain is mostly due to the forward pass speed-up, enabled by the use of ProxQP and thread parallelization. It is also confirmed by Table 5, which reproduces in Table 5 the serial forward timing benchmark proposed in (Amos & Kolter, 2017, Section 4.1). It exhibits from 5 to 9 times faster computation times."
        },
        {
            "heading": "C.2.2 LEARNING TASKS",
            "text": "For this second set of experiments, we report the numerical results obtained on 4 traditional learning tasks (namely MNIST classification, signal denoising, Sudoku solving and cart-pole experiment). For all experiments, we report the average (over all epochs) time spent in the forward and backward passes. Table 3 reports that QPLayer is 3 to 10 times faster than the second fastest approach (i.e., 3 times faster on the classification task, 4 times faster on the Sudoku, about 10 times faster for the denoising and 7 times faster for the cart-pole experiments). In all cases, the test loss incurred using QPLayer is either similar (for the denoising and cart-pole tasks) or far better than its competitor layers (about 2 times smaller and 3 orders of magnitudes better for the classification and Sudoku experiments).\n4Alt-Diff exhibited too slow performances for a fair and reasonable comparison. Note that (Sun et al., 2022) have not yet proposed an Alt-Diff layer deriving all QP Jacobians. Therefore, we have included in our benchmark an open-source implementation of Alt-Diff based on their work.\nMore precisely, the first three experiments reproduce the ones originally described in (Amos & Kolter, 2017, Sections 4.2 to 4.4). A complete description of the cart-pole swing-up task is detailed in Appendix D.2. These tasks involve learning convex feasible QPs using Adam optimizer (Kingma & Ba, 2014). The first three experiments are run with the default batch sizes and the number of epochs fixed by the original authors (i.e., batch size equals 64 for classification, 150 for denoising and Sudoku tasks; 30 epochs for classification, and 20 for denoising and Sudoku tasks). We run the cart-pole example with batch size 1 for 800 epochs. For the first three experiments, we use the same QP layer models as (Amos & Kolter, 2017), except that we have changed the backends for executing the forward and backward passes (using either Qpth, QPLayer5 or CvxpyLayer). Finally, we have used the following learning rates for running the benchmarks: 10\u22123 for classification, 10\u22125 for denoising, 5\u00d7 10\u22122 for Sudoku, and 10\u22121 for cart-pole tasks.\n5Yet two differences should be noted: QPLayer learns LP for the Sudoku experiment. We have not imposed zero Hessian for the CvxpyLayer even if it could learn it, as it would display worse results. Furthermore, for the denoising experiment, QPLayer learns the lower and upper bounds simultaneously."
        },
        {
            "heading": "C.3 TRAINING WITH LARGE LEARNING RATES",
            "text": "In this section, we assess the numerical robustness of QPLayer on traditional learning tasks by demonstrating that it can be trained with larger learning rates than other approaches, potentially resulting in improved attraction pools.\nMore precisely, we ran the MNIST classification and denoising tasks described in ?? with SGD and larger learning rates and reported the corresponding results. We measured the final test loss and error reached after 30 epochs and the standard deviation over the last 10 epochs of the test loss and test error. The results are averaged over 10 seeds and the experiment is performed for different learning rates.\nAs described in Appendix C.2.2, for those tasks, the QP layers need to learn all the model parameters (i.e., H , g, C, and u). We observe that it generates potentially very ill-conditioned problems when the forward or the backward passes are not solved accurately enough. This phenomenon appears to be amplified with larger learning rates. In those situations, it appears that robust solution methods (e.g., allowing for temporary infeasible, or ill-conditioned problems) are critical.\nFigure 10a and Figure 10b show that for too high learning rates (i.e., 10\u22124 or 10\u22125 for denoising task and 10\u22122 for the classification task) the OptNet layer generate errors, whereas it is never the case for QPLayer. Furthermore, for low learning rate levels (i.e., 10\u22126 or 10\u22127 for the denoising task and 10\u22123 and 10\u22124 for the classification task), the final loss reached is similar but with a less important noise amplitude level when using QPLayer ( Figure 11 provides robustness statistics of the classification task using the prediction error rate of the two layers). Finally, QPLayer is capable of being trained with a larger learning rate (i.e., 10\u22124 for the denoising task and 10\u22122 for the classification task). Also,\nnote that CvxpyLayer fails to be run in all these robustness experiments because the Hessian part of the quadratic model fails to fit the required DPP form (Amos et al., 2018, Section 4.1).\nRemark 1 (Numerical differences with OptNet). Our approach offers a few numerical advantages compared to (Amos & Kolter, 2017). In particular, a numerical matrix factorization is at the center of most popular techniques for differentiating through QPs. This factorization procedure represents one of the main bottlenecks in the computational costs. In our approach, we need to factorize smaller and better-conditioned symmetric matrices.\nThe formulation exploited by OptNet consists of a larger linear system to compute its Jacobians. More precisely, they factorize a matrix of the form:\nK = H 0 C\u22a40 D(z\u22c6) D(t\u22c6) C I 0  , where t\u22c6 = Cx\u22c6\u2212u and D(z\u22c6) corresponds to a diagonal matrix whose diagonal entries correspond to z\u22c6. For obtaining a symmetrized version that can be factorized with efficient methods, the second row block is scaled by D(1/t\u22c6) (Amos & Kolter, 2017, Section 3.1). Yet, symmetrization comes at the price of being more sensitive to the localization of the solution w.r.t the constraints. Indeed, if x\u22c6 lies on the boundary, i.e., CIx\u22c6 \u2212 uI = 0 for some component index I , the conditioning of the matrix is degraded, as OptNet needs to divide by zeros (or small clamped numbers in practice)."
        },
        {
            "heading": "On our side, the formulation for feasible QPs relies on a smaller matrix, which is symmetric and betterconditioned (it does not require scaling rows by values that are potentially zeros, see equation 10).",
            "text": ""
        },
        {
            "heading": "D EXPERIMENTAL SETUP",
            "text": "This section details the optimization architectures used for the Sudoku tasks described in Section 4.1. The cart-pole task mentioned in Appendix C.2.2 is detailed in Appendix D.2."
        },
        {
            "heading": "D.1 LAYER ARCHITECTURE FOR THE SUDOKU PROBLEM",
            "text": "The layer architecture used by OptNet Amos & Kolter (2017) for the Sudoku problem is described in Figure 12. In contrast, the QPLayer architecture (which does not require structural feasibility of the QPs) is described in Figure 13. The QPLayer architecture allows learning more structured constraints, such as the Sudoku constraint \u201cAx = 1\u201d, which cannot be done, as is, with OptNet (which requires the QPs to be structurally feasible).\nlayer is trained using OptNet after adding a small strictly convex quadratic (i.e., 5\u00d7 10\u22125\u2225\nxyz\ns\n \u222522)."
        },
        {
            "heading": "D.2 DESCRIPTION OF THE CART-POLE PROBLEM",
            "text": "The cart-pole system (Anderson, 1989) is a classic control problem used for benchmarking control algorithms. The system we consider consists of an extended model with dry friction on the joints of the cart-pole, namely on the prismatic cart joint and the revolute joint of the pole. It makes the dynamics non-smooth. It is described by a set of differential equations relating the position, velocity, acceleration, angle, and angular velocity of the cart and pole plus the additional friction forces. The static friction forces on each joint can be obtained by solving a QP problem, see equation 29 and (Le Lidec et al., 2021).\nTask: The initial position of the cart-pole system consists of the pole hanging down vertically. The objective of the task is to move the cart in such a way as to swing the pole up and keep it balanced in the upright position. To swing the pole up, the control inputs may involve moving the cart back and forth in a particular pattern that generates the necessary forces to overcome the friction and accelerate the pole in the desired direction.\nThe forward dynamics with friction Ma = \u03c4 + \u03bb,\ncan be re-written in terms of velocity and impulses with timestep \u2206t as\nv = vf +M \u22121\u03bb\u2206t = vf +M \u22121\u039b,\nwere M is the inertia matrix of the system, a \u2208 Rnv is the joint acceleration, \u03c4 \u2208 Rnv the joint torque, vf the free velocity of the system without friction and \u03bb \u2208 Rnv the dry friction force on every joint. To obtain the friction impulse \u039b corresponding to the friction coefficient \u03b7, the following quadratic problem can be solved:\nmin \u039b\n1 2 \u039bTM\u22121\u039b + vTf \u039b\ns.t. |\u039b| \u2a7d \u03b7. (29)\nIts Lagrangian L can be written as follows\nL(\u039b, y) := 1\n2 \u039bTM\u22121\u039b + vTf \u039b + y T (|\u039b| \u2212 \u03b7),\nwhich leads to the KKT system:\nM\u22121\u039b + vf + diag(sign(\u039b))y = 0, (30) |\u039b| \u2a7d \u03b7, (31) y \u2a7e 0, (32) y \u2299 [|\u039b| \u2212 \u03b7] = 0, (33)\nwhere \u2299 stands for the standard Hadamard product. Considering the case where the friction force is within the friction cone for a specific joint j, i.e., |\u039bj | < \u03b7j , the joint is then not moving. We see from equation 33 that yj = 0 satisfies equation 32 and we get from equation 30\nM\u22121\u039bj = \u2212vf,j .\nConsequently, the friction impulse is acting in the opposite direction than the joint torque \u03c4j and with a magnitude that is canceling out the free velocity. If |\u039bj | = \u03b7j , the joint will no longer be blocked by the friction forces and will thus start moving. We see from equation 30\nM\u22121\u039bj + vf,j = vj = \u2212diag(sign(\u039bj))yj . (34)\nAs y \u2a7e 0, equation 34 shows that \u039b is opposed to the velocity of the joint.\nOptimal control algorithms such as Differential Dynamic Programming (DDP) can be used to compute the optimal trajectory that minimizes a cost function over a finite time horizon, subject to the dynamics of the cart-pole system and control input constraints.\nThese methods take advantage of the derivatives of the dynamics to efficiently control physical systems. In the presence of non-smooth dynamics, such a class of algorithms is likely to fail due, for instance, to the presence of discontinuities in the dynamics derivatives or because of the noninformative gradient (Lidec et al., 2022). In the cart-pole benchmark, randomized smoothing, as proposed by (Lidec et al., 2022; Suh et al., 2021) is used to cope with the non-smooth dynamical system. For the optimal swing-up trajectory with 20 timesteps, 5 random samples with a uniform Gaussian noise are generated. The random noise is applied to the input controls, and the dynamics are calculated for each of them and afterward averaged in the forward pass, resulting in informative gradients in the backward pass. equation 29, has to be solved for every random sample in every timestep."
        }
    ],
    "title": "LEVERAGING AUGMENTED-LAGRANGIAN TECHNIQUES FOR DIFFERENTIATING OVER INFEASIBLE QUADRATIC PROGRAMS IN MACHINE LEARNING",
    "year": 2023
}