{
    "abstractText": "We investigate the internal behavior of Transformer-based Large Language Models (LLMs) when they generate factually incorrect text. We propose modeling factual queries as constraint satisfaction problems and use this framework to investigate how the LLM interacts internally with factual constraints. We find a strong positive relationship between the LLM\u2019s attention to constraint tokens and the factual accuracy of generations. We curate a suite of 11 datasets containing over 40,000 prompts to study the task of predicting factual errors with the Llama-2 family across all scales (7B, 13B, 70B). We propose SAT Probe, a method probing attention patterns, that can predict factual errors and fine-grained constraint satisfaction, and allow early error identification. The approach and findings take another step towards using the mechanistic understanding of LLMs to enhance their reliability.",
    "authors": [],
    "id": "SP:f9fb60f3fb498d8e329fced03a6b1cf6e741c0b5",
    "references": [
        {
            "authors": [
                "Joshua Ainslie",
                "James Lee-Thorp",
                "Michiel de Jong",
                "Yury Zemlyanskiy",
                "Federico Lebr\u00f3n",
                "Sumit Sanghai"
            ],
            "title": "Gqa: Training generalized multi-query transformer models from multi-head checkpoints",
            "venue": "arXiv preprint arXiv:2305.13245,",
            "year": 2023
        },
        {
            "authors": [
                "Nora Belrose",
                "Zach Furman",
                "Logan Smith",
                "Danny Halawi",
                "Igor Ostrovsky",
                "Lev McKinney",
                "Stella Biderman",
                "Jacob Steinhardt"
            ],
            "title": "Eliciting latent predictions from transformers with the tuned lens",
            "venue": "arXiv preprint arXiv:2303.08112,",
            "year": 2023
        },
        {
            "authors": [
                "Stella Biderman",
                "USVSN Sai Prashanth",
                "Lintang Sutawika",
                "Hailey Schoelkopf",
                "Quentin Anthony",
                "Shivanshu Purohit",
                "Edward Raf"
            ],
            "title": "Emergent and predictable memorization in large language models",
            "venue": "arXiv preprint arXiv:2304.11158,",
            "year": 2023
        },
        {
            "authors": [
                "Steven Bird",
                "Ewan Klein",
                "Edward Loper"
            ],
            "title": "Natural language processing with Python: analyzing text with the natural language toolkit",
            "year": 2009
        },
        {
            "authors": [
                "Collin Burns",
                "Haotian Ye",
                "Dan Klein",
                "Jacob Steinhardt"
            ],
            "title": "Discovering latent knowledge in language models without supervision",
            "venue": "arXiv preprint arXiv:2212.03827,",
            "year": 2022
        },
        {
            "authors": [
                "Nicholas Carlini",
                "Florian Tramer",
                "Eric Wallace",
                "Matthew Jagielski",
                "Ariel Herbert-Voss",
                "Katherine Lee",
                "Adam Roberts",
                "Tom B Brown",
                "Dawn Song",
                "Ulfar Erlingsson"
            ],
            "title": "Extracting training data from large language models",
            "venue": "In USENIX Security Symposium,",
            "year": 2021
        },
        {
            "authors": [
                "Nicholas Carlini",
                "Daphne Ippolito",
                "Matthew Jagielski",
                "Katherine Lee",
                "Florian Tramer",
                "Chiyuan Zhang"
            ],
            "title": "Quantifying memorization across neural language models",
            "venue": "arXiv preprint arXiv:2202.07646,",
            "year": 2022
        },
        {
            "authors": [
                "Kevin Clark",
                "Urvashi Khandelwal",
                "Omer Levy",
                "Christopher D Manning"
            ],
            "title": "What does bert look at? an analysis of bert\u2019s attention",
            "year": 1906
        },
        {
            "authors": [
                "Roi Cohen",
                "May Hamri",
                "Mor Geva",
                "Amir Globerson"
            ],
            "title": "Lm vs lm: Detecting factual errors via cross examination",
            "venue": "arXiv preprint arXiv:2305.13281,",
            "year": 2023
        },
        {
            "authors": [
                "Guy Dar",
                "Mor Geva",
                "Ankit Gupta",
                "Jonathan Berant"
            ],
            "title": "Analyzing transformers in embedding space",
            "venue": "arXiv preprint arXiv:2209.02535,",
            "year": 2022
        },
        {
            "authors": [
                "Tim Dettmers",
                "Mike Lewis",
                "Younes Belkada",
                "Luke Zettlemoyer"
            ],
            "title": "Llm. int8 (): 8-bit matrix multiplication for transformers at scale",
            "venue": "arXiv preprint arXiv:2208.07339,",
            "year": 2022
        },
        {
            "authors": [
                "Tim Dettmers",
                "Mike Lewis",
                "Sam Shleifer",
                "Luke Zettlemoyer"
            ],
            "title": "8-bit optimizers via block-wise quantization",
            "venue": "9th International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova. Bert"
            ],
            "title": "Pre-training of deep bidirectional transformers for language understanding",
            "venue": "arXiv preprint arXiv:1810.04805,",
            "year": 2018
        },
        {
            "authors": [
                "Nelson Elhage",
                "Neel Nanda",
                "Catherine Olsson",
                "Tom Henighan",
                "Nicholas Joseph",
                "Ben Mann",
                "Amanda Askell",
                "Yuntao Bai",
                "Anna Chen",
                "Tom Conerly",
                "Nova DasSarma",
                "Dawn Drain",
                "Deep Ganguli",
                "Zac Hatfield-Dodds",
                "Danny Hernandez",
                "Andy Jones",
                "Jackson Kernion",
                "Liane Lovitt",
                "Kamal Ndousse",
                "Dario Amodei",
                "Tom Brown",
                "Jack Clark",
                "Jared Kaplan",
                "Sam McCandlish",
                "Chris Olah"
            ],
            "title": "A mathematical framework for transformer circuits",
            "venue": "Transformer Circuits Thread,",
            "year": 2021
        },
        {
            "authors": [
                "Yonatan Geifman",
                "Ran El-Yaniv"
            ],
            "title": "Selective classification for deep neural networks",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Ian P Gent",
                "Ewan MacIntyre",
                "Patrick Prosser",
                "Toby Walsh"
            ],
            "title": "The constrainedness of search",
            "venue": "In AAAI/IAAI,",
            "year": 1996
        },
        {
            "authors": [
                "Mor Geva",
                "Roei Schuster",
                "Jonathan Berant",
                "Omer Levy"
            ],
            "title": "Transformer feed-forward layers are key-value memories",
            "venue": "In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2021
        },
        {
            "authors": [
                "Mor Geva",
                "Jasmijn Bastings",
                "Katja Filippova",
                "Amir Globerson"
            ],
            "title": "Dissecting recall of factual associations in auto-regressive language models",
            "venue": "arXiv preprint arXiv:2304.14767,",
            "year": 2023
        },
        {
            "authors": [
                "Wes Gurnee",
                "Neel Nanda",
                "Matthew Pauly",
                "Katherine Harvey",
                "Dmitrii Troitskii",
                "Dimitris Bertsimas"
            ],
            "title": "Finding neurons in a haystack: Case studies with sparse probing",
            "venue": "arXiv preprint arXiv:2305.01610,",
            "year": 2023
        },
        {
            "authors": [
                "Rasmus Hahn",
                "Christian Bizer",
                "Christopher Sahnwaldt",
                "Christian Herta",
                "Scott Robinson",
                "Michaela B\u00fcrgle",
                "Holger D\u00fcwiger",
                "Ulrich Scheel"
            ],
            "title": "Faceted wikipedia search",
            "venue": "In Business Information Systems: 13th International Conference, BIS 2010, Berlin,",
            "year": 2010
        },
        {
            "authors": [
                "Danny Halawi",
                "Jean-Stanislas Denain",
                "Jacob Steinhardt"
            ],
            "title": "Overthinking the truth: Understanding how language models process false demonstrations",
            "venue": "Submitted to International Conference on Learning Representations",
            "year": 2022
        },
        {
            "authors": [
                "Evan Hernandez",
                "Arnab Sen Sharma",
                "Tal Haklay",
                "Kevin Meng",
                "Martin Wattenberg",
                "Jacob Andreas",
                "Yonatan Belinkov",
                "David Bau"
            ],
            "title": "Linearity of relation decoding in transformer language models",
            "venue": "arXiv preprint arXiv:2308.09124,",
            "year": 2023
        },
        {
            "authors": [
                "Phu Mon Htut",
                "Jason Phang",
                "Shikha Bordia",
                "Samuel R Bowman"
            ],
            "title": "Do attention heads in bert track syntactic dependencies",
            "year": 1911
        },
        {
            "authors": [
                "Minlie Huang",
                "Xiaoyan Zhu",
                "Jianfeng Gao"
            ],
            "title": "Challenges in building intelligent open-domain dialog systems",
            "venue": "ACM Transactions on Information Systems (TOIS),",
            "year": 2020
        },
        {
            "authors": [
                "Ziwei Ji",
                "Nayeon Lee",
                "Rita Frieske",
                "Tiezheng Yu",
                "Dan Su",
                "Yan Xu",
                "Etsuko Ishii",
                "Ye Jin Bang",
                "Andrea Madotto",
                "Pascale Fung"
            ],
            "title": "Survey of hallucination in natural language generation",
            "venue": "ACM Computing Surveys,",
            "year": 2023
        },
        {
            "authors": [
                "Nikhil Kandpal",
                "Haikang Deng",
                "Adam Roberts",
                "Eric Wallace",
                "Colin Raffel"
            ],
            "title": "Large language models struggle to learn long-tail knowledge",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Kenneth Li",
                "Oam Patel",
                "Fernanda Vi\u00e9gas",
                "Hanspeter Pfister",
                "Martin Wattenberg"
            ],
            "title": "Inference-time intervention: Eliciting truthful answers from a language model",
            "venue": "arXiv preprint arXiv:2306.03341,",
            "year": 2023
        },
        {
            "authors": [
                "Percy Liang",
                "Rishi Bommasani",
                "Tony Lee",
                "Dimitris Tsipras",
                "Dilara Soylu",
                "Michihiro Yasunaga",
                "Yian Zhang",
                "Deepak Narayanan",
                "Yuhuai Wu",
                "Ananya Kumar"
            ],
            "title": "Holistic evaluation of language models",
            "venue": "arXiv preprint arXiv:2211.09110,",
            "year": 2022
        },
        {
            "authors": [
                "Q Vera Liao",
                "Jennifer Wortman Vaughan"
            ],
            "title": "Ai transparency in the age of llms: A human-centered research roadmap",
            "venue": "arXiv preprint arXiv:2306.01941,",
            "year": 2023
        },
        {
            "authors": [
                "Alex Mallen",
                "Akari Asai",
                "Victor Zhong",
                "Rajarshi Das",
                "Hannaneh Hajishirzi",
                "Daniel Khashabi"
            ],
            "title": "When not to trust language models: Investigating effectiveness and limitations of parametric and non-parametric memories",
            "venue": "arXiv preprint arXiv:2212.10511,",
            "year": 2022
        },
        {
            "authors": [
                "Potsawee Manakul",
                "Adian Liusie",
                "Mark JF Gales"
            ],
            "title": "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models",
            "venue": "arXiv preprint arXiv:2303.08896,",
            "year": 2023
        },
        {
            "authors": [
                "Kevin Meng",
                "David Bau",
                "Alex Andonian",
                "Yonatan Belinkov"
            ],
            "title": "Locating and editing factual associations in gpt",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Sewon Min",
                "Kalpesh Krishna",
                "Xinxi Lyu",
                "Mike Lewis",
                "Wen-tau Yih",
                "Pang Wei Koh",
                "Mohit Iyyer",
                "Luke Zettlemoyer",
                "Hannaneh Hajishirzi"
            ],
            "title": "Factscore: Fine-grained atomic evaluation of factual precision in long form text generation",
            "venue": "arXiv preprint arXiv:2305.14251,",
            "year": 2023
        },
        {
            "authors": [
                "Niels M\u00fcndler",
                "Jingxuan He",
                "Slobodan Jenko",
                "Martin Vechev"
            ],
            "title": "Self-contradictory hallucinations of large language models: Evaluation, detection and mitigation",
            "venue": "arXiv preprint arXiv:2305.15852,",
            "year": 2023
        },
        {
            "authors": [
                "Catherine Olsson",
                "Nelson Elhage",
                "Neel Nanda",
                "Nicholas Joseph",
                "Nova DasSarma",
                "Tom Henighan",
                "Ben Mann",
                "Amanda Askell",
                "Yuntao Bai",
                "Anna Chen"
            ],
            "title": "In-context learning and induction heads",
            "venue": "arXiv preprint arXiv:2209.11895,",
            "year": 2022
        },
        {
            "authors": [
                "Long Ouyang",
                "Jeffrey Wu",
                "Xu Jiang",
                "Diogo Almeida",
                "Carroll Wainwright",
                "Pamela Mishkin",
                "Chong Zhang",
                "Sandhini Agarwal",
                "Katarina Slama",
                "Alex Ray"
            ],
            "title": "Training language models to follow instructions with human feedback",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "F. Pedregosa",
                "G. Varoquaux",
                "A. Gramfort",
                "V. Michel",
                "B. Thirion",
                "O. Grisel",
                "M. Blondel",
                "P. Prettenhofer",
                "R. Weiss",
                "V. Dubourg",
                "J. Vanderplas",
                "A. Passos",
                "D. Cournapeau",
                "M. Brucher",
                "M. Perrot",
                "E. Duchesnay"
            ],
            "title": "Scikit-learn: Machine learning in Python",
            "venue": "Journal of Machine Learning Research,",
            "year": 2011
        },
        {
            "authors": [
                "Fabio Petroni",
                "Tim Rockt\u00e4schel",
                "Patrick Lewis",
                "Anton Bakhtin",
                "Yuxiang Wu",
                "Alexander H Miller",
                "Sebastian Riedel"
            ],
            "title": "Language models as knowledge bases",
            "year": 1909
        },
        {
            "authors": [
                "Amanda Spink",
                "Dietmar Wolfram",
                "Major BJ Jansen",
                "Tefko Saracevic"
            ],
            "title": "Searching the web: The public and their queries",
            "venue": "Journal of the American society for information science and technology,",
            "year": 2001
        },
        {
            "authors": [
                "Aarohi Srivastava",
                "Abhinav Rastogi",
                "Abhishek Rao",
                "Abu Awal Md Shoeb",
                "Abubakar Abid",
                "Adam Fisch",
                "Adam R Brown",
                "Adam Santoro",
                "Aditya Gupta",
                "Adri\u00e0 Garriga-Alonso"
            ],
            "title": "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models",
            "venue": "arXiv preprint arXiv:2206.04615,",
            "year": 2022
        },
        {
            "authors": [
                "Kai Sun",
                "Yifan Ethan Xu",
                "Hanwen Zha",
                "Yue Liu",
                "Xin Luna Dong"
            ],
            "title": "Head-to-tail: How knowledgeable are large language models (llm)? aka will llms replace knowledge graphs",
            "venue": "arXiv preprint arXiv:2308.10168,",
            "year": 2023
        },
        {
            "authors": [
                "Yuandong Tian",
                "Yiping Wang",
                "Beidi Chen",
                "Simon Du"
            ],
            "title": "Scan and snap: Understanding training dynamics and token composition in 1-layer transformer",
            "venue": "arXiv preprint arXiv:2305.16380,",
            "year": 2023
        },
        {
            "authors": [
                "Hugo Touvron",
                "Louis Martin",
                "Kevin Stone",
                "Peter Albert",
                "Amjad Almahairi",
                "Yasmine Babaei",
                "Nikolay Bashlykov",
                "Soumya Batra",
                "Prajjwal Bhargava",
                "Shruti Bhosale"
            ],
            "title": "Llama 2: Open foundation and fine-tuned chat models",
            "venue": "arXiv preprint arXiv:2307.09288,",
            "year": 2023
        },
        {
            "authors": [
                "Daniel Tunkelang"
            ],
            "title": "Faceted search, volume 5",
            "year": 2009
        },
        {
            "authors": [
                "Miles Turpin",
                "Julian Michael",
                "Ethan Perez",
                "Samuel R Bowman"
            ],
            "title": "Language models don\u2019t always say what they think: Unfaithful explanations in chain-of-thought prompting",
            "venue": "arXiv preprint arXiv:2305.04388,",
            "year": 2023
        },
        {
            "authors": [
                "Neeraj Varshney",
                "Wenlin Yao",
                "Hongming Zhang",
                "Jianshu Chen",
                "Dong Yu"
            ],
            "title": "A stitch in time saves nine: Detecting and mitigating hallucinations of llms by validating low-confidence generation",
            "venue": "arXiv preprint arXiv:2307.03987,",
            "year": 2023
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Anne M. Archibald",
                "Ant\u00f4nio H. Ribeiro",
                "Fabian Pedregosa",
                "Paul van"
            ],
            "title": "Mulbregt, and SciPy 1.0 Contributors. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python",
            "venue": "Nature Methods,",
            "year": 2020
        },
        {
            "authors": [
                "Elena Voita",
                "David Talbot",
                "Fedor Moiseev",
                "Rico Sennrich",
                "Ivan Titov"
            ],
            "title": "Analyzing multi-head self-attention: Specialized heads do the heavy lifting, the rest can be pruned",
            "year": 1905
        },
        {
            "authors": [
                "Lidan Wang",
                "Jimmy Lin",
                "Donald Metzler"
            ],
            "title": "A cascade ranking model for efficient ranked retrieval",
            "venue": "In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval,",
            "year": 2011
        },
        {
            "authors": [
                "Thomas Wolf",
                "Lysandre Debut",
                "Victor Sanh",
                "Julien Chaumond",
                "Clement Delangue",
                "Anthony Moi",
                "Pierric Cistac",
                "Tim Rault",
                "R\u00e9mi Louf",
                "Morgan Funtowicz"
            ],
            "title": "Huggingface\u2019s transformers: State-of-the-art natural language processing",
            "year": 1910
        },
        {
            "authors": [
                "Mert Yuksekgonul",
                "Linjun Zhang",
                "James Zou",
                "Carlos Guestrin"
            ],
            "title": "Beyond confidence: Reliable models should also consider atypicality",
            "venue": "arXiv preprint arXiv:2305.18262,",
            "year": 2023
        },
        {
            "authors": [
                "Muru Zhang",
                "Ofir Press",
                "William Merrill",
                "Alisa Liu",
                "Noah A Smith"
            ],
            "title": "How language model hallucinations can snowball",
            "venue": "arXiv preprint arXiv:2305.13534,",
            "year": 2023
        },
        {
            "authors": [
                "Models. Touvron"
            ],
            "title": "2023) reports that since key-value caches become prohibitive for larger models such as the Llama-2 70B, they use Grouped-Query Attention (GQA, (Ainslie et al., 2023)) (as opposed to Multi-Head Attention) with 8 key-value projection variant. GQA divides each query head",
            "year": 2023
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Large language models (LLMs) encode substantial knowledge (Petroni et al., 2019; Srivastava et al., 2022), yet they are prone to generating factually incorrect text. For instance, LLMs can generate confident-appearing completions with hallucinations (Zhang et al., 2023; Ji et al., 2023), fabricating entities or factual claims. As LLMs reach wider audiences and are used for safety-critical applications, understanding the factuality of generations rises to paramount importance. However, our understanding of how LLMs process factual queries and produce errors is nascent. Existing approaches fall into two categories: i) treat the LLM as a black box and query it about generated factual claims, or ii) use white-box methods to study how LLMs internally process factual queries.\nBlack-box approaches center on analyzing the consistency of the claims of an LLM using follow-up questions with other LLMs (Cohen et al., 2023) or having the LLM self-critique (Zhang et al., 2023; Manakul et al., 2023). However, explanations from LLMs are suggested to be unreliable (Turpin et al., 2023) or to convey contradictory signals, e.g., LLMs can produce an answer and then acknowledge that it is wrong (Zhang et al., 2023; M\u00fcndler et al., 2023). Further, black-box methods typically involve multiple generations from LLMs, which may be prohibitively expensive to use in practice.\nMechanistic white-box approaches investigate the internal mechanisms of LLMs to dissect factual recall. For instance, Meng et al. (2022); Geva et al. (2023) focus on facts with the (subject, relation, object) structure (e.g., Paris, capital of, France) and propose insightful mechanisms of how an LLM recalls a fact. They suggest that the multi-layer perceptron layers store facts, and attention layers transfer factual information from the subject tokens. However, these works focus on when the LLM generates factually correct responses. Mechanisms leading to factual errors are scarcely explored.\nOur Contributions: We investigate the internal mechanisms of LLMs, specifically the attention patterns, when they produce factual errors. We propose to view factual queries as constraint satisfaction problems (CSPs), where queries comprise constraints that completions should satisfy to be factually correct (\u00a73); e.g., in Figure 1 the director name or the award name are constraints on the model\u2019s response to a search query for a movie. We investigate the interaction between constraints, attention, and factual correctness (\u00a74). Our key finding is that attention to constraint tokens correlates with LLM\u2019s factual correctness, where less attention to constraints is associated with inaccurate responses. Building on our insights, we propose SAT PROBE, a method that predicts constraint satisfaction (and thus factual correctness), using a simple probe of the LLM\u2019s attention to constraints (\u00a75). To test SAT PROBE, we curate a suite of 11 datasets of single- and multi-constraint queries with in total over 40, 000 prompts. We find that SAT PROBE performs comparably to the LLM\u2019s confidence. Further,\n1\nUnder review as a conference paper at ICLR 2024\nSAT PROBE can predict factual errors halfway through the forward pass to stop the computation partway and save costs. Our findings contribute to the mechanistic understanding of LLMs and demonstrate the potential of model internals to understand and mitigate factual errors. Our datasets, evaluation, and methods will be released with the publication."
        },
        {
            "heading": "2 BACKGROUND: LANGUAGE MODELS AND FACTUAL RECALL",
            "text": "Our presentation of the Transformer architecture (Vaswani et al., 2017) largely follows that of Meng et al. (2022); Geva et al. (2023); Elhage et al. (2021). For brevity, we omit the details around layer normalization. Assume an input sequence of T tokens t1, ..., tT and ti \u2208 V for a fixed vocabulary V . A token ti is represented initially with a d-dimensional vector x0i \u2208 Rd using an embedding matrix E \u2208 R|V|\u00d7d. We use V+ to denote a sequence of tokens. The architecture consists of L layers that transform the input token embeddings to a sequence of hidden states x\u21131, . . . ,x \u2113 T at each layer \u2113 where x \u2113 i denotes the state of token i. Often, each hidden state vector has the same number of dimensions, i.e., \u2200 i, \u2113 x\u2113i \u2208 Rd. The states are obtained by\nx\u2113i = x \u2113\u22121 i + a \u2113 i +m \u2113 i , (1)\nwhere we call m\u2113i the MLP contribution and a \u2113 i the attention contribution to a token i at layer \u2113, respectively. The LLM produces a predicted probability distribution for the next token P\u0302(tT+1|t1:T ) using a linear softmax layer on the last layer representation xLT . In this work, we study the interactions among tokens. Since the MLP layers (see Appendix A) in standard Transformers do not capture token interactions, we focus primarily on the attention operation.\nThe attention operation updates each token\u2019s state using the previous states at all positions, i.e., the representation for a token is updated by \u2018attending\u2019 to all other tokens. Formally, the operation involves four projection matrices W \u2113Q,W \u2113 K ,W \u2113 V ,W \u2113 O \u2208 Rd\u00d7d that correspond to the \u2018query\u2019, \u2018key\u2019, \u2018value\u2019, and \u2018output\u2019 projections. Each of these is split into multiple heads, where W \u2113,hQ ,W \u2113,h K ,W \u2113,h V \u2208 Rd\u00d7dh and W \u2113,hO \u2208 Rdh\u00d7d denote the matrices for head h, H is the total number of heads, dh is the dimensionality for each head for h \u2208 [H]. Often embeddings are split into equal parts such that dh = d H (Elhage et al., 2021; Dar et al., 2022; Touvron et al., 2023). The attention contribution from the token j to token i a\u2113i,j is defined as:\na\u2113i,j =\nH\u2211\nh=1\nA\u2113,hi,j (x \u2113\u22121 j W \u2113,h V )W \u2113,h O , (2)\n2\nUnder review as a conference paper at ICLR 2024\nA\u2113,h = Softmax\n(( X\u2113\u22121W \u2113,hQ )( X\u2113\u22121W \u2113,hK )T \u221a dh/H ) , (3)\nwhere ali = \u2211 j\u2208[T ] a l i,j and Softmax is taken row-wise. A\n\u2113,h \u2208 RT\u00d7T are the attention weights computed by the h-th attention head at layer \u2113, and A\u2113,hi,j is the entry in the i-th row and j-th column of the matrix. For autoregressive LLMs, A\u2113,h is lower triangular since each token can only attend to the representation of the previous tokens. For brevity, we use [H] to denote the sequence of integers from 1 to H , and superscript [H] indicates stacking items for all h \u2208 [H], i.e., A\u2113,[H]i,j = {A\u2113,hi,j }Hh=1 \u2208 RH . Mechanics of Factual Recall in Language Models: Recent work investigates the internal activations of LLMs to understand the mechanics of factual recall. By studying factual queries of the form (subject, relation, object), Meng et al. (2022); Geva et al. (2021) provide evidence that MLP layers store factual associations and Geva et al. (2023); Meng et al. (2022); Elhage et al. (2021) suggest that attention layers transfer factual knowledge to where it will be used. As an example, when an LLM is given the prompt LeBron James professionally plays, the information LeBron James professionally plays basketball is extracted by the MLP contribution to the tokens for LeBron James (subject). Next, the attention layers transfer the information from the tokens of the subject to the last token for the LLM to generate basketball (object). While these works mostly study internal mechanisms when the LLM\u2019s completions are factually correct, we focus on when LLMs produce factually incorrect text."
        },
        {
            "heading": "3 FACTUAL QUERIES AS CONSTRAINT SATISFACTION PROBLEMS",
            "text": "Choosing the right framework to study factual errors is challenging. One can naively categorize completions as factually correct or incorrect, yet this binary view can fall short. For example, queries that are easy for the LLM and ones that it barely gets right are indistinguishable since both are labeled as \u2018correct\u2019. Further, binary labeling prevents us from building an understanding of why some queries are more difficult than others or which parts of the queries drive the LLM to failure.\nTo systematically study factual queries and LLMs\u2019 internal behavior, we propose taking a CSP view:\nDefinition 3.1 (Factual Query as a CSP). A factual query is specified by a set of constraints C = {(C1, V1), . . . (CK , VK)} where Ck \u2208 V+ indicates the sequence of tokens for the constraining entity k1, and Vk : V+ \u2192 {0, 1} is a verifier that takes a set of generation tokens as the input and returns whether the constraint indexed by k is satisfied. Under this view, we call a completion Y as a factual error if \u2203 k \u2208 [K] : Vk(Y ) = 0, that is, if there is a constraint in the factual query that the response does not satisfy2. Otherwise, we call the response factually correct.\nA large set of factual queries can be viewed as a set of constraints that responses must satisfy to be correct, e.g., see Figure 1. This structure is comprehensive; for example, an important subset of queries made by users to search engines has historically been conjunctions of constraints (Spink et al., 2001). Structured and multi-constraint queries are also inherent to faceted search and information retrieval (Tunkelang, 2009; Hahn et al., 2010). Further, under this definition, prior (subject, relation, object) queries (Meng et al., 2022) can be seen to have a single-constraint structure. Similarly, instructions to LLMs are also constraints for controlling the output (Ouyang et al., 2022).\nFocusing on the constraints of a CSP can help us reason about the difficulty of a query and the behavior of the LLM. While there are several factors that can influence LLM\u2019s behavior, we shall start with two factors that can describe the difficulty of factual queries: i) the popularity of the constraining entity, and ii) the constrainedness of the query.\nPopularity of the Entity vs LLM Performance: Recent work has shown the correlation between training data frequency and memorization in LLMs (Carlini et al. (2022); Biderman et al. (2023); inter alia). However, even for many open-source LLMs, we cannot compute the frequency of facts since we do not have the training data or a trivial way to search for complex facts. As an accessible proxy for entities from WikiData, we use the number of site links on a page as the popularity of\n1While it may be nontrivial to generally isolate tokens for the constraining entity for arbitrary queries, in our evaluations we investigate settings in which we assume we have access to this set.\n2Here, we focus on conjunctions of constraints, but the framework can be generalized to other operations.\n3\nUnder review as a conference paper at ICLR 2024\nEx: Tell me the year the basketball player Kobe Bryant was born in\nEx: Tell me a word that starts with e and ends with t\nentity; we hypothesize that it strongly correlates with the training data frequency or popularity. See Tables 3 and 4 for examples of popularity statistics across basketball players and football teams.\nFor Figure 2 left, we use queries of the form Tell me the year the basketball player [name] was born in (see 1) and evaluate LLMs\u2019 accuracy. We compare the correctness of the LLM for entities (players) of varying popularity. We observe that i) LLM performance is better for entities with higher popularity, and ii) larger LLMs have better performance for entities that are less popular. Recent works show similar relationships with popular/typical input (Mallen et al., 2022; Yuksekgonul et al., 2023).\nConstrainedness of the CSP vs LLM Performance: A well-explored complexity metric for CSPs is constrainedness (Gent et al., 1996). Here, we define constrainedness as the number of potential solutions to a given problem in the domain of the output. For instance, for a query of the form Tell me a word that starts with the letter e and ends with the letter t, we quantify constrainedness by the number of such words3 in the English language that satisfy these constraints. Figure 2 right shows how constrainedness relates to success: i) LLMs have worse performance for more constrained problems, and ii) larger models perform better across all constrainedness levels.\nSummary: We argue that the CSP lens can provide a useful vocabulary to capture the difficulty of factual queries. Our goal is to build a framework to discuss how LLMs process factual queries and generate errors. Next, we investigate LLMs\u2019 internal mechanisms to understand factual errors."
        },
        {
            "heading": "4 UNDERSTANDING FACTUAL ERRORS VIA ATTENTION TO CONSTRAINTS",
            "text": "Here, we explore how an LLM processes constraints when the model produces factually incorrect text. Geva et al. (2023); Meng et al. (2022) suggest that attention layers transfer the factual information\n3We use nltk.corpus.words (Bird et al., 2009) to compute the number of such words.\n4\nUnder review as a conference paper at ICLR 2024\nfrom the source entity (e.g., Bad Romance) to the last token for generation (to generate Lady Gaga, Figure 3) when the LLM correctly addresses a query. However, these works do not explore the mechanisms when the model produces factually incorrect responses. Intuitively, we want to quantify how the LLM interacts with constraints to understand constraint satisfaction (and thus factual errors).\nTo study how the LLM processes a constraint, we focus on the attention to the constraint tokens, i.e.,\na\u2113,hc,T = A \u2113,h c,T ( x\u2113\u22121c W \u2113,h V ) W \u2113,hO , (4)\nwhere a\u2113,hc,T \u2208 Rd indicates the attention contribution from a constraint token c through a head h to the final token T (where the T +1th token will be generated). The total attention contribution to T is then is a\u2113c,T = \u2211 h a \u2113,h c,T . When the constraint comprises multiple tokens denoted by the set C, we take the maximum value across all constraint tokens, i.e., A\u2113,hC,T = maxc\u2208C A \u2113,h c,T or a \u2113,h C,T = maxc\u2208C ||a\u2113,hc,T ||4. Figure 1 shows an example. We track the regions that are marked by C1 and C2 that represent the constraints that the movies were directed by the given directors and won the given awards.\nTo understand whether attention to constraints can help explain factual errors, we study three factors. First, we explore the relationship between attention and popularity of the constraining entity, as we find that LLM\u2019s correctness correlates with popularity (Fig 2). Next, we explore the relation of attention to the LLM\u2019s confidence P\u0302(Y |X), which estimates the probability of a completion Y given the prompt X . Finally, we explore how attention patterns behave when we scale the LLMs.\nAttention predicts popularity: In Figure 11, we show the results for predicting the popularity of the constraining entity in the prompt (the basketball player) only from the attention weights (A[L],[H]C,T ) using Lasso Regression. In all Llama-2 models (7B, 13B, 70B), the predicted popularities using attention values significantly correlate with the ground truth popularity (over a held-out set, with Spearman\u2019s Correlation \u03c1 \u2265 0.65 and p-value p \u2248 0 for all LLMs). See Appendix C.1 for details. Popularity seems predictive, yet we may not always have access to a clean popularity measure or frequency of constraints in training data. Our main goal is to characterize and predict factual errors, thus we seek a more reliable indicator of factual correctness.\nAttention correlates with confidence and LLM\u2019s correctness: In Figure 4 (left four panels), each row represents the attention flow across layers for a single sample and we sort the points by the confidence of the LLM. The leftmost panels show the attention for the 25 most confident predictions and the middle panels show the 25 least confident predictions; where the x-axis shows the layers, and colors indicate the norm of the attention contribution from the constraints ( ||a\u2113,[H]C,T || ) . The core observation is that when the LLM is accurate, there is more attention to constraint tokens (first column) in sharp contrast to cases where the LLM fails and the attention is weak (second column).\nIn Figure 4\u2019s rightmost plots, queries are sorted and grouped by the LLM\u2019s total attention contribution from the constraints across all layers ( \u2211 \u2113 ||a\u2113C,T ||), and LLM\u2019s accuracy is computed for each group. We observe that the magnitude of attention to constraints correlates with accuracy. This observation is not only interesting in hindsight; aforethought could have suggested either outcome (e.g., more attention correlating with hallucination). This is a positive observation that suggests attention to constraints can be used to predict LLM\u2019s success.\nLanguage models grow larger, pay more attention, and succeed more: In Figure 5, each panel compares the attention to constraints for the basketball player queries between two different LLMs, where the x-axis indicates the smaller LLM, the y-axis indicates the larger LLM and the coloring indicates the success of the pair of LLMs. We group prompts by the attention contribution, and color the cells by the the most frequent category. We find that more (relatively) attention in both LLMs generally indicates success for both and less attention in both LLMs indicates failure for both. For cases on the top left, the larger LLM does pay more attention, and only the larger LLM succeeds. Overall, we note a consistent pattern between attention and correctness across model scales; and performance improvements in larger LLMs correlate with increased attention to constraint tokens.\n4While there is earlier work that suggests the last constraint token could the most important, we observed that in practice there are subtleties. See Appendix C.2 for a discussion.\n5\nUnder review as a conference paper at ICLR 2024\nSummary: We explored the interaction between attention, constraints, and factual correctness. Our analyses suggest that attention can help us understand and predict factual errors. Next, we further pull this thread with extensive experiments to predict factual errors using LLMs\u2019 attention patterns."
        },
        {
            "heading": "5 PREDICTING FACTUAL ERRORS USING ATTENTION TO CONSTRAINTS",
            "text": "We now show how our mechanistic understanding can be used to predict the failures of LLMs. Let X denote a prompt, a sequence of tokens that specifies a factual query with a set of constraints C = {(C1, V1), . . . (CK , VK)}. Let Y\u0302 be the response tokens obtained from the LLM after feeding X . Broadly, we want to design a function f to estimate the probability that a constraint k is satisfied:\nP\u0302(Vk(Y\u0302 ) = 1) = f(X, Y\u0302 , Ck,M),\nusing the prompt, completion, constraint tokens, and the LLM M. For single-constraint factual queries where there is a single correct completion Y , this can be reduced to the correctness P\u0302(Y = Y\u0302 ) = f(X, Y\u0302 ,M). Note how this formalism closely matches that of selective classification (Geifman & El-Yaniv, 2017), where the goal is to abstain when the model would otherwise fail.\nDatasets: For our evaluations, we curate a benchmark with 11 datasets that are listed in Table 1 containing over 40, 000 queries. For single-constraint queries, we curate 4 datasets using WikiData and 3 datasets using the existing CounterFact dataset (Meng et al., 2022). We further designed four 2-constraint datasets, using WikiData (Books and Movies), Opendatasoft (2023) (Nobel Winners), or hand-curation (Words). Further details about all data curation can be found in Appendix D.\n6\nUnder review as a conference paper at ICLR 2024\nConstraint Verification (Vk): We use Exact Match5 for single-constraint queries with a single solution. We probe WikiData to verify constraints when queries have multiple potential solutions (e.g., we check WikiData for whether the movie name generated by the model is directed by the director in the constraint). Appendix D.3 contains a complete description of the methodology.\nModels: We use the 7B, 13B, and 70B parameter variants of Llama-2 (Touvron et al., 2023) released at HuggingFace\u2019s Transformers (Wolf et al., 2019). We perform our experiments on a single NVIDIA A100-PCIE-80GB GPU. 80GB memory can only fit the Llama-2 70B in 8-bit precision (Dettmers et al. (2022a) report marginal-to-no performance drop). See Appendix A for further details on models.\nEvaluation Metrics: We use AUROC for the binary task of predicting failure or success as it does not require setting a threshold for the classifier. We also report RiskTop 20% (the fraction of errors for the samples with top 20% of the scores by the predictor f ), RiskBottom 20% (the fraction of errors for the samples with the bottom 20% of the scores by the predictor f ). These metrics measure how well the model performs on the most and least reliable completions according to the predictor f . For a good success predictor, we want the error fraction to be low among high-score examples (small RiskTop 20%) and have a large fraction of failures among low-score examples (large RiskBottom 20%)."
        },
        {
            "heading": "5.1 PREDICTING FACTUAL CORRECTNESS",
            "text": "Predictors (f ): We propose the constraint satisfaction probe, SAT PROBE, that predicts if an individual constraint is satisfied by only looking at self-attention. To demonstrate the simplicity, we let f be a linear function of the attention weights to constraints:\nP\u0302(Vk(Y\u0302 ) = 1;ACk,T ) = \u03c3(wTACk,T + b),\nwhere ACk,T , w \u2208 RL\u00d7H , b \u2208 R, ACk,T = {\u2200\u2113 \u2208 [L], h \u2208 [H] : A\u2113,hCk,T }. We linearly probe the attention weights across all layers and attention heads and estimate w and b using Logistic Regression. In multi-constraint settings we use SAT PROBE and combine the predictions for constraints:\nP\u0302( \u220f\nk\u2208[K]\n1{Vk(Y\u0302 )=1};ACk,T ) = \u220f\nk\u2208[K]\nP\u0302(Vk(Y\u0302 ) = 1;ACk,T ).\nBaselines: We compare SAT PROBE to the CONFIDENCE of the model, P\u0302(Y\u0302 |X), which concurrent work reports as a hallucination detector (Varshney et al., 2023); and a CONSTANT predictor that predicts the majority class (either 0 or 1) as baselines. Note that while CONFIDENCE is a strong baseline, it only provides an overall estimate for the whole generation, and cannot predict the failure for individual constraints. We also use the POPULARITY baseline only in the single-constraint WikiData datasets that we curated \u2013 as in other datasets, it is not accessible (CounterFact) or unclear how to compute (multi-constraint). In the Appendix, we also give results with featurization using the attention contribution, e.g., aCk,T = {\u2200\u2113 \u2208 [L], h \u2208 [H] : ||a\u2113,hCk,T ||}, denoted by SAT PROBE(a).\n5We acknowledge that exact match is a strict criterion that could introduce noise to our evaluations, and it constitutes a limitation where we use this verification. Evaluating factual correctness is still an evolving research topic (Min et al., 2023) and we do our best to find queries and prompt structures that suffer the least from this.\n7\nUnder review as a conference paper at ICLR 2024\nFinally, when predicting constraint satisfaction, we concatenate confidence to the set of attention features to the logistic regression and denote this by COMBINED.\nResults: In Figure 6a, we present the overall AUROC of predicting factual correctness for multiconstraint queries, and Table 6 contains all metrics. In this task, we find that SAT PROBE performs comparably to the model\u2019s CONFIDENCE in the correctness prediction task, in addition to being able to provide fine-grained feedback (i.e., which constraint is not satisfied, see \u00a75.2). Figure 6b presents the AUROC results for the single-constraint setting. In the single-constraint setting, SAT PROBE is comparable to CONFIDENCE. Further, we find that the approaches are comparably good in isolating highly reliable vs unreliable points (Table 5,6 show RiskTop 20% and RiskBottom 20% metrics). CONFIDENCE alone appears to be slightly more performant than attention alone, yet attention helps us more efficiently and identify the failures in a fine-grained manner (see \u00a7 5.2). COMBINED predictor that uses both attention and confidence gets the best performance across all three metrics in most scenarios. In Figure 15, we compare the predictions made by SAT PROBE and CONFIDENCE. Notably, while they correlate, both predictors have different errors, e.g., there are cases where the LLM is overconfident yet there is almost no attention and it is a factual error, or vice-versa. This further provides insight into why the COMBINED predictor performs better overall.\nAttention alone is significantly better than the CONSTANT baseline which suggests that the signals relay a nontrivial amount of information, sometimes exceeding CONFIDENCE. Surprisingly, even though LLMs are optimized by maximizing the next token probability, probing attention patterns exclusively on the constraints can match or sometimes exceed this performance\u2014without using hidden states or non-constraint tokens. However, attention alone does not explain all failures (we observe some attention on constraints where the model still fails), there is an opportunity for further investigation. Our findings demonstrate the value of studying the procedure by which a model produces an output, rather than only the output itself."
        },
        {
            "heading": "5.2 EXTENSIONS",
            "text": "We study 3 extensions to explore the potential of SAT PROBE and propose avenues for future work. Early stopping: Using SAT PROBE, we can predict failures partway through the computation and save costs. Appendix Figures 7 shows that we can predict failures earlier in the inference with an experiment across all single-constraint datasets. Specifically, we use only attention weights up to an intermediate layer and predict failures ahead of time. For Llama-2 7B and 13B, we can stop the inference early without degradation in the average performance and save 50% of wall-clock time\n8\nUnder review as a conference paper at ICLR 2024\non failures for most datasets. In 70-B, early stopping results in a slight drop in performance. For use cases where we have a high RiskBottom 20%, we can isolate these most unreliable predictions and abstain from making a prediction. See Appendix B.4 for details on the ablation.\nPredicting partial constraint satisfaction: SAT PROBE gives access to failure predictions for individual constraints. We report the partial constraint satisfaction results in Table 7 where we report the failure prediction metrics for individual constraints and find comparable results to the single-constraint prediction task. While SAT PROBE lets us test whether each constraint is satisfied, using the raw CONFIDENCE does not since it only outputs a single value for all constraints. We believe producing fine-grained reliability statements, such as reporting partial constraint satisfaction, can prove useful for debugging (e.g., failing to follow specific instructions).\nGeneralized predictors: We explore using a single failure predictor across all constraint types. For this purpose, we train a failure predictor on a mixture of single constraint datasets and report the performance over individual datasets in Appendix B.5 and Figure 8. We observe the performance is competitive with training individual predictors for each constraint and better than POPULARITY. This suggests the potential of pursuing efforts to construct general factual error detectors."
        },
        {
            "heading": "6 RELATED WORK",
            "text": "Carlini et al. (2021; 2022); Biderman et al. (2023) related the training data frequency of a string to memorization in LLMs. In recent work, Mallen et al. (2022); Kandpal et al. (2023); Sun et al. (2023) document the relation between the success/difficulty of factual queries and a measure/proxy for training data frequency. Several recent works investigated the mechanics of factual recall. Numerous works Elhage et al. (2021); Devlin et al. (2018); Olsson et al. (2022); Clark et al. (2019); Tian et al. (2023); Htut et al. (2019); Voita et al. (2019); Burns et al. (2022); Gurnee et al. (2023) analyzed how specific attention heads exhibit certain functionalities, such as heads that encode syntax or induction heads that copy tokens. Further, Meng et al. (2022); Geva et al. (2023) discuss the role of attention in specifically transferring factual information, and Hernandez et al. (2023) studies how specific relations can be decoded with a linear transformation from the subject tokens. However, these works do not investigate the generation of factually incorrect text. Halawi et al. (2022); Belrose et al. (2023) study how LLMs internally deal with safety-critical input, such as false demonstrations for in-context learning or prompt injections. Varshney et al. (2023) detect and mitigate hallucinations using the model\u2019s CONFIDENCE. Closest in spirit, in concurrent work Li et al. (2023) seek directions that encode \u2018truthfulness\u2019 in the total attention contributions across all tokens and use these to intervene on LLMs; whereas we focus specifically on predicting factual errors, showing one can use only attention weights and look only at the constraints, contribute the analyses around fine-grained constraint satisfaction and early stopping. M\u00fcndler et al. (2023); Manakul et al. (2023); Zhang et al. (2023) interact with the LLMs in a black box fashion and aim to determine factual errors through inconsistencies, but doing so requires several forward passes and conveys conflicting signals such as refuting an initial claim, which can diminish user trust (Liao & Vaughan, 2023; Huang et al., 2020)."
        },
        {
            "heading": "7 CONCLUSION AND FUTURE WORK",
            "text": "While our analysis provides initial insights and a lens into leveraging LLM\u2019s internals to understand factual errors, it raises several exciting questions for future work. First, we studied only conjunctive factual queries, but the class of potential constraints is much broader (e.g. instructions (Ouyang et al., 2022), disjunctive queries). While this framework extends the scope of mechanistic investigations of factuality in LLMs, it is still limited in that it does not cover all possible factual queries to LLMs. It would be interesting to extend it to different domains, such as mathematical queries or reasoning. While we assume access to the constraint tokens, it is interesting to consider cases where we need to extract this information, e.g. with tools to extract named entities. Second, the content of the information in attention patterns remains opaque and warrants further investigation. Similarly, the reasons behind the correlation between attention and constraint popularity/correctness found here are still unknown. Future work could also investigate more sophisticated mechanisms to probe attention and how to perform different actions to fix errors, such as steering the model behavior through manipulating the attention to constraints. We hope that the methods and analyses of our study will help with the pursuit of reliable and safe generations from LLMs.\n9\nUnder review as a conference paper at ICLR 2024"
        },
        {
            "heading": "A MODEL DETAILS",
            "text": "We use the Llama-2 family models released in Touvron et al. (2023) through the HuggingFace Transformers library (Wolf et al., 2019). To fit Llama-2 70B in a single A100 GPU with 80GBs of memory, we use 8-bit quantization with bitsandbytes (Dettmers et al., 2022b;a). For all of the models, we sample from the model using greedy decoding and temperature 0.\nTouvron et al. (2023) reports that since key-value caches become prohibitive for larger models such as the Llama-2 70B, they use Grouped-Query Attention (GQA, (Ainslie et al., 2023)) (as opposed to Multi-Head Attention) with 8 key-value projection variant. GQA divides each query head into multiple groups, which reduces the size of the KV cache to be loaded into the memory at each inference step. However, this does not change our analyses which focus on the attention weights (A) or the attention contribution (a).\nThe MLP contribution in the Llama-2 family is computed by\nm\u2113i = W \u2113 F \u03c3(W \u2113 I (a \u2113 i + x \u2113\u22121 i )) (5)\nwhere W \u2113F \u2208 Rd\u00d7d, where W \u2113I \u2208 Rd\u00d7d. Unlike attention, the input to the MLP updates for a token only uses the representation of the same token. Since we are interested in the interaction between the generation and the constraint tokens, we explore only the attention contribution in this work. It is possible that the MLP contribution has relevant signals, and we leave this exploration to future work."
        },
        {
            "heading": "B EXPERIMENTAL RESULTS - EXPANDED",
            "text": ""
        },
        {
            "heading": "B.1 SINGLE-CONSTRAINT EXPERIMENTS",
            "text": "In the single-constraint experiments, we evaluate the methods over the datasets and constraints documented in Table 5. For each dataset, we split the dataset into two sets (train and test) and normalize each feature to zero mean and unit variance using the training split. We train a Logistic Regressor with C = 0.05 L1 regularization on one subset and evaluate the performance on the other subset. We repeat this experiment with 10 random seeds and report the mean performance and the standard error next to it in Table 5 for each dataset and method. In the Tables, SAT PROBE(A) indicates using attention weights as the input to the probe, whereas SAT PROBE(a) indicates using the attention contribution as the probe. The latter is closer in spirit to Li et al. (2023) that explores the entire attention contribution through an individual head (a\u2113,hi ) whereas we focus on contributions from only the constraint tokens. In addition, we only look at the attention weights with the former probe, which performs better than SAT PROBE(a)."
        },
        {
            "heading": "B.2 MULTI-CONSTRAINT EXPERIMENTS",
            "text": "In the multi-constraint experiments, we evaluate the methods over the datasets and constraints documented in Table 6. We follow the similar training/test split protocol as in \u00a7B.1. Additionally, when doing the train/test splits, we do not leak the same pair of constraints from the test set to the training test. Specifically, since for a pair of constraints we can have two prompts (e.g. starts with e and ends with r vs ends with r, starts with e), we split samples based on the set of constraints in the prompts. In this case, factual correctness is defined as satisfying both of the constraints in the query. We provide the results in tabular form in 6.\n14\nUnder review as a conference paper at ICLR 2024"
        },
        {
            "heading": "B.3 PREDICTING PARTIAL CONSTRAINT SATISFACTION",
            "text": "Here, we follow the same protocol as in \u00a7B.1, however, we predict constraint satisfaction for individual constraints in multi-constraint queries. Note how CONFIDENCE cannot be a baseline here \u2013 it simply produces a probability that a completion follows a prompt, and cannot make fine-grained statements about individual constraints. We believe future work could pull this thread to reason about individual instructions, factual queries with different compositions (e.g. logical operators such as OR), and beyond."
        },
        {
            "heading": "B.4 EARLY STOPPING EXPERIMENTS",
            "text": "Here, we explore whether we can predict failure ahead of time to stop the execution and save computing time. Specifically, we use the attention weights up to a layer, e.g. A[L\n\u2032],[H] C,T for L\n\u2032 < L. We repeat this experiment across multiple choices of layers with three random seeds, and report the results in Figure 7. Overall, for most datasets, there is little to no performance drop in terms of failure prediction, even if we use up to 50% less computation time. This is less of the case for Llama-2 70B, where using later self-attention layers provides more value to the performance. We believe using the model\u2019s attention patterns could potentially be used to predict failure ahead of time, potentially abstaining from making a prediction or escalating the request to potentially a larger model e.g. similar to a cascading setting (Wang et al., 2011)."
        },
        {
            "heading": "B.5 GENERALIZING THE FAILURE PREDICTOR",
            "text": "Here, we explore whether we can train a single failure predictor across multiple constraints. To do so, we create a mixture of datasets by mixing data from each of the relations. Specifically, for each of the single-constraint datasets in Table 1, we split 50% of the dataset for training, and leave 50% of the dataset for testing. We train a Logistic Regressor on the training set and quantify the performance in the test set. We perform this with 5 random seeds, where the randomness is over the train/test splits. In Figure 8 and Table 8, we present the results. In particular, when compared to training individual predictors as in Figure 6b, we observe minor performance fluctuations. We believe this suggests the potential of training general-purpose failure predictors using attention maps. We leave a detailed exploration of this angle for future work.\n15\nUnder review as a conference paper at ICLR 2024"
        },
        {
            "heading": "C DETAILS ON THE EXPLORATORY ANALYSES",
            "text": ""
        },
        {
            "heading": "C.1 PREDICTING POPULARITY",
            "text": "For the basketball players dataset, we filter the dataset for popularity values \u2265 15, since in the lower end we find that there is less meaningful signal for comparison. After this filtering, we end up with 4022 entities. We split these into two sets of equal size (training and test), and we perform Lasso regression in scikit-learn (Pedregosa et al., 2011) on the training set with 0.005 regularization strength to regress the popularity values. We then use the regressor to make predictions over the held-out set and compute the Spearman rank-order correlation coefficient computed using scipy.stats.spearmanr (Virtanen et al., 2020) and the p-value for testing the null hypothesis that there is no ordinal correlation."
        },
        {
            "heading": "C.2 COMPUTING ATTENTION TO A CONSTRAINT",
            "text": "Taking the Maximum over Constraint Tokens: Previous works report that the last subject tokens have the largest significance in terms of tracing the information (Meng et al., 2022). While we\n16\nUnder review as a conference paper at ICLR 2024\nobserve this to be generally the case, there are subtleties that arise for end-to-end evaluations. For instance, Kelly Oubre Jr., we observe very little attention to Jr. and the most attention is on Oubre. In Figure 12 we have two example prompts. Overall, due to the subtleties in tokenization and potential ambiguity in the definition of what is the core part of a constraint, we choose to take the max over all constraint tokens, instead of only looking at the last token."
        },
        {
            "heading": "D DATASETS",
            "text": ""
        },
        {
            "heading": "D.1 DATA CURATION FOR SINGLE-CONSTRAINT QUERIES",
            "text": "WikiData: For 4 groups of queries that are not from CounterFact, we probe WikiData6. For instance, for basketball players, we searched WikiData for all basketball players with at least 5 site links on the page where this criterion was done to ensure quality (entities with fewer site links did not always turn out to be professional basketball players). This criteria also avoids sampling from extremely tail knowledge, since as demonstrated in Sun et al. (2023), this can be problematic for model performance and we are seeking settings where the model can perform reasonably well, albeit not perfectly. Next, we retrieve the relevant field (e.g. in this case year of birth) of the entity. The choice of relevant fields for constraints was also guided by i) the need to avoid extreme tail knowledge, and ii) the feasibility of the Exact Match metric. For instance, the year of birth or year of founding can simply be evaluated\n6https://query.wikidata.org/sparql\n17\nUnder review as a conference paper at ICLR 2024\nby the exact match between the correct year and the year the model produces (e.g. see queries 16,17). We chose the prompting strategy such that it is well set up for the model and we can expect that the token that follows will likely contain important factual information. CounterFact (Meng et al., 2022): We picked the three relations in Table 1 from CounterFact as they were arguably the least vulnerable to the strictness of the exact match evaluation. Specifically, we found that there is less variation in terms of potential correct responses for mother tongue queries (e.g. Figure 20), citizenship queries (e.g. Figure 21), or headquarter location queries (Figure 22). This is arguably visible from the model performance in Table 5 where we see nontrivial model performance albeit we use Exact Match as our evaluation metric.\n18\nUnder review as a conference paper at ICLR 2024"
        },
        {
            "heading": "D.2 DATA CURATION FOR MULTI-CONSTRAINT QUERIES",
            "text": "We curated four multi-constraint datasets where it is relatively easy to perform constraint verification to label model completions for factual correctness. All of these datasets have at least one correct completion for each query.\nWords: For the word queries, we iterate over letters of the alphabet, and generate prompts that contain starts with and ends with constraints for all pairs of letters, resulting in 26\u00d7 26 = 676 pairs of letters in total, and upon using the permutations of constraints, we in total have 1352 prompts.\nNobel Winner: We use the Nobel Prize Winners dataset (Opendatasoft, 2023) to generate queries with at least one potentially correct completion. For each unique city of birth in this dataset (645), we generate one prompt using the template in Figure 25, asking for the name of a Nobel Prize Winner who was born in a given city. Upon using the permutations, we have a resulting set of 1290 prompts.\nMovies: We probe WikiData to collect a dataset of movies with awards, where we ask for the movie to have the director, award, and award year fields for reliability. We filter for all awards that have under 100 occurrences in WikiData and have a remaining set of 8 awards. Given the list of awards and directors, we generate queries for each of the unique (award, director) pairs, resulting in a total of 533 queries, and upon using the permutations we have a total of 1066 prompts.\nBooks: We probe WikiData to collect a dataset of authors with books. From WikiData, we scrape a collection of 746 books, with a pair of authors and years of publication. For each pair, we generate a query, and using the permutation of constraints, we end up with 1492 prompts.\nD.3 VERIFICATION\nExact Match: Even though the Exact Match criterion is fairly strict, it is still a common metric used in various evaluations of LLMs from classification to question answering(e.g. Liang et al. (2022)). Let Y be the ground truth completion, and let Y\u0302 be the model\u2019s completion, where both are sequences of tokens. We simply check whether the first |Y | tokens of the Y\u0302 sequence are the same as Y , and return V (Y\u0302 ) = 1 if that is the case. Otherwise, we return V (Y\u0302 ) = 0. To mitigate how strict the criterion is, we tried to set the prompts up such that it is more likely that the model completes in the desired format (e.g. see Figure 17 where we include \u2018the year founded in\u2019 in the question, and the assistant\u2019s response starts with \u2018The team was founded in\u2019).\nWikiData Probing: For multi-constraint queries, the evaluation is more challenging. For instance, in a query where we ask the model to return a book whose author is C1 and the book was published between C2, we would like to label whether indeed there was such a book from that author, and separately whether there was a book published in that year. To do so, we perform the following steps:\n1. First, obtain the model\u2019s response up to any new line token (\\n), if present.\n2. We use this entity to search WikiData.\n3. If there was no such entity (e.g. book), we return V1(Y\u0302 ) = 0, V2(Y\u0302 ) = 0.\n4. If we find such an entity (e.g. book), we individually go through the relevant fields. For instance, we retrieve the list of authors and the year the book was published.\n5. Once the list is retrieved, for each constraint and list, we probe the gpt-3.5-turbo API with the prompt in Fig 14 whether the item is in the list. If the items are found, we return 1.\nWe use GPT 3.5 (gpt-3.5-turbo endpoint) in the loop since Exact Match with e.g. arbitrary book names is a lot trickier than what we have in the single constraint queries (e.g. verifying the year of birth is easy with Exact Match). Since this is not a cheap step, we use this strategy only for multi-constraint queries.\nCharacter Match: For the Words dataset, the constraints are simply of the form starts with the letter or ends with the letter. This is simple to verify, as it is simply checking the first character or the last character of the first word in the completion.\n19\nUnder review as a conference paper at ICLR 2024"
        },
        {
            "heading": "E COMPARING CONFIDENCE AND ATTENTION",
            "text": "In Figure 15, we investigate whether attention and confidence behave differently when predicting factual errors. Specifically, for the Football Teams and Basketball Players datasets, we make predictions on the test sets of the datasets, and plot the predicted failure probability by the attention (yaxis), and by the confidence (x-axis). We color the bins indicating which of the models make a correct prediction (assuming a decision threshold of 0.5).\nWe observe that attention and confidence do not always agree in predicting failures. In particular, there are cases where the confidence-based predictor suggests a factual error and attention-based does not, and it is not a factual error (see left); or vice-versa.\n20\nUnder review as a conference paper at ICLR 2024\n21\nUnder review as a conference paper at ICLR 2024\n22\nUnder review as a conference paper at ICLR 2024\n23\nU nderreview as a conference paperatIC L R 2024\nModel Data Constraint Model Success RiskBottom 20%(\u21d1) RiskTop 20%(\u21d3) AUROC(\u21d1) CONFIDENCE SAT-PROBE(A) SAT-PROBE(a) CONSTANT POPULARITY COMBINED CONFIDENCE SAT-PROBE(A) SAT-PROBE(a) CONSTANT POPULARITY COMBINED CONFIDENCE SAT-PROBE(A) SAT-PROBE(a) CONSTANT POPULARITY COMBINED 7B Basketball Players born in the year 0.18 0.96\u00b1 0.00 0.95\u00b1 0.00 0.95\u00b1 0.00 0.82\u00b1 0.00 0.92\u00b1 0.00 0.96\u00b1 0.00 0.46\u00b1 0.00 0.47\u00b1 0.00 0.47\u00b1 0.00 0.82\u00b1 0.00 0.56\u00b1 0.00 0.46\u00b1 0.00 0.82\u00b1 0.00 0.81\u00b1 0.00 0.81\u00b1 0.00 0.50\u00b1 0.00 0.74\u00b1 0.00 0.82\u00b1 0.00 7B CounterFact - Cit Citizenship 0.63 0.45\u00b1 0.01 0.66\u00b1 0.02 0.74\u00b1 0.01 0.38\u00b1 0.01 0.38\u00b1 0.01 0.71\u00b1 0.01 0.29\u00b1 0.01 0.19\u00b1 0.01 0.14\u00b1 0.01 0.38\u00b1 0.01 0.38\u00b1 0.01 0.15\u00b1 0.01 0.51\u00b1 0.01 0.71\u00b1 0.01 0.76\u00b1 0.01 0.50\u00b1 0.00 0.50\u00b1 0.00 0.76\u00b1 0.01 7B CounterFact - HQ Headquarter Location 0.61 0.75\u00b1 0.01 0.81\u00b1 0.01 0.83\u00b1 0.01 0.38\u00b1 0.02 0.38\u00b1 0.02 0.87\u00b1 0.01 0.09\u00b1 0.01 0.20\u00b1 0.01 0.19\u00b1 0.00 0.38\u00b1 0.02 0.38\u00b1 0.02 0.08\u00b1 0.01 0.77\u00b1 0.01 0.75\u00b1 0.01 0.76\u00b1 0.01 0.50\u00b1 0.00 0.50\u00b1 0.00 0.84\u00b1 0.00 7B CounterFact - MT Mother Tongue 0.48 0.98\u00b1 0.00 1.00\u00b1 0.00 1.00\u00b1 0.00 0.51\u00b1 0.02 0.51\u00b1 0.02 0.99\u00b1 0.00 0.08\u00b1 0.01 0.03\u00b1 0.00 0.03\u00b1 0.01 0.51\u00b1 0.02 0.51\u00b1 0.02 0.02\u00b1 0.00 0.89\u00b1 0.00 0.98\u00b1 0.00 0.98\u00b1 0.00 0.50\u00b1 0.00 0.50\u00b1 0.00 0.98\u00b1 0.00 7B Football Teams founded in the year 0.13 0.97\u00b1 0.00 0.96\u00b1 0.00 0.97\u00b1 0.00 0.88\u00b1 0.00 0.94\u00b1 0.00 0.97\u00b1 0.00 0.60\u00b1 0.00 0.63\u00b1 0.00 0.61\u00b1 0.00 0.88\u00b1 0.00 0.67\u00b1 0.00 0.58\u00b1 0.00 0.81\u00b1 0.00 0.79\u00b1 0.00 0.81\u00b1 0.00 0.50\u00b1 0.00 0.74\u00b1 0.00 0.83\u00b1 0.00 7B Movies directed by 0.58 0.97\u00b1 0.00 0.87\u00b1 0.00 0.88\u00b1 0.00 0.42\u00b1 0.00 0.62\u00b1 0.00 0.96\u00b1 0.00 0.04\u00b1 0.00 0.15\u00b1 0.00 0.14\u00b1 0.00 0.42\u00b1 0.00 0.19\u00b1 0.00 0.05\u00b1 0.00 0.90\u00b1 0.00 0.80\u00b1 0.00 0.81\u00b1 0.00 0.50\u00b1 0.00 0.69\u00b1 0.00 0.90\u00b1 0.00 7B Songs performed by 0.22 1.00\u00b1 0.00 1.00\u00b1 0.00 1.00\u00b1 0.00 0.77\u00b1 0.01 0.93\u00b1 0.00 1.00\u00b1 0.00 0.27\u00b1 0.00 0.38\u00b1 0.00 0.38\u00b1 0.00 0.77\u00b1 0.01 0.53\u00b1 0.00 0.27\u00b1 0.01 0.93\u00b1 0.00 0.88\u00b1 0.00 0.88\u00b1 0.00 0.50\u00b1 0.00 0.74\u00b1 0.00 0.93\u00b1 0.00 13B Basketball Players born in the year 0.22 0.95\u00b1 0.00 0.95\u00b1 0.00 0.95\u00b1 0.00 0.78\u00b1 0.00 0.91\u00b1 0.00 0.95\u00b1 0.00 0.28\u00b1 0.00 0.32\u00b1 0.00 0.32\u00b1 0.00 0.78\u00b1 0.00 0.43\u00b1 0.00 0.31\u00b1 0.00 0.86\u00b1 0.00 0.85\u00b1 0.00 0.85\u00b1 0.00 0.50\u00b1 0.00 0.77\u00b1 0.00 0.86\u00b1 0.00 13B CounterFact - Cit Citizenship 0.60 0.57\u00b1 0.01 0.69\u00b1 0.01 0.74\u00b1 0.01 0.41\u00b1 0.01 0.41\u00b1 0.01 0.74\u00b1 0.01 0.23\u00b1 0.01 0.15\u00b1 0.01 0.13\u00b1 0.01 0.41\u00b1 0.01 0.41\u00b1 0.01 0.14\u00b1 0.01 0.58\u00b1 0.00 0.72\u00b1 0.01 0.75\u00b1 0.00 0.50\u00b1 0.00 0.50\u00b1 0.00 0.76\u00b1 0.01 13B CounterFact - HQ Headquarter Location 0.64 0.67\u00b1 0.01 0.68\u00b1 0.01 0.70\u00b1 0.01 0.33\u00b1 0.02 0.33\u00b1 0.02 0.82\u00b1 0.01 0.08\u00b1 0.01 0.23\u00b1 0.01 0.19\u00b1 0.01 0.33\u00b1 0.02 0.33\u00b1 0.02 0.08\u00b1 0.01 0.77\u00b1 0.00 0.70\u00b1 0.01 0.72\u00b1 0.01 0.50\u00b1 0.00 0.50\u00b1 0.00 0.82\u00b1 0.01 13B CounterFact - MT Mother Tongue 0.46 0.91\u00b1 0.01 0.99\u00b1 0.00 0.99\u00b1 0.00 0.53\u00b1 0.01 0.53\u00b1 0.01 0.98\u00b1 0.00 0.13\u00b1 0.01 0.08\u00b1 0.01 0.07\u00b1 0.01 0.53\u00b1 0.01 0.53\u00b1 0.01 0.06\u00b1 0.00 0.80\u00b1 0.00 0.96\u00b1 0.00 0.96\u00b1 0.00 0.50\u00b1 0.00 0.50\u00b1 0.00 0.96\u00b1 0.00 13B Football Teams founded in the year 0.18 0.97\u00b1 0.00 0.96\u00b1 0.00 0.96\u00b1 0.00 0.81\u00b1 0.00 0.94\u00b1 0.00 0.97\u00b1 0.00 0.47\u00b1 0.00 0.48\u00b1 0.00 0.49\u00b1 0.00 0.81\u00b1 0.00 0.51\u00b1 0.01 0.44\u00b1 0.00 0.83\u00b1 0.00 0.81\u00b1 0.00 0.81\u00b1 0.00 0.50\u00b1 0.00 0.77\u00b1 0.00 0.83\u00b1 0.00 13B Movies directed by 0.71 0.83\u00b1 0.00 0.70\u00b1 0.00 0.70\u00b1 0.00 0.29\u00b1 0.00 0.45\u00b1 0.00 0.83\u00b1 0.00 0.04\u00b1 0.00 0.09\u00b1 0.00 0.09\u00b1 0.00 0.29\u00b1 0.00 0.13\u00b1 0.00 0.04\u00b1 0.00 0.87\u00b1 0.00 0.79\u00b1 0.00 0.79\u00b1 0.00 0.50\u00b1 0.00 0.67\u00b1 0.00 0.88\u00b1 0.00 13B Songs performed by 0.24 1.00\u00b1 0.00 1.00\u00b1 0.00 1.00\u00b1 0.00 0.76\u00b1 0.01 0.89\u00b1 0.00 1.00\u00b1 0.00 0.23\u00b1 0.01 0.35\u00b1 0.00 0.35\u00b1 0.01 0.76\u00b1 0.01 0.52\u00b1 0.00 0.25\u00b1 0.01 0.93\u00b1 0.00 0.88\u00b1 0.00 0.88\u00b1 0.00 0.50\u00b1 0.00 0.71\u00b1 0.00 0.92\u00b1 0.00 70B Basketball Players born in the year 0.66 0.88\u00b1 0.00 0.73\u00b1 0.00 0.73\u00b1 0.00 0.34\u00b1 0.00 0.59\u00b1 0.00 0.88\u00b1 0.00 0.01\u00b1 0.00 0.06\u00b1 0.00 0.07\u00b1 0.00 0.34\u00b1 0.00 0.07\u00b1 0.00 0.01\u00b1 0.00 0.91\u00b1 0.00 0.81\u00b1 0.00 0.81\u00b1 0.00 0.50\u00b1 0.00 0.74\u00b1 0.00 0.91\u00b1 0.00 70B CounterFact - Cit Citizenship 0.69 0.47\u00b1 0.01 0.69\u00b1 0.01 0.70\u00b1 0.01 0.32\u00b1 0.01 0.32\u00b1 0.01 0.58\u00b1 0.02 0.16\u00b1 0.01 0.10\u00b1 0.01 0.10\u00b1 0.01 0.32\u00b1 0.01 0.32\u00b1 0.01 0.16\u00b1 0.01 0.58\u00b1 0.00 0.78\u00b1 0.01 0.78\u00b1 0.01 0.50\u00b1 0.00 0.50\u00b1 0.00 0.70\u00b1 0.01 70B CounterFact - HQ Headquarter Location 0.66 0.61\u00b1 0.01 0.69\u00b1 0.01 0.66\u00b1 0.01 0.31\u00b1 0.02 0.31\u00b1 0.02 0.69\u00b1 0.01 0.04\u00b1 0.01 0.13\u00b1 0.01 0.14\u00b1 0.02 0.31\u00b1 0.02 0.31\u00b1 0.02 0.06\u00b1 0.01 0.74\u00b1 0.00 0.74\u00b1 0.01 0.73\u00b1 0.01 0.50\u00b1 0.00 0.50\u00b1 0.00 0.77\u00b1 0.01 70B CounterFact - MT Mother Tongue 0.46 0.94\u00b1 0.00 1.00\u00b1 0.00 1.00\u00b1 0.00 0.54\u00b1 0.01 0.54\u00b1 0.01 1.00\u00b1 0.00 0.13\u00b1 0.01 0.03\u00b1 0.00 0.02\u00b1 0.01 0.54\u00b1 0.01 0.54\u00b1 0.01 0.04\u00b1 0.01 0.82\u00b1 0.00 0.98\u00b1 0.00 0.97\u00b1 0.00 0.50\u00b1 0.00 0.50\u00b1 0.00 0.97\u00b1 0.00 70B Football Teams founded in the year 0.38 0.95\u00b1 0.00 0.91\u00b1 0.00 0.90\u00b1 0.00 0.62\u00b1 0.01 0.86\u00b1 0.00 0.95\u00b1 0.00 0.24\u00b1 0.00 0.28\u00b1 0.00 0.28\u00b1 0.01 0.62\u00b1 0.01 0.27\u00b1 0.00 0.18\u00b1 0.00 0.83\u00b1 0.00 0.77\u00b1 0.00 0.77\u00b1 0.00 0.50\u00b1 0.00 0.76\u00b1 0.00 0.85\u00b1 0.00 70B Movies directed by 0.86 0.34\u00b1 0.00 0.34\u00b1 0.00 0.34\u00b1 0.00 0.14\u00b1 0.00 0.17\u00b1 0.00 0.39\u00b1 0.00 0.04\u00b1 0.00 0.05\u00b1 0.00 0.03\u00b1 0.00 0.14\u00b1 0.00 0.10\u00b1 0.00 0.03\u00b1 0.00 0.75\u00b1 0.00 0.73\u00b1 0.00 0.75\u00b1 0.00 0.50\u00b1 0.00 0.55\u00b1 0.00 0.80\u00b1 0.00 70B Songs performed by 0.44 0.97\u00b1 0.00 0.89\u00b1 0.01 0.89\u00b1 0.01 0.56\u00b1 0.01 0.71\u00b1 0.01 0.96\u00b1 0.00 0.17\u00b1 0.00 0.20\u00b1 0.01 0.18\u00b1 0.01 0.56\u00b1 0.01 0.35\u00b1 0.01 0.15\u00b1 0.01 0.85\u00b1 0.00 0.79\u00b1 0.00 0.80\u00b1 0.00 0.50\u00b1 0.00 0.65\u00b1 0.00 0.85\u00b1 0.00\nTable 5: Predicting factual errors for single-constraint queries (\u21d1) indicates higher is better, and (\u21d3) indicates lower is better. We repeat the experiments with 10 random seeds where the randomness is over the train and test splits. We do not have the popularity numbers for the CounterFact dataset. Standard means \u00b1 standard errors across 10 random seeds are reported in each cell.\nModel Data Constraint Model Success RiskBottom 20%(\u21d1) RiskTop 20%(\u21d3) AUROC(\u21d1) SAT-PROBE(a) SAT-PROBE(A) CONFIDENCE CONSTANT COMBINED SAT-PROBE(a) SAT-PROBE(A) CONFIDENCE CONSTANT COMBINED SAT-PROBE(a) SAT-PROBE(A) CONFIDENCE CONSTANT COMBINED\n7B Books Overall 0.13 0.99\u00b1 0.00 0.99\u00b1 0.00 1.00\u00b1 0.00 0.91\u00b1 0.01 1.00\u00b1 0.00 0.74\u00b1 0.01 0.77\u00b1 0.01 0.80\u00b1 0.01 0.91\u00b1 0.01 0.78\u00b1 0.01 0.78\u00b1 0.01 0.77\u00b1 0.01 0.73\u00b1 0.01 0.50\u00b1 0.00 0.82\u00b1 0.01 7B Movies Overall 0.17 0.99\u00b1 0.00 0.99\u00b1 0.00 1.00\u00b1 0.00 0.83\u00b1 0.01 0.99\u00b1 0.00 0.52\u00b1 0.01 0.51\u00b1 0.01 0.39\u00b1 0.02 0.83\u00b1 0.01 0.51\u00b1 0.02 0.84\u00b1 0.00 0.85\u00b1 0.00 0.93\u00b1 0.00 0.50\u00b1 0.00 0.90\u00b1 0.01 7B Nobel Winner Overall 0.12 0.97\u00b1 0.00 0.98\u00b1 0.00 0.98\u00b1 0.00 0.95\u00b1 0.01 0.98\u00b1 0.00 0.91\u00b1 0.01 0.90\u00b1 0.01 0.88\u00b1 0.01 0.95\u00b1 0.01 0.85\u00b1 0.01 0.61\u00b1 0.01 0.66\u00b1 0.01 0.65\u00b1 0.02 0.50\u00b1 0.00 0.78\u00b1 0.01 7B Words Overall 0.29 0.85\u00b1 0.01 0.90\u00b1 0.01 0.84\u00b1 0.01 0.79\u00b1 0.01 0.90\u00b1 0.01 0.71\u00b1 0.01 0.69\u00b1 0.01 0.70\u00b1 0.01 0.79\u00b1 0.01 0.65\u00b1 0.01 0.58\u00b1 0.01 0.63\u00b1 0.00 0.59\u00b1 0.01 0.50\u00b1 0.00 0.69\u00b1 0.01 13B Books Overall 0.09 0.99\u00b1 0.00 1.00\u00b1 0.00 1.00\u00b1 0.00 0.91\u00b1 0.01 1.00\u00b1 0.00 0.83\u00b1 0.01 0.80\u00b1 0.01 0.80\u00b1 0.01 0.91\u00b1 0.01 0.80\u00b1 0.01 0.76\u00b1 0.00 0.82\u00b1 0.00 0.83\u00b1 0.00 0.50\u00b1 0.00 0.87\u00b1 0.00 13B Movies Overall 0.41 0.93\u00b1 0.01 0.93\u00b1 0.01 1.00\u00b1 0.00 0.62\u00b1 0.01 0.93\u00b1 0.01 0.22\u00b1 0.02 0.19\u00b1 0.02 0.24\u00b1 0.01 0.62\u00b1 0.01 0.19\u00b1 0.02 0.82\u00b1 0.01 0.82\u00b1 0.01 0.86\u00b1 0.01 0.50\u00b1 0.00 0.87\u00b1 0.01 13B Nobel Winner Overall 0.13 0.98\u00b1 0.00 0.97\u00b1 0.00 0.99\u00b1 0.00 0.94\u00b1 0.01 0.98\u00b1 0.00 0.87\u00b1 0.00 0.86\u00b1 0.01 0.84\u00b1 0.01 0.94\u00b1 0.01 0.84\u00b1 0.00 0.66\u00b1 0.02 0.68\u00b1 0.01 0.74\u00b1 0.01 0.50\u00b1 0.00 0.74\u00b1 0.01 13B Words Overall 0.32 0.86\u00b1 0.01 0.87\u00b1 0.01 0.82\u00b1 0.01 0.80\u00b1 0.02 0.87\u00b1 0.01 0.61\u00b1 0.01 0.61\u00b1 0.01 0.69\u00b1 0.01 0.80\u00b1 0.02 0.60\u00b1 0.01 0.63\u00b1 0.01 0.63\u00b1 0.01 0.57\u00b1 0.01 0.50\u00b1 0.00 0.69\u00b1 0.01 70B Books Overall 0.17 0.98\u00b1 0.00 0.99\u00b1 0.00 0.97\u00b1 0.00 0.87\u00b1 0.00 0.98\u00b1 0.01 0.58\u00b1 0.01 0.55\u00b1 0.01 0.65\u00b1 0.01 0.87\u00b1 0.00 0.58\u00b1 0.01 0.81\u00b1 0.01 0.84\u00b1 0.01 0.76\u00b1 0.01 0.50\u00b1 0.00 0.86\u00b1 0.01 70B Movies Overall 0.49 0.94\u00b1 0.01 0.95\u00b1 0.01 0.90\u00b1 0.01 0.54\u00b1 0.01 0.95\u00b1 0.01 0.10\u00b1 0.01 0.11\u00b1 0.01 0.11\u00b1 0.01 0.54\u00b1 0.01 0.10\u00b1 0.01 0.86\u00b1 0.00 0.86\u00b1 0.00 0.85\u00b1 0.00 0.50\u00b1 0.00 0.90\u00b1 0.00 70B Nobel Winner Overall 0.21 0.93\u00b1 0.01 0.94\u00b1 0.01 0.94\u00b1 0.00 0.84\u00b1 0.01 0.93\u00b1 0.01 0.67\u00b1 0.01 0.67\u00b1 0.01 0.63\u00b1 0.01 0.84\u00b1 0.01 0.69\u00b1 0.01 0.70\u00b1 0.01 0.71\u00b1 0.01 0.75\u00b1 0.01 0.50\u00b1 0.00 0.73\u00b1 0.01 70B Words Overall 0.36 0.91\u00b1 0.01 0.91\u00b1 0.01 0.87\u00b1 0.01 0.85\u00b1 0.01 0.90\u00b1 0.01 0.38\u00b1 0.01 0.37\u00b1 0.01 0.53\u00b1 0.01 0.85\u00b1 0.01 0.40\u00b1 0.01 0.76\u00b1 0.01 0.77\u00b1 0.00 0.66\u00b1 0.01 0.50\u00b1 0.00 0.80\u00b1 0.00\nTable 6: Predicting factual errors for multi-constraint queries (\u21d1) indicates higher is better, and (\u21d3) indicates lower is better. We repeat the experiments with 10 random seeds where the randomness is over the train and test splits. Standard means \u00b1 standard errors across 10 random seeds are reported in each cell.\n24\nModel Data Constraint Model Success RiskBottom 20%(\u21d1) RiskTop 20%(\u21d3) AUROC(\u21d1) SAT-PROBE(a) SAT-PROBE(A) CONSTANT SAT-PROBE(a) SAT-PROBE(A) CONSTANT SAT-PROBE(a) SAT-PROBE(A) CONSTANT\n7B Books author 0.38 0.95\u00b1 0.01 0.97\u00b1 0.01 0.61\u00b1 0.01 0.16\u00b1 0.01 0.25\u00b1 0.01 0.61\u00b1 0.01 0.85\u00b1 0.00 0.84\u00b1 0.00 0.50\u00b1 0.00 7B Books published year 0.11 0.97\u00b1 0.00 0.98\u00b1 0.00 0.90\u00b1 0.01 0.81\u00b1 0.01 0.79\u00b1 0.01 0.90\u00b1 0.01 0.68\u00b1 0.01 0.71\u00b1 0.01 0.50\u00b1 0.00 7B Movies directed by 0.19 0.98\u00b1 0.00 0.99\u00b1 0.00 0.80\u00b1 0.01 0.52\u00b1 0.01 0.49\u00b1 0.01 0.80\u00b1 0.01 0.82\u00b1 0.00 0.83\u00b1 0.01 0.50\u00b1 0.00 7B Movies won award 0.17 0.98\u00b1 0.00 0.98\u00b1 0.00 0.83\u00b1 0.01 0.53\u00b1 0.01 0.54\u00b1 0.02 0.83\u00b1 0.01 0.82\u00b1 0.01 0.83\u00b1 0.01 0.50\u00b1 0.00 7B Nobel Winner born in city 0.06 0.95\u00b1 0.01 0.97\u00b1 0.01 0.94\u00b1 0.01 0.91\u00b1 0.01 0.86\u00b1 0.01 0.94\u00b1 0.01 0.57\u00b1 0.01 0.68\u00b1 0.01 0.50\u00b1 0.00 7B Nobel Winner won Nobel 0.62 0.58\u00b1 0.01 0.66\u00b1 0.01 0.42\u00b1 0.01 0.21\u00b1 0.02 0.14\u00b1 0.01 0.42\u00b1 0.01 0.65\u00b1 0.01 0.72\u00b1 0.01 0.50\u00b1 0.00 7B Words ends with 0.23 0.84\u00b1 0.01 0.90\u00b1 0.01 0.77\u00b1 0.01 0.70\u00b1 0.01 0.69\u00b1 0.01 0.77\u00b1 0.01 0.58\u00b1 0.01 0.62\u00b1 0.01 0.50\u00b1 0.00 7B Words starts with 0.93 0.22\u00b1 0.01 0.27\u00b1 0.01 0.12\u00b1 0.01 0.01\u00b1 0.00 0.01\u00b1 0.00 0.12\u00b1 0.01 0.81\u00b1 0.01 0.85\u00b1 0.01 0.50\u00b1 0.00 13B Books author 0.25 0.96\u00b1 0.00 0.98\u00b1 0.01 0.71\u00b1 0.01 0.49\u00b1 0.01 0.33\u00b1 0.02 0.71\u00b1 0.01 0.77\u00b1 0.00 0.87\u00b1 0.01 0.50\u00b1 0.00 13B Books published year 0.08 0.98\u00b1 0.00 0.99\u00b1 0.00 0.91\u00b1 0.01 0.85\u00b1 0.01 0.86\u00b1 0.01 0.91\u00b1 0.01 0.68\u00b1 0.01 0.70\u00b1 0.01 0.50\u00b1 0.00 13B Movies directed by 0.45 0.90\u00b1 0.01 0.91\u00b1 0.01 0.56\u00b1 0.01 0.19\u00b1 0.01 0.17\u00b1 0.01 0.56\u00b1 0.01 0.81\u00b1 0.01 0.81\u00b1 0.00 0.50\u00b1 0.00 13B Movies won award 0.43 0.87\u00b1 0.01 0.86\u00b1 0.01 0.60\u00b1 0.01 0.20\u00b1 0.02 0.20\u00b1 0.01 0.60\u00b1 0.01 0.79\u00b1 0.01 0.79\u00b1 0.01 0.50\u00b1 0.00 13B Nobel Winner born in city 0.08 0.96\u00b1 0.02 0.96\u00b1 0.01 0.94\u00b1 0.01 0.86\u00b1 0.01 0.86\u00b1 0.01 0.94\u00b1 0.01 0.67\u00b1 0.03 0.66\u00b1 0.02 0.50\u00b1 0.00 13B Nobel Winner won Nobel 0.64 0.73\u00b1 0.01 0.72\u00b1 0.01 0.44\u00b1 0.01 0.14\u00b1 0.01 0.11\u00b1 0.01 0.44\u00b1 0.01 0.75\u00b1 0.01 0.77\u00b1 0.00 0.50\u00b1 0.00 13B Words ends with 0.27 0.83\u00b1 0.01 0.83\u00b1 0.01 0.79\u00b1 0.02 0.63\u00b1 0.01 0.61\u00b1 0.01 0.79\u00b1 0.02 0.61\u00b1 0.01 0.61\u00b1 0.01 0.50\u00b1 0.00 13B Words starts with 0.89 0.45\u00b1 0.01 0.44\u00b1 0.02 0.19\u00b1 0.01 0.01\u00b1 0.00 0.01\u00b1 0.00 0.19\u00b1 0.01 0.92\u00b1 0.00 0.93\u00b1 0.01 0.50\u00b1 0.00 70B Books author 0.32 0.95\u00b1 0.01 0.96\u00b1 0.01 0.73\u00b1 0.01 0.25\u00b1 0.01 0.24\u00b1 0.01 0.73\u00b1 0.01 0.82\u00b1 0.01 0.85\u00b1 0.01 0.50\u00b1 0.00 70B Books published year 0.16 0.98\u00b1 0.00 0.98\u00b1 0.00 0.87\u00b1 0.01 0.61\u00b1 0.01 0.56\u00b1 0.01 0.87\u00b1 0.01 0.78\u00b1 0.01 0.82\u00b1 0.01 0.50\u00b1 0.00 70B Movies directed by 0.53 0.89\u00b1 0.01 0.91\u00b1 0.01 0.49\u00b1 0.01 0.08\u00b1 0.01 0.09\u00b1 0.01 0.49\u00b1 0.01 0.85\u00b1 0.00 0.85\u00b1 0.00 0.50\u00b1 0.00 70B Movies won award 0.49 0.93\u00b1 0.01 0.94\u00b1 0.01 0.53\u00b1 0.01 0.10\u00b1 0.01 0.12\u00b1 0.01 0.53\u00b1 0.01 0.85\u00b1 0.00 0.85\u00b1 0.00 0.50\u00b1 0.00 70B Nobel Winner born in city 0.16 0.94\u00b1 0.00 0.95\u00b1 0.01 0.83\u00b1 0.01 0.66\u00b1 0.01 0.66\u00b1 0.01 0.83\u00b1 0.01 0.71\u00b1 0.01 0.72\u00b1 0.01 0.50\u00b1 0.00 70B Nobel Winner won Nobel 0.74 0.38\u00b1 0.01 0.38\u00b1 0.02 0.28\u00b1 0.01 0.18\u00b1 0.01 0.18\u00b1 0.01 0.28\u00b1 0.01 0.61\u00b1 0.01 0.60\u00b1 0.01 0.50\u00b1 0.00 70B Words ends with 0.32 0.88\u00b1 0.01 0.90\u00b1 0.01 0.82\u00b1 0.01 0.38\u00b1 0.01 0.37\u00b1 0.01 0.82\u00b1 0.01 0.73\u00b1 0.01 0.75\u00b1 0.01 0.50\u00b1 0.00 70B Words starts with 0.85 0.45\u00b1 0.01 0.47\u00b1 0.01 0.28\u00b1 0.01 0.01\u00b1 0.00 0.00\u00b1 0.00 0.28\u00b1 0.01 0.87\u00b1 0.00 0.88\u00b1 0.00 0.50\u00b1 0.00\n25\nModel Data Constraint Model Success RiskBottom 20%(\u21d1) RiskTop 20%(\u21d3) AUROC(\u21d1) CONFIDENCE SAT-PROBE(A) SAT-PROBE(a) CONSTANT POPULARITY CONFIDENCE SAT-PROBE(A) SAT-PROBE(a) CONSTANT POPULARITY CONFIDENCE SAT-PROBE(A) SAT-PROBE(a) CONSTANT POPULARITY 7B Basketball Players born in the year 0.18 0.96\u00b1 0.00 0.95\u00b1 0.00 0.94\u00b1 0.00 0.83\u00b1 0.00 0.92\u00b1 0.00 0.46\u00b1 0.01 0.47\u00b1 0.01 0.47\u00b1 0.00 0.83\u00b1 0.00 0.56\u00b1 0.00 0.82\u00b1 0.00 0.80\u00b1 0.00 0.80\u00b1 0.00 0.50\u00b1 0.00 0.74\u00b1 0.00 7B CounterFact Citizenship 0.63 0.45\u00b1 0.01 0.65\u00b1 0.01 0.61\u00b1 0.02 0.38\u00b1 0.02 - 0.29\u00b1 0.02 0.24\u00b1 0.02 0.23\u00b1 0.03 0.38\u00b1 0.02 - 0.51\u00b1 0.01 0.68\u00b1 0.01 0.67\u00b1 0.01 0.50\u00b1 0.00 - 7B CounterFact Headquarter Location 0.61 0.75\u00b1 0.01 0.72\u00b1 0.01 0.71\u00b1 0.02 0.39\u00b1 0.03 - 0.11\u00b1 0.01 0.22\u00b1 0.01 0.23\u00b1 0.02 0.39\u00b1 0.03 - 0.76\u00b1 0.00 0.72\u00b1 0.01 0.71\u00b1 0.01 0.50\u00b1 0.00 - 7B CounterFact Mother Tongue 0.48 0.98\u00b1 0.00 1.00\u00b1 0.00 0.99\u00b1 0.00 0.51\u00b1 0.03 - 0.08\u00b1 0.01 0.03\u00b1 0.01 0.02\u00b1 0.00 0.51\u00b1 0.03 - 0.89\u00b1 0.01 0.98\u00b1 0.00 0.97\u00b1 0.00 0.50\u00b1 0.00 - 7B Football Teams founded in the year 0.13 0.97\u00b1 0.00 0.97\u00b1 0.00 0.97\u00b1 0.00 0.87\u00b1 0.00 0.94\u00b1 0.00 0.60\u00b1 0.00 0.62\u00b1 0.00 0.63\u00b1 0.00 0.87\u00b1 0.00 0.66\u00b1 0.01 0.81\u00b1 0.00 0.79\u00b1 0.00 0.80\u00b1 0.00 0.50\u00b1 0.00 0.74\u00b1 0.00 7B Movies directed by 0.58 0.97\u00b1 0.00 0.86\u00b1 0.00 0.85\u00b1 0.00 0.42\u00b1 0.01 0.62\u00b1 0.00 0.04\u00b1 0.00 0.16\u00b1 0.00 0.16\u00b1 0.01 0.42\u00b1 0.01 0.19\u00b1 0.00 0.90\u00b1 0.00 0.79\u00b1 0.00 0.79\u00b1 0.00 0.50\u00b1 0.00 0.69\u00b1 0.00 7B Songs performed by 0.22 1.00\u00b1 0.00 0.99\u00b1 0.00 0.99\u00b1 0.00 0.77\u00b1 0.01 0.93\u00b1 0.01 0.28\u00b1 0.00 0.39\u00b1 0.00 0.40\u00b1 0.01 0.77\u00b1 0.01 0.53\u00b1 0.00 0.93\u00b1 0.00 0.86\u00b1 0.00 0.86\u00b1 0.00 0.50\u00b1 0.00 0.74\u00b1 0.00\n13B Basketball Players born in the year 0.22 0.95\u00b1 0.00 0.93\u00b1 0.00 0.93\u00b1 0.00 0.78\u00b1 0.00 0.91\u00b1 0.00 0.29\u00b1 0.00 0.33\u00b1 0.00 0.34\u00b1 0.00 0.78\u00b1 0.00 0.43\u00b1 0.01 0.86\u00b1 0.00 0.84\u00b1 0.00 0.83\u00b1 0.00 0.50\u00b1 0.00 0.76\u00b1 0.00 13B CounterFact Citizenship 0.60 0.58\u00b1 0.01 0.60\u00b1 0.02 0.61\u00b1 0.01 0.43\u00b1 0.02 - 0.22\u00b1 0.01 0.24\u00b1 0.02 0.25\u00b1 0.02 0.43\u00b1 0.02 - 0.58\u00b1 0.01 0.66\u00b1 0.02 0.66\u00b1 0.01 0.50\u00b1 0.00 - 13B CounterFact Headquarter Location 0.64 0.68\u00b1 0.01 0.56\u00b1 0.01 0.53\u00b1 0.02 0.32\u00b1 0.04 - 0.09\u00b1 0.01 0.19\u00b1 0.01 0.21\u00b1 0.02 0.32\u00b1 0.04 - 0.77\u00b1 0.01 0.66\u00b1 0.01 0.64\u00b1 0.01 0.50\u00b1 0.00 - 13B CounterFact Mother Tongue 0.46 0.90\u00b1 0.01 0.99\u00b1 0.00 0.97\u00b1 0.00 0.53\u00b1 0.02 - 0.14\u00b1 0.01 0.06\u00b1 0.01 0.07\u00b1 0.01 0.53\u00b1 0.02 - 0.80\u00b1 0.00 0.95\u00b1 0.00 0.95\u00b1 0.00 0.50\u00b1 0.00 - 13B Football Teams founded in the year 0.18 0.97\u00b1 0.00 0.95\u00b1 0.00 0.95\u00b1 0.00 0.82\u00b1 0.00 0.94\u00b1 0.00 0.47\u00b1 0.00 0.52\u00b1 0.00 0.52\u00b1 0.00 0.82\u00b1 0.00 0.52\u00b1 0.01 0.83\u00b1 0.00 0.79\u00b1 0.00 0.78\u00b1 0.00 0.50\u00b1 0.00 0.77\u00b1 0.01 13B Movies directed by 0.71 0.83\u00b1 0.00 0.66\u00b1 0.00 0.66\u00b1 0.00 0.30\u00b1 0.00 0.45\u00b1 0.00 0.04\u00b1 0.00 0.10\u00b1 0.00 0.11\u00b1 0.00 0.30\u00b1 0.00 0.12\u00b1 0.00 0.87\u00b1 0.00 0.76\u00b1 0.00 0.76\u00b1 0.00 0.50\u00b1 0.00 0.67\u00b1 0.00 13B Songs performed by 0.24 1.00\u00b1 0.00 0.97\u00b1 0.00 0.98\u00b1 0.00 0.75\u00b1 0.01 0.89\u00b1 0.01 0.24\u00b1 0.01 0.40\u00b1 0.01 0.39\u00b1 0.01 0.75\u00b1 0.01 0.52\u00b1 0.00 0.93\u00b1 0.00 0.83\u00b1 0.00 0.84\u00b1 0.00 0.50\u00b1 0.00 0.71\u00b1 0.00 70B Basketball Players born in the year 0.66 0.87\u00b1 0.00 0.62\u00b1 0.00 0.58\u00b1 0.01 0.34\u00b1 0.00 0.58\u00b1 0.00 0.01\u00b1 0.00 0.09\u00b1 0.00 0.09\u00b1 0.00 0.34\u00b1 0.00 0.07\u00b1 0.00 0.91\u00b1 0.00 0.76\u00b1 0.00 0.73\u00b1 0.00 0.50\u00b1 0.00 0.74\u00b1 0.00 70B CounterFact Citizenship 0.69 0.48\u00b1 0.01 0.60\u00b1 0.02 0.56\u00b1 0.02 0.32\u00b1 0.02 - 0.16\u00b1 0.01 0.15\u00b1 0.01 0.16\u00b1 0.01 0.32\u00b1 0.02 - 0.58\u00b1 0.01 0.71\u00b1 0.01 0.70\u00b1 0.01 0.50\u00b1 0.00 - 70B CounterFact Headquarter Location 0.66 0.61\u00b1 0.02 0.55\u00b1 0.01 0.55\u00b1 0.02 0.30\u00b1 0.04 - 0.04\u00b1 0.01 0.18\u00b1 0.02 0.23\u00b1 0.02 0.30\u00b1 0.04 - 0.74\u00b1 0.01 0.66\u00b1 0.01 0.65\u00b1 0.02 0.50\u00b1 0.00 - 70B CounterFact Mother Tongue 0.46 0.95\u00b1 0.01 1.00\u00b1 0.00 1.00\u00b1 0.00 0.53\u00b1 0.03 - 0.13\u00b1 0.01 0.06\u00b1 0.02 0.08\u00b1 0.01 0.53\u00b1 0.03 - 0.82\u00b1 0.00 0.96\u00b1 0.00 0.95\u00b1 0.00 0.50\u00b1 0.00 - 70B Football Teams founded in the year 0.38 0.95\u00b1 0.00 0.84\u00b1 0.00 0.80\u00b1 0.00 0.62\u00b1 0.01 0.86\u00b1 0.00 0.24\u00b1 0.00 0.37\u00b1 0.00 0.39\u00b1 0.01 0.62\u00b1 0.01 0.28\u00b1 0.00 0.83\u00b1 0.00 0.71\u00b1 0.00 0.68\u00b1 0.00 0.50\u00b1 0.00 0.76\u00b1 0.00 70B Movies directed by 0.86 0.34\u00b1 0.01 0.25\u00b1 0.01 0.23\u00b1 0.00 0.14\u00b1 0.01 0.17\u00b1 0.00 0.04\u00b1 0.00 0.06\u00b1 0.00 0.06\u00b1 0.00 0.14\u00b1 0.01 0.10\u00b1 0.01 0.75\u00b1 0.00 0.67\u00b1 0.00 0.66\u00b1 0.01 0.50\u00b1 0.00 0.56\u00b1 0.01 70B Songs performed by 0.44 0.97\u00b1 0.00 0.76\u00b1 0.01 0.73\u00b1 0.01 0.55\u00b1 0.01 0.71\u00b1 0.01 0.16\u00b1 0.01 0.27\u00b1 0.01 0.29\u00b1 0.01 0.55\u00b1 0.01 0.35\u00b1 0.01 0.85\u00b1 0.00 0.69\u00b1 0.00 0.67\u00b1 0.00 0.50\u00b1 0.00 0.65\u00b1 0.01\n26"
        }
    ],
    "year": 2023
}