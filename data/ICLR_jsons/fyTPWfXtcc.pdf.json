{
    "abstractText": "Signal restoration is an important constrained optimization problem with significant applications in various domains. Although non-convex constrained optimization problems have been shown to perform better than convex counterparts in terms of reconstruction quality, convex constrained optimization problems have been preferred for their global optima guarantees. Despite the success of nonconvex methods in many applications, it is not an overstatement to say that there is little or no hope for non-convex problems to ensure global optima. In this paper, for the first time, we propose a family of invex functions for handling constrained inverse problems using the non-convex setting along with guarantees for their global optima invex function is a mapping where any critical point is a global minimizer. We also develop relevant theories to extend the global optima guarantee to a family of quasi-invex functions the largest set of optimizable mappings. Our theoretical results show that the proposed family of invex and quasi-invex functions can aid in extending existing convex optimization algorithms, such as the alternating direction of multipliers and accelerated proximal gradient methods. Moreover, our numerical tests show that the proposed family of invex/quasi-invex functions overcome the performance of convex mappings in terms of reconstruction quality across several relevant metrics and imaging tasks.",
    "authors": [
        {
            "affiliations": [],
            "name": "Samuel Pinilla"
        },
        {
            "affiliations": [],
            "name": "Jeyan Thiyagalingam"
        }
    ],
    "id": "SP:96c2c205a42800daa51e65cf858f78fed6a9f589",
    "references": [
        {
            "authors": [
                "Marco Buzzelli",
                "Luigi Celona",
                "Raimondo Schettini",
                "Jiang He",
                "Yi Xiao",
                "Jiajun Xiao",
                "Qiangqiang Yuan",
                "Jie Li",
                "Liangpei Zhang",
                "Taesung Kwon",
                "Dohoon Ryu",
                "Hyokyoung Bae",
                "Hao-Hsiang Yang",
                "Hua-En Chang",
                "Zhi-Kai Huang",
                "Wei-Ting Chen",
                "Sy-Yen Kuo",
                "Junyu Chen",
                "Haiwei Li",
                "Song Liu",
                "Sabarinathan",
                "K Uma",
                "B Sathya Bama",
                "S. Mohamed Mansoor Roomi"
            ],
            "title": "NTIRE 2022 spectral recovery challenge and data",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision",
            "year": 2022
        },
        {
            "authors": [
                "Gonzalo R Arce",
                "David J Brady",
                "Lawrence Carin",
                "Henry Arguello",
                "David S Kittle"
            ],
            "title": "Compressive coded aperture spectral imaging: An introduction",
            "venue": "IEEE Signal Processing Magazine,",
            "year": 2013
        },
        {
            "authors": [
                "Henry Arguello",
                "Jorge Bacca",
                "Hasindu Kariyawasam",
                "Edwin Vargas",
                "Miguel Marquez",
                "Ramith Hettiarachchi",
                "Hans Garcia",
                "Kithmini Herath",
                "Udith Haputhanthri",
                "Balpreet Singh Ahluwalia"
            ],
            "title": "Deep optical coding design in computational imaging: a data-driven framework",
            "venue": "IEEE Signal Processing Magazine,",
            "year": 2023
        },
        {
            "authors": [
                "Adil Bagirov",
                "Napsu Karmitsa",
                "Marko M M\u00e4kel\u00e4"
            ],
            "title": "Introduction to Nonsmooth Optimization: theory, practice and software",
            "year": 2014
        },
        {
            "authors": [
                "Adarsh Barik",
                "Jean Honorio"
            ],
            "title": "Fair sparse regression with clustering: An invex relaxation for a combinatorial problem",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Jonathan T Barron"
            ],
            "title": "A general and adaptive robust loss function",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Mokhtar S Bazaraa",
                "Chitharanjan M Shetty"
            ],
            "title": "Foundations of optimization, volume 122",
            "venue": "Springer Science & Business Media,",
            "year": 2012
        },
        {
            "authors": [
                "Amir Beck"
            ],
            "title": "First-order methods in optimization",
            "year": 2017
        },
        {
            "authors": [
                "Amir Beck",
                "Marc Teboulle"
            ],
            "title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems",
            "venue": "SIAM journal on imaging sciences,",
            "year": 2009
        },
        {
            "authors": [
                "Radu Ioan Bo\u0163",
                "Ern\u00f6 Robert Csetnek",
                "Szil\u00e1rd Csaba L\u00e1szl\u00f3"
            ],
            "title": "An inertial forward\u2013backward algorithm for the minimization of the sum of two nonconvex functions",
            "venue": "EURO Journal on Computational Optimization,",
            "year": 2016
        },
        {
            "authors": [
                "Stephen Boyd",
                "Neal Parikh",
                "Eric Chu",
                "Borja Peleato",
                "Jonathan Eckstein"
            ],
            "title": "Distributed optimization and statistical learning via the alternating direction method of multipliers",
            "venue": "Foundations and Trends\u00ae in Machine learning,",
            "year": 2011
        },
        {
            "authors": [
                "L Richard"
            ],
            "title": "Burden and J Douglas Faires. 2.1 the bisection algorithm",
            "venue": "Numerical analysis,",
            "year": 1985
        },
        {
            "authors": [
                "T Tony Cai",
                "Lie Wang"
            ],
            "title": "Orthogonal matching pursuit for sparse signal recovery with noise",
            "venue": "IEEE Transactions on Information theory,",
            "year": 2011
        },
        {
            "authors": [
                "Yuanhao Cai",
                "Jing Lin",
                "Zudi Lin",
                "Haoqian Wang",
                "Yulun Zhang",
                "Hanspeter Pfister",
                "Radu Timofte",
                "Luc Van Gool"
            ],
            "title": "Mst++: Multi-stage spectral-wise transformer for efficient spectral reconstruction",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Ariolfo Camacho",
                "Edwin Vargas",
                "Henry Arguello"
            ],
            "title": "Hyperspectral and multispectral image fusion addressing spectral variability by an augmented linear mixing model",
            "venue": "International Journal of Remote Sensing,",
            "year": 2022
        },
        {
            "authors": [
                "EJ Cand\u00e8s",
                "Benjamin Recht"
            ],
            "title": "The trace norm and nuclear norm of a matrix",
            "venue": "Communications on Pure and Applied Mathematics,",
            "year": 2006
        },
        {
            "authors": [
                "Emmanuel J Cand\u00e8s",
                "Michael B Wakin"
            ],
            "title": "An introduction to compressive sampling",
            "venue": "IEEE signal processing magazine,",
            "year": 2008
        },
        {
            "authors": [
                "Emmanuel J Candes",
                "Michael B Wakin",
                "Stephen P Boyd"
            ],
            "title": "Enhancing sparsity by reweighted l1 minimization",
            "venue": "Journal of Fourier analysis and applications,",
            "year": 2008
        },
        {
            "authors": [
                "Rafael E Carrillo",
                "Kenneth E Barner",
                "Tuncer C Aysal"
            ],
            "title": "Robust sampling and reconstruction methods for sparse signals in the presence of impulsive noise",
            "venue": "IEEE Journal of Selected Topics in Signal Processing,",
            "year": 2010
        },
        {
            "authors": [
                "Rafael E Carrillo",
                "Ana B Ramirez",
                "Gonzalo R Arce",
                "Kenneth E Barner",
                "Brian M Sadler"
            ],
            "title": "Robust compressive sensing of sparse signals: A review",
            "venue": "EURASIP Journal on Advances in Signal Processing,",
            "year": 2016
        },
        {
            "authors": [
                "Antonin Chambolle"
            ],
            "title": "An algorithm for total variation minimization and applications",
            "venue": "Journal of Mathematical imaging and vision,",
            "year": 2004
        },
        {
            "authors": [
                "Scott Shaobing Chen",
                "David L Donoho",
                "Michael A Saunders"
            ],
            "title": "Atomic decomposition by basis pursuit",
            "venue": "SIAM review,",
            "year": 2001
        },
        {
            "authors": [
                "Juan Carlos De los Reyes",
                "C-B Sch\u00f6nlieb",
                "Tuomo Valkonen"
            ],
            "title": "Bilevel parameter learning for higher-order total variation regularisation models",
            "venue": "Journal of Mathematical Imaging and Vision,",
            "year": 2017
        },
        {
            "authors": [
                "Jie Ding",
                "Vahid Tarokh",
                "Yuhong Yang"
            ],
            "title": "Model selection techniques: An overview",
            "venue": "IEEE Signal Processing Magazine,",
            "year": 2018
        },
        {
            "authors": [
                "Matthias J Ehrhardt",
                "Marta M Betcke"
            ],
            "title": "Multicontrast MRI reconstruction with structure-guided total variation",
            "venue": "SIAM Journal on Imaging Sciences,",
            "year": 2016
        },
        {
            "authors": [
                "Vania Vieira Estrela",
                "Hermes Aguiar Magalh\u00e3es",
                "Osamu Saotome"
            ],
            "title": "Total variation applications in computer vision",
            "venue": "In Handbook of Research on Emerging Perspectives in Intelligent Pattern Recognition, Analysis, and Image Processing,",
            "year": 2016
        },
        {
            "authors": [
                "Jianqing Fan",
                "Runze Li"
            ],
            "title": "Variable selection via nonconcave penalized likelihood and its oracle properties",
            "venue": "Journal of the American statistical Association,",
            "year": 2001
        },
        {
            "authors": [
                "Simon Foucart",
                "Holger Rauhut. A Mathematical Introduction to Compressive Sensing."
            ],
            "title": "ISBN 9780817649487 0817649484",
            "venue": "doi: 10.1007/978-0-8176-4948-7.",
            "year": 2013
        },
        {
            "authors": [
                "Pierre Frankel",
                "Guillaume Garrigos",
                "Juan Peypouquet"
            ],
            "title": "Splitting methods with variable metric for kurdyka\u2013\u0142ojasiewicz functions and general convergence rates",
            "venue": "Journal of Optimization Theory and Applications,",
            "year": 2015
        },
        {
            "authors": [
                "Yun Fu"
            ],
            "title": "Low-rank and sparse modeling for visual analysis",
            "year": 2014
        },
        {
            "authors": [
                "Donald Geman",
                "Chengda Yang"
            ],
            "title": "Nonlinear image recovery with half-quadratic regularization",
            "venue": "IEEE transactions on Image Processing,",
            "year": 1995
        },
        {
            "authors": [
                "Daniel Thomas Ginat",
                "Rajiv Gupta"
            ],
            "title": "Advances in computed tomography imaging technology",
            "venue": "Annual review of biomedical engineering,",
            "year": 2014
        },
        {
            "authors": [
                "Roland Glowinski"
            ],
            "title": "On alternating direction methods of multipliers: a historical perspective. Modeling, simulation and optimization for science and technology",
            "year": 2014
        },
        {
            "authors": [
                "R\u00e9mi Gribonval",
                "Morten Nielsen"
            ],
            "title": "Highly sparse representations from dictionaries are unique and independent of the sparseness measure",
            "venue": "Applied and Computational Harmonic Analysis,",
            "year": 2007
        },
        {
            "authors": [
                "Andr\u00e9s Guerrero",
                "Samuel Pinilla",
                "Henry Arguello"
            ],
            "title": "Phase recovery guarantees from designed coded diffraction patterns in optical imaging",
            "venue": "IEEE Transactions on Image Processing,",
            "year": 2020
        },
        {
            "authors": [
                "Yoseob Han",
                "Jong Chul Ye"
            ],
            "title": "Framing U-Net via deep convolutional framelets: Application to sparse-view CT",
            "venue": "IEEE transactions on medical imaging,",
            "year": 2018
        },
        {
            "authors": [
                "Morgan A Hanson"
            ],
            "title": "On sufficiency of the Kuhn-Tucker conditions",
            "venue": "Journal of Mathematical analysis and applications,",
            "year": 1981
        },
        {
            "authors": [
                "Charles R Harris",
                "K Jarrod Millman",
                "St\u00e9fan J Van Der Walt",
                "Ralf Gommers",
                "Pauli Virtanen",
                "David Cournapeau",
                "Eric Wieser",
                "Julian Taylor",
                "Sebastian Berg",
                "Nathaniel J Smith"
            ],
            "title": "Array programming with numpy",
            "year": 2020
        },
        {
            "authors": [
                "Peter Hedman",
                "Pratul P Srinivasan",
                "Ben Mildenhall",
                "Jonathan T Barron",
                "Paul Debevec"
            ],
            "title": "Baking neural radiance fields for real-time view synthesis",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Yinan Hu",
                "Ivan W Selesnick"
            ],
            "title": "Nonconvex Haar-TV denoising",
            "venue": "Digital Signal Processing,",
            "year": 2020
        },
        {
            "authors": [
                "Marian-Daniel Iordache",
                "Jos\u00e9 M Bioucas-Dias",
                "Antonio Plaza"
            ],
            "title": "Total variation spatial regularization for sparse hyperspectral unmixing",
            "venue": "IEEE Transactions on Geoscience and Remote Sensing,",
            "year": 2012
        },
        {
            "authors": [
                "Andr\u00e9s Jerez",
                "Samuel Pinilla",
                "Henry Arguello"
            ],
            "title": "Fast target detection via template matching in compressive phase retrieval",
            "venue": "IEEE Transactions on Computational Imaging,",
            "year": 2020
        },
        {
            "authors": [
                "Kyong Hwan Jin",
                "Michael T McCann",
                "Emmanuel Froustey",
                "Michael Unser"
            ],
            "title": "Deep convolutional neural network for inverse problems in imaging",
            "venue": "IEEE Transactions on Image Processing,",
            "year": 2017
        },
        {
            "authors": [
                "Jeremy Johnston",
                "Yinchuan Li",
                "Marco Lops",
                "Xiaodong Wang"
            ],
            "title": "ADMM-Net for communication interference removal in stepped-frequency radar",
            "venue": "IEEE Transactions on Signal Processing,",
            "year": 2021
        },
        {
            "authors": [
                "Jakob S J\u00f8rgensen",
                "Evelina Ametova",
                "Genoveva Burca",
                "Gemma Fardell",
                "Evangelos Papoutsellis",
                "Edoardo Pasca",
                "Kris Thielemans",
                "Martin Turner",
                "Ryan Warr",
                "William RB Lionheart"
            ],
            "title": "Core imaging library-part I: A versatile python framework for tomographic imaging",
            "venue": "Philosophical Transactions of the Royal Society A,",
            "year": 2020
        },
        {
            "authors": [
                "Ulugbek S Kamilov",
                "Charles A Bouman",
                "Gregery T Buzzard",
                "Brendt Wohlberg"
            ],
            "title": "Plug-andplay methods for integrating physical and learned models in computational imaging: Theory, algorithms, and applications",
            "venue": "IEEE Signal Processing Magazine,",
            "year": 2023
        },
        {
            "authors": [
                "RN Kaul",
                "Surjeet Kaur"
            ],
            "title": "Optimality criteria in nonlinear programming involving nonconvex functions",
            "venue": "Journal of Mathematical Analysis and Applications,",
            "year": 1985
        },
        {
            "authors": [
                "Razieh Keshavarzian",
                "Ali Aghagolzadeh",
                "Tohid Yousefi Rezaii"
            ],
            "title": "llp norm regularization based group sparse representation for image compressed sensing recovery",
            "venue": "Signal Processing: Image Communication,",
            "year": 2019
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Max Welling"
            ],
            "title": "Auto-Encoding Variational Bayes",
            "venue": "In 2nd International Conference on Learning Representations,",
            "year": 2014
        },
        {
            "authors": [
                "Dmitry Kovalev",
                "Alexander Gasnikov"
            ],
            "title": "The first optimal algorithm for smooth and stronglyconvex-strongly-concave minimax optimization",
            "venue": "arXiv preprint arXiv:2205.05653,",
            "year": 2022
        },
        {
            "authors": [
                "Amine Laghrib",
                "Lekbir Afraites",
                "Aissam Hadri",
                "Mourad Nachaoui"
            ],
            "title": "A non-convex PDEconstrained denoising model for impulse and gaussian noise mixture reduction",
            "venue": "Inverse Problems and Imaging,",
            "year": 2023
        },
        {
            "authors": [
                "Huan Li",
                "Zhouchen Lin"
            ],
            "title": "Accelerated proximal gradient methods for nonconvex programming",
            "venue": "Advances in neural information processing systems,",
            "year": 2015
        },
        {
            "authors": [
                "Ji Li"
            ],
            "title": "Solving blind ptychography effectively via linearized alternating direction method of multipliers",
            "venue": "Journal of Scientific Computing,",
            "year": 2023
        },
        {
            "authors": [
                "Junli Liang",
                "Petre Stoica",
                "Yang Jing",
                "Jian Li"
            ],
            "title": "Phase retrieval via the alternating direction method of multipliers",
            "venue": "IEEE Signal Processing Letters,",
            "year": 2017
        },
        {
            "authors": [
                "Fan Lin",
                "Yingpin Chen",
                "Lingzhi Wang",
                "Yuqun Chen",
                "Wei Zhu",
                "Fei Yu"
            ],
            "title": "An efficient image reconstruction framework using total variation regularization with lp-quasinorm and group gradient",
            "venue": "sparsity. Information,",
            "year": 2019
        },
        {
            "authors": [
                "Xingguo Liu",
                "Yingpin Chen",
                "Zhenming Peng",
                "Juan Wu",
                "Zhuoran Wang"
            ],
            "title": "Infrared image superresolution reconstruction based on quaternion fractional order total variation with lp quasinorm",
            "venue": "Applied Sciences,",
            "year": 2018
        },
        {
            "authors": [
                "Trang C Mai",
                "Hien Quoc Ngo",
                "Le-Nam Tran"
            ],
            "title": "Energy-efficient power allocation in cell-free massive MIMO with zero-forcing: First order methods",
            "venue": "Physical Communication,",
            "year": 2022
        },
        {
            "authors": [
                "Goran Marjanovic",
                "Victor Solo"
            ],
            "title": "On lq optimization and matrix completion",
            "venue": "IEEE Transactions on signal processing,",
            "year": 2012
        },
        {
            "authors": [
                "Anke Meyer-B\u00e4se",
                "Anke Meyer-Baese",
                "Volker J Schmid"
            ],
            "title": "Pattern Recognition and Signal Analysis in Medical Imaging",
            "year": 2004
        },
        {
            "authors": [
                "Shashi K Mishra",
                "Giorgio Giorgi"
            ],
            "title": "Invexity and optimization, volume 88",
            "venue": "Springer Science & Business Media,",
            "year": 2008
        },
        {
            "authors": [
                "Frederick Mosteller",
                "John W Tukey"
            ],
            "title": "Data analysis and regression. A second course in statistics. Addison-Wesley series in behavioral science: quantitative methods",
            "year": 1977
        },
        {
            "authors": [
                "Giorgos Mountrakis",
                "Jungho Im",
                "Caesar Ogole"
            ],
            "title": "Support vector machines in remote sensing: A review",
            "venue": "ISPRS journal of photogrammetry and remote sensing,",
            "year": 2011
        },
        {
            "authors": [
                "Peter Ochs",
                "Yunjin Chen",
                "Thomas Brox",
                "Thomas Pock"
            ],
            "title": "iPiano: Inertial proximal algorithm for nonconvex optimization",
            "venue": "SIAM Journal on Imaging Sciences,",
            "year": 2014
        },
        {
            "authors": [
                "Yuyuan Ouyang",
                "Yunmei Chen",
                "Guanghui Lan",
                "Eduardo Pasiliao Jr."
            ],
            "title": "An accelerated linearized alternating direction method of multipliers",
            "venue": "SIAM Journal on Imaging Sciences,",
            "year": 2015
        },
        {
            "authors": [
                "Diethard Ernst Pallaschke",
                "Stefan Rolewicz"
            ],
            "title": "Foundations of mathematical optimization: convex analysis without linearity, volume 388",
            "venue": "Springer Science & Business Media,",
            "year": 2013
        },
        {
            "authors": [
                "Keunhong Park",
                "Utkarsh Sinha",
                "Jonathan T Barron",
                "Sofien Bouaziz",
                "Dan B Goldman",
                "Steven M Seitz",
                "Ricardo Martin-Brualla"
            ],
            "title": "Nerfies: Deformable neural radiance fields",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Samuel Pinilla",
                "Tingting Mu",
                "Neil Bourne",
                "Jeyan Thiyagalingam"
            ],
            "title": "Improved imaging by invex regularizers with global optima guarantees",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Samuel Pinilla",
                "Seyyed Reza Miri Rostami",
                "Igor Shevkunov",
                "Vladimir Katkovnik",
                "Karen Egiazarian"
            ],
            "title": "Hybrid diffractive optics design via hardware-in-the-loop methodology for achromatic extended-depth-of-field imaging",
            "venue": "Optics Express,",
            "year": 2022
        },
        {
            "authors": [
                "Samuel Pinilla",
                "Kumar Vijay Mishra",
                "Igor Shevkunov",
                "Mojtaba Soltanalian",
                "Vladimir Katkovnik",
                "Karen Egiazarian"
            ],
            "title": "Unfolding-aided bootstrapped phase retrieval in optical imaging: Explainable AI reveals new imaging frontiers",
            "venue": "IEEE Signal Processing Magazine,",
            "year": 2023
        },
        {
            "authors": [
                "Apostolos F Psaros",
                "Kenji Kawaguchi",
                "George Em Karniadakis"
            ],
            "title": "Meta-learning PINN loss functions",
            "venue": "Journal of Computational Physics,",
            "year": 2022
        },
        {
            "authors": [
                "Juan Marcos Ramirez",
                "Jos\u00e9 Ignacio Mart\u0131\u0301nez-Torre",
                "Henry Arguello"
            ],
            "title": "LADMM-Net: An unrolled deep network for spectral image fusion from compressive data",
            "venue": "Signal Processing,",
            "year": 2021
        },
        {
            "authors": [
                "Thomas W Reiland"
            ],
            "title": "Nonsmooth invexity",
            "venue": "Bulletin of the Australian Mathematical Society,",
            "year": 1990
        },
        {
            "authors": [
                "R Tyrrell Rockafellar",
                "Roger J-B Wets"
            ],
            "title": "Variational analysis, volume 317",
            "venue": "Springer Science & Business Media,",
            "year": 2009
        },
        {
            "authors": [
                "Carola-Bibiane Sch\u00f6nlieb",
                "Andrea Bertozzi",
                "Martin Burger",
                "Lin He"
            ],
            "title": "Image inpainting using a fourth-order total variation flow",
            "venue": "In SAMPTA\u201909, pp. Special\u2013session,",
            "year": 2009
        },
        {
            "authors": [
                "Ivan Selesnick",
                "Alessandro Lanza",
                "Serena Morigi",
                "Fiorella Sgallari"
            ],
            "title": "Non-convex total variation regularization for convex denoising of signals",
            "venue": "Journal of Mathematical Imaging and Vision,",
            "year": 2020
        },
        {
            "authors": [
                "Yunquan Song",
                "Zitong Li",
                "Minglu Fang"
            ],
            "title": "Robust variable selection based on penalized composite quantile regression for high-dimensional single-index models",
            "year": 2000
        },
        {
            "authors": [
                "Jian Sun",
                "Huibin Li",
                "Zongben Xu"
            ],
            "title": "Deep ADMM-Net for compressive sensing MRI",
            "venue": "Advances in neural information processing systems,",
            "year": 2016
        },
        {
            "authors": [
                "Shuqin Sun",
                "Ting Kei Pong"
            ],
            "title": "Doubly iteratively reweighted algorithm for constrained compressed sensing models",
            "venue": "arXiv preprint arXiv:2206.08205,",
            "year": 2022
        },
        {
            "authors": [
                "Yuli Sun",
                "Hao Chen",
                "Jinxu Tao",
                "Lin Lei"
            ],
            "title": "Computed tomography image reconstruction from few views via log-norm total variation minimization",
            "venue": "Digital Signal Processing,",
            "year": 2019
        },
        {
            "authors": [
                "Mujahid Syed",
                "Panos Pardalos",
                "Jose Principe"
            ],
            "title": "Invexity of the minimum error entropy criterion",
            "venue": "IEEE Signal Processing Letters,",
            "year": 2013
        },
        {
            "authors": [
                "Mujahid N Syed",
                "Panos M Pardalos",
                "Jose C Principe"
            ],
            "title": "On the optimization properties of the correntropic loss function in data analysis",
            "venue": "Optimization Letters,",
            "year": 2014
        },
        {
            "authors": [
                "Vladimir Tankovich",
                "Christian Hane",
                "Yinda Zhang",
                "Adarsh Kowdle",
                "Sean Fanello",
                "Sofien Bouaziz"
            ],
            "title": "HITNET: Hierarchical iterative tile refinement network for real-time stereo matching",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Edwin Vargas",
                "Oscar Espitia",
                "Henry Arguello",
                "Jean-Yves Tourneret"
            ],
            "title": "Spectral image fusion from compressive measurements",
            "venue": "IEEE Transactions on Image Processing,",
            "year": 2018
        },
        {
            "authors": [
                "Edwin Vargas",
                "Samuel Pinilla",
                "Jorge Bacca",
                "Henry Arguello"
            ],
            "title": "Robust formulation for solving underdetermined random linear system of equations via ADMM",
            "venue": "IEEE Statistical Signal Processing Workshop (SSP),",
            "year": 2018
        },
        {
            "authors": [
                "Edwin Vargas",
                "Henry Arguello",
                "Jean-Yves Tourneret"
            ],
            "title": "Spectral image fusion from compressive measurements using spectral unmixing and a sparse representation of abundance maps",
            "venue": "IEEE Transactions on Geoscience and Remote Sensing,",
            "year": 2019
        },
        {
            "authors": [
                "Peter Vouras",
                "Kumar Vijay Mishra",
                "Alexandra Artusio-Glimpse",
                "Samuel Pinilla",
                "Angeliki Xenaki",
                "David W Griffith",
                "Karen Egiazarian"
            ],
            "title": "An overview of advances in signal processing techniques for classical and quantum wideband synthetic apertures",
            "venue": "arXiv preprint arXiv:2205.05602,",
            "year": 2022
        },
        {
            "authors": [
                "Jiaxi Wang",
                "Li Zeng",
                "Chengxiang Wang",
                "Yumeng Guo"
            ],
            "title": "Admm-based deep reconstruction for limited-angle CT",
            "venue": "Physics in Medicine & Biology,",
            "year": 2019
        },
        {
            "authors": [
                "Mengyuan Wang",
                "Wei He",
                "Hongyan Zhang"
            ],
            "title": "A spatial-spectral transformer network with total variation loss for hyperspectral image denoising",
            "venue": "IEEE Geoscience and Remote Sensing Letters,",
            "year": 2023
        },
        {
            "authors": [
                "Rongfang Wang",
                "Yali Qin",
                "Zhenbiao Wang",
                "Huan Zheng"
            ],
            "title": "Group-based sparse representation for compressed sensing image reconstruction with joint regularization",
            "year": 2022
        },
        {
            "authors": [
                "Weina Wang",
                "Yunmei Chen"
            ],
            "title": "An accelerated smoothing gradient method for nonconvex nonsmooth minimization in image processing",
            "venue": "Journal of Scientific Computing,",
            "year": 2022
        },
        {
            "authors": [
                "Yu Wang",
                "Wotao Yin",
                "Jinshan Zeng"
            ],
            "title": "Global convergence of ADMM in nonconvex nonsmooth optimization",
            "venue": "Journal of Scientific Computing,",
            "year": 2019
        },
        {
            "authors": [
                "Kaixuan Wei",
                "Angelica Aviles-Rivero",
                "Jingwei Liang",
                "Ying Fu",
                "Hua Huang",
                "Carola-Bibiane Sch\u00f6nlieb"
            ],
            "title": "TFPNP: Tuning-free plug-and-play proximal algorithms with applications to inverse imaging problems",
            "venue": "Journal of Machine Learning Research,",
            "year": 2022
        },
        {
            "authors": [
                "Fei Wen",
                "Lei Chu",
                "Peilin Liu",
                "Robert C Qiu"
            ],
            "title": "A survey on nonconvex regularization-based sparse and low-rank recovery in signal processing, statistics, and machine learning",
            "venue": "IEEE Access,",
            "year": 2018
        },
        {
            "authors": [
                "Joseph Woodworth",
                "Rick Chartrand"
            ],
            "title": "Compressed sensing recovery via nonconvex shrinkage penalties",
            "venue": "Inverse Problems,",
            "year": 2016
        },
        {
            "authors": [
                "Rui Wu",
                "Di-Rong Chen"
            ],
            "title": "The improved bounds of restricted isometry constant for recovery via lp-minimization",
            "venue": "IEEE transactions on information theory,",
            "year": 2013
        },
        {
            "authors": [
                "Xingyu Xie",
                "Jianlong Wu",
                "Guangcan Liu",
                "Zhisheng Zhong",
                "Zhouchen Lin"
            ],
            "title": "Differentiable linearized ADMM",
            "venue": "In International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "Constantin Z\u0103linescu"
            ],
            "title": "A critical view on invexity",
            "venue": "Journal of Optimization Theory and Applications,",
            "year": 2014
        },
        {
            "authors": [
                "Cun-Hui Zhang"
            ],
            "title": "Nearly unbiased variable selection under minimax concave penalty",
            "venue": "The Annals of statistics,",
            "year": 2010
        },
        {
            "authors": [
                "Zhihua Zhang",
                "James T Kwok",
                "Dit-Yan Yeung"
            ],
            "title": "Surrogate maximization/minimization algorithms and extensions",
            "venue": "Machine Learning,",
            "year": 2007
        },
        {
            "authors": [
                "Abdelhak M Zoubir",
                "Visa Koivunen",
                "Yacine Chakhchoukh",
                "Michael Muma"
            ],
            "title": "Robust estimation in signal processing: A tutorial-style treatment of fundamental concepts",
            "venue": "IEEE Signal Processing Magazine,",
            "year": 2012
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Signal restoration is an optimization problem that seeks to estimate an unknown original signal x \u2208 Rn from a set of noisy observations y \u2208 Rm. This optimization problem falls under the purview of inverse problems, which are common across all disciplines, from physics (Mountrakis et al., 2011; Vouras et al., 2022), to medical imaging (Ginat & Gupta, 2014; Pinilla et al., 2022b) to signal processing (Pinilla et al., 2023), and to machine learning (Harris et al., 2020; Wei et al., 2022). In general, an inverse problem can be formulated as follows:\nminimize x\u2208Rn\ng(x) subject to f(x) \u2264 \u03f5, (1)\nwhere \u03f5 > 0, f(x) is a mapping constructed as a reconstruction error (fidelity term), and g(x) is a regularizer to model the priors of the signal such as sparsity, low-rankness, and smoothness (Beck, 2017, Chapter 10). Here, f(x) is often considered to be differentiable (i.e., smooth), while g(x) is not. For some imaging tasks, the fidelity term has the form of f(Ax\u2212y), where A \u2208 Rm\u00d7n. When m < n for A, the inverse problem reduces to compressive sensing. This technique is extensively exploited in many areas such as microscopy, optical imaging, and spectroscopy (Arce et al., 2013; Jerez et al., 2020; Guerrero et al., 2020).\nSolving (1), a guarantee for global optimality is of paramount importance to ensure that the bestpossible solution is found subject to the relevant constraints (Parikh & Boyd, 2014; Pinilla et al., 2022a). Convex constructs of f(x), g(x), as demonstrated in the literature (Beck & Teboulle, 2009; Beck, 2017), are helpful for seeking guaranteed global optima, when either the measurements can be considered as ideal and noiseless (i.e., \u03f5 = 0) (Parikh & Boyd, 2014) or when the regularizer g(x) exactly models the priors of the data. However, real-world problems do not fit this assumption, where noise is rather prevalent in all measurements (i.e., \u03f5 > 0), and convex regularizers can easily inaccurately model the sparsity, low-rankness, smoothness, and abnormal patterns in the data (Candes et al., 2008; Laghrib et al., 2023). Although approaches with assumptions tied to noise models (such as Gaussianity) perform better than plain convex approaches, they too fail as the real-world noise models often deviate from these assumptions (Sun & Pong, 2022; Tankovich et al., 2021).\n\u2217Rutherford Appleton Laboratory, Harwell, UK.\nAn alternative approach is to consider non-convex mappings for f(x) and g(x). From (Kaul & Kaur, 1985), it can be seen that there exists a large collection of mappings that can be well-optimized compared to pure convex settings. We summarize important non-convex mappings from the literature in Table 1. These are a set of well-accepted mappings that perform better than convex ones in terms of restoration quality (Pinilla et al., 2022a; Sun & Pong, 2022). Various regularizers have been considered in the literature to overcome the limitations of pure convex approaches, such as the \u21131-norm, total-variation (Chambolle, 2004; Selesnick et al., 2020) and nuclear norm (Cande\u0300s & Recht, 2006), which are the continuous and convex surrogates of the \u21130-pseudo norm and rank, respectively (Fu, 2014). More specifically, several interpolations between the \u21130-pseudonorm and the \u21131-norm have been explored as regularizers including the \u2113p-quasinorms (where 0 < p < 1) (Marjanovic & Solo, 2012), Capped-\u21131 penalty (Zhang et al., 2007), Log-Sum Penalty (Candes et al., 2008), Convexconcave penalty (Kovalev & Gasnikov, 2022), Minimax Concave Penalty (Zhang, 2010), Geman Penalty (Geman & Yang, 1995), and the Smoothly Clipped Absolute Deviation (SCAD) (Fan & Li, 2001). Furthermore, \u21132-norm incorporated as part of the constraint in (1) is often replaced by other loss functions to reflect different noise models or robustness requirements in the noisy data y, such as those outlined in (Carrillo et al., 2016; Zoubir et al., 2012). Concrete alternative reconstruction error functions include the Cauchy loss (Carrillo et al., 2016), the Huber function (Hedman et al., 2021), and the Tukey biweight loss (Mosteller & Tukey, 1977). However, while offering outstanding restoration quality, none of these can offer a guarantee for global optima, which would have been ideal for providing the soundness of these approaches. The lack of approaches for guaranteeing the global minima in non-convex settings leaves any optimization-based algorithmic solution incomplete and non-unique. It hence cannot be categorically accepted as the best possible solution despite their improved performance over convex functions. Motivated by this problem of seeking guarantees for global optimality when solving nonconvex problems, we investigate broader classes of functions that exploit the concept of invexity and quasi-invexity (Hanson, 1981; Reiland, 1990), which have been initially defined in early 1980s (Hanson, 1981). The specialty of invex functions is that any critical point in an invex function is a global minimizer itself (Pinilla et al., 2022a). Quasi-invex mappings generalize invex functions and hence are the largest set of optimizable functions as outlined in (Kaul & Kaur, 1985). This places the quasiinvex functions in a special and unique position for handling inverse problems. Although mathematical implications of quasi-invex (and hence invex) functions are well developed (Syed et al., 2013; Barik & Honorio, 2021; Pinilla et al., 2022a), their practical utility is less understood (Za\u0306linescu, 2014). To the best of our knowledge, there is no existing body of work in the invex literature on applying and developing quasi-invex (and invex)-based methods for seeking global optimality in constrained optimization problems, such as signal restoration. In this paper, we focus on demonstrating the practical utility of assuming f(x), g(x) to be invex/quasi-invex to handle inverse problems as in (1), with guarantees for global optima. Hence, in contrast with results in (Pinilla et al., 2022a), we make the following key contributions in:\n\u2022 We develop a set of mathematical tools to construct a family of f(x) and g(x) in (1) with proved invexity/quasi-invexity for model-based inverse imaging problems. Additionally, we prove that our proposed family of invex/quasi-invex functions is closed under summation - a result that has not been available before in the invex literature of optimization (Za\u0306linescu, 2014).\n\u2022 We prove global optima under the invex/quasi-invex settings. These results extend the capability of alternating direction method of multipliers and accelerated proximal gradient methods to handle non-convex cases otherwise limited to convex settings. We also report their convergence rates, which show both methods using invex/quasi-invex mappings are as efficient as solving the wellestablished convex optimization problems;\n\u2022 We conduct an effective evaluation of the proposed approach in handling a number of signal restoration problems against state-of-the-art algorithms and baselines."
        },
        {
            "heading": "2 PRELIMINARIES",
            "text": "The i-th entry of a vector w, is w[i]. For vectors, \u2225w\u2225p is the \u2113p-norm. An open ball is defined as B(x; r) = {y \u2208 Rn : \u2225y \u2212 x\u22252 < r}. The operation conv(A) represents the convex hull of the set A. We use \u03c3i(W ) to denote the i-th singular value of a matrix W in descending order. We present several concepts needed for the development of this paper starting with the definition of a locally Lipschitz continuous function. Definition 1. A function f : Rn \u2192 R is locally Lipschitz continuous at a point x \u2208 Rn if there exist scalarsK > 0 and \u03f5 > 0 such that for all y, z \u2208 B(x, \u03f5) we have |f(y)\u2212f(z)| \u2264 K\u2225y\u2212z\u22252.\nSince the ordinary directional derivative being the most important tool in optimization does not necessarily exist for locally Lipschitz continuous functions, it is required to introduce the concept of subdifferential (Bagirov et al., 2014) which is calculated in practice as follows. Theorem 1. (Bagirov et al., 2014, Theorem 3.9) Let f : Rn \u2192 R be a locally Lipschitz continuous function at x \u2208 Rn, and define \u2126f = {x \u2208 Rn|f is not differentiable at the point x}. Then the subdifferential of f is given by\n\u2202f(x) = conv ({\u03b6 \u2208 Rn| exists (xi) \u2208 Rn \\ \u2126f such that xi \u2192 x and \u2207f(xi) \u2192 \u03b6}) . (2)\nThe notion of subdifferential is given for locally Lipschitz continuous functions because it is always nonempty (Bagirov et al., 2014, Theorem 3.3). Based on this, we present the concept of invexity. Definition 2. Let f : Rn \u2192 R be locally Lipschitz; then f is invex if there exists a function \u03b7 : Rn \u00d7 Rn \u2192 Rn such that \u2200x,y \u2208 Rn, \u2200\u03b6 \u2208 \u2202f(y) we have f(x)\u2212 f(y) \u2265 \u03b6T \u03b7(x,y).\nIt is well known that a convex function simply satisfies this definition for \u03b7(x,y) = x \u2212 y. The following theorem (Mishra & Giorgi, 2008, Theorem 4.33) makes connection between invexity and its well-known optimum property which motivates the design of invex optimization problems. Theorem 2. (Mishra & Giorgi, 2008, Theorem 4.33) Let f : Rn \u2192 R be locally Lipschitz. Then the following statements are equivalent: 1) f is invex. 2) Every point y \u2208 Rn that satisfies 0 \u2208 \u2202f(y) is a global minimizer of f .\nWe finalize this section by introducing a generalization of invexity; indeed (Reiland, 1990) introduced also the following classes of generalized convex functions. Definition 3. Let f : Rn \u2192 R be locally Lipschitz; then f is quasi-invex if there exists \u03b7 : Rn \u00d7Rn \u2192 Rn such that \u2200x, y \u2208 Rn, \u2200\u03b6 \u2208 \u2202f(y) we have f(x)\u2212 f(y) \u2264 0 =\u21d2 \u03b6T \u03b7(x, y) \u2264 0."
        },
        {
            "heading": "3 INVEX AND QUASI-INVEX FUNCTION SETS",
            "text": "We address the necessity of handling the issues around real-world data by constructing invex/quasiinvex functions for data fidelity loss f(x), and regularizer g(x) functions. To this end, we first define the family of functions this paper investigates and their properties. Definition 4. (Admissible Function) Let h : Rn \u2192 R such that h(x) = \u2211n i=1 s(|x[i]|), where s : [0,\u221e) \u2192 [0,\u221e) and s\u2032(w) > 0 for w \u2208 (0,\u221e). If s with s(0) = 0 such that s(w)/w2 is non-increasing on (0,\u221e), then h(x) is said to be an admissible function. Definition 4 places a requirement on f(x) and g(x) in (1) to operate element-wise on positive values. This condition is mild since it holds for the vast majority of inverse problem formulations, including loss functions in deep learning, whether they are convex or non-convex (Carrillo et al., 2016; Wen et al., 2018; Sun & Pong, 2022). Using element-wise mapping offers notable advantages, especially in developing high-performance algorithms. One key advantage lies in the ability to parallelize, effectively reducing runtimes, making them suitable for addressing large-scale problems (Parikh & Boyd, 2014; Wang & Chen, 2022; Zoubir et al., 2012). Other conditions in Definition 4 are crucial as they establish a vital connection to invexity, which we discuss next in Theorem 3 (see Appendix A for the proof). Theorem 3. Let f, g : Rn \u2192 R be two admissible functions as in Definition 4, such that f(x) =\u2211n\ni=1 sf (|x[i]|), and g(x) = \u2211n\ni=1 sg(|x[i]|). Then the following holds: i) f(x), and g(x) are invex; ii) hs(x) = \u03b1f(x) + \u03b2g(x) is an admissible function (therefore invex) for every \u03b1, \u03b2 \u2265 0; iii) hc(x) = \u2211n i=1(sf \u25e6 sg)(|x[i]|) is an admissible function. In addition to these, if we assume that s\u2032f (w), s \u2032 g(w) \u2265 0 for w \u2208 (0,\u221e), then f(x), g(x), and hs(x), hc(x) are all quasi-invex.\nThe essential breakthrough of Theorem 3 compared with results in the invex literature such as (Pinilla et al., 2022a) lies in the fact that Definition 4 introduces the first family of invex/quasiinvex functions closed under summation. This implies that the sum of invex/quasi-invex functions is also invex/quasi-invex. The significance of this result manifests on two fronts. Firstly, Theorem 3 paves the way for establishing theoretical guarantees for global optima of (1) beyond the realm of convexity. Secondly, it bestows practical benefits to practitioners, as both Definition 4 and the third statement of Theorem 3 offer a systematic methodology for constructing invex/quasiinvex functions. These results also give away another side consequence: for any admissible function f(x) = \u2211n i=1 sf (|x[i]|) such that s\u2032f (w) \u2265 0, then f is not invex. The proof stems from the fact that s\u2032f (w) can be zero in non-minimizer values, leading to its quasi-invexity. In the following sections, we leverage the results in Theorem 3 to present illustrative examples of invex/quasi-invex functions that apply in diverse scientific domains."
        },
        {
            "heading": "3.1 INVEX REGULARIZERS",
            "text": "In addition to the list of original invex regularizer functions presented in (Pinilla et al., 2022a, Lemma 1), consider the following Theorem 4 (See Appendix B for proof). Theorem 4. For p \u2208 (0, 1], \u03f5 > 0, the following mapping\n(LLp-regularizer) g(x) = n\u2211\ni=1\nlog(1 + (|x[i]|+ \u03f5)p), (3)\nis an admissible function. Additionally, let D \u2208 R(n\u22121)\u00d7n be the first-order difference matrix (further details in Appendix B). If g is an admissible function, then gTV (x) = g(Dx) is invex. The key to prove Theorem 4 is centred around the fact that any admissible function is invex, and it is a point-wise non-increasing when divided by a quadratic mapping. It is worth mentioning that the invex function presented in equation (3) is one of the pivotal functions in the domain of compressive sensing (Keshavarzian et al., 2019). Although the analysis of equation (3) is valid with or without \u03f5, we prefer to retain \u03f5 to satisfy Definition 1. Although the literature identified this function as nonconvex (Wang & Chen, 2022; Liu et al., 2018), there is no notion of invexity or proof of invexity.\nThe second part of Theorem 4 presents invex generalizations of the classical convex total-variation (TV) regularizer (Chambolle, 2004; Selesnick et al., 2020) with the \u21131-norm replaced by invex functions - missing result in the invex literature such as (Pinilla et al., 2022a). TV-based regularization is effective in various applications such as computer tomography (Sun et al., 2019), hyperspectral imaging (Iordache et al., 2012; Wang et al., 2023), and computer vision (Estrela et al., 2016), where the goal is purely signal restoration. Classical TV-based algorithms suffer from an issue where the \u21131-norm tends to underestimate the amplitudes of signal discontinuities owing to the limitation of the \u21131-norm regularization itself (Selesnick et al., 2020). Several studies in the literature (Liu et al., 2018; Selesnick et al., 2020) show that \u2113p-quasinorm instead of \u21131-norm can significantly address this issue, albeit the literature not demonstrating the benefits ascribed to the invexity. Again, similar to equation (3), the literature identified this function as non-convex (Wang & Chen, 2022; Liu et al., 2018) without any notion of these functions being invex or proof of invexity.\nDriven by the success of equation (3) in compressive sensing (Keshavarzian et al., 2019), we propose its TV-like regularizer version. Further insights of Theorem 4, including the extension of TV-like regularizers to two- and three-dimensional signals, are presented in Section B.1."
        },
        {
            "heading": "3.2 INVEX FIDELITY LOSSES",
            "text": "Now, to complement the list of invex regularizers stated in Section 3.1, we present five invex data fidelity functions f(x) in the following theorem. Theorem 5. All the following functions for c, \u03b4 > 0, and \u03b1 \u2208 R are admissible\n(Cauchy) f(x) = m\u2211 i=1 log ( 1 + x2[i] \u03b42 ) (4)\n(Geman-McClure) f(x) = m\u2211 i=1 2x2[i] x2[i] + 4\u03b42 (5)\n(Welsh) f(x) = n\u2211\ni=1\n1\u2212 exp ( \u2212x2[i] 2\u03b42 ) (6)\n(Adaptive robust) f(x) = n\u2211\ni=1\n|\u03b1\u2212 2| \u03b1\n(( (x[i]/c)2\n|\u03b1\u2212 2| + 1\n)\u03b1/2 \u2212 1 ) (7)\nf(x) = m\u2211 i=1 log ( 1 + x2[i] ) \u2212 x 2[i] 2x2[i] + 2 (8)\nFidelity losses given in equations (4)-(7) have existed in the literature without ever being identified as invex functions or the benefits being ascribed to their invexity. Equation (6) was identified as an invex function, and its invexity was proved in (Syed et al., 2013; 2014). Equations (4)-(7) are found in the literature replacing the traditional \u21132-norm. This was to account for different noise models and improve the solution\u2019s robustness towards noisy measurements y in (1). Equations (4)-(7) have been used to improve the performance of the original Variational Autoencoder (Kingma & Welling, 2014) by incorporating equations (4)-(6) as robust loss functions in (Barron, 2019). Finally, equation (8) is a novel invex function we propose to provide more flexibility around losses (harder to achieve in a convex setting). The proof of Theorem 5 is deferred to Appendix C."
        },
        {
            "heading": "3.3 QUASI-INVEX REGULARIZERS",
            "text": "We list three quasi-invex function constructs for g(x) in Theorem 6 below. Theorem 6. For constants \u03bb, p \u2208 (0, 1], and \u03f5 > 0, the following mappings are quasi-invex\ng\u03b8(x) = \u03bb n\u2211 i=1 r\u03b8(x[i]); \u03b8 \u2265 1, r\u03b8(x[i]) = { \u03bb|x[i]| \u2212 x2[i]/(2\u03b8) if |x[i]| < \u03b8\u03bb \u03b8\u03bb2/2 if |x[i]| \u2265 \u03b8\u03bb (9)\ng\u03b8(x) = n\u2211 i=1 min (log(1 + (|x[i]|+ \u03f5)p), \u03b8) ; \u03b8 > 0. (10)\nFurther, let D \u2208 R(n\u22121)\u00d7n be the first-order difference matrix. If g is admissible such that g(x) =\u2211n i=1 sg(|x[i]|) with s\u2032g(w) \u2265 0 for w \u2208 (0,\u221e), then gTV (x) = g(Dx) is quasi-invex.\nThe critical aspect of proving Theorem 6 is centred around the quasi-invex construct in Theorem 3 and that it is a point-wise non-increasing when divided by a quadratic mapping. Equation (9) referred to as the Minimax Concave Penalty (MCP) (Zhang, 2010) in the non-convex literature, with a range of applications in various domains (Kovalev & Gasnikov, 2022; Zhang, 2010). Although this mapping function is standard in imaging applications (Ding et al., 2018; Song et al., 2022), the knowledge of its quasi-invexity has never been identified nor proven. For the first time, we provide formal proof of MCP being quasi-invex in Appendix D. Additional functions, such as the Clipped Absolute Deviation (SCAD) (Fan & Li, 2001), are proven to be quasi-invex in Section D. Furthermore, following an analysis analogous to Theorem 4, we can extend to two- and three-dimensional TV-like quasi-invex regularizers. In addition to these three quasi-invex constructs, we propose another way to produce quasi-invex loss functions. We present this in Lemma 1 below."
        },
        {
            "heading": "3.4 QUASI-INVEX FIDELITY LOSSES",
            "text": "We finalize the exposition on quasi-invex functions by presenting the following Lemma 1 for constructing a quasi-invex function for f(x). This result states that the maximum of two invex functions (not necessarily with respect to the same \u03b7) is quasi-invex. This lemma has applications in robust optimization or robust imaging problems (Vargas et al., 2018b), where controlling the accuracy of the final solution is crucial. The route to robustness is achieved by minimizing the maximum between two invex functions, which will bound the highest error to a desirable value (Boyd et al., 2004, Section 1.2.2). The proof of this lemma is deferred to Appendix E. Lemma 1. Let f, h : Rn \u2192 R be two invex functions as in Definition 2 (not necessarily with respect to the same \u03b7). Then, q(x) = max(f(x), h(x)) is quasi-invex."
        },
        {
            "heading": "4 APPLICATIONS",
            "text": "In this section, we demonstrate the use of invex/quasi-invex functions on several applications and guarantees for global optima, which has only been possible for convex functions. To this end, we commence by (1) ensures global optima when f(x), g(x) are admissible functions - missing result\nin the invex literature such as (Pinilla et al., 2022a). The importance of this result, which we prove in Appendix F, lies in the fact that it is the first time that global optima is achieved for a family of invex constrained optimization problems (for the noiseless case \u03f5 = 0). The key to the proof is that both f, g functions are admissible.\nTo complement this result, we provide an extensive list of applications that would directly benefit from the global optima guarantees of (1), and the family of invex/quasi-invex constructs in Theorem 3 summarized in Table 2, and for the reasons of brevity, we selectively discuss three of the important applications. These include two imaging tasks, namely, compressive image restoration and total variation filtering, and two algorithmic applications, namely, extended Alternating Direction Method of Multipliers (ADMM) in Section 4.3, and extended accelerated proximal gradient method (APGM) which we present due to space limitations in Appendix J. Additionally, the extended guarantees of ADMM allows to state the global optimality of solving program (1) when f(x), g(x) are the family of quasi-invex functions introduced in Theorem 3."
        },
        {
            "heading": "4.1 COMPRESSIVE IMAGE RESTORATION",
            "text": "The reconstruction of a signal/image from a compressed set of measurements is essential in a range of scientific domains that rely on the analysis and interpretation of image content (De los Reyes et al., 2017). In this context, program (1) becomes an inverse problem that aims at recovering an image f \u2208 Rn assuming that f has a k-sparse representation \u03b8 \u2208 Rn (k \u226a n non-zero elements) in a basis \u03a8 \u2208 Rn\u00d7n, that is f = \u03a8x, in order to ensure uniqueness under some conditions. Examples of this sparse basis \u03a8 in imaging are the Wavelet (also Haar Wavelet) transform, cosine, and Fourier representations (Foucart & Rauhut, 2013). Hence, one can work with the abstract noisy model y = H\u03a8x = Ax+\u03b7, where \u03b7 is the noise, A encapsulates the product between acquisition matrix H , and \u03a8, with \u21132-normalized columns (Arce et al., 2013; Cande\u0300s & Wakin, 2008). Under this setup, compressive sensing enables the recovery of x using much fewer samples than predicted by the Nyquist criterion (Cande\u0300s & Wakin, 2008). When the regularizer g(x) takes the convex form of \u21131-norm, f(Ax\u2212y) is the \u21132-norm, and when the sampling matrix A satisfies the restricted isometry property (RIP) for any k-sparse vector x \u2208 Rn, i.e., (1\u2212 \u03b42k)\u2225x\u222522 \u2264 \u2225Ax\u222522 \u2264 (1 + \u03b42k)\u2225x\u222522 for \u03b42k < 1 3 (Foucart & Rauhut, 2013, Theorem 6.9), it has been proved that x can be exactly recovered by solving (1) with \u03f5 = 0.\nIt is classically known that (1) has unique solution under convexity assumptions on g(x), and f(Ax \u2212 y) for \u03f5 = 0. We are interested in applying invex and quasi-invex regularizers and fidelity functions. It has been proven that, when g(x) takes the particular invex form in (Pinilla et al., 2022a, Theorem 4), and f(Ax\u2212 y) the \u21132-norm, x can be exactly recovered by program (1) for \u03f5 = 0 (Pinilla et al., 2022a). Below in Theorem 7, we further generalize this result to all the invex/quasi-invex constructs as in Theorem 3 - missing result in the invex literature such as (Pinilla et al., 2022a). Theorem 7. Assume Ax + \u03b7 = y, where x \u2208 Rn is k-sparse, the matrix A \u2208 Rm\u00d7n (m < n) with \u21132-normalized columns that satisfies the RIP condition with \u03b42k < 4\u221a41 , the noise vector \u03b7 satisfies f(Ax \u2212 y) < \u03f5 for \u03f5 > 0 and y \u2208 Rm is a noisy measurement vector. If g(x), and f(x) are admissible functions where g(x) satisfies the triangle inequality (further details in Appendix G), then the solution x\u22c6 of (1) holds \u2225x \u2212 x\u22c6\u22251 \u2264 C\u03b2k,g(x) + D \u221a \u03f5\u03c5f,\u03b7(x), where the constants C,D > 0 depend only on \u03b42k, and \u03b2k,g(x), \u03c5f,\u03b7(x). We show that a similar result holds for quasiinvex constructs as in Theorem 3. In addition, if \u03f5 = 0 then x can be exactly recovered by solving (1) using both invex/quasi-invex constructs.\nThe key to prove Theorem 7 is centred around the properties of invex/quasi-invex constructs in Theorem 3. We present the proof of Theorem 7 in Appendix G. It also includes insights on using Lemma 1 to have more quasi-invex functions, for which Theorem 7 is also valid. We highlight that Theorem 7 is in the same form of convex recovery result (Foucart & Rauhut, 2013, Theorem 6.12), suggesting the effectiveness of our proposed family of invex/quasi-invex functions."
        },
        {
            "heading": "4.2 TOTAL VARIATION FILTERING",
            "text": "Total Variation (TV) regularization is a deterministic technique that safeguards discontinuities in images (Ehrhardt & Betcke, 2016; Selesnick et al., 2020). It is based on the principle that images with sharp edges have high variation while smooth transitions will show low variations (Lin et al., 2019; Liu et al., 2018). These variations are modeled using the first-order difference matrix in Theorem 4 (more details in Appendix B) and have been instrumental on a wide range of image restoration problems, including denoising (Hu & Selesnick, 2020), deblurring (Selesnick et al., 2020), inpainting (Scho\u0308nlieb et al., 2009), infrared super-resolution (Liu et al., 2018), and magnetic resonance imaging (Ehrhardt & Betcke, 2016), among others (Chambolle, 2004).\nMathematically, classical TV regularization of an image u \u2208 Rn is the solution of\nminimize x\u2208Rn\ngTV (x) + 1\n2\u03bb \u2225x\u2212 u\u222522, (11)\nfor \u03bb \u2208 (0, 1] (typical choice in practice), where gTV (x) is the sum of the absolute value differences between adjacent pixel values, i.e., \u21131-norm of differences between adjacent pixel values.By solving for u, TV regularization encourages the output image to have smooth regions while maintaining sharp edges. The main advantage of (11) is that it has no extraneous local minima, and the minimizer is unique (Selesnick et al., 2020). However, owing to the limitations of \u21131-norm (Selesnick et al., 2020; Liu et al., 2018), optimization problem in (11) can have undesirable effects, for example, in denoising, by underestimating signal discontinuities\u2019 amplitudes.\nWe improve program (11) by incorporating the invex/quasi-invex regularizers gTV (x) presented in Theorems 4 and 6 as follows (extensions for two-dimensional in Section B.1). Theorem 8. Consider the optimization problem in (11) for invex and quasi-invex TV regularizers as in Theorems 4, and 6, respectively. Then: 1) The function h(x) = gTV (x) + 12\u03bb\u2225x \u2212 u\u2225 2 2 is convex for a proper range of \u03bb. 2) The resolvent operator (I + \u03bb\u2202gTV )\u22121 is a singleton.\nIt is classically known that the sum of two invex functions (or quasi-invex and invex) is not necessarily invex (Mishra & Giorgi, 2008). Then, the above result is helpful to both the invexity and imaging communities, complementing Theorem 3. We present the proof of Theorem 8 in Appendix H, which uses the fact that any admissible function is point-wise non-increasing when divided by a quadratic mapping. This analysis helps extend the original ADMM algorithm in Section 4.3. A set of mappings called prox-regular or weakly convex, can be found in the literature (Wang et al., 2019b; Rockafellar & Wets, 2009), for which Theorem 8 holds - a function is prox-regular if program (11) is convex for some \u03bb. However, it is crucial to discern a critical disparity between prox-regular functions and admissible mappings. Prox-regularity implies quasi-invexity (proven for the first time in Appendix H). This highlights the intrinsic advantage of admissible functions in attaining global optima, showcasing their prowess in contrast to prox-regular functions."
        },
        {
            "heading": "4.3 EXTENDED ALTERNATING DIRECTION METHOD OF MULTIPLIERS (ADMM)",
            "text": "The ADMM algorithm has a special place in a range of signal restoration and imaging problems under convex settings with linear equality constraints (Boyd et al., 2011). It is particularly favored for handling large-scale problems (Glowinski, 2014) with many constraints given its amenability for parallelization (Boyd et al., 2011). Some notable applications of ADMM include blind ptychography (Li, 2023), phase retrieval (Liang et al., 2017), computer tomography (Wei et al., 2022), unrolling (Xie et al., 2019), and magnetic resonance imaging (Sun et al., 2016).\nThe ADMM method solves problems such as in (1), where the constraint has the form f(Ax \u2212 y) (e.g. Section 4.1), and program (11) which is rewritten using S \u2208 Rm\u00d7n, P \u2208 Rm\u00d7p as\nminimize x\u2208Rn,z\u2208Rp h1(x) + h2(z) subject to Sx+ Pz = y. (12)\nWe provide details on how to cast (1) into program (12 )in Appendix I. To solve (12), we form the scaled augmented Lagrangian as L\u03c1(x, z,v) = h1(x) + h2(z) + \u03c12\u2225Sx + Pz \u2212 y + v\u2225 2 2, where v \u2208 Rm is the dual variable, and \u03c1 > 0. The optimization of L\u03c1(x, z,v) is summarized as\nx(t+1) := argmin x\u2208Rn\n( h1(x) + \u03c1\n2 \u2225Sx+ Pz(t) \u2212 y + v(t)\u222522 ) z(t+1) := argmin\nz\u2208Rp\n( h2(z) + \u03c1\n2 \u2225Sx(t+1) + Pz \u2212 y + v(t)\u222522\n) (13)\nv(t+1) := v(t) + Sx(t+1) + Pz(t+1) \u2212 y.\nThe convergence of the above algorithm is well-known and established for convex h1(x), and h2(z) (Boyd et al., 2011). However, the convergence properties of ADMM are unknown in the quasi-invex (hence invex) space. Here, we extend the ADMM algorithm so that its benefits are available to the signal restoration problems under settings based on Theorem 3, as follows.\nTheorem 9. Let h1(x), h2(z) be admissible functions or quasi-invex constructs in Theorem 3, with \u03c1\u03c3n(S) \u2265 1, and \u03c1\u03c3p(P ) \u2265 1. Assume there exists (x\u2217, z\u2217,v\u2217) for which L\u03c1(x\u2217, z\u2217,v) \u2264 L\u03c1(x\u2217, z\u2217,v\u2217) \u2264 L\u03c1(x, z,v\u2217), for all x, z, and v. Then, equation (13) satisfies: i) Residual \u2225r(t)\u22252 = \u2225Sx(t) + Pz(t) \u2212 y\u22252 \u2192 0 and v(t) \u2192 v\u2217 as t \u2192 \u221e at a rate of O(1/t), where v\u2217 is the dual optimal point; ii) h1(x(t)) + h2(z(t)) approaches the optimal value.\nProof of Theorem 9 relies on Theorem 8 which ensures uniqueness in the estimations of x(t+1), z(t+1) in equation (13). This uniqueness is not obtained by prox-regular functions which highlights the significance of our proposed family of invex/quasi-invex functions. The proof is presented in Appendix I along with applications that satisfy the mild constraints on S,P . Appendix I also provides the proximal solution for the studied invex/quasi-invex functions along with their computational time. These solutions are used to perform the numerical experiments in Section 5."
        },
        {
            "heading": "5 EXPERIMENTAL EVALUATION",
            "text": "We performed three experiments to evaluate the utility of the proposed invex/quasi-invex functions against the state-of-the-art, and we provide only the key results in Table 3. Additional set of results can be found in Appendix K. Across the experiments below we use the following metrics: absolute error (AbsError), peak signal-to-noise ratio (PSNR), root mean square error (RMSE), and structural similarity index measure (SSIM). Lower (higher) values for AbsError and RMSE (PSNR and SSIM) imply better signal restoration quality. In addition to AbsError and RMSE, we have also used square root of the AbsError (SqrtError), and log of the RMSE as additional metrics. Experiment 1: Here, we focus on reconstructing three-dimensional volumes for Computed Tomography (CT). CT is a powerful imaging technique with applications to various domains, including medical and material sciences (Ginat & Gupta, 2014; J\u00f8rgensen et al., 2021). Mathematically, CT is an inverse program modeled as in (1) where the constraint is given by f(Ax \u2212 y) \u2264 \u03f5 with A \u2208 Rm\u00d7n describing the image formation model of the noisy measurements y \u2208 Rm (Xiang et al., 2021). Many model-based recovery algorithms have been proposed to solve (1) using g(x) as the \u21131-norm such as the Iterative Shrinkage/Thresholding Algorithm, ADMM, and Primal-Dual Hybrid Gradient algorithm (Kamilov et al., 2023). However, the performance of the model-based strategies has been overcome by hybrid methods (i.e., unrolled networks) such as the Fast Iterative Shrinkage Thresholding Network (FISTA-Net) (Xiang et al., 2021). Here, we consider FISTA-Net as the state-of-the-art in CT due to its performance and because FISTA-Net solves (1) where g(x) is the convex \u21131-norm and the training loss function f(x) is the \u21132-norm. Then, the invex/quasiinvex regularizers and losses to be tested accordingly in this experiment are equations (3), (9), (10), and equations (4)-(8), respectively. To train FISTA-Net (with invex/quasi-invex functions above), we follow the experimental setting as in (Xiang et al., 2021). The training image dataset contains 2,378 full-dose CT images from eight of ten material sciences objects1. The reference images were reconstructed by iradon operator in MATLAB using all 720 views (Han & Ye, 2018; Jin et al., 2017). The validation set consists of 409 images and 330 slices for the test set. Experiment 2: Here we focus on image spectral reconstruction (ST), which has profound applications in medical imaging, remote sensing, and material sciences (Wang et al., 2023). ST focuses on estimating the spectral reflectance of scenes from a set of RGB images captured at different wavelengths (Cai et al., 2022). Mathematically, spectral imaging is an inverse program modeled as in (1) where the constraint is given by f(Ax \u2212 y) \u2264 \u03f5 with A \u2208 Rm\u00d7n describing the image formation model of the noisy measurements y \u2208 Rm (Arce et al., 2013). Conventional model-based methods adopt hand-crafted priors such as sparsity, total variation, and non-local similarity to regularize the reconstruction procedure Arguello et al. (2023). However, these methods result in poor generalization ability due to convex regularizers like \u21131-norm, and unsatisfactory reconstruction quality (Cai et al., 2022). Deep learning methods such as the Multi-stage Spectral-wise Transformer (MST++) (Cai et al., 2022) has shown to exhibit the best performance because it does not employ regularizer. Originally the fidelity term f(x) of MST++ is the \u21132-norm. Then, the invex losses to be tested here are equations (4)-(8). To train MST++, we followed the setting in (Cai et al., 2022)\n1Acquired with the ISIS Neutron and Muon Source at the Rutherford Appleton Laboratory\nand Appendix K. The image dataset is from (Arad et al., 2022), which contains 1,000 RGB-spectral pairs. This dataset is split into the train, valid, and test subsets in the ratio of 18:1:1.\nExperiment 3: This experiment focuses on solving (11). As we mentioned in Section 4.2 the classical total variation filtering, with global optima guarantees, is defined using the \u21131-norm, then the invex/quasi-invex regularizers to be tested are the TV-regularizer version of \u2113p-quasinorm (TV\u2113p), and equation (3) (Invex TV-LLp) equation (10) (Quasi-invex TV-LLp). We defer the exact details around the ADMM implementation to the supplementary material (Section K). We fixed the number of iterations of the ADMM method to 1,000 for all tested regularizers, and we included the smallest residual value \u2225r(t)\u22252 across iterations to characterize the accuracy of the restored image. The dataset employed here has 40 images1. These images contain the neutron attenuation properties of the object, which helps analyze the material structure. Here, in addition to SSIM, we also use Multi-scale SSIM (MS-SSIM) and residual error of the ADMM (ADMM-residual) as metrics."
        },
        {
            "heading": "6 DISCUSSION, LIMITATIONS AND CONCLUSIONS",
            "text": "In this paper, by defining a family of admissible functions with relevant properties, we identified invex/quasi-invex functions to support real-world signal processing problems - signal restoration. We then provided proof for these functions\u2019 invex/quasi-invex behaviors and global optimality beyond the realm of convexity with their convergence rate(s). Specifically, the breakthrough of Theorem 3 compared with current invex literature lies in that the sum of two proposed invex/quasi-invex functions is also invex/quasi-invex. And the results in Theorem 9 and Appendix J show that both ADMM and APGM methods with invex/quasi-invex losses, are as efficient as solving the wellestablished convex optimization problems.\nWe provided detailed evaluations in Table 3 and Appendix K of these functions in imaging tasks such as computer tomography, spectral imaging, and total-variation regularization. These results show significant benefits of using the proposed family of invex/quasi-invex functions from theoretical and empirical aspects. Specifically, they overcome the performance of convex mappings in terms of reconstruction quality across several relevant metrics and the studied imaging tasks. The superiority of the tested invex/quasi-invex functions is because they provide a more accurate model of the sparsity and abnormal patterns in the data than convex mappings (Sun & Pong, 2022).\nWhile our theoretical analysis to handle signal restoration problems is the first of its kind and performs well on a number of tasks, its applications beyond imaging tasks are yet to be explored. More specifically, the application of these algorithms around deep learning research yet to be explored, which can pave a way to improve several downstream applications, such as low-rank matrix recovery and alike. As a pure algorithm, a number of things can be improved, such as decoupling the \u03b7 from \u03c5f,\u03b7(x), improving the efficiency of the algorithm beyond what ADMM and APGM can offer."
        }
    ]
}