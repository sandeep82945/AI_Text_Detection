{
    "abstractText": "Lipschitz constant estimation plays an important role in understanding generalization, robustness, and fairness in deep learning. Unlike naive bounds based on the network weight norm product, semidefinite programs (SDPs) have shown great promise in providing less conservative Lipschitz bounds with polynomial-time complexity guarantees. However, due to the memory consumption and running speed, standard SDP algorithms cannot scale to modern neural network structures. In this paper, we transform the SDPs for Lipschitz constant estimation into an eigenvalue problem, which aligns with the modern large optimization paradigms based on first-order methods. This is amenable to autodiff frameworks such as PyTorch and TensorFlow, requiring significantly less memory than standard SDP algorithms. The transformation also allows us to leverage various existing numerical techniques for eigenvalue optimization, opening the way for further memory improvement and computational speedup. The essential technique of our eigenvalueproblem transformation is to introduce redundant quadratic constraints and then utilize both Lagrangian and Shor\u2019s SDP relaxations. Numerical examples demonstrate that our technique is more scalable than existing approaches. For networks that existing SDP solvers cannot handle, we improve the Lipschitz constant estimation by up to 58% compared to the weight matrix norm product bound.",
    "authors": [],
    "id": "SP:253f9f22963c769112a593b4baff582bc2083b03",
    "references": [
        {
            "authors": [
                "MOSEK ApS"
            ],
            "title": "The MOSEK optimization toolbox for MATLAB manual",
            "venue": "Version 9.0.,",
            "year": 2019
        },
        {
            "authors": [
                "Alexandre Araujo",
                "Aaron J Havens",
                "Blaise Delattre",
                "Alexandre Allauzen",
                "Bin Hu"
            ],
            "title": "A unified algebraic perspective on lipschitz neural networks",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Alexandre Araujo",
                "Aaron J Havens",
                "Blaise Delattre",
                "Alexandre Allauzen",
                "Bin Hu"
            ],
            "title": "A unified algebraic perspective on lipschitz neural networks",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Peter L Bartlett",
                "Dylan J Foster",
                "Matus J Telgarsky"
            ],
            "title": "Spectrally-normalized margin bounds for neural networks",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2017
        },
        {
            "authors": [
                "Ben Batten",
                "Panagiotis Kouvaros",
                "Alessio Lomuscio",
                "Yang Zheng"
            ],
            "title": "Efficient neural network verification via layer-based semidefinite relaxations and linear cuts",
            "venue": "Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Aharon Ben-Tal",
                "Arkadi Nemirovski"
            ],
            "title": "Lectures on Modern Convex Optimization",
            "venue": "Society for Industrial and Applied Mathematics,",
            "year": 2001
        },
        {
            "authors": [
                "Tong Chen",
                "Jean-Bernard Lasserre",
                "Victor Magron",
                "Edouard Pauwels"
            ],
            "title": "Semialgebraic optimization for lipschitz constants of relu networks",
            "venue": "In Proceedings of the 34th International Conference on Neural Information Processing Systems, NIPS\u201920, Red Hook, NY, USA,",
            "year": 2020
        },
        {
            "authors": [
                "Tong Chen",
                "Jean B Lasserre",
                "Victor Magron",
                "Edouard Pauwels"
            ],
            "title": "Semialgebraic representation of monotone deep equilibrium models and applications to certification",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Steven Diamond",
                "Stephen Boyd"
            ],
            "title": "CVXPY: A Python-embedded modeling language for convex optimization",
            "venue": "Journal of Machine Learning Research,",
            "year": 2016
        },
        {
            "authors": [
                "Lijun Ding",
                "Benjamin Grimmer"
            ],
            "title": "Revisiting spectral bundle methods: Primal-dual (sub) linear convergence rates",
            "venue": "SIAM Journal on Optimization,",
            "year": 2023
        },
        {
            "authors": [
                "Mahyar Fazlyab",
                "Alexander Robey",
                "Hamed Hassani",
                "Manfred Morari",
                "George Pappas"
            ],
            "title": "Efficient and accurate estimation of lipschitz constants for deep neural networks",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Michael Garstka",
                "Mark Cannon",
                "Paul Goulart"
            ],
            "title": "COSMO: A conic operator splitting method for convex conic problems",
            "venue": "Journal of Optimization Theory and Applications,",
            "year": 2021
        },
        {
            "authors": [
                "Christoph Helmberg",
                "Krzysztof C Kiwiel"
            ],
            "title": "A spectral bundle method with bounds",
            "venue": "Mathematical Programming,",
            "year": 2002
        },
        {
            "authors": [
                "Christoph Helmberg",
                "Franz Rendl"
            ],
            "title": "A spectral bundle method for semidefinite programming",
            "venue": "SIAM Journal on Optimization,",
            "year": 2000
        },
        {
            "authors": [
                "Christoph Helmberg",
                "Michael L Overton",
                "Franz Rendl"
            ],
            "title": "The spectral bundle method with secondorder information",
            "venue": "Optimization Methods and Software,",
            "year": 2014
        },
        {
            "authors": [
                "Matt Jordan",
                "Alexandros G Dimakis"
            ],
            "title": "Exactly computing the local lipschitz constant of relu networks",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Jimmy Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "In Yoshua Bengio and Yann LeCun (eds.), 3rd International Conference on Learning Representations,",
            "year": 2015
        },
        {
            "authors": [
                "Alex Krizhevsky",
                "Geoffrey Hinton"
            ],
            "title": "Learning multiple layers of features from tiny images",
            "year": 2009
        },
        {
            "authors": [
                "Cornelius Lanczos"
            ],
            "title": "An iteration method for the solution of the eigenvalue problem of linear differential and integral operators",
            "year": 1950
        },
        {
            "authors": [
                "Fabian Latorre",
                "Paul Rolland",
                "Volkan Cevher"
            ],
            "title": "Lipschitz constant estimation of neural networks via sparse polynomial optimization",
            "venue": "In International Conference on Learning Representations,",
            "year": 2020
        },
        {
            "authors": [
                "Yann LeCun",
                "Corinna Cortes. MNIST handwritten digit database."
            ],
            "title": "URL http://yann",
            "venue": "lecun.com/exdb/mnist/.",
            "year": 2010
        },
        {
            "authors": [
                "Klas Leino",
                "Zifan Wang",
                "Matt Fredrikson"
            ],
            "title": "Globally-robust neural networks",
            "venue": "In International Conference on Machine Learning (ICML),",
            "year": 2021
        },
        {
            "authors": [
                "Claude Lemarechal",
                "Jochem Zowe"
            ],
            "title": "A condensed introduction to bundle methods in nonsmooth optimization. In Algorithms for continuous optimization: the state of the art",
            "year": 1994
        },
        {
            "authors": [
                "Feng-Yi Liao",
                "Lijun Ding",
                "Yang Zheng"
            ],
            "title": "An overview and comparison of spectral bundle methods for primal and dual semidefinite programs",
            "venue": "arXiv preprint arXiv:2307.07651,",
            "year": 2023
        },
        {
            "authors": [
                "Ngoc Hoang Anh Mai",
                "J.B. Lasserre",
                "Victor Magron",
                "Jie Wang"
            ],
            "title": "Exploiting constant trace property in large-scale polynomial optimization",
            "venue": "ACM Trans. Math. Softw.,",
            "year": 2022
        },
        {
            "authors": [
                "Anirudha Majumdar",
                "Georgina Hall",
                "Amir Ali Ahmadi"
            ],
            "title": "Recent scalability improvements for semidefinite programming with applications in machine learning, control, and robotics",
            "venue": "Annual Review of Control, Robotics, and Autonomous Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Takeru Miyato",
                "Toshiki Kataoka",
                "Masanori Koyama",
                "Yuichi Yoshida"
            ],
            "title": "Spectral normalization for generative adversarial networks",
            "venue": "In International Conference on Learning Representations,",
            "year": 2018
        },
        {
            "authors": [
                "Matthew Newton",
                "Antonis Papachristodoulou"
            ],
            "title": "Exploiting sparsity for neural network verification",
            "venue": "Proceedings of the 3rd Conference on Learning for Dynamics and Control,",
            "year": 2021
        },
        {
            "authors": [
                "Brendan O\u2019donoghue",
                "Eric Chu",
                "Neal Parikh",
                "Stephen Boyd"
            ],
            "title": "Conic optimization via operator splitting and homogeneous self-dual embedding",
            "venue": "Journal of Optimization Theory and Applications,",
            "year": 2016
        },
        {
            "authors": [
                "Aditi Raghunathan",
                "Jacob Steinhardt",
                "Percy S Liang"
            ],
            "title": "Semidefinite relaxations for certifying robustness to adversarial examples",
            "venue": "Advances in neural information processing systems,",
            "year": 2018
        },
        {
            "authors": [
                "Andrzej Ruszczynski"
            ],
            "title": "Nonlinear optimization",
            "venue": "Princeton university press,",
            "year": 2011
        },
        {
            "authors": [
                "Kevin Scaman",
                "Aladin Virmaux"
            ],
            "title": "Lipschitz regularity of deep neural networks: Analysis and efficient estimation",
            "venue": "In Proceedings of the 32nd International Conference on Neural Information Processing Systems,",
            "year": 2018
        },
        {
            "authors": [
                "Yusuke Tsuzuku",
                "Issei Sato",
                "Masashi Sugiyama"
            ],
            "title": "Lipschitz-margin training: Scalable certification of perturbation invariance for deep neural networks",
            "venue": "Advances in neural information processing systems,",
            "year": 2018
        },
        {
            "authors": [
                "Ruigang Wang",
                "Ian Manchester"
            ],
            "title": "Direct parameterization of lipschitz-bounded deep networks",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Zi Wang",
                "Gautam Prakriya",
                "Somesh Jha"
            ],
            "title": "A quantitative geometric approach to neural-network smoothness",
            "venue": "In Thirty-Sixth Conference on Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Zi Wang",
                "Somesh Jha",
                "Krishnamurthy (Dj) Dvijotham"
            ],
            "title": "Efficient symbolic reasoning for neuralnetwork verification",
            "venue": "arXiv preprint arXiv:2303.13588,",
            "year": 2023
        },
        {
            "authors": [
                "Zaiwen Wen",
                "Donald Goldfarb",
                "Wotao Yin"
            ],
            "title": "Alternating direction augmented lagrangian methods for semidefinite programming",
            "venue": "Mathematical Programming Computation,",
            "year": 2010
        },
        {
            "authors": [
                "Anton Xue",
                "Lars Lindemann",
                "Alexander Robey",
                "Hamed Hassani",
                "George J. Pappas",
                "Rajeev Alur"
            ],
            "title": "Chordal sparsity for lipschitz constant estimation of deep neural networks",
            "venue": "IEEE 61st Conference on Decision and Control (CDC),",
            "year": 2022
        },
        {
            "authors": [
                "Richard Zhang"
            ],
            "title": "On the tightness of semidefinite relaxations for certifying robustness to adversarial examples",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Yang Zheng",
                "Giovanni Fantuzzi",
                "Antonis Papachristodoulou",
                "Paul Goulart",
                "Andrew Wynn"
            ],
            "title": "Chordal decomposition in operator-splitting methods for sparse semidefinite programs",
            "venue": "Mathematical Programming,",
            "year": 2020
        },
        {
            "authors": [
                "Yang Zheng",
                "Giovanni Fantuzzi",
                "Antonis Papachristodoulou"
            ],
            "title": "Chordal and factor-width decompositions for scalable semidefinite and polynomial optimization",
            "venue": "Annual Reviews in Control,",
            "year": 2021
        },
        {
            "authors": [
                "Liao"
            ],
            "title": "require the penalty parameter to be strictly larger than the trace bound of the semidefinite variable, while our main technical results in Theorem 1 and Theorem 2 allow for the non-strict inequality",
            "venue": "(Liao et al.,",
            "year": 2023
        },
        {
            "authors": [
                "Liao"
            ],
            "title": "Theorem 1 and Theorem 2 directly exploit the neural network structure, and consequently our argument is simpler than those in Liao et al",
            "year": 2023
        },
        {
            "authors": [
                "Raghunathan"
            ],
            "title": "Our work is also partially motivated by Dathathri et al. (2020). We note that the SDP formulations for the robustness verification of neural networks and Lipshcitz estimation are indeed very different. The line of work on robustness verification may give new insights, but it is nontrivial to directly apply those advances",
            "year": 2018
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "The Lipschitz constant of a neural network plays an important role in training stability (Miyato et al., 2018), robustness (Tsuzuku et al., 2018), generalization (Bartlett et al., 2017), etc. Given the fact that computing the Lipschitz constant of a neural network is NP-hard (Scaman & Virmaux, 2018), researchers have attempted to improve upon the naive norm product bound and devise methods to compute tighter and more efficient upper bounds to approximate this Lipschitz constant.\nRecently, researchers have proposed to use semidefinite programming (SDP) to estimate the Lipschitz constant of neural networks (Fazlyab et al., 2019; Wang et al., 2022). LipSDP (Fazlyab et al., 2019) is among the first SDPs that are used to estimate the Lipschitz constant of neural networks and have motivated numerous works on designing smooth network structures and achieving state-of-theart performance on robust networks (Araujo et al., 2023a; Wang & Manchester, 2023). Wang et al. (2022) have drawn the connections between the Lipschitzness estimation problem and the matrix mixed norm problems and hinted that SDP is likely the optimal method to estimate the Lipschitz constant within polynomial time assuming standard complexity theoretical conjectures.\nThough SDPs are convex programs and can be solved by interior point methods (IPMs) within polynomial time (Ben-Tal & Nemirovski, 2001), the memory requirement of IPMs is enormous and cannot scale to modern neural network structures, which contain at least thousands of neurons. If we use general-purpose SDP solvers for LipSDP and cannot improve the scalability, then LipSDP becomes just theoretical and has minor practical impacts. Recently researchers have studied how to improve the scalability of LipSDP (Xue et al., 2022; Newton & Papachristodoulou, 2021). These methods mainly exploit the chordal sparsity contained in SDPs (Zheng et al., 2021), which corresponds to the layerwise structure of neural networks. Chordal sparsity allows us to decompose a large SDP constraint to a set of smaller and coupled ones which might improve efficiency; see Zheng\net al. (2021) for a recent review. However, these methods still cannot scale to practical networks for the standard CIFAR10 dataset (Krizhevsky et al., 2009).\nIn this work, we also aim to improve the scalability of SDPs arising in Lipschitz constant estimation of neural networks. Instead of exploiting chordal sparsity, we transform the SDP of Lipschitz constant estimation into an eigenvalue optimization problem using exact penalty methods (Ruszczynski, 2011). Our nonsmooth eigenvalue perspective is motivated by Dathathri et al. (2020) as well as the advances in large-scale SDP optimization using spectral bundle methods (Helmberg & Rendl, 2000; Ding & Grimmer, 2023; Liao et al., 2023). In addition to the eigenvalue problem transformation, we also provide several performance optimization techniques compatible with the eigenvalue problem. These techniques enable faster eigenvalue estimation for SDPs induced from large networks and provide a good initialization for the first-order subgradient algorithm. Previously, for large networks, we can only estimate the Lipschitz constant using the spectral norm product of weight matrices (Leino et al., 2021). With our initialization, we can recover this bound from the beginning. Because the eigenvalue optimization is iterative, we transform the Lipschitz constant estimation into an incremental optimization process, which is guaranteed to be at least as good as the spectral norm product and can terminate at any time.\nContributions. To summarize, we have made the following contributions:\n\u2022 We introduce a non-smooth eigenvalue formulation for SDPs from the Lipschitz constant of neural networks, which we call EP-LipSDP. This is achieved via exact penalty methods, and we obtain the exact penalty parameter by properly introducing redundant quadratic constraints.\n\u2022 We propose a series of numerical techniques compatible with the eigenvalue optimization, such as eigenvector approximation, sparse matrix multiplication, and analytical initialization. These techniques further improve the running time and convergence of solving the eigenvalue problem.\n\u2022 We implemented the algorithm as LipDiff and evaluated it on practical neural networks. Our evaluation demonstrated that the algorithm significantly improves the memory requirement. For the first time, we scale LipSDP to a practical CIFAR10 neural network.1"
        },
        {
            "heading": "2 RELATED WORK",
            "text": "The Lipchitz constant estimation of neural networks has been extensively studied in many recent works (Scaman & Virmaux, 2018; Fazlyab et al., 2019; Latorre et al., 2020; Jordan & Dimakis, 2020; Wang et al., 2022; Chen et al., 2020; 2021). This problem is in general NP-hard (Scaman & Virmaux, 2018; Jordan & Dimakis, 2020; Wang et al., 2022), and thus an exact estimation of the Lipschitz constant is infeasible in practice. Most scalable techniques are based on certain approximations, and SDP approximations of the Lipschitz constant estimation are usually tight and sometimes induce approximation algorithms (Wang et al., 2022). Thus, it is desirable and important to scale up the SDP-based Lipschitz constant estimation, which can bring practical implications.\nRecently, researchers have proposed techniques to improve the scalability of SDP techniques for neural networks. Xue et al. (2022); Newton & Papachristodoulou (2021); Batten et al. (2021) exploited the chordal sparsity in neural networks and improved the scalability of LipSDP for deep networks. Dathathri et al. (2020) transformed the SDP designed for neural-network verification into an eigenvalue problem and introduced subgradient methods to solve the eigenvalue problem. Our approach is similar to Dathathri et al. (2020). However, Dathathri et al. (2020) solved a different problem and we provide a more general theoretical framework. In the meantime, we develop new optimization techniques tailored specifically for Lipschitz constant estimation, which enables anytime termination with a quality guarantee.\nSince the LipSDP formulation of (Fazlyab et al., 2019), several works (Araujo et al., 2023b; Wang & Manchester, 2023) have proposed direct parameterization of the SDP-based Lipschitz condition for neural network layers. This allows the design of neural networks with prescribed Lipschitz conditions, making them suitable for non-trivial certified accuracy. These approaches have the important advantage of being scalable while still controlling the Lipschitz constant of the network. However, one has to use a specific architecture which is not always possible in a context where networks can be used without having control over the training procedure.\n1Our code is anonymously available at https://github.com/BendingUnit-22/LipDiff.\nAs mentioned above, general-purpose IPMs are not suitable for large-scale SDPs arising in modern neural networks. Improving the scalability of solving SDPs via first-order methods has been a very active research topic (Wen et al., 2010; O\u2019donoghue et al., 2016; Zheng et al., 2020; Garstka et al., 2021); see Majumdar et al. (2020); Zheng et al. (2021) for recent surveys. The formulation in this paper closely follows the perspective of non-smooth eigenvalue formulation, which was pioneered by Helmberg & Rendl (2000). This nonsmooth perceptive is well-suited for applying first-order methods, from vanilla subgradient methods and cutting plane techniques to sophisticated bundle methods (Lemarechal & Zowe, 1994). Helmberg & Rendl (2000) developed a special class of spectral bundle methods for solving this non-smooth eigenvalue formulation of dual SDPs with constant trace constraints. Further developments appeared in Helmberg & Kiwiel (2002); Helmberg et al. (2014). The constant trace property is also investigated in polynomial optimization literature (Mai et al., 2022). Very recently, comprehensive convergence rates of spectral bundle methods have been established in Ding & Grimmer (2023), and a comparison of spectral bundle methods for primal and dual SDPs is discussed in Liao et al. (2023)."
        },
        {
            "heading": "3 BACKGROUND",
            "text": "Notation. We denote the n \u00d7 n identity matrix and the n \u00d7 n zero matrix as In\u00d7n and 0n\u00d7n, respectively. We will omit the subscripts when the dimension is clear from the context. Given a vector v, the notation v \u2265 0 means that all the entries of v are non-negative. We denote the i-th entry of v as vi. In addition, we use the notation diag(v) to denote the diagonal matrix whose (i, i)th entry is equal to vi. For a vector v, \u2225v\u22252 denotes the Euclidean norm of v, i.e., \u2225v\u22252 = \u221a\u2211 vi2. For a matrix M , we use \u2225M\u2225op to denote the operator norm, i.e., the largest singular value of M ."
        },
        {
            "heading": "3.1 A BRIEF REVIEW OF LIPSDP",
            "text": "The LipSDP approach can be formulated in either the primal or dual domain, leading to a pair of SDP conditions for the Lipschitz constant estimation of general neural networks. The original LipSDP was developed in the dual domain (Fazlyab et al., 2019). The primal form of LipSDP was later discussed in Wang et al. (2022; 2023). To illustrate different forms of LipSDP, we first consider the simplest single-layer neural network in the form of f(x) = v\u03c3(Wx+ b0) + b1, where x \u2208 Rnx , W \u2208 Rn\u00d7nx , b0 \u2208 Rn, v \u2208 R1\u00d7n, b1 \u2208 R, and f(x) \u2208 R. Here f is a scalar, and n is the neuron number. The activation \u03c3 is assumed to be slope-restricted on [0, 1]. In the dual domain, the LipSDP (Fazlyab et al., 2019) is formulated as follows:\nmin \u03b6,\u03c4 \u03b6 subject to [\n\u2212\u03b6I WT diag(\u03c4) diag(\u03c4)W \u22122 diag(\u03c4) + vTv\n] \u2aaf 0, \u03c4 \u2265 0,\n(1)\nwhere \u03c4 \u2208 Rn and \u03b6 \u2208 R are the decision variables. The original proof in Fazlyab et al. (2019) is based on the quadratic constraint argument. Given two arbitrary x, x\u2032 \u2208 Rnx , set z = \u03c3(Wx+ b0) and z\u2032 = \u03c3(Wx\u2032 + b0). Denote \u2206x = x\u2032 \u2212 x and \u2206z = z\u2032 \u2212 z. If the matrix inequality (1) holds, we must have [\n\u2206x \u2206z ]T [ \u2212\u03b6I WT diag(\u03c4) diag(\u03c4)W \u22122 diag(\u03c4) + vTv ] [ \u2206x \u2206z ] \u2264 0\nwhich is equivalent to\n\u2225\u2206z\u22252 \u2212 \u03b6 \u2225\u2206x\u22252 + [ \u2206x \u2206z ]T [ 0 WT diag(\u03c4) diag(\u03c4)W \u22122 diag(\u03c4) ] [ \u2206x \u2206z ] \u2264 0.\nThe third term on the left side is non-negative since \u03c3 is slope-restricted on [0, 1] (see Fazlyab et al. (2019, section 2.2) and Wang et al. (2022, section 4) for detailed explanations). Then the sum of the first two terms has to be non-positive, and one has \u2225\u2206z\u2225 \u2264 \u221a \u03b6 \u2225\u2206x\u2225. Hence one just needs to minimize \u03b6 subject to the matrix inequality (1).\nIn the primal side, we let Wi denote the i-th row of W , and one starts with the following problem\nmax |v\u2206z| \u2225\u2206x\u2225\nsubject to (\u2206zi \u2212Wi\u2206x)\u2206zi \u2264 0, \u2200i \u2208 [n],\nwhose solution gives an upper bound for the Lipschitz constant of f due to the fact that \u03c3 is sloperestricted on [0, 1]. Since scaling \u2206x and \u2206z by the same constant always maintains the constraint, one can show that the solution for the above problem is further upper bounded by the optimal value of the following quadratically constrained quadratic program (QCQP):\nmax v\u2206z\nsubject to (\u2206zi \u2212Wi\u2206x)\u2206zi \u2264 0, \u2200i \u2208 [n] \u2225\u2206x\u22252 \u2264 1.\n(2)\nThen Shor\u2019s relaxation of the above QCQP gives the primal form of LipSDP, which is the dual SDP of (1). Specifically, the dual program of Shor\u2019s relaxation of (2) is the following SDP:\nmin \u03b6,\u03c4,\u03b3 \u03b6\nsubject to \u03b3 \u2212 \u03b6 0 v0 \u2212\u03b3I WT diag(\u03c4) vT diag(\u03c4)W \u22122 diag(\u03c4)  \u2aaf 0, \u03b6 \u2265 0, \u03c4 \u2265 0, \u03b3 \u2265 0.\n(3)\nwhich can be shown to give the same Lipschitz upper bound as (1) via Schur complement and some rescaling arguments2; See Wang et al. (2022; 2023) for related arguments.\nThe primal and dual forms of LipSDP give the same solution, which can be extended to the general case where f is a multi-layer network with a vector output; see Fazlyab et al. (2019); Wang et al. (2022; 2023) for details. In this paper, we will show that the solution to the original LipSDP for multi-layer networks (Fazlyab et al., 2019, Theorem 2) can be recovered by another optimization problem with box constraints, and thus can be solved in a scalable and memory-efficient manner."
        },
        {
            "heading": "4 MAIN THEORETICAL RESULTS",
            "text": "The semidefinite constraint in LipSDP is non-trivial to deal with for large-scale problems. One common idea for improving scalability and memory-efficiency is to move the semidefinite constraint into the cost function via the exact penalty method (Ruszczynski, 2011). In this section, we derive the exact penalty form of LipSDP (termed as EP-LipSDP). We show that EP-LipSDP and LipSDP have the same solutions. In addition, EP-LipSDP is an optimization problem with only box constraints and hence can be efficiently solved using first-order methods. To illustrate the essence of our technique, we first present EP-LipSDP for the single-layer setting reviewed in Section 3.1. After that, we present EP-LipSDP for the multi-layer network case."
        },
        {
            "heading": "4.1 EP-LIPSDP FOR SINGLE-LAYER NEURAL NETWORK",
            "text": "Recall that we have f(x) = v\u03c3(Wx+ b0)+ b1, where x \u2208 Rnx , W \u2208 Rn\u00d7nx , b0 \u2208 Rn, v \u2208 R1\u00d7n, b1 \u2208 R, and f(x) \u2208 R. The neural network f : Rnx \u2192 R, has n neurons, and \u03c3 is assumed to be slope-restricted on [0, 1]. A naive way to transform LipSDP to a penalty form is to move the semidefinite constraint in (1) to the cost:\nmin \u03b6\u22650,\u03bb\u22650\n\u03b6 + \u03c1\u03bb+max\n([ \u2212\u03b6I WT diag(\u03c4)\ndiag(\u03c4)W \u22122 diag(\u03c4) + vTv\n]) , (4)\nwhere \u03bb+max(\u00b7) = max(0, \u03bbmax(\u00b7)) with \u03bbmax(\u00b7) denoting the maximum eigenvalue, and \u03c1 > 0 is a penalty parameter (Ruszczynski, 2011, Theorem 7.21). One can then apply first-order methods to\n2Notice that the network f is \u03b6 2 -Lipschitz if the semidefinite constraint in (3) is feasible. Hence the optimal value of (3) corresponds to the product of 2 and the square root of the optimal value of (1). See Appendix E for detailed proofs.\nsolve this new nonsmooth optimization problem (4). However, a crucial issue is that it is unclear how large the penalty parameter \u03c1 has to be such that (4) and (1) can yield the same solution. The key issue here is that the dual form of (1) (which is the Shor\u2019s SDP relaxation of (2)) does not have an explicit trace constraint. Based on the discussion in (Liao et al., 2023, Section 3.2), redundant trace constraints may be used to derive the exact penalty form of SDPs. Next, we will enforce a redundant trace constraint on the dual program of (3) to derive the exact penalty form of LipSDP.\nWe here introduce an explicit trace constraint to the dual program of (1) without affecting its solution. We start by adding redundant constraints into (2) such that its Shor\u2019s SDP relaxation has an explicit trace constraint. Specifically, the constraint in (2) already states \u2225\u2206x\u2225 \u2264 1. Augmenting the inequality (\u2206zi \u2212Wi\u2206x)\u2206zi \u2264 0 leads to a redundant constraint \u2206z2i \u2264 \u2225Wi\u2206x\u2225\n2 \u2264 \u2225Wi\u22252 (one interpretation for this redundant constraint is that \u03c3 is slope-restricted on [0, 1] and hence has to be 1-Lipschitz). Therefore, the following QCQP is feasible if and only if (2) is feasible:\nmax v\u2206z\nsubject to (\u2206zi \u2212Wi\u2206x)\u2206zi \u2264 0, \u2200i \u2208 [n] \u2225\u2206x\u22252 \u2264 1 \u2206z2i \u2264 \u2225Wi\u2225 2 , \u2200i \u2208 [n].\n(5)\nDenote ai = \u2225Wi\u22252. Then Shor\u2019s SDP relaxation of (5) has an explicit trace constraint 1+\u2225\u2206x\u22252+ \u2225\u2206z\u22252 \u2264 2 + \u2211n i=1 aj . One can verify that the dual of the Shor\u2019s SDP relaxation of (5) reads as\nmin \u03b6,\u03bb,\u03c4,\u03b3 \u03b6\nsubject to \u2211nj=1 aj\u03bbj + \u03b3 \u2212 \u03b6 0 v0 \u2212\u03b3I WT diag(\u03c4) vT diag(\u03c4)W \u22122 diag(\u03c4)\u2212 diag(\u03bb)  \u2aaf 0, \u03b6 \u2265 0, \u03bb \u2265 0, \u03c4 \u2265 0, \u03b3 \u2265 0.\n(6)\nHere \u03c4 \u2208 Rn corresponds to the slope-restricted property, \u03bb \u2208 Rn corresponds to the redundant constraints \u2206z2i \u2264 \u2225Wi\u2225 2 2, and \u03b3 corresponds to the constraint \u2225\u2206x\u22252 \u2264 1. Comparing (6) with (3), the only difference is that the redundant variable \u03bb shows up in the (1, 1)-block and (3, 3)-block.\nSince the dual program of (6) has an explicit trace constraint, the penalty formulation of (6) will be exact; see (Liao et al., 2023, Section 3.2) for discussions. For notation convenience, we define\nC := \u2211nj=1 aj\u03bbj + \u03b3 \u2212 \u03b6 0 v0 \u2212\u03b3I WT diag(\u03c4) vT diag(\u03c4)W \u22122 diag(\u03c4)\u2212 diag(\u03bb)  . Now we can transform (6) to its exact penalty form, leading to the following EP-LipSDP:\nmin \u03b6\u22650,\u03bb\u22650,\u03c4\u22650,\u03b3\u22650\n\u03b6 + ( 2 + n\u2211 j=1 aj ) \u03bb+max(C). (7)\nThe penalty parameter is set as 2 + \u2211n\nj=1 aj , which is the trace bound in the dual SDP of (6). This is sufficient for ensuring (6) and (7) to have the same optimal value. In addition, the dual programs of (6) and (3) differ by only a redundant trace constraint. Thus we conclude that EP-LipSDP (7) and the original LipSDP (1) give the same Lipschitz bounds. This leads to the following main result, and its detailed proof is presented in Appendix A. Theorem 1. Let opt1 be the optimal value of Problem (6) and opt2 be the optimal value of Problem (7). In addition, let opt3 be the optimal value of the original LipSDP (1). We have opt1 = opt2 = 2 \u221a\nopt3. Therefore, all three programs give the same Lipschitz bounds.\nWe note that (7) is a nonsmooth problem due to the maximal eigenvalue function. It can be solved via subgradient methods and bundle methods; see Helmberg & Rendl (2000); Ding & Grimmer (2023); Liao et al. (2023). In our case of Lipschitz bound estimation, we can utilize autodiff frameworks like PyTorch to get (sub)gradients of the cost function (7). Thus, this eigenvalue transformation opens the door to applying modern machine learning architectures, numerical algebra, and firstorder techniques such as sparse eigen solvers and iterative subgradient methods. Finally, if we increase the penalty parameter such that \u03c1 > 2 + \u2211n j=1 aj , then we can ensure that the solutions (not just the optimal values) of (6) and (7) are equivalent. See Appendix A for details."
        },
        {
            "heading": "4.2 EP-LIPSDP FOR MULTI-LAYER NEURAL NETWORKS",
            "text": "Next, we present the result for the general multi-layer case. For ease of exposition, we still consider the scalar output case, although the extension to the vector output case is possible. Consider a multi-layer network:\nx(0) = x, x(k) = \u03d5(W (k\u22121)x(k\u22121) + b(k\u22121)) k = 1, . . . , d, f(x) = vx(d) + b(d). (8) Suppose xk \u2208 Rnk . Again, we consider the case that v is a row vector and f is a scalar output. The original LipSDP has the following form:\nmin \u03b6,{\u03c4(k)}dk=1 \u03b6\nsubject to \u039bk = diag(\u03c4 (k)), \u03c4 (k) \u2265 0, \u03c4 (k) \u2208 Rnk , \u03b6 \u2265 0, \u03b6 \u2208 R, \u2212\u03b6I (W (0))T\u039b1 0 \u00b7 \u00b7 \u00b7 0 \u039b1W (0) \u22122\u039b1 . . . . . . ... 0 . . . . . . (W (d\u22122))T\u039bd\u22121 0\n... . . . \u039bd\u22121W (d\u22122) \u22122\u039bd\u22121 (W (d\u22121))T\u039bd 0 0 0 \u039bdW (d\u22121) \u22122\u039bd + vTv\n \u2aaf 0.\n(9) Similar to the equivalent relationship between (1) and (3), we can show that the following SDP can give the same Lipschitz bound to (9):\nmin \u03b6,\u03b3,{\u03c4(k)}dk=1 \u03b6\nsubject to \u03b6 \u2265 0, \u03b3 \u2265 0, \u039bk = diag(\u03c4 (k)), \u03c4 (k) \u2265 0, \u03c4 (k) \u2208 Rnk , for k = 1, \u00b7 \u00b7 \u00b7 , d \u03b3 \u2212 \u03b6 0 0 0 \u00b7 \u00b7 \u00b7 v 0 \u2212\u03b3I (W (0))T\u039b1 0 \u00b7 \u00b7 \u00b7 0 0 \u039b1W (0) \u22122\u039b1 . . . . . . ... 0 0 . . . . . . (W (d\u22122))T\u039bd\u22121 0 ... ...\n. . . \u039bd\u22121W (d\u22122) \u22122\u039bd\u22121 (W (d\u22121))T\u039bd vT 0 0 0 \u039bdW (d\u22121) \u22122\u039bd\n \u2aaf 0.\n(10) Notice (10) can be viewed as the multi-layer extension of (3). Denote the i-th row of W k as W (k)i .\nFor k = 1, \u00b7 \u00b7 \u00b7 , d, denote ckj = \u2225\u2225\u2225W (k\u22121)j \u2225\u2225\u22252 \u00b7 (\u220fk\u22122i=0 \u2225\u2225W (i)\u2225\u22252op) for j = 1, \u00b7 \u00b7 \u00b7 , nk. Then we\ncan use the same argument for the single-layer case to show that 2 + \u2211d\nk=1 \u2211nk j=1 ckj provides an\nexplicit redundant trace constraint to the multi-layer QCQP, and hence can be used to derive the exact penalty formulation of the multi-layer LipSDP. Specifically, we define Sk = diag(\u03bb(k)) with \u03bb(k) \u2265 0 being a vector in Rnk . Then we define\nC =  \u2211 k,j ckj\u03bb (k) j + \u03b3 \u2212 \u03b6 0 0 0 \u00b7 \u00b7 \u00b7 v 0 \u2212\u03b3I (W (0))T\u039b1 0 \u00b7 \u00b7 \u00b7 0 0 \u039b1W (0) \u22122\u039b1 \u2212 S1 . . . . . . ... 0 0 . . . . . . (W (d\u22122))T\u039bd\u22121 0\n... ... . . . \u039bd\u22121W (d\u22122) \u22122\u039bd\u22121 \u2212 Sd\u22121 (W (d\u22121))T\u039bd vT 0 0 0 \u039bdW (d\u22121) \u22122\u039bd \u2212 Sd\n .\n(11) With the above choice of C, we can immediately show the following EP-LipSDP for the multi-layer network case:\nmin \u03b6\u22650,\u03bb(k)\u22650,\u03c4(k)\u22650,\u03b3\u22650\n\u03b6 + ( 2 + d\u2211 k=1 nk\u2211 j=1 ckj ) \u03bb+max(C). (12)\nNow we can use a similar proof for Theorem 1 to show the following result for multi-layer networks.\nTheorem 2. Let opt4 be the optimal value of Problem (10) and opt5 be the optimal value of Problem (12). In addition, let opt6 be the optimal value of the original LipSDP (9). We have opt4 = opt5 = 2 \u221a\nopt6. In other words, all three programs give the same Lipschitz bounds.\nThe proof is similar to the one of Theorem 1 presented in the appendix. Now we have obtained the exact penalty form of LipSDP which can be solved using first-order methods."
        },
        {
            "heading": "5 FURTHER PERFORMANCE OPTIMIZATION",
            "text": "In this section, we study techniques that can further improve the performance in terms of running time and convergence of the algorithm presented in Section 4.\nEigenvalue approximation. We formulate the Lipschitz constant estimation as an eigenvalue problem that is differentiable almost everywhere. Estimating the extreme eigenvalue is an important numerical problem and we have algorithms that are efficient to estimate the extreme value which only compromises a little precision. In this work, we also consider the Lanczos algorithm (Lanczos, 1950) to compute the largest eigenvalue of a matrix as in Dathathri et al. (2020). Lanczos algorithm is an iterative algorithm used to find the extreme eigenvalues of symmetric matrices. It computes a small sub-matrix whose extreme eigenvalues are close to those of the original matrix. One can specify the size of the sub-matrix. The larger the submatrix is, the closer the eigenvalue is to the original value with a cost of higher computational resources.\nSparse matrix multiplication. When using the Lanczos algorithm to compute the extreme eigenvalue of a matrix A, we only need access x \u2192 Ax, instead of the explicit form of A. That is, we only need to know what is Ax for any vector x. This provides further optimization opportunities when using the Lanczos algorithm. Because the matrix considered in this work has a fixed sparse pattern, i.e., it is almost a tridiagonal matrix, which encodes the computation of the neural network. When the network is deep and wide, the SDP constraint matrix is very sparse. Thus, we can implement a native sparse matrix multiplication routine, which can be more efficient when the network is large and deep and the corresponding SDP constraint matrix is very sparse.\nAnalytical initialization. Theoretically, we can initialize the variables randomly and apply gradient descent for infinitely many steps with small step size (learning rate), and the optimization problem would converge to the optimal value. However, if our initial state is close to the optimal solution, we can converge to the optimal value very fast. In fact, we can derive an analytical solution to Equation (11) such that C is negative semidefinite, and this analytical solution recovers the naive matrix norm bound. The main tools to derive this analytical bound are Schur\u2019s complement\u2019s lemma and block matrix inversion formula. We provide this derivation in Appendix B. Notice that a natural corollary of this derivation is that the SDP always produces at least as tight Lipschitz bound as the matrix norm product."
        },
        {
            "heading": "6 EVALUATION AND DISCUSSION",
            "text": "In this section, we conduct several experiments to empirically evaluate the algorithm proposed in this work. The evaluation aims to answer the following research questions: (R1) Does the algorithm produce the same value as the original LipSDP algorithm? (R2) Does the algorithm possess running time and memory advantage compared to LipSDP? (R3) How does each optimization technique contribute to the overall performance of the tool?"
        },
        {
            "heading": "6.1 EXPERIMENTAL DESIGN",
            "text": "We implemented the algorithm and built a tool, naming it LipDiff based on the PyTorch package, because our tool is almost everywhere differentiable and for Lipschitz constant estimation. The pseudocode is described in Appendix C. We use the ADAM optimizer (Kingma & Ba, 2015) as LipDiff\u2019s gradient descent optimizer and tune the number of gradient steps and step size (learning rate) accordingly for each problem. We also implemented a few variants of the algorithm:\n1. LipDiff-Ex is the algorithm using exact eigenvalue instead of the Lanczos approximation."
        },
        {
            "heading": "Datasets Models Product LipSDP LipDiff LipDiff-Ex LipDiff-Dense LipDiff-Rand",
            "text": "2. LipDiff-Dense implements the Lanczos algorithm with explicit matrix multiplication. 3. LipDiff-Rand initializes the algorithm from a random initialization rather than the analytical\nsolution and also implements the Lanczos algorithm in the sparse matrix multiplication way.\nTo summarize, LipDiff uses all the optimization techniques proposed in Section 5. LipDiff-Ex uses the explicit matrix formulation to exactly compute the eigenvalue, thus it is a dense representation, and also it applies the analytical initialization. LipDiff-Dense uses eigenvalue approximation but implements it using the dense matrix multiplication. LipDiff-Rand uses the sparse matrix multiplication to approximate the eigenvalue but initilizes the algorithm with random assignments. We made the following design choice: For the tools using Lanczos algorithm to approximate the maximum eigenvalue, we also include the original constraint to compute the exact eigenvalue, and all the reported numbers come from the exact eigenvalue.\nBaseline. We use two benchmarks to evaluate the tools: 1. Product, the weight matrix norm product, which provides a naive upper bound for the Lipschitz constant of the neural network, and is the only method for large networks (Leino et al., 2021); 2. LipSDP, which is the benchmark that LipDiff wants to compute. We implemented LipSDP (Fazlyab et al., 2019) in the CVXPY package (Diamond & Boyd, 2016) and used the Mosek solver (ApS, 2019) to solve the SDP. The LipSDP is run on CPU and the LipDiff variants are run on GPU.\nWe run the tools on three networks: 1. an MNIST (LeCun & Cortes, 2010) dense network, with a single hidden layer of 128 ReLU nodes; 2. An MNIST convolutional network, with 1 convolutional layer, and 2 fully connected layers; 3. CIFAR10 convolutional network with 3 convolutional layers and 3 fully connected layers. These networks are summarized in Table 1.\nEach of the networks has 10 classes. We will compute the Lipschitz constant of the function corresponding to 8th label as in the evaluation of Wang et al. (2022). For the evaluation, we set the timeout for each experiment to be 10 hours. If the running time is over 10 hours, we will\nterminate the program and report the best number. To answer RQ1 and RQ2, we will compare the performances of LipSDP and LipDiff variants in terms of the results, and memory and running time needed for the computation. To answer RQ3, we will compare the results of LipDiff variants."
        },
        {
            "heading": "6.2 RESULTS AND DISCUSSION",
            "text": "The results of the evaluation are summarized in Table 2.\nRQ1. If we compare the result for MNIST-DNN in table 2, we can find that LipDiff-Ex computes almost the same value as LipSDP does, and LipDiff and LipDiff-Dense produce similar results as\nLipSDP\u2019s value. These results provide an affirmative answer to RQ1, that the eigenvalue formulation computes the same value as LipSDP, as showed in Theorem 1.\nRQ2. In terms of memory consumption, because LipDiff variants are run on GPU while LipSDP is run on CPU with different package implementations, a direct comparison between the numbers is not sensible. However, we can still compare between experiments. Recall that the SDP constraints for MNIST-DNN, MNIST-CNN and CIFAR10-CNN are of sizes 1041 \u00d7 1041, 4021 \u00d7 4021 and 22529 \u00d7 22529. As we can observe from table 2, the memory consumption for LipDiff roughly scales linearly to the size of the SDP constraint. However, for LipSDP, the memory requirement is much more beyond linear. For example, the total memory of the server is 528 GB, 4000 times larger than 118 MB, and LipSDP cannot even work on a network with SDP constraint size 4021 \u00d7 4021, which is roughly 16 times larger than the MNIST-DNN. This comparison establishes the memory efficiency of LipDiff. For running time, because we can tune the number of steps and step size for gradient descent, we can obtain a fairly decent result within a short time. This tuning process offers more flexibility than a closed-form solver.\nRQ3. From all experiments in table 2, we can draw a conclusion that with the analytical solution initialization, LipDiff is consistently better than LipDiff-Random. This is particularly true when the network is large and it is hard for the subgradient method from a bad initial state to converge with many free variables. For approximating extreme eigenvalue using the Lanczos algorithm, we always save significant running time, at a price of a little potential precision loss. When using the sparse matrix representation for matrix multiplication, the benefit is only significant when the network is large enough. For small networks such as the MNIST DNN, matrix multiplication using dense representation is faster than the sparse representation. This is because for small networks, the SDP constraint is almost dense rather than sparse. However, at the scale of the CIFAR10 network, the sparse matrix multiplication can save almost 90% of running time.\nFor memory consumption, we can consistently find that LipDiff-Ex uses least memory and LipDiff uses the most. This comes from our design choice: For the tools using Lanczos algorithm to approximate the maximum eigenvalue, we also include the original constraint to compute the exact eigenvalue. Therefore, the Lanczos tools would compute an extra Lanczos submatrix. The sparse representation will further implement an additional sparse multiplication routine and thus consume even more memory.\nConclusion. Overall, we can conclude that LipDiff is much more memory-efficient than LipSDP. However, without an analytical solution, it is hard for LipDiff to converge from a random initialization. With all the optimization techniques proposed in our work, for the first time, we can estimate the Lipschitz constant of a CIFAR10 scale network, and this estimation is always at least as good as the naive matrix norm bound. Our algorithm can terminate at any time, which further offers more flexibility for users with different time budgets."
        },
        {
            "heading": "A TECHNICAL PROOFS",
            "text": "In this section, we provide the proof details of Theorem 1.\nProof. We first prove opt2 \u2264 opt1. This direction is straightforward. Suppose that an optimal solution to Problem (6) is (\u03b6\u2217, \u03bb\u2217, \u03c4\u2217, \u03b3\u2217). By definition, this solution is also feasible to Problem (7). Furthermore, the corresponding matrix C \u2aaf 0, and thus \u03bb+max(C) = 0. Therefore, we have opt2 \u2264 opt1. We next prove opt1 \u2264 opt2. Suppose an optimal solution to Problem (7) is (\u03b60, \u03c40, \u03bb0, \u03b30). If this solution makes the corresponding matrix C \u2aaf 0, then it is also feasible to Problem (6) with the same cost value 12\u03b6\n0. In this case, we have opt1 \u2264 opt2. If \u03bbmax(C) = \u03b1 > 0, then this solution is not feasible to Problem (6). However, we can construct another optimal solution by exploiting the structure of C. Let\n\u03b3\u2032 = \u03b30 + \u03b1, \u03bb\u2032i = \u03bb 0 i + \u03b1 \u03b6\n\u2032 = \u03b60 + ( 2 + m\u2211 j=1 aj ) \u03b1, \u03c4 \u2032 = \u03c40. (13)\nWe next show that this new solution is optimal for Problem (7) and also feasible for Problem (6). Denote \u039b\u20321 = diag(\u03c4 \u2032), \u039b\u20322 = diag(\u03bb \u2032), \u039b01 = diag(\u03c4 0), and \u039b02 = diag(\u03bb 0). Recall the structure of C and we have \u2211mj=1 aj\u03bb\u2032j + \u03b3\u2032 \u2212 \u03b6 \u2032 0 v0 \u2212\u03b3\u2032I WT\u039b\u20321 vT \u039b\u20321W \u22122\u039b\u20321 \u2212 \u039b\u20322\n =\n\u2211mj=1 aj\u03bb0j + \u03b30 \u2212 \u03b60 0 v0 \u2212\u03b30I WT\u039b01 vT \u039b01W \u22122\u039b01 \u2212 \u039b02 \u2212 \u03b1I \u2aaf 0. Thus, the new solution in (13) is feasible for Problem (6). Furthermore, it is easy to verify that the new solution in (13) has the same cost as the solution (\u03b60, \u03c40, \u03bb0, \u03b30) in Problem (7), which is\n\u03b6 \u2032 2 = \u03b60 2 + 1 2\n( 2 + m\u2211 j=1 aj ) \u03b1.\nWe thus also have opt1 \u2264 opt2. The proof of opt1 = 2 \u221a opt3 can be seen from the equivalence of various forms of LipSDP, i.e. SDP forms (1), (3), and (6). See a detailed proof for the equivalence of (1), (3), and (6) in Appendix E. This finishes the proof.\nUpon choosing \u03c1 > 2+ \u2211n\nj=1 aj as the penalty parameter in Problem (7), one can further show that any optimal solution to (7) makes the corresponding C \u2aaf 0, thus the second case in the proof above never happens. We put this result as a lemma below.\nLemma 1. Let \u03c1 > 2 + \u2211n\nj=1 aj as the penalty parameter in Problem (7). Then any optimal solution to (7) makes the corresponding C \u2aaf 0.\nProof. Let (\u03b60, \u03bb0, \u03c40, \u03b30) be an arbitrary optimal solution to Problem (7). For the sake of deriving contradiction, suppose the corresponding C0 has \u03bbmax ( C0 ) = \u03b1 > 0. We construct another solution (\u03b6 \u2032, \u03c4 \u2032, \u03bb\u2032, \u03b3\u2032) by\n\u03b3\u2032 = \u03b30 + \u03b1, \u03bb\u2032i = \u03bb 0 i + \u03b1, \u03b6 \u2032 = \u03b60 + ( m\u2211 j=1 aj + 2 ) \u03b1, \u03c4 \u2032 = \u03c40. (14)\nThen the corresponding C \u2032 satisfies\nC \u2032 = \u2211mj=1 aj\u03bb\u2032j + \u03b3\u2032 \u2212 \u03b6 \u2032 0 v0 \u2212\u03b3\u2032I W\u22a4\u039b\u20321 v\u22a4 \u039b\u20321W \u22122\u039b\u20321 \u2212 \u039b\u20322  =\n\u2211mj=1 aj\u03bb0j + \u03b30 \u2212 \u03b60 0 v0 \u2212\u03b30I W\u22a4\u039b01 v\u22a4 \u039b01W \u22122\u039b01 \u2212 \u039b02 \u2212 \u03b1I \u2aaf 0. When \u03c1 > 2 + \u2211n j=1 aj , we find that (\u03b6 \u2032, \u03c4 \u2032, \u03bb\u2032, \u03b3\u2032) has the strictly lower cost than (\u03b60, \u03c40, \u03bb0, \u03b30):\n\u03b6 \u2032 2 + \u03c1\u03bb+max(C \u2032) = \u03b60 2 + 1 2\n( 2 + m\u2211 j=1 aj ) \u03b1+ 0 < \u03b60 2 + \u03c1\u03b1 = \u03b60 2 + \u03c1\u03bb+max ( C0 ) ,\nwhich contradicts the optimality of (\u03b60, \u03c40, \u03bb0, \u03b30) to Problem (7)."
        },
        {
            "heading": "B ANALYTICAL SOLUTION FOR THE EIGENVALUE PROBLEM",
            "text": "Let us start with the two-layer network and derive an initial solution to the SDP problem (Equation (7)). We use the SDP for a two-layer network as an example. Recall that\nC = \u2211mj=1 aj\u03bbj + \u03b3 \u2212 \u03b6 0 v0 \u2212\u03b3I WT\u039b1 vT \u039b1W \u22122\u039b1 \u2212 \u039b2  , where \u039b1 = diag(\u03c4), and \u039b2 = diag(\u03bb). Clearly, \u039b2 comes from redundant constraints. Now we can let \u03bb = 0, then we basically reduce C to a similar constraint of LipSDP, then we want to find an analytical solution to\nC = \u03b3 \u2212 \u03b6 0 v0 \u2212\u03b3I WT\u039b1 vT \u039b1W \u22122\u039b1  \u2aaf 0, and minimize \u03b6.\nLet A = [\n\u03b3I \u2212WT\u039b1 \u2212\u039b1W 2\u039b1\n] .\nBy Schur\u2019s complement lemma, to have C \u2aaf 0, we need A \u227b 0 and\n\u03b6 \u2212 \u03b3 \u2212 (0,\u2212v)A\u22121((0,\u2212v))T \u2265 0.\nWe use (A\u22121)22 to denote the second row and second column block matrix of A\u22121.\nAgain, by Schur\u2019s complement lemma, to have A \u227b 0, we need \u03b3 > 0 and\n2\u039b1 \u2212 \u039b1WTW\u039b1/\u03b3 \u2ab0 0.\nWe can set \u039b1 = aI , and \u03b3 = b \u2225W\u22252op:\n2aI \u2212 a 2 b \u2225W\u22252op WTW \u2ab0 a(2\u2212 a b )I.\nThen we need 2b > a.\nFrom the block matrix inversion formula, we have\n(A\u22121)22 = (2T \u2212 TWTWT/\u03b3)\u22121.\nWith the choice of \u039b1 and \u03b3, we have\u2225\u2225(A\u22121)22\u2225\u2225op \u2264 (a(2\u2212 ab ))\u22121 = ba(2b\u2212 a) .\nThen\nv(A\u22121)22v T \u2264 b\na(2b\u2212 a) \u2225v\u22252 .\nTo have \u03b6 \u2212 \u03b3 \u2212 v(A\u22121)22vT \u2265 0, we need\n\u03b6 \u2212 \u03b3 \u2212 b a(2b\u2212 a) \u2225v\u22252 \u2265 0,\nthen we need\n\u03b6 = b \u2225W\u22252op + b\na(2b\u2212 a) \u2225v\u222522 .\nWe can let a = b = \u2225v\u22252\u2225W\u2225op , then we have\n\u03b6 = 2 \u2225W\u2225op \u2225v\u22252 .\nBecause we will divide the \u03b6 by 2, this recovers the naive upper bound of \u21132 Lipshitz constant: \u2225W\u2225op \u2225v\u22252.\nFor general multi-layer networks, the derivation is essentially the same as the two-layer network case. It is a more careful recursive application of Schur\u2019s complement lemma and the block matrix inversion formula. Let us use a three-layer network to taste the recursive structure for multi-layer networks.\nWe have\nC = \u03b3 \u2212 \u03b6 0 0 v0 \u2212\u03b3I WT1 \u039b1 00 \u039b1W1 \u22122\u039b1 W2\u039b2 vT 0 \u039b2W2 \u22122\u039b2  \u2aaf 0 and minimize \u03b6.\nLet\nC1 =  \u03b3I \u2212WT1 \u039b1 0\u2212\u039b1W1 2\u039b1 \u2212W2\u039b2 0 \u2212\u039b2W2 2\u039b2  and\nC2 =\n[ \u03b3I \u2212WT1 \u039b1\n\u2212\u039b1W1 2\u039b1\n] .\nLet\nA1 =  \u03b3I \u2212WT1 \u039b1 0\u2212\u039b1W1 \u039b1 0 0 0 0  and\nA2 = [ 0 0 0 0 \u039b1 \u2212W2\u039b2 0 \u2212\u039b2W2 2\u039b2 ] ,\nso A1 +A2 = C1.\nFrom Schur\u2019s complement, we need\n\u03b6 \u2212 \u03b3 \u2212 (0, 0,\u2212v)C\u221211 (0, 0, v)T \u2265 0\nand C1 \u227b 0. To have C1 \u227b 0, we can have A1 \u2ab0 0 and A2 \u2ab0 0 (We need at least one strict inequality, and our final assignment of the values will achieve this). To have A1 \u2ab0 0, we have \u03b3 > 0 and\n\u039b1 \u2212 \u039b1WT1 W1\u039b1/\u03b3 \u2ab0 0.\nWe can set \u03b3 = a(\u2225W1\u2225op \u2225W2\u2225op)2 and \u039b1 = b \u2225W2\u2225 2 op I:\nb \u2225W2\u22252op I \u2212 b2 \u2225W2\u22252op a \u2225W1\u22252op WT1 W1 \u2ab0 b \u2225W2\u2225 2 op (1\u2212 b a )I.\nTo have A2 \u2265 0, we need b > 0 and\n2\u039b2 \u2212 \u039b2WT2 W2\u039b2/(b \u2225W2\u2225 2 op) \u2ab0 0.\nWe can set \u039b2 = cI:\n2cI \u2212 c 2\nb \u2225W2\u22252op WT2 W2 \u2ab0 c(2\u2212\nc b )I.\nAs a result, we only need b \u2264 a and c \u2264 2b. To have \u03b6 \u2212 \u03b3 \u2212 (0, 0,\u2212v)C\u221211 (0, 0, v)T \u2265 0, we need to use the block inversion formula:\n[C\u221211 ]33 = (\u22122\u039b2 \u2212 (0,\u2212\u039b2W2)C \u22121 2 (0,\u2212\u039b2W2)T)\u22121.\n[C\u221212 ]22 = (2\u039b1 \u2212WT1 \u039b1\u039b1W1/\u03b3)\u22121.\n[C\u221211 ]33 = (2cI \u2212 (\u039b2W2(2\u039b1 \u2212WT\u039b1\u039b1W1/\u03b3)\u22121WT2 \u039b2))\u22121.\u2225\u2225[C\u221211 ]33\u2225\u2225op = \u2225\u2225(2cI \u2212 (\u039b2W2(2\u039b1 \u2212WT1 \u039b1\u039b1W1/\u03b3)\u22121WT2 \u039b2))\u22121\u2225\u2225op \u2264 (2c \u2212 c2 \u2225W2\u22252op (2b \u2225W2\u2225 2 op \u2212 b2 \u2225W2\u2225 2 op /a) \u22121)\u22121.\nNotice that this has recursive inequalities to make the constraint work: \u2225\u2225WTTWT\u2225\u2225\nop \u2264 c \u2225W\u2225op.\nInside each function, we have a \u2212\u25a1 and \u25a1\u22121 to keep the minoration. To have \u03b6 \u2212 \u03b3 \u2212 v(C\u221211 )33vT \u2265 0, we only need\n\u03b6 = a(\u2225W1\u2225op \u2225W2\u2225op) 2 + \u2225v\u222522 (2c\u2212 c 2 \u2225W2\u22252op (2b \u2225W2\u2225 2 op \u2212 b 2 \u2225W2\u22252op /a) \u22121)\u22121.\nWe can let a = b = c = \u2225v\u22252\u2225W1\u2225op\u2225W2\u2225op . This would recover the naive bound of \u2225W1\u2225op \u2225W2\u2225op \u2225v\u22252.\nMore generally, if we have a general multiple-layer network, we only need to apply Schur complements and matrix inverse formula recursively: \u2211 (a (i) j )\u03bbj + \u03b3 \u2212 \u03b6 0 0 . . . v 0 \u2212\u03b3I W (1)\u039b1 . . . 0 ... . . . . . . . . . ...\nvT 0 . . . \u039bd\u22121(W d\u22121)T \u22122\u039bd\u22121 \u2212 Sd\u22121  . We can set all S = 0, and for each \u039bj = \u03a0d\u22121i=j+1c \u2225Wi\u2225 2 op, where c =\n\u2225v\u22252 \u03a0d\u22121i=1 c\u2225Wi\u2225op . \u03b3 =\n\u2225v\u22252 \u03a0 d\u22121 i=j+1c \u2225Wi\u2225op, and \u03b6 = 2 \u2225v\u22252 \u03a0 d\u22121 i=1 c \u2225Wi\u2225op."
        },
        {
            "heading": "C PSEUDOCODE OF LIPDIFF",
            "text": "Here we provide the pseudo-code of the LipDiff algorithm (Algorithm 1). Notice that one can substitute the direct ADAM optimizer with more complicated scheduling methods on learning rates and other optimizers such as the stochastic gradient descent optimizer.\nAlgorithm 1 The LipDiff Algorithm Input: The weight matrices [Wi]di=1 of a neural network. Output: The Lipschitz constant of the neural network. Hyperparameters: Number of Iterations n; Lanczos steps l; Step size \u03b1\n1: Declare decision/dual variables as in Equation (11) and assign their values according to Appendix B 2: Create an ADAM optimizer for the dual variables with learning rate \u03b1 3: for n iterations do 4: Create the SDP constraint eq. (11) with [Wi]di=1 and the dual variables. 5: Compute the Lanczos submatrix L of size l \u00d7 l of C 6: Define the loss function as Equation (12) 7: Compute the subgradient of the loss function via autodiff and update the dual variables 8: end for 9: Return the loss value"
        },
        {
            "heading": "D OTHER EXPERIMENTAL SPECIFICATIONS",
            "text": "Server specification. All the experiments are run on a server with thirty-two AMD EPYC 7313P 16-core processors, 528 GB of memory, and four Nvidia A100 GPUs. Each GPU has 80 GB of memory.\nTraining specification. We train all the networks with the SGD optimizer with a learning rate 0.02, momentum 0.9, and weight decay of 0.0008. We train MNIST networks for 50 epochs, and CIFAR10 networks for 200 epochs.\nLipDiff specifications. For LipDiff, we apply the interval scheduling of step sizes. We divide the number of iterations into n groups. Within each group, we start from a step size \u03b1 and exponentially decay the step size to \u03b1/10.\nFor MNIST-DNN, we run LipDiff for a total of 1000 iterations, and divide the 1000 iterations into 2 groups. The step size is initialized to 0.04. We use Lanczos steps 15.\nFor MNIST-CNN, we run LipDiff for a total of 2000 iterations, and divide the 1000 iterations into 4 groups. The step size is initialized to 0.05. We use Lanczos steps 30.\nFor CIFAR10-CNN, we run LipDiff for a total of 2000 iterations, and divide the 2000 iterations to 5 groups. The step size is initialized to 0.06. We use Lanczos steps 50."
        },
        {
            "heading": "E ON THE EQUIVALENCE OF DIFFERENT FORMS OF LIPSDP",
            "text": ""
        },
        {
            "heading": "E.1 ON THE EQUIVALENCE OF SDP FORMS (1) AND (3)",
            "text": "In this section, we establish the equivalence between (1) and (3). To make our proof more readable, we slightly change the notation of (1). Specifically, (1) is exactly the same as the following problem:\nmin \u03b6\u0302,\u03c4\u0302 \u03b6\u0302 subject to [\n\u2212\u03b6\u0302I WT diag(\u03c4\u0302) diag(\u03c4\u0302)W \u22122 diag(\u03c4\u0302) + vTv\n] \u2aaf 0, \u03c4\u0302 \u2265 0,\n(15)\nWe restate (3) below min \u03b6,\u03c4,\u03b3 \u03b6\nsubject to \u03b3 \u2212 \u03b6 0 v0 \u2212\u03b3I WT diag(\u03c4) vT diag(\u03c4)W \u22122 diag(\u03c4)  \u2aaf 0, \u03b6 \u2265 0, \u03c4 \u2265 0, \u03b3 \u2265 0.\n(16)\nNext, we will prove the following result which establishes the equivalence of (15) and (16).\nProposition 1. Denote the optimal values of (15) and (16) as \u03b6\u0302\u2217 and \u03b6\u2217, respectively. Then \u03b6\u2217 =\n2 \u221a \u03b6\u0302\u2217. Proof. If v = 0, then we trivially have \u03b6\u2217 = 2 \u221a\n\u03b6\u0302\u2217 = 0. For the rest of the proof, we assume that v is not a zero vector. In this case, any feasible solution to (16) implies that \u03b3 \u2212 \u03b6 < 0. By Schur complement, (16) is equivalent to the following problem:\nmin \u03b6,\u03c4,\u03b3 \u03b6 subject to [\n\u2212\u03b3I WT diag(\u03c4) diag(\u03c4)W \u22122 diag(\u03c4) + 1\u03b6\u2212\u03b3 v Tv\n] \u2aaf 0,\n\u03b3 < \u03b6, \u03b6 \u2265 0, \u03c4 \u2265 0, \u03b3 \u2265 0.\n(17)\nIn other words, the optimal solution for (17) is also given by \u03b6\u2217. Let (\u03b6\u0302\u2217, \u03c4\u0302\u2217) be the optimal feasible point for (15). If we choose \u03b3 = \u221a \u03b6\u0302\u2217, \u03b6 = 2\u03b3 = 2 \u221a \u03b6\u0302\u2217, and\n\u03c4 = \u03b3\u03c4\u0302\u2217 = \u221a \u03b6\u0302\u2217\u03c4\u0302\u2217, then we have[\n\u2212\u03b3I WT diag(\u03c4) diag(\u03c4)W \u22122 diag(\u03c4) + 1\u03b6\u2212\u03b3 v Tv\n] =\n1\u221a \u03b6\u0302\u2217\n[ \u2212\u03b6\u0302\u2217I WT diag(\u03c4\u0302\u2217)\ndiag(\u03c4\u0302\u2217)W \u22122 diag(\u03c4\u0302\u2217) + vTv\n] \u2aaf 0.\nTherefore, the above choice of (\u03b3, \u03b6, \u03c4) must be a feasible point for (17). Consequently, the optimal value of (17) must be upper bounded by the value of \u03b6 in this feasible point, which is \u03b6 = 2\u03b3 =\n2 \u221a \u03b6\u0302\u2217. Therefore, we have \u03b6\u2217 \u2264 2 \u221a \u03b6\u0302\u2217\nNext, we show \u03b6\u2217 \u2265 2 \u221a \u03b6\u0302\u2217. Let us introduce the following problem\nmin \u03b6,\u03c4,\u03b3\n2 \u221a \u03b3(\u03b6 \u2212 \u03b3)\nsubject to [\n\u2212\u03b3I WT diag(\u03c4) diag(\u03c4)W \u22122 diag(\u03c4) + 1\u03b6\u2212\u03b3 v Tv\n] \u2aaf 0,\n\u03b3 < \u03b6, \u03b6 \u2265 0, \u03c4 \u2265 0, \u03b3 \u2265 0.\n(18)\nThis problem has the same feasible set as (17). Note that, for any point in the feasible set, we must have 2 \u221a \u03b3(\u03b6 \u2212 \u03b3) \u2264 \u03b6 (this is equivalent to \u03b62 \u2212 4\u03b6\u03b3 + 4\u03b32 \u2265 0). Therefore, considering the same feasible point, the objective function of (18) is always upper bounded by the objective function of (17). Denote the optimal solutions of (18) and (17) as (\u03b6\u2020, \u03c4 \u2020, \u03b3\u2020) and (\u03b6\u2217, \u03c4\u2217, \u03b3\u2217), respectively. Clearly, (\u03b6\u2217, \u03c4\u2217, \u03b3\u2217) is also a feasible point for (18). Then we must have\n2 \u221a \u03b3\u2020(\u03b6\u2020 \u2212 \u03b3\u2020) \u2264 2 \u221a \u03b3\u2217(\u03b6\u2217 \u2212 \u03b3\u2217) \u2264 \u03b6\u2217. (19)\nFinally, if we choose \u03c4\u0302 = (\u03b6\u2020 \u2212 \u03b3\u2020)\u03c4 \u2020 and \u03b6\u0302 = \u03b3\u2020(\u03b6\u2020 \u2212 \u03b3\u2020). Then we have[ \u2212\u03b6\u0302I WT diag(\u03c4\u0302)\ndiag(\u03c4\u0302)W \u22122 diag(\u03c4\u0302) + vTv\n] = (\u03b6\u2020 \u2212 \u03b3\u2020) [ \u2212\u03b3\u2020I WT diag(\u03c4 \u2020)\ndiag(\u03c4 \u2020)W \u22122 diag(\u03c4 \u2020) + 1 \u03b6\u2020\u2212\u03b3\u2020 v Tv\n] \u2aaf 0\nTherefore, this choice of (\u03b6\u0302, \u03c4\u0302) gives a feasible point for (15), and we have\n\u03b6\u0302\u2217 \u2264 \u03b6\u0302 = \u03b3\u2020(\u03b6\u2020 \u2212 \u03b3\u2020). (20)\nA trivial combination of (19) and (20) leads to the desired conclusion \u03b6\u2217 \u2265 2 \u221a \u03b6\u0302\u2217.\nTo summarize, we have established that \u03b6\u2217 = 2 \u221a \u03b6\u0302\u2217. Our proof is now complete.\nRemark 1. The above proof gives the right scaling between \u03b6\u2217 and \u03b6\u0302\u2217. Now we provide a more intuitive treatment to explain how the factor of 2 appears in the scaling. Specifically, as mentioned in our main paper, if the semidefinite constraint in (3) is feasible, then the neural network is \u03be2 - Lipschitz. Now we provide a proof for this fact. Recall that we have f(x) = v\u03c3(Wx + b0) + b1, where f(x) is a scalar. Obviously, the tightest Lipschitz bound is given by\nLmin = max x\u2032,x |f(x\u2032)\u2212 f(x)| \u2225x\u2032 \u2212 x\u2225 . (21)\nFor any L \u2265 Lmin, we have |f(x\u2032) \u2212 f(x)| \u2264 L\u2225x\u2032 \u2212 x\u2225 \u2200x\u2032, x. By using the slope-restricted property of \u03c3, one upper bound for Lmin is provided by the solution of the following problem which basically replaces \u03c3 with the quadratic constraint in Fazlyab et al. (2019, section 2.2):\nmax \u2206x,\u2206z |v\u2206z| \u2225\u2206x\u2225 s. t. [ W\u2206x \u2206z ]T [ 0 diag(\u03c4) diag(\u03c4) \u22122 diag(\u03c4) ] [ W\u2206x \u2206z ] \u2265 0, (22)\nwhere \u2206z = \u03c3(Wx\u2032 + b0)\u2212 \u03c3(Wx+ b0), \u2206x = x\u2032 \u2212 x, and \u03c4 is any vector whose entrieis are all non-negative. If we scale \u2206x and \u2206v with a common factor, the constraint in (22) is maintained, and the cost remains unchanged . Therefore, (22) is equivalent to the following problem\nmax \u2206x,\u2206z v\u2206z s. t. [ W\u2206x \u2206z ]T [ 0 diag(\u03c4) diag(\u03c4) \u22122 diag(\u03c4) ] [ W\u2206x \u2206z ] \u2265 0, \u2225\u2206x\u2225 = 1.\nNotice that the absolute value in the objective is removed due to the fact that scaling (\u2206x,\u2206z) with \u22121 does not affect feasibility. If we replace the equality constraint \u2225\u2206x\u2225 = 1 with an inequality constraint \u2225\u2206x\u2225 \u2264 1, then we get the following problem whose solution is an upper bound for (22).\nmax \u2206x,\u2206z v\u2206z s. t. [ W\u2206x \u2206z ]T [ 0 diag(\u03c4) diag(\u03c4) \u22122 diag(\u03c4) ] [ W\u2206x \u2206z ] \u2265 0, \u2225\u2206x\u2225 \u2264 1. (23)\nDenote the optimal value of the above problem as Lu. Then Lu is an upper bound for Lmin. It is obvious that any upper bound for Lu will also be Lmin. Next, we will show that if the semidefinite constraint in (3) is feasible, then we have \u03b62 \u2265 L\nu \u2265 Lmin, and hence f is \u03b62 -Lipschitz. Specifically, if the semidefinite constraint in (3) is feasible, we immediately have[\n1 \u2206x \u2206z ]T \u03b3 \u2212 \u03b6 0 v0 \u2212\u03b3I WT diag(\u03c4) vT diag(\u03c4)W \u22122 diag(\u03c4) [ 1\u2206x \u2206z ] \u2264 0\nwhich leads to \u03b3(1\u2212 \u2225\u2206x\u22252) + 2v\u2206z \u2212 \u03b6 + [ \u2206x \u2206z ]T [ 0 WT diag(\u03c4) diag(\u03c4)W \u22122 diag(\u03c4) ] [ \u2206x \u2206z ] \u2264 0\nUnder the constraints in (23), we have \u2225\u2206x\u2225 \u2264 1 and[ \u2206x \u2206z ]T [ 0 WT diag(\u03c4) diag(\u03c4)W \u22122 diag(\u03c4) ] [ \u2206x \u2206z ] \u2265 0.\nTherefore, we must have v\u2206z \u2264 \u03b62 and \u03b6 2 becomes an upper bound of L u. This leads to the conclusion that f is \u03b62 -Lipschitz. The factor of 2 is due to v\u2206z +\u2206z\nTvT = 2v\u2206 for the scalar output case."
        },
        {
            "heading": "E.2 ON THE EQUIVALENCE OF SDP FORMS (3) AND (6)",
            "text": "In this section, we establish the equivalence between (3) and (6). Formally, we have the following result.\nProposition 2. Denote the optimal values of (3) and (6) as \u03b6\u2217 and \u03b6\u2021, respectively. Then we have \u03b6\u2217 = \u03b6\u2021.\nProof. First, we will prove \u03b6\u2217 \u2265 \u03b6\u2021. Suppose the optimal feasible point for (3) is given by (\u03b6\u2217, \u03c4\u2217, \u03b3\u2217). Then we can choose \u03b6 = \u03b6\u2217, \u03c4 = \u03c4\u2217, \u03b3 = \u03b3\u2217, and \u03bb = 0, which gives a feasible point for (6). Then this feasible point whose value is exactly \u03b6\u2217 gives an upper bound for the optimal value of (6). Consequently, we must have \u03b6\u2217 \u2265 \u03b6\u2021. Next, we will prove \u03b6\u2217 \u2264 \u03b6\u2021. Suppose the optimal feasible point for (6) is given by (\u03b6\u2021, \u03bb\u2021, \u03c4 \u2021, \u03b3\u2021). Then we choose \u03b6 = \u03b6\u2021, \u03c4 = \u03c4 \u2021 + \u03bb\u2021, and \u03b3 = \u03b3\u2021 + \u2211n j=1 aj\u03bb \u2021 j , and show this gives a feasible point for (3) which has the value \u03b6\u2021. To show that our choice gives a feasible point for (3), we only need to verify that the following matrix inequality holds for our choice of (\u03b6, \u03c4, \u03b3):\u03b3 \u2212 \u03b6 0 v0 \u2212\u03b3I WT diag(\u03c4)\nvT diag(\u03c4)W \u22122 diag(\u03c4)  \u2aaf 0 (24) To verify (24), we can perform the following calculation:\u03b3 \u2212 \u03b6 0 v0 \u2212\u03b3I WT diag(\u03c4)\nvT diag(\u03c4)W \u22122 diag(\u03c4)  =\n\u03b3\u2021 +\u2211nj=1 aj\u03bb\u2021j \u2212 \u03b6\u2021 0 v0 \u2212(\u03b3\u2021 +\u2211nj=1 aj\u03bb\u2021j)I WT diag(\u03c4 \u2021 + \u03bb\u2021) vT diag(\u03c4 \u2021 + \u03bb\u2021)W \u22122 diag(\u03c4 \u2021 + \u03bb\u2021)  =\n\u03b3\u2021 +\u2211nj=1 aj\u03bb\u2021j \u2212 \u03b6\u2021 0 v0 \u2212\u03b3\u2021I WT diag(\u03c4 \u2021) vT diag(\u03c4 \u2021)W \u22122 diag(\u03c4 \u2021)\u2212 diag(\u03bb\u2021) + 0 0 00 \u2212(\u2211nj=1 aj\u03bb\u2021j)I WT diag(\u03bb\u2021) 0 diag(\u03bb\u2021)W \u2212diag(\u03bb\u2021)  where the first term is known to be negative semidefinite due to the fact that (\u03b6\u2021, \u03bb\u2021, \u03c4 \u2021, \u03b3\u2021) gives a feasible point for (6). Therefore, (24) holds as desired if we can show that the second term is also negative semidefinite. By Schur complement, this is equivalent to verifying\n\u2212( n\u2211\nj=1\naj\u03bb \u2021 j)I +W T diag(\u03bb\u2021)W \u2aaf 0\nSince we have WT diag(\u03bb\u2021)W = \u2211n\nj=1 \u03bb \u2021 jW T j Wj , we only need to verify\n\u2212( n\u2211\nj=1\naj\u03bb \u2021 j)I + n\u2211 j=1 \u03bb\u2021jW T j Wj \u2aaf 0\nSince aj = \u2225Wj\u22252, we do have \u03bb\u2021jWTj Wj \u2aaf \u03bb \u2021 jajI for all j. This leads to the desired conclusion that (24) holds. Therefore, we have obtained a feasible point for (3) which gives the value \u03b6\u2021, and the optimal value of (3) can only be smaller than or equal to \u03b6\u2021. This proves \u03b6\u2217 \u2264 \u03b6\u2021. To summarize, we must have \u03b6\u2217 = \u03b6\u2021, and hence (3) and (6) are equivalent."
        },
        {
            "heading": "F ADDITIONAL EXPERIMENTAL RESULTS",
            "text": "We provide more experiments on two additional architectures on MNIST that the LipSDP-MOSEK solver can handle: 1. A single hidden layer with 512 hidden nodes (denoted as WIDE); 2. a twohidden-layer network (denoted as DNN3), and each of the hidden layers has 512 ReLU nodes.\nAdditionally, we provide two new baselines: LB and LipSDP-SCS. For LB, we randomly sampled 500, 000 points from the input space and computed the maximum \u21132 norm of all the gradients induced on these samples, which serve as a lower bound. For SCS, we used the default SCS solver provided by CVXPY to solve the SDP program, with max iterations of 2, 500. Notice that SCS solver cannot scale to the MNIST-CNN network, similar to the MOSEK solver. The specification of MNIST-DNN is included in the main paper.\nThe results are summarized in Table 3."
        },
        {
            "heading": "Datasets Models Product LipSDP-MOSEK LipSDP-SCS LipDiff LipDiff-Ex LipDiff-Dense LipDiff-Rand LB",
            "text": "Notice that we do not know how good the lower bound is because the number of samples is unlikely to be sufficient. For example, even if we only consider the vertices of the input on the [0,1]- hypercube, there would be 2784 vertices for MNIST and 23072 vertices for CIFAR10, which are much greater than 500,000.\nFor SCS, we notice that if we set the max iterations too small (for example, 50), the result can be very unstable. It can return either 0 or inf, which is not useful at all. On MNIST-DNN3, SCS provided a value smaller than the MOSEK solver, which we do not know whether it is a valid upper bound for the Lipschitz constant. However, LipDiff always returns a valid upper bound.\nOn the other hand, because the network is relatively small compared to CNNs, computing exact eigenvalue and using the dense representation of the matrix is more efficient than the sparse representation. The results from LipDiff-Ex and LipDiff-Dense are more desirable. However, because the main goal of LipDiff is to scale LipSDP to huge networks that the general SDP solver cannot handle at all, sparse representation and the Lanczos approximation would be more appropriate for these cases, as shown in Table 2."
        },
        {
            "heading": "G FURTHER DISCUSSIONS AND EXPLANATIONS",
            "text": ""
        },
        {
            "heading": "G.1 TECHNICAL NOVELTY OF OUR WORK",
            "text": "In this section, we clarify the technical novelty of our work.\nAdding redundant trace constraint: To obtain the exact penalty form of LipSDP, we need to add an explicit redundant trace constraint to the primal form of LipSDP. How to add this explicit trace constraint highly depends on the network structure, and there is no general recipe for doing this. We delicately exploit the structure of the neural network to add the redundant trace constraint in a layer-by-layer manner, leading to the first exact penalty form of LipSDP.\nProof techniques beyond Liao et al. (2023); Ding & Grimmer (2023): It is true that our exact penalized SDP formulation is motivated by the recent advances on first-order methods for convex nonsmooth optimization (Liao et al., 2023; Ding & Grimmer, 2023). However, our result is not simply a direct application of their results. In particular, all the existing results from Liao et al. (2023); Ding & Grimmer (2023) require the penalty parameter to be strictly larger than the trace bound of the semidefinite variable, while our main technical results in Theorem 1 and Theorem 2 allow for the non-strict inequality, i.e., our penalty parameter only needs to be larger than or equal to the trace bound. Also, our proofs for Theorem 1 and Theorem 2 directly exploit the neural network structure, and consequently our argument is simpler than those in Liao et al. (2023); Ding & Grimmer (2023). Our proof is also self-contained, while those of Liao et al. (2023); Ding & Grimmer (2023) reply on other technical results, such as strong duality and a general penalized result in Ruszczynski (2011, Theorem 7.21).\nNetwork-dependent tricks for making our algorithm LipDiff work on practical problems: In section 5, we provide further network-dependent tricks for making our method LipDiff work on practical problems. Our tricks include analytically deriving an initialization with nontrivial matrix analysis (see Appendix B) and utilizing the sparse structure of the constraint to faster approximate the maximum eigenvalue. This analytical initialization guarantees that our method is always as good\nas the matrix norm product (which is currently the state-of-the-art technique for estimating Lipschitz bounds of large neural networks) and makes LipDiff practical. From our empirical evaluation, for large networks (MNIST/CIFAR10-CNNs), if we randomly initialize the variables, it is very hard for LipDiff to find a good solution. We propose to initialize from a feasible point that exactly corresponds to the matrix norm product bound, and we leverage matrix analysis tools to derive the analytical form of this initial point. Such a development depends on the network structure, and is completely a new contribution."
        },
        {
            "heading": "G.2 POSSIBILITY OF TIGHTENING LIPSDP",
            "text": "To the best of our knowledge, LipSDP is recognized as the method that can give the least conservative \u21132-Lipschitz upper bound with polynomial time guarantees. On small-scale problems where LipSDP can be efficiently solved, numerically it has been very difficult to find a polynomial-time algorithm that can give less conservative \u21132-Lipschitz upper bounds than LipSDP. Therefore, it is reasonable to focus on how to make LipSDP scalable and memory-efficient. How to tighten LipSDP is beyond the scope of this paper. Tightening LipSDP is an interesting problem and hence should be pursued in the future. In the meantime, given the current redundant trace constraint, tuning the parameter \u03c1 may not be the right way to tighten LipSDP. Specifically, we have theoretically proved that LipSDP with or without the redundant trace constraint (i.e. (3) and (6) in our paper) actually give the same solution (see Appendix E for a detailed proof). It is true that adding redundant constraints can refine the solutions for many SDP relaxations. However, for LipSDP, it is quite unfortunate that the current redundant trace constraint does not refine the solution quality. Consequently, given the current redundant trace constraint, tuning \u03c1 does not seem to be the plausible way to tighten LipSDP. We agree that it is possible to develop other redundant constraints that may be incorporated into the original QCQP formulation to tighten LipSDP. This will be a future direction for us."
        },
        {
            "heading": "G.3 RELATION BETWEEN SDPS IN LIPSCHITZ ESTIMATION AND LOCAL ROBUSTNESS VERIFICATION",
            "text": "We are aware of the recent advances in SDP formulation for the robustness verification of neural networks. One of the early formulations appeared in Raghunathan et al. (2018). Indeed, the highlevel ideas in both robustness verification and Lipschitz constant estimation are very similar: both of them formulate the problems into a QCQP form and then relax the QCQP using standard Lagrangian relaxation or Shor\u2019r relaxation. In principle, if one can formulate a better QCQP form (i.e., adding some effective redundant constraints, see e.g., Batten et al. (2021)), the resulting SDP formulation would provide a better estimation. Some tightness analysis was carried out in Zhang (2020), however, the assumptions therein are very restrictive, which may not hold for practical neural networks. The paper by Dathathri et al. (2020) aims to develop a customized first-order solver to improve the scalability of the SDP in Raghunathan et al. (2018). Our work is also partially motivated by Dathathri et al. (2020). We note that the SDP formulations for the robustness verification of neural networks and Lipshcitz estimation are indeed very different. The line of work on robustness verification may give new insights, but it is nontrivial to directly apply those advances. For example, we have proved that adding some redundant constraints in our formulation does not improve the tightness of the resulting SDP formulation. It is a promising direction to unify the QCQP and SDP formulations and their solutions for both robustness verification and Lipchitz constant estimation."
        },
        {
            "heading": "G.4 RELATED WORK ON POLYNOMIAL OPTIMIZATION",
            "text": "Mai et al. (2022) considers a constant trace property in polynomial optimization. In particular, the variable X satisfies trace(X) = c, which is a constant. Then, Mai et al. (2022) translate this constant trace formulation into an eigenvalue problem via a standard procedure in Helmberg & Kiwiel (2002). However, this property does not hold in LipSDP arising from the Lipschitz constant estimation of neural networks. Indeed, our first theoretical guarantees in Theorem 1 and Theorem 2 offer new exact penalty SDP formulations that are suitable for the application of first-order subgradient methods. Our penalized SDP formulation is motivated by the recent advances in convex nonsmooth optimization (Liao et al., 2023; Ding & Grimmer, 2023). We exploit the problem structure (especially the neural network structure) to provide a simple elegant proof of our main theoretical guarantees in Theorem 1 and Theorem 2.\nG.5 IPM VS FIRST-ORDER METHODS\nNow we discuss the trade-off between accuracy and efficiency for the interior-point methods (IPM) and the first-order methods. The per iteration computation of first-order methods is much cheaper than IPM, while IPM requires much less iterations in total to achieve an \u03f5-solution. To achieve an \u03f5approximate solution, the total iteration number required by IPM is on the order of O(log(1/\u03f5)). For LipDiff, we are applying a subgradient method to solve a convex nonsmooth optimization problem, and the total iteration number needed to get an \u03f5 solution is on the order of O(1/\u03f52). However, for each iteration, the computational/memory efficiency for IPM is much worse than our first-order subgradient method. Let n be the number of nodes in the network, and p be the number of parameters in the network. In general, n < p < n2 and if the network is deep, p << n2. The per iteration memory complexity for IPM is O(n4) and computational complexity is O(n6) (Dathathri et al., 2020). While for our method (LipDiff), the per iteration memory complexity is O(Lp), and per iteration computational complexity is O(Lp), where L is the number of Lanczos iterations used for approximate the maximum eigenvalue. In our evaluation, L ranges from 15 to 50. In practice, Lipschitz estimation of neural networks typically does not require using very small \u03f5, i.e. \u03f5 is typically set to be on the order of 0.1 or at most 0.01. Therefore, we argue that per iteration complexity/efficiency matters more for the Lipschitz estimation problem of larger neural networks. In addition, we have developed the special analytical initialization to reduce the iteration number needed by LipDiff (see Appendix B). This justifies the significance of our contribution."
        },
        {
            "heading": "G.6 COMPARISON WITH COSMO",
            "text": "We have tried COSMO in some additional experiments, and it did not work well. The COSMO solver is implemented in Julia and may be called by the JuMP optimization modeling framework. We implemented LipSDP in Julia with the COSMO solver which gave an accurate solution (identical to MOSEK) for small networks with SDP dim 10 \u00d7 10. Unfortunately, for small MNIST networks of just two layers (resulting in an SDP of dim 800 \u00d7 800), COSMO appears to be unstable and will not converge. Finally, we want to comment that COSMO aims to solve the KKT condition of conic programs, and does not guarantee the returned solution to be valid Lipschitz upper bounds. In contrast, our proposed first-order method LipDiff (EP-LipSDP) guarantees that any value returned by LipDiff is always a valid upper bound higher than or equal to LipSDP\u2019s optimal value, because the iterations of LipDiff naturally correspond to feasible points of LipSDP which directly gives Lipschitz upper bounds."
        },
        {
            "heading": "G.7 CONVEX NONSMOOTH OPTIMIZATION VS. MINIMAX FORMULATION",
            "text": "Here we clarify that we treat EP-LipSDP as a convex nonsmooth optimization problem instead of a minimax problem. For simplicity, we restate the EP-LipSDP problem here as\nmin \u03b6\u22650,\u03bb\u22650,\u03c4\u22650,\u03b3\u22650\nJ(\u03b6, \u03bb, \u03c4, \u03b3) := \u03b6 + ( 2 + n\u2211 j=1 aj ) \u03bb+max(C(\u03b6, \u03bb, \u03c4, \u03b3)).\nwhere C(\u03b6, \u03bb, \u03c4, \u03b3) is defined as\nC(\u03b6, \u03bb, \u03c4, \u03b3) := \u2211nj=1 aj\u03bbj + \u03b3 \u2212 \u03b6 0 v0 \u2212\u03b3I WT diag(\u03c4) vT diag(\u03c4)W \u22122 diag(\u03c4)\u2212 diag(\u03bb)  . Since C is linear in (\u03b6, \u03bb, \u03c4, \u03b3), one can show that J is a convex nonsmooth function of (\u03b6, \u03bb, \u03c4, \u03b3). The nonsmoothness is introduced by the operation \u03bb+max. We emphasize that J is a function of (\u03b6, \u03bb, \u03c4, \u03b3). Although J is nonsmooth, we can still apply the subgradient method with box projection to solve the above problem. Notice that the operation \u03bb+max is not performing a maximization over (\u03b6, \u03bb, \u03c4, \u03b3), and hence we are not solving a minimax problem."
        }
    ],
    "year": 2023
}