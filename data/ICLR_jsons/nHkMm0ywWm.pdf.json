{
    "abstractText": "Conventional causal discovery approaches, which seek to uncover causal relationships among measured variables, are typically sensitive to the presence of latent variables. While various methods have been developed to address this confounding issue, they often rely on strong assumptions about the underlying causal structure. In this paper, we consider a general scenario where measured and latent variables collectively form a partially observed causally sufficient linear system and latent variables may be anywhere in the causal structure. We theoretically show that with the aid of high-order statistics, the causal graph is (almost) fully identifiable if, roughly speaking, each latent set has a sufficient number of pure children, which can be either latent or measured. Naturally, LiNGAM, a model without latent variables, is encompassed as a special case. Based on the identification theorem, we develop a principled algorithm to identify the causal graph by testing for statistical independence involving only measured variables in specific manners. Experimental results show that our method effectively recovers the causal structure, even when latent variables are influenced by measured variables.",
    "authors": [
        {
            "affiliations": [],
            "name": "Songyao Jin"
        },
        {
            "affiliations": [],
            "name": "Feng Xie"
        },
        {
            "affiliations": [],
            "name": "Guangyi Chen"
        },
        {
            "affiliations": [],
            "name": "Biwei Huang"
        },
        {
            "affiliations": [],
            "name": "Zhengming Chen"
        },
        {
            "affiliations": [],
            "name": "Xinshuai Dong"
        },
        {
            "affiliations": [],
            "name": "Kun Zhang"
        }
    ],
    "id": "SP:304acad9495dc5558017bb2223da14e7e88b3e5e",
    "references": [
        {
            "authors": [
                "Jeffrey Adams",
                "Niels Hansen",
                "Kun Zhang"
            ],
            "title": "Identification of partially observed linear causal models: Graphical conditions for the non-gaussian and heterogeneous cases",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Animashree Anandkumar",
                "Daniel Hsu",
                "Adel Javanmard",
                "Sham Kakade"
            ],
            "title": "Learning linear bayesian networks with latent variables",
            "venue": "In International Conference on Machine Learning,",
            "year": 2013
        },
        {
            "authors": [
                "Ruichu Cai",
                "Feng Xie",
                "Clark Glymour",
                "Zhifeng Hao",
                "Kun Zhang"
            ],
            "title": "Triad constraints for learning causal structure of latent variables",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "Venkat Chandrasekaran",
                "Pablo A Parrilo",
                "Alan S Willsky"
            ],
            "title": "Latent variable graphical model selection via convex optimization",
            "venue": "In 2010 48th Annual Allerton Conference on Communication, Control, and Computing (Allerton),",
            "year": 2010
        },
        {
            "authors": [
                "Venkat Chandrasekaran",
                "Sujay Sanghavi",
                "Pablo A Parrilo",
                "Alan S Willsky"
            ],
            "title": "Rank-sparsity incoherence for matrix decomposition",
            "venue": "SIAM Journal on Optimization,",
            "year": 2011
        },
        {
            "authors": [
                "Zhitang Chen",
                "Laiwan Chan"
            ],
            "title": "Causality in linear nongaussian acyclic models in the presence of latent gaussian confounders",
            "venue": "Neural Computation,",
            "year": 2013
        },
        {
            "authors": [
                "David Maxwell Chickering"
            ],
            "title": "Optimal structure identification with greedy search",
            "venue": "Journal of machine learning research,",
            "year": 2002
        },
        {
            "authors": [
                "Myung Jin Choi",
                "Vincent YF Tan",
                "Animashree Anandkumar",
                "Alan S Willsky"
            ],
            "title": "Learning latent tree graphical models",
            "venue": "Journal of Machine Learning Research,",
            "year": 2011
        },
        {
            "authors": [
                "Tom Claassen",
                "Joris Mooij",
                "Tom Heskes"
            ],
            "title": "Learning sparse causal models is not np-hard",
            "venue": "arXiv preprint arXiv:1309.6824,",
            "year": 2013
        },
        {
            "authors": [
                "Diego Colombo",
                "Marloes H Maathuis",
                "Markus Kalisch",
                "Thomas S Richardson"
            ],
            "title": "Learning highdimensional directed acyclic graphs with latent and selection variables",
            "venue": "The Annals of Statistics,",
            "year": 2012
        },
        {
            "authors": [
                "Ruifei Cui",
                "Ioan Gabriel Bucur",
                "Perry Groot",
                "Tom Heskes"
            ],
            "title": "A novel bayesian approach for latent variable modeling from mixed data with missing values",
            "venue": "Statistics and Computing,",
            "year": 2019
        },
        {
            "authors": [
                "Mathias Drton",
                "Shaowei Lin",
                "Luca Weihs",
                "Piotr Zwiernik"
            ],
            "title": "Marginal likelihood and model selection for gaussian latent tree and forest",
            "year": 2017
        },
        {
            "authors": [
                "Karl John Holzinger",
                "Frances Swineford"
            ],
            "title": "A study in factor analysis: The stability of a bi-factor solution",
            "venue": "Supplementary educational monographs,",
            "year": 1939
        },
        {
            "authors": [
                "Patrik O Hoyer",
                "Shohei Shimizu",
                "Antti J Kerminen",
                "Markus Palviainen"
            ],
            "title": "Estimation of causal effects using linear non-gaussian causal models with hidden variables",
            "venue": "International Journal of Approximate Reasoning,",
            "year": 2008
        },
        {
            "authors": [
                "Biwei Huang",
                "Charles Jia Han Low",
                "Feng Xie",
                "Clark Glymour",
                "Kun Zhang"
            ],
            "title": "Latent hierarchical causal structure discovery with rank constraints",
            "venue": "arXiv preprint arXiv:2210.01798,",
            "year": 2022
        },
        {
            "authors": [
                "Aapo Hyv\u00e4rinen",
                "Jarmo Hurri",
                "Patrik O Hoyer"
            ],
            "title": "Independent component analysis",
            "year": 2009
        },
        {
            "authors": [
                "G Karl"
            ],
            "title": "J\u00f6reskog. A general approach to confirmatory maximum likelihood factor analysis",
            "year": 1969
        },
        {
            "authors": [
                "Bohdan Kivva",
                "Goutham Rajendran",
                "Pradeep Ravikumar",
                "Bryon Aragam"
            ],
            "title": "Learning latent causal graphs via mixture oracles",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Lingjing Kong",
                "Biwei Huang",
                "Feng Xie",
                "Eric Xing",
                "Yuejie Chi",
                "Kun Zhang"
            ],
            "title": "Identification of nonlinear latent hierarchical models",
            "venue": "arXiv preprint arXiv:2306.07916,",
            "year": 2023
        },
        {
            "authors": [
                "Erich Kummerfeld",
                "Joseph Ramsey"
            ],
            "title": "Causal clustering for 1-factor measurement models",
            "venue": "In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining,",
            "year": 2016
        },
        {
            "authors": [
                "Takashi Nicholas Maeda",
                "Shohei Shimizu"
            ],
            "title": "Rcd: Repetitive causal discovery of linear nongaussian acyclic models with latent confounders",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2020
        },
        {
            "authors": [
                "Linda K Muth\u00e9n",
                "Bengt Muth\u00e9n"
            ],
            "title": "Mplus user\u2019s guide: Statistical analysis with latent variables, user\u2019s guide",
            "venue": "Muthe\u0301n & Muthe\u0301n,",
            "year": 2017
        },
        {
            "authors": [
                "Judea Pearl"
            ],
            "title": "Probabilistic reasoning in intelligent systems: networks of plausible inference",
            "venue": "Morgan kaufmann,",
            "year": 1988
        },
        {
            "authors": [
                "Yves Rosseel"
            ],
            "title": "lavaan: An r package for structural equation modeling",
            "venue": "Journal of statistical software,",
            "year": 2012
        },
        {
            "authors": [
                "Shohei Shimizu",
                "Patrik O Hoyer",
                "Aapo Hyv\u00e4rinen",
                "Antti Kerminen",
                "Michael Jordan"
            ],
            "title": "A linear non-gaussian acyclic model for causal discovery",
            "venue": "Journal of Machine Learning Research,",
            "year": 2006
        },
        {
            "authors": [
                "Shohei Shimizu",
                "Patrik O Hoyer",
                "Aapo Hyv\u00e4rinen"
            ],
            "title": "Estimation of linear non-gaussian acyclic models for latent factors",
            "year": 2024
        },
        {
            "authors": [
                "Shohei Shimizu",
                "Takanori Inazumi",
                "Yasuhiro Sogawa",
                "Aapo Hyvarinen",
                "Yoshinobu Kawahara",
                "Takashi Washio",
                "Patrik O Hoyer",
                "Kenneth Bollen",
                "Patrik Hoyer"
            ],
            "title": "Directlingam: A direct method for learning a linear non-gaussian structural equation model",
            "venue": "Journal of Machine Learning Research-JMLR,",
            "year": 2011
        },
        {
            "authors": [
                "Ricardo Silva",
                "Richard Scheines",
                "Clark Glymour",
                "Peter Spirtes",
                "David Maxwell Chickering"
            ],
            "title": "Learning the structure of linear latent variable models",
            "venue": "Journal of Machine Learning Research,",
            "year": 2006
        },
        {
            "authors": [
                "Charles Spearman"
            ],
            "title": "Pearson\u2019s contribution to the theory of two factors",
            "venue": "British Journal of Psychology,",
            "year": 1928
        },
        {
            "authors": [
                "Peter Spirtes",
                "Clark Glymour"
            ],
            "title": "An algorithm for fast recovery of sparse causal graphs",
            "venue": "Social science computer review,",
            "year": 1991
        },
        {
            "authors": [
                "Peter Spirtes",
                "Kun Zhang"
            ],
            "title": "Causal discovery and inference: concepts and recent methodological advances",
            "venue": "In Applied informatics,",
            "year": 2016
        },
        {
            "authors": [
                "Peter Spirtes",
                "Christopher Meek",
                "Thomas Richardson"
            ],
            "title": "Causal inference in the presence of latent variables and selection bias",
            "venue": "In Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence,",
            "year": 1995
        },
        {
            "authors": [
                "Peter Spirtes",
                "Clark N Glymour",
                "Richard Scheines"
            ],
            "title": "Causation, prediction, and search",
            "venue": "MIT press,",
            "year": 2000
        },
        {
            "authors": [
                "Chandler Squires",
                "Annie Yun",
                "Eshaan Nichani",
                "Raj Agrawal",
                "Caroline Uhler"
            ],
            "title": "Causal structure discovery between clusters of nodes induced by latent factors",
            "venue": "In Conference on Causal Learning and Reasoning,",
            "year": 2022
        },
        {
            "authors": [
                "Seth Sullivant",
                "Kelli Talaska",
                "Jan Draisma"
            ],
            "title": "Trek separation for gaussian graphical models",
            "year": 2010
        },
        {
            "authors": [
                "Tatsuya Tashiro",
                "Shohei Shimizu",
                "Aapo Hyv\u00e4rinen",
                "Takashi Washio"
            ],
            "title": "Parcelingam: A causal ordering method robust against latent confounders",
            "venue": "Neural computation,",
            "year": 2014
        },
        {
            "authors": [
                "Feng Xie",
                "Ruichu Cai",
                "Biwei Huang",
                "Clark Glymour",
                "Zhifeng Hao",
                "Kun Zhang"
            ],
            "title": "Generalized independent noise condition for estimating latent variable causal graphs",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Feng Xie",
                "Biwei Huang",
                "Zhengming Chen",
                "Yangbo He",
                "Zhi Geng",
                "Kun Zhang"
            ],
            "title": "Identification of linear non-gaussian latent hierarchical structure",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Feng Xie",
                "Biwei Huang",
                "Zhengming Chen",
                "Ruichu Cai",
                "Clark Glymour",
                "Zhi Geng",
                "Kun Zhang"
            ],
            "title": "Generalized independent noise condition for estimating causal structure with latent variables",
            "venue": "arXiv preprint arXiv:2308.06718,",
            "year": 2023
        },
        {
            "authors": [
                "Nevin L Zhang"
            ],
            "title": "Hierarchical latent class models for cluster analysis",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2004
        },
        {
            "authors": [
                "Qinyi Zhang",
                "Sarah Filippi",
                "Arthur Gretton",
                "Dino Sejdinovic"
            ],
            "title": "Large-scale kernel methods for independence testing",
            "venue": "Statistics and Computing,",
            "year": 2018
        },
        {
            "authors": [
                "2016 Ramsey",
                "2019 Cai et al",
                "Xie"
            ],
            "title": "2020) and hierarchical models (Pearl",
            "year": 1988
        },
        {
            "authors": [
                "Xie"
            ],
            "title": "2020) is a more general version that allows multiple parents behind multiple children",
            "year": 2020
        },
        {
            "authors": [
                "Xie"
            ],
            "title": "2022) identify a latent hierarchical structure by using the GIN",
            "year": 2022
        },
        {
            "authors": [
                "Cai"
            ],
            "title": "them after the normal children are settled",
            "year": 2019
        },
        {
            "authors": [
                "Recently",
                "Xie"
            ],
            "title": "2023) extended the original graphical criteria of the GIN condition with the help",
            "year": 2023
        },
        {
            "authors": [
                "Huang"
            ],
            "title": "2022), we permuted the latent variable indices",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Inferring causal relationships from observed data is a popular field within statistics and artificial intelligence. Conventional causal discovery methods, such as the PC algorithm (Spirtes & Glymour, 1991), Greedy Equivalence Search (Chickering, 2002), LiNGAM (Shimizu et al., 2006), are designed to identify causal structures among measured (observed) variables, assuming that no latent variables exist in the causal graph. However, in practice, usually we can not measure all task-related variables, leading to a violation of the no-latent-variable assumption (Spirtes & Zhang, 2016).\nTo estimate causal relationships among measured variables involving latent variables, one line of approaches assumes independent latent confounders and utilizes conditional independence constraints (Spirtes et al., 1995; Colombo et al., 2012; Claassen et al., 2013), or functional causal models and non-Gaussianity (Hoyer et al., 2008; Chen & Chan, 2013; Tashiro et al., 2014; Maeda & Shimizu, 2020). Going beyond this assumption, some approaches allow for causally related latent confounders. These include methods based on measurement models and hierarchical models, distinguished by whether the latent variable\u2019s children are measured or not. In particular, measurement model-based methods typically rely on the Tetrad condition (Silva et al., 2006; Kummerfeld & Ramsey, 2016), non-Gaussianity (Shimizu et al., 2009; Cai et al., 2019; Xie et al., 2020), mixture oracles (Kivva et al., 2021). On the other hand, hierarchical model-based methods have evolved from tree-like structures (Pearl, 1988; Zhang, 2004; Choi et al., 2011; Drton et al., 2017) to more general hierarchical structures (Xie et al., 2022; Huang et al., 2022; Kong et al., 2023). Of particular relevance to us are methods based on the Generalized Independent Noise (GIN) condition (Xie et al., 2020; 2022), which leverage higher-order statistics (beyond the second-order moments in statistics,\nV: A variable V: A set of variables U : An atomic unit U: A set of atomic units \u2225U\u2225: Number of variables PCh: Pure children MS: Measured surrogates\nTable 1: Graph notations. More Details in Appdix. I.\ne.g., skewness, kurtosis, etc. of the data) to improve identifiability in the presence of latent confounders. However, all those methods typically rest on the measurement assumption\u2013that there are no measured variables acting as parents of any latent variables in the underlying causal graph.\nThe aforementioned methods are tailored to specific configurations among measured or latent variables, which limits their practical applicability. In fields like human health, latent genetic factors, for instance, might be influenced by observed environmental factors, subsequently affecting observed host phenotypes. While Adams et al. (2021) established necessary and sufficient conditions for structure identifiability based on overcomplete ICA, it does not have a practical estimation approach and requires knowing the number of latent variables at the beginning. Recently, Squires et al. (2022) presented a method that allows latent variables to be influenced by measured variables, but it still relies on strong assumptions, such as the absence of edges between pairs of observed or latent nodes.\nIn this paper, we target an inclusive scenario involving latent variables, without imposing constraints on their presence and positions. Meanwhile, we seek to strike a delicate balance between theoretical identifiability and practical feasibility. To identify the causal structure within this general scenario, we leverage the linear causal model and non-Gaussianity, giving rise to the proposed Partially Observed Linear Non-Gaussian Acyclic Model (PO-LiNGAM). We demonstrate that, even without prior knowledge of the latent variables, the causal graph is virtually identifiable when each variable conforms to the PO-LiNGAM and each latent set has a sufficient number of pure children. Building upon the identification theorem, we introduce a feasible search algorithm that utilizes the Generalized Independent Noise (GIN) condition in specific manners. The proposed algorithm comprises three iteratively executed phases that sequentially identify latent variables and infer causal relationships among (both latent and measured) variables, progressing from leaf to root variables. The algorithm halts its inference of the higher-level causal structure when the latent set lacks a sufficient number of pure children. This helps to maintain precision and applicability in real-world situations. Furthermore, in cases where there are no latent confounders, our algorithm\u2019s results will reduce to those obtained using LiNGAM-based methods (Shimizu et al., 2006; 2011). Additionally, our algorithm possesses the capability to handle overlapping variables between discovered latent sets, an aspect often overlooked by other methods. Our contributions are summarised as: a.) We consider a broad spectrum of causal structures, regardless of the presence and positions of\nlatent variables, and establish their theoretical identifiability under milder graphical conditions. Figure 1 depicts an illustrated latent graph with several notable characteristics. For instance, the latent variable set {L2,L3} serves not only as hidden confounder for measured variables but also for latent variables, forming a latent hierarchical structure. Additionally, {L3,L4} has its own unique set of pure children, distinct from those of {L2,L3}, though both are influenced by the measured variable {X1}. Latent triangles, such as {X1,L1,X2}, are accommodated as well. b.) We propose an efficient algorithm to estimate the causal structure through a precise application of GIN tests, without prior knowledge of latent variables. Our algorithm infers the causal graph by precisely identifying the pure and impure children."
        },
        {
            "heading": "2 PARTIALLY OBSERVED LINEAR NON-GAUSSIAN ACYCLIC MODEL",
            "text": ""
        },
        {
            "heading": "2.1 MODEL DEFINITION",
            "text": "Precisely, we focus on a partially observed linear non-Gaussian acyclic model where X = {X1, . . . ,Xm} denotes the set of measured variables, L = {L1, . . . ,Ln} denotes the set of latent variables, and V = X\u222aL denotes the total set of variables. Each variable Vi \u2208 V is generated\nwithin a directed acyclic graph (DAG) by the following linear structural equation model: Vi = \u2211 Vj\u2208Pa(Vi) bijVj + \u03b5Vi (1) where Vi and Vj can be either measured or latent variables, Pa(Vi) is the set of parent variables of Vi, bij represents the causal strength from Vj to Vi, and \u03b5Vi represents the noise term of Vi. The noise terms are assumed to be continuous random variables with non-Gaussian distribution, and they are independent of each other. Additionally, without loss of generality, we assume that all variables have zero mean (Otherwise, they can be centered).\nDefinition 1 (Partially Observed Linear Non-Gaussian Acyclic Model (PO-LiNGAM)). A linear graphical model, with its directed acyclic graph G, is called a partially observed linear nonGaussian acyclic model, iff:\n\u2022 Each variable in variable set V is generated by the structural equation model (1). \u2022 The distribution over V is Markov and faithful to the DAG G.\nUnlike the LiNGAM in Shimizu et al. (2006), we allow for the presence of latent variables. As shown in Definition 1, we disregard the specific positions of the measured and latent variables. This means that both measured and latent variables, individually or jointly, can act as parents to other measured or latent variables. It distinguishes our work from previous studies on linear latent models (Silva et al., 2006; Hoyer et al., 2008; Cai et al., 2019; Xie et al., 2020; 2022; Squires et al., 2022; Huang et al., 2022). In this paper, our goal is to establish the identifiability of the PO-LiNGAM causal structure and show how it can be discovered solely from the set of measured variable X."
        },
        {
            "heading": "2.2 GRAPHICAL CONDITION FOR IDENTIFIABILITY: FORMULATION",
            "text": "We now formulate the graphical condition that will be utilized to establish the structural identifiability in Section 3.4. Below, we first give some definitions corresponding to graphical structures.\nDefinition 2 (Pure Child). Let V be the set of all variables that have the common parent variable set P and V \u2229P = \u2205. For any V in V, V is a pure child of P iff V is d-separated from V\\V given the parents P. Similarly, for any subset V of V, V is a pure child of P iff V is d-separated from V\\V given the parents P. Example 1. In Figure 1, {X5}, {X6}, {X7}, {X8} are pure children of {L1, X2}, respectively or in combination. {L1, X2} in combination is a pure child of {X1}. A complex causal graph can be identified by decomposing it into simpler, independent components. This simplifies the analysis by focusing on individual components and their relationships. We now give the definition of the atomic unit which represents the basic building block of causal structures.\nDefinition 3 (Atomic Unit). An atomic unit V is either a single measured variable, or a set of variables V with size \u2225V\u2225 = t \u2265 1 that the following conditions hold:\n\u2022 V contains at least one latent variable. \u2022 V has at least t + 1 atomic units as its pure children, in which in total at least t child\nvariables are contained in the atomic units other than t atomic units, and each of all these pure atomic unit children1 covers all atomic units that share common variables with it. Additionally, when t \u2265 2, V has another atomic unit that either neighbors it or overlaps with it.\n\u2022 V is the minimal set that cannot be decomposed into several smaller atomic units.\nExample 2. In Figure 1, each measured variable is an atomic unit. {L6, L7} is an atomic unit with size t = 2, where in addition to the 2 (note that 2 \u2265 t) pure atomic unit children {X21} and {X22}, the remaining pure atomic unit children {X23} and {X24} in total contain 2 child variables. Furthermore, {L2, L3} is an atomic unit with size t = 2, where in addition to the 2 pure atomic unit children {X10} and {X11}, the remaining pure atomic unit child {L6, L7} contain 2 child variables. However, {L1, X2} is not strictly an atomic unit because it can be decomposed into two smaller atomic units {L1} and {X2}. For measured variables, it is reasonable to examine each variable individually. As for latent variables, linear transitivity allows us to extract their information provided they have a sufficient number\n1It indicates that the pure children themselves are atomic units. The same goes for the following.\nof pure children. Below, for the sake of convenience, we default to considering children at the atomic unit level. It means that when we refer to C as a pure child of P , the premise is that C and P are atomic units. Below is the graphical condition to guarantee identifiability of PO-LiNGAM.\nPO-LiNGAM Identifiability Condition : a.) Any latent variable is in at least one atomic unit. b.) For any two atomic units with overlapping variables, their non-overlapping parts do not influence each other.\nThe first term is the basic condition for identification of latent variables (Xie et al., 2020; Huang et al., 2022). It implies that every latent variable must have measured variables as its descendants. The second term arises because the discovered atomic units may have overlapping variables. In cases where two atomic units share variables, we cannot determine whether the non-overlapping part of one unit causally affects the non-overlapping part of another unit due to insufficient information. Theorem 4 will show the entire causal graph is identifiable at the atomic unit level when the above graphical (identifiability) condition is satisfied."
        },
        {
            "heading": "3 STRUCTURE IDENTIFICATION THROUGH A THREE-PHASE ALGORITHM",
            "text": "In this section, we present our algorithm for structural identification and corresponding theoretical guarantees. Our algorithm is iterative, with each iteration consisting of three phases, progressively uncovering the entire causal graph from leaf to root nodes. Let A be the active atomic unit set consisting of atomic units under investigation, which is initially set to X and updated progressively. Phase I identifies the causal relationships among atomic units in A. Phase II discovers new atomic units from A. Phase III refines the discovered atomic units. After that, A is fed back to phase I, and a new iteration starts until A is not updated. Finally, we simply verify multiple root atomic units by checking the discovered second-highest causal order atomic units (see Appendix C.5).\nAlgorithm 1: The identification procedure of PO-LiNGAM Input: Measured variable set X Output: Causal graph G\n1 Initialize partial causal graph G:= \u2205, active atomic unit set A:= X; 2 while \u2225A\u2225 > 1 and A is updated do 3 (G,A)\u2190 IdentifyLeafNodesAndTheirParents(G,A); // Phase 1 4 (G,A,NewAtomicUnitSet)\u2190 DiscoverNewAtomicUnits(G,A); // Phase 2 5 (G,A)\u2190 RefineAtomicUnits(G,A,NewAtomicUnitSet); // Phase 3 6 end 7 Check for multiple root atomic units (see Appendix C.5); 8 return G"
        },
        {
            "heading": "3.1 PHASE I: IDENTIFYING LEAF NODES AND THEIR PARENTS",
            "text": "Each iteration starts with phase I. In phase I, we deal with the identification of causal structure among atomic units in A by recursively identifying the leaf nodes in the causal graph composed of atomic units in A and their latent confounders. Below, we briefly review the Generalized Independent Noise (GIN) condition (Xie et al., 2020), which is the workhorse for our algorithm.\nDefinition 4 (GIN condition) (Xie et al., 2020). Let Z and Y be sets of variables with zero mean in a linear non-Gaussian acyclic causal model. We say that (Z, Y) follows GIN condition if and only if \u03c9TY is independent of Z, where \u03c9 satisfies \u03c9TE[YZT] = 0 and \u03c9 \u0338= 0. Roughly speaking, if the GIN condition is satisfied, then there is a set of variable P (which can contain variables in Y) of size \u2225P\u2225 < \u2225Y\u2225, which are ascendants of Y and d-separate Y\\P from Z\\P. See Xie et al. (2020) and Appendix F for more details. In a causal graph, for any leaf node variable, it is d-separated from the other variables given its parents. By utilizing the GIN condition and non-Gaussianity, this graphical condition can be statistically linked to the data. To derive the theorem for the general case, we start by considering a scenario in which all variables are measured, meaning there are no latent variables in the causal graph\u2013this corresponds to the case of LiNGAM (Shimizu et al., 2006; 2011).\nProposition 1 (Identifying leaf variables without latent confounders). Let V be a set of variables satisfying PO-LiNGAM with no latent variables, and V be a variable in V. For a set of variable P \u2286 V\\V, V is one of the current leaf variable nodes and P contains all parent variables of V, iff (V\\V,V \u222aP) follows the GIN condition and there is no P\u0303 \u2282 P such that (V\\V,V \u222a P\u0303) follows the GIN condition.\nExample 3. Consider the causal graph in Figure 1 composed of V = {X9,X16,X17,X18}. Let V = X17 and the minimal P = {X16,X18}. ( {X9,X16,X18}, {X17,X16,X18} ) follows the GIN condition, which implies that X17 is the current leaf node, and X16 and X18 are its parents. Removing X17 from V, we can find that X16 is the current leaf node and X9 is its parent.\nIf there are no latent variables, Proposition 1 alone suffices to identify the entire causal graph. We achieve this by recursively identifying the leaf variables and then reconsidering the remaining variables. In practice, however, it is difficult to exhaustively measure and collect all task-related variables (Spirtes et al., 2000). Thanks to the transitivity of linear causal relations, although we cannot directly access to the latent variables, we can use their measured descendants to test GIN conditions.\nDefinition 5 (Surrogate variable & Measured Surrogate Variable set MSa,b). Let P be an atomic unit involving latent variables and atomic unit C \u2208 PCh(P). Surrogate variables of P are the variables in each C or up to \u2225C\u2225 surrogate variables of C. Measured Surrogate variables of P are its surrogate variables that are measured. Measured Surrogate Variable set MSa & MSb of P are two sets of measured surrogate variables, where the minimal set d-separating MSa and MSb is P , and \u2225MSa(P)\u2225 = \u2225MSb(P)\u2225 = \u2225P\u2225. Example 4. In Figure 1, for the atomic unit {L6,L7}, MSa can be {X21,X22} and MSb can be {X23,X24}. For the atomic unit {L2,L3}, MSa can be {X21,X22} and MSb can be {X10,X11}. To harmonize the view, in the following sections, for each measured variable that also serves as an atomic unit, we designate both MSa and MSb to refer to the measured variable itself. We will explain in Phase II how to discover latent atomic units and their measured descendants. Let us now show how the leaf atomic units and their parent atomic units in the causal graph can be identified by utilizing measured surrogate variable sets of each known (measured or latent) atomic unit.\nTheorem 1 (Identifying leaf atomic units). Let U be a set of non-overlapping atomic units satisfying PO-LiNGAM with known MSa,b for each atomic unit in U, and U be an atomic unit in U. For a set of atomic units P \u2286 U\\U , U is one of the current leaf atomic unit nodes and P contains all parent atomic units of U , iff ( MSa(U\\U)2,MSb(U \u222a P) ) follows the GIN condition and there is no P\u0303 \u2282 P\nsuch that ( MSa(U\\U),MSb(U \u222a P\u0303) ) follows the the GIN condition.\nExample 5. Consider the causal graph in Figure 1 composed of U = {{X2}, {X9}, {L5}}. Suppose we know that {L5} is the latent confounder of {X18} and {X19}, meaning that MSa,b({L5}) can be {X18} and {X19}, respectively. ( {X2,X9}, {X2,X19} ) follows the GIN condition, which implies that {L5} is the current leaf node and {X2} is its parent that d-separates it from the other atomic units. Removing {L5} from U, we can find that {X9} is another leaf node and {X2} is its parent. Theorem 1 extends Proposition 1, allowing for the atomic units involving latent variables. In Theorem 1, we make the assumption that each atomic unit does not overlap with other atomic units. However, as shown in Figure 1, {L2,L3} and {L3,L4} are two atomic units with the overlapping variable L3. In our algorithm, during each iteration, Phase III checks for overlap among atomic units after the new atomic units are discovered in Phase II. Below, we propose the complement to Theorem 1 that ensures the theorem\u2019s correctness even in the presence of overlapping atomic units starting from the second iteration onwards.\nRemark 1 (Complement to Theorem 1). In Theorem 1, before testing GIN condition, a.) if any atomic units in U have overlapping variables with U , then we remove them from U and remove them from P if they exist in P. b.) if the atomic units in P overlap with each other, instead of using entire set of MSb(P) for testing, we use its maximal subset S that makes ( MSa(U\\U),S ) does not follow\nGIN condition. Similarly, for P\u0303, instead of using entire MSb(P\u0303) for testing, we use its maximal subset S\u0303 that makes ( MSa(U\\U), S\u0303 ) does not follow GIN condition.\n2MSa(U\\U) denotes the union of MSa of each atomic unit in U\\U . The same goes for the following.\nWe now can infer the causal structure among atomic units in A. Specifically, the atomic units in A and their latent confounders form a causal graph. For any leaf atomic unit of the graph in A, if all its parent atomic units are also in A, it and its parents can be identified by using Theorem 1 and Remark 1. Then, we archive it and remove it from A. The remaining atomic units in A and their latent confounders form a smaller causal graph in which we can continue identifying leaf atomic units. Below, we present the main search procedure of Phase I. The algorithm details can be found in Algorithm 2 (Appendix C.1), which also includes an additional checking and refinement process (lines 8 and 14, Alg. 2) that will be explained in the next subsection.\nPhase I: Identifying Leaf Nodes And Their Parents 1. Start with partial causal graph G and active atomic unit set A. 2. For each atomic unit U in A, test if there is a subset of atomic units P in the A\\U that satisfies\nTheorem 1 with Remark 1. 3. If found, add direct edges from each atomic unit in P to U , and remove U from A. 4. Repeat steps 2 and 3 until no more atomic units can be removed from A. 5. Return G and A.\nExample 6 [An illustration of Phase I]. Consider the causal structure in Figure 1. Suppose that at the beginning, the active variable set is A = {{X1}, . . . , {X26}}. With Phase I, one can know that Pa({X17}) = {{X16}, {X18}}, Pa({X16}) = {X9}, and Pa({X9}) = {X2}."
        },
        {
            "heading": "3.2 PHASE II: DISCOVERING NEW ATOMIC UNITS",
            "text": "After there are no leaf atomic units with their full parents in current A, which can be identified by Phase I, we discover new atomic units by clustering their pure children from A in Phase II. This procedure is achieved by first clustering the child atomic units that have common parents, and then identifying pure children to discover new atomic units.\nTheorem 2 (Clustering atomic units). Let U be a set of non-overlapping atomic units satisfying PO-LiNGAM with known MSa,b for each atomic unit in U, and there is no such leaf atomic unit in U that its full parents are also in U. Let Y \u2286 MSb(Y) be a part of measured surrogate variables of Y, where Y is a subset of U and no Y\u0303 \u2282 Y satisfies Y \u2286 MSb(Y\u0303). The atomic unit set Y have a total of \u2225Y\u2225 \u2212 1 parent variables (including latent variables), denoted as P, which can d-separate Y from U\\(Y\u222aP), if a.) (MSa(U\\Y),Y) follows the GIN condition, b.) there is no subset Y\u0303 \u2282 Y such that (MSa(U\\Y), Y\u0303) follows the GIN condition, and c.) there is no any atomic unit P \u2208 Y such that (MSa(P \u222a U\\Y),Y) follows the GIN condition. Example 7. Consider the causal graph in Figure 1 composed of U = {{X2}, {X3}, . . . , {X8}}. We can find five Y clusters that satisfy Theorem 2, i.e., Y1 = {{X3}, {X4}}, Y2 = {{X5}, {X6}, {X7}}, Y3 = {{X5}, {X6}, {X8}}, Y4 = {{X5}, {X7}, {X8}}, and Y5 = {{X6}, {X7}, {X8}}. Similar to Theorem 1, Theorem 2 focus on the non-overlapping atomic units. Furthermore, for two overlapping atomic units, if one atomic unit is entirely covered by another, the parents of the covered atomic unit must be a subset of or identical to the parents of the covering atomic unit. To leverage the covering atomic unit, we introduce a complement to Theorem 2, which extends its applicability to overlapping atomic units.\nRemark 2 (Complement to Theorem 2) . In Theorem 2, before testing GIN conditions, if any atomic units in U is completely covered by any one atomic unit in Y, then we remove these covered atomic units from U.\nNext, we propose Corollary 1. It helps identify individual pure children of set Y\u2019s common parents from Y, thus providing information for the new atomic units.\nCorollary 1 (Identifying individual pure child). Let U be a set of atomic units satisfying POLiNGAM with known MSa,b for each atomic unit in U, and there is no such leaf atomic unit in U that its full parents are also in U. Let Y be a subset of U that satisfies Theorem 2 with Remark 2, and Y1 be an atomic unit in Y. For any one atomic unit Y2 in U\\Y, iff the new subset {Y2 \u222aY\\Y1} also satisfies Theorem 2 with Remark 2, then {Y2 \u222aY\\Y1} has the same total parent set as those of Y, and Y1 and Y2 are two individual pure children, each of which is not partially or fully covered by other atomic units.\nExample 8. Continuing from Example 7, Y2 = {{X5}, {X6}, {X7}}, Y3 = {{X5}, {X6}, {X8}} are two clusters that fulfill the requirements. We can know Y2 and Y3 share the same parent set because they both have {{X5}{X6}}, and {X7} and {X8} are two individual pure children of their common parent set because either of them can form a cluster with the base set {{X5}{X6}}. Based on the theorems above, we can discover new atomic units by identifying individual pure atomic unit children that have common parents. There is a special situation where only one common latent parent variable is behind only two atomic units, called bi-unit cluster. For example, {{X3}, {X4}} in Figure 1. In such a situation, Corollary 1 does not help to identify whether {X3} and {X4} have direct causal relationship between them. Fortunately, Lemma 1 in Xie et al. (2022) provides a solution and is integrated into our algorithm.\nBelow, we present the search procedure of Phase II, where step 4 is aligned with the requirement of the second term in Definition 3. The detailed algorithm can be found in Algorithm 3 (Appendix C.2). During Phase II, we exclusively focus on pure children in current A. Causal relationships for impure children and uncovered pure children are inferred in Phase I of subsequent iterations.\nPhase II: Discovering New Atomic Units 1. Start with partial causal graph G, active atomic unit set A, and size n = 1. 2. n = n+1. For each variable subset Y from MSb(A) with \u2225Y\u2225 = n, test if Y satisfies Theorem\n2 with Remark 2, until all subset are tested. Collect the satisfactory Y where Y \u2286 MSb(Y). 3. Gather the satisfactory Y sets that contain some same atomic units together as a set of sets, and\nadd it into a collection C, repeatedly and exhaustively. C is thus a collection of sets of sets. 4. For each element (set of sets) in C, first identify individual pure atomic unit children for the bi-\nunit cluster by Lemma 1 in Xie et al. (2022). Then, identify individual pure atomic unit children by choosing a base set and testing Corollary 1. Additionally, with the help of identified pure children, identify whether atomic units in the base set are also pure children. 5. If a sufficient number of pure children that share the same parents are identified, we create new atomic units, add them into A and NewAtomicUnitSet, and remove their pure children from A. 6. Repeat steps 2-5 until no more subsets that satisfy Theorem 2 with Remark 2 are found. 7. Return G, A, and NewAtomicUnitSet.\nExample 9 [An illustration of Phase II]. Continuing from Example 6 and consider the structure in Figure 1. The current A = {{X1}, . . . , {X8}, {X10}, . . . , {X15}, {X18}, . . . , {X26}}. With Phase II, we can discover and introduce new atomic unit {L\u20321} to be parent of {{X3}, {X4}}, {L\u20322,L\u20323} to be parent of {{X5}, {X6}, {X7}, {X8}}, {L\u20324,L\u20325} to be parent of {{X12}, {X13}, {X14}, {X15}}, {L\u20326} to be parent of {{X18}, {X19}}, and {L\u20327,L\u20328} to be parent of {{X21}, {X22}, {X23}, {X24}}. We add the new discovered atomic units into A and remove their individual pure children from A.\nDue to the mechanism of Theorem 2 and the searching procedure of Phase II, a clustering issue may arise when the parent atomic unit is fully covered by others. For example, in Figure 1, if {X3} was a latent atomic unit and not in current A, then during Phase II, {X4} would be clustered with {{X5}, {X6}, {X7}, {X8}}. Consequently, it would be treated as sharing the same parent atomic unit L\u2032 that contains two variables, as other variables in the cluster. Fortunately, after {X3} is discovered, we can identify the sub atomic unit from L\u2032 by re-clustering {{X3}, {X4}}. We introduce Proposition 2 to check sub-atomic units in the general case and incorporate an additional procedure into Phase I (lines 8 and 14, Alg. 2). Further details can be found in Appendix C.4.\nProposition 2 (Checking sub-atomic units) Let P be a collection of a.) an atomic unit, b.) the atomic units that have common children with it, and c.) the atomic units that overlap with it. Let U be the set of all children of each atomic unit in P, and Y be a subset of MSa(Y) where Y is a subset of U. If there is no such Y with \u2225Y\u2225 \u2264 \u2225Pa(Y)\u2225 satisfying Theorem 2 and Remark 2 with corresponding parameters (U, Y, Y), then no undiscovered sub-atomic units in P can be further identified."
        },
        {
            "heading": "3.3 PHASE III: REFINING ATOMIC UNITS",
            "text": "In this phase, we check whether the newly discovered atomic units in Phase II have variable overlap with other atomic units in A, which is relatively under-explored in other methods (Xie et al., 2020; Huang et al., 2022). Following that, we further verify each atomic unit in A by checking whether it can be fully decomposed into other smaller atomic units in A.\nTheorem 3 (Checking the overlap of atomic units). Let U1 and U2 be two atomic units. Let U1 be part of variables in MSb(U1). Iff (MSa(U1 \u222a U2),U1 \u222aMSb(U2)) follows the GIN condition and there is no subset U\u03031 \u2282 U1 such that (MSa(U1 \u222a U2), U\u03031 \u222aMSb(U2)) follows the GIN condition, then the two atomic units have \u2225U1\u2225 \u2212 \u2225U1\u2225+ 1 overlapping variables in total. Example 10. Consider two atomic unit {L1} and {L1,X2}3 in Figure 1. Let U1 = {X4} and we find ({X3,X5,X6}, {X4,X7,X8}) follows the GIN condition. This implies that {L1} and {L1,X2} have 1 = 1-1+1 overlapping variable. The same comes for {X2} and {L1,X2}. By Theorem 3, we identify the overlapping atomic units in A, facilitating structure identification in the subsequent iterations. Furthermore, in the A after Phase II, there may exist decomposable \u2018atomic units\u2019 that can be decomposed and replaced by other smaller atomic units in A. We have the following corollary to identify such situations.\nCorollary 2 (Identifying decomposable \u2018atomic unit\u2019). Let U be an atomic unit and S be a set of small atomic units that can be completely covered by U and do not overlap with each other. U can be completely decomposed as and replaced by the atomic units in S, iff \u2225U\u2225 = \u2225S\u2225. Example 11. Continuing from Example 10, we find that both {L1} and {X2} have one overlapping variable with {L1,X2} but not with each other. {L1,X2} is a decomposable \u2018atomic unit\u2019, which can be replaced by two small atomic units {L1} and {X2}. In our algorithm, for each identified decomposable \u2018atomic unit\u2019 in A, we replace it with the small atomic units that make it up and move the children of that decomposable \u2018atomic unit\u2019 to them. The searching procedure for Phase III is presented below, and a detailed algorithm can be found in Algorithm 4 (Appendix C.3).\nPhase III: Refining Atomic Units 1. Start with partial causal graph G, active atomic unit set A, and NewAtomicUnitSet. 2. For each pair of atomic units in A (at least one of which is also in NewAtomicUnitSet), test\nwhether Theorem 3 applies and, if so, record the number of overlapping variables. 3. For each atomic unit in A, which overlaps with other atomic units in A, test whether it is decom-\nposable by Corollary 2. Move the children of the decomposable \u2018atomic unit\u2019 to the atomic units that decompose it, and remove it from A. 5. Return G and A. Example 12 [An illustration of Phase III]. Continuing from Example 9 and consider the structure in Figure 1. With Phase III, we can find the new discovered atomic unit {L\u20322,L\u20323} can be fully replaced by {L\u20321} and {X2}. We move the children of {L\u20322,L\u20323} to {L\u20321} and {X2}, and remove {L\u20322,L\u20323} from A. After that, we start the next iteration and feed the current A into Phase I."
        },
        {
            "heading": "3.4 IDENTIFIABILITY FOR CAUSAL STRUCTURES",
            "text": "In this section, we discuss the identifiability of our algorithm for the causal structure. Our algorithm runs three phases in a loop, discovering the causal graph from leaf to root nodes. The computational complexity depends on the number of variables (including latent variables) and density of underlying causal graph, which determine the number of iterations needed to discover the entire graph. A complete illustrative example and the algorithm complexity are provided in Appendix D and E, along with some experiments of running time in Appendix G.4.\nTheorem 4 (Identifiability of causal graph). Suppose that the input data X follows PO-LiNGAM with the PO-LiNGAM identifiability condition. Then the atomic units, their size, and the causal structure among them can be fully identified with our algorithm. If there are no direct causal relationships between variables within atomic units, the entire causal graph G is virtually identifiable. Moreover, it is natural that under more stringent conditions, the identification of the causal graph can be accomplished using only a subset of the theorems and procedures outlined earlier.\nCorollary 3 (Identifiability of causal graph with stricter conditions). Suppose that the input data X follows PO-LiNGAM. If each latent variable has at least two pure variable children, the entire causal graph can be identified with aid of Theorem 1, Theorem 2, and Corollary 1 from Phases I and\n3Strictly speaking, {L1,X2} is not an atomic unit because it is decomposable. However, we did not know this when we discovered it by clustering its pure children in Phase II.\nII. Alternatively, if there are no latent confounders, the entire causal graph can be identified with aid of only Proposition 1, a simplified version of Theorem 1 from Phase I."
        },
        {
            "heading": "4 EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "4.1 SYNTHETIC DATA",
            "text": "In the simulation studies, we compared our method with competitive baselines, including typical LiNGAM (Shimizu et al., 2006; 2011), measurement-based methods such as BPC (Silva et al., 2006) and FastGIN (Xie et al., 2020), hierarchical methods such as LaHME (Xie et al., 2022) and IL2H (Huang et al., 2022). We considered four typical causal structures: i) all measured variables, ii) latent mediators between measured variables, iii) latent hierarchies, and iv) a general causal structure synthesized from first three cases, shown in Figure 2 . To evaluate the results, we employed three metrics adapted from Xie et al. (2022) and Huang et al. (2022), including i) Correct Ordering Rate, ii) Error Rate in Latent Variables, and iii) F1-score. For more information, please refer to Appendix G. The experimental results are reported in Table 2. Our algorithm performs well with all structures, which proves that it can deal with general causal structures, whereas other methods focus only on particular settings. For complex causal structures such as Case 4, a substantial sample size is often required. One possible reason is that the reliable estimation of higher-order statistics requires much more samples than that of second-order statistics (Hyva\u0308rinen et al., 2009)."
        },
        {
            "heading": "4.2 REAL-WORLD DATA",
            "text": "We evaluate our method on two real-world datasets, including H&S-1939 dataset (Holzinger & Swineford, 1939) and SOFA dataset (Muthe\u0301n & Muthe\u0301n, 2017). More details is in Appendix H. Result on H&S-1939 dataset: We focus on nine out of the original 26 tests, as in Cui et al. (2019). The result graph is shown in Figure 10(a). Consistent with the path diagram in Cui et al. (2019), the variables belonging to the textual aspect (T1, T2, T3) and visual aspect (V1, V2, V3) are clustered and influenced by their respective latent factors. Furthermore, the variables in the speeded aspect (S1, S2, S3) are influenced by those of textual aspect and visual aspect. This relationship can be attributed to the fact that speed is, in essence, a reflection of both textual and visual comprehension. Result on SOFA dataset: The result graph of our output forms a hierarchical structure, consistent with the hypothesized model given in Chapter 5 of Muthe\u0301n & Muthe\u0301n (2017)."
        },
        {
            "heading": "5 CONCLUSIONS AND FUTURE WORK",
            "text": "In this paper, we have theoretically demonstrated the identifiability of causal structures under the linear causal model and non-Gaussianity assumptions, without prior knowledge regarding the presence or positions of latent variables. Furthermore, we proposed a feasible iterative algorithm to identify the causal graph. To strike a good balance between theoretical identifiability and practical feasibility we currently require a sufficient number of pure children for each atomic unit. One future research is directed towards reducing the number of pure children required. Another direction for future research is to estimate the causal structure under nonlinear causal models."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "This material is based upon work supported by the AI Research Institutes Program funded by the National Science Foundation under AI Institute for Societal Decision Making (AI-SDM), Award No. 2229881. The project is also partially supported by the National Institutes of Health (NIH) under Contract R01HL159805, and grants from Apple Inc., KDDI Research Inc., Quris AI, and Infinite Brain Technology. FX would like to acknowledge the support by the Natural Science Foundation of China (62306019)."
        },
        {
            "heading": "A RELATED WORK",
            "text": "Inferring causal relationships from observed data is a popular field of statistics and artificial intelligence. As described in the introduction, from the scope of application, most methods can be divided into three areas: a) Infer the causal relations among measured variables with the assumption that there are no latent variables, for example, PC algorithm (Spirtes & Glymour, 1991), LiNGAMbased method (Shimizu et al., 2006), Greedy search (Chickering, 2002). b) Infer the causal relations among measured variables in the presence of latent variable interference, for example, FCI and its variants (Spirtes et al., 1995; Colombo et al., 2012; Claassen et al., 2013). c) Infer the causal relations among latent variables, for example, measurement models (Silva et al., 2006; Kummerfeld & Ramsey, 2016; Cai et al., 2019; Xie et al., 2020) and hierarchical models (Pearl, 1988; Zhang, 2004; Choi et al., 2011; Drton et al., 2017; Xie et al., 2022; Huang et al., 2022; Kong et al., 2023).\nDepending on the different constraints and criteria used, most previous causal discovery methods can be divided into the following main categories:\n1.) (Non-parametric setting) Conditional independence constraint: The PC algorithm (Spirtes & Glymour, 1991), as well as the FCI algorithm (Spirtes et al., 1995) and their variants (Colombo et al., 2012; Claassen et al., 2013), are prominent examples of non-parametric methods that infer causal relationships among measured variables by testing conditional independence. They do not care about whether the causal relationships are linear or not. However, these methods struggle with the latent variables and their causal relationships. Another limitation is that they yield multiple Markov equivalent structures, introducing ambiguity regarding the presence of confounders in the resulting graph.\n2.) (Linear Gaussian setting) Tetrad condition and rank deficiency constraint: By investigating the sub-covariance matrix of measured variables, Tetrad condition (Spearman, 1928) allows to locate latent variables and infer the causal relationships among them in linear-Gaussian settings (Pearl, 1988; Silva et al., 2006; Kummerfeld & Ramsey, 2016). These methods generally assume that each latent variable possesses at least three pure measured variables as pure children, and each measured variable is exclusively a pure child of a single latent variable. Squires et al. (2022) presented a Tetrad-based method that allows latent variables to be influenced by measured variables. It relies on strong assumptions, such as the absence of edges between pairs of observed nodes or between pairs of latent nodes. The rank deficiency constraint is a general version of the Tetrad condition. Huang et al. (2022) use it to infer a latent hierarchical structure, which assumes k+1 pure children and k+1 neighbors for a set of latent variables with size k, and implicitly assumes all clustered children are pure children. Similar to the conditional independence constraint-based methods, they return a result that is asymptotic to the ground truth graph.\n3.) (Linear non-Gaussian setting) Independent component analysis (ICA): Shimizu et al. (2006) leveraged non-Gaussianity of data and showed that a linear non-Gaussian acyclic model (LiNGAM) is identifiable based on ICA algorithm. By over-complete ICA, for example, Hoyer et al. (2008); Shimizu et al. (2009); Tashiro et al. (2014) learn the causal structure with latent variables. The limitation of over-complete ICA is that there are equivalence structures and the estimation is easy to fall into local optima. Recently, based on overcomplete ICA, Adams et al. (2021) established necessary and sufficient conditions for structure identifiability in both the linear non-Gaussian and the linear heterogeneous setting. However, it does not have a practical estimation approach and requires knowing the number of latent variables at the beginning.\n4.) (Linear non-Gaussian setting) Independent noise, Triad constraint, and GIN condition: Shimizu et al. (2011) proposed DirectLiNGAM in 2011, which learns LiNGAM by replacing the ICA algorithm with regression and independence tests of noises. Triad constraint (Cai et al., 2019) is an extension of the independent noise condition for latent variables with the same assumption that the noise terms are non-Gaussian, and is used to discover the structure of latent variables. GIN condition Xie et al. (2020) is a more general version that allows multiple parents behind multiple children. Xie et al. (2022) identify a latent hierarchical structure by using the GIN condition, which assumes one-factor clusters and measured variables to be descendants of latent variables.\n5.) (Linear setting) Matrix decomposition and Optimization: Matrix decomposition techniques have been applied to model causal structures. Under specific conditions, the precision matrix can be decomposed into two components: a low-rank matrix that characterizes the causal relationships from\nlatent variables to measured variables, and a sparse matrix that represents the relationships among measured variables (Chandrasekaran et al., 2010; 2011). By requiring triple measured variables than latent variables, Anandkumar et al. (2013) decompose the covariance matrix, and is capable of handling DAGs with effective depth one and multi-level Directed Acyclic Graphs (DAGs) (similar to latent hierarchical structures), with the help of low-order observable moments.\n6.) Others: With the help of discrete latent variables, Kivva et al. (2021) proposed a mixture oraclesbased method to identify the potentially nonlinear latent variable graph. Recently, Kong et al. (2023) learns a nonlinear latent hierarchical causal model by self-supervised representation learning. This innovative method accommodates general nonlinearity and multi-dimensional continuous variables. However, this approach still relies on strong assumptions regarding the data generation process and the estimation is easy to fall into local optima."
        },
        {
            "heading": "B WHEN THE PO-LINGAM IDENTIFIABILITY CONDITION IS VIOLATED",
            "text": ""
        },
        {
            "heading": "B.1 THEORETICAL ANALYSIS",
            "text": "PO-LiNGAM Identifiability Condition: a.) Any latent variable is in at least one atomic unit. b.) For any two atomic units with overlapping variables, their non-overlapping parts do not influence each other.\n(i) Violation of identifiability condition(a): Our algorithm discovers new atomic units by clustering their individual pure children, and whether the number of pure children for latent variables satisfies the condition is tested during the discovery process, which is mainly achieved by Theorem 2, Remark 2, and Corollary 1. Meanwhile, please notice that our algorithm sequentially identifies the whole causal graph from leaves to roots. The higher-order causal structure can be inferred only after the lower-order causal structure are fully identified. As a consequence, the algorithm halts its inference of the higher-order causal structure when the latent set lacks a sufficient number of individual pure children to be located, so that it does not output spurious latent variables. In other word, since this condition is violated, it can not detect all latent variables, but we can still trust the discovered ones. The atomic units, whose causal orders are lower or equal to the unidentified latent set, and the causal relations among them are still identifiable.\n(ii) Violation of identifiability condition(b): Let\u2019s consider the example in Figure 3(a), where two atomic units {L1,L2} and {L2,L3} are both caused by {X1}. Meanwhile, L1 causes L3, which violates identifiability condition(b). In our algorithm, for any two atomic units with overlapping variables, it ignores the influence of non-overlapping part of one atomic unit to that of another and infer their causal relationships separately, as illustrated in Remark 1 and Remark 2. Therefore, the discovered causal graph will ignore the causal relationships between non-overlapping parts of any two overlapping atomic units, as shown in Figure 3(b)."
        },
        {
            "heading": "B.2 EXPERIMENTS",
            "text": "(i) To evaluate the performance of our algorithm under the violation of condition(a), we adjusted the causal graphs in Cases 2 and 3 of the simulation experiment, resulting in Case A and Case B of Figure 4. In Case A, L1 lacks sufficient pure atomic unit children for discovery due to the causal chain X2 \u2192 X3 \u2192 X4. Nevertheless, the algorithm can still identify the causal structure of L1 and its descendants, as shown in Figure 4(b). Moreover, in Case B, where L2 cannot be discovered due to having only one pure atomic unit child, namely X1, the algorithm still identifies the causal structure of L3 and L4, as shown in Figure 4(d). The corresponding average numerical result from\nten executions is presented in Table 3. The high Correct Ordering Rate indicates that the discovered partial causal graph is highly accurate.\n(ii) To evaluate the performance of our algorithm under the violation of condition(b), we tested the algorithm with the ground-truth graph in Figure 3(a). The result discovered by our method is in Figure 3(b). The corresponding average numerical result from ten executions is presented in Case C of Table 3. The high Correct Ordering Rate indicates that the discovered partial causal graph is highly accurate."
        },
        {
            "heading": "C DETAILS OF IDENTIFICATION ALGORITHM",
            "text": "Our algorithm is iterative, with each iteration comprising three main phases, progressively uncovering the entire causal graph from leaf to root nodes. For each iteration, it first recursively identifies the leaf nodes and their parent nodes from the active atomic unit set A in the causal graph composed of atomic units of A and their latent confounders, and update A (Phase I). Then, we discover new atomic units by clustering their pure children in A, and update A (Phase II). After that, we refine newly discovered atomic units by checking overlapping atomic units and decomposable \u2018atomic units\u2019, and update A (Phase III). At the end of an iteration, A is sent back to the Phase I and a new iteration starts until no more atomic units in A are updated."
        },
        {
            "heading": "C.1 PHASE I",
            "text": "The detailed algorithm for Phase I is in Algorithm 2."
        },
        {
            "heading": "C.2 PHASE II",
            "text": "The detailed algorithm for Phase II is in Algorithm 3."
        },
        {
            "heading": "C.3 PHASE III",
            "text": "The detailed algorithm for Phase III is in Algorithm 4."
        },
        {
            "heading": "C.4 SUPPLEMENTARY ALGORITHMS FOR PHASE I",
            "text": "To handle the situation explained at the end of section 3.2, we proposed two additional steps for Phase I, including Algorithm 5 (line 8, Alg. 2) and Algorithm 6 (line 14, Alg. 2).\nSmall atomic units that can be completely covered by larger atomic units are sometimes indistinguishable from those larger atomic units due to the different causal order counting from the leaf nodes of the graph as well as the characterization of the GIN condition. The purpose of Algorithm 5 is to check this case by rechecking the number of parent variables of the related atomic unit children. If such a case happens, most children are re-added into A and treated the same as others in A. For the special children that have partial parents not in A, Algorithm 6 is used to relocate parents for them after the normal children are settled."
        },
        {
            "heading": "C.5 CHECK FOR MULTIPLE ROOT ATOMIC UNITS",
            "text": "Most causal discovery methods for handling latent variables Silva et al. (2006); Cai et al. (2019); Xie et al. (2020; 2022); Huang et al. (2022) implicitly assume that there are no unconditional independence between any two variables in the measured variable set X. In other words, they assume that there is at most one root node in the causal graph, which may be a latent variable or a latent variable set with common children.\nIn practical situations, there may be more than one root node in a causal graph, not to mention that the input measured variables may form multiple disconnected subgraphs. In Figure 5(a), X1 . . .X4 form a subgraph, while X5 is not connected to any other variables. Furthermore, in the sub causal graph consisting of X1 . . .X4, X1 is unconditionally independent of both X3 and X4. In such a case, there are three root nodes: X1, L1, and X5.\nOur methods can handle the situation regardless of the number of root atomic units in the causal graph. At the end of the inference process, the algorithm tends to cluster all the true root atomic units (three or more) together and assigns them a common latent parent variable, as depicted in Figure 5(b). This occurs because when the active atomic unit set A contains only root atomic units, those root atomic units naturally satisfy the GIN condition and are unconditionally independent of each other without requiring any additional operations. It is considered that those root atomic units share a common latent parent variable with a value of 0. To verify the presence of multiple root atomic units in the causal graph, we can perform the independence tests. If the discovered root atomic unit comprises only one latent variable and lacks impure children, we should examine the unconditional independence of the pure atomic unit children of that discovered root atomic unit (For latent atomic units, their measured surrogate sets are used). If these pure children are found to be unconditionally independent of each other, then we can conclude that they are the true root atomic units of the causal graph. One the other hand, if the initially discovered causal graph has only two root atomic units, we can do the same unconditional independence test to check whether there is a common latent variable parent behind them.\nAlgorithm 2: Phase I: IdentifyLeafNodesAndTheirParents Input: Partial causal graph G, Active atomic unit set A Output: Partial causal graph G, Active atomic unit set A\n1 repeat 2 Select an atomic unit U \u2208 A; 3 for GrLen\u2190 1 to |A\\U| do 4 repeat 5 Select atomic unit subset P from A\\U such that |P| = GrLen; 6 if U with P satisfies Theorem 1 and Remark 1 then 7 A\u2190 A\\U , and update G; 8 (G,A)\u2190 CheckSubAtomicUnits(G,A,P); 9 Return to line 2;\n10 end 11 until all subsets with size GrLen in A\\U selected; 12 end 13 until no more atomic units can be removed from A; 14 (G,A)\u2190 RefindChildrenForSubAtomicUnits(G,A); 15 return G,A\nAlgorithm 3: Phase II: DiscoverNewAtomicUnits Input: Partial causal graph G, Active atomic unit set A Output: Partial causal graph G, Active atomic unit set A\n1 GrLen:= 2, A\u2032 := A, and NewAtomicUnitSet := \u2205; 2 repeat 3 ClusterList:= \u2205; 4 repeat 5 Select subset Y from MSb(A \u2032 ) such that \u2225Y\u2225 = GrLen, Y \u2286 MSb(Y) and Y \u2265 2; 6 if Y satisfy the Theorem 2 and Remark 2 then 7 Add Y into ClusterList; 8 end 9 until all subset with size GrLen in MSb(A \u2032 ) selected;\n10 Gather the sets having overlapping atomic units with each other from the ClusterList as a set of sets and add it into another set C, repeatedly and exhaustively; 11 for each Ci \u2208 C do 12 when GrLen= 2, if Ci contains only one set (bi-unit cluster) then identify pure children by Lemma 1 in Xie et al. (2022); 13 Select one set \u2208 Ci, remove one atomic unit from it, get a base B with \u2225B\u2225 \u2265 Grlen-1; 14 PureChildSet = \u2205; for each set S \u2208 Ci if |S| = |B|+ 1 do add S\\B into PureChildSet; 15 for each atomic unit B \u2208 B do 16 Select Grlen-1 atomic units from PureChildSet and patch B with them to form set T; 17 end 18 if bi-unit cluster is pure cluster, or |PureChild| \u2265 Grlen-1 and all Ts \u2208 Ci then 19 The atomic units in PureChildSet and B are all pure children; 20 A\u2190 A\\T\\PureChildSet, and update G; 21 Create a new atomic unit U and save it in NewAtomicUnitSet; 22 end 23 end 24 A\u2032 \u2190 A\u2032\\ClusterList, and GrLen\u2190 GrLen+1; 25 until no more clusters are found; 26 return G,A, and NewAtomicUnitSet\nAlgorithm 4: Phase III: RefineAtomicUnits Input: Partial causal graph G, Active atomic unit set A, NewAtomicUnitSet Output: Partial causal graph G, Active atomic unit set A\n1 repeat 2 Select two atomic unit U1,U2 \u2208 A, where at least one in NewAtomicUnitSet; 3 for m\u2190 1 to \u2225U1\u2225 do 4 Select m measured surrogates from MSb(U1), denoted as U1; 5 if (MSa(U1 \u222a U2), U1 \u222aMSb(U2)) follows GIN condition then 6 U1 and U2 have \u2225U1\u2225 \u2212 \u2225U1\u2225+ 1 overlapping variables; 7 Update G, and merge U1 with U2; 8 Return to line 2; 9 end\n10 end 11 until all binary atomic unit set selected; 12 for each atomic unit U \u2208 A do 13 for each Si \u2208 A\\U and Si \u2286 U do add Si into set C; 14 repeat 15 Select a subset S \u2286 C; 16 if atomic units in S do not overlap and \u2225U\u2225 = \u2225S\u2225 then 17 Move the children of U to below the atomic units in S; 18 if A is not updated, then A\u2190 A\\U ; 19 Update G; 20 end 21 until all subset in C selected; 22 end 23 return G,A\nAlgorithm 5: CheckSubAtomicUnits Input: Partial causal graph G, Active atomic unit set A, atomic unit set P \u2286 A Output: Partial causal graph G, Active atomic unit set A\n1 Let P\u0302 be the union of P and the atomic units in A that overlap with atomic units in P; 2 Let U contains the atomic units whose parents is a subset of P\u0302; 3 GrLen:= 2, U\u2032 := U; 4 repeat 5 ClusterList:= \u2205; 6 repeat 7 Select subset Y from MSb(U \u2032 ) such that \u2225Y\u2225 = GrLen, Y \u2286 MSb(Y) and Y \u2265 2; 8 if Y satisfy the Theorem 2 and Remark 2 then 9 Add Y into ClusterList; 10 if \u2225Y\u2225 \u2264 known \u2225Pa(Y)\u2225 then 11 if there are atomic units /\u2208 A, which has partial atomic unit parents in P\u0302 and the\nrest atomic unit parents /\u2208 A, then mark them and the atomic units in U with matching symbols;\n12 A\u2190 (A\\P\u0302) \u222a U, update G, and go to line 18; 13 end 14 end 15 until all subset with size GrLen in MSb(U \u2032 ) selected; 16 U\u2032 \u2190 U\u2032\\ClusterList, and GrLen\u2190 GrLen+1; 17 until no more clusters are found; 18 return G,A\nAlgorithm 6: RefineChildrenForSubAtomicUnits Input: Partial causal graph G, Active atomic unit set A Output: Partial causal graph G, Active atomic unit set A\n1 for each marked set of atomic units in G do 2 if the atomic units in U are all relocated to be children of the smaller atomic units then 3 Relocate the parents for the atomic units that used to have partial atomic unit parents in\nP\u0302 and the rest of atomic unit parents /\u2208 A, by Theorem 1 and Remark 1; 4 Update G; 5 end 6 end 7 return G,A\nD ILLUSTRATION OF OUR ALGORITHM\nIn this section, we illustrate our algorithm with the ground-truth graph in Figure 6(a). We assume Oracle tests for GIN conditions. In this structure, L1, . . . ,L7 are latent variables and X1, . . . ,X26 are measured variables. We can see from the graph that measured variables are interspersed with\nlatent variables. The causal relationships among them are also complex. The estimation process is as follows:\ni Initially, the active atomic unit set A = {{X1}, . . . , {X26}} and graph G = \u2205. ii During phase I of the first iteration, it first identifies Pa({X17}) = {{X16}, {X18}}, and remove {X17} from the active set A. After that, we sequentially identify Pa({X16}) = {X9} and Pa({X9}) = {X2}, and update A. The result after phase I of the first iteration is shown in Figure 6(b), and the current A = {{X1}, . . . , {X8}, {X10}, . . . , {X15}, {X18}, . . . , {X26}}.\niii During phase II of the first iteration, we cluster the individual pure children in A to form new atomic units. It is worth noting that we do not know the true serial numbers of the latent variables. In the following, for the sake of clarity, we use the true serial numbers of latent variables to denote them. As shown in Figure 6(c), we introduce the new atomic unit {L1} to be parent of individual pure children set {{X3}, {X4}}, the new atomic unit {L\u20321,L\u2032X2} to be parent of individual pure children set {{X5}, {X6}, {X7}, {X8}}, the atomic unit {L3,L4} to be parent of individual pure children set {{X12}, {X13}, {X14}, {X15}}, the atomic unit {L5} to be parent of individual pure children set {{X18}, {X19}}, the atomic unit {L6,L7} to be parent of individual pure children set {{X21}, {X22}, {X23}, {X24}}. We add the newly discovered atomic units into A and remove their individual pure children from A.\niv During phase III of the first iteration, we find that the newly discovered atomic unit {L\u20321,L\u2032X2} can be fully replaced by {L1} and {X2}, as shown in Figure 6(d). We move the children of {L\u20321,L\u2032X2} to {L1} and {X2}, and remove {L \u2032 1,L \u2032 X2 } from A.\nv Now, we start the second iteration. During phase I of the second iteration, we find Pa({L5}) = {X2}, Pa({X20}) = {{X2}, {L6,L7}}, Pa({X2}) = {{L1}, {X1}}, Pa({L1}) = {X1}, Pa({X26}) = {{X25}, {L6,L7}}, and Pa({X25}) = {L6,L7}, as shown in Figure 6(e).\nvi In phase II of the second iteration, we introduce the new atomic unit {L2,L\u20323} to be parent of individual pure children set {{X10}, {X11}, {L6,L7}}, as shown in Figure 6(f).\nvii In phase III of the second iteration, we find that the newly discovered atomic unit {L2,L\u20323} have one variable overlapping with atomic unit {L3,L4}, and merge them. The result is shown in Figure 6(g).\nviii Now, we start the third iteration. During phase I of the third iteration, we find Pa({L2,L3}) = {X1} and Pa({L3,L4}) = {X1}, as shown in Figure 6(h). After that, the current active atomic unit set contains only the measured variable{X1}, and the whole underlying causal graph is identified."
        },
        {
            "heading": "E COMPUTATIONAL COMPLEXITY OF OUR ALGORITHM",
            "text": "In this section, we analyze the complexity of our algorithm. Denote by n the number of active atomic units at the beginning of each phase. The complexity of phase I is upper bounded by O(n \u2211n\u22121 k=1 ( n\u22121 k ) . The phase II has the worst case complexity O( \u2211n k=2 ( n k ) ). Denote by l the size of the largest atomic unit in the active atomic unit set. The complexity of phase III is upper bounded by O(l ( n 2 ) ). The total complexity of the algorithm to discover the whole causal graph depends on the number of (both measured and latent) variables and the structural density of the causal graph, which determine how many iterations the algorithm needs to run."
        },
        {
            "heading": "F PROOFS",
            "text": "Before presenting the proofs of our results, we need a few more theorems and definitions derived from Xie et al. (2020; 2023).\nDefinition 6 (GIN condition (Xie et al., 2020)). Let Z, Y be sets of variables in a linear nonGaussian acyclic causal model. We say that (Z,Y) follows GIN condition if and only if \u03c9\u22baY are statistically independent of Z, where \u03c9 satisfies \u03c9\u22baE[YZ\u22ba] = 0 and \u03c9 \u0338= 0. In other words, (Z,Y) violates the GIN condition if and only if EY||Z is dependent on Z.\nRecently, Xie et al. (2023) extended the original graphical criteria of the GIN condition with the help of trek and trek-separation (t-separation) (Sullivant et al., 2010). We next describe the notion of the trek and trek-separation criterion, which is more general than d-separation in linear causal models. After that, we show the graphical implication of the GIN condition in PO-LiNGAM, which helps to exploit the GIN condition to discover the causal graph.\nDefinition 7 (trek (Sullivant et al., 2010)). A trek in G from i to j is an ordered pair of directed paths (P1,P2) where P1 has sink i, P2 has sink j, and both P1 and P2 have the same source k. The common source k is called the top of the trek, denoted top(P1,P2). Note that one or both of P1 and P2 may consist of a single vertex, that is, a path with no edges.\nDefinition 8 (t-separation (Sullivant et al., 2010)). Let A, B, CA, and CB be four subsets of V. We say the ordered pair (CA, CB) t-separates A from B if, for every trek (\u03c41; \u03c42) from a vertex in A to a vertex in B, either \u03c41 contains a vertex in CA or \u03c42 contains a vertex in CB.\nTheorem 5 (GIN Graphical Criteria in PO-LiNGAM). Let Y and Z be two sets of measured variables of a partially observed linear non-Gaussian acyclic causal model (PO-LiNGAM). Assume the rank-faithfulness holds. (Z,Y) satisfies the GIN condition if and only if there exists a variable set S with 0 \u2264 Dim(S) \u2264 min(Dim(Y)\u2212 1, Dim(Z)), such that 1) the order pair (\u2205,S) t-separates Z and Y, and that 2) the covariance matrix of S and Z has rank Dim(S), and so does that of S and Y.\nNote: In this paper, Dim(S) = \u2225S\u2225 represents the number of variables in S, regardless of whether S is a set of variables or a set of atomic units. Roughly speaking, the conditions in this theorem can be interpreted in the following way: i.) a causally earlier subset (according to the causal order) of Y t-separates Y from Z, and ii.) the linear transformation from that subset of the common causes to Z has full column rank. Based on the definition of d-separation, the first interpretation is that the causally earlier subset S (according to the causal order) of Y d-separates Y\\S from Z\\S .\nProof. Recently, it has been shown in Xie et al. (2023) that the graphical criteria hold in a linear non-Gaussian acyclic causal model. In (Xie et al., 2020; 2022; 2023), they allowed part variables to be latent. In our paper, the latent variable can be the descendent or ancestor of measured variables, which does not affect the graphical criteria of GIN because linear causal models are transitive."
        },
        {
            "heading": "F.1 PROOF OF PROPOSITION 1",
            "text": "Proof. Let V be a set of variables satisfying PO-LiNGAM with no latent variables, and V be a variable in V.\n(i) Assume that V is a leaf variable of the causal graph, and P are its all parents. We know that a) 0 \u2264 \u2225P\u2225 \u2264 min(\u2225V \u222a P\u2225 \u2212 1, \u2225V\\V\u2225), and b) P is the minimal set so that (\u2205,P) t-separates V\\V and V \u222a P. Furthermore, the set of common components between V \u222a P and V\\V is P, so the covariance matrix of P and V\\V has rank \u2225S\u2225, and so does that of P and V \u222a P. Therefore, (V\\V,V \u222aP) follows the GIN condition and there is no P\u0303 \u2282 P such that (V\\V,V \u222a P\u0303) follows the GIN condition.\n(ii) Assume that (V\\V,V \u222aP) follows the GIN condition and there is no P\u0303 \u2282 P such that (V\\V,V\u222aP\u0303) follows the GIN condition. We know that P is the minimal set that (\u2205,P) t-separates V\\V and V \u222a P, and therefore, P is causal earlier than V. In a causal graph, the minimal causal earlier set that t-separates one variable from the other variables is the parent set of that variable.\nTherefore, from (i) and (ii), the proposition is proved."
        },
        {
            "heading": "F.2 PROOF OF THEOREM 1",
            "text": "Proof. The proof of theorem 1 is similar to the proof of Proposition 1. Let U be a set of nonoverlapping atomic units satisfying PO-LiNGAM with known MSa,b for each atomic unit in U, and U be an atomic unit in U.\n(i) Assume that U is a leaf atomic unit in the current causal graph, and P is the set of parent atomic units of U . We know that a) 0 \u2264 \u2225P\u2225 \u2264 min(\u2225U \u222a P\u2225 \u2212 1, \u2225U\\U\u2225), and b) P is the minimal set so that (\u2205,P) t-separates U\\U and U \u222aP. Furthermore, the set of common components between U \u222aP and U\\U is P, so the covariance matrix of P and U \u222aP has rank \u2225P\u2225, and so does that of P and U\\U . And because some of the atomic units may be latent, we use their measured surrogate variable set to represent them. Therefore, ( MSa(U\\U),MSb(U \u222aP) ) follows the GIN condition and there is no\nP\u0303 \u2282 P such that ( MSa(U\\U),MSb(U \u222a P\u0303) ) follows the the GIN condition. The same is true if we represent them using another set of measured surrogate variables.\n(ii) Assume that ( MSa(U\\U),MSb(U \u222a P) ) follows the GIN condition and there is no P\u0303 \u2282 P\nsuch that ( MSa(U\\U),MSb(U \u222a P\u0303) ) follows the the GIN condition. MSa(U\\U) contains a set of measured surrogate set of U\\U , MSb(U\u222aP) contains another set of measured surrogate set of U\u222aP. The common component of U\\U and U \u222a P is P. And, without MSb(P), the GIN condition cannot be satisfied singly using MSb(U) as the Y set. Thus, P is the minimal set that (\u2205,P) t-separates MSa(U\\U) and MSb(U \u222a P), and therefore, P is causal earlier than U . In the causal graph, the minimal causal earlier atomic unit set that t-separates one atomic unit from the other atomic units is the parent set of that atomic unit.\nTherefore, from (i) and (ii), the theorem is proved."
        },
        {
            "heading": "F.3 PROOF OF REMARK 1",
            "text": "Proof. (i) The first term is to eliminate the effect of overlapping atomic unit sets when searching for parents, since for any two atomic units with overlapping variables, we don\u2019t have enough information to know whether the non-overlapping part of one atomic unit is the parent of the non-overlapping part of another atomic unit. As illustrated in case 1 of Figure 7, If we want to know the parent of the atomic unit {L2,L3}, we need remove the atomic unit {L3,L4} from U and P. Otherwise, both {L3,L4} and {L1} will be considered as the parents of {L2,L3} rather than the true parent {L1}. (ii) For the second term, let us consider the case 2 of Figure 7, where we want to find the parent of {X9}. P = {{L1,L2}, {L2,L3}} and U = {X9}. There is no point in testing the GIN condition for ( MSa(U\\U),MSb(U \u222a P) ) , since even without MSb(U) in Y set, the graph criteria of GIN condition is still satisfied, so is GIN condition. That is because those two atomic units {L1,L2} and {L2,L3} have overlapping L2, and therefore the unrepeated variable set behind their measured surrogate variable has size 3 instead of 4. Thus, we need to find a subset of MSb(P) so that the number of variables is equal to the true size \u2225P\u2225. That is the maximal subset S of MSb(P) that makes ( MSa(U\\U),S ) does not follow GIN condition."
        },
        {
            "heading": "F.4 PROOF OF THEOREM 2",
            "text": "The aim behind Theorem 2, Remark 2, and Corollary 1 is to find a sufficiently large number of pure children to support the discovery of new atomic units.\nProof. Let U be a set of non-overlapping atomic units satisfying PO-LiNGAM with known MSa,b for each atomic unit in U, and there is no such leaf atomic unit in U that its full parents are also in U. Assume that (MSa(U\\Y),Y) follows the GIN condition, and there is no subset Y\u0303 \u2282 Y such that (MSa(U\\Y), Y\u0303) follows the GIN condition. It means that there is a variable set S with size\n\u2225Y\u2225 \u2212 1, which is causal earlier than Y, and the order pair (\u2205,S) t-separates MSa(U\\Y) and Y. Since we know in U there is no leaf atomic unit that its full parents are also in U, S contains at least one latent variable which is the parent of Y. However, S may also contain variables that are also in Y. The third statement is to check out this situation by explicitly adding the variables in P into S and testing the GIN condition. Therefore, with these three statements, we can ensure that behind Y there is a parent variable set P involving at least one latent variable, which has size \u2225Y\u2225 \u2212 1 and can d-separates Y from the atomic units of U\\(Y \u222aP)."
        },
        {
            "heading": "F.5 PROOF OF REMARK 2",
            "text": "Proof. It is obvious that Remark 2 does not affect the correctness of Theorem 2 whether or not there are overlapping atomic units in U. However, it is reasonable that the parents of the covered atomic unit must be a subset of or the same as the parents of the covering atomic unit. As illustrated in Figure 8, the atomic unit {L2} is fully covered by {L2,L3}, and both {L2} and {L2,L3} have parent {L1}. After removing {L2} from the active set, the atomic unit {L2,L3} can be considered as an individual pure child for discovering the new atomic unit {L1} according to Corollary 1."
        },
        {
            "heading": "F.6 PROOF OF COROLLARY 1",
            "text": "Proof. If one atomic unit Y is replaceable in the Y that satisfies Theorem 2 with Remark 2, then we know that in the current causal graph composed of atomic units in U and their latent confounders, Y is not directly causally connected to the other atomic units in Y\\Y , except for their common total parent set. The reverse is also true."
        },
        {
            "heading": "F.7 PROOF OF PROPOSITION 2",
            "text": "Proof. We demonstrate the utility of Proposition 2 and prove it with the example in Figure 9. With our algorithm, at the beginning, the active set contains only measured variables. After Phase 1 of the first iteration, nothing is identified. During Phase 2 of the first iteration, we cluster the pure children to discover new atomic units. It is obvious that we can cluster {X8} and {X9} to form the atomic unit {L4}. However, when clustering for discovering the atomic unit {L1,L2}, the atomic unit {X2} will also be clustered together with any two of {{X3}, {X4}, {X5}, {X6}}, and considered as a individual pure children of the atomic unit {L1,L2}, though {X2} is actually the individual pure child of {L1}. That is because that atomic unit {L1,L2} covers atomic unit {L1} and when clustering for {L1,L2}, {L1} does not have enough individual pure children to separate it from {L1,L2}. In the following iterations, {L3} will be discovered and identified as a child of {L1,L2}. After that, {L1} can be separated from {L1,L2} by re-clustering the children of {L1,L2}. We know that {X2} and {L3} can be clustered, which shows the number of parent variables behind them is 1 instead of 2, and therefore, there is a small atomic unit covered by {L1,L2}."
        },
        {
            "heading": "F.8 PROOF OF THEOREM 3",
            "text": "Proof. Let U1 and U2 be two atomic units. Let U1 be part of variables in MSb(U1). (i) Assume that U1 and U2 are two discovered atomic units. (MSa(U1 \u222a U2),MSb(U1 \u222a U2)) can satisfy GIN condition only if U1 and U2 have overlapping variables. According to Theorem 5, S = U1 \u222a U2. Dim(S) should be smaller or equal to Dim(U1) +Dim(U2) \u2212 1 so that the graph\ncriteria of the GIN condition is satisfied. It means U1 and U2 have overlapping variables. When U1 is the minimal set that (MSa(U1 \u222a U2),U1 \u222aMSb(U2)) follows the GIN condition, we know the true number \u2225U1 \u222a U2\u2225 is \u2225U2\u2225 + \u2225U1\u2225 \u2212 1. Therefore, we know that the two atomic units have \u2225U1\u2225 \u2212 \u2225U1\u2225+ 1 overlapping variables in total. (ii) Assume that U1 and U2 have \u2225U1\u2225\u2212\u2225U1\u2225+1 overlapping variables. According to the graphical criteria of PO-LiNGAM (Theorem 5), we can know that U1 is the minimal set that (MSa(U1 \u222a U2),U1 \u222aMSb(U2)) follows the GIN condition."
        },
        {
            "heading": "F.9 PROOF OF COROLLARY 2",
            "text": "Proof. The proof of Corollary 2 is obvious. For a set of atomic units S that do not overlap with each other and can be covered by atomic unit U , \u2225U\u2225 = \u2225S\u2225 is equivalent to the fact that each atomic unit in S is part of U , and together they can form U ."
        },
        {
            "heading": "F.10 PROOF OF THEOREM 4",
            "text": "Proof. In section 3.1, we show that the causal structure among atomic units is identifiable by Theorem 1 and Remark 1. In section 3.2, we show that the new atomic units can be discovered by clustering their pure children with the help of Theorem 2, Remark 2, and Corollary 1. In section 3.3, we refine the discovered atomic units by Theorem 3 and Corollary 2.\nThe three sections are integrated into our iterative algorithm to discover the causal graph from the leaf to root nodes. For the possible problem with covered small atomic units during the iterative discovery process, we check and identify it through Proposition 2. Furthermore, at the end of discovery process, we check for multiple root atomic units by testing unconditional independence relationships. Therefore, the atomic units, their size, and the causal structure among them can be fully identified with our algorithm. It is obvious that if there are no direct causal relationships between variables within atomic units, the entire causal graph G is virtually identifiable."
        },
        {
            "heading": "F.11 PROOF OF COROLLARY 3",
            "text": "Proof. Corollary 3 is similar to Theorem 4, but with stronger assumptions. If each latent variable has at least two pure variable children, each atomic unit we discovered will only contain one variable. Thus, we do not need to consider the problem that the discovered atomic units have overlapping variables. Similarly, we need to check whether there are multiple root atomic units at the end. Roughly speaking, with Theorem 1, Theorem 2, and Corollary 1, the entire causal graph G is fully identifiable. Furthermore, if there is no latent confounder, we need not consider the discovery of latent variables. The entire causal graph G is identifiable with only Proposition 1, and the result is the same as the typical LiNGAM discovery algorithm (Shimizu et al., 2006; 2011)."
        },
        {
            "heading": "G MORE DETAILS ON SIMULATION EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "G.1 DATA GENERATION PROCESS AND IMPLEMENTATION",
            "text": "According to Eq. 1, we generated the causal strength bi,j uniformly from [\u22122,\u22120.5] \u222a [0.5, 2] and the non-Gaussian noise terms were generated from exponential distributions to the second power.\nFor BPC and IL2H, Gaussian noise is used. HSIC-based independence tests (Zhang et al., 2018) were used to test the GIN condition."
        },
        {
            "heading": "G.2 EVALUATION METRICS",
            "text": "We adapted the evaluation metrics from Xie et al. (2022) and Huang et al. (2022) to evaluate the results. They are:\na.) Correct ordering rate: the number of correctly inferred causal orderings divided by the total number of inferred causal orderings.\nb.) Error rate in latent variables: the absolute difference between the inferred number of latent variables and the number of latent variables in the true structure divided by the number of latent variables in the true structure.\nc.) F1-score: 2 precision\u2217recallprecision+recall to measure the similarity between the inferred adjacency matrix and the true adjacency matrix."
        },
        {
            "heading": "G.3 MORE DETAILS ON F1-SCORE",
            "text": "In this paper, an adjacency matrix is a square matrix whose each element represents whether or not the variables in the graph are connected by edges with direction. For example, AdjG(i, j) = 1 represents there is a direct edge from ith point to jth point, and AdjG(i, j) = 0 represents there is no direct edge from ith point to jth point.\nWe used the F1-score to calculate the percentage of similarity between estimated and ground-truth adjacency matrices. To calculate the F1-score, we first calculate the precision = true positivetotal test positive that represents the number of correct inferred edges over number of total inferred edges, and the recall =\ntrue positive total true positive that represents the number of correct inferred edges over number of total groundtruth edges. F1-score = 2 precision\u2217recallprecision+recall , which combines the precision and recall of the adjacency matrices by taking their harmonic mean, and can better represent the structural recovery rate.\nIn practice, the latent variable indices in the estimated graphs may not match those in the real graphs. To remove this ambiguity, similar to Huang et al. (2022), we permuted the latent variable indices in the estimated graphs and used the one that has the minimal difference from the true graph. In addition, if the estimated number of latent variables is smaller than the true number of latent variables, we add extra latent variables that do not have edges with others to G. If the estimated number of latent variables is larger than the true number of latent variables, we find a subset of the latent variables in G that best matches the true one."
        },
        {
            "heading": "G.4 MORE RESULTS OF SIMULATION EXPERIMENTS",
            "text": "Here, we evaluate the running time for four simulation cases. Each case is executed ten times, and the results are averaged. The summarized results are reported in the Table 4.\nTo evaluate the performance of our algorithm when some noise is Gaussian-distributed, we modified the first two cases of the simulation experiment. In Case 1, we generate standard Gaussian noise for X2 and X4. In Case 2, we generate standard Gaussian noise for X2 and X5. Each case is executed ten times, and the results are averaged. The summarized results are reported in the Table 5. Although some of the noise is Gaussian-distributed, our method still recovers the true structures."
        },
        {
            "heading": "H MORE DETAILS ON THE REAL-WORLD DATA EXPERIMENT",
            "text": "The Holzinger and Swineford (1939) dataset consists of mental ability test scores of seventh- and eighth-grade children from two different schools (Pasteur and Grant-White). In the original dataset, there are scores for 26 tests. However, a smaller subset with 9 variables is more widely used in the literature, for example, in Jo\u0308reskog (1969). This dataset can be retrieved from R package lavaan (Rosseel, 2012). The variables used in our paper are given in Table 6, which can be broadly categorized into three dimensions: Visual, Textual, and Speeded.\nThe second-order factor analysis model dataset is a built-in dataset of the Mplus software (Muthe\u0301n & Muthe\u0301n, 2017). The ground truth is the same as in Figure 10(b). Each set of three measured variables has a corresponding first-order latent indicator, all of which are influenced by a secondorder latent indicator. A detailed explanation of the dataset and model can be found in http: //www.statmodel.com/HTML_UG/chapter5V8.htm.\nI NOTATIONS AND TERMS"
        }
    ],
    "title": "STRUCTURAL ESTIMATION OF PARTIALLY OBSERVED LINEAR NON-GAUSSIAN ACYCLIC MODEL: A PRAC-",
    "year": 2024
}