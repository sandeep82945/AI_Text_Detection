{
    "abstractText": "Large language models (LLMs) have achieved remarkable performance in various evaluation benchmarks. However, concerns are raised about potential data contamination in their considerable volume of training corpus. Moreover, the static nature and fixed complexity of current benchmarks may inadequately gauge the advancing capabilities of LLMs. In this paper, we introduce DYVAL, a general and flexible protocol for dynamic evaluation of LLMs. Based on our framework, we build graph-informed DYVAL by leveraging the structural advantage of directed acyclic graphs to dynamically generate evaluation samples with controllable complexities. DYVAL generates challenging evaluation sets on reasoning tasks including mathematics, logical reasoning, and algorithm problems. We evaluate various LLMs ranging from Flan-T5-large to GPT-3.5-Turbo and GPT-4. Experiments show that LLMs perform worse in DYVAL-generated evaluation samples with different complexities, highlighting the significance of dynamic evaluation. We also analyze the failure cases and results of different prompting methods. Moreover, DYVAL-generated samples are not only evaluation sets, but also helpful data for fine-tuning to improve the performance of LLMs on existing benchmarks. We hope that DYVAL can shed light on future evaluation research of LLMs. Code is available at: https://github.com/microsoft/promptbench.",
    "authors": [
        {
            "affiliations": [],
            "name": "REASONING TASKS"
        },
        {
            "affiliations": [],
            "name": "Kaijie Zhu"
        },
        {
            "affiliations": [],
            "name": "Jiaao Chen"
        },
        {
            "affiliations": [],
            "name": "Jindong Wang"
        },
        {
            "affiliations": [],
            "name": "Neil Zhenqiang Gong"
        },
        {
            "affiliations": [],
            "name": "Diyi Yang"
        },
        {
            "affiliations": [],
            "name": "Xing Xie"
        }
    ],
    "id": "SP:d7c8d9966158831da8edd12f9b14d46862bf9d35",
    "references": [
        {
            "authors": [
                "Jacob Andreas"
            ],
            "title": "Good-enough compositional data augmentation",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 7556\u20137566,",
            "year": 2020
        },
        {
            "authors": [
                "Devansh Arpit",
                "Stanislaw Jastrzkebski",
                "Nicolas Ballas",
                "David Krueger",
                "Emmanuel Bengio",
                "Maxinder S. Kanwal",
                "Tegan Maharaj",
                "Asja Fischer",
                "Aaron Courville",
                "Yoshua Bengio",
                "Simon Lacoste-Julien"
            ],
            "title": "A closer look at memorization in deep networks",
            "venue": "In Proceedings of the 34th International Conference on Machine Learning,",
            "year": 2017
        },
        {
            "authors": [
                "Yejin Bang",
                "Samuel Cahyawijaya",
                "Nayeon Lee",
                "Wenliang Dai",
                "Dan Su",
                "Bryan Wilie",
                "Holy Lovenia",
                "Ziwei Ji",
                "Tiezheng Yu",
                "Willy Chung"
            ],
            "title": "A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity",
            "venue": "arXiv preprint arXiv:2302.04023,",
            "year": 2023
        },
        {
            "authors": [
                "Emily M. Bender",
                "Timnit Gebru",
                "Angelina McMillan-Major",
                "Shmargaret Shmitchell"
            ],
            "title": "On the dangers of stochastic parrots: Can language models be too big",
            "venue": "FAccT",
            "year": 2021
        },
        {
            "authors": [
                "Lukas Berglund",
                "Meg Tong",
                "Max Kaufmann",
                "Mikita Balesni",
                "Asa Cooper Stickland",
                "Tomasz Korbak",
                "Owain Evans"
            ],
            "title": "The reversal curse: Llms trained on \u201ca is b\u201d fail to learn \u201cb is a",
            "venue": "arXiv preprint arXiv:2309.12288,",
            "year": 2023
        },
        {
            "authors": [
                "Stella Biderman",
                "USVSN Sai Prashanth",
                "Lintang Sutawika",
                "Hailey Schoelkopf",
                "Quentin Anthony",
                "Shivanshu Purohit",
                "Edward Raf"
            ],
            "title": "Emergent and predictable memorization in large language models",
            "venue": "arXiv preprint arXiv:2304.11158,",
            "year": 2023
        },
        {
            "authors": [
                "Nathan Brody"
            ],
            "title": "What is intelligence",
            "venue": "International Review of Psychiatry,",
            "year": 1999
        },
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are few-shot learners",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "S\u00e9bastien Bubeck",
                "Varun Chandrasekaran",
                "Ronen Eldan",
                "Johannes Gehrke",
                "Eric Horvitz",
                "Ece Kamar",
                "Peter Lee",
                "Yin Tat Lee",
                "Yuanzhi Li",
                "Scott Lundberg"
            ],
            "title": "Sparks of artificial general intelligence: Early experiments with gpt-4",
            "venue": "arXiv preprint arXiv:2303.12712,",
            "year": 2023
        },
        {
            "authors": [
                "Richard L Burden",
                "J Douglas Faires",
                "Annette M Burden"
            ],
            "title": "Numerical analysis",
            "venue": "Cengage learning,",
            "year": 2015
        },
        {
            "authors": [
                "Nicholas Carlini",
                "Daphne Ippolito",
                "Matthew Jagielski",
                "Katherine Lee",
                "Florian Tramer",
                "Chiyuan Zhang"
            ],
            "title": "Quantifying memorization across neural language models",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Jiaao Chen",
                "Xiaoman Pan",
                "Dian Yu",
                "Kaiqiang Song",
                "Xiaoyang Wang",
                "Dong Yu",
                "Jianshu Chen"
            ],
            "title": "Skills-in-context prompting: Unlocking compositionality in large language models",
            "venue": "arXiv preprint arXiv:2308.00304,",
            "year": 2023
        },
        {
            "authors": [
                "Wei-Lin Chiang",
                "Zhuohan Li",
                "Zi Lin",
                "Ying Sheng",
                "Zhanghao Wu",
                "Hao Zhang",
                "Lianmin Zheng",
                "Siyuan Zhuang",
                "Yonghao Zhuang",
                "Joseph E Gonzalez"
            ],
            "title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality",
            "venue": "See https://vicuna. lmsys. org (accessed",
            "year": 2023
        },
        {
            "authors": [
                "Minje Choi",
                "Jiaxin Pei",
                "Sagar Kumar",
                "Chang Shu",
                "David Jurgens"
            ],
            "title": "Do llms understand social knowledge? evaluating the sociability of large language models with socket benchmark",
            "venue": "arXiv preprint arXiv:2305.14938,",
            "year": 2023
        },
        {
            "authors": [
                "Hyung Won Chung",
                "Le Hou",
                "Shayne Longpre",
                "Barret Zoph",
                "Yi Tay",
                "William Fedus",
                "Eric Li",
                "Xuezhi Wang",
                "Mostafa Dehghani",
                "Siddhartha Brahma"
            ],
            "title": "Scaling instruction-finetuned language models",
            "venue": "arXiv preprint arXiv:2210.11416,",
            "year": 2022
        },
        {
            "authors": [
                "Peter Clark",
                "Oyvind Tafjord",
                "Kyle Richardson"
            ],
            "title": "Transformers as soft reasoners over language",
            "venue": "Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "Karl Cobbe",
                "Vineet Kosaraju",
                "Mohammad Bavarian",
                "Mark Chen",
                "Heewoo Jun",
                "Lukasz Kaiser",
                "Matthias Plappert",
                "Jerry Tworek",
                "Jacob Hilton",
                "Reiichiro Nakano"
            ],
            "title": "Training verifiers to solve math word problems",
            "venue": "arXiv preprint arXiv:2110.14168,",
            "year": 2021
        },
        {
            "authors": [
                "George Cybenko"
            ],
            "title": "Approximation by superpositions of a sigmoidal function",
            "venue": "Mathematics of control, signals and systems,",
            "year": 1989
        },
        {
            "authors": [
                "Nouha Dziri",
                "Ximing Lu",
                "Melanie Sclar",
                "Xiang Lorraine Li",
                "Liwei Jian",
                "Bill Yuchen Lin",
                "Peter West",
                "Chandra Bhagavatula",
                "Ronan Le Bras",
                "Jena D Hwang"
            ],
            "title": "Faith and fate: Limits of transformers on compositionality",
            "venue": "arXiv preprint arXiv:2305.18654,",
            "year": 2023
        },
        {
            "authors": [
                "Irena Gao",
                "Gabriel Ilharco",
                "Scott Lundberg",
                "Marco Tulio Ribeiro"
            ],
            "title": "Adaptive testing of computer vision models",
            "venue": "arXiv preprint arXiv:2212.02774,",
            "year": 2022
        },
        {
            "authors": [
                "J. Gao",
                "J. Lanchantin",
                "M.L. Soffa",
                "Y. Qi"
            ],
            "title": "Black-box generation of adversarial text sequences to evade deep learning classifiers",
            "venue": "IEEE Security and Privacy Workshops (SPW),",
            "year": 2018
        },
        {
            "authors": [
                "Shahriar Golchin",
                "Mihai Surdeanu"
            ],
            "title": "Data contamination quiz: A tool to detect and estimate contamination in large language models",
            "venue": "arXiv preprint arXiv:2311.06233,",
            "year": 2023
        },
        {
            "authors": [
                "Shahriar Golchin",
                "Mihai Surdeanu"
            ],
            "title": "Time travel in llms: Tracing data contamination in large language models",
            "venue": "arXiv preprint arXiv:2308.08493,",
            "year": 2023
        },
        {
            "authors": [
                "Simeng Han",
                "Hailey Schoelkopf",
                "Yilun Zhao",
                "Zhenting Qi",
                "Martin Riddell",
                "Luke Benson",
                "Lucy Sun",
                "Ekaterina Zubova",
                "Yujie Qiao",
                "Matthew Burtell"
            ],
            "title": "Folio: Natural language reasoning with first-order logic",
            "venue": "arXiv preprint arXiv:2209.00840,",
            "year": 2022
        },
        {
            "authors": [
                "Dan Hendrycks",
                "Collin Burns",
                "Steven Basart",
                "Andy Zou",
                "Mantas Mazeika",
                "Dawn Song",
                "Jacob Steinhardt"
            ],
            "title": "Measuring massive multitask language understanding",
            "venue": "In International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Edward J Hu",
                "yelong shen",
                "Phillip Wallis",
                "Zeyuan Allen-Zhu",
                "Yuanzhi Li",
                "Shean Wang",
                "Lu Wang",
                "Weizhu Chen"
            ],
            "title": "LoRA: Low-rank adaptation of large language models",
            "venue": "In International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Yuzhen Huang",
                "Yuzhuo Bai",
                "Zhihao Zhu",
                "Junlei Zhang",
                "Jinghan Zhang",
                "Tangjun Su",
                "Junteng Liu",
                "Chuancheng Lv",
                "Yikai Zhang",
                "Jiayi Lei"
            ],
            "title": "C-eval: A multi-level multi-discipline chinese evaluation suite for foundation models",
            "venue": "arXiv preprint arXiv:2305.08322,",
            "year": 2023
        },
        {
            "authors": [
                "Di Jin",
                "Zhijing Jin",
                "Joey Tianyi Zhou",
                "Peter Szolovits"
            ],
            "title": "Is bert really robust? a strong baseline for natural language attack on text classification and entailment",
            "venue": "In Proceedings of the AAAI conference on artificial intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "Zhijing Jin",
                "Jiarui Liu",
                "Zhiheng Lyu",
                "Spencer Poff",
                "Mrinmaya Sachan",
                "Rada Mihalcea",
                "Mona Diab",
                "Bernhard Sch\u00f6lkopf"
            ],
            "title": "Can large language models infer causation from correlation",
            "venue": "arXiv preprint arXiv:2306.05836,",
            "year": 2023
        },
        {
            "authors": [
                "Tushar Khot",
                "Harsh Trivedi",
                "Matthew Finlayson",
                "Yao Fu",
                "Kyle Richardson",
                "Peter Clark",
                "Ashish Sabharwal"
            ],
            "title": "Decomposed prompting: A modular approach for solving complex tasks",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Douwe Kiela",
                "Max Bartolo",
                "Yixin Nie",
                "Divyansh Kaushik",
                "Atticus Geiger",
                "Zhengxuan Wu",
                "Bertie Vidgen",
                "Grusha Prasad",
                "Amanpreet Singh",
                "Pratik Ringshia",
                "Zhiyi Ma",
                "Tristan Thrush",
                "Sebastian Riedel",
                "Zeerak Waseem",
                "Pontus Stenetorp",
                "Robin Jia",
                "Mohit Bansal",
                "Christopher Potts",
                "Adina Williams"
            ],
            "title": "Dynabench: Rethinking benchmarking in NLP",
            "venue": "In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human",
            "year": 2021
        },
        {
            "authors": [
                "Dan Klein",
                "Christopher D Manning"
            ],
            "title": "Accurate unlexicalized parsing",
            "venue": "In Proceedings of the 41st annual meeting of the association for computational linguistics,",
            "year": 2003
        },
        {
            "authors": [
                "Jan Koco\u0144",
                "Igor Cichecki",
                "Oliwier Kaszyca",
                "Mateusz Kochanek",
                "Dominika Szyd\u0142o",
                "Joanna Baran",
                "Julita Bielaniewicz",
                "Marcin Gruza",
                "Arkadiusz Janz",
                "Kamil Kanclerz"
            ],
            "title": "Chatgpt: Jack of all trades, master of none",
            "venue": "Information Fusion,",
            "year": 2023
        },
        {
            "authors": [
                "Ben Krause",
                "Emmanuel Kahembwe",
                "Iain Murray",
                "Steve Renals"
            ],
            "title": "Dynamic evaluation of neural sequence models",
            "venue": "In International Conference on Machine Learning,",
            "year": 2018
        },
        {
            "authors": [
                "Jinfeng Li",
                "Shouling Ji",
                "Tianyu Du",
                "Bo Li",
                "Ting Wang"
            ],
            "title": "TextBugger: Generating adversarial text against real-world applications",
            "venue": "In Proceedings 2019 Network and Distributed System Security Symposium. Internet Society,",
            "year": 2019
        },
        {
            "authors": [
                "Linyang Li",
                "Ruotian Ma",
                "Qipeng Guo",
                "Xiangyang Xue",
                "Xipeng Qiu"
            ],
            "title": "BERT-ATTACK: Adversarial attack against BERT using BERT",
            "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
            "year": 2020
        },
        {
            "authors": [
                "Minghao Li",
                "Feifan Song",
                "Bowen Yu",
                "Haiyang Yu",
                "Zhoujun Li",
                "Fei Huang",
                "Yongbin Li"
            ],
            "title": "Apibank: A benchmark for tool-augmented llms",
            "venue": "arXiv preprint arXiv:2304.08244,",
            "year": 2023
        },
        {
            "authors": [
                "Xuechen Li",
                "Tianyi Zhang",
                "Yann Dubois",
                "Rohan Taori",
                "Ishaan Gulrajani",
                "Carlos Guestrin",
                "Percy Liang",
                "Tatsunori B. Hashimoto"
            ],
            "title": "Alpacaeval: An automatic evaluator of instruction-following models. https://github.com/tatsu-lab/alpaca_eval, 2023b",
            "year": 2023
        },
        {
            "authors": [
                "Xuechen Li",
                "Tianyi Zhang",
                "Yann Dubois",
                "Rohan Taori",
                "Ishaan Gulrajani",
                "Carlos Guestrin",
                "Percy Liang",
                "Tatsunori B Hashimoto"
            ],
            "title": "Alpacaeval: An automatic evaluator of instruction-following models, 2023c",
            "year": 2023
        },
        {
            "authors": [
                "Yuanzhi Li",
                "S\u00e9bastien Bubeck",
                "Ronen Eldan",
                "Allie Del Giorno",
                "Suriya Gunasekar",
                "Yin Tat Lee"
            ],
            "title": "Textbooks are all you need ii: phi-1.5 technical report",
            "venue": "arXiv preprint arXiv:2309.05463,",
            "year": 2023
        },
        {
            "authors": [
                "Yucheng Li"
            ],
            "title": "An open source data contamination report for llama series models",
            "venue": "arXiv preprint arXiv:2310.17589,",
            "year": 2023
        },
        {
            "authors": [
                "Mert Yuksekgonul",
                "Mirac Suzgun",
                "Nathan Kim",
                "Neel Guha",
                "Niladri S. Chatterji",
                "Omar Khattab",
                "Peter Henderson",
                "Qian Huang",
                "Ryan Andrew Chi",
                "Sang Michael Xie",
                "Shibani Santurkar",
                "Surya Ganguli",
                "Tatsunori Hashimoto",
                "Thomas Icard",
                "Tianyi Zhang",
                "Vishrav Chaudhary",
                "William Wang",
                "Xuechen Li",
                "Yifan Mai",
                "Yuhui Zhang",
                "Yuta Koreeda"
            ],
            "title": "Holistic evaluation of language models",
            "venue": "Transactions on Machine Learning Research,",
            "year": 2023
        },
        {
            "authors": [
                "David F Lohman",
                "Joni M Lakin"
            ],
            "title": "Intelligence and reasoning",
            "venue": "The Cambridge handbook of intelligence,",
            "year": 2011
        },
        {
            "authors": [
                "Brian Lovin"
            ],
            "title": "Gpt-4 performs significantly worse on coding problems not in its training data",
            "year": 2023
        },
        {
            "authors": [
                "Haipeng Luo",
                "Qingfeng Sun",
                "Can Xu",
                "Pu Zhao",
                "Jianguang Lou",
                "Chongyang Tao",
                "Xiubo Geng",
                "Qingwei Lin",
                "Shifeng Chen",
                "Dongmei Zhang"
            ],
            "title": "Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct",
            "venue": "arXiv preprint arXiv:2308.09583,",
            "year": 2023
        },
        {
            "authors": [
                "Zhiyi Ma",
                "Kawin Ethayarajh",
                "Tristan Thrush",
                "Somya Jain",
                "Ledell Wu",
                "Robin Jia",
                "Christopher Potts",
                "Adina Williams",
                "Douwe Kiela"
            ],
            "title": "Dynaboard: An evaluation-as-a-service platform for holistic next-generation benchmarking",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Inbal Magar",
                "Roy Schwartz"
            ],
            "title": "Data contamination: From memorization to exploitation",
            "venue": "arXiv preprint arXiv:2203.08242,",
            "year": 2022
        },
        {
            "authors": [
                "Yonatan Oren",
                "Nicole Meister",
                "Niladri Chatterji",
                "Faisal Ladhak",
                "Tatsunori B Hashimoto"
            ],
            "title": "Proving test set contamination in black box language models",
            "venue": "arXiv preprint arXiv:2310.17623,",
            "year": 2023
        },
        {
            "authors": [
                "John Palowitch",
                "Anton Tsitsulin",
                "Brandon Mayer",
                "Bryan Perozzi"
            ],
            "title": "Graphworld: Fake graphs bring real insights for gnns",
            "venue": "In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,",
            "year": 2022
        },
        {
            "authors": [
                "Arkil Patel",
                "Satwik Bhattamishra",
                "Navin Goyal"
            ],
            "title": "Are NLP models really able to solve simple math word problems",
            "venue": "In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,",
            "year": 2021
        },
        {
            "authors": [
                "Marco Tulio Ribeiro",
                "Scott Lundberg"
            ],
            "title": "Adaptive testing and debugging of nlp models",
            "venue": "In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
            "year": 2022
        },
        {
            "authors": [
                "Marco Tulio Ribeiro",
                "Tongshuang Wu",
                "Carlos Guestrin",
                "Sameer Singh"
            ],
            "title": "Beyond accuracy: Behavioral testing of NLP models with CheckList",
            "venue": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
            "year": 2020
        },
        {
            "authors": [
                "Subhro Roy",
                "Dan Roth"
            ],
            "title": "Solving general arithmetic word problems",
            "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2015
        },
        {
            "authors": [
                "Tomohiro Sawada",
                "Daniel Paleka",
                "Alexander Havrilla",
                "Pranav Tadepalli",
                "Paula Vidas",
                "Alexander Kranias",
                "John J Nay",
                "Kshitij Gupta",
                "Aran Komatsuzaki"
            ],
            "title": "Arb: Advanced reasoning benchmark for large language models",
            "venue": "arXiv preprint arXiv:2307.13692,",
            "year": 2023
        },
        {
            "authors": [
                "Rylan Schaeffer"
            ],
            "title": "Pretraining on the test set is all you need",
            "venue": "arXiv preprint arXiv:2309.08632,",
            "year": 2023
        },
        {
            "authors": [
                "Koustuv Sinha",
                "Shagun Sodhani",
                "Jin Dong",
                "Joelle Pineau",
                "William L. Hamilton"
            ],
            "title": "CLUTRR: A diagnostic benchmark for inductive reasoning from text",
            "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),",
            "year": 2019
        },
        {
            "authors": [
                "Xiaojuan Tang",
                "Zilong Zheng",
                "Jiaqi Li",
                "Fanxu Meng",
                "Song-Chun Zhu",
                "Yitao Liang",
                "Muhan Zhang"
            ],
            "title": "Large language models are in-context semantic reasoners rather than symbolic reasoners",
            "venue": "arXiv preprint arXiv:2305.14825,",
            "year": 2023
        },
        {
            "authors": [
                "Michael T\u00e4nzer",
                "Sebastian Ruder",
                "Marek Rei"
            ],
            "title": "Memorisation versus generalisation in pre-trained language models",
            "venue": "In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
            "year": 2022
        },
        {
            "authors": [
                "Krishnaiyan Thulasiraman",
                "Madisetti NS Swamy"
            ],
            "title": "Graphs: theory and algorithms",
            "year": 2011
        },
        {
            "authors": [
                "Jidong Tian",
                "Yitian Li",
                "Wenqing Chen",
                "Liqiang Xiao",
                "Hao He",
                "Yaohui Jin"
            ],
            "title": "Diagnosing the first-order logical reasoning ability through LogicNLI",
            "venue": "In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2021
        },
        {
            "authors": [
                "Yuchi Tian",
                "Kexin Pei",
                "Suman Jana",
                "Baishakhi Ray"
            ],
            "title": "Deeptest: Automated testing of deepneural-network-driven autonomous cars",
            "venue": "In Proceedings of the 40th international conference on software engineering,",
            "year": 2018
        },
        {
            "authors": [
                "Hugo Touvron",
                "Louis Martin",
                "Kevin Stone",
                "Peter Albert",
                "Amjad Almahairi",
                "Yasmine Babaei",
                "Nikolay Bashlykov",
                "Soumya Batra",
                "Prajjwal Bhargava",
                "Shruti Bhosale"
            ],
            "title": "Llama 2: Open foundation and fine-tuned chat models",
            "venue": "arXiv preprint arXiv:2307.09288,",
            "year": 2023
        },
        {
            "authors": [
                "Oriol Vinyals",
                "\u0141ukasz Kaiser",
                "Terry Koo",
                "Slav Petrov",
                "Ilya Sutskever",
                "Geoffrey Hinton"
            ],
            "title": "Grammar as a foreign language",
            "venue": "Advances in neural information processing systems,",
            "year": 2015
        },
        {
            "authors": [
                "Jason Wei",
                "Xuezhi Wang",
                "Dale Schuurmans",
                "Maarten Bosma",
                "brian ichter",
                "Fei Xia",
                "Ed H. Chi",
                "Quoc V Le",
                "Denny Zhou"
            ],
            "title": "Chain of thought prompting elicits reasoning in large language models",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Tianwen Wei",
                "Liang Zhao",
                "Lichang Zhang",
                "Bo Zhu",
                "Lijie Wang",
                "Haihua Yang",
                "Biye Li",
                "Cheng Cheng",
                "Weiwei L\u00fc",
                "Rui Hu"
            ],
            "title": "Skywork: A more open bilingual foundation model",
            "year": 1934
        },
        {
            "authors": [
                "Zhaofeng Wu",
                "Linlu Qiu",
                "Alexis Ross",
                "Ekin Aky\u00fcrek",
                "Boyuan Chen",
                "Bailin Wang",
                "Najoung Kim",
                "Jacob Andreas",
                "Yoon Kim"
            ],
            "title": "Reasoning or reciting? exploring the capabilities and limitations of language models through counterfactual tasks",
            "venue": "arXiv preprint arXiv:2307.02477,",
            "year": 2023
        },
        {
            "authors": [
                "Linyi Yang",
                "Shuibai Zhang",
                "Libo Qin",
                "Yafu Li",
                "Yidong Wang",
                "Hanmeng Liu",
                "Jindong Wang",
                "Xing Xie",
                "Yue Zhang"
            ],
            "title": "Glue-x: Evaluating natural language understanding models from an out-ofdistribution generalization perspective",
            "venue": "In Findings of ACL,",
            "year": 2023
        },
        {
            "authors": [
                "Shuo Yang",
                "Wei-Lin Chiang",
                "Lianmin Zheng",
                "Joseph E Gonzalez",
                "Ion Stoica"
            ],
            "title": "Rethinking benchmark and contamination for language models with rephrased samples",
            "venue": "arXiv preprint arXiv:2311.04850,",
            "year": 2023
        },
        {
            "authors": [
                "Matej Ze\u010devi\u0107",
                "Moritz Willig",
                "Devendra Singh Dhami",
                "Kristian Kersting"
            ],
            "title": "Causal parrots: Large language models may talk causality but are not causal",
            "venue": "Transactions on Machine Learning Research,",
            "year": 2023
        },
        {
            "authors": [
                "Chiyuan Zhang",
                "Samy Bengio",
                "Moritz Hardt",
                "Benjamin Recht",
                "Oriol Vinyals"
            ],
            "title": "Understanding deep learning (still) requires rethinking generalization",
            "venue": "Communications of the ACM,",
            "year": 2021
        },
        {
            "authors": [
                "Le Zhang",
                "Zichao Yang",
                "Diyi Yang"
            ],
            "title": "TreeMix: Compositional constituency-based data augmentation for natural language understanding",
            "venue": "In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,",
            "year": 2022
        },
        {
            "authors": [
                "Yifan Zhang",
                "Jingqin Yang",
                "Yang Yuan",
                "Andrew Chi-Chih Yao"
            ],
            "title": "Cumulative reasoning with large language models",
            "venue": "arXiv preprint arXiv:2308.04371,",
            "year": 2023
        },
        {
            "authors": [
                "Jie Zhao",
                "Xiang Deng",
                "Huan Sun"
            ],
            "title": "Easy-to-hard: Leveraging simple questions for complex question generation, 2019",
            "year": 2019
        },
        {
            "authors": [
                "Lianmin Zheng",
                "Wei-Lin Chiang",
                "Ying Sheng",
                "Siyuan Zhuang",
                "Zhanghao Wu",
                "Yonghao Zhuang",
                "Zi Lin",
                "Zhuohan Li",
                "Dacheng Li",
                "Eric Xing"
            ],
            "title": "Judging llm-as-a-judge with mt-bench and chatbot arena",
            "venue": "arXiv preprint arXiv:2306.05685,",
            "year": 2023
        },
        {
            "authors": [
                "Wanjun Zhong",
                "Ruixiang Cui",
                "Yiduo Guo",
                "Yaobo Liang",
                "Shuai Lu",
                "Yanlin Wang",
                "Amin Saied",
                "Weizhu Chen",
                "Nan Duan"
            ],
            "title": "Agieval: A human-centric benchmark for evaluating foundation models",
            "venue": "arXiv preprint arXiv:2304.06364,",
            "year": 2023
        },
        {
            "authors": [
                "Chunting Zhou",
                "Pengfei Liu",
                "Puxin Xu",
                "Srini Iyer",
                "Jiao Sun",
                "Yuning Mao",
                "Xuezhe Ma",
                "Avia Efrat",
                "Ping Yu",
                "Lili Yu",
                "Susan Zhang",
                "Gargi Ghosh",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Omer Levy. Lima"
            ],
            "title": "Less is more for alignment, 2023a",
            "year": 2023
        },
        {
            "authors": [
                "Denny Zhou",
                "Nathanael Sch\u00e4rli",
                "Le Hou",
                "Jason Wei",
                "Nathan Scales",
                "Xuezhi Wang",
                "Dale Schuurmans",
                "Claire Cui",
                "Olivier Bousquet",
                "Quoc Le"
            ],
            "title": "Least-to-most prompting enables complex reasoning in large language models",
            "venue": "In ICLR,",
            "year": 2023
        },
        {
            "authors": [
                "Kun Zhou",
                "Yutao Zhu",
                "Zhipeng Chen",
                "Wentong Chen",
                "Wayne Xin Zhao",
                "Xu Chen",
                "Yankai Lin",
                "Ji-Rong Wen",
                "Jiawei Han"
            ],
            "title": "Don\u2019t make your llm an evaluation benchmark cheater",
            "venue": "arXiv preprint arXiv:2311.01964,",
            "year": 2023
        },
        {
            "authors": [
                "Yongchao Zhou",
                "Andrei Ioan Muresanu",
                "Ziwen Han",
                "Keiran Paster",
                "Silviu Pitis",
                "Harris Chan",
                "Jimmy Ba"
            ],
            "title": "Large language models are human-level prompt engineers",
            "venue": "In ICLR,",
            "year": 2023
        },
        {
            "authors": [
                "Kaijie Zhu",
                "Jindong Wang",
                "Jiaheng Zhou",
                "Zichen Wang",
                "Hao Chen",
                "Yidong Wang",
                "Linyi Yang",
                "Wei Ye",
                "Neil Zhenqiang Gong",
                "Yue Zhang"
            ],
            "title": "Promptbench: Towards evaluating the robustness of large language models on adversarial prompts",
            "venue": "arXiv preprint arXiv:2306.04528,",
            "year": 2023
        },
        {
            "authors": [
                "Zeyuan Allen Zhu",
                "Yuanzhi Li"
            ],
            "title": "Physics of language models: Part 3.1, knowledge storage and extraction, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Caleb Ziems",
                "William Held",
                "Omar Shaikh",
                "Jiaao Chen",
                "Zhehao Zhang",
                "Diyi Yang"
            ],
            "title": "Can large language models transform computational social science",
            "venue": "arXiv preprint arXiv:2305.03514,",
            "year": 2023
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Large Language Models (LLMs) have recently achieved unprecedented performance across diverse tasks (OpenAI, 2023b; Bubeck et al., 2023). The great endeavor have led to positive speculation on the possibility of LLMs being precursors of artificial general intelligence, necessitating the creation of nuanced evaluations. By pinpointing gaps for improvements, evaluation becomes the bedrock that enhances the understanding of current models and ensures AI\u2019s continued progression.\nEfforts to evaluate LLMs have become intensified significantly. Liang et al. (2023) introduced HELM, which offers a holistic assessment of LLM in various scenarios. Similarly, Chatbot Arena (Zheng et al., 2023) evaluates LLMs by contrasting their generated output. Other benchmarks that have set the standard in the realm of LLM evaluations include AlpacaEval (Li et al., 2023c), C-Eval (Huang et al., 2023), ARB (Sawada et al., 2023), API-Bank (Li et al., 2023a), Socket (Choi et al., 2023), and Big-Bench (bench authors, 2023). Moreover, manual experiments have emerged as a complementary approach to these benchmarks, with works such as Bubeck et al. (2023) and Bang et al. (2023). Complementing these, human evaluators have also been instrumental in gauging the prowess of LLMs, as discussed by Ziems et al. (2023) and Zec\u030cevic\u0301 et al. (2023).\nCurrent evaluation benchmarks face two fundamental challenges. First, data contamination. Many benchmarks source their data from the Internet, causing potential overlap with the vast corpus on which LLMs are trained, leading to the debate of \u201cGeneralization vs. Memorization\u201d (Bender et al., 2021; Magar & Schwartz, 2022; Carlini et al., 2023; Biderman et al., 2023): Are the model\u2019s results stemming from genuine ability or just memorization of the training data? A recent example is provided by Zec\u030cevic\u0301 et al. (2023): LLMs can ambiguously deduce the conclusion that altitude influences temperature based on seen data. Similarly, Berglund et al. (2023) found that LLMs trained\n\u2217Equal contribution. Contact: kaijiezhu11@gmail.com, jiaaochen@gatech.edu. \u2020Correspondence to: Jindong Wang <jindong.wang@microsoft.com>.\non \u201cA is B\u201d fail to infer \u201cB is A\u201d, which doubts the abilities of LLMs might come from memorization. Second, static dataset and fixed complexity. As LLMs progress at a rapid pace, existing datasets usually fail to match the models\u2019 ever-evolving capabilities, because the complexity level of existing benchmarks is usually static and fixed. As Dziri et al. (2023) demonstrated, while handling simple problems pretty well, LLMs fail to solve complex problems. The inability to automatically and dynamically increase complexity levels based on existing data prevents static benchmarks from being adapted to accurately select, compare, and advance LLMs. Although there are a few existing dynamic benchmarks like DynaBench (Kiela et al., 2021) and DynaBoard (Ma et al., 2021), they rely on crowd-sourcing efforts for data collection, which might be expensive and tedious.\nIn this paper, we introduce DYVAL\u2014a novel, general, and flexible evaluation protocol for the dynamic evaluation of LLMs (Sec. 3.1). The core of DYVAL is to dynamically generate evaluation samples on the fly instead of collecting a fixed set of data. DYVAL consists of three components: 1) the generation algorithm G to generate test samples with diversities; 2) the constraint C to modulate sample complexity and validity; and 3) the description function F to translate the generated samples into natural languages. Based on this framework, we propose a graph-informed DYVAL (Sec. 3.2, Figure 1) to generate data using graphs. Specifically, inspired by techniques such as the compiler principle (Alfred V et al., 2007) and parsing trees which decompose complexities (Klein & Manning, 2003; Vinyals et al., 2015), we employ directed acyclic graphs (DAG) (Thulasiraman & Swamy, 2011) to compose fundamental elements into more intricate problems, with each unit symbolized as a graph node. The extendable and stochastic nature of graph generation effectively regulates the complexity levels. Additionally, the hierarchical attributes of graphs suit them for multi-step inferential tasks like logics. Problems generated by DYVAL not only require profound understanding of problem solving rather than simple memorization but also echo the human approach to incremental problem-solving and solution derivation. Being general and flexible, DYVAL co-exists and co-evolves with existing benchmarks for better LLMs evaluation and evolution.\nWe leverage DYVAL to synthesize 7 reasoning tasks1, encompassing: (1) Mathematics: arithmetic and linear equations; (2) Logical reasoning: boolean, deductive, and abductive logic; (3) Algorithm: reachability and maximum sum path problems. We then re-examine the state-of-the-art LLMs ranging from Flan-T5-large (Chung et al., 2022), phi-1.5 (Li et al., 2023d), Xwin-13B (Team, 2023), Llama2-13B-chat (Touvron et al., 2023), Vicuna-13B-v1.3 (Chiang et al., 2023), WizardMath13B (Luo et al., 2023), to GPT-3.5-Turbo (OpenAI, 2023a) and GPT-4 (OpenAI, 2023b) with DYVAL. We also test with recent prompting techniques including Few-shot (Brown et al., 2020), CoT (Wei et al., 2022), Least to Most prompting (Zhou et al., 2023b), Automatic Prompt Engineering (Zhou et al., 2023d), and Skills-in-Context prompting (Chen et al., 2023). Finally, we perform human study involving 82 human evaluators for comparison and fine-tuning experiments using DYVAL-generated evaluation samples. Furthermore, experiments on existing benchmarks also show that fine-tuning LLMs with data generated by DYVAL could directly improve models\u2019 abilities without extra careful collection of training data (Zhou et al., 2023a). We further show the flexibility of DYVAL by extending it to natural language tasks in Appendix H. Our key findings are:\n\u2022 Results on DYVAL evaluation are not always consistent with those on existing benchmarks, indicating possible low training data quality and/or data contamination of existing LLMs (Sec. 4.2). For instance, phi-1.5, WizardMath-13B, and Xwin-13B perform poorly on DYVAL while claiming huge improvements on existing benchmarks.\n\u2022 As difficulty increases, LLMs tend to perform worse and their performance gap becomes larger, emphasizing the lack of compositionality of current LLMs and the importance of evolving complexity evaluations (Sec. 4.2).\n\u2022 Our error analysis based on DYVAL evaluation exhibits various failure patterns which shed light on how to further improve LLMs. (Sec. 4.3).\n\u2022 No prompt engineering methods can perform best in all of our evaluation sets; and larger model sizes tend to achieve better performances (Sec. 4.4).\n\u2022 DYVAL can further be utilized to generate training data to improve the abilities of LLMs. (Sec. 5). For instance, fine-tuning the Llama2 models with our DYVAL generated data demonstrates enhanced results on 6 existing benchmarks. 1We choose reasoning tasks mainly due to (1) the intrinsic connection between reasoning proficiency and intelligence; (2) the notable progress LLMs have achieved in reasoning-centric tasks (Sawada et al., 2023). Note that DYVAL could also be applied to existing benchmarks to create new and harder evaluation data.\nTo sum up, this paper makes the following contributions:\n\u2022 A dynamic evaluation protocol. DYVAL is a dynamic evaluation protocol designed to generate test samples dynamically, mitigating the issues of data contamination and static complexity.\n\u2022 A graph-informed DYVAL algorithm for evaluation of the reasoning abilities of LLMs. We use DAGs to compose 7 reasoning problems from mathematics, logical reasoning to algorithms.\n\u2022 Extensive experiments and analysis. We conduct extensive experiments to provide insights for evaluating and improving LLMs."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "Evaluating LLMs. While neural networks are recognized as the universal function approximators (Cybenko, 1989) with remarkable data fitting capabilities (Zhang et al., 2021; Arpit et al., 2017), debates (Bender et al., 2021; Zhang et al., 2021; Ta\u0308nzer et al., 2022; Magar & Schwartz, 2022; Carlini et al., 2023; Wu et al., 2023; Tang et al., 2023; Zec\u030cevic\u0301 et al., 2023; Kocon\u0301 et al., 2023; Schaeffer, 2023; Biderman et al., 2023; Zhu & Li, 2023) persist regarding the true nature of LLMs\u2019 generalization abilities. The growing prominence of LLMs necessitates rigorous benchmarks (Hendrycks et al., 2021; Li et al., 2023b; Zhong et al., 2023; HuggingFace, 2023). Recent trends include: (1) human-centric evaluations (Gao et al., 2022; Ribeiro & Lundberg, 2022), (2) crowd-sourced testing (Kiela et al., 2021; Ma et al., 2021), and (3) specialized task challenges (Liang et al., 2023; Tian et al., 2018; Ribeiro et al., 2020; bench authors, 2023). Complementing with these, our DYVAL introduces a dynamic evaluation system, consistently relevant in the swiftly evolving landscape of AI. Although Krause et al. (2018) introduced the term \u201cdynamic evaluation\u201d, our DYVAL differs considerably in its approach and goals. Specifically, reasoning is widely recognized as the core of both human and AI. Our focus on constructing reasoning tasks mirrors the intricate and multi-step nature of human reasoning (Brody, 1999; Lohman & Lakin, 2011; Sawada et al., 2023), building reasoning benchmarks is a critical step to help LLMs towards intelligence.\nData Contamination. Researchers start to realize the potential data contamination problem in LLMs (Lovin, 2023; Chowdhuri et al., 2023; Bender et al., 2021; Kocon\u0301 et al., 2023). The GPT-4 and LLama reports clearly stated the phenomenon of data contamination. Recently, Zhou et al. (2023c) discussed the risks and impacts of data contamination of evaluation benchmarks in assessing LLMs. Li (2023) examined the data contamination problem of LLama models. The Skywork LLM Wei et al. (2023) again demonstrated the data contamination issue in several. Golchin & Surdeanu (2023a;b); Oren et al. (2023); Yang et al. (2023b) designed novel methods to detect the data contamination of LLMs. DYVAL is not a detection approach but a new protocol to mitigate the contamination issue.\nComplex-to-simple problem decomposition and evaluation set construction. Employing graphs to deconstruct complex tasks has been an enduring and effective strategy across domains. Compilers, as seen in computational theory (Alfred V et al., 2007), effectively break down highlevel constructs, while in NLP, parsing trees bring clarity to intricate syntactic and semantic structures (Klein & Manning, 2003; Vinyals et al., 2015). Roy & Roth (2015) displayed the potency of this method in arithmetic, using trees for solving multi-step problems. Additionally, several contemporary techniques have implored LLMs to decompose complex problems (Wei et al., 2022; Zhou et al., 2023b; Khot et al., 2022; Zhang et al., 2023). Several studies have leveraged graph-based approaches for constructing compositional tasks, particularly in the domains of first-order logic (Sinha et al., 2019; Clark et al., 2020; Tian et al., 2021) and causal reasoning (Jin et al., 2023). DYVAL presents notable distinctions in both objective and methodology. Additionally, GraphWorld (Palowitch et al., 2022) primarily benchmarks Graph Neural Networks (GNNs), whereas DYVAL focuses on LLMs using the graph structure. They are different in nature."
        },
        {
            "heading": "3 DYVAL",
            "text": "In this section, we first elucidate our general dynamic evaluation protocol to address the challenges of data contamination with dynamic data generation and controllable complexity in Sec. 3.1. We then adapt this general protocol for reasoning tasks by leveraging the Directed Acyclic Graphs (DAGs) in Sec. 3.2. More analysis of the flexibility of DYVAL is in Sec. 3.3."
        },
        {
            "heading": "3.1 GENERAL DYNAMIC EVALUATION DESCRIPTION LANGUAGE",
            "text": "First, we introduce the general description language of the dynamic evaluation protocol. Given a task T , a dynamic evaluation algorithm is formulated as AT = F(G(C)), where (1) G is the sample generation algorithm, incorporating randomness to guarantee uniqueness of each sample. Randomness may vary in different tasks, such as the numbers in math problems and the logic chains in a logic reasoning task. (2) C = {CT , CG} denotes constraints on G, where CT is the task constraint for task T such as the legality guarantee of the generated samples in the context of the task. CG is the complexity constraint for the generation process, such as the sampling strategy for the value at each node and the number of perturbations added to the evaluation samples. (3) F = {FT ,FG} is the description function to translate the raw evaluation samples generated by G into natural language descriptions. FG elucidates the characteristics and properties of the samples generated by G. FT is the description for task T such as task objective and expected outcomes.\nIn general, an evaluation sample can be represented as deval = FT (FG(G(CG , CT ))) using the above description language. G first produces a sample that adheres to the complexity constraint CG and the task constraint CT . Then it undergoes transformation by description function FG into a natural language format and finally goes through the task description function FT . The description language above naturally (1) avoids data contamination by dynamic generation through G, and (2) promises dynamic datasets and controllable complexity through C. Specifically, by varying the constraints in C, we can generate evaluation samples of different difficulties, allowing \u201cco-evolution\u201d of both the LLMs and the evaluation process. The description language is flexible since it allows for different generation algorithms and complexity control by changing G and C accordingly."
        },
        {
            "heading": "3.2 GRAPH-INFORMED DYNAMIC EVALUATION FOR REASONING TASKS",
            "text": "In this section, following the general evaluation description language, we implement DYVAL for reasoning tasks by taking inspiration from the graph structure. Given the intrinsic multistep inferential nature of reasoning tasks, they inherently exhibit structural characteristics, making directed acyclic graphs (DAGs) a natural choice for modeling these tasks. DAGs also facilitate dynamic sample generation by modulating the internal structure and fine-grained control over problem difficulty by adjusting the structural complexity. More background of DAGs can be found in Appendix A."
        },
        {
            "heading": "3.2.1 GENERATION ALGORITHM G : DAG CONSTRUCTION",
            "text": "The generation algorithm is established on the graph construction process. We categorize DAGs as Tree-based DAGs (T-DAGs) and General DAGs (G-DAGs), illustrated in Figure 1. T-DAGs are inherently hierarchical, making them suitable for tasks that proceed from a set of initial premises to\na final inference, such as arithmetic problems and logical reasoning tasks. Each node in T-DAGs represents a foundational subproblem. These subproblems are chained by the links between nodes and finally form a complex problem. Conversely, G-DAGs excel in mapping intricate relationships, especially in tasks demanding understanding of non-linear interactions. They are ideal for algorithmic challenges involving complex dependencies. For instance, imagine modeling a system where a change in one entity might impact multiple others in a cascading fashion, or tasks require finding different potential pathways between entities. The generation process for these two types of DAGs are presented in Appendix B.1.\nRandomness in DAGs generation process. T-DAG randomness arises from operations assigned to the nodes and the initial values of the leaf nodes. For instance, in arithmetic, the operation can be \u201c+\u201d, with the leaf nodes receiving random numbers. On the other hand, for G-DAGs, each node is endowed with a random value (if needed for a certain problem). For every node, the number of children is determined randomly, and the maximum number of children depends on the input. We then establish the links by selecting the target child nodes at random.\nTheorems 3.1 and 3.2 formally guarantee the dynamic generation process by exploring the probability that two samples generated by T-DAG and G-DAG are identical. We focus exclusively on the base case, setting aside additional complexities like the integration of random links or the embedding of random descriptions, which would further diminish the likelihood of two DAGs being identical. Theorem 3.1. Given a tree-based DAG with depth d and width w, if the operation set for nonleaf nodes has k distinct operations and the value set for leaf nodes contains n distinct values, the\nprobability that two independently generated DAGs are identical is: P = ( k wd\u22121\u22121 w\u22121 \u00d7 nwd\u22121 )\u22121 .\nTheorem 3.2. Given a general DAG with n nodes where each node has a minimum of l \u2265 1 links, the probability that two randomly selected DAGs are identical is bounded by 1(n\u22121)! . Proofs can be found in Appendix C. These theorems guarantee that the odds of producing identical evaluation samples are considerably low. For instance, in the arithmetic task (where k = 6, n = 10) with d = 4 and w = 2, the chances that two DAGs are identical hover around 1e\u221215."
        },
        {
            "heading": "3.2.2 CONSTRAINTS C FOR GRAPH GENERATION",
            "text": "Task constraint CT . Task constraints vary for tasks. Take the node creation for instance: 1) What distribution should the node value adhere to? 2) What set of operations is permissible? 3) How should a node\u2019s value be computed from its children\u2019s values? In arithmetic tasks, CT includes ensuring that a dividend is nonzero, avoiding overflow, etc. Here, we concentrate on two general task constraints: (1) Value distribution V: Specifies the permissible range or distribution from which leaf node values can be assigned. For example, in logic reasoning tasks, the premises (leaf nodes) are assigned either as True or False. (2) Operation set O: Lists the operations allowed within the DAG. The operation set constraint is usually used for tree-based DAGs. For example, in an arithmetic task, the set of allowed operations can be defined as the basic arithmetic operations {+,\u2212,\u00d7, /}. Complexity constraint CG . We investigate 4 techniques to inject complexity into DAGs (Figure 5): (1) Change width and depth for T-DAGs: The natural way to control tree complexity. (2) Change number of nodes and links for G-DAGs: We control the total number of nodes in G-DAGs. The\nnumber of links in each node is randomly selected from a predefined range, e.g., [1, 5]. (3) Add extra random links: For each node, we may introduce an additional link to another random node. (4) Embed random descriptions: Add random descriptions to the primary DAG\u2019s descriptions. More details of complexity can be found in Appendix B.2 with Figure 7 as illustrations."
        },
        {
            "heading": "3.2.3 DESCRIPTION FUNCTION F",
            "text": "After constructing DAGs with certain constraints, we then need to convert them into comprehensible natural language descriptions using the description function F . DAG description function FG . We describe the DAG node by node and then form the description of the nodes into sequences. The interpretation of each node in natural language depends on its position and the task. For leaf nodes that represent primary input or premises, they can be described as: \u201cThe value of [Name] is [Value].\u201d For instance, a node denoting number 5 could be expressed as: \u201cThe value of node A is 5.\u201d For T-DAGs, the intermediate nodes that typically denote operations performed on their child nodes, the description can be formulated as: \u201cThe value of [Name] is derived by [Operation] the values of [Children\u2019s Names].\u201d For G-DAG, the intermediate nodes are usually described as the connections between nodes: \u201cThe [Name] points to [Children\u2019s Names]\u201d. Note that natural language descriptions can be replaced according to custom needs and can be further incorporated with textual adversarial attacks (Li et al., 2019; Gao et al., 2018; Jin et al., 2020; Li et al., 2020).\nMoreover, complexity is also influenced by the order that nodes are described. We design three orders: topological, reversed topological, and random orders, each offering a unique challenge in understanding the DAGs. The details of these orders are presented in Appendix B.4.\nTask description function FT . The construction of F highly depends on the context of tasks. Notebly, this construction is also highly flexible. For instance, incorporating adversarial prompts (Zhu et al., 2023) to the task description can make problems more difficult. Here we present the task description function for arithmetic and reachability tasks that are representative of T-DAG and G-DAG, respectively. Appendix B.3 presents details and examples of the remaining 5 tasks.\nArithmetic: Given a T-DAG, the DAG description function has already demonstrated the premise: the leaf nodes and the intermediate steps of inference: non-leaf nodes. Next, we select the root node as the variable required to solve, we append the question \u201cWhat is the value of [Root]?\u201d to the description where [Root] is filled with the name of the root variable (Figure 8).\nReachability: The reachability task aims to model if two nodes are connected in a graph. For a GDAG, the DAG description function has demonstrated the connections between nodes. The task description for reachability task is: \u201cCan the [Node i] be reached by [Node j]\u201d where Node i and Node j are randomly selected from the nodes in G-DAG (Figure 9).\nFinally, while it is feasible to directly adopt GPT-4 to generate a contextualized description rather than the plain one (see Appendix B.5), it is challenging to verify the rationale of the problems generated by GPT-4. Thus, we leave it for future work."
        },
        {
            "heading": "3.3 DYVAL COEXISTS AND CO-EVOLVES WITH EXISTING BENCHMARKS",
            "text": "DYVAL is complementary to existing benchmarks. First, tasks with an intrinsic structure benefit significantly from DYVAL since they can modulate complexity and randomness by adjusting the generation process. Efforts such as CheckList (Ribeiro et al., 2020), data augmentation (Andreas, 2020; Zhang et al., 2022), and reasoning dataset synthesis (Sinha et al., 2019; Zhao et al., 2019; Clark et al., 2020; Tian et al., 2021; Jin et al., 2023) can be easily integrated into DYVAL. On the contrary, tasks without a well-defined structure may present challenges for DYVAL\u2019s implementation. Second, DYVAL can be enhanced by existing benchmarks to formulate more challenging scenarios. For instance, the description function F is all about natural language texts, so it can be easily combined with adversarial attacks (Li et al., 2019; Jin et al., 2020; Zhu et al., 2023) or out-of-distribution prompts (Yang et al., 2023a) to assess the robustness of LLMs.\nNote that while this papers focuses on evaluating reasoning tasks, DYVAL is flexible to evaluate natural language tasks. We show an initial study using DYVAL to evaluate sentiment analysis in Appendix H and more work can be done in the future. Finally, DYVAL guarantees an unbiased and\nbalanced construction of evaluation samples by nature, since one can easily control the generation process, as shown in Appendix F."
        },
        {
            "heading": "4 EXPERIMENT",
            "text": ""
        },
        {
            "heading": "4.1 SETUP",
            "text": "Tasks and complexity level. We mainly discuss the constraint used in each task. Test set accuracy might differ as it is generated dynamically. To balance test time and discrepancy, we produce 500 samples for each dataset. To mitigate the impact of randomness on evaluation results, we assess each dataset three times. We define 4 complexity levels (D1\u223cD4) for each task. For tasks that use general DAGs, the number of nodes is set to {7, 10, 15, 20} with each node having {3, 4, 6, 8} maximum links and 1 minimum link. For tasks that use tree-based DAGs, tree depths and widths are (2, 2), (3, 2), (3, 3), (4, 2), respectively. More details of D1\u223cD4 are presented in Appendix D. Evaluation metric. Our primary evaluation metric is accuracy. For tasks where answers are numerical, we employ relative precision (Burden et al., 2015) to determine the correctness of a prediction, i.e., an answer is deemed correct if its relative precision is within a specified threshold, \u03c3 (e.g., 0.01%), in relation to the ground truth value. Relative precision is calculated as |pred \u2212 gt|/(gt + \u03f5) \u2264 \u03c3 where gt represents the ground truth value, pred is the model\u2019s prediction, | \u00b7 | is the absolute value function, \u03c3 is the desired relative precision threshold, and \u03f5 is a small value introduced to prevent division by zero.\nLLMs. Our evaluated LLMs include Flan-T5-large (Chung et al., 2022), phi-1.5 (Li et al., 2023d), WizardMath-13B (Luo et al., 2023), Xwin-13B (Team, 2023), Llama2-13B-chat (Touvron et al., 2023), Vicuna-13B-v1.3 (Chiang et al., 2023), GPT-3.5-Turbo (OpenAI, 2023a), and GPT-4 (OpenAI, 2023b). Temperature is set to 0 to avoid randomness. We set the generation length to be directly proportional to the input length. Specifically, for GPT-3.5-Turbo and GPT-4, the generate length is set to be twice the input length; for the remaining models, it is set to be five times the input length. We designed prompts for each task, incorporating demonstrations of rules, particularly for reasoning and algorithm tasks. To ensure formatted output, we further ask LLMs to explicitly output their predictions between \u201c\u27e8\u27e8\u27e8\u201d and \u201c\u27e9\u27e9\u27e9\u201d. All implementations are based on Huggingface."
        },
        {
            "heading": "4.2 RESULTS FOR MATH, LOGICAL REASONING, AND ALGORITHM TASKS",
            "text": "Before presenting the main results, note that the results of Flan-T5-large, phi-1.5, WizardMath13B, and Xwin-13B in all tasks are 0, so we no longer report them. We carried out experiments using three random seeds. Figure 2 shows the results of all tasks averaged in three generation orders and three random seeds (full results in Appendix D.4). GPT-4 performs best, followed closely by GPT-3.5-Turbo. Llama2-13B-chat\u2019s performance is subpar, with Vicuna-13B-v1.3 occasionally outperforming Llama2-13b-chat. More findings are as follows.\nInconsistent performance between existing static benchmarks and DYVAL: Despite the excellent results of phi-1.5, Xwin-13B and WizardMath-13B on existing benchmarks, their poor performance in our evaluations highlights the potential problems when evaluating LLMs solely on static benchmarks and possible low training data quality or data contamination issue.\nDifficulty with complex datasets: Performance mostly decreases sharply from D1 to D4, highlighting LLMs\u2019 struggles with increasing complexity. For example, GPT-3.5-Turbo\u2019s performance drops by 23% for arithmetic task as complexity increases. Notably, performance in abductive logic (inferring premises from conclusions) is much lower than in deductive logic (deriving conclusions from premises), as supported by Berglund et al. (2023), which shows LLMs excel more in \u201cA is B\u201d than \u201cB is A\u201d. In addition, the performance difference between GPT-4 and GPT-3.5-Turbo, while subtle in simpler tasks like D1, becomes prominent in complex tasks. These observations indicate the value of intricate and evolving tasks to effectively differentiate and evaluate models. We also present more interesting observations in Appendix D.4.\nHuman study: We recruited 82 human evaluators with at least a bachelor\u2019s degree2, to gauge their skills against LLMs on the most complex dataset (D4) for mathematical and logical reasoning tasks. Each participant tackled 5 problems from each dataset. As depicted in Figure 3, both GPT-4 and GPT-3.5-Turbo consistently showed high competence in most tasks, surpassing average human results. The reason could be that the generated problems are generally harder for humans but easier for LLMs. Nevertheless, GPT-4 struggled in areas like linear equations and abductive logic. This indicates that future development could involve more data from specific domains.\n4.3 CASE STUDY\nIn an endeavor to comprehensively understand the behavior of LLMs, we meticulously examined the failure modes. Our focus is especially on the most challenging datasets for arithmetic, deductive logic, abductive logic, and reachability tasks based on the performance of GPT-4. We randomly selected 20 failure samples for each task and summarized the failure modes in Figure 4. The detailed failure cases are presented in Appendix D.5. The error types vary, indicating that there is much room for improvement.\nPartial calculation error: GPT-4 occasionally errs in intermediate steps, while keeping the remaining steps correct. We emphasize that the errors may be as simple as 20/7 = 37.28. This aligns with (Dziri et al., 2023) noting LLMs sometimes give partially correct multi-digit multiplication results. Incorrect reasoning and self contradiction: In reasoning tasks, GPT-4 may misinterpret rules. Given an abductive logic A \u2228 B \u2192 C with C is False, the premise A,B must be False. However, GPT-4 inaccurately abduced that either A or B might be False. Further, GPT-4 occasionally contradicts itself in its assumptions for the same inference in abductive logic task. Unsubstantiated response: In reasoning tasks and algorithm tasks, GPT-4 often answers without any inferences or justifications. Its answer-only responses suggest possible memorization or shallow understanding. Instructional oversight: Occasionally, GPT-4 adeptly arrives at the correct computation but stumbles when it comes to adhering to the output instructions laid out in prompts, for example, the required relative precision of mathematic calculation."
        },
        {
            "heading": "4.4 ABLATION STUDY",
            "text": "Impact of complexity constraints CG: In Figure 5, we vary complexity in GPT-3.5-Turbo by adjusting constraints as described in Sec. 3.2.2 and observe how LLMs performance shifts across arithmetic, boolean logic, and deductive logic tasks. Notably, as task intricacy rises due to augmented complexity parameters, LLMs\u2019 performance diminishes. Depth emerges as the predominant challenge in tree-based DAGs, emphasizing the LLMs\u2019 difficulty with extended inference steps.\nPrompt engineering: We evaluate five prompting techniques (PE) on our most challenging datasets, as outlined in Table 5 and Appendix D.7. No PE methods can perform best in all tasks. While APE notably boosts the Linear Equation task by 10%, it negatively impacts deductive and abductive logic. These varied outcomes highlight the importance of task-specific PE selection and development.\n2The results may not represent the highest level of human performance. Demographics are in Appendix D.8.\nArithmetic\nBoolean Logic\nDeductive Logic\nDepth Width Add Extra Links Embed Random Descs\nInfluence of model size: We further evaluate the performance of Llama2 with different model sizes of arithmetic, boolean logic and reachability tasks on their simplest dataset D1. Table 6 shows that larger sizes produce better results, but mostly still not surpass GPT-4 and human.\n5 DYVAL HELPS FINE-TUNING\nIn this section, we show that DYVAL-generated data can further be utilized to fine-tune LLMs to improve their capabilities of solving complex tasks. Specifically, we generate training data for 7 tasks to fine-tune Llama2-13Bchat. The details of fine-tuning and training sample generation are in Appendix E. We then test the model with different settings: (1) in-distribution samples with the same difficulty as the training data; (2) out-of-distribution samples, whose difficulty levels are higher than the training data. To further demonstrate the effectiveness of our generated data, we test the models with few-shot examples on existing benchmarks including GSM8K (Cobbe et al., 2021) and SVAMP (Patel et al., 2021) to evaluate math abilities, FOLIO (Han et al., 2022) and RACO (bench au-\nthors, 2023) to evaluate the logical reasoning abilities, and DP (Dziri et al., 2023) and LCS (bench authors, 2023) to evaluate the algorithm abilities. Results in Figure 6 and 10 show that the performance of the fine-tuned model increases in all tasks. It shows that DYVAL is effective not only as a benchmark but also in enhancing the performance of LLMs on existing benchmarks via fine-tuning on its generated samples. The improvement might stem from the similarities between various benchmarks and DYVAL-generated samples. For instance, GSM8K samples can be interpreted as trees of depth 2 or 3. Interestingly, even no dynamic programming tasks in our fine-tuning, the fine-tuned model also showed improved performance on the DP and LCS datasets. This underscores the potential learning capability of LLMs and the efficacy of training samples generated by DYVAL. We further fine-tuned GPT-3.5-Turbo and examined its ability on general natural language understanding. The results indicated that fine-tuning on our generated datasets does not necessarily hurt the natural language understanding ability, as comprehensively discussed in Appendix G."
        },
        {
            "heading": "6 CONCLUSION AND DISCUSSION",
            "text": "We proposed DYVAL, a dynamic LLMs evaluation protocol to mitigate the data contamination and static complexity of existing benchmarks. We designed the graph-informed DYVAL for reasoning tasks. The strength of DYVAL lies in its dynamic generation of samples, with inherent flexibility for difficulty adjustment. We observed several interesting findings in experiments using our benchmark. More importantly, DYVAL-generated samples can not only be used as evaluation samples, but also act as fine-tuning data for LLMs to enhance their performance in existing benchmarks.\nOur work has several limitations. (1) Tasks: We currently focused on reasoning tasks. While DYVAL supports other tasks (see Sec. H), it requires design of the generation algorithm G. (2) Samples: Our experiments utilized a limited set of test samples due to resource constraints. Evaluations on larger sets may help to observe more findings. (3) Fine-tuning: Fine-tuning can be done on more diverse models and datasets to gain deeper insights."
        },
        {
            "heading": "ACKNOWLEDGEMENT AND DISCLAIMER",
            "text": "The purpose of this research is to present a dynamic and evolving evaluation protocol in response to the rapid development of LLMs. We have the following claims. First, the generation mechanism of DYVAL does not contain any potentially harmful words or expressions but only mathematical, logical, and algorithmic descriptions. In the future, the usage of DYVAL on other natural language tasks should be dealt with cautions to not include any harmful or irresponsible languages. Second, human subjects are involved in this study to act as LLMs\u2019 competitors for performance comparison and analysis. All human studies are conducted obeying laws and regulations in certain countries. Third, the experiments on GPT-3.5-Turbo and GPT-4 conducted in this paper are based on their latest version in June, 2023. Authors recommend using the same version of these services for reproducibility. As we tried our best to tune the best prompts for our experiments, it is, however, well-known that LLMs are highly sensitive to prompts. Therefore, the experiments in this paper are only based on our prompt design and codebase. Finally, we may have concluded that some LLMs in this paper achieved poor performance in our benchmark, but this does not mean these models are not good or cannot be used in practice. Authors remain positive and optimistic to all evaluated LLMs that they will further be stronger."
        },
        {
            "heading": "CONTENTS",
            "text": ""
        },
        {
            "heading": "A Preliminary on Directed Acyclic Graph 16",
            "text": ""
        },
        {
            "heading": "B Details of DYVAL 17",
            "text": "B.1 Generation Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\nB.2 Complexity control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\nB.3 Description function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\nB.4 Description order . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\nB.5 Potentials in Using GPT-4 to Generate Description Functions . . . . . . . . . . . . 22"
        },
        {
            "heading": "C Proof 23",
            "text": ""
        },
        {
            "heading": "D Details of Experiments 23",
            "text": "D.1 Experiment Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\nD.2 Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\nD.3 Evaluation Set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\nD.4 Details of Experiment Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\nD.5 Details of Case Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\nD.6 Details of Varing Complexity Constraints . . . . . . . . . . . . . . . . . . . . . . 30\nD.7 Details of Prompt Engineering . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\nD.8 Human Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31"
        },
        {
            "heading": "E Details of Fine-tuning 32",
            "text": "E.1 Constructing training data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\nE.2 Training data and testing data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\nE.3 Results of Fine-tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\nF Imbalanced Generated Dataset 36"
        },
        {
            "heading": "G General Language Understanding Ability after Fine-tuning 37",
            "text": ""
        },
        {
            "heading": "H Flexibility to Natural Language Tasks 37",
            "text": ""
        },
        {
            "heading": "A PRELIMINARY ON DIRECTED ACYCLIC GRAPH",
            "text": "Directed Acyclic Graphs, commonly referred to as DAGs, are a category of graphs that encapsulate a unique structure: they are directed and contain no cycles. In a DAG, vertices are connected by directed links, and there exists no sequence of links that loops back to an original node. Every link in a DAG has an initial node and a terminal node, giving it a direction. This is often symbolized as a \u2192 b, where a is the starting node and b is the ending node. A key property that differentiates DAGs from other directed graphs is their lack of cycles. In other words, starting from any node in the graph, one cannot traverse a series of links and return to the same node.\nIn our implementation, each node comprises three attributes: 1) Children (Links): These are the direct dependents or subsequent nodes that a given node connects to. They highlight the immediate\nrelations or following a particular node. 2) Value: Every node possesses a value, which can either be explicitly assigned or derived based on its operation and its children. This value captures the essence or result of the represented subproblem. 3) Operation: Especially relevant in tree-based DAGs, the operation dictates how a node interprets or processes the values of its children to compute its own value. Operations might include mathematical functions, logical evaluations."
        },
        {
            "heading": "B DETAILS OF DYVAL",
            "text": ""
        },
        {
            "heading": "B.1 GENERATION ALGORITHM",
            "text": "We distinguish DAGs into two primary categories: Tree-based DAGs (T-DAGs) and General DAGs (G-DAGs), as shown in Figure 1.\nB.1.1 T-DAGS\nTree-based DAGs possess an innate hierarchical structure that frequently encapsulate tasks that entail a sequence of conditions culminating in a definitive conclusion or result. This hierarchy naturally aligns with the structure of many mathematical and logical problems. For instance, in solving a multi-step algebraic problem, one often starts with the provided equations (leaf nodes) and proceeds step-by-step, combining and reducing these equations until arriving at the final solution (root node). Such a natural progression of deduction makes tree-based DAGs particularly feasible for these problems.\nWe employ a top-down approach to construct a Tree-based DAG. This algorithm is tailored to produce a tree with a designated depth and width. The inherent randomness stems from two main factors: the operations assigned to intermediate nodes and the initialization values of the leaf nodes. For the intermediate nodes, we commence by randomly selecting an operation that defines the relationship between the node and its children. Take an arithmetic task as an example: selecting \u2018addition (+)\u2019 implies that the node\u2019s value is the sum of its children\u2019s values. Once all child nodes are established, we compute the parent node\u2019s value accordingly. In the case of leaf nodes, values are assigned randomly, such as picking an integer from the range [1, 10] for arithmetic tasks.\nB.1.2 G-DAGS\nGeneral DAGs, diverging from tree-based ones, lack a strict hierarchy. Instead, they present a more intricate web of node relationships. Their strength lies in simulating complex, intertwined relations in real-world situations. A classic use-case is the representation of transportation systems where nodes symbolize cities and edges represent connecting roads. Challenges such as determining if one city is accessible from another encapsulate the real-world problems general DAGs adeptly model. Their flexibility extends to representing a plethora of situations, from mapping supply-chain logistics to analyzing social networks.\nTo create a general DAG, we initiate by generating isolated nodes without any connecting links. Subsequently, each node is endowed with a random value. For every node, the number of children is determined randomly, the maximum number of children is depended on the input. We then establish the links by selecting target child nodes at random."
        },
        {
            "heading": "B.2 COMPLEXITY CONTROL",
            "text": "Figure 7 demonstrated 4 types of complexity constraints for T-DAGs. Compared to original case, adding width and additional links augments the computational intricacy of each subproblem. Increasing the depth escalates the complexity by necessitating more inference steps. Embedding random descriptions aims to distract LLMs."
        },
        {
            "heading": "B.3 DESCRIPTION FUNCTION",
            "text": "Figure 9 presented an illustration of our generated 7 tasks in 3 subjects: (1) Mathematics (DYVALM), which includes arithmetic task and linera equation task; (2) Logical Reasoning (DYVAL-L),\nPublished as a conference paper at ICLR 2024\nA ding difficulty\nwhich includes boolean logic task, deductive logic task, and abductive logic task; (3) Algorithm Tasks (DYVAL-A), which includes reachability task and max sum path task.\nB.3.1 DYVAL-M\nFor DYVAL-M, we design mathematical problems that can be categorized into two main types:\nArithmetic: Given a T-DAG, the DAG description function has already demonstrated the premise: the leaf nodes and the intermediate steps of inference: non-leaf nodes. Next, we select the root node as the the variable required to solve, we append the question \u201cWhat is the value of [Root]?\u201d to the final of the description where [Root] is filled with the name of the root variable.\nHere is a description of an arithmetic problem:\nThe value of aaa is 9.\nThe value of aad is 4.\naae gets its value by taking the square root of the value that aad has.\nThe value of aab is 3.\naac gets its value by adding together the value of aaa and aab.\naaf gets its value by subtracting the value of aae from the value of aac.\nCompute the result of aaf. If the solution cannot be calculated, answer \u2019N/A\u2019. Ensure your result is within a relative precision of 0.0001 (or 0.01%) compared to the ground truth value. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is 1, your final result should be <<<1>>>.\nLinear Equations: Linear equations with multiple variables present a higher degree of complexity compared to arithmetic. We use two-variable linear equations described as a1x + b1y = c1, a2x + b2y = c2. The coefficients are assigned a random value. We ask LLMs to solve the value of x, y for this linear system. Note that constructing such linear equations does not need T-DAGs or G-DAGs. To introduce additional challenges, some coefficients can be substituted with values derived from the T-DAG\u2019s roots, forcing a two-step problem-solving approach: first calculating the coefficients from the DAG and subsequently resolving the linear equations. Note that in our experiment, the tree depth and width for linear equation task are (1, 1), (2, 2), (3, 2), (4, 2) respectively. (1, 1) represent that the value of the replaced coefficient is directly given.\nGiven the following linear equation system with two variables:\n-7 x + aac0 y = 1\n8 x + -1 y = 10\nThe calculation of aac0 is defined as:\nThe value of aab0 is 4.\nThe value of aaa0 is 9.\naac0 gets its value by adding together the value of aaa0 and aab0.\nDetermine the values of x and y. Ensure your results are within a relative precision of 0.001 (or 0.1%) compared to the ground truth values. Your response should be formatted as: <<<x\u2019s value y\u2019s value>>>, e.g., if x=1 and y=2, then it should be <<<1 2>>>\nB.3.2 DYVAL-L\nDYVAL-L also shares a natural compatibility with the structured representation of T-DAGs due to the innate progression and dependencies inherent in logical constructs. The tasks are:\nBoolean Logic: Similar to arithmetic task, it primarily revolves around the manipulation and combination of True and False values using operators: AND,OR,NOT. The problems are presented as: What is the truth value of [Root]?.\nHere is a description of a boolean logic problem:\naaa is True.\nThe value of aab equals to (NOT aaa).\nThe value of aac equals to (NOT aab).\nCompute the result of aac. If the solution can not be calculated, answer \u2019N/A\u2019. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is True, your final result should be <<<True>>>.\nDeductive Logic: The process of deductive logic is similar to boolean logic, but deduction introduces a bit complexity compared to boolean logic inference. For instance, given premises A (True) and B (False), and the relationship (A \u2227 B) \u2192 C, the value of conclusion C remains undetermined because the conjunction (A \u2227 B) is false. Given the description of T-DAGs, the problem is formulated as By the rule of deduction, what is the value of [Root]?\nHere is a description of a deductive logic problem:\naab is True.\naaa is True.\n(aaa and aab) -> aac.\naad is False.\n(NOT aad) -> aae.\n(aac or aae) -> aaf.\nThe symbol \u2019->\u2019 represents a deductive relationship, e.g., A -> B implies that if A is true, then B is true. If A is false, B\u2019s truth value remains undetermined (N/A). Deduct the result of aaf. If the\nsolution can not be abducted, answer \u2019N/A\u2019. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is True, your final result should be <<<True>>>.\nAbductive Logic: It aims to hypothesize the most likely cause or explanation based on observed outcomes. When working with a T-DAG, we assign a random value to the root node. Then, we randomly select a leaf node, the problem is to determine the leaf node\u2019 value based on the given the DAG structure and root\u2019s value. The task description is Given the value of [Root] is [value], what is the value of [Node]?\nHere is a description of an abductive logic problem:\n(aaa or aab) -> aac.\n(NOT aac) -> aad.\nGiven aad is False, what is the value of aab?\nThe symbol \u2019->\u2019 represents a deductive relationship, e.g., A -> B implies that if B is false, then A is false. If B is true, A\u2019s truth value remains undetermined (N/A). If the solution can not be deducted, answer \u2019N/A\u2019. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is True, your final result should be <<<True>>>.\nB.3.3 DYVAL-A\nDYVAL-A tasks is suitable for D-DAG since they aim to model the real-world applications. Among many problems that can be abstracted and modeled as a G-DAG, here we select two representative tasks.\nReachability: A classic example of where G-DAGs shine is in modeling problems like the reachability of two nodes in the DAG. Given various nodes representing cities and links indicating roads between them, the question models can help deduce the if there exists a route from one city to another. Thus, the description for this task is: \u201cCan the [Node1] be reached by [Node2]\u201d where Node1 and Node2 are randomly selected from the nodes in G-DAG.\nGiven a directed graph:\naai points to: (None).\naac points to: (aai).\naaj points to: (aai).\naah points to: (aai, aac, aaj).\naag points to: (aac).\naaf points to: (aag, aah, aaj).\naab points to: (aaf, aah).\naaa points to: (aag, aah, aaf, aaj).\naae points to: (aai, aac, aaa).\naad points to: (aab, aaf, aae).\nCan aaf be reached starting from aag?\nRespond with either \u2019<<<True>>>\u2019 if reachable, or \u2019<<<False>>>\u2019 otherwise.\nMax sum path: Compared to reachiability problem, max sum path is more complex. This problem assign a value for each city, and then requires to find a path from two cities that the sum of the values the path go through is maximum. It requires the LLMs to find all the path between two nodes, and then determine the path with maximum value. The description for this task is What is the max sum path from [Node 1] to [Node 2]?\nGiven a directed graph with values assigned to each node:\naaj points to: (None).\naah points to: (None).\naai points to: (aah).\naag points to: (aai).\naac points to: (aag).\naab points to: (aac, aag).\naaf points to: (aai).\naae points to: (aac, aah).\naad points to: (aag, aae, aaj).\naaa points to: (aae, aai, aaj, aad).\nThe value of aaj is 9\nThe value of aab is 8\nThe value of aah is 3\nThe value of aaf is 3\nThe value of aai is 3\nThe value of aae is 3\nThe value of aad is 6\nThe value of aac is 4\nThe value of aag is 8\nThe value of aaa is 4\nWhat\u2019s the maximum sum path from aaa to aae? For exmaple, the value of the path A->B->C is obtained by summing the values of nodes A, B, and C. Please format your response as <<<Answer>>>. For example, if the answer is 1, it should be presented as <<<1>>>."
        },
        {
            "heading": "B.4 DESCRIPTION ORDER",
            "text": "\u2022 Topological Order: This approach sequences the description of nodes in a manner where every node is introduced after all its descendent nodes. Such a sequence ensures that leaf nodes are laid out prior to any operation that utilizes them (e.g., an addition or a logical AND).\n\u2022 Reversed Topological Order: Taking an almost counter-intuitive approach, this order starts by spotlighting the culminating nodes or outcomes. Once these results are laid bare, the narrative retraces its steps, navigating backwards to the root nodes or primary inputs.\n\u2022 Random Order: This unstructured method presents nodes in a random sequence, irrespective of their dependencies within the DAG. Such a disordered narrative challenges LLMs to independently connect the dots and derive patterns.\nD +\nA 1\nB 4\nE \u221a\nC 7\nF \u00f7\nB\u2019s value is 4.\nF gets its value by dividing D from E Topological OrderA is ..., B is \u2026, C is \u2026\nD is ..., E is \u2026, F is ...\nReversed Topological Order F is ... D is ..., E is \u2026, A is ..., B is \u2026, C is \u2026\nRandom Order A is ..., E is \u2026, F is ..., D is ..., B is \u2026, C is \u2026\n\ud835\udcd5\ud835\udcd6 \ud835\udcd5\ud835\udc7b\nFigure 8: Description function of arithmetic task.\nG X\nF -\nC 8 D 4\nB\nC D\nE F G H\nA\nF\nD E\nA 2 B 3 C 7\nB\nC D\nE F G\nA 8\nE +\nA 3 B 2\n2x+3y=5 4x+4y=G\nG F F\nArithmetic What is the value of F?\nLinear Equation Here is the lineareq with two variable, where G is calculated by\u2026\nBoolean Logic What is the value of G? Deductive Logic What is the value of F? Abductive Logic What is the value of F?\nReachability Can G be reached by A?\nMax Sum Path What is the maximum sum path from A to F?\nFigure 9: Descriptions of 7 tasks."
        },
        {
            "heading": "B.5 POTENTIALS IN USING GPT-4 TO GENERATE DESCRIPTION FUNCTIONS",
            "text": "In this section, we explore the potentials in using GPT-4 to generate more natural and contextualized problem descriptions rather than the plain ones in Section B.3.\nWe simply feed the following instruction to GPT-4:\n\u201cHere is a description of an arithmetic problem, please generate an application math test using the following information. Do not change the exact numbers. Note that the test should be contextualized, real applications test, instead of the plain description.\u201d followed by the DYVALgenerated problems such as the one in DYVAL-M.\nThen, GPT-4 will generate the following application problem which is more vivid:\nProblem:\nImagine you are managing a small warehouse. The warehouse has a total storage capacity of 9 large crates (represented by \u2019aaa\u2019). You also have an additional area that can store 3 more crates (represented by \u2019aab\u2019).\nRecently, you purchased a set of 4 special crates (represented by \u2019aad\u2019) that are stackable. When stacked, these crates take up the space of 2 regular crates.\nYour task is to calculate the new total storage capacity of your warehouse after adding the stackable crates and utilizing the additional storage area.\nSteps:\nIdentify the total initial capacity (aaa). Identify the additional capacity (aab). Calculate the effective space taken by the stackable crates (aae) - consider them as a single unit after stacking. Calculate the new total capacity by adding the initial and additional capacities (aac). Finally, adjust the total capacity by considering the space taken by the stackable crates (aaf). Question:\nWhat is the new total storage capacity of the warehouse after these adjustments?\n(Use the given values and operations to solve the problem)\nWhile the above application problem looks more vivid than the plain one, it is in fact challenging to verify its rationale and correctness. For instance, is the problem natural? Is the context correct? Note that GPT-4 tends to first compute the answers to the original problem before generating a new one, which may accumulate errors including problem understanding, application generation, and computation. Therefore, while we point the feasibility of such practice, this in current stage is difficult to verify and should be left for future work."
        },
        {
            "heading": "C PROOF",
            "text": "Theorem C.1. Given a tree-based DAG with depth d and width w, if the operation set for nonleaf nodes has k distinct operations and the value set for leaf nodes contains n distinct values, the\nprobability that two independently generated DAGs are identical is: P = ( k wd\u22121\u22121 w\u22121 \u00d7 nwd\u22121 )\u22121 .\nProof. To determine the overall probability, we analyze the likelihood at each depth and then multiply these probabilities. For depth i, the number of nodes is wi\u22121.\nFor depth i, 1 \u2264 i \u2264 d\u2212 1. Since these nodes are non-leaf nodes, the probability they are identical in two independently generated DAGs is the likelihood all of them have the same operations: pi =\n1\nkwi\u22121 .\nFor the leaf nodes at depth d, the probability that they are the same across two DAGs is: pd = 1 nwd\u22121 .\nThus, the overall probability P that two DAGs are identical is: P = \u220fd\u22121\ni=1 pi \u00d7 pd. Substituting the above expressions and simplifying gives the result: P = ( k wd\u22121\u22121 w\u22121 \u00d7 nwd\u22121 )\u22121 .\nNote: We consider two trees to be distinct even if they only differ in the order of operations. For instance, the tree representing 3\u00d75 is considered different from the tree representing 5\u00d73. Excluding such cases may be non-trivial and is unlikely to significantly affect the odds.\nTheorem C.2. Given a general DAG with n nodes where each node has a minimum of l \u2265 1 links, the lower bound of the probability that two randomly selected DAGs of this configuration are identical is ((n\u2212 1)!)\u22121.\nProof. Consider a DAG where each node has exactly one outgoing link. The first node can be connected to any of the remaining n \u2212 1 nodes. Subsequently, the second node can connect to any of the remaining n\u2212 2 nodes, excluding the one already connected to the first node. Following this logic, the third node can connect to any of the n\u2212 3 unconnected nodes, and so on. Thus, the total number of distinct DAGs that can be constructed under these constraints is given by: (n\u2212 1)\u00d7 (n\u2212 2)\u00d7 . . .\u00d7 2\u00d7 1 = (n\u2212 1)! Given two randomly chosen DAGs of this kind, the likelihood they are identical is the inverse of the number of unique DAGs: 1(n\u22121)!\nThis probability serves as the lower bound when considering the general case of DAGs with nodes having a minimum of l \u2265 1 links, hence proving the theorem."
        },
        {
            "heading": "D DETAILS OF EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "D.1 EXPERIMENT ENVIRONMENT",
            "text": "All experiments are conducted on a workstation equipped with an NVIDIA V100 GPU with 16GB memory and A100 GPU with 80GB memory. For GPT-3.5-Turbo and GPT-4, we use OpenAI\u2019s\nAPI for inference, the versions are gpt-3.5-turbo-0613 and gpt-4-0613. For the Llama2 models, we downloaded from the Llama2 github repository3 and follow the instruction4 to convert them into huggingface models. For Vicuna-13B-v1.3, we downloaded it from its github repository5. The remaining models can be downloaded directly via huggingface."
        },
        {
            "heading": "D.2 PROMPTS",
            "text": "\u2022 Arithmetic:\nHere is a description of an arithmetic problem: {} Compute the result of {}. If the solution cannot be calculated, answer \u2019N/A\u2019. Ensure your result is within a relative precision of 0.0001 (or 0.01%) compared to the ground truth value. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is 1, your final result should be <<<1>>>.\n\u2022 Linear Equation:\nGiven the following linear equation system with two variables: {} Determine the values of x and y. Ensure your results are within a relative precision of 0.001 (or 0.1%) compared to the ground truth values. Your response should be formatted as: <<<x\u2019s value y\u2019s value>>>, e.g., if x=1 and y=2, then it should be <<<1 2>>>\n\u2022 Boolean Logic:\nHere is a description of a boolean logic problem: {} Compute the result of {}. If the solution can not be calculated, answer \u2019N/A\u2019. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is True, your final result should be <<<True>>>.\n\u2022 Deductive Logic:\nHere is a description of a deductive logic problem: {} The symbol \u2019->\u2019 represents a deductive relationship, e.g., A -> B implies that if A is true, then B is true. If A is false, B\u2019s truth value remains undetermined (N/A). Deduce the result of {}. If the solution can not be deduced, answer \u2019N/A\u2019. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is True, your final result should be <<<True>>>.\n\u2022 Abductive Logic:\nHere is a description of an abductive logic problem: {} The symbol \u2019->\u2019 represents a deductive relationship, e.g., A -> B implies that if B is false, then A is false. If B is true, A\u2019s\n3https://github.com/facebookresearch/llama 4https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/convert llama weights to hf.py 5https://github.com/lm-sys/FastChat\ntruth value remains undetermined (N/A). If the solution can not be abduced, answer \u2019N/A\u2019. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is True, your final result should be <<<True>>>.\n\u2022 Reachability:\nGiven a directed graph: {} Respond with either \u2019<<<True>>>\u2019 if reachable, or \u2019<<<False>>>\u2019 otherwise.\n\u2022 Max Sum Path:\nGiven a directed graph with values assigned to each node: {} For exmaple, the value of the path A->B->C is obtained by summing the values of nodes A, B, and C. Please format your response as <<<Answer>>>. For example, if the answer is 1, it should be presented as <<<1>>>."
        },
        {
            "heading": "D.3 EVALUATION SET",
            "text": "We categorize tasks into four complexity levels, denoted as D1 to D4. For tasks reliant on general Directed Acyclic Graphs (DAGs), the node count is set to 7, 10, 15, 20. Each of these nodes possesses a maximum link range of 3, 4, 6, 8 and a minimum link count of 1. Conversely, for tasks that utilize tree-based DAGs, the tree depths and widths are defined as (2, 2), (3, 2), (3, 3), (4, 2), in order of increasing complexity.\nThe range of these datasets progresses from simple to intricate. To illustrate, an arithmetic problem with a tree depth of 2 represents a basic two-variable arithmetic computation. In contrast, a task with a tree depth of 4 exhibits heightened complexity, necessitating multiple inferential steps for resolution."
        },
        {
            "heading": "D.4 DETAILS OF EXPERIMENT RESULTS",
            "text": "We do not report the results of Flan-T5-large, phi-1.5, WizardMath-13B, and Xwin-13B since their performance is almost 0 even on simplest evaluation sets generated by our DYVAL. Therefore, we extensively run the results of four remaining models: Vicuna-13B-v1.3, Llama2-13B-chat, GPT-3.5Turbo, and GPT-4. Table 2, 3, and 4 report the detailed results (average\u00b1standard error) of these models in different complexity (D1\u223cD4) and different description generation orders (topological, reversed topological, and random orders).\nIn the reachability task, as task difficulty escalated, Llama2-13B-chat\u2019s performance paradoxically improved. Upon investigation, Llama2-13B-chat essentially resorted to random guessing across datasets. The proportion of \u2019True\u2019 answers increased (from 40% in D1 to 60% in D3), with \u2019False\u2019 responses being nearly absent. The remainder were non-responses, thus elevating the overall accuracy. The observation is similar to those made in Sec.4.4 where we investigated the influence of different model size.\nFurther, generation description order affects outcomes: in the reachability task, GPT-4\u2019s accuracy drops by 13.67% when given reversed order compared to topological order. See Appendix D.4 for details of experiment results."
        },
        {
            "heading": "D.5 DETAILS OF CASE STUDY",
            "text": "We select 20 failure cases of the most challenging datasets of arithmetic, deductive logic, abductive logic, and reachability of GPT-4.\nHere we present one failure case for each error type.\nPartial calculation error It has been observed that GPT-4, in certain situations, commits errors in intermediate computational steps, while it maintains correctness in the remaining steps. This characteristic anomaly is not isolated to complex calculations. In fact, not only complex calculation, seemingly straightforward calculations such as can be incorrectly computed. This observed behavior is consistent with the findings presented by (Dziri et al., 2023), where they highlighted that low-level learning models (LLMs) occasionally produce results that are only partially accurate, particularly in the realm of multi-digit multiplication."
        },
        {
            "heading": "Input:",
            "text": "Task Dataset GPT4 ChatGPT Llama2-13b-chat Vicuna-13b-v1.3\nTopo Reversed Rand Topo Reversed Rand Topo Reversed Rand Topo Reversed Rand\nReachability D1 83.67\u00b11.15 92.67\u00b11.15 85.33\u00b13.06 59.53\u00b10.76 63.87\u00b11.51 63.40\u00b12.42 21.60\u00b11.20 23.20\u00b10.80 26.87\u00b11.47 11.47\u00b11.29 29.80\u00b12.03 23.53\u00b12.20 D2 85.00\u00b10.00 91.00\u00b13.00 83.00\u00b12.00 53.53\u00b13.97 56.73\u00b12.81 54.27\u00b11.79 34.60\u00b11.40 26.87\u00b11.27 26.27\u00b11.17 12.07\u00b10.58 31.73\u00b10.64 21.73\u00b10.50 D3 68.17\u00b12.93 77.67\u00b10.58 67.67\u00b12.31 49.67\u00b12.55 57.53\u00b11.90 53.73\u00b13.13 39.33\u00b12.08 39.33\u00b11.80 37.47\u00b11.01 13.60\u00b11.00 29.67\u00b13.75 21.80\u00b12.88 D4 63.00\u00b11.00 76.67\u00b10.58 74.33\u00b12.52 49.40\u00b12.71 59.13\u00b13.49 52.33\u00b12.89 33.67\u00b12.97 41.53\u00b11.22 38.60\u00b10.92 10.80\u00b10.72 30.73\u00b11.53 22.00\u00b11.64\nMax Sum Path D1 37.33\u00b15.86 30.67\u00b16.11 26.67\u00b16.03 29.47\u00b12.08 29.67\u00b12.77 25.27\u00b10.83 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00 D2 38.67\u00b18.14 27.00\u00b18.54 25.67\u00b15.69 14.20\u00b11.25 13.33\u00b12.37 11.33\u00b10.76 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00 D3 21.33\u00b14.04 17.00\u00b15.00 16.67\u00b14.16 6.40\u00b11.64 8.40\u00b11.51 7.60\u00b10.72 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00 D4 16.67\u00b12.52 12.00\u00b12.00 10.67\u00b10.58 5.07\u00b10.76 6.20\u00b11.11 6.67\u00b11.33 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00 0.00\u00b10.00\naae gets its value by dividing the value of aac by those of aad.\naaf gets its value by dividing the value of aab by those of aae.\naao gets its value by adding together the value of aaf and aan.\nCompute the result of aao. If the solution cannot be calculated, answer \u2019N/A\u2019. Ensure your result is within a relative precision of 0.0001 (or 0.01%) compared to the ground truth value. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is 1, your final result should be <<<1>>>."
        },
        {
            "heading": "GPT-4\u2019s response:",
            "text": "First, let\u2019s calculate the values step by step:\naaj = 7\naak = aaj2 = 72 = 49\naah = 6\naag = 2\naai = aag / aah = 2 / 6 = 0.3333\naan = aai * aak = 0.3333 * 49 = 16.3167 (should be 16.3317)\naaa = 6\naab = aaa2 = 62 = 36\naac = 8\naad = 1\naae = aac / aad = 8 / 1 = 8\naaf = aab / aae = 36 / 8 = 4.5\naao = aaf + aan = 4.5 + 16.3167 = 20.8167\nSo, the result of aao is 20.8167.\nTherefore, the final result is <<<20.8167>>>.\nGround truth: 20.8333\nIncorrect reasoning When tasked with reasoning, GPT-4 can occasionally falter in rule interpretation, especially in abductive logic task."
        },
        {
            "heading": "Input:",
            "text": "Here is a description of an abductive logic problem:\n(aaa and aab) -> aac.\n(aae or aaf) -> aag.\n(aah or aai) -> aaj.\n(aag or aaj) -> aak.\n(NOT aac) -> aad.\n(aad or aak) -> aan.\nGiven aan is False, what is the value of aab?\nThe symbol \u2019->\u2019 represents a deductive relationship, e.g., A -> B implies that if B is false, then A is false. If B is true, A\u2019s truth value remains undetermined (N/A). If the solution can not be abduced, answer \u2019N/A\u2019. Ensure your final result begins with \u2019<<<\u2019 and ends with\n\u2019>>>\u2019, for example, if the answer is True, your final result should be <<<True>>>."
        },
        {
            "heading": "GPT-4\u2019s response:",
            "text": "Given aan is False, it means either aad or aak must be False (both aad and aak should be False) (since aad or aak -> aan).\nIf aak is False, then either aag or aaj must be False (since aag or aaj -> aak).\nIf aag is False, then either aae or aaf must be False (since aae or aaf -> aag).\nIf aaj is False, then either aah or aai must be False (since aah or aai -> aaj).\nHowever, none of these conditions provide any information about aab.\nTherefore, the value of aab cannot be abduced from the given information.\nSo, the answer is <<<N/A>>>.\nGround truth: N/A\nSelf Contradiction GPT-4, on occasion, presents self-contradictory assumptions during the same inference in an abductive logic task."
        },
        {
            "heading": "Input:",
            "text": "Here is a description of an abductive logic problem:\n(aah or aai) -> aaj.\n(NOT aaj) -> aak.\n(aad or aae) -> aaf.\n(aaa or aab) -> aac.\n(aac or aaf) -> aag.\n(aag or aak) -> aan.\nGiven aan is False, what is the value of aah?\nThe symbol \u2019->\u2019 represents a deductive relationship, e.g., A -> B implies that if B is false, then A is false. If B is true, A\u2019s truth value remains undetermined (N/A). If the solution can not be abduced, answer \u2019N/A\u2019. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is True, your final result should be <<<True>>>."
        },
        {
            "heading": "GPT-4\u2019s response:",
            "text": "Since aan is False, at least one of aag or aak must be False. However, we don\u2019t know which one is False, so we can\u2019t determine the value of aah. (This inference step contradicts to the former example, where GPT-4 assumes aah is False.) Therefore, the answer is \u2019N/A\u2019.\n<<<N/A>>>\nGround truth: N/A\nUnsubstaintiated response A recurring observation in both reasoning and algorithmic tasks is GPT-4\u2019s propensity to provide answers without accompanying justifications. These succinct, answer-only responses raise concerns about the depth of GPT-4\u2019s understanding and whether its approach is grounded in actual comprehension or simply a result of memorization. This error mostly happens in algorithm tasks and occasionally happens in logical reasoning tasks."
        },
        {
            "heading": "Input:",
            "text": "Here is a description of an abductive logic problem:\n(aaa or aab) -> aac.\n(aad or aae) -> aaf.\n(aac or aaf) -> aag.\n(NOT aah) -> aai.\n(NOT aaj) -> aak.\n(aai or aak) -> aan.\n(aag or aan) -> aao.\nGiven aao is False, what is the value of aaa?\nThe symbol \u2019->\u2019 represents a deductive relationship, e.g., A -> B implies that if B is false, then A is false. If B is true, A\u2019s truth value remains undetermined (N/A). If the solution can not be abduced, answer \u2019N/A\u2019. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is True, your final result should be <<<True>>>.\nGPT-4\u2019s response: <<<N/A>>>\nGround truth: N/A\nInstructional oversight Interestingly, while GPT-4 often computes accurately, it sometimes falters when it comes to precisely following the output instructions as described in given prompts. This discrepancy points to a potential gap in the model\u2019s ability to parse and adhere to intricate instructional details, even when the underlying computational capability is sound."
        },
        {
            "heading": "Input:",
            "text": "Here is a description of an arithmetic problem:\nThe value of aac is 6.\nThe value of aai is 6.\nThe value of aag is 8.\naan gets its value by subtracting the sum of the values of aak and aae from the value of aah.\naao gets its value by multiplying together the value of aae and aan and aae.\naah gets its value by multiplying together the value of aaf and aag and aae.\nThe value of aap is 1.\nThe value of aaa is 6.\naad gets its value by taking the square root of the value that aac has.\nThe value of aaj is 4.\naak gets its value by subtracting the sum of the values of aaj and aae from the value of aai.\nThe value of aaq is 7.\naar gets its value by dividing the value of aap by those of aaq.\naab gets its value by squaring the value that aaa has.\nThe value of aaf is 10.\naae gets its value by multiplying together the value of aab and aad and aai.\nCompute the result of aao. If the solution cannot be calculated, answer \u2019N/A\u2019. Ensure your result is within a relative precision of 0.0001 (or 0.01%) compared to the ground truth value. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is 1, your final result should be <<<1>>>."
        },
        {
            "heading": "GPT-4\u2019s response:",
            "text": "Let\u2019s solve this step by step:\n1. aac = 6\n2. aai = 6\n3. aag = 8\n4. aaa = 6\n5. aad = sqrt(aac) = sqrt(6)\n6. aaj = 4\n7. aaq = 7\n8. aap = 1\n9. aaf = 10\n10. aab = aaa2 = 62 = 36\n11. aae = aab * aad * aai = 36 * sqrt(6) * 6\n12. aak = aai - (aaj + aae) = 6 - (4 + 36 * sqrt(6) * 6)\n13. aah = aaf * aag * aae = 10 * 8 * 36 * sqrt(6) * 6\n14. aan = aah - (aak + aae) = 10 * 8 * 36 * sqrt(6) * 6 - (6 - (4 + 36 * sqrt(6) * 6) + 36 * sqrt(6) * 6)\n15. aao = aae * aan * aae = (36 * sqrt(6) * 6) * (10 * 8 * 36 * sqrt(6) * 6 - (6 - (4 + 36 * sqrt(6) * 6) + 36 * sqrt(6) * 6)) * (36 * sqrt(6) * 6)\nThis is a complex calculation and it\u2019s not possible to simplify it further. However, it\u2019s clear that the result will be a very large number. Since the problem doesn\u2019t provide any constraints on the values of the variables, we can\u2019t say that the solution is \u2019N/A\u2019. (The equation is correct however GPT-4 did not simplify it. In our experiment, we found that GPT-4 can handle large numbers, so the error does not originate from them.)\nSo, the result of aao is a very large number that can\u2019t be simplified further.\nGround truth: 11848342359.78579"
        },
        {
            "heading": "D.6 DETAILS OF VARING COMPLEXITY CONSTRAINTS",
            "text": "As shown in Figure 5, we systematically vary the levels of complexity in GPT-3.5-Turbo by adjusting individual constraints while keeping others constant. Specifically, we explore how performance metrics evolve as we incrementally adjust depth, width, #nodes, #max links, the number of extra links, and the quantity of random descriptions across arithmetic, boolean logic, and deductive logic tasks. To comprehensively evaluate the impact of complexity constraints, various parameters were meticulously adjusted. The following elucidates the configurations employed:\nTable 5: Results of GPT-3.5-Turbo with prompt engineering techniques on the toughest evaluation sets generated by DYVAL (D4).\nPrompt engineering Arithmetic LinearEquation Deductive Logic Abductive Logic Reachability Max Sum Path\nVanilla 42.13 14.93 56.40 54.33 49.40 5.07 CoT (Wei et al., 2022) 42.33 21.93 52.93 43.73 47.73 1.93 Fewshot (Brown et al., 2020) 47.86 2.40 35.93 41.60 81.80 12.20 Least2most (Zhou et al., 2023b) 36.73 12.47 44.07 38.80 76.53 8.07 APE (Zhou et al., 2023d) 45.20 23.40 44.67 53.13 62.80 8.87 SKiC (Chen et al., 2023) 32.07 13.70 63.00 78.27 71.40 11.80\nTable 6: Results of Llama 2 with different sizes on DYVAL-generated evaluation samples (D1).\nSize Arithmetic Boolean logic Reachability\n7b 13.07 28.93 29.53 13b 24.20 19.53 26.53 70b 29.71 28.30 47.38\n\u2022 Depth Constraint: Maintaining the width at 2, with neither the addition of random links nor the embedding of extra descriptions (both set to 0), the depth was systematically varied, with values set to 2, 3, 4, 5, and 6.\n\u2022 Width Constraint: With a fixed depth of 3, and with the addition of random links and embedding of extra descriptions both neutralized to 0, the width was tested with the values 2, 3, 4, 5, and 6.\n\u2022 Random Link Addition Constraint: For this, a depth of 4 and a width of 2 were maintained, with extra descriptions set to 0. The number of random links introduced varied as 0, 1, 2, 3, and 4. It should be highlighted that due to the inherent acyclic constraint, certain nodes may preclude the addition of extra links.\n\u2022 Embedding Extra Descriptions: With a depth and width fixed at 4 and 2, respectively, and no addition of random links (set to 0), the levels of embedded extra descriptions were calibrated to 0, 1, 2, 3, and 4.\nAcross these variations, our results consistently underscore a notable trend: as the tasks become more intricate through the augmentation of these complexity parameters, LLMs progressively struggle, underscoring the inherent challenges posed by increasing task intricacy. It can be observed that depth is the most influential complexity constraint of tree-based DAGs, indicates that LLMs struggle to deal with problems that requires more inference steps."
        },
        {
            "heading": "D.7 DETAILS OF PROMPT ENGINEERING",
            "text": "We explored five prompting techniques to evaluate their potential impact on our most challenging datasets (excluding boolean logic since GPT-3.5-Turbo achieved comparable results on most challenging datasets): Zeroshot-CoT (Wei et al., 2022), Few-shot (3-shot in our experiments) (Brown et al., 2020), Least-to-most (Zhou et al., 2023b), automatic prompt engineering (APE) (Zhou et al., 2023d), and skill-in-context (SkiC) (Chen et al., 2023). The details of these techniques are as follows:\n\u2022 Zeroshot-CoT: An approach that allows models to generalize from their pre-training without explicit examples in the target task (Wei et al., 2022).\n\u2022 Fewshot (3-shot in our experiments): Provides the model with a small number of examples from the target task to aid in understanding and generalizing to the broader task (Brown et al., 2020).\n\u2022 Least to Most Prompting: This technique incrementally provides more specific prompts to guide the model\u2019s responses, adapting the prompt based on the difficulty level of the problem (Zhou et al., 2023b).\n\u2022 Automatic Prompting Engineering (APE): A method where prompts are automatically engineered to elicit the desired response from the model, often maximizing its performance (Zhou et al., 2023d).\n\u2022 Skill-in-Context (SKiC): This method seeks to understand a model\u2019s inherent skills and utilize them in a specific context to improve its outputs (Chen et al., 2023)."
        },
        {
            "heading": "D.8 HUMAN STUDY",
            "text": "We conducted our human study by obeying the local laws and regulations. The demographics of the human subjects are shown in Table 7."
        },
        {
            "heading": "E DETAILS OF FINE-TUNING",
            "text": ""
        },
        {
            "heading": "E.1 CONSTRUCTING TRAINING DATA",
            "text": "The training data includes the problems and their corresponding inference steps. Constructing inference steps is similar to the DAG description. For mathematics tasks and logical reasoning tasks, which utilize T-DAG, we follow the topological order to describe how the intermediate gets its value from its children. For algorithm tasks, the inference are indeed an algorithm, thus, we formalize each step in the algorithm into natural language, which finally form the inference steps. Following list presented a training sample of each task. Note that the inference steps for each task are also highly flexible and can be augmented with more details, and we believe that the more detailed inference steps will benefit more.\n\u2022 Arithmetic:"
        },
        {
            "heading": "Input:",
            "text": "Here is a description of an arithmetic problem: The value of aae is 2. The value of aad is 4. aaf gets its value by dividing the value of aad by those of aae. aag gets its value by taking the square root of the value that aaf has. Compute the result of aag. If the solution cannot be calculated, answer \u2019N/A\u2019. Ensure your result is within a relative precision of 0.0001 (or 0.01%) compared to the ground truth value. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is 1, your final result should be <<<1>>>. Inference steps: aae is 2.0 aad is 4.0 aaf = aad / aae = 4.0 / 2.0 = 2.0 aag = sqrt aaf = sqrt(2.0) = 1.41421356\nThus, the answer is <<<1.41421356>>>\n\u2022 Linear Equation:"
        },
        {
            "heading": "Input:",
            "text": "Given the following linear equation system with two variables:\naag0 x + -6 y = -6 -2 x + 6 y = 0\nThe calculation of aag0 is defined as: The value of aab0 is 10. The value of aaa0 is 6. aac0 gets its value by adding together the value of aaa0 and aab0. The value of aad0 is 6. The value of aae0 is 1. aaf0 gets its value by multiplying together the value of aad0 and\naae0. aag0 gets its value by multiplying together the value of aac0 and aaf0.\nDetermine the values of x and y. Ensure your results are within a relative precision of 0.001 (or 0.1%) compared to the ground truth values. Your response should be formatted as: <<<x\u2019s value y\u2019s value>>>, e.g., if x=1 and y=2, then it should be <<<1 2>>> Inference steps: Let\u2019s first solve the coefficients of the linear equation. aab0 is 10.0 aaa0 is 6.0 aac0 = aaa0 + aab0 = 6.0 + 10.0 = 16.0 aad0 is 6.0 aae0 is 1.0 aaf0 = aad0 * aae0 = 6.0 * 1.0 = 6.0 aag0 = aac0 * aaf0 = 16.0 * 6.0 = 96.0 Thus, aag0 = 96.0\nNext, solve the linear equation:\n96.0 x + -6.0 y = -6.0 -2.0 x + 6.0 y = 0.0 To eliminate \u2019y\u2019, multiply the first equation by 6 and the second equation by -6. This makes the coefficients of \u2019y\u2019 equal. Subtracting the second equation from the first then gives: 564.0x = -36.0. From the equation 564.0x = -36.0, we can solve for x. Solving for x, we get x = -0.06382979. Substituting x = -0.06382979 into the first original equation, we get: -6.0y = 0.12765957, which gives y = -0.0212766.\nThus, the answer is <<<-0.06382979 -0.0212766>>>\n\u2022 Boolean Logic:"
        },
        {
            "heading": "Input:",
            "text": "Here is a description of a boolean logic problem: aaa is False. aab is True. The value of aac equals to (aaa OR aab). aad is False. aae is False. The value of aaf equals to (aad AND aae). The value of aag equals to (aac AND aaf). Compute the result of aag. If the solution can not be calculated, answer \u2019N/A\u2019. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is True, your final result should be <<<True>>>. Inference steps: aaa is False. aab is True. aac = (aaa OR aab) = (False OR True) = True. aad is False. aae is False. aaf = (aad AND aae) = (False AND False) = False.\naag = (aac AND aaf) = (True AND False) = False.\nThus, the answer is <<<False>>>\n\u2022 Deductive Logic:"
        },
        {
            "heading": "Input:",
            "text": "Here is a description of a deductive logic problem: aaa is False. aab is False. (aaa or aab) -> aac. (NOT aac) -> aad. The symbol \u2019->\u2019 represents a deductive relationship, e.g., A -> B implies that if A is true, then B is true. If A is false, B\u2019s truth value remains undetermined (N/A). Deduce the result of aad. If the solution can not be deduced, answer \u2019N/A\u2019. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is True, your final result should be <<<True>>>. Inference steps: aaa is False. aab is False. (aaa OR aab) = (False OR False) -> aac. The premise (False OR False) is False, thus, the value of aac cannot be deduced and is set to N/A. (NOT aac) = (NOT N/A) -> aad. The value of aad cannot be deduced, and is set to N/A.\nThus, the answer is <<<N/A>>>\n\u2022 Abductive Logic:"
        },
        {
            "heading": "Input:",
            "text": "Here is a description of an abductive logic problem: (aad or aae) -> aaf. (aaa or aab) -> aac. (aac or aaf) -> aag. Given aag is False, what is the value of aab? The symbol \u2019->\u2019 represents a deductive relationship, e.g., A -> B implies that if B is false, then A is false. If B is true, A\u2019s truth value remains undetermined (N/A). If the solution can not be abduced, answer \u2019N/A\u2019. Ensure your final result begins with \u2019<<<\u2019 and ends with \u2019>>>\u2019, for example, if the answer is True, your final result should be <<<True>>>. Inference steps: (aac OR aaf) -> aag = False. Given aag is False, the value of premise (aac OR aaf) is False, thus, the value of aac is abduced as False. (aaa OR aab) -> aac = False. Given aac is False, the value of premise (aaa OR aab) is False, thus, the value of aab is abduced as False.\nThus, the answer is <<<False>>>\n\u2022 Reachability:"
        },
        {
            "heading": "Input:",
            "text": "Given a directed graph: aag points to: (None). aaf points to: (None). aaa points to: (aag, aaf). aac points to: (aaa). aab points to: (aaa). aad points to: (aaa). aae points to: (aad). Can aag be reached starting from aaf? Respond with either \u2019<<<True>>>\u2019 if reachable, or \u2019<<<False>>>\u2019 otherwise. Inference steps: Starting the search process from node aaf with the goal to reach node aag. Checking node aaf. Node aaf has no unvisited children. Moving back. Exhausted all possible paths without reaching node aag.\nThus, the answer is <<<False>>>\n\u2022 Max Sum Path:"
        },
        {
            "heading": "Input:",
            "text": "Given a directed graph with values assigned to each node: aag points to: (None). aaf points to: (aag). aae points to: (aaf, aag). aab points to: (aaf). aad points to: (aab, aae). aac points to: (aag, aad). aaa points to: (aac, aag, aae). The value of aaa is 3 The value of aab is 2 The value of aaf is 5 The value of aag is 5 The value of aae is 1 The value of aad is 7 The value of aac is 2 What\u2019s the maximum sum path from aab to aae? For exmaple, the value of the path A->B->C is obtained by summing the values of nodes A, B, and C. Please format your response as <<<Answer>>>. For example, if the answer is 1, it should be presented as <<<1>>>. Inference steps: Starting the search for the maximum sum path from node aab to node aae. Reaching node aab with current sum of 2. Now, we explore the children of node aab: aaf. Reaching node aaf with current sum of 7. Now, we explore the children of node aaf: aag. Reaching node aag with current sum of 12. Node aag has no children. Moving back. There is no path from node aab to node aae.\nThus, the answer is <<<N/A>>>"
        },
        {
            "heading": "E.2 TRAINING DATA AND TESTING DATA",
            "text": ""
        },
        {
            "heading": "E.2.1 TRAINING DATA",
            "text": "For mathematical tasks and logical reasoning tasks that utilize T-DAGs, we construct four types of training datasets. Each dataset consists of 500 training samples. All of these types have a depth of 3. The settings are as follows:\n1. width=2, add random links=0, embed random descs=0, 2. width=2, add random links=1, embed random descs=0, 3. width=2, add random links=1, embed random descs=1, 4. width=3, add random links=0, embed random descs=0.\nFor algorithm tasks, two types of training datasets are generated:\n1. num nodes=7, max links per node=3, 2. num nodes=10, max links per node=4."
        },
        {
            "heading": "E.2.2 TESTING DATA",
            "text": "We create three types of testing data:\n1. In-Distribution (ID) Test Set: The difficulty level matches that of the training set. \u2022 For T-DAGs: depth=4, width=2, with no extra links and random descriptions. \u2022 For G-DAGs: num nodes=15 with max links=6.\n2. Out-of-Distribution (OOD) Test Set: \u2022 For T-DAGs: depth=4, width=2, without extra links and random descriptions. \u2022 For G-DAGs: num nodes=15 with max links=6.\n3. Out-of-Distribution-Hard (OOD-hard) Test Set: \u2022 For T-DAGs: depth=4, width=2, with one extra link per node and one random description. \u2022 For G-DAGs: num nodes=20 with max links=8.\nNote that the definition of OOD in our tasks is mainly on the different complexities of the samples that may come with more advanced structures or descriptions. For model evaluation, when using the DYVAL generated testing data, a zero-shot setting was adopted. For existing benchmarks, few-shot COT examples were provided in the context: 4 examples for GSM8K and SVAMP, 3 for FOLIO and RACO, and 2 for DP and LCS. The results of evaluation in our tasks are presented in Figure 10."
        },
        {
            "heading": "E.3 RESULTS OF FINE-TUNING",
            "text": "We fine-tuned Llama2-13b-chat with LORA (Hu et al., 2022) for 3 epochs where the rank was 8, the scaling factor was 16 and the drop out rate was 0.05. We used a 0.0003 learning rate with batch size 128. Results on existing benchmarks of the fine-tuned model is in Figure 6 of the main paper.\nFigure 10 displays the results after fine-tuning on our test datasets as described in Sec.E.2.2. The performance of Llama2-13B-chat on tasks like boolean logic, deductive logic, and reachability significantly improves after fine-tuning on our dataset. However, noticeable gaps remain, particularly in areas such as mathematic tasks, abductive logic and the max sum path.\nF IMBALANCED GENERATED DATASET\nOur algorithm can easily satisfy the balance requirement by meticulously controlling the flexible dynamic generation process. For example, in reachability task, we can drop the generated evaluation samples with \u2019False\u2019 labels until we generate a sample with \u2019True\u2019 label. We presented the results of GPT-3.5-Turbo and GPT-4 in balanced datasets in Table 8. The results in balanced datasets are similar to our initial findings: (1) GPT-3.5-Turbo consistently predicted all questions as \u201cTrue.\u201d, resulted in a uniform accuracy rate of 50%. (2) GPT-4 demonstrated excellent performance. It maintained significantly higher accuracy rates across all complexity levels.\nArith metic Linea r Eq Bool Logic\nDedu ctive\nLogic\nAbdu ctive\nLogic Reach abilit y\nMax Sum\nPath 0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nA cc\nu ra\ncy\nVanilla-ID Gain FT-ID\nVanilla-OOD Gain FT-OOD\nVanilla-OOD hard Gain FT-OOD hard\nFigure 10: Fine-tuned results on ID and OOD sets of our tasks. For arithmetic, linear equation, reachability and max sum path tasks, the vanilla accuracy is zero."
        },
        {
            "heading": "G GENERAL LANGUAGE UNDERSTANDING ABILITY AFTER FINE-TUNING",
            "text": "We fine-tuned GPT-3.5-turbo-0613 using our generated data on abductive logic and reachability datasets, as GPT-3.5 performs worst on these two datasets. Specifically, we generated 100 samples across complexity levels D1, D2, and D3 for each task. We compared the performance of original and fine-tuned models on several benchmark tasks in GLUE dataset. The performance of abductive logic and reachability task are tested on D4 task (different from fine-tuning dataset). As shown in Table 9, performance on WNLI and QNLI datasets dropped for the fine-tuned model. However, finetuned model achieves better results on CoLA, QQP, and MRPC datasets. Despite the mixed results, the overall improvement in several datasets suggests that fine-tuning on our generated datasets does not necessarily hurt the general language understanding ability."
        },
        {
            "heading": "H FLEXIBILITY TO NATURAL LANGUAGE TASKS",
            "text": "Finally, we discuss the flexibility of DYVAL while the main focus of this paper is on reasoning tasks. We show that DYVAL can be easily extended to natural language processing tasks using an initial experiment on sentiment analysis.\nGenerally speaking, a natural language sentence can be expressed as a syntax tree, similar to DAGs. However, generating sentences through direct syntax tree construction (which is similar to the construction of arithmetic task) presents notable challenges, primarily due to the need for grammatical correctness and the inherent naturalness of these sentences. Nevertheless, DYVAL can still be applied to generate tasks in natural language by utilizing syntax tree templates extracted by existing sentences. For each sentence in the SST-2 dataset, we initially employ GPT-3.5-Turbo to extract its syntactic structure. Within each syntax tree (i.e., DAGs), we identify the elements that can be modified: namely, nouns (such as names and places) and adjectives. GPT-3.5-Turbo is then used to create five alternative candidates for each of these modifiable components, which are subsequently replaced in an iterative fashion. Throughout this process, we continuously assess whether these replacements alter the original semantic meaning of the sentence. Any changes that result in a semantic shift are discarded. Note that the graph cannot be randomly generated as the reasoning tasks\nsince we need to constrain the naturalness and grammar correctness of the generated sentences. As a remedy, the structure of the graph can be abstracted using the template sentences generated by GPT-3.5-Turbo.\nWe generate three alternative versions for each sentence in the above process, forming our newly generated dataset. We then evaluate the performance of both Flan-T5-large and Llama2-7b models, using the original SST-2 dataset as well as our generated dataset for comparison. The results of these evaluations are detailed in Table 10. It shows that using our generated samples, the performance drops, indicating that we are creating challenging test sets. Note that this is an initial study and extending DYVAL to NLP tasks is nontrivial that cannot be covered in this paper, but should be left for future work."
        }
    ],
    "year": 2024
}