{
    "abstractText": "To enhance the efficiency and practicality of federated bandit learning, recent advances have introduced incentives to motivate communication among clients, where a client participates only when the incentive offered by the server outweighs its participation cost. However, existing incentive mechanisms naively assume the clients are truthful: they all report their true cost and thus the higher cost one participating client claims, the more the server has to pay. Therefore, such mechanisms are vulnerable to strategic clients aiming to optimize their own utility by misreporting. To address this issue, we propose an incentive compatible (i.e., truthful) communication protocol, named TRUTH-FEDBAN, where the incentive for each participant is independent of its self-reported cost, and reporting the true cost is the only way to achieve the best utility. More importantly, TRUTHFEDBAN still guarantees the sub-linear regret and communication cost without any overhead. In other words, the core conceptual contribution of this paper is, for the first time, demonstrating the possibility of simultaneously achieving incentive compatibility and nearly optimal regret in federated bandit learning. Extensive numerical studies further validate the effectiveness of our proposed solution.",
    "authors": [
        {
            "affiliations": [],
            "name": "FEDERATED BANDITS"
        },
        {
            "affiliations": [],
            "name": "Zhepei Wei"
        },
        {
            "affiliations": [],
            "name": "Chuanhao Li"
        },
        {
            "affiliations": [],
            "name": "Tianze Ren"
        },
        {
            "affiliations": [],
            "name": "Haifeng Xu"
        },
        {
            "affiliations": [],
            "name": "Hongning Wang"
        }
    ],
    "id": "SP:5c6b47fc5337f122f1e7ef7a442ec8d26d8203b7",
    "references": [
        {
            "authors": [
                "Yasin Abbasi-Yadkori",
                "D\u00e1vid P\u00e1l",
                "Csaba Szepesv\u00e1ri"
            ],
            "title": "Improved algorithms for linear stochastic bandits",
            "venue": "In NIPS,",
            "year": 2011
        },
        {
            "authors": [
                "Gagan Aggarwal",
                "Ashish Goel",
                "Rajeev Motwani"
            ],
            "title": "Truthful auctions for pricing search keywords",
            "venue": "In Proceedings of the 7th ACM Conference on Electronic Commerce,",
            "year": 2006
        },
        {
            "authors": [
                "Aaron Archer",
                "\u00c9va Tardos"
            ],
            "title": "Truthful mechanisms for one-parameter agents",
            "venue": "In Proceedings 42nd IEEE Symposium on Foundations of Computer Science,",
            "year": 2001
        },
        {
            "authors": [
                "Aaron Archer",
                "\u00c9va Tardos"
            ],
            "title": "Frugal path mechanisms",
            "venue": "ACM Transactions on Algorithms (TALG),",
            "year": 2007
        },
        {
            "authors": [
                "Jean-Yves Audibert",
                "S\u00e9bastien Bubeck",
                "R\u00e9mi Munos"
            ],
            "title": "Best arm identification in multi-armed bandits",
            "venue": "In COLT, pp",
            "year": 2010
        },
        {
            "authors": [
                "Peter Auer",
                "Nicolo Cesa-Bianchi",
                "Paul Fischer"
            ],
            "title": "Finite-time analysis of the multiarmed bandit problem",
            "venue": "Machine learning,",
            "year": 2002
        },
        {
            "authors": [
                "Avrim Blum",
                "Nika Haghtalab",
                "Richard Lanas Phillips",
                "Han Shao"
            ],
            "title": "One for one, or all for all: Equilibria and optimality of collaboration in federated learning",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Richard L Burden",
                "J Douglas Faires",
                "Annette M Burden"
            ],
            "title": "Numerical analysis",
            "venue": "Cengage learning,",
            "year": 2015
        },
        {
            "authors": [
                "Edward H Clarke"
            ],
            "title": "Multipart pricing of public goods",
            "venue": "Public choice, pp",
            "year": 1971
        },
        {
            "authors": [
                "Kate Donahue",
                "Jon Kleinberg"
            ],
            "title": "Fairness in model-sharing games",
            "venue": "In Proceedings of the ACM Web Conference",
            "year": 2023
        },
        {
            "authors": [
                "Abhimanyu Dubey",
                "AlexSandy\u2019 Pentland"
            ],
            "title": "Differentially-private federated linear bandits",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Audrey Durand",
                "Charis Achilleos",
                "Demetris Iacovides",
                "Katerina Strati",
                "Georgios D Mitsis",
                "Joelle Pineau"
            ],
            "title": "Contextual bandits for adapting treatment in a mouse model of de novo carcinogenesis",
            "venue": "In Machine learning for healthcare conference,",
            "year": 2018
        },
        {
            "authors": [
                "Aur\u00e9lien Garivier",
                "Emilie Kaufmann"
            ],
            "title": "Optimal best arm identification with fixed confidence",
            "venue": "In Conference on Learning Theory,",
            "year": 2016
        },
        {
            "authors": [
                "Theodore Groves"
            ],
            "title": "Incentives in teams",
            "venue": "Econometrica: Journal of the Econometric Society, pp",
            "year": 1973
        },
        {
            "authors": [
                "David A Harville"
            ],
            "title": "Matrix Algebra From a Statistician\u2019s Perspective",
            "venue": "Springer Science & Business Media,",
            "year": 2008
        },
        {
            "authors": [
                "Jiafan He",
                "Tianhao Wang",
                "Yifei Min",
                "Quanquan Gu"
            ],
            "title": "A simple and provably efficient algorithm for asynchronous federated contextual linear bandits",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Ruiquan Huang",
                "Weiqiang Wu",
                "Jing Yang",
                "Cong Shen"
            ],
            "title": "Federated linear contextual bandits",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Atsushi Iwasaki",
                "David Kempe",
                "Yasumasa Saito",
                "Mahyar Salek",
                "Makoto Yokoo"
            ],
            "title": "False-nameproof mechanisms for hiring a team",
            "venue": "In Internet and Network Economics: Third International Workshop,",
            "year": 2007
        },
        {
            "authors": [
                "Rishabh K Iyer",
                "Jeff A Bilmes"
            ],
            "title": "Submodular optimization with submodular cover and submodular knapsack constraints",
            "venue": "Advances in neural information processing systems,",
            "year": 2013
        },
        {
            "authors": [
                "Kirthevasan Kandasamy",
                "Joseph E Gonzalez",
                "Michael I Jordan",
                "Ion Stoica"
            ],
            "title": "Vcg mechanism design with unknown agent values under stochastic bandit feedback",
            "venue": "Journal of Machine Learning Research,",
            "year": 2023
        },
        {
            "authors": [
                "Sai Praneeth Karimireddy",
                "Wenshuo Guo",
                "Michael I Jordan"
            ],
            "title": "Mechanisms that incentivize data sharing in federated learning",
            "venue": "arXiv preprint arXiv:2207.04557,",
            "year": 2022
        },
        {
            "authors": [
                "Peter Landgren",
                "Vaibhav Srivastava",
                "Naomi Ehrich Leonard"
            ],
            "title": "On distributed cooperative decision-making in multiarmed bandits",
            "venue": "In 2016 European Control Conference (ECC),",
            "year": 2016
        },
        {
            "authors": [
                "Tor Lattimore",
                "Csaba Szepesv\u00e1ri"
            ],
            "title": "Bandit algorithms",
            "year": 2020
        },
        {
            "authors": [
                "Tra Huong Thi Le",
                "Nguyen H Tran",
                "Yan Kyaw Tun",
                "Minh NH Nguyen",
                "Shashi Raj Pandey",
                "Zhu Han",
                "Choong Seon Hong"
            ],
            "title": "An incentive mechanism for federated learning in wireless cellular networks: An auction approach",
            "venue": "IEEE Transactions on Wireless Communications,",
            "year": 2021
        },
        {
            "authors": [
                "Daniel Lehmann",
                "Liadan Ita O\u0107allaghan",
                "Yoav Shoham"
            ],
            "title": "Truth revelation in approximately efficient combinatorial auctions",
            "venue": "Journal of the ACM (JACM),",
            "year": 2002
        },
        {
            "authors": [
                "Chuanhao Li",
                "Hongning Wang"
            ],
            "title": "Asynchronous upper confidence bound algorithms for federated linear bandits",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2022
        },
        {
            "authors": [
                "Chuanhao Li",
                "Hongning Wang"
            ],
            "title": "Communication efficient federated learning for generalized linear bandits",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Chuanhao Li",
                "Huazheng Wang",
                "Mengdi Wang",
                "Hongning Wang"
            ],
            "title": "Communication efficient distributed learning for kernelized contextual bandits",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Chuanhao Li",
                "Huazheng Wang",
                "Mengdi Wang",
                "Hongning Wang"
            ],
            "title": "Learning kernelized contextual bandits in a distributed and asynchronous environment",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Lihong Li",
                "Wei Chu",
                "John Langford",
                "Robert E Schapire"
            ],
            "title": "A contextual-bandit approach to personalized news article recommendation",
            "venue": "In Proceedings of the 19th international conference on World wide web,",
            "year": 2010
        },
        {
            "authors": [
                "Wei Li",
                "Xuerui Wang",
                "Ruofei Zhang",
                "Ying Cui",
                "Jianchang Mao",
                "Rong Jin"
            ],
            "title": "Exploitation and exploration in a performance based contextual advertising system",
            "venue": "In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining,",
            "year": 2010
        },
        {
            "authors": [
                "Oded Maron",
                "Andrew Moore"
            ],
            "title": "Hoeffding races: Accelerating model selection search for classification and function approximation",
            "venue": "Advances in neural information processing systems,",
            "year": 1993
        },
        {
            "authors": [
                "David Mart\u0131\u0301nez-Rubio",
                "Varun Kanade",
                "Patrick Rebeschini"
            ],
            "title": "Decentralized cooperative stochastic bandits",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Ahuva Mu\u2019Alem",
                "Noam Nisan"
            ],
            "title": "Truthful approximation mechanisms for restricted combinatorial auctions",
            "venue": "Games and Economic Behavior,",
            "year": 2008
        },
        {
            "authors": [
                "Noam Nisan",
                "Amir Ronen"
            ],
            "title": "Algorithmic mechanism design",
            "venue": "In Proceedings of the thirty-first annual ACM symposium on Theory of computing,",
            "year": 1999
        },
        {
            "authors": [
                "Jian Pei"
            ],
            "title": "A survey on data pricing: from economics to data science",
            "venue": "IEEE Transactions on knowledge and Data Engineering,",
            "year": 2020
        },
        {
            "authors": [
                "Ariel D Procaccia"
            ],
            "title": "Cake cutting: Not just child\u2019s play",
            "venue": "Communications of the ACM,",
            "year": 2013
        },
        {
            "authors": [
                "Ariel D Procaccia",
                "Moshe Tennenholtz"
            ],
            "title": "Approximate mechanism design without money",
            "venue": "ACM Transactions on Economics and Computation (TEAC),",
            "year": 2013
        },
        {
            "authors": [
                "Alvin E Roth"
            ],
            "title": "On the allocation of residents to rural hospitals: a general property of two-sided matching markets",
            "venue": "Econometrica: Journal of the Econometric Society,",
            "year": 1986
        },
        {
            "authors": [
                "Chengshuai Shi",
                "Cong Shen"
            ],
            "title": "Federated multi-armed bandits",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Chengshuai Shi",
                "Wei Xiong",
                "Cong Shen",
                "Jing Yang"
            ],
            "title": "Decentralized multi-player multi-armed bandits with no collision information",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2020
        },
        {
            "authors": [
                "Rachael Hwee Ling Sim",
                "Yehong Zhang",
                "Mun Choon Chan",
                "Bryan Kian Hsiang Low"
            ],
            "title": "Collaborative machine learning with incentive-aware model rewards",
            "venue": "In International conference on machine learning,",
            "year": 2020
        },
        {
            "authors": [
                "Maxim Sviridenko"
            ],
            "title": "A note on maximizing a submodular set function subject to a knapsack constraint",
            "venue": "Operations Research Letters,",
            "year": 2004
        },
        {
            "authors": [
                "Kunal Talwar"
            ],
            "title": "The price of truth: Frugality in truthful mechanisms",
            "venue": "In Annual Symposium on Theoretical Aspects of Computer Science,",
            "year": 2003
        },
        {
            "authors": [
                "Xuezhen Tu",
                "Kun Zhu",
                "Nguyen Cong Luong",
                "Dusit Niyato",
                "Yang Zhang",
                "Juan Li"
            ],
            "title": "Incentive mechanisms for federated learning: From economic and game theoretic perspective",
            "venue": "IEEE transactions on cognitive communications and networking,",
            "year": 2022
        },
        {
            "authors": [
                "William Vickrey"
            ],
            "title": "Counterspeculation, auctions, and competitive sealed tenders",
            "venue": "The Journal of finance,",
            "year": 1961
        },
        {
            "authors": [
                "Yuanhao Wang",
                "Jiachen Hu",
                "Xiaoyu Chen",
                "Liwei Wang"
            ],
            "title": "Distributed bandit learning: Nearoptimal regret with efficient communication",
            "venue": "In International Conference on Learning Representations,",
            "year": 2020
        },
        {
            "authors": [
                "Zhepei Wei",
                "Chuanhao Li",
                "Haifeng Xu",
                "Hongning Wang"
            ],
            "title": "Incentivized communication for federated bandits",
            "venue": "In Thirty-seventh Conference on Neural Information Processing Systems,",
            "year": 2023
        },
        {
            "authors": [
                "Laurence A Wolsey"
            ],
            "title": "An analysis of the greedy algorithm for the submodular set covering problem",
            "year": 1982
        },
        {
            "authors": [
                "Xinyi Xu",
                "Lingjuan Lyu",
                "Xingjun Ma",
                "Chenglin Miao",
                "Chuan Sheng Foo",
                "Bryan Kian Hsiang Low"
            ],
            "title": "Gradient driven rewards to guarantee fairness in collaborative machine learning",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Zhaowei Zhu",
                "Jingxuan Zhu",
                "Ji Liu",
                "Yang Liu"
            ],
            "title": "Federated bandit: A gossiping approach",
            "venue": "In Abstract Proceedings of the 2021 ACM SIGMETRICS/International Conference on Measurement and Modeling of Computer Systems,",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Bandit learning (Lattimore & Szepesva\u0301ri, 2020) addresses the exploration-exploitation dilemma in interactive environments, where the learner repeatedly chooses actions and observes the corresponding rewards from the environment. Subject to different goals of the learner, e.g., maximizing cumulative rewards (Abbasi-Yadkori et al., 2011; Auer et al., 2002) vs., identifying the best arm (Audibert et al., 2010; Garivier & Kaufmann, 2016), bandit algorithms have been widely applied in various real-world applications, such as model selection (Maron & Moore, 1993), recommender systems (Li et al., 2010a;b), and clinical trials (Durand et al., 2018). Most recently, propelled by the increasing scales of data across various sources and public concerns about data privacy, there has been growing research effort devoted to federated bandit learning, which enables collective bandit learning among distributed learners while preserving data privacy of each learner. Recent advances in this line of research mainly focus on addressing the communication bottleneck in the federated network, which leads to communication-efficient protocols for both non-contextual (Landgren et al., 2016; Mart\u0131\u0301nez-Rubio et al., 2019; Shi et al., 2020; Zhu et al., 2021) and contextual bandits (Wang et al., 2020; Huang et al., 2021; Li et al., 2022; 2023) under various environment settings.\nHowever, almost all previous works assume clients are altruistic in sharing their local data with the server whenever communication is triggered (Wang et al., 2020; Li & Wang, 2022a; He et al., 2022). This limits their practical deployment in real-world scenarios involving individual rational clients who share data only if provided with clear benefits. The only notable exception is Wei et al. (2023), where incentive is provided to motivate client\u2019s participation in federated learning. Nevertheless, their protocol naively assumes the clients are truthful in reporting their participation cost; and thus, they simply calculate incentives by each client\u2019s claimed cost, leaving it as a design flaw for strategic clients to exploit. Therefore, how to design an incentive compatible mechanism for federated bandits that ensures truthful reporting while still preserving the near-optimal regret and communication cost still remains an open research problem.\n\u2217Equal Contribution\nFollowing Wei et al. (2023)\u2019s setting for learning contextual linear bandits in a federated environment, we develop the first incentive compatible communication protocol TRUTH-FEDBAN, which ensures the clients can only achieve their best utility by reporting the true participation costs. Specifically, instead of simply paying a client by its claimed cost, we decouple the calculation of incentive from the target client\u2019s reported cost, while preserving individual rationality through a critical-value based payment design that depends on all other clients\u2019 report cost. Besides the theoretical guarantee on truthfulness, we also empirically demonstrate that misreporting cost brings no benefit to the client\u2019s utility. More encouragingly, we prove that this can be achieved without any compromise in maintaining the near-optimal performance in regret and communication cost.\nOn the other hand, in addition to the above desiderata, maintaining a minimal social cost is also an important objective in the incentivized communication problem, especially in practical applications. Following classical economic literature (Procaccia & Tennenholtz, 2013), social cost is defined as the sum of true participation costs among all participating clients. While incentivizing all clients\u2019 participation ensures nearly optimal performance (Wang et al., 2020), it can be scientifically trivial (e.g., paying everyone to have all of them participate) and practically undesirable \u2014 it not only brings unnecessary burden for the server, but can also expose unnecessary clients to potential downsides of participation (e.g., privacy breaches, added resource consumption, etc.), resulting in worse social cost. Minimizing social cost while ensuring sufficient client participation is non-trivial, as it in nature is NP-hard (see Eq. (1)). Though the method proposed by Wei et al. (2023) achieves sub-linear regret and communication cost (albeit assuming truthfulness), it provides no guarantee on the social cost. In contrast, our proposed TRUTH-FEDBAN guarantees both sub-linear regret and near-optimal social cost, with only a constant-factor approximation ratio. To better illustrate our contribution, we compare the proposed TRUTH-FEDBAN with the most related works in Table 1."
        },
        {
            "heading": "2 RELATED WORK",
            "text": ""
        },
        {
            "heading": "2.1 FEDERATED BANDIT LEARNING",
            "text": "Federated bandit learning has been well investigated for sequential decision making in distributed environments. These studies mainly differ in how they model the clients\u2019 and environment characteristics, which can be categorized into 1) bandit-wise: problem profile (e.g., context-free (Mart\u0131\u0301nezRubio et al., 2019; Shi & Shen, 2021; Shi et al., 2020) vs. contextual (Wang et al., 2020)) and decision set (e.g., fixed (Huang et al., 2021) vs. time-varying (Li & Wang, 2022b)), and 2) system-wise: client type (e.g., homogeneous (He et al., 2022) vs. heterogeneous (Li & Wang, 2022a)), network type (e.g., peer-to-peer (P2P) (Dubey & Pentland, 2020) vs. star-shaped (Wang et al., 2020)), and communication type (e.g., synchronous (Li et al., 2022) vs. asynchronous (Li et al., 2023)).\nMost recently, Wei et al. (2023) expand this spectrum by introducing the notion of incentivized communication, where the server has to pay the clients for their participation. Despite being free from the long-standing assumption about the client\u2019s willingness of participation in literature, they still assume truthfulness of clients in cost reporting. Specifically, their incentive calculation is based on the client\u2019s self-reported cost, which leads to serious vulnerability in adversarial scenarios as clients can exploit this flaw, ultimately paralyzing the federated learning system. This is particularly concerning in real-world applications where self-interested clients are motivated to strategically game the system for increased utilities, i.e., increase the difference between incentives offered by the server and actual participation costs. Our work aims to address this issue by introducing a truthful incentive mechanism under which clients reporting true costs is in their best interest, while ensuring near-optimal learning performance."
        },
        {
            "heading": "2.2 MECHANISM DESIGN",
            "text": "Mechanism design (Nisan & Ronen, 1999) has been playing a crucial role in the fields of economics, computer science and operation research, with fruitful auction-like real-world applications such as matching markets (Roth, 1986), resource allocation (Procaccia, 2013), online advertisement pricing (Aggarwal et al., 2006). Typically, the auctioneer (server) aims to sell/purchase one or more entries of a collection to/from multiple bidders (clients), with the objective of maximizing social welfare or minimizing social cost. The goal of mechanism design is to incentivize clients to truthfully report the values of the entries (i.e., truthfulness), while ensuring non-negative utilities if they participate in the mechanism (i.e., individual rationality).\nThe Vickrey-Clarke-Groves (VCG) mechanism (Vickrey, 1961; Clarke, 1971; Groves, 1973) is probably the most well-known truthful mechanism. Despite having been well explored in many theoretical studies, VCG is rarely applied in practical applications due to its computational inefficiency. This is because VCG requires finding an optimal solution to the concerned problem, which is often NP-hard (Archer & Tardos, 2001). Otherwise, truthfulness cannot be guaranteed when VCG mechanisms are applied to sub-optimal solutions (Lehmann et al., 2002). To facilitate study on this issue, Mu\u2019Alem & Nisan (2008) identified the key character of a truthful mechanism and reduced the problem to designing a monotone algorithm (see Section 4.1). One notable recent related work is (Kandasamy et al., 2023), where the authors model repeated auctions as a bandit learning problem for the server, with clients being unaware of their values but able to provide bandit feedback based on the server\u2019s allocation. The server\u2019s goal is to find allocations that maximize social welfare, while ensuring the clients\u2019 truthfulness in their feedback. In contrast, in our work, clients know their participation costs and are concerned to solve the bandit problem collectively. The server\u2019s goal is to incentivize clients\u2019 participation for regret minimization, while ensuring the clients\u2019 truthfulness in cost reporting and minimizing social cost.\nIn terms of problem formulation, our work is closest to the hiring-a-team task in procurement auctions (Talwar, 2003; Archer & Tardos, 2007), where the server aims to incentivize a set of selfinterested clients to jointly perform a task. One standard assumption in this task is that the environment is monopoly-free, i.e., no single client exists in all feasible sets (Iwasaki et al., 2007). The reason is that if a client is essential, it has the bargaining power to ask for infinite incentive. In this paper, we do not assume a monopoly-free environment, otherwise additional environment assumptions will be needed (e.g., how the context or arms should distribute across clients). Instead, we are intrigued in studying the origin and impact of the monopoly issue from both theoretical and empirical perspectives. And we also rigorously prove that we can eliminate the issue via hyper-parameter control in our mechanism (see Lemma 7)."
        },
        {
            "heading": "2.3 MECHANISM DESIGN IN FEDERATED LEARNING",
            "text": "On the other hand, there have been growing efforts in investigating mechanism design in the context of federated learning (Pei, 2020; Tu et al., 2022). For example, Karimireddy et al. (2022) introduced a contract-theory based incentive mechanism to maximize data sharing while avoiding free-riding clients. In their design, every client gets different snapshots of the global model with different levels of accuracy as incentive, and truthfully reporting their data sharing costs is the best response under the proposed incentive mechanism. Therefore, there is no overall performance guarantee and their focus is on investigating the level of accuracy the system can achieve under this truthful incentive mechanism. Le et al. (2021) also investigated truthful mechanism design in the application scenario of wireless communication, where server\u2019s goal is to maximize the system\u2019s social welfare, with respect to a knapsack upper bound constraint. In contrast, in our problem the server is obligated to improve the overall performance of the learning system, i.e., obtaining near-optimal regret among all clients. Furthermore, our optimization problem (defined in Eq. (3)) aims at minimizing the social cost, with respect to a submodular lower bound constraint. Therefore, despite we share a similar idea of using the monotone participant selection rule and critical-value based payment design to guarantee truthfulness, the underlying fundamental optimization problems are completely different, and consequently their solution cannot be used to solve our problem. Besides pursuing the truthfulness guarantee in mechanism design under the collaborative/federated setting, the other related line of research focuses on designing incentive mechanisms that ensures fairness among distributed clients (Blum et al., 2021; Xu et al., 2021; Sim et al., 2020; Donahue & Kleinberg, 2023), which is also an important direction, despite being beyond the scope of our work. To our best knowledge, our work is the first attempt that studies truthful mechanism design for federated bandit learning."
        },
        {
            "heading": "3 PRELIMINARY: INCENTIVIZED FEDERATED BANDITS",
            "text": "In this section, we present the incentivized communication problem for federated bandits in general and the existing solution framework under the linear reward assumption (Wang et al., 2020). More precisely, we focus our discussions on the learning objectives, including minimizing regret, communication cost, social cost, and ensuring truthfulness.\nConsider a learning system with 1) N distributed strategic and individual rational clients that repeatedly interact with the environment by taking actions to receive rewards, and 2) a central server responsible for motivating the clients to participate in federated learning via incentives. As in line with Wei et al. (2023), we assume the clients can only communicate with the server, forming a star-shaped communication network. Specifically, at each time step t \u2208 [T ], an arbitrary client it \u2208 [N ] chooses an arm xt \u2208 At from its given arm set At \u2286 Rd. Then, client it receives a reward yt = x \u22a4 t \u03b8\u22c6 + \u03b7t \u2208 R, where \u03b8\u22c6 is the unknown parameter shared by all clients and \u03b7t denotes zeromean sub-Gaussian noise. Typically, in the centralized setting of bandit learning, a ridge regression estimator \u03b8\u0302t = V \u22121g,t bg,t is constructed for arm selection based on the sufficient statistics from all N clients at time step t, where Vg,t = \u2211t s=1 xsx \u22a4 s and bg,t = \u2211t s=1 xsys. In contrast, since communication does not occur at every time step t in the federated setting, each client i only has a delayed copy of Vg,t and bg,t, denoted as Vi,t = Vg,tlast + \u2206Vi,t, bi,t = bg,tlast + \u2206bi,t, where Vg,tlast , bg,tlast are the aggregated statistics shared by the server in the last communication, and \u2206Vi,t,\u2206bi,t are the accumulated local updates that client i has collected from the environment since tlast.\nRegret and Communication Cost One key objective of the learning system is to minimize the (pseudo) regret for all N clients across the entire time horizon T , i.e., RT = \u2211T t=1 rt, where rt = maxx\u2208At E[y|x]\u2212E[yt|xt] is the instantaneous regret of client it at time step t. Meanwhile, a low communication cost is also desired to keep the efficiency of federated learning, which is measured by the total number of scalars transferred throughout the system up to time T . Intuitively, more frequent communication leads to lower regret. For example, communicating at every time step recovers the centralized setting, leading to the lowest regret, but with an undesirably high communication cost. Efficient communication protocol design becomes the key to balance regret and communication cost. And using determinant ratio to measure the outdatedness of the sufficient statistics stored on the server side against those on the client side has become the reference solution to control communication in federated linear bandits (Wang et al., 2020; Li & Wang, 2022a).\nIncentivized Communication When dealing with individual rational clients, additional treatment is needed to facilitate communication, as it becomes possible that no client participates unless properly incentivized thus leading to terrible regret. In other words, client i only participates if its utility ui,t = Ii,t\u2212Di,t is non-negative, where Ii,t is the server-provided incentive, and Di,t is the client\u2019s participation cost. To address this challenge and maintain near-optimal learning outcome, Wei et al. (2023) pinpointed the core optimization problem in incentivized communication as follows:\nmin St\u22082S\u0303 \u2211 i\u2208St D\u0302i,t s.t. det(Vg,t(St)) det(Vg,t(S\u0303)) \u2265 \u03b2 (1)\nwhere D\u0302i,t is client i\u2019s reported participation cost, St is the set of clients selected to participate at time step t, S\u0303 = {1, 2, \u00b7 \u00b7 \u00b7 , N} is the set of all clients, \u03b2 is specified as an input to the algorithm, and Vg,t(S) = Vg,tlast + \u2211 j\u2208S \u2206Vj,t. In particular, they assume the clients\u2019 reported cost is simply\nthe true cost, i.e., D\u0302i,t = Di,t. A heuristic search algorithm is executed to solve the optimization problem whenever the standard communication event (Wang et al., 2020) is triggered. A detailed description of this communication protocol is provided in Appendix F.\nNote that Wei et al. (2023)\u2019s work is limited to a constant cost setting of Di,t = Ci \u00b7 I(\u2206Vi,t \u0338= 0), which restricts the actual cost Di,t of client i to be independent of time and its local updates \u2206Vi,t. In our work, we relax it to Di,t = f(\u2206Vi,t), where f can be any reasonable data valuation function, and even time-varying1. Moreover, their proposed solution for Eq. (1) fails to provide any approximation guarantee on the objective, thus having no guarantee on the social cost. Below, we provide a formal definition of truthfulness and social cost employed in this paper.\n1In fact, our proposed TRUTH-FEDBAN works with any realization of the valuation function, as all that matters is that client i has a value Di,t for its data at time step t.\nDefinition 1 (Truthfulness) An incentive mechanism is truthful (i.e., incentive compatible) if at any time t the utility ui,t of any client i is maximized when it reports its true participation cost, i.e., D\u0302i,t = Di,t, regardless of the reported costs of the other clients\u2019 D\u0302\u2212i,t.\nDefinition 2 (Social Cost) The social cost of the learning system is defined as the total actual costs incurred by all participating clients in the incentivized client set St, i.e., \u2211 i\u2208St Di,t.\nNote that the social cost defined above is different from the incentive cost studied in Wei et al. (2023), which is the total payment the server made to all clients. As truthfulness is assumed in their setting, the payment that the server needs to make to incentivize a client is trivially upper bounded by the client\u2019s true cost. However, in order to ensure truthfulness in our setting, the server needs to overpay the selected clients (compared with their true cost). In the case where there exists monopoly client as introduced in Section 2.2, an infinite incentive cost is required."
        },
        {
            "heading": "4 METHODOLOGY",
            "text": ""
        },
        {
            "heading": "4.1 CHARACTERIZATION OF TRUTHFUL INCENTIVE MECHANISMS",
            "text": "Our idea stems from the seminal result of Mu\u2019Alem & Nisan (2008), who provided a characterization of a truthful incentive mechanism as a combination of a monotone selection rule and a critical value payment scheme, which reduces the problem of designing a truthful mechanism to that of designing a monotone selection rule. Though it is originally intended for combinatorial auctions in economics, we are the first to extend it to the incentivized communication problem in federated bandit learning, laying the foundations for future work.\nDefinition 3 (Monotonicity) The selection rule for the set St is monotone if for any client i and any reported costs of the other clients D\u0302\u2212i,t, client i will remain selected whenever it reports D\u0302\u2032i,t \u2264 D\u0302i,t, provided it is incentivized when reporting D\u0302i,t.\nFurthermore, according to Mu\u2019Alem & Nisan (2008), any monotone selection rule of the incentive mechanism has an associated critical payment scheme, with its definition given below.\nDefinition 4 (Critical Payment) Let M be a monotone selection rule of the incentive mechanism and St be the set of selected clients, then for any client i and any reported costs of the other clients D\u0302\u2212i,t, there exists a critical value ci,t(M, D\u0302\u2212i,t) \u2208 (R+ \u222a \u221e) such that i \u2208 St, \u2200D\u0302i,t < ci,t(M, D\u0302\u2212i,t), and i /\u2208 St, \u2200D\u0302i,t > ci,t(M, D\u0302\u2212i,t).\nIn this way, we can decouple the incentive Ii,t for client i from its reported participation cost D\u0302i,t, and calculate the critical value based only on the other clients\u2019 reported costs D\u0302\u2212i,t. Formally,\nIi,t = ci,t(M, D\u0302\u2212i,t) \u00b7 I(i \u2208 St) (2)\nwhich is fundamentally different from the incentive design in (Wei et al., 2023) where Ii,t = D\u0302i,t \u00b7 I(i \u2208 St), as our payment method leaves no room for strategic clients to manipulate the incentive and benefit from misreporting."
        },
        {
            "heading": "4.2 TRUTH-FEDBAN: A TRUTHFUL MECHANISM FOR INCENTIVIZED COMMUNICATION",
            "text": "To balance regret and communication cost, while ensuring truthfulness and minimizing social cost, our proposed incentive mechanism TRUTH-FEDBAN inherits the incentivized communication protocol by Wei et al. (2023), with the distinction in implementing a truthful incentive search. As stated above, the truthfulness of clients is ensured once we devise a monotone algorithm for client selection, combined with a critical payment scheme. But straightforward monotone algorithms (e.g., a greedy algorithm ranking clients by their claimed costs) offer no guarantee on social cost. To address this challenge, we rewrite the original optimization problem in Eq. (1) into the following equivalent submodular set cover (SSC) problem, where g(S) is a submodular set function (see Definition 11).\nmin St\u22082S\u0303 \u2211 i\u2208St D\u0302i,t s.t. gt(St) \u2265 log \u03b2, gt(St) = log det(Vg,t(St)) det(Vg,t(S\u0303)) (3)\nAlgorithm 1 Truthful Incentive Search Require: \u03b2, \u03f5 > 0\n1: St \u2190 \u2205, S\u0303 = {1, 2, \u00b7 \u00b7 \u00b7 , N} 2: b\u2190 mini\u2208S\u0303 D\u0302i,t 3: while gt(St) < (1\u2212 e\u22121) log \u03b2 do 4: b\u2190 (1 + \u03f5)b 5: St \u2190 GREEDY(S\u0303, b) 6: return St\nAlgorithm 2 GREEDY\nRequire: S\u0303, b 1: St \u2190 \u2205 2: while \u2211 i\u2208St D\u0302i,t < b do\n3: u\u2190 argmax j\u2208S\u0303\\St:D\u0302j,t+ \u2211 i\u2208St D\u0302i,t<b gt(St\u222a{j})\u2212gt(St) D\u0302j,t 4: St \u2190 St \u222a {u} 5: return St\nInspired by Iyer & Bilmes (2013), we propose Algorithm 1 that achieves a constant-factor bi-criteria approximation for both the objective and constraint in the problem defined by Eq. (3). As outlined above, we first initialize a minimal budget (Line 2) for social cost and repeatedly increase the budget (Line 4) until the resulting client set found by Algorithm 2 satisfies the specified condition (Line 3).\nIn Algorithm 2, for a given budget b, we iteratively find the best set of clients from the complete client set until the budget cannot afford more clients. At each iteration, all the remaining nonselected clients are ranked based on their contribution-to-cost ratio (and hence being greedy). The algorithm then chooses the client with the highest ratio while ensuring the total cost of all selected clients is within the budget (Line 3 of Algorithm 2). The correctness of our method hinges on the following crucial monotonicity property that we prove. Interestingly, despite the wide use of greedy algorithms in submodular maximization, this monotonicity result is unknown in previous literature to the best of our knowledge. We thus present it as a proposition in case it is of independent interest.\nProposition 5 (Monotonicity) Algorithm 1 is monotone.\nIt is not difficult to show that Algorithm 2 is monotone for a fixed input budget b \u2014 that is, if client i is selected under D\u0302i,t by Algorithm 2, it remains selected when it reports any D\u0302\u2032i,t \u2264 D\u0302i,t. But it is highly non-trivial to prove monotonicity for Algorithm 1. This is because decreasing a client\u2019s reported cost can cause a different output by Algorithm 2 and, consequently, terminate the search process in Algorithm 1 at a different budget b with a potentially different selection of participant set St. We prove Proposition 5 by showing the resulting objective value gt(St) from Algorithm 2\u2019s selection of clients is non-decreasing with respect to its input budget b. The proof is a bit involving since Algorithm 2 is an approximate algorithm and generally outputs sub-optimal solutions. We will have to show that the quality of these sub-optimal solutions \u2014 which can be close to or far away from the exact optimality \u2014 will not degenerate as the budget b increases. The proof of the above property, together with the formal proof of Proposition 5, can be found in Appendix A.\nLemma 6 If the selection rule of a truthful mechanism is computable in polynomial time, so is the critical payment scheme (Mu\u2019Alem & Nisan, 2008).\nNote that in the star-shaped communication network, only the server has the necessary information to calculate the critical value of each client, and we assume the server is committed not to tricking the clients. Due to space limit, we leave the detailed critical payment calculation to Appendix G. In particular, as we do not assume a monopoly-free environment, a client\u2019s critical value could be infinite at a certain point, as introduced in Section 2.2. Nonetheless, Lemma 7 shows that this infinite payment issue can be essentially eliminated by hyper-parameter control. The time complexity analysis of Algorithm 1 can be found in Appendix H.\nLemma 7 (Elimination of Infinite Critical Value) With parameter \u03b2 \u2264 (1 + tL2/\u03bbd)\u2212d in Algorithm 1, no client will be essential in any communication round at time step t.\nA detailed proof is provided in Appendix D. Building upon the properties above, we are now ready to state the main incentive guarantee of our TRUTH-FEDBAN protocol.\nTheorem 8 The incentive mechanism induced by Algorithm 1 is (a) truthful in the sense that every client achieves the highest utility by reporting its true participation cost; and (b) individually rational in the sense that every client\u2019s utility of participating in the mechanism is non-negative.\nProof The truthfulness guarantee directly follows Lemma 5. Below, we further elaborate on the impact of misreporting. Denote St and S\u2032t as the participant sets when client i truthfully reports and misreports its data sharing cost as D\u0302i,t = Di,t and D\u0302\u2032i,t \u0338= Di,t, respectively. Let ci,t be the critical value of client i, and ui,t and u\u2032i,t be its utilities in the above two conditions respectively. According to Definition 4, we have i \u2208 St whenever D\u0302i,t < ci,t, and i /\u2208 S\u2032t whenever D\u0302\u2032i,t > ci,t. Moreover, if i /\u2208 St, then ui,t = 0. For simplicity, the subscript t is omitted in the following discussion. Specifically, there are four possible cases: 1) i \u2208 S and i \u2208 S\u2032, as critical payment is independent from the client\u2019s reported cost D\u0302i and D\u0302\u2032i, therefore u \u2032 i \u2212 ui = (ci \u2212Di)\u2212 (ci \u2212Di) = 0; 2) i \u2208 S and i /\u2208 S\u2032, in this case, D\u0302i = Di < ci < D\u0302\u2032i. Therefore, u\u2032i \u2212 ui = 0\u2212 (ci \u2212Di) = Di \u2212 ci < 0; 3) i /\u2208 S and i \u2208 S\u2032, in this case, D\u0302\u2032i < ci < D\u0302i = Di. Therefore, u\u2032i \u2212 ui = (ci \u2212Di)\u2212 0 < 0; 4) i /\u2208 S and i /\u2208 S\u2032, in this case, both utilizes are zero, therefore u\u2032i \u2212 ui = 0 \u2212 0 = 0. To conclude, there is no benefit to misreport under our truthful mechanism design in all cases, and only reporting the true data sharing cost can lead to the client\u2019s best utility.\nWe now prove the individual rationality. Given the truthfulness guarantee, each client i reports its true cost D\u0302i,t = Di,t, and only gets incentivized if D\u0302i,t < ci,t. Therefore, the utility of client i is ui,t = ci,t \u2212 Di,t > 0 if client i gets incentivized; otherwise, ui,t = 0. In either case, client i is ensured to have a non-negative utility, which completes the proof."
        },
        {
            "heading": "4.3 LEARNING PERFORMANCE OF TRUTH-FEDBAN PROTOCOL",
            "text": "The truthfulness property above helps the system induce desirable clients participation behaviors. In this subsection, we demonstrate the learning performance of TRUTH-FEDBAN under these client behaviors. Our main results are the following guarantees regarding total social cost that the TRUTHFEDBAN protocol has to suffer and the resultant regret guarantee it induces.\nTheorem 9 (Social Cost) For any \u03f5 > 0, using Algorithm 2 to search for participants in Algorithm 1 provides a [1 + \u03f5, 1 \u2212 e\u22121] bi-criteria approximation solution for the problem defined in Eq. (3). In other words, to maintain a social cost that is within a (1 + \u03f5) factor of the optimal value, it necessitates a relaxation of the constraint by a factor of (1\u2212 e\u22121). Formally,\u2211\ni\u2208St D\u0302i,t \u2264 (1 + \u03f5) \u2211 i\u2208S\u22c6t D\u0302i,t and gt(St) \u2265 (1\u2212 e\u22121) log \u03b2\nwhere St is the output of Algorithm 1, and S\u22c6t is the ground-truth optimizer of Eq. (3). Proof Denote the optimal objective value of Eq. (3) as OPT. For the solution S\u22c6t , we have OPT =\u2211 i\u2208S\u22c6t\nD\u0302i,t and gt(S\u22c6t ) \u2265 log \u03b2. To simplify out discussions, we omit the subscript t and let Sb and b be the output set and terminating budget of Algorithm 1 for solving the problem in Eq. (3), and Sb\u2032 and b\u2032 = b/(1 + \u03f5) be the set and budget at the previous iteration before termination, then we have{\ng(Sb\u2032) < (1\u2212 e\u22121) log \u03b2 (4) g(Sb) \u2265 (1\u2212 e\u22121) log \u03b2 (5)\nDenote S\u22c6b\u2032 as the optimal solution for the subroutine search problem with budget b \u2032 (denote the problem solved by Algorithm 2 in Line 5 of Algorithm 1 as SUBPROBLEM). According to Sviridenko (2004), the approximation ratio of Algorithm 2 for this SUBPROBLEM is (1\u2212 e\u22121), i.e.,\ng(Sb\u2032) \u2265 (1\u2212 e\u22121)g(S\u22c6b\u2032) (6)\nCombining Eq. (4) and Eq. (6), we have g(S\u22c6b\u2032) < log \u03b2. Furthermore, we can show that OPT > b \u2032 by contradiction. Assuming OPT \u2264 b\u2032, then S\u22c6 is a feasible solution for the SUBPROBLEM, and thus g(S\u22c6) \u2264 g(S\u22c6b\u2032) < log \u03b2. However, this contradicts the fact that g(S\u22c6) \u2265 log \u03b2, so OPT > b\u2032. Hence, we can show that the objective value of solution Sb satisfies the following inequality:\u2211\ni\u2208Sb\nD\u0302i \u2264 b = (1 + \u03f5)b\u2032 < (1 + \u03f5)OPT (7)\nThis, combined with Eq. (5), concludes the proof.\nSince D\u0302i,t = Di,t is guaranteed (see Theorem 8), Theorem 9 directly bounds the social cost as defined in Definition 2. Note that as indicated by Theorem 9, we can flexibly choose any desired level of social cost by adjusting the parameter \u03f5, which allows us to accommodate various computation resources in practical scenarios. For example, in the case where computation is not a limiting factor and the core objective is to minimize the social cost, we can set the factor (1 + \u03f5) to be almost 1, approaching the optimal social cost. Moreover, though this bi-criteria approximation slightly deviates from the constraint of the original problem in Eq. (3), it only incurs a constant-factor gap of (1 \u2212 e\u22121), and Theorem 10 shows that we still attain near-optimal regret and communication cost, despite this deviation (see proof in Appendix E).\nTheorem 10 (Regret and Communication Cost) Under threshold \u03b2, with high probability the communication cost of TRUTH-FEDBAN satisfies CT = O(Nd2) \u00b7 P = O(N2d3 log T ), where P = O(Nd log T ) is the total number of communication rounds, under the communication thresh-\nold Dc = TN2d log T \u2212 \u221a\nT 2 N2dR log T log \u03b2 (1\u2212e\u22121) in Algorithm 6, where R = \u2308 d log(1 + T\u03bbd ) \u2309 .\nFurthermore, by setting \u03b2(1\u2212e \u22121) \u2265 e\u2212 1N , the cumulative regret is RT = O ( d \u221a T log T ) ."
        },
        {
            "heading": "5 EXPERIMENTS",
            "text": "To validate our solution, we create a simulated federated bandit learning environment with context feature dimension d = 5 and N = 25 clients sequentially interacting with the environment for a fixed time horizon T . Due to space limit, more implementation details can be found in Appendix G. The results, averaged over 5 runs, are presented alongside the standard deviation."
        },
        {
            "heading": "5.1 COMPARISON BETWEEN DIFFERENT TRUTHFUL INCENTIVE MECHANISMS",
            "text": "We compare TRUTH-FEDBAN with a vanilla greedy algorithm (Algorithm 3). Despite Algorithm 3 also induces a monotone mechanism (and thus truthful), it does not admit any constant-factor approximation guarantee, hence is less theoretically exciting compared to TRUTH-FEDBAN. A comprehensive analysis regrading this baseline method can be found in Appendix B. As reported in Figure 1(a) and Figure 1(b), TRUTH-FEDBAN achieved competitive sub-linear regret and communication cost compared to DisLinUCB (Wang et al., 2020), with lower incentive and social costs compared to the baseline greedy method, validating our theoretical analysis."
        },
        {
            "heading": "5.2 IMPACT ON MISREPORTING",
            "text": "Micro-level Study. In this experiment, we study how misreporting affects an individual, in terms of the client\u2019s regret, incentive and utility. To do so, we randomly designate a client to keep misreporting throughout the entire time horizon while keeping the others being truthful, and compare the corresponding outcome for this client. We take truth-report as the benchmark and plot the individual\u2019s total regret, incentive, and utility on the same chart using the normalized score (the respective value divided by that under truth-report), along with the actual value on top of each bar. As presented in Figure 1(c) and Figure 1(d), both TRUTH-FEDBAN and the greedy method demonstrate the ability to prevent client from benefiting via misreporting. It is important that the incentive payment (i.e., critical value) for the client is subject to the incentive mechanism and independent of its claimed cost. Therefore, though under-reporting may encourage the client to be selected by the incentive mechanism, its net utility essentially becomes negative. Meanwhile, despite over-reporting cost only undertakes the risk of being ruled out and losing incentives, it is surprising that this behav-\nior leads to a slightly higher utility under the vanilla greedy incentive mechanism. We attribute this to the reduced participation cost incurred by the client \u2014 the less it participates, the less it suffers.\nMacro-level Study. As presented in Figure 2, we also empirically investigate how different levels of misreporting across the set of clients affect the entire federated learning system. Specifically, we vary the number of misreporting clients from 0% to 100% to investigate the impact on overall system performance, including regret, communication cost, incentive cost, and social cost. Generally, as guaranteed by our communication protocol, the overall regret under different degrees of misreporting remains virtually identical to the situation when no client misreports. Meanwhile, the communication cost tends to increase when clients under report and decrease when they over report. This aligns with our algorithm\u2019s design, which selects clients based on their value-to-cost ratio (Line 3 in Algorithm 2). For example, when a client under reports, its ratio increases, which increases its chance to be selected in communication, hence leading to an increased communication cost.\nAn interesting finding that might seem contradictory to our discovery in the previous micro-level study is the overall impact of over reporting on incentive costs, which implies that the more clients over report, the higher the incentives they will receive. But our finding in the micro-level study suggests that over reporting brings no benefit to the client\u2019s individual utility under TRUTH-FEDBAN. We note that the observation in our macro-level study is due to collusion among clients \u2014 once a sufficient group of clients colludes, the server has to increase the critical value or even pay infinity. This actually rationalizes individual client\u2019s commitment to be truthful, as they are unaware of others clients\u2019 decision on truthfulness. Meanwhile, this finding reveals the vulnerability of the incentivized truthful communication to collusion, leaving an interesting avenue for future work to explore. On the other hand, it can be observed that both overreporting and underreporting hurt the social cost until the misreporting ratio reaches approximately 50%. This is interesting from the perspective of societal divisions \u2014 when the society is equally divided into two parts, the social cost is at its largest. And as division decreases, the cost becomes lower. For example, when the misreporting ratio reaches 100%, meaning that everyone in the system is misreporting, the social cost resets the scenario where no one misreports, marking the establishment of a new stability in the system."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "In this work, we introduce the first truthful incentivized communication protocol TRUTH-FEDBAN for federated bandit learning, where a set of strategic and individual rational clients are incentivized to truthfully report their cost to participate distributed learning. Our key contribution is to design a monotone client selection rule and its corresponding critical value based payment scheme. We establish the theoretical foundations for incentivized truthful communication, under which not only the social cost but also the regret and communication cost obtain their near-optimal performance. Numerical simulations verify our theoretical results, especially the truthfulness guarantee, i.e., individual clients\u2019 utility can only be maximized when reporting their true cost.\nOur work opens a broad new direction for future exploration. First of all, our truthful incentivized communication protocol is not only limited to federated bandit learning, but can be applied to general distributed learning environments where self-interested clients need to be incentivized for collaborative learning. Second, our truthful guarantee is proved for every round of communication, but it is unclear whether a client can do long-term planning to game the system. For example, keep over reporting until it becomes monopoly, ultimately leading to an infinite incentive for its participation. Last but not least, although we no longer assume clients are truthful, we still assume they are not malicious, i.e., they only want to maximize their own utility. In practice, it is necessary to investigate the problem under an adversarial context, e.g., malicious clients intentionally misreport their costs to hurt other clients\u2019 utilities or system\u2019s learning outcome."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "We thank the anonymous reviewers for their insightful and constructive comments. This project is partially supported by NSF Award IIS-2213700 and IIS-2128019. Haifeng Xu is supported by an NSF Award CCF-2303372, an Army Research Office Award W911NF-23-1-0030, an Office of Naval Research Award N00014-23-1-2802, and AI2050 program at Schmidt Sciences (Grant G-2466104)."
        },
        {
            "heading": "A PROOF OF MONOTONICITY (PROPOSITION 5)",
            "text": "Our proof of monotonicity relies on the submodularity property and the following lemma. Note that our proof holds true for any time step t, and thus the subscript t is omitted below to keep our notations simple.\nDefinition 11 (Submodularity) A set function g : 2S \u2192 R is submodular, if for every A \u2286 B \u2286 S and i \u2208 S \\B it holds that\ng(A \u222a {i})\u2212 g(A) \u2265 g(B \u222a {i})\u2212 g(B)\nLemma 12 Increasing the input budget of Algorithm 2 always leads to a no worse output. Formally, denote the output of Algorithm 2 as Sb and Sb\u2032 under different input budgets b and b\u2032. For any budget pair b\u2032 > b, we must have either Sb\u2032 = Sb or g(Sb\u2032) > g(Sb).\nProof of Lemma 12. Considering two input budget b and b\u2032 and the corresponding outputs Sb and Sb\u2032 of Algorithm 2. In the following, we show that g(Sb\u2032) \u2265 g(Sb) if b\u2032 > b. Without loss of generality, we denote Sb = {j1, j2, \u00b7 \u00b7 \u00b7 , jn} \u2208 2S\u0303 and Sb\u2032 = {k1, k2, \u00b7 \u00b7 \u00b7 , km} \u2208 2S\u0303 as the corresponding output, where S\u0303 = {1, 2, \u00b7 \u00b7 \u00b7 , N}, 1 \u2264 n \u2264 N , 1 \u2264 m \u2264 N . Under different budget, the selected client in each round can vary due to the changed constraint in Line 3 of Algorithm 2. For example, under budget b, a client with the largest ratio may not be selected because including it would cause the total cost to exceed b. In contrast, under budget b\u2032, it can be selected due to the increased budget. Consequently, this can create different output sequences Sb and Sb\u2032 .\nLet \u03c4 be the first time when the two sequences diverge, i.e, ji = ki,\u22001 \u2264 i < \u03c4 , and j\u03c4 \u0338= k\u03c4 . If such a \u03c4 does not exist, the two sequences are precisely the same and we will have Sb\u2032 = Sb. In the remainder of this proof, we assume \u03c4 exists and show that g(Sb\u2032) > g(Sb) consequently. Let S\u03c4b and S\u03c4b\u2032 be the set that contains the first \u03c4 elements in Sb and Sb\u2032 , so we have S \u03c4\u22121 b = S \u03c4\u22121 b\u2032 . According\nto the greedy strategy (Line 3 of Algorithm 2), it is clear that D\u0302k\u03c4 > \u2211n\ni=\u03c4 D\u0302ji , meaning that the cost of client k\u03c4 is even higher than the total costs of clients in Sb \\S\u03c4\u22121b , which is the reason that k\u03c4 appears in the output Sb\u2032 under a larger budget b\u2032 but is not (thus is skipped) in the output Sb under b. Moreover, this also implies that client k\u03c4 has a larger value-to-cost ratio than that of any client in Sb \\ S\u03c4\u22121b at the \u03c4 -th round, formally\ng(S\u03c4\u22121b\u2032 \u222a {k\u03c4})\u2212 g(S \u03c4\u22121 b\u2032 )\nD\u0302k\u03c4 \u2265\ng(S\u03c4\u22121b \u222a {ji})\u2212 g(S \u03c4\u22121 b )\nD\u0302ji ,\u2200i \u2208 [\u03c4, n] (8)\nFor clarity, we denote the value of client k\u03c4 as v(k\u03c4 |S\u03c4\u22121b\u2032 ) = g(S \u03c4\u22121 b\u2032 \u222a {k\u03c4})\u2212 g(S \u03c4\u22121 b\u2032 ), quantifying how much client k\u03c4 can improve the objective function g with respect to the set S\u03c4\u22121b\u2032 . Then we have\nn\u2211 i=\u03c4 v(ji|S\u03c4\u22121b ) D\u0302ji \u00b7 D\u0302ji \u2264 v(k\u03c4 |S\u03c4\u22121b\u2032 ) D\u0302k\u03c4 n\u2211 i=\u03c4 \u00b7D\u0302ji < v(k\u03c4 |S\u03c4\u22121b\u2032 ) D\u0302k\u03c4 \u00b7 D\u0302k\u03c4 = v(k\u03c4 |S\u03c4\u22121b\u2032 )\nwhere the first inequality follows from Eq. (8), and the second one holds true because D\u0302k\u03c4 >\u2211n i=\u03c4 D\u0302ji . Therefore, we can derive that\nv(k\u03c4 |S\u03c4\u22121b\u2032 ) > n\u2211\ni=\u03c4\nv(ji|S\u03c4\u22121b ) (9)\nNow we are ready to compare the objective value of Sb and Sb\u2032 , and show that g(Sb\u2032) > g(Sb). By simple decomposition, we can rewrite g(Sb) as follows\ng(Sb) = g({j1, j2, \u00b7 \u00b7 \u00b7 , jn}) = g(\u2205) + [g({j1})\u2212 g(\u2205)] + [g({j1, j2})\u2212 g(j1)] + \u00b7 \u00b7 \u00b7+ [g(Sb)\u2212 g(Sb \\ {jn})] = g(\u2205) + v(j1|S0b ) + v(j2|S1b ) + \u00b7 \u00b7 \u00b7+ v(jn|Sn\u22121b )\n= g(\u2205) + \u03c4\u2211\ni=1\nv(ji|Si\u22121b ) + n\u2211\np=\u03c4\nv(jp|Sp\u22121b )\nLikewise, we have\ng(Sb\u2032) = g(\u2205) + \u03c4\u2211\ni=1\nv(ki|Si\u22121b\u2032 ) + n\u2211\np=\u03c4\nv(kp|Sp\u22121b\u2032 )\nRecall that ji = ki,\u2200i < \u03c4 , and thus we have v(ji|Si\u22121b ) = v(ki|S i\u22121 b\u2032 ),\u2200i < \u03c4 . Therefore,\ng(Sb\u2032)\u2212 g(Sb) = n\u2211\ni=\u03c4\nv(ki|Si\u22121b\u2032 )\u2212 n\u2211\ni=\u03c4\nv(ji|Si\u22121b )\n= v(k\u03c4 |S\u03c4\u22121b\u2032 ) + n\u2211\ni=\u03c4+1\nV (ki|Si\u22121b\u2032 )\u2212 n\u2211\ni=\u03c4\nv(ji|Si\u22121b )\n> n\u2211 i=\u03c4 v(ji|S\u03c4\u22121b )\u2212 n\u2211 i=\u03c4 v(ji|Si\u22121b ) + n\u2211 i=\u03c4+1 v(ki|Si\u22121b\u2032 )\n> n\u2211 i=\u03c4 v(ji|S\u03c4\u22121b )\u2212 v(ji|S i\u22121 b )\n> 0\nwhere the first inequality directly follows Eq. (9), and the last step utilizes the submodularity property (see Definition 11) of the submodular function g, i.e., v(ji|S\u03c4\u22121b ) > v(ji|S i\u22121 b ),\u2200i > \u03c4 . This concludes the proof.\nNow we are ready to prove the monotonicity of Algorithm 1 by contradiction.\nProof of Proposition 5. An algorithm is monotone if a client \u03b1 remains selected by the algorithm whenever its reported cost satisfies D\u0302\u2032\u03b1 < D\u0302\u03b1, provided it gets selected when reporting D\u0302\u03b1. Let S = {i1, i2, \u00b7 \u00b7 \u00b7 , in} and b be the resulting participant set and budget determined by Algorithm 1 when client \u03b1 reports D\u0302\u03b1. Without loss of generality, we set \u03b1 = ik, where 1 \u2264 k \u2264 n, and denote Sk = {i1, i2, \u00b7 \u00b7 \u00b7 , ik} as the set of clients selected before \u03b1. According to the greedy selection strategy in Algorithm 2, we have\ng(Sk\u22121 \u222a {\u03b1})\u2212 g(Sk\u22121) D\u0302\u03b1 > g(Sk\u22121 \u222a {i})\u2212 g(Sk\u22121) D\u0302i ,\u2200i \u2208 S\u0303 \\ Sk : D\u0302i + \u2211 j\u2208Sk\u22121 D\u0302j \u2264 b (10)\nDenote S\u2032 and b\u2032 as the resulting participant set and budget determined by Algorithm 1 when client \u03b1 reports D\u0302\u2032\u03b1 < D\u0302\u03b1. Since decreasing client \u03b1\u2019s claimed cost will increase the ratio in the lefthand side of Eq. (10), it will remain selected (no later than the k-th round) when b\u2032 \u2264 b, otherwise the terminating participant set Sb\u2032 is not sufficient. The algorithm only deviates from this when the following condition is true:\ng(Sk\u22121 \u222a {\u03b1})\u2212 g(Sk\u22121) D\u0302\u2032\u03b1 < g(Sk\u22121 \u222a {i})\u2212 g(Sk\u22121) D\u0302i ,\u2203i \u2208 S\u0303 \\ Sk : D\u0302i + \u2211 j\u2208Sk\u22121 D\u0302j \u2264 b\u2032\nAccording to Eq. (10), this is only possible when b\u2032 > b because the increased budget allows additional candidate clients with both larger value and cost, potentially surpassing the largest affordable ratio under b. However, it contradicts the fact that any feasible terminating budget must be at most b \u2014 as Lemma 12 guarantees that a larger budget input to Algorithm 2 must always result in either exactly the same set or a different set with strictly higher objective value. Meanwhile, the terminating condition (Line 3 of Algorithm 1) ensures that the entire search process will promptly terminate once it finds the minimum budget that satisfies the constraint. Therefore, given budget b already satisfies the constraint, it is impossible for the algorithm to terminate with a solution that has a higher budget than b, which finishes the proof."
        },
        {
            "heading": "B GREEDY INCENTIVE SEARCH",
            "text": "In contrast to Algorithm 1, one straightforward alternative is to adopt the vanilla greedy method to solve the problem in Eq. (3), as presented in Algorithm 3. The idea is to iteratively rank all nonselected clients according to their individual value-to-cost ratio and choose the one with the largest ratio (Line 3-4), until the resulting participant set satisfies the constraint (Line 2).\nAlgorithm 3 Vanilla Greedy Incentive Search\n1: St \u2190 \u2205, S\u0303 = {1, 2, \u00b7 \u00b7 \u00b7 , N} 2: while gt(St) < log \u03b2 do 3: i\u2190 argmaxj\u2208S\u0303\\St gt(St\u222a{j})\u2212g(St) D\u0302j,t 4: St \u2190 St \u222a {i} 5: return S.\nIt is not difficult to verify this straightforward greedy algorithm is also monotonic, as decreasing a client\u2019s claimed cost essentially encourages its selection, thus making it a truthful mechanism. One notable difference between this greedy incentive search algorithm and our truthful incentive search (Algorithm 1) is that it does not compromise for the constraint. As a result, as pointed out by previous studies (Wolsey, 1982), this greedy algorithm does not admit any constant-factor approximation guarantee (i.e., it becomes problem instance specific), as shown in Lemma 13.\nLemma 13 (Theorem 2 of Wolsey (1982)) Under parameter \u03b2 and clients\u2019 reported participation cost D\u0302t = {D\u03021,t, \u00b7 \u00b7 \u00b7 , D\u0302N,t}, Algorithm 3 is guaranteed to obtain a participant set St such that\u2211\ni\u2208S D\u0302i,t \u2264 (1 + lnmin{\u03bb1, \u03bb2, \u03bb3}) \u2211 i\u2208S\u22c6t D\u0302i,t and gt(St) \u2265 log \u03b2\nin which \u03bb1 = max i,k { gt({i})\u2212gt(\u2205) gt(Skt \u222a{i})\u2212gt(Skt ) | gt(Skt \u222a {i}) \u2212 gt(Skt ) > 0} where the denominator\nis the smallest non-zero marginal gain from adding any element i \u2208 S\u0303 to the intermediate set Skt , i.e., the set contains the first k elements of the output set St, and the numerator is the largest singleton value of g; \u03bb2 = \u03c31\u03c3K where K is the total number of iterations in the greedy search and\n\u03c3k = max i\ngt(S k t \u222a{i})\u2212gt(S k t )\nD\u0302i,t ; \u03bb3 = g(S\u0303)\u2212g(\u2205) g(S\u0303)\u2212g(SK\u22121t ) .\nAlternatively, we can reformulate Algorithm 3 into an equivalent counterpart (Algorithm 4) that provides a bi-criteria approximation guarantee similar to Algorithm 1. Note that these two variants essentially lead to the same outcome when parameterized with \u03b21 = \u03b2(1\u2212e\n\u22121) and \u03b22 = \u03b2, where \u03b21 and \u03b22 are the specified hyper-parameters in Algorithm 3 and Algorithm 4, respectively.\nAlgorithm 4 Greedy Incentive Search (V2)\nRequire: \u03b2, S\u0303 = {1, 2, . . . , N} 1: B \u2190 ORDEREDBUDGET(S\u0303) 2: St \u2190 \u2205, b\u2190 0, k \u2190 0 3: while gt(St) < (1\u2212 e\u22121) log \u03b2 do 4: b\u2190 b+B[k] 5: S \u2190 GREEDY(S\u0303, b) 6: k \u2190 k + 1 7: return St\nAlgorithm 5 ORDEREDBUDGET\nRequire: S\u0303 = {1, 2, \u00b7 \u00b7 \u00b7 , N} 1: St \u2190 \u2205, B \u2190 \u2205 2: while S\u0303 \\ St \u0338= \u2205 do 3: u\u2190 argmaxj\u2208S\u0303\\St gt(St\u222a{j})\u2212gt(St) D\u0302j,t\n4: St \u2190 St \u222a {u} 5: B \u2190 B \u222a {D\u0302u,t} 6: return B\nLemma 14 Under parameter \u03b2 and clients\u2019 reported participation cost D\u0302t = {D\u03021,t, \u00b7 \u00b7 \u00b7 , D\u0302N,t}, Algorithm 4 provides a bi-criteria approximation such that\u2211\ni\u2208St D\u0302i,t \u2264 max D\u0302t + \u2211 i\u2208S\u22c6t D\u0302i,t and gt(St) \u2265 (1\u2212 e\u22121) log \u03b2\nwhere St is the output of Algorithm 1, and S\u22c6t is the ground-truth optimizer of problem defined in Eq. (1).\nProof of Lemma 14. The proof of this lemma largely repeats that of Lemma 9, with a minor difference in Eq. (7) (i.e., b = (1 + \u03f5)b\u2032 vs., b = b\u2032 + B[k]). Unlike Algorithm 1 slightly increasing the\nbudget by a constant factor (1+ \u03f5), Algorithm 4 increases the budget in a pre-ordered way based on the result of Algorithm 5. Similar to Eq. (7), the subscript t is omitted, and we have\u2211\ni\u2208Sb D\u0302i \u2264 b = b\u2032 +B[k] \u2264 max D\u0302 + \u2211 i\u2208S\u22c6 D\u0302i (11)\nAdditionally, it is not difficult to see gt(St) \u2265 (1\u2212 e\u22121) log \u03b2 since this is the terminating condition of Algorithm 4. Combining both completes the proof."
        },
        {
            "heading": "C TECHNICAL LEMMAS",
            "text": "Lemma 15 (Lemma 10 of Abbasi-Yadkori et al. (2011)) Suppose x1,x2, \u00b7 \u00b7 \u00b7 ,xt \u2208 Rd and for any 1 \u2264 s \u2264 t, \u2225xs\u22252 \u2264 L. Let V t = \u03bbI + \u2211t s=1 xsx \u22a4 s for some \u03bb > 0. Then,\ndet(V t) \u2264 (\u03bb+ tL2/d)d.\nLemma 16 (Lemma 11 of Abbasi-Yadkori et al. (2011)) Let {Xt}\u221et=1 be a sequence in Rd, V is a d\u00d7 d positive definite matrix and define Vt = V + \u2211t s=1 XsX \u22a4 s . Then we have that\nlog\n( det (Vn)\ndet(V )\n) \u2264 n\u2211 t=1 \u2225Xt\u22252V \u22121t\u22121 .\nFurther, if \u2225Xt\u22252 \u2264 L for all t, then n\u2211 t=1 min { 1, \u2225Xt\u22252V \u22121t\u22121 } \u2264 2 (log det (Vn)\u2212 log detV ) \u2264 2 ( d log (( trace(V ) + nL2 ) /d ) \u2212 log detV ) ."
        },
        {
            "heading": "D PROOF OF LEMMA 7",
            "text": "Our proof utilizes the following matrix determinant lemma (Harville, 2008).\nLemma 17 (Matrix Determinant Lemma) Let A \u2208 Rn\u00d7n be an invertible n-by-n matrix, and B,C \u2208 Rn\u00d7m are n-by-m matrices, we have that\ndet(A+BC\u22a4) = det(A) det(Im + C \u22a4A\u22121B)\nProof of Lemma 7. It is known that the infinite critical value is unavoidable for a monopoly client under the truthful mechanism design. To eliminate this issue, we first analyze the root cause of the existence of a monopoly client. Denote V\u0303t as the covariance matrix constructed by all sufficient statistics available in the system at time step t, and \u2206Vi,t = X\u22a4n Xn, Xn \u2208 R\u2206t\u00d7d. Specifically, client i is a monopoly, i.e., being essential to satisfy the constraint in Eq. (3) at time step t, such that having all the other N \u2212 1 clients\u2019 data still cannot satisfy the constraint. According to Lemma 17, plugging in A = V\u0303t \u2212\u2206Vi,t and B = C = X\u22a4n , we have\ndet(V\u0303t \u2212\u2206Vi,t) det(V\u0303t) = 1 det(I\u2206t +Xn(V\u0303t \u2212\u2206Vi,t)\u22121X\u22a4n )\nwhere \u2206Vi,t = X\u22a4n Xn, Xn \u2208 R\u2206t\u00d7d, \u2206t represents the number of new data points in \u2206Vi,t. Next, we show that there exists a lower bound of the ratio above, such that as long as we set the hyperparameter \u03b2 less than the lower bound, it is guaranteed that no client can be essential. Moreover, for a positive definite matrix A \u2208 Rd\u00d7d, we have A\u22121 \u227c I\u03bbmin(A) where \u03bbmin(A) denotes the minimum eigenvalue of A. Plugging in A = V\u0303t \u2212 \u2206Vi,t, we have (V\u0303t \u2212 \u2206Vi,t)\u22121 \u227c I\u03bbmin(V\u0303t\u2212\u2206Vi,t) \u227c I \u03bb ,\nwhere \u03bb > 0 is the regularization parameter defined in Eq. (12). It follows that\n1 det(I\u2206t +Xn(V\u0303t \u2212\u2206Vi,t)\u22121X\u22a4n ) \u2265 1 det(I\u2206t + 1 \u03bbXnX \u22a4 n )\n= 1\ndet(Id + 1 \u03bbX \u22a4 n Xn)\n= \u03bbd\ndet(\u03bbId +\u2206Vi,t)\n\u2265 \u03bb d\ndet(Vi,t + \u03bbId)\n\u2265 \u03bb d\n(\u03bb+ tL2/d)d = (1 + tL2/\u03bbd)\u2212d\nwhere the second step holds by elementary algebra, the third step utilizes the fact that Vi,t \u227d \u2206Vi,t, and the last step follows from Lemma 15. Therefore, as long as we set \u03b2 \u2264 (1 + tL2/\u03bbd)\u2212d, it is guaranteed that no client will be essential at time step t. This finishes the proof."
        },
        {
            "heading": "E COMMUNICATION COST AND REGRET ANALYSIS",
            "text": "As TRUTH-FEDBAN directly inherits from the basic protocol proposed in (Wei et al., 2023) with a truthful incentive mechanism, most part of the proof for communication cost and regret analysis (Theorem 4) in their paper extends to our problem setting. Therefore, with slight modifications, we can achieve the same sub-linear guarantee.\nIn essence, the only difference in terms of establishing the theoretical bounds for regret and communication cost between our method and (Wei et al., 2023) lies in the relaxation of the constraint in Eq. (3), which deviated from the original constraint in Eq. (1) by a constant-factor gap of (1\u2212e\u22121). Moreover, as we reformulate the determinant ratio constraint (i.e., det(Vg,t(St))\ndet(Vg,t(S\u0303)) \u2265 \u03b2) into a log de-\nterminant ratio constraint (i.e., log det(Vg,t(St)) det(Vg,t(S\u0303)) \u2265 (1 \u2212 e\u22121) log \u03b2), the notion of \u03b2 in our work is slightly different from that in their work. Specifically, denote the hyper-parameter in their method as \u03b2, then any \u03b2 used in their theoretical results can be replaced by our notation of \u03b2 via the transformation \u03b2 = \u03b21\u2212e \u22121 .\nIn the following, we present the corresponding theoretical results of our proposed TRUTH-FEDBAN and refer the readers to the proof details in Theorem 4 of (Wei et al., 2023).\nLemma 18 (Communication Frequency Bound) By setting the communication threshold Dc = T N2d log T \u2212(1\u2212e \u22121) \u221a T 2\nN2dR log T log \u03b2, the total number of communication rounds is upper bounded by\nP = O(Nd log T ) where R = \u2308 d log(1 + T\u03bbd ) \u2309 = O(d log T ).\nCommunication Cost: In each communication round, all clients first upload O(d2) scalars to the server and then download O(d2) scalars. According to Lemma 18, the total communication cost is CT = P \u00b7O(Nd2) = O(N2d3 log T ).\nLemma 19 (Instantaneous Regret Bound) Given parameter \u03b2, with probability 1\u2212 \u03b4, the instantaneous pseudo-regret rt = \u27e8\u03b8\u22c6,x\u22c6 \u2212 xt\u27e9 in j-th communication round is bounded by\nrt = O\n(\u221a d log T\n\u03b4\n) \u00b7 \u2225xt\u2225V\u0303 \u22121t\u22121 \u00b7 \u221a 1 \u03b2(1\u2212e\u22121) \u00b7 det(Vg,tj )\ndet(Vg,tj\u22121)\nProof of Theorem 10. We followed the notion of good epoch and bad epoch defined in (Wang et al., 2020). Combining with Lemma 16, we can bound the accumulative regret in the good epochs as,\nREGgood = O\n( d\u221a \u03b21\u2212e\u22121 \u00b7 \u221a T \u00b7 \u221a log T \u03b4 \u00b7 logT ) .\nFurthermore, we can show that the regret across all bad epochs satisfies,\nREGbad = O\n( Nd1.5 \u221a Dc \u00b7 log T\n\u03b4 log T\n) .\nUsing the communication threshold Dc = TN2d log T \u2212 (1 \u2212 e \u22121) \u221a\nT 2\nN2dR log T log \u03b2 specified in Lemma 18, we have\nRT = REGgood +REGbad\n= O ( d\u221a\n\u03b21\u2212e\u22121\n\u221a T log T ) +O ( Nd1.5 log1.5 T \u00b7 \u221a T\nN2d log T +\nT\nNd log T log\n1\n\u03b21\u2212e\u22121\n)\nHenceforth, by setting \u03b21\u2212e \u22121 > e\u2212 1 N , we can show that TN2d log T > T Nd log T log 1 \u03b21\u2212e\u22121 , and therefore\nRT = O\n( d\u221a\n\u03b21\u2212e\u22121\n\u221a T log T ) +O ( d \u221a T log T ) = O ( d \u221a T log T ) This concludes the proof."
        },
        {
            "heading": "F GENERAL FRAMEWORK FOR INCENTIVIZED FEDERATED BANDITS",
            "text": "Algorithm 6 Incentivized Communication for Federated Linear Bandits\nRequire: Dc \u2265 0, D\u0302t = {D\u03021,t, \u00b7 \u00b7 \u00b7 , D\u0302N,t}, \u03c3, \u03bb > 0, \u03b4 \u2208 (0, 1) 1: Initialize: [Server] Vg,0 = 0d\u00d7d \u2208 Rd\u00d7d, bg,0 = 0d \u2208 Rd 2: \u2206V\u2212j,0 = 0d\u00d7d,\u2206b\u2212j,0 = 0d, \u2200j \u2208 [N ] 3: [All clients] Vi,0 = 0d\u00d7d, bi,0 = 0d, \u2206Vi,0 = 0d\u00d7d, \u2206bi,0 = 0d, \u2206ti,0 = 0,\u2200i \u2208 [N ] 4: for t = 1, 2, . . . , T do 5: [Client it] Observe arm set At 6: [Client it] Select arm xt \u2208 At by Eq. (12) and observe reward yt 7: [Client it] Update: Vit,t += xtx\u22a4t , bit,t += xtyt 8: \u2206Vit,t += xtx \u22a4 t , \u2206bit,t += xtyt, \u2206tit,t += 1\n9: if \u2206tit,t log det(Vit,t+\u03bbI)\ndet(Vit,t\u2212\u2206Vit,t+\u03bbI) > Dc then\n10: [All clients\u2192 Server] Upload \u2206Vi,t, and let S\u0303t = {1, 2, \u00b7 \u00b7 \u00b7 , N} 11: [Server] Select incentivized participants St =M(S\u0303t|D\u0302t) \u25b7 Incentive Mechanism 12: for i \u2208 St do 13: [Participant i\u2192 Server] Upload \u2206bi,t 14: [Server] Update: Vg,t += \u2206Vi,t, bg,t += \u2206bi,t 15: \u2206V\u2212j,t += \u2206Vi,t, \u2206b\u2212j,t += \u2206bi,t,\u2200j \u0338= i 16: [Participant i] Update: \u2206Vi,t = 0, \u2206bi,t = 0, \u2206ti,t = 0 17: for \u2200i \u2208 [N ] do 18: [Server\u2192 All Clients] Download \u2206V\u2212i,t, \u2206b\u2212i,t 19: [Client i] Update: Vi,t += \u2206V\u2212i,t, bi,t += \u2206b\u2212i,t 20: [Server] Update: \u2206V\u2212i,t = 0, \u2206b\u2212i,t = 0\nAlgorihtm 6 shows the incentivized communication protocol proposed by Wei et al. (2023). The arm selection strategy for client it as time step t is based on the upper confidence bound method:\nxt = argmax x\u2208At x\u22a4\u03b8\u0302it,t\u22121(\u03bb) + \u03b1it,t\u22121||x||V \u22121it,t\u22121(\u03bb) (12)\nwhere \u03b8\u0302it,t\u22121(\u03bb) = V \u22121 it,t\u22121(\u03bb)bit,t\u22121 is the ridge regression estimator of \u03b8\u22c6 with regularization parameter \u03bb > 0, Vit,t\u22121(\u03bb) = Vit,t\u22121+\u03bbI , and \u03b1it,t\u22121 = \u03c3 \u221a log det(Vit,t\u22121(\u03bb)) det (\u03bbI) + 2 log 1/\u03b4+ \u221a \u03bb. Vit,t(\u03bb) denotes the covariance matrix constructed using the data available to client it up to time t.\nG IMPLEMENTATION DETAILS\nG.1 HYPER-PARAMETER SETTINGS\nAs introduced in Section 3, the proposed TRUTH-FEDBAN works with any realization of the valuation function. For demonstration purpose, we instantiate it as a combination of client\u2019s weighted data collection cost plus its intrinsic preference cost, i.e., f(\u2206Vi,t) = w \u00b7 det(\u2206Vi,t) + Ci, where w = 10\u22124, and each client i\u2019s intrinsic preference cost Ci is uniformly sampled from U(0, 100). In the simulated environment (Section 5), the time horizon is T = 6250, total number of clients N = 25, context dimension d = 5. We set the hyper-parameter \u03f5 = 1.0, \u03b2 = 0.5 in Algorithm 1 and Algorithm 3. The tolerance factor in Algorithm 7 is \u03b3 = 1.0.\nAs stated in Section 4.2, we do not assume a monopoly-free environment and thus any truthful incentive mechanism has to pay essential clients infinite incentives to guarantee their participation when necessary. Nonetheless, to visualize the impact of infinite payment, we simplify it as a constant value of 104 that is orders of magnitude greater than the average participation cost. and the infinite critical value is simplified.\nG.2 CRITICAL VALUE CALCULATION FOR ALGORIHTM 3\nIt is not difficult to show that Algorithm 3 is also monotone and thus inherently associated with a critical payment scheme to make the resulting mechanism truthful. We now elaborate on the critical value calculation method for it. And the critical value based payment scheme for Algorithm 1 can be derived in a similar spirit.\nFor each client \u03b1 \u2208 S in the participant set S (subscript t is omitted for simplicity), the critical value c\u03b1 is determined as follows. First, rerun Algorithm 3 without client \u03b1, i.e., setting S\u0303\u2032 = S\u0303 \\ {\u03b1}; if the process fails to terminate with a feasible set S\u2032, it suggests that client \u03b1 is essential to satisfy the constraint, then its critical value is c\u03b1 = \u221e. Otherwise, the process can terminate and return a feasible set, denoted as S\u2032 = {i1, i2, \u00b7 \u00b7 \u00b7 , iK}, then the critical value c\u03b1 is calculated by\nc\u03b1 = max k\u2208[K] D\u0302ik \u00b7 g(S\u2032k\u22121 \u222a {\u03b1})\u2212 g(S\u2032k\u22121) g(S\u2032k\u22121 \u222a {ik})\u2212 g(S\u2032k\u22121)\n(13)\nwhere ik and S\u2032k represent the selected client and intermediate set of S \u2032 at k-th round. Denote v(\u03b1|S\u2032k\u22121) = g(S\u2032k\u22121 \u222a {\u03b1}) \u2212 g(S\u2032k\u22121), now suppose we are placing client \u03b1 at the k-th position of S\u2032. To do so, the maximal participation cost that client \u03b1 can claim should satisfy that the corresponding value-to-cost ratio is higher than that of client ik, i.e., v(\u03b1|S\u2032k\u22121)/D\u0302\u03b1 \u2265 v(ik|S\u2032k\u22121)/D\u0302ik . In other words, the maximal cost client \u03b1 can claim to replace ik is D\u0302\u03b1 = D\u0302ik \u00b7 v(\u03b1|S\u2032k\u22121)/v(ik|S\u2032k\u22121). Therefore, the critical value c\u03b1 calculated in Eq. (13) ensures that as long as the client \u03b1 claims slightly less than c\u03b1, it can replace at least one client in the K rounds, thus becomes selected by the server. On the contrary, if D\u0302i is higher than c\u03b1, we can show that it will by no means get selected by the server. Specifically, the condition D\u0302\u03b1 > c\u03b1 guarantees g(S\u2032k\u22121\u222a{\u03b1})\u2212g(S \u2032 k\u22121)\nD\u0302\u03b1 <\ng(S\u2032k\u22121\u222a{ik})\u2212g(S \u2032 k\u22121)\nD\u0302ik ,\u2200k \u2208 [K]. We can start from the selection of the\nfirst client k = 1, and we want to guarantee client \u03b1 will not be selected. The condition tells us g(\u03b1)\nD\u0302\u03b1 < g(i1) D\u0302i1 , where i1 denotes the client that was selected in the first place when we exclude \u03b1.\nWe know g(i1) D\u0302i1 is also higher than all the other clients, so algorithm will still select client i1, i.e., S1 = {i1} = S\u20321. Then for k = 2, the condition suggests g(S1\u222a{\u03b1})\u2212g(S1)\nD\u0302\u03b1 =\ng(S\u20321\u222a{\u03b1})\u2212g(S \u2032 1)\nD\u0302\u03b1 <\ng(S\u20321\u222a{i2})\u2212g(S \u2032 1)\nD\u0302i2 = g(S1\u222a{i2})\u2212g(S1) D\u0302i2 . Therefore, \u03b1 will not be selected at k = 2 either, and\nS2 = S \u2032 2. We can show client \u03b1 will not be selected in S by induction.\nG.3 CRITICAL VALUE CALCULATION FOR ALGORIHTM 1\nIn contrast, there is no explicit formula to calculate the critical value in TRUTH-FEDBAN. Following Mu\u2019Alem & Nisan (2008), we calculate the critical value using bisection search as described in Algorithm 7.\nAlgorithm 7 Critical Value Calculation (Bisection Search)\nRequire: S\u0303 = {1, 2, \u00b7 \u00b7 \u00b7 , N}, D\u0302t = {D\u03021,t, D\u03022,t, \u00b7 \u00b7 \u00b7 , D\u0302N,t}, incentive mechanismM, concerned client i, budget b, tolerance \u03b3\n1: Initialization: L\u2190 0, H \u2190 b 2: while H\u2212L2 \u2265 \u03b3 do 3: Calculate critical value: ci \u2190 L+H2 4: Update D\u0302 : D\u0302i,t \u2190 ci,t 5: Run incentive mechanism: S =M(S\u0303; D\u0302) \u25b7 Algorithm 1 6: if i \u2208 S then 7: L\u2190 ci,t 8: else 9: H \u2190 ci,t\n10: Return client i\u2019s critical value ci,t\nThe idea remains the same as stated above, to calculate the critical value of a particular client, we first rerun Algorithm 1 without it in the candidate client set. If the client is essential, its critical value is ci,t = \u221e. Otherwise, we can calculate the critical value via Algorithm 7. Specifically, for any participant i in the set St found by Algorithm 1, it is clear that the bound of i\u2019s critical value is its claimed cost D\u0302i,t, otherwise it would not have been included in St. Denote b as the terminating budget determined by Algorithm 1 when client i is not considered, we can also have a upper bound for ci,t \u2264 b. With the lower and upper bound as input to Algorithm 7, it has been proven (Burden et al., 2015) that the number of iterations that Algorithm 7 needs to converge to a root to within a certain tolerance \u03b3 is bounded by \u2308log2( \u03b30 \u03b3 )\u2309, where \u03b30 = |b|."
        },
        {
            "heading": "H TIME COMPLEXITY ANALYSIS OF ALGORITHM 1",
            "text": "As the proposed Algorithm 1 includes a subroutine process of Algorithm 2, thus we start the time complexity analysis with Algorithm 2. Specifically, the worst-case time complexity of the while loop is O(N). The operation inside the while loop involves finding the maximum element in a set, which takes O(N) time. Therefore, the time complexity of Algorithm 2 is O(N2).\nLet M be the number of iterations of the while loop (Line 3) in Algorithm 1. Hence, the time complexity of Algorithm 1 is O(M \u00b7 N2). Specifically, the worst case is to consistently increase the budget b until it reaches \u2211N i=1 D\u0302i,t. Therefore, we can upper bound M by considering\nthe loop-breaking case: b0 \u00b7 (1 + \u03f5)M \u2265 \u2211N i=1 D\u0302i,t, i.e., M \u2264 \u2308 log1+\u03f5 (\u2211N i=1 D\u0302i,t b0 )\u2309 , where\nb0 = mini\u2208S\u0303 D\u0302i,t. As a result, Algorithm 1 yields the following polynomial time complexity of O( \u2308 log1+\u03f5 (\u2211N i=1 D\u0302i,t b0 )\u2309 \u00b7N2)."
        }
    ],
    "year": 2024
}