{
    "abstractText": "The capacity of a modern deep learning system to determine if a sample falls within its realm of knowledge is fundamental and important. In this paper, we offer insights and analyses of recent state-of-the-art out-of-distribution (OOD) detection methods extremely simple activation shaping (ASH). We demonstrate that activation pruning has a detrimental effect on OOD detection, while activation scaling enhances it. Moreover, we propose SCALE, a simple yet effective post-hoc network enhancement method for OOD detection, which attains state-of-the-art OOD detection performance without compromising in-distribution (ID) accuracy. By integrating scaling concepts into the training process to capture a sample\u2019s ID characteristics, we propose Intermediate Tensor SHaping (ISH), a lightweight method for training time OOD detection enhancement. We achieve AUROC scores of +1.85% for near-OOD and +0.74% for far-OOD datasets on the OpenOOD v1.5 ImageNet-1K benchmark.",
    "authors": [],
    "id": "SP:b65341fe50b647036451a2032a4a9847748f522d",
    "references": [
        {
            "authors": [
                "Julian Bitterwolf",
                "Maximilian M\u00fcller",
                "Matthias Hein"
            ],
            "title": "out? fixing imagenet out-ofdistribution detection evaluation",
            "venue": "International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Joya Chen",
                "Kai Xu",
                "Yuhui Wang",
                "Yifei Cheng",
                "Angela Yao"
            ],
            "title": "Dropit: Dropping intermediate tensors for memory-efficient DNN training",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Xuanyao Chen",
                "Zhijian Liu",
                "Haotian Tang",
                "Li Yi",
                "Hang Zhao",
                "Song Han"
            ],
            "title": "Sparsevit: Revisiting activation sparsity for efficient high-resolution vision transformer",
            "venue": "In IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2023
        },
        {
            "authors": [
                "Mircea Cimpoi",
                "Subhransu Maji",
                "Iasonas Kokkinos",
                "Sammy Mohamed",
                "Andrea Vedaldi"
            ],
            "title": "Describing textures in the wild",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2014
        },
        {
            "authors": [
                "Jia Deng",
                "Wei Dong",
                "Richard Socher",
                "Li-Jia Li",
                "Kai Li",
                "Li Fei-Fei"
            ],
            "title": "Imagenet: A large-scale hierarchical image database",
            "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
            "year": 2009
        },
        {
            "authors": [
                "Terrance DeVries",
                "Graham W. Taylor"
            ],
            "title": "Learning confidence for out-of-distribution detection in neural networks. CoRR, abs/1802.04865, 2018",
            "venue": "URL http://arxiv.org/abs/1802",
            "year": 2018
        },
        {
            "authors": [
                "Andrija Djurisic",
                "Nebojsa Bozanic",
                "Arjun Ashok",
                "Rosanne Liu"
            ],
            "title": "Extremely simple activation shaping for out-of-distribution detection",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "R. David Evans",
                "Tor M. Aamodt"
            ],
            "title": "AC-GC: lossy activation compression with guaranteed convergence",
            "venue": "Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems",
            "year": 2021
        },
        {
            "authors": [
                "Chuan Guo",
                "Geoff Pleiss",
                "Yu Sun",
                "Kilian Q. Weinberger"
            ],
            "title": "On calibration of modern neural networks",
            "venue": "Proceedings of the 34th International Conference on Machine Learning,",
            "year": 2017
        },
        {
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2016
        },
        {
            "authors": [
                "Dan Hendrycks",
                "Kevin Gimpel"
            ],
            "title": "A baseline for detecting misclassified and out-of-distribution examples in neural networks",
            "venue": "In 5th International Conference on Learning Representations,",
            "year": 2017
        },
        {
            "authors": [
                "Dan Hendrycks",
                "Norman Mu",
                "Ekin Dogus Cubuk",
                "Barret Zoph",
                "Justin Gilmer",
                "Balaji Lakshminarayanan"
            ],
            "title": "Augmix: A simple data processing method to improve robustness and uncertainty",
            "venue": "In 8th International Conference on Learning Representations,",
            "year": 2020
        },
        {
            "authors": [
                "Dan Hendrycks",
                "Steven Basart",
                "Mantas Mazeika",
                "Andy Zou",
                "Joseph Kwon",
                "Mohammadreza Mostajabi",
                "Jacob Steinhardt",
                "Dawn Song"
            ],
            "title": "Scaling out-of-distribution detection for real-world settings",
            "venue": "International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Grant Van Horn",
                "Oisin Mac Aodha",
                "Yang Song",
                "Yin Cui",
                "Chen Sun",
                "Alexander Shepard",
                "Hartwig Adam",
                "Pietro Perona",
                "Serge J. Belongie"
            ],
            "title": "The inaturalist species classification and detection dataset",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2018
        },
        {
            "authors": [
                "Gao Huang",
                "Zhuang Liu",
                "Laurens van der Maaten",
                "Kilian Q. Weinberger"
            ],
            "title": "Densely connected convolutional networks",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2017
        },
        {
            "authors": [
                "Alex Krizhevsky"
            ],
            "title": "Learning multiple layers of features from tiny images",
            "venue": "URL https: //api.semanticscholar.org/CorpusID:18268744",
            "year": 2009
        },
        {
            "authors": [
                "Mark Kurtz",
                "Justin Kopinsky",
                "Rati Gelashvili",
                "Alexander Matveev",
                "John Carr",
                "Michael Goin",
                "William M. Leiserson",
                "Sage Moore",
                "Nir Shavit",
                "Dan Alistarh"
            ],
            "title": "Inducing and exploiting activation sparsity for fast inference on deep neural networks",
            "venue": "In Proceedings of the 37th International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Kimin Lee",
                "Kibok Lee",
                "Honglak Lee",
                "Jinwoo Shin"
            ],
            "title": "A simple unified framework for detecting out-of-distribution samples and adversarial attacks",
            "venue": "Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems",
            "year": 2018
        },
        {
            "authors": [
                "Zonglin Li",
                "Chong You",
                "Srinadh Bhojanapalli",
                "Daliang Li",
                "Ankit Singh Rawat",
                "Sashank J. Reddi",
                "Ke Ye",
                "Felix Chern",
                "Felix X. Yu",
                "Ruiqi Guo",
                "Sanjiv Kumar"
            ],
            "title": "The lazy neuron phenomenon: On emergence of activation sparsity in transformers",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Weitang Liu",
                "Xiaoyun Wang",
                "John D. Owens",
                "Yixuan Li"
            ],
            "title": "Energy-based out-of-distribution detection",
            "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems",
            "year": 2020
        },
        {
            "authors": [
                "Xixi Liu",
                "Yaroslava Lochman",
                "Christopher Zach"
            ],
            "title": "GEN: pushing the limits of softmax-based outof-distribution detection",
            "venue": "In IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2023
        },
        {
            "authors": [
                "Yifei Ming",
                "Yiyou Sun",
                "Ousmane Dia",
                "Yixuan Li"
            ],
            "title": "How to exploit hyperspherical embeddings for out-of-distribution detection",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Yuval Netzer",
                "Tao Wang",
                "Adam Coates",
                "Alessandro Bissacco",
                "Bo Wu",
                "Andrew Y. Ng"
            ],
            "title": "Reading digits in natural images with unsupervised feature learning",
            "venue": "In NIPS Workshop on Deep Learning and Unsupervised Feature Learning",
            "year": 2011
        },
        {
            "authors": [
                "Francesco Pinto",
                "Harry Yang",
                "Ser Nam Lim",
                "Philip H.S. Torr",
                "Puneet K. Dokania"
            ],
            "title": "Using mixup as a regularizer can surprisingly improve accuracy & out-of-distribution robustness",
            "venue": "In NeurIPS,",
            "year": 2022
        },
        {
            "authors": [
                "Jie Ren",
                "Stanislav Fort",
                "Jeremiah Z. Liu",
                "Abhijit Guha Roy",
                "Shreyas Padhy",
                "Balaji Lakshminarayanan"
            ],
            "title": "A simple fix to mahalanobis distance for improving near-ood detection",
            "venue": "CoRR, abs/2106.09022,",
            "year": 2021
        },
        {
            "authors": [
                "Yiyou Sun",
                "Yixuan Li"
            ],
            "title": "DICE: leveraging sparsification for out-of-distribution detection",
            "venue": "Computer Vision - ECCV 2022:",
            "year": 2022
        },
        {
            "authors": [
                "Yiyou Sun",
                "Chuan Guo",
                "Yixuan Li"
            ],
            "title": "React: Out-of-distribution detection with rectified activations",
            "venue": "Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems",
            "year": 2021
        },
        {
            "authors": [
                "Sagar Vaze",
                "Kai Han",
                "Andrea Vedaldi",
                "Andrew Zisserman"
            ],
            "title": "Open-set recognition: A good closed-set classifier is all you need",
            "venue": "In The Tenth International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Haoqi Wang",
                "Zhizhong Li",
                "Litong Feng",
                "Wayne Zhang"
            ],
            "title": "Vim: Out-of-distribution with virtual-logit matching",
            "venue": "In IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Hongxin Wei",
                "Renchunzi Xie",
                "Hao Cheng",
                "Lei Feng",
                "Bo An",
                "Yixuan Li"
            ],
            "title": "Mitigating neural network overconfidence with logit normalization",
            "venue": "International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Pingmei Xu",
                "Krista A. Ehinger",
                "Yinda Zhang",
                "Adam Finkelstein",
                "Sanjeev R. Kulkarni",
                "Jianxiong Xiao"
            ],
            "title": "Turkergaze: Crowdsourcing saliency with webcam based eye",
            "venue": "tracking. CoRR,",
            "year": 2015
        },
        {
            "authors": [
                "Jingkang Yang",
                "Pengyun Wang",
                "Dejian Zou",
                "Zitang Zhou",
                "Kunyuan Ding",
                "Wenxuan Peng",
                "Haoqi Wang",
                "Guangyao Chen",
                "Bo Li",
                "Yiyou Sun",
                "Xuefeng Du",
                "Kaiyang Zhou",
                "Wayne Zhang",
                "Dan Hendrycks",
                "Yixuan Li",
                "Ziwei Liu"
            ],
            "title": "Openood: Benchmarking generalized out-of-distribution detection",
            "venue": "NeurIPS,",
            "year": 2022
        },
        {
            "authors": [
                "Fisher Yu",
                "Yinda Zhang",
                "Shuran Song",
                "Ari Seff",
                "Jianxiong Xiao"
            ],
            "title": "LSUN: construction of a large-scale image dataset using deep learning with humans",
            "venue": "in the loop. CoRR,",
            "year": 2015
        },
        {
            "authors": [
                "Jingyang Zhang",
                "Jingkang Yang",
                "Pengyun Wang",
                "Haoqi Wang",
                "Yueqian Lin",
                "Haoran Zhang",
                "Yiyou Sun",
                "Xuefeng Du",
                "Kaiyang Zhou",
                "Wayne Zhang",
                "Yixuan Li",
                "Ziwei Liu",
                "Yiran Chen",
                "Hai Li"
            ],
            "title": "Openood v1.5: Enhanced benchmark for out-of-distribution detection",
            "venue": "CoRR, abs/2306.09301,",
            "year": 2023
        },
        {
            "authors": [
                "Bolei Zhou",
                "\u00c0gata Lapedriza",
                "Aditya Khosla",
                "Aude Oliva",
                "Antonio Torralba"
            ],
            "title": "Places: A 10 million image database for scene recognition",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,",
            "year": 2018
        },
        {
            "authors": [
                "Sun"
            ],
            "title": "ResNet is trained with ID data (ImageNet-1k",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "The capacity of a modern deep learning system to determine if a sample falls within its realm of knowledge is fundamental and important. In this paper, we offer insights and analyses of recent state-of-the-art out-of-distribution (OOD) detection methods - extremely simple activation shaping (ASH). We demonstrate that activation pruning has a detrimental effect on OOD detection, while activation scaling enhances it. Moreover, we propose SCALE, a simple yet effective post-hoc network enhancement method for OOD detection, which attains state-of-the-art OOD detection performance without compromising in-distribution (ID) accuracy. By integrating scaling concepts into the training process to capture a sample\u2019s ID characteristics, we propose Intermediate Tensor SHaping (ISH), a lightweight method for training time OOD detection enhancement. We achieve AUROC scores of +1.85% for near-OOD and +0.74% for far-OOD datasets on the OpenOOD v1.5 ImageNet-1K benchmark."
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "In deep neural networks, out-of-distribution (OOD) detection distinguishes samples which deviate from the training distribution. Standard OOD detection concerns semantic shifts (Yang et al., 2022; Zhang et al., 2023), where OOD data is defined as test samples from semantic categories unseen during training. Ideally, the neural network should be able to reject such samples as being OOD, while still maintaining strong performance on in-distribution (ID) test samples belonging to seen training categories.\nMethods for detecting OOD samples work by scoring network outputs such as logits or softmax values (Hendrycks & Gimpel, 2017; Hendrycks et al., 2022), post-hoc network adjustment during inference to improve OOD scoring (Sun & Li, 2022; Sun et al., 2021; Djurisic et al., 2023), or by adjusting model training (Wei et al., 2022; Ming et al., 2023; DeVries & Taylor, 2018). These approaches can be used either independently or in conjunction with one another. Typically, post-hoc adjustments together with OOD scoring is the preferred combination since it is highly effective at discerning OOD samples with minimal ID drop and can also be applied directly to already-trained models off-the-shelf. Examples include ReAct (Sun et al., 2021), DICE (Sun & Li, 2022) and more recently, ASH (Djurisic et al., 2023).\nOn the surface, each method takes different and sometimes even contradictory approaches. ReAct rectifies penultimate activations which exceed a threshold; ASH, on the other hand, prunes penultimate activations that are too low while amplifying remaining activations. While ASH currently achieves state-of-the-art performance, it lacks a robust explanation of its underlying operational principles. This limitation highlights the need for a comprehensive explanatory framework.\nThis work seeks to understand the working principles behind ASH. Through observations and mathematical derivations, we reveal that OOD datasets tend to exhibit a lower rate of pruning due to distinct mean and variance characteristics. We also demonstrate the significant role of scaling in enhancing OOD detection in ASH, while highlighting that the lower-part pruning approach, in contrast to ReAct, hinders the OOD detection process. This understanding leads to new state-of-theart results by leveraging scaling, achieving significant improvements without compromising on ID accuracy.\nThrough the lens of studying the distributions, we highlight the importance of scaling as a key metric for assessing a sample\u2019s ID nature. We integrate this concept into the training process, hypothesizing the feasibility of shaping the ID-ness objective even without the inclusion of OOD samples. The ID-ness objective introduces an optimization weighting factor for different samples through proposed intermediate tensor shaping (ISH). Remarkably, ISH achieves outstanding performance in both near-OOD and far-OOD detection tasks, with only one-third of the training effort required compared to current state-of-the-art approaches.\nOur contributions can be summarized as follows:\n\u2022 We analyze and explain the working principles of pruning and scaling for OOD detection and reveal that pruning, in some scenario, actually hurts OOD detection.\n\u2022 Based on our analysis, we devise SCALE, a new post-hoc network enhancement method for OOD detection, which achieves state-of-the-art results on OOD detection without any ID accuracy trade-off.\n\u2022 By incorporating scaling concepts into the training process to capture a sample\u2019s ID characteristics, we introduce ISH, a lightweight and innovative method for improving OOD detection during training. ISH yields remarkable OOD detection results."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "OOD scoring methods indicate how likely a sample comes from the training distribution, i.e. is in-distribution, based on sample features or model outputs. From a feature perspective, Lee et al. (2018) proposed to score a sample via the minimum Mahalanobis distance of that sample\u2019s features to the nearest ID class centroid. For model outputs, two common variants are based on the maximum softmax prediction (Hendrycks & Gimpel, 2017) and the maximum logit scores (Hendrycks et al., 2022). The raw softmax or logit scores are susceptible to the overconfidence issue, therefore, Liu et al. (2020) proposed to use an energy-based function to transform the logits as an improved score. A key benefit of deriving OOD scores from feature or model outputs is that it does not impact the model or the inference procedure, so the ID accuracy will not be affected.\nPost-hoc model enhancement methods modify the inference procedure to improve OOD detection and are often used together with OOD scoring methods. Examples include ReAct (Sun et al., 2021), which rectifies the penultimate activations for inference, DICE (Sun & Li, 2022), which sparsifies the network\u2019s weights in the last layer, and ASH (Djurisic et al., 2023), which scales and prunes the penultimate activations. Each of these methods is then combined with energy-based score (Liu\net al., 2020) to detect the OOD data. While effective at identifying OOD data, these methods have a reduced ID accuracy as the inference procedure is altered. Our proposed SCALE is also post-hoc model enhancement, while our ID accuracy will not be affected, where we applies different scaling factor based on sample\u2019s activations shape, which do not alter the ID estimates for single sample, but emphasize difference among samples.\nTraining-time model enhancement techniques aims to make OOD data more distinguishable directly at training. Various strategies including the incorporation of additional network branches (DeVries & Taylor, 2018), alternative training strategies (Wei et al., 2022), or data augmentation (Pinto et al., 2022; Hendrycks et al., 2020). The underlying assumption behind each of these techniques is training towards OOD detection objective can provide more discriminative features for OOD detection. A significant drawback of training-time enhancement is the additional computational cost. For example, AugMix (Hendrycks et al., 2020) requires double training time and extra GPU memory cost. Our intermediate tensor shaping (ISH) improves the OOD detection with one-third of the computational cost compares to the most lightweight method, without modifying model architecture.\nIntermediate tensor shaping: Activation shaping have been explored in deep learning for various purposes. DropOut is the first to utilize this idea by sparsifying the activations for regularization. Similar ideas has been applied on Li et al. (2023) for transformers. Activation shaping can also help efficient training and inference by compression (Kurtz et al., 2020; Chen et al., 2023b). Shaping operations on intermediate tensors differ from those on activations. Activation shaping affects both forward pass inference and backward gradient computation during training. In contrast, shaping intermediate tensors exclusively influences the backward gradient computation. Since intermediate tensors tend to consume a significant portion of GPU memory, techniques for compressing intermediate tensors have gained widespread use in memory-efficient training, all without altering the forward pass. (Evans & Aamodt, 2021; Liu et al., 2022; Chen et al., 2023a)."
        },
        {
            "heading": "3 ACTIVATION SCALING FOR POST-HOC MODEL ENHANCEMENT",
            "text": "We start by presenting the preliminaries of Out-of-Distribution (OOD) detection in Sec. 3.1 to set the stage for our subsequent discussion and analysis of the ASH method in Sec. 3.2. The results of our analysis directly leads to our own OOD criterion in Sec. 3.3. Finally, we introduce our intermediate tensor shaping approach for training time OOD detection enhancement in Sec. 3.4."
        },
        {
            "heading": "3.1 PRELIMINARIES",
            "text": "While OOD is relevant for many domains, we follow previous works (Yang et al., 2022) and focus specifically on semantic shifts in image classification. During training, the classification model is trained with ID data that fall into a pre-defined set of K semantic categories: \u2200(x, y) \u223c DID, y \u2208 YID. During inference, there are both ID and OOD samples; the latter are samples drawn from categories unobserved during training, i.e. \u2200(x, y) \u223c DOOD, y /\u2208 YID. Now consider a neural network consisting of two parts: a feature extractor f(\u00b7), and a linear classifier parameterized by weight matrix W \u2208 RK\u00d7D and a bias vector b \u2208 RD. The network logit can be mathematically represented as\nz = W \u00b7 a+ b, a = f(x), (1)\nwhere a \u2208 RD is the D-dimensional feature vector in the penultimate layer of the network and z \u2208 RK is the logit vector from which the class label can be estimated by y\u0302 = argmax(z). In line with other OOD literature (Sun et al., 2021), an individual dimension of feature a, denoted with index j as aj , is referred to as an \u201cactivation\u201d.\nFor a given test sample x, an OOD score can be calculated to indicate the confidence that x is in-distribution. By convention, scores above a threshold \u03c4 are ID, while those equal or below are considered OOD. A common setting is the energy-based OOD score SEBO(x) together with indicator function G(\u00b7) that applies the thresholding (Liu et al., 2020):\nG(x; \u03c4) = { 0 if SEBO(x) \u2264 \u03c4 (OOD), 1 if SEBO(x) > \u03c4 (ID), , SEBO(x) = T \u00b7 log K\u2211 k ezk/T , (2)\nwhere T is a temperature parameter, k is the logit index for the K classes."
        },
        {
            "heading": "3.2 ANALYSIS ON ASH:",
            "text": "A state-of-the-art method for OOD detection is ASH (Djurisic et al., 2023). ASH stands for activation shaping and is a simple post-hoc method that applies a rectified scaling to the feature vector a. Activations in a up to the pth percentile across the D dimensions are rectified (\u201cpruned\u201d in the original text); activations above the pth percentile are scaled. More formally, ASH introduces a shaping function sf that is applied to each activation aj in a given sample. If we define Pp(a) as the pth percentile of the elements in a, ASH produces the logit zASH:\nzASH = W \u00b7 (a \u25e6 sf (a)) + b, where sf (a)j = { 0 if aj \u2264 Pp(a), exp(r) if aj > Pp(a), , (3)\nand \u25e6 denotes an element-wise matrix multiplication, and the scaling factor r is defined as the ratio of the sum of all activations versus the sum of un-pruned activations in a:\nr = Q\nQp , where Q = D\u2211 j aj and Qp = \u2211\naj>Pp(a)\naj . (4)\nSince Qp \u2264 Q, the factor r \u2265 1; the higher the percentile p, i.e. the greater the extent of pruning, the smaller Qp is with respect to Q and the larger the scaling factor r. To distinguish OOD data, ASH then passes the logit from Eq. 3 to score and indicator function as given in Eq. 2.\nWhile ASH is highly effective, the original paper has no explanation of the working mechanism1. We analyze the rectification and scaling components of ASH below and reveal that scaling helps to separate ID versus OOD energy scores, while rectification has an adverse effect.\nAssumptions: Our analysis is based on two assumptions. (1) The penultimate activations of ID and OOD samples follow two differing rectified Gaussian distributions parameterized by (\u00b5ID, \u03c3ID) and (\u00b5OOD, \u03c3OOD). The Gaussian assumption is commonly used in the literature (Sun et al., 2021)and we verify it in Tab. 1; the rectification follows naturally if a ReLU is applied as the final operation of the penultimate layer. (2) Normalized ID activations are higher than that of OOD activations; this assumption is supported by (Liu et al., 2020) , who suggested that well-trained networks have\n1In fact, the authors put forth a call for explanation in their Appendix L.\nhigher responses to samples resembling those seen in training. Fig. 2 and Fig. 3 visualize statistical corroboration of these assumptions.\nProposition 3.1. Assume that ID activations a(ID)j \u223c NR(\u00b5ID, \u03c3ID) and OOD activations a (OOD) j \u223c NR(\u00b5OOD, \u03c3OOD) where NR denotes a rectified Gaussian distribution. If \u00b5ID/\u03c3ID > \u00b5OOD/\u03c3OOD, then there is a range of percentiles p for which a factor C(p) = \u03c6( \u221a 2 erf\u22121(2p\u22121))\n1\u2212\u03a6( \u221a 2 erf\u22121(2p\u22121)) is large enough\nsuch that QIDp /Q ID < QOODp /Q OOD.\nThe full proof is given in Appendix A. Above, \u03c6 and \u03a6 denote the probability density function and cumulative distribution function of the standard normal distribution, respectively. The factor C(p), plotted in Fig. 4a, relates the percentile of activations that distinguishes ID from OOD data.\nRectification (Pruning) sets activations smaller than Pp(a) to 0. The relative reduction of activations can be expressed as:\nDPruning = (Q\u2212Qp)/Q. (5)\nNote that a reduction in activations also leads to a reduction in the OOD energy. Since QIDp /Q ID < QOODp /Q OOD, it directly implies that the decrease in ID samples will be greater than that in OOD samples, denoted as DPruningID > D Pruning OOD . From this result, we can show that the expected value of the relative decrease in energy scores with rectification will be greater for ID samples than OOD samples following ReAct following the Remark 2 in Sun et al. (2021), which illustrates that the changes in logits is proportional to the changes in activations.\nOur result above shows that rectification or pruning creates a greater overlap in energy scores between ID and OOD samples, making it more difficult to distinguish them. Empirically, this result is shown in Fig. 4b, where AUROC steadily decreases with stand-alone pruning as the percentile p increase.\nScaling on the other hand behaves in a manner opposite to the derivation above and enlarges the separation between ID and OOD scores.\nGiven QIDp /Q ID < QOODp /Q OOD and r = Q/Qq , we have rID > rOOD, which motivates the separation on r between ID and OOD, Fig. 4c depicts the histograms for these respective distributions, they are well separated and therefore scale activations of ID and OOD samples differently. The relative increase on activation can be expressed as:\nIScaling = (r \u2212 1) (6)\nwhere we can get IscalingID > I scaling OOD . This increase is then transferred to logit spaces z and energy-based scores SEBO(ID) and SEBO(OOD), which increase the gap between ID and OOD samples.\nDiscussion on percentile p: Note that C(p) does not monotonically increasing with respect to p (see Fig. 4a). When p \u2248 0.95, there is an inflection point and C(p) decreases. A similar inflection follows on the AUROC for scaling (see Fig. 4b), though it is not exactly aligned to C(p). The difference is likely due to the approximations made to estimate C(p). Also, as p gets progressively larger, fewer activations (D = 2048 total activations) are considered for estimating r, leading to unreliable logits for the energy score. Curiously, pruning also drops off, which we believe to come similarly from the extreme reduction in activations."
        },
        {
            "heading": "3.3 SCALE CRITERION FOR OOD DETECTION",
            "text": "From our analyses and findings above, we propose a new post-hoc model enhancement criterion, which we call SCALE. As the name suggests, it shapes the activation with (only) a scaling:\nz\u2032 = W \u00b7 (a \u25e6 sf (a)) + b, where sf (a)j = exp(r) and r = \u2211\nj aj\u2211 aj>Pp(a) aj . (7)\nFig. 5a illustrates how SCALE works. SCALE applies the same scaling factor r as ASH, based on percentile p. Instead of pruning, it retains and scales all the activations. Doing so has two benefits. First, it enhances the separation in energy scores between ID and OOD samples. Secondly, scaling all activations equally preserve the ordinality of the logits z\u2032 compared to z. As such, the argmax is not affected and there is no trade-off for ID accuracy; this is not the case with rectification, be it pruning, like in ASH or clipping, or like ReAct (see Fig. 1). Results in Tab. 2 and 3 verify that SCALE outperform ASH-S on all datasets and model architectures."
        },
        {
            "heading": "3.4 INCORPORATING SCALE INTO TRAINING",
            "text": "In practice, the semantic shift of ID versus OOD data may be ambiguous. For example, iNaturalist dataset features different species of plants; similar objects may be found in ImageNet. Our hypothesis is that, during training, we can emphasize the impact of samples possessing the most distinctive in-distribution characteristics, denoted as \u201dID-ness\u201d. Quantifying the ID-ness of specific samples is a challenging task, so we rely on a well-trained network to assist us in this endeavor. In particular, for a well-trained network, we can reacquire the activations of all training samples. We proceed on the assumption that the normalized ID activations are greater than those of out-of-distribution (OOD) activations. To measure the degree of ID-ness within the training data, we compute their scale factor, represented as Q/Qp. Armed with this measurement of ID-ness, we can then undertake the process of re-optimizing the network using the high ID-ness data. Our approach draws inspiration from the concept of intermediate tensor compression found in memory-efficient training methods (Chen et al., 2023a), where modifications are exclusively applied to the backward pass, leaving the forward pass unchanged.\nFig. 5b illustrates our training time enhancement methods for OOD detection. We finetune a welltrained network, by introducing a modification to the gradient of the weights of the fully connected layer. The modified gradient is defined as follows:\nWt+1 = Wt \u2212 \u03b7 \u2211 i [(ai \u25e6 sf (ai))\u22a4\u2207zi] (8)\nwhere i denotes sample index in the batch, \u2207 denotes the gradient regarding to the cross entropy loss, t denotes the training step t, and \u03b7 represents the learning rate.\nModifying activations exclusively in the backward pass offers several advantages. Firstly, it leaves the forward pass unaffected, resulting in only a minimal loss in ID accuracy. Secondly, the model architecture remains exactly the same during inference, making this training strategy compatible with any OOD post-processing techniques. Since the saved activations in the backward pass are also referred to as intermediate tensors, we term this method as Intermediate tensor SHaping (ISH)."
        },
        {
            "heading": "4 EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "4.1 SETTINGS",
            "text": "To verify SCALE as a post-hoc OOD method, we conduct experiments using CIFAR10, CIFAR100 (Krizhevsky, 2009), and ImageNet-1k (Deng et al., 2009) as in-distribution (ID) data sources.\nCIFAR. We used SVHN (Netzer et al., 2011), LSUN-Crop (Yu et al., 2015), LSUN-Resize (Yu et al., 2015), iSUN (Xu et al., 2015), Places365 (Zhou et al., 2018), and Textures (Cimpoi et al., 2014) as OOD datasets, For consistency with previous work, we use the same model architecture and pretrained weights, namely, DenseNet-101 (Huang et al., 2017), in accordance with the other post-hoc approaches DICE, ReAct, and ASH. Table 3 compares the FPR@95 and AUROC averaged across all six datasets; detailed results are provided in Appendix B\nImageNet. In our ImageNet experiments, we follow the OpenOOD v1.5 (Zhang et al., 2023) benchmark, which separates OOD datasets as near-OOD and far-OOD groups. We employed SSB-hard (Vaze et al., 2022) and NINCO (Bitterwolf et al., 2023) as near-OOD datasets and iNaturalist (Horn et al., 2018), Textures (Cimpoi et al., 2014), and OpenImage-O (Wang et al., 2022) as far-OOD datasets. Our reported metrics are the average FPR@95 and AUROC values across these categories; detailed results are given in Appendix B. The OpenOOD benchmark includes improved hyperparameter selection with a dedicated OOD validation set to prevent overfitting to the testing set. Additionally, we provide results following the same dataset and test/validation split settings as ASH and ReAct in the appendix. We adopted the ResNet50 (He et al., 2016) model architecture and obtained the pretrained network from the torchvision library.\nMetrics. We evaluate with two measures. The first is FPR@95, which measures the false positive rate at a fixed true positive rate of 95%; lower scores are better). The second is AUROC (Area under the ROC curve). It represents the probability that a positive in-distribution (ID) sample will have a higher detection score than a negative out-of-distribution (OOD) sample; higher scores indicate superior discrimination."
        },
        {
            "heading": "4.2 SCALE FOR POST-HOC OOD DETECTION",
            "text": "Comparison of ODD score methods and post-hoc model enhancement methods (separated with a solid line) on the ImageNet and CIFAR are illustrated in the Table 2 and 3. Notably, SCALE attains the highest OOD detection scores.\nOOD Detection Accuracy. Compared to the current state-of-the-art ASH-S, SCALE demonstrates significant improvements on ImageNet \u2013 1.73 on Near-OOD and 0.26 on far-OOD when considering AUROC. For FPR@95, it outperforms ASH-S by 2.27 and 0.33. On CIFAR10 and CIFAR100, SCALE has even greater improvements of 2.48 and 2.41 for FPR@95, as well as 0.66 and 0.72 for AUROC, respectively.\nID Accuracy. One of SCALE\u2019s key advantages is it only applies linear transformations on features, so ID accuracy is guaranteed to stay the same. This differentiates it from other post-hoc enhancement\nmethods that rectify or prune activations, thereby modifying inference and invariably compromises the ID accuracy. SCALE\u2019s performance surpasses ASH-S by a substantial margin of 0.67 on the ID dataset, ImageNet-1k. This capability is pivotal for establishing a unified pipeline that excels for ID and OOD.\nComparison with TempScale. Temperature scaling (TempScale) is widely used for confidence calibration (Guo et al., 2017). SCALE and TempScale both leverage scaling for OOD detection, but with two distinctions. Firstly, TempScale directly scales logits for calibration, whereas SCALE applies scaling at the penultimate layer. Secondly, TempScale employs a uniform scaling factor for all samples, whereas SCALE applies a sample-specific scaling factor based on the sample\u2019s activation statistics. The sample-specific scaling is a crucial differentiator that enables the discrimination between ID and OOD samples. Notably, our SCALE model significantly outperforms TempScale in both Near-OOD and Far-OOD scenarios.\nSCALE with different percentiles p. Table 2 uses p = 0.85 for SCALE and ASH-S, which is verified on the validation set. As detailed in Section 3.2, in order to ensure the validity of scaling, it is essential for the percentile value p to fall within a specific range where the parameter C(p) exhibits a sufficiently high value to meet the required condition. Our experimental observations align with this theoretical premise. Specifically, we have empirically observed that, up to the 85% percentile threshold, the AUROC values for both Near-OOD and Far-OOD scenarios consistently show an upward trend. However, a noticeable decline becomes apparent beyond this percentile threshold. This empirical finding corroborates our theoretical insight, indicating that the parameter C(p) experiences a reduction in magnitude as p approaches the 90%."
        },
        {
            "heading": "4.3 ISH FOR TRAINING-TIME MODEL ENHANCEMENT",
            "text": "We used the same dataset splits as the post-hoc experiments in Sec. 4.1. For training, we fine-tuned the torchvision pretrained model with ISH for 10 epochs with a cosine annealing learning rate schedule\ninitiated at 0.003 and a minimum of 0. We additionally observed that using a smaller weight decay value (5e-6) enhances OOD detection performance. The results are presented in Table 5. We compare ISH with other training time model enhancement methods.\nComparison with OOD traning methods.\nThe work LogitNorm(Wei et al., 2022) focuses on diagnosing the gradual narrowing of the gap between the logit magnitudes of ID and OOD distributions during later stages of training. Their proposed approach involves normalizing logits, and the scaling factor is applied within the logits space during the backward pass.\nThe key distinction between their LogitNorm method and our ISH approach lies in the purpose of scaling. LogitNorm scales logits primarily for confidence calibration, aiming to align the model\u2019s confidence with the reliability of its predictions. In contrast, ISH scales activations to prioritize weighted optimization, emphasizing the impact of high ID-ness data on the fine-tuning process.\nComparisons with data augmentation-based methods. Zhang et al. (2023) indicates that data augmentation methods, while not originally designed for OOD detection improvement, can simultaneously enhance both ID and OOD accuracy.\nIn comparison to AugMix and RegMixup, our ISH approach, while slightly reducing ID accuracy, delivers superior OOD performance with significantly fewer computational resources. When compared to AugMix, ISH achieves substantial improvements, enhancing AUROC by 0.46 and 0.8 for Near-OOD and Far-OOD, respectively, with just 0.1x the extended training epochs. Notably, ISH sets the highest AUROC records, reaching 84.01% on Near-OOD scores and 96.79% on Far-OOD scores among all methods on OpenOODv1.5 benchmark."
        },
        {
            "heading": "5 CONCLUSION",
            "text": "In this paper, we have conducted an in-depth investigation into the efficacy of scaling techniques in enhancing out-of-distribution (OOD) detection. Our study is grounded in the analysis of activation distribution disparities between in-distribution (ID) and OOD data. To this end, we introduce SCALE, a post-hoc model enhancement method that achieves state-of-the-art OOD accuracy when integrated with energy scores, without compromising ID accuracy. Furthermore, we extend the application of scaling to the training phase, introducing ISH, a training-time enhancement method that significantly bolsters OOD accuracy."
        },
        {
            "heading": "A DETAILS OF PROOF",
            "text": "Proposition 3.1. Assume that ID activations a(ID)j \u223c NR(\u00b5ID, \u03c3ID) and OOD activations a (OOD) j \u223c NR(\u00b5OOD, \u03c3OOD) where NR denotes a rectified Gaussian distribution. If \u00b5ID/\u03c3ID > \u00b5OOD/\u03c3OOD, then there is a range of percentiles p for which a factor C(p) = \u03c6( \u221a 2 erf\u22121(2p\u22121))\n1\u2212\u03a6( \u221a 2 erf\u22121(2p\u22121)) is large enough\nsuch that QIDp /Q ID < QOODp /Q OOD.\nProof. The proof schema is to derive equivalent conditions. Under the assumption that data in the latent space follows an independent and identically distributed (IID) Gaussian distribution prior to the ReLU activation (Sun et al. (2021)), we can derive that each coefficient a(ID)j \u223c NR(\u00b5ID, \u03c3ID) and OOD activations a(OOD)j \u223c NR(\u00b5OOD, \u03c3OOD) where NR denotes a rectified Gaussian distribution. Moreover if we denote high activation h(ID)j = a (ID) j if aj > Pp(a) and zeros elsewhere. Then we have h(ID)j \u223c N T (\u00b5ID, \u03c3ID) and identically h (OOD) j \u223c N T (\u00b5OOD, \u03c3OOD), where N T denotes a truncated Gaussian distribution. Then, we can calculate the expectations as follows:\nE[aj ] = \u00b5 [ 1\u2212 \u03a6(\u2212\u00b5 \u03c3 ) ] + \u03c6(\u2212\u00b5 \u03c3 )\u03c3 (9)\nE[hj ] = \u00b5+ \u03c6(m)\n1\u2212 \u03a6(m) \u03c3, m = s\u2212 \u00b5 \u03c3\n(10)\nHere, \u03c6(\u00b7) is the probability density function of the standard normal distribution, and \u03a6(\u00b7) is its cumulative distribution function.\nQp/Q = \u2211\nj hj\u2211 j aj = E[hj ](1\u2212p)D E[aj ]D . Let us consider the notation \u03b2 = (1\u2212p)Q/Qp = E[aj ] E[hj ] . Q ID p /Q ID <\nQOODp /Q OOD \u21d0\u21d2 \u03b2ID > \u03b2OOD. So we focus on: \u03b2 = \u00b5 [ 1\u2212 \u03a6(\u2212\u00b5\u03c3 ) ] + \u03c6(\u2212\u00b5\u03c3 )\u03c3\n\u00b5+ \u03c6(m)1\u2212\u03a6(m)\u03c3 = 1\u2212 \u03a6(\u2212\u00b5\u03c3 ) 1 + \u03c6(m)1\u2212\u03a6(m) \u03c3 \u00b5 + \u03c6(\u2212\u00b5\u03c3 )\u03c3 \u00b5+ \u03c6(m)1\u2212\u03a6(m)\u03c3 (11)\nLet\u2019s introduce some notations for ease of analysis:\n\u2022 \u03b3 = \u00b5\u03c3\n\u2022 A = \u03a6(\u2212\u03b3)\n\u2022 B = \u03c6(\u2212\u03b3)\n\u2022 C = \u03c6(m)1\u2212\u03a6(m) = \u03c6( s\u2212\u00b5\u03c3 )\n1\u2212\u03a6( s\u2212\u00b5\u03c3 ) ,\nWith these definitions, we can express \u03b2 as:\n\u03b2 = 1\u2212A\n1 + C\u03b3\u22121 +\nB\u03c3\n\u00b5+ C\u03c3 (12)\nWe consider that \u03b3ID \u2265 \u03b3OOD Hence, we also have:\n\u2022 AID \u2264 AOOD\n\u2022 BID \u2264 BOOD\nBy definition we have that sID(p) = \u00b5ID + \u03c3ID \u221a 2 erf\u22121(2p\u2212 1) and sOOD(p) = \u00b5OOD + \u03c3OOD \u221a 2 erf\u22121(2p\u2212 1) where p is the proportion of data that we want to keep. So we have:\nC ID(p) = \u03c6(mID)\n1\u2212 \u03a6(mID) =\n\u03c6( s ID\u2212\u00b5ID \u03c3ID )\n1\u2212 \u03a6( sID\u2212\u00b5ID\u03c3ID ) =\n\u03c6( \u221a 2 erf\u22121(2p\u2212 1))\n1\u2212 \u03a6( \u221a 2 erf\u22121(2p\u2212 1))\n(13)\nMoreover, we can prove that COOD(p) = \u03c6(m OOD) 1\u2212\u03a6(mOOD) = \u03c6( s\nOOD\u2212\u00b5OOD\n\u03c3OOD )\n1\u2212\u03a6( sOOD\u2212\u00b5OOD \u03c3OOD\n) = \u03c6(\n\u221a 2 erf\u22121(2p\u22121))\n1\u2212\u03a6( \u221a 2 erf\u22121(2p\u22121)) =\nC ID(p).\nNow, if we consider the approximation: E[aj ] \u2243 \u00b5 [ 1\u2212 \u03a6(\u2212\u00b5 \u03c3 ) ]\n(14)\nWe assume that \u03c6 ( \u2212\u00b5\u03c3 ) \u03c3 \u2248 0 since the sigma term is very small, and the second term is below one. With this approximation, we have:\n\u03b2 = \u03b3(1\u2212A) \u03b3 + C\n(15)\nWe want to compare \u03b2 for in-distribution (ID) denoted \u03b2ID and out-of-distribution (OOD) data denoted \u03b2OOD. Moreover, we have:\n\u03b2ID \u2265 \u03b2OOD \u21d0\u21d2 1\u2212A ID\n1 + C\u03b3ID \u22121 \u2265\n1\u2212AOOD\n1 + C\u03b3OOD \u22121 \u21d0\u21d2\n1\u2212AID\n1\u2212AOOD \u2265 1 + C\u03b3\nID\u22121\n1 + C\u03b3OOD \u22121 (16)\nWe can use the approximation: 1 1+C\u03b3OOD\u22121 \u2243 1\u2212C\u03b3OOD\u22121 by applying a first-order Taylor expansion. Then we have:\n1\u2212AID\n1\u2212AOOD \u2265 (1 + C\u03b3ID\u22121)(1\u2212 C\u03b3OOD\u22121) (17)\n\u2265 1 + C(\u03b3ID\u22121 \u2212 \u03b3OOD\u22121)\u2212 C2(\u03b3ID\u22121\u03b3OOD\u22121) (18)\nNote that by definition C should be positive. The given inequality can be expressed as:\n1\u2212AID\n1\u2212AOOD \u2212 1\u2212 C(\u03b3ID\u22121 \u2212 \u03b3OOD\u22121) + C2(\u03b3ID\u22121\u03b3OOD\u22121) \u2265 0 (19)\nWe can rewrite it as:\n\u21411C2 + \u21412C + \u21413 \u2265 0 (20)\nHere we have the following notations: \u21411 = (\u03b3ID \u22121 \u03b3OOD \u22121 ) and \u21412 = \u2212(\u03b3ID \u22121 \u2212 \u03b3OOD\u22121) and \u21413 = 1\u2212A ID 1\u2212AOOD \u2212 1. Let us define \u2206 = \u2141 2 2 \u2212 4\u21411\u21413 Then we have:\n\u2206 = (\u03b3ID \u22121 \u2212 \u03b3OOD\u22121)2 \u2212 4(\u03b3ID\u22121\u03b3OOD\u22121)\n( 1\u2212AID\n1\u2212AOOD \u2212 1\n) (21)\n= \u03b3ID \u22122 + \u03b3OOD \u22122 \u2212 2(\u03b3ID\u22121\u03b3OOD\u22121) ( 2 1\u2212AID\n1\u2212AOOD \u2212 1\n) (22)\n= ( \u03b3ID \u22121 + \u03b3OOD \u22121)2 \u2212 4(\u03b3ID\u22121\u03b3OOD\u22121)( 1\u2212AID 1\u2212AOOD ) (23)\nSince \u21411 > 0, there are two possible cases:\n\u2022 if \u2206 \u2264 0 then C(p) \u2208 R+ \u2022 if \u2206 > 0 then C(p) \u2208 [ max ( (\u03b3ID \u22121\u2212\u03b3OOD\u22121)+ \u221a \u2206\n2(\u03b3ID\u22121\u03b3OOD\u22121) , 0+\n) ,+\u221e ) . Note that another side\n(\u03b3ID \u22121 \u2212 \u03b3OOD\u22121) \u2264 0 so (\u03b3ID\u22121 \u2212 \u03b3OOD\u22121)\u2212 \u221a \u2206 \u2264 0. So we do not consider this.\nIn summary, there is a valid range of pruning p value satisfying the valid range of C(p) so that the statistics Qp/Q of the ID distribution is smaller than that of the OOD distributions. p with a larger C(p) is more applicable to any case."
        },
        {
            "heading": "B FULL EXPERIMENTS",
            "text": "In this section, we provide full results for SCALE post-hoc model enhancement. Tab. 6 shows full results on ImageNet and Tab. 8 and 9 show full results on CIFAR10 and CIFAR100. We also provide ImageNet results following dataset setting of ReAct and ASH in Tab. 7 for more comparison.\nTa bl\ne 8:\nD et\nai le\nd re\nsu lts\nfo rC\nIF A\nR -1\n0.\nM et\nho d\nSV H\nN L\nSU N\n-c L\nSU N\n-r iS\nU N\nTe xt\nur es\nPl ac\nes 36\n5 Av\ner ag\ne ID\nA C C FP R 95 A U R O C FP R 95 A U R O C FP R 95 A U R O C FP R 95 A U R O C FP R 95 A U R O C FP R 95 A U R O C FP R 95 A U R O C \u2193 \u2191 \u2193 \u2191 \u2193 \u2191 \u2193 \u2191 \u2193 \u2191 \u2193 \u2191 \u2193 \u2191 \u2191\nM SP\n47 .2\n4 93\n.4 8\n33 .5\n7 95\n.5 4\n42 .1\n0 94\n.5 1\n42 .3\n1 94\n.5 2\n64 .1\n5 88\n.1 5\n63 .0\n2 88\n.5 7\n48 .7\n3 92\n.4 6\n94 .5 3 E B O 40 .6 1 93 .9 9 3. 81 99 .1 5 9. 28 98 .1 2 10 .0 7 98 .0 7 56 .1 2 86 .4 3 39 .4 0 91 .6 4 26 .5 5 94 .5 7 94 .5 3 R eA ct 41 .6 4 93 .8 7 5. 96 98 .8 4 11 .4 6 97 .8 7 12 .7 2 97 .7 2 43 .5 8 92 .4 7 43 .3 1 91 .0 3 26 .4 5 94 .6 7 - D IC E 25 .9 9\u00b1 5 .1 0 95 .9 0\u00b1 1 .0 8 0. 26 \u00b1 0 .1 1 99 .9 2\u00b1 0 .0 2 3. 91 \u00b1 0 .5 6 99 .2 0\u00b1 0 .1 5 4. 36 \u00b1 0 .7 1 99 .1 4\u00b1 0 .1 5 41 .9 0\u00b1 4 .4 1 88 .1 8\u00b1 1 .8 0 48 .5 9\u00b1 1 .5 3 89 .1 3\u00b1 0 .3 1 20 .8 3\u00b1 1 .5 8 95 .2 4\u00b1 0 .2 4 - A SH -S 6. 51 98 .6 5 0. 90 99 .7 3 4. 96 98 .9 2 5. 17 98 .9 0 24 .3 4 95 .0 9 48 .4 5 88 .3 4 15 .0 5 96 .6 1 94 .0 2 SC A L E (O ur s) 5. 80 98 .7 2 0. 73 99 .7 4 3. 36 99 .2 2 3. 43 99 .2 1 23 .4 2 94 .9 7 38 .6 9 91 .7 4 12 .5 7 97 .2 7 94 .5 3\nTa bl\ne 9:\nD et\nai le\nd re\nsu lts\nfo rC\nIF A\nR -1\n00 .\nM et\nho d\nSV H\nN L\nSU N\n-c L\nSU N\n-r iS\nU N\nTe xt\nur es\nPl ac\nes 36\n5 Av\ner ag\ne ID\nA C C FP R 95 A U R O C FP R 95 A U R O C FP R 95 A U R O C FP R 95 A U R O C FP R 95 A U R O C FP R 95 A U R O C FP R 95 A U R O C \u2193 \u2191 \u2193 \u2191 \u2193 \u2191 \u2193 \u2191 \u2193 \u2191 \u2193 \u2191 \u2193 \u2191 \u2191\nM SP\n81 .7\n0 75\n.4 0\n60 .4\n9 85\n.6 0\n85 .2\n4 69\n.1 8\n85 .9\n9 70\n.1 7\n84 .7\n9 71\n.4 8\n82 .5\n5 74\n.3 1\n80 .1\n3 74\n.3 6\n75 .0 4 E B O 87 .4 6 81 .8 5 14 .7 2 97 .4 3 70 .6 5 80 .1 4 74 .5 4 78 .9 5 84 .1 5 71 .0 3 79 .2 0 77 .7 2 68 .4 5 81 .1 9 75 .0 4 R eA ct 83 .8 1 81 .4 1 25 .5 5 94 .9 2 60 .0 8 87 .8 8 65 .2 7 86 .5 5 77 .7 8 78 .9 5 82 .6 5 74 .0 4 62 .2 7 84 .4 7 - D IC E 54 .6 5\u00b1 4 .9 4 88 .8 4\u00b1 0 .3 9 0. 93 \u00b1 0 .0 7 99 .7 4\u00b1 0 .0 1 49 .4 0\u00b1 1 .9 9 91 .0 4\u00b1 1 .4 9 48 .7 2\u00b1 1 .5 5 90 .0 8\u00b1 1 .3 6 65 .0 4\u00b1 0 .6 6 76 .4 2\u00b1 0 .3 5 79 .5 8\u00b1 2 .3 4 77 .2 6\u00b1 1 .0 8 49 .7 2\u00b1 1 .6 9 87 .2 3\u00b1 0 .7 3 - A SH -S 25 .0 2 95 .7 6 5. 52 98 .9 4 51 .3 3 90 .1 2 46 .6 7 91 .3 0 34 .0 2 92 .3 5 85 .8 6 71 .6 2 41 .4 0 90 .0 2 71 .6 5 SC A L E (O ur s) 22 .0 5 96 .2 9 4. 48 99 .1 6 46 .0 2 91 .5 4 42 .1 4 92 .4 7 34 .2 0 92 .3 4 85 .0 4 72 .6 6 38 .9 9 90 .7 4 75 .0 4"
        }
    ],
    "year": 2023
}