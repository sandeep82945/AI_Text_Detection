{
    "abstractText": "Invariance and equivariance to geometrical transformations have proven to be very useful inductive biases when training (convolutional) neural network models, especially in the low-data regime. Much work has focused on the case where the symmetry group employed is compact or abelian, or both. Recent work has explored enlarging the class of transformations used to the case of Lie groups, principally through the use of their Lie algebra, as well as the group exponential and logarithm maps. The applicability of such methods to larger transformation groups is limited by the fact that depending on the group of interest G, the exponential map may not be surjective. Further limitations are encountered when G is neither compact nor abelian. Using the structure and geometry of Lie groups and their homogeneous spaces, we present a framework by which it is possible to work with such groups primarily focusing on the Lie groups G = GL(n,R) and G = SL(n,R), as well as their representation as affine transformations R \u22ca G. Invariant integration as well as a global parametrization is realized by decomposing the \u2018larger\u2018 groups into subgroups and submanifolds which can be handled individually. Under this framework, we show how convolution kernels can be parametrized to build models equivariant with respect to affine transformations. We evaluate the robustness and out-of-distribution generalisation capability of our model on the standard affine-invariant benchmark classification task, where we outperform all previous equivariant models as well as all Capsule Network proposals.",
    "authors": [],
    "id": "SP:a822db2020ceb9403796f46b3f6b30eee79519fe",
    "references": [
        {
            "authors": [
                "Esteban Andruchow",
                "Gabriel Larotonda",
                "Lazaro Recht",
                "Alejandro Varela"
            ],
            "title": "The left invariant metric in the general linear group",
            "venue": "Journal of Geometry and Physics,",
            "year": 2014
        },
        {
            "authors": [
                "Vincent Arsigny",
                "Pierre Fillard",
                "Xavier Pennec",
                "Nicholas Ayache"
            ],
            "title": "Geometric means in a novel vector space structure on symmetric positive-definite matrices",
            "venue": "SIAM journal on matrix analysis and applications,",
            "year": 2007
        },
        {
            "authors": [
                "Ilyes Batatia",
                "Mario Geiger",
                "Jose Munoz",
                "Tess Smidt",
                "Lior Silberman",
                "Christoph Ortner"
            ],
            "title": "A general framework for equivariant neural networks on reductive lie groups",
            "venue": "arXiv preprint arXiv:2306.00091,",
            "year": 2023
        },
        {
            "authors": [
                "Erik J Bekkers"
            ],
            "title": "B-spline cnns on lie groups",
            "venue": "In International Conference on Learning Representations,",
            "year": 2019
        },
        {
            "authors": [
                "Gregory Benton",
                "Marc Finzi",
                "Pavel Izmailov",
                "Andrew G Wilson"
            ],
            "title": "Learning invariances in neural networks from training data",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Alexander Bogatskiy",
                "Brandon Anderson",
                "Jan Offermann",
                "Marwah Roussi",
                "David Miller",
                "Risi Kondor"
            ],
            "title": "Lorentz group equivariant neural network for particle physics",
            "venue": "In International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Martin R Bridson",
                "Andr\u00e9 Haefliger"
            ],
            "title": "Metric spaces of non-positive curvature, volume 319",
            "venue": "Springer Science & Business Media,",
            "year": 2013
        },
        {
            "authors": [
                "Michael M Bronstein",
                "Joan Bruna",
                "Taco Cohen",
                "Petar Veli\u010dkovi\u0107"
            ],
            "title": "Geometric deep learning: Grids, groups, graphs, geodesics, and gauges",
            "venue": "arXiv preprint arXiv:2104.13478,",
            "year": 2021
        },
        {
            "authors": [
                "Gregory S. Chirikjian"
            ],
            "title": "Stochastic Models, Information Theory, and Lie Groups",
            "venue": "Volume 2. Birkha\u0308user Boston, MA,",
            "year": 2012
        },
        {
            "authors": [
                "Taco Cohen",
                "Max Welling"
            ],
            "title": "Group equivariant convolutional networks",
            "venue": "In International conference on machine learning,",
            "year": 2016
        },
        {
            "authors": [
                "Taco S Cohen",
                "Mario Geiger",
                "Maurice Weiler"
            ],
            "title": "A general theory of equivariant cnns on homogeneous spaces",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "Alberto Dolcetti",
                "Donato Pertici"
            ],
            "title": "Differential properties of spaces of symmetric real matrices",
            "venue": "Rendiconti del Seminario Matematico,",
            "year": 2019
        },
        {
            "authors": [
                "Morris L Eaton"
            ],
            "title": "Multivariate statistics: a vector space approach",
            "venue": "Institute of Mathematical Statistics,",
            "year": 1983
        },
        {
            "authors": [
                "Jacques Faraut"
            ],
            "title": "Analysis on Lie Groups: An Introduction. Cambridge Studies in Advanced Mathematics",
            "year": 2008
        },
        {
            "authors": [
                "Jacques Faraut",
                "Giancarlo Travaglini"
            ],
            "title": "Bessel functions associated with representations of formally real jordan algebras",
            "venue": "Journal of functional analysis,",
            "year": 1987
        },
        {
            "authors": [
                "Roger H Farrell"
            ],
            "title": "Multivariate calculation: Use of the continuous groups",
            "venue": "Springer Science & Business Media,",
            "year": 2012
        },
        {
            "authors": [
                "Marc Finzi",
                "Samuel Stanton",
                "Pavel Izmailov",
                "Andrew Gordon Wilson"
            ],
            "title": "Generalizing convolutional neural networks for equivariance to lie groups on arbitrary continuous data",
            "venue": "In International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Marc Finzi",
                "Max Welling",
                "Andrew Gordon Wilson"
            ],
            "title": "A practical method for constructing equivariant multilayer perceptrons for arbitrary matrix groups",
            "venue": "In International conference on machine learning,",
            "year": 2021
        },
        {
            "authors": [
                "Gerald B Folland"
            ],
            "title": "Real analysis: modern techniques and their applications, volume 40",
            "year": 1999
        },
        {
            "authors": [
                "Gerald B Folland"
            ],
            "title": "A course in abstract harmonic analysis, volume 29",
            "venue": "CRC press,",
            "year": 2016
        },
        {
            "authors": [
                "Wolfgang F\u00f6rstner",
                "Boudewijn Moonen"
            ],
            "title": "A metric for covariance matrices. Geodesy-the Challenge of the 3rd Millennium",
            "year": 2003
        },
        {
            "authors": [
                "Jean Gallier",
                "Jocelyn Quaintance"
            ],
            "title": "Differential geometry and Lie groups: a computational perspective, volume 12",
            "year": 2020
        },
        {
            "authors": [
                "Evan S Gawlik",
                "Melvin Leok"
            ],
            "title": "Interpolation on symmetric spaces via the generalized polar decomposition",
            "venue": "Foundations of computational mathematics,",
            "year": 2018
        },
        {
            "authors": [
                "Kenneth I Gross",
                "Ray A Kunze"
            ],
            "title": "Bessel functions and representation theory",
            "venue": "i. Journal of Functional Analysis,",
            "year": 1976
        },
        {
            "authors": [
                "Jindong Gu",
                "Volker Tresp"
            ],
            "title": "Improving the robustness of capsule networks to image affine transformations",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2020
        },
        {
            "authors": [
                "B. Hall"
            ],
            "title": "Lie Groups, Lie Algebras, and Representations: An Elementary Introduction",
            "venue": "Graduate Texts in Mathematics. Springer International Publishing,",
            "year": 2015
        },
        {
            "authors": [
                "Jiaqi Han",
                "Yu Rong",
                "Tingyang Xu",
                "Wenbing Huang"
            ],
            "title": "Geometrically equivariant graph neural networks: A survey",
            "venue": "arXiv preprint arXiv:2202.07230,",
            "year": 2022
        },
        {
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2016
        },
        {
            "authors": [
                "Sigurdur Helgason"
            ],
            "title": "Differential geometry, Lie groups, and symmetric spaces",
            "venue": "Academic press,",
            "year": 1979
        },
        {
            "authors": [
                "Sigurdur Helgason"
            ],
            "title": "Groups and geometric analysis: integral geometry, invariant differential operators, and spherical functions, volume 83",
            "venue": "American Mathematical Society,",
            "year": 1984
        },
        {
            "authors": [
                "Sigurdur Helgason"
            ],
            "title": "Differential geometry and symmetric spaces, volume 341",
            "venue": "American Mathematical Soc.,",
            "year": 2001
        },
        {
            "authors": [
                "Dan Hendrycks",
                "Kevin Gimpel"
            ],
            "title": "Gaussian error linear units (gelus)",
            "venue": "arXiv preprint arXiv:1606.08415,",
            "year": 2016
        },
        {
            "authors": [
                "Pedro Hermosilla",
                "Tobias Ritschel",
                "Pere-Pau V\u00e1zquez",
                "\u00c0lvar Vinacua",
                "Timo Ropinski"
            ],
            "title": "Monte carlo convolution for learning on non-uniformly sampled point clouds",
            "venue": "ACM Transactions on Graphics (TOG),",
            "year": 2018
        },
        {
            "authors": [
                "Carl S Herz"
            ],
            "title": "Bessel functions of matrix argument",
            "venue": "Annals of Mathematics, pp",
            "year": 1955
        },
        {
            "authors": [
                "Edwin Hewitt",
                "Kenneth A Ross"
            ],
            "title": "Abstract Harmonic Analysis: Volume I Structure of Topological Groups Integration Theory Group Representations, volume 115",
            "venue": "Springer Science & Business Media,",
            "year": 2012
        },
        {
            "authors": [
                "Michael J Hutchinson",
                "Charline Le Lan",
                "Sheheryar Zaidi",
                "Emilien Dupont",
                "Yee Whye Teh",
                "Hyunjik Kim"
            ],
            "title": "Lietransformer: Equivariant self-attention for lie groups",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "J\u00fcrgen Jost",
                "Jeurgen Jost"
            ],
            "title": "Riemannian geometry and geometric analysis, volume 42005",
            "year": 2008
        },
        {
            "authors": [
                "Eberhard Kaniuth",
                "Keith F Taylor"
            ],
            "title": "Induced representations of locally compact groups",
            "venue": "Number 197. Cambridge university press,",
            "year": 2013
        },
        {
            "authors": [
                "Diederik P Kingma",
                "Jimmy Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "arXiv preprint arXiv:1412.6980,",
            "year": 2014
        },
        {
            "authors": [
                "David M Knigge",
                "David W Romero",
                "Erik J Bekkers"
            ],
            "title": "Exploiting redundancy: Separable group convolutional networks on lie groups",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Risi Kondor",
                "Shubhendu Trivedi"
            ],
            "title": "On the generalization of equivariance and convolution in neural networks to the action of compact groups",
            "venue": "In International Conference on Machine Learning,",
            "year": 2018
        },
        {
            "authors": [
                "Leon Lang",
                "Maurice Weiler"
            ],
            "title": "A wigner-eckart theorem for group equivariant convolution kernels",
            "venue": "arXiv preprint arXiv:2010.10952,",
            "year": 2020
        },
        {
            "authors": [
                "Serge Lang"
            ],
            "title": "Real and functional analysis, volume 142",
            "venue": "Springer Science & Business Media,",
            "year": 2012
        },
        {
            "authors": [
                "Yann LeCun",
                "Yoshua Bengio"
            ],
            "title": "Convolutional networks for images, speech, and time series",
            "venue": "The handbook of brain theory and neural networks,",
            "year": 1995
        },
        {
            "authors": [
                "John Lee"
            ],
            "title": "Introduction to topological manifolds, volume 202",
            "venue": "Springer Science & Business Media,",
            "year": 2010
        },
        {
            "authors": [
                "John M Lee"
            ],
            "title": "Smooth manifolds. In Introduction to smooth manifolds, pp. 1\u201331",
            "year": 2013
        },
        {
            "authors": [
                "Jan Eric Lenssen",
                "Matthias Fey",
                "Pascal Libuschewski"
            ],
            "title": "Group equivariant capsule networks",
            "venue": "Advances in neural information processing systems,",
            "year": 2018
        },
        {
            "authors": [
                "Mario Lezcano-Casado"
            ],
            "title": "Geometric optimisation on manifolds with applications to deep learning",
            "venue": "arXiv preprint arXiv:2203.04794,",
            "year": 2022
        },
        {
            "authors": [
                "Lachlan E MacDonald",
                "Sameera Ramasinghe",
                "Simon Lucey"
            ],
            "title": "Enabling equivariance for arbitrary lie groups",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Robert Martin",
                "Patrizio Neff"
            ],
            "title": "Minimal geodesics on gl (n) for left-invariant, right-o (n)-invariant riemannian metrics",
            "venue": "arXiv preprint arXiv:1409.7849,",
            "year": 2014
        },
        {
            "authors": [
                "Ben Mildenhall",
                "Pratul P Srinivasan",
                "Matthew Tancik",
                "Jonathan T Barron",
                "Ravi Ramamoorthi",
                "Ren Ng"
            ],
            "title": "Nerf: Representing scenes as neural radiance fields for view synthesis",
            "venue": "Communications of the ACM,",
            "year": 2021
        },
        {
            "authors": [
                "Robb J Muirhead"
            ],
            "title": "Aspects of multivariate statistical theory",
            "year": 2009
        },
        {
            "authors": [
                "Hans Z Munthe-Kaas",
                "GRW Quispel",
                "Antonella Zanna"
            ],
            "title": "Generalized polar decompositions on lie groups with involutive automorphisms",
            "venue": "Foundations of Computational Mathematics,",
            "year": 2001
        },
        {
            "authors": [
                "Hans Z Munthe-Kaas",
                "Gilles Reinout W Quispel",
                "Antonella Zanna"
            ],
            "title": "Symmetric spaces and lie triple systems in numerical analysis of differential equations",
            "venue": "BIT Numerical Mathematics,",
            "year": 2014
        },
        {
            "authors": [
                "B. O\u2019Neill"
            ],
            "title": "Semi-Riemannian Geometry With Applications to Relativity",
            "venue": "ISSN. Elsevier Science,",
            "year": 1983
        },
        {
            "authors": [
                "Xavier Pennec"
            ],
            "title": "Manifold-valued image processing with spd matrices. In Riemannian geometric statistics in medical image analysis, pp. 75\u2013134",
            "year": 2020
        },
        {
            "authors": [
                "Quentin Rentmeesters"
            ],
            "title": "Algorithms for data fitting on some common homogeneous spaces",
            "venue": "PhD thesis, Ph. D. thesis, Universite\u0301 Catholique de Louvain, Louvain, Belgium,",
            "year": 2013
        },
        {
            "authors": [
                "Fabio De Sousa Ribeiro",
                "Georgios Leontidis",
                "Stefanos Kollias"
            ],
            "title": "Introducing routing uncertainty in capsule networks",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Fabio De Sousa Ribeiro",
                "Georgios Leontidis",
                "Stefanos D Kollias"
            ],
            "title": "Capsule routing via variational bayes",
            "venue": "In AAAI,",
            "year": 2020
        },
        {
            "authors": [
                "David W Romero",
                "Anna Kuzina",
                "Erik J Bekkers",
                "Jakub M Tomczak",
                "Mark Hoogendoorn"
            ],
            "title": "Ckconv: Continuous kernel convolution for sequential data",
            "venue": "arXiv preprint arXiv:2102.02611,",
            "year": 2021
        },
        {
            "authors": [
                "Vishwanath Saragadam",
                "Daniel LeJeune",
                "Jasper Tan",
                "Guha Balakrishnan",
                "Ashok Veeraraghavan",
                "Richard G Baraniuk"
            ],
            "title": "Wire: Wavelet implicit neural representations",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2023
        },
        {
            "authors": [
                "Armin Schwartzman"
            ],
            "title": "Lognormal distributions and geometric averages of symmetric positive definite matrices",
            "venue": "International statistical review,",
            "year": 2016
        },
        {
            "authors": [
                "Vincent Sitzmann",
                "Julien Martel",
                "Alexander Bergman",
                "David Lindell",
                "Gordon Wetzstein"
            ],
            "title": "Implicit neural representations with periodic activation functions",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Ivan Sosnovik",
                "Micha\u0142 Szmaja",
                "Arnold Smeulders"
            ],
            "title": "Scale-equivariant steerable networks",
            "venue": "In International Conference on Learning Representations,",
            "year": 2020
        },
        {
            "authors": [
                "Maximilian Stegemeyer",
                "Knut H\u00fcper"
            ],
            "title": "Endpoint geodesics on the set of positive definite real matrices",
            "venue": "CONTROLO",
            "year": 2020
        },
        {
            "authors": [
                "Audrey Terras"
            ],
            "title": "Harmonic analysis on symmetric spaces\u2014higher rank spaces, positive definite matrix space and generalizations",
            "year": 2016
        },
        {
            "authors": [
                "Yann Thanwerdas",
                "Xavier Pennec"
            ],
            "title": "O (n)-invariant riemannian metrics on spd matrices",
            "venue": "Linear Algebra and its Applications,",
            "year": 2023
        },
        {
            "authors": [
                "Nathaniel Thomas",
                "Tess Smidt",
                "Steven Kearnes",
                "Lusann Yang",
                "Li Li",
                "Kai Kohlhoff",
                "Patrick Riley"
            ],
            "title": "Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds",
            "venue": "arXiv preprint arXiv:1802.08219,",
            "year": 2018
        },
        {
            "authors": [
                "Hsien-Chung Wang"
            ],
            "title": "Discrete nilpotent subgroups of lie groups",
            "venue": "Journal of Differential Geometry,",
            "year": 1969
        },
        {
            "authors": [
                "Frank W Warner"
            ],
            "title": "Foundations of differentiable manifolds and Lie groups, volume 94",
            "venue": "Springer Science & Business Media,",
            "year": 1983
        },
        {
            "authors": [
                "Maurice Weiler",
                "Gabriele Cesa"
            ],
            "title": "General e (2)-equivariant steerable cnns",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Maurice Weiler",
                "Patrick Forr\u00e9",
                "Erik Verlinde",
                "Max Welling"
            ],
            "title": "Coordinate independent convolutional networks\u2013isometry and gauge equivariant convolutions on riemannian manifolds",
            "venue": "arXiv preprint arXiv:2106.06020,",
            "year": 2021
        },
        {
            "authors": [
                "R.A. Wijsman"
            ],
            "title": "Invariant Measures on Groups and Their Use in Statistics",
            "venue": "IMS Lecture Notes. Institute of Mathematical Statistics,",
            "year": 1990
        },
        {
            "authors": [
                "Ernesto Zacur",
                "Matias Bossa",
                "Salvador Olmos"
            ],
            "title": "Left-invariant riemannian geodesics on spatial transformation groups",
            "venue": "SIAM Journal on Imaging Sciences,",
            "year": 2014
        },
        {
            "authors": [
                "Alexander J Smola"
            ],
            "title": "Wolfgang Ziller. Lie groups, representation theory and symmetric spaces",
            "venue": "Deep sets. Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "MacDonald"
            ],
            "title": "The lifting layer equivariance here was derived for the case where X is the homogeneous space R = Aff(G)/G, however a similar process is available for more general homogeneous spaces",
            "venue": "([Lg\u0303f",
            "year": 2022
        },
        {
            "authors": [
                "Weiler"
            ],
            "title": "2021) and a review focused on the application of induced representations in the context of neural networks can be found in Kondor",
            "year": 2019
        },
        {
            "authors": [
                "Batatia"
            ],
            "title": "by making use of the generators of the Lie algebra of a group. The resulting linear system is solved for finite dimensional representations by using the singular value decomposition. More general solutions are developed in Bogatskiy et al",
            "venue": "MacDonald et al",
            "year": 2022
        },
        {
            "authors": [
                "MacDonald"
            ],
            "title": "2022), which proposes a possible solution while still working with the group exponential. To overcome its lack of surjectivity and be able to sample with respect",
            "year": 2022
        },
        {
            "authors": [
                "MacDonald"
            ],
            "title": "ad\u2212X ) is the Jacobian determinant of the differential of expm and dX is the Lebesgue measure on g. The change of variables of Proposition A.4 and the expression",
            "year": 2022
        },
        {
            "authors": [
                "Sitzmann"
            ],
            "title": "SIREN networks can be considered as one example of an Implicit Neural Representation (INR) model. These models have seen widespread use in various areas of computer vision and graphics, e.g",
            "venue": "Mildenhall et al",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Symmetry constraints in the form of invariance or equivariance to geometric transformations have shown to be widely applicable inductive biases in the context of deep learning (Bronstein et al., 2021). Group-theoretic methods for imposing such constraints have led to numerous breakthroughs across a variety of data modalities. CNNs (LeCun et al., 1995) which make use of translation equivariance while operating on image data have been generalized in several directions. Groupequivariant convolutional neural networks (GCNNs) represent one such generalization. Originally proposed in Cohen & Welling (2016), GCNNs make use of group convolution operators to construct layers that produce representations which transform in a predictable manner whenever the input signal is transformed by an a-priori chosen symmetry group G. These models have been shown to exhibit increased generalization capabilities, while being less sensitive to G-perturbations of the input data. For these reasons, equivariant architectures have been proposed for signals in a variety of domains such as graphs (Han et al., 2022), sets (Zaheer et al., 2017) or point cloud data (Thomas et al., 2018). Constructing equivariant networks entails first choosing a group G, a representation for the signal space in which our data lives and a description of the way this space transforms when the group acts on it. Choosing a particular group G entails making a modelling assumption about the underlying (geometrical) structure of the data that should be preserved. Early work has focused on the case where G is finite, with subsequent work largely concentrated on the Euclidean group E(n), and its subgroups SE(n,R) or the rotation group SO(n). Working with continuous groups is much more challenging, and the vast majority of equivariant models focus on the case where the group G has a set of desirable topological and structural properties, namely G is either compact or abelian, or both. Recent work (Bekkers, 2019; Finzi et al., 2020) explores the possibility of building equivariant networks for Lie groups - continuous groups with a smooth structure.\nThis research direction is promising since it allows for the modelling of symmetry groups beyond Euclidean geometry. Affine and projective geometry, respectively affine and homography transformations are ubiquitous within computer vision, robotics and computer graphics (Zacur et al., 2014). Accounting for a larger degree of geometric variation has the promise of making (vision) architectures more robust to real-world data shifts. When working with non-compact and non-abelian Lie groups, for which the group exponential is not surjective, standard harmonic analysis tools cannot be employed directly. Our contribution is a framework making it possible to work with such groups.\nContributions We present a procedure by which invariant integration with respect to the Haar measure can be done in a principled manner, allowing for an efficient numerical integration scheme to be realized. We then construct global parametrization maps which allow us to map elements back and forth between the Lie algebra and the group, addressing the non-surjectivity of the group exponential. We apply our framework to the groups G = GL+(n,R) and G = SL(n,R), and more broadly the family of affine matrix Lie groups Aff(G) := Rn\u22caG,G \u2264 GL(n,R). The methodology and tools are generally applicable to any Lie group with finitely many connected components, and we explain how our approach can be seen as a generalization of previous proposals for constructing equviariant layers when working with the regular representation of a topological group."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "Recent proposals for Lie group equivariance (Bekkers, 2019; Finzi et al., 2020) focus on the infinitedimensional regular representation of a group and rely on the group exponential map to allow convolution kernels to be defined analytically in the Lie algebra of the group. Working with the regular representation entails dealing with an intractable convolution integral over the group, and a (Monte Carlo) numerical integration procedure approximating the integral needs to be employed, which requires sampling group elements with respect to the Haar measure of the group. Unfortunately, the applicability of these methods is limited to Lie groups for which the group exponential map is surjective, which is not the case for the affine group Aff(GL(n,R)). These methods also rely on the fact that for compact and abelian groups sampling with respect to the Haar measure of the group is straightforward, which is not the case for the affine groups of interest. MacDonald et al. (2022) propose a framework which can be applied to arbitrary Lie groups, aiming to address such limitations while still relying on the group exponential. This proposal is more closely reviewed in Sec. A.3, together with other related equivariant models."
        },
        {
            "heading": "3 BACKGROUND",
            "text": "Continuous group equivariance A Lie groupG is a group as well as a smooth manifold, such that \u2200g, h \u2208 G the group operation (g, h) 7\u2192 gh and the inversion map g 7\u2192 g\u22121 are smooth. GL(n,R) denotes the Lie group consisting of all invertible n\u00d7n matrices. A linear or matrix Lie group refers to a Lie subgroup of GL(n,R). GL(n,R), the translation group (Rn,+) and the family of affine groups Aff(G), G \u2264 GL(n,R) are our primary interest, with G usually being one of GL+(n,R), SL(n,R) \u2264 GL+(n,R) or SO(n). Equivariance with respect to the action of a locally compact group G can be realized by constructing layers using the cross-correlation/convolution operators. We recall that in the continuous setting we model our signals as functions f : X \u2192 RK defined on some underlying domain X . For example, images and feature maps can be defined as K-channel functions f \u2208 L2\u00b5(R2,RK) which are square-integrable (with respect to the measure \u00b5), and which have bounded support in practice, e.g. f : [\u22121, 1]2 \u2286 R2 \u2192 RK . Lg denotes the left-regular representation of G, encoding the action of G on function spaces. For any continuous f \u2208 C(X):\n[Lgf ](x) := f(g\u22121x), \u2200g \u2208 G, x \u2208 X (1) Every locally compact group G has a left (right) invariant Radon measure \u00b5G called the left (right) Haar measure of G. The Haar measure allows for G-invariant integration to be realized, and for the group convolution to be defined. To state the invariance property of \u00b5G, define the functional \u03bb\u00b5G :\n\u03bb\u00b5G : L 1(G) \u2192 R, \u03bb\u00b5G(f) = \u222b G f(g)d\u00b5G(g), \u2200f \u2208 L1(G) (2)\nThen, a left Haar measure respects \u03bb\u00b5G(Lgf) = \u03bb\u00b5G(f) for any g \u2208 G and f \u2208 L1(G). Additional details on convolution operators are provided in Sec. A.1, with Lie groups reviewed in Sec. B.1.\nConvolution operators For a group G acting transitively on locally compact spaces X and Y we then seek to construct an operator K : L2(X) \u2192 L2(Y ) satisfying the equivariance constraint Lg\u25e6K = K\u25e6Lg . We formalize two scenarios, whenX is a homogeneous space ofG (not necessarily a group) and Y = G, and the case where X = Y = G. Focusing on the second case, if d\u00b5X = d\u00b5G is the Haar measure onG, the integral operator K can be defined was the standard convolution/crosscorrelation. Let k : Y \u00d7X \u2192 R be a kernel that is invariant to the left action ofG in both arguments, such that k(gx, gy) = k(x, y) for any (x, y) \u2208 Y \u00d7X and g \u2208 G. Let \u00b5X be a G-invariant Radon measure on X , and define K := Ck : Lp(X) \u2192 Lp(G) (p \u2208 {1, 2}) such that \u2200f \u2208 Lp(X):\nCk : f 7\u2192 Ckf(y) = \u222b X f(x)k(x, y)d\u00b5X(x), \u2200y \u2208 Y (3)\nCk is G-equivariant: Lg \u25e6 Ck = Ck \u25e6 Lg, \u2200g \u2208 G (A.2). Since X = Y = G are homogeneous spaces ofGwe can easily define a bi-invariant kernel by projection k(x, y) = k\u0303(g\u22121y x) (k\u0303 : G\u2192 R) for any (x, y) \u2208 Y \u00d7X , where y = gyy0 for some fixed y0. The kernel is bi-invariant:\nk(hx, hy) = k\u0303((hgy) \u22121hx) = k\u0303(g\u22121y h \u22121hx) = k\u0303(g\u22121y x) = k(x, y), \u2200h \u2208 G (4) For the case Y = G and gy = y (y0 = e, the identity of G) this corresponds to a cross-correlation. For a convolution operator, we would analogously define k(x, y) = k\u0303(g\u22121x y) where x = gxx0 for x0 \u2208 X . In this case the essential component needed for equivariance of the operator Ck is the Ginvariant measure d\u00b5X , which is the Haar measure when X = Y = G. When X is a homogeneous space of G, but not necessarily G itself, we have to work with an operator which takes in a signal in Lp(X) and produces a signal Lp(G) on the group. This encompasses the case of the lifting layers, which are commonly employed when working with the regular representation of a group (Cohen & Welling, 2016; Kondor & Trivedi, 2018). The kernel k(\u00b7) in this case can be derived through an equivariance constraint as in Bekkers (2019); Cohen et al. (2019). It can also be shown (A.2) that an equivariant lifting cross-correlation can be defined as an operator C\u2191k such that for any f \u2208 Lp(X):\nC\u2191k : f 7\u2192 C \u2191 kf, C \u2191 kf : g 7\u2192 \u222b X f(x)k(g\u22121x)\u03b4(g\u22121)d\u00b5X(x), \u2200g \u2208 G (5)\nwhere \u03b4 : G \u2192 R\u00d7>0 records the change of variables by the action of G (see A.2). Group crosscorrelation C\u22c6k := Ck and convolution C \u2217 k operators will be defined for any f \u2208 Lp(G):\nCk : f 7\u2192 Ckf, Ckf : g 7\u2192 \u222b G f(g\u0303)k(g\u22121g\u0303)d\u00b5G(g\u0303), \u2200g \u2208 G (6)\nC\u2217k : f 7\u2192 C\u2217kf, C\u2217kf : g 7\u2192 \u222b G f(g\u0303)k(g\u0303\u22121g)d\u00b5G(g\u0303), \u2200g \u2208 G (7)\nLie algebra parametrization The tangent space at the identity of a Lie group G is denoted by g and called the Lie algebra of G. A Lie algebra is a vector space equipped with a bilinear map [\u00b7, \u00b7] : g \u00d7 g \u2192 g called the Lie bracket. To construct an equivariant layer using the Lie algebra of the group, one defines the kernels k(\u00b7) in (6) or (7) as functions which take in Lie algebra elements. This requires a map \u03be : g \u2192 G which is (at least locally) a diffeomorphism, with an inverse that can be easily calculated, preferably in closed-form. This allows us to rewrite the kernel k : G\u2192 R as:\nk(g\u22121g\u0303) = k(\u03be(\u03be\u22121(g\u22121g\u0303))) = k\u0303\u03b8(\u03be \u22121(g\u22121g\u0303)) (8)\nk\u0303\u03b8(\u00b7) is effectively an approximation of k(\u00b7) of the form k\u0303\u03b8 \u223c= k \u25e6 \u03be : g \u2192 R with learnable parameters \u03b8. Using the inverse map \u03be\u22121(g\u22121g\u0303), k\u0303\u03b8 maps the Lie algebra coordinates of the \u2018offset\u2019 group element g\u22121g\u0303 (for cross-correlations) to real values corresponding to the evaluation k(g\u22121g\u0303). Our kernels are now maps k\u0303\u03b8\u25e6\u03be\u22121 : G\u2192 R, requiring the implementation of \u03be\u22121(\u00b7) and a particular choice for the Lie algebra kernel k\u0303\u03b8. This description encompasses recent proposals for Lie group equivariant layers. In Bekkers (2019) the kernels are implemented by modelling k\u0303\u03b8 via B-splines, while Finzi et al. (2020) choose to parametrize k\u0303\u03b8 as small MLPs. Once k\u0303\u03b8 and \u03be are chosen, we can approximate e.g. the cross-correlation using Monte Carlo integration:\u222b\nG\nf(g\u0303)k\u0303\u03b8(\u03be \u22121(g\u22121g\u0303))d\u00b5G(g\u0303) \u2248\n\u00b5G(G)\nN N\u2211 i=1 f(g\u0303i)k\u0303\u03b8(\u03be \u22121(g\u22121g\u0303i)), g\u0303i \u223c \u00b5G (9)\nwhere \u00b5G(G) denotes the volume of the integration space G and g\u0303i \u223c \u00b5G indicates that g\u0303i is sampled (uniformly) with respect to the Haar measure. This allows one to obtain equivariance (in expectation) with respect to G. For compact groups, \u00b5G can be normalized such that \u00b5G(G) = 1. To summarize, we record the components of the framework which are needed for (9) to realize an equivariant operator. Namely, we require (1) a parametrization map \u03be\u22121 : G \u2192 g, as well as (2) the implementation of an efficient sampling scheme with respect to the Haar measure \u00b5G such that numerical integration is feasible in practice."
        },
        {
            "heading": "4 LIE GROUP DECOMPOSITIONS FOR CONTINUOUS EQUIVARIANCE",
            "text": "Limitations of the group exponential For every Lie group we can define the Lie group exponential map expm : g \u2192 G, which is a diffeomorphism locally around 0 \u2208 g. Since we are interested in GL(n,R) and its subgroups, we can make things more concrete as follows. Mnn(R) := Mn(R) (the vector space of n \u00d7 n real matrices) is the Lie algebra of GL(n,R) (Sec. B.1). The notation gl(n,R) = Mn(R) is used for this identification. For G = GL(n,R) with g = gl(n,R), the group exponential is the matrix exponential expm : gl(n,R) \u2192 GL(n,R), with the power series expressionX 7\u2192 eX = \u2211\u221e k=0 1 k!X\nk. The map \u03be in (8) is most commonly implemented as the group exponential \u03be := expm. Given a subgroup G \u2264 GL(n,R) for which expm is surjective, every element g \u2208 G can be expressed as g = expm(X) = eX for X \u2208 g, and fast routines for calculating expm(\u00b7) are available. In this case, the inverse map \u03be\u22121 is given by the matrix logarithm, giving us:\n\u03be\u22121(g\u22121g\u0303) = logm(g\u22121g\u0303), logm : G\u2192 g (10)\nIn general, we need to consider if both \u03be and \u03be\u22121 need to be implemented, and whether these maps are available in closed form. Assuming there exist X and Y such that eX = g\u22121 and eY = g\u0303, (10) can be rewritten as logm(g\u22121g\u0303) = logm(eXeY ). A key optimization underlying this framework is enabled by employing the BCH formula (B.1), which tells us that for abelian Lie groups logm(eXeY ) = X + Y . This simplifies calculations considerably and allows one to work primarily at the level of the Lie algebra, bypassing the need to calculate and sample the kernel inputs g\u22121g\u0303 at the group level. Considering the affine Lie groups Aff(G), G \u2264 GL(n,R), this simplification can be used for example for the abelian groupsG = SO(2) andG = R\u00d7(2)\u00d7SO(2), consisting of rotations and scaling. Bekkers (2019); Finzi et al. (2020) primarily work with these groups, and choose \u03be and \u03be\u22121 to be the matrix exponential and logarithm, respectively. If the group is non-abelian but the exponential remains surjective (such as with compact groups like SO(3)), expm(\u00b7) remains a generally valid choice for \u03be as long as \u03be\u22121 can be accurately calculated in closed-form. For the non-abelian, non-compact groups SL(n,R) or GL+(n,R) the non-surjectivity of the exponential map limits the applicability of the matrix logarithm outside of a neighborhood around the identity (Prop. B.2). The class of equivariant networks that can be implemented with this framework is then firstly limited by the parametrization maps \u03be and \u03be\u22121, motivating the search for an alternative.\nAnother key limitation is that for (9) to realize an equivariant estimator when numerically approximating the convolution/cross-correlation integral, sampling needs to be realised with respect to the Haar measure of the group G. Techniques for sampling with respect to the Haar measure on the groups SO(n) or R\u00d7(n) \u00d7 SO(n) are known, and generally reduce to working with uniform measures on Euclidean spaces or unit quaternions in the case of SO(3). We aim to address these limitations, allowing the previously described framework to be generalized to arbitrary Lie groups G \u2264 GL(n,R). We further seek a solution that places minimal limitations on the class of \u2018Lie algebra kernels\u2019 k\u03b8 : g \u2192 R that can be used, and one should be able to employ any k\u03b8 that uses the coordinates of tangent vectors in g expressed in some basis. In the following we present a set of generally applicable tools while considering SL(n,R) and GL+(n,R) as working examples, since these groups require more consideration and represent our primary application."
        },
        {
            "heading": "4.1 LIE GROUP DECOMPOSITION THEORY",
            "text": "We exploit the fact that the groups GL+(n,R) and SL(n,R) have an underlying product structure that allows them to be decomposed into subgroups and submanifolds which are easier to work with individually. More precisely, G \u2208 {GL+(n,R),SL(n,R)} can be decomposed as a product P \u00d7H , where H \u2264 G is the maximal compact subgroup of G and P \u2286 G is a submanifold which is diffeomorphic to Rk, for some k \u2265 0, and we have a diffeomorphism \u03c6 : P \u00d7H \u2192 G.\nSimilar decompositions are available for a larger class of groups G \u2264 GL(n,R) (Abbaspour & Moskowitz, 2007, Ch. 6). It can be shown that if the map \u03c6 is chosen correctly the Haar measure \u00b5G can be expressed as the pushforward measure\u03c6\u2217(\u00b5P\u2297\u00b5H), where \u00b5P is aG-invariant measure on P and \u00b5H is the Haar measure onH . In some cases the group decomposition presents a corresponding Lie algebra decomposition, which we can leverage to build the parametrization map \u03be\u22121 : G\u2192 g.\nFactorizing the Haar measure Let G be a locally compact group of interest (e.g. GL+(n,R)), with (left) Haar measure \u00b5G. Assume there exist a set of subspaces or subgroups P \u2286 G, K \u2286 G, such that G = PK, and a homeomorphism \u03c6 : P \u00d7 K \u2192 G. Further assume that \u00b5P and \u00b5K are (left) G-invariant Radon measures on the corresponding spaces. We look to express (up to multiplicative coefficients) the Haar measure \u00b5G as the pushforward of the product measure \u00b5P\u2297\u00b5K under the map \u03c6. This allows for the following change of variables for any f \u2208 L1(G):\u222b\nG f(g)d\u00b5G(g) = \u222b P\u00d7K f(\u03c6(p, k))d(\u00b5P \u2297 \u00b5K)(p, k) = \u222b P \u222b K f(\u03c6(p, k))d\u00b5K(k)d\u00b5P (p) (11)\nIn the context of Monte Carlo simulation this will enable us to produce random samples distributed according the measure \u00b5G by sampling on the independent factor spaces P and K and constructing a sample on P \u00d7 K and respectively on G using the map \u03c6. The space P will either be another closed subgroup, or a measurable subset P \u2286 G that is homeomorphic to the quotient space G/K. In particular, if P is not a subgroup, we will focus on the case where P is a homogeneous space of G with stabilizerK such that P \u223c= G/K. When the left and right Haar measure of a group coincide, the group is called unimodular. The groups GL+(n,R), SL(n,R) are unimodular, however this is not true for all affine groups Aff(G). For groups which are volume-preserving, this is not as much of an issue in practice. However, GL+(n,R) is not volume-preserving, and we also desire that our framework be general enough to deal with the non-unimodular case as well. If G is not unimodular and \u00b5G is its left Haar measure, there exists a continuous group homomorphism \u2206G : G \u2192 R\u00d7>0, called the modular function of G, which records the degree to which \u00b5G fails to be right-invariant. We now have the tools necessary to record two possible integral decomposition methods. Theorem 4.1. (1) Let G be a locally compact group, H \u2264 G a closed subgroup, with left Haar measures \u00b5G and \u00b5H respectively. There is a G-invariant Radon measure \u00b5G/H on G/H if and only if \u2206G|H = \u2206H . The measure \u00b5G/H is unique up to a scalar factor and if suitably normalized:\u222b\nG f(g)d\u00b5G(g) = \u222b G/H \u222b H f(gh)d\u00b5H(h)d\u00b5G/H(gH), \u2200f \u2208 L1(G) (12)\n(2) Let P \u2264 G, K \u2264 G closed subgroups such that G = PK. Assume that P \u2229K is compact, and Z0 denotes the stabilizer of the transitive left action of P \u00d7 K on G given by (p, k) \u00b7 g = pgk\u22121, for any (p, k) \u2208 P \u00d7 K and g \u2208 G. Let G, P and K be \u03c3-compact (which holds for matrix Lie groups), \u00b5G, \u00b5P and \u00b5K left Haar measures on G, P , and K respectively and \u2206G|K = \u039b is the modular function of G restricted to K. Then \u00b5G is given by \u00b5G = \u03c0\u2217(\u00b5P \u2297 \u039b\u22121\u00b5K), where \u03c0 : P \u00d7K \u2192 (P \u00d7K)/Z0 is the canonical projection. In integral form we have:\u222b\nG f(g)d\u00b5G(g) = \u222b P \u222b K f(pk) \u2206G(k) \u2206K(k) d\u00b5K(k)d\u00b5P (p), \u2200f \u2208 L1(G) (13)\nProof. Folland (2016, Theorem 2.51) and Wijsman (1990, Proposition 7.6.1).\nThe existence and range of the convolution operators (for arbitrary Lie groups G) are described in Sec. A.2.1, with the non-unimodular case being covered by Prop. A.3. When going to the Lie group setting, we can already deal with semi-direct products of groups of the form N \u22ca G. The modular function on N \u22ca G is \u2206N\u22caG(n, g) = \u2206N (n)\u2206G(g)\u03b4(g)\u22121 (Kaniuth & Taylor, 2013). The term \u03b4 : G \u2192 R\u00d7>0 records the effect of the action of G on N , and it coincides with the term \u03b4(\u00b7) used in the lifting layer definition (27). Concretely, take the affine groups Aff(G) = Rn \u22ca G, G \u2264 GL(n,R), defined under the semi-direct product structure:\nAff(G) = Rn \u22caG = {(x,A) | x \u2208 Rn, A \u2208 G} (14) G acts on Rn by matrix multiplication and for (x,A), (y,B) \u2208 Aff(G), the product and inverse are:\n(x,A)(y,B) = (x+Ay,AB), (x,A)\u22121 = (\u2212A\u22121x,A\u22121) (15)\nElements of Rn are concretely represented as column vectors. Viewing (Rn,+) as the additive group, we have \u03b4 : G\u2192 R\u00d7>0 given by \u03b4(A) = |det(A)| for any A \u2208 G. Applying Thm. 4.1, gives:\u222b\nAff(G) f(g) d\u00b5Aff(G)(g) = \u222b G \u222b Rn f((x,A)) dxd\u00b5G(A) |det(A)| , \u2200f \u2208 Cc(Aff(G)) (16)\nExpressing the cross-correlation Ckf of (7) in this product space we have for f \u2208 L2(Aff(G)): Ckf : (x,A) 7\u2192 \u222b G \u222b Rn f(x\u0303, A\u0303)k((x,A)\u22121(x\u0303, A\u0303))\u03b4(A\u0303\u22121)dx\u0303d\u00b5G(A\u0303) (17)\nFor the affine groups Aff(G) = Rn \u22ca G a parametrization map \u03beAff(G) : Rn \u2295 g \u2192 Aff(G) will simply be the identity on the first factor, since the Lie algebra of Aff(GL(n,R)) decomposes as Rn \u2295 gl(n,R) when represented as a Lie subalgebra of gl(n + 1,R). We are then left with the parametrization and invariant integration of the G-factor of Aff(G). We provide a solution for the cases G = SL(n,R) and G = GL+(n,R), while remarking that a solution for GL+(n,R) can be immediately extended to GL(n,R) (Sec. B.4). Our approach is based on a generalized Polar decomposition of matrices, which is applicable in the case of reductive (GL+(n,R)) or semi-simple (SL(n,R)) Lie groups. An alternative decomposition is discussed in Sec. B.6.1.\nManifold splitting via Cartan/Polar decomposition Let Sym(n,R) be the vector space of n\u00d7 n real symmetric matrices and Pos(n,R) the subset of Sym(n,R) of symmetric positive definite (SPD) matrices. Denote by SPos(n,R) the subset of Pos(n,R) consisting of SPD matrices with unit determinant, and by Sym0(n,R) the subspace of Sym(n,R) of traceless real symmetric matrices. Any matrix A \u2208 GL(n,R) can be uniquely decomposed via the left polar decomposition as A = PR where P \u2208 Pos(n,R) and R \u2208 O(n) (B.4). The factors of this decomposition are uniquely determined and we have a bijection GL(n,R) \u2192 Pos(n,R)\u00d7 O(n) given by:\nA 7\u2192 ( \u221a AAT , \u221a AAT \u22121 A), \u2200A \u2208 GL(n,R) (18)\nFor the reader unfamiliar with Lie group structure theory, the following results can simply be understood in terms of matrix factorizations commonly used in numerical linear algebra. The polar decomposition splits the manifold GL+(n,R) into the product Pos(n,R)\u00d7 SO(n), and SL(n,R) into SPos(n,R)\u00d7SO(n). We use the notationG\u2192M\u00d7H to cover both cases. This decomposition can be generalized, as the spaces Pos(n,R) = GL+(n,R)/SO(n) and SPos(n,R) = SL(n,R)/SO(n) are actually symmetric spaces, and a Cartan decomposition is available in this case (B.4). The Cartan decomposition tells us how to decompose not only at the level of the Lie group, but also at the level of the Lie algebra. In fact, using this decomposition we can also obtain a factorization of the measure on these groups. Let (G/H,M,m) define our \u2018Lie group data\u2019, corresponding to (GL+(n,R)/SO(n),Pos(n,R),Sym(n,R)) or (SL(n,R)/SO(n),SPos(n,R),Sym0(n,R)). Theorem 4.2. Let (G/H,M,m) be as above, and denote by g, h the Lie algebras of G and H .\n1. The matrix exponential and logarithm are diffeomorphisms between m andM , respectively. For any P \u2208M and \u03b1 \u2208 R, the power map P 7\u2192 P\u03b1 is smooth and can be expressed as:\nP\u03b1 = expm(\u03b1logm(P )), \u2200P \u2208 Pos(n,R) (19)\n2. G \u223c=M \u00d7H and G \u223c= m\u00d7H . We have group-level diffeomorphisms: \u03c7 :M \u00d7H \u2192 G, \u03c7(P,R) 7\u2192 PR (20)\n\u03a6 : m\u00d7H \u2192 G, \u03a6 : (X,R) 7\u2192 expm(X)R = eXR (21)\n3. The above maps can be inverted in closed-form:\n\u03c7\u22121 : G\u2192M \u00d7H, \u03c7\u22121 : A 7\u2192 ( \u221a AAT , \u221a AAT \u22121 A) (22)\n\u03a6\u22121 : G\u2192 m\u00d7H, \u03a6\u22121 : A 7\u2192 (1 2 logm(AAT ), expm(\u22121 2 logm(AAT ))A) (23)\nSee (B.5) for proofs and references. At the level of the Lie algebra, we have the decomposition gl(n,R) = so(n) \u2295 Sym(n,R). The Lie algebra of SL(n,R) is sl(n,R) = {X \u2208 gl(n,R) | tr(X) = 0}. It decomposes similarly sl(n,R) = so(n)\u2295 Sym0(n,R). Then h = so(n) with m = Sym(n,R) if G = GL+(n,R) and m = Sym0(n,R) if G = SL(n,R)."
        },
        {
            "heading": "4.2 A PARAMETRIZATION BASED ON THE CARTAN DECOMPOSITION",
            "text": "Consider again the notation (G/H,M,m) as in Theorem 4.2 (G = GL+(n,R) or G = SL(n,R)).\nConcrete integral decompositions From Theorem 4.2 and the fact that symmetric matrices have a unique square root, we actually have equivalent decompositions for A \u2208 G as A = PR or A = S1/2R for S, P \u2208 M , R \u2208 H and P = S1/2. For GL(n,R), the decomposition A = S1/2R, has a factorization of the Haar measure of GL(n,R) as a product of invariant measures on Pos(n,R) (shortened Pos(n)) and O(n). Let \u00b5Pos(n) denote the GL(n,R) invariant measure on Pos(n). Theorem 4.3. Denote G = GL(n,R), H = O(n), and let \u00b5G be the Haar measure on G and \u00b5H the Haar measure on H normalized by Vol(H) = 1. For A \u2208 G, under the decomposition A = S1/2R, S \u2208 Pos(n), R \u2208 H , the measure on G splits as d\u00b5G(A) = \u03b2nd\u00b5Pos(n)(S)d\u00b5H(R), where \u03b2n = Vol(O(n)) 2n is a normalizing constant. Restricting to G = GL\n+(n,R) and H = SO(n) and ignoring constants, we have:\nf 7\u2192 \u222b G f(A)d\u00b5G(A) = \u222b Pos(n) \u222b H f(S1/2R)d\u00b5H(R)d\u00b5Pos(n)(S), \u2200f \u2208 Cc(G) (24)\nThe Haar measure of GL(n,R) is d\u00b5GL(n,R)(A) = |det(A)|\u2212ndA, with dA the Lebesgue measure on Rn2 . We now describe how to sample on the individual factors to obtain GL(n,R) samples. Theorem 4.4. If a random matrix A \u2208 GL(n,R) has a left-O(n) invariant density function relative to |AAT |\u2212n/2dA, then (AAT )1/2 = S1/2 andR = (AAT )\u22121/2A are independent random matrices and R has a uniform probability distribution on O(n). The uniform distribution on O(n) will be the normalized Haar measure \u00b5O(n). Conversely, if S \u2208 Pos(n) has a density function f : Pos(n) \u2192 R\u22650 relative to \u00b5Pos(n) and R \u2208 O(n) is uniformly distributed with respect to the Haar measure \u00b5O(n), then A = S1/2R has a density function \u03b2\u22121n f(AA T )|det(A)|\u2212n relative to dA.\nTheorems 4.3 and 4.4 are known results that appear in the random matrix theory literature, but have not seen recent application in the context of deep learning. In (B.6) we provide more details and references. Using the decomposition A = S1/2R invariant integration problems on G can be transferred to the product space M \u00d7 H , and we can express up to normalization the invariant measure \u00b5G as \u03c6\u2217(\u00b5M \u2297 \u00b5H). To construct samples {A1, . . . ,An} \u223c \u00b5G one produces samples {R1, . . . ,Rn} \u223c \u00b5H where \u00b5H will be the uniform distribution on H , and samples {M1, . . . ,Mn} \u223c \u00b5M . Then \u00b5G-distributed random values are obtained by {A1, . . . ,An} = {\u03c6(M1,R1), . . . , \u03c6(Mn,Rn)}, where again \u03c6 :M \u00d7H \u2192 G is given by \u03c6 : (S,R) 7\u2192 S1/2R.\nMapping to the Lie algebra and back Any A \u2208 G can be expressed uniquely as A = eXR for x \u2208 m and R \u2208 H . Since H = SO(n) in both cases, the fact that expm : so(n) \u2192 SO(n) is surjective, allows us to write it A = eXeY , Y \u2208 so(n). The factors X and R = eY are obtained using \u03a6\u22121 (22). Then by taking the principal branch of the matrix logarithm on H = SO(n), Y = logm(R). A map \u03be\u22121 : G \u2192 g as described in (8) and (9) is constructed as \u03be\u22121 = (idm \u00d7 logm) \u25e6 \u03a6\u22121. More precisely, for any A = eXeY \u2208 G, using \u03be\u22121 we obtain the tangent vectors (Y,X) \u2208 so(n)\u00d7m and since g = so(n)\u2295m we have a unique Z = X + Y \u2208 g. Details are given in (B.7).\nDefine K\u0303\u03b8 := k\u03b8 \u25e6 \u03be\u22121 : G \u2192 R as our Lie algebra kernel. A Monte Carlo approximation of a cross-correlation operator Ck : L2(G) \u2192 L2(G) as in (9) will be of the form:\nCkf : g 7\u2192 1\nN N\u2211 i=1 f(g\u0303i)K\u0303\u03b8(g\u0303 \u22121 i g), g\u0303i \u223c \u00b5G, \u2200g \u2208 G (25)\nFor affine groups, every element (x,A) of Rn \u22ca G, can be uniquely decomposed as (x, I)(0, A), with I the n\u00d7 n identity matrix. One can use the fact that L(x,A) = L(x,I)L(0,A) to write:\nk((x,A)\u22121(x\u0303, A\u0303)) = L(x,A)k(x\u0303, A\u0303) = L(x,I)[L(0,A)k(x\u0303, A\u0303)] = Lx[k(A\u22121x\u0303, A\u22121A\u0303)] (26) An efficient implementation of a convolutional layer can be realised in practice for n \u2208 {2, 3} by first obtaining the transformed kernel k(A\u22121x\u0303, A\u22121A\u0303) and then applying the translation Lx using an efficient convolution routine, as done for example in Cohen & Welling (2016); Bekkers (2019).\nIn practice, the exact discretization of the translation factor Rn will depend on the support of the input data. For example, if our input signals are defined compactly on a grid (e.g. 2D images), we can approximate a continuous convolution (Finzi et al., 2020) by sampling the translation factor in a uniform grid of coordinates x\u0303 \u223c [\u22121, 1]n \u2282 Rn as the parametrization \u03beAff(G) : Rn\u00d7gl(n,R) \u2192 G is the identity map for the first factor. We can then approximate a lifting cross-correlation layer by:\nC\u2191kf : (x,A) 7\u2192 \u222b Rn f(x\u0303)Lxk(A\u22121x\u0303)\u03b4(A\u22121)dx\u0303 (27)\n\u2248 1 N N\u2211 i=1 f(x\u0303i)Lx[k\u03b8(A\u22121x\u0303i)\u03b4(A\u22121)], xi \u223c [\u22121, 1]n (28)\nFor the non-lifting layers, starting from (17), denoting dA\u0303 = d\u00b5G(A\u0303) and applying (26) we have:\n[Ckf ](x,A) = \u222b Rn \u222b G f(x\u0303, A\u0303)Lxk(A\u22121x\u0303, A\u22121A\u0303)\u03b4(A\u0303\u22121)dx\u0303dA\u0303 (29)\nUsing Theorem 4.3, denote the invariant measures \u00b5M and \u00b5H by dS and dR, we obtain:\n[Ckf ](x,A) = \u03b2n \u222b Rn \u222b H \u222b M f(x\u0303, S1/2R)Lxk(A\u22121x\u0303, A\u22121S1/2R)\u03b4(S\u22121/2)dSdRdx\u0303 (30)\nThe kernel in (25) is now of the form K\u03b8 : Rn \u22caG\u2192 R, giving us:\n[Ckf ](x,A) \u2248 V\nN N\u2211 i=1 f(x\u0303i, S 1/2 i Ri)Lx[K\u03b8(A \u22121x\u0303i, \u03be \u22121(A\u22121S 1/2 i Ri))\u03b4(S \u22121/2 i )] (31)\nwhere x\u0303i \u223c [\u22121, 1]n, Si\u00d7Ri \u223c (\u00b5M \u2297\u00b5H), andRi sampled uniformly with respect \u00b5H . V records both the volume of the integration space from the MC approximation as well as the constant \u03b2n."
        },
        {
            "heading": "5 EXPERIMENTS",
            "text": "For all experiments we use a ResNet-style architecture, replacing convolutional layers with crosscorrelations that are equivariant (in expectation) with respect to the groups R2 \u22ca GL+(2,R) and R2 \u22ca SL(2,R). Details regarding the network architecture and training are given in Appendix D.\nAffine-transformation invariance We evaluate our model on a benchmark affine-invariant image classification task employing the affNIST dataset1. The main works we compare with are the affineequivariant model of MacDonald et al. (2022) and the Capsule Networks Ribeiro et al. (2020a;b) which are state of the art for this task. The experimental setup involves training on the standard set of 50000 non-transformed MNIST images (padded to 40\u00d7 40), and evaluating on the affNIST test set, which consists of 320000 affine-transformed MNIST images. The model never sees the transformed affNIST images during training, and we do not use any data augmentation techniques. In this case, robustness with respect to the larger groups of the affine family of transformations is needed. For a fair comparison we roughly equalize the number of parameters with the referenced models.\nTable 1 reports the average test performance of our model at the final epoch, over five training runs with different initialisations. We observe that our equivariant models are robust and generalize well, with the R2\u22caSL(2,R) model outperforming all previous equivariant models and Capsule Networks. Note that, compared to MacDonald et al. (2022), our sampling scheme requires 10 times less samples to realize an accurate Monte Carlo approximation of the convolution. The R2 \u22ca GL+(2,R) model performs slightly worse than the volume-preserving affine group R2 \u22ca SL(2,R). This can be explained by considering that the affNIST dataset contains only a small degree of scaling.\nHomography transformations We further evaluate and report in Table 2 the performance of the same model evaluate on the homNIST dataset of MacDonald et al. (2022). The setup is identical to the affNIST case, with the images now being transformed by random homographies. We observe a similar degree of robustness in this case, again outperforming previous methods applied to this task.\nAs our models are only equivariant in expectation, we analyze numerically in Sec. D the degree to which the equivariance error is dependent on the number of Monte Carlo samples used to approximate the convolution/cross-correlation integral."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "We have built a framework for constructing equivariant networks when working with matrix Lie groups that are not necessarily compact or abelian. Using the structure theory of semisimple/reductive Lie groups we have shown one possible avenue for constructing invariant/equivariant (convolutional) layers primarily relying on tools which allow us to decompose larger groups into smaller ones. In our preliminary experiments, the robustness and out-of-distribution capabilities of the equivariant models were shown to outperform previous proposals on tasks where the symmetry group of relevance is one of GL+(n,R) or SL(n,R).\nOur contribution is largely theoretical, providing a framework by which equivariance/invariance to complex symmetry groups can be obtained. Further experiments will look to validate the applicability of our method to other data modalities, such as point clouds or molecules, as in Finzi et al. (2020).\nWhile we have primarily focused on convolution operators, we remark that the tools explored here are immediately applicable to closely-related machine learning models which employ Lie groups and their regular representation for invariance/equivariance. For example, the \u2018LieTransformer\u2019 architecture proposed in Hutchinson et al. (2021) opts to replace convolutional layers with selfattention layers, while still using the Lie algebra of the group as a mechanism for incorporating positional information. They face the same challenge in that their parametrization is dependent on the mapping elements back and forth between a chosen Lie group and its Lie algebra, and they require a mechanism for sampling on the desired group. The methods presented here are directly applicable in this case.\nFuture work will explore expanding the class of Lie groups employed by such models using the tools presented here. Another potential avenue to explore is the applicability of the presented tools to the problem of \u2018partial\u2019 and \u2018learned\u2019 invariance/equivariance (Benton et al., 2020). The sampling mechanism of the product decomposition allows one to specify a probability distribution for the nonorthogonal factor, which could be learned from data."
        },
        {
            "heading": "APPENDIX",
            "text": ""
        },
        {
            "heading": "A ADDITIONAL BACKGROUND",
            "text": "A symmetry group refers to a set of transformations which preserve some underlying structure present in the data. Formally, a group G is a set together with an associative binary operation G \u00d7 G \u2192 G which tells us how group elements can be composed to form another. Every element g \u2208 G has an inverse g\u22121 \u2208 G, and the group has an identity element e \u2208 G such that gg\u22121 = e."
        },
        {
            "heading": "A.1 TOPOLOGICAL GROUPS AND THE HAAR MEASURE",
            "text": "A Hausdorff2 topological space M is locally compact if each point m \u2208 M has a compact neighborhood. A topological group G is a group as well as a Hausdorff topological space such that the group operation (g, h) 7\u2192 gh and inversion map g 7\u2192 g\u22121 are continuous. For the following and more details on Radon measures see Folland (1999); Lang (2012).\nRadon measures Let (X,BX , \u00b5) be a measure space with Hausdorff topological spaceX , BX the \u03c3-algebra of Borel sets and \u00b5 : BX \u2192 [0,\u221e] any measure on BX (referred to as a Borel measure). The measure \u00b5 is called locally finite if every point x \u2208 X has an open neighborhood U \u220b x for which \u00b5(U) <\u221e. A Borel set E \u2286 X (E \u2208 BX ) is called inner regular if:\n\u00b5(E) = sup{\u00b5(K) | K \u2286 E, K compact} (32) Respectively, a Borel set E \u2286 X is called outer regular if:\n\u00b5(E) = inf{\u00b5(V ) | V \u2287 E, V open} (33) The measure \u00b5 is called inner (outer) regular if all Borel sets are inner (outer) regular. It is called regular if it is both inner and outer regular. \u00b5 is a Radon measure if it is locally finite, inner regular on open sets and outer regular. \u00b5 is \u03c3-finite if there exists a countable family of Borel sets {Bn}n\u2208N, where \u00b5(Bn) <\u221e, \u2200n \u2208 N and \u22c3 n\u2208N Bn = X . If \u00b5 is a Borel measure on a Hausdorff topological space X , local finiteness will imply that \u00b5 is finite on compact subsets of X . Theorem A.1. 3 Every locally compact group G has a left (right) nonzero Radon measure \u00b5G such that \u00b5G(gB) = \u00b5G(B) (respectively \u00b5G(Bg) = \u00b5G(B)) for any Borel subset B \u2286 G and any g \u2208 G. The measure \u00b5G is called the left (right) Haar measure of G and if \u03bdG is another Haar measure on G, then \u00b5G = c \u00b7 \u03bdG for some c \u2208 R>0.\nWhen integrating with respect to the left Haar measure \u00b5G we have for any f \u2208 Cc(G):\u222b G f(yx)d\u00b5G = \u222b G f(x)d\u00b5G, \u2200y \u2208 G (34) All of the groups and topological spaces in the main text will be \u03c3-compact. A locally compact space X is \u03c3-compact (or countable at infinity) if it is a countable union of compact subsets. We will use the notation \u00b5G to refer to the left Haar measure and when needed the notation \u00b5L(\u00b7) and \u00b5R(\u00b7) will be used to differentiate left and right Haar measures. Remark A.2. If X is a homogeneous space of G (but not G itself), then a G-invariant Radon measure d\u00b5X on X (if it exists) respects the same invariance property presented in Thm. A.1 and (34), and we simply refer to d\u00b5X as a G-invariant measure. For a review of such measures, see (Folland, 2016, Chapter 2.6).\nFunction spaces Suppose (X,BX , \u00b5) is a measure space where X is locally compact Hausdorff space and \u00b5 a Radon measure on X . Lp\u00b5(X,R) := Lp(X) for 1 <= p < \u221e denotes the space of equivalence classes of functions {f : X \u2192 R | f Borel measurable and \u222b X |f |pd\u00b5 < \u221e}\nthat agree \u00b5-almost everywhere. Equipped with the norm \u2225f\u2225p = ( \u222b X |f |pd\u00b5)1/p, Lp(X) is a Banach space. C(X) := C(X,R) denotes the space of continuous real-valued functions on X . The support of f \u2208 C(X) is defined as supp(f) = {x \u2208 X | f(x) \u0338= 0}. We state that a function f has compact support whenever supp(f) is compact. Cc(X) denotes the subspace ofC(X) of continuous functions with compact support.\n2A topological space where any two distinct points have disjoint neighbourhoods is called Hausdorff. 3See Proposition 2.9 and Theorems 2.10 & 2.20 of Folland (2016)."
        },
        {
            "heading": "A.2 EQUIVARIANT CONVOLUTIONAL OPERATORS",
            "text": "In this section we show that the convolution/cross-correlation operators (6), (7) as well as the lifting cross-correlation (5) are equivariant. We then clarify the existence and range of these operators. For a non-lifting convolution/cross-correlation operator, recall that X = Y = G and k : Y \u00d7X \u2192 R is a bi-invariant kernel:\nk(gx, gy) = k(x, y), \u2200(x, y) \u2208 Y \u00d7X, \u2200g \u2208 G (35)\n\u00b5X is a G-invariant Radon measure on X . The operator Ck was defined for any f \u2208 L1\u00b5X (X): Ck : f 7\u2192 Ckf(y) = \u222b X f(x)k(x, y)d\u00b5X(x), \u2200y \u2208 Y (36)\nCk : f 7\u2192 Ckf maps an element of L1(X) to L1(G), respecting Lg \u25e6Ck = Ck \u25e6 Lg for any g \u2208 G: Lg(Ckf)(y) = Ckf(g\u22121y) = \u222b X f(x)k(x, g\u22121y)d\u00b5X(x) (37)\n(Haar invariance) = \u222b X f(g\u22121x)k(g\u22121x, g\u22121y)d\u00b5X(x) (38)\n(Kernel bi-invariance) = \u222b X f(g\u22121x)k(x, y)d\u00b5X(x) = Ck(Lg[f ])(y) (39)\nA lifting cross-correlation operator C\u2191k was defined for f \u2208 L1(X) by:\nC\u2191k : f 7\u2192 C \u2191 kf, C \u2191 kf : g 7\u2192 \u222b X f(x)k(g\u22121x)\u03b4(g\u22121)d\u00b5X(x), \u2200g \u2208 G (40)\nwhereX is a homogeneousG-space with Radon measure d\u00b5X and \u03b4 : G\u2192 R\u00d7>0 records the change of variables produced by the action of G:\u222b\nX f(x)d\u00b5X(x) = \u222b X f(gx)\u03b4(g)d\u00b5X(x) (41)\nIn the case whereX = Rn and Y = Aff(G), for Aff(G) the semi-direct product Aff(G) = Rn \u22caG, G \u2264 GL(n,R), we have Aff(G) acting transitively on X , and we can make the identification X \u223c= Aff(G)/G. Each element g \u2208 Aff(G) can be represented as g = (x, h) with x \u2208 Rn, h \u2208 G. In this case, we have \u03b4(g) = |det(g)| = |det(h)|. Note that the form of the kernel can equivalently be derived through an equivariance constraint relation as in Bekkers (2019, Theorem 1). The lifting layer is then more concretely of the form C\u2191kf = f \u22c6 k where:\n(f \u22c6 k)(g) = \u222b Rn f(x)k(g\u22121x) dx |det(h)|\n(42)\nThe lifting layer is equivariant (Lg\u0303[f \u22c6 k] = [Lg\u0303f ] \u22c6 k), since for any g\u0303 = (x\u0303, h\u0303) \u2208 Aff(G) we have: Lg\u0303[f \u22c6 k](g) = (f \u22c6 k)(g\u0303\u22121g) = \u222b Rn f(x)k(g\u22121g\u0303x) dx |det(h\u0303\u22121h)| (43)\n(x 7\u2192 g\u0303\u22121x) = \u222b Rn f(g\u0303\u22121x)k(g\u22121x)|det(h\u0303\u22121)| dx |det(h\u0303\u22121h)| (44)\n= \u222b Rn Lg\u0303f(x)k(g\u22121x) dx |det(h)| = ([Lg\u0303f ] \u22c6 k)(g) (45)\nA similar derivation appears in MacDonald et al. (2022, Theorem 4.2). The lifting layer equivariance here was derived for the case where X is the homogeneous space Rn = Aff(G)/G, however a similar process is available for more general homogeneous spaces. One only has to identify the appropriate relatively invariant measure \u03b4(\u00b7)\u22121d\u00b5X which appears in (5). For more details on relatively invariant measures see Hewitt & Ross (2012)."
        },
        {
            "heading": "A.2.1 EXISTENCE AND RANGE OF CONVOLUTION OPERATORS",
            "text": "If G is a locally compact Hausdorff group, Cc(G) is dense in Lp(G) for 1 \u2264 p < \u221e4. We can therefore approximate functions in Lp(G) using functions in Cc(G). While some results hold in a more general setting, we assume that all topological groups are (locally) compact Hausdorff and second countable (and therefore \u03c3-compact), as the Lie groups of interest satisfy these properties.\nProposition A.3. 5 We record the following results concerning the existence and range of the convolution operators for a locally compact group G.\n1. If f \u2208 L1(G) and for any k \u2208 Lp(G) (1 <= p <= \u221e) then \u222b G f(g\u0303)k(g\u0303\u22121g)d\u00b5G(g\u0303)\nconverges absolutely, f \u2217 k \u2208 Lp(G) and \u2225f \u2217 k\u2225p \u2264 \u2225f\u22251\u2225k\u2225p.\n2. If G is not unimodular, f \u2208 Lp(G) and k \u2208 L1(G) \u2229 Cc(G) then f \u2217 k \u2208 Lp(G).\n3. If f, k \u2208 L2(G) then f \u2217 k \u2208 C0(G), see also (Hewitt & Ross, 2012, Theorem 20.16).\nFor the cross-correlation operator, if we define the involution f\u2217(g) = f(g\u22121), we can write f \u22c6k as f \u2217 k\u2217, and reuse the results of Proposition A.3. In the case of a nonunimodular semi-direct product group G = N \u22caH , where H is unimodular, the Haar measure is of the form \u00b5G = \u2206G \u00b7\u00b5N \u2297\u00b5H6. Since \u2206G : G \u2192 (0,\u221e) is unbounded, we therefore always make the assumption that the support of fk is a compact set where \u2206G is bounded.\nAssumption. We assume f, k \u2208 L1(G) \u2229 L2(G) and additionally k \u2208 Cc(G). When working with image data, one can also take f \u2208 Cc(G) directly. Going forward we therefore establish for p \u2208 {1, 2}, C\u2191k : Lp(X) \u2192 Lp(G) defined by (5) and C\u2217k or Ck are similarly operators Lp(G) \u2192 Lp(G) given by (6) and (7).\nThe restriction to a compact subset of G can also be motivated if we wish to employ a Monte Carlo approximation of the integral using a uniform distribution, since the Haar measure is finite on compact subsets. However, the restriction will not tied to the injectivity/surjectivity radius of the group exponential map, as we will use a different parametrization as shown in the main text."
        },
        {
            "heading": "A.3 RELATED WORK",
            "text": "The theory behind constructing equivariant convolutional layers when our input space is a homogeneous space of some locally compact topological group is covered in Cohen & Welling (2016); Kondor & Trivedi (2018); Cohen et al. (2019); Bekkers (2019). A differential geometric formulation not necessarily limited to homogeneous spaces is given in Weiler et al. (2021) and a review focused on the application of induced representations in the context of neural networks can be found in Kondor & Trivedi (2018); Cohen et al. (2019). Employing Monte Carlo integration to approximate convolution integrals has also been proposed e.g. in Hermosilla et al. (2018); Finzi et al. (2020); Romero et al. (2021); Knigge et al. (2022). In Hutchinson et al. (2021) the Lie algebra parametrization is employed with convolution operators being replaced with self-attention layers. Steerable CNNs make use of group representation theory to parametrise convolution kernels by solving a kernel steerability constraint Weiler & Cesa (2019); Lang & Weiler (2020).\nIn the context of finite-dimensional group representation Finzi et al. (2021) present a general solution for constructing equivariant MLPs. They present a framework for solving the equivariance constraint by making use of the generators of the Lie algebra of a group. The resulting linear system is solved for finite dimensional representations by using the singular value decomposition. More general solutions are developed in Bogatskiy et al. (2020); Batatia et al. (2023) for a wider class of Lie groups and representations.\nMacDonald et al. (2022) The limitations of previous Lie algebra methods (as reviewed in 4) are also discussed in MacDonald et al. (2022), which proposes a possible solution while still working with the group exponential. To overcome its lack of surjectivity and be able to sample with respect\n4(Folland, 1999, Proposition 7.9). 5(Folland, 2016, Propositions 2.40 & 2.41). 6Corresponds to Thm. 4.1(2) in integral form. A more precise reference is Wijsman (1990, Corollary 7.6.3).\nto the Haar measure of Aff(GL(n,R)) = Rn \u22ca GL(n,R), the domain of integration itself is restricted and the convolution integral is reformulated, ensuring that the group elements g\u0303\u22121g (using the convolution operator notation) are within the injectivity radius of the exponential map. This is done by first changing the convolution operator after the lifting layer to work with the right Haar measure7:\n(f \u2217 k)(g) = \u222b G f(g\u0303)k(g\u0303\u22121g)d\u00b5L(g\u0303) = \u222b G f(gg\u0303\u22121)k(g\u0303)d\u00b5R(g\u0303) (46)\nFor non-lifting layers instead of the kernel k(\u00b7), the feature map f(\u00b7) is now evaluated at f(gg\u0303\u22121). Proposition A.4. 8 Let G be a Lie group with Lie algebra g and suppose U \u2286 g is a neighborhood of 0 \u2208 g and expm(U) a neighborhood in e \u2208 G such that the group exponential expm : g \u2192 G is a diffeomorphism of U onto expm(U). For f \u2208 Cc(G) with support in expm(U) we have:\u222b\nG f(g)d\u00b5G(g) = \u222b g f(expm(X)) det ( 1\u2212 e\u2212ad\u2212X ad\u2212X )dX (47)\nwhere det ( 1\u2212e \u2212ad\u2212X\nad\u2212X ) is the Jacobian determinant of the differential of expm and dX is the\nLebesgue measure on g.\nThe change of variables of Proposition A.4 and the expression (46) allow MacDonald et al. (2022) to define the non-lifting convolutional layers to be of the form:\n(f \u2217 k)(g) = \u222b G f(gg\u0303\u22121)k(g\u0303)d\u00b5R(g\u0303) = \u222b g f(ge\u2212X))k\u0303\u03b8(X) det ( 1\u2212 e\u2212ad\u2212X ad\u2212X )dX (48)\nk\u0303\u03b8 is again a learnable map that takes in Lie algebra elements approximating k \u25e6expm : g \u2192 R. The difference here lies in the fact that one does not need to use the inverse map \u03be\u22121 to map back to g. By treating det ( 1\u2212e \u2212ad\u2212X\nad\u2212X ) as (proportional to) a density function, sampling is realised directly on the\nLie algebra using standard MCMC methods. One starts the sampling process from the outer-most convolution integral and rejects samples that lie outside of the support of the exponential map.\nWhile the approach can be applied to any matrix Lie group, in practice because every possible g\u0303\u22121g element must be precalculated and kept in memory before the forward pass, the scalability of the method is greatly limited due to its memory requirements. Further numerical errors are introduced due to the fact that det ( 1\u2212e \u2212ad\u2212X\nad\u2212X ) is approximated with limited precision by the power\nseries expression ( 1\u2212e \u2212ad\u2212X\nad\u2212X ) = \u2211\u221e k=0 (\u22121)k (k+1)! (adX)\nk. Additionally, while a discretization of the integral is always necessary, this approach is limited in that the domain of integration must still be restricted to the injectivity/surjectivity radius of the group exponential for the change of variables to apply. In this paper, we also employ a change of variables in the context of invariant integration with respect to the Haar measure. However, rather than working with the tangent space of the group as in Prop. A.4, we make use of group-level decompositions into independent factor spaces, and show that the Haar measure decomposes as a product of invariant measures, allowing us to construct a sampling scheme on the lower-dimensional subcomponents, as explained in Sections 4.1 and B.6."
        },
        {
            "heading": "B LIE GROUP DECOMPOSITIONS",
            "text": ""
        },
        {
            "heading": "B.1 LIE GROUPS",
            "text": "A Lie group G is a group as well as a smooth manifold, such that both the group operation and the inversion map are smooth. Lie groups are therefore second countable Hausdorff topological spaces. An abelian Lie group G is a Lie group and an abelian group, i.e. a group for which the order of the group operation does not matter gh = hg, \u2200g, h \u2208 G. Mnn(R) := Mn(R) denotes the vector space of n \u00d7 n matrices. It is canonically isomorphic to Rn2 , which is locally compact. Closed or open\n7See (MacDonald et al., 2022, Theorem 4.3) or (Folland, 2016, (2.32) & (2.36)). Here, we used the convolution operator to be consistent with the derivation of MacDonald et al. (2022).\n8(Helgason, 1984, Theorem 1.14), (MacDonald et al., 2022, Theorem 4.4).\nsubsets of Mn(R) will be locally compact with respect to the induced topology9. One such open subset is GL(n,R), the Lie group of invertible matrices:\nGL(n,R) = {X \u2208 Mn(R) | det(X) \u0338= 0} (49)\nThe notationH \u2264 G (H < G) is used to indicate thatH is a (proper) subgroup ofG, rather than just a (proper) subset H \u2286 G (H \u2282 G). We are only interested in closed Lie subgroups of GL(n,R). A (closed) Lie subgroup10 H of a Lie group G will refer to a closed subgroup and a submanifold of G (with the induced topology). A linear or matrix Lie group is defined to be a Lie subgroup of GL(n,R), and will therefore be locally compact and second countable. GL(n,R), the translation group (Rn,+) and the family of affine groups Rn \u22ca H , H \u2264 GL(n,R) are our primary interest, with H being one of the groups:\n\u2022 GL+(n,R) = {X \u2208 GL(n,R) | det(X) > 0}, the identity component of GL(n,R); It it also referred to as the positive general linear group;\n\u2022 SL(n,R) = {X \u2208 GL(n,R) | det(X) = 1}, the special linear group; \u2022 O(n) = {X \u2208 GL(n,R) | XTX = In}, the orthogonal group; \u2022 SO(n) = {X \u2208 O(n) | det(X) = 1}, the special orthogonal group.\nProposition B.1. 11 The group exponential map expm : g \u2192 G is smooth with d(expm)0 = id, making expm a diffeomorphism expm|U : U \u2192 V of some neighborhood U of 0 \u2208 g onto a neighborhood V of e \u2208 G.\nThe notation expm : g \u2192 G for the Lie group exponential is used to differentiate it from the Riemannian exponential, which is mentioned later on. Unless the group G can be equipped with a bi-invariant Riemannian metric, the exponentials do not coincide (see Proposition B.10). Mn(R) equipped with the matrix commutator [X,Y ] = XY \u2212Y X forX,Y \u2208 Mn(R) is a Lie algebra, and more precisely it is (canonically isomorphic to) the Lie algebra of GL(n,R)12. We use the notation gl(n,R) = Mn(R) when working with this identification. For G = GL(n,R) with g = gl(n,R), the group exponential is given by the matrix exponential:\nexpm : gl(n,R) \u2192 GL(n,R), X 7\u2192 eX = \u221e\u2211 k=0 1 k! Xk (50)\nFrom Prop. B.1 we can define the inverse of the group exponential (expm|U )\u22121 : V \u2192 U which is a diffeomorphism of V onto U . For matrix Lie groups this map is the matrix logarithm which we denote by logm(\u00b7). Its power series expression is:\nlogm(A) = \u221e\u2211 i=1 (\u22121)k+1 k (A\u2212 I)k, A \u2208 GL(n,R) (51)\nThe existence of the inverse of the matrix exponential is characterized as follows.\nProposition B.2. 13 Let B(I, 1) = {X \u2208 Mn(R) | \u2225X \u2212 I\u2225 < 1} where \u2225 \u00b7 \u2225 is a norm on Mn(R) (e.g. Frobenius norm) and I the identity matrix. Note that B(I, 1) \u2286 GL(n,R). Then for every g \u2208 B(I, 1) we have expm(logm(g)) = g and for every X \u2208 B(0, log(2)), we have logm(expm(X)) = X .\nRecall from Section 4 that if the parametrization map \u03be : g \u2192 G is chosen to be the group exponential \u03be = expm, then \u03be\u22121 is given by the matrix logarithm:\n\u03be\u22121(g\u22121g\u0303) = logm(g\u22121g\u0303), logm : G\u2192 g (52)\n9(Lee, 2010, Proposition 4.66). 10An abstract subgroup H of G is a submanifold iff H is closed with the induced topology ((Gallier &\nQuaintance, 2020, Theorem 19.18)). 11(Lee, 2013, Proposition 20.8). 12(Lee, 2013, Example 8.36 & Proposition 8.41). 13(Faraut, 2008, Theorem 2.2.1).\nFor the following, see Hall (2015, Chapter 5). Assuming there exist X and Y such that eX = g\u22121 and eY = g\u0303, (10) can be rewritten as logm(eXeY ). The Baker-Campbell-Hausdorff (BCH) formula states that there exists a sufficiently small open subset 0 \u2208 U \u2282 g so that eXeY \u2208 eU and one has:\nlogm(eXeY ) = X + Y + 1\n2 [X,Y ] +\n1 12 [X, [X,Y ]]\u2212 1 12 [Y, [X,Y ]] + . . . (53)\nFor abelian Lie groups this reduces to:\nlogm(eXeY ) = X + Y (54)\nFor V a finite-dimensional vector space over R, we denote by GL(V ) the group of invertible linear maps of V and by gl(V,R) = End(V ) the space of linear maps V \u2192 V . GL(V ) admits a Lie group structure as it is isomorphic to GL(n,R) once a basis is chosen. The space gl(V,R) can be made into a Lie algebra under the commutator bracket and it is isomorphic to Mn(R) = gl(n,R). Definition B.3. Let V be a vector space. A (finite-dimensional real) representation of a Lie group G is a Lie group homomorphism \u03c1 : G \u2192 GL(V ). For g a (real) Lie algebra, a representation of g is a Lie algebra homomorphism \u03d5 : g \u2192 gl(V,R).\nThe conjugation (inner automorphism) map Cg : G\u2192 G is defined such that Cg = Lg \u25e6Rg\u22121 :\nCg : G\u2192 G, Cg : h 7\u2192 ghg\u22121 (55)\nThe adjoint representation G, is given by the homomorphism14\nAd : G\u2192 GL(g), g 7\u2192 Adg (56) where Adg : g \u2192 g, Adg = d(Cg)e = (dLg)g\u22121 \u25e6 (dRg\u22121)e. The differential of Ad is used to define the adjoint representation of g, denoted by ad:\nad : g \u2192 gl(g), adX = d(Ad)e(x) (57)"
        },
        {
            "heading": "B.2 PRIMER ON RIEMANNIAN GEOMETRY",
            "text": "For more details on smooth and Riemannian manifolds see Lee (2013).\nRiemannian manifolds A Riemannian metric (tensor) g on a smooth manifold M is a covariant 2-tensor field smoothly assigning to each p \u2208 M , an inner product gp : TpM \u00d7 TpM \u2192 R at its tangent space TpM :\np 7\u2192 gp(\u00b7, \u00b7) = \u27e8\u00b7, \u00b7\u27e9p (58) A smooth manifold M with a Riemannian metric g is a Riemannian manifold (M, g). Definition B.4. Let (M, g) and (N,h) be Riemannian manifolds. A map \u03d5 : M \u2192 N is an isometry if \u03d5 is a diffeomorphism and g = \u03d5\u2217h. Equivalently, \u03d5 is bijective, smooth and \u2200p \u2208 M , d\u03d5p : TpM \u2192 T\u03d5(p)N is a linear isometry:\ngp(u, v) = h\u03d5(p)(d\u03d5p(u), d\u03d5p(v)), \u2200u, v \u2208 TpM (59)\nAn affine connection is a bilinear map \u2207 that maps a pair of vector fields X,Y to another vector field \u2207XY , which is the covariant derivative of Y with respect to X . The affine connection allows us to define the notion of a parallel vector field. If M is a smooth manifold and \u2207 a connection on M , then for \u03b3 : I \u2192M a smooth curve, any vector field X along \u03b3 is called parallel if \u2207\u03b3\u0307(t)X = 0 for any t \u2208 I , where \u03b3\u0307 (t0) := d\u03b3t0 ( d dt \u2223\u2223 t0 ) . A smooth curve \u03b3 : I \u2192 M is a geodesic (with respect to \u2207) iff \u03b3\u0307(t) is parallel along \u03b3, that is \u2207\u03b3\u0307(t)\u03b3\u0307(t) = 0, \u2200t \u2208 I . For every point p \u2208M and every tangent vector v \u2208 TpM there exists some interval I = (\u2212\u03b7, \u03b7), \u03b7 > 0 around 0 and a unique geodesic \u03b3 : I \u2192M satisfying:\n\u03b3(0) = p, and \u03b3\u2032(0) = v (60)\nThere exists a unique geodesic \u03b3 satisfying these conditions and for which the domain I cannot be extended. In this case, \u03b3 is the unique maximal geodesic satisfying the initial conditions (60). We denote it by \u03b3p,v , and say that \u03b3p,v is a geodesic through p with initial velocity v.\n14(Lee, 2013, Proposition 20.24).\nDefinition B.5 (Exponential map of connection). Let M be a manifold and \u2207 a connection on M . Define for a point p \u2208M the set D(p) = {v \u2208 TpM | \u03b3p,v(1) defined}. The exponential map expp : D(p) \u2192M is given by:\nexpp : v 7\u2192 \u03b3p,v(1) (61)\nProposition B.6. 15 The differential of the exponential map d(expp) at 0 is the identity on TpM . For every p \u2208M , the exponential expp is a diffeomorphism from an open subset U \u2286 TpM centered at 0 such that expp(U) \u2286M is open.\nIt is therefore possible to build a local chart (expp(U), exp \u22121 p ) around every point p \u2208M using the inverse of the exponential map exp\u22121p . The Levi-Civita connection is the unique affine connection that is metric-compatible and torsion free. Definition B.7. 16 The exponential map of the Levi-Civita connection will be called the Riemannian exponential. For any p \u2208 M , a normal neighborhood of p is an open neighborhood Up = expp(B(0, \u03f5)) where expp is a diffeomorphism from the open ball B(0, \u03f5) \u2286 TpM onto Up. The injectivity radius injM (p) at p is the least upper bound value \u03f5 > 0 such that expp is a diffeomorphism on B(0, \u03f5). The chart (expp(B(0, injM (p))), exp \u22121 p ) is called a normal chart and the inverse of the exponential exp\u22121p is the Riemannian logarithm."
        },
        {
            "heading": "B.2.1 LIE GROUPS AS RIEMANNIAN MANIFOLDS",
            "text": "A Riemannian metric on a Lie group G is called left-invariant iff the left-translation map is an isometry:\n\u27e8u, v\u27e9x = \u27e8(dLa)xu, (dLa)xv\u27e9ax, \u2200a, x \u2208 G, \u2200u, v \u2208 TxG (62)\nRight-invariant metrics are defined analogously. A bi-invariant metric onG is a Riemannian metric that is both left and right invariant. To specify an invariant metric we can use the following. Proposition B.8. 17 For G a Lie group with Lie algebra g there is a one-to-one correspondence between inner products on g and left (right) invariant metrics on G.\nLeft (right) invariant metrics can therefore be determined uniquely by specifying an inner product on g. This can be seen since for any x \u2208 G and u, v \u2208 TxG:\n\u27e8u, v\u27e9x = \u27e8d(Lx\u22121)xu, d(Lx\u22121)xv\u27e9e (63)\nThe analogue result for bi-invariant metrics is the following. Proposition B.9. 18 There is a one-to-one correspondence between Ad-invariant inner products on g and bi-invariant metrics on G. An Ad-invariant inner product on g is defined such that for any g \u2208 G, Adg is a linear isometry:\n\u27e8u, v\u27e9 = \u27e8Adg(u),Adg(v)\u27e9, \u2200g \u2208 G, \u2200u, v \u2208 g (64)\nLie groups with bi-invariant metrics are convenient to work with as the group and Riemannian exponential maps coincide at the identity. Proposition B.10. 19 If a Lie group G is compact, then it has a bi-invariant metric. If G has a bi-invariant metric, then the Riemannian exponential at the identity expe : TeG \u2192 G coincides with the Lie group exponential expm : g \u2192 G.\nThe Lie groups of interest SL(n,R), GL(n,R) or SE(n,R) do not admit bi-invariant Riemannian metrics20. When only a left (right) invariant metric is available, it is still possible in some cases\n15(Gallier & Quaintance, 2020, Propositions 16.4 & 16.5). 16(Gallier & Quaintance, 2020, Definitions 16.8-16.10). 17(Gallier & Quaintance, 2020, Propositions 21.1 & 21.2) 18(Gallier & Quaintance, 2020, Proposition 21.3). 19(Gallier & Quaintance, 2020, Propositions 21.6 & 21.20). 20A connected Lie group G has a bi-invariant metric iff it is isomorphic to the Cartesian product of a compact\ngroup and an additive vector group (Rn,+) for n \u2265 0 ((Gallier & Quaintance, 2020, Theorem 21.9)).\nto obtain closed-form expressions for geodesics such as the Riemannian exponential. Suppose the group GL(n,R) is endowed with the canonical left-invariant metric determined by the inner product \u27e8X,Y \u27e9 := tr(XTY ) for X,Y \u2208 gl(n,R). Then for any A \u2208 GL(n,R):\ngA(X1, X2) = gI(A \u22121X1, A \u22121X2) = \u27e8A\u22121X1, A\u22121X2\u27e9, \u2200X1, X2 \u2208 TAGL(n,R) (65)\nA closed-form expression for the Riemannian exponential map at the identity is given by21:\nexpI(X) = e XT eX\u2212X T , \u2200X \u2208 gl(n,R) (66)\nOn the right-hand side we have used the Lie group exponential, given by the matrix exponential. The same expression holds for SL(n,R)22 and can be used to define the exponential at any point. Remark B.11. If we equip GL+(n,R) or SL(n,R) with their canonical left-invariant metric, the Riemannian exponential is available in closed form given by (66). As opposed to the Lie group exponential, the Riemannian exponential is surjective, and one could see it as a possible choice for the parametrization map \u03be : g \u2192 G. However, as explained in Section 4, if one cannot work only at the level of the Lie algebra, and group elements have to be mapped from the groupG to g, the map \u03be\u22121 would also need to be available. We are not aware of a closed-form expression for the Riemannian logarithm on the groups GL+(n,R), SL(n,R), corresponding to the canonical left-invariant metric.\nOne could employ a shooting or relaxation method to compute the Riemannian logarithm23, as done for example in (Rentmeesters et al., 2013, Chapter 6.2). However, since \u03be\u22121 is used at every (lifting) cross-correlation layer, this would add a large computational cost during the forward pass. This issue motivated the search for an alternative solution, as the one proposed in the main text."
        },
        {
            "heading": "B.3 GROUP ACTIONS & HOMOGENEOUS SPACES",
            "text": "Let G be a group and M a set. The left action of G on M is a map \u03bb : G\u00d7M \u2192 M satisfying for any m \u2208M and group elements h, g \u2208 G:\n\u03bb(e,m) = m and \u03bb(h, \u03bb(g,m)) = \u03bb(hg,m) (67)\nRight actions are defined analogously. Where it is clear we are referring to a left action we use the notation g \u00b7m or gm for \u03bb(g,m). Using the action we can define the map \u03bbg : M \u2192 M given by \u03bbg : x 7\u2192 g \u00b7 x. Since Lie groups are locally compact topological groups some results will be useful if stated more generally. If G is a topological group and M a topological space, then \u03bb is continuous and \u03bbg will be a homeomorphism. Whereas when G is a Lie group and M a smooth manifold the action is smooth and \u03bbg will be a diffeomorphism. The action of G on M is transitive if:\n\u2200x, y \u2208M : \u2203g \u2208 G : g \u00b7 x = y (68)\nIf a group G acts transitively on a set M , then M is called a homogeneous space of G. For any point x \u2208 M , the set of group elements that fix x form a subgroup of G called the isotropy group or stabilizer of x, and denoted by Gx. The orbit of a point x \u2208M is denoted by Ox:\nGx = {g \u2208 G | g \u00b7 x = x} (69) Ox = G \u00b7 x = {g \u00b7 x | g \u2208 G} \u2286M (70)\nLet G also act on a set N . A map f :M \u2192 N is equivariant if it commutes with the action of G:\nf(g \u00b7m) = g \u00b7 f(m), \u2200m \u2208M, \u2200g \u2208 G (71)\nProposition B.12. 24 Let \u03bb : G \u00d7M \u2192 M be a transitive left action of a group G on a set M , and denote by H = Gx the stabilizer of x \u2208 M . The map by \u03c0 : G \u2192 G/H denotes the canonical\n21See Andruchow et al. (2014); Martin & Neff (2014). Note that in this case, the metric will be left invariant and right-O(n)-invariant.\n22See (Zacur et al., 2014, Section 8.9) which references Wang (1969); Helgason (1979). 23See Zacur et al. (2014, Section 9) for a general discussion on obtaining the Riemannian logarithm in the\ncontext of matrix Lie groups. 24See for example (Gallier & Quaintance, 2020, Proposition 5.2).\nprojection \u03c0 : g 7\u2192 gH on the left cosets for any g \u2208 G. For any such x \u2208 M the projection (or orbit) map \u03c0x : G\u2192M is a surjective map defined by:\n\u03c0x : G\u2192M, \u03c0x : g 7\u2192 \u03bb(g, x) = g \u00b7 x (72)\nSince \u03c0x is surjective and we have \u03c0x(gH) = gH \u00b7 x = g \u00b7Hx = g \u00b7 x = \u03c0x(g) for any g \u2208 G, it induces a bijection \u03d5x : G/H \u2192M by passing to the quotient:\n\u03c0x = \u03d5x \u25e6 \u03c0, \u03d5x : \u03c0(g) 7\u2192 g \u00b7 x (73)\nTheorem B.13. 25 Let G be a locally compact Hausdorff group that is also \u03c3-compact. Suppose G acts transitively and continuously on a locally compact Hausdorff space M . For any x \u2208 M , the stabilizer Gx is a closed subgroup of G and the quotient space G/Gx is Hausdorff. The projection \u03c0 : G \u2192 G/H is a continuous open map, and the orbit map \u03c0x : G \u2192 M is also continuous. Furthermore, the map \u03d5x : G/Gx \u2192 M is a homeomorphism, and it is G-equivariant with the action of G on G/H defined as in (74)26.\nIf M and N are smooth manifolds, \u03c0 : M \u2192 N a smooth map, and d\u03c0p : TpM \u2192 T\u03c0(p)N its differential at p \u2208 M . \u03c0 is a smooth submersion if d\u03c0p is surjective for every p \u2208 M . The subset \u03c0\u22121(x) for any x \u2208 N is referred to as the fiber (of \u03c0) over x, and it is a properly embedded submanifold27. The \u2018analogue\u2019 of Theorem B.13 in the Lie group setting are the following results.\nTheorem B.14. 28 Suppose H is a closed Lie subgroup of a Lie group G. There exists a unique smooth structure on the set of left cosets G/H so that the canonical projection \u03c0 : G \u2192 G/H is a smooth submersion. Furthermore, the left action of G on the cosets:\n\u03c4 : G\u00d7G/H \u2192 G/H, (g1, g2H) 7\u2192 g1g2H (74)\nis transitive and smooth, i.e. G/H is a homogeneous G-space.\nG/H is also referred to as a coset manifold. Note that \u03c0 : G\u2192 G/H is G-equivariant, and we have a diffeomorphism \u03c4h : G/H \u2192 G/H, \u03c4h : gH 7\u2192 hgH such that:\n\u03c4g \u25e6 \u03c0 = \u03c0 \u25e6 Lg, \u03c4gh = \u03c4g \u25e6 \u03c4h, \u2200g, h \u2208 G (75)\nTheorem B.15. 29 Let \u03bb : G \u00d7M \u2192 M be a smooth transitive left action of a Lie group G on a smooth manifold M . For any x \u2208M , let Gx = H denote its stabilizer. The stabilizer H is a closed Lie subgroup of G. \u03d5x : G/H \u2192M defined as in (73):\n\u03d5x : G/H \u2192M, gH 7\u2192 \u03bb(g, x) = g \u00b7 x (76)\nis a diffeomorphism. Furthermore, \u03d5x is equivariant with respect to the action ofG onG/H and the action of G on M . The projection map \u03c0x : G\u2192M, g 7\u2192 \u03bb(g, x) = g \u00b7 x (which can be expressed as \u03c0x = \u03d5x \u25e6 \u03c0) is a smooth submersion.\nIn the main text, we employ the decomposition of a group G as G/H \u00d7 H for H \u2264 G a closed subgroup. The following sections describe the specific class of homogeneous spacesG/H for which these decompositions are realised. Our starting point is the following general result.\nProposition B.16. 30 Let G be a Lie group, H a closed Lie subgroup, and denote M = G/H . If the projection \u03c0 : G\u2192M has a smooth cross section \u03c3 :M \u2192 G (\u03c0 \u25e6 \u03c3 = idM ) then:\n\u03c6 :M \u00d7H \u2192 G, \u03c6(m,h) = \u03c3(m)h (77)\ndefines a diffeomorphism from the product space M \u00d7H onto G. 25(Gallier & Quaintance, 2020, Proposition 5.7 & Theorems 5.13-5.14). 26(Abbaspour & Moskowitz, 2007, Theorem 0.4.5). 27(Lee, 2013, Corollaries 5.13 & 5.14). 28(Lee, 2013, Theorem 21.17). 29See (Lee, 2013, Theorem 21.18) and (O\u2019Neill, 1983, Proposition 11.13). 30The same result is obtained in the case of topological groups when \u03c3 : G \u2192 M is a continuous cross section of \u03c0, in which case \u03c6 : M \u00d7H \u2192 G is then a homeomorphism.\nProof. The proof is given in (O\u2019Neill, 1983, Lemma 11.16). Here we give a more verbose description of the construction since the inverse of this map is mentioned in the following sections. Let H = Gx be the stabilizer of a point x \u2208M , where M = G/H . To show that \u03c6 :M \u00d7H \u2192 G is a diffeomorphism we define the inverse map \u03c8 : G\u2192M \u00d7H such that:\n\u03c8 : g 7\u2192 (\u03c0(g), (\u03c3(\u03c0(g)))\u22121g), \u2200g \u2208 G (78)\n\u03c8 is smooth as it is a composition of smooth maps. To show that \u03c8 is well-defined one shows \u03c3(\u03c0(g))\u22121g \u2208 H = Gx. Recall from Proposition B.12 the projection \u03c0x(g) = g \u00b7 x for any g \u2208 G and that we\u2019ve assumed \u03c0 \u25e6 \u03c3 = idM :\n\u03c3(\u03c0(g)) \u00b7 x = \u03c0x(\u03c3(\u03c0(g))) = \u03c0x(g) = g \u00b7 x (79)\nThen (\u03c3(\u03c0(g)))\u22121g \u00b7 x = (\u03c3(\u03c0(g)))\u22121\u03c3(\u03c0(g)) \u00b7 x = x, such that \u03c3(\u03c0(g))\u22121g \u2208 H = Gx. We therefore have \u03c8(g) \u2208 M \u00d7 H , and it is clear that \u03c6 \u25e6 \u03c8 = idG and \u03c8 \u25e6 \u03c6 = idM\u00d7H , the result follows.\nLemma 11.27 of O\u2019Neill (1983) gives a method for constructing such a map for a class of homogeneous spaces M = G/H called naturally reductive. Before reviewing these spaces, we need to define Riemannian submersions. These class of submersions will allow us to describe the geometry of G/H using the geometry of G. For a comprehensive description one can consult O\u2019Neill (1983, Chapter 7) or (Gallier & Quaintance, 2020, Section 18.3), which serve as our main references.\nSuppose M and N are smooth manifolds, and \u03c0 : M \u2192 N a submersion. For any x \u2208 \u03c0(M), the fiber above x given by \u03c0\u22121(x) is a submanifold of M . For any p \u2208 \u03c0\u22121(x) then Tp\u03c0\n\u22121(x) = ker d\u03c0p. Any complement of ker d\u03c0p = Tp\u03c0\u22121(x) in TpM will be isomorphic to T\u03c0(p)N . In the Riemannian case for (M, g) and (N,h) smooth manifolds endowed with metrics, the fibers \u03c0\u22121(x) will be Riemannian submanifolds of M , and we can define an orthogonal decomposition with respect to the metric. The orthogonal subspaces are referred to as horizontal and vertical subspaces. More precisely, for each x \u2208 \u03c0(M) \u2286 N and p \u2208 \u03c0\u22121(x), the tangent space TpM can be decomposed into orthogonal subspaces TpM = ker d\u03c0p \u2295 (ker d\u03c0p)\u22a5 = Vp \u2295Hp. Tangent vectors v \u2208 TpM , can be written uniquely using horizontal and vertical components:\nv = vH + vV , vH \u2208 Hp, vV \u2208 Vp (80)\nIf v \u2208 Hp (Vp), then v is called a horizontal (vertical) tangent vector. The differential d\u03c0p of a submersion being surjective for any p \u2208 M allows us to construct a vector space isomorphism d\u03c0p|Hp : Hp \u2192 T\u03c0(p)N between horizontal spaces Hp and T\u03c0(p)N . \u03c0 is a Riemannian submersion if for all p \u2208M , the differential d\u03c0p restricted to Hp is a linear isometry onto T\u03c0(p)N :\ngp(u, v) = h\u03c0(p)(d\u03c0p(u), d\u03c0p(v)), \u2200u, v \u2208 Hp (81)\nThe main utility of Riemannian submersions in our case comes from the next theorem which describes how to express geodesics in N as projections of horizontal geodesics in M .\nTheorem B.17. 31 Let \u03c0 : M \u2192 N be a Riemannian submersion between Riemannian manifolds (M, g) and (N,h) equipped with the Levi-Civita connection. If \u03b3 : I \u2192M is a geodesic that starts horizontally, i.e. \u03b3\u2032(0) is a horizontal vector, then \u03b3 is a horizontal geodesic (\u03b3\u2032(t) is horizontal for all t \u2208 I). Furthermore, the projection \u03c0 \u25e6 \u03b3 = \u03b3 is a geodesic in N of the same length as \u03b3. Conversely, for any p \u2208 M , if \u03b3 is a geodesic in N with \u03b3(0) = \u03c0(p), there exists a unique local horizontal lift \u03b3 of \u03b3 such that \u03b3(0) = p and \u03b3 is a geodesic in M .\nTheorem B.17 states that if a Riemannian submersion \u03c0 :M \u2192 N is available, horizontal geodesics in M are mapped to geodesics in N . As d\u03c0 is an isomorphism when restricted to horizontal spaces, if we have a smooth cross-section \u03c3 : N \u2192 M we can express the Riemannian exponential on N using the Riemannian exponential on M :\nexpx(v) = \u03c0 \u25e6 exp\u03c3(x)(v), \u2200x \u2208 N, v \u2208 TxN (82)\n31See (Gallier & Quaintance, 2020, Proposition 18.8) or (O\u2019Neill, 1983, Lemma 7.45 & Corollary 7.46)."
        },
        {
            "heading": "B.3.1 NATURALLY REDUCTIVE & SYMMETRIC SPACES",
            "text": "Definition B.18. 32 Let G be a Lie group, H \u2264 G a closed subgroup Ad : G \u2192 GL(g) be the adjoint representation of G. A homogeneous space G/H is reductive if there is a subspace m of g where:\ng = h\u2295m, and Adh(m) \u2286 m, \u2200h \u2208 H (83)\nThat is, G/H is reductive if we can find an Ad(H)-invariant subspace m complementary to h in g.\nThe following property gives a recipe for constructing a G-invariant metric on G/H and extending it to a left-invariant metric on G that is right H-invariant such that \u03c0 : G \u2192 G/H is a Riemannian submersion, with h and m being the vertical and horizontal subspaces at e \u2208 G. Proposition B.19. 33 LetG be a Lie group,H a closed subgroup andG/H a reductive homogeneous space with reductive decomposition g = h\u2295m.\n1. There is a one-to-one correspondence between G-invariant metrics on G/H and Ad(H)invariant inner products on m. The correspondence can be established by making d\u03c0e|m : m \u2192 To(G/H) into a linear isometry, where o = \u03c0(e) = eH . A G-invariant metric on G/H exists iff the closure of Ad(H)(m) is compact. If H is compact then Ad(H)(m) is compact, so there exists a G-invariant metric on G/H .\n2. Let m have an Ad(H)-invariant inner product. If we extend it to an inner product on g = h \u2295 m such that h\u22a5 = m, and endow G with the corresponding left-invariant metric then the canonical map \u03c0 : G\u2192 G/H is a Riemannian submersion.\nThe reductive homogeneous spaces of interest are the following. Definition B.20. 34 Let G be a Lie group and H a closed subgroup of G. The homogeneous space G/H is naturally reductive if it is reductive with decomposition g = h \u2295 m, has a G-invariant metric and satisfies:\n\u27e8[X,Z]m, Y \u27e9 = \u27e8X, [Z, Y ]m\u27e9, \u2200X,Y, Z \u2208 m (84)\nIn this case, it is possible to express geodesics in G/H with respect to the Levi-Civita connection as orbits of one-parameter subgroups generated by the tangent vectors in m. Proposition B.21. 35 Suppose G/H is a naturally reductive homogeneous space, and we have g = h \u2295 m. Using the G-invariant metric of G/H , a left-invariant metric is constructed on G, such that its restriction to on m is Ad(H)-invariant and we have m = h\u22a5, and recall that in this case \u03c0 : G \u2192 G/H is a Riemannian submersion. For every X \u2208 m the geodesic starting at o = \u03c0(e) = eH with initial velocity d\u03c0e(X) is given by:\n\u03b3o,d\u03c0e(X)(t) = expm(tX) \u00b7 o = \u03c0 \u25e6 expm(tX), \u2200t \u2208 R (85)\nSince the one-parameter subgroups t 7\u2192 expm(tX) are defined for any t \u2208 R, by the preceding proposition so are maximal geodesics through o and therefore through any point since we are working with a homogeneous space. Naturally reductive homogeneous spaces are therefore complete36.\nDefinition B.22. A connected Riemannian manifold (M, g) is a (Riemannian) symmetric space if for every point p \u2208 M there exists a unique isometry sp : M \u2192 M such that sp(p) = p and (dsp)p = \u2212 idp. Equivalently, for every p \u2208 M , the map sp is an involutive isometry (s2p = id) having p as its only fixed point.\nThe isometry sp : M \u2192 M is called the global symmetry of M at the p. Symmetric spaces can be constructed from \u2019Lie group data\u2019. The connection can be made clear with a few more definitions.\n32(Gallier & Quaintance, 2020, Definition 23.8). 33Corresponds to (Gallier & Quaintance, 2020, Propositions 23.23). 34(Gallier & Quaintance, 2020, Definition 23.9). 35(Gallier & Quaintance, 2020, Propositions 23.25-23.27). 36(O\u2019Neill, 1983, pp. 313).\nAn involutive automorphism of a Lie group G is an automorphism \u03c3 : G \u2192 G such that \u03c3 \u0338= id and \u03c32 = id. For \u03c3 an involutive automorphism G, G\u03c3 = {g \u2208 G | \u03c3(g) = g} will denote the closed subgroup of fixed points of \u03c3 and G\u03c30 its identity component. Definition B.23. 37 A symmetric pair is a triplet (G,H, \u03c3) where G is a connected Lie group, H a closed Lie subgroup of G, and \u03c3 : G \u2192 G an involutive automorphism of G such that G\u03c30 \u2286 H \u2286 G\u03c3 . If additionally Ad(H) \u2286 GL(g) is compact (where Ad : G \u2192 GL(g) is the adjoint representation of G), then (G,H, \u03c3) is a Riemannian symmetric pair.\nThe differential d\u03c3e : g \u2192 g of an involutive automorphism \u03c3 : G\u2192 G defines the \u00b11 eigenspaces:\nh = {X \u2208 g | d\u03c3e(X) = X}, m = {X \u2208 g | d\u03c3e(X) = \u2212X} (86)\nTheorem B.24. 38 Suppose that (G,H, \u03c3) is a symmetric pair. Then the following properties hold. Note that items 1-3 make G/H into a reductive homogeneous space.\n1. h = {X \u2208 g | d\u03c3e(X) = X} is the Lie algebra of H .\n2. g = h \u2295 m, where m = {X \u2208 g | d\u03c3e(X) = \u2212X}. The decomposition follows from d\u03c3e : g \u2192 g also being an involution d\u03c32e = id and the identity:\nX = 1\n2 (X + d\u03c3e(X)) +\n1 2 (X \u2212 d\u03c3e(X)), \u2200X \u2208 g (87)\n3. Adk(m) \u2286 m, \u2200k \u2208 K.\n4. [h, h] \u2286 h, [h,m] \u2286 m, [m,m] \u2286 h.\nThe map d\u03c3e : g \u2192 g associated to a symmetric pair (G,H, \u03c3) is referred to as a Cartan involution, with the automorphism \u03c3 : G\u2192 G being a global Cartan involution. The decomposition g = h\u2295m given by d\u03c0e as in Thm. B.24 is called a Cartan Decomposition of g. If one further assumes that G\u03c30 and H are compact, then we obtain a symmetric space. Theorem B.25. 39 Suppose that (G,H, \u03c3) is a Riemannian symmetric pair withG\u03c30 andH compact. Denote by g and h the Lie algebras of G and H respectively.\n1. SinceH is compact,G/H admits aG-invariant metric from Proposition B.19 (1). From the previous theorem, G/H has a reductive decomposition g = h \u2295 m where h and m are the \u00b11 eigenspaces of d\u03c3e. Using the identity [m,m] \u2286 h and assuming a G-invariant metric on G/H the natural reductivity condition of B.20 holds trivially (since h \u2229m = {0}).\n2. For every p \u2208 G/H , there exists a isometry sp : G/H \u2192 G/H such that sp(p) = p and d(sp)p = \u2212idp, making G/H a Riemannian symmetric space. For the projection \u03c0 : G\u2192 G/H and o = \u03c0(e) = eH , the symmetry at o is defined such that so : gH 7\u2192 \u03c3(g)H:\nso \u25e6 \u03c0 = \u03c0 \u25e6 \u03c3 (88)\nFor an arbitrary p = gH \u2208 G/H , the geodesic symmetry is given by:\nsp = \u03c4g \u25e6 so \u25e6 \u03c4g\u22121 (89)\nBy the preceding theorem symmetric spaces can be given a naturally reductive structure. We can now use Proposition B.16 to construct a global cross section, under which the Lie group G can be identified with the product space m \u00d7 H or expm(m) \u00d7 H . Recall from Proposition B.21 that geodesics starting at o = \u03c0(e) = eH = H with initial velocity d\u03c0e(X) for X \u2208 m are of the form \u03b3o,d\u03c0e(X)(t) = expm(tX)\u00b7o = \u03c0(expm(tX)). In particular, we can obtain the following expression for the Riemannian exponential expo : ToM \u2192M :\nexpo(d\u03c0e|m(X)) = \u03c0(expm(X)), \u2200X \u2208 m (90) 37(Helgason, 2001, Chapter IV, \u00a73). 38(Gallier & Quaintance, 2020, Theorem 23.33). 39See (Ziller, 2010, Proposition 6.25) or (Helgason, 2001, Proposition 3.4). Corresponds to (Gallier &\nQuaintance, 2020, Theorem 23.34), (O\u2019Neill, 1983, Theorem 11.29).\nThat is, the following diagram commutes:\nm ToM\nG M\nd\u03c0e|m\nexpm expo\n\u03c0\n(91)\nProposition B.26. Let M = G/H be a naturally reductive homogeneous space and \u03c0 : G \u2192 G/H the canonical projection. If the Riemannian exponential expo at the point o = \u03c0(e) = eH \u2208 M is a diffeomorphism, we can construct a diffeomorphism of m\u00d7H onto G given by:\n\u03a6 : m\u00d7H \u2192 G, (X,h) 7\u2192 expm(X)h (92)\nProof. O\u2019Neill (1983, Lemma 11.27). Again, we reproduce the proof as the maps defined are referenced in later sections. The map is built by constructing a cross-section of \u03c0 : G\u2192 G/H using the relation (90) of the Riemannian exponential such that one first defines:\nExpe := expo \u25e6 d\u03c0e|m = \u03c0 \u25e6 expm : m \u2192M (93)\nBy hypothesis expo : To(M) \u2192M is a diffeomorphism, and so is d\u03c0e|m making Expe a diffeomorphism. We can define the cross-section by \u03c3 :M \u2192 G by:\n\u03c3 := expm \u25e6 Exp\u22121e (94)\nThen \u03c0 \u25e6 \u03c3 = \u03c0 \u25e6 expm \u25e6 Exp\u22121e = Expe \u25e6 Exp \u22121 e = idM , and by Proposition B.16 we have a diffeomorphism \u03c6 :M \u00d7H \u2192 G given by (77):\n\u03c6 : (m,h) 7\u2192 \u03c3(m)h = expm(Exp\u22121e (X))h (95)\nComposing this map with the map Expe \u00d7 idH we obtain the desired map \u03a6 := \u03c6 \u25e6 (Expe \u00d7 idH):\n\u03a6 : m\u00d7H \u2192 G, \u03a6 : (X,h) 7\u2192 \u03c3(Expe(X))h = expm(X)h (96)"
        },
        {
            "heading": "B.4 THE CARTAN/POLAR DECOMPOSITION",
            "text": "Define the following subsets of Mn(R):\nSym(n,R) = {P \u2208 Mn(R) | P = PT } (97) Pos(n,R) = {P \u2208 Sym(n,R) | \u2200v \u2208 Rn, v \u0338= 0, vTPv > 0} (98)\nSPos(n,R) = {P \u2208 Pos(n,R) | det(P ) = 1} (99) Sym0(n,R) = {P \u2208 Sym(n,R) | tr(P ) = 0} (100)\nSym(n,R) is the vector space of n \u00d7 n real symmetric matrices and Pos(n,R) is the subset of Sym(n,R) of symmetric positive definite (SPD) matrices. SPos(n,R) denotes the subset of Pos(n,R) consisting of SPD matrices with unit determinant, and Sym0(n,R) the subspace of Sym(n,R) of traceless real symmetric matrices. Every SPD matrix S \u2208 Pos(n,R) has a unique square root40 S1/2 = P , P \u2208 Pos(n,R), which shows the uniqueness of the polar decomposition. Proposition B.27 (Polar decomposition). 41 Any matrixA \u2208 GL(n,R) can be uniquely decomposed as A = PR or A = R\u0303P\u0303 , where P, P\u0303 \u2208 Pos(n,R) and R, R\u0303 \u2208 O(n). We refer to the factorization A = PR as the left polar decomposition and to A = R\u0303P\u0303 as the right polar decomposition. We choose to work with the left polar decomposition. The factors of this decomposition are uniquely determined and we have a bijection GL(n,R) \u2192 Pos(n,R)\u00d7 O(n) given by:\nA 7\u2192 ( \u221a AAT , \u221a AAT \u22121 A), \u2200A \u2208 GL(n,R) (101)\n40(Hall, 2015, Lemma 2.18) or (Horn & Johnson, 2012, Theorem 7.2.6). 41See (Jost & Jost, 2008, Lemma 7.5.1) or (Horn & Johnson, 2012, Theorem 7.3.1).\nAs mentioned in the main text, this decomposition can be generalized using the fact that the spaces Pos(n,R) = GL+(n,R)/SO(n) and SPos(n,R) = SL(n,R)/SO(n) are symmetric spaces, and a Cartan decomposition is available in this case. We first state some useful properties of Pos(n,R) and then review its symmetric space and naturally reductive structure. Proposition B.28. 42 Every real symmetric matrix X \u2208 Sym(n,R) has a spectral decomposition X = ODOT where O \u2208 SO(n) and D = diag(d1, . . . , dn), di \u2208 R is a diagonal matrix consisting of the eigenvalues of X , which are positive iff X is positive-definite. Using this decomposition we have simplified expressions for the matrix exponential expm : Sym(n,R) \u2192 Pos(n,R) and logarithm logm : Pos(n,R) \u2192 Sym(n,R):\nexpm(X) = Odiag(exp(d1), . . . , expm(dn))OT , \u2200X \u2208 Sym(n,R) (102) logm(P ) = Odiag(log(d1), . . . , log(dn))OT , \u2200P \u2208 Pos(n,R) (103)\nPos(n,R) is an open subset of Sym(n,R) and a smooth manifold of dimension n(n + 1)/2, with the tangent space TP Pos(n,R) at any P \u2208 TP Pos(n,R) naturally isomorphic (by translation) to Sym(n,R). The matrix exponential and logarithm maps are diffeomorphisms between Sym(n,R) and Pos(n,R), and the power map P 7\u2192 P\u03b1 is smooth for any \u03b1 \u2208 R, since it can be expressed as:\nP\u03b1 = expm(\u03b1logm(P )), \u2200P \u2208 Pos(n,R) (104)\nAs a reference for the following results on Pos(n,R) and SPos(n,R) see Fo\u0308rstner & Moonen (2003); Pennec (2020); Stegemeyer & Hu\u0308per (2021). The presentation here also follows (Rentmeesters et al., 2013, Section 3.5) and (Lezcano-Casado, 2022, Section 3.5.3).\nPos(n,R) is a homogeneous space of the positive general linear group GL+(n,R). More precisely, GL+(n,R) has a smooth transitive action on Pos(n,R) given by:\n\u03bb : GL+(n,R)\u00d7 Pos(n,R) \u2192 Pos(n,R), (A,P ) 7\u2192 APAT (105)\nNote that every SPD matrix P \u2208 Pos(n,R) can be written as P = AAT for some A \u2208 GL+(n,R). The isotropy group of the identity matrix I \u2208 Pos(n,R) corresponding to this action is the special orthogonal group SO(n) since RIRT = RRT = I for R \u2208 SO(n).\nApplying Theorems B.14 & B.15 we have that GL+(n,R)/SO(n) = Pos(n,R). That is, we have a diffeomorphism:\n\u03d5I : GL+(n,R)/SO(n) \u2192 Pos(n,R), A \u00b7 SO(n) 7\u2192 AAT (106)\nAnd a smooth submersion of GL+(n,R) onto Pos(n,R) given by:\n\u03c0I = \u03d5I \u25e6 \u03c0 : GL+(n,R) \u2192 Pos(n,R), A 7\u2192 AAT (107)\nLet g = gl(n,R) denote the Lie algebra of GL+(n,R). The Lie algebra of SO(n) is the space so(n) = {X \u2208 Mn(R) | X = \u2212XT } of skew-symmetric matrices. Pos(n,R) = GL+(n,R)/SO(n) is a reductive homogeneous space (see Definition B.18) since Ad(SO(n))(Sym(n,R)) \u2286 Sym(n,R) and we have the decomposition g = h\u2295m given by:\ngl(n,R) = so(n)\u2295 Sym(n,R) (108) Then h = so(n) and m = Sym(n,R), and the bracket relations [h, h] \u2286 h, [h,m] \u2286 m, [m,m] \u2286 h hold. We now choose an inner product on gl(n,R) such that its restriction to Sym(n,R) is Ad(SO(n))-invariant, SO(n)\u22a5 = Sym(n,R) and we can use it to define a left-invariant Riemannian metric on GL+(n,R). We work with a scaled version of the canonical inner product \u27e8X,Y \u27e9 := tr(XTY ):\nB(X,Y ) := 4\u27e8X,Y \u27e9 = 4tr(XTY ), X, Y \u2208 gl(n,R) (109) The inner product respects the decomposition (108) into symmetric and skew-symmetric matrices, and the left-invariant metric on GL+(n,R) (which is also right-SO(n)-invariant) is:\ng GL+(n,R) A (X,Y ) = B(A \u22121X,A\u22121Y ), \u2200A \u2208 GL+(n,R), \u2200X,Y \u2208 TAGL+(n,R) (110) 42(Arsigny et al., 2007, Theorems 2.6, 2.8 & Corollary 2.9) more specifically for the matrix exp/log and power map. For a review of algebraic properties and the Riemannian manifold structure of Pos(n,R) see Arsigny et al. (2007); Pennec (2020).\nTo define a GL+(n,R)-invariant metric on Pos(n,R) = GL+(n,R)/SO(n), note that the differential of the projection (107) at I is d\u03c0I(X) = X+XT for anyX \u2208 gl(n,R), with ker(d\u03c0I) = so(n) and its restriction to m = Sym(n,R) gives the isomorphism:\nd\u03c0I : m \u2192 TIPos(n,R), X 7\u2192 2X (111)\nWe have \u03bb(P 1/2, I) = P , and the differential with respect to the second argument at identity is X 7\u2192 P 1/2XP 1/2. The linear isomorphism d(\u03c0I \u25e6 LP 1/2)I : m \u2192 TP Pos(n,R) is then given by:\nd(\u03c0I \u25e6 LP 1/2)I : X 7\u2192 2P 1/2XP 1/2, \u2200X \u2208 m (112)\nWe denote its inverse by \u03b7P : TP Pos(n,R) \u2192 m, such that \u03b7P : X 7\u2192 12P \u22121/2XP\u22121/2. The induced (quotient) metric on Pos(n,R)43 is defined for any P \u2208 Pos(n,R) and X,Y \u2208 TP Pos(n,R):\ng Pos(n,R) P (X,Y ) := B(\u03b7P (X), \u03b7P (Y )) = \u27e8P \u22121/2XP\u22121/2, P\u22121/2XP\u22121/2\u27e9 = tr(P\u22121XP\u22121Y ) (113)\nEndowed with this metric the action of GL+(n,R) is by isometries and \u03c0I is a Riemannian submersion. (Pos(n,R), gPos(n,R)) is also a Riemannian symmetric space and (GL+(n,R),SO(n),\u0398) is a Riemannian symmetric pair, with \u0398 the global Cartan involution:\n\u0398 : GL+(n,R) \u2192 GL+(n,R), \u0398 : A 7\u2192 (AT )\u22121 (114)\nIn this case we have G\u03980 = SO(n) = G \u0398, and we have corresponding Lie algebra involution:\n\u03b8 := d\u0398e : gl(n,R) \u2192 gl(n,R), \u03b8 : X 7\u2192 \u2212XT (115)\nAnalog results hold for SPos(n,R) = SL(n,R)/SO(n), such that (SL(n,R),SO(n),\u0398) is a Riemannian symmetric pair. The group SL(n,R) has Lie algebra:\nsl(n,R) = {X \u2208 gl(n,R) | tr(X) = 0} (116)\nSL(n,R)/SO(n) is an example of a non-compact symmetric space44. We can reuse the metrics (110) and (113), restricting them to SL(n,R) and SPos(n,R), respectively. Proposition B.29. 45 GL+(n,R) can be represented as a product SL(n,R)\u00d7R\u00d7>0 by the Lie group isomorphism:\nGL+(n,R) \u2192 SL(n,R)\u00d7 R\u00d7>0, A 7\u2192 ( A\ndet(A) 1 n\n,det(A) 1 n ) (117)\nReusing the previously defined metrics, SL(n,R) and SPos(n,R) are totally geodesic submanifolds46 of GL+(n,R) and Pos(n,R), respectively. The decomposition (117) restricted to Pos(n,R) can be shown to induce a Riemannian isometry Pos(n,R) \u223c= SPos(n,R)\u00d7R>0. The tangent space decomposition is Sym(n,R) = Sym0(n,R)\u2295 d, where d(n,R) are scalar diagonal matrices."
        },
        {
            "heading": "B.5 PROOF OF THEOREM 4.2",
            "text": "As in the main text, we let (G/H,M,m) define our \u2018Lie group data\u2019, corresponding to (GL+(n,R)/SO(n),Pos(n,R),Sym(n,R)) or (SL(n,R)/SO(n),SPos(n,R),Sym0(n,R)). Theorem 4.2. Let (G/H,M,m) be as above, and denote by g, h the Lie algebras of G and H .\n1. The matrix exponential and logarithm are diffeomorphisms between m andM , respectively. For any P \u2208M and \u03b1 \u2208 R, the power map P 7\u2192 P\u03b1 is smooth and can be expressed as:\nP\u03b1 = expm(\u03b1logm(P )), \u2200P \u2208 Pos(n,R) (19) 43Known as the affine-invariant metric, see (Thanwerdas & Pennec, 2023, Proposition 3.1). 44For a classification of symmetric spaces see for example (Ziller, 2010, Chapter 6). 45A detailed treatment can be found in Dolcetti & Pertici (2015; 2019). 46N is a totally geodesic submanifold of a Riemannian manifold M , if for any two points of N and a geodesic\n\u03b3 in M that joins them, \u03b3 is entirely contained in N .\n2. G \u223c=M \u00d7H and G \u223c= m\u00d7H . We have group-level diffeomorphisms:\n\u03c7 :M \u00d7H \u2192 G, \u03c7(P,R) 7\u2192 PR (20) \u03a6 : m\u00d7H \u2192 G, \u03a6 : (X,R) 7\u2192 expm(X)R = eXR (21)\n3. The above maps can be inverted in closed-form:\n\u03c7\u22121 : G\u2192M \u00d7H, \u03c7\u22121 : A 7\u2192 ( \u221a AAT , \u221a AAT \u22121 A) (22)\n\u03a6\u22121 : G\u2192 m\u00d7H, \u03a6\u22121 : A 7\u2192 (1 2 logm(AAT ), expm(\u22121 2 logm(AAT ))A) (23)\nProof. The theorem is a collection of results related to the Cartan decomposition and the structure theory of Lie groups, which can be found for example in (Bridson & Haefliger, 2013, Chapter II.10) or (Abbaspour & Moskowitz, 2007, Chapter 6). Similar results apply to algebraic subgroups of GL(n,R) that are closed and stable under transposition (see (Abbaspour & Moskowitz, 2007, Prop. 6.3.3 & Definition 6.3.4) or (Bridson & Haefliger, 2013, Definition 10.56)).\n1. The first result holds due to Proposition B.28, and the fact that for any X \u2208 m we have expm(tX) \u2208 M for all t \u2208 R, see (Bridson & Haefliger, 2013, Lemma 10.52). The Riemannian exponential on M is also a diffeomorphism at any point.\n2. For the group-level Cartan/Polar decomposition see (Abbaspour & Moskowitz, 2007, Theorem 6.2.5 & 6.3.5). Given a tangent vector in m, the Riemannian exponential on M and the matrix exponential are related by the diffeomorphism:\nExpe : m \u2192M, X 7\u2192 expm(X) \u00b7 I = expm(X)Iexpm(X)T = expm(2X) (118)\nExpe is obtained from applying Proposition B.21. The map \u03a6 of (21) can be obtained from (20) and the fact that the matrix exponential is a diffeomorphism on M , or using Proposition B.26, such that (21) corresponds to (96).\n3. The map \u03c7\u22121 is simply the polar decomposition. To obtain \u03be\u22121 we use the fact thatAAT \u2208 M for A \u2208 G and the identities:\nlogm(P 1/2) = 1 2 logm(P ), P\u22121/2 = expm(\u22121 2 logm(P )), \u2200P \u2208M (119)\nThe identities (119) can be obtained from (19).\nB.6 INTEGRAL FACTORIZATIONS FOR THE CARTAN/POLAR DECOMPOSITION\nConsider again the notation (G/H,M,m) as in Theorem 4.2. Recall that we have G = GL+(n,R) (M = Pos(n,R)) or G = SL(n,R) (M = SPos(n,R)), with H = SO(n). We have equivalent decompositions which allow us to represent A \u2208 G as A = PR or A = S1/2R for S, P \u2208 M , R \u2208 H and therefore P = S1/2. For GL(n,R), the decomposition A = S1/2R, produces a factorization of the Haar measure \u00b5GL(n,R) as a product of invariant measures on Pos(n,R) and O(n). The Haar measure on GL(n,R) is given for any A = (Aij) \u2208 GL(n,R) by47:\nd\u00b5GL(n,R)(A) = |det(A)|\u2212ndA = |det(A)|\u2212n n\u220f\ni,j=1\ndAij (120)\nwhere dA is the Lebesgue measure on Rn2 and dAij is the Lebesgue measure on R. GL(n,R) has two homeomorphic connected components consisting of the group of invertible matrices with positive determinant GL+(n,R) and with negative determinant GL\u2212(n,R)48. Integrating the full group GL+(n,R) can be done by integrating each component separately, and we focus on constructing a\n47(Bourbaki & Berberian, 2004, VII, \u00a73, No. 3, Example 1). 48(Warner, 1983, Theorem 3.68).\nsolution for the identity component GL+(n,R). We use the shorter notation Pos(n) and SPos(n) going forward to denote Pos(n,R) and SPos(n,R).\nUsing a similar notation scheme as in (120), the unique (up to scaling) GL(n,R)-invariant measure on Pos(n) is49:\nd\u00b5Pos(n)(S) = |det(S)|\u2212(n+1)/2dS = |det(S)|\u2212(n+1)/2 n\u220f\n1\u2264i\u2264j\u2264n\ndSij , \u2200S \u2208 Pos(n) (121)\nThe following result can be found in a more general setting, often expressed using the \u2018right\u2019 polar coordinates of the decomposition A = RS1/2. Let H = Vn,m = {R \u2208 Mnm(R) | RTR = Im} for n \u2265 m and G = Mnm(R)\u2217 = {A \u2208 Mnn(R) | rank(A) = m} the set of n\u00d7m matrices of rank m. Vn,m is the Stiefel manifold of orthonormal m-frames in Rn, on which O(n) acts transitively by left multiplication such that Vn,m = O(n)/O(n \u2212 m), with special cases Vn,n = O(n) and Vn,n\u22121 = SO(n). The complement of Mnm(R)\u2217 in Mnm(R) has Lebesgue measure zero50, and Mnn(R)\u2217 = GL(n,R). In this case it will correspond to (Herz, 1955, Lemma 1.4) or (Muirhead, 2009, Theorem 2.1.14). Theorem 4.3. Denote G = GL(n,R), H = O(n), and let \u00b5G be the Haar measure on G and \u00b5H the Haar measure on H normalized by Vol(H) = 1. For A \u2208 G, under the decomposition A = S1/2R, S \u2208 Pos(n), R \u2208 H , the measure on G splits as d\u00b5G(A) = \u03b2nd\u00b5Pos(n)(S)d\u00b5H(R), where \u03b2n = Vol(O(n)) 2n is a normalizing constant. Restricting to G = GL\n+(n,R) and H = SO(n) and ignoring constants, we have:\nf 7\u2192 \u222b G f(A)d\u00b5G(A) = \u222b Pos(n) \u222b H f(S1/2R)d\u00b5H(R)d\u00b5Pos(n)(S), \u2200f \u2208 Cc(G) (24)\nProof. A proof is given in (Gross & Kunze, 1976, Prop. 5.6) for the decomposition of the form A = RS1/2. In the form S1/2R it is proven for example in (Faraut & Travaglini, 1987, Section 4). In the context of multivariate statistics see Theorem 5.2.2 and Remark 5.2.3 of Farrell (2012). A recent reference is (Chirikjian, 2012, Section 16.7.2).\nNote that the constant \u03b2n is independent of f \u2208 Cc(G). From (Chirikjian, 2012, (16.36)):\nVol(O(n)) = 2 \u00b7 Vol(SO(n)) = 2 n\u03c0n\n2/2\n\u0393n(n/2) (122)\nWhere \u0393n(\u00b7) denotes the multivariate Gamma function. From (Chirikjian, 2012, (16.55) & (16.56)), if dA is the Lebesgue measure on Rn2 , under the decomposition A = S1/2R we have:\ndA = d(S1/2R) = \u03b2n|det(S)|1/2dOdS (123)\nThen considering that S = AAT , the Haar measure d\u00b5GL(n,R) = |det(A)|\u2212ndA can be expressed:\nd\u00b5GL(n,R)(dA) = |S1/2R|\u2212nd(S1/2R) = \u03b2n |det(AAT )|\u2212n/2|det(S)|1/2dOdS (124)\nWe use this decomposition treating G (GL+(n,R) or SL(n,R)) as our sample space. From Section 5.2 of Farrell (2012), for the case G = Mnm(R)\u2217 \u223c= Vn,m \u00d7 Pos(m) it can be shown that if a A \u2208 Mnm(R)\u2217 is a random matrix with a O(n)-left invariant distribution, then for \u03c6(A) = RS1/2 the corresponding random variables R \u2208 Vn,m and S1/2 \u2208 Pos(m) will be independent, and R will have a uniform distribution on Vn,m. Furthermore, there exists a relationship between the density function of A = RS1/2 \u2208 Mnm(R)\u2217 with respect to the O(n)-invariant measure and that of S \u2208 Pos(n) with respect to (121). If G = GL+(n,R) or G = SL(n,R), the Haar measure \u00b5G is bi-O(n)-invariant (respectively bi-SO(n)-invariant). We can then work with either decomposition 51 S1/2R or RS1/2. 49(Bourbaki & Berberian, 2004, VII, \u00a73, No. 3, Example 8). \u00b5Pos(n,R) is bi-GL(n,R)-invariant, as well as invariant under P 7\u2192 P\u22121. 50(Gross & Kunze, 1976, Example 5.5) or (Eaton, 1983, Proposition 7.1). 51In the second case, one considers the right action ATPA, for A \u2208 GL(n,R) and P \u2208 Pos(n).\nTheorem 4.4. If a random matrix A \u2208 GL(n,R) has a left-O(n) invariant density function relative to |AAT |\u2212n/2dA, then (AAT )1/2 = S1/2 andR = (AAT )\u22121/2A are independent random matrices and R has a uniform probability distribution on O(n). The uniform distribution on O(n) will be the normalized Haar measure \u00b5O(n). Conversely, if S \u2208 Pos(n) has a density function f : Pos(n) \u2192 R\u22650 relative to \u00b5Pos(n) and R \u2208 O(n) is uniformly distributed with respect to the Haar measure \u00b5O(n), then A = S1/2R has a density function \u03b2\u22121n f(AA T )|det(A)|\u2212n relative to dA.\nProof. This theorem collects Lemma 5.2.4 & 5.2.8 of Farrell (2012) applied to the case where we are working with random matrices in GL+(n,R) and using the left polar decomposition. See also (Eaton, 1983, Proposition 7.4).\nRestricting only to the connected component GL+(n,R), the task is now to specify a probability distribution on Pos(n) relative to the measure d\u00b5Pos(n). For the case of SL(n,R), using the isomorphism (117), we can define a SL(n,R)-invariant measure on SPos(n). More precisely, P = (det(P )1/nI)P\u0303 for P \u2208 Pos(n), P\u0303 = det(P )\u22121/nP \u2208 SPos(n), which we write P = t1/nP\u0303 , t > 0, such that d\u00b5Pos(n)(P ) = dtt d\u00b5SPos(n)(P\u0303 ) and for f \u2208 L\n1(Pos(n))52:\u222b Pos(n) f(P )d\u00b5Pos(n)(P ) = \u222b t>0 \u222b SPos(n) f(t1/nP\u0303 ) dt t d\u00b5SPos(n)(P\u0303 ) (125)"
        },
        {
            "heading": "B.6.1 ALTERNATIVE DECOMPOSITION BASED ON THE QR FACTORIZATION",
            "text": "There are several choices available for decomposing GL+(n,R) and SL(n,R) such that invariant integration can be made easier while working with the smaller factors.\nThe primary tools of interest are the Iwasawa and the Cartan decomposition, and one possibility is given by the Gram decomposition (QR factorization). Let T(n,R) = {X \u2208 GL(n,R) | Xij = 0 if i > j} be the group of real upper triangular matrices and T(n,R)+ \u2264 T(n,R) its subgroup whose diagonal entries are positive. Every matrix A \u2208 GL(n,R) has a unique decomposition as A = RT or A = TR for T \u2208 T(n,R)+ and R \u2208 O(n). Under this decomposition, Theorem 4.1 (2) is applicable. The orthogonal factor becomes R \u2208 SO(n) if restricted to A \u2208 GL+(n,R). For A \u2208 SL(n,R) the decomposition is given by replacing T(n,R)+ with its subgroup ST(n,R)+ \u2264 T(n,R)+ of matrices with unit determinant."
        },
        {
            "heading": "B.7 MORE DETAILS ON THE LIE ALGEBRA PARAMETRIZATION",
            "text": "Any A \u2208 G can be expressed uniquely as A = eXR for x \u2208 m and R \u2208 H . Since H = SO(n) in both cases, the fact that expm : so(n) \u2192 SO(n) is surjective53, allows us to write it A = eXeY , Y \u2208 so(n). The factors X and R = eY are obtained using \u03a6\u22121 (22). Then by taking the principal branch of the matrix logarithm on H = SO(n), Y = logm(R). A map \u03be\u22121 : G \u2192 g as described in Section 4 is therefore constructed as \u03be\u22121 = (idm \u00d7 logm) \u25e6 \u03a6\u22121. More precisely, for any A = eXeY \u2208 G, using \u03be\u22121 we obtain the horizontal/vertical tangent vectors (Y,X) \u2208 so(n) \u00d7 m and since g = so(n)\u2295m we have a unique Z = X + Y \u2208 g. If d is the dimension of G, the tangent space g is a d-dimensional vector space isomorphic to Rd, with basis elements denoted by (E1, . . . , Ed). Once a basis is chosen we can concretely represent any element of g (or h, m) as a linear combination of the \u2018generators\u2019 such that v = \u2211d i=1 viEi for any v \u2208 g. The vee and hat functions (denoted \u2228 and \u2227) are used to map tangent vectors to their coordinates in this basis and back:\n\u2227 : Rd \u2192 g, \u2227 : v = (v1, v2, . . . , vd)T 7\u2192 v\u2227 = k\u2211\ni=1\nviEi (126)\n\u2228 : g \u2192 Rd, \u2228 : v\u2227 7\u2192 (v\u2227)\u2228 = v (127)\n52(Terras, 2016, (1.21) & (1.39)). 53(Gallier & Quaintance, 2020, Theorem 2.6).\nThe basis (Ei)i\u2208[d] is chosen to be orthonormal with respect to the inner product (109) which is used to construct the invariant metric. Going forward it is understood that functions parametrized on the Lie algebra, such as the kernel k\u0303\u03b8 : g \u2192 R, take as input the vector of scalar coefficients of the tangent vector expressed in the chosen basis (the result of the \u2228 map). To summarize, the map \u03be\u22121 : G\u2192 g is implemented for any A \u2208 G by54:\n1. Mapping A to its product space representation in m\u00d7 SO(n) using \u03a6\u22121(A) = (X,R). 2. Using the matrix logarithm on R = eY (which is available in closed form for the cases of\ninterest SO(2) and SO(3)) to obtain (X, logm(R)) = (X,Y ).\n3. Expressing the tangent vector Z = X + Y using the chosen basis as Z\u2228 \u2208 Rd."
        },
        {
            "heading": "C ARCHITECTURE & TRAINING DETAILS",
            "text": "All experiments will use the same ResNet-like architecture He et al. (2016), and it will consist of a lifting cross-correlation layer, a single residual block and a final cross-correlation layer. Finally, to achieve invariance global pooling is applied over the spatial and group dimensions. The (lifting) cross-correlation layers are always followed by normalization and non-linear activation layers. In the case of the affine robustness task, we use GeLU nonlinearities and \u2018LayerNorm\u2019 normalization55. The residual block contains 2 group cross-correlation layers and we apply max-pooling over the spatial dimension of the feature maps after each block to increase the robustness of the model. For all experiments, the kernels k\u03b8 : g \u2192 R are parametrized using \u2018SIREN networks\u2019, introduced in Sitzmann et al. (2020). SIREN networks can be considered as one example of an Implicit Neural Representation (INR) model. These models have seen widespread use in various areas of computer vision and graphics, e.g. Mildenhall et al. (2021). INRs can be formalized as learned continuous function approximators based on MLPs (multi-layer perceptrons). They can be described simply as MLP layers of the form:\nym = \u03c3 (Wmym\u22121 + bm) (128)\nwhere \u03c3 is a non-linearity. In case of SIRENs we have \u03c3(x) = sin(\u03c90x), where \u03c90 \u2208 R>0 is a multiplier controlling the frequency of the sinusoid56. We emphasize again that the proposed methodology is not dependent on the specific parametrization of k\u03b8, and have experimentally found that other activation functions such as the (complex) Gabor wavelet Saragadam et al. (2023) offer comparable results. We set \u03c90 = 10 for all experiments. We use 42 output channels in both the lifting and cross-correlation layers. Each SIREN network consists of 2 layers of size 60.\nA key hyperparameter to consider is the number of group elements that will be sampled in the Monte Carlo approximation of each of the cross-correlation layers. Empirically, we have found that 10\u221212 samples are enough to achieve a better performance compared to the previously described models. The models are trained for 100 epochs, with a batch size of 128, and the Adam optimizer of Kingma & Ba (2014) with a standard learning rate of 0.0001. Sampling from Pos(2,R) is done using the log-Normal distribution of Schwartzman (2016) centered at the identity while for SO(2) we work with a discretization of equi-distant points in [0, 2\u03c0]."
        },
        {
            "heading": "D EQUIVARIANCE ERROR ANALYSIS",
            "text": "Equivariance error Since our models are only equivariant in expectation, we validate this property numerically by measuring their equivariance error following the same approach as Sosnovik et al. (2020), where we look to quantify:\n\u2206 := \u2225Lg[\u03a6(f)]\u2212 \u03a6[Lg(f)]\u222522/\u2225Lg[\u03a6(f)]\u222522 (129)\n54Similar interpolation methods have been explored in the context of numerical linear algebra and computational mathematics. See Munthe-Kaas et al. (2001; 2014) and especially Gawlik & Leok (2018), as this method can in part be seen as an instance of their more general framework.\n55See Hendrycks & Gimpel (2016) and Ba et al. (2016). 56See Sitzmann et al. (2020) for further details.\nwhere g \u2208 G and \u03a6 represents our network. We evaluate the equivariance error before training the network, i.e. \u03a6 is a convolutional network with randomly initialized weights. We take \u03a6 to be a simple convolutional network composed of a lifting map (5), a cross correlation (7) and a projection correlation mapping our data back to a scalar field (which transforms under the trivial representation). The same normalization and nonlinearities described previously are employed. The architecture is essentially composed of the first layers of our affNIST model. In Figure 1 we plot the equivariance error of \u03a6, for different choices of k\u03b8, and compare our model to a standard CNN with the same input-output dimensionality for its layers. For the evaluation we use 100 samples from the Haar measure of SL(2,R), using the tools described in this thesis, and obtain an average estimate over 10 random seeds.\nWe compare three possible choices of kernel parametrizations, namely a standard MLP with Swish non-linearities as employed by Finzi et al. (2020), as well as the Siren Sitzmann et al. (2020) and WIRE Saragadam et al. (2023) INRs. Note that this choice will also have an effect on the equivariance error, as we are working with a discrete pixel grid when representing images, and any symmetry breaking operations will propagate the loss of equivaraince through the network.\nFigure 2 quantifies the degree to which the performance of the model described in the previous section is affected by the number of MC samples used when approximating the convolution/crosscorrelation integral. In general, we observe significant performance degradation when employing \u2264 6 samples and as in previous work on integral approximations of continuous convolutions Knigge et al. (2022) observe no additional benefits beyond 12\u221214 samples. However, an exact specification of the approximation bounds corresponding to the groups employed is missing in our presentation."
        }
    ],
    "year": 2023
}