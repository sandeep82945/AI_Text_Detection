{
    "abstractText": "This paper presents a data-driven, task-specific paradigm for experimental design, to shorten acquisition time, reduce costs, and accelerate the deployment of imaging devices. Current approaches in experimental design focus on model-parameter estimation and require specification of a particular model, whereas in imaging, other tasks may drive the design. Furthermore, such approaches often lead to intractable optimization problems in real-world imaging applications. Here we present a new paradigm for experimental design that simultaneously optimizes the design (set of image channels) and trains a machine-learning model to execute a userspecified image-analysis task. The approach obtains data densely-sampled over the measurement space (many image channels) for a small number of acquisitions, then identifies a subset of channels of prespecified size that best supports the task. We propose a method: TADRED for TAsk-DRiven Experimental Design in imaging, to identify the most informative channel-subset whilst simultaneously training a network to execute the task given the subset. Experiments demonstrate the potential of TADRED in diverse imaging applications: several clinicallyrelevant tasks in magnetic resonance imaging; and remote sensing and physiological applications of hyperspectral imaging. Results show substantial improvement over classical experimental design, two recent application-specific methods within the new paradigm, and state-of-the-art approaches in supervised feature selection. We anticipate further applications of our approach. Code is available: Code Link.",
    "authors": [
        {
            "affiliations": [],
            "name": "Stefano B. Blumberg"
        },
        {
            "affiliations": [],
            "name": "Paddy J. Slator"
        },
        {
            "affiliations": [],
            "name": "Daniel C. Alexander"
        }
    ],
    "id": "SP:8ae724cab9cd6ee5a61f6c13894f7cd38762acd0",
    "references": [
        {
            "authors": [
                "Abubakar Abid",
                "Muhammed Fatih Bal\u0131\u0306n",
                "James Zou"
            ],
            "title": "Concrete autoencoders: Differentiable feature selection and reconstruction",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2019
        },
        {
            "authors": [
                "Daniel C. Alexander"
            ],
            "title": "A general framework for experiment design in diffusion MRI and its application in measuring direct tissue-microstructure features",
            "venue": "Magnetic resonance in medicine,",
            "year": 2008
        },
        {
            "authors": [
                "Daniel C. Alexander",
                "Tim B. Dyrby",
                "Markus Nilsson",
                "Hui Zhang"
            ],
            "title": "Imaging brain microstructure with diffusion MRI: practicality and applications",
            "venue": "NMR in Biomedicine,",
            "year": 2019
        },
        {
            "authors": [
                "Yashas Annadani",
                "Panagiotis Tigas",
                "Desi R. Ivanova",
                "Andrew Jesson",
                "Yarin Gal",
                "Adam Foster",
                "Stefan Bauer"
            ],
            "title": "Differentiable multi-target causal bayesian experimental design",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2023
        },
        {
            "authors": [
                "Jiju Antony"
            ],
            "title": "Design of Experiments for Engineers and Scientists",
            "venue": "Oxford: Butterworth-Heinemann,",
            "year": 2003
        },
        {
            "authors": [
                "Boaz Arad",
                "Ohad Ben-Shahar"
            ],
            "title": "Filter selection for hyperspectral estimation",
            "venue": "In: International Conference on Computer Vision (ICCV),",
            "year": 2017
        },
        {
            "authors": [
                "David Arbour",
                "Drew Dimmery",
                "Tung Mai",
                "Anup Rao"
            ],
            "title": "Online balanced experimental design",
            "venue": "In: International Conference of Machine Learning (ICML),",
            "year": 2022
        },
        {
            "authors": [
                "Peter J. Basser",
                "Carlo Pierpaoli"
            ],
            "title": "Microstructural and physiological features of tissues elucidated by quantitative-diffusion-tensor MRI",
            "venue": "Journal of Magnetic Resonance,",
            "year": 1996
        },
        {
            "authors": [
                "Peter J. Basser",
                "James Mattiello",
                "Denis LeBihan"
            ],
            "title": "MR diffusion tensor spectroscopy and imaging",
            "venue": "Biophysical journal,",
            "year": 1994
        },
        {
            "authors": [
                "Marion F. Baumgardner",
                "Larry L. Biehl",
                "David A. Landgrebe"
            ],
            "title": "220 band AVIRIS hyperspectral image data set: June 12, 1992 indian pine test site",
            "venue": "Purdue University Research Repository doi:10.4231/R7RX991C,",
            "year": 2015
        },
        {
            "authors": [
                "Marion F. Baumgardner",
                "Larry L. Biehl",
                "David A. Landgrebe"
            ],
            "title": "Aviris hyperspectral image data",
            "venue": "set. https://purr.purdue.edu/publications/1947/1,",
            "year": 1947
        },
        {
            "authors": [
                "Tom Blau",
                "Edwin V. Bonilla",
                "Iadine Chades",
                "Amir Dezfouli"
            ],
            "title": "Optimizing sequential experimental design with deep reinforcement learning",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2022
        },
        {
            "authors": [
                "Stefano B. Blumberg",
                "Hongxiang Lin",
                "Francesco Grussu",
                "Yukun Zhou",
                "Matteo Figini",
                "Daniel C. Alexander"
            ],
            "title": "Progressive subsampling for oversampled data - application to quantitative MRI. 2022",
            "year": 2022
        },
        {
            "authors": [
                "Romain Camilleri",
                "Kevin Jamieson",
                "Julian Katz-Samuels"
            ],
            "title": "High-dimensional experimental design and kernel bandit",
            "year": 2021
        },
        {
            "authors": [
                "Osman Melih Can",
                "Yekta \u00dclgen"
            ],
            "title": "Modeling diffuse reflectance spectra of donated blood with their hematological parameters. Clinical and Preclinical Optical Diagnostics II, 2019",
            "year": 2019
        },
        {
            "authors": [
                "Timothy Castiglia",
                "Yi Zhou",
                "Shiqiang Wang",
                "Swanand Kadhe",
                "Nathalie Baracaldo",
                "Stacy Patterson"
            ],
            "title": "LESS-VFL: Communication-efficient feature selection for vertical federated learning",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2023
        },
        {
            "authors": [
                "Mara Cercignani",
                "Daniel C. Alexander"
            ],
            "title": "Optimal acquisition schemes for in vivo quantitative magnetization transfer MRI",
            "venue": "Magnetic Resonance in Medicine,",
            "year": 2006
        },
        {
            "authors": [
                "Mara Cercignani",
                "Nicholas G. Dowell",
                "Paul S. Tofts"
            ],
            "title": "Quantitative MRI of the Brain: Principles of Physical Measurement",
            "venue": "CRC Press, second edition,",
            "year": 2018
        },
        {
            "authors": [
                "Jianbo Chen",
                "Mitchell Stern",
                "Martin J. Wainwright",
                "Michael I. Jordan"
            ],
            "title": "Kernel feature selection via conditional covariance minimization",
            "venue": "Neural Information Processing Systems (NIPS),",
            "year": 2017
        },
        {
            "authors": [
                "David Cohen",
                "Tal Shnitzer",
                "Yuval Kluger",
                "Ronen Talmon"
            ],
            "title": "Few-sample feature selection via feature manifold learning",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2023
        },
        {
            "authors": [
                "Bethany Connolly",
                "Kim Moore",
                "Tobias Schwedes",
                "Alexander Adam",
                "Gary Willis",
                "Ilya Feige",
                "Christopher Frye"
            ],
            "title": "Task-specific experimental design for treatment effect estimation",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2023
        },
        {
            "authors": [
                "Ian Covert",
                "Wei Qiu",
                "Mingyu Lu",
                "Nayoon Kim",
                "Nathan White",
                "Su-In Lee"
            ],
            "title": "Learning to maximize mutual information for dynamic feature selection",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2023
        },
        {
            "authors": [
                "Nick Doudchenko",
                "Khashayar Khosravi",
                "Jean Pouget-Abadie",
                "Sebastien Lahaie",
                "Miles Lubin",
                "Vahab Mirrokni",
                "Jann Spiess",
                "Guido Imbens"
            ],
            "title": "Synthetic design: An optimization approach to experimental design with synthetic controls",
            "venue": "Neural Information Processing Systems (NIPS),",
            "year": 2021
        },
        {
            "authors": [
                "David C. Van Essen",
                "Stephen M. Smith",
                "Deanna M. Barch",
                "Timothy E.J. Behrens",
                "Essa Yacoub",
                "Kamil Ugurbil",
                "WU-Minn HCP Consortium"
            ],
            "title": "The WU-Minn Human Connectome Project: an overview",
            "year": 2013
        },
        {
            "authors": [
                "Zalan Fabian",
                "Berk Tinaz",
                "Mahdi Soltanolkotabi"
            ],
            "title": "HUMUS-Net: Hybrid unrolled multi-scale network architecture for accelerated mri reconstruction",
            "venue": "Neural Information Processing Systems (NIPS),",
            "year": 2022
        },
        {
            "authors": [
                "Rutger Fick",
                "Demian Wassermann",
                "Rachid Deriche"
            ],
            "title": "The Dmipy toolbox: Diffusion MRI multicompartment modeling and microstructure recovery made easy",
            "venue": "Frontiers in Neuroinformatics,",
            "year": 2019
        },
        {
            "authors": [
                "Xavier Fontaine",
                "Pierre Perrault",
                "Michal Valko",
                "Vianney Perchet"
            ],
            "title": "Online A-Optimal design and active linear regression",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2021
        },
        {
            "authors": [
                "Adam Foster",
                "Desi R. Ivanova",
                "Ilyas Malik",
                "Tom Rainforth"
            ],
            "title": "Deep adaptive design: Amortizing sequential bayesian experimental design",
            "venue": "Neural Information Processing Systems (NIPS),",
            "year": 2021
        },
        {
            "authors": [
                "Peter W. Glynn",
                "Ramesh Johari",
                "Mohammad Rasouli"
            ],
            "title": "Adaptive experimental design with temporal interference: A maximum likelihood approach",
            "venue": "Neural Information Processing Systems (NIPS),",
            "year": 2020
        },
        {
            "authors": [
                "Francesco Grussu",
                "Torben Schneider",
                "Carmen Tur",
                "Richard L. Yates",
                "Mohamed Tachrount",
                "Andrada Ianu\u015f",
                "Marios C. Yiannakas",
                "Jia Newcombe",
                "Hui Zhang",
                "Daniel C. Alexander",
                "Gabriele C. DeLuca"
            ],
            "title": "Neurite dispersion: a new marker of multiple sclerosis spinal cord pathology",
            "venue": "Annals of Clinical and Translational Neurology,",
            "year": 2017
        },
        {
            "authors": [
                "Francesco Grussu",
                "Stefano B. Blumberg",
                "Marco Battiston",
                "Lebina S. Kakkar",
                "Hongxiang Lin",
                "Andrada Ianu\u015f",
                "Torben Schneider",
                "Saurabh Singh",
                "Roger Bourne",
                "Shonit Punwani",
                "David Atkinson",
                "Eleftheria Panagiotaki",
                "Thomy Mertzanidou",
                "Daniel C. Alexander"
            ],
            "title": "Feasibility of data-driven, model-free quantitative MRI protocol design: Application to brain and prostate diffusion-relaxation imaging",
            "venue": "Frontiers in Physics,",
            "year": 2021
        },
        {
            "authors": [
                "H\u00e1kon Gudbjartsson",
                "Samuel Patz"
            ],
            "title": "The Rician distribution of noisy MRI data",
            "venue": "Magnetic Resonance in Medicine,",
            "year": 1995
        },
        {
            "authors": [
                "Isabelle Guyon",
                "Jason Weston",
                "Stephen Barnhill",
                "Vladimir Vapnik"
            ],
            "title": "Gene selection for cancer classification using support vector machines",
            "venue": "Journal of Machine Learning Research,",
            "year": 2002
        },
        {
            "authors": [
                "Noemi G. Gyori",
                "Marco Palombo",
                "Christopher A. Clark",
                "Hui Zhang",
                "Daniel C. Alexander"
            ],
            "title": "Training data distribution significantly impacts the estimation of tissue microstructure with machine learning",
            "venue": "Magnetic Resonance in Medicine,",
            "year": 2022
        },
        {
            "authors": [
                "Derek Hansen",
                "Brian Manzo",
                "Jeffrey Regier"
            ],
            "title": "Normalizing flows for knockoff-free controlled feature selection",
            "venue": "Neural Information Processing Systems (NIPS),",
            "year": 2022
        },
        {
            "authors": [
                "Xiaofei He",
                "Deng Cai",
                "Partha Niyogi"
            ],
            "title": "Laplacian score for feature selection",
            "venue": "Neural Information Processing Systems (NIPS),",
            "year": 2005
        },
        {
            "authors": [
                "Rafael Neto Henriques"
            ],
            "title": "Advanced methods for diffusion MRI data analysis and their application to the healthy ageing brain",
            "venue": "Ph.D Thesis,",
            "year": 2018
        },
        {
            "authors": [
                "Jana Hutter",
                "Paddy J. Slator",
                "Daan Christiaens",
                "Rui Pedro Teixeira",
                "Thomas Roberts",
                "Laurence Jackson",
                "Anthony N. Price",
                "Shaihan Malik",
                "Joseph V. Hajnal"
            ],
            "title": "Integrated and efficient diffusionrelaxometry using ZEBRA",
            "venue": "Scientific reports,",
            "year": 2018
        },
        {
            "authors": [
                "Fergus Imrie",
                "Alexander Norcliffe",
                "Pietro Li\u00f2",
                "Mihaela van der Schaar"
            ],
            "title": "Composite feature selection using deep ensembles",
            "venue": "Neural Information Processing Systems (NeurIPS),",
            "year": 2022
        },
        {
            "authors": [
                "Desi R. Ivanova",
                "Adam Foster",
                "Steven Kleinegesse",
                "Michael U. Gutmann",
                "Tom Rainforth"
            ],
            "title": "Implicit deep adaptive design: Policy-based experimental design without likelihoods",
            "venue": "Neural Information Processing Systems (NeurIPS),",
            "year": 2021
        },
        {
            "authors": [
                "Desi R. Ivanova",
                "Joel Jennings",
                "Tom Rainforth",
                "Cheng Zhang",
                "Adam Foster"
            ],
            "title": "Co-bed: Informationtheoretic contextual optimization via bayesian experimental design",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2023
        },
        {
            "authors": [
                "Jens H. Jensen",
                "Joseph A. Helpern"
            ],
            "title": "MRI quantification of non-Gaussian water diffusion by kurtosis analysis",
            "venue": "NMR in Biomedicine,",
            "year": 2010
        },
        {
            "authors": [
                "Shali Jiang",
                "Henry Chai",
                "Javier Gonzalez",
                "Roman Garnett"
            ],
            "title": "BINOCULARS for efficient, nonmyopic sequential experimental design",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2020
        },
        {
            "authors": [
                "Eleftheria Panagiotaki",
                "Shonit Punwani"
            ],
            "title": "VERDICT MRI for prostate cancer: Intracellular volume fraction versus apparent diffusion",
            "venue": "coefficient. Radiology,",
            "year": 2019
        },
        {
            "authors": [
                "Jean Kaddour",
                "Steind\u00f3r S\u00e6mundsson",
                "Marc Peter Deisenroth"
            ],
            "title": "Probabilistic active meta-learning",
            "venue": "Neural Information Processing Systems (NeurIPS),",
            "year": 2020
        },
        {
            "authors": [
                "Kouhei Kamiya",
                "Masaaki Hori",
                "Shigeki Aoki"
            ],
            "title": "NODDI in clinical research",
            "venue": "Journal of Neuroscience Methods,",
            "year": 2020
        },
        {
            "authors": [
                "Shahid Karim",
                "Akeel Qadir",
                "Umar Farooq",
                "Muhammad Shakir",
                "Asif Laghari"
            ],
            "title": "Hyperspectral imaging: A review and trends towards medical imaging",
            "venue": "Current Medical Imaging,",
            "year": 2022
        },
        {
            "authors": [
                "Tero Karras",
                "Timo Aila",
                "Samuli Laine",
                "Jaakko Lehtinen"
            ],
            "title": "Progressive growing of GANs for improved quality, stability, and variation",
            "venue": "In: International Conference on Learning Representations (ICLR),",
            "year": 2018
        },
        {
            "authors": [
                "Muhammad Khan",
                "Hamid Khan",
                "Adeel Yousaf",
                "Khurram Khurshid",
                "Asad Abbas"
            ],
            "title": "Modern trends in hyperspectral image analysis: A review",
            "venue": "IEEE Access,",
            "year": 2018
        },
        {
            "authors": [
                "Steven Kleinegesse",
                "Michael U. Gutmann"
            ],
            "title": "Bayesian experimental design for implicit models by mutual information neural estimation",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2020
        },
        {
            "authors": [
                "Florian Knoll",
                "Tullie Murrell",
                "Anuroop Sriram",
                "Nafissa Yakubova",
                "Jure Zbontar",
                "Michael Rabbat"
            ],
            "title": "Advancing machine learning for mr image reconstruction with an open competition: Overview of the 2019 fastMRI challenge",
            "venue": "Magnetic resonance in medicine,",
            "year": 2020
        },
        {
            "authors": [
                "Ron Kohavi",
                "George H. John"
            ],
            "title": "Wrappers for feature subset selection",
            "venue": "Artificial Intelligence,",
            "year": 1997
        },
        {
            "authors": [
                "Atsutoshi Kumagai",
                "Tomoharu Iwata",
                "Yasutoshi Ida"
            ],
            "title": "Few-shot learning for feature selection with Hilbert-Schmidt independence criterion",
            "venue": "Neural Information Processing Systems (NeurIPS),",
            "year": 2022
        },
        {
            "authors": [
                "Changhee Lee"
            ],
            "title": "Code for self-supervision enhanced feature selection",
            "year": 2020
        },
        {
            "authors": [
                "Changhee Lee",
                "Fergus Imrie",
                "Mihaela van der Schaar"
            ],
            "title": "Self-supervision enhanced feature selection with correlated gates",
            "venue": "International Conference on Learning Representations (ICLR),",
            "year": 2022
        },
        {
            "authors": [
                "Yifeng Li",
                "Chih-Yu Chen",
                "Wyeth W. Wasserman"
            ],
            "title": "Deep feature selection: Theory and application to identify enhancers and promoters",
            "venue": "Journal of Computational Biology,",
            "year": 2016
        },
        {
            "authors": [
                "Jonathan Lightley",
                "Frederik G\u00f6rlitz",
                "Sunil Kumar",
                "Ranjan Kalita",
                "Arinbjorn Kolbeinsson",
                "Edwin Garcia",
                "Yuriy Alexandrov",
                "Vicky Bousgouni",
                "Riccardo Wysoczanski",
                "Peter Barnes",
                "Louise Donnelly",
                "Chris Bakal",
                "Christopher Dunsby",
                "Mark A.A. Neil",
                "Seth Flaxman",
                "Paul M.W. French"
            ],
            "title": "Robust deep learning optical autofocus system applied to automated multiwell plate single molecule localization microscopy",
            "venue": "Journal of Microscopy,",
            "year": 2022
        },
        {
            "authors": [
                "Ofir Lindenbaum",
                "Uri Shaham",
                "Erez Peterfreund",
                "Jonathan Svirsky",
                "Nicolas Casey",
                "Yuval Kluger"
            ],
            "title": "Differentiable unsupervised feature selection based on a gated laplacian",
            "venue": "Neural Information Processing Systems (NeurIPS),",
            "year": 2021
        },
        {
            "authors": [
                "Guolan Lu",
                "Baowei Fei"
            ],
            "title": "Medical hyperspectral imaging: a review",
            "venue": "Journal of Biomedical Optics,",
            "year": 2014
        },
        {
            "authors": [
                "Clare Lyle",
                "Arash Mehrjou",
                "Pascal Notin",
                "Andrew Jesson",
                "Stefan Bauer",
                "Yarin Gal",
                "Patrick Schwab"
            ],
            "title": "DiscoBAX: Discovery of optimal intervention sets in genomic experiment design",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2023
        },
        {
            "authors": [
                "Gustavo Malkomes",
                "Bolong Cheng",
                "Eric H Lee",
                "Mike Mccourt"
            ],
            "title": "Beyond the pareto efficient frontier: Constraint active search for multiobjective experimental design",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2021
        },
        {
            "authors": [
                "Dimitris G. Manolakis",
                "Ronald B. Lockwood",
                "Thomas W. Cooley"
            ],
            "title": "Hyperspectral Imaging Remote Sensing: Physics, Sensors, and Algorithms",
            "year": 2016
        },
        {
            "authors": [
                "Arash Mehrjou",
                "Ashkan Soleymani",
                "Andrew Jesson",
                "Pascal Notin",
                "Yarin Gal",
                "Stefan Bauer",
                "Patrick Schwab"
            ],
            "title": "Genedisco: A benchmark for experimental design in drug",
            "venue": "discovery. In: International Conference on Learning Representations (ICLR),",
            "year": 2022
        },
        {
            "authors": [
                "Viraj Mehta",
                "Biswajit Paria",
                "Jeff Schneider",
                "Stefano Ermon",
                "Willie Neiswanger"
            ],
            "title": "An experimental design perspective on model-based reinforcement learning",
            "venue": "In: International Conference on Learning Representations (ICLR),",
            "year": 2022
        },
        {
            "authors": [
                "Douglas C. Montgomery"
            ],
            "title": "Design and analysis of experiments",
            "venue": "John Wiley & Sons, fifth edition,",
            "year": 2001
        },
        {
            "authors": [
                "Matthew J. Muckley",
                "Benedikt Riemenschneider",
                "Alaleh Radmanesh",
                "Sooyoung Kim",
                "Gukyeong Jeong",
                "Jaeho Ko"
            ],
            "title": "Results of the 2020 fastMRI challenge for machine learning MR image reconstruction",
            "venue": "IEEE transactions on medical imaging,",
            "year": 2021
        },
        {
            "authors": [
                "Mojmir Mutny",
                "Andreas Krause"
            ],
            "title": "Experimental design for linear functionals in reproducing kernel Hilbert spaces",
            "venue": "Neural Information Processing Systems (NeurIPS),",
            "year": 2022
        },
        {
            "authors": [
                "Preetam Nandy",
                "Divya Venugopalan",
                "Chun Lo",
                "Shaunak Chatterjee"
            ],
            "title": "A/B testing for recommender systems in a two-sided marketplace",
            "venue": "Neural Information Processing Systems (NeurIPS),",
            "year": 2021
        },
        {
            "authors": [
                "Eleftheria Panagiotaki",
                "Rachel W. Chan",
                "Nikolaos Dikaios",
                "Hashim U. Ahmed",
                "James O\u2019Callaghan",
                "Alex Freeman",
                "David Atkinson",
                "Shonit Punwani",
                "David J. Hawkes",
                "Daniel C. Alexander"
            ],
            "title": "Microstructural characterization of normal and malignant human prostate tissue with vascular, extracellular, and restricted diffusion for cytometry in tumours magnetic resonance imaging",
            "venue": "Investigative Radiology,",
            "year": 2015
        },
        {
            "authors": [
                "Eleftheria Panagiotaki",
                "Andrada Ianu\u015f",
                "Edward Johnston",
                "Rachel W. Chan",
                "Nicola Stevens",
                "David Atkinson",
                "Shonit Punwani",
                "David J. Hawkes",
                "Daniel C. Alexander"
            ],
            "title": "Optimised VERDICT MRI protocol for prostate cancer characterisation. In: International Society for Magnetic Resonance in Medicine (ISMRM), 2015b",
            "year": 2015
        },
        {
            "authors": [
                "Eletheria Panagiotaki",
                "Simon Walker-Samuel",
                "Bernard Siow",
                "Peter S. Johnson",
                "Vineeth Rajkumar",
                "Barbara R. Pedley",
                "Mark F. Lythgoe",
                "Daniel C. Alexander"
            ],
            "title": "Noninvasive quantification of solid tumor microstructure using VERDICT MRI",
            "venue": "Cancer research,",
            "year": 1902
        },
        {
            "authors": [
                "Hanchuan Peng",
                "Fuhui Long",
                "Chris Ding"
            ],
            "title": "Feature selection based on mutual information: criteria of max-dependency, max-relevance, and min-redundancy",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2005
        },
        {
            "authors": [
                "Friedrich Pukelsheim"
            ],
            "title": "Optimal Design of Experiments",
            "venue": "Society for Industrial and Applied Mathematics,",
            "year": 2006
        },
        {
            "authors": [
                "Francesco Quinzan",
                "Ashkan Soleymani",
                "Patrick Jaillet",
                "Cristian R. Rojas",
                "Stefan Bauer"
            ],
            "title": "DRCFS: Doubly robust causal feature selection",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2023
        },
        {
            "authors": [
                "Logan R. Ranzenberger",
                "Travis Snyder"
            ],
            "title": "Diffusion Tensor Imaging. StatPearls Publishing, fifth edition, 2022",
            "year": 2022
        },
        {
            "authors": [
                "David Simchi-Levi",
                "Chonghuan Wang"
            ],
            "title": "Pricing experimental design: Causal effect, expected revenue and tail risk",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2023
        },
        {
            "authors": [
                "John J. Simmonds",
                "Robert O. Green"
            ],
            "title": "Current status, preformance and plans for the NASA airborne visible and infrared imaging spectrometer (AVIRIS)",
            "venue": "URL https://www.osti.gov/ biblio/379497",
            "year": 1996
        },
        {
            "authors": [
                "Andrew Sinkoe",
                "Juergen Hahn"
            ],
            "title": "Optimal experimental design for parameter estimation of an IL-6 signaling",
            "venue": "model. Processes,",
            "year": 2017
        },
        {
            "authors": [
                "Paddy J. Slator",
                "Marco Palombo",
                "Karla L. Miller",
                "Carl-Fredrik Westin",
                "Frederik Laun",
                "Daeun Kim",
                "Justin P. Haldar",
                "Dan Benjamini",
                "Gregory Lemberskiy",
                "Joao P. de Almeida Martins",
                "Jana Hutter"
            ],
            "title": "Combined diffusion-relaxometry microstructure imaging: Current status and future prospects",
            "venue": "Magnetic Resonance in Medicine,",
            "year": 2021
        },
        {
            "authors": [
                "Ghada Sokar",
                "Zahra Atashgahi",
                "Mykola Pechenizkiy",
                "Decebal Constantin Mocanu"
            ],
            "title": "Where to pay attention in sparse training for feature selection",
            "venue": "Neural Information Processing Systems (NeurIPS),",
            "year": 2022
        },
        {
            "authors": [
                "Le Song",
                "Alexander J. Smola",
                "Arthur Gretton",
                "Justin Bedo",
                "Karsten M. Borgwardt"
            ],
            "title": "Supervised feature selection via dependence estimation",
            "venue": "In: International Conference on Machine learning (ICML),",
            "year": 2007
        },
        {
            "authors": [
                "Le Song",
                "Alexander J. Smola",
                "Arthur Gretton",
                "Justin Bedo",
                "Karsten M. Borgwardt"
            ],
            "title": "Feature selection via dependence maximization",
            "venue": "Journal of Machine Learning Research,",
            "year": 2012
        },
        {
            "authors": [
                "Mary B. Stuart",
                "Andrew J.S. McGonigle",
                "Jon R. Willmott"
            ],
            "title": "Hyperspectral imaging in environmental monitoring: A review of recent developments and technological advances in compact field deployable systems",
            "year": 2019
        },
        {
            "authors": [
                "Mary B. Stuart",
                "Leigh R. Stanger",
                "Matthew J. Hobbs",
                "Tom D. Pering",
                "Daniel Thio",
                "Andrew J.S. McGonigle",
                "Jon R. Willmott"
            ],
            "title": "Low-cost hyperspectral imaging system: Design and testing for laboratory-based environmental applications",
            "year": 2020
        },
        {
            "authors": [
                "Woo Suk Tae",
                "Byung Joo Ham",
                "Sung Bom Pyun",
                "Shin Hyuk Kang",
                "Byung Jo Kim"
            ],
            "title": "Current clinical applications of diffusion-tensor imaging in neurological disorders",
            "venue": "Journal of Clinical Neurology,",
            "year": 2018
        },
        {
            "authors": [
                "Ali Ahmadi Teshnizi",
                "Saber Salehkaleybar",
                "Negar Kiyavash"
            ],
            "title": "Lazyiter: A fast algorithm for counting markov equivalent dags and designing experiments",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2020
        },
        {
            "authors": [
                "David R. Thompson",
                "Joseph W. Boardman",
                "Michael L. Eastwood",
                "Robert O. Green"
            ],
            "title": "A large airborne survey of earth\u2019s visible-infrared spectral dimensionality",
            "venue": "Optics Express,",
            "year": 2017
        },
        {
            "authors": [
                "Robert Tibshirani"
            ],
            "title": "Regression shrinkage and selection via the lasso",
            "venue": "Journal of the Royal Statistics Society. Series B (Methodological), pp",
            "year": 1996
        },
        {
            "authors": [
                "Panagiotis Tigas",
                "Yashas Annadani",
                "Andrew Jesson",
                "Bernhard Sch\u00f6lkopf",
                "Yarin Gal",
                "Stefan Bauer"
            ],
            "title": "Interventions, where and how? Experimental design for causal models at scale",
            "venue": "Neural Information Processing Systems (NeurIPS),",
            "year": 2022
        },
        {
            "authors": [
                "Panagiotis Tigas",
                "Yashas Annadani",
                "Desi R. Ivanova",
                "Andrew Jesson",
                "Yarin Gal",
                "Adam Foster",
                "Stefan Bauer"
            ],
            "title": "Differentiable multi-target causal bayesian experimental design",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2023
        },
        {
            "authors": [
                "Dale J. Waterhouse",
                "Danail Stoyanov"
            ],
            "title": "Optimized spectral filter design enables more accurate estimation of oxygen saturation in spectral imaging",
            "venue": "Biomedical Optics Express,",
            "year": 2022
        },
        {
            "authors": [
                "Maksymilian A. Wojtas"
            ],
            "title": "Code for feature importance ranking for deep learning, git commit 836096edb9f822e509cadcf9cd2e7cc5fa2324cc",
            "venue": "FeatureImportanceDL,",
            "year": 2021
        },
        {
            "authors": [
                "Maksymilian A. Wojtas",
                "Ke Chen"
            ],
            "title": "Feature importance ranking for deep learning",
            "venue": "Neural Information Processing System (NeurIPS),",
            "year": 2020
        },
        {
            "authors": [
                "Renjie Wu",
                "Yuqi Li",
                "Xijiong Xie",
                "Zhijie Lin"
            ],
            "title": "Optimized multi-spectral filter arrays for spectral reconstruction",
            "year": 2019
        },
        {
            "authors": [
                "Yutaro Yamada",
                "Ofir Lindenbaum",
                "Sahand Negahban",
                "Yuval Kluger"
            ],
            "title": "Feature selection using stochastic gates",
            "venue": "In: International Conference on Machine Learning (ICML),",
            "year": 2020
        },
        {
            "authors": [
                "Burhaneddin Yaman",
                "Seyed Amir Hossein Hosseini",
                "Mehmet Ak\u00e7akaya"
            ],
            "title": "Zero-shot selfsupervised learning for MRI reconstruction",
            "venue": "In: International Conference on Learning Representations (ICLR),",
            "year": 2022
        },
        {
            "authors": [
                "Vincent D. Zaballa",
                "Elliot E. Hui"
            ],
            "title": "Stochastic gradient bayesian optimal experimental designs",
            "year": 2024
        },
        {
            "authors": [
                "Jure Zbontar",
                "Florian Knoll",
                "Anuroop Sriram",
                "Tullie Murrell",
                "Zhengnan Huang",
                "Matthew J Muck"
            ],
            "title": "Machine Learning (ICML), 2023",
            "year": 2023
        },
        {
            "authors": [
                "Sue Zheng",
                "David Hayden",
                "Jason Pacheco",
                "John W Fisher III"
            ],
            "title": "Sequential bayesian experimental",
            "venue": "International Conference on Machine Learning (ICML),",
            "year": 2022
        },
        {
            "authors": [
                "Waterhouse",
                "Stoyanov"
            ],
            "title": "2022), we followed standard practice and performed a brief hyperparameter search on the validation",
            "venue": "set. We used C1,",
            "year": 2022
        },
        {
            "authors": [
                "Lee"
            ],
            "title": "The full optimization procedure follows Lee et al",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Experimental design seeks a sampling scheme or design D = {d1, ...,dC}, where each di, i = 1, ..., C, is a combination of experimental variables that are under the control of the experimenter, that provides data optimally informative for some criteria or task Antony (2003); Pukelsheim (2006). The experimental outcome (measured data) of design D is a matrix XD \u2208 Rn\u00d7C with C corresponding measurements from each of n samples. The optimal choice of design depends on the experimental task, which we express as a function T that maps XD to a corresponding matrix Y of labels. Experimental design optimization seeks the design that maximizes the ability to perform the task, subject to constraints of time or cost, i.e.\nD\u2217 = argmin D L(T (XD), Y ), subject to |D| = C (1)\nwhere L is a loss function. Here we limit cost simply to the size C of D; T can be any task, but often in imaging involves estimating/mapping model parameters e.g. via gradient-descent model-fitting in every pixel/voxel, as in Alexander (2008); Cercignani & Alexander (2006), or machine learning as in Gyori et al. (2022); Waterhouse & Stoyanov (2022).\nIn imaging, as illustrated in figure 1a, XD is typically a collection of n pixels or voxels with C channels (e.g. RGB images have C = 3). The choice of di \u2208 D controls the contrast in channel i and is global to the whole channel. Compact (small C) but informative designs are often critical in reducing acquisition or development costs in real-world applications. Examples include acquiring magnetic resonance imaging (MRI) contrasts, e.g. to estimate and map microstructural tissue"
        },
        {
            "heading": "Combination of Independent Variables",
            "text": "properties within the time a patient can stay still in a scanner Alexander (2008), or manufacturing affordable hyperspectral imaging devices including a few well-chosen spectral filters, e.g. for estimating tissue oxygenation Waterhouse & Stoyanov (2022).\nStandard approaches for experimental design typically optimize D over a continuous space, for the task of model parameter estimation. For example, a classical approach still widely deployed uses the Fisher matrix Montgomery (2001), whilst more recent approaches use the paradigm of sequential Bayesian experimental design Blau et al. (2022); Foster et al. (2021); Ivanova et al. (2021). Both require a priori model choice, limiting consideration to model-based tasks, and even specific model-parameter choices or assumptions on their prior distribution. Moreover, such approaches rapidly become computationally intractable as the dimension of the optimization increases.\nHere we suggest a new task-driven paradigm for experimental design for real-world imaging applications, illustrated in figure 1b, that does not require a priori model specification and replaces high-dimensional continuous search with a subsampling problem. First, the paradigm requires training data XD\u0304 with C\u0304 channels/measurements acquired using a design D\u0304 that densely samples the measurement space. Secondly the paradigm selects a subset of size C \u226a C\u0304 image channels from XD\u0304 (optimizing the design and choosing XD \u2282 XD\u0304), coupled with the training of a high-performing neural network that executes the task T driving the experimental design. Thus, the new paradigm replaces the optimization in equation 1 with:\nD\u2217, T \u2217 = argmin D,T L(T (XD), Y ) subject to D \u2282 D\u0304. (2)\nIn this paradigm, the task must be specified a priori, but may go beyond standard model-based tasks that drive classical/Bayesian experimental design, to include \u2018model free\u2019 tasks such as missing data reconstruction. The training data requires only a small number of subjects/samples, so may use specialized hardware, lengthy acquisitions, or even simulations. In practice, such acquisitions are often made during early development phases of imaging technologies to explore the range of sensitivity, which informs the choice of, and often provides, D\u0304. The paradigm we propose formalizes the exploitation of such data in experimental design for downstream systems designed for wide deployment and directly supports the use of deep learning for T . In the new paradigm, the experimental design problem becomes similar to supervised feature selection, where the C\u0304 image channels of XD\u0304 are considered features. In supervised feature selection, stateof-the-art approaches Wojtas & Chen (2020); Lee et al. (2022) couple feature selection with task optimization, however the structure of the data in typical supervised feature selection problems differs from those in experimental design for imaging. Feature selection algorithms typically assume most features are uninformative and the task is to \u2018identify a small, highly discriminative subset\u2019 Kuncheva et al. (2020) e.g. genes associated with drug response from the entire genome. In experimental design for imaging, however, most channels individually offer similar amounts of information to support task performance, since they view the same scene/sample but with often-subtle differences in contrast (see e.g. figure 6). Design optimization seeks a compact combination that covers all important aspects.\nTherefore we propose TADRED, a novel method for TAsk-DRiven Experimental Design in imaging. TADRED couples feature scoring and task execution in consecutive networks. The scoring and subsampling procedure enables efficient identification of subsets of complementarily informative\nchannels jointly with training a high-performing network for the task. TADRED also gradually reduces the full set of samples stepwise to obtain the subsamples, which improves optimization.\nKey contributions are:\n1. A new coupled subsampling-task paradigm for experimental design in imaging. 2. TADRED: a novel approach for supervised feature selection tuned specifically for experimental\ndesign in imaging. TADRED performs task-based image channel selection. Code is: Code Link. 3. A demonstration of our approach on six datasets/tasks in both clinically-relevant MRI and remote\nsensing and physiological applications in hyperspectral imaging. TADRED outperforms (i) Classical experimental design, (ii) Recent application-specific published results, (iii) State-of-theart approaches in supervised feature selection."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "Approaches in Experimental Design A typical task in experimental design is to optimize the design D for estimating model parameters. The most widely used classical approach in imaging uses the Fisher information matrix Pukelsheim (2006). However, for non-linear models, the optimization requires pre-specification of parameter values of interest, leading to circularity, e.g. the standard design for VERDICT model with primary application in prostate cancer detection and classification Panagiotaki et al. (2015a) (used as a baseline in table 1) is computed by optimizing the Fisher-matrix for one specific combination of parameter values, despite aiming to highlight contrast in those parameters throughout the entire prostate. Approaches in the sequential Bayesian experimental design paradigm Blau et al. (2022); Foster et al. (2021); Ivanova et al. (2021) reduce this circularity by optimizing over combinations or ranges of parameter values. Recently Blau et al. (2022) also implemented an experimental design optimization in a discrete space and obtained state-of-the-art performance and deployment time, by using reinforcement learning to map history of designs and outcomes to the next design. However, the tasks driving experimental design in imaging are often \u2018model free\u2019 supervised tasks such as missing data reconstruction (tables 2, 3) to recover missing image channels. Classical Fisher-matrix experimental design or sequential Bayesian techniques do not apply in such problems. Furthermore, the sequential Bayesian techniques have been deployed on only small-scale experiments with simulated data e.g. a simple localization problem for two sources. For example, experiments in Blau et al. (2022) have C \u2264 2 and D \u2208 Rdim, dim \u2264 6. In contrast, e.g. the real-world experiment in table 1 has C \u2208 {110, 55, 28, 14} and D \u2208 R7\u00b7C . Preliminary experiments suggest the application of these approaches to the high dimensional problems is not computationally tractable with the published code/methods. These issues motivate the reformulation of the experimental design paradigm and the introduction of TADRED. Appendix-E is a broader review of experimental design for quantitative MRI (qMRI) and hyperspectral imaging.\nSupervised Feature Selection operates either at the instance level e.g. identifying different salient parts of different images; or at the population level by selecting across all the instances. In imaging, each combination of acquisition parameters di \u2208 D is global across all image pixels/voxels, so channel-selection for experimental design must be population-wide. Recursive feature elimination (RFE) / backward selection Guyon et al. (2002); Scikit-Learn (2023); Kohavi & John (1997) are frameworks that seek the most informative set of features among a superset to inform a model or task. They work by eliminating the least informative features stepwise to reach a prespecified feature-set size. \u2018Feature Importance Ranking for Deep Learning\u2019 (FIRDL) Wojtas & Chen (2020), \u2018Self-Supervision Enhanced Feature Selection with Correlated Gates\u2019 (SSEFS) Lee et al. (2022) are considered state-of-the-art in feature selection, outperforming both classical (e.g. RFE) and recent approaches outlined in appendix-E. Both techniques are specifically designed to \u2018identify a small, highly discriminative\u2019 subset Kuncheva et al. (2020) of features from a larger group of mostly uninformative features. SSEFS, in a first step, uses a probabilistic approach to search for this subset, whilst also exploiting the presence of correlated subsets for enhanced performance. A second step then trains a network on the chosen subset to execute the task. FIRDL instead has a complex optimization procedure involving exploration-exploitation stochastic local search. SSEFS and FIRDL are detailed in appendix A and are baselines in later experiments.\nIn contrast to typical feature selection problems, most candidate choices in experimental design are informative: few, if any, features are uninformative so no single small discriminative set exists. SSEFS\u2019s first step seeks groups of correlated features, which is less useful in experiment design, as\nmost image channels correlate strongly (examples in figure 5). FIRDL incorporates global information by performing multiple evaluations on different feature combinations. However, FIRDL\u2019s search for a discriminative subset is inappropriate in the experimental design application; its multiple evaluations of the task-execution network are redundant and result in covariate shift and overfitting.\nNevertheless, TADRED builds upon the basic principles of task-driven feature selection, which is the foundation of FIRDL and SSEFS\u2019s success. TADRED adopts the same dual-network architecture, but with a different optimization procedure tailored to the experimental design problem. Specifically, TADRED\u2019s implements a novel combination of the dual selection/task network optimization within the paradigms of RFE/backwards selection. As such, it adopts a comparatively simple scoring procedure, which avoids the complicated and suboptimal joint optimization FIRDL/SSEFS require to search for a distinctively discriminative subset. TADRED\u2019s end-to-end dual networks avoids FIRDL\u2019s multiple evaluations on different feature combinations, and TADRED\u2019s passing of information through the optimization procedure improves on both SSEFS and FIRDL.\nFinally, PROSUB Blumberg et al. (2022) (baseline in table 2) is a previous attempt to equate experimental design with feature selection and also uses RFE. It uses a customized neural architecture search at every step and was designed specifically to address a measurement-selection problem in qMRI (data in table 2) where it achieves state-of-the-art performance. However, the technique does not naturally generalize to other tasks, which is a key motivation for TADRED. TADRED avoids PROSUB\u2019s cumbersome neural architecture search and implements instead a novel four-phase procedure in each step, which keeps the gradient updates smooth and allows feature selection at each step. Also, beyond standard RFE, TADRED efficiently passes information from the optimization on larger feature sets to smaller sets by passing information on the network weights across the steps, unlike PROSUB. These advances combine to enhance substantially the performance, portability and generalizability of the algorithm across diverse experimental design problems."
        },
        {
            "heading": "3 TADRED: TASK-DRIVEN EXPERIMENTAL DESIGN FOR IMAGING",
            "text": "TADRED presents a novel approach to supervised feature selection, tailored to the particularities of the experimental design problem in imaging, and aims to solve equation 2. Section 3.1 describes an outer loop of the procedure, which is inspired by classical paradigms Kohavi & John (1997); Guyon et al. (2002), that gradually eliminates elements from the densely-sampled design D\u0304 in t = 1, ..., T steps to obtain designs D\u0304 = D1 \u2283 ... \u2283 DT . This corresponds to performing supervised feature selection for decreasing sizes C\u0304 = C1 > ... > CT , where {Ct}Tt=1 are chosen by the user a priori. Then section 3.2 outlines an inner loop for training with fixed 1 \u2264 t \u2264 T . Inspired by recent supervised feature selection advances Imrie et al. (2022); Wojtas & Chen (2020), TADRED trains two coupled networks at each step: a scoring network St, which scores individual elements of XD\u0304 for importance to inform the subsampling, and a task network Tt, which performs the task driving the design, i.e. estimates Y from chosen feature subset XDt \u2282 XD\u0304. The training procedure is split into four phases that allows feature selection at each step and is inspired by Karras et al. (2018); Blumberg et al. (2022) which produced enhanced optimization. The full procedure is outlined in algorithm 2."
        },
        {
            "heading": "3.1 OUTER LOOP",
            "text": "Across steps t = 1, ..., T we consider decreasing feature set sizes C\u0304 = C1 > C2 > ... > CT and perform supervised feature selection at each step in an inner loop (see section 3.2). Reducing feature set sizes stepwise aids the optimization procedure compared to e.g. training on all features then subsampling all at once (see table 5). The procedure passes information from the optimization on larger feature sets to smaller sets. Finally, the stepwise procedure efficiently produces a set of optimized designs (as is typical in supervised feature selection see e.g. Wojtas & Chen (2020) and also in Waterhouse & Stoyanov (2022)), which can be useful for post-hoc selection of design size to balance economy (small C) with task performance. Whilst iterative subsampling also increases computational time, this is comparable to other supervised feature selection approaches (appendix D)."
        },
        {
            "heading": "3.2 INNER LOOP: FOUR-PHASE DEEP LEARNING TRAINING",
            "text": "At step 1 \u2264 t \u2264 T of the outer loop the inner loop constructs (i) a binary mask mt \u2208 {0, 1}C\u0304 , ||mt||0 = Ct to subsample the features; (ii) a weight vector for the features s\u0304t \u2208 RC\u0304+;\n(iii) a trained network Tt to perform the task, which corresponds to solving the optimization problem:\nminimize mt, Tt, s\u0304t L(Tt(XDt \u2299 s\u0304t), Y ), subject to ||mt||0 = Ct,\nwhere XDt = mt \u2299XD\u0304 + (1C\u0304 \u2212mt)\u2299XfillD\u0304 , (3)\nthe \u2299 operation is element-wise dot product which follows broadcasting rules when inputs have mismatched dimensions, ||\u00b7||0 is the L0 norm, 1C\u0304 is a vector with C\u0304 ones, and \u2018feature fill\u2019 XfillD\u0304 \u2208 R C\u0304 is a hyperparameter that fills the removed features (we take the data median, see appendix C.2). The weight vector s\u0304t contains feature scores, which the training procedure uses to remove low-scoring features by setting corresponding values of the mask mt to 0.\nScoring, Subsampling, and Task Execution The core of the training procedure uses the forward/backward pass in algorithm 1. The full procedure in algorithm 2 uses the forward/backward pass to update feature scoring gradually in tandem with improving label prediction.\nThe procedure aims to learn a meaningful sample-independent feature score to rank the features. In practice, deep-learning training is performed in batches and not across the whole data. Therefore we first learn a sample-dependent feature score \u03c3(St(XD\u0304)) = s\u0303 \u2208 Rn\u00d7C\u0304+ , where St is a neural network and \u03c3 : R\u2192 [0,\u221e) is an activation function to ensure positive scores (we take \u03c3 = 2 \u00b7 sigmoid and at initialization \u03c3(0) = 1). We then compute a sample-independent score s\u0304t \u2208 RC\u0304+ as an average of s\u0303 across the n samples in XD. We also compute a combined score that aids task execution\ns = \u03b1\u2299 s\u0303+ (1\u2212 \u03b1)\u2299 s\u0304t, \u03b1 \u2208 [0, 1], (4)\nwhich balances the current learned sample-dependent score with a fixed global estimate of the sampleindependent score and allows smooth integration between the two. The mix parameter \u03b1 is set in the optimization procedure to shift the balance from sample-dependent to sample-independent scores.\nWe use a mask mt \u2208 [0, 1]C\u0304 to subsample the features XDt = mt \u2299 XD\u0304 + (1C\u0304 \u2212 mt) \u2299 XfillD\u0304 , and replace the removed features with default values Xfill\nD\u0304 to retain the shape of the data structures\nthroughout training. Rather than learning the mask mt end-to-end e.g. using a sparsity term/prior as in Lee et al. (2022), we modify elements of mt during our training procedure. This is important to enable the outer loop of the procedure to output candidate designs at each step.\nWe now estimate the target Y with Y\u0302 = Tt(s\u2299XDt) from the subsampled data weighted feature-wise by the score, then calculate the loss L(Y\u0302 , Y ). This weighting allows gradients to flow end-to-end.\nTraining Procedure The key challenges in the design of the training procedure in the inner loop are how to (i) obtain meaningful global sample-independent scores s\u0304t from learnt sample-dependent scores s\u0303t, (ii) differentiate through a masking operation to compute mt. TADRED\u2019s four-phase procedure, inspired by Karras et al. (2018); Blumberg et al. (2022) gradually modifies the neural network structure during deep learning training, moving from learning a simpler task (learning sample-dependent scores and retaining most features) to a more complex task (learning sampleindependent scores and removing more features) by linear interpolation of network components. This improves optimization over directly learning the more difficult task. Thus we address (i) by first learning s\u0303 and then progressively reducing the final score to the average of s\u0303 its average i.e. s = s\u0304t (in algorithm 2 phase 2), and (ii) by progressively setting elements of mt to zero i.e., during training, mask elements are real valued but gradually reduce to binary values (in phase 3).\nThe training procedure is different for the first outer loop step t = 1 compared to steps t \u2265 2. This is because for step t = 1 we train on all C\u0304 features and do not have information from previous steps and for steps t \u2265 2 we perform supervised feature selection for user-chosen Ct (solve equation 3) and training is initialized from step t\u2212 1. We describe each step with reference to algorithm 2. Training for Step t = 1 In the first step (lines 1-4), we simply train S1, T1 on full information i.e. on all features for total (chosen) E epochs. At completion, we set the first sample-independent score s\u03041 (line 4) to be the mean of the sample-dependent scores s\u0303 across samples/batches. We found training solely on a sample-dependent score results in faster optimization.\nTraining for Steps t = 2,...,T The four phases require choosing the number of epochs for each phase: 1 <= E1 < E2 < E3 < E for total number of epochs E, training proceeds as follows:\nAlgorithm 1 TADRED Forward & Backward Pass (FBP) in Step t Requires: Input and Target Data XD\u0304, Y , Mask mt Scoring and Task Networks St, Tt, Loss L Sample-independent Feature Score s\u0304t Mix Parameter \u03b1 \u2208 [0, 1], Feature Fill Xfill\nD\u0304\n1: s\u0303 = \u03c3(St(XD\u0304)) 2: s = \u03b1\u2299 s\u0303+ (1\u2212 \u03b1)\u2299 s\u0304t # Equation 4 3: XDt = mt \u2299XD\u0304 + (1C\u0304 \u2212mt)\u2299XfillD\u0304 4: Y\u0302 = Tt(s\u2299XDt) 5: Compute L(Y\u0302 , Y ) and backpropagate\nAlgorithm 2 TADRED Optimization Requires: Input and Target Data XD\u0304 \u2208 Rn\u00d7C\u0304 , Y Loss L, Feature Fill Xfill\nD\u0304 \u2208 RC\u0304\nFeature Set Sizes C\u0304 = C1 > ... > CT Training Steps 1 \u2264 E1 < E2 < E3 < E Initial Scoring and Task Networks S1, T1\n1: t\u2190 1; m1 \u2190 1C\u0304 ; \u03b1\u2190 1 # Step t = 1 2: for e\u2190 1, ..., E do 3: FBP() # Algorithm 1 4: s\u03041 \u2190 mean of s\u0303 across data 5: for t\u2190 2, ..., T do # Steps t \u2265 2 6: # Phase 1 7: s\u0304t \u2190 s\u0304t\u22121; \u03b1\u2190 12 ; mt \u2190 mt\u22121 8: for e\u2190 1, ..., E1 do 9: FBP()\n10: s\u0304\u2190 mean of s\u0303 on data # Phase 2 11: s\u0304t \u2190 12 (s\u0304t + s\u0304) 12: for e\u2190 E1 + 1, ..., E2 do 13: \u03b1\u2190 max{\u03b1\u2212 12(E2\u2212E1) , 0} 14: FBP() 15: # Indices that sort an array; Phase 3 16: R = argsort{s\u0304t[i] : mt[i] = 1} 17: Dt \u2190 {R[0], ..., R[Ct\u22121 \u2212 Ct]} 18: for e\u2190 E2 + 1, ..., E3 do 19: mt \u2190 max{mt\u2212\nI[i]i\u2208Dt E3\u2212E2 , 0C\u0304}\n20: FBP() 21: for e\u2190 E3+1, ..., E do # Phase 4 22: FBP() 23: Cache Tt, mt, s\u0304t for equation 3\nPhase 1) Initialize St and Tt from St\u22121 and Tt\u22121, s\u0304t to s\u0304t\u22121, mt to mt\u22121,e and \u03b1 = 12 to balance learning a new score for this step and using information from the learnt score from step t\u2212 1. Run E1 epochs to refine scores and task execution with \u03b1 and mt fixed.\nPhase 2) Update the sample-independent score s\u0304t with the learnt score from phase 1 (line 11). Run E2 \u2212 E1 epochs progressively linearly modifying \u03b1 (line 13), so training moves gradually from using sample-dependent scores to sample-independent.\nPhase 3) Choose the Ct\u22121\u2212Ct lowest-scored features to remove (lines 16, 17). Run E3 \u2212 E2 epochs linearly modifying the mask for subsampling (line 19). This alters the Ct\u22121 \u2212 Ct elements of mt corresponding to the lowest-scored features gradually to 0. Thus ||mt||0 = Ct\u22121 goes to ||mt||0 = Ct. Separating this phase from phase 2 increases the stability of the optimization, as modifying the mask and score simultaneously results in large gradients.\nPhase 4) Train Tt for final refinement for E \u2212 E3 epochs with the score weights fixed and features chosen. At completion return Tt, mt, s\u0304t."
        },
        {
            "heading": "Implementation Details and Hyperparameters",
            "text": "TADRED\u2019s hyperparameters are fixed across experiments and different application areas. They are detailed in appendix A."
        },
        {
            "heading": "4 EXPERIMENTS AND RESULTS",
            "text": "This section demonstrates the benefits of TADRED in multiple scenarios, with example applications in qMRI and hyperspectral imaging. First, in table 1, we consider the standard experimental design task of model parameter estimation and outperform classical Fishermatrix approaches. Within the new paradigm, we also show improvements over recent supervised feature selection approaches. We then show TADRED\u2019s efficacy in a \u2018model-free\u2019 experimental design scenario: reconstruction of a densely sampled data set from a sparse subset, where Fisher-matrix or recent Bayesian experimental design cannot operate and TADRED outperforms best published results in an MRI challenge in table 2. In figure 2 we consider a reconstruction task to then estimate multiple clinically-relevant downstream metrics from model fitting - extending the traditional model-parameter estimation task to estimate multiple quantities. TADRED outperforms recent supervised feature selection techniques in this task that has immediate deployment potential. We then show the generalizability of TADRED by performing similar sets of experiments on hyperspectral images, outperforming both supervised feature selection baselines for earth remote sensing in table 3 and recent work in tissue oxygenation estimation in table 4. Tables 5, 6 show an ablation study and that TADRED is mostly robust to randomness in deep learning training.\nAppendix C provides additional analysis. Appendix E provides details on experimental design in qMRI and hyperspectral imaging and how to implement our paradigm in real-world scenarios. Appendix F summarizes and visualizes the resultant densely-sampled data XD\u0304. Following standard practice in MR parameter estimation Alexander et al. (2019); Cercignani et al. (2018), and hyperspectral image filter design Waterhouse & Stoyanov (2022), data samples are individual pixels/voxels.\nBaselines and Comparisons We compare TADRED with standard model-based approaches such as the classical Fisher-matrix. Within the subsampling-task paradigm we use i) recent applicationspecific published results optimized by the respective authors; ii) state-of-the-art supervised feature selection approaches FIRDL, SSEFS (see section 2) and random selection then deep learning training (denoted by \u2018random\u2019) to mimic random baselines used in experimental design papers. Each feature selection approach conducts an extensive hyperparameter search, for fairness, the same number of evaluations are used for each feature subset C. All details are in appendix A. As this requires multiple training run (SSEFS in table 1 requires >400 runs), we examine the effect of the random seed on performance in table 6. We compare the computational costs of different approaches in appendix D."
        },
        {
            "heading": "TADRED Outperforms Classical Experimental Design and Baselines in Model Parameter",
            "text": "Estimation A standard task in experimental design is selecting the design D to maximize the precision of model parameters. We evaluate strategies for this using the VERDICT-MRI model which aids early detection and classification of prostate cancer Panagiotaki et al. (2015a). We sample parameters \u03b8i for voxel i = 1, ..., n, from a biologically plausible range, add synthetic noise representative of clinical qMRI, and the task is to estimate Y = {\u03b81, ...,\u03b8n} with performance metric MSE. The first baseline Panagiotaki et al. (2015b) uses classical Fisher-matrix experimental design (see section 2), to compute the design D with C = 20. The design produces a root-mean square error of 15.0\u00d7 10\u22122 in this experiment. The TADRED design with C = 20 has corresponding error of 2.04\u00d710\u22122. The supervised feature selection approaches in the new paradigm use a densely-sampled design D\u0304, where C\u0304 = 220 from Panagiotaki et al. (2015a) and use deep learning to estimate \u03b8i. Appendix F.1 documents all designs, models, and data. Table 1 shows TADRED outperforms the feature selection baselines where C = C\u03042 , C\u0304 4 , C\u0304 8 , C\u0304 16 . Thus it can better estimate parameters shown to reduce unnecessary biopsies Singh et al. (2022) in shorter scan times, spurring wider deployment in clinical settings. Similar results on the well-known NODDI model are in appendix B.\nBest Performance on qMRI Challenge Data The Multi-Diffusion Challenge Pizzolato et al. (2020) aimed to identify an informative subset of data, from which to reconstruct the original full dataset XD\u0304 (i.e. Y = XD\u0304) which had C\u0304 = 1344 measurements. This task provides a generic challenge that tests the ability of an experimental design or supervised feature selection algorithm to identify a\nsubset with maximal information content. As discussed in section 2, neither classical Fisher matrix nor Bayesian experimental design approaches can perform this task. Data are brain scans of five human subjects, which were acquired from a state-of-the-art technique that acquires multiple MRI modalities simultaneously in a high-dimensional space where di \u2208 R6. Thus experimental design is important, as sampling in a time budget realistic in clinical settings is difficult Slator et al. (2021). The first experiment follows Blumberg et al. (2022) which has the best performance on the data and table 2 shows TADRED outperforms this approach. We also show TADRED outperforms the supervised feature selection baselines in appendix B. All details are in appendix F.2.\nSurpassing the Baselines in Estimation of Multiple Downstream Metrics DTI, DKI, and MSDKI Basser et al. (1994); Jensen & Helpern (2010); Henriques (2018) are widely-used qMRI methods. They quantify tissue microstructure and show promise for extracting imaging biomarkers for many medical applications, such as mild brain trauma, epilepsy, stroke, and Alzheimer\u2019s disease Jensen & Helpern (2010); Ranzenberger & Snyder (2022); Tae et al. (2018). Reducing acquisition requirements (picking a small C) whilst obtaining more accurate quantification will enable their usage in a wider range of clinical application areas. We use publicly available, rich, high-resolution HCP data with C\u0304 = 288 measurements from six human subjects, corresponding to \u2248 30 minute scan times in the clinic \u2013 too long for general deployment. The task is to subsample sizes C = C\u03048 , C\u0304 16 then reconstruct the data, where the models are then fitted using standard techniques. Further details on the models, data, and model fitting techniques are in appendix F.3. Quantitative and qualitative results are in figure 2 and appendix B and show TADRED outperforms the baselines on 17/18 comparisons on clinically useful downstream metrics. Furthermore, the downstream metrics produced by TADRED are visually closer to the gold standard than those from the best baseline, potentially enhancing the diagnosis of aberrations in tissue microstructure.\nOutperforming Baselines in Reconstructing Remote Sensing Ground Images The JPL\u2019s Airborne Visible / Infrared Imaging Spectrometer (AVIRIS) Thompson et al. (2017) remotely senses elements of the Earth\u2019s atmosphere and surface from aeroplanes, and has been used to examine the effect and rehabilitation of forests affected by large wildfires. Purdue University Agronomy Department obtained AVIRIS data to support soils research and we use this publicly available \u2018Indian Pine\u2019 data Baumgardner et al. (2015), obtained from two flights - which acquired ground images from C = 220 different wavelengths. Details are in appendix F.4. This experiment follows experiment in table 2 and examines a sampling-reconstruction task where we investigate if we can obtain the same quality data with fewer wavelengths \u2013 which would in practice require fewer sensors. Table 3 shows TADRED outperforms the supervised feature selection baselines with subsample sizes C = C\u03042 , C\u0304 4 , C\u0304 8 , C\u0304 16 . These improvements demonstrate the potential for using fewer filters in AVIRIS. In the development of next-generation airborne hyperspectral devices, TADRED may be used to choose the filters. Further results are in appendix B, promising additional applications are outlined in appendix E.\nImproving the Estimation of Oxygen Saturation This experiment follows Waterhouse & Stoyanov (2022). Tissue oxygen saturation levels provide information regarding chemical and heat burns, along with the likelihood of healing. However, techniques such as spectrophotometers and pulse oximetry do not provide the spatial resolution to observe differences in blood saturation in neighboring tissue. Hyperspectral imaging is a non-invasive and real-time alternative to improve oxygenation estimation, yet application-specific spectral band selection is required to reduce the high cost of imaging sensors, allowing widespread clinical adoption. To address this, Waterhouse & Stoyanov (2022) adapted the model in Can & \u00dclgen (2019) for simulations and the objective is to estimate the pixel-wise abundance of oxyhemoglobin HbO2 and deoxyhemoglobin Hb; and oxygen saturation SO2. Design\nelements di \u2208 D\u0304 are chosen from 4 filters of different widths applied to 87 wavelengths (center), producing C\u0304 = 348 measurements. Table 4 shows that TADRED produces directly outperforms all approaches and results published and optimized in Waterhouse & Stoyanov (2022) for estimating the abundance of HbO2, Hb, SO2; for feature sizes C = 6, 5, 4, 3. This suggests that using TADRED during the development of clinically-viable hyperspectral devices may be beneficial to reduce costs.\nComponent Analysis and the Effect of Randomness We use the experimental settings in table 1. Table 5 examines the impact of removing TADRED\u2019s components on performance. First it considers TADRED without iteratively removing features in the optimization procedure, fixing t = 2 and C1, C2 = C\u0304, C, showing that iterative subsampling has better performance than subsampling all features one iteration. As the feature scoring is a key element of TADRED, we also show that removing the scoring network S , whilst still learning a score, results in extremely poor performance, as training is destabilized when progressively setting the score from sample-dependent to sampleindependent (recall equation 4). Table 6 shows how changing the random seed affects network initialization and data shuffling impacts performance; TADRED performs favorably compared to alternative approaches, and TADRED is mostly robust to the randomness inherent in deep learning."
        },
        {
            "heading": "5 DISCUSSION",
            "text": "This paper proposes TADRED, a feature selection algorithm that enables a new subsampling paradigm for experimental design particularly in multi-channel imaging applications. We demonstrate substantial performance benefits over standard Fisher-matrix approaches at the heart of widely used quantitative MRI techniques, as well as strong potential in multiple hyperspectral-imaging applications. \"Standard\" data sets for testing TADRED do not exist, as its new paradigm is largely unexplored, but in the few available examples (dataset used in table 2 and hyperspectral datasets in tables 3, 4) TADRED strongly outperforms existing algorithms, even on datasets for which those baselines were specifically designed, and without problem-specific hyperparameter tuning.\nTADRED combines the dual selection/task network training strategy in state-of-the-art feature selection algorithms (SSEFS and FIRDL) with an RFE framework better suited to identifying complementary subsets among many informative candidate features. Thus, TADRED outperforms SSEFS and FIRDL on the imaging experimental design problems we consider. In fact, random supervised feature selection often outperforms SSEFS when there are no informative/correlated feature subsets to identify and FIRDL\u2019s complex optimization procedure is often not beneficial when there is no such subset to identify and it underperforms simpler approaches. On the other hand, TADRED is likely to underperform SSEFS and FIRDL on typical applications in supervised feature selection where small sets of discriminative features reside among many uninformative features. One possible limitation is that TADRED\u2019s iterative subsampling in the paradigm of RFE and backward selection decreases the upper bound on performance as the optimal feature sets for sizes Ct, Ct\u22121 may not be nested. Future work will consider alternative strategies. This iterative subsampling also increases computational time compared to random supervised feature selection. However, appendix D shows TADRED\u2019s computational time is comparable to SSEFS and FIRDL. Here, we consider all image channels to have equal cost, but in practice some measurements/channels may be more expensive than others; TADRED\u2019s formulation adapts naturally to more complex cost functions on the experimental design. Also here we consider only tasks that treat each image pixel/voxel independently which is typical in quantitative imaging Alexander et al. (2019); Cercignani et al. (2018), so use only fully-connected networks (as the baselines), again TADRED\u2019s formulation adapts naturally to use e.g. a CNN for T . TADRED has further applications to other imaging problems e.g autofocus for specialized equipment Lightley et al. (2022) and potentially beyond imaging to e.g. studies of cell populations Sinkoe & Hahn (2017)."
        },
        {
            "heading": "REPRODUCIBILITY STATEMENT",
            "text": "We provide the code: Code Link, which contains the entire source code for our algorithm TADRED. The code also contains the script to create simulations used in tables 1, 7 and downloading and preprocessing the data in for results presented in tables 2, 3 and figure 2. Further details on all data and preprocessing are in appendix F. We also provide detailed information on the implementation of TADRED and the baselines in appendix A."
        },
        {
            "heading": "ACKNOWLEDGEMENTS",
            "text": "HPC: Tristan Clark, James O\u2019Connor, Edward Martin; Ahmed Abdelkarim, Daniel Beechey, George Blumberg, Ra\u0306zvan Ca\u0306ramalua\u0306u Amy Chapman, Luca Franceschi, G-Research (for a previous grant), Fredrik Helltr\u00f6m, Jessica Hoang, Chen Jin, Jean Kaddour, Marcus Keil, Johannes Kirschner, Marcela Konanova, Hongxiang Lin, Nina Monta\u00f1a-Brown, Luca Morreale, MUDI Organizers, Brooks Paige, David P\u00e9rez-Su\u00e1rez, Stefan Piatek, Reviewers, Oliver Slumbers, Dennis Soemers, Danail Stoyanov, Shinichi Tamura, Dale Waterhouse, Tom Young, An Zhao, Yukun Zhou. Funding: EPSRC grants M020533 R006032 R014019, Microsoft scholarship, NIHR UCLH Biomedical Research Centre, Research Initiation Project of Zhejiang Lab (No.2021ND0PI02). Data were provided [in part] by the Human Connectome Project, MGH-USC Consortium (Principal Investigators: Bruce R. Rosen, Arthur W. Toga and Van Wedeen; U01MH093765) funded by the NIH Blueprint Initiative for Neuroscience Research grant; the National Institutes of Health grant P41EB015896; and the Instrumentation Grants S10RR023043, 1S10RR023401, 1S10RR019307."
        },
        {
            "heading": "APPENDIX STRUCTURE",
            "text": "The appendices are structured as follows:\n1. Appendix A provides comprehensive details on all approaches utilized in this paper, including the specific hyperparameters employed.\n2. Appendix B are supplementary experimental results. 3. Appendix C offers further experimental analysis of our method, TADRED. 4. Appendix D compares the computational cost of all the approaches used in this paper and outlines\nthe computational resources employed. 5. Appendix E is a comprehensive description of prior work related to our problem. 6. Appendix F details all data for each experiment, along with specifics of each task."
        },
        {
            "heading": "A KEY APPROACHES, HYPERPARAMETERS, AND SETTINGS",
            "text": "This section describes the different supervised feature selection approaches used in this paper and details the choice of parameter settings within each."
        },
        {
            "heading": "GENERAL EXPERIMENTAL SETTINGS",
            "text": "For every experiment comparing TADRED with baselines, we split the data into training, validation/development, and test sets. This is described in detail in section F. Following Lee et al. (2022) (paper of SSEFS), we conducted an extensive hyperparameter search for each approach (using the validation set), for different experimental settings and subsample values C. This is described in detail below for every approach. For fairness, we have the same number of evaluations on the validation set for each different feature set size C, i.e. number of trials for model selection. The best model was then applied to the test set and we reported the performance.\nOther general hyperparameters are: batch size 1500, learning rate 10\u22124 (10\u22125 for the experiment in figure 2), ADAM optimizer, and default network weight initialization. The default option for early stopping used 20 epochs for patience (i.e training stops if validation performance does not improve in 20 epochs)."
        },
        {
            "heading": "TADRED - TASK-DRIVEN EXPERIMENTAL DESIGN FOR MULTI-CHANNEL IMAGING",
            "text": "This subsection details the hyperparameters for the method we present in this paper: TADRED for TAsk-DRiven Experimental Design in imaging, as outlined in section 3. Figure 3 provides a graphical representation of TADRED\u2019s structure and computational graph.\nWe conducted a brief search for TADRED-specific hyperparameters and fixed these hyperparameters across all experiments. We set the numbers of epochs in the four-phase inner loop training procedure as E1 = 25, E2 = E1+10, E3 = E2+10. Following other baselines, we do not fix the total number of training epochs E, but keep training beyond e = E3 in algorithm 2 phase 4 until early stopping criteria (on the validation set) are met.\nFor fairness, when comparing TADRED with other supervised feature selection baselines, we chose a simple set of hyperparameters for the feature set sizes {Ct}Tt=1 and number of outer loop steps T . Here we fixed T = 5 and C1, C2, C3, C4, C5 = C\u0304, C\u03042 , C\u0304 4 , C\u0304 8 , C\u0304 16 . When comparing TADRED against two recent application-specific published results optimized by the authors of Blumberg et al. (2022); Waterhouse & Stoyanov (2022), we followed standard practice and performed a brief hyperparameter search on the validation set. We used C1, ..., C9 = {1344, 500, 250, 100, 50, 40, 30, 20, 10}, T = 9 in table 2 and C1, ..., C19 = [348] + [250::45::-50] + [45::8::-5] + [8,6,5,4,3,2], T = 19 (notation is [start::stop::step] ) in table 4.\nWe perform a grid search to find the optimal network architecture hyperparameters for each task. The Scoring Network S and Task Network T have the same number of hidden layers \u2208 {1, 2, 3}, number of units \u2208 {30, 100, 300, 1000, 3000}, and for each combination we obtain task performance on the feature set sizes C1 > C2 > ... > CT . The best performing network on the validation set is deployed on the test data."
        },
        {
            "heading": "RANDOM SUPERVISED FEATURE SELECTION",
            "text": "This baseline is inspired by the random design baselines used in experimental design papers e.g. Foster et al. (2021); Ivanova et al. (2021). For a particular design size, C, we repeat the following process: i) randomly select C features/channels; ii) perform grid search on the task network (mapping subsampled data XD\u0304 to target Y ), with number of hidden layers \u2208 {1, 2, 3}, number of units \u2208 {30, 100, 300, 1000, 3000}; iii) train until early stopping criteria specified on the validation set are met; iv) evaluate the best trained model on the test set."
        },
        {
            "heading": "SELF-SUPERVISION ENHANCED FEATURE SELECTION WITH CORRELATED GATES (SSEFS)",
            "text": "LEE ET AL. (2022)\nThis approach has a lengthy hyperparameter search detailed in Appendix B of Lee et al. (2022), which consists of a three-phase procedure and four neural networks. Note that this required multiple training steps e.g. obtaining results for in table 1 requires >400 runs. SSEFS exploits task-performance, self-supervision, additional unlabeled data, and correlated feature subsets. It scores the features then subsequently trains a task-based network (analogous to T in TADRED) on subsampled data. We use the official repository Lee (2022) and verified our implementation by replicating results in the\npaper Lee et al. (2022). The full optimization procedure follows Lee et al. (2022) and is split into i) self-supervision phase, ii) supervision phase, iii) training on selected features only.\nThe self-supervision phase finds the optimal encoder network hyperparameters. We follow Appendix B of Lee et al. (2022) and perform grid search. Similar to other approaches in this paper, we consider the encoder network, feature vector estimator network, gate vector estimator network, all have same number of hidden layers \u2208 {1, 2, 3} number of units, including hidden dimension \u2208 {30, 100, 300, 1000, 3000}. Directly following Lee et al. (2022) table S.1, other hyperparameters \u03b1 \u2208 {0.01, 0.1, 1.0, 10, 100}, \u03c0 \u2208 {0.2, 0.4, 0.6, 0.8}. The self-supervisory dataset is input data XD\u0304. On the best validation performance (with early stopping), this returns a trained encoder network, cached for the supervision phase.\nThe supervision phase scores the features. The pretrained encoder is loaded from the previous phase. We then perform grid search, where the predictor network has number of hidden layers \u2208 {1, 2, 3}, number of units \u2208 {30, 100, 300, 1000, 3000}, following Lee et al. (2022) table S.1 \u03b2 \u2208 {0.01, 0.1, 1.0, 10, 100}. On the best validation performance with early stopping, the process returns a score for all features.\nThe final phase is repeated for a different number of subset sizes C. We extract the C highest scored features from the previous phase and perform grid search on the task network (mapping subsampled data XD\u0304 to target Y ), with number of hidden layers \u2208 {1, 2, 3}, number of units \u2208 {30, 100, 300, 1000, 3000}. Training is until early stopping on the validation set. The best trained model is evaluated on the test set.\nFEATURE IMPORTANCE RANKING FOR DEEP LEARNING (FIRDL) WOJTAS & CHEN (2020)\nThis approach has a three-stage procedure detailed in Appendix D of Wojtas & Chen (2020) and uses two neural networks. One of the networks scores the masks (analogous to mask m in TADRED), and the other trains a task network to perform a task on the subsampled data (analogous to T in TADRED). We use the official repository Wojtas (2021) and verified our implementation by replicating results in the paper Wojtas & Chen (2020). The following process is repeated for different feature subset sizes C.\nWe perform a grid search to find the optimal hyperparameters. The operator network (analogous to task network T in this paper) and the selector network have the same number of hidden layers \u2208 {1, 2, 3}, number of units \u2208 {30, 100, 300, 1000, 3000}, sp = 5, E1 = 15000. The joint training uses early stopping on the validation set, and returns an optimal feature set size, of size C and a trained operator network. The best performing operator network on the validation set is deployed on the test data."
        },
        {
            "heading": "B ADDITIONAL RESULTS",
            "text": "This section provides additional results supporting the experiments presented in the main paper.\nTable 7 contains results that repeat the experiment in table 1 using the NODDI model Zhang et al. (2012) instead of VERDICT. The first baseline uses the classical Fisher-matrix experimental design Alexander (2008) to compute the design D from Zhang et al. (2012) where C = 99. For the supervised feature selection approaches we use densely-sampled designs D\u0304 where C\u0304 = 3612 Ferizi et al. (2017). Similar to results in table 1, table 7 shows TADRED outperforms classical experimental design with C set to 99 following the classical approach used in current practice. In addition, TADRED outperforms the supervised feature selection baselines where C = C\u03042 , C\u0304 4 , C\u0304 8 , C\u0304 16 . The optimized designs enable us to estimate the widely used NODDI parameters in shorter scan times opening the potential for a wider range of clinical applications. All information on designs, models and data is in section F.1.\nTable 8 shows extra results within the experiment documented in figure 2. We consider an additional feature set subsample size C = 36 which extends the results in figure 2 and show TADRED outperforms the baselines on 17/18 comparisons on clinically useful downstream metrics. This is beneficial as pressure for time in clinical MRI protocols is intense as many different MR contrasts are informative, but patient-time in the scanner is limited. Therefore shorter acquisition protocols for\nthese widely informative downstream metrics (parametric maps) enables their exploitation in a wider range of clinical studies and applications.\nTable 9 shows additional results on the MUDI data in table 2. This experiment compares TADRED with the supervised feature selection baselines following settings in the original MUDI challenge. Evaluation uses the MSE metric as in the original challenge. Further details are in appendix F.2.\nTable 10 shows additional results on the AVIRIS data presented in table 3. Here, we only use data from the north-to-south flight. Improvements of TADRED over the supervised feature selection baselines are similar to that in table 3."
        },
        {
            "heading": "C FURTHER ANALYSIS",
            "text": ""
        },
        {
            "heading": "C.1 ANALYZING THE EFFECT ON RANDOMNESS ON FEATURE SET CHOSEN",
            "text": "Table 11 examines how the changing the random seed that affects network initialization and data shuffling, impacts the feature set chosen. Results show TADRED performs favorably compared to alternative approaches and mostly chooses the same features"
        },
        {
            "heading": "C.2 EVALUATION OF THE CHOICE OF FEATURE FILL X FILL",
            "text": "D\u0304\nTable 12 examines the effect of varying the values Xfill D\u0304 that fill the unsubsampled features. FIRDL used zeros for its equivalent of Xfill\nD\u0304 and SSEFS used the data mean (per channel/feature). Results\nshow even if we set the values of Xfill D\u0304 to that of the baselines, TADRED has large improvements over the baselines.\nC.3 HOW DOES THE SIZE OF THE DENSELY-SAMPLED DESIGN AFFECT PERFORMANCE?\nTable 12: Comparison of the choice of Xfill D\u0304 . Experimental settings follow table 1.\nXfill D\u0304 C = 110 55 28 14 SSEFS data mean 1.06 1.28 1.89 4.58 FIRDL zeros 2.22 2.14 3.09 4.05 TADRED data median 1.03 1.19 1.80 2.55 TADRED data mean 1.03 1.20 1.79 2.80 TADRED zeros 1.03 1.19 1.79 2.51\n2030405060 Size of Densely-Sampled Design CBar\n2.75\n3.00\n3.25\n3.50\n3.75\n4.00\n4.25\n4.50\nVa lid\nat io\nn M\nea n-\nSq ua\nre d-\nEr ro\nr x 10\n0 on\nC\n=1 4\nM ea\nsu re\nm en\nts O\nve r 1\n0 Ra\nnd om\nS ee\nds\nFigure 4: Analyzing the performance on different densely-sampled designs D\u0304 where |D\u0304| = C\u0304 and C = 14. Settings follow table 1.\nWe examine how varying the size of denselysampled design D\u0304 (used to create XD\u0304) affects performance. Across 10 random seeds, we randomly sample the design from Panagiotaki et al. (2015b) to create a custom D\u0304 with C\u0304 elements. Training is on fixed network sizes for a single subsampling rate C2 = C = 14. We use 10% of the training data within the experimental settings of table 1. Results are in figure 4 and exemplify typical behavior that while performance is reasonably stable for large C\u0304 a phase change occurs as C\u0304 nears C and performance decreases rapidly, as the set of samples to choose from becomes too sparse."
        },
        {
            "heading": "C.4 TADRED",
            "text": ""
        },
        {
            "heading": "VARIANT WITH RANDOM SELECTION",
            "text": "We tested a modified training procedure that works in the \u2018same manner\u2019 as the original implementation of TADRED whilst the scores chosen are random. Across different modifications, in settings of table 5, results (MSE) are more than 10% worse, even more than \u2018w/o iterative subsampling\u2019. Thus, although the \u2018gradual aspect\u2019 of TADRED\u2019s training procedure improves performance (in fact line 2 in the ablation study table 5 already demonstrates this with \u2018less gradual\u2019 scenario without iterative subsampling decreases performance), the learning of the scoring network is working as intended and further improves results."
        },
        {
            "heading": "D COMPUTATIONAL COST OF DIFFERENT APPROACHES AND INFRASTRUCTURE",
            "text": "It is difficult to compare the computational cost of TADRED against SSEFS, FIRDL. The official implementations, described in appendix A use different machine learning frameworks and all use customized early stopping. In particular, SSEFS has a three stage procedure (first two are large hyperparameter searches) which are completed consecutively; TADRED does not require this. TADRED and FIRDL train on two distinct networks, whilst SSEFS uses four, as such, training costs are somewhat comparable if network sizes are taken to be the same. Practical requirements in all cases were reasonable and training for all methods for each experiment were performed within 24 hours. As an example, we compare the time to run the various methods for the results in table 6 per C with the network sizes fixed and no hyperparameter search over different network sizes. Training speeds are: Random supervised feature selection (baseline) 505s; SSEFS (baseline) 1934s (using only run a single run per seed for the first two stages; as previously noted, for other results in the paper, this is much slower as the method proposes a computationally expensive sequential hyperparameter search); FIRDL (baseline) 1756s; TADRED (the new approach) 1988s. The random supervised feature selection baseline is by far the most computationally economical, as we expect, because it uses no iterative search. TADRED\u2019s computational cost is similar to the two state-of-the-art supervised feature selection baselines, SSEFS and FIRDL.\nExploratory analysis and development was conducted on a mid-range (as of 2023) machine with a AMD Ryzen Threadripper 2950X CPU and single Titan V GPU. All experimental results reported in this paper were computed on low-to-mid range (as of 2023) graphical processing units (GPU): GTX 1080 Ti, Titan Xp, Titan X, Titan V, RTX 2080 Ti. We ran jobs on a high-performance computing cluster shared with other users, allowing multiple jobs to run in parallel."
        },
        {
            "heading": "E EXTENDED RELATED WORK",
            "text": "This section provides further information to section 2, detailing previous work related to our problem.\nClassical and Other Recent Supervised Feature Selection Approaches Supervised feature selection approaches are either i) \u2018filter methods\u2019, which select features using some proxy metric independent of the final task, ii) \u2018wrapper methods\u2019, which use the task to evaluate feature set performance, or iii) \u2018embedded methods\u2019, which couple the feature selection with the task training. Embedded methods FIRDL Wojtas & Chen (2020), SSEFS Lee et al. (2022) are state-of-the-art outperforming classical approaches e.g recursive feature elimination (RFE)-original Guyon et al. (2002), BAHSIC Song et al. (2007; 2012), mRMR Peng et al. (2005), CCM Chen et al. (2017), RF Breiman (2001), DFS Li et al. (2016), LASSO Tibshirani (1996), L-Score He et al. (2005) and recent deep learning-based CE Abid et al. (2019), STG Yamada et al. (2020), DUFS Lindenbaum et al. (2021). More recent approaches extend the supervised feature selection paradigm to limit false discovery rate Hansen et al. (2022), few-shot learning Kumagai et al. (2022), discovering groups of predictive features Imrie et al. (2022), the unsupervised setting Sokar et al. (2022), few-sample classification problems Cohen et al. (2023), dynamic feature selection Covert et al. (2023), for federated learning Castiglia et al. (2023), for identifying high-dimensional causal features Quinzan et al. (2023). They are not designed for the standard regression-based supervised feature selection problem considered in this paper.\nOther Recent Experimental Design Approaches Techniques for experimental design have been developed for causal modeling Tigas et al. (2022); Zhang et al. (2022); Teshnizi et al. (2020), linear models Fontaine et al. (2021); Mutny & Krause (2022), online learning Arbour et al. (2022), active learning Kaddour et al. (2020), drug discovery Mehrjou et al. (2022), reinforcement learning Mehta et al. (2022), A/B testing Nandy et al. (2021), panel-data settings Doudchenko et al. (2021), bandit problems Camilleri et al. (2021), balancing competing objectives with uncertainty Malkomes et al. (2021), temporal treatment and control Glynn et al. (2020), causal discovery when interventions can be costly or risky Tigas et al. (2023), designing pricing experiments Simchi-Levi & Wang (2023), contextual optimization for Bayesian experimental design Ivanova et al. (2023), genomics Lyle et al. (2023), treatment effects in large randomized trials Connolly et al. (2023), learning causal models with Bayesian approaches Annadani et al. (2023). These are not applicable to the problem setting we consider. Approaches Zheng et al. (2020); Kleinegesse & Gutmann (2020); Jiang et al. (2020) are older sequential experimental design approaches, whilst Zaballa & Hui (2023) is contemporary to this work \u2013 they face the same issues as Blau et al. (2022); Foster et al. (2021); Ivanova et al. (2021) (discussed in section 2) \u2013 which focus on estimating model parameters and are mostly demonstrated in small-scale problems which do not scale up to the high dimensional problems we face in experimental design for image-channel selection.\nExperimental Design in qMRI In qMRI the design D is known as an \u2018acquisition scheme\u2019. One standard task is \u2018parameter mapping\u2019, first estimating biologically-informative model parameters by voxel-wise model fitting, to then obtain downstream metrics Alexander et al. (2019). This provides information that is not visible directly from the images, such as microstructural properties of tissue. However, acquisition time (corresponding to C = |D|) is limited by factors of cost and the ability of (often sick) subjects to remain motionless in the noisy and claustrophobic environment of the scanner. Thus experimental design can be crucial to support the most accurate image-driven diagnosis, prognosis, or treatment choices. Many clinical scenarios use D based on intuition loosely guided by understanding of the physical systems under examination, but this can lead to highly suboptimal designs particularly for complex models. However, some studies optimize the design using the Fisher information matrix, e.g. Alexander (2008); Cercignani & Alexander (2006).\nLengthy MRI acquisitions corresponding to D\u0304 to enable our new experimental design paradigm are made easily on a few subjects, but are not feasible in routine patient imaging. However, such lengthy acquisitions are often made in the design phase of quantitative imaging techniques, e.g. as in Ferizi et al. (2017). We note also that several distinct experiment design problems arise in MRI.\nHere we focus on estimating per-voxel parameter values, but others e.g. Zbontar et al. (2018); Knoll et al. (2020); Muckley et al. (2021); Fabian et al. (2022); Yaman et al. (2022), focus on how best to subsample the k-space. Our approach is complementary to and may be combined with those; they expedite the acquisition of each individual channel, we identify a compact/economical set of channels."
        },
        {
            "heading": "F DATA AND TASK EVALUATION",
            "text": "Name Results Data Type Channels Target Pixel/Voxel No. Independent No. pixels/voxels n x10 3\nC\u0304 Regressors Size Variables Train Val Test VERDICT Table 1 Simulated qMRI 220 8 - di \u2208 R7 1000 100 100\nNODDI Table 7 Simulated qMRI 3612 7 - di \u2208 R7 100 10 10 MUDI Table 2 qMRI Scan 1344 1344 2.5mm3 di \u2208 R6 321 132 105 HCP Figure 2 qMRI Scan 288 288 1.25mm3 di \u2208 R4 2182 774 674 Indian Pine Table 3 Remote Sensing Hyperspectral 220 220 20m2 di \u2208 R 1480 164 1135 Oxygen Saturation Table 4 Simulated Hyperspectral 348 2 - di \u2208 R2 0.4 0.044 10\nThis section includes additional details about the experimental data. Table 13 provides a summary, figure 6 visualizes various examples,figure 5 is a correlation plot of the measurements/channels/features.\nWe follow Grussu et al. (2021) and normalize each channel/measurement/feature by dividing by its 99th percentile value calculated from the training set. This is performed in both the input and output of the neural network."
        },
        {
            "heading": "F.1 SIMULATIONS WITH THE VERDICT AND NODDI BIOPHYSICAL MODELS.",
            "text": "This section describes the the VERDICT and NODDI models and the experimental settings used in tables 1, 7. Exact code to perform the simulations is in Code Link.\nThe VERDICT (Vascular, Extracellular and Restricted Diffusion for Cytometry in Tumors) model Panagiotaki et al. (2014), maps histological features of solid-cancer tumors particularly for early detection and classification of prostate cancer Panagiotaki et al. (2015a); Johnston et al. (2019); Singh et al. (2022). The VERDICT model includes parameters: fI the intra-cellular volume fraction, fV the vascular volume fraction, Dv the vascular perpendicular diffusivity, R the mean cell radius, and n - a 3D vector defining mean local vascular orientation.\nThe NODDI (Neurite Orientation Dispersion and Density Imaging) model Zhang et al. (2012), maps parameters of the cellular composition of brain tissue and is widely used in neuroimaging studies in neuroscience such as the UK Biobank study Alfaro-Almagro et al. (2018), and neurology e.g. in Alzheimer\u2019s disease Kamiya et al. (2020) and multiple sclerosis Grussu et al. (2017). The NODDI model includes five tissue parameters: fic the intra-cellular volume fraction, fiso the isotropic volume fraction, the orientation dispersion index (ODI) that reflects the level of variation in neurite orientation, and n - a 3D vector defining the mean local fiber orientation.\nTo conduct the simulations on the VERDICT and NODDI models, we employ the widely-used, open-source dmipy toolbox Fick et al. (2019). The code is available: Code Link. In each case, data simulation uses a known, fixed, acquisition scheme, i.e. experimental design, in combination with a set of ground truth model parameters. We chose the ground truth model parameters {\u03b81, ...,\u03b8n} for voxel/sample i = 1, ..., n by uniformly sampling parameter combinations from the bounds given in table 14. We choose these bounds as they approximate the physically feasible limits of the parameters.\nThe VERDICT data has number of samples n = 1000K, 100K, 100K in the train, validation, test split, with target data Y \u2208 Rn\u00d78,\u03b8i \u2208 R8, i = 1, ..., n. The classical experimental design approach yields an acquisition scheme derived from the Fisher information matrix Panagiotaki et al. (2015b) and here XD \u2208 Rn\u00d720, C = 20. The approaches in supervised feature selection (including TADRED) also use a densely-sampled empirical acquisition scheme, designed specifically for the VERDICT protocol from Panagiotaki et al. (2015a) and here XD\u0304 \u2208 Rn\u00d7220 with C\u0304 = 220 measurements. The NODDI data has number of samples n = 100K, 10K, 10K in the train,validation,test split, with target data Y \u2208 Rn\u00d77,\u03b8i \u2208 R7, i = 1, ..., n. The classical experimental design approach yields an acquisition scheme derived from the Fisher information matrix Zhang et al. (2012) and so XD\u0304 \u2208 Rn\u00d799, C = 99. The approaches in supervised feature selection use a densely-sampled empirical acquisition scheme from an extremely rich acquisition from Ferizi et al. (2017). This was designed for the ISBI 2015 White Matter Challenge, which aimed to collect the richest possible data to rank biophysical models, and required a single subject to remain motionless for two uncomfortable back-to-back 4 hour scans. Here XD\u0304 \u2208 Rn\u00d73612 with C\u0304 = 3612 measurements. We added Rician noise to all simulated signals, which is standard for MRI data Gudbjartsson & Patz (1995). The signal to noise ratio of the unweighted signal is 50, which is representative of clinical qMRI."
        },
        {
            "heading": "F.2 MULTI-DIFFUSION (MUDI) CHALLENGE DATA",
            "text": "Data used in tables 2, 9 are images from five in-vivo human subjects, and are publicly available MUDI Organizers (2022), and was acquired with the state-of-the-art ZEBRA sequence Hutter et al. (2018). This diffusion-relaxation MRI dataset has a 6D acquisition parameter space di \u2208 R6:\necho time (TE), inversion time (TI), b-value, and b-vector directions in 3 dimensions: bx, by, bz . Data has 2.5mm isotropic resolution and field-of-view 220 \u00d7 230 \u00d7 140mm and resulted in 5 3D brain volumes (i.e. images) with C\u0304 = 1344 measurements/channels, which here are unique diffusion- T2\u2217 and T1- weighting contrasts. More information is in Hutter et al. (2018); Pizzolato et al. (2020). Each subject has an associated brain mask, after removing outlier voxels resulted in 104520, 110420, 105743, 132470, 105045 voxels for respective subjects 11, 12, 13, 14, 15. For the experiment in table 2 we follow Blumberg et al. (2022) and perform 5-fold cross validation on the 5 subjects. For the experiment in table 9, we followed the original challenge Pizzolato et al. (2020) and took subjects 11, 12, 13 as the training and validation set, and subjects 14, 15 as the unseen test set, where 90%\u2212 10% of the training/validation set voxels are respectively, for training and validation."
        },
        {
            "heading": "F.3 HUMAN CONNECTOME PROJECT (HCP) TEST-RETEST DATA",
            "text": "This section describes the data and model fitting procedure used in figure 2 and table 8.\nThis section utilizes WU-Minn Human Connectome Project (HCP) diffusion data, which is publicly available at www.humanconnectome.org (Test Retest Data Release, release date: Mar 01, 2017) Essen et al. (2013). The data comprises C\u0304 = 288 volumes (i.e. measurements/channels), with 18 b=0 s mm\u22122 (i.e. non-diffusion weighted) volumes, 90 gradient directions for b=1000 s mm\u22122, 90 directions for b=2000 s mm\u22122, and 90 directions for b=3000 s mm\u22122. We used 3 scans for training (ID numbers 103818_1, 105923_1, 111312_1), one scan for validation (114823_1) and one scan for testing (115320_1), which produced numbers of samples n = 708724 + 791369 + 681650 = 2181743, 774149, 674404 for the respective splits. We used only voxels inside the provided brain mask and normalized the data voxelwise with a standard technique in MRI, by dividing all measurements by the mean signal in each voxel\u2019s b=0 values. Undefined voxels were then removed.\nDiffusion tensor imaging (DTI) Basser et al. (1994), diffusion kurtosis imaging (DKI) Jensen & Helpern (2010), and Mean Signal DKI (MSDKI) Henriques (2018) are widely-used qMRI methods. Like NODDI and VERDICT, they use diffusion MRI to sensitize the image intensity to the Brownian motion of water molecules within the tissue to provide a window on tissue microstructure. However, whereas NODDI and VERDICT are designed specifically for application to brain tissue and cancer tumors, respectively, DTI and DKI are more general purpose techniques that provide indices of diffusivity (e.g. mean diffusivity - MD), diffusion anisotropy (e.g. fractional anisotropy Basser & Pierpaoli (1996) - FA), and the deviation from Gaussianity, or kurtosis, (e.g. mean kurtosis Jensen & Helpern (2010) - MK) that can inform on tissue integrity or pathology. Mean signal diffusion kurtosis imaging (MSDKI) is a simplified version of DKI that quantifies kurtosis using a simpler model that is easier to fit Henriques (2018). These techniques show promise for extracting imaging biomarkers for a wide variety of medical applications, such mild brain trauma, epilepsy, stroke, and Alzheimer\u2019s disease Jensen & Helpern (2010); Ranzenberger & Snyder (2022); Tae et al. (2018).\nTo fit the DTI, DKI, and MSDKI biophysical models to the data, and obtain the downstream metrics (parameter maps), we employ the widely-used, open-source DIPY library Garyfallidis et al. (2014). We followed standard practice for model fitting in MRI and used the least-squares optimization approach and default fitting settings. To remove outliers, values were clamped where DTI FA \u2208 [0, 1], DTI MD,AD,RD \u2208 [0, 0.003], DKI MK,AK,RK \u2208 [0, 3], MSDKI MSD \u2208 [0, 0.003] MSDKI MSK \u2208 [0, 3]. Code for model fitting is in Code Link. The results in figure 2 and table 8 are all scaled by: DTI-FA \u00d7102, DTI-MD \u00d7109, DTI-AD \u00d7109, DTI-RD \u00d7109, DKI-MK \u00d7102, DKI-AK \u00d7102, DKI-RK 102, MSDKI-MSD \u00d7109, MSDKI-MSK \u00d7102."
        },
        {
            "heading": "F.4 AIRBORNE VISIBLE / INFRARED IMAGING SPECTROMETER (AVIRIS) DATA AND TASK",
            "text": "This section describes the data and task considered in tables 3, 10.\nThe Airborne Visible / Infrared Imaging Spectrometer (AVIRIS) is a highly-specialized hyperspectral device for earth remote sensing commissioned by the Jet Propulsion Laboratory (JPL). It obtains acquisitions from adjacent spectral channels bands between the wavelengths 400nm - 2500nm. It is flown from four different aircrafts and has been deployed worldwide, for purposes such as examining the effect and rehabilitation of forests affected by large wildfires, the effect of climate change, and\nother applications in atmospheric studies and snow hydrology. More information is available Jet Propulsion Laboratory (JPL) (2023); Simmonds & Green (1996); Thompson et al. (2017) and on the webpage https://aviris.jpl.nasa.gov.\nData used was obtained in June 1992, when the Purdue University Agronomy Department commissioned AVIRIS to obtain two ground images of the \u2018Indian Pine\u2019 to support soils research Baumgardner et al. (2015) from two flight lines: east-to-west and north-to-south. This is publicly available Baumgardner et al. (2022). The data are two \u2018image cube\u2019 corresponding to a 2miles2 area of 20m2 pixel size with C\u0304 = 220 channels.\nData from the north-to-south flight are used for training and validation. This consists of 1644292 pixels of which 90-10 % were used for training-validation. Data from the east-to-west flight were used for test data, which consists of 1134672 pixels. We removed outliers from both images - details in Code Link and then normalized the image channel-wise so the 99th-percentile is 255 (the maximum in standard images).\nThe objective is examine whether our supervised feature selection approaches can reconstruct the entire image from a subset of wavelengths, typical of the ground obtained over Indiana (the location of \u2018Indian Pine\u2019)."
        },
        {
            "heading": "F.5 ESTIMATION OF OXYGEN SATURATION DATA AND TASK",
            "text": "This experiment and data follows directly from Waterhouse & Stoyanov (2022). Data was generated from the code presented in Waterhouse & Stoyanov (2022), with assistance from its author."
        }
    ],
    "title": "ING VIA TASK-DRIVEN FEATURE SELECTION",
    "year": 2024
}