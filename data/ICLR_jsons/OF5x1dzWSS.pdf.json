{
    "abstractText": "Assigning importance weights to adversarial data has achieved great success in training adversarially robust networks under limited model capacity. However, existing instance-reweighted adversarial training (AT) methods heavily depend on heuristics and/or geometric interpretations to determine those importance weights, making these algorithms lack rigorous theoretical justification/guarantee. Moreover, recent research has shown that adversarial training suffers from a severe non-uniform robust performance across the training distribution, e.g., data points belonging to some classes can be much more vulnerable to adversarial attacks than others. To address both issues, in this paper, we propose a novel doubly-robust instance reweighted AT framework, which allows to obtain the importance weights via exploring distributionally robust optimization (DRO) techniques, and at the same time boosts the robustness on the most vulnerable examples. In particular, our importance weights are obtained by optimizing the KL-divergence regularized loss function, which allows us to devise new algorithms with a theoretical convergence guarantee. Experiments on standard classification datasets demonstrate that our proposed approach outperforms related state-of-the-art baseline methods in terms of average robust performance, and at the same time improves the robustness against attacks on the weakest data points. Codes can be found in the Supplement.",
    "authors": [],
    "id": "SP:d5608062b58f0bad63eae847c07858dd1a30a191",
    "references": [
        {
            "authors": [
                "Motasem Alfarra",
                "Adel Bibi",
                "Hasan Hammoud",
                "Mohamed Gaafar",
                "Bernard Ghanem"
            ],
            "title": "On the decision boundaries of neural networks: A tropical geometry perspective",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Maksym Andriushchenko",
                "Nicolas Flammarion"
            ],
            "title": "Understanding and improving fast adversarial training",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Anish Athalye",
                "Nicholas Carlini",
                "David Wagner"
            ],
            "title": "Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples",
            "venue": "In International conference on machine learning,",
            "year": 2018
        },
        {
            "authors": [
                "Anish Athalye",
                "Logan Engstrom",
                "Andrew Ilyas",
                "Kevin Kwok"
            ],
            "title": "Synthesizing robust adversarial examples",
            "venue": "In International conference on machine learning,",
            "year": 2018
        },
        {
            "authors": [
                "Luca Bertinetto",
                "Joao F Henriques",
                "Philip Torr",
                "Andrea Vedaldi"
            ],
            "title": "Meta-learning with differentiable closed-form solvers",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2018
        },
        {
            "authors": [
                "Jose Blanchet",
                "Donald Goldfarb",
                "Garud Iyengar",
                "Fengpei Li",
                "Chaoxu Zhou"
            ],
            "title": "Unbiased simulation for optimizing stochastic function compositions",
            "venue": "arXiv preprint arXiv:1711.07564,",
            "year": 2017
        },
        {
            "authors": [
                "Yair Carmon",
                "Aditi Raghunathan",
                "Ludwig Schmidt",
                "John C Duchi",
                "Percy S Liang"
            ],
            "title": "Unlabeled data improves adversarial robustness",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "Tianlong Chen",
                "Zhenyu Zhang",
                "Sijia Liu",
                "Shiyu Chang",
                "Zhangyang Wang"
            ],
            "title": "Robust overfitting may be mitigated by properly learned smoothening",
            "venue": "In International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Tianyi Chen",
                "Yuejiao Sun",
                "Wotao Yin"
            ],
            "title": "Solving stochastic compositional optimization is nearly as easy as solving stochastic optimization",
            "venue": "IEEE Transactions on Signal Processing,",
            "year": 2021
        },
        {
            "authors": [
                "Adam Coates",
                "Andrew Ng",
                "Honglak Lee"
            ],
            "title": "An analysis of single-layer networks in unsupervised feature learning",
            "venue": "Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics,",
            "year": 2011
        },
        {
            "authors": [
                "Francesco Croce",
                "Matthias Hein"
            ],
            "title": "Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks",
            "venue": "In International conference on machine learning,",
            "year": 2020
        },
        {
            "authors": [
                "Adithya M Devraj",
                "Jianshu Chen"
            ],
            "title": "Stochastic variance reduced primal dual algorithms for empirical composition optimization",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Gavin Weiguang Ding",
                "Yash Sharma",
                "Kry Yik Chau Lui",
                "Ruitong Huang"
            ],
            "title": "Mma training: Direct input space margin maximization through adversarial training",
            "venue": "arXiv preprint arXiv:1812.02637,",
            "year": 2018
        },
        {
            "authors": [
                "Justin Domke"
            ],
            "title": "Generic methods for optimization-based modeling",
            "venue": "International Conference on Artificial Intelligence and Statistics (AISTATS), pp",
            "year": 2012
        },
        {
            "authors": [
                "Chelsea Finn",
                "Pieter Abbeel",
                "Sergey Levine"
            ],
            "title": "Model-agnostic meta-learning for fast adaptation of deep networks",
            "venue": "In Proc. International Conference on Machine Learning (ICML),",
            "year": 2017
        },
        {
            "authors": [
                "Luca Franceschi",
                "Michele Donini",
                "Paolo Frasconi",
                "Massimiliano Pontil"
            ],
            "title": "Forward and reverse gradient-based hyperparameter optimization",
            "venue": "In International Conference on Machine Learning (ICML),",
            "year": 2017
        },
        {
            "authors": [
                "Luca Franceschi",
                "Paolo Frasconi",
                "Saverio Salzo",
                "Riccardo Grazzi",
                "Massimiliano Pontil"
            ],
            "title": "Bilevel programming for hyperparameter optimization and meta-learning",
            "venue": "In International Conference on Machine Learning (ICML),",
            "year": 2018
        },
        {
            "authors": [
                "Ian J Goodfellow",
                "Jonathon Shlens",
                "Christian Szegedy"
            ],
            "title": "Explaining and harnessing adversarial examples",
            "venue": "arXiv preprint arXiv:1412.6572,",
            "year": 2014
        },
        {
            "authors": [
                "Stephen Gould",
                "Basura Fernando",
                "Anoop Cherian",
                "Peter Anderson",
                "Rodrigo Santa Cruz",
                "Edison Guo"
            ],
            "title": "On differentiating parameterized argmin and argmax problems with application to bi-level optimization",
            "venue": "arXiv preprint arXiv:1607.05447,",
            "year": 2016
        },
        {
            "authors": [
                "Sven Gowal",
                "Sylvestre-Alvise Rebuffi",
                "Olivia Wiles",
                "Florian Stimberg",
                "Dan Andrei Calian",
                "Timothy A Mann"
            ],
            "title": "Improving robustness using generated data",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Riccardo Grazzi",
                "Luca Franceschi",
                "Massimiliano Pontil",
                "Saverio Salzo"
            ],
            "title": "On the iteration complexity of hypergradient computation",
            "venue": "International Conference on Machine Learning (ICML)),",
            "year": 2020
        },
        {
            "authors": [
                "Riccardo Grazzi",
                "Luca Franceschi",
                "Massimiliano Pontil",
                "Saverio Salzo"
            ],
            "title": "On the iteration complexity of hypergradient computation",
            "venue": "In Proc. International Conference on Machine Learning (ICML),",
            "year": 2020
        },
        {
            "authors": [
                "Wenqing Hu",
                "Chris Junchi Li",
                "Xiangru Lian",
                "Ji Liu",
                "Huizhuo Yuan"
            ],
            "title": "Efficient smooth non-convex stochastic compositional optimization via stochastic recursive gradient descent",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Kaiyi Ji",
                "Yingbin Liang"
            ],
            "title": "Lower bounds and accelerated algorithms for bilevel optimization",
            "venue": "arXiv preprint arXiv:2102.03926,",
            "year": 2021
        },
        {
            "authors": [
                "Kaiyi Ji",
                "Jason D Lee",
                "Yingbin Liang",
                "H Vincent Poor"
            ],
            "title": "Convergence of meta-learning with task-specific adaptation over partial parameter",
            "venue": "In Advances in Neural Information Processing Systems (NeurIPS),",
            "year": 2020
        },
        {
            "authors": [
                "Kayi Ji",
                "Junjie Yang",
                "Yingbin Liang"
            ],
            "title": "Bilevel optimization: Convergence analysis and enhanced design",
            "venue": "International Conference on Machine Learning (ICML)),",
            "year": 2021
        },
        {
            "authors": [
                "Jing Jiang",
                "ChengXiang Zhai"
            ],
            "title": "Instance weighting for domain adaptation in nlp",
            "year": 2007
        },
        {
            "authors": [
                "Alex Krizhevsky",
                "Geoffrey Hinton"
            ],
            "title": "Learning multiple layers of features from tiny images",
            "year": 2009
        },
        {
            "authors": [
                "Xiangru Lian",
                "Mengdi Wang",
                "Ji Liu"
            ],
            "title": "Finite-sum composition optimization via variance reduced gradient descent",
            "venue": "In Artificial Intelligence and Statistics,",
            "year": 2017
        },
        {
            "authors": [
                "Renjie Liao",
                "Yuwen Xiong",
                "Ethan Fetaya",
                "Lisa Zhang",
                "Xaq Yoon",
                "KiJung Pitkow",
                "Raquel Urtasun",
                "Richard Zemel"
            ],
            "title": "Reviving and improving recurrent back-propagation",
            "venue": "International Conference on Machine Learning (ICML)),",
            "year": 2018
        },
        {
            "authors": [
                "Tianyi Lin",
                "Chengyou Fan",
                "Mengdi Wang",
                "Michael I Jordan"
            ],
            "title": "Improved sample complexity for stochastic compositional variance reduced gradient",
            "venue": "American Control Conference (ACC),",
            "year": 2020
        },
        {
            "authors": [
                "Feng Liu",
                "Bo Han",
                "Tongliang Liu",
                "Chen Gong",
                "Gang Niu",
                "Mingyuan Zhou",
                "Masashi Sugiyama"
            ],
            "title": "Probabilistic margins for instance reweighting in adversarial training",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Hanxiao Liu",
                "Karen Simonyan",
                "Yiming Yang"
            ],
            "title": "Darts: Differentiable architecture search",
            "venue": "arXiv preprint arXiv:1806.09055,",
            "year": 2018
        },
        {
            "authors": [
                "Risheng Liu",
                "Pan Mu",
                "Xiaoming Yuan",
                "Shangzhi Zeng",
                "Jin Zhang"
            ],
            "title": "A generic first-order algorithmic framework for bi-level programming beyond lower-level singleton",
            "venue": "In International Conference on Machine Learning (ICML),",
            "year": 2020
        },
        {
            "authors": [
                "Risheng Liu",
                "Jiaxin Gao",
                "Jin Zhang",
                "Deyu Meng",
                "Zhouchen Lin"
            ],
            "title": "Investigating bi-level optimization for learning and vision from a unified perspective: A survey and beyond",
            "venue": "arXiv preprint arXiv:2101.11517,",
            "year": 2021
        },
        {
            "authors": [
                "Risheng Liu",
                "Yaohua Liu",
                "Shangzhi Zeng",
                "Jin Zhang"
            ],
            "title": "Towards gradient-based bilevel optimization with non-convex followers and beyond",
            "venue": "Advances in Neural Information Processing Systems (NeurIPS),",
            "year": 2021
        },
        {
            "authors": [
                "Jonathan Lorraine",
                "Paul Vicol",
                "David Duvenaud"
            ],
            "title": "Optimizing millions of hyperparameters by implicit differentiation",
            "venue": "International Conference on Artificial Intelligence and Statistics (AISTATS),",
            "year": 2020
        },
        {
            "authors": [
                "Dougal Maclaurin",
                "David Duvenaud",
                "Ryan Adams"
            ],
            "title": "Gradient-based hyperparameter optimization through reversible learning",
            "venue": "In International Conference on Machine Learning (ICML),",
            "year": 2015
        },
        {
            "authors": [
                "Aleksander Madry",
                "Aleksandar Makelov",
                "Ludwig Schmidt",
                "Dimitris Tsipras",
                "Adrian Vladu"
            ],
            "title": "Towards deep learning models resistant to adversarial attacks",
            "venue": "arXiv preprint arXiv:1706.06083,",
            "year": 2017
        },
        {
            "authors": [
                "Seyed-Mohsen Moosavi-Dezfooli",
                "Alhussein Fawzi",
                "Jonathan Uesato",
                "Pascal Frossard"
            ],
            "title": "Robustness via curvature regularization, and vice versa",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Yuval Netzer",
                "Tao Wang",
                "Adam Coates",
                "Alessandro Bissacco",
                "Bo Wu",
                "Andrew Y Ng"
            ],
            "title": "Reading digits in natural images with unsupervised feature learning",
            "year": 2011
        },
        {
            "authors": [
                "Anh Nguyen",
                "Jason Yosinski",
                "Jeff Clune"
            ],
            "title": "Deep neural networks are easily fooled: High confidence predictions for unrecognizable images",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2015
        },
        {
            "authors": [
                "Nicolas Papernot",
                "Patrick McDaniel",
                "Somesh Jha",
                "Matt Fredrikson",
                "Z Berkay Celik",
                "Ananthram Swami"
            ],
            "title": "The limitations of deep learning in adversarial settings",
            "venue": "IEEE European symposium on security and privacy (EuroS&P),",
            "year": 2016
        },
        {
            "authors": [
                "Fabian Pedregosa"
            ],
            "title": "Hyperparameter optimization with approximate gradient",
            "venue": "In International Conference on Machine Learning (ICML),",
            "year": 2016
        },
        {
            "authors": [
                "Thomas Pethick",
                "Grigorios G Chrysos",
                "Volkan Cevher"
            ],
            "title": "Revisiting adversarial training for the worst-performing class",
            "venue": "arXiv preprint arXiv:2302.08872,",
            "year": 2023
        },
        {
            "authors": [
                "Qi Qi",
                "Zhishuai Guo",
                "Yi Xu",
                "Rong Jin",
                "Tianbao Yang"
            ],
            "title": "An online method for a class of distributionally robust optimization with non-convex objectives",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Qi Qian",
                "Shenghuo Zhu",
                "Jiasheng Tang",
                "Rong Jin",
                "Baigui Sun",
                "Hao Li"
            ],
            "title": "Robust optimization over multiple domains",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2019
        },
        {
            "authors": [
                "Hamed Rahimian",
                "Sanjay Mehrotra"
            ],
            "title": "Distributionally robust optimization: A review",
            "venue": "arXiv preprint arXiv:1908.05659,",
            "year": 2019
        },
        {
            "authors": [
                "Aravind Rajeswaran",
                "Chelsea Finn",
                "Sham M Kakade",
                "Sergey Levine"
            ],
            "title": "Meta-learning with implicit gradients",
            "venue": "In Advances in Neural Information Processing Systems (NeurIPS),",
            "year": 2019
        },
        {
            "authors": [
                "Sylvestre-Alvise Rebuffi",
                "Sven Gowal",
                "Dan Andrei Calian",
                "Florian Stimberg",
                "Olivia Wiles",
                "Timothy A Mann"
            ],
            "title": "Data augmentation can improve robustness",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Mengye Ren",
                "Wenyuan Zeng",
                "Bin Yang",
                "Raquel Urtasun"
            ],
            "title": "Learning to reweight examples for robust deep learning",
            "venue": "In International conference on machine learning,",
            "year": 2018
        },
        {
            "authors": [
                "Leslie Rice",
                "Eric Wong",
                "Zico Kolter"
            ],
            "title": "Overfitting in adversarially robust deep learning",
            "venue": "In International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Amirreza Shaban",
                "Ching-An Cheng",
                "Nathan Hatch",
                "Byron Boots"
            ],
            "title": "Truncated back-propagation for bilevel optimization",
            "venue": "In International Conference on Artificial Intelligence and Statistics (AISTATS),",
            "year": 2019
        },
        {
            "authors": [
                "Johannes Stallkamp",
                "Marc Schlipsing",
                "Jan Salmen",
                "Christian Igel"
            ],
            "title": "Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition",
            "venue": "Neural networks,",
            "year": 2012
        },
        {
            "authors": [
                "Christian Szegedy",
                "Wojciech Zaremba",
                "Ilya Sutskever",
                "Joan Bruna",
                "Dumitru Erhan",
                "Ian Goodfellow",
                "Rob Fergus"
            ],
            "title": "Intriguing properties of neural networks",
            "venue": "arXiv preprint arXiv:1312.6199,",
            "year": 2013
        },
        {
            "authors": [
                "Qi Tian",
                "Kun Kuang",
                "Kelu Jiang",
                "Fei Wu",
                "Yisen Wang"
            ],
            "title": "Analysis and applications of class-wise robustness in adversarial training",
            "venue": "In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining,",
            "year": 2021
        },
        {
            "authors": [
                "Florian Tram\u00e8r",
                "Nicolas Papernot",
                "Ian Goodfellow",
                "Dan Boneh",
                "Patrick McDaniel"
            ],
            "title": "The space of transferable adversarial examples",
            "venue": "arXiv preprint arXiv:1704.03453,",
            "year": 2017
        },
        {
            "authors": [
                "Rasul Tutunov",
                "Minne Li",
                "Alexander I Cowen-Rivers",
                "Jun Wang",
                "Haitham Bou-Ammar"
            ],
            "title": "Compositional adam: An adaptive compositional solver",
            "venue": "arXiv preprint arXiv:2002.03755,",
            "year": 2020
        },
        {
            "authors": [
                "Jingkang Wang",
                "Tianyun Zhang",
                "Sijia Liu",
                "Pin-Yu Chen",
                "Jiacen Xu",
                "Makan Fardad",
                "Bo Li"
            ],
            "title": "Adversarial attack generation empowered by min-max optimization",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Mengdi Wang",
                "Ji Liu",
                "Ethan Fang"
            ],
            "title": "Accelerating stochastic composition optimization",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2016
        },
        {
            "authors": [
                "Mengdi Wang",
                "Ethan X Fang",
                "Han Liu"
            ],
            "title": "Stochastic compositional gradient descent: algorithms for minimizing compositions of expected-value functions",
            "venue": "Mathematical Programming,",
            "year": 2017
        },
        {
            "authors": [
                "Wentao Wang",
                "Han Xu",
                "Xiaorui Liu",
                "Yaxin Li",
                "Bhavani Thuraisingham",
                "Jiliang Tang"
            ],
            "title": "Imbalanced adversarial training with reweighting",
            "venue": "IEEE International Conference on Data Mining (ICDM),",
            "year": 2022
        },
        {
            "authors": [
                "Eric Wong",
                "Leslie Rice",
                "J Zico Kolter"
            ],
            "title": "Fast is better than free: Revisiting adversarial training",
            "venue": "arXiv preprint arXiv:2001.03994,",
            "year": 2020
        },
        {
            "authors": [
                "Tong Wu",
                "Ziwei Liu",
                "Qingqiu Huang",
                "Yu Wang",
                "Dahua Lin"
            ],
            "title": "Adversarial robustness under long-tailed distribution",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Yao-Yuan Yang",
                "Cyrus Rashtchian",
                "Hongyang Zhang",
                "Ruslan Salakhutdinov",
                "Kamalika Chaudhuri"
            ],
            "title": "Adversarial robustness through local lipschitzness",
            "venue": "arXiv preprint arXiv:2003.02460,",
            "year": 2020
        },
        {
            "authors": [
                "Yao-Yuan Yang",
                "Cyrus Rashtchian",
                "Hongyang Zhang",
                "Russ R Salakhutdinov",
                "Kamalika Chaudhuri"
            ],
            "title": "A closer look at accuracy vs. robustness",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Mingyang Yi",
                "Lu Hou",
                "Lifeng Shang",
                "Xin Jiang",
                "Qun Liu",
                "Zhi-Ming Ma"
            ],
            "title": "Reweighting augmented samples by minimizing the maximal expected loss",
            "venue": "arXiv preprint arXiv:2103.08933,",
            "year": 2021
        },
        {
            "authors": [
                "Huimin Zeng",
                "Chen Zhu",
                "Tom Goldstein",
                "Furong Huang"
            ],
            "title": "Are adversarial examples created equal? a learnable weighted minimax risk for robustness under non-uniform attacks",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Hongyang Zhang",
                "Yaodong Yu",
                "Jiantao Jiao",
                "Eric Xing",
                "Laurent El Ghaoui",
                "Michael Jordan"
            ],
            "title": "Theoretically principled trade-off between robustness and accuracy",
            "venue": "In International conference on machine learning,",
            "year": 2019
        },
        {
            "authors": [
                "Jingfeng Zhang",
                "Xilie Xu",
                "Bo Han",
                "Gang Niu",
                "Lizhen Cui",
                "Masashi Sugiyama",
                "Mohan Kankanhalli"
            ],
            "title": "Attacks which do not kill training make adversarial learning stronger",
            "venue": "In International conference on machine learning,",
            "year": 2020
        },
        {
            "authors": [
                "Jingfeng Zhang",
                "Jianing Zhu",
                "Gang Niu",
                "Bo Han",
                "Masashi Sugiyama",
                "Mohan Kankanhalli"
            ],
            "title": "Geometry-aware instance-reweighted adversarial training",
            "venue": "arXiv preprint arXiv:2010.01736,",
            "year": 2020
        },
        {
            "authors": [
                "Miao Zhang",
                "Steven Su",
                "Shirui Pan",
                "Xiaojun Chang",
                "Ehsan Abbasnejad",
                "Reza Haffari"
            ],
            "title": "idarts: Differentiable architecture search with stochastic implicit gradients",
            "venue": "arXiv preprint arXiv:2106.10784,",
            "year": 2021
        },
        {
            "authors": [
                "Yihua Zhang",
                "Guanhua Zhang",
                "Prashant Khanduri",
                "Mingyi Hong",
                "Shiyu Chang",
                "Sijia Liu"
            ],
            "title": "Revisiting and advancing fast adversarial training through the lens of bi-level optimization",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Yonggang Zhang",
                "Mingming Gong",
                "Tongliang Liu",
                "Gang Niu",
                "Xinmei Tian",
                "Bo Han",
                "Bernhard Sch\u00f6lkopf",
                "Kun Zhang"
            ],
            "title": "Causaladv: Adversarial robustness through the lens of causality",
            "venue": "arXiv preprint arXiv:2106.06196,",
            "year": 2021
        },
        {
            "authors": [
                "2018 Franceschi et al",
                "Shaban et al",
                "meta-learning (Bertinetto et al",
                "2019 Rajeswaran et al",
                "2020 Ji et al",
                "Liu"
            ],
            "title": "2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke",
            "venue": "Pedregosa,",
            "year": 2012
        },
        {
            "authors": [
                "2015 Maclaurin et al",
                "2017 Franceschi et al",
                "2017 Finn et al",
                "2019 Shaban et al",
                "2019 Rajeswaran et al",
                "Liu"
            ],
            "title": "The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021",
            "venue": "Rajeswaran et al.,",
            "year": 2020
        },
        {
            "authors": [
                "Blanchet"
            ],
            "title": "stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate. Many extentions of SCGD have been proposed with improved rates, including accelerated and adaptive SCGD methods Wang et al. (2016); Tutunov et al. (2020), and variance reduced SCGD methods Lian et al",
            "year": 2019
        },
        {
            "authors": [
                "Qian"
            ],
            "title": "distributionally robust optimization (DRO) Rahimian",
            "venue": "B MORE EMPIRICAL SPECIFICATIONS",
            "year": 2019
        },
        {
            "authors": [
                "Liu"
            ],
            "title": "MORE DETAILS ABOUT TRAINING AND HYPERPARAMETERS SEARCH Following the standard practice in adversarial training Madry et al",
            "year": 2017
        },
        {
            "authors": [
                "Zhang"
            ],
            "title": "2021c) (please see fig. 2). We consider l\u221e-norm bounded adversarial perturbations with a maximum radius of \u03b5 = 8/255 both for training and testing",
            "year": 2021
        },
        {
            "authors": [
                "Liu"
            ],
            "title": "learning a weight distribution that boosts worst-case adversarial robustness. All hyperparameters were fixed by holding out 10% of the training data as a validation set and selecting the values that achieve the best performance on the validation set. For the reported results, we train on the full training dataset and report the performance on the testing set Zhang et al",
            "year": 2021
        },
        {
            "authors": [
                "GTSRB Stallkamp"
            ],
            "title": "For CIFAR10, SVHN, and STL10 we use the training and test splits provided by Torchvision",
            "venue": "For GTSRB, we use the splits provided in Zhang et al",
            "year": 2012
        },
        {
            "authors": [
                "Zhang"
            ],
            "title": "We thank the authors for making it publicly available. All codes are tested with Python 3.7 and Pytorch 1.8",
            "venue": "For example,",
            "year": 2022
        },
        {
            "authors": [
                "Ji"
            ],
            "title": "where the last equality follows from the implicit differentiation result for bilevel optimization Pedregosa",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Assigning importance weights to adversarial data has achieved great success in training adversarially robust networks under limited model capacity. However, existing instance-reweighted adversarial training (AT) methods heavily depend on heuristics and/or geometric interpretations to determine those importance weights, making these algorithms lack rigorous theoretical justification/guarantee. Moreover, recent research has shown that adversarial training suffers from a severe non-uniform robust performance across the training distribution, e.g., data points belonging to some classes can be much more vulnerable to adversarial attacks than others. To address both issues, in this paper, we propose a novel doubly-robust instance reweighted AT framework, which allows to obtain the importance weights via exploring distributionally robust optimization (DRO) techniques, and at the same time boosts the robustness on the most vulnerable examples. In particular, our importance weights are obtained by optimizing the KL-divergence regularized loss function, which allows us to devise new algorithms with a theoretical convergence guarantee. Experiments on standard classification datasets demonstrate that our proposed approach outperforms related state-of-the-art baseline methods in terms of average robust performance, and at the same time improves the robustness against attacks on the weakest data points. Codes can be found in the Supplement."
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "Deep learning models are known to be vulnerable to malicious adversarial attacks Nguyen et al. (2015), i.e., small perturbation added to natural input data can easily fool state-of-the-art networks. Given that these deep neural networks are being heavily deployed in real-life applications, even in safety-critical applications, adversarial training (AT) Madry et al. (2017); Athalye et al. (2018a); Carmon et al. (2019) has been proposed for training networks to be robust to adversarial attacks Athalye et al. (2018b); Szegedy et al. (2013); Goodfellow et al. (2014); Papernot et al. (2016); Nguyen et al. (2015); Zhang et al. (2021b; 2020a). In particular, most existing defense strategies are based on the recipes similar to AT Madry et al. (2017), where the goal is to minimize the average loss of the worst-case adversarial data for the training distribution via solving a minimax optimization problem.\nDespite its success, the traditional AT method Madry et al. (2017) has some major limitations. First, even though existing overparameterized neural networks seem to be good enough for natural data, highly adversarial data consumes much more model capacity compared to their clean counterpart, making the minimization of the uniform average adversarial loss a very pessimistic goal, as argued in Zhang et al. (2020b). To overcome this limitation, recent works Zhang et al. (2020b); Liu et al. (2021a); Zeng et al. (2021); Ding et al. (2018) assign an importance weight to each data point in the training distribution, in order to emphasize the ones that are critical to determining the model\u2019s decision boundaries. By allowing more careful exploitation of the limited model capacity, such a simple instance-reweighted scheme combined with traditional adversarial training has yielded a significant boost in the robust performance of current adversarially trained models. Yet, existing methods for instance-reweighted AT mostly adopt heuristic techniques and/or geometric intuitions in order to compute the instance weights, which makes these algorithms lack a principled and rigorous theoretical justification/guarantee. This hence motivates the following question we ask:\nHow to systematically determine the importance weights via a principled approach, rather than resorting to heuristics/interpretations which are often sub-optimal?\nMoreover, as observed in Tian et al. (2021), another critical limitation of the transitional AT method is that it suffers a severe non-uniform performance across the empirical distribution. For example, while the average robust performance of the AT method on the CIFAR10 dataset can be as high as 49%, the robust accuracy for the weakest class is as low as 14%, which depicts a huge disparity in robust performance across different classes. We note that such a non-uniform performance across classes is also slightly observed in the standard training with clean data, but its severity is much worsened in adversarial training (see Figure 1). Indeed, this is a critical limitation that requires special attention as, in a real-world situation, a more intelligent attacker can, in fact, decide which examples to attack so as to achieve a much higher success rate (e.g., 86% when attacking the most vulnerable class). This non-uniform robust performance is even worsened in the case of imbalanced training distributions Wu et al. (2021); Wang et al. (2022), where the robust performance for the most vulnerable class can be as low as 0%. This motivates our second question given below:\nCan such an issue of non-uniform performance particularly over imbalanced datasets be addressed at the instance level simultaneously as we design the importance weights to address the first question?\nIn this paper, we propose a novel doubly robust instance reweighted optimization approach to address both of the above questions."
        },
        {
            "heading": "1.1 OUR CONTRIBUTIONS",
            "text": "(A novel principled framework for instance reweighted AT) In order to determine the instance weights for AT in a theoretically grounded way, we propose a novel doubly robust instance reweighted optimization framework, based on distributionally robust optimization (DRO) Rahimian & Mehrotra (2019); Qian et al. (2019) and bilevel optimization (Zhang et al., 2022; Pedregosa, 2016; Grazzi et al., 2020b). Through building a model that is robust not only to the adversarial attacks but also to the worst-case instance weight selections, our framework (a) enjoys better robust performance than existing instance-reweighted schemes based on heuristic/geometric techniques Zhang et al. (2020b); Liu et al. (2021a); Zeng et al. (2021) as well as tradtional AT baselines Madry et al. (2017); and (b) addresses the non-uniform issues Tian et al. (2021); Pethick et al. (2023) of traditional AT by carefully optimizing the instance weights so as to boost the robust performance of the most vulnerable examples. Moreover, the proposed framework can be reformulated into a new finite-sum compositional bilevel optimization problem (CBO), which can be of great interest to the optimization community on its own.\n(A novel algorithm with theoretical guarantee) Solving the proposed doubly robust optimization problem is technically challenging, including the non-differentiability of the optimizer for the constrained inner level problem and the biased hypergradient estimation for the compositional outer level problem. To tackle these challenges, we first propose a penalized reformulation based on the log-barrier penalty method, and then develop a novel algorithm which exploits the implicit function theorem and keeps track of a running average of the outer level composed function values. Our algorithm not only leads to a robust model for the proposed instance reweighted optimization problem but also provides a solution to the generic compositional bilevel optimization problem. Under widely adopted assumptions in the bilevel (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021) and compositional optimization Wang et al. (2017); Chen et al. (2021b); Lian et al. (2017); Blanchet et al. (2017); Devraj & Chen (2019) literature, we further establish the convergence guarantee for the proposed algorithm.\n(Strong experimental performance) Experiments on several balanced and imbalanced image recognition datasets demonstrate the effectiveness of our proposed approach. In particular, on CIFAR10 our approach yields +3.5% improvement in overall robustness against PGD attacks Madry et al. (2017) with most of it coming from boosting robustness on vulnerable data points."
        },
        {
            "heading": "1.2 RELATED WORK",
            "text": "Adversarial training for robust learning Adversarial training (AT) Madry et al. (2017); Athalye et al. (2018a); Carmon et al. (2019) was proposed for training deep neural networks robust to malicious adversarial attacks Goodfellow et al. (2014); Tram\u00e8r et al. (2017). In particular, Madry et al. (2017) introduced a generic AT framework based on minimax optimization with the goal of minimizing the training loss of the worst-case adversarial data for the training distribution. However, despite AT method being still considered as one of the most powerful defense strategies, Rice et al. (2020)\nhighlights a severe decrease in robust performance of traditional AT when training is not stopped early, a phenomenon they dubbed robust overfitting. Several extensions of the standard AT method have been proposed to mitigate this intriguing problem, such as data augmentation-based techniques Rebuffi et al. (2021); Gowal et al. (2021), or smoothing-based methods Chen et al. (2021a); Yang et al. (2020a;b). Zhang et al. (2019) proposed a theoretically grounded objective for AT to strike a balance between robust and natural performance. However, those methods suffer a severe nonuniform performance across classification categories, as observed in Tian et al. (2021). Our proposed framework helps mitigate this drawback by carefully optimizing for the most vulnerable data points.\nInstance reweighted adversarial training Another line of works Zhang et al. (2020b); Liu et al. (2021a); Zeng et al. (2021); Ding et al. (2018) assign an importance weight to each data point in the empirical distribution and minimize the weighted adversarial losses. This has been shown to significantly boost the performance of AT due to more careful exploitation of the limited capacity of large deep neural networks to fit highly adversarial data, and helps overcome robust overfitting to some extent Zhang et al. (2020b). For example, in the geometry-aware adversarial instance reweighted adversarial training (GAIRAT) Zhang et al. (2020b) method, the instance weight is computed based on the minimum number of PGD Madry et al. (2017) steps required to generate a mis-classified adversarial example. Liu et al. (2021a) leverages probabilistic margins to compute weights. Existing approaches for instance reweighted AT are, however, all based on heuristics/geometric intuitions to determine the weights. In this paper, we propose a principled approach to instance-reweighted AT by exploiting robust optimization techniques Qian et al. (2019); Rahimian & Mehrotra (2019).\nInstance reweighting has also been used in the context of domain adaptation Jiang & Zhai (2007), data augmentation Yi et al. (2021), and imbalanced classification Ren et al. (2018). By determining the instance weights in a more principled way, our method also has the potential to be applied to these contexts, which we leave as future work.\nDue to space limitation, more discussions about related literature in Bilevel Optimization and Stochastic Compositional Optimization is deferred to Appendix A."
        },
        {
            "heading": "2 PRELIMINARY ON AT",
            "text": "Traditional AT. The traditional adversarial training (AT) Madry et al. (2017) framework is formulated as the following minimax optimization problem over the training dataset D = {(xi, yi)}Mi=1\nmin \u03b8\n1\nM M\u2211 i=1 max \u03b4\u2208C \u2113(xi + \u03b4, yi; \u03b8), (1)\nwhere \u2113(xi + \u03b4, yi; \u03b8) is the loss function on the adversarial input xi + \u03b4, C is the treat model that defines the constraint on the adversarial noise \u03b4, and \u03b8 \u2208 Rd corresponds to the model parameters. Thus, the traditional AT builds robust models by optimizing the parameters \u03b8 for the average worstcase adversarial loss \u2113(xi + \u03b4, yi; \u03b8) over the training dataset D. A natural solver for the problem in Equation (1) is the AT algorithm Madry et al. (2017), where 1) the projected gradient descent (PGD) Madry et al. (2017) method is first adopted to approximate the worst-case adversarial noise \u03b4 and 2) an outer minimization step is performed on the parameters \u03b8 using stochastic gradient descent (SGD) methods. However, the traditional AT is known to consume tremendous amount of model capacity due to its overwhelming smoothing effect of natural data neighborhoods Zhang et al. (2020b). In other words, the traditional AT robustifies models by making decision boundaries far away from natural data points so that their adversarial counterparts are still correctly classified (i.e., do not cross the decision boundary), and thus requires significantly more model capacity compared to the standard training on clean data.\nInstance Reweighted AT. The geometry-aware approach in Zhang et al. (2020b) introduces a new line of methods that reweights the adversarial loss on each individual data point in order to address the drawback of traditional AT. The key motivation is that distinct data points are unequal by nature and should be treated differently based on how important they participate on the selection of decision boundaries. Hence, the learning objective of the geometry-aware instance-reweighted adversarial training (GAIRAT) method as well as its variants Zhang et al. (2020b); Liu et al. (2021a); Zeng et al. (2021) can be written as\nmin \u03b8 M\u2211 i=1 wi max \u03b4\u2208Ci \u2113(xi + \u03b4, yi; \u03b8) with M\u2211 i=1 wi = 1 and wi \u2265 0, (2)\nwhere the constraints on the weights vector w = (w1, ..., wM )\u22a4 are imposed in order to make Equation (2) consistent with the original objective in Equation (1). This framework assumes that the weight vector w = (w1, ..., wM )\u22a4 can be obtained separately and the goal is only to optimize for \u03b8 once an off-the-shelf technique/heuristic can be used to compute w. Intuitively, the key idea driving the weight assignments in instance reweighted methods is that larger weights should be assigned to the training examples closer to the decision boundaries, whereas the ones that are far away should have smaller weights because they are less important in determining the boundaries. The major difference among the existing instance reweighted AT methods lies in the heuristics used to design/compute the instance weights wi, i = 1, ...,M . However, none of those methods adopt a scheme that is theoretically grounded, nor does the formulation in Equation (2) provide a way of determining those weights.\nBilevel Optimization Formulation for AT. Along a different line, bilevel optimization has recently been leveraged to develop a more powerful framework for adversarial training Zhang et al. (2022):\nmin \u03b8\n1\nM M\u2211 i=1 \u2113(xi + \u03b4 \u2217 i (\u03b8), yi; \u03b8) s.t. \u03b4 \u2217 i (\u03b8) = argmin \u03b4\u2208Ci \u2113\u2032(xi + \u03b4, yi; \u03b8), (3)\nwhere for each data point (xi, yi), \u03b4\u2217i (\u03b8) represents some worst-case/optimal adversarial noise under the attack loss function \u2113\u2032(\u00b7; \u03b8). Such a bilevel optimization formulation of AT has key advantages over the traditional framework in Equation (1). First, the traditional AT can be recovered by setting the attack objective to be the negative of the training objective, i.e., \u2113\u2032(\u00b7; \u03b8) = \u2212\u2113(\u00b7; \u03b8). Second, the bilevel formulation gives one the flexibility to separately design the inner and outer level objectives, \u2113\u2032 and \u2113, respectively. These key advantages make the formulation in Equation (3) a more generic and powerful framework than the one in Equation (1). As we will see next, this enables us to independently construct a new outer level objective that also solves for the instance weights w, and an inner level objective for regularized attack."
        },
        {
            "heading": "3 PROPOSED FRAMEWORK FOR INSTANCE REWEIGHTED AT",
            "text": ""
        },
        {
            "heading": "3.1 DONE: DOUBLY ROBUST INSTANCE REWEIGHTED AT",
            "text": "Using the bilevel formulation for AT in Eq. equation 3, we can incorporate the instance reweighted idea as\nmin \u03b8 M\u2211 i=1 wi\u2113(xi + \u03b4 \u2217 i (\u03b8), yi; \u03b8) s.t. \u03b4 \u2217 i (\u03b8) = argmin \u03b4\u2208Ci \u2113\u2032(xi + \u03b4, yi; \u03b8) with M\u2211 i=1 wi = 1 and wi \u2265 0. (4)\nBased on bilevel optimization and distributionally robust optimization (DRO), we next propose a new framework for AT which determines the weights w in a more principled way rather than using heuristic methods. Specifically, by letting w maximize the weighted sum of the adversarial losses \u2113(xi + \u03b4 \u2217 i (\u03b8), yi; \u03b8), i = 1, ...,M , we seek to build a model in the outer level problem that is robust not only to the adversarial attacks but also to the worst-case attack distribution:\nmin \u03b8 max w\u2208P M\u2211 i=1 wi\u2113(xi + \u03b4 \u2217 i (\u03b8), yi; \u03b8)\u2212r M\u2211 i=1 wi log(Mwi) s.t. \u03b4\u2217i (\u03b8) = argmin \u03b4\u2208Ci \u2113\u2032(xi + \u03b4, yi; \u03b8), (5)\nwhere P represents the probability simplex, i.e., P = {w \u2208 RM : \u2211M\ni=1 wi = 1 and wi \u2265 0}, and the term r \u2211M i=1 wi log(Mwi) in the outer level objective captures the KL-divergence between w and the uniform weight distribution, which is a widely adopted choice of regularizer in the DRO literature Rahimian & Mehrotra (2019). Note that the regularization parameter r > 0 controls the tradeoff between two extreme cases: 1) r = 0 leads to an un-regularized problem (as we comment below), and 2) r \u2192 \u221e yields wi \u2192 1M , and hence, we recover the average objective in Equation (1). Such a regularizer is introduced to promote the balance between the uniform and worst-case weights w; otherwise the outer level objective in Equation (5) becomes linear in weights vector w, which makes the solution of the \u2018max\u2019 problem to be trivially a one-hot vector w (where the only \u20181\u2019 is at index i with the largest adversarial loss), and in practice, such a trivial one-hot vector w makes the optimization routine unstable and usually hurts generalization to the training distribution Qian et al. (2019); Wang et al. (2021).\nOverall, the formulation in Equation (5) becomes a doubly robust bilevel optimization: (a) the inner level finds the worst-case noise \u03b4 in order to make the model parameters \u03b8 robust to such\nadversarial perturbation of data input; and (b) the outer level finds the worst-case reweighting first so that the optimization over the model \u03b8 can focus on those data points with high loss values, i.e., the optimization over \u03b8 is over the worst-case adversarial losses."
        },
        {
            "heading": "3.2 AN EQUIVALENT COMPOSITIONAL BILEVEL OPTIMIZATION PROBLEM",
            "text": "An important consequence of choosing the KL-divergence as the regularizer is that the max problem in the outer objective of Equation (5) admits a unique solution w\u2217(\u03b8) (see Qi et al. (2021) for proof), which has its i-the entry given by w\u2217i (\u03b8) = exp ( \u2113i(\u03b8,\u03b4 \u2217 i (\u03b8)) r ) / \u2211 j exp ( \u2113j(\u03b8,\u03b4 \u2217 j (\u03b8)) r ) . Here we denote \u2113i(\u03b8, \u03b4\u2217i (\u03b8)) = \u2113(xi + \u03b4 \u2217 i (\u03b8), yi; \u03b8). Substituting this optimal weights vector w\n\u2217(\u03b8) back in Equation (5) yields the following equivalent optimization problem\nmin \u03b8 r log\n( 1\nM M\u2211 i=1 exp ( \u2113i(\u03b8, \u03b4 \u2217 i (\u03b8)) r )) s.t. \u03b4\u2217i (\u03b8) = argmin \u03b4\u2208Ci \u2113\u2032i(\u03b8, \u03b4). (6)\nProblem (6) is, in fact to the best of our knowledge, a novel optimization framework, which we define as a compositional bilevel optimization problem. Without the inner level problem, stochastic algorithms with known convergence behaviors have been devised for the single-level compositional problem. Nevertheless, directly solving problem (6) suffers from several key technical challenges. In particular, the fact that the minimizer of the inner level constrained problem in Equation (6) may not be differentiable w.r.t. to the model parameter \u03b8 prevents the usage of implicit differentiation for solving the bilevel optimization problem.\nTo tackle this challenge, we propose a penalized reformulation based on the log-barrier penalty method. More specifically, we consider \u2113\u221e-norm based attack constraint given by C = {\u03b4 \u2208 Rp :\u2225\u2225\u03b4\u2225\u2225\u221e \u2264 \u03f5, x + \u03b4 \u2208 [0, 1]p} for radius \u03f5 > 0 and input x \u2208 Rp. In this case, the constraint set C can be written in the form of linear constraint A\u03b4 \u2264 b with A = ( Ip,\u2212Ip\n)\u22a4 \u2208 R2p\u00d7p and b = ( min(\u03f51p,1p \u2212 x),min(\u03f51p, x)\n)\u22a4 \u2208 R2p. With this, we can reformulate the inner problem in Equation (6) as \u03b4\u2217i (\u03b8) = argmin{Ai\u03b4\u2264bi} \u2113 \u2032 i(\u03b8, \u03b4), where Ai and bi are realizations of aforementioned A and b for input xi. By using the log-barrier penalty method to penalize the linear constraint into the attack objective, the optimization problem (6) becomes\nmin \u03b8\nL(\u03b8) := r log\n( 1\nM M\u2211 i=1 exp\n( \u2113i(\u03b8, \u03b4\u0302 \u2217 i (\u03b8))\nr\n)) s.t. \u03b4\u0302\u2217i (\u03b8) = argmin\n\u03b4\u2208Ci \u2113bari (\u03b8, \u03b4), (7)\nwhere \u2113bari (\u03b8, \u03b4) := \u2113 \u2032 i(\u03b8, \u03b4)\u2212 c \u22112p k=1 log(bk \u2212 \u03b4\u22a4ak), ak denotes the k-th row of matrix Ai and bk is the k-th entry of vector bi. Note that now the constraint {\u03b4 \u2208 Ci} is never binding in Equation (7), because the log-barrier penalty forces the minimizer of \u2113bari (\u03b8, \u03b4) to be strictly inside the constraint set. Based on this, we show that the minimizer \u03b4\u0302\u2217i (\u03b8) becomes differentiable, i.e., \u2202\u03b4\u0302\u2217i (\u03b8)\n\u2202\u03b8 exists when \u2113\u2032i(\u03b8, \u03b4) is twice differentiable and under some mild conditions. With the smoothness of \u03b4\u0302 \u2217 i (\u03b8), we also provide the expression of the gradient \u2207L(\u03b8) in the following proposition. Proposition 1. Let \u2113\u2032i(\u03b8, \u03b4) be twice differentiable. Define \u03b3k = 1/(bk \u2212 a\u22a4k \u03b4\u0302\u2217i (\u03b8))2, k = 1, ..., 2p and diagonal matrix Ci(\u03b8) = cdiag ( \u03b31+\u03b3p+1, \u03b32+\u03b3p+2, ..., \u03b3p+\u03b32p ) . If \u22072\u03b4 \u2113\u2032i(\u03b8, \u03b4\u0302\u2217i (\u03b8))+Ci(\u03b8) is invertible, then the implicit gradient \u2202\u03b4\u0302 \u2217 i (\u03b8) \u2202\u03b8 exists and we have\n\u2207L(\u03b8) = r \u2211M i=1 ( \u2207\u03b8 gi(\u03b8, \u03b4\u0302\u2217i (\u03b8))\u2212\u2207\u03b8\u03b4 \u2113\u2032i(\u03b8, \u03b4\u0302\u2217i (\u03b8)) [ \u22072\u03b4 \u2113\u2032i(\u03b8, \u03b4\u0302\u2217i (\u03b8)) + Ci(\u03b8) ]\u22121\u2207\u03b4 gi(\u03b8, \u03b4\u0302\u2217i (\u03b8)))\u2211M i=1 gi(\u03b8, \u03b4\u0302 \u2217 i (\u03b8)) ,\nwhere gi(\u03b8, \u03b4\u0302\u2217i (\u03b8)) = exp ( \u2113i(\u03b8,\u03b4\u0302 \u2217 i (\u03b8)) r ) .\nProposition 1 provides the expression of the total gradient \u2207L(\u03b8), which is useful for practical implementation of implicit differentiation based algorithms for problem (6). Moreover, as in Zhang et al. (2022), when \u2113\u2032i(\u03b8, \u00b7) is modeled by a ReLU-based deep neural network, the hessian \u22072\u03b4 \u2113\u2032i(\u03b8, \u03b4) w.r.t. input \u03b4 can be safely neglected due to the fact that ReLU network generally lead to piece-wise linear decision boundaries w.r.t. its inputs Moosavi-Dezfooli et al. (2019); Alfarra et al. (2022), i.e., \u22072\u03b4 \u2113\u2032i(\u03b8, \u03b4) \u2248 0. Further, the diagonal matrix Ci(\u03b8) can be efficiently inverted. Hence, in order to approximate \u2207L(\u03b8), we only need Jacobian-vector product computations which can be efficiently computed using existing automatic differentiation packages."
        },
        {
            "heading": "3.3 COMPOSITIONAL IMPLICIT DIFFERENTIATION (CID)",
            "text": "To solve our reformulated problem (7) for AT, we consider the following generic compositional bilevel optimization problem, which can be of great interest to the optimization community:\nmin \u03b8\nF (\u03b8) := f (g (\u03b8, \u03b4\u2217(\u03b8))) = f\n( 1\nM M\u2211 i=1 gi (\u03b8, \u03b4 \u2217 i (\u03b8))\n) (8)\ns.t. \u03b4\u2217(\u03b8) = (\u03b4\u22171(\u03b8), ..., \u03b4 \u2217 M (\u03b8)) = argmin\n(\u03b41,...,\u03b4M )\u2208V1\u00d7...\u00d7VM\n1\nM M\u2211 i=1 hi (\u03b8, \u03b4i) ,\nwhich can immediately recover problem (7) by setting gi = exp ( \u2113i(\u03b8,\u03b4\u0302 \u2217 i (\u03b8)) r ) , hi = \u2113\u2032i(\u03b8, \u03b4) \u2212\nc \u22112p\nk=1 log(bk\u2212\u03b4\u22a4ak), and the constraint set Vi = Ci. Here the outer functions gi(\u03b8, \u03b4) : Rd\u00d7Rp \u2192 Rm and f(z) : Rm \u2192 R are generic nonconvex and continuously differentiable functions. The inner function hi(\u03b8, \u03b4) : Rd \u00d7 Vi \u2192 R is a twice differentiable and admits a unique minimizer in \u03b4, Vi is a convex subset of Rp that is assumed to contain the minizers \u03b4\u2217i (\u03b8). We collect all inner loop minimizers into a single vector \u03b4\u2217(\u03b8). The goal is to minimize the total objective function F (\u03b8) : Rd \u2212\u2192 R, which not only leads to a robust model for our instance reweighted optimization problem (7) but also provides a solution to the generic compositional bilevel optimization problem.\nAs alluded earlier, solving the compositional bilevel optimization problem is nontrivial. More specifically, it can be shown that the gradient of the total objective is \u2207F (\u03b8) = \u2202g(\u03b8,\u03b4\n\u2217(\u03b8)) \u2202\u03b8 \u2207f (g (\u03b8, \u03b4 \u2217(\u03b8))) by applying the chain rule. Due to the fact that \u2207f(\u00b7) needs to be evaluated at the full value g (\u03b8, \u03b4\u2217(\u03b8)), standard stochastic gradient descent methods cannot be naively applied here. The reason is that even if we can obtain the unbiased estimates gi (\u03b8, \u03b4\u2217i (\u03b8)), the product \u2202gi(\u03b8,\u03b4 \u2217 i (\u03b8))\n\u2202\u03b8 \u2207f (gi (\u03b8, \u03b4 \u2217 i (\u03b8))) would still be biased, unless f(\u00b7) is a linear function. This key difference makes problem (8) particularly challenging and sets it apart from the standard finite-sum bilevel optimization problem in which the total objective is linear w.r.t. the sampling probabilities 1M .\nTo design a theoretically grounded algorithm for problem (8), note that the stochastic compositional gradient descent (SCGD) Wang et al. (2017) algorithm for the single-level compositional optimization problem keeps track of a running average of the composed function evaluations during the algorithm running. Inspired by SCGD, we propose a novel algorithm (see Algorithm 1) that exploits the implicit differentiation technique to deal with the bilevel aspect of problem (8). Using the implicit function theorem, we can obtain\n\u2202gi (\u03b8, \u03b4 \u2217 i (\u03b8))\n\u2202\u03b8 = \u2207\u03b8gi (\u03b8, \u03b4\u2217i (\u03b8))\u2212\u2207\u03b8\u2207\u03b4hi (\u03b8, \u03b4\u2217i (\u03b8)) v\u2217i , (9)\nwith each v\u2217i being the solution of the linear system \u22072\u03b4hi (\u03b8, \u03b4\u2217i (\u03b8)) v = \u2207\u03b4gi (\u03b8, \u03b4\u2217i (\u03b8)).\nSpecifically, at each step t, the algorithm first samples a batch B of cost functions {(gi, hi)} and applies K steps of projected gradient descent to obtain \u03b4Ki (\u03b8t) as an estimate of the minimizer \u03b4\u2217i (\u03b8t) of each hi(\u03b8t, \u00b7) in B. Then, the algorithm computes an approximation \u2207\u0302gi(\u03b8t, \u03b4Ki (\u03b8t)) of the stochastic gradient sample \u2202gi(\u03b8t,\u03b4\n\u2217(\u03b8t)) \u2202\u03b8 by replacing each \u03b4 \u2217 i (\u03b8t) with \u03b4 K i (\u03b8t) in Equation (9). The\nrunning estimate ut of \u2202g(\u03b8,\u03b4\u2217(\u03b8))\n\u2202\u03b8 and the parameters \u03b8 will be next updated as follows\nut+1 = (1\u2212 \u03b7t)ut + \u03b7t |B| |B|\u2211 i=1 gi(\u03b8t, \u03b4 K i (\u03b8t)) and \u03b8t+1 = \u03b8t \u2212 \u03b2t |B| |B|\u2211 i=1 \u2207\u0302gi(\u03b8t, \u03b4Ki (\u03b8t))\u2207f(ut+1). (10)\nNote that we will refer the instantiation of Algorithm 1 for solving the instance reweighted problem (7) as DONE (which stands for Doubly Robust Instance Reweighted AT)."
        },
        {
            "heading": "3.4 CONVERGENCE ANALYSIS OF CID",
            "text": "In the following, we establish the convergence rate of the proposed CID algorithm under widely adopted assumptions in bilevel and compositional optimization literatures (see Appendix E for the statement of assumptions and proof of Theorem 1). Theorem 1. Suppose that Assumptions 1, 2, 3 (which are given in Appendix) hold. Select the stepsizes as \u03b2t = 1\u221aT and \u03b7t \u2208 [ 1 2 , 1), and batchsize as O(T ). Then, the iterates \u03b8t, t = 0, ..., T \u2212 1 of the\nAlgorithm 1 Compositional Implicit Differentiation (CID)\n1: Input: stepsizes \u03b1, {\u03b2t}, {\u03b7t}, initializations \u03b80 \u2208 Rd, \u03b40 \u2208 Rp, and u0 \u2208 Rm. 2: for k = 0, 1, 2, ..., T \u2212 1 do 3: Draw a minibatch of cost functions B = {(gi, hi)} 4: for each (gi, hi) \u2208 B (in parallel) do 5: for k = 1, ...,K do 6: Update \u03b4ki,t = \u03a0C ( \u03b4k\u22121i,t \u2212 \u03b1\u2207\u03b4hi(\u03b8t, \u03b4 k\u22121 i,t )\n) 7: end for 8: Compute sample gradient estimate \u2207\u0302gi(\u03b8t, \u03b4Ki,t) as in Equation (9) by replacing \u03b4\u2217i (\u03b8t) with \u03b4Ki,t 9: end for\n10: Compute g(\u03b8t, \u03b4Kt ;B) = 1|B| \u2211|B| i=1 gi(\u03b8t, \u03b4 K i,t) and \u2207\u0302g(\u03b8t, \u03b4Kt ;B) = 1|B| \u2211|B| i=1 \u2207\u0302gi(\u03b8t, \u03b4 K i,t) 11: Update ut+1 = (1\u2212 \u03b7t)ut + \u03b7tg(\u03b8t, \u03b4Kt ;B) 12: Update \u03b8t+1 = \u03b8t \u2212 \u03b2t\u2207\u0302g(\u03b8t, \u03b4Kt ;B)\u2207f(ut+1) 13: end for\nCID algorithm satisfy \u2211T\u22121 t=0 E \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 T \u2264 O ( 1\u221a T + (1\u2212 \u03b1\u00b5)K ) ,\nThe proof can be found in the Appendix. Theorem 1 indicates that Algorithm 1 can achieve an \u03f5-accurate stationary point by selecting T = O(\u03f5\u22122) and K = O(log 1\u03f5 ). The dependency on the batchsize can be reduced to O(\u03f5\u22121) by selecting \u03b7t = T\u22120.25, which would also lead to a higher iteration complexity of O(\u03f5\u22124)."
        },
        {
            "heading": "4 EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "4.1 EXPERIMENTAL SETUP",
            "text": "Datasets and Baselines. We consider image classification problems and compare the performance of our proposed DONE method with related baselines on four image recognition datasets CIFAR10 Krizhevsky & Hinton (2009), SVHN Netzer et al. (2011), STL10 Coates et al. (2011), and GTSRB Stallkamp et al. (2012). More details about the datasets can be found in the appendix. We compare against standard adversarial training methods AT Madry et al. (2017) and FAT Zhang et al. (2020a), and three other state-of-the-art instance re-weighted adversarial training methods GAIRAT Zhang et al. (2020b), WMMR Zeng et al. (2021), and MAIL Liu et al. (2021a). We use the official publicly available codes of the respective baselines and their recommended training configurations. For our algorithm DONE, we consider three implementations based on how we solve the inner loop optimization: (i) DONE-GD uses simple non-sign projected gradient descent steps; (ii) DONEADAM employs the Adam optimizer; and (iii) DONE-PGD adopts the projected gradient sign method. We run all baselines on a single NVIDIA Tesla V100 GPU.\nMore details about the training and hyperparameters search can be found in Appendix B.\nEvaluation. For all baselines, we report their standard accuracy on clean data (SA), the robust accuracy against 20 steps PGD attacks (RA-PGD) Madry et al. (2017), the robust accuracy against AutoAttacks (RA-AA) Croce & Hein (2020), and the RA-PGD of the 30% most vulnerable classes (RA-Tail-30) as a measure of robustness against attacks on the most vulnerable data points."
        },
        {
            "heading": "4.2 BETTER DISTRIBUTION OF ROBUST PERFORMANCE",
            "text": "We first demonstrate that our proposed doubly robust formulation can indeed achieve robust performance in a more balanced way across the empirical distribution. Figure 1 shows the per class robust accuracy (RA-PGD) of the standard AT method and our doubly-robust approach (i.e., vanilla DONE-GD method) for both balanced and imbalanced (with an imbalance ratio of 0.2) CIFAR10 dataset. For the balanced case, our algorithm improves the robustness on all classes, meanwhile with a more significant boost on the weakest classes (cat, deer, and bird). On the other hand, for the imbalanced data case, the classes with more examples (last five categories) heavily dominate the robust training dynamic. This consequently leads to very high robustness on those classes, but\nnearly zero robustness on the vulnerable classes (such as cat). However, our method can still boost the per class RA-PGD on the weak classes (+11% on average on the 3 most vulnerable classes) and at the same time maintain a superior average RA-PGD. Overall, the results for both balanced and imbalanced settings clearly demonstrate that our doubly-robust approach can, in fact, improve worst-case robustness and hence achieve superior average robust performance.\n4.3 MAIN RESULTS\nComparisons under CIFAR10. The overall performance of the compared baselines under both balanced and imbalanced CIFAR10 are reported in Table 1. We highlight the following important observations. First, overall our methods outperform all other baselines in terms of all three robustness metrics (RAPGD, RA-Tail-30, and RA-AA), meanwhile also maintaining a competitive standard acurracy (SA). In particular, our algorithms can improve the RA-PGD of the strongest base-\nline (MAIL) by over 3% with most of the gain coming from improvement on the weakest classes, as is depicted on the RA-Tail-30 column. This shows that our doubly robust approach can mitigate the weak robustness on the vulnerable data points while also keeping the robust performance on well guarded examples (i.e., easy data points) at the same level. Second, note that the instance reweighted baselines consistently outperform the methods without reweighting on the RA-Tail-30 metric, which indicates that reweighting in general boosts the robustness on weak examples. This advantage is even clearer on the imbalanced data case. Yet, our algorithms still outperform the other instance reweighted methods by around 3% in terms of RA-Tail-30 in the balanced data setup due to their doubly-robust nature, which clearly is helpful both for average and worst-case robust performance. Third, note that the other methods that employ heuristics to compute the instance weights achieve worst RA-AA performance compared to the standard AT method. In contrast, our algorithms, which also fall in the instance reweighted paradigm, can still attain competitive performance for RA-AA compared to the standard AT method. This highlights the suboptimality of using heuristics which\ncould be geared towards improving one metric (such as the RA-PGD) but may not be necessarily beneficial to the overall robustness of the model.\nPerformance Comparisons on the other datasets. Table 2 shows the evaluations of the compared baselines on the SVHN dataset. As depicted, our algorithms (DONE-PGD and DONE-ADAM) significantly outperform the standard AT method on the RA-PGD metric and at the same time achieve better robustness against AutoAttacks (RA-AA). Compared with the instance reweighted baselines (MAIL & GAIRAT), the advantage of our methods is even more important on the RA-AA metric (e.g., up to around +8% on RA-AA vs +1.5% on RA-PGD for the balanced data setting). We also note considerable improvements on the GTSRB and STL10 datasets in Table 3. Similarly to the CIFAR10 dataset, our approach yields an important boost on the RA-Tail-30 robustness metric compared to all other baselines and the advantage is more significant on the imbalanced data case. These results consistently demonstrate that our doubly-robust approach can indeed improve worst-case robust performance meanwhile also maintaining/improving the overall robustness.\nEvaluations under Fast AT Setting. We also compare our approach with fast adversarial training methods. For this setup, we generate the adversarial attacks during training with only 1 GD step after initialization with 1 PGD warm-up step Zhang et al. (2022) and train all baselines for 25 epochs. We compare our method with Fast-BAT Zhang et al. (2022), Fast-AT Wong et al. (2020), and Fast-AT-GA Andriushchenko & Flammarion (2020) on CIFAR10. The evaluations of the compared methods are reported in Table 4. Our algorithm achieves a much better robust performance and at the same time keeps a competitive SA. In particular, we note a significant boost (+11%) in RA-Tail-30, which is mainly the cause of the improvement in the overall RA-PGD."
        },
        {
            "heading": "5 CONCLUSIONS",
            "text": "In this paper, we proposed a novel doubly robust instance reweighted adversarial training framework based on DRO and bilevel optimization, which not only determines the instance weights for AT in a theoretically grounded way but also addresses the non-uniform issues of traditional AT by boosting the robust performance of the most vulnerable examples. To address the technical challenges in solving the doubly robust optimization problem, we proposed a penalized reformulation using the log-barrier penalty method, and developed a novel algorithm based on implicit function theorem and tracking a running average of the outer level function values. Our proposed framework also leads to a new finite-sum compositional bilevel optimization problem, which can be of great interest to the optimization community and solved by our developed algorithm with theoretical guarantee. In the experiments on standard benchmarks, our doubly-robust approach (DONE) outperforms related state-of-the-art baseline approaches in average robust performance and also improves the robustness against attacks on the weakest data points."
        },
        {
            "heading": "A MORE RELATED WORK DISCUSSIONS ABOUT BILEVEL OPTIMIZATION AND STOCHASTIC COMPOSITIONAL OPTIMIZATION",
            "text": "Bilevel optimization Bilevel optimization is a powerful tool to study many machine learning applications such as hyperparameter optimization (Franceschi et al., 2018; Shaban et al., 2019), meta-learning (Bertinetto et al., 2018; Franceschi et al., 2018; Rajeswaran et al., 2019; Ji et al., 2020; Liu et al., 2021b), neural architecture search (Liu et al., 2018; Zhang et al., 2021a), etc. Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012; Pedregosa, 2016; Gould et al., 2016; Liao et al., 2018; Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012; Maclaurin et al., 2015; Franceschi et al., 2017; Finn et al., 2017; Shaban et al., 2019; Rajeswaran et al., 2019; Liu et al., 2020). The convergence rates of these methods have been widely established (Grazzi et al., 2020a; Ji et al., 2021; Rajeswaran et al., 2019; Ji & Liang, 2021). Bilevel optimization has been leveraged in adversarial training very recently, which provides a more generic framework by allowing independent designs of the inner and outer level objectives Zhang et al. (2022). However, none of these studies investigated bilevel optimization when the outer objective is in the form of compositions of functions. In this work, we introduce the compositional bilevel optimization problem as a novel pipeline for instance reweighted AT, and establish its first known convergence rate.\nStochastic compositional optimization Stochastic compositional optimization (SCO) deals with the minimization of compositions of stochastic functions. Wang et al. (2017) proposed the compositional stochastic gradient descent (SCGD) algorithm as a pioneering method for SCO problems and established its convergence rate. Many extentions of SCGD have been proposed with improved rates, including accelerated and adaptive SCGD methods Wang et al. (2016); Tutunov et al. (2020), and variance reduced SCGD methods Lian et al. (2017); Blanchet et al. (2017); Lin et al. (2020); Devraj & Chen (2019); Hu et al. (2019). A SCO reformulation has also been used to solve nonconvex distributionally robust optimization (DRO) Rahimian & Mehrotra (2019); Qian et al. (2019) problems. The problem studied in this paper naturally falls into a new class of problems but with an additional inner loop compared to the existing single-level SCO problem, which we refer to as compositional bilevel optimization (CBO)."
        },
        {
            "heading": "B MORE EMPIRICAL SPECIFICATIONS",
            "text": "B.1 MORE DETAILS ABOUT TRAINING AND HYPERPARAMETERS SEARCH\nFollowing the standard practice in adversarial training Madry et al. (2017); Liu et al. (2021a); Zhang et al. (2020b), we train our baselines using stochastic gradient descent with a minibtach size of 128 and a momentum of 0.9. We use ResNet-18 as the backbone network as in Madry et al. (2017) and train our baselines for 60 epochs with a cyclic learning rate schedule where the maximum learning rate is set to 0.2 Zhang et al. (2020b); Liu et al. (2021c) (please see fig. 2). We consider \u2113\u221e-norm bounded adversarial perturbations with a maximum radius of \u03f5 = 8/255 both for training and testing.\nFor the KL-divergence regularization parameter r in our algorithms, we use a decayed schedule where we initially set it to 10 and decay it to 1 and 0.1, respectively at epochs 40 and 50 (see fig. 2). This setting allows our methods to start with an instance-weight distribution close to uniform at the beginning of training where the weights are less informative, and progressively emphasize more on learning a weight distribution that boosts worst-case adversarial robustness. All hyperparameters were fixed by holding out 10% of the training data as a validation set and selecting the values that achieve the best performance on the validation set. For the reported results, we train on the full training dataset and report the performance on the testing set Zhang et al. (2020b); Liu et al. (2021a).\nB.2 FURTHER DESCRIPTIONS ABOUT DATASETS\nWe consider image recognition problems and compare the performance of the baselines on four datasets: CIFAR10 Krizhevsky & Hinton (2009), SVHN Netzer et al. (2011), STL10 Coates et al. (2011), and GTSRB Stallkamp et al. (2012). For CIFAR10, SVHN, and STL10 we use the training and test splits provided by Torchvision. For GTSRB, we use the splits provided in Zhang et al. (2022). STL10 has 10 categories that are similar to those in CIFAR10 but with larger colour images (96\u00d7 96 resolution) and less samples (500 per class for training and 800 per class for testing). The German Traffic Sign Recognition Benchmark (GTSRB) contains 43 classes of traffic signs, split into 39,209\ntraining images and 12,630 test images. The images are 32 \u00d7 32 resolution colour. The dataset is highly class-imbalanced with some classes having over 2000 samples and others only 200 samples.\nB.3 FURTHER IMPLEMENTATION SPECIFICATIONS\nWe use the official publicly available codes of the respective baselines and their recommended training configurations. Pytorch codes for our method are provided in the supplementary material of our submission. Our implementation is built upon the codebase accompanying the paper Zhang et al. (2022). We thank the authors for making it publicly available. All codes are tested with Python 3.7 and Pytorch 1.8.\nFor example, to run our DONE-ADAM algorithm on the balanced CIFAR10 dataset, please run the following command:\npy thon main . py \u2212\u2212mode o u r s ++ \u2212\u2212 d a t a s e t CIFAR10 \u2212\u2212 i r 1 . \u2212\u2212 k l _ c o e f 10 \u2212\u2212 epochs 60 \u2212\u2212 c y c l i c _ m i l e s t o n e 25 \u2212\u2212 k l c _ m i l e s t o n e 1 40 \u2212\u2212 k l c _ m i l e s t o n e 2 50 \u2212\u2212 a t t a c k _ r s _ t e s t 1 \u2212\u2212 a t t a c k _ s t e p _ t e s t 20\nFor example the argument \u2018ir\u2019 can be used to control the imbalance ratio. The argument \u2018mode\u2019 can be set to \u2018ours\u2019 or \u2018ours++\u2019, and selects among different implementations of our same approach.\nBoth implementations perform similarly. Please check the file \u2018train.py\u2019 for more details about the arguments and the possible options.\nWe run all baselines on a single NVIDIA Tesla V100 GPU."
        },
        {
            "heading": "C DISTRIBUTIONS OF LEARNED WEIGHTS",
            "text": "Figure 5 shows the distributions of the learned weights per-class for CIFAR10, SVHN, and STL10 datasets. The distributions are obtained on the testing sets using 20 PGD steps. Further per-class insights are also provided in Figure 3 as confusion matrices (where per-class robust accuracies are depicted in the diagonals). Comparing the two figures, we note a negative correlation between the magnitude of weights and the per-class robust performance, i.e., classes on which the model achieve high robustness are usually associated with weights that are closer to 0. For example, the class automobile in CIFAR10 datset, in which the model achieves the highest adversarial robustness of 74.5% also has around 70% of its associated weights less than 0.001. As a comparison, the most vulnerable class (i.e., cat, in which the model achieves a robustness of 34.4%) has more than 90% of its associated weights larger than 0.001. We note a similar correlation of the weights distributions and the robust performance in STL10 dataset. Interestingly, the robust performance is more uniformly distributed across classes in the SVHN dataset (as depicted in the corresponding confusion matrix in Figure 3) and our method was able to automatically discover very close weights distributions across classes for this dataset. This further demonstrates the generality/robustness of our approach, which can perform well no matter if instance re-weighting is advantageous or less important.\nFigures 4 and 6 provides examples of images from CIFAR10 and STL10 datasets with low/high associated weights. Examples with low weights are usually \u2018easy\u2019 images in which the objects are well centered with clear/non-ambiguous backgrounds. Our algorithm was able to correctly classify the adversarial examples crafted from these images. In contrast, examples with high weights are generally \u2018hard\u2019 samples with only parts of the objects appearing or/and backgrounds that can lead to ambiguity. For example, the true label of the second image in the first row of Figure 6 is deer but the image also contains a car in its background, which may easily lead to confusion. Also note the first image in the third row of Figure 6, where only part of the tires of the car appears in the image."
        },
        {
            "heading": "D PROOF OF PROPOSITION 1",
            "text": "Recall the reformulated problem (7), which we rewrite as\nmin \u03b8\nL(\u03b8) := f\n( 1\nM M\u2211 i=1 gi(\u03b8, \u03b4\u0302 \u2217 i (\u03b8))\n)\ns.t. \u03b4\u0302\u2217i (\u03b8) = argmin \u03b4\u2208Ci \u2113bari (\u03b8, \u03b4) := \u2113 \u2032 i(\u03b8, \u03b4)\u2212 c 2p\u2211 k=1 log(bk \u2212 \u03b4\u22a4ak),\nwhere gi(\u03b8, \u03b4\u0302\u2217i (\u03b8)) = exp ( \u2113i(\u03b8,\u03b4\u0302 \u2217 i (\u03b8)) r ) , and f(z) = r log(z) for z \u2265 1.\nApplying the chain rule to the outer function, we have\n\u2207L(\u03b8) =\u2207f\n( 1\nM M\u2211 i=1 gi(\u03b8, \u03b4\u0302 \u2217 i (\u03b8))\n) 1\nM M\u2211 i=1 \u2202gi(\u03b8, \u03b4\u0302 \u2217 i (\u03b8)) \u2202\u03b8\n= r\u2211M\ni=1 gi(\u03b8, \u03b4\u0302 \u2217 i (\u03b8)) M\u2211 i=1 ( \u2207\u03b8gi(\u03b8, \u03b4\u0302\u2217i (\u03b8)) + \u2202\u03b4\u0302\u2217i (\u03b8) \u2202\u03b8 \u2207\u03b4gi(\u03b8, \u03b4\u0302\u2217i (\u03b8)) ) . (11)\nAlso, note that \u2207\u03b4\u2113bari (\u03b8, \u03b4) = \u2207\u03b4\u2113\u2032i(\u03b8, \u03b4) + c \u22112p k=1 ak bk\u2212\u03b4\u22a4ak . Using the implicit differentiation w.r.t. \u03b8 of equation \u2207\u03b4\u2113bari (\u03b8, \u03b4\u0302\u2217i (\u03b8)) = 0, i.e.,\n\u2207\u03b4\u2113\u2032i(\u03b8, \u03b4\u0302\u2217i (\u03b8))) + c 2p\u2211 k=1\nak\nbk \u2212 a\u22a4k \u03b4\u0302\u2217i (\u03b8)) = 0,\nwe obtain\n\u2207\u03b8\u03b4\u2113\u2032i(\u03b8, \u03b4\u0302\u2217i (\u03b8)) + \u2202\u03b4\u0302\u2217i (\u03b8)\n\u2202\u03b8 \u22072\u03b4\u2113\u2032i(\u03b8, \u03b4\u0302\u2217i (\u03b8)) + c\n\u2202\u03b4\u0302\u2217i (\u03b8)\n\u2202\u03b8 2p\u2211 k=1 aka \u22a4 k( bk \u2212 a\u22a4k \u03b4\u0302\u2217i (\u03b8)) )2 = 0.\nTherefore, we obtain\n\u2202\u03b4\u0302\u2217i (\u03b8)\n\u2202\u03b8\n[ \u22072\u03b4\u2113\u2032i(\u03b8, \u03b4\u0302\u2217i (\u03b8)) + c 2p\u2211 k=1 \u03b3kaka \u22a4 k ] = \u2212\u2207\u03b8\u03b4\u2113\u2032i(\u03b8, \u03b4\u0302\u2217i (\u03b8)). (12)\nwhere we define \u03b3k := 1(bk\u2212a\u22a4k \u03b4\u0302\u2217i (\u03b8))) 2 .\nFurther, note that A = ( Ip,\u2212Ip )\u22a4 . Thus the first p rows of A (i.e., ak, k = 1, ..., p) correspond to the p basis vectors of Rp, and hence aka\u22a4k = diag(ek), where ek is the k-th basis vector of Rp. Thus, considering the first p rows we obtain \u2211p k=1 \u03b3kaka \u22a4 k = diag(\u03b31, ..., \u03b3p). Similarly, the bottom p\nrows yields \u22112p\nk=p+1 \u03b3kaka \u22a4 k = diag(\u03b3p+1, ..., \u03b32p). Therefore, we have\nc 2p\u2211 k=1 \u03b3kaka \u22a4 k = cdiag(\u03b31 + \u03b3p+1, ..., \u03b3p + \u03b32p) := Ci(\u03b8). (13)\nSubstituting eq. (13) in eq. (12) yields\n\u2202\u03b4\u0302\u2217i (\u03b8)\n\u2202\u03b8\n[ \u22072\u03b4\u2113\u2032i(\u03b8, \u03b4\u0302\u2217i (\u03b8)) + Ci(\u03b8) ] = \u2212\u2207\u03b8\u03b4\u2113\u2032i(\u03b8, \u03b4\u0302\u2217i (\u03b8)).\nIf \u22072\u03b4\u2113\u2032i(\u03b8, \u03b4\u0302\u2217i (\u03b8)) + Ci(\u03b8) is invertable, the above equation further implies\n\u2202\u03b4\u0302\u2217i (\u03b8)\n\u2202\u03b8 = \u2212\u2207\u03b8\u03b4\u2113\u2032i(\u03b8, \u03b4\u0302\u2217i (\u03b8))\n[ \u22072\u03b4\u2113\u2032i(\u03b8, \u03b4\u0302\u2217i (\u03b8)) + Ci(\u03b8) ]\u22121 . (14)\nNow, combining eq. (14) and eq. (11) we obtain\n\u2207L(\u03b8) = r\u2211M i=1 gi(\u03b8, \u03b4\u0302 \u2217 i (\u03b8)) M\u2211 i=1 ( \u2207\u03b8gi(\u03b8, \u03b4\u0302\u2217i (\u03b8))\n\u2212\u2207\u03b8\u03b4\u2113\u2032i(\u03b8, \u03b4\u0302\u2217i (\u03b8)) [ \u22072\u03b4\u2113\u2032i(\u03b8, \u03b4\u0302\u2217i (\u03b8)) + Ci(\u03b8) ]\u22121 \u2207\u03b4gi(\u03b8, \u03b4\u0302\u2217i (\u03b8)) ) ,\nwhich completes the proof."
        },
        {
            "heading": "E CONVERGENCE ANALYSIS OF THE CID ALGORITHM",
            "text": "We provide the convergence analysis of the CID algorithm for solving the generic compositional bilevel optimization problem (8), which we rewrite as follows:\nmin \u03b8\nF (\u03b8) := f (g (\u03b8, \u03b4\u2217(\u03b8))) = f\n( 1\nM M\u2211 i=1 gi (\u03b8, \u03b4 \u2217 i (\u03b8))\n) (15)\ns.t. \u03b4\u2217(\u03b8) = (\u03b4\u22171(\u03b8), ..., \u03b4 \u2217 M (\u03b8)) = argmin\n(\u03b41,...,\u03b4M )\u2208V1\u00d7...\u00d7VM\n1\nM M\u2211 i=1 hi (\u03b8, \u03b4i) .\nChallenge and Novelty. We note that although bilevel optimization and compositional optimization have been well studied in the optimization literature, to our best knowledge, there have not been any theoretical analysis of compositional bilevel optimization. The special challenge arising in such a problem is due to the fact that the bias error caused by the stochastic estimation of the compositional function in the outer-loop is further complicated by the approximation error from the inner loop. Our main novel development here lies in tracking such an error in the convergence analysis.\nTo proceed the analysis, we let w = (\u03b8, \u03b4) denote all optimization parameters. We denote by \u2225\u2225 \u00b7 \u2225\u2225 the \u21132 norm for vectors and the spectral norm for matrices.\nWe adopt the following assumptions for our analysis, which are widely used in bilevel and compositional optimization literature (Grazzi et al., 2020a; Ji et al., 2021; Ji & Liang, 2021; Wang et al., 2017; Chen et al., 2021b). Assumption 1. The objective functions f , gi, and hi for any i = 1, . . . ,M satisfy\n\u2022 f is Cf -Lipschitz continuous and Lf -smooth, i.e., for any z and z\u2032,\u2223\u2223f(z)\u2212 f(z\u2032)\u2223\u2223 \u2264 Cf\u2225\u2225z \u2212 z\u2032\u2225\u2225, \u2225\u2225\u2207f(z)\u2212\u2207f(z\u2032)\u2225\u2225 \u2264 Lf\u2225\u2225z \u2212 z\u2032\u2225\u2225. (16) \u2022 gi is Cg-Lipschitz continuous and Lg-smooth, i.e., for any w and w\u2032,\u2225\u2225gi(w)\u2212 gi(w\u2032)\u2225\u2225 \u2264 Cg\u2225\u2225w \u2212 w\u2032\u2225\u2225, \u2225\u2225\u2207gi(w)\u2212\u2207gi(w\u2032)\u2225\u2225 \u2264 Lg\u2225\u2225w \u2212 w\u2032\u2225\u2225. (17) \u2022 hi is Lh-smooth, i.e., for any w and w\u2032,\u2225\u2225\u2207hi(w)\u2212\u2207hi(w\u2032)\u2225\u2225 \u2264 Lh\u2225\u2225w \u2212 w\u2032\u2225\u2225. (18)\nAssumption 2. The function hi(\u03b8, \u03b4) for any i = 1, . . . ,M is \u00b5-strongly convex w.r.t. \u03b4 and its second-order derivatives \u2207\u03b8\u2207\u03b4hi(w) and \u22072\u03b4hi(w) are L\u03b8\u03b4- and L\u03b4\u03b4-Lipschitz, i.e., for any w and w\u2032,\u2225\u2225\u2207\u03b8\u2207\u03b4hi(w)\u2212\u2207\u03b8\u2207\u03b4hi(w)\u2225\u2225 \u2264 L\u03b8\u03b4\u2225\u2225w \u2212 w\u2032\u2225\u2225, \u2225\u2225\u22072\u03b4hi(w)\u2212\u22072\u03b4hi(w\u2032)\u2225\u2225 \u2264 L\u03b4\u03b4\u2225\u2225w \u2212 w\u2032\u2225\u2225.\n(19)\nAssumption 3. The stochastic sample gi for any i = 1, . . . ,M has bounded variance, i.e.,\nEi \u2225\u2225gi(\u03b8, \u03b4i)\u2212 1\nM M\u2211 j=1 gj(\u03b8, \u03b4j) \u2225\u22252 \u2264 \u03c32g . (20)\nThe following theorem (as restatement of Theorem 1) characterizes the convergence rate of our designed CID algorithm. Theorem 2 (Re-statement of Theorem 1). Suppose that Assumptions 1, 2, 3 hold. Select the stepsizes as \u03b2t = 1\u221aT and \u03b7t \u2208 [ 1 2 , 1), and batchsize as |B| = O(T ). Then, the iterates \u03b8t, t = 0, ..., T \u2212 1 of the CID algorithm satisfy\u2211T\u22121 t=0 E\n\u2225\u2225\u2207F (\u03b8t)\u2225\u22252 T \u2264 O ( 1\u221a T + (1\u2212 \u03b1\u00b5)K ) In the following two subsections, we first establish a number of useful supporting lemmas and then provide the proof of Theorem 2 (which is a restatement of Theorem 1).\nE.1 SUPPORTING LEMMAS\nFor notational convenience, we let L = max{Lf , Lg, Lh}, C = max{Cf , Cg}, and \u03c4 = max{L\u03b8\u03b4, L\u03b4\u03b4}. Lemma 1. Suppose that Assumptions 1 and 2 hold. Then, the total objective F (\u03b8) (defined at the outer level of problem (15) is LF -smooth, i.e., for any \u03b8, \u03b8\u2032,\u2225\u2225\u2207F (\u03b8)\u2212\u2207F (\u03b8\u2032)\u2225\u2225 \u2264 LF\u2225\u2225\u03b8 \u2212 \u03b8\u2032\u2225\u2225, (21) where LF = C2L ( 1 + L\u00b5 )2 + CLG.\nProof. Applying the chain rule, we have\n\u2207F (\u03b8) = \u2202g (\u03b8, \u03b4 \u2217(\u03b8))\n\u2202\u03b8 \u2207f (g (\u03b8, \u03b4\u2217(\u03b8))) . (22)\nTherefore, using triangle inequality, we obtain\u2225\u2225\u2207F (\u03b8)\u2212\u2207F (\u03b8\u2032)\u2225\u2225 =\u2225\u2225\u2202g (\u03b8, \u03b4\u2217(\u03b8)) \u2202\u03b8 \u2207f (g (\u03b8, \u03b4\u2217(\u03b8)))\u2212 \u2202g (\u03b8 \u2032, \u03b4\u2217(\u03b8\u2032)) \u2202\u03b8 \u2207f (g (\u03b8\u2032, \u03b4\u2217(\u03b8\u2032))) \u2225\u2225 \u2264 \u2225\u2225\u2202g (\u03b8, \u03b4\u2217(\u03b8))\n\u2202\u03b8 (\u2207f (g (\u03b8, \u03b4\u2217(\u03b8)))\u2212\u2207f (g (\u03b8\u2032, \u03b4\u2217(\u03b8\u2032)))) \u2225\u2225 + \u2225\u2225(\u2202g (\u03b8, \u03b4\u2217(\u03b8))\n\u2202\u03b8 \u2212 \u2202g (\u03b8\n\u2032, \u03b4\u2217(\u03b8\u2032))\n\u2202\u03b8\n) \u2207f (g (\u03b8\u2032, \u03b4\u2217(\u03b8\u2032))) \u2225\u2225\n\u2264 \u2225\u2225\u2202g (\u03b8, \u03b4\u2217(\u03b8))\n\u2202\u03b8 \u2225\u2225\u2225\u2225\u2207f (g (\u03b8, \u03b4\u2217(\u03b8)))\u2212\u2207f (g (\u03b8\u2032, \u03b4\u2217(\u03b8\u2032)))\u2225\u2225 + \u2225\u2225\u2202g (\u03b8, \u03b4\u2217(\u03b8))\n\u2202\u03b8 \u2212 \u2202g (\u03b8\n\u2032, \u03b4\u2217(\u03b8\u2032))\n\u2202\u03b8 \u2225\u2225\u2225\u2225\u2207f (g (\u03b8\u2032, \u03b4\u2217(\u03b8\u2032)))\u2225\u2225 \u2264Lf \u2225\u2225\u2202g (\u03b8, \u03b4\u2217(\u03b8)) \u2202\u03b8\n\u2225\u2225\u2225\u2225g (\u03b8, \u03b4\u2217(\u03b8))\u2212 g (\u03b8\u2032, \u03b4\u2217(\u03b8\u2032))\u2225\u2225 + Cf \u2225\u2225\u2202g (\u03b8, \u03b4\u2217(\u03b8)) \u2202\u03b8 \u2212 \u2202g (\u03b8 \u2032, \u03b4\u2217(\u03b8\u2032)) \u2202\u03b8\n\u2225\u2225. (23) The chain rule yields\n\u2202gi (\u03b8, \u03b4 \u2217 i (\u03b8))\n\u2202\u03b8 =\u2207\u03b8gi (\u03b8, \u03b4\u2217i (\u03b8)) +\n\u2202\u03b4\u2217i (\u03b8)\n\u2202\u03b8 \u2207\u03b4gi (\u03b8, \u03b4\u2217i (\u03b8))\n=\u2207\u03b8gi (\u03b8, \u03b4\u2217i (\u03b8))\u2212\u2207\u03b8\u2207\u03b4hi (\u03b8, \u03b4\u2217i (\u03b8)) [ \u22072\u03b4hi (\u03b8, \u03b4\u2217i (\u03b8)) ]\u22121 \u2207\u03b4gi (\u03b8, \u03b4\u2217i (\u03b8)) , where the last equality follows from the implicit differentiation result for bilevel optimization Pedregosa (2016); Ji et al. (2021).\nThus, we obtain\u2225\u2225\u2202gi (\u03b8, \u03b4\u2217i (\u03b8)) \u2202\u03b8 \u2225\u2225 \u2264 \u2225\u2225\u2207\u03b8gi (\u03b8, \u03b4\u2217i (\u03b8)) \u2225\u2225+ \u2225\u2225\u2207\u03b8\u2207\u03b4hi (\u03b8, \u03b4\u2217i (\u03b8)) [\u22072\u03b4hi (\u03b8, \u03b4\u2217i (\u03b8))]\u22121 \u2207\u03b4gi (\u03b8, \u03b4\u2217i (\u03b8))\u2225\u2225\n\u2264 Cg + L\n\u00b5 Cg. (24)\nTherfore, g (\u03b8, \u03b4\u2217(\u03b8)) = 1M \u2211M i=1 gi (\u03b8, \u03b4 \u2217 i (\u03b8))) is Lipschitz with constant CG = Cg ( 1 + L\u00b5 ) . Further, following from Lemma 2 in Ji et al. (2021) we obtain that \u2202g(\u03b8,\u03b4 \u2217(\u03b8))\n\u2202\u03b8 is Lipschitz with the constant LG. Thus, combining with eq. (23), we obtain\u2225\u2225\u2207F (\u03b8)\u2212\u2207F (\u03b8\u2032)\u2225\u2225 \u2264LfC2G\u2225\u2225\u03b8 \u2212 \u03b8\u2032\u2225\u2225+ CfLG\u2225\u2225\u03b8 \u2212 \u03b8\u2032\u2225\u2225 (25) Rearranging the above equation completes the proof.\nLemma 2. Suppose that Assumptions 1 and 3 hold. Then, we have\nEB \u2225\u2225ut+1\u2212g(\u03b8t, \u03b4Kt )\u2225\u22252 \u2264 (1\u2212\u03b7t)\u2225\u2225ut\u2212g(\u03b8t\u22121, \u03b4Kt\u22121)\u2225\u22252+2\u03b72t|B| \u03c32g+C2\u03b7t (1+\u03ba2)\u2225\u2225\u03b8t\u2212\u03b8t\u22121\u2225\u22252. (26)\nProof. We first show that \u2202\u03b4Ki,t \u2202\u03b8 is \u03ba-Lipschitz. To explicitly write the dependency of \u03b4 k i,t on \u03b8t, we define \u03b4ki (\u03b8t) := \u03b4 k i,t. Then we have\u2225\u2225\u03b4Ki (\u03b8)\u2212 \u03b4Ki (\u03b8\u2032)\u2225\u2225\n= \u2225\u2225\u03a0X (\u03b4K\u22121i (\u03b8)\u2212 \u03b1\u2207\u03b4hi (\u03b8, \u03b4K\u22121i (\u03b8)))\u2212\u03a0X (\u03b4K\u22121i (\u03b8\u2032)\u2212 \u03b1\u2207\u03b4hi (\u03b8\u2032, \u03b4K\u22121i (\u03b8\u2032))) \u2225\u2225\n\u2264 \u2225\u2225\u03b4K\u22121i (\u03b8)\u2212 \u03b1\u2207\u03b4hi (\u03b8, \u03b4K\u22121i (\u03b8))\u2212 \u03b4K\u22121i (\u03b8\u2032) + \u03b1\u2207\u03b4hi (\u03b8\u2032, \u03b4K\u22121i (\u03b8\u2032)) \u2225\u2225\n\u2264 \u2225\u2225\u03b4K\u22121i (\u03b8)\u2212 \u03b4K\u22121i (\u03b8\u2032) + \u03b1 (\u2207\u03b4hi (\u03b8\u2032, \u03b4K\u22121i (\u03b8\u2032))\u2212\u2207\u03b4hi (\u03b8\u2032, \u03b4K\u22121i (\u03b8))) \u2225\u2225\ufe38 \ufe37\ufe37 \ufe38\nT1 + \u03b1 \u2225\u2225\u2207\u03b4hi (\u03b8\u2032, \u03b4K\u22121i (\u03b8))\u2212\u2207\u03b4hi (\u03b8, \u03b4K\u22121i (\u03b8)) \u2225\u2225\n\u2264 ( L\u2212 \u00b5 L+ \u00b5 )\u2225\u2225\u03b4K\u22121i (\u03b8)\u2212 \u03b4K\u22121i (\u03b8\u2032)\u2225\u2225+ \u03b1L\u2225\u2225\u03b8 \u2212 \u03b8\u2032\u2225\u2225, where we upper-bound the term T1 using the fact that the operator y \u2192 y \u2212 \u03b1\u2207h(y) is a contraction mapping with the constant L\u2212\u00b5L+\u00b5 for an L-smooth and \u00b5-stongly convex function h when the stepsize \u03b1 is set to 2L+\u00b5 . Hence, telescoping the previous inequality over k from K \u2212 1 down to 0 yields\u2225\u2225\u03b4Ki (\u03b8)\u2212 \u03b4Ki (\u03b8\u2032)\u2225\u2225 \u2264(L\u2212 \u00b5L+ \u00b5 )K \u2225\u2225\u03b40i (\u03b8)\u2212 \u03b40i (\u03b8\u2032)\u2225\u2225+ \u03b1L\u2225\u2225\u03b8 \u2212 \u03b8\u2032\u2225\u2225K\u22121\u2211 k=0 ( L\u2212 \u00b5 L+ \u00b5 )k\n\u22640 + \u03b1L 1\u2212 L\u2212\u00b5L+\u00b5 \u2225\u2225\u03b8 \u2212 \u03b8\u2032\u2225\u2225 = \u03ba\u2225\u2225\u03b8 \u2212 \u03b8\u2032\u2225\u2225, (27) where the second inequality follows because \u03b40i (\u03b8) = \u03b4 0 i (\u03b8\n\u2032) as the same initial point, and the last equality follows by setting the stepsize \u03b1 to 2L+\u00b5 .\nDenote dt = (1 \u2212 \u03b7t) ( g(\u03b8t, \u03b4 K t )\u2212 g(\u03b8t\u22121, \u03b4Kt\u22121) ) = 1\u2212\u03b7tM \u2211M i=1 ( gi(\u03b8t, \u03b4 K i,t)\u2212 gi(\u03b8t\u22121, \u03b4Ki,t\u22121) ) . We can then obtain\u2225\u2225dt\u2225\u22252 \u2264 (1\u2212 \u03b7t)2 M M\u2211 i=1\n\u2225\u2225gi(\u03b8t, \u03b4Ki,t)\u2212 gi(\u03b8t\u22121, \u03b4Ki,t\u22121)\u2225\u22252 \u2264 (1\u2212 \u03b7t) 2\nM\nM\u2211 i=1 C2 (\u2225\u2225\u03b8t \u2212 \u03b8t\u22121\u2225\u22252 + \u2225\u2225\u03b4Ki,t \u2212 \u03b4Ki,t\u22121\u2225\u22252)\n\u2264 (1\u2212 \u03b7t) 2\nM\nM\u2211 i=1 C2(1 + \u03ba2) \u2225\u2225\u03b8t \u2212 \u03b8t\u22121\u2225\u22252\n=(1\u2212 \u03b7t)2(1 + \u03ba2)C2 \u2225\u2225\u03b8t \u2212 \u03b8t\u22121\u2225\u22252. (28)\nRecall ut+1 = (1\u2212 \u03b7t)ut + \u03b7tg(\u03b8t, \u03b4Kt ;B). Thus combining with the definition of dt, we have EB \u2225\u2225ut+1 \u2212 g(\u03b8t, \u03b4Kt ) + dt\u2225\u22252 =EB\n\u2225\u2225(1\u2212 \u03b7t) (ut \u2212 g(\u03b8t\u22121, \u03b4Kt\u22121))+ \u03b7t (g(\u03b8t, \u03b4Kt ;B)\u2212 g(\u03b8t, \u03b4Kt )) \u2225\u22252 =(1\u2212 \u03b7t)2\n\u2225\u2225ut \u2212 g(\u03b8t\u22121, \u03b4Kt\u22121)\u2225\u22252 + \u03b72tEB\u2225\u2225g(\u03b8t, \u03b4Kt ;B)\u2212 g(\u03b8t, \u03b4Kt )\u2225\u22252 + 2(1\u2212 \u03b7t)\u03b7t \u2329 ut \u2212 g(\u03b8t\u22121, \u03b4Kt\u22121),EB ( g(\u03b8t, \u03b4 K t ;B)\u2212 g(\u03b8t, \u03b4Kt )\n)\u232a =(1\u2212 \u03b7t)2\n\u2225\u2225ut \u2212 g(\u03b8t\u22121, \u03b4Kt\u22121)\u2225\u22252 + \u03b72t|B|Ei\u2225\u2225gi(\u03b8t, \u03b4Ki,t)\u2212 g(\u03b8t, \u03b4Kt )\u2225\u22252 \u2264(1\u2212 \u03b7t)2\n\u2225\u2225ut \u2212 g(\u03b8t\u22121, \u03b4Kt\u22121)\u2225\u22252 + \u03b72t|B|\u03c32g . (29) Based on the inequality\n\u2225\u2225a + b\u2225\u22252 \u2264 (1 + c)\u2225\u2225a\u2225\u22252 + (1 + 1c )\u2225\u2225b\u2225\u22252 for any c > 0, by letting c = \u03b7t, we have\nEB \u2225\u2225ut+1 \u2212 g(\u03b8t, \u03b4Kt )\u2225\u22252 \u2264(1 + \u03b7t)EB\u2225\u2225ut+1 \u2212 g(\u03b8t, \u03b4Kt ) + dt\u2225\u22252 + (1 + 1\u03b7t )EB\u2225\u2225dt\u2225\u22252\n\u2264(1 + \u03b7t)(1\u2212 \u03b7t)2 \u2225\u2225ut \u2212 g(\u03b8t\u22121, \u03b4Kt\u22121)\u2225\u22252 + (1 + \u03b7t)\u03b72t|B| \u03c32g\n+ 1 + \u03b7t \u03b7t\n(1\u2212 \u03b7t)2(1 + \u03ba2)C2 \u2225\u2225\u03b8t \u2212 \u03b8t\u22121\u2225\u22252\n\u2264(1\u2212 \u03b7t) \u2225\u2225ut \u2212 g(\u03b8t\u22121, \u03b4Kt\u22121)\u2225\u22252 + 2\u03b72t|B| \u03c32g + C2\u03b7t (1 + \u03ba2)\u2225\u2225\u03b8t \u2212 \u03b8t\u22121\u2225\u22252.\n(30)\nHence, the proof is complete.\nLemma 3. Suppose that Assumptions 1 and 2 hold. Then we have\u2225\u2225\u2225\u2202g (\u03b8t, \u03b4\u2217(\u03b8t)) \u2202\u03b8 \u2212 \u2207\u0302g(\u03b8t, \u03b4Kt ) \u2225\u2225\u22252 \u2264 \u2126(1\u2212 \u03b1\u00b5)K\u22060, (31)\nwhere \u22060 = maxi,t \u2225\u2225\u03b4\u2217i (\u03b8t)\u2212 \u03b40\u2225\u22252 and \u2126 = O(L+ \u03c42C2\u00b52 + L(\u03ba+ \u03c4C\u00b52 )2 ).\nProof. The proof follows the steps similar to those in the proof of Lemma 3 in Ji et al. (2021).\nIn the following, we define \u039b = \u2126(1\u2212 \u03b1\u00b5)K\u22060.\nLemma 4. Suppose that Assumptions 1, 2, 3 hold. Then, we have EBF (\u03b8t+1)\u2212 F (\u03b8t) \u2264\u2212 \u03b2t\u03b1t \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2t\u0393\u22060(1\u2212 \u03b1\u00b5)K\n+ \u03b7tEB \u2225\u2225g(\u03b8t, \u03b4Kt )\u2212 ut+1\u2225\u22252 + LF\u03b22t2 C4 ( 1 + L \u00b5 )2 , (32)\nwhere \u03b1t = 12 \u2212 \u03b2tL\n2 \u03b7t C2 ( 1 + L\u00b5 )2 .\nProof. Based on the Lipschitzness of \u2207F (\u03b8) in Lemma 1, we have\nF (\u03b8t+1)\u2212 F (\u03b8t) \u2264\u27e8\u2207F (\u03b8t), \u03b8t+1 \u2212 \u03b8t\u27e9+ LF 2 \u2225\u2225\u03b8t+1 \u2212 \u03b8t\u2225\u22252 \u2264\u2212 \u03b2t\n\u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2t \u2329\u2207F (\u03b8t),\u2207F (\u03b8t)\u2212 \u2207\u0302g(\u03b8t, \u03b4Kt ;B)\u2207f(ut+1)\u232a + LF\u03b2 2 t\n2 \u2225\u2225\u2207\u0302g(\u03b8t, \u03b4Kt ;B)\u2207f(ut+1)\u2225\u22252 \u2264\u2212 \u03b2t\n\u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2t \u2329\u2207F (\u03b8t),\u2207F (\u03b8t)\u2212 \u2207\u0302g(\u03b8t, \u03b4Kt )\u2207f (g(\u03b8t, \u03b4Kt ))\u232a\ufe38 \ufe37\ufe37 \ufe38 A1\n+ \u03b2t \u2329 \u2207F (\u03b8t), \u2207\u0302g(\u03b8t, \u03b4Kt )\u2207f ( g(\u03b8t, \u03b4 K t ) ) \u2212 \u2207\u0302g(\u03b8t, \u03b4Kt ;B)\u2207f(ut+1) \u232a \ufe38 \ufe37\ufe37 \ufe38\nA2\n+ LF\u03b2\n2 t\n2 \u2225\u2225\u2207\u0302g(\u03b8t, \u03b4Kt ;B)\u2207f(ut+1)\u2225\u22252. (33) Next, we upper-bound the inner product terms A1 and A2, respectively. Using Young\u2019s inequality, we obtain\nA1 \u2264 \u03b2t 2 \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2t 2 \u2225\u2225\u2207F (\u03b8t)\u2212 \u2207\u0302g(\u03b8t, \u03b4Kt )\u2207f (g(\u03b8t, \u03b4Kt )) \u2225\u22252 \u2264\u03b2t\n2 \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2t\u2225\u2225\u2202g (\u03b8t, \u03b4\u2217(\u03b8t)) \u2202\u03b8 \u2225\u22252\u2225\u2225\u2207f (g (\u03b8t, \u03b4\u2217(\u03b8t)))\u2212\u2207f (g(\u03b8t, \u03b4Kt )) \u2225\u22252 + \u03b2t\n\u2225\u2225\u2207f (g(\u03b8t, \u03b4Kt )) \u2225\u22252\u2225\u2225\u2202g (\u03b8t, \u03b4\u2217(\u03b8t))\u2202\u03b8 \u2212 \u2207\u0302g(\u03b8t, \u03b4Kt )\u2225\u22252 \u2264\u03b2t\n2 \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2tL2GL2\u2225\u2225g (\u03b8t, \u03b4\u2217(\u03b8t))\u2212 g(\u03b8t, \u03b4Kt )\u2225\u22252 + \u03b2tC 2 \u2225\u2225\u2202g (\u03b8t, \u03b4\u2217(\u03b8t))\n\u2202\u03b8 \u2212 \u2207\u0302g(\u03b8t, \u03b4Kt ) \u2225\u22252 \u2264\u03b2t\n2 \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2tL2GL2 M M\u2211 i=1 \u2225\u2225gi (\u03b8t, \u03b4\u2217i (\u03b8t))\u2212 gi(\u03b8t, \u03b4Ki,t)\u2225\u22252 + \u03b2tC2\u039b \u2264\u03b2t\n2 \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2tL2GL2C2 M M\u2211 i=1 \u2225\u2225\u03b4\u2217i (\u03b8t)\u2212 \u03b4Ki,t\u2225\u22252 + \u03b2tC2\u039b \u2264\u03b2t\n2 \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2tL2GL2C2 (1\u2212 \u03b1\u00b5)KM M\u2211 i=1 \u2225\u2225\u03b4\u2217i (\u03b8t)\u2212 \u03b40\u2225\u22252 + \u03b2tC2\u039b \u2264\u03b2t\n2 \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2tL2GL2C2\u22060(1\u2212 \u03b1\u00b5)K + \u03b2tC2\u2126(1\u2212 \u03b1\u00b5)K\u22060 = \u03b2t 2\n\u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2t\u0393\u22060(1\u2212 \u03b1\u00b5)K , (34) where \u0393 = L2GL 2C2 + C2\u2126, \u22060 = maxi,t \u2225\u2225\u03b4\u2217i (\u03b8t)\u2212 \u03b40\u2225\u22252, and \u039b = \u2126(1\u2212 \u03b1\u00b5)K\u22060.\nFurther, we have EBA2 =\u03b2tEB \u2329 \u2207F (\u03b8t), \u2207\u0302g(\u03b8t, \u03b4Kt ;B)\u2207f ( g(\u03b8t, \u03b4 K t ) ) \u2212 \u2207\u0302g(\u03b8t, \u03b4Kt ;B)\u2207f(ut+1) \u232a\n\u2264\u03b2t \u2225\u2225\u2207F (\u03b8t)\u2225\u2225EB [\u2225\u2225\u2207\u0302g(\u03b8t, \u03b4Kt ;B)\u2225\u2225\u2225\u2225\u2207f (g(\u03b8t, \u03b4Kt ))\u2212\u2207f(ut+1)\u2225\u2225]\n\u2264\u03b2tL \u2225\u2225\u2207F (\u03b8t)\u2225\u2225EB [\u2225\u2225\u2207\u0302g(\u03b8t, \u03b4Kt ;B)\u2225\u2225\u2225\u2225g(\u03b8t, \u03b4Kt )\u2212 ut+1\u2225\u2225]\n\u2264\u03b7tEB \u2225\u2225g(\u03b8t, \u03b4Kt )\u2212 ut+1\u2225\u22252 + \u03b22tL2\u03b7t \u2225\u2225\u2207F (\u03b8t)\u2225\u22252EB\u2225\u2225\u2207\u0302g(\u03b8t, \u03b4Kt ;B)\u2225\u22252\n\u2264\u03b7tEB \u2225\u2225g(\u03b8t, \u03b4Kt )\u2212 ut+1\u2225\u22252 + \u03b22tL2\u03b7t C2(1 + L\u00b5 )2\u2225\u2225\u2207F (\u03b8t)\u2225\u22252, (35)\nwhere the last inequality uses the upper-bound \u2225\u2225\u2207\u0302gi(\u03b8t, \u03b4Ki,t)\u2225\u2225 \u2264 C + L\u00b5C, which can be obtained similarly to eq. (24).\nTherefore, taking the conditional expectation EB in both sides of eq. (33), applying the bounds for A1 and EBA2 in eqs. (34) and (35), and noting that EB \u2225\u2225\u2207\u0302g(\u03b8t, \u03b4Kt ;B)\u2207f(ut+1)\u2225\u22252 \u2264 C2EB\n\u2225\u2225\u2207\u0302g(\u03b8t, \u03b4Kt ;B)\u2225\u22252 \u2264 C4 (1 + L\u00b5)2, we obtain EBF (\u03b8t+1)\u2212 F (\u03b8t) \u2264\u2212\n\u03b2t 2 \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2t\u0393\u22060(1\u2212 \u03b1\u00b5)K + \u03b7tEB\u2225\u2225g(\u03b8t, \u03b4Kt )\u2212 ut+1\u2225\u22252 + \u03b22tL 2\n\u03b7t C2 ( 1 + L \u00b5 )2 \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + LF\u03b22t 2 C4 ( 1 + L \u00b5 )2 \u2264\u2212 \u03b2t ( 1\n2 \u2212 \u03b2tL\n2 \u03b7t C2 ( 1 + L \u00b5 )2)\u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2t\u0393\u22060(1\u2212 \u03b1\u00b5)K + \u03b7tEB \u2225\u2225g(\u03b8t, \u03b4Kt )\u2212 ut+1\u2225\u22252 + LF\u03b22t2 C4 ( 1 + L \u00b5 )2 .\nThen, the proof is complete.\nE.2 PROOF OF THEOREM 2 (I.E., THEOREM 1)\nDenote Vt = F (\u03b8t) + \u2225\u2225g(\u03b8t\u22121, \u03b4Kt\u22121)\u2212 ut\u2225\u22252. Then, using eq. (32) we obtain\nEBVt+1 \u2212 Vt \u2264\u2212 \u03b2t\u03b1t \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2t\u0393\u22060(1\u2212 \u03b1\u00b5)K \u2212 \u2225\u2225g(\u03b8t\u22121, \u03b4Kt\u22121)\u2212 ut\u2225\u22252\n+ (1 + \u03b7t)EB \u2225\u2225g(\u03b8t, \u03b4Kt )\u2212 ut+1\u2225\u22252 + 12LF\u03b22tC4 ( 1 + L \u00b5 )2 \u2264\u2212 \u03b2t\u03b1t\n\u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2t\u0393\u22060(1\u2212 \u03b1\u00b5)K \u2212 \u2225\u2225g(\u03b8t\u22121, \u03b4Kt\u22121)\u2212 ut\u2225\u22252 + (1 + \u03b7t)(1\u2212 \u03b7t)\n\u2225\u2225g(\u03b8t\u22121, \u03b4Kt\u22121)\u2212 ut\u2225\u22252 + 2(1 + \u03b7t)|B| \u03b72t \u03c32g + C2\n\u03b7t (1 + \u03b7t)(1 + \u03ba\n2)\u03b22tC 4\n( 1 + L\n\u00b5\n)2 + 1\n2 LF\u03b2\n2 tC 4\n( 1 + L\n\u00b5\n)2 , (36)\nwhere the last inequality follows from lemma 2. Further, following from the fact that (1\u2212\u03b7t)(1+\u03b7t) = 1\u2212 \u03b72t < 1, we obtain\nEBVt+1 \u2212 Vt \u2264\u2212 \u03b2t\u03b1t \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2t\u0393\u22060(1\u2212 \u03b1\u00b5)K + 2(1 + \u03b7t)|B| \u03b72t \u03c32g\n+ 1 + \u03b7t \u03b7t \u03b22tC 6(1 + \u03ba2)\n( 1 + L\n\u00b5\n)2 + 1\n2 LF\u03b2\n2 tC 4\n( 1 + L\n\u00b5\n)2 . (37)\nNow, select \u03b7t \u2208 [ 12 , 1) and \u03b2t such that \u03b1t \u2265 1 4 , i.e., \u03b2t \u2264\n1\n2L2FC 2(1+L\u00b5 )\n2 . Hence, taking total\nexpectation of eq. (37) yields\nEVt+1 \u2212 EVt \u2264\u2212 \u03b2t 4 E \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2t\u0393\u22060(1\u2212 \u03b1\u00b5)K + 4\u03c32g|B|\n+ 4\u03b22tC 6(1 + \u03ba2)\n( 1 + L\n\u00b5\n)2 + 1\n2 LF\u03b2\n2 tC 4\n( 1 + L\n\u00b5 )2 =\u2212 \u03b2t\n4 \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + \u03b2t\u0393\u22060(1\u2212 \u03b1\u00b5)K + 4\u03c32g|B| + \u03b22tD\u03ba, (38) where we define D\u03ba = ( 4C2(1 + \u03ba2) + 12LF ) (1 + \u03ba) 2 C4. Therefore, telescoping eq. (38) over t from 0 to T \u2212 1 yields\nEVT \u2212 V0 \u2264\u2212 T\u22121\u2211 t=0 \u03b2t 4 E \u2225\u2225\u2207F (\u03b8t)\u2225\u22252 + 4\u03c32gT|B| + \u0393\u22060(1\u2212 \u03b1\u00b5)K T\u22121\u2211 t=0 \u03b2t +D\u03ba T\u22121\u2211 t=0 \u03b22t .\nThus, rearranging terms, we obtain\u2211T\u22121 t=0 \u03b2tE \u2225\u2225\u2207F (\u03b8t)\u2225\u22252\u2211T\u22121 t=0 \u03b2t \u2264 16\u03c32gT |B| \u2211T\u22121 t=0 \u03b2t + 4\u0393\u22060(1\u2212 \u03b1\u00b5)K + 4D\u03ba \u2211T\u22121 t=0 \u03b2 2 t\u2211T\u22121 t=0 \u03b2t + 4V0\u2211T\u22121 t=0 \u03b2t . (39)\nHence, the proof is complete by choosing the batchsize |B| = O(T ) and stepsize \u03b2t = 1\u221aT ."
        }
    ],
    "title": "DOUBLY ROBUST INSTANCE-REWEIGHTED ADVERSARIAL TRAINING",
    "year": 2023
}