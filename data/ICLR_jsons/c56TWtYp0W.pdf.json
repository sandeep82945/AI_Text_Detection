{
    "abstractText": "Analyzing multivariate time series is important in many domains. However, it has been difficult to learn robust and generalizable representations within multivariate datasets due to complex inter-channel relationships and dynamic shifts. In this paper, we introduce a novel approach for learning spatiotemporal structure and using it to improve the application of transformers to timeseries datasets. Our framework learns a set of group tokens, and builds an instance-specific group embedding (GE) layer that assigns input tokens to a small number of group tokens to incorporate structure into learning. We then introduce a novel architecture, GroupAware transFormer (GAFormer), which incorporates both spatial and temporal group embeddings to achieve state-of-the-art performance on a number of timeseries classification and regression tasks. In evaluations on a number of diverse timeseries datasets, we show that GE on its own can provide a nice enhancement to a number of backbones, and that by coupling spatial and temporal group embeddings, the GAFormer can outperform the existing baselines. Finally, we show how our approach discerns latent structures in data even without information about the spatial ordering of channels, and yields a more interpretable decomposition of spatial and temporal structure underlying complex multivariate datasets.",
    "authors": [],
    "id": "SP:970150be32c609035f92a038029b45ecf9d3d674",
    "references": [
        {
            "authors": [
                "Anthony Bagnall",
                "Hoang Anh Dau",
                "Jason Lines",
                "Michael Flynn",
                "James Large",
                "Aaron Bostrom",
                "Paul Southam",
                "Eamonn Keogh"
            ],
            "title": "The uea multivariate time series classification archive, 2018",
            "venue": "arXiv preprint arXiv:1811.00075,",
            "year": 2018
        },
        {
            "authors": [
                "N Birbaumer",
                "H Flor",
                "N Ghanayim",
                "T Hinterberger",
                "I Iverson",
                "E Taub",
                "B Kotchoubey",
                "A Kbler"
            ],
            "title": "Perelmouter. A brain-controlled spelling device for the completely paralyzed",
            "year": 2001
        },
        {
            "authors": [
                "Zhengping Che",
                "Sanjay Purushotham",
                "Kyunghyun Cho",
                "David Sontag",
                "Yan Liu"
            ],
            "title": "Recurrent neural networks for multivariate time series with missing values",
            "venue": "Scientific reports,",
            "year": 2018
        },
        {
            "authors": [
                "Xiangxiang Chu",
                "Zhi Tian",
                "Bo Zhang",
                "Xinlong Wang",
                "Xiaolin Wei",
                "Huaxia Xia",
                "Chunhua Shen"
            ],
            "title": "Conditional positional encodings for vision transformers",
            "venue": "arXiv preprint arXiv:2102.10882,",
            "year": 2021
        },
        {
            "authors": [
                "Rahul Dey",
                "Fathi M Salem"
            ],
            "title": "Gate-variants of gated recurrent unit (gru) neural networks",
            "venue": "IEEE 60th international midwest symposium on circuits and systems (MWSCAS),",
            "year": 2017
        },
        {
            "authors": [
                "John R Dormand",
                "Peter J Prince"
            ],
            "title": "A family of embedded runge-kutta formulae",
            "venue": "Journal of computational and applied mathematics,",
            "year": 1980
        },
        {
            "authors": [
                "Eva L Dyer",
                "Mohammad Gheshlaghi Azar",
                "Matthew G Perich",
                "Hugo L Fernandes",
                "Stephanie Naufel",
                "Lee E Miller",
                "Konrad P K\u00f6rding"
            ],
            "title": "A cryptography-based approach for movement decoding",
            "venue": "Nature biomedical engineering,",
            "year": 2017
        },
        {
            "authors": [
                "Jonas Gehring",
                "Michael Auli",
                "David Grangier",
                "Denis Yarats",
                "Yann N Dauphin"
            ],
            "title": "Convolutional sequence to sequence learning",
            "venue": "In International conference on machine learning,",
            "year": 2017
        },
        {
            "authors": [
                "Bidisha Ghosh",
                "Biswajit Basu",
                "Margaret O\u2019Mahony"
            ],
            "title": "Multivariate short-term traffic flow forecasting using time-series analysis",
            "venue": "IEEE transactions on intelligent transportation systems,",
            "year": 2009
        },
        {
            "authors": [
                "Samuel Greydanus",
                "Misko Dzamba",
                "Jason Yosinski"
            ],
            "title": "Hamiltonian neural networks",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "Lu Han",
                "Han-Jia Ye",
                "De-Chuan Zhan"
            ],
            "title": "The capacity and robustness trade-off: Revisiting the channel independent strategy for multivariate time series forecasting",
            "venue": "arXiv preprint arXiv:2304.05206,",
            "year": 2023
        },
        {
            "authors": [
                "Zhiheng Huang",
                "Davis Liang",
                "Peng Xu",
                "Bing Xiang"
            ],
            "title": "Improve transformer models with better relative position embeddings",
            "venue": "arXiv preprint arXiv:2009.13658,",
            "year": 2020
        },
        {
            "authors": [
                "Muhammad Ibrahim",
                "Naveed Akhtar",
                "Saeed Anwar",
                "Ajmal Mian"
            ],
            "title": "Sat3d: Slot attention transformer for 3d point cloud semantic segmentation",
            "venue": "IEEE Transactions on Intelligent Transportation Systems,",
            "year": 2023
        },
        {
            "authors": [
                "Andrei C Jalba",
                "Michael HF Wilkinson",
                "Jos BTM Roerdink"
            ],
            "title": "Automatic segmentation of diatom images for classification",
            "venue": "Microscopy research and technique,",
            "year": 2004
        },
        {
            "authors": [
                "Guolin Ke",
                "Di He",
                "Tie-Yan Liu"
            ],
            "title": "Rethinking positional encoding in language pre-training",
            "venue": "arXiv preprint arXiv:2006.15595,",
            "year": 2020
        },
        {
            "authors": [
                "Diederik P Kingma",
                "Jimmy Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "arXiv preprint arXiv:1412.6980,",
            "year": 2014
        },
        {
            "authors": [
                "Thomas Lal",
                "Thilo Hinterberger",
                "Guido Widman",
                "Michael Schr\u00f6der",
                "N Hill",
                "Wolfgang Rosenstiel",
                "Christian Elger",
                "Niels Birbaumer",
                "Bernhard Sch\u00f6lkopf"
            ],
            "title": "Methods towards invasive human brain computer interfaces",
            "venue": "Advances in neural information processing systems,",
            "year": 2004
        },
        {
            "authors": [
                "James Large",
                "E Kate Kemsley",
                "Nikolaus Wellner",
                "Ian Goodall",
                "Anthony Bagnall"
            ],
            "title": "Detecting forged alcohol non-invasively through vibrational spectroscopy and machine learning. In Advances in Knowledge Discovery and Data Mining: 22nd Pacific-Asia Conference, PAKDD 2018",
            "year": 2018
        },
        {
            "authors": [
                "Colin Lea",
                "Michael D Flynn",
                "Rene Vidal",
                "Austin Reiter",
                "Gregory D Hager"
            ],
            "title": "Temporal convolutional networks for action segmentation and detection",
            "venue": "In proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2017
        },
        {
            "authors": [
                "Yang Li",
                "Si Si",
                "Gang Li",
                "Cho-Jui Hsieh",
                "Samy Bengio"
            ],
            "title": "Learnable fourier features for multidimensional spatial positional encoding",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Yan Lin",
                "Huaiyu Wan",
                "Shengnan Guo",
                "Youfang Lin"
            ],
            "title": "Pre-training context and time aware location embeddings from spatial-temporal trajectories for user next location prediction",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Hangchen Liu",
                "Zheng Dong",
                "Renhe Jiang",
                "Jiewen Deng",
                "Jinliang Deng",
                "Quanjun Chen",
                "Xuan Song"
            ],
            "title": "Spatio-temporal adaptive embedding makes vanilla transformer sota for traffic forecasting",
            "venue": "arXiv preprint arXiv:2308.10425,",
            "year": 2023
        },
        {
            "authors": [
                "Ran Liu",
                "Mehdi Azabou",
                "Max Dabagia",
                "Chi-Heng Lin",
                "Mohammad Gheshlaghi Azar",
                "Keith Hengen",
                "Michal Valko",
                "Eva Dyer"
            ],
            "title": "Drop, swap, and generate: A self-supervised approach for generating neural activity",
            "venue": "Advances in neural information processing systems,",
            "year": 2021
        },
        {
            "authors": [
                "Ran Liu",
                "Mehdi Azabou",
                "Max Dabagia",
                "Jingyun Xiao",
                "Eva Dyer"
            ],
            "title": "Seeing the forest and the tree: Building representations of both individual and collective dynamics with transformers",
            "venue": "Advances in neural information processing systems,",
            "year": 2022
        },
        {
            "authors": [
                "Francesco Locatello",
                "Dirk Weissenborn",
                "Thomas Unterthiner",
                "Aravindh Mahendran",
                "Georg Heigold",
                "Jakob Uszkoreit",
                "Alexey Dosovitskiy",
                "Thomas Kipf"
            ],
            "title": "Object-centric learning with slot attention",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Ilya Loshchilov",
                "Frank Hutter"
            ],
            "title": "Sgdr: Stochastic gradient descent with warm restarts",
            "venue": "arXiv preprint arXiv:1608.03983,",
            "year": 2016
        },
        {
            "authors": [
                "Fabian M\u00f6rchen"
            ],
            "title": "Time series knowlegde mining",
            "venue": "Go\u0308rich und Weiersha\u0308user,",
            "year": 2006
        },
        {
            "authors": [
                "Yuqi Nie",
                "Nam H Nguyen",
                "Phanwadee Sinthong",
                "Jayant Kalagnanam"
            ],
            "title": "A time series is worth 64 words: Long-term forecasting with transformers",
            "venue": "arXiv preprint arXiv:2211.14730,",
            "year": 2022
        },
        {
            "authors": [
                "Mandela Patrick",
                "Dylan Campbell",
                "Yuki Asano",
                "Ishan Misra",
                "Florian Metze",
                "Christoph Feichtenhofer",
                "Andrea Vedaldi",
                "Joao F Henriques"
            ],
            "title": "Keeping your eye on the ball: Trajectory attention in video transformers",
            "venue": "Advances in neural information processing systems,",
            "year": 2021
        },
        {
            "authors": [
                "Felix Pei",
                "Joel Ye",
                "David Zoltowski",
                "Anqi Wu",
                "Raeed H Chowdhury",
                "Hansem Sohn",
                "Joseph E O\u2019Doherty",
                "Krishna V Shenoy",
                "Matthew T Kaufman",
                "Mark Churchland"
            ],
            "title": "Neural latents benchmark\u201921: evaluating latent variable models of neural population activity",
            "venue": "arXiv preprint arXiv:2109.04463,",
            "year": 2021
        },
        {
            "authors": [
                "Alec Radford",
                "Karthik Narasimhan",
                "Tim Salimans",
                "Ilya Sutskever"
            ],
            "title": "Improving language understanding by generative pre-training",
            "year": 2018
        },
        {
            "authors": [
                "Alec Radford",
                "Jeffrey Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "venue": "OpenAI blog,",
            "year": 2019
        },
        {
            "authors": [
                "Yankun Ren",
                "Longfei Li",
                "Xinxing Yang",
                "Jun Zhou"
            ],
            "title": "Autotransformer: Automatic transformer architecture design for time series classification",
            "venue": "In Pacific-Asia Conference on Knowledge Discovery and Data Mining,",
            "year": 2022
        },
        {
            "authors": [
                "Vinit Shah",
                "Eva Von Weltin",
                "Silvia Lopez",
                "James Riley McHugh",
                "Lillian Veloso",
                "Meysam Golmohammadi",
                "Iyad Obeid",
                "Joseph Picone"
            ],
            "title": "The temple university hospital seizure detection",
            "venue": "corpus. Frontiers in neuroinformatics,",
            "year": 2018
        },
        {
            "authors": [
                "Oriane Sim\u00e9oni",
                "Gilles Puy",
                "Huy V Vo",
                "Simon Roburin",
                "Spyros Gidaris",
                "Andrei Bursuc",
                "Patrick P\u00e9rez",
                "Renaud Marlet",
                "Jean Ponce"
            ],
            "title": "Localizing objects with self-supervised transformers and no labels",
            "venue": "arXiv preprint arXiv:2109.14279,",
            "year": 2021
        },
        {
            "authors": [
                "Jianlin Su",
                "Yu Lu",
                "Shengfeng Pan",
                "Ahmed Murtadha",
                "Bo Wen",
                "Yunfeng Liu"
            ],
            "title": "Roformer: Enhanced transformer with rotary position embedding",
            "venue": "arXiv preprint arXiv:2104.09864,",
            "year": 2021
        },
        {
            "authors": [
                "Ruey S Tsay"
            ],
            "title": "Multivariate time series analysis: with R and financial applications",
            "year": 2013
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Zepu Wang",
                "Yuqi Nie",
                "Peng Sun",
                "Nam H Nguyen",
                "John Mulvey",
                "H Vincent Poor"
            ],
            "title": "St-mlp: A cascaded spatio-temporal linear framework with channel-independence strategy for traffic forecasting",
            "venue": "arXiv preprint arXiv:2308.07496,",
            "year": 2023
        },
        {
            "authors": [
                "Kan Wu",
                "Houwen Peng",
                "Minghao Chen",
                "Jianlong Fu",
                "Hongyang Chao"
            ],
            "title": "Rethinking and improving relative position encoding for vision transformer",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Joel Ye",
                "Chethan Pandarinath"
            ],
            "title": "Representation learning for neural population activity with neural data transformers",
            "venue": "arXiv preprint arXiv:2108.01210,",
            "year": 2021
        },
        {
            "authors": [
                "George Zerveas",
                "Srideepika Jayaraman",
                "Dhaval Patel",
                "Anuradha Bhamidipaty",
                "Carsten Eickhoff"
            ],
            "title": "A transformer-based framework for multivariate time series representation learning",
            "venue": "In Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining,",
            "year": 2021
        },
        {
            "authors": [
                "Yunhao Zhang",
                "Junchi Yan"
            ],
            "title": "Crossformer: Transformer utilizing cross-dimension dependency for multivariate time series forecasting",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Jianqiao Zheng",
                "Sameera Ramasinghe",
                "Simon Lucey"
            ],
            "title": "Rethinking positional encoding",
            "venue": "arXiv preprint arXiv:2107.02561,",
            "year": 2021
        },
        {
            "authors": [
                "Haoyi Zhou",
                "Shanghang Zhang",
                "Jieqi Peng",
                "Shuai Zhang",
                "Jianxin Li",
                "Hui Xiong",
                "Wancai Zhang"
            ],
            "title": "Informer: Beyond efficient transformer for long sequence time-series forecasting",
            "venue": "In Proceedings of the AAAI conference on artificial intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Tian Zhou",
                "Ziqing Ma",
                "Qingsong Wen",
                "Xue Wang",
                "Liang Sun",
                "Rong Jin"
            ],
            "title": "Fedformer: Frequency enhanced decomposed transformer for long-term series forecasting",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Multivariate time series (MTS) are widely used in a variety of domains, from finance and traffic prediction to healthcare (Ghosh et al., 2009; Tsay, 2013; Che et al., 2018). MTS consist of many channels of univariate time series, where each channel holds its own temporal dynamics and there are also latent interactions or dependencies across channels. The temporal dynamics, or temporal structure of each channel, together with the relationship across different channels, or the channelwise structure, jointly form the overall representation of the time series (Zerveas et al., 2021; Zhang & Yan, 2022). Being able to learn shared spatial and temporal structure in multivariate time series data is essential for obtaining robust representations and building inferences in downstream tasks.\nTransformers have demonstrated impressive performance when being used to extract representations from MTS (Zerveas et al., 2021; Nie et al., 2022), where position embeddings are used to encode the relative ordering or relationships between channel and/or temporal period (Vaswani et al., 2017). However, for time series, solely relying on standard approaches for position embedding is problematic for the following reasons:\n\u2022 For general timeseries datasets, there is no predetermined ordering or spatial \u201cposition\u201d for different channels. Thus, unlike in language or vision, it is challenging to use positional embeddings to build inductive bias to understand the relationships across channels (Su et al., 2021).\n\u2022 The relationships across channels and time segments might be instance-specific. For example, when localizing an event in the brain (e.g., seizure) using multiple electrodes spanning the brain, the dynamics would be altered depending on the specific brain region where the seizure occurs (Shah et al., 2018). In this case, having a fixed set of positional embeddings across samples may lead to ambiguity.\nThese characteristics of timeseries make conventional positional embedding methods inadequate and ineffective. Moving forward, it will be necessary to design novel types of embeddings techniques tailored to decipher the spatiotemporal structure of MTS.\nIn this work, we present a novel framework for learning both channel and temporal structures in timeseries data and then integrating this information into our tokens through \u201cgroup embeddings\u201d (Figure 1). Our approach learns a concise set of group-level tokens across the dataset and determines how to adaptively assign them to individual samples based on similarity between the group embedding and specific sample embeddings. This versatile methodology can be employed across sequences to integrate group-level structures into transformer layer in either space or time.\nBuilding on this foundation, we introduce the Group-Aware transFormer (GAFormer). By integrating spatial and temporal group embeddings with a spatiotemporal transformer architecture, GAFormer processes multivariate time series (MTS) data uniquely. It examines interactions across both temporal and spatial dimensions, allowing it to form a more comprehensive understanding of the structure within the data. Additionally, by decomposing our grouping into either the spatial or temporal dimension, we show that this also leads to enhanced interpretability, making GAFormer a more interpretable architecture for modeling time-series.\nWe tested our proposed technique on both classification and regression tasks spanning a number of different multivariate timeseries datasets. Our results suggest that group embeddings can be used to boost performance with a number of backbones, and that by combining both temporal and spatial group embeddings, GAFormer can provide state-of-the-art performance in comparison to previous methods. When we further analyzed the learned group structure, we found that GAFormer can reveal meaningful structure in data without any prior knowledge on the channel or temporal grouping in the data.\nWe summarize the major contributions of our work are as follows:\n\u2022 We introduced a novel data-adaptive group embedding (GE) technique that can be used to learn both spatial and temporal structure in multi-variate timeseries datasets. GE can be applied flexibly to any transformer encoder, and we show its application in multiple backbones and architectures for incorporating both spatial and temporal group awareness.\n\u2022 We develop a group-aware transformer, named GAFormer, which provides a robust solution to learning of spatial and temporal patterns that leads to improved classification.\n\u2022 The GAFormer, in addition to enhanced performance, offers meaningful interpretability and state-of-the-art performance in a variety of different types of timeseries datasets."
        },
        {
            "heading": "2 METHOD",
            "text": "In this work, we consider the benefit of instance-specific group embeddings that can allow for grouping across different tokens, either channel-wise (spatially) or time-wise (temporally). Ideally, we would like to learn a consistent and hence interpretable set of group embeddings, which is shared across the whole dataset and represents important across-token dependencies. We first describe our general approach for learning group embeddings, and then introduce our GAFormer architecture."
        },
        {
            "heading": "2.1 GROUP EMBEDDINGS",
            "text": "Consider a sequence of tokens X = [x1, ...,xN ] \u2208 RN\u00d7D, where N is the total number of tokens in a sequence, and D is the token dimensionality. The sequence can be effectively processed by the transformer architectures, where transformer would study the relationship across xi for 1 \u2264 i \u2264 N with multi-head self-attention blocks (Vaswani et al., 2017).\nWe construct group embeddings as a compact set of K \u226a N learnable parameters G \u2208 RK\u00d7D that are optimized during training. To adaptively assign the group embeddings to input tokens through an instance-specific operation, we pass an input sequence to an encoder layer Encoder(\u00b7), and then\nlearn a linear weight matrix W \u2208 RD\u00d7K to project each token down to a space of K dimensions. After projecting the sequence into a lower-dimensional space, we then apply a softmax function to obtain the weights; this operation will effectively sparsify the coefficients that assign group tokens to input tokens. This group embedding operation GE(X) can then be written as follows:\nGE(X) = S(Encoder(X)W ) \u00b7G (1) where S represents the softmax function that is applied along the dimensionality (D) direction. The group embedding GE(X) is then added to the input tokens X to add group awareness, resulting in:\nX \u2190 X +GE(X) (2) Intuitively, this group embedding operation computes the coefficients that assign each input token to a set of group tokens, where the coefficients are computed as: group-cofi = softmax(qiW ), where we can think of qi as a \u2018group query\u2019 of xi, which is i-th element of the group encoder output Encoder(X) in our implementation."
        },
        {
            "heading": "2.2 GAFORMER: A GROUP-AWARE SPATIOTEMPORAL TRANSFORMER",
            "text": "Our group embedding approach provides a general way to find and assign group tokens to an input sequence. Based on the proposed group embedding techniques, we further propose GAFormer, a spatiotemporal transformer that concurrently extracts both temporal and spatial grouping structures through learning group embeddings in both dimensions (Figure 2). GAFormer is designed to learn representation from multivariate time series X \u2208 RC\u00d7T , where C represents total amount of channels, and T represents total amount of timepoints along the temporal dimension.\nTokenization Layer: Following the channel-invariant design of Nie et al. (2022), we first divide the complete temporal sequence from each channel into smaller temporally contiguous patches, creating a tensor of shape X \u2208 RC\u00d7P\u00d7L, where P denotes the total number of patches, and L represents the length of each patch. We use an encoder Token(\u00b7) to tokenize each patch, forming Z = Token(X) \u2208 RC\u00d7P\u00d7D for each sample as their latent embeddings. In practice, to both retain the channel-wise separation and also inform the model about the temporal semantics of each channel, we implement Token(\u00b7) as a transformer encoder with learned positional embeddings that processes X along the temporal (P ) dimension. Thus, the latent embeddings could be used in later stages for extracting the spatiotemporal grouping structures without losing fidelity.\nSpatial (Channel-Wise) Group Awareness: After building the latent embeddings Z, GAFormer learns a channel-wise group embedding through a transformer encoder Trans-S(\u00b7) and a spatial group embedding module SGE(\u00b7). To extract the channel-wise interactions, we treat each temporal patch of data as an independent sequence by dividing the latent embedding Z into P multi-channel tokens ZS \u2208 RC\u00d7D. Therefore, we can learn the channel-wise grouping with a spatial set of group tokens GS \u2208 RKS\u00d7D, where KS is the number of spatial groups. The spatial operations jointly update the latent embeddings ZS as below:\nZ \u2032 = Trans-S(ZS + SGE(ZS)) (3)\nCritically, since each temporal patch of data is an independent sample to the spatial group embedding module SGE(\u00b7), we can extract different spatial groupings for each time period. This gives GAFormer impressive expressiveness, such that it gives customized spatial grouping to each temporal period based on the structure of the complete training dataset.\nTemporal Group Awareness: Obtaining Z \u2032, we further apply a dimension reduction layer H(\u00b7) to extract ZT = H([Z \u20321, ..., Z \u2032 P ]) \u2208 RP\u00d7D \u2032 for each sample, where C channels of D-dimension tokens are bottlenecked into one token of D\u2032-dimension to build spatiotemporal hierarchy.\nThe GAFormer further learns the temporal group awareness through a transformer encoder Trans-T(\u00b7) and a temporal group embedding module TGE(\u00b7). Similar as in spatial group awareness layer, the latent embedding ZT is updated as Zfinal = Trans-T(ZT +TGE(ZT )) where GAFormer maintains a temporal set of group tokens GT \u2208 RKT\u00d7D \u2032 with KT groups.\nThe architecture is trained end-to-end, where the parameters of the tokenization layer, the spatial layer, the dimension reduction layer, and the temporal layer are jointly optimized. When performing discriminative tasks, the tokens in Zfinal are averaged and fed into a linear classifier."
        },
        {
            "heading": "3 RESULTS",
            "text": ""
        },
        {
            "heading": "3.1 AN INTUITIVE EXAMPLE: NOISY MANY-BODY SYSTEMS",
            "text": "We first provide an intuitive example to motivate the benefits of our proposed group embedding. Specifically, we examine a system where the classification can only be performed after correctly identifying the channel groupings. In this scenario, we inspect the shortcomings of existing positional embedding solutions and assess the necessity of employing our proposed GE technique.\nNoisy Many-Body Systems: To dissect the performance of our model, we consider mutivariate time series generated from the trajectories of many-body systems consisting of mutually interacting particles (Greydanus et al., 2019; Liu et al., 2022). In our experiments, the task is to classify the total energy of a many-body system to decide if it belongs to a high-energy or a low-energy system. However, to make the problem more challenging, we pollute the system with irrelevant objects that are just passing by and not interacting with the system. To solve this task, we assume that the system needs to (i) identify the objects that are within the interactive system, and then (ii) classify the total energy of the system. We denote the resulting system as the noisy many-body system (Figure 3(A)).\nExperiment Setup: For each noisy many-body system, we first initialize a pair of interacting objects and a pair of non-interacting objects in a near-circular way (Liu et al., 2022), and then solve the trajectories with the Explicit Runge-Kutta method (Dormand & Prince, 1980). We sample 20 consecutive observations with a gap of 0.2 within time span [0, 10] for each system, and randomly generate 30,000 trials to provide rich variability of the trajectories. We compute the total energy of\neach system and keep the top and bottom quartiles for the classification labels. We then perform a 60/40% train/test random split, and used the same generated dataset throughout.\nTo benchmark the effectiveness of GE , we train the exact same transformer architecture with (i) learnable positional embedding (Gehring et al., 2017; Radford et al., 2018; 2019), (ii) parameterfree sin-cos positional embedding (Vaswani et al., 2017), and (iii) GE. Each architecture contains 4-layer transformer blocks with 4 attention heads and 32 dimensions, where for GE we share the first transformer layer as the Encoder(\u00b7) that generates group embedding coefficients to keep the total depth of the transformer consistent. We train all models with learning rate of 0.0001 using the Adam optimizer (Kingma & Ba, 2014), with a batch size of 64 for 200k steps till the model converges. All runs are repeated for five random seeds.\nResults: We examine the robustness of GE in three settings: (i) Stable setting, where the relative position of objects (channels) never shifts; (ii) Shuffle setting, where the observed objects could be in any position and are randomized similarly in training and testing; (iii) Biased setting, where the observed objects have different positions that are randomly sampled from non-overlapping sets for the training and testing data.\nAs shown in Figure 3(B), the synthetic results demonstrate that GE is necessary for the successful modeling of MTS with varying spatial structures. When the channel structure is known and fixed (Stable), GE performs similar as the other two position embedding techniques. However, when the channel structure is randomized and thus exhibits rich variability (Shuffle), GE shows impressive improvement over learnable position embedding (\u2248\u219110%) albeit having similar amount of parameters, and outperforms sin-cos position embedding by a large margin of \u2248\u21914%. Finally, when the spatial structure distribution differs from the train and test (Biased), GE becomes the only embedding method that gives robust performance (\u224897%), while the other two baseline methods fail to learn (\u224850%). The results on synthetic experiments demonstrate that GE is a necessary component for effective learning on datasets where the token-wise structure is unknown or biased."
        },
        {
            "heading": "3.2 TIME-SERIES CLASSIFICATION TASKS",
            "text": "In this section, we aim to validate: (i) The effectiveness of GE when it is added into other architectures; (ii) The effectiveness of GAFormer when it is used in multivariate time-series.\nUnivariate and Multivariate Datasets: We validate the effectiveness of GE on both the univariate datasets and the muiltivariate datasets; and further examine the performance of GAFormer on muiltivariate datasets. Both datasets are selected from the UEA Time Series Classification benchmark (Bagnall et al., 2018), where univariate time-series datasets contain InlineSkate (7 classes) (Mo\u0308rchen, 2006), Earthquakes (2 classes), Adiac (37 classes) (Jalba et al., 2004); While the multivariate time-series datasets contain MotorImagery (64-channel ECoG, 2 classes) (Lal et al., 2004), SelfRegSCP2 (7-channel EEG, 2 classes) (Birbaumer et al., 2001), FaceDetect (144-channel MEG, 2 classes), and Ethanol (3-channel Spectrometer, 4 classes) (Large et al., 2018). The selected datasets present a multifaceted spectrum of challenges inherent to time series analysis.\nBaselines: For univariate experiments, we add GE on the temporal dimension (TGE) on top of two representative transformers for time-seires classification: MVTS (Zerveas et al., 2021) and AutoTransformer (Ren et al., 2022). We examine the benefit of our temporal grouping structure by evaluating the gain of the performance. We also selected two non-transformer architectures GRU (Dey & Salem, 2017) and TCN (Lea et al., 2017) for comparison.\nWe implement GAFormer for multivariate time-series experiments. For the baselines, aside from running the same baselines for univariate experiments, we also include the nearest neighbor classifier (NN) (Peterson, 2009) and two dynamic time warping approaches that either use the same (DTWI ) or different (DTWD) warping factors across dimensions, as reported in Bagnall et al. (2018). We\nalso implement a supervised version of PatchTST (Nie et al., 2022). More details of benchmarks and model implementation are stated in Appendix B.\nExperiment Setup: We evaluate all methods in the setting of supervised learning. For each dataset, we perform an 80/20% train/val split on the original training dataset, and select the best model on the validation set to obtain results on the testing set. We perform consistent evaluation on all experiments, where we train all models with the Adam optimizer with an initial learning rate of 0.0003, a cosine annealing scheduler with warm restarts (Loshchilov & Hutter, 2016), a restarting period of 5 epochs, and the multiplying factor of 2. We set the maximum number of epochs as 300. All models are trained until convergence. To validate the effectiveness and adaptiveness of the proposed group embeddings, we add the temporal group embedding module (TGE) to two baseline models and evaluate how temporal group embeddings impact the performance of existing models. We provide more details of the models and the optimization process in Appendix B.\nUnivariate Results: We show the classification performance of univariate experiments in Table 1. In all datasets, we show that when adding the temporal group embedding module (TGE), the performance of baseline transformers can be greatly improved. Especially, in InlineSkate dataset, adding TGE to MVTS gives an impressive \u219112.55% increase of accuracy; while in Adiac dataset, adding TGE to AutoTransformer gives \u21918.43% increase of accuracy. The experimental results demonstrate that adding temporal grouping awareness to univariate time-series could give an impressive boost of performance for learning on time-series.\nMultivariate Results: As shown in Table 2, we report the classification performance of GAFormer and the performance gain given by GE across various multivariate datasets. Similar to the univariate results, we show that integrating the temporal group embeddings TGE to transformer architectures MVTS and AutoTransformer gives notable improvements in accuracy, whereas in SelfRegSCP2 the classification accuracy gain is \u21918.00%. Furthermore, when combining spatial and temporal grouping structures, we show that GAFormer can obtain further boosts in performance, giving an average classification performance increase of \u2248\u21916%. This robustness of GAFormer accentuates its capability in concurrently learning spatial and temporal group tokens, proving its prowess in processing multivariate time series data. Our analysis demonstrates the benefits of group embeddings, highlighting its versatility both on its own and when implemented as an independent architecture."
        },
        {
            "heading": "3.3 CLASSIFICATION AND REGRESSION TASKS ON NEURAL RECORDINGS",
            "text": "Brain-computer interfaces (BCIs) enable the direct translation of neural activity into outputs that can control external devices, bridging the gap between the brain and machines. Crucially, the success of BCIs heavily relies on the accuracy of the neural decoding methods, which benefit from the identification of neuronal function groups. Thus, we examine GAFormer for neural decoding tasks.\nNeural Decoding Datasets: We systematically evaluate GAFormer across six neural decoding datasets that capture neural population activities from the motor cortex of nonhuman primates engaged in different movement tasks (Pei et al., 2021; Liu et al., 2022). In neural recording datasets,\nthe activities of individual neurons are sorted into distinct channels, and the number of spikes across temporal period (20ms) are counted to produce multivariate time-series.\nWe first test GAFormer on the Mihi-Chewie reaching dataset for classification (Dyer et al., 2017). The dataset consists of stable behavior-based neural responses from different neuron populations and animals performing the same task (Dyer et al., 2017; Liu et al., 2021), where two rhesus macaques, Chewie and Mihi, were trained to reach one of eight locations. While executing different reaches, neural activity in their primary motor cortex was continuously recorded across the two subjects on two different days, forming a total of four sub-datasets.\nWe also examine the performance of GAFormer on the Maze and the Random Target Task (RTT) tasks of the Neural Latents Benchmark (NLB) for regression (Pei et al., 2021). The Maze dataset records the neural activity from the dorsal premotor (PMd) and primary motor (M1) cortices, where the objective is to predict the hand movement trajectories of the observed subject. The RTT dataset is a unique self-paced sequential reaching task set amidst random elements of a grid. The dataset contains neural spikes from the primary cortex, which is used to predict the subject\u2019s hand position.\nExperimental Setup: We benchmark GAFormer against existing state-of-the-art transformer-based models for neural data, including NDT (Ye & Pandarinath, 2021) and EIT (Liu et al., 2022), as well as traditional methods GRU and TCN. For all experiments, we use the same GAFormer architecture as stated in Section 3.2, and simply add one linear projection layer to the final embeddings of GAFormer to predict the hand velocities for the regression task with an MSE loss. For all experiments, we train the model for 300 epochs, and optimize the network with an Adam optimizer and a cosine annealing learning rate scheduler, and report the converged accuracy and R2 score on the test set. We report additional details about the hyperparameters in Appendix B.\nResults and Insights: We show the experimental results as in Table 3. Across the board, we find that GAFormer provides strong performance on all neural decoding tasks, with major improvements over the baseline methods in multiple instances. The good performance happens in both classification tasks and regression tasks, where significant improvements in the Chewie-2 and Mihi-1 datasets of a classification accuracy of 94.44% and 92.86% are observed, surpassing the previous state-of-the-art by \u2248\u21913%. For the more complicated regression tasks, GAFormer also gives the new state-of-the-art, demonstrating robust decoding performance decoding neural activities. The neural decoding results demonstrate that GAFormer can consistently outperform the previous state-of-thearts, suggesting its adaptability and promise for a diverse range of tasks.\nOverall, the GAFormer model showcases versatility across datasets, highlighting its potential as a robust tool for neural decoding in BCIs, even when compared against the previous state-of-the-art models. Besides the impressive classification performance, another major advantage of GAFormer is its interpretability, which is demonstrated through the visualizations in Appendix C, where the structural information about neurons organizations as well as temporal stages are generated through group embedding assignments automatically."
        },
        {
            "heading": "3.4 ABLATION STUDIES",
            "text": "To understand the contributions of various components in our GAFormer architecture, we conducted a number of ablations to the model on the UEA datasets studied in Table 2. These experiments aimed to quantify the impact of temporal group embedding and spatial group embedding within the system.\nThe first ablation revolved around understanding the performance of GAFormer without any of the group-aware embeddings (Table 4, Base). By comparing this stripped-down version with the full model, we could gauge the foundational performance gain offered by our group-aware embedding\nmechanism. We found that training the model without group-aware embeddings resulted in suboptimal performance across all datasets that we tested. This demonstrates that the embedding strategy is integral to harnessing the intricate patterns present in multivariate time series.\nThe second ablation aimed to dissect the individual impacts of spatial and temporal group embeddings. To do this, we trained two distinct model variants: one exclusively leveraging spatial group embeddings (+SGE) and the other reliant solely on temporal group embeddings (+TGE). Both variants improved over the base model with no group embeddings. How-\never, neither reached the performance of the combined spatial and temporal model, indicating that the joint utility of spatial and temporal tokens plays a crucial role in the learning process."
        },
        {
            "heading": "3.5 INTERPRETABILITY OF GROUP EMBEDDINGS",
            "text": "A key advantage of our group-aware architecture is that, once trained, we can examine the spatial and temporal group embedding assignments that are learned by the model. Thus, we studied the spatial and temporal embeddings learned by GAFormer in the MotorImagery ECoG dataset and the NLB RTT dataset (Figure 4, Appendix C.1). In both cases, we found clear temporal grouping structure that appeared to segment the data in a data-adaptive manner, where the temporal grouping structure of NLB RTT seems to follow the intrinsic structure of the movement task (Pei et al., 2021). In the case of the MotorImagery dataset, we also found distinguishable grouping structures along the channel (spatial) dimension, where the imagined movements of fingers have huge variation (Figure 4 left); while the imagined movements of the tongue exhibit similar grouping structures across trials (Figure 4 right). We believe that the distinction of grouping structures across different samples reveal the underlying complexity of the task, as the movement of the finger is originally richer than the movement of tongue. The impressive interpretability of the proposed group embedding technique opens avenues for a myriad of prospective applications."
        },
        {
            "heading": "4 RELATED WORK",
            "text": "Position Embedding: Position embedding plays a critical role in the transformer architecture, spanning from textual, images, to temporal data (Huang et al., 2020; Su et al., 2021). Given the orderagnostic nature of transformers, positional embeddings introduce the essential sequential context. Numerous studies, represented by Li et al. (2021); Zheng et al. (2021); Ke et al. (2020); Wu et al. (2021), have delved into the specifics and refinements of positional embeddings. Among existing techniques, our approach shares similarities with the conditional positional embedding that is used in visual representation learning (Chu et al., 2021). However, their method focuses on instancespecific learning of positional embedding without specifically targeting the discovery of grouping\nstructures, which is the unique advantage of our proposed approach. Moreover, it is worth noting that recent works on multivariate time series also explored the use of spatiotemporal embeddings that have been developed for traffic forecasting (Liu et al., 2023) and future location prediction (Lin et al., 2021). Different from them, the robustness of GE relies on the design of the grouping structure, which effectively identifies distinctive spatiotemporal structures.\nSet Discovery and Prediction: In the domain of computer vision, Locatello et al. (2020) introduced slot attention, which is used for weakly supervised set discovery and prediction problems. Drawing parallels with our proposed methodology, both techniques require the construction of a fixed-size \u2018group tokens\u2019, which are referred to as \u2018slots\u2019 in slot attention. However, our proposed group embedding differs from slot attention and its successive works (Patrick et al., 2021; Sime\u0301oni et al., 2021; Ibrahim et al., 2023) such that GE can effectively improve representation demonstrated by increased performance in downstream tasks. We hypothesize that the performance gain is due to the uniqueness of the structure of multivariate time series, which is often neglected in previous works.\nTransformers for Multivariate Timeseries: The transformer architecture, originally developed for natural language processing tasks, has been adapted for the analysis of multivariate time series data. Its inherent self-attention mechanism enables it to assign appropriate weights to sequential inputs, capturing the temporal relationships intrinsic to time series data.\nInitial approaches to integrating transformers for multivariate time series involved tokenizing short context windows from sequences. These tokenized segments were subsequently embedded using Multi-Layer Perceptrons (MLP) or Temporal Convolutional Networks (TCN) (Zerveas et al., 2021). Despite its foundational nature, this method exhibited limitations in extracting channel-specific features and incorporating them into the training process. Recent methodologies, notably EIT (Liu et al., 2022) and PatchTST (Nie et al., 2022), introduced a channel-independent design, optimizing both classification and forecasting tasks. Building on this work, Wang et al. (2023) introduces a spatiotemporal channel-independent transformer architecture for traffic prediction.\nIn the realm of forecasting, PatchTST (Nie et al., 2022) has introduced an innovative patch design tailored for time series predictions, maintaining a channel-invariant design. Similarly, CrossFormer (Zhang & Yan, 2022) prioritizes patch designs but with a focus on exploiting inter-channel dependencies. Such methodologies underscore the importance of channel relationships for enhancing forecasting outcomes. Other significant contributions in this domain include works like (Zhou et al., 2021; 2022), which have expanded the use cases of transformer-based forecasting."
        },
        {
            "heading": "5 DISCUSSION",
            "text": "In this work, we introduced a novel framework for incorporating group-level structure into timeseries analysis. Central to our contributions is the development of a group embedding scheme tailored for transformer architectures. By adaptively learning compact grouping tokens across channel and temporal dimensions, our model introduces group-aware structural information into the representation space. Empirical validations on several time-series benchmarks validate the efficacy of our approach, where our method achieves superior classification accuracy compared to existing models, outperforming the previous state-of-the-art. Moreover, without any predefined structure or additional supervision beyond classification or regression, our method adaptively discerns channel-wise and temporal groupings by assigning group embeddings to tokens, giving enhanced interpretability.\nLimitations and Future Work: GAFormer partially relies on the channel-independent design as proposed in Nie et al. (2022); Liu et al. (2022). While broad-ranging, as discussed in Han et al. (2023), it might not adequately capture the complexities of data with intricate inter-channel dynamics, leading to suboptimal representations in certain datasets. In addition, as the spatial and temporal dimension grows, more data is needed for the model to effectively extract a reliable grouping structures. Moving forward, improving the group embedding module to train it effectively on high-dimensional data when limited samples are available would be an exciting line of research.\nIn the future, it would be interesting to use our group embedding approach with more complicated transformer architectures and also test its application to other types of sequential data, such as audio signals or videos. Additionally, a more in-depth examination into the model interpretability, possibly using advanced quantification metrics or visualization tools, can shed light on the intricacies of how the group tokens capture and represent data dynamics."
        }
    ],
    "title": "GAFORMER: ENHANCING TIMESERIES TRANSFORM-",
    "year": 2023
}