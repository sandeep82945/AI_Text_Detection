{
    "abstractText": "Misclassification detection is an important problem in machine learning, as it allows for the identification of instances where the model\u2019s predictions are unreliable. However, conventional uncertainty measures such as Shannon entropy do not provide an effective way to infer the real uncertainty associated with the model\u2019s predictions. In this paper, we introduce a novel data-driven measure of uncertainty relative to an observer for misclassification detection. By learning patterns in the distribution of soft-predictions, our uncertainty measure can identify misclassified samples based on the predicted class probabilities. Interestingly, according to the proposed measure, soft-predictions corresponding to misclassified instances can carry a large amount of uncertainty, even though they may have low Shannon entropy. We demonstrate empirical improvements over multiple image classification tasks, outperforming state-of-the-art misclassification detection methods.",
    "authors": [
        {
            "affiliations": [],
            "name": "Eduardo Dadalto"
        },
        {
            "affiliations": [],
            "name": "Marco Romanelli"
        },
        {
            "affiliations": [],
            "name": "Georg Pichler"
        },
        {
            "affiliations": [],
            "name": "Pablo Piantanida"
        }
    ],
    "id": "SP:c58528d7999b6ebb037de8a161363bc373c87e28",
    "references": [
        {
            "authors": [
                "Naveed Akhtar",
                "Ajmal Mian"
            ],
            "title": "Threat of adversarial attacks on deep learning in computer vision: A survey",
            "year": 2018
        },
        {
            "authors": [
                "Dario Amodei",
                "Chris Olah",
                "Jacob Steinhardt",
                "Paul Christiano",
                "John Schulman",
                "Dan Man\u00e9"
            ],
            "title": "Concrete problems in ai safety",
            "venue": "arXiv preprint arXiv:1606.06565,",
            "year": 2016
        },
        {
            "authors": [
                "Anastasios N. Angelopoulos",
                "Stephen Bates"
            ],
            "title": "A gentle introduction to conformal prediction and distribution-free uncertainty quantification",
            "venue": "CoRR, abs/2107.07511,",
            "year": 2021
        },
        {
            "authors": [
                "Anastasios Nikolas Angelopoulos",
                "Stephen Bates",
                "Michael I. Jordan",
                "Jitendra Malik"
            ],
            "title": "Uncertainty sets for image classifiers using conformal prediction",
            "venue": "In 9th International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Jun Cen",
                "Di Luan",
                "Shiwei Zhang",
                "Yixuan Pei",
                "Yingya Zhang",
                "Deli Zhao",
                "Shaojie Shen",
                "Qifeng Chen"
            ],
            "title": "The devil is in the wrongly-classified samples: Towards unified open-set",
            "venue": "recognition. ArXiv,",
            "year": 2023
        },
        {
            "authors": [
                "Raghavendra Chalapathy",
                "Sanjay Chawla"
            ],
            "title": "Deep learning for anomaly detection: A survey",
            "venue": "CoRR, abs/1901.03407,",
            "year": 2019
        },
        {
            "authors": [
                "C.K. Chow"
            ],
            "title": "On optimum recognition error and reject tradeoff",
            "venue": "IEEE Trans. Inf. Theory,",
            "year": 1970
        },
        {
            "authors": [
                "Oliver Cobb",
                "Arnaud Van Looveren"
            ],
            "title": "Context-aware drift detection",
            "venue": "International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Charles Corbi\u00e8re",
                "Nicolas Thome",
                "Avner Bar-Hen",
                "Matthieu Cord",
                "Patrick P\u00e9rez"
            ],
            "title": "Addressing failure prediction by learning model confidence",
            "venue": "Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems",
            "year": 2019
        },
        {
            "authors": [
                "Imre Csisz\u00e1r"
            ],
            "title": "Eine informationstheoretische ungleichung und ihre anwendung auf den beweis der ergodizit\u00e4t von markoffschen ketten",
            "venue": "Magyer Tud. Akad. Mat. Kutato Int. Koezl.,",
            "year": 1964
        },
        {
            "authors": [
                "Bat-Sheva Einbinder",
                "Yaniv Romano",
                "Matteo Sesia",
                "Yanfei Zhou"
            ],
            "title": "Training uncertainty-aware classifiers with conformalized deep learning",
            "venue": "CoRR, abs/2205.05878,",
            "year": 2022
        },
        {
            "authors": [
                "Stanislav Fort",
                "Jie Ren",
                "Balaji Lakshminarayanan"
            ],
            "title": "Exploring the limits of out-of-distribution detection",
            "venue": "Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems",
            "year": 2021
        },
        {
            "authors": [
                "Yarin Gal",
                "Zoubin Ghahramani"
            ],
            "title": "Dropout as a bayesian approximation: Representing model uncertainty in deep learning",
            "venue": "Proceedings of the 33nd International Conference on Machine Learning,",
            "year": 2016
        },
        {
            "authors": [
                "Chuanxing Geng",
                "Sheng-Jun Huang",
                "Songcan Chen"
            ],
            "title": "Recent advances in open set recognition: A survey",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Corrado Gini"
            ],
            "title": "Variabilit\u00e0 e mutabilit\u00e0; contributo allo studio delle distribuzioni e delle relazioni statistiche",
            "venue": "In [Fasc. I.]",
            "year": 1912
        },
        {
            "authors": [
                "Federica Granese",
                "Marco Romanelli",
                "Daniele Gorla",
                "Catuscia Palamidessi",
                "Pablo Piantanida"
            ],
            "title": "DOCTOR: A simple method for detecting misclassification errors",
            "venue": "Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems",
            "year": 2021
        },
        {
            "authors": [
                "Chuan Guo",
                "Geoff Pleiss",
                "Yu Sun",
                "Kilian Q. Weinberger"
            ],
            "title": "On calibration of modern neural networks",
            "venue": "Proceedings of the 34th International Conference on Machine Learning,",
            "year": 2017
        },
        {
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2016
        },
        {
            "authors": [
                "Dan Hendrycks",
                "Kevin Gimpel"
            ],
            "title": "A baseline for detecting misclassified and out-of-distribution examples in neural networks",
            "venue": "In 5th International Conference on Learning Representations,",
            "year": 2017
        },
        {
            "authors": [
                "Gao Huang",
                "Zhuang Liu",
                "Laurens van der Maaten",
                "Kilian Q. Weinberger"
            ],
            "title": "Densely connected convolutional networks",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2017
        },
        {
            "authors": [
                "Nikita Yurevich Kotelevskii",
                "Aleksandr Artemenkov",
                "Kirill Fedyanin",
                "Fedor Noskov",
                "Alexander Fishkov",
                "Artem Shelmanov",
                "Artem Vazhentsev",
                "Aleksandr Petiushko",
                "Maxim Panov"
            ],
            "title": "Nonparametric uncertainty quantification for single deterministic neural network",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Alex Krizhevsky"
            ],
            "title": "Learning multiple layers of features from tiny images",
            "venue": "Technical report,",
            "year": 2009
        },
        {
            "authors": [
                "Solomon Kullback",
                "Richard A Leibler"
            ],
            "title": "On information and sufficiency",
            "venue": "The Annals of Mathematical Statistics,",
            "year": 1951
        },
        {
            "authors": [
                "Balaji Lakshminarayanan",
                "Alexander Pritzel",
                "Charles Blundell"
            ],
            "title": "Simple and scalable predictive uncertainty estimation using deep ensembles",
            "venue": "In NIPS,",
            "year": 2016
        },
        {
            "authors": [
                "Kimin Lee",
                "Kibok Lee",
                "Honglak Lee",
                "Jinwoo Shin"
            ],
            "title": "A simple unified framework for detecting out-of-distribution samples and adversarial attacks",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2018
        },
        {
            "authors": [
                "Shiyu Liang",
                "Yixuan Li",
                "Rayadurgam Srikant"
            ],
            "title": "Enhancing the reliability of out-of-distribution image detection in neural networks",
            "venue": "arXiv preprint arXiv:1706.02690,",
            "year": 2017
        },
        {
            "authors": [
                "Shiyu Liang",
                "Yixuan Li",
                "R. Srikant"
            ],
            "title": "Enhancing the reliability of out-of-distribution image detection in neural networks",
            "venue": "In International Conference on Learning Representations,",
            "year": 2018
        },
        {
            "authors": [
                "Jeremiah Liu",
                "Zi Lin",
                "Shreyas Padhy",
                "Dustin Tran",
                "Tania Bedrax Weiss",
                "Balaji Lakshminarayanan"
            ],
            "title": "Simple and principled uncertainty estimation with deterministic deep learning via distance awareness",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Matthias Minderer",
                "Josip Djolonga",
                "Rob Romijnders",
                "Frances Ann Hubis",
                "Xiaohua Zhai",
                "Neil Houlsby",
                "Dustin Tran",
                "Mario Lucic"
            ],
            "title": "Revisiting the calibration of modern neural networks",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Jishnu Mukhoti",
                "Joost van Amersfoort",
                "Philip H.S. Torr",
                "Yarin Gal"
            ],
            "title": "Deep deterministic uncertainty for semantic segmentation",
            "venue": "In CoRR, volume abs/2111.00079,",
            "year": 2021
        },
        {
            "authors": [
                "Jishnu Mukhoti",
                "Andreas Kirsch",
                "Joost van Amersfoort",
                "Philip H.S. Torr",
                "Yarin Gal"
            ],
            "title": "Deep deterministic uncertainty: A new simple baseline",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2023
        },
        {
            "authors": [
                "Marco AF Pimentel",
                "David A Clifton",
                "Lei Clifton",
                "Lionel Tarassenko"
            ],
            "title": "A review of novelty detection",
            "venue": "Signal processing,",
            "year": 2014
        },
        {
            "authors": [
                "Francesco Pinto",
                "Harry Yang",
                "Ser-Nam Lim",
                "Philip Torr",
                "Puneet K. Dokania"
            ],
            "title": "Regmixup: Mixup as a regularizer can surprisingly improve accuracy and out distribution robustness",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "C Radhakrishna Rao"
            ],
            "title": "Diversity and dissimilarity coefficients: a unified approach",
            "venue": "Theoretical population biology,",
            "year": 1982
        },
        {
            "authors": [
                "Jie Ren",
                "Stanislav Fort",
                "Jeremiah Z. Liu",
                "Abhijit Guha Roy",
                "Shreyas Padhy",
                "Balaji Lakshminarayanan"
            ],
            "title": "A simple fix to mahalanobis distance for improving near-ood detection",
            "year": 2021
        },
        {
            "authors": [
                "Alfr\u00e9d R\u00e9nyi"
            ],
            "title": "On measures of entropy and information",
            "venue": "In Proceedings of the fourth Berkeley symposium on mathematical statistics and probability. Berkeley, California,",
            "year": 1961
        },
        {
            "authors": [
                "Yaniv Romano",
                "Matteo Sesia",
                "Emmanuel J. Cand\u00e8s"
            ],
            "title": "Classification with valid and adaptive coverage",
            "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems",
            "year": 2020
        },
        {
            "authors": [
                "C.E. Shannon"
            ],
            "title": "A mathematical theory of communication",
            "venue": "The Bell System Technical Journal,",
            "year": 1948
        },
        {
            "authors": [
                "Constantino Tsallis"
            ],
            "title": "Possible generalization of boltzmann-gibbs statistics",
            "venue": "Journal of statistical physics,",
            "year": 1988
        },
        {
            "authors": [
                "Meet P. Vadera",
                "Adam D. Cobb",
                "Brian Jalaian",
                "Benjamin M. Marlin"
            ],
            "title": "Ursabench: Comprehensive benchmarking of approximate bayesian inference methods for deep neural networks",
            "year": 2007
        },
        {
            "authors": [
                "Joost Van Amersfoort",
                "Lewis Smith",
                "Yee Whye Teh",
                "Yarin Gal"
            ],
            "title": "Uncertainty estimation using a single deep deterministic neural network",
            "venue": "Proceedings of the 37th International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Hongxin Wei",
                "Renchunzi Xie",
                "Hao Cheng",
                "Lei Feng",
                "Bo An",
                "Yixuan Li"
            ],
            "title": "Mitigating neural network overconfidence with logit normalization",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Hongyi Zhang",
                "Moustapha Ciss\u00e9",
                "Yann N. Dauphin",
                "David Lopez-Paz"
            ],
            "title": "mixup: Beyond empirical risk",
            "venue": "minimization. CoRR,",
            "year": 2017
        },
        {
            "authors": [
                "Fei Zhu",
                "Zhen Cheng",
                "Xu-Yao Zhang",
                "Cheng-Lin Liu"
            ],
            "title": "Openmix: Exploring outlier samples for misclassification detection",
            "venue": "ArXiv, abs/2303.17093,",
            "year": 2023
        },
        {
            "authors": [
                "Fei Zhu",
                "Zhen Cheng",
                "Xu-Yao Zhang",
                "Cheng-Lin Liu"
            ],
            "title": "Rethinking confidence calibration for failure",
            "venue": "prediction. ArXiv,",
            "year": 2023
        },
        {
            "authors": [
                "A.3.2 ODIN Liang"
            ],
            "title": "Hendrycks & Gimpel (2017) by introducing temperature scaling and input pre-processing techniques as described in Appendix A.4, and then compute (20) as the detection score. We tune hyperparameters T and \u03b5 on a validation set for each pair of network and training procedure",
            "year": 2017
        },
        {
            "authors": [
                "A.3.3 DOCTOR Granese"
            ],
            "title": "as the detection score and applies temperature scaling and input pre-processing as described in Appendix A.4. Likewise, we tune hyperparameters T and \u03b5 on a validation set for each pair of network and training procedure",
            "year": 2021
        },
        {
            "authors": [
                "Angelopoulos"
            ],
            "title": "pass of multiple models trained on different initializations. We ran experiments with k = 5 different random seeds. To compute the confidence score, we averaged logits and computed the MSP response",
            "year": 2021
        },
        {
            "authors": [
                "A.3.8 LOGITNORM Wei"
            ],
            "title": "2022) observe that the norm of the logit keeps increasing during training, leading to overconfident predictions. So, they propose Training neural networks with logit normalization to hopefully produce more distinguishable confidence scores between in- and out-of-distribution data. They propose normalizing the logits of the cross entropy loss, resulting in the following loss function",
            "year": 2022
        },
        {
            "authors": [
                "MIXUP Zhang"
            ],
            "title": "2017) propose to train a neural network on convex combinations of pairs of examples and their label to minimize the empirical vicinal risk",
            "year": 2017
        },
        {
            "authors": [
                "A.3.10 REGMIXUP Pinto"
            ],
            "title": "2022) use the cross entropy of the mixup data as in (22) with \u03bb sampled according to a Beta(10, 10) distribution as a regularizer of the classic cross entropy loss for training a network. The objective is balanced with a hyperparameter \u03b3, usually set to 0.5",
            "year": 2022
        },
        {
            "authors": [
                "A.3.11 OPENMIX Zhu"
            ],
            "title": "2023a) explicitly add an extra class for outlier samples and uses mixup as a regularizer for the cross entropy loss, but mixing between inlier training samples and outlier samples collected from the wild. It yields the objective L",
            "year": 2023
        },
        {
            "authors": [
                "Liang"
            ],
            "title": "soft-probability output, therefore comparable to Granese et al",
            "year": 2018
        },
        {
            "authors": [
                "Angelopoulos"
            ],
            "title": "Performance of conformal prediction. We take into account the application of conformal predictors applied to the problem of misclassification",
            "venue": "In particular,",
            "year": 2021
        },
        {
            "authors": [
                "Angelopoulos"
            ],
            "title": "models, learn a \u201cprediction set function\u201d, i.e. they return a set of labels, which should contain the correct value with high probability, for a given data distribution",
            "year": 2024
        },
        {
            "authors": [
                "Angelopoulos"
            ],
            "title": "on a sample basis: samples that are \u201charder\u201d to classify can produce larger sets than samples that are easier to correctly classify. The models are \u201cconformalized",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Critical applications, such as autonomous driving and automatic tumor segmentation, have benefited greatly from machine learning algorithms. This motivates the importance of understanding their limitations and urges the need for methods that can detect patterns on which the model uncertainty may lead to dangerous consequences (Amodei et al., 2016). In recent years, considerable efforts have been dedicated to uncovering methods that can deceive deep learning models, causing them to make classification mistakes. While these findings have highlighted the vulnerabilities of deep learning models, it is important to acknowledge that erroneous classifications can also occur naturally. The likelihood of such incorrect classifications is strongly influenced by the characteristics of the data being analyzed and the specific model being used. Even small changes in the distribution of the training and evaluation samples can significantly impact the occurrence of these misclassifications.\nA recent thread of research has shown that issues related to misclassifications might be addressed by augmenting the training data for better representation (Zhu et al., 2023a; Zhang et al., 2017; Pinto et al., 2022). However, in order to build misclassification detectors, all these approaches rely on some statistics derived from the soft-prediction output by the model, such as the entropy or related notions, interpreting it as an expression of the model\u2019s confidence. We argue that relying on the assumption that the model\u2019s output distribution is a good representation of the uncertainty of the model is inadequate. For example, a model may be very confident on a sample that is far from the training distribution and, therefore, it is likely to be misclassified, which undermines the effective use of the Shannon entropy as a measure of the real uncertainty associated with the model\u2019s prediction.\n\u2217Equal contribution.\nIn this work, we propose a data-driven measure of relative uncertainty inspired by Rao (1982) that relies on negative and positive instances to capture meaningful patterns in the distribution of soft-predictions. For example, positive instances can be correctly classified samples for which the uncertainty is expected to be low while negative instances (misclassified samples) are expected to have high uncertainty. Thus, the goal is to yield high and low uncertainty values for negative and positive instances, respectively. Our measure is \u201crelative\u201d, as it is not characterized axiomatically, but only serves the purpose of measuring uncertainty of positive instances relative to negative ones from the point of view of a subjective observer d. We employ relative uncertainty to measure the overall uncertainty of a model, encompassing both aleatoric and epistemic uncertainty components. By learning to minimize the uncertainty in positive instances and to maximize it in negative instances, our metric can effectively capture meaningful information to differentiate between the underlying structure of distributions corresponding to two categories of data. Interestingly, this notion can be expanded to any binary detection tasks in which both positive and negative samples are available.\nOur contributions are three-fold: 1) We leverage a novel statistical framework for categorical distributions to devise a learnable measure of relative uncertainty (REL-U) for a model\u2019s predictions, which induces large uncertainty for negative instances, even if they may lead to low Shannon entropy (cf. Section 3); 2) We propose a closed-form solution for training REL-U in the presence of positive and negative instances (cf. Section 4); 3) We report favorable and consistent results over different models and datasets, considering both natural misclassifications within the same statistical population, and in case of distribution shift, or mismatch, between training and testing distributions (cf. Section 5)."
        },
        {
            "heading": "2 RELATED WORKS",
            "text": "Misclassification detection aims to evaluate the reliability of decisions made by classifiers and determine whether they can be trusted or not. A simple baseline relies on the maximum predicted probability (Hendrycks & Gimpel, 2017), but state-of-the-art classifiers have shown to be overconfident in their predictions, even when they fail (Cobb & Looveren, 2022). Liang et al. (2017) proposes applying temperature scaling (Guo et al., 2017) and perturbing the input samples to the direction of the decision boundary to detect misclassifications better. A line of research trains auxiliary parameters to estimate a detection score (Corbi\u00e8re et al., 2019) directly, following the idea of learning to reject (Chow, 1970; Geifman & El-Yaniv, 2017). Exposing the model to outliers or severe augmentations during training has been explored in previous work (Zhu et al., 2023a) to evaluate if these heuristics are beneficial for this particular task apart from improving robustness to outliers. Granese et al. (2021) proposes a mathematical framework and a simple detection method based on the estimated probability of error. We show that their proposed detection metric is a special case of ours. Zhu et al. (2023b) study the phenomenon that calibration methods are most often useless or harmful for failure prediction and provide insights into why. Cen et al. (2023) discusses how training settings such as pre-training or outlier exposure impact misclassification and open-set recognition performance. Related sub-fields are out-of-distribution detection (Lee et al., 2018), open set recognition (Geng et al., 2021), novelty detection (Pimentel et al., 2014), anomaly detection (Chalapathy & Chawla, 2019), adversarial attacks detection (Akhtar & Mian, 2018), and predictive uncertainty estimation via Bayesian Neural Networks estimation (Gal & Ghahramani, 2016; Lakshminarayanan et al., 2016; Mukhoti et al., 2021; Einbinder et al., 2022; Snoek et al., 2019). We refer the reader to Vadera et al. (2020) as a survey in the topic.\nA different take on the problem of uncertainty in AI is conformal learning Angelopoulos et al. (2021); Romano et al. (2020): in addition to estimating the most likely outcome, a conformal predictor provides a \u201cprediction set\u201d that provably contains the ground truth with high probability. Recently, considerable effort has been invested into quantifying uncertainty by disentangling and estimating two quantities: epistemic uncertainty, i.e. the uncertainty that can be decreased by adding new observation to the training set available to a model, and aleatoric uncertainty, which is fundamentally present in the data and cannot be reduced by adding training data. In general, these works rely on inducing higher sensitivity at the level of the network\u2019s internal representation or on modifications to the training procedure or auxiliary models.Liu et al. (2020) proposes to embed a distance-awareness ability in a given neural network by adding spectral normalization to the weights during training so as to translate the distance in the data manifold into dissimilarity at the hidden representation level. Van Amersfoort et al. (2020) proposes a new loss function and centroid updating scheme to speed up the computation of RBF-based nets.Kotelevskii et al. (2022) proposes an approach\nthat provides disentanglement of epistemic and aleatoric uncertainty by computing the agreement between a given model and the Bayes classifier based on their kernel estimate and measuring the point-wise Bayes risk. Finally, Mukhoti et al. (2023) utilizes spectral normalization during training and a feature-space density estimator after training to quantify the epistemic uncertainty disentangling it from the aleatoric one."
        },
        {
            "heading": "3 A DATA-DRIVEN MEASURE OF UNCERTAINTY",
            "text": "Before we introduce our method, we start by stating basic definitions and notations. Then, we describe our statistical model and some useful properties of the underlying detection problem.\nLet X \u2286 Rd be a (possibly continuous) feature space and let Y = {1, . . . , C} denote the label space related to some task of interest. Moreover, we denote by PXY be the underlying joint probability distribution on X \u00d7 Y . We assume that a machine learning model is trained on some training data, which ultimately yields a model that, given samples x \u2208 X , outputs a probability mass function (pmf) on Y , which we denote as a vector p\u0302(x). This may result from a soft-max output layer, for example. A predictor f : X \u2192 Y is then constructed, which yields f(x) = argmaxy\u2208Y p\u0302(x)y . We note that we may also interpret p\u0302(x) as the probability distribution of Y\u0302 on Y , i.e., given X = x, Y\u0302 is distributed according to pY\u0302 |X(y|x) \u225c p\u0302(x)y .\nIn statistics and information theory, many measures of uncertainty were introduced, and some were utilized in machine learning to great effect. Among these are Shannon entropy (Shannon, 1948, Sec. 6), R\u00e9nyi entropy (R\u00e9nyi, 1961), q-entropy (Tsallis, 1988), as well as several divergence measures, capturing a notion of distance between probability distributions, such as Kullback-Leibler divergence (Kullback & Leibler, 1951), f -divergence (Csisz\u00e1r, 1964), and R\u00e9nyi divergence (R\u00e9nyi, 1961). These definitions are well motivated, axiomatically and/or by their use in coding theorems. While some measures of uncertainty offer flexibility by choosing parameters, e.g., \u03b1 for R\u00e9nyi \u03b1-entropy, they are invariant w.r.t. relabeling of the underlying label space. In our case, however, this semantic meaning of specific labels can be important and we do not expect a useful measure of \u201crelative\u201d uncertainty to satisfy this invariance property.\nRecall that the quantity p\u0302(x) is the soft-prediction output by the model given the input x. The entropy measure of Shannon (Shannon, 1948, Sec. 6)\nH(Y\u0302 |x) \u225c \u2212 \u2211 y\u2208Y p\u0302(x)y log (p\u0302(x)y) (1)\nand the concentration measure of Gini (Gini, 1912) sgini(x) \u225c 1\u2212 \u2211 y\u2208Y (p\u0302(x)y) 2 (2)\nhave commonly been used to measure the dispersion of a categorical random variable Y\u0302 given a sample x. It is worth to emphasize that either measure may be used to carry out an analysis of\ndispersion for a random variable predicting a discrete value (e.g., a label). This is comparable to the analysis of variance for the prediction of continuous random values.\nRegrettably, these measures suffer from two major inconveniences: they are invariant to relabeling of the underlying label space, and, more importantly, they lead to very low values for overconfident predictions, even if they are wrong. These observations make both Shannon entropy and the Gini coefficient unfit for our purpose, i.e., the detection of misclassification instances. Evidently, we need a novel measure of uncertainty that can operate on probability distributions p\u0302(x) and that allows us to identify meaningful patterns in the distribution from which uncertainty can be inferred from data. To overcome the aforementioned difficulties, we propose to construct a class of uncertainty measures that is inspired by the measure of diversity investigated in Rao (1982), defined as\nsd(x) \u225c E[d(Y\u0302 , Y\u0302 \u2032)|X = x] = \u2211 y\u2208Y \u2211 y\u2032\u2208Y d(y, y\u2032)p\u0302(x)yp\u0302(x)y\u2032 , (3)\nwhere d \u2208 D is in a class of distance measures and, given X = x, the random variables Y\u0302 , Y\u0302 \u2032 \u223c p\u0302(x) are independently and identically distributed according to p\u0302(x). The statistical framework we are introducing here offers great flexibility by allowing for an arbitrary function d that can be learned from data, as opposed to fixing a predetermined distance as in Rao (1982). In essence, we regard the uncertainty in equation 3 as relative to a given observer d, which appears as a parameter in the definition. To the best of our knowledge, this is a fundamentally novel concept of uncertainty."
        },
        {
            "heading": "4 FROM UNCERTAINTY TO MISCLASSIFICATION DETECTION",
            "text": "We wish to perform misclassification detection based on the statistical properties of soft-predictions of machine learning systems. In essence, the resulting problem requires a binary hypothesis test, which, given a probability distribution over the class labels (the soft-prediction), decides whether a misclassification event likely occurred. We follow the intuition that by examining the soft-prediction of categories corresponding to a given sample, the patterns present in this distribution can provide meaningful information to detect misclassified samples. For example, if a sample is misclassified, this can cause a significant shift in the soft-prediction, even if the classifier is still overconfident. From a broad conceptual standpoint, examining the structure of the population of predicted distributions is very different from the Shannon entropy of a categorical variable. We are primarily interested in the different distributions that we can distinguish from each other by means of positive (correctly classified) and negative (incorrectly classified) instances."
        },
        {
            "heading": "4.1 MISCLASSIFICATION DETECTION BACKGROUND",
            "text": "We define the indicator of the misclassification event as E(X) \u225c 1[f(X) \u0338= Y ]. The occurrence of the \u201cmisclassification\" event is then characterized by E = 1. Misclassification detection is a standard binary classification problem, where E needs to be estimated from X. We will denote the misclassification detector as g : X \u2192 {0, 1}. The underlying pdf pX can be expressed as a mixture of two random variables: X+ \u223c pX|E(x|0) (positive instances) and X\u2212 \u223c pX|E(x|1) (negative instances), where pX|E(x|1) and pX|E(x|0) represent the pdfs conditioned on the error event and the event of correct classification, respectively.\nLet s : X \u2192 R be the uncertainty measure in (3) that assigns a score s(x) to every sample x in the input space X . We can derive a misclassification detector g by fixing a threshold \u03b3 \u2208 R, g(x; s, \u03b3) = 1 [s(x) \u2264 \u03b3], where g(x) = 1 means that the input sample x is detected as being E = 1. In Granese et al. (2021), the authors propose to use the Gini coefficient (2) as a measure of uncertainty, which is equivalent to the R\u00e9nyi entropy of order two, i.e., H2(Y\u0302 |x) = \u2212 log \u2211 y\u2208Y (p\u0302(x)y) 2."
        },
        {
            "heading": "4.2 A DATA-DRIVEN MEASURE OF RELATIVE UNCERTAINTY FOR MODEL\u2019S PREDICTIONS",
            "text": "We first rewrite sd(x) (3) in order to make it amenable to learning the metric d. By defining the C \u00d7 C matrix D \u225c (dij) using dij = d(i, j), we have sd(x) = p\u0302(x)D p\u0302(x)\u22a4. For sd(x) to yield a good detector g, we design a contrastive objective, where we would like E[sd(X+)], which is the expectation over the positive samples, to be small compared to the expectation over negative samples,\ni.e., E[sd(X\u2212)]. This naturally yields the following objective function, where we assume the usual properties of a distance function d(y, y) = 0 and d(y\u2032, y) = d(y, y\u2032) \u2265 0 for all y, y\u2032 \u2208 Y . Definition 1. Let us introduce our objective function with hyperparameter \u03bb \u2208 [0, 1],\nL(D) \u225c (1\u2212 \u03bb) \u00b7 E [ p\u0302(X+)D p\u0302(X+) \u22a4]\u2212 \u03bb \u00b7 E [p\u0302(X\u2212)D p\u0302(X\u2212)\u22a4] (4) and for a fixed K \u2208 R+, define our optimization problem as follows: minimizeD\u2208RC\u00d7C L(D) subject to dii = 0, \u2200i \u2208 Y dij \u2265 0, \u2200i, j \u2208 Y dij = dji, \u2200i, j \u2208 Y Tr(DD\u22a4) \u2264 K (5)\nThe first constraint in equation 5 states that the elements along the diagonal are zeros, which ensures that the uncertainty measure is zero when the distribution is concentrated at a single point. The second constraint ensures that all elements are non-negative, which is a natural condition, so the measure of uncertainty is non-negative. The natural symmetry between two elements stems from the third constraint, while the last constraint imposes a constant upper-bound on the Frobenius norm of the matrix D, guaranteeing that a solution for the underlying optimization problem exists. Proposition 1 (Closed form solution). The constrained optimization problem defined in (5) admits a closed form solution D\u2217 = 1Z (d \u2217 ij), where\nd\u2217ij = ReLU ( \u03bb \u00b7 E [ p\u0302(X\u2212) \u22a4 i p\u0302(X\u2212)j ] \u2212 (1\u2212 \u03bb) \u00b7 E [ p\u0302(X+) \u22a4 i p\u0302(X+)j ]) i \u0338= j\n0 i = j . (6)\nThe multiplicative constant Z is chosen such that D\u2217 satisfies the condition Tr(D\u2217(D\u2217)\u22a4) = K.\nThe proof is based on a Lagrangian approach and relegated to Appendix A.1. Algorithm 1 in Appendix A.2, summarizes all the main steps for the empirical evaluation, including the data preparation and the computation of the matrix D\u2217.\nNote that, apart from the zero diagonal and up to normalization, D\u2217 = ReLU ( \u03bb \u00b7 E [ p\u0302(X\u2212) \u22a4p\u0302(X\u2212) ] \u2212 (1\u2212 \u03bb) \u00b7 E [ p\u0302(X+) \u22a4p\u0302(X+) ] ) . (7)\nFinally, we define the Relative Uncertainty (REL-U) score for a given sample x as\nsREL-U(x) \u225c p\u0302(x)D \u2217 p\u0302(x)\u22a4. (8)\nRemark. (2) is a special case of (8) when dij = 1 if i \u0338= j and dii = 0. Thus, s1\u2212d(x) = sgini(x) when choosing d to be the Hamming distance, which was also pointed out in (Rao, 1982, Note 1)."
        },
        {
            "heading": "5 EXPERIMENTS AND DISCUSSION",
            "text": "In this section, validate our measure of uncertainty in the context of misclassification detection, considering both the case when the training and test distributions match (cf. Section 5.1), and the case in which the two distributions mismatch (cf. Section 5.2). Although our method requires additional positive and negative instances, we show that lower amounts are needed (hundreds or few thousands) compared to methods that involve re-training or fine-tuning (hundreds of thousands)."
        },
        {
            "heading": "5.1 MISCLASSIFICATION DETECTION ON MATCHED DATA",
            "text": "We designed our experiments as follows: for a given model architecture and dataset, we trained the model on the training dataset. We split the test set into two sets: one portion for tuning the detector (held out validation set) and the other for evaluating it. Consequently, we can compute all hyperparameters in an unbiased way and cross-validate performance over many splits generated from ten random seeds. For ODIN (Liang et al., 2017) and Doctor (Granese et al., 2021), we found\nthe best temperature (T ) and input pre-processing magnitude perturbation (\u03f5). For our method, we tuned the best lambda parameter (\u03bb), T , and \u03f5. For details on temperature and input pre-processing equations, see Appendix A.6. As of evaluation metric, we consider the false positive rate (fraction of misclassifications detected as being correct classifications) when 95% of data is true positive (fraction of correctly classified samples detected as being correct classifications), denoted as FPR at 95% TPR (lower is better). AUROC results are similar among methods (see Figure 6 in the appendix).\nTable 1 showcases the misclassification detection performance in terms of FPR at 95% TPR of our method and the strongest baselines (MSP (Hendrycks & Gimpel, 2017), ODIN (Liang et al., 2017), Doctor (Granese et al., 2021)) on different neural network architectures (DenseNet-121 (Huang et al., 2017), ResNet-34 (He et al., 2016)) trained on different datasets (CIFAR-10, CIFAR-100 (Krizhevsky, 2009)) with different learning objectives (Cross-entropy loss, LogitNorm (Wei et al., 2022), MixUp (Zhang et al., 2017), RegMixUp (Pinto et al., 2022), OpenMix (Zhu et al., 2023a)). Please refer to Appendix A.3 for details on the baseline methods. We observe that, on average, our method performs best 11/20 experiments and is equal to the second best in 4/9 out of the remaining experiments. It works consistently better on all the models trained with cross-entropy loss and the models trained with RegMixUp objective, which achieved the best accuracy among them. We observed some negative results when training with logit normalization, but also, the accuracy of the base model decreased. Results for Bayesian methods for uncertainty estimation such as Deep Ensembles (Lakshminarayanan et al., 2016) and MCDropout (Gal & Ghahramani, 2016), as well as results for an MLP directly trained on the tuning data are reported in Table 3 in the Appendix A.6. We report superior detection capabilities for the task at hand.\nFigure 2 displays how the amount of data reserved for the tuning split impacts the performance of the best two detection methods. We demonstrate how our data-driven uncertainty estimation metric generally improves with the amount of data fed to it in the tuning phase, especially on a more challenging setup such as on the CIFAR-100 model.\nTraining losses or regularization is independent of detection. Previous work highlights the independence of training objectives from detection methods, which challenges the meaningfulness of evaluations. In particular, we identify three major limitations in (Zhu et al., 2023a): The evaluation of post-hoc methods, such as Doctor and ODIN, lacks consideration of perturbation and temperature hyperparameters. Despite variations in accuracy and the absence of measures for coverage and risk, different training methods are evaluated collectively. Furthermore, the post-hoc methods are not assessed on these models. The primary flaw in their analysis stems from evaluating different detectors on distinct models, leading to comparisons between (models, detectors) tuples that have different\nmisclassification rates. As a result, such an analysis may fail to determine the most performant detection method in real-world scenarios.\nDoes calibration improve detection? There has been growing interest in developing machine learning algorithms that are not only accurate but also well-calibrated, especially in applications where reliable probability estimates are desirable. In this section, we investigate whether models with calibrated probability predictions help improve the detection capabilities of our method or not. Previous work (Zhu et al., 2023b) has shown that calibration does not particularly help or impact misclassification detection on models with similar accuracies, however, they focused only on calibration methods and overlooked detection methods.\nTo assess this problem in the optics of misclassification detectors, we calibrated the soft-probabilities of the models with a temperature parameter (Guo et al., 2017). Note that this temperature is not necessarily the same value as the detection hyperparameter temperature. This calibration method is simple and effective, achieving performance close to state-of-the-art (Minderer et al., 2021). To measure how calibrated the model is before and after temperature scaling, we measured the expected calibration error (ECE) (Guo et al., 2017) before, with T = 1, and after calibration. We obtained the optimal temperature after a cross-validation procedure on the tuning set and measured the detection performance of the detection methods over the calibrated model on the test set. For the detection methods, we use the optimal temperature obtained from calibration, and no input pre-processing is conducted (\u03f5 = 0), to observe precisely what is the effect of calibration. We set \u03bb = 0.5.\nTable 2 shows the detection performance over the calibrated models. We cannot conclude much from the CIFAR benchmark as the models are already well-calibrated out of the training, with ECE of around 0.03. In general, calibrating the models slightly improved performance on this benchmark. However, for the ImageNet benchmark, we observe that Doctor gained a lot from the calibration, while REL-U remained more or less invariant to calibration on ImageNet, suggesting that the performance of REL-U is robust under the model\u2019s calibration."
        },
        {
            "heading": "5.2 MISMATCHED DATA",
            "text": "So far, we have evaluated methods for misclassification detection under the assumption that the data available to learn the uncertainty measure and that during testing are drawn from the same distribution.\nIn this section, we consider cases in which this assumption does not hold true, leading to a mismatch between the generative distributions of the data. Specifically, we investigate two sources of mismatch: i) Datasets with different label domains, where the symbol sets and symbols cardinality are different in each dataset; ii) Perturbation of the feature space domain generated using popular distortion filters. Understanding how machine learning models and misclassification detectors perform under such conditions can help us gauge and evaluate their robustness.\nMismatch from different label domains. We considered pre-trained classifiers on the CIFAR-10 dataset and evaluated their performance in detecting samples in CIFAR-10 and distinguishing them from samples in CIFAR-100, which has a different label domain. Similar experiments have been conducted in Ren et al. (2021); Fort et al. (2021); Zhu et al. (2023a). The test splits were divided into a validation set and an evaluation set, with the validation set consisting of 10%, 20%, 33%, or 50% of the total test split and samples used for training were not reused. For each split, we\ncombine the number of validation samples from CIFAR-10 with an equal number of samples from CIFAR-100. In order to assess the validity of our results, each split has been randomly selected 10 times, and the results are reported in terms of mean and standard deviation in Figure 3. We observe how our proposed data-driven method performs when samples are provided to accurately describe the two groups. In order to reduce the overlap between the two datasets, and in line with previous work (Fort et al., 2021), we removed the classes in CIFAR-100 that most closely resemble the classes in CIFAR-10. For the detailed list of the removed labels, we refer the reader to Appendix A.7.\nMismatch from feature space corruption. We trained a model on the CIFAR-10 dataset and evaluated its ability to detect misclassification on the popular CIFAR-10C corrupted dataset, which contains a version of the classic CIFAR-10 test set perturbed according to 19 different types of corruption and 5 levels of intensities. With this experiment, we aim to investigate if our proposed detector is able to spot misclassifications that arise from input perturbation, based on the sole knowledge of the misclassified patterns within the CIFAR-10 test split.\nConsistent with previous experiments, we ensure that no samples from the training split are reused during validation and evaluation. To explore the effect of varying split sizes, we divide the test splits into validation and evaluation sets, with validation sets consisting of 10%, 20%, 33%, or 50% of the total test split. Each split has been produced 10 times with 10 different seeds and the average of the results has been reported in the spider plots in Figure 4. In the case of datasets with perturbed feature spaces, we solely utilize information from the validation samples in CIFAR-10 to detect misclassifications in the perturbed instances of the evaluation datasets, without using corrupted data during validation. We present visual plots that demonstrate the superior performance achieved by our proposed method compared to other methods. Additionally, for the case of perturbed feature spaces, we introduce radar plots, in which each vertex corresponds to a specific perturbation type, and report results for intensity 5. This particular choice of intensity is motivated by the fact that it creates the most relevant divergence between the accuracy of the model on the original test split and the accuracy of the model on the perturbed test split. Indeed the average gap in accuracy between the original test split and the perturbed test split is reported in Table 5 in Appendix A.8.\nWe observe that our proposed method outperforms Doctor in terms of AUROC and FPR, as demonstrated by the radar plots. As we can see, in the case of CIFAR-10 vs CIFAR-10C, the radar plots (Figure 4) show how the area covered by the AUROC values achieves similar or larger values for the proposed method, indeed confirming that it is able to better detect misclassifications in the\nmismatched data. Moreover, the FPR values are lower for the proposed method. For completeness, we report the error bar tables in Tables 6 and 7, Appendix A.8. Additionally, as a particular case of mismatch from feature space corruption, we have considered the task of detecting mismatch between MNIST and SVHN, the results are reported in Figure 7, Appendix A.8."
        },
        {
            "heading": "5.3 EMPIRICAL INTERPRETATION OF THE RELATIVE UNCERTAINTY MATRIX.",
            "text": "Figure 1 exemplifies the advantage of our method over the entropy-based methods in (1) and (2). In particular, the left-end side heatmap represents the D matrix learned by optimizing (4) on CIFAR10. Darker shades of blue indicate higher uncertainty, while lighter shades of blue indicate lower uncertainty. The central heatmap is the predictor\u2019s class-wise true confusion matrix. The vertical axis represents the true class, while the horizontal axis represents the predicted class. For each combination of two classes ij, the corresponding cell reports the count of samples of class j that were predicted as class i. The correct matches along the diagonal are dashed for better visualization of the mistakes. The confusion matrix is computed on the same validation set used to compute the D matrix. Crucially, our uncertainty matrix can express different degrees of uncertainty depending on the specific combination of classes at hand. Let us focus for instance on the fact that most of the incorrectly classified dogs are predicted as cats, and vice-versa. The matrix D fully captures this by assigning high uncertainty to the cells at the intersection between these two classes. This is not the case for the entropy-based methods, which cannot capture such a fine-grained uncertainty, and assign the same uncertainty to all the cells, regardless of the specific combination of classes at hand."
        },
        {
            "heading": "6 SUMMARY AND CONCLUDING REMARKS",
            "text": "To the best of our knowledge, we are the first to propose REL-U, a method for uncertainty assessment that departs from the conventional practice of directly measuring uncertainty through the entropy of the output distribution. REL-U uses a metric that leverages higher uncertainty score for negative data w.r.t. positive data, e.g., incorrectly and correctly classified samples in the context of misclassification detection, and attains favorable results on matched and mismatched data. In addition, our method stands out for its flexibility and simplicity, as it relies on a closed form solution to an optimization problem. Extensions to diverse problems present both an exciting and promising avenue for future research.\nLimitations. We presented machine learning researchers with a fresh methodological outlook and provided machine learning practitioners with a user-friendly tool that promotes safety in real-world scenarios. Some considerations should be put forward, such as the importance of cross-validating the hyperparameters of the detection methods to ensure their robustness on the targeted data and model. As a data-driven measure of uncertainty, to achieve the best performance, it is important to have enough samples at the disposal to learn the metric from as discussed on Section 5.1. As every detection method, our method may be vulnerable to targeted attacks from malicious users."
        },
        {
            "heading": "ACKNOWLEDGEMENTS",
            "text": "This work has been supported by the project PSPC AIDA: 2019-PSPC-09 funded by BPI-France. This work was granted access to the HPC/AI resources of IDRIS under the allocation 2023 - AD011012803R2 made by GENCI."
        },
        {
            "heading": "A APPENDIX",
            "text": "A.1 PROOF OF PROPOSITION 1\nWe have the optimization problem minimizeD\u2208RC\u00d7C L(D) subject to dii = 0, \u2200i \u2208 {1, . . . , C}; dij \u2212 dji = 0, \u2200i, j \u2208 {1, . . . , C} Tr(DD\u22a4)\u2212K \u2264 0 \u2212dij \u2264 0, \u2200i, j \u2208 {1, . . . , C}\n(9)\nin standard form (Boyd & Vandenberghe, 2004, eq. (4.1)) and can thus apply the KKT conditions (Boyd & Vandenberghe, 2004, eq. (5.49)). We find\n\u2207L(D\u2217)\u2212 \u2211 i,j \u03be\u2217ij\u2207d\u2217ij + \u2211 i \u00b5\u2217i\u2207d\u2217ii + \u2211 ij \u03bd\u2217ij\u2207(d\u2217ij \u2212 d\u2217ji) + \u03ba\u2217\u2207(Tr(D\u2217(D\u2217)\u22a4)\u2212K) = 0\n(10) as well as the constraints\nd\u2217ii = 0 d \u2217 ij \u2212 d\u2217ji = 0 (11) \u2212d\u2217ij \u2264 0 \u03be\u2217ij \u2265 0 (12) \u03be\u2217ijdij = 0 \u03ba\n\u2217 \u2265 0 (13) \u03ba\u2217(Tr(D\u2217(D\u2217)\u22a4)\u2212K) = 0 (14)\nWe have \u2207L(D\u2217) = (1\u2212 \u03bb) \u00b7 E [ p\u0302(X+) \u22a4p\u0302(X+) ] \u2212 \u03bb \u00b7 E [ p\u0302(X\u2212) \u22a4p\u0302(X\u2212) ]\n(15)\n\u2207(Tr(D\u2217(D\u2217)\u22a4)\u2212K) = 2D\u2217 (16) and thus1\n0 = (1\u2212 \u03bb) \u00b7 E [ p\u0302(X+) \u22a4p\u0302(X+) ] \u2212 \u03bb \u00b7 E [ p\u0302(X\u2212) \u22a4p\u0302(X\u2212) ] \u2212 \u03be\u2217 + diag(\u00b5\u2217)\n+ \u03bd\u2217 \u2212 (\u03bd\u2217)\u22a4 + \u03ba\u22172D\u2217 (17)\nD\u2217 = 1\n2\u03ba\u2217\n( \u2212 (1\u2212 \u03bb) \u00b7 E [ p\u0302(X+) \u22a4p\u0302(X+) ] + \u03bb \u00b7 E [ p\u0302(X\u2212) \u22a4p\u0302(X\u2212) ] + \u03be\u2217 \u2212 diag(\u00b5\u2217)\n\u2212 \u03bd\u2217 + (\u03bd\u2217)\u22a4 )\n(18)\nAs\u2207L(D\u2217) in (15) is already symmetric, we can choose \u03bd\u2217 = 0. We choose2 \u00b5\u2217 = diag(\u2207L(D\u2217)) to ensures d\u2217ii = 0. The non-negativity constraint can be satisfied by appropriately choosing 0 \u2264 \u03be\u2217 = ReLU(\u2212\u2207L(D\u2217)). Finally, \u03ba\u2217 is chosen such that the constraint Tr(D\u2217(D\u2217)\u22a4) = K is satisfied. In total, this yields D\u2217 = 1Z ReLU(d \u2217 ij), where\nd\u2217ij =\n{ \u2212 (1\u2212 \u03bb) \u00b7 E [ p\u0302(X+) \u22a4 i p\u0302(X+)j ] + \u03bb \u00b7 E [ p\u0302(X\u2212) \u22a4 i p\u0302(X\u2212)j ] i \u0338= j\n0 i = j . (19)\nThe multiplicative constant Z = 2\u03ba\u2217 > 0 is chosen such that D\u2217 satisfies the condition Tr(D\u2217(D\u2217)\u22a4) = K. Remark. A technical problem may occur when d\u2217ij as defined in (19) is equal to zero for all i, j \u2208 {1, 2, . . . , C}. In this case, D\u2217 cannot be normalized to satisfy Tr(D\u2217(D\u2217)\u22a4) = K and the solution to the optimization problem in (9) is the all-zero matrix D\u2217 = 0. I.e., no learning is performed in this case. We deal with this problem by falling back to the Gini coefficient (2), where similarly no learning is required.\nEquivalently, one may also add a small numerical correction \u03b5 to the definition of the ReLU function, i.e., ReLU(x) = max(x, \u03b5). Using this slightly adapted definition when defining D\u2217 = 1ZReLU(d \u2217 ij) naturally yields the Gini coefficient in this case. 1We use X = diag(x) for a vector x to obtain a matrix X with x on the diagonal and zero otherwise. 2Slightly abusing notation, we also write x = diag(X) to obtain the diagonal of the matrix X as a vector x.\nA.2 ALGORITHM\nIn this section, we introduce a comprehensive algorithm to clarify the computation of the relative uncertainty matrix D\u2217.\nAlgorithm 1 Offline relative uncertainty matrix computation.\nRequire: p\u0302 : X 7\u2192 RC trained on a training set with C classes, validation set Dm = {(xj , yj) \u223c i.i.d\npXY }mj=1, and hyperparameter \u03bb \u2208 [0, 1]\nD+m \u2190 \u2205, D\u2212m \u2190 \u2205 \u25b7 Initialize empty positive and negative sets for (x, y) \u2208 Dm do \u25b7 Fill the respective sets with positive or negative samples\nif argmaxy\u2032\u2208Y p\u0302(x)y\u2032 = y then D+m \u2190 D+m \u222a {p\u0302(x)} else D\u2212m \u2190 D\u2212m \u222a {p\u0302(x)}\nend if end for \u00b5+ \u2190 1|D+m| \u2211 p\u0302\u2208D+m p\u0302 \u22a4p\u0302, \u00b5\u2212 \u2190 1|D\u2212m| \u2211 p\u0302\u2208D\u2212m p\u0302 \u22a4p\u0302 D\u2217 \u2190 0C\u00d7C \u25b7 C by C square matrix with zeroed out elements for i\u2190 1, i \u2264 C, i\u2190 i+ 1 do \u25b7 Build D\u2217 according to (6)\nfor j \u2190 1, j \u2264 C, j \u2190 j + 1 do if i \u0338= j then d\u2217ij \u2190 max ( \u03bb\u00b5\u2212ij \u2212 (1\u2212 \u03bb)\u00b5 + ij , 0 ) end if\nend for end for return D\u2217\nAt test time, it suffices to compute (8) to obtain the relative uncertainty of the prediction.\nA.3 DETAILS ON BASELINES AND BENCHMARKS\nIn this section, we provide a comprehensive review of the baselines used on our benchmarks. We state the definitions using our notation introduced in Section 3.\nA.3.1 MSP\nThe Maximum Softmax Probability (MSP) baseline Hendrycks & Gimpel (2017) proposes to use the confidence of the network as a detection score:\nsMSP(x) = max y\u2208Y p\u0302(x)y (20)\nA.3.2 ODIN\nLiang et al. (2017) improve upon Hendrycks & Gimpel (2017) by introducing temperature scaling and input pre-processing techniques as described in Appendix A.4, and then compute (20) as the detection score. We tune hyperparameters T and \u03f5 on a validation set for each pair of network and training procedure.\nA.3.3 DOCTOR\nGranese et al. (2021) propose (2) as the detection score and applies temperature scaling and input pre-processing as described in Appendix A.4. Likewise, we tune hyperparameters T and \u03f5 on a validation set for each pair of network and training procedure.\nA.3.4 MLP\nWe trained an MLP with two hidden layers of 128 units with ReLU activation function and dropout with p = 0.2 on top of the hidden representations with a binary cross entropy objective on the\nvalidation set with Adam optimizer and learning rate equal to 10\u22123 until convergence. Results on misclassification are presented in Table 3.\nA.3.5 MCDROPOUT\nGal & Ghahramani (2016) propose to approximate Bayesian NNs by performing multiple forward passes with dropout enabled. To compute the confidence score, we averaged the logits and computed the Shannon entropy defined in (1). We set the number of inferences hyperparameter to k = 10 and we set the dropout probability to p = 0.2. Results on misclassification are presented in Table 3.\nA.3.6 DEEP ENSEMBLES\nLakshminarayanan et al. (2016) propose to approximate Bayesian NNs by averaging the forward pass of multiple models trained on different initializations. We ran experiments with k = 5 different random seeds. To compute the confidence score, we averaged logits and computed the MSP response (20). Results on misclassification are presented in Table 3.\nA.3.7 CONFORMAL PREDICTIONS\nAccording to conformal learning Angelopoulos & Bates (2021); Angelopoulos et al. (2021); Romano et al. (2020) the presence of uncertainty in predictions is dealt by providing, in addition to estimating the most likely outcome\u2014actionable uncertainty quantification, a \u201cprediction set\u201d that provably \u201ccovers\u201d the ground truth with a high probability. This means that the predictor implements an uncertainty set function, i.e., a function that returns a set of labels and guarantees the presence of the right label within the set with a high probability for a given distribution.\nA.3.8 LOGITNORM\nWei et al. (2022) observe that the norm of the logit keeps increasing during training, leading to overconfident predictions. So, they propose Training neural networks with logit normalization to hopefully produce more distinguishable confidence scores between in- and out-of-distribution data. They propose normalizing the logits of the cross entropy loss, resulting in the following loss function:\n\u2113(f(x), y) = \u2212 log exp fy(x)/(T\u2225p\u0302(x)\u22252)\u2211C i=1 exp fi(x)/(T\u2225p\u0302(x)\u22252) . (21)\nA.3.9 MIXUP\nZhang et al. (2017) propose to train a neural network on convex combinations of pairs of examples and their label to minimize the empirical vicinal risk. The mixup data is defined as\nx\u0303 = \u03bbxi + (1\u2212 \u03bb)xj and y\u0303 = \u03bbyi + (1\u2212 \u03bb)yj for i, j \u2208 {1, ..., n}, (22) where \u03bb is sampled according to a Beta(\u03b1, \u03b1) distribution. We used \u03b1 = 1.0 to train the models. Observe a slight abuse of notation here, where y is actually an one-hot encoding of the labels y = [1y=1, . . . ,1y=C ] \u22a4.\nA.3.10 REGMIXUP\nPinto et al. (2022) use the cross entropy of the mixup data as in (22) with \u03bb sampled according to a Beta(10, 10) distribution as a regularizer of the classic cross entropy loss for training a network. The objective is balanced with a hyperparameter \u03b3, usually set to 0.5.\nA.3.11 OPENMIX\nZhu et al. (2023a) explicitly add an extra class for outlier samples and uses mixup as a regularizer for the cross entropy loss, but mixing between inlier training samples and outlier samples collected from the wild. It yields the objective\nL = EDinlier [\u2113(f(x), y)] + \u03b3EDoutlier [\u2113(f(x\u0303), y\u0303)], (23) where \u03b3 \u2208 R+ is a hyperparameter, x\u0303 = \u03bbxinlier + (1\u2212 \u03bb)xoutlier, and y\u0303 = \u03bbyinlier + (1\u2212 \u03bb)(C + 1) with a slight abuse of notation. The parameter \u03bb is sampled according to a Beta(10, 10) distribution.\nA.4 TEMPERATURE SCALING AND INPUT PRE-PROCESSING\nTemperature scaling involves the use of a scalar coefficient T \u2208 R+ that divides the logits of the network before computing the softmax. This affects the network confidence and the posterior output probability distribution. Larger values of T induce a more flat posterior distribution and smaller values, peakier responses. The final temperature-scaled-softmax function is given by:\n\u03c3(z) = exp (z/T )\u2211 j exp (zj/T ) .\nMoreover, the perturbation is applied to the input image in order to increase the network \u201csensitivity\" to the input. In particular, the perturbation is given by:\nx\u2032 = x\u2212 \u03f5\u00d7 sign [\u2212\u2207x log (sREL-U(x)] ,\nfor \u03f5 > 0. Note that sREL-U(\u00b7) is replaced by the scoring functions of ODIN (20), and Doctor (2) to compute input pre-processing in their respective experiments.\nA.5 ADDITIONAL COMMENTS ON THE ABLATION STUDY FOR HYPER-PARAMETER SELECTION\nAblation study. We conducted ablation studies on all relevant parameters: T , \u03f5, and \u03bb. It is crucial to emphasize that T is intrinsic to the network architecture and, therefore, must not be considered a hyper-parameter for REL-U. Figure 5 illustrates three ablation studies conducted to analyze and comprehend the effects of different factors on the experimental results. Each subplot represents each hyperparameter ablation study, showcasing the outcomes obtained under specific conditions. We observe that \u03bb \u2265 0.5, low temperatures, and low noise magnitude achieve better performance. Overall, the method is shown to be robust to the choices of hyperparameters under reasonable ranges.\nAdditionally, the introduction of additive noise \u03f5 serves the purpose of ensuring a fair comparison with Doctor/ODIN, where the noise was utilized to enhance detection performance. Nevertheless, as indicated by the results in the ablation study illustrated in Figure 5, \u03f5 = 0 seems to be close to optimal most of the time, thereby positioning REL-U as an effective algorithm that relies only on the soft-probability output, therefore comparable to Granese et al. (2021); Liang et al. (2018) in their version with no perturbation, and Hendrycks & Gimpel (2017). Furthermore, REL-U exhibits a considerable degree of insensitivity to various values of \u03bb, as evident from Figure 5. This suggests that a potential selection for \u03bb could have been \u03bb = N+/(N+ +N\u2212), aiming to balance the ratio between the number of positive (N+) and negative (N\u2212) examples. In such a scenario, there are no hyper-parameters at all.\nA.6 ADDITIONAL RESULTS ON MISCLASSIFICATION DETECTION\nBayesian methods. In this paragraph, we compare our method to additional uncertainty estimation methods, such as Deep Ensembles (Lakshminarayanan et al., 2016), MCDropout (Gal & Ghahramani, 2016), and a MLP directly trained on the validation data used to tune the relative uncertainty matrix. The results are available in Table 3.\nROC and Risk-Coverage curves. We also display the ROC and the risk-coverage curves for our main benchmark on models trained on CIFAR-10 with cross entropy loss. We observe that the performance of REL-U is comparable to other methods in terms of AUROC while outperforming them in high-TPR regions and reducing the risk of classification errors when abstention is desired (coverage) as observed in Figure 6.\nPerformance of conformal prediction. We take into account the application of conformal predictors applied to the problem of misclassification. In particular, we consider the excellent work in Angelopoulos & Bates (2021), but most importantly Angelopoulos et al. (2021), which, in turn, builds upon Romano et al. (2020). Conformal predictors, in stark contrast with standard prediction\nmodels, learn a \u201cprediction set function\u201d, i.e. they return a set of labels, which should contain the correct value with high probability, for a given data distribution. In particular, Angelopoulos et al. (2021) proposed a revision of Romano et al. (2020), with the main objective of preserving the guarantees of conformal prediction, while, at the same time, minimizing the prediction set cardinality on a sample basis: samples that are \u201charder\u201d to classify can produce larger sets than samples that are easier to correctly classify. The models are \u201cconformalized\u201d (cf. Angelopoulos et al. (2021)) using the same validation samples, that are also available to the other methods. We reject the decision if the second largest probability within the prediction set exceeds a given threshold, as then, the prediction set would contain more than one label, indicating a possible misclassification event. The experiments are run on 2 models, 2 datasets and 3 training techniques for a total of 12 additional numerical results reported in Table 4. For the model trained with cross entropy in Table 4, the area\nunder the ROC curve, averaged over 10 seeds, is 0.92 (0.7) for the DenseNet-121 conformalized model on CIFAR-10, and 0.93 (0.7) for the ResNet-34 conformalized model on CIFAR-10, showing comparable results w.r.t. the results in Figures 6a and 6b.\nA.7 MISMATCH FROM DIFFERENT LABEL DOMAINS\nIn order to reduce the overlap between the label domain of CIFAR-10 and CIFAR-100, in this experimental setup we have ignored the samples corresponding to the following classes in CIFAR100: bus, camel, cattle, fox, leopard, lion, pickup truck, streetcar, tank, tiger, tractor, train, and wolf.\nA.8 MISMATCH FROM DIFFERENT FEATURE SPACE CORRUPTION\nTable 5: We report the gap in accuracy between the original and the corrupted test set for the considered model. The gap is reported and average and standard deviation over the 19 different types of corruptions for corruption intensity equal to 5. The maximum and minimum gap are also reported, with the relative corruption type.\nArchitecture Average gap Max gap Min gap\nDenseNet121 0.36\u00b1 0.18 0.66 (Gaussian Blur) 0.04 (Brightness) ResNet34 0.35\u00b1 0.20 0.72 (Impulse Noise) 0.03 (Brightness)\nTable 6: DenseNet-121, error bar table, mismatch from different feature space corruption\nDoctor REL-U\nCorruption Split (%) AUC FPR AUC FPR\nBrightness"
        },
        {
            "heading": "10 0.90 \u00b1 0.00 0.31 \u00b1 0.00 0.90 \u00b1 0.01 0.35 \u00b1 0.03",
            "text": ""
        },
        {
            "heading": "20 0.90 \u00b1 0.00 0.31 \u00b1 0.00 0.90 \u00b1 0.00 0.32 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.90 \u00b1 0.00 0.31 \u00b1 0.00 0.90 \u00b1 0.00 0.32 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.90 \u00b1 0.00 0.31 \u00b1 0.00 0.90 \u00b1 0.00 0.32 \u00b1 0.00",
            "text": "Contrast"
        },
        {
            "heading": "10 0.66 \u00b1 0.02 0.77 \u00b1 0.03 0.73 \u00b1 0.02 0.70 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "20 0.66 \u00b1 0.02 0.77 \u00b1 0.02 0.73 \u00b1 0.01 0.69 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "33 0.67 \u00b1 0.01 0.76 \u00b1 0.01 0.74 \u00b1 0.01 0.68 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.66 \u00b1 0.01 0.77 \u00b1 0.01 0.74 \u00b1 0.01 0.67 \u00b1 0.01",
            "text": "Defocus blur"
        },
        {
            "heading": "10 0.70 \u00b1 0.01 0.75 \u00b1 0.00 0.72 \u00b1 0.03 0.71 \u00b1 0.05",
            "text": ""
        },
        {
            "heading": "20 0.70 \u00b1 0.01 0.75 \u00b1 0.00 0.73 \u00b1 0.01 0.69 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.70 \u00b1 0.00 0.75 \u00b1 0.00 0.73 \u00b1 0.01 0.70 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.70 \u00b1 0.00 0.75 \u00b1 0.00 0.73 \u00b1 0.01 0.71 \u00b1 0.01",
            "text": "Elastic transform"
        },
        {
            "heading": "10 0.80 \u00b1 0.01 0.56 \u00b1 0.00 0.81 \u00b1 0.01 0.55 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "20 0.80 \u00b1 0.01 0.56 \u00b1 0.00 0.82 \u00b1 0.00 0.53 \u00b1 0.02",
            "text": "33 0.80 \u00b1 0.00 0.56 \u00b1 0.00 0.82 \u00b1 0.00 0.53 \u00b1 0.01 50 0.80 \u00b1 0.00 0.56 \u00b1 0.00 0.82 \u00b1 0.00 0.53 \u00b1 0.01\nFog"
        },
        {
            "heading": "10 0.76 \u00b1 0.01 0.63 \u00b1 0.01 0.79 \u00b1 0.01 0.56 \u00b1 0.03",
            "text": ""
        },
        {
            "heading": "20 0.76 \u00b1 0.01 0.63 \u00b1 0.01 0.79 \u00b1 0.01 0.55 \u00b1 0.02",
            "text": "33 0.77 \u00b1 0.00 0.63 \u00b1 0.01 0.80 \u00b1 0.00 0.56 \u00b1 0.02 50 0.77 \u00b1 0.00 0.63 \u00b1 0.00 0.80 \u00b1 0.00 0.55 \u00b1 0.01\nFrost"
        },
        {
            "heading": "10 0.78 \u00b1 0.00 0.62 \u00b1 0.00 0.79 \u00b1 0.01 0.61 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "20 0.78 \u00b1 0.00 0.62 \u00b1 0.00 0.79 \u00b1 0.01 0.59 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "33 0.78 \u00b1 0.00 0.62 \u00b1 0.00 0.80 \u00b1 0.00 0.59 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.78 \u00b1 0.00 0.62 \u00b1 0.00 0.80 \u00b1 0.00 0.59 \u00b1 0.01",
            "text": "Gaussian blur"
        },
        {
            "heading": "10 0.60 \u00b1 0.00 0.84 \u00b1 0.00 0.61 \u00b1 0.05 0.82 \u00b1 0.05",
            "text": ""
        },
        {
            "heading": "20 0.60 \u00b1 0.00 0.84 \u00b1 0.00 0.63 \u00b1 0.03 0.82 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "33 0.60 \u00b1 0.00 0.84 \u00b1 0.00 0.62 \u00b1 0.02 0.82 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.60 \u00b1 0.00 0.84 \u00b1 0.00 0.61 \u00b1 0.02 0.83 \u00b1 0.01",
            "text": "Gaussian noise"
        },
        {
            "heading": "10 0.70 \u00b1 0.00 0.72 \u00b1 0.00 0.69 \u00b1 0.02 0.73 \u00b1 0.02",
            "text": "20 0.70 \u00b1 0.00 0.72 \u00b1 0.00 0.71 \u00b1 0.01 0.72 \u00b1 0.01"
        },
        {
            "heading": "33 0.70 \u00b1 0.00 0.72 \u00b1 0.00 0.70 \u00b1 0.01 0.73 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.70 \u00b1 0.00 0.72 \u00b1 0.00 0.70 \u00b1 0.01 0.73 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "10 0.72 \u00b1 0.00 0.73 \u00b1 0.00 0.71 \u00b1 0.01 0.73 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "20 0.72 \u00b1 0.00 0.73 \u00b1 0.00 0.72 \u00b1 0.01 0.72 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.72 \u00b1 0.00 0.73 \u00b1 0.00 0.72 \u00b1 0.01 0.73 \u00b1 0.00",
            "text": ""
        },
        {
            "heading": "50 0.72 \u00b1 0.00 0.73 \u00b1 0.00 0.72 \u00b1 0.00 0.73 \u00b1 0.00",
            "text": ""
        },
        {
            "heading": "10 0.62 \u00b1 0.00 0.85 \u00b1 0.00 0.61 \u00b1 0.03 0.84 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "20 0.62 \u00b1 0.00 0.85 \u00b1 0.00 0.63 \u00b1 0.02 0.83 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.62 \u00b1 0.00 0.85 \u00b1 0.00 0.62 \u00b1 0.01 0.84 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.62 \u00b1 0.00 0.85 \u00b1 0.00 0.62 \u00b1 0.01 0.84 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "10 0.81 \u00b1 0.00 0.58 \u00b1 0.00 0.80 \u00b1 0.01 0.56 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "20 0.81 \u00b1 0.00 0.58 \u00b1 0.00 0.80 \u00b1 0.00 0.55 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.81 \u00b1 0.00 0.58 \u00b1 0.00 0.81 \u00b1 0.00 0.55 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.81 \u00b1 0.00 0.58 \u00b1 0.00 0.81 \u00b1 0.00 0.55 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "10 0.78 \u00b1 0.01 0.63 \u00b1 0.00 0.81 \u00b1 0.01 0.56 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "20 0.78 \u00b1 0.01 0.63 \u00b1 0.00 0.82 \u00b1 0.01 0.53 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "33 0.78 \u00b1 0.00 0.63 \u00b1 0.00 0.82 \u00b1 0.00 0.54 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "50 0.78 \u00b1 0.00 0.63 \u00b1 0.00 0.82 \u00b1 0.00 0.54 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "10 0.68 \u00b1 0.00 0.82 \u00b1 0.00 0.68 \u00b1 0.03 0.80 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "20 0.68 \u00b1 0.00 0.82 \u00b1 0.00 0.67 \u00b1 0.03 0.81 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.68 \u00b1 0.00 0.82 \u00b1 0.00 0.66 \u00b1 0.02 0.81 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.68 \u00b1 0.00 0.82 \u00b1 0.00 0.67 \u00b1 0.02 0.81 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "10 0.89 \u00b1 0.00 0.37 \u00b1 0.01 0.88 \u00b1 0.01 0.39 \u00b1 0.03",
            "text": ""
        },
        {
            "heading": "20 0.89 \u00b1 0.00 0.37 \u00b1 0.01 0.88 \u00b1 0.00 0.36 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.89 \u00b1 0.00 0.37 \u00b1 0.00 0.88 \u00b1 0.00 0.37 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.89 \u00b1 0.00 0.37 \u00b1 0.00 0.88 \u00b1 0.00 0.36 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "10 0.71 \u00b1 0.00 0.72 \u00b1 0.00 0.72 \u00b1 0.02 0.72 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "20 0.71 \u00b1 0.00 0.72 \u00b1 0.00 0.73 \u00b1 0.01 0.70 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "33 0.71 \u00b1 0.00 0.72 \u00b1 0.00 0.73 \u00b1 0.01 0.70 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.71 \u00b1 0.00 0.72 \u00b1 0.00 0.73 \u00b1 0.01 0.71 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "10 0.81 \u00b1 0.00 0.60 \u00b1 0.00 0.81 \u00b1 0.01 0.57 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "20 0.81 \u00b1 0.00 0.60 \u00b1 0.00 0.81 \u00b1 0.01 0.57 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "33 0.81 \u00b1 0.00 0.60 \u00b1 0.00 0.81 \u00b1 0.00 0.57 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.81 \u00b1 0.00 0.60 \u00b1 0.00 0.81 \u00b1 0.00 0.57 \u00b1 0.00",
            "text": ""
        },
        {
            "heading": "10 0.78 \u00b1 0.00 0.80 \u00b1 0.00 0.77 \u00b1 0.02 0.80 \u00b1 0.04",
            "text": ""
        },
        {
            "heading": "20 0.78 \u00b1 0.00 0.80 \u00b1 0.00 0.77 \u00b1 0.01 0.79 \u00b1 0.03",
            "text": ""
        },
        {
            "heading": "33 0.78 \u00b1 0.00 0.80 \u00b1 0.00 0.77 \u00b1 0.01 0.80 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "50 0.78 \u00b1 0.00 0.80 \u00b1 0.00 0.77 \u00b1 0.00 0.80 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "10 0.73 \u00b1 0.00 0.68 \u00b1 0.00 0.74 \u00b1 0.02 0.67 \u00b1 0.03",
            "text": ""
        },
        {
            "heading": "20 0.73 \u00b1 0.00 0.68 \u00b1 0.00 0.75 \u00b1 0.01 0.65 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "33 0.73 \u00b1 0.00 0.68 \u00b1 0.00 0.75 \u00b1 0.01 0.65 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.73 \u00b1 0.00 0.68 \u00b1 0.00 0.75 \u00b1 0.01 0.66 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "10 0.73 \u00b1 0.01 0.72 \u00b1 0.01 0.76 \u00b1 0.01 0.67 \u00b1 0.04",
            "text": ""
        },
        {
            "heading": "20 0.73 \u00b1 0.01 0.71 \u00b1 0.00 0.76 \u00b1 0.01 0.65 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "33 0.73 \u00b1 0.00 0.72 \u00b1 0.00 0.77 \u00b1 0.01 0.66 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "50 0.73 \u00b1 0.00 0.72 \u00b1 0.00 0.77 \u00b1 0.01 0.67 \u00b1 0.01",
            "text": "Doctor REL-U\nCorruption Split (%) AUC FPR AUC FPR\nBrightness"
        },
        {
            "heading": "10 0.91 \u00b1 0.00 0.30 \u00b1 0.02 0.91 \u00b1 0.01 0.33 \u00b1 0.06",
            "text": ""
        },
        {
            "heading": "20 0.91 \u00b1 0.00 0.30 \u00b1 0.01 0.92 \u00b1 0.00 0.30 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "33 0.91 \u00b1 0.00 0.30 \u00b1 0.01 0.92 \u00b1 0.00 0.30 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.92 \u00b1 0.00 0.30 \u00b1 0.01 0.92 \u00b1 0.00 0.31 \u00b1 0.01",
            "text": "Contrast"
        },
        {
            "heading": "10 0.66 \u00b1 0.03 0.76 \u00b1 0.03 0.70 \u00b1 0.02 0.68 \u00b1 0.03",
            "text": ""
        },
        {
            "heading": "20 0.66 \u00b1 0.02 0.76 \u00b1 0.03 0.71 \u00b1 0.01 0.67 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "33 0.66 \u00b1 0.02 0.75 \u00b1 0.02 0.72 \u00b1 0.01 0.66 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "50 0.66 \u00b1 0.01 0.75 \u00b1 0.01 0.72 \u00b1 0.01 0.66 \u00b1 0.01",
            "text": "Defocus blur"
        },
        {
            "heading": "10 0.75 \u00b1 0.02 0.60 \u00b1 0.01 0.82 \u00b1 0.01 0.49 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "20 0.75 \u00b1 0.01 0.60 \u00b1 0.01 0.82 \u00b1 0.01 0.49 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.76 \u00b1 0.01 0.60 \u00b1 0.00 0.82 \u00b1 0.00 0.50 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.76 \u00b1 0.01 0.60 \u00b1 0.00 0.82 \u00b1 0.00 0.50 \u00b1 0.01",
            "text": "Elastic transform"
        },
        {
            "heading": "10 0.81 \u00b1 0.02 0.53 \u00b1 0.01 0.84 \u00b1 0.01 0.45 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "20 0.81 \u00b1 0.01 0.52 \u00b1 0.01 0.85 \u00b1 0.00 0.44 \u00b1 0.01",
            "text": "33 0.81 \u00b1 0.01 0.52 \u00b1 0.00 0.85 \u00b1 0.00 0.44 \u00b1 0.01 50 0.81 \u00b1 0.01 0.52 \u00b1 0.00 0.85 \u00b1 0.00 0.44 \u00b1 0.00\nFog"
        },
        {
            "heading": "10 0.73 \u00b1 0.02 0.78 \u00b1 0.05 0.81 \u00b1 0.01 0.56 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "20 0.73 \u00b1 0.01 0.77 \u00b1 0.03 0.81 \u00b1 0.01 0.57 \u00b1 0.03",
            "text": "33 0.74 \u00b1 0.01 0.77 \u00b1 0.03 0.81 \u00b1 0.01 0.59 \u00b1 0.02 50 0.74 \u00b1 0.01 0.77 \u00b1 0.02 0.82 \u00b1 0.00 0.59 \u00b1 0.03\nFrost"
        },
        {
            "heading": "10 0.80 \u00b1 0.00 0.65 \u00b1 0.02 0.81 \u00b1 0.01 0.60 \u00b1 0.05",
            "text": ""
        },
        {
            "heading": "20 0.80 \u00b1 0.00 0.65 \u00b1 0.01 0.82 \u00b1 0.00 0.59 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "33 0.80 \u00b1 0.00 0.65 \u00b1 0.01 0.82 \u00b1 0.00 0.59 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.80 \u00b1 0.00 0.65 \u00b1 0.01 0.82 \u00b1 0.00 0.58 \u00b1 0.01",
            "text": "Gaussian blur"
        },
        {
            "heading": "10 0.71 \u00b1 0.01 0.72 \u00b1 0.00 0.75 \u00b1 0.01 0.65 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "20 0.71 \u00b1 0.00 0.72 \u00b1 0.00 0.75 \u00b1 0.01 0.66 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.71 \u00b1 0.00 0.72 \u00b1 0.00 0.75 \u00b1 0.00 0.66 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.71 \u00b1 0.00 0.72 \u00b1 0.00 0.75 \u00b1 0.00 0.67 \u00b1 0.01",
            "text": "Gaussian noise"
        },
        {
            "heading": "10 0.60 \u00b1 0.00 0.85 \u00b1 0.01 0.60 \u00b1 0.03 0.87 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "20 0.60 \u00b1 0.00 0.85 \u00b1 0.01 0.61 \u00b1 0.01 0.87 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.60 \u00b1 0.00 0.85 \u00b1 0.00 0.61 \u00b1 0.01 0.87 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.60 \u00b1 0.00 0.85 \u00b1 0.00 0.61 \u00b1 0.01 0.87 \u00b1 0.00",
            "text": "Glass blur"
        },
        {
            "heading": "10 0.72 \u00b1 0.00 0.72 \u00b1 0.00 0.73 \u00b1 0.01 0.70 \u00b1 0.03",
            "text": ""
        },
        {
            "heading": "20 0.72 \u00b1 0.00 0.72 \u00b1 0.00 0.74 \u00b1 0.01 0.69 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.72 \u00b1 0.00 0.72 \u00b1 0.00 0.74 \u00b1 0.00 0.70 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.72 \u00b1 0.00 0.71 \u00b1 0.00 0.74 \u00b1 0.00 0.69 \u00b1 0.00",
            "text": "Impulse noise"
        },
        {
            "heading": "10 0.63 \u00b1 0.00 0.82 \u00b1 0.00 0.66 \u00b1 0.02 0.80 \u00b1 0.03",
            "text": ""
        },
        {
            "heading": "20 0.63 \u00b1 0.00 0.82 \u00b1 0.00 0.66 \u00b1 0.01 0.80 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.63 \u00b1 0.00 0.82 \u00b1 0.00 0.66 \u00b1 0.01 0.80 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.63 \u00b1 0.00 0.82 \u00b1 0.00 0.67 \u00b1 0.01 0.80 \u00b1 0.00",
            "text": "Jpeg compression"
        },
        {
            "heading": "10 0.81 \u00b1 0.01 0.57 \u00b1 0.02 0.82 \u00b1 0.01 0.51 \u00b1 0.03",
            "text": ""
        },
        {
            "heading": "20 0.81 \u00b1 0.01 0.56 \u00b1 0.01 0.83 \u00b1 0.00 0.50 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.81 \u00b1 0.00 0.57 \u00b1 0.01 0.83 \u00b1 0.00 0.51 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.81 \u00b1 0.00 0.57 \u00b1 0.00 0.83 \u00b1 0.00 0.51 \u00b1 0.01",
            "text": "Motion blur"
        },
        {
            "heading": "10 0.78 \u00b1 0.01 0.59 \u00b1 0.02 0.83 \u00b1 0.01 0.47 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "20 0.78 \u00b1 0.01 0.58 \u00b1 0.01 0.84 \u00b1 0.01 0.47 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.78 \u00b1 0.01 0.58 \u00b1 0.01 0.84 \u00b1 0.00 0.48 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.78 \u00b1 0.00 0.57 \u00b1 0.00 0.84 \u00b1 0.00 0.48 \u00b1 0.01",
            "text": "Pixelate"
        },
        {
            "heading": "10 0.73 \u00b1 0.00 0.70 \u00b1 0.01 0.73 \u00b1 0.02 0.69 \u00b1 0.04",
            "text": ""
        },
        {
            "heading": "20 0.73 \u00b1 0.00 0.70 \u00b1 0.01 0.74 \u00b1 0.02 0.69 \u00b1 0.03",
            "text": ""
        },
        {
            "heading": "33 0.73 \u00b1 0.00 0.70 \u00b1 0.01 0.74 \u00b1 0.01 0.69 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "50 0.73 \u00b1 0.00 0.70 \u00b1 0.00 0.74 \u00b1 0.01 0.68 \u00b1 0.01",
            "text": "Saturate\n10 0.90 \u00b1 0.00 0.31 \u00b1 0.01 0.90 \u00b1 0.01 0.32 \u00b1 0.08"
        },
        {
            "heading": "20 0.90 \u00b1 0.00 0.31 \u00b1 0.00 0.91 \u00b1 0.00 0.30 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.90 \u00b1 0.00 0.31 \u00b1 0.00 0.91 \u00b1 0.00 0.30 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "50 0.90 \u00b1 0.00 0.31 \u00b1 0.00 0.91 \u00b1 0.00 0.29 \u00b1 0.01",
            "text": "Shot noise"
        },
        {
            "heading": "10 0.63 \u00b1 0.00 0.86 \u00b1 0.01 0.65 \u00b1 0.03 0.86 \u00b1 0.04",
            "text": ""
        },
        {
            "heading": "20 0.63 \u00b1 0.00 0.85 \u00b1 0.01 0.65 \u00b1 0.01 0.86 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.63 \u00b1 0.00 0.86 \u00b1 0.00 0.65 \u00b1 0.01 0.86 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "50 0.63 \u00b1 0.00 0.86 \u00b1 0.00 0.65 \u00b1 0.01 0.86 \u00b1 0.00",
            "text": "Snow"
        },
        {
            "heading": "10 0.84 \u00b1 0.00 0.55 \u00b1 0.03 0.85 \u00b1 0.01 0.49 \u00b1 0.03",
            "text": ""
        },
        {
            "heading": "20 0.84 \u00b1 0.00 0.55 \u00b1 0.02 0.85 \u00b1 0.00 0.48 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "33 0.84 \u00b1 0.00 0.55 \u00b1 0.01 0.85 \u00b1 0.00 0.48 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "50 0.84 \u00b1 0.00 0.56 \u00b1 0.01 0.85 \u00b1 0.00 0.48 \u00b1 0.01",
            "text": "Spatter"
        },
        {
            "heading": "10 0.83 \u00b1 0.00 0.59 \u00b1 0.02 0.82 \u00b1 0.01 0.60 \u00b1 0.06",
            "text": ""
        },
        {
            "heading": "20 0.83 \u00b1 0.00 0.58 \u00b1 0.01 0.83 \u00b1 0.01 0.58 \u00b1 0.04",
            "text": ""
        },
        {
            "heading": "33 0.83 \u00b1 0.00 0.59 \u00b1 0.01 0.83 \u00b1 0.01 0.58 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "50 0.83 \u00b1 0.00 0.59 \u00b1 0.00 0.83 \u00b1 0.00 0.58 \u00b1 0.01",
            "text": "Speckle noise"
        },
        {
            "heading": "10 0.68 \u00b1 0.00 0.81 \u00b1 0.01 0.70 \u00b1 0.03 0.79 \u00b1 0.06",
            "text": ""
        },
        {
            "heading": "20 0.68 \u00b1 0.00 0.81 \u00b1 0.01 0.70 \u00b1 0.01 0.78 \u00b1 0.03",
            "text": ""
        },
        {
            "heading": "33 0.68 \u00b1 0.00 0.81 \u00b1 0.00 0.70 \u00b1 0.01 0.79 \u00b1 0.02",
            "text": ""
        },
        {
            "heading": "50 0.68 \u00b1 0.00 0.81 \u00b1 0.00 0.70 \u00b1 0.01 0.79 \u00b1 0.01",
            "text": "Zoom blur"
        },
        {
            "heading": "50 0.79 \u00b1 0.00 0.58 \u00b1 0.00 0.84 \u00b1 0.00 0.49 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "33 0.79 \u00b1 0.01 0.58 \u00b1 0.00 0.84 \u00b1 0.00 0.49 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "20 0.79 \u00b1 0.01 0.58 \u00b1 0.00 0.84 \u00b1 0.00 0.48 \u00b1 0.01",
            "text": ""
        },
        {
            "heading": "10 0.79 \u00b1 0.01 0.58 \u00b1 0.01 0.84 \u00b1 0.01 0.47 \u00b1 0.02",
            "text": ""
        }
    ],
    "year": 2024
}