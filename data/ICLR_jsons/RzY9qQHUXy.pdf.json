{
    "abstractText": "Real-world tasks are universally associated with training samples that exhibit a long-tailed class distribution, and traditional deep learning models are not suitable for fitting this distribution, thus resulting in a biased trained model. To surmount this dilemma, massive deep long-tailed learning studies have been proposed to achieve inter-class fairness models by designing sophisticated sampling strategies or improving existing model structures and loss functions. Habitually, these studies tend to apply data augmentation strategies to improve the generalization performance of their models. However, this augmentation strategy applied to balanced distributions may not be the best option for long-tailed distributions. For a profound understanding of data augmentation, we first theoretically analyze the gains of traditional augmentation strategies in long-tailed learning, and observe that augmentation methods cause the long-tailed distribution to be imbalanced again, resulting in an intertwined imbalance: inherent data-wise imbalance and extrinsic augmentation-wise imbalance, i.e., two \u2018birds\u2019 co-exist in long-tailed learning. Motivated by this observation, we propose an adaptive Dynamic Optional Data Augmentation (DODA) to address this intertwined imbalance, i.e., one \u2018stone\u2019 simultaneously \u2018kills\u2019 two \u2018birds\u2019, which allows each class to choose appropriate augmentation methods by maintaining a corresponding augmentation probability distribution for each class during training. Extensive experiments across mainstream long-tailed recognition benchmarks (e.g., CIFAR-100-LT, ImageNetLT, and iNaturalist 2018) prove the effectiveness and flexibility of the DODA in overcoming the intertwined imbalance.",
    "authors": [
        {
            "affiliations": [],
            "name": "DEEP LONG"
        },
        {
            "affiliations": [],
            "name": "TAILED LEARNING"
        },
        {
            "affiliations": [],
            "name": "Binwu Wang"
        },
        {
            "affiliations": [],
            "name": "Pengkun Wang"
        },
        {
            "affiliations": [],
            "name": "Wei Xu"
        },
        {
            "affiliations": [],
            "name": "Xu Wang"
        },
        {
            "affiliations": [],
            "name": "Yudong Zhang"
        },
        {
            "affiliations": [],
            "name": "Kun Wang"
        },
        {
            "affiliations": [],
            "name": "Yang Wang"
        }
    ],
    "id": "SP:23f586d731de560a38b08e73fff31844d22dacf9",
    "references": [
        {
            "authors": [
                "Sumyeong Ahn",
                "Jongwoo Ko",
                "Se-Young Yun"
            ],
            "title": "Cuda: Curriculum of data augmentation for long-tailed recognition",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Randall Balestriero",
                "Leon Bottou",
                "Yann LeCun"
            ],
            "title": "The effects of regularization and data augmentation are class dependent",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Kaidi Cao",
                "Colin Wei",
                "Adrien Gaidon",
                "Nikos Arechiga",
                "Tengyu Ma"
            ],
            "title": "Learning imbalanced datasets with label-distribution-aware margin loss",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "Hsin-Ping Chou",
                "Shih-Chieh Chang",
                "Jia-Yu Pan",
                "Wei Wei",
                "Da-Cheng Juan"
            ],
            "title": "Remix: rebalanced mixup",
            "venue": "In Computer Vision\u2013ECCV 2020 Workshops: Glasgow, UK, August 23\u201328,",
            "year": 2020
        },
        {
            "authors": [
                "Peng Chu",
                "Xiao Bian",
                "Shaopeng Liu",
                "Haibin Ling"
            ],
            "title": "Feature space augmentation for long-tailed data",
            "venue": "In Computer Vision\u2013ECCV 2020: 16th European Conference,",
            "year": 2020
        },
        {
            "authors": [
                "Ekin D Cubuk",
                "Barret Zoph",
                "Dandelion Mane",
                "Vijay Vasudevan",
                "Quoc V Le"
            ],
            "title": "Autoaugment: Learning augmentation strategies from data",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Ekin D Cubuk",
                "Barret Zoph",
                "Jonathon Shlens",
                "Quoc V Le"
            ],
            "title": "Randaugment: Practical automated data augmentation with a reduced search space",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops,",
            "year": 2020
        },
        {
            "authors": [
                "Yin Cui",
                "Menglin Jia",
                "Tsung-Yi Lin",
                "Yang Song",
                "Serge Belongie"
            ],
            "title": "Class-balanced loss based on effective number of samples",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Lan-Zhe Guo",
                "Yu-Feng Li"
            ],
            "title": "Class-imbalanced semi-supervised learning with adaptive thresholding",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Lan-Zhe Guo",
                "Yi-Ge Zhang",
                "Zhi-Fan Wu",
                "Jie-Jing Shao",
                "Yu-Feng Li"
            ],
            "title": "Robust semi-supervised learning when not all classes have labels",
            "year": 2022
        },
        {
            "authors": [
                "Guy Hacohen",
                "Daphna Weinshall"
            ],
            "title": "On the power of curriculum learning in training deep networks",
            "venue": "In International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ],
            "title": "Deep residual learning for image recognition",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2016
        },
        {
            "authors": [
                "Xinting Hu",
                "Yi Jiang",
                "Kaihua Tang",
                "Jingyuan Chen",
                "Chunyan Miao",
                "Hanwang Zhang"
            ],
            "title": "Learning to segment the tail",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Chen Huang",
                "Yining Li",
                "Chen Change Loy",
                "Xiaoou Tang"
            ],
            "title": "Learning deep representation for imbalanced classification",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2016
        },
        {
            "authors": [
                "Lin-Han Jia",
                "Lan-Zhe Guo",
                "Zhi Zhou",
                "Jie-Jing Shao",
                "Yuke Xiang",
                "Yu-Feng Li"
            ],
            "title": "Bidirectional adaptation for robust semi-supervised learning with inconsistent data distributions",
            "venue": "In ICML 2023,",
            "year": 2023
        },
        {
            "authors": [
                "Bingyi Kang",
                "Saining Xie",
                "Marcus Rohrbach",
                "Zhicheng Yan",
                "Albert Gordo",
                "Jiashi Feng",
                "Yannis Kalantidis"
            ],
            "title": "Decoupling representation and classifier for long-tailed recognition",
            "venue": "In Eighth International Conference on Learning Representations (ICLR),",
            "year": 2020
        },
        {
            "authors": [
                "Bingyi Kang",
                "Yu Li",
                "Sa Xie",
                "Zehuan Yuan",
                "Jiashi Feng"
            ],
            "title": "Exploring balanced feature spaces for representation learning",
            "venue": "In International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Chris Dongjoo Kim",
                "Jinseo Jeong",
                "Gunhee Kim"
            ],
            "title": "Imbalanced continual learning with partitioning reservoir sampling",
            "venue": "In Computer Vision\u2013ECCV 2020: 16th European Conference,",
            "year": 2020
        },
        {
            "authors": [
                "Jaehyung Kim",
                "Jongheon Jeong",
                "Jinwoo Shin"
            ],
            "title": "M2m: Imbalanced classification via major-tominor translation",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Yonggang Li",
                "Guosheng Hu",
                "Yongtao Wang",
                "Timothy Hospedales",
                "Neil M Robertson",
                "Yongxin Yang"
            ],
            "title": "Differentiable automatic data augmentation",
            "venue": "In Computer Vision\u2013ECCV 2020: 16th European Conference,",
            "year": 2020
        },
        {
            "authors": [
                "Yu Li",
                "Tao Wang",
                "Bingyi Kang",
                "Sheng Tang",
                "Chunfeng Wang",
                "Jintao Li",
                "Jiashi Feng"
            ],
            "title": "Overcoming classifier imbalance for long-tail object detection with balanced group softmax",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Tsung-Yi Lin",
                "Priya Goyal",
                "Ross Girshick",
                "Kaiming He",
                "Piotr Doll\u00e1r"
            ],
            "title": "Focal loss for dense object detection",
            "venue": "In Proceedings of the IEEE international conference on computer vision,",
            "year": 2017
        },
        {
            "authors": [
                "Ziwei Liu",
                "Zhongqi Miao",
                "Xiaohang Zhan",
                "Jiayun Wang",
                "Boqing Gong",
                "Stella X Yu"
            ],
            "title": "Largescale long-tailed recognition in an open world",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Wanli Ouyang",
                "Xiaogang Wang",
                "Cong Zhang",
                "Xiaokang Yang"
            ],
            "title": "Factors in finetuning deep model for object detection with long-tail distribution",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2016
        },
        {
            "authors": [
                "Seulki Park",
                "Youngkyu Hong",
                "Byeongho Heo",
                "Sangdoo Yun",
                "Jin Young Choi"
            ],
            "title": "The majority can help the minority: Context-rich minority oversampling for long-tailed classification",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Adam Paszke",
                "Sam Gross",
                "Soumith Chintala",
                "Gregory Chanan",
                "Edward Yang",
                "Zachary DeVito",
                "Zeming Lin",
                "Alban Desmaison",
                "Luca Antiga",
                "Adam Lerer"
            ],
            "title": "Automatic differentiation in pytorch",
            "venue": "In Advances in Neural Information Processing Systems Workshops,",
            "year": 2017
        },
        {
            "authors": [
                "Jiawei Ren",
                "Cunjun Yu",
                "Xiao Ma",
                "Haiyu Zhao",
                "Shuai Yi"
            ],
            "title": "Balanced meta-softmax for long-tailed visual recognition",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Herbert Robbins",
                "Sutton Monro"
            ],
            "title": "A stochastic approximation method",
            "venue": "The annals of mathematical statistics,",
            "year": 1951
        },
        {
            "authors": [
                "Olga Russakovsky",
                "Jia Deng",
                "Hao Su",
                "Jonathan Krause",
                "Sanjeev Satheesh",
                "Sean Ma",
                "Zhiheng Huang",
                "Andrej Karpathy",
                "Aditya Khosla",
                "Michael Bernstein"
            ],
            "title": "Imagenet large scale visual recognition challenge",
            "venue": "International journal of computer vision,",
            "year": 2015
        },
        {
            "authors": [
                "Jingru Tan",
                "Changbao Wang",
                "Buyu Li",
                "Quanquan Li",
                "Wanli Ouyang",
                "Changqing Yin",
                "Junjie Yan"
            ],
            "title": "Equalization loss for long-tailed object recognition",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Kaihua Tang",
                "Jianqiang Huang",
                "Hanwang Zhang"
            ],
            "title": "Long-tailed classification by keeping the good and removing the bad momentum causal effect",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Yuji Tokozume",
                "Yoshitaka Ushiku",
                "Tatsuya Harada"
            ],
            "title": "Between-class learning for image classification",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2018
        },
        {
            "authors": [
                "Grant Van Horn",
                "Oisin Mac Aodha",
                "Yang Song",
                "Yin Cui",
                "Chen Sun",
                "Alex Shepard",
                "Hartwig Adam",
                "Pietro Perona",
                "Serge Belongie"
            ],
            "title": "The inaturalist species classification and detection dataset",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2018
        },
        {
            "authors": [
                "Vladimir Vapnik"
            ],
            "title": "Principles of risk minimization for learning theory",
            "venue": "Advances in neural information processing systems,",
            "year": 1991
        },
        {
            "authors": [
                "Pengkun Wang",
                "Xu Wang",
                "Binwu Wang",
                "Yudong Zhang",
                "Lei Bai",
                "Yang Wang"
            ],
            "title": "Long-tailed time series classification via feature space rebalancing",
            "venue": "In Proc. of DASFAA,",
            "year": 2023
        },
        {
            "authors": [
                "Tao Wang",
                "Yu Li",
                "Bingyi Kang",
                "Junnan Li",
                "Junhao Liew",
                "Sheng Tang",
                "Steven Hoi",
                "Jiashi Feng"
            ],
            "title": "The devil is in classification: A simple framework for long-tail instance segmentation",
            "venue": "In Computer Vision\u2013ECCV 2020: 16th European Conference,",
            "year": 2020
        },
        {
            "authors": [
                "Xudong Wang",
                "Long Lian",
                "Zhongqi Miao",
                "Ziwei Liu",
                "Stella X Yu"
            ],
            "title": "Long-tailed recognition by routing diverse distribution-aware experts",
            "venue": "In International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Saining Xie",
                "Ross Girshick",
                "Piotr Doll\u00e1r",
                "Zhuowen Tu",
                "Kaiming He"
            ],
            "title": "Aggregated residual transformations for deep neural networks",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2017
        },
        {
            "authors": [
                "Xi Yin",
                "Xiang Yu",
                "Kihyuk Sohn",
                "Xiaoming Liu",
                "Manmohan Chandraker"
            ],
            "title": "Feature transfer learning for face recognition with under-represented data",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Salah Zaiem",
                "Titouan Parcollet",
                "Slim Essid"
            ],
            "title": "Automatic data augmentation selection and parametrization in contrastive self-supervised speech representation learning",
            "venue": "In Interspeech",
            "year": 2022
        },
        {
            "authors": [
                "Yuhang Zang",
                "Chen Huang",
                "Chen Change Loy"
            ],
            "title": "Fasa: Feature augmentation and sampling adaptation for long-tailed instance segmentation",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Hongyi Zhang",
                "Moustapha Cisse",
                "Yann N Dauphin",
                "David Lopez-Paz"
            ],
            "title": "mixup: Beyond empirical risk minimization",
            "venue": "arXiv preprint arXiv:1710.09412,",
            "year": 2017
        },
        {
            "authors": [
                "Xiao Zhang",
                "Zhiyuan Fang",
                "Yandong Wen",
                "Zhifeng Li",
                "Yu Qiao"
            ],
            "title": "Range loss for deep face recognition with long-tailed training data",
            "venue": "In Proceedings of the IEEE International Conference on Computer Vision, pp. 5409\u20135418,",
            "year": 2017
        },
        {
            "authors": [
                "Xing Zhang",
                "Zuxuan Wu",
                "Zejia Weng",
                "Huazhu Fu",
                "Jingjing Chen",
                "Yu-Gang Jiang",
                "Larry S Davis"
            ],
            "title": "Videolt: large-scale long-tailed video recognition",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 7960\u20137969,",
            "year": 2021
        },
        {
            "authors": [
                "Yifan Zhang",
                "Bingyi Kang",
                "Bryan Hooi",
                "Shuicheng Yan",
                "Jiashi Feng"
            ],
            "title": "Deep long-tailed learning: A survey",
            "venue": "arXiv preprint arXiv:2110.04596,",
            "year": 2021
        },
        {
            "authors": [
                "Yifan Zhang",
                "Bryan Hooi",
                "Lanqing Hong",
                "Jiashi Feng"
            ],
            "title": "Self-supervised aggregation of diverse experts for test-agnostic long-tailed recognition",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Boyan Zhou",
                "Quan Cui",
                "Xiu-Shen Wei",
                "Zhao-Min Chen"
            ],
            "title": "Bbn: Bilateral-branch network with cumulative learning for long-tailed visual recognition",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Zhipeng Zhou",
                "Lanqing Li",
                "Peilin Zhao",
                "Pheng-Ann Heng",
                "Wei Gong"
            ],
            "title": "Class-conditional sharpness-aware minimization for deep long-tailed recognition",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2023
        },
        {
            "authors": [
                "Jianggang Zhu",
                "Zheng Wang",
                "Jingjing Chen",
                "Yi-Ping Phoebe Chen",
                "Yu-Gang Jiang"
            ],
            "title": "Balanced contrastive learning for long-tailed visual recognition",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "re-balancing Kang"
            ],
            "title": "2022), and information augmentation Chu et al",
            "year": 2020
        },
        {
            "authors": [
                "quintuplet sampling Huang"
            ],
            "title": "On the other hand, some studies, called cost-sensitive learning, re-balance classes by adjusting the loss values of different classes. For example, CB Cui et al. (2019) proposed a effective number to approximate the expected sample number of each class, and Focal loss Lin et al. (2017) used the prediction probabilities to inversely re-weight classes",
            "year": 2020
        },
        {
            "authors": [
                "Zhang"
            ],
            "title": "they designed contrastive learning based losses to learn a more class-balanced and class-discriminative feature space. Furthermore, as a classic theory, ensemble learning is also applied to LTL by designing and combining multiple expert networks. For instance, BBN Zhou et al. (2020) proposed to use two network branches to handle LTL. Following BBN, BAGS Li et al. (2020b) explored a multi-head",
            "year": 2022
        },
        {
            "authors": [
                "Kim"
            ],
            "title": "scheme to handle test distribution-agnostic LTL. Although the overall performance is improved, these methods cannot essentially handle the issue of lacking information, particularly on tail classes due to limited data amount. Orthogonally, some information augmentation studies seek to introduce additional information into model training, such as FTL Yin et al",
            "year": 2020
        },
        {
            "authors": [
                "Ahn"
            ],
            "title": "classes to enhance model training on tail classes considering the inter-class knowledge imbalance. To solve information restrictions in essence, another line of research is to apply representation augmentation or data augmentation to LTL. For example, CMO Park et al. (2022) augmented diversified minority samples by leveraging the rich context of the majority classes as background images",
            "venue": "Considering fairness, FSR Wang et al",
            "year": 2023
        },
        {
            "authors": [
                "Cubuk"
            ],
            "title": "In addition, researchers are improving DAs to make them suitable for LTL, however, they ignore that DA is class-independent, and thus may cause a mismatch between augmented data and actual labels Park et al",
            "venue": "DADA Li et al. (2020a), and RandAugment Cubuk et al",
            "year": 2019
        },
        {
            "authors": [
                "ImageNet-LT Liu"
            ],
            "title": "2019): is a long-tailed version of artificially truncated from the original balanced dataset ImageNet, which includes 1,000 different categories, 115,846 training images and 50,000 test images. The most frequent or least frequent class has 1,280 or 5 images, so the imbalance ratio",
            "year": 2019
        },
        {
            "authors": [
                "Van Horn"
            ],
            "title": "2018): is a real-world, naturally long-tailed dataset, which includes 8,142 different categories, 437,513 training images and 24,426 test images. Each image has one ground truth label. The iNat dataset is highly imbalanced with dramatically different number of images per category and the imbalance ratio \u03c1 is 500",
            "venue": "iNaturalist",
            "year": 2018
        },
        {
            "authors": [
                "\u2022 CE He"
            ],
            "title": "2016): is a cross-entropy loss based model, which is one of the most classic methods in the field of deep long-tailed learning",
            "year": 2020
        },
        {
            "authors": [
                "\u2022 cRT Kang"
            ],
            "title": "2020): is a two-stage training strategy, which keeps the representations fixed and randomly re-initialize and optimize the classifier weights using class-balanced sampling",
            "year": 2020
        },
        {
            "authors": [
                "\u2022 LDAM-DRW Cao"
            ],
            "title": "2019): extends the existing soft margin loss by enforcing classdependent margins based on label frequencies and further introduces a deferred re-balancing optimization schedule",
            "year": 2019
        },
        {
            "authors": [
                "\u2022 BS Ren"
            ],
            "title": "2020): proposes to use the label frequencies to adjust mode predictions during training, so that the bias of class imbalance can be alleviated by the prior knowledge",
            "year": 2020
        },
        {
            "authors": [
                "Wang"
            ],
            "title": "2021): introduces a knowledge distillation multi-expert framework to reduce the parameters by learning a student network with fewer experts",
            "venue": "RIDE",
            "year": 2021
        },
        {
            "authors": [
                "\u2022 BCL Zhu"
            ],
            "title": "2022): proposes a balanced contrastive learning loss and learns stronger feature representations through a dual-branch framework",
            "year": 2022
        },
        {
            "authors": [
                "\u2022 CMO Park"
            ],
            "title": "2022): focuses on utilizing the rich context of majority samples to improve the diversity of minority samples and mixes minority and majority images by using CutMix to enhance balancing and robustness simultaneously",
            "year": 2022
        },
        {
            "authors": [
                "\u2022 CUDA Ahn"
            ],
            "title": "2023): is a simple and efficient curriculum, which is designed to find the appropriate per-class strength of data augmentation",
            "year": 2023
        },
        {
            "authors": [
                "\u2022 AutoAugment Cubuk"
            ],
            "title": "2019): describes a simple procedure to automatically search for improved data augmentation policies by designing a search space where a policy consists of many sub-policies, one of which is randomly chosen for each image in each mini-batch",
            "year": 2019
        },
        {
            "authors": [
                "\u2022 Fast AutoAugment Lim"
            ],
            "title": "2019): finds effective augmentation policies via a more efficient search strategy based on density matching",
            "year": 2019
        },
        {
            "authors": [
                "\u2022 DADA Li"
            ],
            "title": "2020a): relaxes the discrete DA policy selection to a differentiable optimization problem via Gumbel-Softmax and introduces an unbiased gradient estimator to learn an efficient and accurate DA policy",
            "year": 2020
        },
        {
            "authors": [
                "\u2022 RandAugment Cubuk"
            ],
            "title": "2020): proposes a simplified search space that vastly reduces the computational expense of automated augmentation, and permits the removal of a separate proxy",
            "year": 2020
        },
        {
            "authors": [
                "Ahn"
            ],
            "title": "2017) as our backbone network on ImageNet-LT. We conduct comparative experiments on three baselines (e.g., CE, BS, and BCL), and the results show that no matter what kind of backbone is used, DODA can always bring stable improvement to long-tailed learning algorithms",
            "year": 2017
        },
        {
            "authors": [
                "Zaiem"
            ],
            "title": "So we partially implemented the augmentation strategies",
            "year": 2022
        },
        {
            "authors": [
                "Zaiem"
            ],
            "title": "It can be observed that using the automatic augmentation strategy from Zaiem et al. (2022) results in limited performance improvement, while our method outperforms it significantly. The reasons for this are as follows: (1) Zaiem et al. (2022) relies on a carefully designed pretext task, so the improvement it brings may come from diversified data augmentation",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "With the maturity of deep learning LeCun et al. (2015), massive deep models show extraordinary performance on large-scale curated datasets (e.g., ImageNet Russakovsky et al. (2015) and CIFAR100 Cao et al. (2019)). However, balanced artificial datasets do not conform to the data distribution (e.g., class imbalance) of real-world applications. Once facing imbalanced datasets, the performance of the deep models trained by the common practice of empirical risk minimization Vapnik (1991) will decrease significantly, e.g., the model can be easily biased towards majority classes.\nRecently, massive deep long-tailed learning studies have been proposed to surmount the class imbalance problem. The most intuitive and mainstream paradigm is class re-balancing, which balances the training sample numbers or weights of different classes during model training by resampling Kang et al. (2020); Ren et al. (2020); Wang et al. (2020); Jia et al. (2023) or cost-sensitive\n\u2217Prof. Yang Wang and Pengkun Wang are the corresponding authors.\nlearning Lin et al. (2017); Cui et al. (2019); Tan et al. (2020); Guo et al. (2022); Guo & Li (2022). Although the average performance is improved, class rebalancing methods cannot essentially handle the issue of lacking information, particularly on tail classes due to limited data amount Zhang et al. (2021b). To break through this restraint, some studies seek to transfer the knowledge from head classes to enhance model training on tail classes Yin et al. (2019); Kim et al. (2020b).\nAnother flexible line of research is to directly apply data augmentation methods to enhance the quantity and quality of training samples from the perspectives of data and representation. For example, FASA Zang et al. (2021) proposed to generate class-wise representations based on a Gaussian prior to augment the under-represented tail classes. Remix Chou et al. (2020) and VideoLT Zhang et al. (2021a) introduced a re-balanced mixup method to particularly enhance tail classes. However, simply using existing class-independent augmentation strategies for improving long-tailed learning is unfavorable, since they may further increase imbalance considering head classes have more samples and would be augmented more Zhang et al. (2021b). Considering this, as a pioneer, FSR Wang et al. (2023) first proposed an adaptive augmentation to rebalance the potential temporal feature space from the data perspective. CUDA Ahn et al. (2023) further proposed a simple algorithm to find the proper class-wise augmentation strength through curriculum learning Hacohen & Weinshall (2019). Despite extensive recent studies, an unresolved problem is whether it is optimal to utilize the same kind of augmentation strategy on all classes for long-tailed learning.\nAug.\nSacrificed\nSacrificed\nAug.\nN u\nm b\ne r\no f\ntr ai\nn in\ng sa\nm p\nle s\nSorted class index\nto confirm the explanation. From the results shown in Figure 2, we can observe that DA caused a significant reduction in performance for some classes (e.g., most tail classes), which runs counter to the purpose of long-tailed learning.\nTo this end, we propose an adaptive \u2018stone\u2019 called Dynamic Optional Data Augmentation (DODA) to \u2018kill\u2019 this intertwined imbalance, which allows each class to choose appropriate augmentation methods during training. Specifically, to avoid the sacrifice caused by class-independent DA, we maintain a \u2018preference list\u2019 for each class (i.e., a probability distribution of DAs being selected) during training, which is the basis for each class to choose applied augmentation methods. Then, to make this \u2018list\u2019 more precise, we adjust the corresponding probability distribution according to the positive sample size of each class. In this way, this \u2018list\u2019 will be dynamically corrected during training, thus each class will choose the most beneficial augmentation method to avoid being sacrificed, thereby reducing the overall sacrifice probability. We integrate DODA with various long-tailed learning methods and prove that DODA can significantly improve the model performance and have high flexibility. Furthermore, we conduct several experiments to compare DODA with existing DAs for long-tailed learning and show that DODA achieves state-of-the-art performance.\nOur contributions in this paper are summarized as follows:\n\u2022 New problem and insight: for the first time, we theoretically analyze the gains of traditional augmentation strategies in long-tailed learning: DA will potentially sacrifice certain classes (especially tail classes) while improving the model performance, thus we need to discreetly handle the inherent data-wise imbalance and extrinsic augmentation-wise imbalance.\n\u2022 New advisable augmentation: to \u2018kill\u2019 these two \u2018birds\u2019, we propose an adaptive \u2018stone\u2019 called Dynamic Optional Data Augmentation (DODA) to allow each class to choose appropriate augmentation methods during training.\n\u2022 Compelling empirical results: DODA achieves the state-of-the-art performance across mainstream long-tailed benchmarks including CIFAR-100-LT, ImageNet-LT, and iNaturalist 2018."
        },
        {
            "heading": "2 RETHINKING DA: IS DA ALWAYS BENEFICIAL TO LONG-TAILED LEARNING?",
            "text": "Applying DA in long-tailed learning has been empirically proven to significantly improve the average accuracy of the deep model. This overall improvement is encouraging, but it also prompts us to think about how DA brings gains to the problem. In this section, we will analyze this further."
        },
        {
            "heading": "2.1 MOTIVATION: DA IN LONG-TAILED LEARNING IS \u2018HYPOCRITICAL\u2019",
            "text": "Preliminary. Class-independent DA is the mainstream strategy in long-tailed learning, which is simple but effective (i.e., average improvement). However, recent work has found that DA can result in unfair model complexity control across different classes, leading to the deep model that achieve an overall accuracy improvement but perform poorly on some classes. This phenomenon reflects the fact that DA actually produces a hypocritical improvement. In a class-balanced setting, Balestriero et al. (2022) explains this from the perspective of level-set. Formally, given a training dataset D = {(xi, yi)|yi \u225c f\u2217(xi)}Ni=1, our goal is to learn a deep model f\u03b8 to approximate the ideal model f\u2217 as closely as possible. To improve the generalization performance of the model, a DA strategy O(\u00b7) will be habitually applied to x, which is a combination of one or more augmentation methods. During this approximation, the model that we intuitively consider to be ideal may already be biased.\nTheorem 1. Augmented samples produced by O(\u00b7) do not respect the level-set of f\u2217. When we approximate the ideal model f\u2217 by minimizing the training loss (i.e., 0 training error), the latter tends to zero, while the former is greater than zero due to the augmented samples deviate from the level set of f\u2217. In this case, the trained model f\u03b8 is biased compared to the ideal model f\u2217.\u2211\n(x,y)\u2208D\nE[||y \u2212 f\u2217(O(x))||22] > 0 \u2227 \u2211\n(x,y)\u2208D\nE[||y \u2212 f\u03b8(O(x))||22] = 0 =\u21d2 bias (1)\nFurthermore, we rethink the problem from the perspective of long-tailed learning. For each class in the long-tailed distribution dataset, such as class c, we also hope that the trained model f\u03b8 can successfully predict the labels of all samples of this class. Therefore, f\u03b8 also has the above bias in the class dimension. This explanation is formalized by the following theorem.\nTheorem 2. Under the long-tailed distribution, minimizing the training loss (i.e., 0 training error) is equivalent to minimizing the training loss for each class. For class c and augmented samples {(O(x), y)|y = c, (O(x), y) \u2208 D}, the ideal trained model can minimize the training loss of class c, but when O(x) deviates from the level-set of f\u2217, DA will cause irreducible class-wise bias in f\u03b8.\u2211 (x,y)\u2208D|y=c E[||y \u2212 f\u2217(O(x))||22] > 0 \u2227 \u2211 (x,y)\u2208D|y=c E[||y \u2212 f\u03b8(O(x))||22] = 0 =\u21d2 class-wise bias\n(2)\nTheorem 2 states that for long-tailed distributions, a DA cannot guarantee that it is label-preserving on all classes, which leads to some classes being sacrificed (i.e., seriously deviating from the level-set) after DA, resulting in irreducible class-wise bias. The detailed proof is in Appendix A. Based on this theorem, we observed the class-wise bias caused by various DAs under two imbalance rate settings (IR = {50, 100}) of CIFAR-100-LT, including simple augmentation (Cutout), flexible augmentation\n(CUDA), and hybrid augmentation (Cutout with CUDA). From the experimental results shown in Figure 2, we analyze the sacrifice rate (SR) under each setting and make the following findings: (1) All three types of DA can improve the average model performance (i.e., average accuracy); (2) The improvement in average performance inevitably sacrifices some classes, whether they are head or tail classes; (3) The phenomenon of sacrificing classes is especially evident on tail classes.\nThe experimental results are consistent with the statement of Theorem 2, which proves that the traditional class-independent DA is \u2018hypocritical\u2019 and will potentially sacrifice some classes (especially tail classes) when improving the average performance of the long-tailed learning model, which runs counter to the purpose of long-tailed learning."
        },
        {
            "heading": "2.2 DA FAVORS LONG-TAILED LEARNING THROUGH \u2018BULLYING\u2019",
            "text": "As mentioned in Section 2.1, class-independent DA is hypocritical, and it shows its effectiveness by pleasing the \u2018strong\u2019, while tail classes are more likely to be regarded as the bullied \u2018weak\u2019. To explain this phenomenon, we analyze the data distribution shift of different classes before and after DA from the perspective of feature space. In high-dimensional space, samples of the same class are usually closer to each other and form approximate clusters due to their inherent similarities. When applying the same data augmentation, the features in high-dimensional space undergo shifts that are consistent across different classes. To intuitively understand the impact of data augmentation on features of different classes, we approximate the high-dimensional space as a regular hyperspace and use the variation in the distribution span to represent the diversity improvement and high-dimensional space expansion caused by data augmentation. Intuitively, we approximate the feature space of classes to two-dimensional space to illustrate this. And we also provide a theoretical explanation in high-dimensional feature space in Appendix A. Definition 1 (Distribution Span). Approximating the distribution of each class in the training set as a circle in a two-dimensional feature space, the distribution center of class c is defined as (Xc,Yc) and the distribution radius is Rc. The distribution span Sc can be expressed as follows:\nSc \u21d2 (X\u2212 Xc)2 \u2212 (Y\u2212 Yc)2 = Rc2 (3)\nFor intuitive understanding, we assume that the data distribution of head class ch and tail class ct are Sch and Sct , respectively. We uniformly apply the same DA O(\u00b7) to the whole training set. Furthermore, the distribution span after DA can be defined as follows:\nS\u0304ch \u21d2 (X\u2212 Xch)2 \u2212 (Y\u2212 Ych)2 = (Rch +\u2206ch)2 (4) S\u0304ct \u21d2 (X\u2212 Xct)2 \u2212 (Y\u2212 Yct)2 = (Rct +\u2206ct)2 (5)\nHere, \u2206ch and \u2206ct represent the increase in distribution radius within each class after DA. For the same augmentation method, \u2206ch = \u2206ct . Based on the increase in distribution radius, we analyze the sensitivity of each class to this augmentation. Theorem 3. The augmented data distribution is a combination of the original data distribution (base space) and the expanded data distribution (marginal space). The augmentation sensitivity \u03c8 can be defined as the ratio of the marginal space to the base space. Under the same DA, tail classes have a higher augmentation sensitivity, indicating that tail classes are more sensitive to the marginal space.\n\u03c8ct \u2212 \u03c8ch = 2\u2206ch \u00b7 Rch \u2212 Rct RchRct +\u2206ch 2 \u00b7 Rch 2 \u2212 Rct 2 Rch 2Rct 2 > 0 (6)\nThe main idea of the proof, provided in Appendix A, is to demonstrate that tail classes are more likely to have label non-preservation compared to head classes after DA, resulting in a greater deviation between the level-set learned by f\u03b8 and the level-set of f\u2217 on tail classes.\nIn summary, DA in long-tailed learning is hypocritical and bullying, as it potentially sacrifices certain classes, especially tail classes, while boosting the average performance. Therefore, we not only need to deal with the inherent data-wise imbalance caused by the traditional sample distribution but also pay attention to the side effects of DA, the extrinsic augmentation-wise imbalance. It is frustrating that the existing \u2018stones\u2019 cannot kill both \u2018birds\u2019, so we need to consider how to achieve a simple and effective DA to address this intertwined imbalance."
        },
        {
            "heading": "3 DYNAMIC OPTIONAL DATA AUGMENTATION: AN ADVISABLE STRATEGY",
            "text": "In this section, based on the aforementioned theoretical analysis, we propose an advisable \u2018stone\u2019 called Dynamic Optional Data Augmentation (DODA) to address the intertwined imbalance. The core philosophy of DODA is to allow each class to choose appropriate augmentation methods during training by maintaining a \u2018preference list\u2019 for each class. The detailed algorithm overview of DODA is shown in Figure 3.\n3.1 CLASS-WISE PREFERENCE LIST CONSTRUCTION\nFirstly, we assume the existence of K optional DAs and define the index of each DA as k \u2208 {1, 2, ...,K}. These DAs are task-specific, such as Gaussian blur, rotation, and horizontal flip. Each DA Ok(\u00b7) : Rd \u2192 Rd has its predefined augmentation function and strength. For traditional strategies, we pre-determine the selected DAs and use them for all classes during training. However, this class-\nindependent DA may sacrifice certain classes. Therefore, we maintain an augmentation preference list Qc \u2200c \u2208 {1, ..., C} for each class during training. This list records the optional DAs for each class c and the probability of each DA being selected. Definition 2 (Probability of Each DA Being Selected). The augmentation preference list Qc for class c records the selection hierarchy Qkc \u2200k \u2208 {1, ...,K} of the K optional DAs. Based on the selection hierarchy, we define the probability of each DA Ok(\u00b7) being selected as follows:\nPOkc (\u00b7) = |Qkc |\u2211 j\u2208Qc |j| , where Qc = {Q1c ,Q2c , ...,QKc } (7)\nBased on this preference list, we perform DA on the original dataset D and define the augmented dataset as D\u0304 = {(x\u0304i, yi)|(xi, yi) \u2208 D}. To preserve the knowledge of the original dataset D, we define the augmentation probability as paug < 1, so each sample has a probability of paug of being augmented. When performing DA, we randomly decide whether to augment the current sample with paug . Therefore, the augmented sample can be represented as follows:\nx\u0304i = { Okc (xi), with prob. paug xi, otherwise\n(8)"
        },
        {
            "heading": "3.2 CLASS-WISE PREFERENCE LIST MAINTENANCE",
            "text": "On the augmented dataset D\u0304, we apply a long-tailed learning algorithm F to learn the desired deep model f\u03b8, i.e., F(f\u03b8, D\u0304). It is worth mentioning that the choice of F is flexible, for example, we test various long-tailed learning algorithms in subsequent experiments.\nDuring the early stages of training, the augmentation preference list set for one class may be inaccurate, meaning that there is still a high probability to select DAs that are detrimental to this class. Therefore, continually updating this list during training is necessary. The core philosophy of updating is to up-weight the positive DAs and down-weight the negative DAs. After each training epoch, we count the number of correctly predicted samples in each class, i.e., the positive sample size for each class. Formally, for class c, its positive sample size is defined as follows:\n\u2207pos zkc\n= \u2211\n(x\u0304i,yi)\u2208D\u0304|yi=c\n1{f\u03b8(x\u0304i)=c} (9)\nDefinition 3 (Augmentation Dominance). For the dataset D and class c, DA Ok1 is said to dominate DA Ok2 on class c if and only if \u2207pos\nz k1 c > \u2207pos z k2 c , where \u2207pos z k1 c\n= \u2211\n(xi,yi)\u2208D|yi=c 1{f\u03b8(Ok1 (xi))=c}\nand \u2207pos z k2 c\n= \u2211\n(xi,yi)\u2208D|yi=c 1{f\u03b8(Ok2 (xi))=c}.\nTheorem 4. The level-set bias \u03b4(Q,P ) can be defined as the degree of distributional deviation between the level-sets Q and P . Suppose the level-set of the model f\u03b8 trained on the original dataset is P , and the level-sets of the models fk1\u03b8 and f k2 \u03b8 learned using DA Ok1 and DA Ok2 , respectively, are Qk1 and Qk2 . If the augmentation dominance of Ok1 is higher than that of Ok2 , then the bias of Qk1 from P is smaller than that of Qk2 from P , i.e., \u03b4(Qk1 , P ) < \u03b4(Qk2 , P ).\nAlgorithm 1: DODA Input: DatasetD = (xi, yi)Ni=1, algorithm F , training epoch E, number of optional aug. K, aug. probability paug . Output: trained model f\u03b8 . Initialize: Weight of each DA for each class Qkc = 1 \u2200k \u2208 {1, ..., K}, \u2200c \u2208 {1, ..., C}. for e \u2264 E do\nfor c \u2264 C do Randomly select a DAOkc (\u00b7) for class c according to\nthe weight distributionQc.\nPOkc (\u00b7) = |Qkc |\u2211 j\u2208Qc |j|\nwhereQc = {Q1c,Q 2 c, ...,Q K c }\nend Generate D\u0304 = {(x\u0304i, yi)|(xi, yi) \u2208 D} where\nx\u0304i = { Okc (xi), with prob. paug xi, otherwise.\nRun LTL algorithm F using D\u0304, i.e., F(f\u03b8, D\u0304). for c \u2264 C do\nCompute positive sample size\u2207pos zkc for class c\n\u2207pos zkc\n= \u2211\n(x\u0304i,yi)\u2208D\u0304|yi=c 1{f\u03b8(x\u0304i)=c}\nif\u2207pos zkc > tempc thenQkc \u2190\u2212 Q k c + 1\n// Up-weight the positive DA\nelif\u2207pos zkc = tempc thenQkc \u2190\u2212 Q k c else // Down-weight the negative DA ifQkc > 1 thenQ k c \u2190\u2212 Q k c \u2212 1\nelseQkc \u2190\u2212 1 tempc = \u2207pos\nzkc\nend end\nTheorem 4 states that a more dominant DA tends to avoid severe distribution bias. The detailed proof is in Appendix A. Therefore, to explore optional DA, we record the positive sample size tempc from the previous epoch for class c to facilitate observation of whether the DA used in this epoch brings benefits to the class.\nBased on the positive sample sizes from the current epoch and the previous epoch, we update the augmentation preference list for each class. For class c and DA Okc used in the current epoch, if the positive sample size from the current epoch is greater than that from the previous epoch, we consider this DA is beneficial for class c, and thus we up-weight this DA that has a positive impact. Conversely, if this DA has a negative impact on class c, we down-weight it.\nBy dynamically maintaining the augmentation preference lists, DODA achieves adaptive classdependent augmentation, which is not \u2018hypocritical\u2019 and not \u2019bullying\u2019, allowing each class (especially the tail classes) to choose appropriate augmentation methods and avoid being potentially sacrificed during training. To better illustrate the execution process of DODA, we provide a detailed execution flow in Algorithm 1. The code is available in https://github. com/pongkun/Code-for-DODA."
        },
        {
            "heading": "4 EXPERIMENTS",
            "text": "In this section, we conduct empirical evaluations on multiple mainstream datasets to demonstrate the superiority of the proposed DODA in long-tailed learning."
        },
        {
            "heading": "4.1 EXPERIMENTAL SETTINGS",
            "text": "Datasets. To ensure a fair comparison, we conducted experiments on three mainstream long-tailed image recognition benchmarks including CIFAR-100-LT Cao et al. (2019), ImageNet-LT Liu et al.\n(2019), and iNaturalist 2018 Van Horn et al. (2018). CIFAR-100-LT and ImageNet-LT are longtailed versions artificially truncated from the original balanced datasets, while iNaturalist 2018 is a real-world, naturally long-tailed dataset. CIFAR-100-LT has three imbalance ratio settings {10, 50, 100}, where the imbalance ratio is defined as Nmax/Nmin. For each dataset, we employ the officially provided version. The detailed descriptions for datasets are in Appendix C.\nEvaluation Metrics. Model performance is mainly measured by the overall Top-1 accuracy (All). Following Ahn et al. (2023), we also statistically measure the accuracy on three disjoint subsets of the long-tailed datasets: head classes (Head), medium classes (Medium), and tail classes (Tail). Accuracy is reported as a percentage.\nComparison Baselines. We select a variety of long-tailed recognition methods as baselines, which are based on different theoretical ideas, including cross-entropy loss (CE) He et al. (2016), class re-balancing methods: CE-DRW Cao et al. (2019), LWS Kang et al. (2020), cRT Kang et al. (2020), LDAM-DRW Cao et al. (2019), Balanced Softmax (BS) Ren et al. (2020), information augmentation methods: CMO Park et al. (2022), CUDA Ahn et al. (2023), and module improvement methods: RIDE with three experts Wang et al. (2021), BCL Zhu et al. (2022). Thanks to the high flexibility of DODA, we integrate it with the aforementioned baseline to observe the gains DODA brings to existing methods. The detailed discussions and descriptions for baselines are in Appendix B and Appendix C.\nImplementation. We use Pytorch Paszke et al. (2017) to implement all neural networks and train the model on 8 NVIDIA Tesla V100 GPUs. For CIFAR-100-LT dataset, we follow the general experimental setup from Cao et al. (2019) and utilize ResNet-32 He et al. (2016) as a backbone network. The networks are trained for 200 epochs by the SGD optimizer with an initial learning rate of 10\u22124, a momentum of 0.9, and a weight decay of 2\u00d7 10\u22124. We use a random strategy (up-weight and down-weight operations aren\u2019t active) for the first 50 epochs to avoid cold-boot issues and then switch to the proposed strategy for the remaining epochs. For ImageNet-LT and iNaturalist 2018 datasets, we use ResNet-50 as a backbone network. We train the network for 100 epochs using an initial learning rate of 0.1, and decay the learning rate at epochs 60 and 80 by 0.1. For all experiments, we set the hyperparameter values paug as 0.5."
        },
        {
            "heading": "4.2 BENCHMARK RESULTS",
            "text": "CIFAR-100-LT. Table 1 displays the overall classification accuracies on CIFAR-100-LT dataset. It can be observed that DODA achieves comprehensive and stable improvements over the original long-tailed learning baselines: CE He et al. (2016), CE-DRW Cao et al. (2019), LDAM-DRW Cao et al. (2019), BS Ren et al. (2020), RIDE with three experts Wang et al. (2021), BCL Zhu et al.\n(2022). The outstanding performance on tail classes also demonstrates that DODA alleviates severe class sacrifice issues. Moreover, compared to existing class-independent long-tailed augmentation baselines: CMO Park et al. (2022) and CUDA Ahn et al. (2023), DODA achieves superior performance, especially on tail classes. Essentially, this improvement is due to the special \u2018care\u2019 given to the sacrificed classes in class-independent augmentation.\nImageNet-LT and iNaturalist 2018. We also compared DODA with state-of-the-art long-tailed recognition methods on large-scale datasets, and the experimental results are shown in Table 2. Applying DODA to the basic CE loss significantly improves the model performance and can be comparable to the performance of existing long-tailed learning methods. It is worth noting that ImageNet-LT and iNaturalist 2018 have higher imbalance ratios (i.e., 256 and 500) than CIFAR-100LT (i.e., 10, 50, and 100), so the results also demonstrate that DODA can improve model performance in scenarios with varying degrees of imbalance.\n4.3 FURTHER ANALYSIS\nIn this section, we conduct a detailed analysis of the mechanism of DODA and discuss the following four issues. All the analysis experiments are conducted on CIFAR-100-LT (IR=100). More empirical results are reported in Appendix D.\nDoes DODA make fewer classes be \u2018sacrificed\u2019? In Section 2, we analyze and validate that classindependent DA is \u2018hypocritical\u2019, as it achieves the improvement of average performance by sacrificing certain classes (especially tail classes), which runs counter to the purpose of long-tailed learning. The goal of DODA is to pursue inter-class fairness while alleviating both inherent data-wise imbalance and extrinsic augmentation-wise imbalance. By allowing each class to choose appropriate DAs, DODA can effectively alle-\nviate the problem of sacrificing \u2018weak\u2019 classes while achieving generalization performance. From the visualization of the accuracy of each class in Figure 4, it can be found that compared with CUDA,\nDODA reduces the sacrifice rate by 31% and 24%, respectively, indicating that DODA makes fewer classes be \u2018sacrificed\u2019.\nWhy DODA can alleviate the long-tailed problem? Long-tailed learning aims to learn an accurate and robust deep model that can achieve generalized performance on long-tailed distribution tasks. DODA addresses the common problem of unfair DA in existing long-tailed methods from the perspective of DA. Our method is orthogonal to existing methods. By maintaining a preference list for each class, DODA provides each class with the right to choose DA fairly. As shown in Figure 5, we observe the trend of the selection hierarchies on two baselines (BS and CE). We randomly selected four classes (Index = {0, 10, 40, 80}) and 10 common DAs. It can be observed that, as the epoch increases, the preferred DA for specific classes gradually becomes apparent, indicating that each class can choose positive DAs to avoid being sacrificed, thereby alleviating the long-tailed problem.\nWhat are the trends in DAs favored by classes? As illustrated in Figure 6, we visualized the preferred augmentation methods for different classes, and it can be observed that certain augmentation methods are highly favored because some DAs tend to distort some decisive information in the data, while other DAs prefer to preserve label-related information.\nWould other augmentation methods be better? We also compared DODA with existing DAs to demonstrate its superiority in long-tailed learning. Following the setting of Ahn et al. (2023), we select six augmentation methods, including AutoAugment (AA) Cubuk et al. (2019), Fast AutoAugment (FAA) Lim et al. (2019), DADA Li et al.\n(2020a), RandAugment (RA) Cubuk et al. (2020), and CUDA Ahn et al. (2023). Except for CUDA, other methods require additional computational resources to search for suitable DAs for datasets. Although CUDA implements class-wise strength adjustment, it still struggles to avoid class sacrifice issues. As shown in Figure 7, DODA outperforms other search-based and strength-based DAs, achieving fair augmentation while being computationally efficient."
        },
        {
            "heading": "5 CONCLUSION",
            "text": "In this study, we first theoretically analyzed the gains of traditional DAs in long-tailed learning and then proposed a \u2018stone\u2019 called Dynamic Optional Data Augmentation (DODA) to kill two \u2018birds\u2019: inherent data-wise imbalance and extrinsic augmentation-wise imbalance. DODA allows each class to choose appropriate DAs by maintaining a corresponding DA probability distribution for each class. Extensive experiments across long-tailed benchmarks verify the effectiveness of the DODA."
        },
        {
            "heading": "6 ACKNOWLEDGEMENT",
            "text": "This paper is partially supported by the National Natural Science Foundation of China (No.62072427, No.12227901), the Project of Stable Support for Youth Team in Basic Research Field, CAS (No.YSBR-005), Academic Leaders Cultivation Program, USTC."
        },
        {
            "heading": "Appendix Kill Two Birds with One Stone: Rethinking Data Augmentation for Deep Long-tailed Learning",
            "text": "The content of the Appendix is summarized as follows:\n1) in Sec. A, we state the proofs of Theorem 2 (Sec. 2.1), Theorem 3 (Sec. 2.2), and Theorem 4 (Sec. 3.2).\n2) in Sec. B, we summarize existing long-tailed learning (LTL) and data augmentation (DA) methods and explicitly illustrate the novelty of DODA.\n3) in Sec. C, we demonstrate the details of datasets and baselines we use in experiments of DODA.\n4) in Sec. D, we illustrate more detailed empirical results and analyses of DODA."
        },
        {
            "heading": "A DETAILED PROOFS",
            "text": ""
        },
        {
            "heading": "A.1 PROOF OF THEOREM 2",
            "text": "Proof. In Sec. 2.1, Theorem 1 states that when we approximate the ideal model f\u2217 by minimizing the training loss (i.e., 0 training error), the latter tends to zero, while the former is greater than zero due to the augmented samples deviate from the level set of f\u2217. Therefore, the trained model f\u03b8 will be biased compared to the ideal model f\u2217.\u2211\n(x,y)\u2208D\nE[||y \u2212 f\u2217(O(x))||22] > 0 \u2227 \u2211\n(x,y)\u2208D\nE[||y \u2212 f\u03b8(O(x))||22] = 0 =\u21d2 bias (10)\nFrom the perspective of the dataset, the reason for the bias is that the semantic information of some samples does not match their original labels after DA, which means that DA cannot guarantee that it is label-preserving. We reconsider this problem from the perspective of long-tailed learning. First of all, for the whole dataset D, minimizing the training loss essentially means that the trained model f\u03b8 should achieve 0 training error on each class, i.e.,\u2211\n(x,y)\u2208D\nE[||y \u2212 f\u03b8(O(x))||22] = 0 =\u21d2 \u2211\n(x,y)\u2208D|y=c\nE[||y \u2212 f\u03b8(O(x))||22] = 0 \u2200c \u2208 C (11)\nSimilarly, for class c and augmented samples {(O(x), y)|y = c, (O(x), y) \u2208 D}, when we achieve or approximately achieve the minimization of the training loss on class c, DA inevitably makes some samples of class c mismatch with their original labels, i.e., the augmented samples deviate from the level set of the ideal model f\u2217. Therefore, when we use the augmented samples of class c as inputs to f\u2217, f\u2217 cannot predict the labels completely correctly.\u2211\n(x,y)\u2208D\nE[||y \u2212 f\u2217(O(x))||22] > 0 =\u21d2 \u2211\n(x,y)\u2208D|y=c\nE[||y \u2212 f\u2217(O(x))||22] > 0 \u2200c \u2208 C (12)\nAlthough we achieve a seemingly optimal (ideal) training model f\u03b8, its fitting process on class c has actually deviated from the ideal optimization process. Therefore, the deviation between the trained model f\u03b8 and the ideal model f\u2217 on class c is inevitable, i.e., f\u03b8 has class-wise bias.\u2211 (x,y)\u2208D|y=c E[||y \u2212 f\u2217(O(x))||22] > 0 \u2227 \u2211 (x,y)\u2208D|y=c E[||y \u2212 f\u03b8(O(x))||22] = 0 =\u21d2 class-wise bias\n(13)"
        },
        {
            "heading": "A.2 PROOF OF THEOREM 3",
            "text": "Proof. According Definition 1, the distribution of each class in the training set can be approximate as a circle in a two-dimensional feature space, and the distribution center of class c can be defined as (Xc,Yc) and the distribution radius is Rc. So, the distribution span Sc can be expressed as follows:\nSc \u21d2 (X\u2212 Xc)2 \u2212 (Y\u2212 Yc)2 = Rc2 (14)\nFor the data distribution Sch and Sct of head class ch and tail class ct, the new distribution span after using uniform DA O(\u00b7) can be defined as S\u0304ch \u21d2 (Rch +\u2206ch)2 and S\u0304ct \u21d2 (Rct +\u2206ct)2, and \u2206ch and \u2206ct represent the increase in distribution radius within each class after DA. For the same augmentation method, \u2206ch = \u2206ct .\nHere, we define the original data distributions of head class ch and tail class ct as the base spaces Rct 2 and Rch 2, and define the expanded data distributions of head class ch and tail class ct as the marginal spaces (Rct +\u2206ct)2 \u2212 Rct 2 and (Rch +\u2206ch)2 \u2212 Rch 2\nThen, the augmentation sensitivity of head class ch and tail class ct can be defined as \u03c8ch and \u03c8ct .\n\u03c8ch = (Rch +\u2206ch)2 \u2212 Rch\n2\nRch 2 (15)\n\u03c8ct = (Rct +\u2206ct)2 \u2212 Rct\n2\nRct 2 (16)\nTherefore, we can measure the augmentation sensitivity difference between head class ch and tail class ct, i.e.,\n\u03c8ct \u2212 \u03c8ch = (Rct +\u2206ct)2 \u2212 Rct\n2\nRct 2 \u2212\n(Rch +\u2206ch)2 \u2212 Rch 2\nRch 2\n= Rct 2 + 2Rct\u2206ct +\u2206ct 2 \u2212 Rct 2\nRct 2 \u2212\nRch 2 + 2Rch\u2206ch +\u2206ch 2 \u2212 Rch 2\nRch 2\n= 2Rct\u2206ct +\u2206ct\n2\nRct 2 \u2212\n2Rch\u2206ch +\u2206ch 2\nRch 2\n= 2RctRch 2\u2206ct + Rch 2\u2206ct 2 \u2212 2R2ctRch\u2206ch \u2212 Rct 2\u2206ch 2\nRct 2Rch 2\n= 2RctRch(Rch\u2206ct \u2212 Rct\u2206ch)\nRct 2Rch\n2 + Rch 2\u2206ct 2 \u2212 Rct 2\u2206ch 2\nRct 2Rch 2\n= 2\u2206ch \u00b7 Rch \u2212 Rct RchRct +\u2206ch 2 \u00b7 Rch 2 \u2212 Rct 2 Rch 2Rct 2\n> 0\n(17)\nThe above derivation indicating that tail classes are more sensitive to the marginal space.\nFor high-dimensional feature space,\nProof. Assuming that the dimension of high-dimensional features is n,the distribution center of class c is defined as (X1c ,X2c , ...,Xnc ) and the distribution radius is Rc. The distribution span Sc can be expressed as\n(X1 \u2212 X1c)2 \u2212 (X2 \u2212 X2c)2 \u2212 ...\u2212 (Xn \u2212 Xnc )2 = Rc 2 (18)\nWe assume that the data distribution of head class ch and tail class ct are Sch and Sct and the distribution span after DA S\u0304ch and S\u0304ct . So the augmentation sensitivity \u03c8 of class c can be expressed as follows:\n\u03c8c =\n\u03c0n/2(Rc+\u2206) \u0393(1+n/2) \u2212 \u03c0n/2Rc \u0393(1+n/2)\n\u03c0n/2Rc \u0393(1+n/2)\n, (19)\nand further deduce:\n\u03c8ct \u2212 \u03c8ch = \u03c0n/2\n\u0393(1 + n/2)\n(RctRch +\u2206Rch)n \u2212 (RctRch +\u2206Rct)n\nRct nRch\nn > 0 (20)\nThis indicates that this theoretical explanation is equally applicable to higher-dimensional spaces."
        },
        {
            "heading": "A.3 PROOF OF THEOREM 4",
            "text": "Proof. We want to show that for a more dominant DA Ok1 , the bias of Ok1 from P is smaller than that of Ok2 from P , where Qk1 and Qk2 are the level-sets of the models fk1\u03b8 and f k2 \u03b8 learned using DA Ok1 and DA Ok2 , respectively, and P is the level-set of the model f\u03b8 trained on the original dataset.\nHerr, we use Chebyshev\u2019s inequality to bound the probability that a random variable deviates from its expected value by a certain amount. Let X be a random variable that represents the deviation of f\u03b8(x) from y for a sample (x, y) in the original dataset. Let Y be a random variable that represents the deviation of fk\u03b8 (Ok(x)) from y for a sample (x, y) in the augmented dataset using DA Ok. Then we have:\nP (|X \u2212 E(X)| > t) \u2264 V ar(X)/t2 (21) P (|Y \u2212 E(Y )| > t) \u2264 V ar(Y )/t2 (22)\nThe level-set bias \u03b4(Qk, P ) can be defined as the degree of distributional deviation between the level-sets Qk and P . Intuitively, this can be measured by the difference between E(Y ) and E(X), or the difference between V ar(Y ) and V ar(X). We assume that E(X) = 0, since f\u03b8 is trained to minimize the training loss on the original dataset. Then we have:\n\u03b4(Qk, P ) = |E(Y )|+ |V ar(Y )\u2212 V ar(X)| (23)\nNow, suppose that Ok1 dominates Ok2 on class c, i.e., \u2207pos z k1 c > \u2207pos z k2 c . This means that f\u03b8(Ok1(x)) is more likely to be equal to y than f\u03b8(Ok2(x)) for samples (x, y) in class c. Therefore, we have:\nE(Y |y = c,Ok1) < E(Y |y = c,Ok2) (24)\nV ar(Y |y = c,Ok1) < V ar(Y |y = c,Ok2) (25)\nBy taking the weighted average over all classes, we obtain,\nE(Y |Ok1) < E(Y |Ok2) (26)\nV ar(Y |Ok1) < V ar(Y |Ok2) (27)\nHence, we conclude that: \u03b4(Qk1 , P ) < \u03b4(Qk2 , P ) (28)\nThis completes the proof."
        },
        {
            "heading": "B RELATED WORK",
            "text": ""
        },
        {
            "heading": "B.1 LONG-TAILED LEARNING (LTL)",
            "text": "Real-world training datasets typically exhibit a long-tailed class distribution, where a small fraction of classes have massive samples and the rest classes are associated with only a few samples. Unfortunately, the deep models trained by the common practice of empirical risk minimization cannot handle this distribution, resulting in a significant decrease in model performance Zhang et al. (2021b). Recently, missive novel longt-tailed learning methods have been proposed to learn a more generalized model from imbalanced training datasets, which can be divide into three main categories: class re-balancing Kang et al. (2020); Ren et al. (2020); Wang et al. (2020); Lin et al. (2017); Cui et al. (2019); Tan et al. (2020), module improvement Zhang et al. (2017b); Ouyang et al. (2016); Tang et al. (2020); Kang et al. (2020); Zhou et al. (2020); Zhang et al. (2022), and information augmentation Chu et al. (2020); Kim et al. (2020b); Hu et al. (2020); Zang et al. (2021); Park et al. (2022); Ahn et al. (2023).\nClass re-balancing is the most typical strategy, which balances inter-class sample numbers or weights by re-sampling or cost-sensitive learning. On the one hand, traditional re-sampling methods, e.g., random over-sampling (ROS) and random under-sampling (RUS), achieve re-balancing by repeating the samples from tail classes and discarding the samples from head classes, but they tend to overfit\nto tail classes when datasets are extremely unbalanced. To this end, recent studies propose classbalanced re-sampling strategies, e.g., bi-level class-balanced sampling Wang et al. (2020) and meta learning based sampling Ren et al. (2020). Besides from the perspective of classes, scheme-oriented sampling strategies try to re-balance classes by designing some specific learning schemes, such as quintuplet sampling Huang et al. (2016) and replay based sampling Kim et al. (2020a). On the other hand, some studies, called cost-sensitive learning, re-balance classes by adjusting the loss values of different classes. For example, CB Cui et al. (2019) proposed a effective number to approximate the expected sample number of each class, and Focal loss Lin et al. (2017) used the prediction probabilities to inversely re-weight classes.\nIn addition to class re-balancing, researchers also explored enhancing model performance by improving network modules. A intuitive method is decoupled training, which decouples the learning procedure into representation learning and classifier training. As a pioneering work, Decoupling Kang et al. (2020) proposed a two-stage training scheme and showed some refreshing observations. KCL Kang et al. (2021) and FRS Wang et al. (2023) believed that a balanced feature space is beneficial to LTL, so they designed contrastive learning based losses to learn a more class-balanced and class-discriminative feature space. Furthermore, as a classic theory, ensemble learning is also applied to LTL by designing and combining multiple expert networks. For instance, BBN Zhou et al. (2020) proposed to use two network branches to handle LTL. Following BBN, BAGS Li et al. (2020b) explored a multi-head scheme. Not restricted to a balanced test set, SADE Zhang et al. (2022) explored the multi-expert scheme to handle test distribution-agnostic LTL.\nAlthough the overall performance is improved, these methods cannot essentially handle the issue of lacking information, particularly on tail classes due to limited data amount. Orthogonally, some information augmentation studies seek to introduce additional information into model training, such as FTL Yin et al. (2019) and M2m Kim et al. (2020b) transferred the knowledge from head classes to enhance model training on tail classes considering the inter-class knowledge imbalance. To solve information restrictions in essence, another line of research is to apply representation augmentation or data augmentation to LTL. For example, CMO Park et al. (2022) augmented diversified minority samples by leveraging the rich context of the majority classes as background images. Considering fairness, FSR Wang et al. (2023) and CUDA Ahn et al. (2023) advocate to find appropriate augmentation strength for each class. However, although these methods enrich the overall information to a certain extent and improve model performance, they ignored the sacrifice of some classes behind this improvement. For this reason, we jointly pay attention to the inherent datawise imbalance and extrinsic augmentation-wise imbalance, thereby minimizing the sacrifice."
        },
        {
            "heading": "B.2 DATA AUGMENTATION",
            "text": "DA has been applied in many fields because it can effectively alleviate overfitting and improve model generalization performance. DA is simple in design, and various DAs can be achieved through image manipulation, e.g., filp, crop, and rotate Robbins & Monro (1951). Recently, mixup based DA methods are proposed to improve model robustness by fusing two images and their labels Zhang et al. (2017a); Tokozume et al. (2018). Considering the diversity of DA, some studies try to combine them randomly or in order, such as AutoAugment Cubuk et al. (2019), Fast AutoAugment Lim et al. (2019), DADA Li et al. (2020a), and RandAugment Cubuk et al. (2020). In addition, researchers are improving DAs to make them suitable for LTL, however, they ignore that DA is class-independent, and thus may cause a mismatch between augmented data and actual labels Park et al. (2022); Wang et al. (2023); Ahn et al. (2023). Therefore, it is necessary to design a class-dependent long-tailed DA to allow each class to choose an appropriate augmentation method."
        },
        {
            "heading": "C DATASET AND BASELINE DETAILS",
            "text": ""
        },
        {
            "heading": "C.1 DATASET",
            "text": "CIFAR-100-LT Cao et al. (2019): is a long-tailed version of artificially truncated from the original balanced dataset CIFAR-100, which includes 100 different categories, 50,000 training images and 10,000 test images. The 100 categories in CIFAR-100 form 20 superclasses, each with 5 classes. CIFAR-100-LT has three imbalance ratio settings 10, 50, 100, where the imbalance ratio \u03c1 is defined as the ratio of the sample sizes of the most frequent and least frequent classes, i.e., \u03c1 = Nmax/Nmin.\nImageNet-LT Liu et al. (2019): is a long-tailed version of artificially truncated from the original balanced dataset ImageNet, which includes 1,000 different categories, 115,846 training images and 50,000 test images. The most frequent or least frequent class has 1,280 or 5 images, so the imbalance ratio \u03c1 = 256.\niNaturalist 2018 Van Horn et al. (2018): is a real-world, naturally long-tailed dataset, which includes 8,142 different categories, 437,513 training images and 24,426 test images. Each image has one ground truth label. The iNat dataset is highly imbalanced with dramatically different number of images per category and the imbalance ratio \u03c1 is 500."
        },
        {
            "heading": "C.2 AUGMENTATION",
            "text": "we incorporated ten commonly used DA methods in our experiments, and descriptions are shown in Table 4. The specific code implementation can be found in \u2019/aug/doda.py\u2019."
        },
        {
            "heading": "C.3 BASELINES",
            "text": "To ensure a fair comparison, we select a large number of long-tailed learning methods as baselines in our experiments, and integrate DODA with these baselines to evaluate the effectiveness and flexibility of DODA. In addition, we also select the state-of-the-art data augmentation methods as comparison baselines to prove the superiority of DODA in long-tailde learning."
        },
        {
            "heading": "Long-tailed methods:",
            "text": "\u2022 CE He et al. (2016): is a cross-entropy loss based model, which is one of the most classic methods in the field of deep long-tailed learning.\n\u2022 CE-DRW Cao et al. (2019): is a two-stage fine-tuning strategy based on cross-entropy loss. \u2022 LWS Kang et al. (2020): is a two-stage training strategy, which keeps both the representations\nand classifier weights fixed and only learn the scaling factors.\n\u2022 cRT Kang et al. (2020): is a two-stage training strategy, which keeps the representations fixed and randomly re-initialize and optimize the classifier weights using class-balanced sampling.\n\u2022 LDAM-DRW Cao et al. (2019): extends the existing soft margin loss by enforcing classdependent margins based on label frequencies and further introduces a deferred re-balancing optimization schedule.\n\u2022 BS Ren et al. (2020): proposes to use the label frequencies to adjust mode predictions during training, so that the bias of class imbalance can be alleviated by the prior knowledge.\n\u2022 RIDE (3 experts) Wang et al. (2021): introduces a knowledge distillation multi-expert framework to reduce the parameters by learning a student network with fewer experts.\n\u2022 BCL Zhu et al. (2022): proposes a balanced contrastive learning loss and learns stronger feature representations through a dual-branch framework.\n\u2022 CMO Park et al. (2022): focuses on utilizing the rich context of majority samples to improve the diversity of minority samples and mixes minority and majority images by using CutMix to enhance balancing and robustness simultaneously.\n\u2022 CUDA Ahn et al. (2023): is a simple and efficient curriculum, which is designed to find the appropriate per-class strength of data augmentation."
        },
        {
            "heading": "Data augmentation methods:",
            "text": "\u2022 AutoAugment Cubuk et al. (2019): describes a simple procedure to automatically search for improved data augmentation policies by designing a search space where a policy consists of many sub-policies, one of which is randomly chosen for each image in each mini-batch.\n\u2022 Fast AutoAugment Lim et al. (2019): finds effective augmentation policies via a more efficient search strategy based on density matching.\n\u2022 DADA Li et al. (2020a): relaxes the discrete DA policy selection to a differentiable optimization problem via Gumbel-Softmax and introduces an unbiased gradient estimator to learn an efficient and accurate DA policy.\n\u2022 RandAugment Cubuk et al. (2020): proposes a simplified search space that vastly reduces the computational expense of automated augmentation, and permits the removal of a separate proxy task."
        },
        {
            "heading": "D MORE EMPIRICAL RESULTS",
            "text": "D.1 PARAMETER SENSITIVITY ANALYSIS OF paug\nTo preserve the knowledge of the original dataset, we define the augmentation probability paug . For further analyze the impact of paug, we conduct a sensitivity analysis of hyperparameter paug. As shown in Figure 8, we test 8 different hyperparameter settings on three baselines, and the experimental results showed that a too small augmentation probability cannot sufficiently improve the model\u2019s generalization, while a too large augmentation probability cannot retain the knowledge in the original dataset, resulting in a decrease in model performance.\nD.2 PARAMETER SENSITIVITY ANALYSIS OF t\nIn previous analyses, we select the optimal DA for each class. However, we find that in some baselines, multiple DAs can be beneficial. Therefore, we further conduct a parameter sensitivity analysis on the number of DAs be selected t. As shown in Figure 9, we test three hyperparameter settings (t = 1, 2, 3) on three baselines. It can be observed that on CE and BCL, the model tends to select the optimal DA, while on BS, it tends to select both the optimal and suboptimal DAs. This phenomenon is consistent with the trend of selection hierarchies during training mentioned in the main text."
        },
        {
            "heading": "D.3 PARAMETER SENSITIVITY ANALYSIS OF NUM. OF DAS",
            "text": "As shown in Figure 10, we gradually reduced the number of DAs based on the degree of preference. The results indicate that reducing the number of augmentations leads to a loss of diversity. However, when the \u2019neglected\u2019 augmentations are removed, the model performance does not significantly degrade."
        },
        {
            "heading": "D.4 NETWORK ARCHITECTURE ANALYSIS",
            "text": "As shown in Figure 11, following Ahn et al. (2023), we also utilize ResNet-10 Liu et al. (2019) and ResNeXt-50 Xie et al. (2017) as our backbone network on ImageNet-LT. We conduct comparative experiments on three baselines (e.g., CE, BS, and BCL), and the results show that no matter what kind of backbone is used, DODA can always bring stable improvement to long-tailed learning algorithms."
        },
        {
            "heading": "D.5 TRAINING TIME ANALYSIS",
            "text": "In DODA\u2019s augmentation pipeline, we require additional computations to update and maintain the augmentation preference list for each class. Therefore, compared to the original baselines, using\nDODA incurs additional training time. As shown in Table 5, using DODA inevitably brings varying degrees of computational cost, but these costs are acceptable. For example, BS w/o DODA achieves better model performance and avoids serious sacrifices with only \u00d7 0.09 additional cost."
        },
        {
            "heading": "D.6 MORE ANALYSIS ON SACRIFICE RATES",
            "text": "SR on Different Long-tailed Baselines: We provided the sacrifice rates of different data augmentations on CE in Figure 2, indicating that DA can lead to sacrifice problems for the original baseline. Similarly, long-tailed learning baselines also face this issue. Based on your comments, we have conducted further experiments on cRT and CIFAR-100-LT dataset (IR = 100). The results in Table 6 show that CUDA improved accuracy while sacrificing performance for certain classes, while DODA mitigated this sacrifice issue by preserving performance across classes.\nIn general, just like focusing on tail classes when improving the average accuracy, when applying DAs in long-tailed learning, focusing on vulnerable classes that are easy to be sacrificed is also in line with the purpose of long-tailed learning.\nSR on Different DA Baselines: We also tested different class-independent techniques (e.g., AutoAugment, CutOut) to demonstrate the superiority of our method. The specific experimental results are shown in Table 8.\nAutoAugment improves the average accuracy on cRT and takes effect on each shot. However, we further analyze the sacrifice problem caused by DAs, and we find that despite achieving good performance, AutoAugment still cannot avoid the sacrifice problem, which means,\n\u2022 The performance improvement of AutoAugment is hypocritical, for example, in the tail classes, the model achieves performance gains on some classes, while performing badly on others (i.e., pleasing the \u2019strong\u2019 and bullying the \u2019weak\u2019). This sacrifice goes against the purpose of long-tailed learning despite the average performance improvement of the model on the tail classes.\n\u2022 Both class-independent techniques lead to the sacrifice problem of sacrifice. From the sacrifice rate of different shots, it can be found that compared with the head classes, more classes in the tail classes are sacrificed, indicating that the tail classes are more likely to be regarded as the bullied \u2019weak\u2019 mentioned above.\nSR on Different Epochs: Here, we analyzed the changes in the sacrifice rate. The results shown in Table 2 show that the sacrifice problem caused by previous DAs cannot be eliminated during training, while DODA significantly improves this."
        },
        {
            "heading": "D.7 MORE COMPARISONS WITH MODIFIED TWO-STAGE MODEL",
            "text": "Here, we compare DODA with CC-SAM Zhou et al. (2023), which is a two-stage model improvement method that trains the model in a decoupled manner and introduces class-conditional sharpness-aware minimization in the first stage. We have improved the existing open-source implementation and incorporated DODA\u2019s augmentation strategy. The quantitative experimental results are shown in Table 9."
        },
        {
            "heading": "D.8 MORE COMPARISONS WITH AUTO DA IN OTHER FIELDS",
            "text": "In this section, we compare DODA with Auto DA selection algorithms in other fields. Here we choose the most advanced method Zaiem et al. (2022) in the speech field as a comparison. However, directly applying the complete method from it in long-tailed learning does not lead to fair comparisons. So we partially implemented the augmentation strategies proposed in Zaiem et al. (2022). Firstly, since Zaiem et al. (2022) relies on a carefully designed pretext task, we replaced it with contrastive learning using cropping and augmentation, where pretext labels for each augmented view of a sample corresponding to the ID of the sample it originated from. Then, we replaced the downstream task related to speech with a long-tailed classification task. The experimental results of this modified implementation are shown in Table 10.\nIt can be observed that using the automatic augmentation strategy from Zaiem et al. (2022) results in limited performance improvement, while our method outperforms it significantly. The reasons for this are as follows: (1) Zaiem et al. (2022) relies on a carefully designed pretext task, so the improvement it brings may come from diversified data augmentation. (2) Zaiem et al. (2022) lacks the necessary focus on the tail classes, while our method pays more attention to inter-class fairness, resulting in better performance."
        },
        {
            "heading": "D.9 EXPLORATION OF COMBINATIONS WITH SOTA LONG-TAILED DA",
            "text": "From the macro perspective of long-tailed learning, both DODA and CUDA belong to dynamic DA. However, at the methodology level, the two are different. A simple comparison is as Table 11:\nIt can be seen that to ensure fairness between classes while improving accuracy, we have made some methodology-level improvements. More interestingly, we find that CUDA and DODA are orthogonal, and we can find the optimal DA function and strength at the same time. The exploratory results are as follows:"
        },
        {
            "heading": "CE + DODA 74.8 43.8 10.0 44.5",
            "text": ""
        },
        {
            "heading": "CE + DODA + CUDA 74.7 44.1 10.2 44.6",
            "text": "Although the performance gain is limited, continuing to explore this compositionality is beneficial for long-tailed learning.\nD.10 MORE TRENDS OF THE SELECTION HIERARCHIES ON DIFFERENT INDEXS"
        }
    ],
    "year": 2024
}