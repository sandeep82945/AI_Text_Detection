{
    "abstractText": "In this paper, we propose a novel approach to conformal prediction for language models (LMs) in which we produce prediction sets with performance guarantees. LM responses are typically sampled from a predicted distribution over the large, combinatorial output space of language. Translating this to conformal prediction, we calibrate a stopping rule for sampling LM outputs that get added to a growing set of candidates until we are confident that the set covers at least one acceptable response. Since some samples may be low-quality, we also simultaneously calibrate a rejection rule for removing candidates from the output set to reduce noise. Similar to conformal prediction, we can prove that the final output set obeys certain desirable distribution-free guarantees. Within these sets of candidate responses, we also show that we can also identify subsets of individual components\u2014such as phrases or sentences\u2014that are each independently correct (e.g., that are not \u201challucinations\u201d), again with guarantees. Our method can be applied to any LM API that supports sampling. Furthermore, we empirically demonstrate that we can achieve many desired coverage levels within a limited number of total samples when applying our method to multiple tasks in open-domain question answering, text summarization, and radiology report generation using different LM variants.",
    "authors": [],
    "id": "SP:c38445443ebe1ecd9551d7262f9c48a6f8215fe0",
    "references": [
        {
            "authors": [
                "Anastasios N. Angelopoulos",
                "Stephen Bates"
            ],
            "title": "A gentle introduction to conformal prediction and distribution-free uncertainty quantification, 2022",
            "year": 2022
        },
        {
            "authors": [
                "Anastasios Nikolas Angelopoulos",
                "Stephen Bates",
                "Emmanuel J. Cand\u00e8s",
                "Michael I. Jordan",
                "Lihua Lei"
            ],
            "title": "Learn then test: Calibrating predictive algorithms to achieve risk control",
            "venue": "ArXiv preprint:",
            "year": 2021
        },
        {
            "authors": [
                "Anastasios Nikolas Angelopoulos",
                "Stephen Bates",
                "Jitendra Malik",
                "Michael I. Jordan"
            ],
            "title": "Uncertainty sets for image classifiers using conformal prediction",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2021
        },
        {
            "authors": [
                "Rina Foygel Barber",
                "Emmanuel J Candes",
                "Aaditya Ramdas",
                "Ryan J Tibshirani"
            ],
            "title": "Predictive inference with the jackknife+",
            "venue": "The Annals of Statistics,",
            "year": 2021
        },
        {
            "authors": [
                "Stephen Bates",
                "Anastasios Nikolas Angelopoulos",
                "Lihua Lei",
                "Jitendra Malik",
                "Michael I. Jordan"
            ],
            "title": "Distribution free, risk controlling prediction sets",
            "venue": "ArXiv preprint:",
            "year": 2020
        },
        {
            "authors": [
                "Bernd Bohnet",
                "Vinh Q. Tran",
                "Pat Verga",
                "Roee Aharoni",
                "Daniel Andor",
                "Livio Baldini Soares",
                "Massimiliano Ciaramita",
                "Jacob Eisenstein",
                "Kuzman Ganchev",
                "Jonathan Herzig",
                "Kai Hui",
                "Tom Kwiatkowski",
                "Ji Ma",
                "Jianmo Ni",
                "Lierni Sestorain Saralegui",
                "Tal Schuster",
                "William W. Cohen",
                "Michael Collins",
                "Dipanjan Das",
                "Donald Metzler",
                "Slav Petrov",
                "Kellie Webster"
            ],
            "title": "Attributed question answering: Evaluation and modeling for attributed large language models, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Samuel R. Bowman",
                "Gabor Angeli",
                "Christopher Potts",
                "Christopher D. Manning"
            ],
            "title": "A large annotated corpus for learning natural language inference",
            "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2015
        },
        {
            "authors": [
                "Maxime Cauchois",
                "Suyash Gupta",
                "Alnur Ali",
                "John Duchi"
            ],
            "title": "Predictive inference with weak supervision, 2022",
            "year": 2022
        },
        {
            "authors": [
                "Shrey Desai",
                "Greg Durrett"
            ],
            "title": "Calibration of pre-trained transformers",
            "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 295\u2013302,",
            "year": 2020
        },
        {
            "authors": [
                "Neil Dey",
                "Jing Ding",
                "Jack Ferrell",
                "Carolina Kapper",
                "Maxwell Lovig",
                "Emiliano Planchon",
                "Jonathan P. Williams"
            ],
            "title": "Conformal prediction for text infilling and part-of-speech prediction",
            "venue": "The New England Journal of Statistics in Data Science,",
            "year": 2022
        },
        {
            "authors": [
                "Alexey Dosovitskiy",
                "Lucas Beyer",
                "Alexander Kolesnikov",
                "Dirk Weissenborn",
                "Xiaohua Zhai",
                "Thomas Unterthiner",
                "Mostafa Dehghani",
                "Matthias Minderer",
                "Georg Heigold",
                "Sylvain Gelly",
                "Jakob Uszkoreit",
                "Neil Houlsby"
            ],
            "title": "An image is worth 16x16 words: Transformers for image recognition at scale, 2021",
            "year": 2021
        },
        {
            "authors": [
                "Alexander Fabbri",
                "Chien-Sheng Wu",
                "Wenhao Liu",
                "Caiming Xiong"
            ],
            "title": "QAFactEval: Improved QAbased factual consistency evaluation for summarization",
            "venue": "In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,",
            "year": 2022
        },
        {
            "authors": [
                "Adam Fisch",
                "Tal Schuster",
                "Tommi Jaakkola",
                "Regina Barzilay"
            ],
            "title": "Efficient conformal prediction via cascaded inference with expanded admission",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2021
        },
        {
            "authors": [
                "Adam Fisch",
                "Tal Schuster",
                "Tommi Jaakkola",
                "Regina Barzilay"
            ],
            "title": "Few-shot conformal prediction with auxiliary tasks",
            "venue": "In International Conference on Machine Learning (ICML),",
            "year": 2021
        },
        {
            "authors": [
                "Adam Fisch",
                "Tal Schuster",
                "Tommi Jaakkola",
                "Regina Barzilay"
            ],
            "title": "Conformal prediction sets with limited false positives",
            "venue": "In International Conference on Machine Learning (ICML),",
            "year": 2022
        },
        {
            "authors": [
                "Samuel Gehman",
                "Suchin Gururangan",
                "Maarten Sap",
                "Yejin Choi",
                "Noah A. Smith"
            ],
            "title": "RealToxicityPrompts: Evaluating neural toxic degeneration in language models. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 3356\u20133369",
            "venue": "Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.301. URL https://aclanthology.org/2020.findings-emnlp.301",
            "year": 2020
        },
        {
            "authors": [
                "Chirag Gupta",
                "Aleksandr Podkopaev",
                "Aaditya Ramdas"
            ],
            "title": "Distribution-free binary classification: prediction sets, confidence intervals and calibration",
            "venue": "In Advances in Neural Information Processing Systems (NeurIPS),",
            "year": 2020
        },
        {
            "authors": [
                "Karl Moritz Hermann",
                "Tomas Kocisky",
                "Edward Grefenstette",
                "Lasse Espeholt",
                "Will Kay",
                "Mustafa Suleyman",
                "Phil Blunsom"
            ],
            "title": "Teaching machines to read and comprehend",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2015
        },
        {
            "authors": [
                "Sture Holm"
            ],
            "title": "A simple sequentially rejective multiple test procedure",
            "venue": "Scandinavian journal of statistics,",
            "year": 1979
        },
        {
            "authors": [
                "Ari Holtzman",
                "Jan Buys",
                "Li Du",
                "Maxwell Forbes",
                "Yejin Choi"
            ],
            "title": "The curious case of neural text degeneration",
            "venue": "In International Conference on Learning Representations (ICLR),",
            "year": 2020
        },
        {
            "authors": [
                "Or Honovich",
                "Roee Aharoni",
                "Jonathan Herzig",
                "Hagai Taitelbaum",
                "Doron Kukliansy",
                "Vered Cohen",
                "Thomas Scialom",
                "Idan Szpektor",
                "Avinatan Hassidim",
                "Yossi Matias"
            ],
            "title": "TRUE: Re-evaluating factual consistency evaluation",
            "venue": "In Proceedings of the Second DialDoc Workshop on Documentgrounded Dialogue and Conversational Question Answering,",
            "year": 2022
        },
        {
            "authors": [
                "Eliahu Horwitz",
                "Yedid Hoshen"
            ],
            "title": "Conffusion: Confidence intervals for diffusion models",
            "year": 2022
        },
        {
            "authors": [
                "Dongfu Jiang",
                "Bill Yuchen Lin",
                "Xiang Ren"
            ],
            "title": "Pairreranker: Pairwise reranking for natural language generation, 2022",
            "year": 2022
        },
        {
            "authors": [
                "Zhengbao Jiang",
                "Jun Araki",
                "Haibo Ding",
                "Graham Neubig"
            ],
            "title": "How can we know when language models know? on the calibration of language models for question answering",
            "venue": "Transactions of the Association for Computational Linguistics,",
            "year": 2021
        },
        {
            "authors": [
                "Alistair EW Johnson",
                "Tom J Pollard",
                "Nathaniel R Greenbaum",
                "Matthew P Lungren",
                "Chih-ying Deng",
                "Yifan Peng",
                "Zhiyong Lu",
                "Roger G Mark",
                "Seth J Berkowitz",
                "Steven Horng"
            ],
            "title": "Mimic-cxr-jpg, a large publicly available database of labeled chest radiographs",
            "venue": "arXiv preprint arXiv:1901.07042,",
            "year": 2019
        },
        {
            "authors": [
                "Erik Jones",
                "Jacob Steinhardt"
            ],
            "title": "Capturing failures of large language models via human cognitive biases",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Mandar Joshi",
                "Eunsol Choi",
                "Daniel S. Weld",
                "Luke Zettlemoyer"
            ],
            "title": "Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension, 2017",
            "year": 2017
        },
        {
            "authors": [
                "Joseph",
                "Ben Mann",
                "Sam McCandlish",
                "Chris Olah",
                "Jared Kaplan"
            ],
            "title": "Language models (mostly) know what they know",
            "year": 2022
        },
        {
            "authors": [
                "Tushar Khot",
                "Ashish Sabharwal",
                "Peter Clark"
            ],
            "title": "Scitail: A textual entailment dataset from science question answering",
            "venue": "In AAAI Conference on Artificial Intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "Kalpesh Krishna",
                "Aurko Roy",
                "Mohit Iyyer"
            ],
            "title": "Hurdles to progress in long-form question answering",
            "venue": "Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.393. URL https://aclanthology.org/2021.naacl-main.393",
            "year": 2021
        },
        {
            "authors": [
                "Lorenz Kuhn",
                "Yarin Gal",
                "Sebastian Farquhar"
            ],
            "title": "Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Philippe Laban",
                "Tobias Schnabel",
                "Paul N. Bennett",
                "Marti A. Hearst"
            ],
            "title": "SummaC: Re-visiting NLI-based models for inconsistency detection in summarization",
            "venue": "Transactions of the Association for Computational Linguistics,",
            "year": 2022
        },
        {
            "authors": [
                "Bracha Laufer-Goldshtein",
                "Adam Fisch",
                "Regina Barzilay",
                "Tommi S. Jaakkola"
            ],
            "title": "Efficiently controlling multiple risks with pareto testing",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Jing Lei",
                "James Robins",
                "Larry Wasserman"
            ],
            "title": "Distribution-free prediction sets",
            "venue": "Journal of the American Statistical Association,",
            "year": 2013
        },
        {
            "authors": [
                "Jing Lei",
                "Max G\u2019Sell",
                "Alessandro Rinaldo",
                "Ryan J. Tibshirani",
                "Larry Wasserman"
            ],
            "title": "Distributionfree predictive inference for regression",
            "venue": "Journal of the American Statistical Association,",
            "year": 2018
        },
        {
            "authors": [
                "Chin-Yew Lin"
            ],
            "title": "ROUGE: A package for automatic evaluation of summaries",
            "venue": "In Text Summarization Branches Out,",
            "year": 2004
        },
        {
            "authors": [
                "Stephanie Lin",
                "Jacob Hilton",
                "Owain Evans"
            ],
            "title": "TruthfulQA: Measuring how models mimic human falsehoods. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3214\u20133252, Dublin, Ireland, May 2022a",
            "venue": "Association for Computational Linguistics. doi: 10.18653/v1/2022.acl-long.229. URL https://aclanthology.org/2022.acl-long.229",
            "year": 2022
        },
        {
            "authors": [
                "Stephanie C. Lin",
                "Jacob Hilton",
                "Owain Evans"
            ],
            "title": "Teaching models to express their uncertainty",
            "venue": "in words. ArXiv,",
            "year": 2022
        },
        {
            "authors": [
                "Guanxiong Liu",
                "Tzu-Ming Harry Hsu",
                "Matthew McDermott",
                "Willie Boag",
                "Wei-Hung Weng",
                "Peter Szolovits",
                "Marzyeh Ghassemi"
            ],
            "title": "Clinically accurate chest x-ray report generation",
            "venue": "In Machine Learning for Healthcare Conference,",
            "year": 2019
        },
        {
            "authors": [
                "Nelson F. Liu",
                "Tianyi Zhang",
                "Percy Liang"
            ],
            "title": "Evaluating verifiability in generative search engines, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Alex Mallen",
                "Akari Asai",
                "Victor Zhong",
                "Rajarshi Das",
                "Hannaneh Hajishirzi",
                "Daniel Khashabi"
            ],
            "title": "When not to trust language models: Investigating effectiveness and limitations of parametric and non-parametric memories",
            "year": 2022
        },
        {
            "authors": [
                "Mengqi Miao",
                "Fandong Meng",
                "Yijin Liu",
                "Xiao-Hua Zhou",
                "Jie Zhou"
            ],
            "title": "Prevent the language model from being overconfident in neural machine",
            "year": 2021
        },
        {
            "authors": [
                "Sabrina J. Mielke",
                "Arthur Szlam",
                "Emily Dinan",
                "Y-Lan Boureau"
            ],
            "title": "Reducing conversational agents\u2019 overconfidence through linguistic calibration",
            "venue": "Transactions of the Association for Computational Linguistics,",
            "year": 2022
        },
        {
            "authors": [
                "Eric Mitchell",
                "Joseph Noh",
                "Siyan Li",
                "Will Armstrong",
                "Ananth Agarwal",
                "Patrick Liu",
                "Chelsea Finn",
                "Christopher Manning"
            ],
            "title": "Enhancing self-consistency and performance of pre-trained language models through natural language inference",
            "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2022
        },
        {
            "authors": [
                "Yasuhide Miura",
                "Yuhao Zhang",
                "Emily Bao Tsai",
                "Curtis P. Langlotz",
                "Dan Jurafsky"
            ],
            "title": "Improving factual completeness and consistency of image-to-text radiology report",
            "year": 2021
        },
        {
            "authors": [
                "Aaron Nicolson",
                "Jason Dowling",
                "Bevan Koopman"
            ],
            "title": "Improving chest x-ray report generation by leveraging warm-starting, 2022",
            "year": 2022
        },
        {
            "authors": [
                "Harris Papadopoulos"
            ],
            "title": "Inductive conformal prediction: Theory and application to neural networks",
            "venue": "In Tools in Artificial Intelligence,",
            "year": 2008
        },
        {
            "authors": [
                "Harris Papadopoulos",
                "Kostas Proedrou",
                "Volodya Vovk",
                "Alex Gammerman"
            ],
            "title": "Inductive confidence machines for regression",
            "venue": "In European Conference on Machine Learning,",
            "year": 2002
        },
        {
            "authors": [
                "Alec Radford",
                "Jeffrey Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "venue": "OpenAI blog,",
            "year": 2019
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J. Liu"
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "year": 2020
        },
        {
            "authors": [
                "Maribeth Rauh",
                "John Mellor",
                "Jonathan Uesato",
                "Po-Sen Huang",
                "Johannes Welbl",
                "Laura Weidinger",
                "Sumanth Dathathri",
                "Amelia Glaese",
                "Geoffrey Irving",
                "Iason Gabriel",
                "William Isaac",
                "Lisa Anne Hendricks"
            ],
            "title": "Characteristics of harmful text: Towards rigorous benchmarking of language models, 2022",
            "year": 2022
        },
        {
            "authors": [
                "Shauli Ravfogel",
                "Yoav Goldberg",
                "Jacob Goldberger"
            ],
            "title": "Conformal nucleus sampling",
            "year": 2023
        },
        {
            "authors": [
                "Yaniv Romano",
                "Evan Patterson",
                "Emmanuel Cand\u00e8s"
            ],
            "title": "Conformalized quantile regression",
            "venue": "In Advances in Neural Information Processing Systems (NeurIPS),",
            "year": 2019
        },
        {
            "authors": [
                "Tal Schuster",
                "Adam Fisch",
                "Regina Barzilay"
            ],
            "title": "Get your vitamin C! robust fact verification with contrastive evidence",
            "venue": "In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,",
            "year": 2021
        },
        {
            "authors": [
                "Tal Schuster",
                "Adam Fisch",
                "Tommi Jaakkola",
                "Regina Barzilay"
            ],
            "title": "Consistent accelerated inference via confident adaptive transformers",
            "venue": "In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,",
            "year": 1865
        },
        {
            "authors": [
                "Tal Schuster",
                "Sihao Chen",
                "Senaka Buthpitiya",
                "Alex Fabrikant",
                "Donald Metzler"
            ],
            "title": "Stretching sentence-pair NLI models to reason over long documents and clusters. In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 394\u2013412",
            "venue": "Abu Dhabi, United Arab Emirates,",
            "year": 2022
        },
        {
            "authors": [
                "Tal Schuster",
                "Adam Fisch",
                "Jai Gupta",
                "Mostafa Dehghani",
                "Dara Bahri",
                "Vinh Q. Tran",
                "Yi Tay",
                "Donald Metzler"
            ],
            "title": "Confident adaptive language modeling",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Abigail See",
                "Peter J. Liu",
                "Christopher D. Manning"
            ],
            "title": "Get to the point: Summarization with pointer-generator",
            "venue": "networks. CoRR,",
            "year": 2017
        },
        {
            "authors": [
                "Noam Shazeer",
                "Mitchell Stern"
            ],
            "title": "Adafactor: Adaptive learning rates with sublinear memory cost, 2018",
            "year": 2018
        },
        {
            "authors": [
                "Akshay Smit",
                "Saahil Jain",
                "Pranav Rajpurkar",
                "Anuj Pareek",
                "Andrew Y. Ng",
                "Matthew P. Lungren"
            ],
            "title": "Chexbert: Combining automatic labelers and expert annotations for accurate radiology report labeling using bert, 2020",
            "year": 2020
        },
        {
            "authors": [
                "Aarohi Srivastava",
                "Abhinav Rastogi",
                "Abhishek Rao",
                "Abu Awal Md Shoeb",
                "Abubakar Abid",
                "Adam Fisch",
                "Adam R. Brown",
                "Adam Santoro",
                "Aditya Gupta",
                "Adri\u00e0 Garriga-Alonso"
            ],
            "title": "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models, 2022",
            "year": 2022
        },
        {
            "authors": [
                "Jacopo Teneggi",
                "Matthew Tivnan",
                "J. Webster Stayman",
                "Jeremias Sulam"
            ],
            "title": "How to trust your diffusion model: A convex optimization approach to conformal risk",
            "venue": "control. ArXiv,",
            "year": 2023
        },
        {
            "authors": [
                "James Thorne",
                "Andreas Vlachos",
                "Christos Christodoulopoulos",
                "Arpit Mittal"
            ],
            "title": "FEVER: a largescale dataset for fact extraction and VERification",
            "year": 2018
        },
        {
            "authors": [
                "Hugo Touvron",
                "Thibaut Lavril",
                "Gautier Izacard",
                "Xavier Martinet",
                "Marie-Anne Lachaux",
                "Timoth\u00e9e Lacroix",
                "Baptiste Rozi\u00e8re",
                "Naman Goyal",
                "Eric Hambro",
                "Faisal Azhar",
                "Aurelien Rodriguez",
                "Armand Joulin",
                "Edouard Grave",
                "Guillaume Lample"
            ],
            "title": "Llama: Open and efficient foundation language models, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Helena Vasconcelos",
                "Gagan Bansal",
                "Adam Fourney",
                "Q. Vera Liao",
                "Jennifer Wortman Vaughan"
            ],
            "title": "Generation probabilities are not enough: Exploring the effectiveness of uncertainty highlighting in ai-powered code completions",
            "year": 2023
        },
        {
            "authors": [
                "Vladimir Vovk"
            ],
            "title": "On-line confidence machines are well-calibrated",
            "venue": "In The 43rd Annual IEEE Symposium on Foundations of Computer Science.,",
            "year": 2002
        },
        {
            "authors": [
                "Vladimir Vovk",
                "Alex Gammerman",
                "Glenn Shafer"
            ],
            "title": "Algorithmic Learning in a Random World",
            "year": 2005
        },
        {
            "authors": [
                "Vladimir Vovk",
                "Ivan Petej",
                "Valentina Fedorova"
            ],
            "title": "Large-scale probabilistic predictors with and without guarantees of validity",
            "venue": "In Advances in Neural Information Processing Systems (NeurIPS),",
            "year": 2015
        },
        {
            "authors": [
                "Vladimir Vovk",
                "Jieli Shen",
                "Valery Manokhin",
                "Min-ge Xie"
            ],
            "title": "Nonparametric predictive distributions based on conformal prediction",
            "venue": "In Proceedings of the Sixth Workshop on Conformal and Probabilistic Prediction and Applications,",
            "year": 2017
        },
        {
            "authors": [
                "Xuezhi Wang",
                "Jason Wei",
                "Dale Schuurmans",
                "Quoc V Le",
                "Ed H. Chi",
                "Sharan Narang",
                "Aakanksha Chowdhery",
                "Denny Zhou"
            ],
            "title": "Self-consistency improves chain of thought reasoning in language models",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Johannes Welbl",
                "Amelia Glaese",
                "Jonathan Uesato",
                "Sumanth Dathathri",
                "John F.J. Mellor",
                "Lisa Anne Hendricks",
                "Kirsty Anderson",
                "Pushmeet Kohli",
                "Ben Coppin",
                "Po-Sen Huang"
            ],
            "title": "Challenges in detoxifying language",
            "venue": "models. ArXiv,",
            "year": 2021
        },
        {
            "authors": [
                "Adina Williams",
                "Nikita Nangia",
                "Samuel Bowman"
            ],
            "title": "A broad-coverage challenge corpus for sentence understanding through inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1112\u20131122",
            "year": 2018
        },
        {
            "authors": [
                "Thomas Wolf",
                "Lysandre Debut",
                "Victor Sanh",
                "Julien Chaumond",
                "Clement Delangue",
                "Anthony Moi",
                "Pierric Cistac",
                "Tim Rault",
                "R\u2019emi Louf",
                "Morgan Funtowicz",
                "Jamie Brew"
            ],
            "title": "Huggingface\u2019s transformers: State-of-the-art natural language processing",
            "year": 1910
        },
        {
            "authors": [
                "Yonghui Wu",
                "Mike Schuster",
                "Zhifeng Chen",
                "Quoc V Le",
                "Mohammad Norouzi",
                "Wolfgang Macherey",
                "Maxim Krikun",
                "Yuan Cao",
                "Qin Gao",
                "Klaus Macherey"
            ],
            "title": "Google\u2019s neural machine translation system: Bridging the gap between human and machine translation",
            "venue": "arXiv preprint arXiv:1609.08144,",
            "year": 2016
        },
        {
            "authors": [
                "Xiang Yue",
                "Boshi Wang",
                "Kai Zhang",
                "Ziru Chen",
                "Yu Su",
                "Huan Sun"
            ],
            "title": "Automatic evaluation of attribution by large language models",
            "venue": "arXiv preprint arXiv:2305.06311,",
            "year": 2023
        },
        {
            "authors": [
                "Polina Zablotskaia",
                "Du Phan",
                "Joshua Maynez",
                "Shashi Narayan",
                "Jie Ren",
                "Jeremiah Liu"
            ],
            "title": "On uncertainty calibration and selective generation in probabilistic neural summarization: A benchmark study",
            "year": 2023
        },
        {
            "authors": [
                "Yuan Zhang",
                "Jason Baldridge",
                "Luheng He"
            ],
            "title": "PAWS: Paraphrase adversaries from word scrambling",
            "year": 2019
        },
        {
            "authors": [
                "Kaitlyn Zhou",
                "Dan Jurafsky",
                "Tatsunori Hashimoto"
            ],
            "title": "Navigating the grey area: Expressions of overconfidence and uncertainty in language",
            "venue": "models. ArXiv,",
            "year": 2023
        },
        {
            "authors": [
                "Angelopoulos"
            ],
            "title": "2021a). Intuitively, this defines a sequence of configurations that are Pareto-optimal, ordered by the likelihood of them being able to satisfy all of our constraints. Since in this work we only have one constraint (coverage), this reduces to finding the sequence of Pareto-optimal configurations ordered from most to least likely to result in valid coverage",
            "year": 2021
        },
        {
            "authors": [
                "PAWS (Zhang et al",
                "VitaminC (Schuster"
            ],
            "title": "2021a) to make a binary prediction of whether an hypothesis sentence is entailed by the given premise (in three-way datasets, the neutral class was merged with the negative class). We query the model with each component as the hypothesis, and the source summary as the premise, and measure the log-probability of predicting \u201centailment",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "In this paper, we propose a novel approach to conformal prediction for language models (LMs) in which we produce prediction sets with performance guarantees. LM responses are typically sampled from a predicted distribution over the large, combinatorial output space of language. Translating this to conformal prediction, we calibrate a stopping rule for sampling LM outputs that get added to a growing set of candidates until we are confident that the set covers at least one acceptable response. Since some samples may be low-quality, we also simultaneously calibrate a rejection rule for removing candidates from the output set to reduce noise. Similar to conformal prediction, we can prove that the final output set obeys certain desirable distribution-free guarantees. Within these sets of candidate responses, we also show that we can also identify subsets of individual components\u2014such as phrases or sentences\u2014that are each independently correct (e.g., that are not \u201challucinations\u201d), again with guarantees. Our method can be applied to any LM API that supports sampling. Furthermore, we empirically demonstrate that we can achieve many desired coverage levels within a limited number of total samples when applying our method to multiple tasks in open-domain question answering, text summarization, and radiology report generation using different LM variants."
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "Language models (LMs) have emerged as powerful tools for solving natural language processing (NLP) tasks. Given an input prompt, LMs generate a response from some predicted distribution over output text sequences. For modern models, these generations are often coherent and contextually relevant. At the same time, these generations can still contain mistakes, and lack certain aspects of robustness and reliability in terms of providing accurate, trustworthy predictions (Jones and Steinhardt, 2022; Krishna et al., 2021; Lin et al., 2022a; Mallen et al., 2022; Srivastava et al., 2022; Wang et al., 2023). Unfortunately, quantifying the uncertainty in LM outputs has remained a major challenge.\nConformal prediction is a popular model-agnostic and distribution-free method for creating prediction sets that contain the correct answers with high probability (Angelopoulos et al., 2023; 2021a;b; Bates et al., 2020; Lei et al., 2018; Romano et al., 2019; Vovk et al., 2005). Applying conformal prediction to generative models such as LMs, however, is challenging due to (a) the unbounded nature of their output space (i.e., all possible text sequences), and (b) the limited available (tractable) mechanisms for exploring all possible predictions. In particular, LMs can typically only approximately search or sample candidate responses. Furthermore, while several possible responses might be acceptable (e.g., correct or factual), small differences can result in abrupt changes in coherence or meaning.\nIn this paper, we propose an extension of conformal prediction that is tailored specifically to generative LMs. We only assume that the (potentially black-box) LM that is given to us can be used to sample diverse output sequences, together with their evaluated model likelihoods (i.e., the output token sequence logits). Like conformal prediction, our method offers a rigorous coverage guarantee by constructing prediction sets that, in our case, provably contain at least one acceptable response with high probability. Unlike conformal prediction, however, we do not enumerate the entire output space (which is impossible). Instead, we derive a calibrated stopping rule for sampling different outputs from the LM that get added to a growing output set of candidates, until we are confident that the output set is sufficient. Since not all samples from the LM may be high quality (e.g., some may be redundant, incoherent, or have lower confidence), we also simultaneously calibrate a rejection rule for removing candidates from the output set\u2014while still ensuring that our coverage bound is not violated. This gives the benefit of making our output sets not only accurate, but also precise (i.e., small).\nTo more concretely describe the exact type of guarantee that we provide, suppose we have been given a calibration set Dcal = (Xi, Ai) \u2208 X \u00d7A, i = 1, . . . , n of independent and identically distributed (i.i.d.) prompts and \u201cadmission\u201d functions (see also (Fisch et al., 2021a)). Here, Ai is a binary random function that measures whether or not a generation y \u2208 Y for prompt Xi is \u201cgood enough\u201d (i.e., Ai(y) = 1). Note that randomness in Ai can come from implicit random covariates\u2014such as relying on a random annotated reference, Y refi , to compare the candidate y to. Figure 1 illustrates a setting where Xi is an X-ray to automatically analyze and produce a report for, while Ai extracts individual findings from each generated report and checks if they correspond to those given by an expert radiologist. Let Xtest be a new i.i.d. test prompt. Using Dcal to guide our choice of hyper-parameters \u03bb \u2208 \u039b, for any \u03f5, \u03b4 \u2208 (0, 1), our goal is to generate a set of samples C\u03bb(Xtest) \u2286 2Y that satisfies\nP ( P ( \u2203y \u2208 C\u03bb(Xtest) : Atest(y) = 1 | Dcal ) \u2265 1\u2212 \u03f5 ) \u2265 1\u2212 \u03b4. (1)\nThe outer and inner probabilities are over the draws of Dcal and (Xtest, Atest), respectively. \u03f5 is our error tolerance, while \u03b4 controls for the sensitivity of our algorithm with respect to calibration data.\nWhile Eq. (1) stipulates the existence of at least one \u201cacceptable\u201d generation in C\u03bb(Xtest), it does not tell us much about individual responses, y \u2208 C\u03bb(Xtest). Additionally, longer generations are often composed of multiple statements. In our radiology setting, a report may contain multiple findings, such as \u201cCardiomegaly is moderate. There is mild pulmonary interstitial edema.\u201d We futher identify a subset of confident components that would independently be categorized as being correct (given another admission function Actest, this time operating over generation fragments). For example, we might predict that \u201cCardiomegaly is moderate.\u201d is correct, but perhaps not \u201cThere is mild pulmonary interstitial edema.\u201d This can not only be useful in catching incorrect statements, but can also help identify independently correct parts of a larger generation, even when the overall quality of the full generation is poor. Like Eq. (1), we calibrate this process such that it gives accurate results with high probability.\nContributions. In summary, our main results are as follows:\n\u2022 We bridge the gap between conformal prediction and LMs by calibrating the sampling of output sets, rather than enumerating and selecting candidate responses directly from the output space;\n\u2022 We extend multi-label conformal prediction to identify confident components of long generations; \u2022 Though limitations apply, we demonstrate valid risk control on multiple diverse tasks with different\nLMs, while still retaining meaningful output sets that are efficient and precise compared to baselines."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "Conformal prediction and risk control. Our work adds to the rich collection of tools for uncertainty estimation and risk control for machine learning algorithms (Angelopoulos et al., 2023; 2021a; Barber et al., 2021; Bates et al., 2020; Fisch et al., 2022; Gupta et al., 2020; Lei et al., 2013; 2018; Vovk, 2002; Vovk et al., 2015; 2017, inter alia). These techniques were previously extended and\napplied in the language domain to classification with finitely-many classes (Fisch et al., 2021a;b; Jones and Steinhardt, 2022), to token-level predictions (Dey et al., 2022; Ravfogel et al., 2023), and to reliably accelerate LMs (Laufer-Goldshtein et al., 2023; Schuster et al., 2021b; 2022b). Here, we address the emerging challenge of providing reliable prediction sets for unbounded, free-text generation\u2014which previous methods are unequipped for. The distribution-free, finite-sample performance guarantees that we derive are similar to those given by prediction sets or regression intervals in standard conformal prediction (Angelopoulos et al., 2023; Papadopoulos et al., 2002; Vovk et al., 2005), but with slightly relaxed \u201ccorrectness\u201d criterions (Cauchois et al., 2022; Fisch et al., 2021a). In particular, we build on the groundwork set by Angelopoulos et al. (2021a), which provides a general methodology for calibrating any risk function that is controllable via some low-dimensional hyper-parameter configuration. We extend their framework to handle sampling-based algorithms that can effectively be used for LMs, and that, critically, do not require enumerating the full output space (which is intractable in our case). Most relevant to our work in LMs, other recent approaches have built on conformal principles to construct confidence intervals for generative diffusion models over images (Horwitz and Hoshen, 2022; Teneggi et al., 2023). These methods do not directly translate to LMs, however, as they only provide non-combinatorial confidence intervals at the pixel-level.\nUncertainty estimation in LMs. As the use of LMs in-the-wild quickly grows, there is increasing interest in obtaining and expressing meaningful confidence estimates for each output. Recent studies show that the logits of out-of-the-box LMs tend to exhibit overconfidence, even when wrong (Desai and Durrett, 2020; Kadavath et al., 2022; Miao et al., 2021; Vasconcelos et al., 2023). Recent alignment techniques degrade this even further (Kadavath et al., 2022; OpenAI, 2023). Most current mitigation approaches focus on introducing linguistic cues (Lin et al., 2022b; Zhou et al., 2023) or post-hoc logit calibration (Jiang et al., 2021; Kadavath et al., 2022; Mielke et al., 2022; Zablotskaia et al., 2023). In this work, we develop similar techniques to improve the output of the underlying LM. Our methods are model agnostic and provide rigorous guarantees. Our conformal component selection (\u00a74.4) also relates to recent self-consistency work that builds on the empirical observation that repeated similar samples are more likely to be correct (Mitchell et al., 2022; Wang et al., 2023), and cross-sample entailment can approximate uncertainty (Kuhn et al., 2023). Unlike previous work that uses a fixed number of re-samples and compares full outputs, we (a) introduce a dynamic stopping rule to reduce the number of samples, (b) extend this concept to semantically compare sub-components of long text outputs, and (c) conformalize the process to provide proper guarantees.\nReliable generation. xIt is common practice to post-hoc apply classifiers and filters on top of LM generations for various quality goals such as preventing toxicity (Gehman et al., 2020; Rauh et al., 2022; Welbl et al., 2021), verifying grounding against sources (Bohnet et al., 2023; Liu et al., 2023; Yue et al., 2023), or re-ranking the set of decoded outputs (Jiang et al., 2022). Our work provides a systematic and reliable approach for filtering or flagging poor-quality outputs\u2014both at a full generation and component level\u2014and can also readily incorporate additional signal from auxiliary classifiers. For example, we demonstrate in our experiments using off-the-shelf natural language inference (NLI) models (Bowman et al., 2015; Khot et al., 2018; Schuster et al., 2021a; Thorne et al., 2018; Williams et al., 2018; Zhang et al., 2019) to help guide the selection of individual, confident components in text summarization (i.e., sentences that are fully entailed by the larger text (Fabbri et al., 2022; Honovich et al., 2022; Laban et al., 2022; Schuster et al., 2022a))."
        },
        {
            "heading": "3 BACKGROUND",
            "text": "We begin with a review of conformal prediction and risk control (see also (Angelopoulos and Bates, 2022)). We use upper-case letters (X) to denote random variables; lower-case letters (x) to denote constants, and script letters (X ) to denote sets, unless otherwise specified. Proofs are in Appendix D. Given a new example x, for every candidate label y \u2208 Y standard conformal prediction either accepts or rejects the null hypothesis that the pairing (x, y) is correct. The test statistic for this test is a nonconformity measure, M((x, y),D), where D is a dataset of labeled examples. Informally, a lower value ofM reflects that point (x, y) \u201cconforms\u201d to D, whereas a higher value ofM reflects that (x, y) does not. For example, a practical choice forM could be the model-based negative log likelihood, \u2212 log p\u03b8(y|x), where \u03b8 are parameters fit to D. Split conformal prediction (Papadopoulos, 2008) uses a separate training set Dtrain to learn a fixedM that is not modified during calibration or prediction. To construct a prediction set for the new test point x, the conformal classifier outputs\nall y for which the null hypothesis (that pairing (x, y) is correct) is not rejected. This is achieved by comparing the scores of the test candidate pairs to the scores computed over n calibration examples. Theorem 3.1 (Split conformal prediction (Papadopoulos, 2008; Vovk et al., 2005)). Let (Xi, Yi), i = 1, . . . , n+ 1 be exchangeable random variables. Let random variable Vi =M(Xi, Yi) be the nonconformity score of (Xi, Yi), whereM is fixed. For \u03f5 \u2208 (0, 1), define the prediction (based on the first n examples) at x \u2208 X as\nC\u03f5(x) := { y \u2208 Y :M(x, y) \u2264 Quantile(1\u2212 \u03f5; V1:n \u222a {\u221e}) } (2)\nThen P(Yn+1 \u2208 C\u03f5(Xn+1)) \u2265 1\u2212 \u03f5.\nNote that the coverage expressed in Theorem 3.1 is marginal over the draw of calibration and test data. The recent Learn Then Test (LTT) framework of Angelopoulos et al. (2021a) extends conformal prediction to control the expectation of any loss function (conditional on the draw of calibration data) by reframing hyper-parameter selection as a multiple hypothesis testing problem.\nSpecifically, let L : \u039b\u2192 R be any random function using a hyper-parameter configuration \u03bb in some space \u039b. For example, we might have L(\u03bb) := \u2113(X,Y ;\u03bb) for some fixed loss function \u2113 with random inputs (X,Y ). Unlike conformal prediction, however, \u03bb can be multi-dimensional (e.g., consist of multiple thresholds). Let Li, i = 1, . . . , n be an i.i.d. calibration set Dcal of random functions, and Ltest a random test function. Let \u03f5 \u2208 R be a tolerance for the test risk, E[Ltest(\u03bb)] \u2264 \u03f5. LTT then identifies a random (depending on Dcal) subset of parameters, \u039bvalid \u2286 \u039b, with the goal of guaranteeing\nP (\nsup \u03bb\u2208\u039bvalid\nE[Ltest(\u03bb) | Dcal] \u2264 \u03f5 ) \u2265 1\u2212 \u03b4, (3)\nwhere the outer probability is over the draw of Dcal, and the inner expectation is over draws of Ltest. This then implies that any \u03bb \u2208 \u039bvalid can be selected to control the risk of Ltest. In short, this is achieved by associating the null hypothesisH\u03bb : E[Ltest(\u03bb)] > \u03f5 to each \u03bb \u2208 \u039b. For each null hypothesis, we then use the calibration set to compute a super-uniform p-value p\u03bb using concentration inequalities. Any multiple testing algorithm T (p\u03bb : \u03bb \u2208 \u039b) that controls the family-wise error rate (FWER) can then be used to identify the subset of non-rejected \u03bb, i.e., \u039bvalid.1 Note that it is possible that \u039bvalid = \u2205, in the case that we fail to identify any statistically valid solutions (and the desired risk may not even be achievable with any \u03bb). In this situation, we set \u03bb = null, and either reject the task, or provide a trivial solution (e.g., a classifier that provides all possible labels Y). Theorem 3.2 (Learn Then Test (Angelopoulos et al., 2021a)). Suppose p\u03bb is super-uniform under H\u03bb for all \u03bb. Let T be any FWER-controlling algorithm at level \u03b4. Then \u039bvalid satisfies Eq. (3).\nDefining C\u03bb(x) := {y \u2208 Y :M(x, y) \u2264 \u03bb}, \u039b \u2282 R, and L(\u03bb) := 1{Y \u0338\u2208 C\u03bb(X)} recovers a criterion similar to that of conformal prediction (though not marginal over Dcal). Unfortunately, in either instantiation (LTT vs. conformal prediction) iterating over y \u2208 Y is intractable for LMs, regardless of whatever calibration technique is ultimately used. Instead, in \u00a74, we introduce our method for generating uncertainty sets by casting \u03bb as a configuration of a sampling algorithm, rather than a filter on the output space Y . We then show that this randomized algorithm can still be calibrated with LTT."
        },
        {
            "heading": "4 CONFORMAL LANGUAGE MODELING",
            "text": "We now introduce our method for generating uncertainty sets for LMs. At a high level, our procedure consists of three main steps to sample and return an collection of plausible output predictions:\n1. Sample. A new candidate response y is sampled from our language model. 2. Accept or reject. The sample y is added to the growing output set, as long as it is diverse (e.g.,\nmaximum overlap with any other element is\u2264 \u03bb1) and confident (e.g., the LM likelihood is\u2265 \u03bb2). 3. Stop or repeat. Using a set-based scoring function, we check if the confidence in the current set\nis \u2265 \u03bb3. If it is, then we stop and return the current set. Otherwise we return to Step 1.\n\u03bb = (\u03bb1, \u03bb2, \u03bb3) is a configuration that we calibrate to find a valid setting, \u03bb\u0302 = (\u03bb\u03021, \u03bb\u03022, \u03bb\u03023), that controls the risk of our output sets. In the following, we more carefully define our setting and notation\n1A FWER-controlling algorithm at level \u03b4 is any procedure that accepts or rejects null hypotheses H\u03bb, while ensuring that the probability of falsely rejecting any H\u03bb, \u2200\u03bb \u2208 \u039b, is less than \u03b4.\nAlgorithm 1 Conformal sampling with rejection Definitions: x is an input prompt, F is our set-based confidence function, S is our text similarity function,Q is our sample quality estimator, \u03bb is our threshold configuration, and kmax is our sampling budget. p\u03b8(y | x) is the conditional output distribution defined by our language model.\n1: function SAMPLE(x, F , S, Q, \u03bb, kmax) 2: C\u03bb \u2190 {} \u25b7 Initialize an empty output set. 3: for k = 1, 2, . . . , kmax do 4: yk \u2190 y \u223c p\u03b8(y | x). \u25b7 Sample a new response. 5: if Q(x, yk) < \u03bb2 then \u25b7 Reject if its estimated quality is too low. 6: continue 7: if max{S(yk, yj) : yj \u2208 C\u03bb} > \u03bb1 then \u25b7 Reject if it is too similar to other samples. 8: continue 9: C\u03bb = C\u03bb \u222a {yk}. \u25b7 Add the new response to the output set. 10: if F(C\u03bb) \u2265 \u03bb3 then \u25b7 Check if we are confident enough to stop. 11: break 12: return C\u03bb\n(\u00a74.1), and then describe our sampling (\u00a74.2) and calibration algorithms (\u00a74.3). Then, in \u00a74.4, we provide an additional extension for highlighting confident generation components\u2014i.e., subsections of our full generations that are independently likely to be correct, even if the full generation is not."
        },
        {
            "heading": "4.1 FORMAL SETTING AND NOTATION",
            "text": "Let V be an alphabet (a non-empty, finite set of tokens such as {\u201ca\u201d, \u201cb\u201d, \u201cc\u201d, . . .}) from which all possible output strings, y, are composed, i.e. Y := \u22c3\u221e n=0 Vn. We assume that we are given a generative model p\u03b8(y | x) that defines a conditional probability distribution given some input prompt x \u2208 X which we can sample from to obtain output strings, y \u223c p\u03b8(y | x). Following Fisch et al. (2021a), for every input prompt x, we also further assume access to some \u201cadmission\u201d function A : Y \u2192 {0, 1} that is used to measure the acceptability of a given sample y. Intuitively, A tells us if an output is \u201cgood enough\u201d. We explore different tasks and admission functions in our experiments in \u00a75. See Appendix A for an extended discussion of this setting and its assumptions. Given a sampled calibration set Dcal, our goal is then to derive a configurable algorithm with input parameters \u03bb \u2208 \u039b for constructing a prediction C\u03bb that we can calibrate to satisfy Eq. (1). In the framework of LTT (refer to \u00a73), this is equivalent to defining Li(\u03bb) = 1{\u2204y \u2208 C\u03bb(Xi) : Ai(y) = 1}, and using Dcal to find a value \u03bb\u0302 such that E[Ltest(\u03bb\u0302)] \u2264 \u03f5, with probability at least 1\u2212 \u03b4 over the draw of Dcal."
        },
        {
            "heading": "4.2 CONFORMAL SAMPLING WITH REJECTION",
            "text": "Let F : 2Y \u2192 R be a set-based function that, for any set C \u2208 2Y , gives a set confidence score for the event 1{\u2203y \u2208 C : A(y) = 1}. F should not depend on Dcal. Furthermore, let S : Y \u00d7 Y \u2192 R be a text-based similarity function (e.g., BLEU or ROUGE) that we use to detect duplicates and preserve diversity in C, and Q : X \u00d7 Y \u2192 R an input-conditional text-based measure of an individual response\u2019s quality\u2014such as the LM\u2019s likelihood function, p\u03b8(y | x). We define and test different instances of these functions in \u00a75.2. We then adopt a sampling-based procedure that grows an output set, C1 \u2286 C2 \u2286 . . . \u2286 Ck\u22121, by repeatedly taking samples yk \u223c p\u03b8(y | x), and updating\nCk :=  Ck\u22121 \u222a {yk} if max{S(yk, yj) : yj \u2208 Ck\u22121} \u2264 \u03bb1\nand Q(x, yk) \u2265 \u03bb2, Ck\u22121 otherwise.\n(4)\nuntil the confidence after k samples, F(Ck), is \u2265 \u03bb3 (or some sampling budget kmax is reached). As an intuitive, but toy, example, suppose we modeled yk \u223c p\u03b8(y | x), k = 1, 2, . . . as a Bernoulli process, where each yk has the same probability of success p that we assume (albeit unrealistically) that we know. For Xtest, \u201csuccess\u201d is determined by the admission function, Atest. The confidence that our current set Ck contains at least one admissible answer (without rejection) then follows a geometric distribution, Geo(p): all that remains is to compute the minimum number of samples to take such that Eq. (1) is satisfied. This is achieved by taking F(Ck) = k and \u03bb3 = \u2308log(\u03f5)/ log(1\u2212 p)\u2309.\nOf course, in reality we do not know the probability of success p for test examples. Furthermore, the samples yk are not independent, and since we are also able to observe their values, better strategies may exist to conditionally estimate A(yk) = 1. Therefore, we allow F to be any set-based function\u2014 that we also pair with similarity function S, and sample quality function Q, for handling rejections. Pseudocode is given in Algorithm 1. We derive, calibrate, and test different variations of F , S , andQ in \u00a75 and \u00a76, respectively. Using \u03bb = (\u03bb1, \u03bb2, \u03bb3), we write C\u03bb(Xtest) to denote the final output set."
        },
        {
            "heading": "4.3 CALIBRATION WITH LEARN THEN TEST",
            "text": "Let \u039b be a finite set of configurations. For example, if searching for a value of \u03bb = (\u03bb1, \u03bb2, \u03bb3) \u2208 [0, 1]3, we might consider the evenly-spaced set \u039b = { i\u03ba : i = 1, . . . , \u03ba}\n3 for some finite \u03ba \u2208 N. For each \u03bb \u2208 \u039b, LTT then requires computing a valid p-value p\u03bb, where p\u03bb is a super-uniform random variable underH\u03bb. Here, we can obtain valid p-values from the empirical risk on Dcal,\nR\u0302n(\u03bb) := 1\nn n\u2211 i=1 Li(\u03bb), where Li(\u03bb) = 1 { \u2204y \u2208 C\u03bb(Xi) : Ai(y) = 1 } , (5)\nLemma 4.1 (Binomial tail bound p-values). Let R\u0302n(\u03bb) be the empirical risk in Eq. (5), and let Binom(n, \u03f5) denote a binomial random variable with sample size n and success probability \u03f5. Then\npBT\u03bb := P(Binom(n, \u03f5) \u2264 nR\u0302n(\u03bb)) (6) is a valid p-value forH\u03bb : E[Ltest(\u03bb)] > \u03f5.\nWhen paired with any FWER-controlling algorithm T at level \u03b4, we obtain the set \u039bvalid \u2286 \u039b by selecting all configurations for hypotheses H\u03bb that are rejected by T (pBT\u03bb : \u03bb \u2208 \u039b). If \u039bvalid is empty, then we abstain (i.e., return null). Otherwise, we are free to use any configuration in \u039bvalid. We then select the one that empirically minimizes a weighted combination of the average final set size (after rejection) as well as the relative number of \u201cexcess\u201d samples taken from our model (i.e., how many extra samples our algorithm takes after the first admissible answer has already been surfaced, proportional to the total number of samples). Specifically, let S\u03bb(x) be the total number of samples taken, S\u2217(x) be the oracle sample index j of the first admissible generation (where A(yj) = 1), and C\u03bb(x) be the final prediction set. Then, reusing Dcal, we take\n\u03bb\u0302 = argmin \u03bb\u2208\u039bvalid\n1\nn n\u2211 i=1 ( \u03c11|C\u03bb(Xi)|+ \u03c12 [S\u03bb(Xi)\u2212 S\u2217(Xi)]+ S\u03bb(Xi) ) (7)\nwhere \u03c11, \u03c12 \u2208 R\u22650 are hyper-parameters and [\u00b7]+ \u225c max(\u00b7, 0). We choose \u03c11 = \u03c12 = 0.5. As a consequence of LTT, the chosen \u03bb\u0302 (which is a random variable that depends on Dcal) is risk-controlling.\nTheorem 4.2 (Sampling-based LTT). Let \u03bb\u0302 be defined according to Eq. (7). Then the prediction C\u03bb\u0302(Xtest) computed by Algorithm 1 satisfies Eq. (1). Remark 4.3. Given a finite kmax, Algorithm 1 is guaranteed to terminate. Smaller kmax will, however, shrink the range of achievable \u03f5 (i.e., with \u03bb\u0302 \u0338= null). See Appendix C for additional discussion.\nTo efficiently search and test the higher dimensional \u03bb = (\u03bb1, \u03bb2, \u03bb3), we use the Pareto Testing procedure from Laufer-Goldshtein et al. (2023). Pareto Testing exploits structure in \u039b by first using a proportion ofDcal to find \u039b\u2019s Pareto-optimal frontier, and then iteratively validates promising configurations using Fixed Sequence Testing (Holm, 1979) on the remaining calibration data. See Appendix E."
        },
        {
            "heading": "4.4 CONFORMAL SELECTION OF INDIVIDUAL COMPONENTS",
            "text": "A caveat of language generation is that LM responses can be verbose, and composed of multiple components. We consider a \u201ccomponent\u201d to be a logically defined subpart of a larger response, such as a series of phrases or propositions. For example, a radiology report like \u201cThe heart is mildly enlarged. The lungs are clear.\u201d can be broken down into two findings: \u201cThe heart is mildly enlarged.\u201d and \u201cThe lungs are clear.\u201d While Theorem 4.2 guarantees that complete, admissible generations do exist within our prediction sets, we cannot use it to make statements about the relative reliability of individual components within each response contained within that prediction set. Let E : Y \u2192 2Y be a deterministic function that takes a text string and breaks it down into components. We implement\nAlgorithm 2 Conformal component selection Definitions: C\u03bb is a prediction set, E is an algorithm for splitting candidates y into components, Fc is a confidence estimator for individual components, \u03b3 is our threshold configuration.\n1: function SELECT(C\u03bb, E , Fc, \u03b3) 2: Cinner\u03b3 \u2190 {} \u25b7 Initialize an empty output set. 3: for y \u2208 C\u03bb do \u25b7 Iterate over full predictions. 4: for e \u2208 E(y) do \u25b7 Iterate over individual components. 5: if Fc(e) \u2265 \u03b3 then 6: Cinner\u03b3 \u2190 Cinner\u03b3 \u222a {e} \u25b7 Keep only high-confidence components. 7: return Cinner\u03b3\nE to be a simple sentence splitter. For every input x, we assume access to some component-based admission function Ac : Y \u2192 {0, 1} that is used to judge individual components for correctness. For example, Ac may check if e is entailed by another component e\u2032 \u2208 E(yref), where yref is a human reference. Let Fc : Y \u2192 R be a function that, for component e \u2208 Y , gives a confidence score for the event Ac(e) = 1. We then define the subset of components Cinner\u03b3 \u2286 2Y as\nCinner\u03b3 (x) := { e \u2208 \u22c3 y\u2208C\u03bb(x) E(y) : Fc(e) \u2265 \u03b3 } . (8)\nUsing Dcal, we seek to calibrate \u03b3 \u2208 \u0393, such that for test pair (Xtest, Actest) and \u03b1, \u03b4 \u2208 (0, 1), P ( P ( Actest(e) = 1,\u2200e \u2208 Cinner\u03b3 (Xtest) | Dcal ) \u2265 1\u2212 \u03b1 ) \u2265 1\u2212 \u03b4. (9)\nThe outer and inner probabilities are over the draws of Dcal and (Xtest, Actest), respectively. The new parameter \u03b1 can be interpreted as the maximum rate of making any false positive predictions in which we select a component that is not in fact acceptable. Like C\u03bb, we calibrate Cinner\u03b3 using LTT, but seek to make Cinner\u03b3 as large as possible, in order to maximize recall of correct components. Concretely, let Lci (\u03b3) = 1{\u2203e \u2208 Cinner\u03b3 : Aci (e) = 0} and let \u0393valid be the set of non-rejected configurations found by LTT (again using binomial tail p-values). During calibration we define Cinner\u03b3 (Xi) using an upper bound to C\u03bb(Xi), by simply taking the first kmax samples, {y1, . . . , ykmax}. This will allow us to conveniently decouple component calibration from set calibration. We then use the configuration that empirically maximizes the average number of confident components (where we again reuse Dcal):\n\u03b3\u0302 = argmax \u03b3\u2208\u0393valid\n1\nn n\u2211 i=1 |C\u03b3(Xi)|. (10)\nProposition 4.4 (Component-based LTT). Let \u03b3\u0302 be defined according to Eq. (10), where C\u03b3(Xi) uses C\u03bb(Xi) \u2261 {y1, . . . , ykmax} during calibration. Then the prediction set of components, C\u03b3\u0302(Xtest) computed by Algorithm 2 paired with any C\u03bb at test time with supx |C\u03bb(x)| \u2264 kmax satisfies Eq. (9).\nBy the union bound, Eq. (1) and Eq. (9) hold simultaneously with probability 1\u2212 2\u03b4."
        },
        {
            "heading": "5 EXPERIMENTAL SETUP",
            "text": ""
        },
        {
            "heading": "5.1 TASKS",
            "text": "Radiology report generation. As motivated in \u00a71, we apply our method to chest X-ray radiology report generation using the MIMIC-CXR (Johnson et al., 2019) dataset. For our LM, we fine-tune an encoder-decoder architecture based on a pretrained ViT (Dosovitskiy et al., 2021) image encoder and a GPT2-small (Radford et al., 2019) text decoder. To judge admission, we use the popular Clinical Efficacy metric (Liu et al., 2019; Nicolson et al., 2022) to check if the 14 labels predicted by an auxiliary CheXbert (Smit et al., 2020) model on the generated report exactly match the labels predicted by the same CheXbert model for a reference report from a radiologist. Similarly, a component (here a sentence including a finding) is defined to be admissible if it has a ROUGE-L (Lin, 2004) score \u2265 0.4 (picked empirically), when compared to any component directly extracted from the reference.\nNews summarization. We also apply our method to news article text summarization using the CNN/DM (Hermann et al., 2015) dataset. For our LM, we finetune a T5-XL (Raffel et al., 2020) model. We define a candidate generation to be admissible if it has a ROUGE-L score \u2265 0.35, when compared to all available reference summaries from human annotators. Like MIMIX-CXR, we define a component to be admissible if it has a ROUGE-L score\u2265 0.4 when compared to components extracted from human summaries. These thresholds are picked through manual validation.\nOpen-domain question answering. Finally, we apply our method to open-domain QA using the TriviaQA (Joshi et al., 2017) dataset. Here we sample answers from LLaMA-13B (Touvron et al., 2023) in the few-shot setting (k = 32), without any additional fine-tuning. Since answers are limited to one or few tokens, a candidate output generation is acceptable only if it exactly matches an annotated reference answer (after removing articles, casing, and punctuation). Furthermore, since the expected answers are short and fairly atomic, we do not evaluate component-level confidence for this dataset.\nWe set kmax = 20 for all experiments. See also Appendix F for additional task and model details."
        },
        {
            "heading": "5.2 SCORING FUNCTIONS",
            "text": "Our method can support different quality functionsQ, similarity functions S , and set scoring functions F . We show that a straightforward approach is to simply use transformations on the model likelihoods (from token logits). We define Q(x, y) = p\u03b8(y | x) using the likelihood function of the base LM, with length-normalization (Wu et al., 2016). We use ROUGE-L for S. For F , we experiment with: \u2022 FIRST-K. As a baseline, we score a set by its size, FFIRST-K(C) = |C|, and do not use rejection. This\ncorresponds to the number of samples taken, and follows the intuition from our toy example in \u00a74.2.\n\u2022 FIRST-K+REJECT. This variant uses our duplicate rejection component (\u00a74.2), but like FIRST-K, scores a set by the total number of samples taken so far (where the number of samples is now\u2265 |C|).\n\u2022 MAX. The FMAX scoring function stems from the intuition that a set is only as good as its best element, and defines FMAX(C) = max{Q(y) : y \u2208 C}.\n\u2022 SUM. Alternatively, we also use the sum of item-level scores: FSUM(C) = \u2211 y\u2208C Q(y)."
        },
        {
            "heading": "5.3 METRICS",
            "text": "Our main motivation is to produce valid confidence sets that are also precise. To reflect this, we measure both the loss of our sets (which is guaranteed to satisfy our prescribed limits), as well as both (a) the relative number of \u201cexcess\u201d samples taken from our model (including rejected samples, see also Eq. (7)), and (b) the ultimate output size of the prediction set (after rejection). Both metrics are important, as over-sampling wastes computation (or expensive API calls), while large output sets can be unwieldy to use and overall less helpful as an uncertainty quantification tool. We measure results and compute the normalized2 AUC over the range of achievable \u03f5 or \u03b1 (using a fixed \u03b4 = 0.05), excluding trivial values (e.g., that a policy that always returns the first generation would satisfy)."
        },
        {
            "heading": "6 EXPERIMENTAL RESULTS",
            "text": "Validity of conformal sampling with rejection. We demonstrate in Figure 2 that our conformal sampling approach matches our theory in practice, as the average set loss often matches but never exceeds the target risk level. Methods that have access to the model logits (MAX, SUM, FIRST-K-REJECT) are close to, but still below, the diagonal line, indicating that they are valid, but not conservative.\nPrediction efficiency. The likelihood-based approaches outperform the uniform FIRST-K baseline across all three tasks. For example, as Figure 2c shows, the AUC of expected set size of MAX and SUM are both less than half the AUC of FIRST-K in the QA task. In tasks with longer output texts, FIRST-K produces competitive set sizes across all achievable \u03f5. However, on the relative number of excess samples metric, the MAX scoring function largely outperforms SUM and FIRST-K. FIRST-K+REJECT achieves similar size efficiency to the other rejection algorithms, but still lacks sampling efficiency.\nIndividual components. We evaluate two scoring functions Fc for conformal component selection. SPAN-LOGITS extracts the likelihood of a component using the base language model. However, as\n2Specifically, we compute AUC(f ; a, b) = 1 b\u2212a \u222b b a f(\u03f5)d\u03f5, where [a, b] is the range of evaluated \u03f5 (or \u03b1).\nthat likelihood is also conditioned on previous context, it may underestimate the score of a correct component that follows an incorrect component. We therefore also test an application-specific CLASSIFIER to assign a conformity score to each component. We compare to a RANDOM baseline which attributes a random score to any (x, e) pair. Figure 3 shows that by modeling components independently, we produce better (larger) sets. We include additional results in Appendix G and H."
        },
        {
            "heading": "7 CONCLUSION",
            "text": "Reliably using language models (LMs) in real-world tasks inevitably requires meaningful uncertainty quantification. In this paper, we introduced an approach to conformal prediction that allows a user to sample prediction sets from generative LMs with infinite, combinatorial output spaces, while retaining desirable statistical guarantees. Our method bridges the gap between standard conformal prediction and LM inference by calibrating a stopping rule for an algorithm that iteratively grows an output prediction set by sampling new generations (with rejection). Moreover, we can separately identify confident answer subcomponents. This can help users better understand the quality of long responses, which often include both correct and incorrect aspects. Empirically, we demonstrated that we can obtain efficient prediction sets, both in terms of size and total required samples.\nREPRODUCIBILITY STATEMENT\nTo allow convenient and accurate reproduction of our results, we share our Python codebase for reproducing all our results: https://anonymous.4open.science/r/clm-91E2/. The codebase includes implementations of Algorithms 1 and 2, pre-processing code for our tasks, and functions for computing the metrics and producing all our plots and tables. In Section 5 and Appendix F we describe in detail all the datasets, language models, and scoring and admission functions we used, with references to downloading the public data and models, and all our hyper-parameters."
        },
        {
            "heading": "A ASSUMPTIONS",
            "text": "For clarity, we provide some additional discussion on our assumptions, and their implications.\nAssumption 1. Input prompts x are i.i.d. for both calibration and testing.\nThe inputs to our LM are considered to be randomly sampled from some fixed distribution. This is a reasonable assumption for many standard scenarios, such as the ones that we explore in our experiments, i.e.: questions for question answering, articles for summarization, and X-rays for radiology report generation. Importantly, however, this does not include multi-turn dialogue where successive prompts are dependent, or when there is distribution shift between calibration and testing. Additional modifications can be done to extend our calibration procedure to handle certain types of distribution shift (e.g., by defining new p-values that remain super-uniform under the target distribution using weighting), although we do not evaluate this direction in this work.\nAssumption 2. We can sample y \u223c p\u03b8(y | x) using a language model API that accesses p\u03b8.\nNo other assumptions are placed on the LM itself or its sampling process. That said, two additional LM qualities also affect the performance of our method in practice:\nQ1. There exists a good response that is expressible by the LM, i.e., \u2203y \u2208 V\u2217 s.t. A(y) = 1. This simply is to say that all inputs are not impossible to answer appropriately.\nQ2. The LM places high enough probability mass on good responses such that good responses are sampled within a tractable number of calls sufficiently often (i.e., 1\u2212 \u03f5 fraction of the time).\nWithout qualities Q1 and Q2, some settings of kmax and \u03f5 may be unachievable, and our algorithm will fail to return a risk-controlling configuration. Nevertheless, this does not affect the validity of our algorithm; it only affects its application. See Appendix C for a discussion on kmax. Assumption 3. The admission function A is a good proxy for assessing generation quality.\nOur guarantees are based on bounding the expected value of A on future outputs. For this to be meaningful, A(y) = 1 should reflect that y is a good sample. In our experiments, we manually design A by using similarity metrics that compare possible responses to human references. For example, in our radiology report generation task, x is the X-ray, y is the report, and p\u03b8(y | x) is our image-to-text LM. Given y and a \u201cground truth\u201d report y\u2217 written by a radiologist (from the MIMIC-CXR dataset), we use the popular Clinical Efficacy metric (Liu et al., 2019; Nicolson et al., 2022) as a proxy for \u201cadmissibility\u201d, where we check if all of the 14 labels predicted by an auxiliary CheXbert (Smit et al., 2020) model given y exactly match the labels predicted by the same CheXbert model given y\u2217.\nThe admission function is flexible, however, and need not be automatic. For example, the most reliable admission function is to directly use real users to assess whether a generated sample is acceptable or not (or the majority vote of one or more human annotators, when given clear, consistent guidelines). Such a user-based calibration set would be ideal, but also often costly to obtain.\nWhen automatic admission functions are needed, here we show that it is also sufficient to only require access to a conservative admission function, A\u0304 : V\u2217 \u2192 {0, 1}, where \u2200y \u2208 V\u2217 we have A\u0304(y) \u2264 A(y). For instance, A\u0304 might measure exact match on a word-for-word basis between y and y\u2217, instead of accounting for differences in dictation. We show that \u03bb\u0302 remains valid with respect to the \u201ctrue\u201d (but inaccessible) Atest if conservative admission functions A\u0304i were used during calibration.\nCorollary A.1 (Conservative sampling-based LTT). Suppose that over Dcal we let Li(\u03bb) = 1{\u2204y \u2208 C\u03bb(Xi) : A\u0304i(y) = 1} where A\u0304(y) \u2264 A(y), \u2200y \u2208 V\u2217. Then C\u03bb\u0302(Xtest) still satisfies Eq. (1).\nProof. The following proof is analogous to that of Propostion 4.4. Let\nL\u0304(\u03bb) = 1{\u2204y \u2208 C\u03bb(x) : A\u0304 = 1} (11) For all y \u2208 V\u2217, we have A\u0304test(y) = 1 =\u21d2 Atest(y) = 1, which implies that L\u0304(\u03bb) \u2265 L(\u03bb) for all \u03bb. This implies that for any choice of Dcal\nE[L\u0304test(\u03bb\u0302) | Dcal] \u2265 E[Ltest(\u03bb\u0302) | Dcal]. (12)\nApplying Theorem 4.2 gives that the left hand side is \u2264 \u03f5 w.p. \u2265 1\u2212 \u03b4."
        },
        {
            "heading": "B LIMITATIONS",
            "text": "Our work aims to provide rigorous, yet useful, uncertainty estimates for language models. This has important implications for the safety and reliability of deployed models that make decisions with real consequences. At the same time, definite limitations do exist for the algorithms presented here, in particular (a) the assumption of i.i.d. data, (b) an appropriate admission function A, and (c) having resulting C\u03bb that are not too large or expensive to obtain (e.g., requiring many samples). In the same vein, if kmax, the maximum number of samples drawn, is too low, then many levels of \u03f5 will be unattainable, and the method will fail to find a valid configuration (it will return null). Finally, it is important to emphasize that the guarantees presented here are probabilistic in nature\u2014and also do not necessarily hold when conditioned on a particular type of input. While setting \u03b4 and \u03f5 to low values is possible and decreases the changes of failures, it will also make the algorithm more conservative and potentially less useful. The admission function A also requires careful construction. Nevertheless, these results can be improved by (a) plugging in better language models, (b) using higher signal confidence metrics (e.g., as opposed to raw logits), and (c) obtaining larger samples Dcal for calibration.\nC EFFECTS OF TRUNCATED SAMPLING (kmax)\nTo be useful, it is critical to ensure that our sampling algorithm terminates in a reasonable number of steps. For this reason, we use kmax as a hard stop on the total number of samples we take from p\u03b8(y | x). Naturally, this also effects the achievable coverage that we can guarantee, as certain LMs\nmay require more than kmax samples to get a correct response for certain input examples. For each kmax there is therefore a band of achievable (non-trivial) \u03f5, that ranges from the error rate at first-1 to the error rate at first-kmax (where first-k denotes the strategy of always taking the first k samples for a fixed k). In our experiments, we set kmax = 20, although the best practice is to empirically choose kmax using a development set along with an idea for how many samples one is willing to take in the worst case, which is primarily determined by the one\u2019s computational budget."
        },
        {
            "heading": "D PROOFS",
            "text": "D.1 PROOF OF LEMMA 4.1\nProof. Let X = Binom(n, \u03f5) and Y = nR\u0302n(\u03bb), which also has distribution Binom(n, \u03f5\u2032), for some unknown success probability \u03f5\u2032, as Li\u2019s are binary. We write FX(x) and FY (y) to denote the CDFs of X and Y , respectively. Under the null hypothesisH\u03bb : E[Ltest(\u03bb)] > \u03f5 (or equivalently,H\u03bb : \u03f5\u2032 > \u03f5), Y stochastically dominates X , i.e., FX(u) \u2265 FY (u), \u2200u. Let Z = pBT\u03bb = FX(Y ). Then\nP(Z \u2264 z) = P(FX(Y ) \u2264 z) (13) \u2264 P(FY (Y ) \u2264 z) (14) = P(Y \u2264 F\u22121Y (z)) (15) = FY F \u22121 Y (z) (16)\n= z. (17)\nTherefore since pBT\u03bb is super-uniform, it is a valid p-value.\nD.2 PROOF OF THEOREM 4.2\nProof. Since sampling is performed independently for each (i.i.d.) input prompt Xi and admission function Ai, the set losses Li(\u03bb) are also i.i.d. According to Lemma 4.1, pBT\u03bb is super-uniform under H\u03bb : E[Ltest(\u03bb)] > \u03f5. Given T , a FWER-controlling algorithm at level \u03b4, we can apply Theorem 3.2 to identify \u039bvalid such that\nP (\nsup \u03bb\u2208\u039bvalid\nE[Ltest(\u03bb) | Dcal] \u2264 \u03f5 ) \u2265 1\u2212 \u03b4. (18)\ni.e.\nP (\ninf \u03bb\u2208\u039bvalid\nP ( \u2203y \u2208 C\u03bb(Xtest) : Atest(y) = 1 | Dcal ) \u2265 1\u2212 \u03f5 ) \u2265 1\u2212 \u03b4. (19)\nTherefore, Equation 1 holds for any \u03bb \u2208 \u039bvalid. In particular, it holds for selecting \u03bb\u0302 by Eq. (7).\nD.3 PROOF OF PROPOSITION 4.4\nProof. Let\nL\u0304c(\u03b3) = 1 { \u2203e \u2208\nykmax\u22c3 i=1 yi : A c(e) = 0\n} (20)\nSince C\u03bb(x) \u2286 {y1, . . . , ykmax} for any \u03bb by definition, we have L\u0304c(\u03b3) \u2265 Lc(\u03b3) for all \u03b3. This implies that for any draw of Dcal,\nE[L\u0304ctest(\u03b3\u0302) | Dcal] \u2265 E[Lctest(\u03b3\u0302) | Dcal]. (21)\nSimilar to the proof of Theorem 4.2, since L\u0304c(\u03b3) is also binary, we can use Lemma 4.1 to show that pBT\u03b3 is a valid p-value, and apply LTT to show that the left hand side is \u2264 \u03b1 w.p. \u2265 1\u2212 \u03b4."
        },
        {
            "heading": "E PARETO TESTING",
            "text": "We briefly review the Pareto Testing method for configuration selection, but refer the reader to Laufer-Goldshtein et al. (2023) for full details. Pareto Testing is a computationally and statistically efficient procedure that improves Fixed Sequence Testing (Holm, 1979), a common FWER-controlling procedure, by optimizing the ordering of configurations to test. The method consists of two stages:\nStage 1: Constructing the Pareto frontier\nFirst we solve an unconstrained, multi-objective optimization problem in order to recover an approximate set of Pareto-optimal configurations, i.e., settings for which no other configuration exists that is uniformly better in all respects. Some of these objectives are meant to eventually be constrained (e.g., controlled to be \u2264 \u03f5), while others are meant to be optimized (e.g., find the smallest set). Specifically, suppose that there are c objectives we seek to control and k objectives that we seek to optimize. In our setting, c = 1 (we would like to control coverage) and k = 1 (we would like to minimize a weighted combination of the number of samples and the set size per Eq. (7)). Let \u039b \u225c \u039b1\u00d7...\u00d7\u039bm (here m = 3) be a multi-dimensional configuration space, and let q(\u03bb) : \u039b\u2192 Rc+k be a map from \u03bb to the values of the objective functions (both constrained and unconstrained), i.e.,\nq(\u03bb) = [ Q\u0302opt1 (\u03bb), . . . , Q\u0302 opt c+k(\u03bb) ] (22)\nwhere Q\u0302opti is the empirical average of the objective evaluated over a split of data, Dopt (e.g., the empirical coverage). Generally speaking, there is typically no single value of \u03bb that minimizes all objectives simultaneously. Instead, we find the Pareto frontier of all points that are not dominated (i.e., there exists another \u03bb\u2032 \u2208 \u039b that is better in all respects):\n\u039bpar = {\u03bb \u2208 \u039b : {\u03bb\u2032 \u2208 \u039b : \u03bb\u2032 \u227a \u03bb, \u03bb\u2032 \u0338= \u03bb } = \u2205}. (23) \u039bpar then represents a set of configurations with optimal trade-offs (at least, according to the empirical values computed over Dopt). Let [\u03b11, . . . , \u03b1c] be a list of our target constraints for the first c constrained objectives. We then sort \u039bpar by estimated p-values\npopt(\u03bb, \u03b1) = max 1\u2264i\u2264c p(Q\u0302opti (\u03bb);\u03b1i), (24)\nwhich we compute overDopt (the same used to find the Pareto frontier, but separate from testing data). Different p-values can be used, see Angelopoulos et al. (2021a). Intuitively, this defines a sequence of configurations that are Pareto-optimal, ordered by the likelihood of them being able to satisfy all of our constraints. Since in this work we only have one constraint (coverage), this reduces to finding the sequence of Pareto-optimal configurations ordered from most to least likely to result in valid coverage.\nStage 2: Fixed sequence testing\nThe second stage is simple. Given the sequence of configurations identified in Stage 1, Stage 2 applies Fixed Sequence Testing. Concretely, given calibration data Dcal, we sequentially test each configuration by checking if the maximum p-value for constrained objectives is greater than \u03b4, i.e.,\npcal(\u03bb, \u03b1) = max 1\u2264i\u2264c p(Q\u0302cali (\u03bb);\u03b1i) \u2265 \u03b4, (25)\nand stopping at the first configuration for which this inequality holds. The set of evaluated \u03bb for which Eq. (25) does not hold is then taken to be \u039bvalid. It can be shown that this procedure is FWER-controlling at level \u03b4, and often powerful, as the constructed sequence of \u03bb generally allows for identifying a \u039bvalid with high-recall (i.e., we recover many of the valid configurations)."
        },
        {
            "heading": "F ADDITIONAL EXPERIMENTAL DETAILS",
            "text": "In this section, we provide additional details regarding the experiments conducted for the three tasks discussed in Section 5. Our code will be released after the review process.\nF.1 RADIOLOGY REPORT GENERATION\nDataset For the radiology report generation experiment, we utilized the labeled MIMIC-CXR and MIMIC-CXR-JPG datasets (Johnson et al., 2019). The MIMIC-CXR dataset can be accessed at\nhttps://physionet.org/content/mimic-cxr/2.0.0/ under the PhysioNet Credentialed Health Data License 1.5.0. Similarly, the MIMIC-CXR-JPG dataset is available at https://physionet.org/content/mimiccxr-jpg/2.0.0/ under the same license.\nWe start with the standard splits prescribed in MIMIC-CXR-JPG. However, we further divide the training set into a train set and a dev set using a 0.9/0.1 ratio. The train set is used for training the model, using the validation set for early stopping. We then exclusively use the dev set for conformal prediction experiments. Subsequently, we filtered the dataset to include only anterior to posterior (AP) or posterior to anterior (PA) views and retained only one image per report. Furthermore, we removed examples where the report did not start with the phrase \u201cFINAL REPORT\u201d as these reports often contained a summary of the findings at the beginning, inadvertently leaking the answer we aimed to generate with the model. Table F.1 provides an overview of the resulting dataset.\nSplit Train Dev Validation Test Number of Images 176,078 19,658 1,594 2,799 Number of Studies 176,078 19,658 1,594 2,799 Number of Patients 54,482 6,053 463 286\nTable F.1: Dataset statistics for preprocessed MIMIC-CXR. The splits and preprocessing scripts are available within our code release. The train and validation split is used for to train the encoder-deocder model with early stopping. The dev set is used for conformal prediction. The test set is unused.\nEach image was resized and cropped to a resolution of 224x224. Following prior methodology (Miura et al., 2021), we split each report into a prompt part and a findings part (which may also contain the impressions section) by identifying one of the following phrases: \u201cFINDINGS AND IMPRESSION\u201d, \u201cFINDINGS\u201d or \u201cIMPRESSION\u201d.\nModel The image encoder used in our experiment was a Vision Transformer (ViT) model pretrained on ImageNet-21k at a resolution of 224x224. Specifically, we utilized the google/vit-base-patch16-224-in21k model available in the Transformers library (Wolf et al., 2019). The text decoder was a GPT2-small model (gpt2 on HuggingFace). We trained the model with a batch size of 128 distributed over 8 GPUs, resulting in a batch size of 16 per GPU. The AdamW optimizer was employed with \u03b21 = 0.9, \u03b22 = 0.999, and \u03f5 = 10\u22128. The learning rate was set to 5\u00d7 10\u22125. The training process consisted of 10 epochs, and the total training time on 8 RTX A6000 GPUs was approximately 11 hours.\nGenerations Candidate reports were sampled from the model using default arguments from the Transformers library, i.e. top_k = 50, top_p = 1.0 and temperature = 1. Each generated report is then evaluated using a trained CheXbert model (Smit et al., 2020). The CheXbert model is available at https://stanfordmedicine.box.com/ under the Stanford Academic Software License. The CheXbert model labels each report for 14 conditions, assigning one of the following labels: \u201cBlank,\u201d \u201cPositive,\u201d \u201cNegative,\u201d or \u201cUncertain.\u201d\nTo determine the admission of a candidate report, we compare it with a reference (human) report from the MIMIC dataset. If the candidate report matches all 14 labels of the reference report, the admission function returns 1; otherwise, it returns 0.\nComponents We define a component as a sentence delimited by a period. The component-level admission function is defined based on how well a sentence\u201calmost matches\u201d one of the reference sentences. Two sentences are considered to \u201calmost match\u201d if their ROUGE score is above 0.4. If a sentence almost matches a reference sentence, the component-level admission function returns 1; otherwise, it returns 0.\nF.2 OPEN-DOMAIN QUESTION ANSWERING\nWe use the TriviaQA (Joshi et al., 2017) dataset available at https://nlp.cs.washington.edu/triviaqa/ under the Apache License Version 2.0. To generate candidate responses, we used LLaMA-13B (Touvron et al., 2023). We considered the closed-book setting, where the model does not have access to supporting text for answering the questions. We performed experiments in the few-shot setting by\nAnswer these questions"
        },
        {
            "heading": "Q: Which American-born Sinclair won the Nobel Prize for Literature in 1930?",
            "text": ""
        },
        {
            "heading": "A: Sinclair Lewis",
            "text": ""
        },
        {
            "heading": "Q: Where in England was Dame Judi Dench born?",
            "text": ""
        },
        {
            "heading": "A: York",
            "text": "Q: In which decade did Billboard magazine first publish and American hit chart? A: 30s"
        },
        {
            "heading": "Q: From which country did Angola achieve independence in 1975?",
            "text": ""
        },
        {
            "heading": "A: Portugal",
            "text": ""
        },
        {
            "heading": "Q: Which city does David Soul come from?",
            "text": ""
        },
        {
            "heading": "A: Chicago",
            "text": ""
        },
        {
            "heading": "Q: Who won Super Bowl XX?",
            "text": ""
        },
        {
            "heading": "A: Chicago Bears",
            "text": ""
        },
        {
            "heading": "Q: Which was the first European country to abolish capital punishment?",
            "text": ""
        },
        {
            "heading": "A: Norway",
            "text": "Q: In which country did he widespread use of ISDN begin in 1988?"
        },
        {
            "heading": "A: Japan",
            "text": ""
        },
        {
            "heading": "Q: What is Bruce Willis\u2019 real first name?",
            "text": ""
        },
        {
            "heading": "A: Walter",
            "text": ""
        },
        {
            "heading": "Q: Which William wrote the novel Lord Of The Flies?",
            "text": ""
        },
        {
            "heading": "A: Golding",
            "text": ""
        },
        {
            "heading": "Q: Which innovation for the car was developed by Prince Henry of Prussia in 1911?",
            "text": ""
        },
        {
            "heading": "A: Windshield wipers",
            "text": ""
        },
        {
            "heading": "Q: How is musician William Lee Conley better known?",
            "text": ""
        },
        {
            "heading": "A: Big Bill Broonzy",
            "text": ""
        },
        {
            "heading": "Q: How is Joan Molinsky better known?",
            "text": ""
        },
        {
            "heading": "A: Joan Rivers ...",
            "text": "Figure F.1: Truncated replication of the prompt used to generate answer on the TriviaQA dev set. The actual prompt contains 32 question-answer pairs.\nproviding 32 example question-answer pairs sampled from the training set. A truncated prompt used for generating answers on the TriviaQA dev set is reproduced as an illustration in Figure F.1. Please note that the actual prompt used in the experiment contains 32 question-answer pairs.\nFor generating answers in the open-domain question answering task, we use the default Transformers parameters reported in the previous section. We extract an answer by considering the text until the first line break, comma, or period is encountered. We then normalize the answers: this involves converting the generated answers to lowercase, removing articles, punctuation, and duplicate whitespace. Generated answers are then compared using the exact match metric: an answer is considered correct only if it matches the provided answer exactly.\nF.3 NEWS SUMMARIZATION\nWe use the CNN/DM dataset (Hermann et al., 2015; See et al., 2017) that includes news articles from CNN and the Daily Mail paired with their human written summaries, and is available at https://github.com/abisee/cnn-dailymail under MIT License. We use the standard train set for finetuning, the validation set for selecting the best checkpoint, and the test set for all reported conformal experiments.\nWe use a T5 1.1 XL model, which includes roughly 3B parameters, and was further pretrained for 100k steps with a multilayer objective (Schuster et al., 2022b). We finetune the model on the train set for 200k steps with a batch size of 128 using 64 TPUv4 chips for approximately 40 hours. We use the Adafactor (Shazeer and Stern, 2018) optimizer with a deacy rate of 0.8, initial learning rate of 0.001 and 1k warm-up steps.\nTo generate candidate responses, we use Nucleus sampling (Holtzman et al., 2020) with top-p set to 0.95, temperature 0.7, and maximum output length set to 256 tokens.\nTo get the response components we use a simple sentence spliter and treat each sentence as a component. As a classifier for evaluating the correctness of each component, we use an independent T5 XXL\nmodel trained on a mixture of NLI datasets (Honovich et al., 2022; Schuster et al., 2022a). Specifically, we leverage the model used in the TRUE benchmark (Honovich et al., 2022) and is available at https://huggingface.co/google/t5_xxl_true_nli_mixture. This model was trained on SNLI (Bowman et al., 2015), MNLI (Williams et al., 2018), FEVER (Thorne et al., 2018), SciTail (Khot et al., 2018), PAWS (Zhang et al., 2019), and VitaminC (Schuster et al., 2021a) to make a binary prediction of whether an hypothesis sentence is entailed by the given premise (in three-way datasets, the neutral class was merged with the negative class). We query the model with each component as the hypothesis, and the source summary as the premise, and measure the log-probability of predicting \u201centailment\u201d.\nF.4 DATASET DETAILS\nDataset Standard split Size Purpose\nMIMIC\nTrain 176,078 Train the generative model Dev\u2217 19,658 Calibration experiments\nValidation 1,594 Early stopping Test 2,799 Unused\nTriviaQA Train 138,384 Prompt LLaMA (32 samples)\nValidation 18,669 Calibration experiments Test 17,210 Unused\nCNN/DM Train 287,113 Train the generative model\nValidation 13,368 Early stopping Test 11,490 Calibration experiments\nTable F.2: We use the standard splits of each dataset and reserve unseen data for our calibration experiments. The only exception is for MIMIC where validation and test data are too small, so we reserve a subset of the official train set as unseen data for calibration. The asterisk marks that exception.\nDataset Split Size MIMIC Calibration train 2,000\nCalibration val 2,000 Calibration test 15,658\nTriviaQA Calibration train 2,000 Calibration val 2,000 Calibration test 14,669 CNNDM Calibration train 2,000 Calibration val 2,000 Calibration test 7,490\nTable F.3: Additional splits for calibration experiments\nFor each dataset, we use the standard splits as shown in Figure F.2 and further split the data reserved for calibration experiments, as described in Figure F.3. The calibration \u201cval\u201d set was used in our earlier experiments to compare scoring functions. Some scoring functions required training (e.g. Platt scaling) and we used an additional calibration \u201ctrain\u201d set for that purpose. For final evaluation, we used the calibration \u201ctest\u201d set to run 100 trials. For each trial, the calibration test data was split as follows: 10% is used to compute the Pareto frontier, 20% is used for Fixed Sequence Testing. The remaining 70% is used to measure test metrics (validity and efficacy).\nF.5 LENGTH-NORMALIZATION\nFor all tasks, we apply length-normalization (Wu et al., 2016) to the model logits, i.e. we compute: Q(x, yk) = exp ( log p\u03b8(yk|x)\nlp(yk) ) where\nlp(y) = (5 + |y|)0.6\n(5 + 1)0.6 .\n(a) MIMIC-CXR (b) CNN/DM\nFigure G.1: Component selection results for Cinner\u03b3 as a function of \u03b1. First row: validity curves. Second row: recall achieved by Cinner\u03b3 , which we want to maximize. We also report the AUC over \u03b1."
        },
        {
            "heading": "G ADDITIONAL RESULTS",
            "text": "We describe another metric useful to characterize the effectiveness of the components identified by our component selection method.\nGiven an input x and a component set C\u03b3inner(x), we compute the recall by counting the number of reference sentences that \u201calmost match\u201d at least one element in C\u03b3inner(x). We then divide this count by the total number of reference sentences for that particular example. This gives us a measure of how much of the human reference is covered by the selected components. To obtain the expected recall, we average the recall values over all examples. The expected recall is reported in Figure G.1.\nIn particular, we observe that component sets generated using scoring functions based on an auxiliary CLASSIFIER outperform uncertainty measures based solely on the span logits provided by the model."
        },
        {
            "heading": "H QUALITATIVE RESULTS",
            "text": "We present qualitative results for radiology report generation and news summarization. In this section, we use the SUM method and consider FSUM(C) = \u2211 y\u2208C Q(y). The choice of \u03b1 and \u03f5 is reported in\nTable H.7. We use 30% of the dev dataset (chosen uniformly at random) to determine \u03bb\u0302 as described in \u00a74.3, and reserve the remaining 70% of the dataset for qualitative inspection. The corresponding values of \u03bb\u0302 and \u03b3 are reported in Table H.7. Notably, the method produces \u03bb2 = \u2212\u221e for the CNN/DM task, indicating that individual summaries are not rejected based on their quality but only for redundancy reasons.\nIn Figure H.1, an X-ray example is shown, depicting left basilar opacities while the rest of the X-ray appears normal. Table H.1 indicates that our method terminates the generation process after producing three samples. The third generation correctly identifies \u201capical scarring\u201d; however, it mistakenly attributes it to the right lung instead of the left lung. This highlights a limitation of using CheXbert as the basis for the admission function, as its label granularity does not differentiate between left and right. Our component selection method accurately identifies several sentences that align with the reference report. These sentences are displayed in bold. Notably, our method avoids emphasizing\nlow-confidence findings such as \u201cright apical scarring\u201d and instead focuses on the absence of an acute cardiopulmonary process.\nA more challenging example is described in Figure H.2. The report mentions an enlarged heart, signs of cardiomegaly, and edema. Samples 4 and 5 correctly capture these findings but are considered incorrect due to the inclusion of \u201ceffusion.\u201d The conformal selection of components chooses not to highlight any sentences since none of them meet the confidence threshold defined by \u03f5.\nIn Tables H.3\u2013H.6, we illustrate how our method continues sampling candidate summaries until the produced set is deemed acceptable. Specifically, Table H.3 demonstrates that the component selection process highlights the main idea while excluding minor ideas, which exist in multiple variations. Table H.4 exemplifies that the method stops after Sample 9, not because Sample 9 has the highest score, but because the sum of the scores collectively exceeds the target threshold of \u03bb3 = 1.02. Indeed, as shown in Table H.5, a higher individual score does not necessarily imply that a generation is more acceptable than one with a lower score. Finally, Table H.6 reveals a model failure, where the scores indicate high confidence in Sample 2, but the proposed generations are missing some main ideas from the reference summary.\nAP and lateral views of the chest. Streaky biapical and left basilar opacities are most compatible with scarring. The lungs are clear of confluent consolidation. There is no effusion. Cardiomediastinal silhouette is within normal limits. No acute osseous abnormalities detected. IMPRESSION: No definite acute cardiopulmonary process.\nFigure H.1: Chest X-ray and reference radiology report for study id 55663120\nTable H.1: Example prediction sets for study id 55663120, at \u03b1 = 0.7, \u03f5 = 0.7. Bolded sentences are sentences that are chosen by the component selection process. Here we see that several phrases common to all generations, such as \u201cAP and lateral views of the chest\u201d, are high confidence (and also correct). The finding about the cardiomediastinal silhouette is also confident. A completely correct generation, however, is not achieved until the third sample (after which the algorithm stopped).\nText Score Label Sample 1 AP upright and lateral views of the chest provided. There\nis chronic left lower lobe atelectasis. There is no focal consolidation concerning for pneumonia. No large effusion or pneumothorax. The cardiomediastinal silhouette is normal. Imaged osseous structures are notable for a mild compression deformity of an upper lumbar vertebral body. Degenerative change is seen in the right acromioclavicular joint. IMPRESSION: No acute intrathoracic process.\n1.45e-05 False\nSample 2 AP and lateral views of the chest. Diffusely calcified pleural plaques are identified bilaterally suggesting prior asbestos exposure. There is no pleural effusion. The cardiomediastinal silhouette is within normal limits. No acute osseous abnormalities detected. Surgical clips project over the upper abdomen. IMPRESSION: No definite acute cardiopulmonary process. 1.98e-05 False Sample 3 AP and lateral views of the chest. There is right apical scarring. Elsewhere, the lungs are clear. The cardiomediastinal silhouette is within normal limits. Atherosclerotic calcifications noted at the aortic knob. No acute osseous abnormality detected. IMPRESSION: No acute cardiopulmonary process. 5.36e-03 True\nIn comparison with the study of ___, there is continued enlargement of the cardiac silhouette with increasing fullness and indistinctness of central pulmonary vessels, consistent with worsening pulmonary edema. Mild asymmetry at the left base could represent developing aspiration or even infectious\nFigure H.2: Chest X-ray and reference radiology report for study id 55770135\nTable H.2: Example prediction sets for study id 55770135, at \u03b1 = 0.7, \u03f5 = 0.7. No sentences are selected by the component selection process. As a symptom of low component confidence, most generations have low overlap in exact phrasing and findings. In this case, the sampling process failed to produce a correct response (though the probability of this happening overall is \u2264 0.3).\nText Score Label Sample 1 In comparison with the study of ___, there is little overall\nchange. Again there is enlargement of the cardiac silhouette with elevated pulmonary venous pressure and bilateral opacification is consistent with developing pulmonary edema or pneumonia in the appropriate clinical setting. The nasogastric tube again extends at least to the lower body of the stomach, where it crosses the lower margin of the image.\n1.96e-05 False\nSample 2 Compared to chest radiographs ___ through ___. Moderate pulmonary edema is exaggerated due to the low lung volumes, but is new, including mild interstitial edema and engorgement of the mediastinal veins. Mediastinal veins are still engorged, but not large. Pleural effusions are presumed, but not large. Indwelling right subclavian line ends in the low SVC. 7.10e-08 False Sample 3 Compared to chest radiographs ___ through ___. Moderate pulmonary edema is improving, although heart remains moderately enlarged and mediastinal veins are substantially dilated due to volume status. Bilateral pleural effusions are presumed, but not large. No pneumothorax. NOTIFICATION: I discussed the findings with the referring physician by telephone on ___ at 3:08 PM. 2.42e-07 False Sample 4 Compared to chest radiographs ___ through ___. Moderate to severe pulmonary edema has worsened. Moderate cardiomegaly is chronically large, exaggerated by lower lung volumes. Pleural effusions are small if any. No pneumothorax. 2.35e-04 False Sample 5 No previous images. The cardiac silhouette is enlarged and there is some indistinctness of pulmonary vessels consistent with mild elevation of pulmonary venous pressure. In view of the prominence of the pulmonary vasculature, it would be difficult to unequivocally exclude superimposed pneumonia, especially in the absence of a lateral view. 4.69e-04 False\nTable H.3: Example prediction sets for example from CNN/DM dataset, at \u03b1 = 0.3, \u03f5 = 0.7. Bolded sentences are sentences that are selected by the component selection process. Missing sample indices represent samples that were rejected. Here we can observe that component selection highlights the main idea, while excluding minor details, which are lower confidence. A fully correct sample is not obtained until the 19th draw.\nText Score Label Ref Debris from boat to be dried, inspected and taken to landfill.\nThe debris contained fish normally found in Japanese waters. The earthquake and tsunami hit Japan in March 2011.\nSample 1 Section of boat believed to be from 2011 Japan tsunami is found off Oregon coast . Biologists say the environmental threat is small . 3.62e-01 False Sample 2 Ship debris found off Oregon coast is suspected to be from 2011 Japan tsunami . Biologists say the invasive species threat is small . 2.63e-01 False Sample 3 Ship fragment found off Oregon coast . It\u2019s suspected to be from 2011 Japan tsunami . Yellowtail jack fish were found inside the boat . 1.71e-01 False Sample 7 Ship debris found off Oregon coast may be from 2011 Japan tsunami . Yellowtail jack fish were found inside the vessel . 2.76e-01 False Sample 12 Ship debris found off Oregon coast and towed to harbor . Biologists say it poses no threat to the environment . 1.22e-01 False Sample 13 Section of boat found off Oregon coast suspected to be from 2011 Japan tsunami . Biologists say the boat fragment will be taken to a landfill . Yellowtail jack fish, normally found in Japanese waters, will be taken to an aquarium . 2.63e-01 False Sample 16 Section of boat found off Oregon coast may be from 2011 Japan tsunami . Biologists say the environmental threat is small . 3.62e-01 False Sample 19 Section of boat found off Oregon coast suspected to be from 2011 Japan tsunami . Biologists say the environmental threat posed by the boat is small . 1.40e-01 True\nTable H.4: Example prediction sets for example from CNN/DM dataset, at \u03b1 = 0.3, \u03f5 = 0.7. Bolded sentences are sentences that are selected by the component selection process. Of note is how this example demonstrates that the method stops after Sample 9, not because Sample 9 has the highest score, but because the sum of the scores collectively exceeds the target threshold of \u03bb3 = 1.02.\nText Score Label Ref Jordan Ibe showed off the impressive dance move on his\nInstagram. The Liverpool star has broken into the first team during this campaign. Ibe is currently on the sidelines after suffering a knee injury. CLICK HERE for all the latest Liverpool news.\nSample 1 Jordon Ibe has been a key player for Liverpool this season . The 19-year-old winger has been sidelined with a knee injury . Ibe has been performing the moonwalk while recovering from the injury . He posted a video on Instagram of him performing the move . Liverpool face Newcastle in their next Premier League game . 2.63e-01 True Sample 2 Jordon Ibe has been a key player for Liverpool this season . The 19-year-old winger has been sidelined with a knee injury . Ibe took to Instagram to show off his skills performing the moonwalk . 1.60e-01 False Sample 3 Jordon Ibe has been a key player for Liverpool this season . The 19-year-old is currently out with a knee injury . But Ibe showed off some impressive moves on his Instagram account . The Liverpool winger posted a video of him performing the moonwalk . 2.63e-01 True Sample 5 Jordon Ibe has been a key player for Liverpool this season . The 19-year-old took to Instagram to show off his dance moves . Ibe is currently out with a knee injury but is expected to return in the next few weeks . 2.27e-01 True Sample 7 Jordon Ibe has been a key player for Liverpool this season . The 19-year-old took to Instagram to show off his moves . He posted a video of him performing the moonwalk . Ibe is currently out with a knee injury but is expected to return soon . 3.89e-01 True Sample 8 Jordon Ibe has broken into the Liverpool first team this season . The 19-year-old took to Instagram to show off his skills performing the moonwalk . Liverpool face Newcastle in their next Premier League game . 3.89e-01 True Sample 9 Jordon Ibe posted a video on Instagram of him performing the moonwalk . The Liverpool winger is currently out with a knee injury . But Ibe is expected to return in the next few weeks . Liverpool face Newcastle in the Premier League on Sunday . 2.92e-01 False\nTable H.5: Example prediction sets for example from CNN/DM dataset, at \u03b1 = 0.3, \u03f5 = 0.7. No sentences are selected by the component selection process. Here we can also see that a higher individual score does not necessarily imply that a generation is more acceptable than one with a lower score, which highlights why set calibration is critical. Note that this example also highlights a case in which a finer-grained component splitter might be useful: though no complete sentence is confident, certain topics, like \u201chormone therapy\u201d appear to be.\nText Score Label Ref Craig Lister, 54, from Watford, is on hormone therapy for\nprostate cancer. This starves cancer cells by reducing levels of testosterone in the body. One side-effect is hot flushes: \u2019I have about ten to 12 flushes a day\u2019\nSample 1 Hormone therapy for prostate cancer starves cancer cells by reducing levels of testosterone in the body - and has the side-effect of hot flushes . It can\u2019t cure the cancer, but can help keep it under control . The majority of prostate cancers rely on the hormone to grow . Lowering the amount in the body means it\u2019s less able to spread . 5.11e-01 True Sample 2 Hormone therapy is usually given in the form of regular injections or implants . It can\u2019t cure the cancer, but can help keep it under control . The majority of prostate cancers rely on the hormone to grow . Lowering the amount in the body means it\u2019s less able to spread . 9.10e-01 False\nTable H.6: Example prediction sets for example from CNN/DM dataset, at \u03b1 = 0.3, \u03f5 = 0.7. Bolded sentences are sentences that are selected by the component selection process. This example reveals a model failure, where the scores indicate high confidence in Sample 2, but the proposed generations are missing some main ideas from the reference summary.\nText Score Label Ref Independent Commission for Reform in Cycling (CIRC) con-\ncluded that the UCI colluded with Lance Armstrong to cover up allegations. Hein Verbruggen was criticised as events occurred under his leadership. Verbruggen has revealed he is having the report analysed by lawyers.\nSample 1 Hein Verbruggen is unhappy with the CIRC report verdict . The former head of international cycling has sent the report to lawyers . Verbruggen claims the report is a \u2019character assassination\u2019 5.18e-01 False Sample 2 Hein Verbruggen is unhappy with the CIRC report verdict . The former head of international cycling has sent the report to lawyers . Verbruggen says he is having the report analysed by Swiss lawyers . 6.67e-01 False\nTable H.7: Choice of \u03f5, \u03b1 and corresponding \u03bb, \u03b3 for qualitative results presented in Appendix H.\nDataset MIMIC-CXR CNN/DM \u03b1 0.7 0.3 \u03f5 0.7 0.7 \u03bb1 (similarity) 7.37e-1 8.67e-1 \u03bb2 (quality) 2.47e-10 \u2212\u221e \u03bb3 (set score) 2.82e-4 1.02 \u03b3 (component threshold) 2.04e-1 9.88e-1"
        }
    ],
    "year": 2023
}