{
    "abstractText": "We extend JAX with the capability to automatically differentiate higher-order functions (functionals and operators). By representing functions as a generalization of arrays, we seamlessly use JAX\u2019s existing primitive system to implement higher-order functions. We present a set of primitive operators that serve as foundational building blocks for constructing several key types of functionals. For every introduced primitive operator, we derive and implement both linearization and transposition rules, aligning with JAX\u2019s internal protocols for forward and reverse mode automatic differentiation. This enhancement allows for functional differentiation in the same syntax traditionally use for functions. The resulting functional gradients are themselves functions ready to be invoked in python. We showcase this tool\u2019s efficacy and simplicity through applications where functional derivatives are indispensable. The source code of this work is released at https://github.com/sail-sg/autofd.",
    "authors": [
        {
            "affiliations": [],
            "name": "IN JAX"
        },
        {
            "affiliations": [],
            "name": "Min Lin"
        }
    ],
    "id": "SP:e9200229819d46e14560abfeb354338916881400",
    "references": [
        {
            "authors": [
                "Mart\u00edn Abadi",
                "Paul Barham",
                "Jianmin Chen",
                "Zhifeng Chen",
                "Andy Davis",
                "Jeffrey Dean",
                "Matthieu Devin",
                "Sanjay Ghemawat",
                "Geoffrey Irving",
                "Michael Isard"
            ],
            "title": "TensorFlow}: a system for {Large-Scale} machine learning",
            "venue": "In 12th USENIX symposium on operating systems design and implementation (OSDI",
            "year": 2016
        },
        {
            "authors": [
                "Fr\u00e9d\u00e9ric Bastien",
                "Pascal Lamblin",
                "Razvan Pascanu",
                "James Bergstra",
                "Ian Goodfellow",
                "Arnaud Bergeron",
                "Nicolas Bouchard",
                "David Warde-Farley",
                "Yoshua Bengio"
            ],
            "title": "Theano: new features and speed improvements",
            "venue": "arXiv preprint arXiv:1211.5590,",
            "year": 2012
        },
        {
            "authors": [
                "Jesse Bettencourt",
                "Matthew J Johnson",
                "David Duvenaud"
            ],
            "title": "Taylor-mode automatic differentiation for higher-order derivatives in jax",
            "venue": "In Program Transformations for ML Workshop at NeurIPS",
            "year": 2019
        },
        {
            "authors": [
                "Asgeir Birkisson",
                "Tobin A Driscoll"
            ],
            "title": "Automatic fr\u00e9chet differentiation for the numerical solution of boundary-value problems",
            "venue": "ACM Transactions on Mathematical Software (TOMS),",
            "year": 2012
        },
        {
            "authors": [
                "Tianqi Chen",
                "Mu Li",
                "Yutian Li",
                "Min Lin",
                "Naiyan Wang",
                "Minjie Wang",
                "Tianjun Xiao",
                "Bing Xu",
                "Chiyuan Zhang",
                "Zheng Zhang"
            ],
            "title": "Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems",
            "venue": "arXiv preprint arXiv:1512.01274,",
            "year": 2015
        },
        {
            "authors": [
                "Pietro Di Gianantonio",
                "Abbas Edalat",
                "Ran Gutin"
            ],
            "title": "A language for evaluating derivatives of functionals using automatic differentiation",
            "venue": "arXiv preprint arXiv:2210.06095,",
            "year": 2022
        },
        {
            "authors": [
                "Leon Ehrenpreis"
            ],
            "title": "On the theory of kernels of schwartz",
            "venue": "Proceedings of the American Mathematical Society,",
            "year": 1956
        },
        {
            "authors": [
                "Conal Elliott"
            ],
            "title": "The simple essence of automatic differentiation",
            "venue": "Proceedings of the ACM on Programming Languages,",
            "year": 2018
        },
        {
            "authors": [
                "C. Daniel Freeman",
                "Erik Frey",
                "Anton Raichuk",
                "Sertan Girgin",
                "Igor Mordatch",
                "Olivier Bachem"
            ],
            "title": "Brax - a differentiable physics engine for large scale rigid body simulation, 2021",
            "venue": "URL http: //github.com/google/brax",
            "year": 2021
        },
        {
            "authors": [
                "Roy Frostig",
                "Matthew James Johnson",
                "Chris Leary"
            ],
            "title": "Compiling machine learning programs via high-level tracing",
            "venue": "Systems for Machine Learning,",
            "year": 2018
        },
        {
            "authors": [
                "A Gonis"
            ],
            "title": "Functionals and functional derivatives of wave functions and densities",
            "venue": "World Journal of Condensed Matter Physics,",
            "year": 2014
        },
        {
            "authors": [
                "Zheyuan Hu",
                "Tianbo Li",
                "Zekun Shi",
                "Kunhao Zheng",
                "Giovanni Vignale",
                "Kenji Kawaguchi",
                "YAN Shuicheng",
                "Min Lin"
            ],
            "title": "Neural integral functionals",
            "venue": "In ICLR 2023 Workshop on Physics for Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Mathieu Huot",
                "Sam Staton",
                "Matthijs V\u00e1k\u00e1r"
            ],
            "title": "Correctness of automatic differentiation via diffeologies and categorical gluing",
            "venue": "In FoSSaCS,",
            "year": 2020
        },
        {
            "authors": [
                "Susi Lehtola",
                "Conrad Steigemann",
                "Micael JT Oliveira",
                "Miguel AL Marques"
            ],
            "title": "Recent developments in libxc\u2014a comprehensive library of functionals for density functional",
            "venue": "theory. SoftwareX,",
            "year": 2018
        },
        {
            "authors": [
                "Zongyi Li",
                "Nikola Kovachki",
                "Kamyar Azizzadenesheli",
                "Burigede Liu",
                "Kaushik Bhattacharya",
                "Andrew Stuart",
                "Anima Anandkumar"
            ],
            "title": "Fourier neural operator for parametric partial differential equations",
            "venue": "arXiv preprint arXiv:2010.08895,",
            "year": 2020
        },
        {
            "authors": [
                "Johannes T Margraf",
                "Karsten Reuter"
            ],
            "title": "Pure non-local machine-learned density functional theory for electron correlation",
            "venue": "Nature communications,",
            "year": 2021
        },
        {
            "authors": [
                "Adam Paszke",
                "Sam Gross",
                "Francisco Massa",
                "Adam Lerer",
                "James Bradbury",
                "Gregory Chanan",
                "Trevor Killeen",
                "Zeming Lin",
                "Natalia Gimelshein",
                "Luca Antiga"
            ],
            "title": "Pytorch: An imperative style, high-performance deep learning library",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "Barak A Pearlmutter",
                "Jeffrey Mark Siskind"
            ],
            "title": "Reverse-mode ad in a functional framework: Lambda the ultimate backpropagator",
            "venue": "ACM Transactions on Programming Languages and Systems (TOPLAS),",
            "year": 2008
        },
        {
            "authors": [
                "John P Perdew",
                "Karla Schmidt"
            ],
            "title": "Jacob\u2019s ladder of density functional approximations for the exchange-correlation energy",
            "venue": "In AIP Conference Proceedings,",
            "year": 2001
        },
        {
            "authors": [
                "Davide Piras",
                "A Spurio Mancini"
            ],
            "title": "Cosmopower-jax: high-dimensional bayesian inference with differentiable cosmological emulators",
            "venue": "arXiv preprint arXiv:2305.06347,",
            "year": 2023
        },
        {
            "authors": [
                "Alexey Radul",
                "Adam Paszke",
                "Roy Frostig",
                "Matthew J Johnson",
                "Dougal Maclaurin"
            ],
            "title": "You only linearize once: Tangents transpose to gradients",
            "venue": "Proceedings of the ACM on Programming Languages,",
            "year": 2023
        },
        {
            "authors": [
                "Samuel S Schoenholz",
                "Ekin D"
            ],
            "title": "Cubuk. Jax, md a framework for differentiable physics",
            "venue": "Journal of Statistical Mechanics: Theory and Experiment,",
            "year": 2021
        },
        {
            "authors": [
                "Amir Shaikhha",
                "Andrew Fitzgibbon",
                "Dimitrios Vytiniotis",
                "Simon Peyton Jones"
            ],
            "title": "Efficient differentiable programming in a functional array-processing language",
            "venue": "Proceedings of the ACM on Programming Languages,",
            "year": 2019
        },
        {
            "authors": [
                "Benjamin Sherman",
                "Jesse Michel",
                "Michael Carbin"
            ],
            "title": "Computable semantics for differentiable programming with higher-order functions and datatypes",
            "venue": "Proceedings of the ACM on Programming Languages,",
            "year": 2021
        },
        {
            "authors": [
                "Shlomo Sternberg"
            ],
            "title": "Lectures on differential geometry, volume 316",
            "venue": "American Mathematical Soc.,",
            "year": 1999
        },
        {
            "authors": [
                "Fei Wang",
                "Daniel Zheng",
                "James Decker",
                "Xilun Wu",
                "Gr\u00e9gory M Essertel",
                "Tiark Rompf"
            ],
            "title": "Demystifying differentiable programming: Shift/reset the penultimate backpropagator",
            "venue": "Proceedings of the ACM on Programming Languages,",
            "year": 2019
        },
        {
            "authors": [
                "Federico Zahariev",
                "Sarom Sok Leang",
                "Mark S Gordon"
            ],
            "title": "Functional derivatives of meta-generalized gradient approximation (meta-gga) type exchange-correlation density functionals",
            "venue": "The Journal of Chemical Physics,",
            "year": 2013
        },
        {
            "authors": [
                "Kunhao Zheng",
                "Min Lin"
            ],
            "title": "Jax-xc: Exchange correlation functionals library in jax",
            "venue": "In Workshop on\u201dMachine Learning for Materials\u201dICLR",
            "year": 2023
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "In functional analysis, functions can be characterized as continuous generalizations of vectors. Correspondingly, the principles of linear algebra, derivatives, and calculus for vectors can be extended to the spaces of functions. Based on this generalization, we can build higher-order functions whose domain/codomain are function spaces. These higher-order functions are traditionally called functionals or operators. For example, definite integral is a functional that maps a function to a scalar, and the differential operator is an operator that maps a function to its derivative function. The generalization of gradient descent to functionals is particularly interesting to the machine learning audiences. Like we optimize a function by moving the input in the gradient direction, a functional can be optimized by varying the input function using the functional derivative. Gradient descent for functionals has been used for a long history in science and engineering, named the calculus of variations. Well known examples include the least action principle in Lagrangian mechanics, and the variational method in quantum mechanics.\nWhile the theoretical framework for functional differentiation is established, there remains a notable gap in computational tools tailored to automatically compute functional derivatives. To this date, functional differentiation with respect to functions are usually done in one of the following ways: (1) manually derived by human and explicitly implemented (Zahariev et al., 2013; Gonis, 2014); (2) for semi-local functionals, convert it to the canonical Euler-Lagrange form, which can be implemented generally using existing AD tools (Hu et al., 2023; Cranmer et al., 2020). In stark contrast, the domain of automatic differentiation (AD) for functions that maps real tensors has seen significant advancement recently and widespread application in various domains, e.g. robotic simulation (Freeman et al., 2021), cosmology (Piras & Mancini, 2023) and molecular dynamics (Schoenholz & Cubuk, 2021). Like AD has transformed several fields and industries, we believe automatic functional differentiation (AutoFD) holds the potential to catalyze a similar wave of innovation.\nBased on the idea that functions can be represented as a generalization of arrays, we propose that AutoFD can be implemented in the same vein as AD. Building AutoFD in this way avoids the complexity of symbolic approaches that depends on analytical integrals. JAX provides an elegant machinery for supporting both forward mode and reverse mode AD without redundant code. The forward mode differentiation is implemented via linearization rules, also called jacobian vector product (JVP) rules for each primitive computation. The reverse mode differentiation consists of three steps (Radul et al., 2023), 1. perform forward mode AD on a function; 2. unzip the linear and\nnonlinear part of the function; 3. transposition of the linear part. Therefore, to make a primitive computation differentiable in JAX, it is crucial that the primitive is implemented with a JVP rule and a transpose rule. Similarly, AutoFD for an operator relies on higher-order generalizations of JVP and transpose rules, which are well defined in mathematics. The Fr\u00e9chet derivative extends the idea of derivative to higher-order functions whose inputs and outputs are functions. And the adjoint operator generalizes the concept of transposition from function to higher order functions.\nHaving introduced the fundamental mechanisms for AutoFD, we now delve into the specific operators we include in this work. We motivate the choice of operators from the types of operators and functionals that are commonly used, which we summarize as non-linear semi-local functionals and linear non-local operators. These two types cover the most used functionals in various applications, for instance, the majority of exchange-correlation functionals in density functional theory fall under semi-local or linear non-local functional categories (Perdew & Schmidt, 2001). It turns out that to build any functional described in Section 2, there is a set of five essential operators, namely, compose, \u2207, linearize, linear transpose and integrate. These operators, along with their JVP and transpose rules, are detailed in Section 3.2. To ensure the completeness of the operator set, we also introduce some auxiliary operators in Section 3.3. We discuss the applications of AutoFD in Section 4, presenting both opportunities for new methods and improvements on the coding style."
        },
        {
            "heading": "2 OPERATORS AND FUNCTIONALS",
            "text": "By convention, we define operators as mappings whose domain and codomain are both functions. For example, the \u2207 operator when applied on a function returns the derivative of that function. Functionals are mappings from functions to scalars. To distinguish them from plain functions that map real values, we denote both functionals and operators with capital letters, with an extra hat for operators. We use round brackets to denote the application of operators on functions as well as the application of functions on real values. e.g. O\u0302(f)(x) means application of operator O\u0302 on function f , and apply the resulting function on x. Without loss of generality, we write integrals without specifying the domain. For simplicity, we present the results on scalar functions when there is no ambiguity. The actual implementation supports functions that map arbitrarily shaped tensors or nested data structure of them. The operators we aim to support can be categorized into three different types based on their property.\nLocal operator generalizes element-wise transformation in finite dimensional vector spaces. Consider the input function f : X \u2192 Y , with any function \u03d5L : X \u00d7 Y \u2192 Z, a local operator \u03a6\u0302L needs to satisfy\n\u03a6\u0302L(f) : X \u2192 Z;x 7\u2192 \u03d5L(x, f(x)). (1)\nSemilocal operator extends local operator by introducing extra dependencies on the derivatives of the input function up to a finite maximum order n.\n\u03a6\u0302S(f) : X \u2192 Z;x 7\u2192 \u03d5S(x, f(x),\u2207f(x),\u2207(2)f(x), \u00b7 \u00b7 \u00b7 ,\u2207(n)f(x)). (2)\nThis type of operator is called semilocal because \u03a6\u0302S(f)(x) not only depend on the value of f(x) at the point x, but also on the function values in the infinitesimal neighborhood, i.e. f(x+ \u03b4x), via the knowledge of the derivatives.\nNonlocal operators are the operators that are neither local nor semilocal. Although they do not need to assume any specific forms, one of the most interesting nonlocal operator is the integral transform,\n\u03a6\u0302I(f) : U \u2192 Y ;u 7\u2192 \u222b \u03d5I(u, x)f(x)dx. (3)\nThe function \u03d5I : U \u00d7X \u2192 Y is called the kernel function. Integral transform generalizes finite dimensional matrix vector product; therefore it is a linear mapping of f . The Schwartz kernel theorem (Ehrenpreis, 1956) states that any linear operators can be expressed in this form.\nIntegral functionals are functionals that conform to the following form: F : F \u2192 R; f 7\u2192 \u222b \u03a6\u0302(f)(x)dx. (4)\nCorrespondingly, integral functionals are called local, semilocal or nonlocal depending on the property of operator \u03a6\u0302. The components used to build functional approximators in existing works belong to one of the above types. For example, the fourier neural operator (Li et al., 2020) is a direct generalization of multilayer perceptron, the linear layers are nonlocal integral transforms, while the nonlinear activation layers are pointwise transformation that follows the form of local operator. The lagrangian neural networks (Cranmer et al., 2020) is implicitly a composition of a integral functional with a learnable semilocal operator. In applications like density functional theory, most empirically developed functionals belongs to the semi-local family. Recently, non-local functionals are also introduced for better treatments of electron correlation (Margraf & Reuter, 2021)."
        },
        {
            "heading": "3 IMPLEMENTATION",
            "text": ""
        },
        {
            "heading": "3.1 GENERALIZED ARRAY",
            "text": "In JAX, array is a fundamental data structure that corresponds to vector, matrix and tensor in mathematics. Primitives are algebraic operations for transforming the arrays. Following the notation of JAX, we use f[3,5] to describe an float array of shape 3 by 5. To represent functions as generalied arrays, we first generalize the notations. The shape of a function is represented as a list of its return value and each arguments in the format of F[ret,arg0,\u00b7 \u00b7 \u00b7 ]. For example, F[f[],f[3],f[2,3]] describes a function: R3 \u00d7 R2\u00d73 \u2192 R. In AutoFD, this abstract information is implemented as a custom class and it is registered via jax.core.pytype_aval_mappings[types.FunctionType] to make JAX recognize and convert python functions into generalized arrays when tracing higher order function."
        },
        {
            "heading": "3.2 PRIMITIVE OPERATORS",
            "text": "The primitive operators considered in this work are focused to realize the most used types of operators and functionals described in Section 2. To enable functional derivatives for these primitives, as mentioned in the introduction, we need to define a JVP rule and a tranpose rule for each of them. Here we only make connections between the programming notation and math notation of the JVP and tranpose rules, which should be enough for understanding the implementation of AutoFD. For formal definitions, we refer the readers to Section II.5 in Sternberg (1999) for tangent/cotangent vectors, and Definition 3.6.5 in Balakrishnan (2012) for Fr\u00e9chet derivative.\nThe JVP function in JAX is defined as\njax.jvp(f, x\ufe38\ufe37\ufe37\ufe38 primal , \u03b4x\ufe38\ufe37\ufe37\ufe38 tangent ) = Jf (x)\u03b4x = D(f)(x)(\u03b4x)\ufe38 \ufe37\ufe37 \ufe38 Fr\u00e9chet notation . (5)\nWhere Jf (x) = \u2202f\u2202x \u2223\u2223 x\nis the jacobian of function f at point x. The JVP function is also called the forward mode gradient, it evaluates change of function f at point x along the direction \u03b4x. However, backward mode gradient is what we usually use in backpropagation. In JAX, the function associated with backward gradient is vector jacobian product (VJP), VJP means vector is on the left hand side of the jacobian, but we usually transpose it instead to obtain a column vector.\njax.vjp(f, x\ufe38\ufe37\ufe37\ufe38 primal )( \u03b4y\ufe38\ufe37\ufe37\ufe38 cotangent ) = Jf (x) \u22a4\u03b4y\nUsually, forward mode and backward mode are implemented separately. However, Radul et al. (2023) introduces that idea that the VJP is simply the linear transposition of JVP. Here we introduce the notations of linear transpose in programming and in math. With f(x) = Mx; f\u22a4(y) = M\u22a4y,\njax.linear_transpose(f, x\ufe38\ufe37\ufe37\ufe38 primal )( y\ufe38\ufe37\ufe37\ufe38 cotangent ) = f\u22a4(y) = T (f)(x)(y)\ufe38 \ufe37\ufe37 \ufe38 our own Fr\u00e9chet like notation\n(6)\nIt can be easily seen that when we apply linear transposition to JVP: \u03b4x 7\u2192 Jf (x)\u03b4x, it results in the VJP: \u03b4y 7\u2192 Jf (x)\u22a4\u03b4y. Therefore, in JAX, each primitive is given a JVP rule and a transpose rule, together they are used to derive the backward mode gradient in JAX.\nThe JVP and transpose rules can be generalized to higher order functions. We use the Fr\u00e9chet derivatives D and \u2202i to denote JVP rules and partial JVP rules. D(O\u0302)(f)(\u03b4f) denotes the JVP of\noperator O\u0302 with the primal value f and tangent value \u03b4f . We add a \u03b4 prefix for functions from the tangent and cotangent space. Similarly to the Fr\u00e9chet notation, we introduce the symbol T and Ti to denote transpose and partial transpose rules. Note that although transpose rules generally do not require a primal value, partial transposes do sometimes need the primal values when the operator is not jointly linear on the inputs. Therefore, we explicitly write out the primal values for transpose rules for consistency; i.e. Tf (O\u0302)(f, g)(\u03b4h) denotes transposition of the operator O\u0302 with respect to f , with the primal values f , g and cotangent value \u03b4h. The generalization of transposition to operators is the adjoint of the operator T (O\u0302) = O\u0302\u2217, satisfying \u27e8O\u0302f, g\u27e9 = \u27e8f, O\u0302\u2217g\u27e9. To support high order derivative, the JVP and transpose rules need to be implemented using primitives exclusively, which means any operator used in the right hand side of the JVP and transpose rules needs to be implemented as a primitive themselves. For example, the JVP rule (7) of the compose operator uses the linearize operator L\u0302, which is described in Section 3.2.3. To save space, we leave the proof of these rules to the Appendix."
        },
        {
            "heading": "3.2.1 THE COMPOSE OPERATOR",
            "text": "Function composition is a frequently used operator, with g : X \u2192 Y ; f : Y \u2192 Z. The compose operator is defined as f \u25e6 g : X \u2192 Z;x 7\u2192 f(g(x)). Here the compose operator \u25e6 is written as an infix operator, alternatively, we can use the symbol C\u0302 to represent the compose operator, and C\u0302(f, g) to denote the composition of f and g. The compose operator can be generalized to more than two functions. For example, C\u0302(f, g1, g2) describes the function x 7\u2192 f(g1(x), g2(x)). Implementation of compose in python is simple\ndef compose_impl(f, g): return lambda *args: f(g(*args))\nThe JVP and transpose rules of compose are derived as follows:\n\u2202g(C\u0302)(f, g) : \u03b4g 7\u2192 C\u0302(L\u0302(f), g, \u03b4g). (7) \u2202f (C\u0302)(f, g) : \u03b4f 7\u2192 C\u0302(\u03b4f, g). (8)\nTf (C\u0302)(f, g) : { \u03b4h 7\u2192 C\u0302(\u03b4h, g\u22121)|det\u2207(g\u22121)| if g is invertible. undefined otherwise.\n(9)\nTg(C\u0302)(f, g) : { \u03b4h 7\u2192 C\u0302(T\u0302 (f), \u03b4h) if f is linear. undefined otherwise.\n(10)\nAs can be seen, the implementation of the compose operator requires two auxiliary operators L\u0302(linearize) and T\u0302 (transpose), which will be defined independently in Section 3.2.3 and 3.2.4. The function inverse on the right hand side of the Tf (C\u0302) rule is not implemented because currently a general mechanism for checking the invertibility and for defining inversion rules of the primitives are not yet available in JAX. The compose operator is the basis for all local operators defined in (1). Replacing the dependency on x with an identity function I , all local operators can be composed with C\u0302(\u03d5L, I, f) : x 7\u2192 \u03d5L(I(x), f(x)). A large number of common operators can be defined via C\u0302, for example, we overload the infix operators in python to support the syntax f + g which converts to C\u0302((x, y) 7\u2192 x + y, f, g). All direct algebraic operations on functions in our code examples are supported in a similar way."
        },
        {
            "heading": "3.2.2 THE \u2207 (NABLA) OPERATOR",
            "text": "The\u2207 operator converts a function to its derivative function. In JAX, the corresponding transformations are jax.jacfwd and jax.jacrev. Its JVP and transpose rules are:\nD(\u2207)(f) : \u03b4f 7\u2192 \u2207(\u03b4f). (11) T (\u2207)(f) : \u03b4h 7\u2192 \u2212\u2207 \u00b7 \u03b4h. (12)\nThe implementation of the \u2207 operator is readily available in JAX as jax.jacfwd and jax.jacrev. The JVP rule is the same as the primal computation because \u2207 is a linear operator. The transpose\nrule uses\u2207 as the divergence operator, which can be implemented as C\u0302(trace,\u2207(\u03b4h)). We provide a quick proof of the transpose rule here for scalar variable functions, the full derivation is provided in Appendix C.2. To see the transpose rule, we write the \u2207 operator in the Schwartz kernel form, i.e. \u2207 = \u222b dy \u03b4\u2032(x\u2212 y). Like finite dimensional linear transposition swaps the axis that is contracted,\nthe T (\u2207) = \u222b dx \u03b4\u2032(x\u2212 y) simply changes the variable under integration, using integral by parts, we can verify that\nT (\u2207)(f)(y) = \u222b dx \u03b4\u2032(x\u2212 y)f(x) = \u03b4(x\u2212 y)f(x)|+\u221e\u2212\u221e \u2212 \u222b dy \u03b4(x\u2212 y)f \u2032(x) = \u2212\u2207(f)(y).\nThe \u2207 operator can be used for constructing semilocal operators together with the C\u0302 operator, i.e. semilocal operator in the form of (2) can be implemented as C\u0302(\u03d5S , I, f,\u2207f, \u00b7 \u00b7 \u00b7 ,\u2207(n)f), where I : x 7\u2192 x is the identity function, and\u2207(n) is the repeated application of\u2207 for n times."
        },
        {
            "heading": "3.2.3 THE LINEARIZE OPERATOR",
            "text": "The linearize operator has the same meaning as the Fr\u00e9chet derivative D. Except that D can be used with any higher-order functions, while we reserve the symbol L\u0302(f) : x, \u03b4x 7\u2192 \u2207(f)(x)\u03b4x for the linearization of functions. The linearize operator is necessary for the completeness of local operators, as it is used in the JVP rule (7) of the compose operator. The JVP and transpose rules of the linearize operator are defined as following:\nD(L\u0302)(f) : \u03b4f 7\u2192 L\u0302(\u03b4f). (13) T (L\u0302)(f) : \u03b4h 7\u2192 \u2212\u2207I\u0302y(y\u03b4h(\u00b7, y)). (14)\nThe I\u0302y symbol used in the transpose rule represents integration over the variable y. The corresponding function transformation implemented in JAX is jax.jvp."
        },
        {
            "heading": "3.2.4 THE LINEAR TRANSPOSE OPERATOR",
            "text": "The linear transpose operator can be applied only on linear functions. It is easy to see that the operator itself is also linear. We only manage to derive a general form for the adjoint of the transpose operator when the cotangent function is invertible.\nD(T\u0302 )(f) : \u03b4f 7\u2192 T\u0302 (\u03b4f). (15)\nT (T\u0302 )(f) : { \u03b4h 7\u2192 \u03b4h\u22121|det\u2207\u03b4h\u22121| if \u03b4h is invertible. undefined otherwise.\n(16)\nThe corresponding transformation defined in JAX for linear transposition is jax.linear_transpose."
        },
        {
            "heading": "3.2.5 THE INTEGRATE FUNCTIONAL",
            "text": "The integrate functional indispensable component for building functionals. It is required in the integral functionals (4), for constructing nonlocal operators (3), and used in the transpose rule (14) of the linearize operator. The integrate functional is called an integrate operator when we perform integration over only part of the variables. We use I\u0302 for integrate operator, with a subscript for the variable under integration. For a function of two variables, I\u0302x(f) : f 7\u2192 \u222b f(x, y)dx. The JVP rule and transpose rules are: D(I\u0302x)(f) : \u03b4f 7\u2192 I\u0302x(\u03b4f) (17) T (I\u0302x)(f) : \u03b4h 7\u2192 (x, y 7\u2192 \u03b4h(y)) (18)\nOnly a limited subset of functions admit analytical integrals, the Risch algorithm provides a robust mechanism for determining the existence of an elementary integral and for computing it. In practical applications, numerical integration techniques are more commonly employed. These techniques are rooted in the concept that a function can be expanded in a series of integrable functions. Methods of numerical integration often hinge on a designated grid of integration points associated with respective weights. For example, the Fourier series converts to summation over a uniform grid, and the Gaussian quadrature induces points that are the roots of the Legendre/Laguerre polynomials. With the grids and corresponding weights, integration of a function converts to a weighted summation over a finite set of points. We implement the integrate operator by supplying a numerical grid for the integrand function."
        },
        {
            "heading": "3.3 COMPLETENESS OF THE PRIMITIVES",
            "text": "Besides the above listed operators, a few other operators are needed for completeness. For example, the operator to permute the order that arguments are passed to a function: PermuteArgs21(f) : x, y 7\u2192 f(y, x), the operator to zip together two functions: Zip(f, g) : x, y 7\u2192 f(x), g(y). We can inspect whether these rules forms a closed set by examining whether the right hand side of the rules (7) to (18) can be implemented with these primitives themselves. Most of the rules are readily implementable with the primitives, with a few exceptions:\n1. Rule (9) and rule (16) requires the inverse of a function, which is not implemented because the general mechanism to invert a function is not available in JAX. When the function is a noninvertible map, the transpose rules can still exist mathematically (Equation 25). However, it has to be implemented case by case based on specific properties of the mapping.\n2. Rule (14) involves an integral, as discussed in Section 3.2.5, there is no general rule for integration for any functions. Therefore, the accuracy of the integral is limited by the chosen numerical grid."
        },
        {
            "heading": "3.4 EFFICIENCY OF THE IMPLEMENTATION",
            "text": "There are a few practical issues considered in our system. Firstly, chain of function composition is expensive, if we have a function h, and we compose with the expression f \u25e6 h+ g \u25e6 h. In python code this is lambda x: f(h(x)) + g(h(x)), without proper treatment, h(x) will be invoked twice. The situation is exacerbated when the resulting function is again composed with other functions multiple times. Although in JAX, common sub-expression elimination (CSE) is performed to remove redundant computations during the JIT compilation, we find in practice that the computation graph could grow to a prohibitively large size before we could JIT it. To resolve this problem, we add a cache for the function calls. When the same function is invoked several times with the same argument, the cached output is directly returned. With a large amount of redundant computations, this optimization greatly reduced the computation time of the resulting function (Appendix D).\nAnother performance issue hides in the \u2207 operator. For one, the reverse mode derivative approximately doubles the nodes in the computation graph, the size of the graph grows quickly when we perform higher order derivatives. Moreover, it is quite common in applications that we need to perform various orders of differentiation on different variables, e.g. \u2207y(\u2207x(f))(x, y) and \u2207y(f)(x, y). It is worth noting that the inner differentiation of the first expression \u2207x(f) shares computation graph with the second expression. Again, it could be prohibitively expensive for the tracing phase. This issue is not specific to our system but in general exists in JAX. We can see an opportunity for optimization using our system because we build a graph made of \u2207 operators and functions without actually executing it. It is desirable to compile mixed order differentiation of functions into efficient programs, for example, Fa\u00e0 di Bruno mode differentiation (Bettencourt et al., 2019). We leave this optimization as a future work."
        },
        {
            "heading": "4 APPLICATIONS",
            "text": "In numerous application scenarios, function approximation problems are often transformed into parameter fitting tasks, such as using neural networks or linear combinations of function bases. Gradients in the function space may appear unnecessary, as our ultimate optimization takes place in the parameter space. In this section, we focus on application cases where functional derivative plays a crucial role."
        },
        {
            "heading": "4.1 SOLVING VARIATIONAL PROBLEM",
            "text": "Variational problems are problems that search for the optima of a functional. We consider local functional of the form F (y) = \u222b I(y\u03b8(x),\u2207y\u03b8(x))dx. Conceptually, we just need to compute the functional derivative \u03b4F\u03b4y and perform gradient descent for functionals. In practice, to make it implementable, we usually introduce a parametric function y\u03b8(x). For optimization, we can directly compute the gradient w.r.t. \u03b8,\n\u2202\n\u2202\u03b8 F (y\u03b8) =\n\u222b \u2202\n\u2202\u03b8 I(y\u03b8(x),\u2207y\u03b8(x))dx (19)\nWhile the above is the most straightforward method for this problem, with the introduction of functional gradient, we enable a few more options. One of the new options is to perform chain rule through the functional gradient, namely, we compute the functional derivative \u03b4T (y)\u03b4y first, then pointwisely backpropagate the gradient to the parameter,\n\u2202\n\u2202\u03b8 F (y\u03b8) =\n\u222b \u03b4T (y\u03b8)\n\u03b4y\u03b8 (x)\n\u2202y\u03b8(x)\n\u2202\u03b8 dx (20)\nNotice that in Equation (20) the functional derivative can be explicitly expanded using the EulerLagrange formula. With some derivation (Appendix E), we can see that Equation (20) and (19) are two different estimators for the gradient of \u03b8, though they share the same expectation.\nOne more choice we have is to directly minimize the magnitude of the functional gradient based on the fact that at the optimal, functional gradient should be zero.\nmin \u03b8\n\u222b \u2225\u03b4T (y \u03b8)\n\u03b4y\u03b8 (x)\u22252dx (21)\nWe apply the above methods on the classic brachistochrone problem. The brachistochrone curve represents the optimal path that minimizes the travel time for a particle moving between two points in the gravitational field. Assume the initial position x, y = 0, 0, and the end position x, y = 1,\u22121. The travel time can be represented as a functional of the curve, denoted as F (y) = \u222b 1 0 \u221a 1 +\u2207y(x)2/ \u221a \u2212y(x)dx. The numerator calculates the length of the curve, the denominator is the speed of particle. We use y\u03b8(x) = nn\u03b8(x) sin(\u03c0x)\u2212x as the approximator, where nn\u03b8 is an MLP and the other terms are used to constrain the initial and end positions. More details of the experimental settings can be found in Appendix G\nInstead of implementing Equation (20) explicitly, we illustrated below the simplicity of using AutoFD to compose the functional and compute functional gradient. The results are summarized in Figure 1, the methods (19), (20) and (21) are named minimize F, minimize F via FD and minimize FD correspondingly. It is worth highlighting that the directly minimize in the parameter space is limited by the numerical integration, it easily overfits to the numerical grid. Meanwhile, the functional derivative involved in the other two methods seems to provide a strong regularization effect, leading to curves close to the groundtruth. Better functional optimal are found as can be seen in Figure 1 (right) that the functional gradient is closer to zero. Whether Equation (20) is better than Equation (19) in a general context needs further investigation.\nfrom autofd.operators import integrate, sqrt, nabla\ndef y(params, x): ...\ndef F(y: Callable) -> Callable: return integrate(sqrt(1+nabla(y, argnums=1)**2)/sqrt(-y)) fd = jax.grad(F)(y)"
        },
        {
            "heading": "4.2 DENSITY FUNCTIONAL THEORY",
            "text": "Density functional theory (DFT) is widely used for calculating electronic structures. Although the DFT theory proves the existence of a functional that maps electron density to the ground state energy, the accuracy of DFT in practice relies heavily on approximated exchange-correlation (XC) energy functionals with the general form\nExc(\u03c1) = \u222b \u03c1(r)\u03f5xc(\u03c1)(r)dr (22)\nWhere \u03c1 is the electron density function, and \u03f5xc(\u03c1) is the XC energy density which is dependent on \u03c1. A comprehensive list of XC functionals are maintained in LibXC (Lehtola et al., 2018), its JAX translation is introduced in JAX-XC (Zheng & Lin, 2023). In the Self-Consistent Field (SCF) update of the DFT calculation, the effective potential induced by the XC functional is computed as its functional derivative Vxc = \u03b4Exc(\u03c1) \u03b4\u03c1 . Traditionally, the Vxc is derived via the Euler-Lagrange equation. Its implementation is often done in the parameter space of \u03c1 and entangled with the numerical integral scheme. With automatic functional differentiation, the computation of Vxc can be decoupled from the choice of parameterization and integral schemes. In the code example below, gga_x_pbe is implemented as an semilocal operator using the primitives defined in this work. Vxc can be obtained by calling jax.grad on Exc.\nfrom autofd.operators import integrate # a point in 3D r = jnp.array([0.1, 0.2, 0.3]) # Exc, exchange-correlation energy functional def exc(rho: Callable) -> Float:\nepsilon_xc = gga_x_pbe(rho) return integrate(epsilon_xc * rho)\n# Vxc is the functional derivative of Exc vxc = jax.grad(exc)(rho) # Vxc is itself a function callable with r as input vxc(r)"
        },
        {
            "heading": "4.3 DIFFERENTIATING NONLOCAL FUNCTIONALS",
            "text": "Both the brachistochrone and DFT shown in previous sections are examples of integral functionals with semi-local functionals that conforms to 2. In this section, we explore a more interesting case where a nonlocal operator is involved. We consider the higher order version of multilayer perceptron (MLP), where the input is a R \u2192 R function. The ith linear layers follows fi(x) =\u222b k(x, y)fi\u22121(y)dy+ b(x), where k is the kernel function resembling the weights in MLP, and b acts as the bias. Activation functions are applied pointwise after the linear layer. For the last layer, we don\u2019t apply any activation, but compares the the output with a target function t with L2 loss. This is often called neural operator or neural functional, or which the Fourier Neural Operator (FNO) is a special case where the integral is done via fourier series.\nTo learn a neural operator, traditionally we use parameterized neural networks as k\u03b8(x, y) and b\u03d5(x) where \u03b8, \u03d5 are network parameters. The gradient descent is directly done in the parameter space, it seems like we can\u2019t apply AutoFD here. There is, however, an expensive way to do it, we can directly subtract the functional gradient from the old function, i.e. k \u2190 k \u2212 \u03b7 \u03b4L(k)\u03b4k , where \u03b7 is the learning rate and both k and \u03b4L(k)\u03b4k are functions. It is expensive because the new k expands in the computation graph. The purpose of this experiment is only to show that AutoFD is capable of handling such complex computations. We show in Appendix H that our proposed update moves in the direction of smaller losses, though each step gets more expensive and yields more complex k."
        },
        {
            "heading": "5 RELATED WORKS",
            "text": "AD has a long history of wide applications across various domains in science and engineering. More recently, the success of deep learning has brought automatic differentiation to a focal point in machine\nlearning. In the world of machine learning, several differentiable programming frameworks backed by highly optimized vectorized implementations are proposed in the past few years, for example, Theano (Bastien et al., 2012), Mxnet (Chen et al., 2015), Tensorflow (Abadi et al., 2016), Jax (Frostig et al., 2018) and Torch (Paszke et al., 2019). All of these frameworks focus on AD of functions that map real values. Differentiation of functionals and operators, however, has been mostly derived analytically and implemented case by case. There are a number of works that studies AD in the context of higher-order functionals (Pearlmutter & Siskind, 2008; Elliott, 2018; Shaikhha et al., 2019; Wang et al., 2019; Huot et al., 2020; Sherman et al., 2021). They mainly focus on how AD can be implemented more efficiently and in a compositional manner when the code contains high-order functional transformations, which is related to but distinct from this work. For example, Elliott (2018) studies how D(f \u25e6 g)(x) can be implemented more efficiently using the algebraic relation of D(f \u25e6 g)(x) = D(f)(g(x)) \u25e6 D(g)(x); while in this work, we study the differentiation of the higher-order function \u25e6 itself, namely D(\u25e6)(f). The most closely related works are Birkisson & Driscoll (2012) and Di Gianantonio et al. (2022). Birkisson & Driscoll (2012) computes the Fr\u00e9chet derivative of operators by representing functions as linear combination of Chebyshev basis functions. Di Gianantonio et al. (2022) describes a language called Dual PCF which is capable of evaluating forward mode directional derivatives of functionals. The method is based on dual numbers and there is no reverse mode support mentioned. There are also implementations of functional derivatives in symbolic math packages. For example, Both Mathmematica (Wolfram Research) and SymPy (Meurer et al., 2017) implement the semi-local functional derivative in the canonical Euler-Lagrange form. In Maple (Maplesoft), there is also the FunDiff command, which relies on the calculus of Dirac delta function and its derivatives based on the provided information. Their implementation differs from the AD approach we take in this work, and they do not support vectorized execution on modern hardwares."
        },
        {
            "heading": "6 DISCUSSION",
            "text": "In this work, we introduce AutoFD, a system to perform automatic functional differentiation. We take a novel approach to functional differentiation by directly reusing the AD machinery for higher order functions. We implemented a core set of operators that covers various useful types of functionals. We discuss several limitations here as potential directions for future work.\nCompleteness: As discussed in Section 3.3, in several of the rules, the inversion operator is required. It would rely on a systematic mechanism to register the invertibility and inverse function for the primitives, at the time of writing, such mechanism is not implemented in JAX.\nAnalytical integration: It is desirable in applications like quantum chemistry to use analytical functions and integrate them analytically. While integrating symbolic packages like SymPy to JAX (Kidger) could provide this functionality, it is limited to scalar functions. Automatically devmapping the vectorized primitive to scalar functions could be one potential path to generally bring analytical integral to JAX.\nStatic shape: AutoFD requires accurate annotation of functions using jaxtyping. This is a design choice to allow early raising of errors as it is more informative than delayed to the execution of resulting functions. However, this not only adds extra work but also limits the flexibility of using AutoFD. Further exploration is required for a better trade-off.\nProgramming in mixed order: For example, the partial transformation in python is a mixed order operator that binds an argument to a function (both considered inputs to the partial operator). While it is possible to support gradients for both the argument and the function. Complications emerge during the just in time compilation, jitting a mixed computation graph is not possible because the operator primitives are pure python and do not support lowering. Ultimately we would like to remove this constraint and program differentiably for real values as well as any order of functions."
        },
        {
            "heading": "A EXAMPLE OF IMPLEMENTATION",
            "text": "To clarify how the math are correspondingly implemented as extension to JAX, we show a minimal implementation of the operator\u2207. We restrict the implementation to take only scalar function, so that the divergence \u2207 \u00b7 \u03b4h is equal to the gradient \u2207\u03b4h. With this simplification, the JVP and transpose rules are\nD(\u2207)(f) : \u03b4f 7\u2192 \u2207(\u03b4f). (23) T (\u2207)(f) : \u03b4h 7\u2192 \u2212\u2207\u03b4h. (24)\nHere\u2019s a list of mappings between math symbols and the code.\n\u2022 f : f \u2022 \u03b4f : df \u2022 \u03b4h: dh \u2022 \u2207: nabla \u2022 D(\u2207)(f)(\u03b4f): nabla_jvp_rule((f,), (df,)) \u2022 T (\u2207)(f)(\u03b4h): nabla_transpose_rule(dh, f)\nWe first implement\u2207 as a JAX primitive.\nnabla_p = core.Primitive(\"nabla\")\ndef nabla(f): return nabla_p.bind(f)\n@nabla_p.def_impl def nabla_impl(f): return jax.grad(f)\n@nabla_p.def_abstract_eval def nabla_abstract_eval(f): # f has scalar input and output # jax.grad(f) has same signature as f return f.shape\ndef nabla_jvp_rule(primals, tangents): # nabla is a linear operator f, df = primals[0], tangents[0] return nabla(f), nabla(df)\ndef nabla_transpose_rule(cotangent, primal): # According to the transpose rule in math dh = cotangent # we assume here negation on a function # is already implemented by the compose operator return -nabla(cotangent)\n# we register the jvp and transpose rules. jax.interpreters.ad.primitive_jvps[nabla_p] = nabla_jvp_rule jax.interpreters.ad.primitive_transposes[nabla_p] = nabla_transpose_rule\nNow we define some random functions as primal, tangent and cotangent values.\ndef f(x): return jnp.sin(x)\ndef df(x): return x ** 2\ndef dh(x): return jnp.exp(x)\nFinally, we show how the operator can be invoked, and how to perform automatic functional differentiation on the operator.\n# We can use nabla directly on f, nf = nabla(f) # triggers nabla_impl, nf: jnp.cos\n# Or, we can compute the jvp of nabla, remember nabla is an operator # jax.jvp here is computing the forward mode gradient for an operator! nf, ndf = jax.jvp(nabla, primals=(f,), tangents=(df,)) # triggers nabla_jvp_rule, nf: jnp.cos, ndf: lambda x: 2x\n# Since nabla is an linear operator, we can transpose it. tnabla = jax.linear_transpose(nabla, primals=(f,)) # linear transpose of an operator is still an operator, # we apply this new operator tnabla on the function dh. tndh = tnabla(dh) # triggers nabla_transpose_rule, tndh: lambda x: -jnp.exp(x)\n# Or, we can do the backward mode gradient on nabla primal_out, vjp_function = jax.vjp(nabla, f) # invoke the vjp function on the cotangent dh vjp_dh = vjp_function(dh) # this triggers both nabla_jvp_rule and nabla_transpose_rule # vjp_dh: lambda x: -jnp.exp(x)"
        },
        {
            "heading": "B PROOFS OF JVP RULES",
            "text": "JVP rules are trivial for linear operator, for a linear operator O\u0302, the JVP rule are always simply applying the same operator on the tangent function,\nD(O\u0302)(f) : \u03b4f 7\u2192 O\u0302(\u03b4f)\nFor our core set of operators,\u2207, L\u0302 and T\u0302 are all linear operators that need no extra proof for the JVP rules. We give here a step by step derivation for the JVP rules of the C\u0302 operator.\n\u2202g(C\u0302)(f, g)(\u03b4g)(x) = lim \u03c4\u21920 f(g(x) + \u03c4\u03b4g(x))\u2212 f(g(x)) \u03c4\n= d\nd\u03c4 f(g(x) + \u03c4\u03b4g(x)) |\u03c4=0= \u2207(f)(g(x)) \u00b7 \u03b4g(x)\n= C\u0302(L\u0302(f), g, \u03b4g)(x)\n\u2202f (C\u0302)(f, g)(\u03b4f)(x) = lim \u03c4\u21920 f(g(x)) + \u03c4\u03b4f(g(x))\u2212 f(g(x)) \u03c4\n= \u03b4f(g(x))\n= C\u0302(\u03b4f, g)(x)"
        },
        {
            "heading": "C PROOFS OF TRANSPOSE RULES",
            "text": "Given an operator O\u0302 the adjoint of an operator O\u0302\u2217 satisfies (O\u0302u, v) = (u, O\u0302\u2217v).\nC.1 COMPOSE The Schwartz kernel form of compose operator is C\u0302(f, g) = \u222b \u03b4(x\u2212 g(y))f(x)dx.\n\u27e8C\u0302(f, g), \u03b4h\u27e9 = \u222b dy\u03b4h(y) \u222b dx\u03b4(x\u2212 g(y))f(x)\n= \u222b dxf(x) \u222b dy\u03b4(x\u2212 g(y))\u03b4h(y)\n= \u27e8f, \u222b dy\u03b4(x\u2212 g(y))\u03b4h(y)\u27e9 (25)\n= \u222b dxf(x) \u222b dz|det\u2207(g\u22121)(z)|\u03b4(x\u2212 z)\u03b4h(g\u22121(z))\n= \u222b dxf(x)|det\u2207(g\u22121)(x)|\u03b4h(g\u22121(x))\n= \u27e8f, C\u0302(\u03b4h, g\u22121)|det\u2207(g\u22121)|\u27e9\nTherefore, transposition of C\u0302 w.r.t. f is,\nTf (C\u0302)(f, g)(\u03b4h) = C\u0302(\u03b4h, g \u22121)|det\u2207(g\u22121)|.\nIn the case where f is linear, we can write f(x) as Jfx where Jf is the jacobian matrix of f . We omit the case where f is nonlinear, as transposition is only defined and implemented for linear operators. Transposition w.r.t. g is simple\n\u27e8C\u0302(f, g), \u03b4h\u27e9 = \u222b (Fg(y))\u22a4\u03b4h(y)dy\n= \u222b g\u22a4(y)F\u22a4\u03b4h(y)dy\n= \u27e8g, C\u0302(T\u0302 (f), \u03b4h)\u27e9\nTherefore, transpose of C\u0302 w.r.t. g is,\nTg(C\u0302)(f, g)(\u03b4h) = C\u0302(T\u0302 (f), \u03b4h)\nC.2 NABLA\nA brief proof for single variable function was given in the main text, here we expand to the multivariate case.\n\u27e8\u2207f, g\u27e9 = \u2211 ij \u222b dygij(y) \u222b dx\u03b4\u2032(xj \u2212 yj)fi(y\u223cj , xj)\n= \u2211 ij \u222b dy\u03b4\u2032(xj \u2212 yj)gij(y) \u222b fi(y\u223cj , xj)dx\n= \u27e8f,\u2212\u2207 \u00b7 g\u27e9\nC.3 LINEARIZE\n\u27e8L\u0302(f), \u03b4h\u27e9 = \u222b\u222b\u222b dz\u03b4\u2032(z \u2212 x)f(z)\u03b4x \u00b7 \u03b4h(x, \u03b4x)dxd\u03b4x\n= \u222b dzf(z) \u00b7 \u222b d\u03b4x \u03b4x \u222b dx\u03b4\u2032(z \u2212 x)\u03b4h(x, \u03b4x)\n= \u222b dzf(z) \u00b7 ( \u2212 \u222b \u03b4x\u2207\u03b4h(\u00b7, \u03b4x)d\u03b4x )\n= \u27e8f,\u2212 \u222b \u03b4x\u2207\u03b4h(\u00b7, \u03b4x)d\u03b4x\u27e9\nTherefore,\nT (L\u0302)(f)(\u03b4h) = \u2212 \u222b \u03b4x\u2207\u03b4h(\u00b7, \u03b4x)d\u03b4x\nC.4 LINEAR TRANSPOSE\nLinear transpose of linear transpose operator sounds interesting. Since linear transpose can only be applied to linear functions, we write the function being transposed as x 7\u2192 Jfx, transpose of T (f) : y 7\u2192 J\u22a4f y. We\u2019re only able to derive the adjoint of T\u0302 when \u03b4h is an invertible mapping.\n\u27e8T\u0302 (f), \u03b4h\u27e9 = \u222b\n(J\u22a4f y) \u00b7 \u03b4h(y)dy\n= \u222b y\u22a4Jf\u03b4h(y)dy\n= \u222b \u03b4h\u22121(x)\u22a4Jfxd\u03b4h \u22121(x)\n= \u222b |det\u2207(\u03b4h\u22121)(x)|\u03b4h\u22121(x)\u22a4Jfxdx\n= \u27e8f, |det\u2207(\u03b4h\u22121)|\u03b4h\u22121\u27e9\nTherefore, T (T\u0302 )(f)(\u03b4h) = T\u0302 \u2217(\u03b4h) = |det\u2207(\u03b4h\u22121)|\u03b4h\u22121\nC.5 INTEGRAL OPERATOR\n\u27e8I\u0302i(f), \u03b4h\u27e9 = \u222b dx\u223ci \u222b dxif(xi, x\u223ci)\u03b4h(x\u223ci)\n= \u222b f(x)\u03b4\u0304h(x)dx = \u27e8f, \u03b4\u0304h\u27e9\nWhere \u03b4\u0304h is xi, x\u223ci 7\u2192 \u03b4h(x\u223ci). Therefore the adjoint of the integral operator is simply augmenting the cotangent function \u03b4h with unused arguments to match the domain of the f ."
        },
        {
            "heading": "D COMMON SUBEXPRESSION ELIMINATION VIA CACHING",
            "text": "In Section 3.4, we introduced the composition f \u25e6h+ g \u25e6h. We can recursively nest this composition by setting hi = f \u25e6 hi\u22121 + g \u25e6 hi\u22121. The redundant computations are then exponential to the depth of the composition. Specifically, we use the following code for measuring the execution cost for different nested depth, with and without function call caching.\n# we use sin, exp, tanh for h, f, g respectively. def F(h): for _ in range(depth): h = f(h) + g(h)\nreturn h\n# Fh is h = f(h) + g(h) nested to depth times Fh = F(h) # time the execution t1 = time.time() jax.jit(Fh)(0.) t2 = time.time() cost = t2 - t1\nWhen the above nested function composition are implemented naively, the time cost of computation grows exponentially with the nest depth, because there are two branches f(h) and g(h) at each composition. However, when function call caching is used, at each level one branch can reuse the cached result of the other branch, resulting in a linear time cost with respect to the nest depth. We plot the time cost vs the nest depth in Figure 2."
        },
        {
            "heading": "E COMPARING GRADIENT ESTIMATORS",
            "text": "Subtracting Equation (19) and (20) we get:\u222b ( \u2202I\n\u2202\u2207y\u03b8(x) \u2202\u2207y\u03b8(x) \u2202\u03b8 +\u2207 \u2202I \u2202\u2207y\u03b8(x) \u2202y\u03b8(x) \u2202\u03b8\n) dx\n=\n\u222b ( \u2202I\n\u2202\u2207y\u03b8(x) \u2207\u2202y\n\u03b8(x)\n\u2202\u03b8 +\u2207 \u2202I \u2202\u2207y\u03b8(x) \u2202y\u03b8(x) \u2202\u03b8\n) dx\n= \u222b \u2207 ( \u2202I\n\u2202\u2207y\u03b8(x) \u2202y\u03b8(x) \u2202\u03b8\n) dx\n= \u2207 \u222b ( \u2202I\n\u2202\u2207y\u03b8(x) \u2202y\u03b8(x) \u2202\u03b8\n) dx = 0 (26)\nIn Equation (26), the integral evaluate to a constant that is not dependent on x; therefore taking \u2207 on the integral yields 0. This proves Equation (19) and (20), when the integrals are discretized, are different estimators of the same quantity."
        },
        {
            "heading": "F HIGHER ORDER FUNCTIONAL DERIVATIVE IN LIBXC",
            "text": ""
        },
        {
            "heading": "G EXPERIMENTAL SETTINGS FOR BRACHISTOCHRONE",
            "text": "For the brachistochrone experiment, the initial position is at (x0, y0) = (0, 0) and the end position is (xT , yT ) = (1,\u22121). The functional we minimize is\nF (y) = \u222b 1 0 \u221a 1 +\u2207y(x)2/ \u221a \u2212y(x)dx\nWe aim to find y\u2217 = argmin\ny F (y)\nWe use y(x) = MLP(x) sin(\u03c0x)\u2212 x to ensure that it passes through (0, 0) and (1,\u22121). The MLP is a multi-layer perceptron that maps R\u2192 R, with hidden dimensions as {128, 128, 128, 1}. All layers uses the sigmoid function as the activation function, except for the last layer which has no activation function.\nFor the integration, we use a uniformly sampled grid of 50 points, the starting point is at 0.01 and the ending point is at 1. The reason we choose a non-zero starting point is because 0 is a singular point for the integrand, i.e. the denominator \u221a \u2212y(0) = 0. For the optimization process, since it is a toy problem, we use out of the box adam optimizer from optax, with fixed learning rate 1e\u22123 and optimize for 10000 steps.\nIt is worth noting that this is not the optimal setting for doing integration, one can either use a more densely sampled grid or use Monte Carlo integration for a better fitted brachistochrone curve. We choose this setting to show that Equation (19) and Equation (20) are very different estimators, and that Eqation (20) could have a regularizing effect on the scale of functional derivative (Figure 1) due to the fact that functional derivative is explicitly used."
        },
        {
            "heading": "H NONLOCAL NEURAL FUNCTIONAL WITH FUNCTIONAL GRADIENT DESCENT",
            "text": "We describe our precedure of optimizing the nonlocal neural functional in more detail here. The neural functional we use has two linear operator layers, the first layer uses a \u2018tanh\u2018 activation function, while the second layer uses no activation. The final output function is compared with the target function via L2 loss. We take a learning rate of 0.1 for 4 steps. The code of this experiment is presented below.\nimport autofd.operators as o\ndef f(x: Float32[Array, \"\"]) -> Float32[Array, \"\"]: return jnp.sin(4 * x * jnp.pi)\ndef b(x: Float32[Array, \"\"]) -> Float32[Array, \"\"]: return jnp.sin(x * jnp.pi)\ndef y(x: Float32[Array, \"\"]) -> Float32[Array, \"\"]: return jnp.cos(x * jnp.pi)\ndef k(y: Float32[Array, \"\"], x: Float32[Array, \"\"]) -> Float32[Array, \"\"]: return jnp.sin(y) + jnp.cos(x)\ndef layer(k, b, f, activate=True): # here k @ f is syntatic sugar for # o.integrate(k * broadcast(f), argnums=1) g = k @ f + b if activate: a = o.numpy.tanh(g) return a\nelse: return g\ndef loss(params, f, t): # two layer mlp k1, b1, k2, b2 = params h1 = layer(k1, b1, f, activation=True) h2 = layer(k2, b2, h1, activation=False) return o.integrate((h2 - t)**2)\n# initialize both k1, k2 to k, b1, b2 to b param = (k, b, k, b)\n# perform gradient steps l = loss(param, f, t) print(f\"initial loss: {l}\") for i in range(3): grad = jax.grad(loss)(param, f, t) param = jax.tree_util.tree_map(lambda x, dx: x - 0.1 * dx, param, grad) l = loss(param, f, t) print(f\"loss at step {i}: {l}\")\nAs can be seen, in the limited number of steps we take, the loss steadily goes smaller (Figure 4). We visualize the prediction from the neural functional vs the target function in Figure 5, and the kernel k(x, y) from the first layer of the neural functional in Figure 6. The reason we only takes 4 steps of descent is because the learned kernel function gets prohibitively large. We show the JAXPR graphs of k(x, y) from the first neural functional layer for each step in Figure 7, notice that the graph for step 4 is too big that we failed to render it."
        }
    ],
    "title": "AUTOMATIC FUNCTIONAL DIFFERENTIATION",
    "year": 2024
}