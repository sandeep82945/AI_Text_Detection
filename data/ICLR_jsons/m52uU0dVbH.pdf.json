{
    "abstractText": "Vertical federated learning (VFL), where each participating client holds a subset of data features, has found numerous applications in finance, healthcare, and IoT systems. However, adversarial attacks, particularly through the injection of adversarial examples (AEs), pose serious challenges to the security of VFL models. In this paper, we investigate such vulnerabilities through developing a novel attack to disrupt the VFL inference process, under a practical scenario where the adversary is able to adaptively corrupt a subset of clients. We formulate the problem of finding optimal attack strategies as an online optimization problem, which is decomposed into an inner problem of adversarial example generation (AEG) and an outer problem of corruption pattern selection (CPS). Specifically, we establish the equivalence between the formulated CPS problem and a multiarmed bandit (MAB) problem, and propose the Thompson sampling with Empirical maximum reward (E-TS) algorithm for the adversary to efficiently identify the optimal subset of clients for corruption. The key idea of E-TS is to introduce an estimation of the expected maximum reward for each arm, which helps to specify a small set of competitive arms, on which the exploration for the optimal arm is performed. This significantly reduces the exploration space, which otherwise can quickly become prohibitively large as the number of clients increases. We analytically characterize the regret bound of E-TS, and empirically demonstrate its capability of efficiently revealing the optimal corruption pattern with the highest attack success rate, under various datasets of popular VFL tasks.",
    "authors": [
        {
            "affiliations": [],
            "name": "RUPTION THROUGH"
        },
        {
            "affiliations": [],
            "name": "MULTI-ARMED BANDIT"
        },
        {
            "affiliations": [],
            "name": "Duanyi"
        },
        {
            "affiliations": [],
            "name": "Yao"
        }
    ],
    "id": "SP:c0d8edf9125aa09bfb659dbf6bdc592454268327",
    "references": [
        {
            "authors": [
                "Tian Li",
                "Anit Kumar Sahu",
                "Ameet Talwalkar",
                "Virginia Smith"
            ],
            "title": "Federated learning: Challenges, methods, and future directions",
            "venue": "IEEE signal processing magazine,",
            "year": 2020
        },
        {
            "authors": [
                "Maarten G Poirot",
                "Praneeth Vepakomma",
                "Ken Chang",
                "Jayashree Kalpathy-Cramer",
                "Rajiv Gupta",
                "Ramesh Raskar"
            ],
            "title": "Split learning for collaborative deep learning in healthcare",
            "year": 1912
        },
        {
            "authors": [
                "Priyanka Mary Mammen"
            ],
            "title": "Federated learning: opportunities and challenges",
            "venue": "arXiv preprint arXiv:2101.05428,",
            "year": 2021
        },
        {
            "authors": [
                "Yang Liu",
                "Yan Kang",
                "Tianyuan Zou",
                "Yanhong Pu",
                "Yuanqin He",
                "Xiaozhou Ye",
                "Ye Ouyang",
                "Ya-Qin Zhang",
                "Qiang Yang"
            ],
            "title": "Vertical federated learning",
            "venue": "arXiv preprint arXiv:2211.12814,",
            "year": 2022
        },
        {
            "authors": [
                "Jong Hwan Ko",
                "Taesik Na",
                "Mohammad Faisal Amir",
                "Saibal Mukhopadhyay"
            ],
            "title": "Edge-host partitioning of deep neural networks with feature space encoding for resource-constrained internet-of-things platforms",
            "venue": "In 2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS),",
            "year": 2018
        },
        {
            "authors": [
                "Cheng Shi",
                "Yenan Dang",
                "Li Fang",
                "Minghua Zhao",
                "Zhiyong Lv",
                "Qiguang Miao",
                "Chi-Man Pun"
            ],
            "title": "Multifeature collaborative adversarial attack in multimodal remote sensing image classification",
            "venue": "IEEE Transactions on Geoscience and Remote Sensing,",
            "year": 2022
        },
        {
            "authors": [
                "Ian J Goodfellow",
                "Jonathon Shlens",
                "Christian Szegedy"
            ],
            "title": "Explaining and harnessing adversarial examples",
            "venue": "arXiv preprint arXiv:1412.6572,",
            "year": 2014
        },
        {
            "authors": [
                "Vuk Lesi",
                "Ilija Jovanov",
                "Miroslav Pajic"
            ],
            "title": "Integrating security in resource-constrained cyberphysical systems",
            "venue": "ACM Transactions on Cyber-Physical Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Fangfei Li",
                "Yang Tang"
            ],
            "title": "False data injection attack for cyber-physical systems with resource constraint",
            "venue": "IEEE transactions on cybernetics,",
            "year": 2018
        },
        {
            "authors": [
                "Guangyu Wu",
                "Jian Sun",
                "Jie Chen"
            ],
            "title": "Optimal data injection attacks in cyber-physical systems",
            "venue": "IEEE transactions on cybernetics,",
            "year": 2018
        },
        {
            "authors": [
                "Qi Pang",
                "Yuanyuan Yuan",
                "Shuai Wang"
            ],
            "title": "Attacking vertical collaborative learning system using adversarial dominating inputs",
            "venue": "arXiv preprint arXiv:2201.02775,",
            "year": 2022
        },
        {
            "authors": [
                "Pengyu Qiu",
                "Xuhong Zhang",
                "Shouling Ji",
                "Changjiang Li",
                "Yuwen Pu",
                "Xing Yang",
                "Ting Wang"
            ],
            "title": "Hijack vertical federated learning models with adversarial embedding",
            "venue": "arXiv preprint arXiv:2212.00322,",
            "year": 2022
        },
        {
            "authors": [
                "Shipra Agrawal",
                "Navin Goyal"
            ],
            "title": "Analysis of thompson sampling for the multi-armed bandit problem",
            "venue": "In Conference on learning theory,",
            "year": 2012
        },
        {
            "authors": [
                "Kaleel Mahmood",
                "Rigel Mahmood",
                "Ethan Rathbun",
                "Marten van Dijk"
            ],
            "title": "Back in black: A comparative evaluation of recent state-of-the-art black-box attacks",
            "venue": "IEEE Access,",
            "year": 2021
        },
        {
            "authors": [
                "Mauro Conti",
                "Nicola Dragoni",
                "Viktor Lesyk"
            ],
            "title": "A survey of man in the middle attacks",
            "venue": "IEEE communications surveys & tutorials,",
            "year": 2016
        },
        {
            "authors": [
                "Derui Wang",
                "Chaoran Li",
                "Sheng Wen",
                "Surya Nepal",
                "Yang Xiang"
            ],
            "title": "Man-in-the-middle attacks against machine learning classifiers via malicious generative models",
            "venue": "IEEE Transactions on Dependable and Secure Computing,",
            "year": 2020
        },
        {
            "authors": [
                "Dong Wang",
                "Zidong Wang",
                "Bo Shen",
                "Fuad E Alsaadi",
                "Tasawar Hayat"
            ],
            "title": "Recent advances on filtering and control for cyber-physical systems under security and resource constraints",
            "venue": "Journal of the Franklin Institute,",
            "year": 2016
        },
        {
            "authors": [
                "Aleksander Madry",
                "Aleksandar Makelov",
                "Ludwig Schmidt",
                "Dimitris Tsipras",
                "Adrian Vladu"
            ],
            "title": "Towards deep learning models resistant to adversarial attacks",
            "venue": "arXiv preprint arXiv:1706.06083,",
            "year": 2017
        },
        {
            "authors": [
                "Andrew Ilyas",
                "Logan Engstrom",
                "Anish Athalye",
                "Jessy Lin"
            ],
            "title": "Black-box adversarial attacks with limited queries and information",
            "venue": "In International Conference on Machine Learning,",
            "year": 2018
        },
        {
            "authors": [
                "Samarth Gupta",
                "Shreyas Chaudhari",
                "Gauri Joshi",
                "Osman Ya\u011fan"
            ],
            "title": "Multi-armed bandits with correlated arms",
            "venue": "IEEE Transactions on Information Theory,",
            "year": 2021
        },
        {
            "authors": [
                "Shipra Agrawal",
                "Navin Goyal"
            ],
            "title": "Near-optimal regret bounds for thompson sampling",
            "venue": "Journal of the ACM (JACM),",
            "year": 2017
        },
        {
            "authors": [
                "Adam Paszke",
                "Sam Gross",
                "Soumith Chintala",
                "Gregory Chanan",
                "Edward Yang",
                "Zachary DeVito",
                "Zeming Lin",
                "Alban Desmaison",
                "Luca Antiga",
                "Adam Lerer"
            ],
            "title": "Automatic differentiation in pytorch",
            "year": 2017
        },
        {
            "authors": [
                "I-Cheng Yeh",
                "Che-hui Lien"
            ],
            "title": "The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients",
            "venue": "Expert systems with applications,",
            "year": 2009
        },
        {
            "authors": [
                "Chih-Chung Chang",
                "Chih-Jen Lin"
            ],
            "title": "Libsvm: a library for support vector machines",
            "venue": "ACM transactions on intelligent systems and technology (TIST),",
            "year": 2011
        },
        {
            "authors": [
                "Han Xiao",
                "Kashif Rasul",
                "Roland Vollgraf"
            ],
            "title": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms",
            "venue": "arXiv preprint arXiv:1708.07747,",
            "year": 2017
        },
        {
            "authors": [
                "Alex Krizhevsky",
                "Geoffrey Hinton"
            ],
            "title": "Learning multiple layers of features from tiny images",
            "year": 2009
        },
        {
            "authors": [
                "Andrew L. Maas",
                "Raymond E. Daly",
                "Peter T. Pham",
                "Dan Huang",
                "Andrew Y. Ng",
                "Christopher Potts"
            ],
            "title": "Learning word vectors for sentiment analysis",
            "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,",
            "year": 2011
        },
        {
            "authors": [
                "Jeremy Cohen",
                "Elan Rosenfeld",
                "Zico Kolter"
            ],
            "title": "Certified adversarial robustness via randomized smoothing",
            "venue": "In international conference on machine learning,",
            "year": 2019
        },
        {
            "authors": [
                "Dongyu Meng",
                "Hao Chen"
            ],
            "title": "Magnet: a two-pronged defense against adversarial examples",
            "venue": "In Proceedings of the 2017 ACM SIGSAC conference on computer and communications security,",
            "year": 2017
        },
        {
            "authors": [
                "Blerta Lindqvist",
                "Shridatt Sugrim",
                "Rauf Izmailov"
            ],
            "title": "Autogan: Robust classifier against adversarial attacks",
            "venue": "arXiv preprint arXiv:1812.03405,",
            "year": 2018
        },
        {
            "authors": [
                "Nicolas Papernot",
                "Patrick McDaniel",
                "Ian Goodfellow"
            ],
            "title": "Transferability in machine learning: from phenomena to black-box attacks using adversarial samples",
            "venue": "arXiv preprint arXiv:1605.07277,",
            "year": 2016
        },
        {
            "authors": [
                "Yanpei Liu",
                "Xinyun Chen",
                "Chang Liu",
                "Dawn Song"
            ],
            "title": "Delving into transferable adversarial examples and black-box attacks",
            "venue": "arXiv preprint arXiv:1611.02770,",
            "year": 2016
        },
        {
            "authors": [
                "Arjun Nitin Bhagoji",
                "Warren He",
                "Bo Li",
                "Dawn Song"
            ],
            "title": "Practical black-box attacks on deep neural networks using efficient query mechanisms",
            "venue": "In Proceedings of the European Conference on Computer Vision (ECCV),",
            "year": 2018
        },
        {
            "authors": [
                "Pin-Yu Chen",
                "Huan Zhang",
                "Yash Sharma",
                "Jinfeng Yi",
                "Cho-Jui Hsieh"
            ],
            "title": "Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models",
            "venue": "In Proceedings of the 10th ACM workshop on artificial intelligence and security,",
            "year": 2017
        },
        {
            "authors": [
                "Richard S Sutton",
                "Andrew G Barto"
            ],
            "title": "Reinforcement learning: An introduction",
            "venue": "MIT press,",
            "year": 2018
        },
        {
            "authors": [
                "Tze Leung Lai",
                "Herbert Robbins"
            ],
            "title": "Asymptotically efficient adaptive allocation rules",
            "venue": "Advances in applied mathematics,",
            "year": 1985
        },
        {
            "authors": [
                "Aur\u00e9lien Garivier",
                "Olivier Capp\u00e9"
            ],
            "title": "The kl-ucb algorithm for bounded stochastic bandits and beyond",
            "venue": "In Proceedings of the 24th annual conference on learning theory,",
            "year": 2011
        },
        {
            "authors": [
                "Rahul Singh",
                "Fang Liu",
                "Xin Liu",
                "Ness Shroff"
            ],
            "title": "Contextual bandits with side-observations",
            "venue": "arXiv preprint arXiv:2006.03951,",
            "year": 2020
        },
        {
            "authors": [
                "Wei Chu",
                "Lihong Li",
                "Lev Reyzin",
                "Robert Schapire"
            ],
            "title": "Contextual bandits with linear payoff functions",
            "venue": "In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics,",
            "year": 2011
        },
        {
            "authors": [
                "Wei Chen",
                "Yajun Wang",
                "Yang Yuan"
            ],
            "title": "Combinatorial multi-armed bandit: General framework and applications",
            "venue": "In International conference on machine learning,",
            "year": 2013
        }
    ],
    "sections": [
        {
            "text": "Vertical federated learning (VFL), where each participating client holds a subset of data features, has found numerous applications in finance, healthcare, and IoT systems. However, adversarial attacks, particularly through the injection of adversarial examples (AEs), pose serious challenges to the security of VFL models. In this paper, we investigate such vulnerabilities through developing a novel attack to disrupt the VFL inference process, under a practical scenario where the adversary is able to adaptively corrupt a subset of clients. We formulate the problem of finding optimal attack strategies as an online optimization problem, which is decomposed into an inner problem of adversarial example generation (AEG) and an outer problem of corruption pattern selection (CPS). Specifically, we establish the equivalence between the formulated CPS problem and a multiarmed bandit (MAB) problem, and propose the Thompson sampling with Empirical maximum reward (E-TS) algorithm for the adversary to efficiently identify the optimal subset of clients for corruption. The key idea of E-TS is to introduce an estimation of the expected maximum reward for each arm, which helps to specify a small set of competitive arms, on which the exploration for the optimal arm is performed. This significantly reduces the exploration space, which otherwise can quickly become prohibitively large as the number of clients increases. We analytically characterize the regret bound of E-TS, and empirically demonstrate its capability of efficiently revealing the optimal corruption pattern with the highest attack success rate, under various datasets of popular VFL tasks."
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "Federated learning (FL) Li et al. (2020) is a distributed learning paradigm that enables multiple clients to collaboratively train and utilize a machine learning model without sharing their data. Conventionally, most FL research considers the Horizontal FL (HFL) setting, where clients hold different data samples with the same feature space. In contrast, vertical FL (VFL) tackles the secnarios where clients have identical samples but disjoint feature spaces. A typical VFL model comprises a top model maintained by a server and multiple bottom models, one at each participating client. During the inference process, each client computes the local embedding of data features using its bottom model and uploads it to the server through a communication channel for further prediction. Due to its advantage of incorporating attributes from diverse information sources, VFL has found promising applications in healthcare systems Poirot et al. (2019), e-commerce platforms Mammen (2021), and financial systems Liu et al. (2022). VFL inference has also been applied to the Internet of Things (IoT) scenarios (also known as collaborative inference Liu et al.; Ko et al. (2018)), where sensor data with distinct features are aggregated by a fusion center for further processing. A recent example is to utilize multi-modal image data from sensors for remote sensing image classification Shi et al. (2022).\nDespite its widespread applications, ML models have been shown vulnerable to adversarial examples (AEs) Goodfellow et al. (2014), which are modified inputs designed to cause model misclassification during the inference. Constructing AEs in the VFL setting presents unique challenges compared to the conventional ML setting. Specifically, we consider a third-party adversary who can access, replay, and manipulate messages on the communication channel between a client and the server. (For simplicity, we use client x to denote the communication channel between client x and the server throughout the paper). However, it can only corrupt a subset of clients due to resource constraints, like computational and network bandwidth Lesi et al. (2020); Li and Tang (2018); Wu et al. (2018). Also, the server\u2019s top model and the other uncorrupted clients\u2019 embeddings and models are unknown to the adversary. Under this setting, the adversary aims to generate AEs by adding manipulated perturbations to embeddings in the corrupted clients, such that the attack success rate (ASR) over a sequence of test samples is maximized. Prior works have proposed methods to generate AEs for VFL inference, for a fixed corruption pattern (i.e., the set of corrupted clients remains fixed throughout the attack). In Pang et al. (2022), a finite difference method was proposed to generate adversarial dominating inputs, by perturbing the features of a fixed corrupted client, to control the inference result, regardless of the feature values of other clients; another work Qiu et al. (2022) employed zeroth-order optimization (ZOO) to find the optimal perturbation on the uploaded embedding of a malicious client. Meanwhile, these attacks also make assumptions on certain prior knowledge at the adversary, e.g., the adversary can obtain a subset of complete test samples in advance.\nIn this paper, we consider an adversary who lacks prior knowledge on test data or VFL models, but can adaptively adjust its corruption pattern based on the effectiveness of the previous attacks, subject to a maximum number of clients that can be corrupted. For a VFL inference process of T rounds, we formulate the attack as an online optimization problem, over T corruption patterns, one for each inference round, and the embedding perturbations for the test samples in each round. To solve the problem, we first decompose it into two sub-problems: the inner adversarial examples generation (AEG) problem and the outer corruption pattern selection (CPS) problem. For the AEG problem with a fixed corruption pattern, we apply the natural evolution strategy (NES) to estimate the gradient for perturbation optimization. For the outer CPS problem, we establish its equivalence with arm selection in a multi-armed bandit (MAB) problem, with the reward being the optimal ASR obtained from the AEG problem. Given the unique challenge that the total number of arms scale combinatorially with the number of clients, we propose a novel method named Thompson sampling with empirical maximum reward (E-TS), enabling the adversary to efficiently identify the optimal corruption pattern. The key idea is to limit the exploration within the competitive set, which is defined using the expected maximum reward of each arm. Compared with plain Thompson sampling (TS) for the MAB problem Agrawal and Goyal (2012), E-TS additionally maintains the empirical maximum reward for each arm, which are utilized to estimate the underlying competitive arms, within which TS is executed to select the corruption pattern.\nWe theoretically characterize a regret bound of (N \u2212 D)O(1) + DO(log(T )) for the proposed E-TS algorithm, where N is the number of arms and D is the number of competitive arms. This demonstrates the advantage of E-TS over the plain TS, especially for a small number of competitive arms. We also empirically evaluate the performance of the proposed attack on datasets with four major types of VFL tasks. In all experiments, the proposed attack uniformly dominates all baselines with fastest convergence to the optimal corruption pattern with the highest ASR. For the proposed attack, we further conduct extensive experiments to evaluate its effectiveness under various combinations of system parameters and the design parameter, and common defense strategies against AEs."
        },
        {
            "heading": "2 PRELIMINARIES",
            "text": "VFL inference. A VFL system consists of a central server and M clients. Each client m \u2208 [M ] possesses a subset of disjoint features xm and a corresponding bottom model fm, where [M ] denotes the set {1, . . . ,M}. The central server maintains a top model f0. Given a test sample X = [x1, . . . ,xM ], VFL inference is carried out in two stages. First, each client m computes a local embedding hm = fm(xm) using its bottom model, and uploads it to the server through a communication channel for querying a label. In the second stage, the server aggregates the embeddings from all clients and computes the predicted result p = f0([h1, . . . ,hM ]) \u2208 Rc, which is a probability vector over c classes. The server broadcasts p to all the clients, who then obtain the predicted label y\u0302(p), where y\u0302(\u00b7) returns the class with the highest probability. To enhance robustness\nagainst system impairments, such as dropouts in embedding transmission, the system permits repeated queries for the same test sample, with a maximum limit of Q times. The inference process operates in an online mode, such that test samples are received continuously in a streaming fashion.\nMulti-armed bandit. A multi-armed bandit (MAB) problem consists of N arms. Each arm k \u2208 [N ] corresponds to a random reward following an unknown distribution with mean \u00b5k. The bandit is played for T rounds. In each round t \u2208 [T ], one of the N arms, denoted by k(t), is pulled. The pulled arm yields a random reward rk(t)(t) supported in the range [0, 1], which is i.i.d. from repeated plays of the same arm and observed by the player. The player must decide which arm to pull at each round t, i.e., k(t), based on the rewards in previous rounds, to maximize the expected cumulative reward at round T , expressed as E[ \u2211T t=1 \u00b5k(t)], where \u00b5k(t) = Et[rk(t)(t)]. Assuming there exists an optimal arm with the highest mean reward \u00b5\u2217, the problem is equivalent to minimizing the expected regret E[R(T )], which is defined as follows:\nE[R(T )] = E\n[ T\u2211\nt=1\n(\u00b5\u2217 \u2212 \u00b5k(t)) ] = E [ N\u2211\nk=1\nnk(T )\u2206k\n] , (1)\nwhere nk(T ) denotes the number of times pulling arm k in T rounds, and \u2206k = \u00b5\u2217 \u2212 \u00b5k denotes the mean reward gap between the optimal arm and arm k."
        },
        {
            "heading": "3 THREAT MODEL",
            "text": "Goal of the adversary. We consider two types of attacks: targeted attack and untargeted attack. For the targeted attack with some target label yv , the adversary aims to corrupt the samples whose original prediction is not yv, making the top model output y\u0302 = yv . For instance in a lending application, the adversary might set yv to \u201clending\u201d to secure a loan to an unqualified customer. For the untargeted attack with some label yu, the adversary would like to corrupt the samples whose original prediction is yu, making the top model output y\u0302 \u0338= yu. Note that the conventional untargeted attack Mahmood et al. (2021) is a special case of the one considered here, when setting yu as the true label of the attacked samples.\nMetric. The attack\u2019s effectiveness is measured by attack success rate (ASR), which is defined as ASRsv = \u2211s i=1 1(y\u0302(pi)=yv) s and ASR s u = \u2211s i=1 1(y\u0302(pi) \u0338=yu)\ns for targeted and untargeted attack, respectively, where s is the number of samples to be attacked, pi is the probability vector of test sample i, and 1(\u00b7) is the indicator function. Capability of the adversary. We consider an adversary as a third party in VFL inference, who can access, replay, and manipulate messages on the communication channel between two endpoints. This scenario stems from a man-in-the-middle (MITM) attack Conti et al. (2016); Wang et al. (2020), e.g., Mallory can open letters sent from Bob to Alice and change or resend their contents before handing over the letter to Alice. In VFL inference, a communication channel is established between each client and the server, through which embeddings and predictions are exchanged. The adversary can choose to corrupt any specific channel, e.g., client 1 (for simplicity, we use client x to denote the communication channel between client x and the server). However, due to resource constraints like computational power and network bandwidth (see, e.g., Lesi et al. (2020); Wang et al. (2016); Wu et al. (2018)), the adversary can corrupt at most C \u2264 M clients. Formally, for a test sample i, the adversary can perturb the embeddings of up to C clients, denoted as hi,a with |hi,a| \u2264 C, to obtain h\u0303i,a such that \u2225h\u0303i,a \u2212 hi,a\u2225\u221e \u2264 \u03b2(ubi \u2212 lbi), where ubi and lbi represent the maximum and minimum values of the elements in hi,a respectively, and \u03b2 \u2208 [0, 1] is the perturbation budget of some simple magnitude-based anomaly detector.\nAdaptive corruption. In the context of online inference, we focus on a class of powerful adversaries capable of adaptively adjusting their corruption patterns. In each attack round, the adversary perturbs the embeddings in the corrupted clients for a batch of test samples. In subsequent attack rounds, the sets of corrupted clients can be adjusted subject to the constraint C, exploiting feedbacks on attack performance from previous rounds."
        },
        {
            "heading": "4 PROBLEM DEFINITION",
            "text": "The attack proceeds in T rounds. In each attack round t \u2208 [T ], the adversary seeks to perturb a batch of Bt test samples following a corruption pattern Ct = {a1, . . . , aC}, where aj , j \u2208 [C], denotes the\nindex of the corrupted client. More precisely, given the embeddings of a test sample i \u2208 [Bt], denoted as hti = [h t i,1, . . . ,h t i,M ], where h t i,m,m \u2208 [M ], represents the embedding vector of client m, we partition hti into the adversarial part h t i,a = [h t i,a1 , . . . ,hti,aC ], and the benign part h t i,b, according to Ct. The adversary crafts a perturbation \u03b7ti = [\u03b7ti,a1 , . . . ,\u03b7 t i,aC\n] with \u2225\u03b7ti\u2225\u221e \u2264 \u03b2(ubi \u2212 lbi), and adds it to hti,a to obtain an adversarial embedding h\u0303 t i,a = h t i,a + \u03b7 t i , before submitting it to the server. Upon receiving h\u0303ti,a and h t i,b, the server returns the prediction f0(h\u0303 t i,a;h t i,b) to all clients. After collecting all predictions of Bt adversarial embeddings, the adversary computes the ASR,\ni.e., A({\u03b7ti}B t i=1, Ct;Bt) = \u2211Bt i=1 1(y\u0302(f0(h\u0303 t i,a;h t i,b))=yv) Bt for the targeted attack with target label yv , or\nA({\u03b7ti}B t i=1, Ct;Bt) = \u2211Bt i=1 1(y\u0302(f0(h\u0303 t i,a;h t i,b))\u0338=yu) Bt for the untargeted attack with label yu.\nThe adversary aims to find the optimal set of corruption patterns {Ct}Tt=1, and the optimal set of perturbations {{\u03b7ti}B t\ni=1}Tt=1 for each sample i \u2208 [Bt] in attack round t \u2208 [T ], thus maximizing the expected cumulative ASR over T attack rounds. We formulate this attack as an online optimization problem in (2). Note that the expectation Et is taken over the randomness with the t-th attack round and the expectation E is taking over the randomness of all T rounds.\nmax {Ct}Tt=1\nE [\u2211T t=1 Et [ max{\u03b7ti}B t i=1 A({\u03b7ti}B t i=1, Ct;Bt) ]]\n\u2211T t=1 B t\ns.t. |Ct| = C, \u2225\u03b7ti\u2225\u221e \u2264 \u03b2(ubi \u2212 lbi), \u2200t \u2208 [T ].\n(2)"
        },
        {
            "heading": "5 METHODOLOGY",
            "text": "To solve Problem (2), we decompose the above problem into an inner problem of adversarial example generation (AEG) and an outer problem of corruption pattern selection (CPS). We first specify the inner problem of AEG. At each round t, t \u2208 [T ], with a fixed corruption pattern Ct, for each test sample i \u2208 [Bt], the adversary intends to find the optimal perturbation \u03b7ti that minimizes some loss function, as shown in (3). We consider the loss function L(\u03b7ti ; Ct) = l(f0(h\u0303ti,a;hti,b), yv) for the targeted attack with target label yv , and L(\u03b7ti ; Ct) = \u2212l(f0(h\u0303ti,a;hti,b), yu) for the untargeted attack with label yu, where l(\u00b7) denotes the loss metric, such as cross-entropy or margin loss.\nInner problem (AEG): min \u03b7ti L(\u03b7ti ; Ct), s.t. \u2225\u03b7ti\u2225\u221e \u2264 \u03b2(ubi \u2212 lbi),\u2200i \u2208 [Bt]. (3)\nThen, we obtain the ASR of Bt test samples, i.e., A\u2217(Ct;Bt) = A({\u03b7t\u2217i }B t i=1, Ct;Bt), obtained using optimal perturbations \u03b7t\u2217i , i \u2208 [Bt], from solving the problem AEG. As such, the outer problem of CPS can be cast into\nOuter problem (CPS): min {Ct}Tt=1\nE [\u2211T\nt=1(\u03b1 \u2217 \u2212 Et [A\u2217(Ct;Bt)] ] \u2211T\nt=1 B t\ns.t. |Ct| = C, \u2200t \u2208 [T ],\n(4)\nwhere \u03b1\u2217 is any positive constant. The inherent randomness of A\u2217(Ct;Bt) for a fixed Ct arises from the random test samples and the random noises in the AE generation process."
        },
        {
            "heading": "5.1 AE GENERATION BY SOLVING THE AEG PROBLEM",
            "text": "To address the box-constraint inner AEG problem (3), one might initially consider employing the projected gradient descent (PGD) method Madry et al. (2017). However, in our setting, the adversary can only access the value of the loss function and cannot directly obtain the gradient, thus necessitating the use of ZOO methods. The ZOO method iteratively seeks for the optimal variable. Each iteration typically commences with an estimation of the current variable\u2019s gradient, followed by a gradient descent-based variable update. NES Ilyas et al. (2018), a type of ZOO method, not only estimates the gradient but also requires fewer queries than conventional finite-difference methods. NES is thus\nAlgorithm 1 E-TS for CPS 1: Initialization: \u2200k \u2208 [N ], \u00b5\u0302k = 0, \u03c3\u0302k = 1, nk = 0, rmaxk = 0, \u03c6\u0302k = 0. 2: for t = 1, 2, . . . , T do 3: if t > t0 then 4: Select fully explored arms to construct the set St = {k \u2208 [N ] : nk \u2265 (t\u22121)N }. 5: Select the empirical best arm kemp(t) = maxk\u2208St \u00b5\u0302k. 6: Initialize Et = \u2205, add arms k \u2208 [N ] which satisfy \u03c6\u0302k \u2265 \u00b5\u0302kemp(t) to Et. 7: else 8: Initialize set Et = [N ]. 9: end if 10: \u2200k \u2208 Et: Sample \u03b8k \u223c N (\u00b5\u0302k, \u03c3\u0302k). 11: Choose the arm k(t) = argmaxk \u03b8k and decide the corrpution pattern Ct = k(t). 12: Sample batch data [Bt], play the arm k(t) as the corruption pattern in Algorithm 2 and\nobserve the reward rk(t)(t) from the attack result for the corrupted embedding hti,a = [hti,a1 , . . . ,h t i,aC\n],\u2200i \u2208 [Bt]. 13: Update nk(t) = nk(t) + 1, \u00b5\u0302k(t) = \u00b5\u0302k(t)(nk(t)\u22121)+rk(t)(t) nk(t) , \u03c3\u0302k(t) = 1nk(t)+1 , r max k(t) =\nmax{rmaxk(t) , rk(t)(t)}, \u03c6\u0302k(t) = \u03c6\u0302k(t)(nk(t)\u22121)+rmaxk(t) nk(t) .\n14: end for 15: Output {k(1), . . . , k(T )}\nespecially well-suited for addressing the AEG problem (3) in the VFL setting, where query times are inherently limited. In the process of AE generation using NES, the adversary samples n Gaussian noises \u03b4j \u223c N (0, I), j \u2208 [n], and adds them to the current variable \u03b7ti , with some scaling parameter \u03c3 > 0. Then, the gradient estimation is given by\n\u2207\u03b7tiL(\u03b7 t i ; Ct) \u2248\n1\n\u03c3n n\u2211 j=1 \u03b4jL ( \u03b7ti + \u03c3\u03b4j ; Ct ) . (5)\nAfter obtaining the gradient estimates, the adversary can update \u03b7ti in a PGD manner. The details of the AE generation process are provided in Algorithm 2 in Appendix A. Note that the number of queries on each test sample is limited to Q, therefore, the adversary can update the drafted perturbation at most \u230aQn \u230b times for each sample."
        },
        {
            "heading": "5.2 THOMPSON SAMPLING WITH THE EMPIRICAL MAXIMUM REWARD FOR SOLVING THE CPS PROBLEM",
            "text": "To solve the CPS problem, we make a key observation that the outer problem in (4) can be cast as an MAB problem. Specifically, picking C out of total M clients to corrupt results in N = ( M C ) possible corruption patterns, which are defined as N arms in the MAB problem. That is to say, there is a bijection between the set of N arms and the optimization space of Ct. Therefore, we can transform optimization variables {Ct}Tt=1 in (4) into the selected arms at t round, i.e., {k(t)}Tt=1. At round t, pulling an arm k(t) returns the reward rk(t)(t) as the ASR, i.e., rk(t)(t) = A\u2217(Ct;Bt) \u2208 [0, 1]. We define the mean of the reward for arm k(t) as Et[rk(t)(t)] = \u00b5k(t) = Et[A\u2217(Ct;Bt)]. Without loss of generality, we assign the best arm the arm 1 with fixed positive mean \u00b51 > 0, which can be considered as the positive value \u03b1\u2217 in (4). Finally, the CPS problem in (4) is transformed into an MAB problem, i.e., min{(k(t)}Tt=1 E [\u2211T t=1(\u00b51 \u2212 \u00b5k(t)) ] .\nE-TS algorithm. In our context, the adversary could face a significant challenge as the exploration space N can become prohibitively large when engaging with hundreds of clients, which could result in a steep accumulation of regret. To mitigate the issue from extensive exploration, we first introduce the following definition of the competitive arm.\nDefinition 1 (Competitive arm). An arm k is described as a competitive arm when the expected maximum reward is larger than the best arm\u2019s mean, i.e., \u2206\u0303k,1 = \u2211T t=1 E[r max k (t)]\nT \u2212 \u00b51 \u2265 0, where rmaxk (t) = max\u03c4\u2208[t]{rk(\u03c4)}. Otherwise, it is a non-competitive arm.\nBased on the above definition, we propose Thompson sampling with Empirical maximum reward (ETS) algorithm. The basic idea of E-TS is to restrict the exploration space within the set of competitive arms to reduce accumulated regret. However, the ground-truth competitive arms cannot be accessed a priori. Therefore, we propose to construct an empirical competitive set Et with estimated competitive arms at each round t and restrict exploration within it. Estimating the competitive arms requires calculating the empirical best arm and empirical maximum reward defined as follows. Definition 2 (Empirical best arm and empirical maximum reward). An arm k is selected as the empirical best arm kemp(t) at round t, when k = argmaxk\u2208St \u00b5\u0302k(t), where \u00b5\u0302k(t) is the estimated mean of arm k\u2019s reward at round t, St = {k \u2208 [N ] : nk(t) \u2265 (t\u22121)N }, and nk(t) denotes the number of times pulling arm k in t rounds. An arm k\u2019s empirical maximum reward \u03c6\u0302k(t) is computed by: \u03c6\u0302k(t) := \u2211t \u03c4=1 r max k (\u03c4)1(k(\u03c4)=k)\nnk(t) .\nBased on Definitions 1 and 2, we are now able to present the key components of the E-TS algorithm. E-TS consists of two steps: first, for constructing an empirical competitive set Et at round t, E-TS estimates \u00b51 and \u2211T t=1 E[r max k (t)]\nT using the mean of empirical best arm \u00b5\u0302kemp(t) (t) and the empirical maximum reward \u03c6\u0302k(t), and obtains Et = {k \u2208 [N ] : \u03c6\u0302k(t) \u2212 \u00b5\u0302kemp(t)(t) \u2265 0}. Second, while performing TS to explore each arm, E-TS adopts a Gaussian prior N (\u00b5\u0302k(t), 1nk(t)+1 ) to approximate\nthe distribution of the reward, where \u00b5\u0302k(t) is defined as \u00b5\u0302k(t) := \u2211t \u03c4=1 rk(\u03c4)1(k(\u03c4)=k)\nnk(t) . In addition\nto the above two steps, E-TS also involves t0 warm-up rounds, in which it simply executes TS across all arms. These warm-up rounds are designed to facilitate a more accurate estimation of each arm\u2019s reward mean and expected maximum reward. The complete algorithm is presented in Algorithm 1. Remark 1. Previous work Gupta et al. (2021) leverages the upper bound sk,l(r) of arm k\u2019s reward conditioned on obtaining reward r from pulling arm l (i.e., E[rk(t)|rl(t) = r] \u2264 sk,l(r)) to reduce the exploration space, where sk,l(r) is a known constant. In contrast, the proposed E-TS algorithm does not require any prior information about reward upper bound, making it more practical."
        },
        {
            "heading": "6 REGRET ANALYSIS",
            "text": "In this section, we analyze the regret bound for the proposed E-TS algorithm. Prior to proof, we assume that each arm is pulled at least twice during the initial warm-up rounds. This assumption aligns with our analysis on the optimal choice of warm-up rounds detailed in Appendix C.6. Achieving this assumption is highly probable as the number of warm-up rounds increases asymptotically Agrawal and Goyal (2017). Additionally, an adversary can traverse all arms before implementing E-TS to ensure this prerequisite is met. To facilitate discussion, we first introduce two key lemmas. Then, we present the expected regret bound of E-TS algorithm in Theorem 1. We defer all proof details of the lemmas and the theorem in Appendix B. Lemma 1 (Expected pulling times of a non-competitive arm). Under the above assumption, for a non-competitive arm knc \u0338= 1 with \u2206\u0303knc,1 < 0, the expected number of pulling times in T rounds, i,e., E[nknc(T )], is bounded by E[nknc(T )] \u2264 O(1). Lemma 2 (Expected pulling times of a competitive but sub-optimal arm). Under the above assumption, the expected number of times pulling a competitive but sub-optimal arm ksub with \u2206\u0303ksub,1 \u2265 0 in T rounds is bounded as follows,\nE[nksub(T )] = T\u2211\nt=1\nPr(k(t) = ksub, n1(t) \u2265 t\nN ) \u2264 O(log(T )).\nTheorem 1 (Upper bound on expected regret of E-TS). Let D \u2264 N denote the number of competitive arms. Under the above assumption, the expected regret of the E-TS algorithm is upper bounded by DO(log(T )) + (N \u2212D)O(1). Proof sketch. We first demonstrate that the probability that pulling the optimal arm is infrequent (i.e., n1(t) < (t\u22121) N ) is bounded. Next, we categorize the sub-optimal arms into non-competitive arms and competitive but sub-optimal arms, and analyse their regret bound respectively. For a non-competitive arm knc, the probability of k(t) = knc is bounded by the probability of selecting as the competitive arm, i.e., Pr(knc \u2208 Et), which is further bounded as in Lemma 1. On the other hand, for a competitive\nbut sub-optimal arm ksub, we further divide the analysis in two cases based on whether or not the optimal arm is included in Et. By combining the probability upper bounds in these two cases, we arrive at an upper bound on the probability of k(t) = ksub as in Lemma 2. Remark 2. In comparison with plain TS, our proposed E-TS holds a significant advantage in terms of limiting the expected number of times pulling a non-competitive arm, which is reduced from O(log(T )) to O(1)."
        },
        {
            "heading": "7 EXPERIMENTAL EVALUATIONS",
            "text": ""
        },
        {
            "heading": "7.1 SETUP",
            "text": "The proposed attack is implemented using the PyTorch framework Paszke et al. (2017), and all experiments are executed on a single machine equipped with four NVIDIA RTX 3090 GPUs. Each experiment is repeated for 10 trials, and the average values and their standard deviations are reported.\nDatasets. We perform experiments on six datasets of distinct VFL tasks. 1) Tabular dataset: Credit Yeh and Lien (2009) and Real-Sim Chang and Lin (2011), where data features are equally partitioned across 6 and 10 clients, respectively; 2) Computer vision (CV) dataset: FashionMNIST Xiao et al. (2017) and CIFAR-10 Krizhevsky et al. (2009), with features equally distributed across 7 and 8 clients, respectively; 3) Multi-view dataset: Caltech-7 Li et al. (2022), which consists of 6 views, each held by a separate client; 4) Natural language dataset: IMDB Maas et al. (2011), where each complete movie review is partitioned among 6 clients, each possessing a subset of sentences. More details about the datasets and model structures are provided in Appendix C.1.\nBaselines. We consider three baseline strategies for corruption pattern selection: 1) Fixed corruption pattern, where the adversary corrupts a fixed set of clients during the inference. For comparison, we consider two fixed corruption patterns where one is the underlying optimal pattern with the highest ASR, and another is randomly selected at the beginning of the attack; 2) Random corruption (RC), where the adversary selects uniformly at random a set of C clients to corrupt in each attack round; and 3) Plain Thompson sampling (TS), where the adversary executes the plain TS to improve the corruption pattern selection.\nExperimental parameters setting. The adversary can query the server for up to Q = 2000 times per test sample. The number of warm-up rounds in E-TS t0 is set to 80 for FashionMNIST, CIFAR-10, and Caltech-7, 50 for Credit and Real-Sim, and 40 for IMDB. For the targeted attack, we set the target label to 7 for FashonMNIST and CIFAR-10, and 3 for Caltech-7. We measure the ASR over 30 test epochs, each comprising multiple attack rounds. In our ablation study, we adjust one parameter at a time, keeping the rest constant, with default settings of C = 2, t0 = 80, Q = 2000, and \u03b2 = 0.3."
        },
        {
            "heading": "7.2 RESULTS",
            "text": "We plot the ASR of targeted and untargeted attacks for different datasets in Figure 1. Note that the targeted and untargeted attacks are equivalent for Credit, Real-Sim, and IMDB with binary labels. We observe that uniformly across all datasets, the proposed E-TS method effectively attacks VFL models with an ASR of 38% \u223c 99% for targeted attack and 41% \u223c 99% for untargeted attack. For each attack, we observe a significant gap in ASR between the best and sub-optimal corruption patterns, demonstrating the significance of corruption pattern selection. The RC baseline exhibits a stable, yet sub-optimal ASR performance, as it does not leverage any information from historical ASRs. In sharp contrast, the performance of both TS and E-TS converge to that of the best corruption pattern. Notably, thanks to the estimation of empirical maximum reward, the E-TS algorithm efficiently narrows down the exploration space, achieving a much faster and more stable convergence than TS. Ablation study. We evaluate the effects of system parameters, including corruption constraint C, query budget Q, and perturbation budget \u03b2, and the design parameter, the number of warm-up rounds t0, on the performance of the proposed attack. Besides, we test the attack performance under a larger search space. As shown in Figure 3(a), ASR increases as more clients are corrupted, and E-TS consistently outperforms random corruption. It is illustrated in Figure 3(b) that it is critical to select the appropriate number of warm-up rounds t0 at the beginning of E-TS. When t0 is too small, i.e., t0 = 20, it leads to an inaccurate estimate of the empirical competitive set which may exclude the best arm, causing E-TS to converge on a sub-optimal arm. However, if t0 is too large, i.e., t0 = 200 or 1000, the advantage over plain TS diminishes. That is, one needs to optimize t0 to find the optimal arm with the fastest speed. Figure 3(c) and (d) show that ASR generally increases with\nFashionMNIST CIFAR-10 (25 attack rounds/test epoch) (27 attack rounds/test epoch)\n0 5 10 15 20 25 30 Test epoch\n26 28 30 32 34 36 38 40 AS R( % )\nE-TS TS RC Client 1,7 Client 1,2\n(a) Targeted (\u03b2 = 0.15)\n0 5 10 15 20 25 30 Test epoch\n65\n70\n75\n80\n85\nE-TS TS RC Client 1,4 Client 1,7\n(b) Untargeted (\u03b2 = 0.1)\n0 5 10 15 20 25 30 Test epoch\n20\n30\n40\n50\n60\n70\nE-TS TS RC Client 4,5 Client 7,8\n(c) Targeted (\u03b2 = 0.08)\n0 5 10 15 20 25 30 Test epoch\n50\n60\n70\n80\n90\nAS R(\n% )\nE-TS TS RC Client 4,5 Client 7,8\n(d) Untargeted (\u03b2 = 0.08)\nCredit Real-Sim Caltech (30 attack rounds/test epoch) (27 attack rounds/test epoch)\n0 5 10 15 20 25 30 Test epoch\n20 30 40 50 60 70 80 90\n100\nAS R(\n% )\nE-TS TS RC Client 2,7 Client 1,4\n(e) \u03b2 = 0.3\n0 5 10 15 20 25 30 Test epoch\n10\n20\n30\n40\n50\n60\nE-TS TS RC Client 1, 8 Client 3, 7\n(f) \u03b2 = 0.3\n0 5 10 15 20 25 30 Test epoch\n10\n20\n30\n40\nE-TS TS RC Client 3,5 Client 1,2\n(g) Targeted (\u03b2 = 0.3)\n0 5 10 15 20 25 30 Test epoch\n10\n20\n30\n40\n50\nE-TS TS RC Client 4,5 Client 2,6\n(h) Untargeted (\u03b2 = 0.3)\nIMDB Defense (20 attack rounds/test epoch) (4 different strategies)\n0 5 10 15 20 25 30 Test epoch\n60\n65\n70\n75\n80\n85\nAS R(\n% )\nE-TS TS RC Client 3,6 Client 2,4\n(i) \u03b2 = 0.05\n1 2 3 4 5 6 7 Number of corrupted clients(C)\n10\n20\n30\n40\n50\n60\nAS R(\n% )\n(a) Targeted (\u03b2 = 0.3)\n1 2 3 4 5 6 7 Number of corrupted clients(C)\n20\n40\n60\n80\n100\nNo defense Manifold projection Dropout Randomized smoothing\n(b) Untargeted (\u03b2 = 0.1)\nFigure 1: Attack performance on six datasets of distinct VFL tasks.\nFigure 2: Attack performance on FashionMNIST under different defense strategies.\nlarger Q and \u03b2. Nevertheless, after reaching 0.3, increasing perturbation budget has negligible effect on improving ASR. Figure 4 shows that E-TS consistently outperforms baselines in larger exploration space, i.e., when there are ( 16 2 ) = 120, ( 16 3 ) = 560, ( 28 2 ) = 378, and ( 28 3 ) = 3276 choices. Notably, this performance gap between E-TS and TS becomes even more pronounced when the exploration space is expanded, demonstrating its effectiveness in handling larger exploration spaces. More experimental results of corrupting different numbers of clients on other datasets are provided in Appendix C.2. We also investigated the dynamics of arm selection and empirical competitive set in TS and E-TS (in Appendix C.3), minimum query budget and corruption channels to achieve 50% ASR (in Appendix C.4), the E-TS performance in large exploration spaces (in Appendix C.5), and the optimal choice on the warm-up round t0(in Appendix C.6).\nDefenses. We further evaluate the effectiveness of the proposed attack under the following common defense strategies. Randomized smoothing (Cohen et al. (2019)): The main idea is to smooth out the decision boundary of a classifier, such that it\u2019s less sensitive to small perturbations in the input data. To construct a smooth VFL classifier, Gaussian noises are added to clients\u2019 embeddings, which are then processed by the top model to make a prediction. The final prediction is obtained by majority voting over 100 such trials; Dropout (Qiu et al. (2022)): A dropout layer is added after\neach activation layer in the server\u2019s top model to improve the robustness. Here, we set the dropout rate to 0.3; Manifold projection (Meng and Chen (2017); Lindqvist et al. (2018)): An autoencoder is incorporated into the model as a pre-processing step before the top model. During training, the autoencoder is trained using clean embeddings and designed to reconstruct the original embeddings. During inference, the clients\u2019 embeddings are first processed using the autoencoder before being passed to the top model for prediction.\nAs shown in Figure 2, for a targeted attack with \u03b2 = 0.3, the ASR of the proposed attack reduces under all considered defenses; for an untargeted attack when \u03b2 = 0.1, the ASRs experience marginal reductions under the randomized smoothing and dropout defenses, but significant drops of 35% \u223c 72% in the ASR under manifold projection. The advantage of manifold projection can be attributed to the learning of the manifold structure and the transformation of adversarial embeddings into clean embeddings. Overall, while manifold projection exhibits the strongest capability in defending the proposed attack, it fails to completely eliminate all AEs."
        },
        {
            "heading": "8 RELATED WORK",
            "text": "AE generation for ML models. AE generation methods can be generally classified into two categories: white-box and black-box settings. While the former assumes the adversary knows full knowledge of model parameters and architectures, the latter assumes no prior knowledge of either the models or training data. Our work is concerned with a black-box setting, which is typically addressed using either transfer-based or query-based solutions. Transfer-based methods Papernot et al. (2016); Liu et al. (2016) generate AEs using a substitute model, which is trained either by querying the model\u2019s output or using a subset of training data. Query-based methods Bhagoji et al. (2018); Chen et al. (2017) optimize AEs utilizing gradient information, which is estimated through the queried outputs. One classical example is the ZOO attack Chen et al. (2017), which employs zeroth-order stochastic coordinate descent for gradient estimation.\nMAB algorithms. Multiple classical algorithms, such as \u03f5-greedy Sutton and Barto (2018), Upper Confidence Bounds (UCB) Lai et al. (1985); Garivier and Cappe\u0301 (2011), and Thompson sampling (TS) Agrawal and Goyal (2012), are proposed to solve the MAB problem. Recent advancements have proposed variants of MAB under different settings, leveraging additional information to minimize the exploration. These include correlated arm bandit Gupta et al. (2021), contextual bandit Singh et al. (2020); Chu et al. (2011), and combinatorial bandit Chen et al. (2013). However, their application in the context of adversarial attacks, particularly in VFL, remains largely unexplored."
        },
        {
            "heading": "9 CONCLUSION",
            "text": "We propose a novel attack, for an adversary who can adaptively corrupt a certain number of communication channels between a client and the server, to generate AEs for inference of VFL models. Specifically, we formulate the problem of adaptive AE generation as an online optimization problem, and decompose it into an adversarial example generation (AEG) problem and a corruption pattern selection (CPS) problem. We transform the CPS problem into an MAB problem, and propose a novel Thompson Sampling with Empirical maximum reward (E-TS) algorithm to find the optimal corruption pattern. We theoretically characterize the expected regret bound of E-TS, and perform extensive experiments on various VFL tasks to substantiate the effectiveness of our proposed attack."
        },
        {
            "heading": "ACKNOWLEDGMENT",
            "text": "This work is in part supported by the National Nature Science Foundation of China (NSFC) Grant 62106057."
        },
        {
            "heading": "APPENDIX",
            "text": ""
        },
        {
            "heading": "A AE GENERATION ALGORITHM",
            "text": "The function (6) is used to estimate the gradient from the Natural evolution strategy (NES) Ilyas et al. (2018). The detailed method for zeroth-order AE generation in VFL is presented in Algorithm 2. In step 6, we use antithetic sampling to generate noise for efficiency.\n\u2207\u03b7tiL(\u03b7 t i , Ct) \u2248\n1\n\u03c3n n\u2211 j=1 \u03b4jL ( \u03b7ti + \u03c3\u03b4j , Ct ) , (6)\nAlgorithm 2 Zeroth-order AE generation in VFL 1: Input: Batch [Bt], adversarial embedding hti,a, benign embedding hti,b, i \u2208 [Bt], corruption\npattern Ct, learning rate lr, the sample size of the Gaussion noise n, the perturbation budget \u03b2, query budget Q, and the embedding range [lbi, ubi], i \u2208 [Bt].\n2: Initialization: \u03b7ti,m = 0,m \u2208 [M ] , \u03b7ti = [\u03b7ti,a1 , . . . ,\u03b7 t i,aC ], counter s = 0. 3: for i \u2208 [Bt] do 4: for q \u2208 [Qn ] do 5: Clamp the perturbation to \u2225\u03b7ti\u2225\u221e \u2264 \u03b2(ubi \u2212 lbi). 6: Make a query to the server with adversarial embedding h\u0303ti,a = h t i,a + \u03b7 t i 7: if the attack is not successful then 8: Initiate n2 noise vectors \u03b4v \u223c N (0, I), v \u2208 {1, .., n 2 }, another n 2 noise vectors are \u03b4u = \u2212\u03b4v, u \u2208 {n2 , ..., n}. 9: Clamp the perturbation to \u2225\u03b7ti + \u03b4j\u2225\u221e \u2264 \u03b2(ubi \u2212 lbi), where j \u2208 [n].\n10: Make n queries to the server and estimate the gradient G\u0302 through function (6). 11: Update the perturbation \u03b7ti = \u03b7 t i \u2212 lr \u2217 G\u0302. 12: else 13: Break the loop, store \u03b7ti and s = s+ 1. 14: end if 15: end for 16: end for 17: Clamp \u2225\u03b7ti\u2225\u221e \u2264 \u03b2(ubi \u2212 lbi), i \u2208 [Bt], return \u03b7ti and the attack success rate sBt ."
        },
        {
            "heading": "B PROOFS IN SECTION REGRET ANALYSIS",
            "text": "In this section, we provide detailed proofs of lemmas and the theorem in Section 6 Regret Analysis of our paper. We initiate the proof procedure by establishing the definitions for two key events and three supporting facts, intended to streamline the proof process. Fact 1 (Hoeffding\u2019s inequality). Let X1, . . . , Xn be independent i.i.d. random variables bounded in [a, b], then for any \u03b4 > 0, we have\nPr (\u2223\u2223\u2223\u2223\u2211ni=1 Xin \u2212 E(Xi) \u2223\u2223\u2223\u2223 \u2265 \u03b4) \u2264 2 exp( \u22122n\u03b42(b\u2212 a)2 ) .\nFact 2 (Abramowitz And Stegun 1964). For a Gaussian distributed random variable Z with mean m and variance \u03c32, for any z,\n1\n4 \u221a \u03c0 \u00b7 e\u22127z 2/2 < Pr(|Z \u2212m| > z\u03c3) \u2264 1 2 e\u2212z 2/2\nFact 3 (Concentration Bounds). Let X1, . . . , Xn be 0-1-valued random variables. Suppose that there are 0 \u2a7d \u03b4i \u2a7d 1, for 1 \u2a7d i \u2a7d n, such that, for every set S \u2286 [n],Pr [\u2227i\u2208SXi = 1] \u2a7d \u220f i\u2208S \u03b4i.\nLet \u03b4 = (1/n) \u2211n i=1 \u03b4i. Then, for any \u03b3 such that \u03b4 \u2a7d \u03b3 \u2a7d 1, we have Pr [ \u2211n\ni=1 Xi \u2a7e \u03b3n] \u2a7d e\u2212nD(\u03b3\u2225\u03b4), where D(a\u2225b) is the cross entropy of a and b.\nDefinition 3 (Events E1(t) and E2(t)). E1(t) is the event that the optimal arm 1 satisfies n1(t) < (t\u22121) N ,\u2200t \u2208 [T \u2212 t0]. E2(t) is the event that the optimal arm 1 is not identified in the empirical competitive set Et at round t, t > t0.\nBased on the above facts and the definition, we then provide the following lemmas.\nLemma 3. Let \u03b3 = N\u22121N , and \u03b4 = (N \u2212 1)( 1 2 exp(\u2212\u2206 2 min/16) + 2 exp(\u2212\u22062min/4) \u2212 1 2 exp(\u22125\u2206 2 min/16)+exp ( \u2212 (t0\u22121)\u2206 2 min 2N ) +exp(\u2212\u22062min)). The probability of event E1(t) is upper bounded by Pr(n1(t) < t\u22121N ) \u2264 exp (\u2212tD(\u03b3\u2225\u03b4)).\nProof. Let X\u03c4 = 0 denote the optimal arm 1 is pulled at \u03c4 round, and X\u03c4 = 1 denotes that the best arm is not pulled. Considering the probability Pr(n1(t) < t\u22121N , t > t0), we assume that each arm is pulled at least two times after the warm-up round t0. Therefore, we can transform the probability Pr(n1(t) < t N , t > t0) into Pr( \u2211t \u03c4=t0+1 X\u03c4 > (N\u22121) N t+ 2N+1 N ) \u2264 Pr( \u2211t \u03c4=t0+1 X\u03c4 > (N\u22121) N t).\nIn our algorithm, for every set S \u2286 [t\u2212 t0], Pr (\u2227\u03c4\u2208SX\u03c4 = 1) = \u220f\n\u03c4\u2208S Pr (X\u03c4 = 1|F\u03c4 ), where F\u03c4 is the history of pulling the optimal arm 1 until round \u03c4 . We first analyze the upper bound of the probability Pr (X\u03c4 = 1|F\u03c4 ), when \u03c4 \u2208 [t\u2212 t0]. From our algorithm, we can derive that Pr (X\u03c4 = 1|F\u03c4 ) \u2264 \u2211 \u2113\u2208[N ]\\1 Pr (\u03b81(\u03c4) < \u03b8\u2113(\u03c4)|F\u03c4 )\n+ \u2211 \u2113\u2208[N ]\\1 Pr ( \u03c6\u03021(\u03c4) < \u00b5\u0302\u2113(\u03c4), n\u2113(t) \u2265 (\u03c4\u22121)N ) , where \u2113 is a sub-optimal arm. We then analyze the bound of probablity Pr (X\u03c4 = 1|F\u03c4 ) as follows:\n\u2211 \u2113\u2208[N ]\\1 Pr (\u03b81(\u03c4) < \u03b8\u2113(\u03c4)|F\u03c4 ) + \u2211 \u2113\u2208[N ]\\1 Pr ( \u03c6\u03021(\u03c4) < \u00b5\u0302\u2113(\u03c4), n\u2113(\u03c4) \u2265 (\u03c4 \u2212 1) N )\n\u2264 \u2211\n\u2113\u2208[N ]\\1\nPr (( \u03b81(\u03c4) < \u00b51 \u2212\n\u2206\u2113 2\n)\u22c3( \u03b8\u2113(\u03c4) > \u00b51 \u2212\n\u2206\u2113 2\n))\n+ \u2211\n\u2113\u2208[N ]\\1\nPr (( \u03c6\u03021(\u03c4) < \u00b51 \u2212\n\u2206min 2\n)\u22c3( \u00b5\u0302\u2113(\u03c4) > \u00b51 \u2212\n\u2206min 2\n) , n\u2113(\u03c4) \u2265\n(\u03c4 \u2212 1) N ) (a)\n\u2264 \u2211\n\u2113\u2208[N ]\\1\nPr ( \u03b81(\u03c4) < \u00b51 \u2212\n\u2206\u2113 2\n) + \u2211 \u2113\u2208[N ]\\1 Pr ( \u03b8\u2113(\u03c4) > \u00b5\u2113 + \u2206\u2113 2 )\n+ \u2211\n\u2113\u2208[N ]\\1\nPr ( \u03c6\u03021(\u03c4) < \u2211T t=1 E[rmax1 (t)]\nT \u2212 \u2206min 2\n)\n+ \u2211\n\u2113\u2208[N ]\\1\nPr ( \u00b5\u0302\u2113(\u03c4) > \u00b5\u2113 +\n\u2206min 2 , n\u2113(\u03c4) \u2265 (\u03c4 \u2212 1) N ) (b) \u2264 (N \u2212 1)((1 2 exp(\u2212\u22062min/16) + 2 exp(\u2212\u22062min/4)\n\u2212 1 2 exp(\u22125\u22062min/16) + exp\n( \u2212 (t0 \u2212 1)\u2206 2 min\n2N\n) + exp(\u2212\u22062min)),\n(7)\nwhere we have (a) from the union bound. For inequality (b), our objective is to delineate the upper bounds of to derive the upper bound of Pr ( \u03b81(\u03c4) < \u00b51 \u2212 \u2206\u21132 ) and Pr ( \u03b8\u2113(\u03c4) > \u00b5\u2113 + \u2206\u2113 2 ) .\nTo achieve this, we invert our approach to discuss the lower bounds of Pr ( \u03b81(\u03c4) \u2265 \u00b51 \u2212 \u2206\u21132 ) and\nPr ( \u03b8\u2113(\u03c4) \u2264 \u00b5\u2113 + \u2206\u21132 ) . We first focus on the probability Pr ( \u03b81(\u03c4) \u2265 \u00b51 \u2212 \u2206\u21132 ) :\nPr ( \u03b81(\u03c4) \u2265 \u00b51 \u2212\n\u2206\u2113 2\n) \u2265 Pr ( \u03b81(\u03c4) \u2265 \u00b5\u03021(\u03c4)\u2212\n\u2206\u2113 4 \u2265 \u00b51 \u2212 \u2206\u2113 2 ) = Pr ( \u03b81(\u03c4) \u2265 \u00b5\u03021(\u03c4)\u2212\n\u2206\u2113 4\n) Pr ( \u00b5\u03021(\u03c4)\u2212\n\u2206\u2113 4 \u2265 \u00b51 \u2212 \u2206\u2113 2 ) (c)\n\u2265 ( 1\u2212 1\n4 exp(\u2212n1(\u03c4)\u22062\u2113/32)\n)( 1\u2212 exp(\u2212n1(\u03c4)\u22062\u2113/8) ) = 1\u2212 1\n4 exp(\u2212n1(\u03c4)\u22062\u2113/32)\u2212 exp(\u2212n1(\u03c4)\u22062\u2113/8) +\n1 4 exp(\u22125n1(\u03c4)\u22062\u2113/32),\n(8) where the inequality (c) is from Fact 1 and 2. Similarly, we can derive\nPr ( \u03b8\u2113(\u03c4) \u2264 \u00b5\u2113 +\n\u2206\u2113 2\n) \u2265 1\u22121\n4 exp(\u2212n\u2113(\u03c4)\u22062\u2113/32)\u2212exp(\u2212n1(\u03c4)\u22062\u2113/8)+\n1 4 exp(\u22125n\u2113(\u03c4)\u22062\u2113/32).\nThen we can derive (b) using Fact 1 and we have ensured each arm is pulled at least 2 times during the warm-up round t0.\nFor every S \u2286 [t \u2212 t0], we have an upper bound value \u03b4max for Pr (X\u03c4 = 1|F\u03c4 ): \u03b4max = (N \u2212 1)( 12 exp(\u2212\u2206 2 min/16) + 2 exp(\u2212\u22062min/4) \u2212 12 exp(\u22125\u2206 2 min/16) + exp ( \u2212 (t0\u22121)\u2206 2 min 2N ) +\nexp(\u2212\u22062min)). Let \u03b4 = 1t\u2212t0 \u2211t \u03c4=t0+1 \u03b4max = \u03b4max and \u03b3 = (N\u22121) N , we can derive the following bound from Fact 3:\nPr(n1(t) < t\u2212 1 N ) = Pr( t\u2211 \u03c4=0 X\u03c4 > t (N \u2212 1) N ) \u2264 exp (\u2212tD(\u03b3\u2225\u03b4)) . (9)\nLemma 4. After the warm-up round t0, for any sub-optimal arm k \u0338= 1,\u2206k = \u00b51 \u2212 \u00b5k \u2265 0, the following inequality holds,\nT\u2211 t=t0+1 Pr ( k = kemp(t), n1(t) \u2265 (t\u2212 1) N ) \u2264 4N \u22062k\nProof. We bound the probability by :\n= T\u2211 t=t0+1 Pr ( k = kemp(t), n1(t) \u2265 (t\u2212 1) N ) (d) =\nT\u2211 t=t0+1 Pr ( k = kemp(t), n1(t) \u2265 (t\u2212 1) N ,nk(t) \u2265 (t\u2212 1) N )\n\u2264 T\u2211\nt=t0+1\nPr ( \u00b5\u0302k(t) \u2265 \u00b5\u03021(t), nk(t) \u2265\n(t\u2212 1) N ,n1(t) \u2265 (t\u2212 1) N\n)\n\u2264 T\u2211\nt=t0+1\nPr (( (\u00b5\u03021(t) \u2264 \u00b51 \u2212\n\u2206k 2\n) \u22c3\n(\u00b5\u0302k(t) \u2265 \u00b51 \u2212 \u2206k 2 )\n) , nk(t) \u2265\n(t\u2212 1) N ,n1(t) \u2265 (t\u2212 1) N\n)\n= T\u2211 t=t0+1 Pr (( (\u00b5\u03021(t) \u2264 \u00b51 \u2212 \u2206k 2 ) \u22c3 (\u00b5\u0302k(t) \u2265 \u00b5k + \u2206k 2 ) ) , nk(t) \u2265 (t\u2212 1) N ,n1(t) \u2265 (t\u2212 1) N ) (e)\n\u2264 T\u2211\nt=t0+1\nPr ( \u00b5\u03021(t)\u2212 \u00b51 \u2264 \u2212\n\u2206k 2 , n1(t) \u2265 (t\u2212 1) N\n) + T\u2211 t=t0+1 Pr ( \u00b5\u0302k(t)\u2212 \u00b5k \u2265 \u2206k 2 , nk(t) \u2265 (t\u2212 1) N ) (f)\n\u2264 T\u2211\nt=t0+1\n2 exp\n( \u2212(t\u2212 1)\u22062k\n2N\n) (g)\n\u2264 4N \u22062k ,\n(10)\nHere, (d) holds because of the truth that the empirical best arm is kemp(t) selected from the set St = {k \u2208 [N ] : nk(t) \u2265 (t\u22121)N }. Inequality (e) follows the union bound. We have (f) from the truth that \u00b5\u0302k(t) = \u2211t \u03c4=1 rk(\u03c4)1(k(\u03c4)=k)\nnk(t) ,\u2200k \u2208 [N ] and Fact 1. The last inequality (g) uses the fact\nthat \u2206 2 k\n2N > 0 and the geometric series.\nProof of Lemma 1. Now, we prove Lemma 1 in the main paper.\nProof. During t0 warm-up rounds, the maximum pulling times of a non-competitive arm knc are bound in t0. We then analyze the expected number of times pulling knc after round t0.\nT\u2211 t=t0+1 Pr(k(t) = knc)\n= T\u2211 t=t0+1 Pr(k(t) = knc, n1(t) \u2265 (t\u2212 1) N ) + T\u2211 t=t0+1 Pr(k(t) = knc, n1(t) < (t\u2212 1) N )\n(h) \u2264 T\u2211\nt=t0+1\nPr(k(t) = knc, knc = kemp(t), n1(t) \u2265 (t\u2212 1) N )\n+ T\u2211 t=t0+1 Pr ( k(t) = knc, knc \u2208 St \\ kemp(t), n1(t) \u2265 (t\u2212 1) N ) + T\u2211 t=t0+1 Pr(n1(t) < (t\u2212 1) N )\n(i) \u2264 T\u2211\nt=t0+1\nPr ( \u00b5\u03021(t) \u2264 \u03c6\u0302knc(t), k(t) = knc, n1(t) \u2265\n(t\u2212 1) N\n) + 4N\n\u22062knc + T\u2211 t=t0+1 exp (\u2212tD(\u03b3\u2225\u03b4))\n\u2264 T\u2211\nt=t0+1\nPr (( (\u00b5\u03021(t) \u2264 \u00b51 +\n\u2206\u0303knc,1 2\n) \u22c3 (\u03c6\u0302knc(t) \u2265 \u00b51 + \u2206\u0303knc,1\n2 )\n) , k(t) = knc, n1(t) \u2265\n(t\u2212 1) N\n)\n+ T\u2211 t=t0+1 exp (\u2212tD(\u03b3\u2225\u03b4)) + 4N \u22062knc\n(j) \u2264 T\u2211\nt=t0+1\nPr ( \u00b5\u03021(t) \u2264 \u00b51 +\n\u2206\u0303knc,1 2 n1(t) \u2265 (t\u2212 1) N\n)\n+ T\u2211 t=t0+1 Pr\n( \u03c6\u0302knc(t) \u2265 \u2211T t=1 E[rmaxknc (t)]\nT \u2212 \u2206\u0303k nc,1 2 , k(t) = knc\n) +\nT\u2211 t=t0+1 exp (\u2212tD(\u03b3\u2225\u03b4)) + 4N \u22062knc\n(k) \u2264 T\u2211\nt=t0+1\nexp\n( \u2212(t\u2212 1)\u2206\u03032knc,1\n2N\n) +\nT\u2211 j=1 Pr\n( \u03c6\u0302knc(\u03c4j)\u2212 \u2211T t=1 E[rmaxknc (t)]\nT \u2265 \u2212\u2206\u0303k nc,1 2\n)\n+ T\u2211 t=t0+1 exp (\u2212tD(\u03b3\u2225\u03b4)) + 4N \u22062knc\n(l) \u2264 T\u2211\nt=t0+1\nexp\n( \u2212(t\u2212 1)\u2206\u03032knc,1\n2N\n) +\nT\u2211 j=1 exp\n( \u2212 j\u2206\u03032knc,1\n2\n) +\nT\u2211 t=t0+1 exp (\u2212tD(\u03b3\u2225\u03b4)) + 4N \u22062knc\n(m)\n\u2264 2N \u2206\u03032knc,1 + 2 \u2206\u03032knc,1 +\n1\nD(\u03b3\u2225\u03b4) +\n4N\n\u22062knc = O(1),\n(11) Here, both (h) and (j) are derived using the union bound. We have (i) from the Lemma 4 and Lemma 3. The inequality (k) is obtained from Fact 1, wherein j in (k) explicitly denotes the round index when arm ksub is pulled. Inequality (l) stems from Fact 1. We have (m) because of the truth that \u2206\u03032knc,1 2N \u2265 0, \u2206\u03032knc,1 2 \u2265 0, and D(\u03b3\u2225\u03b4) \u2265 0. We also use geometric series in (m).\nWe provide another Lemma to facilitate the proof of Lemma 2 in the main paper.\nLemma 5. The following inequality holds, Pr (E2(t)) \u2264 4(N \u2212 1)t exp ( \u2212 (t\u2212 1)\u2206 2 min\n2N\n) +\n(N \u2212 1) D(\u03b3\u2225\u03b4) ,\nwhere \u2206min = mink \u2206k."
        },
        {
            "heading": "Proof.",
            "text": "Pr (E2(t)) (n) \u2264 \u2211\n\u2113\u2208[N ]\\1\nPr ( \u03c6\u03021(t) < \u00b5\u0302\u2113(t), n1(t) \u2265\n(t\u2212 1) N ,n\u2113(t) \u2265 (t\u2212 1) N\n)\n+ \u2211\n\u2113\u2208[N ]\\1\nPr ( \u03c6\u03021(t) < \u00b5\u0302\u2113(t), n1(t) <\n(t\u2212 1) N ,n\u2113(t) \u2265 (t\u2212 1) N\n)\n+ \u2211\n\u2113\u2208[N ]\\1\nPr ( \u00b5\u03021(t) < \u00b5\u0302\u2113(t), n1(t) \u2265\n(t\u2212 1) N ,n\u2113(t) \u2265 (t\u2212 1) N\n)\n\u2264 \u2211\n\u2113\u2208[N ]\\1\nPr( ( (\u03c6\u03021(t) < \u00b51 \u2212\n\u2206min 2\n) \u22c3\n(\u00b5\u0302\u2113(t) > \u00b51 \u2212 \u2206min 2 )\n) ,\nn1(t) \u2265 (t\u2212 1) N ,n\u2113(t) \u2265 (t\u2212 1) N )\n+ \u2211\n\u2113\u2208[N ]\\1\nPr( ( (\u00b5\u03021(t) < \u00b51 \u2212\n\u2206min 2\n) \u22c3\n(\u00b5\u0302\u2113(t) > \u00b51 \u2212 \u2206min 2 )\n) ,\nn1(t) \u2265 (t\u2212 1) N ,n\u2113(t) \u2265 (t\u2212 1) N\n) + \u2211\n\u2113\u2208[N ]\\1\nPr ( n1(t) <\n(t\u2212 1) N ) (o)\n\u2264 \u2211\n\u2113\u2208[N ]\\1\nPr ( (\u03c6\u03021(t) < \u2211T t=1 E[rmax1 (t)]\nT \u2212 \u2206min 2 , n1(t) \u2265 (t\u2212 1) N\n)\n+ \u2211\n\u2113\u2208[N ]\\1\nPr ( (\u00b5\u03021(t) < \u00b51 \u2212\n\u2206min 2 , n1(t) \u2265 (t\u2212 1) N\n)\n+ 2 \u2211\n\u2113\u2208[N ]\\1\nPr ( \u00b5\u0302\u2113(t) > \u00b5\u2113 +\n\u2206min 2 , n\u2113(t) \u2265 (t\u2212 1) N\n) + (N \u2212 1) exp (\u2212tD(\u03b3\u2225\u03b4))\n(p) \u2264 4(N \u2212 1) exp ( \u2212 (t\u2212 1)\u2206 2 min\n2N\n) + (N \u2212 1) exp (\u2212tD(\u03b3\u2225\u03b4)) ,\n(12) Inequality (n), using union bound, arises from the observation that when arm 1 is absent from the empirical competitive set Et at round t, it is either not selected as the empirical best arm kemp(t) or its \u03c6\u03021(t) is less than the estimated mean of the empirical best arm \u00b5\u0302kemp(t)(t). The validity of inequality\n(n) relies on the fact that \u2211T t=1 E[r max 1 (t)]\nT \u2265 \u00b51 and Lemma 3. We establish the final inequality (p) by leveraging Fact 1.\nProof of Lemma 2. Now, we present proof details of Lemma 2 in the main paper.\nProof. We split the analysis of \u2211T\nt=1 Pr(k(t) = k sub) into three parts: the pulls in the warm round;\nthe pulls when the event E2(t) happens after the warm round; the pulls when the complementary of\nE2(t) happens. We summarize it as follows:\nT\u2211 t=1 Pr ( k(t) = ksub ) = t0\u2211 t=1 Pr ( k(t) = ksub ) + T\u2211 t=t0+1 Pr ( k(t) = ksub, E2(t) ) +\nT\u2211 t=t0+1 Pr ( k(t) = ksub, Ec2(t) ) \u2264\nT\u2211 t=1 Pr ( k(t) = ksub ) + T\u2211 t=t0+1 Pr (E2(t))\n(13)\nWhen event E2(t) does not happen, the analysis of the upper bound of pulling the competitive but sub-optimal arm aligns to plain TS. We apply the result from Agrawal and Goyal (2012), which bounds the number of times a sub-optimal arm k \u0338= 1 is pulled within O(log(T )). In Lemma 5, when E2(t) happens, we derive the following bound:\nT\u2211 t=t0+1 Pr(E2(t)) \u2264 T\u2211 t=t0+1 ( 4(N \u2212 1) exp ( \u2212 (t\u2212 1)\u2206 2 min 2N ) + (N \u2212 1) exp (\u2212tD(\u03b3\u2225\u03b4)) ) \u2264 8N(N \u2212 1)\n\u22062min +\n1\nD(\u03b3\u2225\u03b4) = O(1).\n(14) The proof is completed."
        },
        {
            "heading": "Proof the Theorem 1.",
            "text": "Proof. We revisit the definition of expected regret, given by:\nE[R(T )] = E\n[ T\u2211\nt=1\n(\u00b51 \u2212 \u00b5k(t))\n] = E [ N\u2211\nk=1\nnk(T )\u2206k\n] .\nConsidering D competitive arms and (N \u2212D) non-competitive arms, the regret of E-TS in T rounds is bounded by:\nE[R(T )] = \u2211\nknc\u2208[N\u2212D]\nE[nknc(T )]\u2206knc + \u2211\nksub\u2208[D]\nE[nksub(T )]\u2206ksub\n(1) \u2264 \u2211\nknc\u2208[N\u2212D]\n\u2206kncO(1) + \u2211\nksub\u2208[D]\n\u2206ksubO(log(T ))\n\u2264 (N \u2212D)O(1) +DO(log(T )),\n(15)\nwhere the inequality (1) is from Lemma 2 and Lemma 1. Thus the proof is finalized."
        },
        {
            "heading": "C SUPPLEMENTARY EXPERIMENTS AND EXPERIMENTAL DETAILS",
            "text": ""
        },
        {
            "heading": "C.1 DATASET AND MODEL STRUCTURE",
            "text": "Table 1 provides essential information about each dataset used in our study. We will introduce more details regarding the dataset characteristics and the corresponding model structures.\nThe Credit dataset consists of information regarding default payments, demographic characteristics, credit data, payment history, and credit card bill statements from clients in Taiwan. The dataset is partitioned evenly across six clients, each managing a bottom model with a Linear-BatchNormReLU structure. The server hosts the top model, comprising of two Linear-ReLU-BatchNorm layers followed by a WeightNorm-Linear-Sigmoid layer.\nThe Real-sim dataset is from LIBSVM, which is a library for support vector machines (SVMs). 10 clients equally hold the data features and compute embeddings through a bottom model with 2 Linear-ReLU-BatchNorm layers. The server controls the top model with 3 Linear-ReLU layers.\nThe FashionMNIST dataset consists of 28 \u00d7 28 grayscale images of clothing items. The dataset is equitably distributed across 7 clients, with each holding a data portion of 28 \u00d7 4 dimensions. On the client side, it holds a Linear-BatchNorm-ReLU bottom model. On the server side, the top model comprises eight groups of Conv-BatchNorm-ReLU structures, two MaxPool layers, two Linear-Dropout-ReLU layers, and a final Linear output layer.\nThe CIFAR-10 dataset contains 60,000 color images of size 32 \u00d7 32, representing vehicles and animals. We divide each image into 4\u00d7 32 sub-images and distribute them among 8 clients. Each client\u2019s bottom model consists of 2 convolutional layers and 1 max-pooling layer. The server\u2019s top model is built with 6 convolutional layers and 3 linear layers.\nThe Caltech-7 dataset, a subset of seven classes from the Caltech-101 object recognition collection, is distributed across six clients. Each client is assigned one unique feature view, encompassing the Gabor feature, Wavelet moments (WM), CENTRIST feature, Histogram of Oriented Gradients (HOG) feature, GIST feature, and Local Binary Patterns (LBP) feature, respectively. Every client maintains a bottom model utilizing a Linear-BatchNorm-ReLU structure. At the server level, the top model comprises eight Linear-ReLU layers, two Dropout layers, and a final Linear output layer.\nThe IMDB dataset comprises 50,000 highly polarized movie reviews, each categorized as either positive or negative. For distributed processing across 6 clients, each review is divided into several sentences, and an equal number of these sentences are allocated to each client. Each client utilizes a Bert model without fine-tuning\u2014at the bottom level to obtain an embedding with 512 dimensions. These embeddings are then input to the server\u2019s top model, which consists of two Linear-ReLU layers followed by a final Linear output layer."
        },
        {
            "heading": "C.2 EXPERIMENTAL RESULT IN ABLATION STUDY",
            "text": "Additional experiments have been conducted across a variety of datasets under diverse corruption constraints, as illustrated in Figure 5."
        },
        {
            "heading": "C.3 DYNAMICS OF ARM SELECTION AND EMPIRICAL COMPETITIVE SET IN TS AND E-TS",
            "text": "We investigated the arm selection behavior of TS and E-TS during a targeted attack on FashionMNIST, as shown in Figure 6. This study also tracked the variation in the size of E-TS\u2019s empirical competitive set, depicted in Figure 6. The parameters for this analysis were consistent with those in the FashionMNIST targeted attack scenario (Figure 1): t0 = 80, C = 2, \u03b2 = 0.15, Q = 2000 and the number of arms N = ( 7 2 ) = 21. We list all arms as follow:\n[0: (client 1, client 2), 1: (client 1, client 3), 2: (client 1, client 4), 3: (client 1, client 5), 4:(client 1, client 6), 5: (client 1, client 7), 6: (client 2, client 3), 7: (client 2, client 4), 8: (client 2, client 5), 9: (client 2, client 6), 10: (client 2, client 7), 11: (client 3, client 4), 12: (client 3, client 5), 13: (client 3, client 6), 14: (client 3, client 7), 15: (client 4, client 5), 16: (client 4, client 6), 17: (client 4, client 7), 18: (client 5, client 6), 19: (client 5, client 7), 20: (client 6, client 7)].\nAnalysis of Figure 6(a) reveals that initially, E-TS selected a suboptimal arm. However, after 140 rounds, it consistently chose arm 5 (representing the pair of client 1 and client 7), indicating a stable\nselection. In contrast, TS continued to explore different arms during this period. Figure 6(b) shows that the empirical competitive set in E-TS reduced to a single arm within the first 40 rounds. Initially, the competitive arm selected by E-TS was not optimal. Nevertheless, E-TS effectively narrowed down its focus to this suboptimal arm, eventually dismissing it as non-competitive and identifying the best arm for selection."
        },
        {
            "heading": "C.4 MINIMUM QUERY BUDGET AND CORRUPTION CHANNELS TO ACHIEVE 50% ASR",
            "text": "To explore how the necessary number of queries and corrupted channels vary across different models, datasets, and systems, we conducted experiments using Credit and Real-sim datasets. We specifically analyzed the average number of queries q required to attain a 50% ASR under various levels of client corruption (corruption constraint C). For this analysis, we applied the proposed attack on both the Credit and Real-sim datasets in a 7-client setting. We varied C from 1 to 7 and recorded the average queries q needed for attacking over 50% of the samples successfully. In addition to assessing the impact of different datasets, we investigated the influence of model complexity by attacking two deeper Real-sim models contrasting it with the standard 3-layer server model. Specifically, the standard 3-layer model Real-sim(standard) has a Dropout layer after the first layer of the server model and achieves 96.1% test accuracy. One deeper server model Real-sim(deep) added an extra three layers to the Real-sim(standard) after the Dropout layer of the server model. Another model\nReal-sim(dropout) structure is the same as Real-sim(deep) except that it added another Dropout layer before the penultimate layer of the server model. Both Real-sim(deep) and Real-sim(dropout) have 97% test accuracy. Furthermore, to analyze the system\u2019s effect on q and C, we conducted experiments on Real-sim in a 10-client scenario, varying C from 1 to 10 and recording q. Throughout these experiments, we maintained \u03b2 = 0.8 and t0 = 2N , where N denotes the number of arms. The results are presented in Figure 7.\nFrom Figure 7, we observe that the required average number of queries decreases with a looser (or higher) corruption constraint C. The comparison of Real-sim and Credit (Figure 7(a)) reveals that simpler datasets in the same task category (both being tabular datasets) necessitate fewer queries.\nContrary to our initial assumption, a deeper model does not necessarily require more queries. The results for Real-sim(standard), Real-sim(deep), and Real-sim(norm) from Figure 7(a) suggest that attacking a Real-sim(deep) requires fewer queries. A deeper model with an extra Dropout layer can make the model more robust and needs more quires to achieve 50% ASR. The reason for that is the deeper model will learn a different hidden feature of the sample, thus making the model have different robustness compared to the shallow one. Dropout can enhance robustness by preventing the model from becoming overly reliant on any single feature or input node, encouraging the model to learn more robust and redundant representations.\nComparing Figure 7 (a) and (b), we deduce that systems with more clients demand a greater number of queries to achieve the same ASR at a given C, due to each client possessing fewer features.\nIn conclusion, to attain a target ASR with the same C, simpler datasets within the same task require fewer queries. Systems with a higher number of clients necessitate more queries. However, the influence of the model\u2019s complexity does not simply depend on the scales of model parameters but is affected more by the Dropout layer."
        },
        {
            "heading": "C.5 DISCUSSION ON THE LARGE EXPLORATION SPACES",
            "text": "We extend the experiments in Figure 4 to larger exploration spaces, i.e. set the corruption constraint C = 7 and C = 8, which results in ( 16 7 ) = 11, 440, ( 16 8 ) = 12, 870 arms, respectively. However, constrained by the computation power and limited time in the rebuttal period, we compare E-TS and plain TS in large exploration spaces through numerical simulation where ASR is substituted with a sample in Gaussian distribution. For the simulation, we created a list of means starting from 0 up to 0.99, in increments of 0.01, each with a variance of 0.1. This list was extended until it comprised 11, 440 \u2212 1 and 12, 870 \u2212 1 elements, to which we added the best arm, characterized by a mean of 1 and a variance of 0.1. This list represents the underlying mean and variance of the arms. Upon playing an arm, a reward is determined by randomly sampling a value, constrained to the range [0, 1]. With knowledge of the underlying mean, we plotted the cumulative regret over rounds, R(t) = \u2211t \u03c4=1(\u00b51 \u2212 \u00b5k(\u03c4)), where \u00b51 is the best arm\u2019s mean, and k(\u03c4) is the arm selected in round \u03c4 . These results are presented in Figure 8.\nThe results from Figure 8 reveal that in large exploration spaces, TS struggles to locate the best arm within a limited number of rounds. In contrast, E-TS demonstrates more rapid convergence, further confirming the benefits of utilizing an empirical competitive set in large exploration spaces.\nC.6 THE STUDY OF OPTIMAL CHOICE ON THE WARM-UP ROUND t0\nTo ascertain the ideal number of warm-up rounds t0 for different arm settings, we conducted numerical experiments with N = 100 and N = 500. For N = 100, we experimented with t0 = 150 (less than 2N ), t0 = 200, 300, 500 (within [2N, 5N ]), and t0 = 800 (greater than 5N ). Similarly, for N = 500, the settings were t0 = 750 (less than 2N ), t0 = 1000, 2000, 2500 (within [2N, 5N ]), and t0 = 4000 (greater than 5N ).\nIn these experiments, ASR was replaced with Gaussian distribution samples. We initialized 100 arms with means from 0 to 0.99 (in 0.01 increments) and variances of 0.1. The reward for playing an arm was sampled from its Gaussian distribution. The cumulative regret R(T ) was computed as R(T ) = \u2211T t=1(\u00b51 \u2212 \u00b5k(t)), where \u00b51 = 0.99 and k(t) is the arm selected at round t, as illustrated in Figure 9.\nFigure 9(a) shows that E-TS converges faster with a smaller t0, but with t0 = 150, it converges to a sub-optimal arm. Figure 9(b) indicates faster convergence with smaller t0. Both figures suggest that t0 = 2N achieves the most stable and rapid convergence, while t0 > 5N results in the slowest convergence rate. Analyzing the pull frequencies of each arm during t0, we find that with t0 < 2N , most arms are pulled only once, and some are never explored. Conversely, with t0 \u2208 [2N, 5N ], most arms are pulled at least twice, yielding a more reliable estimation of their prior distributions.\nThus, we recommend setting t0 to at least N , with the optimal range being [2N, 5N ] in practical scenarios. This range ensures that each arm is sampled at least twice using TS, enabling a more accurate initial assessment of each arm\u2019s prior distribution. Such preliminary knowledge is vital for E-TS to effectively form an empirical competitive set of arms. If t0 is too small, there\u2019s an increased risk of E-TS prematurely converging on a suboptimal arm due to inadequate initial data, possibly overlooking the best arm in the empirical competitive set."
        }
    ],
    "title": "TICAL FEDERATED LEARNING: OPTIMAL CLIENT COR-",
    "year": 2024
}