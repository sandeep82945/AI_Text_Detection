{
    "abstractText": "Recent advancements in autonomous driving have relied on data-driven approaches, which are widely adopted but face challenges including dataset bias, overfitting, and uninterpretability. Drawing inspiration from the knowledge-driven nature of human driving, we explore the question of how to instill similar capabilities into autonomous driving systems and summarize a paradigm that integrates an interactive environment, a driver agent, as well as a memory component to address this question. Leveraging large language models (LLMs) with emergent abilities, we propose the DiLu framework, which combines a Reasoning and a Reflection module to enable the system to perform decision-making based on common-sense knowledge and evolve continuously. Extensive experiments prove DiLu\u2019s capability to accumulate experience and demonstrate a significant advantage in generalization ability over reinforcement learning-based methods. Moreover, DiLu is able to directly acquire experiences from real-world datasets which highlights its potential to be deployed on practical autonomous driving systems. To the best of our knowledge, we are the first to leverage knowledge-driven capability in decision-making for autonomous vehicles. Through the proposed DiLu framework, LLM is strengthened to apply knowledge and to reason causally in the autonomous driving domain. Project page: https://pjlab-adg.github.io/DiLu/",
    "authors": [
        {
            "affiliations": [],
            "name": "Licheng Wen"
        },
        {
            "affiliations": [],
            "name": "Daocheng Fu"
        },
        {
            "affiliations": [],
            "name": "Xin Li"
        },
        {
            "affiliations": [],
            "name": "Xinyu Cai"
        },
        {
            "affiliations": [],
            "name": "Tao Ma"
        },
        {
            "affiliations": [],
            "name": "Pinlong Cai"
        },
        {
            "affiliations": [],
            "name": "Min Dou"
        },
        {
            "affiliations": [],
            "name": "Botian Shi"
        },
        {
            "affiliations": [],
            "name": "Liang He"
        },
        {
            "affiliations": [],
            "name": "Yu Qiao"
        }
    ],
    "id": "SP:714d66608def64e830880ef50b8dedb1ef68d70f",
    "references": [
        {
            "authors": [
                "Josh Achiam",
                "Steven Adler",
                "Sandhini Agarwal",
                "Lama Ahmad",
                "Ilge Akkaya",
                "Florencia Leoni Aleman",
                "Diogo Almeida",
                "Janko Altenschmidt",
                "Sam Altman",
                "Shyamal Anadkat"
            ],
            "title": "Gpt-4 technical report",
            "venue": "arXiv preprint arXiv:2303.08774,",
            "year": 2023
        },
        {
            "authors": [
                "Daniel Bogdoll",
                "Jasmin Breitenstein",
                "Florian Heidecker",
                "Maarten Bieshaar",
                "Bernhard Sick",
                "Tim Fingscheidt",
                "Marius Z\u00f6llner"
            ],
            "title": "Description of corner cases in automated driving: Goals and challenges",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision Workshop,",
            "year": 2021
        },
        {
            "authors": [
                "Jan-Aike Bolte",
                "Andreas Bar",
                "Daniel Lipinski",
                "Tim Fingscheidt"
            ],
            "title": "Towards corner case detection for autonomous driving",
            "venue": "IEEE Intelligent vehicles symposium (IV),",
            "year": 2019
        },
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are few-shot learners",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "S\u00e9bastien Bubeck",
                "Varun Chandrasekaran",
                "Ronen Eldan",
                "Johannes Gehrke",
                "Eric Horvitz",
                "Ece Kamar",
                "Peter Lee",
                "Yin Tat Lee",
                "Yuanzhi Li",
                "Scott Lundberg"
            ],
            "title": "Sparks of artificial general intelligence: Early experiments with gpt-4",
            "venue": "arXiv preprint arXiv:2303.12712,",
            "year": 2023
        },
        {
            "authors": [
                "Long Chen",
                "Yuchen Li",
                "Chao Huang",
                "Bai Li",
                "Yang Xing",
                "Daxin Tian",
                "Li Li",
                "Zhongxu Hu",
                "Xiaoxiang Na",
                "Zixuan Li"
            ],
            "title": "Milestones in autonomous driving and intelligent vehicles: Survey of surveys",
            "venue": "IEEE Transactions on Intelligent Vehicles,",
            "year": 2022
        },
        {
            "authors": [
                "Long Chen",
                "Yuchen Li",
                "Chao Huang",
                "Yang Xing",
                "Daxin Tian",
                "Li Li",
                "Zhongxu Hu",
                "Siyu Teng",
                "Chen Lv",
                "Jinjun Wang"
            ],
            "title": "Milestones in autonomous driving and intelligent vehicles\u2014part 1: Control, computing system",
            "year": 2023
        },
        {
            "authors": [
                "Long Chen",
                "Siyu Teng",
                "Bai Li",
                "Xiaoxiang Na",
                "Yuchen Li",
                "Zixuan Li",
                "Jinjun Wang",
                "Dongpu Cao",
                "Nanning Zheng",
                "Fei-Yue Wang"
            ],
            "title": "Milestones in autonomous driving and intelligent vehicles\u2014part ii: Perception and planning",
            "venue": "IEEE Transactions on Systems, Man, and Cybernetics: Systems,",
            "year": 2023
        },
        {
            "authors": [
                "Aakanksha Chowdhery",
                "Sharan Narang",
                "Jacob Devlin",
                "Maarten Bosma",
                "Gaurav Mishra",
                "Adam Roberts",
                "Paul Barham",
                "Hyung Won Chung",
                "Charles Sutton",
                "Sebastian Gehrmann"
            ],
            "title": "Palm: Scaling language modeling with pathways",
            "venue": "arXiv preprint arXiv:2204.02311,",
            "year": 2022
        },
        {
            "authors": [
                "Felipe Codevilla",
                "Eder Santana",
                "Antonio M L\u00f3pez",
                "Adrien Gaidon"
            ],
            "title": "Exploring the limitations of behavior cloning for autonomous driving",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2019
        },
        {
            "authors": [
                "Danny Driess",
                "Fei Xia",
                "Mehdi SM Sajjadi",
                "Corey Lynch",
                "Aakanksha Chowdhery",
                "Brian Ichter",
                "Ayzaan Wahid",
                "Jonathan Tompson",
                "Quan Vuong",
                "Tianhe Yu"
            ],
            "title": "Palm-e: An embodied multimodal language model",
            "venue": "arXiv preprint arXiv:2303.03378,",
            "year": 2023
        },
        {
            "authors": [
                "Jiafei Duan",
                "Samson Yu",
                "Hui Li Tan",
                "Hongyuan Zhu",
                "Cheston Tan"
            ],
            "title": "A survey of embodied ai: From simulators to research tasks",
            "venue": "IEEE Transactions on Emerging Topics in Computational Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Daocheng Fu",
                "Xin Li",
                "Licheng Wen",
                "Min Dou",
                "Pinlong Cai",
                "Botian Shi",
                "Yu Qiao"
            ],
            "title": "Drive like a human: Rethinking autonomous driving with large language models",
            "venue": "In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision: Workshop,",
            "year": 2024
        },
        {
            "authors": [
                "Peng Gao",
                "Jiaming Han",
                "Renrui Zhang",
                "Ziyi Lin",
                "Shijie Geng",
                "Aojun Zhou",
                "Wei Zhang",
                "Pan Lu",
                "Conghui He",
                "Xiangyu Yue",
                "Hongsheng Li",
                "Yu Qiao"
            ],
            "title": "Llama-adapter v2: Parameter-efficient visual instruction model",
            "venue": "arXiv preprint arXiv:2304.15010,",
            "year": 2023
        },
        {
            "authors": [
                "Florian Heidecker",
                "Jasmin Breitenstein",
                "Kevin R\u00f6sch",
                "Jonas L\u00f6hdefink",
                "Maarten Bieshaar",
                "Christoph Stiller",
                "Tim Fingscheidt",
                "Bernhard Sick"
            ],
            "title": "An application-driven conceptualization of corner cases for perception in highly automated driving",
            "venue": "IEEE Intelligent Vehicles Symposium (IV),",
            "year": 2021
        },
        {
            "authors": [
                "Siyuan Huang",
                "Zhengkai Jiang",
                "Hao Dong",
                "Yu Qiao",
                "Peng Gao",
                "Hongsheng Li"
            ],
            "title": "Instruct2act: Mapping multi-modality instructions to robotic actions with large language model",
            "venue": "arXiv preprint arXiv:2305.11176,",
            "year": 2023
        },
        {
            "authors": [
                "Wenlong Huang",
                "Chen Wang",
                "Ruohan Zhang",
                "Yunzhu Li",
                "Jiajun Wu",
                "Li Fei-Fei"
            ],
            "title": "Voxposer: Composable 3d value maps for robotic manipulation with language models",
            "venue": "arXiv preprint arXiv:2307.05973,",
            "year": 2023
        },
        {
            "authors": [
                "Ye Jin",
                "Xiaoxi Shen",
                "Huiling Peng",
                "Xiaoan Liu",
                "Jingli Qin",
                "Jiayang Li",
                "Jintao Xie",
                "Peizhong Gao",
                "Guyue Zhou",
                "Jiangtao Gong"
            ],
            "title": "Surrealdriver: Designing generative driver agent simulation framework in urban contexts based on large language model",
            "venue": "arXiv preprint arXiv:2309.13193,",
            "year": 2023
        },
        {
            "authors": [
                "Jeff Johnson",
                "Matthijs Douze",
                "Herv\u00e9 J\u00e9gou"
            ],
            "title": "Billion-scale similarity search with gpus",
            "venue": "IEEE Transactions on Big Data,",
            "year": 2019
        },
        {
            "authors": [
                "Yann LeCun"
            ],
            "title": "A path towards autonomous machine intelligence version 0.9",
            "venue": "Open Review,",
            "year": 2022
        },
        {
            "authors": [
                "Edouard Leurent"
            ],
            "title": "An environment for autonomous driving decision-making",
            "venue": "https:// github.com/eleurent/highway-env,",
            "year": 2018
        },
        {
            "authors": [
                "Xin Li",
                "Yeqi Bai",
                "Pinlong Cai",
                "Licheng Wen",
                "Daocheng Fu",
                "Bo Zhang",
                "Xuemeng Yang",
                "Xinyu Cai",
                "Tao Ma",
                "Jianfei Guo"
            ],
            "title": "Towards knowledge-driven autonomous driving",
            "venue": "arXiv preprint arXiv:2312.04316,",
            "year": 2023
        },
        {
            "authors": [
                "Theo X Olausson",
                "Jeevana Priya Inala",
                "Chenglong Wang",
                "Jianfeng Gao",
                "Armando Solar-Lezama"
            ],
            "title": "Is self-repair a silver bullet for code generation",
            "venue": "arXiv preprint arXiv:2306.09896,",
            "year": 2023
        },
        {
            "authors": [
                "Long Ouyang",
                "Jeffrey Wu",
                "Xu Jiang",
                "Diogo Almeida",
                "Carroll Wainwright",
                "Pamela Mishkin",
                "Chong Zhang",
                "Sandhini Agarwal",
                "Katarina Slama",
                "Alex Ray"
            ],
            "title": "Training language models to follow instructions with human feedback",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Joon Sung Park",
                "Joseph C O\u2019Brien",
                "Carrie J Cai",
                "Meredith Ringel Morris",
                "Percy Liang",
                "Michael S Bernstein"
            ],
            "title": "Generative agents: Interactive simulacra of human behavior",
            "venue": "arXiv preprint arXiv:2304.03442,",
            "year": 2023
        },
        {
            "authors": [
                "Rolf Pfeifer",
                "Fumiya Iida"
            ],
            "title": "Embodied artificial intelligence: Trends and challenges",
            "venue": "In Embodied Artificial Intelligence: International Seminar, Dagstuhl Castle, Germany, July 7-11,",
            "year": 2003
        },
        {
            "authors": [
                "Fawaz Sammani",
                "Tanmoy Mukherjee",
                "Nikos Deligiannis"
            ],
            "title": "Nlx-gpt: A model for natural language explanations in vision and vision-language tasks",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Timo Schick",
                "Jane Dwivedi-Yu",
                "Roberto Dess\u00ec",
                "Roberta Raileanu",
                "Maria Lomeli",
                "Luke Zettlemoyer",
                "Nicola Cancedda",
                "Thomas Scialom"
            ],
            "title": "Toolformer: Language models can teach themselves to use tools",
            "venue": "arXiv preprint arXiv:2302.04761,",
            "year": 2023
        },
        {
            "authors": [
                "Hugo Touvron",
                "Thibaut Lavril",
                "Gautier Izacard",
                "Xavier Martinet",
                "Marie-Anne Lachaux",
                "Timoth\u00e9e Lacroix",
                "Baptiste Rozi\u00e8re",
                "Naman Goyal",
                "Eric Hambro",
                "Faisal Azhar"
            ],
            "title": "Llama: Open and efficient foundation language models",
            "venue": "arXiv preprint arXiv:2302.13971,",
            "year": 2023
        },
        {
            "authors": [
                "Guanzhi Wang",
                "Yuqi Xie",
                "Yunfan Jiang",
                "Ajay Mandlekar",
                "Chaowei Xiao",
                "Yuke Zhu",
                "Linxi Fan",
                "Anima Anandkumar"
            ],
            "title": "Voyager: An open-ended embodied agent with large language models",
            "venue": "arXiv preprint arXiv:2305.16291,",
            "year": 2023
        },
        {
            "authors": [
                "Jason Wei",
                "Maarten Bosma",
                "Vincent Y Zhao",
                "Kelvin Guu",
                "Adams Wei Yu",
                "Brian Lester",
                "Nan Du",
                "Andrew M Dai",
                "Quoc V Le"
            ],
            "title": "Finetuned language models are zero-shot learners",
            "venue": "arXiv preprint arXiv:2109.01652,",
            "year": 2021
        },
        {
            "authors": [
                "Jason Wei",
                "Xuezhi Wang",
                "Dale Schuurmans",
                "Maarten Bosma",
                "Fei Xia",
                "Ed Chi",
                "Quoc V Le",
                "Denny Zhou"
            ],
            "title": "Chain-of-thought prompting elicits reasoning in large language models",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Licheng Wen",
                "Pinlong Cai",
                "Daocheng Fu",
                "Song Mao",
                "Yikang Li"
            ],
            "title": "Bringing diversity to autonomous vehicles: An interpretable multi-vehicle decision-making and planning framework",
            "venue": "In Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems,",
            "year": 2023
        },
        {
            "authors": [
                "Zerong Xi",
                "Gita Sukthankar"
            ],
            "title": "A graph representation for autonomous driving",
            "venue": "In The 36th Conference on Neural Information Processing Systems Workshop,",
            "year": 2022
        },
        {
            "authors": [
                "Shunyu Yao",
                "Jeffrey Zhao",
                "Dian Yu",
                "Nan Du",
                "Izhak Shafran",
                "Karthik Narasimhan",
                "Yuan Cao"
            ],
            "title": "React: Synergizing reasoning and acting in language models",
            "venue": "arXiv preprint arXiv:2210.03629,",
            "year": 2022
        },
        {
            "authors": [
                "Wayne Xin Zhao",
                "Kun Zhou",
                "Junyi Li",
                "Tianyi Tang",
                "Xiaolei Wang",
                "Yupeng Hou",
                "Yingqian Min",
                "Beichen Zhang",
                "Junjie Zhang",
                "Zican Dong"
            ],
            "title": "A survey of large language models",
            "venue": "arXiv preprint arXiv:2303.18223,",
            "year": 2023
        },
        {
            "authors": [
                "Ou Zheng",
                "Mohamed Abdel-Aty",
                "Lishengsa Yue",
                "Amr Abdelraouf",
                "Zijin Wang",
                "Nada Mahmoud"
            ],
            "title": "Citysim: A drone-based vehicle trajectory dataset for safety-oriented research and digital twins",
            "venue": "Transportation Research Record,",
            "year": 2023
        },
        {
            "authors": [
                "Jingxing Zhou",
                "J\u00fcrgen Beyerer"
            ],
            "title": "Corner cases in data-driven automated driving: Definitions, properties and solutions",
            "venue": "IEEE Intelligent Vehicles Symposium (IV),",
            "year": 2023
        },
        {
            "authors": [
                "Deyao Zhu",
                "Jun Chen",
                "Xiaoqian Shen",
                "Xiang Li",
                "Mohamed Elhoseiny"
            ],
            "title": "Minigpt-4: Enhancing vision-language understanding with advanced large language models",
            "venue": "arXiv preprint arXiv:2304.10592,",
            "year": 2023
        },
        {
            "authors": [
                "Xizhou Zhu",
                "Yuntao Chen",
                "Hao Tian",
                "Chenxin Tao",
                "Weijie Su",
                "Chenyu Yang",
                "Gao Huang",
                "Bin Li",
                "Lewei Lu",
                "Xiaogang Wang"
            ],
            "title": "Ghost in the minecraft: Generally capable agents for open-world enviroments via large language models with text-based knowledge and memory",
            "venue": "arXiv preprint arXiv:2305.17144,",
            "year": 2023
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Autonomous driving has witnessed remarkable advancements in recent years, propelled by the data-driven manner (Bogdoll et al., 2021; Chen et al., 2023a;b). These data-driven algorithms strive to capture and model the underlying distributions of the accumulated data (Bolte et al., 2019; Zhou & Beyerer, 2023), but they always encounter challenges such as dataset bias, overfitting, and uninterpretability (Codevilla et al., 2019; Jin et al., 2023). Exploring methods to mitigate these challenges could lead to a deeper understanding of driving scenarios and more rational decision-making, potentially enhancing the performance of autonomous driving systems. Drawing inspiration from the profound question posed by LeCun (2022): \u201cWhy can an adolescent learn to drive a car in about 20 hours of practice and know how to act in many situations he/she has never encountered before?\u201d, we explore the core principles that underlie human driving skills and raise a pivotal distinction: human driving is fundamentally knowledge-driven, as opposed to data-driven. For example, when faced with a situation\nwhere the truck ahead is in danger of losing its cargo, humans can rely on common sense and explainable reasoning to ensure a safe distance is maintained between vehicles. Conversely, data-driven methods rely on a large quantity of similar data to fit this scenario which lacks environment comprehension and limits generalization ability (Heidecker et al., 2021; Chen et al., 2022; Wen et al., 2023). Furthermore, this task requires significant human labor and financial resources to collect and annotate driving data to handle varied real-world scenarios. This observation catalyzes a fundamental question: How can we instill such knowledgedriven capabilities of human drivers into an autonomous driving system? Recent advancements in large language models (LLMs) with emergent abilities offer an ideal embodiment of human knowledge, providing valuable insights toward addressing this question. LLMs possess exceptional human-level abilities and show strong abilities in robotics manipulation (Driess et al., 2023a; Huang et al., 2023a;b), multi-modal understanding (Gao et al., 2023) and lifelong skill learning (Wang et al., 2023; Zhu et al., 2023b). However, just as humans may need 20 hours of practice to learn to drive, LLMs cannot successfully perform the driving task without any experience or guidance. Through these analyses, we summarize the knowledge-driven paradigm for autonomous driving systems, as illustrated in Figure 1, including three components: (1) an environment with which an agent can interact; (2) a driver agent with recall, reasoning, and reflection abilities; (3) a memory component to persist experiences. In continuous evolution, the driver agent observes the environment, queries, and updates experiences from memory and performs decision-making. Following the paradigm above, we design a novel framework named DiLu as illustrated in Figure 2. Specifically, the driver agent utilizes the Reasoning Module to query experiences from the Memory Module and leverage the common-sense knowledge of the LLM to generate decisions based on current scenarios. It then employs the Reflection Module to identify safe and unsafe decisions produced by the Reasoning Module, subsequently refining them into correct decisions using the knowledge embedded in the LLM. These safe or revised decisions are then updated into the Memory Module. Extensive experiments demonstrate that the proposed framework DiLu can leverage LLM to make proper decisions for the autonomous driving system. We design a closed-loop driving environment and prove that DiLu can perform better and better with the experience accumulated in the memory module. Remarkably, with only 40 memory items, DiLu achieves comparable performance to the reinforcement learning (RL) based methods that have extensively trained over 600,000 episodes, but with a much stronger generalization ability to diverse scenarios. Moreover, DiLu\u2019s ability to directly acquire experiences from real-world datasets highlights its potential to be deployed on practical autonomous driving systems. The contributions of our work are summarized as follows:\n\u2022 To the best of our knowledge, we are the first to leverage knowledge-driven capability in decision-making for autonomous vehicles from the perspective of how humans drive. We summarize the knowledge-driven paradigm that involves an interactive environment, a driver agent, as well as a memory component.\n\u2022 We propose a novel framework called DiLu which implements the above paradigm to address the closed-loop driving tasks. The framework incorporates a Memory Module to record the experiences, and leverages LLM to facilitate reasoning and reflection processes.\n\u2022 Extensive experimental results highlight DiLu\u2019s capability to continuously accumulate experience by interacting with the environment. Moreover, DiLu exhibits stronger generalization ability than RL-based methods and demonstrates the potential to be applied in practical autonomous driving systems."
        },
        {
            "heading": "2 Related works",
            "text": ""
        },
        {
            "heading": "2.1 Advancements in Large language models",
            "text": "Large language models (LLMs) are the category of Transformer-based language models that are characterized by having an enormous number of parameters, typically numbering in the hundreds of billions or even more. These models are trained on massive text datasets, enabling them to understand natural language and perform a wide range of complex tasks, primarily through text generation and comprehension (Zhao et al., 2023). Some well-known examples of LLMs include GPT-3 (Brown et al., 2020), PaLM (Chowdhery et al., 2022), and LLaMA (Touvron et al., 2023), GPT-4 (Achiam et al., 2023). The emergent abilities of LLMs are one of the most significant characteristics that distinguish them from smaller language models. Specifically, in-context learning (ICL) (Brown et al., 2020), instruction following (Ouyang et al., 2022; Wei et al., 2021) and reasoning with chain-of-thought (CoT) (Wei et al., 2022) are three typical emergent abilities for LLMs. OpenAI\u2019s pursuit of LLMs has led to the achievement of two remarkable milestones: ChatGPT (OpenAI, 2023) and GPT4 (Achiam et al., 2023). These two milestones signify significant advancements in LLMs\u2019 capabilities, particularly in natural language understanding and generation. Notably, recent developments in large LLMs have showcased human-like intelligence and hold the potential to propel us closer to the realm of Artificial General Intelligence (AGI) (Zhao et al., 2023; Zhu et al., 2023a)."
        },
        {
            "heading": "2.2 Advanced tasks based on Large language model",
            "text": "Owing to the superior capability of common-sense knowledge embedded in LLMs, they are widely adopted for diverse tasks (Sammani et al., 2022; Bubeck et al., 2023; Schick et al., 2023). Furthermore, there has emerged a flourishing research area that leverages LLMs to create autonomous agents endowed with human-like capabilities (Chowdhery et al., 2022; Yao et al., 2022; Park et al., 2023; Fu et al., 2024; Zhu et al., 2023b; Li et al., 2023). In particular, LLMs are shown to possess a wealth of actionable knowledge that can be extracted for robot manipulation in the form of reasoning and planning. For instance, (Driess et al., 2023b) proposed embodied language models that directly integrate real-world continuous sensor data into language models, establishing a direct link between words and perceptual information. Voyager (Wang et al., 2023) introduces lifelong learning through the incorporation of prompting mechanisms, a skill library, and self-verification. These three modules are all grounded by LLM and empower the agent to learn more sophisticated behaviors. Similarly, Voxposer(Huang et al., 2023b) leveraged LLMs to generate robot trajectories for a wide range of manipulation tasks, guided by open-ended instructions and objects. Simultaneously, motivated by insights from AGI and the principles of embodied AI (Pfeifer & Iida, 2004; Duan et al., 2022), the field of autonomous driving is also undergoing a profound transformation. An open-loop driving commentator LINGO-1 is proposed by Wayve (2023) which combines vision, language and action to enhance how to interpret and train the driving models. LLMs have demonstrated remarkable human-level capabilities across various domains, but we observe that they lack the inherent ability to engage with and comprehend the complex driving environment as humans. In contrast, autonomous vehicles depend on systems that can actively interact with and understand the driving environment. To bridge this gap, we propose a novel knowledge-driven autonomous driving paradigm and DiLu framework that enables LLMs to comprehend driving environments and drive by incorporating human knowledge."
        },
        {
            "heading": "3 Methodology",
            "text": ""
        },
        {
            "heading": "3.1 Overview",
            "text": "Based on the knowledge-driven paradigm for autonomous driving systems introduced previously, we propose a practical framework called DiLu, as illustrated in Figure 2. DiLu consists of four core modules: Environment, Reasoning, Reflection, and Memory. In particular, the Reasoning module begins by observing the environment and obtaining descriptions of the current scenario. Concurrently, a prompt generator is employed to combine this scenario description with the few-shot experiences of similar situations, which retrieved from the Memory module. These prompts are then fed into an out-of-the-box Large Language Model (LLM), and the decision decoder make an action by decoding LLM\u2019s response. This process is iterated within the Reasoning module, resulting in time-series decision sequences. Subsequently, we employ the Reflection module to assess past decision sequences, categorizing them as either safe or unsafe. The unsafe decisions are revised and these refined decisions are finally updated back into the Memory module. Detailed implementations of the Memory, Reasoning, and Reflection modules will be elaborated in the following sections."
        },
        {
            "heading": "3.2 Memory module",
            "text": "Without few-shot experiences, the out-of-the-box LLMs fail to perform precise reasoning when tackling the complex closed-loop driving tasks. Therefore, we employ a Memory module to store the experiences from past driving scenarios, which include the decision prompts, reasoning processes, and other valuable information. The memory stored in the memory module consists of two parts: scene descriptions and corresponding reasoning processes. The scene description provides a detailed account of the situation, serving as the key to the memory module for retrieving similar memories. The reasoning process, on the other hand, records the appropriate method for handling the situation. This is the value of the memory, guiding the agent towards the correct driving logic. The memory module is constructed in three stages: initialization, memory recall, and memory storage. Initialization: The Initialization of memory module is akin to a human attending driving school before hitting the road. We select a few scenarios and manually outline the correct reasoning and decision-making processes for these situations to form the initial memory. These memories instruct the agent on the correct decision-making process for driving.\nMemory recall: At each decision frame, the agent receives a textual description of the driving scenario. Before making a decision, the current driving scenario is embedded into a vector, which serves as the memory key. This key is then clustered and searched to find the closest scenarios (Johnson et al., 2019) in the memory module and their corresponding reasoning processes, or memories. These recalled memories are provided to the agent in a few-shot format to assist in making accurate reasoning and decisions for the current scenario. Memory storage: As the agent makes correct reasoning and decisions, or reflects on the correct reasoning process, it gains driving experience. We embed the scene description into a key, pair it with the reasoning process to form and store memory in the memory module."
        },
        {
            "heading": "3.3 Reasoning Module",
            "text": "In the Reasoning module, we utilize the experiences derived from the Memory module and the common-sense knowledge of the LLM to perform decision-making for the current traffic scenario. Specifically, the reasoning procedure is illustrated in Figure 3, including the following procedures: (1) encode the scenario by a descriptor; (2) recall several experience from the Memory module; (3) generate the prompt; (4) feed the prompt into the LLM; (5) decode the action from the LLM\u2019s response. The detailed prompt design can be found in Appendix A.2. Encode the scenario by a descriptor: To facilitate DiLu\u2019s understanding of the current traffic conditions, the scenario descriptor transcribes the present scenario data into descriptive text. The scenario descriptor follows a standard sentence structure and utilizes natural language to offer a comprehensive depiction of the ongoing driving scenario. This description contains static road details as well as dynamic information regarding the ego vehicle and surrounding vehicles within the scenario. These generated descriptions are then used as input for the prompt generator and as keys to acquire relevant few-shot experiences from the Memory module. Recall several experience from the Memory module: During the reasoning process, the description of the current driving scenario is also embedded into a vector, as illustrated in Figure 3. This vector is then used to initiate a similarity query within the Memory module, searching for the top k similar situations. The resulting paired scene descriptions and reasoning procedures assemble as few-shot experiences, which are then integrated into the prompt generator. Generate the prompt: As depicted in the blue dashed box in Figure 3, the prompts for each frame consist of three key components: system prompts, textual descriptions from scenario descriptor, and the few-shot experience. Within the system prompts, we offer a concise overview of the closed-loop driving task, which includes an introduction to the content and format of task inputs and outputs, along with constraints governing the reasoning process. In each decision frame, we construct tailored prompts based on the current driving"
        },
        {
            "heading": "Decision Sequences Memory Module",
            "text": "scenario. These prompts are subsequently employed by LLM to engage in reasoning and determine the appropriate action for the current frame. Feed the prompt into the LLM: Since the closed-loop driving task requires a complex reasoning process to make proper decisions, we employ the Chain-of-Thought (CoT) prompting techniques introduced by Wei et al. (2022). These techniques require LLM to generate a sequence of sentences that describe the step-by-step reasoning logic, ultimately leading to the final decision. This approach is adopted due to the inherent complexity and variability of driving scenarios, which may lead to hallucinations if the language model directly produces decision results. Also, the generated reasoning process facilitates further refinement and modification of incorrect decisions by the Reflection module in Section 3.4. Decode the action from the LLM\u2019s response: After feeding the prompt into the LLM, we decode the final decision in action decoder. The action decoder translates LLM\u2019s decision outcomes into actions for the ego vehicle and provides feedback to the environment. By repeating the procedures above, we establish a closed-loop decision-making system."
        },
        {
            "heading": "3.4 Reflection Module",
            "text": "In the Reasoning module, we use the LLM to undertake closed-loop driving tasks with the support of the proposed Memory module. As a next step we hope to accumulate valuable experiences and enrich the Memory module upon the conclusion of a driving session. To achieve this goal, we propose the Reflection module in DiLu, which continuously learns from past driving experiences. DiLu can progressively improve its performance through the Reflection module, similar to the progression of a novice becoming an experienced driver. The Reflection module is illustrated in Figure 4. During the closed-loop driving task, we record the prompts used as input based on the driving scenario and the corresponding decisions generated by the LLM for each decision frame. Once a driving session concludes, we obtain a decision sequence, e.g., 5 decision frames from 0 to 4 in Figure 4. When the session ends without any collisions or hazardous incidents, indicating a successful session, DiLu proceeds to sample several key decision frames from the sequence. These frames then directly become part of the historical driving experience and enrich the Memory module. On the contrary, if the current session is terminated due to hazardous situations such as collisions with other vehicles, this indicates that the driver agent has made inaccurate decisions. It is crucial for the system to rectify the unsafe decision made by the Reasoning module. Thanks to the interpretable chain-of-thoughts responses, we can easily find the causes of dangerous situations. Certainly, we can ask a human expert to complete such an error correction process. However, our goal is to make the autonomous driving system learn\nfrom mistakes on its own. We discover that LLM can effectively act as a mistake rectifier. Our approach is to use the driving scenarios in which incorrect decisions occurred, together with the original reasoning output, as prompts for LLM. We instruct LLM to pinpoint the reasons behind the incorrect decision and provide the correct one. We also ask LLM to propose strategies in order to avoid similar errors in the future. Finally, the correct reasoning process and the revised decision learned from the mistakes are retained in Memory module."
        },
        {
            "heading": "4 Experiments",
            "text": "In our experimental setup, we utilize the well-established Highway-env as our simulation environment, which is a widely used platform in the fields of autonomous driving and tactical decision-making (Leurent, 2018). This environment provides several driving models and offers a realistic multi-vehicle interaction environment. In addition, the density of vehicles and the number of lanes in the environment can be freely adjusted. The detailed setup of DiLu framework and Highway-env are described in Appendix A.1. The demonstration video of DiLu can be found in the project page: https://pjlab-adg.github.io/DiLu/."
        },
        {
            "heading": "4.1 The validation of the DiLu framework",
            "text": "In this section, we primarily focus on validating the effectiveness of the DiLu framework, in particular the reasoning and reflection process with or without the Memory module. The DiLu framework without the Memory module is referred to as the 0-shot baseline, and we conduct comparative experiments with 1-shot, 3-shots, and 5-shots experiences to demonstrate the necessity of experience accumulation. The initial Memory module contains 5 human-crafted experiences. These experiences are then used in different few-shot settings for reasoning and reflection, allowing for continuous accumulation and updating of experiences. We conduct comparative experiments when the Memory module has 5, 20, and 40 experiences, respectively. Each setting is repeated 10 times with different seeds. The results are shown as a box plot in Figure 5 (a). Success Steps (SS) is the number of consecutive frames without collision, an SS of 30 means that the ego car has completed the driving task. We found that as the number of experiences in the Memory module increases, the performance of the DiLu framework improves in all few-shot settings. Notably, the 5-shots setting successfully completes the closed-loop driving task in the majority of cases in scenarios with 20 experiences. Furthermore, when the Memory module is equipped with 40 experiences, all trials achieve a median SS of over 25. In comparison, when the framework lacks the Memory module and runs a 0-shot experiment, no tasks are successfully conducted and the median SS is below 5. This indicates that LLM cannot directly perform the closed-loop driving tasks without any adaptation. In addition, we observed that for a fixed number of memory items, the performance of the framework improved as the number of few-shot experiences increased. Specifically, with 40 memory items, the 5-shot framework successfully passed almost all tests, while the median SS for the 3-shots and 1-shot frameworks were 27 and 25, respectively. This can be attributed to the fact that a higher number of few-shots includes a diverse range of experiences in similar driving scenarios. When fed into the LLM as prompts, these allow the LLM to draw on a wider range of information and decision strategies, thereby facilitating more rational decisions. Several detailed case studies can be found in Appendix A.3."
        },
        {
            "heading": "4.2 Comparison with Reinforcement Learning Method",
            "text": "We conducted comparative experiments between DiLu and the SOTA reinforcement learning (RL) method in Highway-env, GRAD (Graph Representation for Autonomous Driving) (Xi & Sukthankar, 2022). GRAD is an RL-based approach specifically designed for autonomous driving scenarios, it generates a global scene representation that includes estimated future trajectories of other vehicles. We trained GRAD under the setting of lane-4-density-2, which means the 4-lane motorway scenarios with vehicle density of 2.0. The training details are given in Appendix A.4 and A.5. As a comparison, DiLu used 40 experiences purely obtained from lane-4-density-2 setting. We defined the success rate (SR) as driving\nwithout any collision for 30 decision frames and then conducted experiments under three environment settings: lane-4-density-2, lane-5-density-2.5, and lane-5-density-3. Each setup includes 10 test scenarios with different seeds. The results are illustrated in Figure 6 (a). Firstly, in the lane-4-density-2 setting, DiLu uses only 40 experience in the Memory module to achieve 70% SR while the GRAD converges to 69% SR after 600,000 training episodes. We found that many failures from GRAD are due to the inability to brake in time, resulting in collisions with the vehicle ahead. This is because reinforcement learning methods tend to fit the environment and fail to take human-like driving knowledge into consideration. Secondly, we migrate DiLu and GRAD optimized on lane-4-density-2 to lane-5-density-2.5 and lane-5-density-3 settings. We observe that both methods suffer varying degrees of performance degradation in the migrated environments, as the number of lanes changes and traffic density increases. However, in the most complex lane-5-density-3 environment, DiLu still maintains a 35% SR without extra optimization, while the GRAD has an 85% performance drop. DiLu accumulated experience in one environment can be generalized into another one, while RL method tends to overfit the training environment."
        },
        {
            "heading": "4.3 Experiments on generalization and transformation",
            "text": "Data-driven approaches often overfit the training environment, while human knowledge should be domain-agnostic and can be generalized to different environments. We perform several experiments to evaluate DiLu\u2019s generalization and transformation abilities. Generalization ability in different environments. We verify whether the experiences obtained in DiLu\u2019s Memory module have generalization capabilities. More formally, we used 20 experiences obtained from the lane-4-density-2 environment, and conducted experiments in the lane-5-density-3 setting, testing the closed-loop performance of 3- shot and 5-shot respectively. The experimental results are shown in Figure 5 (b). As we can see, the 3-shot version of DiLu achieves 13 median SS on the setting of lane-4-density-2 while decreasing to 5 media SS under the lane-5-density-3 setting. But in the 5-shot version, we achieve 30\u219223 median SS degradation in the same situation. This suggests that the ability to generalize is better with more few-shot experience fed into the LLM. Transformation ability using real-world dataset. Since DiLu\u2019s Memory module stores experiences in the form of natural language text, it contains environment-agnostic knowledge that can be readily transferred to different environments. To illustrate this capability, we created two Memory modules, each containing 20 experiences extracted from two distinct sources: (1) Highway-env and (2) CitySim, a dataset comprising real-world vehicle trajectory data (Zheng et al., 2023). We subsequently evaluated these modules on the lane-4-density-2 and lane-5-density-3 scenarios within the Highway-env environment. The experimental results are presented in Figure 6 (b). In comparison to a system without any prior experiences (depicted by the gray dash-dot line), CitySim-contributed knowledge\nenhanced DiLu\u2019s performance. Also, when transferring experiences to a more congested environment (from lane-4-density-2 to lane-5-density-3), the memory derived from real-world data exhibited superior robustness compared to the memory accumulated solely within the simulation domain."
        },
        {
            "heading": "4.4 Effectiveness of two memory types in the Reflection module",
            "text": "In this section, we explore the significance of incorporating successful experiences and revised unsafe experiences in the Reflection module through an ablation study. We adopt the Memory module containing 20 initial experiences and observe the performance change during the new memory accumulation. The results are shown in Table 1. The baseline indicates the system using the Memory module with 20\ninitial experiences. Then we add 12 success memories and 6 correction memories into the baseline successively. In the experiments, the median success step of the baseline is only 10. However, after updating with new experiences, all two methods achieve a median success step of over 20, and the method with both types of experiences shows higher success steps on all statistical measures. Therefore, it is both reasonable and effective to add two different types of experiences during reflection."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this paper, we explore the realm of instilling human-level knowledge into autonomous driving systems. We summarize a knowledge-driven paradigm and propose the DiLu framework, which includes a memory module for recording past driving experiences and an agent equipped with Reasoning and Reflection modules. Extensive experimental results showcase DiLu\u2019s capability to continuously accumulate experience and exhibit its strong generalization ability compared to the SOTA RL-based method. Moreover, DiLu\u2019s ability to directly acquire experiences from real-world datasets highlights its potential to be deployed on practical autonomous driving systems. The DiLu framework, while effective, is not without limitations. Presently, it experiences a decision-making latency of 5-10 seconds, encompassing LLM inference and API response times. Additionally, it does not completely eradicate hallucinations generated by LLMs. Future improvements could capitalize on recent advances in LLM compression and optimization, aiming to enhance both efficiency and effectiveness."
        },
        {
            "heading": "Acknowledgments",
            "text": "The research was supported by Shanghai Artificial Intelligence Laboratory, the National Key R&D Program of China (Grant No. 2022ZD0160104) and the Science and Technology Commission of Shanghai Municipality (Grant Nos. 22DZ1100102 and 23YF1462900)."
        },
        {
            "heading": "A Appendix",
            "text": ""
        },
        {
            "heading": "A.1 Detailed setup of the experiment",
            "text": "Within our DiLu framework, the large language model we adopt is the GPT family developed by OpenAI. GPT-3.5 (OpenAI, 2023) is used in the Reasoning module of the framework, which is responsible for making reasonable decisions for the ego vehicle. GPT-4 is used in the Reflection module since it has demonstrated significantly improved self-repair and fact-checking capabilities compared to GPT-3.5 (Bubeck et al., 2023; Olausson et al., 2023). To serve as the Memory module in the DiLu framework, we adopt Chroma1, an open-source embedding vector database. The scenario descriptions are transformed into vectors using the text-embedding-ada-002 model of OpenAI. In terms of the setup for highway-env, we directly obtain vehicle information from the underlying simulation and input it into the scenario descriptor. This information only includes each vehicle\u2019s position, speed, and acceleration data in the current frame, without any decision intent or potential risk information, as shown in Figure 7. Meta-actions are used as the decision output in our experiments, which include five discrete actions to control the ego vehicle: acceleration, maintaining speed, deceleration, and lane changes to the left and right. For each closed-loop driving task, we define a successful completion time of 30 seconds, with a decision-making frequency of 1Hz. This means that if the ego vehicle can navigate through traffic at a reasonable speed and without collisions for 30 seconds, we consider the task to be successfully completed. Unless otherwise stated, our experimental environment is a four-lane motorway with a vehicle density of 2.0, representing scenarios with relatively high traffic density and complexity. All other settings follow the simulator\u2019s default configurations."
        },
        {
            "heading": "A.2 Prompts example",
            "text": "In this section, we detail the specific prompts design in the reasoning and reflection modules. Reasoning prompts As mentioned in the article, the prompts for the reasoning module primarily consist of three parts: system prompts, scenario description, and few-shot experience. Specifically, as shown in Figure 7, the system prompts section is entirely fixed and mainly includes an introduction to the closed-loop driving task, instructions for input and output, and formatting requirements for LLM responses. Most of the scenario description is fixed, but three parts are directly related to the scenario and are dynamically generated based on the current decision frame. The driving scenario description contains information about the positions, speeds, and accelerations of the ego vehicle and surrounding key vehicles. It\u2019s important to note that we only embed the text of the driving scenario description into vectors and use it as a query input to the memory module. Available action includes all meta-actions. The driving intention can be input by humans to modify the vehicle\u2019s behavior, with the default intention being: \u201cYour driving intention is to drive safely and avoid collisions.\u201d As for the few-shot experience, it is entirely obtained from the memory module. Each experience consists of a human-LLM dialogue pair, where the human question includes the scenario description at that decision frame, and the LLM response represents the correct (or correct after revised) reasoning and decision made by the driver agent. The extracted experiences are directly utilized with a few-shot prompting technique to input into the large language model, enabling in-context learning. Figure 8 demonstrates the results of a 3-shot experience query, which includes two \u201dkeep speed\u201d decisions and one \u201ddecelerate\u201d decision. It\u2019s important to note that consistency in decisions is not a requirement within the few-shot experience.\n1https://github.com/chroma-core/chroma\nReflection prompts Figure 9 presents the template for the reflection module\u2019s prompts, primarily comprising two sections: system prompts and reflection prompts. The system prompts section is entirely fixed and mainly consists of an introduction to the reflection task, along with instructions and formatting requirements for LLM responses. On the other hand, the reflection prompts section includes the scenario description of the erroneous decision and the faulty reasoning process made by the LLM. We require the reflection module to produce three components: an error analysis, corrected reasoning and decision-making, and suggestions on how to avoid making the same mistake in the future."
        },
        {
            "heading": "A.3 Case study",
            "text": "In this section, let\u2019s demonstrate several case studies. First, we present the results of the reasoning module for three cases, as shown in Figure 10. In Case 1, the green ego car is closely following the car 368 in front, and their speeds are similar. Initially, the driver agent explores whether it can accelerate in the current lane. The agent determines that, since the ego car\u2019s speed is similar to the car in front, there\u2019s no need to accelerate. Subsequently, the driver agent explores the possibility of maintaining the current speed. Through reasoning, the agent concludes that although the distance between the vehicles is slightly shorter than the ideal following distance, it\u2019s safe to maintain the speed because the ego car\u2019s speed is slightly lower than that of the car in front. Lastly, the agent verifies the feasibility of changing lanes to the right and calculates that the ego car\u2019s speed is lower than the car in the right lane by 5.88 m/s, with a safe following distance. Therefore, changing lanes to the right is also safe. In the end, the agent decides to change lanes to the right. In Case 2, the scenario is relatively simple. The agent observes a long distance with the car in front and that the ego car\u2019s speed is lower than that car. Consequently, it decides to accelerate. In this case, the agent does not perform further calculations regarding maintaining speed or changing lanes, aligning with the typical thought process and reasoning of human drivers. In Case 3, we changed the driving intention in the prompts from the default to \u201cI need to change to the rightmost lane.\u201d The driver agent recognizes this intent. Although it determines that it can maintain speed in the current lane, it continues to evaluate whether changing lanes to the right in the current lane is feasible. Ultimately, considering the intention, the agent chooses to change lanes to the right over maintaining speed."
        },
        {
            "heading": "Reasoning and Decision",
            "text": ""
        },
        {
            "heading": "Reasoning and Decision",
            "text": ""
        },
        {
            "heading": "Reasoning and Decision",
            "text": ""
        },
        {
            "heading": "Revised Decision",
            "text": ""
        },
        {
            "heading": "Original Decision",
            "text": "Next, in Figure 11, we present a result of the reflection module. In this case, the ego car is traveling in the second right lane and made the incorrect decision to change lanes to the right, resulting in a collision with car 408. Consequently, the reflection module intervenes to correct the mistake. First, it conducts an analysis of the cause of the collision. Upon reviewing the original reasoning process, GPT-4 astutely identifies the source of the error. It realizes that the initial decision did not take into account the relative distance between the vehicles in the right lane. In fact, car 408 was merely \u201cslightly ahead\u201d of the ego car, contrary to what the initial decision process described as an \u201cappropriate\u201d distance. Subsequently, in the revised decision process, the driver agent supplements and correctly calculates the relative position of the ego car and the car in the right lane. It also includes the calculation of \u201ctime to collision\u201d (which was completely absent in the original decision). Based on this calculation, it determines that \u201ctime to collision is too short to safely change lanes.\u201d As a result, it chooses to decelerate, avoiding the collision. Finally, the reflection module summarizes the lesson learned from this error, emphasizing the importance of ensuring that there is enough space and time to safely complete a lane change without causing a collision: \u201cIt\u2019s important to ensure that there\u2019s enough space and time to safely complete the lane change without causing a collision.\u201d"
        },
        {
            "heading": "A.4 Training settings of GRAD",
            "text": "Here we introduce the training settings of the RL method GRAD for the comparing with the DiLu. The rewards for each episode of GRAD are evaluated during the training process as shown in Figure 12. During the training, We set the Observations consisting of the kinematic status of the agent and the surrounding vehicles, specifically their coordinates, velocity, and heading. The maximum number of surrounding vehicles that can be observed is 32, and their speeds range from 15 to 25 units. As for the Action, it is discrete and comprises the following options: OneLaneLeft, Idle, OneLaneRight, SpeedLevelUp, and SpeedLevelDown. The available speed levels are 10, 15, 20, 25, and 32 units. The reward system includes two components, one is that a reward of 0.2 is granted for each time step survived by the agent, and the other one is that the reward is linearly mapped from the driving speed (10, 32), a reward value between 0 and 0.8. Moreover, Each model is trained for 600,000 action steps and is subsequently evaluated over 24 episodes using deterministic policies."
        },
        {
            "heading": "A.5 Different density level",
            "text": "In order to give the reader an intuitive understanding of the different vehicle densities under Highway-env, we show in Figure 13 screenshots of a number of scenarios for the experimental part of this paper for three different traffic densities. It can be seen that with increasing vehicle density, there are more vehicles in the scenario, and the vehicle spacing and vehicle speed are reduced."
        }
    ],
    "title": "DiLu : A Knowledge-Driven Approach to Autonomous Driving with Large Language Models",
    "year": 2024
}