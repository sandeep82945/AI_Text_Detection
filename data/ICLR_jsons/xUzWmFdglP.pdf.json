{
    "abstractText": "Privacy amplification exploits randomness in data selection to provide tighter differential privacy (DP) guarantees. This analysis is key to DP-SGD\u2019s success in machine learning (ML), but, is not readily applicable to the newer state-of-the-art (SOTA) algorithms. This is because these algorithms, known as DP-FTRL, use the matrix mechanism to add correlated noise instead of independent noise as in DP-SGD. In this paper, we propose \u201cMMCC\u201d, the first algorithm to analyze privacy amplification via sampling for any generic matrix mechanism. MMCC is nearly tight in that it approaches a lower bound as \u03b5\u2192 0. To analyze correlated outputs in MMCC, we prove that they can be analyzed as if they were independent, by conditioning them on prior outputs. Our \u201cconditional composition theorem\u201d has broad utility: we use it to show that the noise added to binary-tree-DP-FTRL can asymptotically match the noise added to DP-SGD with amplification. Our algorithm also has practical empirical utility. We show that amplification leads to significant improvement in the privacy/utility trade-offs for DP-FTRL style algorithms for standard benchmark tasks.",
    "authors": [
        {
            "affiliations": [],
            "name": "Christopher A. Choquette-Choo"
        },
        {
            "affiliations": [],
            "name": "Arun Ganesh"
        },
        {
            "affiliations": [],
            "name": "Thomas Steinke"
        },
        {
            "affiliations": [],
            "name": "Abhradeep Thakurta"
        }
    ],
    "id": "SP:60f043d9c66d6c70f66f371c3a37b15928c89c21",
    "references": [
        {
            "authors": [
                "Borja Balle",
                "Peter Kairouz",
                "H Brendan McMahan",
                "Om Thakkar",
                "Abhradeep Thakurta"
            ],
            "title": "Privacy amplification via random check-ins",
            "venue": "In NeurIPS,",
            "year": 2020
        },
        {
            "authors": [
                "Raef Bassily",
                "Adam Smith",
                "Abhradeep Thakurta"
            ],
            "title": "Private empirical risk minimization: Efficient algorithms and tight error bounds",
            "venue": "In Proc. of the 2014 IEEE 55th Annual Symp. on Foundations of Computer Science (FOCS),",
            "year": 2014
        },
        {
            "authors": [
                "T.-H. Hubert Chan",
                "Elaine Shi",
                "Dawn Song"
            ],
            "title": "Private and continual release of statistics",
            "venue": "ACM Trans. on Information Systems Security,",
            "year": 2011
        },
        {
            "authors": [
                "Christopher A Choquette-Choo",
                "Arun Ganesh",
                "Ryan McKenna",
                "H Brendan McMahan",
                "Keith Rush",
                "Abhradeep Guha Thakurta",
                "Zheng Xu"
            ],
            "title": "amplified) banded matrix factorization: A unified approach to private training",
            "venue": "arXiv preprint arXiv:2306.08153,",
            "year": 2023
        },
        {
            "authors": [
                "Christopher A. Choquette-Choo",
                "Hugh Brendan McMahan",
                "J Keith Rush",
                "Abhradeep Guha Thakurta"
            ],
            "title": "Multi-epoch matrix factorization mechanisms for private machine learning",
            "venue": "Proceedings of the 40th International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Sergey Denisov",
                "H. Brendan McMahan",
                "John Rush",
                "Adam Smith",
                "Abhradeep Guha Thakurta"
            ],
            "title": "Improved differential privacy for sgd via optimal private linear operators on adaptive streams",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Cynthia Dwork",
                "Aaron Roth"
            ],
            "title": "The algorithmic foundations of differential privacy",
            "venue": "Foundations and Trends in Theoretical Computer Science,",
            "year": 2014
        },
        {
            "authors": [
                "Cynthia Dwork",
                "Moni Naor",
                "Toniann Pitassi",
                "Guy N Rothblum"
            ],
            "title": "Differential privacy under continual observation",
            "venue": "In Proceedings of the forty-second ACM symposium on Theory of computing,",
            "year": 2010
        },
        {
            "authors": [
                "\u00dalfar Erlingsson",
                "Vitaly Feldman",
                "Ilya Mironov",
                "Ananth Raghunathan",
                "Kunal Talwar",
                "Abhradeep Thakurta"
            ],
            "title": "Amplification by shuffling: From local to central differential privacy via anonymity",
            "venue": "In ACMSIAM Symposium on Discrete Algorithms (SODA),",
            "year": 2019
        },
        {
            "authors": [
                "Vitaly Feldman",
                "Ilya Mironov",
                "Kunal Talwar",
                "Abhradeep Thakurta"
            ],
            "title": "Privacy amplification by iteration",
            "venue": "IEEE 59th Annual Symposium on Foundations of Computer Science (FOCS),",
            "year": 2018
        },
        {
            "authors": [
                "Vitaly Feldman",
                "Audra McMillan",
                "Kunal Talwar"
            ],
            "title": "Hiding among the clones: A simple and nearly optimal analysis of privacy amplification by shuffling",
            "venue": "IEEE 62nd Annual Symposium on Foundations of Computer Science (FOCS),",
            "year": 2021
        },
        {
            "authors": [
                "Hendrik Fichtenberger",
                "Monika Henzinger",
                "Jalaj Upadhyay"
            ],
            "title": "Constant matters: Fine-grained error bound on differentially private continual observation",
            "venue": "International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Arun Ganesh"
            ],
            "title": "Tight group-level dp guarantees for dp-sgd with sampling via mixture of gaussians mechanisms, 2024",
            "year": 2024
        },
        {
            "authors": [
                "Monika Henzinger",
                "Jalaj Upadhyay",
                "Sarvagya Upadhyay"
            ],
            "title": "A unifying framework for differentially private sums under continual observation, 2023",
            "year": 2023
        },
        {
            "authors": [
                "James Honaker"
            ],
            "title": "Efficient use of differentially private binary trees",
            "year": 2015
        },
        {
            "authors": [
                "Peter Kairouz",
                "Brendan McMahan",
                "Shuang Song",
                "Om Thakkar",
                "Abhradeep Thakurta",
                "Zheng Xu"
            ],
            "title": "Practical and private (deep) learning without sampling or shuffling",
            "venue": "In ICML,",
            "year": 2021
        },
        {
            "authors": [
                "Shiva Prasad Kasiviswanathan",
                "Adam Smith"
            ],
            "title": "On the \u2019semantics\u2019 of differential privacy: A bayesian formulation",
            "venue": "J. Priv. Confidentiality,",
            "year": 2014
        },
        {
            "authors": [
                "Shiva Prasad Kasiviswanathan",
                "Homin K. Lee",
                "Kobbi Nissim",
                "Sofya Raskhodnikova",
                "Adam D. Smith"
            ],
            "title": "What can we learn privately",
            "venue": "In 49th Annual IEEE Symp. on Foundations of Computer Science (FOCS),",
            "year": 2008
        },
        {
            "authors": [
                "Antti Koskela",
                "Joonas J\u00e4lk\u00f6",
                "Antti Honkela"
            ],
            "title": "Computing tight differential privacy guarantees using fft",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2020
        },
        {
            "authors": [
                "Ryan McKenna",
                "Gerome Miklau",
                "Michael Hay",
                "Ashwin Machanavajjhala"
            ],
            "title": "Hdmm: Optimizing error of high-dimensional statistical queries under differential privacy",
            "venue": "arXiv preprint arXiv:2106.12118,",
            "year": 2021
        },
        {
            "authors": [
                "Natalia Ponomareva",
                "Hussein Hazimeh",
                "Alex Kurakin",
                "Zheng Xu",
                "Carson Denison",
                "H. Brendan McMahan",
                "Sergei Vassilvitskii",
                "Steve Chien",
                "Abhradeep Guha Thakurta"
            ],
            "title": "How to DP-fy ML: A practical guide to machine learning with differential privacy",
            "venue": "Journal of Artificial Intelligence Research,",
            "year": 2023
        },
        {
            "authors": [
                "Adam Smith",
                "Abhradeep Thakurta"
            ],
            "title": "nearly) optimal algorithms for private online learning in fullinformation and bandit settings",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2013
        },
        {
            "authors": [
                "Shuang Song",
                "Kamalika Chaudhuri",
                "Anand D Sarwate"
            ],
            "title": "Stochastic gradient descent with differentially private updates",
            "venue": "IEEE Global Conference on Signal and Information Processing,",
            "year": 2013
        },
        {
            "authors": [
                "Thomas Steinke"
            ],
            "title": "Composition of differential privacy & privacy amplification by subsampling",
            "venue": "arXiv preprint arXiv:2210.00597,",
            "year": 2022
        },
        {
            "authors": [
                "Salil Vadhan"
            ],
            "title": "The complexity of differential privacy",
            "venue": "In Tutorials on the Foundations of Cryptography,",
            "year": 2017
        },
        {
            "authors": [
                "Yuqing Zhu",
                "Jinshuo Dong",
                "Yu-Xiang Wang"
            ],
            "title": "Optimal accounting of differential privacy via characteristic function",
            "venue": "Proceedings of The 25th International Conference on Artificial Intelligence and Statistics,",
            "year": 2022
        },
        {
            "authors": [
                "k. In (Zhu"
            ],
            "title": "2022), only the first part of Lem. C.1 is stated. However, the proof allows arbitrary measures, i.e., measures that don\u2019t integrate to 1, which implies the second part of Lem",
            "year": 2022
        },
        {
            "authors": [
                "Fichtenberger et al",
                "Henzinger"
            ],
            "title": "2023) showed that a post-processing of the matrix mechanism",
            "year": 2023
        }
    ],
    "sections": [
        {
            "text": "Privacy amplification exploits randomness in data selection to provide tighter differential privacy (DP) guarantees. This analysis is key to DP-SGD\u2019s success in machine learning (ML), but, is not readily applicable to the newer state-of-the-art (SOTA) algorithms. This is because these algorithms, known as DP-FTRL, use the matrix mechanism to add correlated noise instead of independent noise as in DP-SGD.\nIn this paper, we propose \u201cMMCC\u201d, the first algorithm to analyze privacy amplification via sampling for any generic matrix mechanism. MMCC is nearly tight in that it approaches a lower bound as \u03b5\u2192 0. To analyze correlated outputs in MMCC, we prove that they can be analyzed as if they were independent, by conditioning them on prior outputs. Our \u201cconditional composition theorem\u201d has broad utility: we use it to show that the noise added to binary-tree-DP-FTRL can asymptotically match the noise added to DP-SGD with amplification. Our algorithm also has practical empirical utility. We show that amplification leads to significant improvement in the privacy/utility trade-offs for DP-FTRL style algorithms for standard benchmark tasks."
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "Privacy amplification is key in differentially private (DP) machine learning (ML) as it enables tighter privacy budgets under certain assumptions on the data processing. For example, one of the main contributions in the DP-SGD (DP Stochastic Gradient Descent) work by Abadi et al. (2016) was the \u201cmoments accountant\u201d, which relies on privacy amplification (Kasiviswanathan et al., 2008; Bassily et al., 2014) for bounding the privacy cost. Recently, privacy amplification analysis enabled Choquette-Choo et al. (2023a) to show that a class of DP-FTRL (DP Follow-The-Regularized-Leader) algorithms (Smith & Thakurta, 2013; Kairouz et al., 2021) was superior in privacy-utility tradeoffs to DP-SGD.1 At the heart of DP-FTRL is the construct of matrix mechanism (McKenna et al., 2021; Denisov et al., 2022) that effectively computes the prefix sums \u2211 i\u2264t xi over a sequence of adaptively chosen vectors {xi : i \u2208 [n]} (given by A \u00b7 x, where A is a lower triangular matrix of all ones and x = [x1| \u00b7 \u00b7 \u00b7 |xn]> \u2208 Rn\u00d7d). Matrix mechanism corresponds to factorizing A = B \u00b7C to minimize the error in the estimation of the prefix sums, while ensuring C \u00b7 x + z satisfies DP, where z is drawn from an isotropic normal distribution. Bringing privacy amplification to matrix mechanisms is thus an important area of research to enable better privacy-utility tradeoffs. (In the rest of the paper, we will refer to the matrix B as the decoder matrix, and C as the encoder matrix.)\n\u2217Google DeepMind. cchoquette@google.com. \u2020Google Research. arunganesh@google.com. \u2021Google DeepMind. steinke@google.com. \u00a7Google DeepMind. athakurta@google.com. 1Precisely, they showed DP-FTRL is never worse, and often better, than DP-SGD\u2014it \u201cpareto-dominates\u201d.\nMatrix mechanism poses a major challenge for privacy amplification analysis of DP-FTRL style algorithms. Standard privacy amplification exploits randomness in the selection of minibatches2 but requires that the noise added to each minibatch is independent. In the matrix mechanism, a minibatch (given by xi) contributes to multiple rows of C \u00b7 x + z, thus preventing direct application of amplification. This challenge can be seen by the limitations of the amplification analysis of Choquette-Choo et al. (2023a) which only applies to a special class of \u2018b-banded\u2019 matrix mechanisms (i.e., the first b principal diagonals of C are non-zero), that in-turn leads to multiplicatively higher sampling probabilities preventing the full benefits of amplification. Resulting from these limitations is a large region of epsilons where banded matrix mechanisms cannot simultaneously leverage the benefits of correlated noise and privacy amplification; in other words, they perform equivalent to, but no better than, DP-SGD3. Further, since their analysis only applies to the special banded case, matrix mechanisms from the extant literature cannot leverage amplification and correlated noise, e.g., Kairouz et al. (2021); Choquette-Choo et al. (2023b); Denisov et al. (2022).\nIn this work, we provide a generic privacy amplification machinery for adaptive matrix mechanisms for any lower-triangular encoder matrix C that strictly generalizes the approach in (Choquette-Choo et al.,\n2023a)."
        },
        {
            "heading": "1.1 OUR CONTRIBUTIONS",
            "text": "Our main contribution is to prove a general privacy amplification analysis for any matrix mechanism, i.e., arbitrary encoder matrices C for non-adaptively chosen x, and for lower-triangular C\u2019s when x is adaptively chosen (which is the typical situation for learning tasks). We then demonstrate that our method yields both asymptotic improvements and experimental improvements.\nConditional composition (Sec. 3, Theorem 3.1): This is our main technical tool that gracefully handles dependence between the queries C[i,:] \u00b7x, and C[i+1,:] \u00b7x that arises due to multiple participation of a single row of the data matrix x. Standard composition theorems (Dwork & Roth, 2014) only handle this via a pessimistic worst-case privacy guarantee that holds with certainty for each query (in our application, a query is C[i,:]\u00b7x+zi conditioned on C[1:i\u22121,:]\u00b7x+z1:i\u22121). Theorem 3.1 relaxes this to holding with high probability (over the randomness of the algorithm) leading to significantly better guarantees. This generalizes an idea previously used in (Erlingsson et al., 2019; Balle et al., 2020) to analyze privacy amplification by shuffling. We believe this theorem will be useful for analyzing correlated noise mechanisms beyond those studied herein.\nMatrix mechanism with uniform sampling via MMCC (Sec. 4): We prove amplified privacy guarantees for the matrix mechanism with uniform sampling, using Theorem 3.1, that are nearly-tight in the low-epsilon regime (as \u03b5\u2192 0). We improve over Choquette-Choo et al. (2023a) because we enable \u201cmore randomness\u201d in sampling\u2014instead of participating w.p. bp in n/b rounds, data records can participate w.p. p in all n rounds. Recall we need to analyze the privacy of outputting Cx + z, where rows of x are chosen via uniform sampling. We use Thm. 4.3 to reduce Cx + z to a series of mixture of Gaussians (MoG) mechanisms for which we can use privacy loss distribution (PLD) accounting (see the proof sketch of Thm. 4.3 in Sec. 4). Our algorithm MMCC formally stating this reduction is given in Fig. 1. We plan to publicly release a library implementing MMCC with the final manuscript. The analysis of MoG mechanisms included in this library has other uses, such as tighter privacy guarantees for DP-SGD with group-level DP or for linear losses, see App. F for more discussion.\n2E.g., for a data set D, a row x[i,:] = \u2211 d\u2208S \u2207\u03b8`(\u03b8i; d), where S is a randomly chosen subset of D (e.g., sampled u.a.r. from D, or a subset from a random shuffling of D), ` is a loss function, and \u03b8i is obtained via an SGD state update process.\n3In Choquette-Choo et al. (2023a), this region surfaces empirically even for larger \u03b5 \u2248 1.\nBinary tree analysis (Sec. 5): Letting \u03c3\u03b5,\u03b4 be the noise required for the Gaussian mechanism to achieve to satisfy (\u03b5, \u03b4)-DP, the binary tree mechanism requires noise \u03c3\u03b5,\u03b4 \u00b7 \u221a log n. Owing to the versatility of conditional composition, we show that with shuffling, the (non-adaptive) binary tree mechanism only needs noise \u03c3\u03b5,\u03b4 \u00b7 min{ \u221a log n, \u221a log log(1/\u03b4)}. This is optimal given current amplification by shuffling results, which require n = \u2126(log 1/\u03b4)4. To the best of our knowledge, this is the first amplification guarantee (of any kind) for the binary tree mechanism.\nEmpirical improvements (Sec. 6): First we implement and show that \u03b5 computed via MMCC for the binary tree mechanism matches the theoretical predictions of \u2126( \u221a log n) from Sec. 5. Then we apply our work to machine learning and show we can improve the privacy-utility tradeoff for binary-tree-DP-FTRL (Kairouz et al., 2021) entirely post-hoc. Finally, we show that the \u201cevery round\u201d sampling enabled by MMCC achieves better amplification than the \u201cb-min-sep\u201d sampling of (Choquette-Choo et al., 2023a)."
        },
        {
            "heading": "1.2 PROBLEM DEFINITION",
            "text": "Matrix mechanism (MM): Consider a workload matrix A \u2208 Rn\u00d7n, and consider a data set D = {d1, . . . , dm} \u2208 Dm. Let x = [x1(D)| \u00b7 \u00b7 \u00b7 |xn(D)]> \u2208 Rn\u00d7d be a matrix s.t. each row xi : D\u2217 \u2192 Rd is a randomized function that first selects a subset of the data set D, and then maps it to a real valued vector. Furthermore, each of the xi has the following two properties. a) Decomposability: For the subset of the data set D that xi chooses (call it Si), we have xi(D) = \u2211 d\u2208Si gi(d) with gi : D \u2192 R\nd is a vector valued function, and b) bounded sensitivity: \u2200d \u2208 D : \u2016gi(d)\u20162 \u2264 1. Matrix mechanism corresponds to the class of DP algorithms that approximates Ax with low-error. Typically, one designs a pair of matrices A = BC ( which we will call the decoder and the encoder matrices respectively) s.t. Cx + z satisfies DP5 (with z being isotropic normal noise), and Bz is minimized in appropriately chosen norm. We will assume C is non-negative for simplicity.\nPrivacy amplification for MM: In this work we study the problem of amplifying the DP guarantee of MM if we incorporate the randomness in the selection of the subsets of D by each function xi. In particular we consider two selection strategies: i) uniform sampling: each xi selects each entry of D independently w.p. p, ii) shuffling: First the records of D are randomly permuted, and then each xi picks a fixed disjoint subset (of equal size) from D.\nAdaptivity: In our work we allow the choice of xi\u2019s to be adaptive, i.e., xi can be chosen based on the first i\u22121 outputs of MM. Under adaptivity, we will only consider encoder (B) decoder matrices (C) that are lower triangular. However, for non-adaptive choices of the xi\u2019s we allow arbitrary choice of the matrices B and C. Unless mentioned specifically, all our results will be for the adaptive setting."
        },
        {
            "heading": "2 BACKGROUND AND RELATED WORKS",
            "text": ""
        },
        {
            "heading": "2.1 PRIVACY LOSS DISTRIBUTIONS (PLD)",
            "text": "Suppose we have a DP mechanismM that outputs a sample from the continuous distribution P = M(D) when given database D, and outputs a sample from Q = M(D\u2032) when given D\u2032. The \u03b5-hockey stick divergence between two distributions P,Q is defined as:\nH\u03b5(P,Q) = \u222b x max{P (x)\u2212 e\u03b5Q(x), 0}dx = Ex\u223cP [ max { 1\u2212 e \u03b5 eln(P (x)/Q(x)) , 0 }] .\n4We believe this requirement is fundamental and thus \u03c3\u03b5,\u03b4 \u00b7min{ \u221a logn, \u221a log log(1/\u03b4)} is optimal, but if it were\nremoved, our result would improve to O(1) \u00b7 \u03c3\u03b5,\u03b4 . 5We use the zero-out adjacency (Ponomareva et al., 2023) to define DP in this paper.\nA mechanism M satisfies (\u03b5, \u03b4)-DP if and only if for all adjacent databases D,D\u2032 we have H\u03b5(M(D),M(D\u2032)) \u2264 \u03b4. From the definition, we see that to obtain the \u03b5-hockey stick divergence between P and Q, it suffices to know their privacy loss distribution (PLD):\nDefinition 2.1. The privacy loss random variable for P and Q is given by sampling x \u223c P , and computing ln(P (x)/Q(x)). The PLD of P and Q is the distribution of this random variable.\nWe frequently use the notion of dominating PLDs:\nDefinition 2.2 (Definition 7 in (Zhu et al., 2022)). The PLD of P,Q dominates the PLD of P \u2032, Q\u2032 if for any \u03b5,H\u03b5(P,Q) \u2265 H\u03b5(P \u2032, Q\u2032). We will also say random variable L dominates random variable L\u2032 if for any \u03b5,H\u03b5(L) \u2265 H\u03b5(L\u2032), where H\u03b5(L) = E`\u223cL [ max { 1\u2212 e\u03b5\u2212`, 0 }] .\nInformally, a PLD dominates another PLD if any privacy guarantee satisfied by mechanisms with the dominating PLD is also satisfied by mechanisms with the dominated PLD. In particular, if the PLD of some pair of distributions P,Q dominates the PLDs of all pairsM(D),M(D\u2032) for adjacentD,D\u2032, then ifH\u03b5(P,Q) \u2264 \u03b4, M satisfies (\u03b5, \u03b4)-DP."
        },
        {
            "heading": "2.2 PRIVACY AMPLIFICATION",
            "text": "Privacy amplification via sampling analyzes the improvement in privacy given by randomly sampling a minibatch of examples instead of choosing it deterministically. Roughly, a (\u03b5, \u03b4)-DP mechanism run on a batch where each example participates with probability p satisfies (log(1 \u2212 p + pe\u03b5), \u03b4)-DP. The relative improvement from \u03b5 to log(1 \u2212 p + pe\u03b5) gets better as \u03b5 gets smaller: log(1 \u2212 p + pe\u03b5) \u2248 p\u03b5 for \u03b5 < 1, but log(1 \u2212 p + pe\u03b5) \u2248 \u03b5 \u2212 log(1/p) for large \u03b5. The benefits of privacy amplification via sampling in the independent noise setting of DP-SGD, i.e., the decoder matrix C = I, are extremely well-studied (Song et al., 2013; Bassily et al., 2014; Abadi et al., 2016; Mironov et al., 2019; Steinke, 2022; Koskela et al., 2020) with tight analyses. In particular, one round of DP-SGD is dominated by the PLD of N(0, \u03c32) and (1\u2212p) \u00b7N(0, \u03c32) +p \u00b7N(1, \u03c32) and since each round of DP-SGD has independent randomness, composing this PLD with itself n times gives a tight dominating PLD, i.e. tight (\u03b5, \u03b4) curve, for DP-SGD."
        },
        {
            "heading": "3 CONDITIONAL COMPOSITION",
            "text": "We first show a conditional composition theorem, which allows us to analyze a sequence of adaptive mechanisms using high-probability instead of worst-case privacy guarantees for each mechanism. We state conditional composition formally as Theorem C.2. This is a generalization of an idea used in (Erlingsson et al., 2019; Balle et al., 2020) to analyze amplification by shuffling.\nTheorem 3.1 (Informal version of Theorem C.2). LetM1,M2, . . . be a sequence of adaptive mechanisms, where eachMi takes D and the previous mechanisms\u2019 output as input. Suppose there is some \u201cbad\u201d event E that happens with probability at most \u03b4bad over the randomness ofM1,M2, . . . for any input D. If the composition of the worst-case privacy guarantees of M1,M2, . . . each conditioned on E not happening satisfies (\u03b5, \u03b4)-DP, then the composition ofM1,M2, . . . satisfies (\u03b5, \u03b4 + \u03b4bad)-DP.\nThe proof is given in App. C. To apply Theorem 3.1 to correlated noise mechanisms, we observe that they can be viewed as a sequence of adaptive independent-noise mechanisms:\nObservation 3.2. LetM : D \u2192 X1 \u00d7 X2 \u00d7 . . . \u00d7 Xn be a mechanism that takes a dataset D and outputs the tuple x = (x1, x2, . . . , xn) drawn from the distribution M(D). Let Mi : X1 \u00d7 X2 \u00d7 . . . \u00d7 Xi\u22121 \u00d7 D \u2192 Xi be the mechanism that takes x\u20321, x\u20322, . . . , x\u2032i\u22121 and a dataset D and outputs x\u2032i with probability (or likelihood) Prx\u223cM(D) [ xi = x \u2032 i|x1 = x\u20321, x2 = x\u20322, . . . , xi\u22121 = x\u2032i\u22121 ] . The output distributions ofM and the composition ofM1,M2, . . . are the same.\nAlgorithm 1 Matrix Mechanism Conditional Composition algorithm, MMCC(C, p, \u03c3, \u03b41, \u03b42) 1: Input: Matrix C, sampling probability p, noise standard deviation \u03c3, probabilities \u03b41, \u03b42. 2: {p\u0303i,j}i,j\u2208[n] \u2190ProbabilityTailBounds(C, p, \u03c3, \u03b41). . p\u0303i,j is a high-probability upper bound on the probability that an example participated in round j, conditioned on output in rounds 1 to i\u2212 1."
        },
        {
            "heading": "4 PRIVACY ANALYSIS FOR MATRIX MECHANISMS",
            "text": "In this section, we give an algorithm for computing an upper bound on the privacy guarantees of the matrix mechanism, and prove its correctness."
        },
        {
            "heading": "4.1 MIXTURE OF GAUSSIANS MECHANISMS",
            "text": "The key tool in our privacy analysis is a mixture of Gaussians mechanism, a generalization of the Gaussian mechanism with sampling. Here we define these mechanisms under the add adjacency, i.e. D\u2032 contains an example zeroed out in D. Definition 4.1. A mixture of Gaussians (MoG) mechanism is defined by two lists, a list of probabilities {p1, p2, . . . , pk}, with \u2211 i pi = 1, pi \u2208 [0, 1], a list of sensitivities {c1, c2, . . . ck} and a noise level \u03c3. For simplicity, we will assume ci \u2265 0. Given D, the mechanismMMoG({p1, p2, . . . , pk}, {c1, c2, . . . ck}) outputs z \u223c N(0, \u03c32). Given D\u2032, it samples s from the distribution with support {ci}i\u2208[k] and associated probabilities {pi}i\u2208[k], and outputs z \u223c N(s, \u03c32). In other words, it is a Gaussian mechanism where the sensitivity s is a random variable distributed according to {pi}i\u2208[k], {ci}i\u2208[k]. A vector mixture of Gaussians (VMoG) mechanismMVMoG is the same as a MoG mechanism, except the sensitivities ci are allowed to be vectors ci instead of scalars, and our output is sampled from a multivariate Gaussian z \u223c N(0, \u03c32 \u00b7 I) or z \u223c N(s, \u03c32 \u00b7 I).\nFor our proofs, we will need to prove a few properties of MoG mechanisms. We give these properties and their proofs in App. B. It will be easier for us to work with a special case of MoG mechanisms, where the probabilities and sensitivities arise from a product distribution: Definition 4.2. A product mixture of Gaussians (PMoG) mechanism is defined by two lists {p1, . . . , pk} and {c1, . . . ck} and a noise level \u03c3. The mechanismMPMoG({p1, . . . , pk}, {c1, . . . , ck}) is defined equivalently asMMoG({ \u220f i\u2208S pi \u00b7 \u220f i 6\u2208S(1\u2212 pi)|S \u2208 2[k]}, { \u2211 i\u2208S ci|S \u2208 2[k]})."
        },
        {
            "heading": "4.2 MATRIX MECHANISM CONDITIONAL COMPOSITION",
            "text": "The high-level idea of our algorithm, MMCC (short for matrix mechanism conditional composition), for analyzing the matrix mechanism with amplification is the following: The output of each round conditioned on the previous rounds\u2019 output is a MoG mechanism. For each round, we specify a MoG mechanism that dominates this MoG mechanism with high probability. Then by Theorem 3.1, it suffices to compute the\nprivacy loss distribution of each of the dominating MoGs, and then use composition to get our final privacy guarantee. MMCC is given in Fig. 1. In App. C, we prove that MMCC computes a valid DP guarantee:\nTheorem 4.3. Let \u03b5 be the output of MMCC(C, p, \u03c3, \u03b41, \u03b42). The matrix mechanism with matrix C, uniform sampling probability p, and noise level \u03c3 satisfies (\u03b5, \u03b41 + \u03b42)-DP.\nWe give a high-level overview of the proof. The proof proceeds in three steps. First, we show the matrix mechanism is dominated by a sequence of adaptively chosen scalar MoG mechanisms, by analyzing the distribution for each round conditioned on previous rounds and applying a vector-to-scalar reduction (Lem. B.4). Second, we simplify these MoG mechanisms by showing that each is dominated by a PMoG mechanism with probabilities pi,j depending on the outputs from previous rounds. Third, we show that with high probability pi,j \u2264 p\u0303i,j for all i, j, i.e., the upper bounds generated by ProbabilityTailBounds hold. We then apply Theorem 3.1.\nTightness: To get a sense for how tight MMCC is, if in MMCC we instead set p\u0303i,j = p for all i, j, this is equivalent to analyzing the matrix mechanism as if each row were independent. Since the rows are actually correlated, we expect this analysis to give a lower bound on the true value of \u03b5. So we can use maxi,j p\u0303i,j/p as roughly an upper bound on the ratio of the \u03b5 reported by MMCC and the true \u03b5 value. In particular, as \u03c3 \u2192\u221e, for p\u0303i,j computed by ProbabilityTailBounds this ratio approaches 1, i.e. MMCC gives tight \u03b5 guarantees in the limit as \u03c3 \u2192\u221e.\nSampling scheme of (Choquette-Choo et al., 2023a): The techniques used in MMCC are complementary to those in (Choquette-Choo et al., 2023a): In App. D, we give a generalization of MMCC that analyzes the matrix mechanism under their \u201cb-min-sep sampling.\u201d For b = 1, this is the same as i.i.d. sampling every round so this generalization retrieves MMCC. For b-banded matrices this generalization retrieves exactly the DP-SGD-like analysis of (Choquette-Choo et al., 2023a). In other words, this generalization subsumes all existing amplification results for matrix mechanisms.\nBenefits of i.i.d. sampling: MMCC is the first analysis that allows us to benefit from both correlated noise and privacy amplification via i.i.d. (i.e., maximally random) sampling. In Sec. 6.3 we demonstrate that the combination of benefits allows us to get better `22-error for computing all prefix sums than independent-noise mechanisms, for much smaller \u03b5 than prior work."
        },
        {
            "heading": "5 AMPLIFICATION VIA SHUFFLING FOR NON-ADAPTIVE BINARY TREE",
            "text": "In this section, we show that amplification allows us to improve the privacy guarantees of the binary tree mechanism of (Dwork et al., 2010; Chan et al., 2011). We consider the setting where first the data set D is randomly permuted (call it \u03a0(D)), and each function xi (in the definition of MM from Section 1.2) picks the i-th data record in \u03a0(D). Roughly speaking, using privacy amplification by shuffling (see Section 1.2) we improve \u03c3 for this mechanism by \u2126( \u221a log n/ \u221a log log(1/\u03b4)), while maintaining that each example participates once. For simplicity throughout the section we restrict to the case where n is a power of 2.\nBinary tree mechanism: The binary tree computes sums of rows of x over the intervals [1 : 1], [2 : 2], . . . , [n : n], [1 : 2], [3 : 4], . . . , [n \u2212 1 : n], [1 : 4], . . . [1 : n] with noise. That is, it outputs{\u2211\nk\u00b72j+1\u2264i\u2264(k+1)\u00b72j xi + zj,k } 0\u2264j\u2264logn,0\u2264k<n/2j , where zj,k i.i.d.\u223c N(0, \u03c32). Equivalently, it is a (nonsquare) matrix mechanism where for each j, k pair there is a row of C where the entries in the interval [k \u00b7 2j + 1 : (k+ 1) \u00b7 2j ] are 1 and the remaining entries are 0. We refer to all the noisy sums indexed by the same j as level j. In the single-epoch setting (without shuffling), each row of xi is a sensitivity-1 function computed on the ith example inD. The binary tree mechanism then satisfies the privacy guarantees of distinguishing z and Cei+z, where ei is an elementary vector. Since each row of x is included in log n+1 of the\nsums, we have \u2016Cei\u20162 = \u221a log n+ 1, i.e. the binary tree mechanism satisfies ( O (\u221a log(n) log(1/\u03b4) \u03c3 ) , \u03b4 ) -"
        },
        {
            "heading": "DP.",
            "text": "We now analyze the binary tree mechanism under shuffling. To apply Theorem 3.1, we need the following analysis of \u201capproximate shuffling\u201d given in Lem. 5.1, proven in App. C.\nLemma 5.1 (Simplification of Lem. C.4 in App. C). Suppose we run n Gaussian mechanisms on n inputs, where the order of the inputs is chosen according to a distribution such that no input appears in a certain position with probability more than 1/n\u2032. Then for \u03b4 \u2265 2\u2212\u2126(n\u2032), \u03b40 \u2265 0, this set of mechanisms satisfies( O (\u221a ln(1/\u03b40) ln(1/\u03b4)\n\u03c3 \u221a n\u2032\n) , \u03b4 + n\u2032\u03b40 ) -DP.\nTheorem 5.2. The non-adaptive binary tree mechanism run on \u03a0(D) satisfies( O (\u221a log(1/\u03b4) log log(1/\u03b4)\n\u03c3\n) , \u03b4 ) -DP for \u03c3 = \u2126( \u221a log(1/\u03b4) log log(1/\u03b4)), \u03b4 \u2208 [2\u2212\u2126(n), 1/n].\nThe proof of Theorem 5.2 is given in App. C. We give a summary here: For the \u201ctop\u201d levels j \u2208 [log n \u2212 O(log log(1/\u03b4)), log n], the number of sums per level (i.e., n\u2032 in Lem. 5.1) is less than log(1/\u03b4) so we cannot apply Lem. 5.1. Instead we use the unamplified privacy analysis of the Gaussian mechanism to analyze the privacy of the corresponding noisy sums. For the remaining levels, we combine Theorem 3.1 and Lem. 5.1 to show level j\u2019s privacy parameter \u03b5 is exponentially decaying in log n\u2212 j, i.e. the top O(log log(1/\u03b4)) levels dominate the privacy guarantee. Note that the theorem is proven in the non-adaptive case; our argument for adaptivity in Sec. 4 implicitly requires independence of participations across examples, which does not hold for shuffling."
        },
        {
            "heading": "6 EMPIRICAL IMPROVEMENTS",
            "text": "We implement MMCC by building on methods in the open-source dp accounting Python library (DP Team, 2022), and perform empirical studies of the amplification benefits from MMCC. PLD accounting for MoG mechanisms is currently open-sourced as part of the dp accounting library. We plan to opensource our implementation of MMCC which builds on dp accounting. There are some challenges in the implementation which we discuss in App. F. For simplicity we use \u03b41, \u03b42 = \u03b4/2 in MMCC."
        },
        {
            "heading": "6.1 BINARY TREE MECHANISM AMPLIFICATION",
            "text": "In this section, we show how the privacy guarantee of the binary tree mechanism empirically improves if we use sampling and MMCC. In App. E we repeat this study for a different matrix mechanism proposed by (Fichtenberger et al., 2023).\nAs a baseline, we fix a constant c, and consider the binary tree mechanism under a single-participation constraint, with \u03c3 = c \u221a log(n) + 1. By the analysis of the Gaussian mechanism, for all n that are powers of 2, the binary tree mechanism with this choice of \u03c3 under a single-participation constraint without amplification satisfies (\u03b5, \u03b4)-DP for the same \u03b5, \u03b4. In other words, as we increase n, the privacy guarantee of the unamplified mechanism remains fixed. Then, for the same c and n that are powers of 2, we use MMCC to compute a privacy guarantee for the binary tree mechanism with subsampling probability 1/n and the same choice of \u03c3. By the analyses in Section 5, we expect that with subsampling, the value of \u03b5 will decrease as \u2126( \u221a log n). In Fig. 2, we observe that empirical improvement in \u03b5 due to amplification is roughly proportional to\u221a log(n) + 1. We also observe two improvements as c (i.e., \u03c3) increases. First, the multiplicative im-\nprovement in \u03b5 increases; second, empirical improvements better match a linear fit to \u221a log(n) + 1. Both\nlog(n) + 1.\nA higher ratio (> 1) indicates amplification is better. We plot n = 2i, i \u2208 {1, 2, . . . , 10} with \u03c3 = c\n\u221a\nlog(n) + 1 so \u03b5 is fixed for unamplified single-participation. \u03b4 = 10\u22126.\nthese improvements are explained by the fact that (as discussed in Sec. 4) as \u03c3 \u2192\u221e, MMCC reports a tighter \u03b5."
        },
        {
            "heading": "6.2 LEARNING EXPERIMENTS WITH BINARY-TREE-DP-FTRL",
            "text": "A motivating reason for us to study matrix mechanisms is that the analysis of Kairouz et al. (2021) has a suboptimal scaling in the amount of noise added, which manifests in their experiments with DP machine learning. We reproduce the centralized DP training on CIFAR-10 from Choquette-Choo et al. (2023b), including model architecture, tuning setup, hyperparameter choices, and optimizations to the tree aggregation mechanism for ML; we use these as our baseline results.\nIn Fig. 3, we re-analyze the baseline using MMCC and show significant improvements in privacy-utility tradeoffs for DP-FTRL via binary trees. In particular, we observe that these benefits become larger as \u03b5 becomes small. Note that these improvements are entirely \u201cpost-hoc,\u201d i.e. the algorithm is the same, but with a better privacy analysis.\n6.3 I.I.D. SAMPLING ENABLES BETTER AMPLIFICATION THAN b-MIN-SEP SAMPLING\nThe prior work of (Choquette-Choo et al., 2023a) gives an amplification result using a sampling scheme we call \u201cb-min-sep sampling\u201d for b-banded matrices. In their sampling scheme, each example participates in\nn/b rounds with sampling probability bp. In contrast, MMCC enables sampling each example in all n rounds with probability p, a \u201cmore random\u201d form of sampling. We compare the two amplification analyses using the DP-FTRL-TreeRestart algorithm of (Kairouz et al., 2021), which sequentially runs n/2h\u22121 height-h binary tree mechanisms, each binary tree mechanism run for 2h\u22121 rounds. This corresponds to a matrix mechanism that is 2h\u22121-banded, so we can apply the results of (Choquette-Choo et al., 2023a). In Fig. 4, we compare the \u03b5 for DP-FTRL-TreeRestart computed as a function of \u03c3 using MMCC and the analysis of (Choquette-Choo et al., 2023a), in the setting of n = 512, p = 1/16, h = 4, and we see that indeed the more random sampling enabled by MMCC allows for improved privacy guarantees compared to b-min-sep sampling."
        },
        {
            "heading": "7 DISCUSSION, FUTURE DIRECTIONS, AND CONCLUSION",
            "text": "In this paper, we proposed MMCC, which gives tight amplification guarantees for sampling in the limit as \u03b5 \u2192 0. One limitation of our work is that we are not able to prove adaptivity for non-lower triangular C, which captures important matrix mechanisms like the \u201cfully efficient\u201d binary tree mechanism (Honaker, 2015). It is an important future direction to fully understand what combinations of privacy amplification and correlated noise allow the same privacy for non-adaptive and adaptive inputs. In addition, there are many potential improvements to MMCC, as well as open problems that naturally follow from our work. Another open problem that we make progress towards is proving DP-FTRL strictly dominates DP-SGD, i.e. for any \u03b5 > 0 DP-FTRL achieves strictly6 better utility than DP-SGD under an appropriate definition of utility. In particular, we conjecture that a tighter amplification analysis than that of MMCC could show that even for \u03b5 close to 0, DP-FTRL with a matrix mechanism where C is close to but not equal to the identity has strictly better utility than DP-SGD.\nOur interest in the matrix mechanism is primarily motivated by the works of (Denisov et al., 2022; Choquette-Choo et al., 2023b;a) which considered the problem of choosing C that optimizes (a proxy for) the utility of DP-FTRL. The utility of DP-FTRL can be written as a function of C\u22121, and thus can be optimized under a constraint of the form \u201cthe matrix mechanism defined by C satisfies a given privacy definition\u201d. Without amplification, this constraint can usually be easily written as e.g. C \u2208 S where S is a convex set of matrices, which makes optimizing under this constraint easy. An interesting question is whether we can solve the same problem, except the privacy constraint accounts for amplification. This would likely require designing a function that takes C, p, \u03c3 and approximates \u03b5 that is differentiable in C (unlike MMCC, which is an algorithmic computation that is not easily differentiable).\nIn these works, DP-FTRL is always strictly better than DP-SGD without amplification, but with amplification for small \u03b5 the optimal choice of C with amplification is the identity, i.e. the optimal DP-FTRL is just DP-SGD (with independent noise). If we could optimize C under an amplified privacy constraint, we conjecture the following (perhaps surprising) statement could be proven as a corollary: As long as we are not in the full-batch setting, even with amplification by sampling, the optimal choice of C is never the identity for \u03b5 > 0. In other words, despite its ubiquity, DP-SGD is never the optimal algorithm to use (ignoring computational concerns).\nDue to space constraints, we defer the discussion of other future directions to App. A."
        },
        {
            "heading": "A MORE FUTURE DIRECTIONS",
            "text": "First, our tail bound on the conditional sampling probabilities p\u0303i,j approach p as \u03c3 \u2192 \u221e. However, for finite \u03c3, p\u0303i,j can be much larger than p, i.e. the \u03b5 computed by MMCC can be much larger than the true \u03b5. We believe the values of p\u0303i,j we compute are not tight and can be improved. In particular, in computing p\u0303i,j , we give a tail bound on the maximum of the dot product of a Gaussian with a set of vectors, and the values of p\u0303i,j we compute effectively correspond to the case where this tail bound is attained by every dot product. This is overly pessimistic, and it should be possible to obtain tighter \u03b5 via a more refined tail-bounding approach.\nSecond, while MMCC has a polynomial dependence on n (whereas computing H\u03b5 via e.g. numerical integration would require time exponential in n), empirically we found that even with many optimizations for runtime, running MMCC for n \u2248 2000 still took several hours. In practice, we would often like to run for larger n, or do multiple sequential runs of MMCC in order to e.g. compute the smallest \u03c3 that gives a certain \u03b5 via binary search. In turn, it is practically interesting/important to make MMCC more efficient, or discover another algorithm that gives \u03b5 comparable to or better than MMCC, but with a smaller runtime."
        },
        {
            "heading": "B PROPERTIES OF MOG MECHANISMS",
            "text": "The following lemma informally lets us show that domination for the remove adjacency (i.e., D contains an example zeroed out in D\u2032) is equivalent to domination for the add adjacency (i.e., D\u2032 contains an example zeroed out in D). Thus, we usually only need to prove statements under one of the two adjacencies, and it is implied for the other as well.\nLemma B.1 (Lemma 29 in (Zhu et al., 2022)). The PLD of P,Q dominates the PLD of P,Q\u2032 if and only if the PLD of Q,P dominates the PLD of Q\u2032, P ."
        },
        {
            "heading": "B.1 MONOTONICITY OF MOG MECHANISMS",
            "text": "The following shows the privacy guarantees of a MoG mechanism are \u201cmonotonic\u201d in the sensitivity random variable ci:\nLemma B.2. Let {p1, p2, . . . pk}, {c1, c2, . . . , ck} and {c\u20321, c\u20322, . . . c\u2032k} be such that (i) each ci is nonnegative and (ii) c\u2032i is entry-wise greater than or equal to ci for all i, i.e. each c \u2032 i \u2212 ci is non-negative.\nThen the PLD of MVMoG({p1, p2, . . . pk}, {c1, c2, . . . , ck})\nis dominated by the PLD of\nMVMoG({p1, p2, . . . pk}, {c\u20321, c\u20322, . . . c\u2032k}).\nProof. By Lem. B.1, it suffices to only consider the remove adjacency, i.e. given D we sample ci and then sample from N(ci, \u03c32I) and given D\u2032 from N(0, \u03c32I). The privacy loss of outputting x is:\nPL(x) := ln (\u2211 i pi exp ( 2\u3008ci,x\u3009 \u2212 \u2016ci\u201622 2\u03c32 )) .\nLet S \u2286 Rd be monotonic if for any x \u2208 S,y such that y\u2212x is non-negative, y is also in S. In other words, increasing any subset of the entries of x \u2208 S gives another vector in S. Since all ci are non-negative, if y \u2212 x is non-negative, then the privacy loss of outputting y is larger than that of outputting x. So for any\nVMoG mechanism and any t, the set of outputs St = {x : PL(x) \u2265 t} is monotonic. By the NeymanPearson lemma it suffices to consider only the sets St in the definition of (\u03b5, \u03b4)-DP, i.e. a mechanism satisfies (\u03b5, \u03b4)-DP if and only if\n\u2200t : Pr x\u223cM(D) [x \u2208 St] \u2264 e\u03b5 \u00b7 Pr x\u223cM(D\u2032) [x \u2208 St] + \u03b4.\nSo, in order to show that to show the first VMoG mechanism is dominated by the second, it suffices to show the probability that x \u223c N(ci, \u03c32I) is in any monotonic set S is at most the probability that x \u223c N(c\u2032i, \u03c32I) is in S. This is immediate by a coupling of the two random variables: we let the first random variable be ci + z and the second random variable be c\u2032i + z, where the choice of i and Gaussian noise z are the same for both random variables. For any monotonic S, since c\u2032i \u2212 ci is non-negative, ci + z is in S only if c\u2032i + z is in S, giving that the probability x \u223c N(ci, \u03c32I) is in S is at most the probability x \u223c N(c\u2032i, \u03c32I) is in S.\nSince the above proof holds for any ci, c\u2032i satisfying the assumptions in the lemma, it also holds if c \u2032 i are fixed/non-adaptive but the entries in ci are chosen adaptively (while still satisfying the assumptions in the lemma), i.e. the jth coordinate of ci is chosen only after seeing the first j \u2212 1 coordinates of the output. In the scalar case, we get the following corollary:\nCorollary B.3. Let {p1, p2, . . . pk}, {c1, c2, . . . , ck} and {p\u20321, p\u20322, . . . p\u2032k\u2032}, {c\u20321, c\u20322, . . . c\u2032k\u2032} be such that for all T , \u2211 i:c\u2032i\u2265T p\u2032i \u2265 \u2211 i:ci\u2265T pi. In other words, the random variable induced by {pi}i, {ci}i is stochastically dominated by the random variable induced by {p\u2032i}i, {c\u2032i}i. We also assume ci, c\u2032i \u2265 0 for all i. Then the PLD of MMoG({p1, p2, . . . pk}, {c1, c2, . . . , ck}) is dominated by the PLD of\nMMoG({p\u20321, p\u20322, . . . p\u2032k\u2032}, {c\u20321, c\u20322, . . . c\u2032k\u2032}).\nCor. B.3 follows from Lem. B.2 since by allowing duplicate ci values, we can reduce to the setting where the probabilities are the same, and ci \u2264 c\u2032i for all ci. For example, if ci is 0 or 1 w.p. 1/2 and c\u2032i is 0, 1, or 2 w.p. 1/3, we can use {pi} = {1/3, 1/6, 1/6, 1/3}, {ci} = {0, 0, 1, 1}, and {c\u2032i} = {0, 1, 1, 2}."
        },
        {
            "heading": "B.2 DIMENSION REDUCTION FOR MOG MECHANISMS",
            "text": "We now give the following lemma, which lets us reduce the dimensions of a VMoG mechanism.\nLemma B.4. Let c1, c2, . . . , ck \u2208 Rn\u00d7p. Let c\u20321, c\u20322, . . . , c\u2032k \u2208 Rn be vectors such that \u2016(ci)j,:\u20162 \u2264 c \u2032 i(j) for all i, j, i.e. the entries of c\u2032i upper bound the `2-norms of the corresponding rows of ci. Then the PLD of\nMVMoG({p1, p2, . . . , pk}, {c1, c2, . . . , ck})\nis dominated by the PLD of\nMVMoG({p1, p2, . . . , pk}, {c\u20321, c\u20322, . . . , c\u2032k}).\nFurthermore, this holds even if the rows of each ci are adaptively chosen and c\u2032i are fixed, i.e. the jth row of all ci is chosen by an adversary after seeing the first j \u2212 1 rows of the output of the VMoG mechanism, as long as the assumption \u2016(ci)j,:\u20162 \u2264 c \u2032 i(j) holds.\nWe need the following lemma, which we can apply multiple times to prove Lem. B.4:\nLemma B.5. Let w1, w2, . . . wk > 0 be positive scalars and let c1, c2, . . . ck \u2208 Rp be arbitrary vectors. Then for any \u03b5 and \u03c3 > 0:\nEx\u223cN(0,\u03c32Ip)\n[ max {\u2211 i wi exp(\u3008ci,x\u3009)\u2212 e\u03b5, 0 }] \u2264 Ex\u223cN(0,\u03c32) [ max {\u2211 i wi exp(\u2016ci\u20162 x)\u2212 e \u03b5, 0 }] .\nProof. \u2211 i wi exp(\u2016ci\u20162 x) as a function of x is continuous, increasing in x, and has range R+. So, there\nexists some t such that \u2211 i wi exp(\u2016ci\u20162 t) = e\u03b5. For this choice of t, let ti = wi exp(\u2016ci\u20162 t). Then we have for all x:\nmax {\u2211 i wi exp(\u2016ci\u20162 x)\u2212 e \u03b5, 0 } = \u2211 i max {wi exp(\u2016ci\u20162 x)\u2212 ti, 0} .\nNow, by linearity of expectation and the fact that max{ \u2211 i ai, \u2211 i bi} \u2264 \u2211 i max{ai, bi}:\nEx\u223cN(0,\u03c32Ip)\n[ max {\u2211 i wi exp(\u3008ci,x\u3009)\u2212 e\u03b5, 0 }] \u2264 Ex\u223cN(0,\u03c32Ip) [\u2211 i max {wi exp(\u3008ci,x\u3009)\u2212 ti, 0} ] = \u2211 i Ex\u223cN(0,\u03c32Ip) [max {wi exp(\u3008ci,x\u3009)\u2212 ti, 0}]\n= \u2211 i Ex\u223cN(0,\u03c32) [max {wi exp(\u2016ci\u20162 x)\u2212 ti, 0}]\n= Ex\u223cN(0,\u03c32) [\u2211 i max {wi exp(\u2016ci\u20162 x)\u2212 ti, 0} ]\n= Ex\u223cN(0,\u03c32)\n[ max {\u2211 i wi exp(\u2016ci\u20162 x)\u2212 e \u03b5, 0 }] .\nProof of Lem. B.4. Lem. B.2 holds for adaptively chosen ci and fixed c\u2032i (using the notation of that lemma), so by Lem. B.2 it suffices to prove the lemma for adaptive ci and fixed c\u2032i such that \u2016(ci)j,:\u20162 = c \u2032 i(j) for all i, j. Further, by Lem. B.1, it suffices to show the lemma under the remove adjacency. That is, P = N(ci, \u03c3\n2In\u00d7p), Q = N(0, \u03c32In\u00d7p), P \u2032 = N(c\u2032i, \u03c32In), Q\u2032 = N(0, \u03c32In), and it suffices to show H\u03b5(P,Q) \u2264 H\u03b5(P \u2032, Q\u2032) for all \u03b5. We have:\nH\u03b5(P,Q) = Ex\u223cQ [ max { P (x)\nQ(x) \u2212 e\u03b5, 0 }] = Ex\u223cN(0,\u03c32In\u00d7p) [ max {\u2211 i pi exp(\u2016x\u2212 ci\u2016 2 2 /2\u03c3 2)\nexp(\u2016x\u201622 /2\u03c32) \u2212 e\u03b5, 0\n}]\n= Ex\u223cN(0,\u03c32In\u00d7p)\n[ max {\u2211 i pi exp ( 2\u3008ci,x\u3009 \u2212 \u2016ci\u201622 2\u03c32 ) \u2212 e\u03b5, 0 }]\nTo reflect the fact that ci can be chosen adaptively, let ci,j(x1:j\u22121) denote any adversary\u2019s adaptive choice of the jth row of ci after observing the first j \u2212 1 rows of x. We can then write H\u03b5(P,Q) as:\nEx1,x2,...xn\u223cN(0,\u03c32Ip) max \u2211\ni pi \u220f j\u2208[n] exp\n( 2\u3008ci,j(x1:j\u22121),xj\u3009 \u2212 \u2016ci,j(x1:j\u22121)\u201622\n2\u03c32\n) \u2212 e\u03b5, 0   =\nEx1,x2,...xn\u22121\u223cN(0,\u03c32Ip) Exn\u223cN(0,\u03c32Ip) max \u2211 i pi \u220f j\u2208[n] exp ( 2\u3008ci,j(x1:j\u22121),xj\u3009 \u2212 \u2016ci,j(x1:j\u22121)\u201622 2\u03c32 ) \u2212 e\u03b5, 0   .\n(1)\nNote that the values of all ci,j in (1) are constants with respect to the inner expectation. So for any realization of x1,x2, . . . ,xn\u22121, choosing\nwi = pi exp\n( \u2212 \u2016ci,n(x1:n\u22121)\u201622\n2\u03c32\n) \u220f j\u2208[n\u22121] exp ( 2\u3008ci,j(x1:j\u22121),xj\u3009 \u2212 \u2016ci,j(x1:j\u22121)\u201622 2\u03c32 ) and observing that by assumption \u2016ci,n(x1:n\u22121)\u20162 = c \u2032 i(n), we can apply Lem. B.5 to upper bound the inner expectation in (1) as:\n(1) \u2264 Ex1,x2,...xn\u22121\u223cN(0,\u03c32Ip),xn\u223cN(0,\u03c32) max \u2211\ni\npi \u220f\nj\u2208[n\u22121]\n\u00b7 exp\n( 2\u3008ci,j(x1:j\u22121),xj\u3009 \u2212 \u2016ci,j(x1:j\u22121)\u201622\n2\u03c32\n) \u00b7 exp ( 2c\u2032i(n)xn \u2212 c\u2032i(n)2\n2\u03c32\n) \u2212 e\u03b5, 0 }] .\nWe can then iteratively repeat this argument for rows n\u2212 1, n\u2212 2, . . . 1 to get:\nH\u03b5(P,Q) \u2264 Ex1,x2,...xn\u22121\u223cN(0,\u03c32Ip),xn\u223cN(0,\u03c32)\n[ max {\u2211 i pi\n\u00b7 \u220f\nj\u2208[n\u22121]\nexp\n( 2\u3008ci,j(x1:j\u22121),xj\u3009 \u2212 \u2016ci,j(x1:j\u22121)\u201622\n2\u03c32\n) \u00b7 exp ( 2c\u2032i(n)xn \u2212 c\u2032i(n)2\n2\u03c32\n) \u2212 e\u03b5, 0  \n\u2264 Ex1,x2,...xn\u22122\u223cN(0,\u03c32Ip),xn\u22121,xn\u223cN(0,\u03c32)\n[ max {\u2211 i pi\n\u220f j\u2208[n\u22122] exp\n( 2\u3008ci,j(x1:j\u22121),xj\u3009 \u2212 \u2016ci,j(x1:j\u22121)\u201622\n2\u03c32\n) \u00b7\n\u220f j\u2208[n]\\[n\u22122] exp ( 2c\u2032i(j)xj \u2212 c\u2032i(j)2 2\u03c32 ) \u2212 e\u03b5, 0  \n\u2264 Ex1,x2,...xn\u22123\u223cN(0,\u03c32Ip),xn\u22122,xn\u22121,xn\u223cN(0,\u03c32)\n[ max {\u2211 i pi\n\u220f j\u2208[n\u22123] exp\n( 2\u3008ci,j(x1:j\u22121),xj\u3009 \u2212 \u2016ci,j(x1:j\u22121)\u201622\n2\u03c32\n) \u00b7\n\u220f j\u2208[n]\\[n\u22123] exp ( 2c\u2032i(j)xj \u2212 c\u2032i(j)2 2\u03c32 ) \u2212 e\u03b5, 0  \n. . .\n\u2264 Ex1,x2,...,xn\u223cN(0,\u03c32) max \u2211\ni pi \u220f j\u2208[n] exp ( 2c\u2032i(j)xj \u2212 c\u2032i(j)2 2\u03c32 ) \u2212 e\u03b5, 0  \n= Ex\u223cN(0,\u03c32In)\n[ max {\u2211 i pi exp ( 2\u3008c\u2032i,x\u3009 \u2212 \u2016c\u2032i\u2016 2 2 2\u03c32 ) \u2212 e\u03b5, 0 }] = H\u03b5(P \u2032, Q\u2032).\nAs a corollary to the above \u201cmatrix-to-vector reduction\u201d, we have a \u201cvector-to-scalar reduction\u201d for MoG mechanisms:\nCorollary B.6. The PLD of\nMVMoG({p1, p2, . . . , pk}, {c1, c2, . . . , ck})\nis dominated by the PLD of\nMMoG({p1, p2, . . . , pk}, {\u2016c1\u20162 , \u2016c2\u20162 , . . . , \u2016ck\u20162})."
        },
        {
            "heading": "C DEFERRED PROOFS",
            "text": ""
        },
        {
            "heading": "C.1 PROOF OF THEOREM C.2",
            "text": "We will need the following lemma, which shows domination is preserved by composition:\nLemma C.1 (Theorem 10 in (Zhu et al., 2022)). LetM1, . . . ,Mk be an adaptive sequence of mechanisms, i.e., each mechanism receives the output of all previous mechanism and the database. Suppose for all i and joint outputs x ofM1, . . .Mi\u22121, the PLD ofMi(x,D) andMi(x,D\u2032) is dominated by the PLD of Pi, Qi. Then lettingM be the composition of these mechanisms, the PLD ofM(D),M(D\u2032) is dominated by the PLD of P1 \u00d7 P2 \u00d7 . . . , Q1 \u00d7Q2 \u00d7 . . .. Similarly, if L1, L2, . . . , Lk and L\u20321, L \u2032 2, . . . , L \u2032 k are random variables such that Li dominates L \u2032 i for all i, then L1 + L2 + . . .+ Lk dominates L\u20321 + L \u2032 2 + . . .+ L \u2032 k.\nIn (Zhu et al., 2022), only the first part of Lem. C.1 is stated. However, the proof allows arbitrary measures, i.e., measures that don\u2019t integrate to 1, which implies the second part of Lem. C.1.\nTheorem C.2. LetM1 : D \u2192 X1,M2 : X1 \u00d7D \u2192 X2,M3 : X1 \u00d7X2 \u00d7D \u2192 X3, . . .Mn be a sequence of adaptive mechanisms, where eachMi takes a dataset inD and the output of mechanismsM1, . . . ,Mi\u22121 as input. Let M be the mechanism that outputs (x1 = M1(D), x2 = M2(x1, D), . . . , xn = Mn(x1, . . . , xn\u22121, D)). Fix any two adjacent datasets D,D\u2032. Suppose there exists \u201cbad events\u201d E1 \u2286 X1, E2 \u2286 X1\u00d7X2, . . . ...En\u22121 \u2286 X1\u00d7X2\u00d7 . . .\u00d7Xn\u22121 such that\nPr x\u223cM(D)\n[\u2203i : (x1, x2, . . . xi) \u2208 Ei] \u2264 \u03b4\nand pairs of distributions (P1, Q1), (P2, Q2), . . . (Pn, Qn) such that the PLD of M1(D) and M1(D\u2032) is dominated by the PLD of P1, Q1 and for any i \u2265 1 and \u201cgood\u201d output (x1, x2, . . . xi) /\u2208 Ei, the PLD of Mi+1(x1, . . . , xi, D) andMi+1(x1, . . . , xi, D\u2032) is dominated by the PLD of Pi+1, Qi+1. Then for all \u03b5:\nH\u03b5(M(D),M(D\u2032)) \u2264 H\u03b5 (P1 \u00d7 P2 \u00d7 . . .\u00d7 Pn, Q1 \u00d7Q2 \u00d7 . . .\u00d7Qn) + \u03b4.\nAlgorithm 2 ProbabilityTailBounds(C, p, \u03c3, \u03b41) 1: Input: Matrix C, sampling probability p, noise standard deviation \u03c3, probability \u03b41. 2: \u03b4\u2032 = \u03b412\u00b7(nnz(C)\u2212n) . nnz is the number of non-zeros. 3: z = \u03a6\u22121(1\u2212 \u03b4\u2032) . Tail bound on normal distribution; here, \u03a6 is the standard normal CDF. 4: for i, j \u2208 [n] do 5: if Ci,j = 0 then 6: p\u0303i,j = 1 7: else 8: si,j = minimum s s.t. Pr[ \u2211 j\u2032\u2264i xj\u2032\u3008C1:i\u22121,j ,C1:i\u22121,j\u2032\u3009 > s] \u2264 \u03b4\u2032, xj\u2032\ni.i.d.\u223c Bern(p) . si,j is a tail bound on the dot product of first i\u2212 1 entries of Cx and C1:i\u22121,j .\n9: \u03b5i,j = z\u2016C1:i\u22121,j\u20162 \u03c3 + 2si,j\u2212\u2016C1:i\u22121,j\u201622 2\u03c32\n. \u03b5i,j is a tail bound on the privacy loss of a participation in round j after outputting first i\u2212 1 rounds 10: p\u0303i,j =\np\u00b7exp(\u03b5i,j) p\u00b7exp(\u03b5i,j)+(1\u2212p)\n11: return {p\u0303i,j}i,j\u2208[n].\nFigure 5: Algorithm for computing p\u0303i,j , tail bound on conditional probability of participating in round j given first i\u2212 1 outputs.\nProof. Let L1 be the privacy loss random variable ofM, and let L2 be the privacy loss random variable of P1 \u00d7 P2 \u00d7 . . .\u00d7 Pn, Q1 \u00d7Q2 \u00d7 . . .\u00d7Qn. We want to show H\u03b5(L1) \u2264 H\u03b5(L2) + \u03b4 for all \u03b4. Let L\u20321 be the random variable coupled with L1, with the coupling defined as follows: If \u2203i : (x1, x2, . . . , xi) \u2208 Ei, then L\u20321 = \u2212\u221e, otherwise L\u20321 = L1. Let E = {x|\u2203i : (x1, x2, . . . xi) \u2208 Ei}. Then for all \u03b5:\nH\u03b5(L1) = Ex [ max { 1\u2212 e\u03b5\u2212L1(x), 0 }] = Pr\nx [x /\u2208 E] \u00b7 Ex\n[ max { 1\u2212 e\u03b5\u2212L1(x), 0 }\u2223\u2223\u2223x /\u2208 E]+ Pr x [x \u2208 E] \u00b7 Ex [ max { 1\u2212 e\u03b5\u2212L1(x), 0 }\u2223\u2223\u2223x \u2208 E] = H\u03b5(L \u2032 1) + Pr\nx [x \u2208 E] \u00b7 Ex\n[ max { 1\u2212 e\u03b5\u2212L1(x), 0 }\u2223\u2223\u2223x \u2208 E] \u2264 H\u03b5(L\u20321) + Pr x [x \u2208 E] \u2264 H\u03b5(L\u20321) + \u03b4.\nSo it suffices to show L\u20321 is dominated by L2. We consider the following process for sampling L \u2032 1: For each i, if for any i\u2032 < i, (x1, x2, . . . , xi\u2032) \u2208 Ei\u2032 , then we let L1,i = \u2212\u221e deterministically. Otherwise we sample xi \u223c Mi(x1, . . . , xi\u22121, D), L1,i = ln ( Pryi\u223cMi(x1,...,xi\u22121,D)[yi=xi]\nPryi\u223cMi(x1,...,xi\u22121,D)[yi=xi]\n) . Then L\u20321 = \u2211 i L \u2032 1,i. Similarly, let\nL2,i be the privacy loss random variable for Pi, Qi, and let L2 = \u2211 i L2,i. By assumption, the distribution of L\u20321,i conditioned on x1, x2, . . . , xi\u22121 is always dominated by L2,i. So by Lem. C.1, L \u2032 1 is dominated by L2."
        },
        {
            "heading": "C.2 PROOF OF THM. 4.3",
            "text": "Before stating the proof, in Fig. 5 we give ProbabilityTailBounds, the subroutine used to compute the values of p\u0303i,j .\nProof of Thm. 4.3. For simplicity in the proof we only consider remove adjacency, i.e. D contains a sensitive example zeroed out in D\u2032. By symmetry the proof also works for add adjacency. By quasi-convexity\nof approximate DP, it suffices to prove the theorem assuming the participation of all examples except the sensitive example is deterministic, i.e. we know the contribution of all examples except the sensitive example to x, so we can assume these contributions are zero. So, let x be the matrix used in the matrix mechanism if we were to sample the sensitive example in each round. Then, the matrix mechanism is a VMoG mechanism with probabilities {p|S|(1\u2212 p)n\u2212|S|}S\u2286[n] and sensitivities { \u2211 j\u2208S C:,jxj}S\u2286[n].\nOur proof proceeds in three high-level steps:\n1. We show the matrix mechanism is dominated by a sequence of adaptively chosen MoG mechanisms. 2. We show each of the adaptively chosen MoG mechanisms is further dominated by a PMoG mechanism. 3. We show these PMoG mechanisms are with high probability dominated by the PMoG mechanisms in MMCC, and then apply Theorem C.2.\nStep 1 (matrix mechanism dominated by sequence of MoG mechanisms): Let f be the function that takes a matrix M and returns a vector f(M) where the ith entry of this vector is the `2-norm of the ith row of M. Using triangle inequality, for any x such that each row of x has norm at most 1, f( \u2211 j\u2208S C:,jxj)\nis entrywise less than or equal to \u2211 j\u2208S C:,j . So by Lem. B.4 the matrix mechanism is dominated by the\nVMoG mechanism with probabilities {p|S|(1 \u2212 p)n\u2212|S|}S\u2286[n] and sensitivities { \u2211 j\u2208S C:,j}S\u2286[n]7. Note that this is exactly the (non-adaptive) matrix mechanism where each xi = 1 (prior to sampling), i.e. it suffices to prove the privacy guarantee holds for this choice of x. So, for the rest of the proof we will assume the input of the matrix mechanism (prior to sampling) is the all ones vector.\nNow, let \u03b81:i denote the output of rounds 1 to i. By Observation 3.2, this random variable is the same as the composition over i of outputting \u03b8i sampled from its distribution conditioned on \u03b81:i\u22121. Let Si denote the set of rounds in [i] in which we sample the sensitive example. Abusing notation to let Pr denote a likelihood, the likelihood of the matrix mechanismM(D) outputting \u03b8i in round i conditioned on \u03b81:i\u22121 is:\u2211\nT\u2286[i]\nPr \u03c4\u223c\u0398(D) [Si = T |\u03c41:i\u22121 = \u03b81:i\u22121] Pr \u03c4i\u223cN( \u2211 j\u2208T Ci,j ,\u03c3 2\u00b7I) [\u03c4i = \u03b8i]\nThe likelihood ofM(D\u2032) outputting \u03b8i in round i (conditioned on \u03b81:i\u22121, which doesn\u2019t affect the likelihood since since each coordinate of \u03b8 is independent when sampled fromM(D\u2032)) is\nPr \u03c4i\u223cN(0,\u03c32\u00b7I) [\u03c4i = \u03b8i] .\nIn other words, the distribution of \u03b8i conditioned on \u03b81:i\u22121 underM(D),M(D\u2032) is exactly the same as the pairs of output distributions given by the MoG mechanism.\nMMoG { Pr \u03c4\u223c\u0398(D) [Si = T |\u03c41:i\u22121 = \u03b81:i\u22121] } T\u2286[i] , { \u2211 j\u2208T Ci,j}T\u2286[i]  . So the matrix mechanism with x being all ones is the same as the sequence of (adaptively chosen) MoG mechanisms given by\n7Note that since C is lower-triangular, so the choice of the distribution of the ith row of Cx by an adaptive adversary depends only on rows 1 to i\u2212 1 of Cx+ z. That is, an adversary who chooses the jth row of x after seeing the j \u2212 1st first rows of the matrix mechanism satisfies the adaptivity condition in Lem. B.4.\nMMoG { Pr \u03c4\u223c\u0398(D) [Si = T |\u03c41:i\u22121 = \u03b81:i\u22121] } T\u2286[i] , { \u2211 j\u2208T Ci,j}T\u2286[i]  i\u2208[n] .\nStep 2 (each MoG is dominated by a PMoG): To achieve step 2, we use the following lemma:\nLemma C.3. Let\npi,j = p exp\n( 2\u3008\u03b81:i\u22121,C1:i\u22121,j\u3009\u2212\u2016C1:i\u22121,j\u201622\n2\u03c32 ) p exp ( 2\u3008\u03b81:i\u22121,C1:i\u22121,j\u3009\u2212\u2016C1:i\u22121,j\u201622\n2\u03c32\n) + 1\u2212 p .\nThe random variable induced by probabilities {\u220f j\u2208T pi,j \u220f j\u2208[i]\\T (1\u2212 pi,j) } T\u2286[i] and support\n{ \u2211 j\u2208T Ci,j}T\u2286[i] stochastically dominates the random variable induced by probabilities {Pr\u03c4\u223c\u0398(D)[Si = T |\u03c41:i\u22121 = \u03b81:i\u22121]}T\u2286[i] and the same support.\nProving Lem. C.3 completes the step as with this lemma and Cor. B.3, the PLD of\nMMoG { Pr \u03c4\u223c\u0398(D) [Si = T |\u03c41:i\u22121 = \u03b81:i\u22121] } T\u2286[i] , { \u2211 j\u2208T Ci,j}T\u2286[i]  . is dominated by the PLD of\nMPMoG ( {pi,j}j\u2208[n], {Ci,j}j\u2208[n] ) .\nProof of Lem. C.3. Sampling T according to probabilities {Pr\u03c4\u223c\u0398(D)[Si = T |\u03c41:i\u22121 = \u03b81:i\u22121]}T\u2286[i] is equivalent to the following process: We start with T = \u2205, and for each j \u2208 [i], add it to T with probability Pr[T \u222a {j} \u2286 Si|T \u2286 Si, \u03c41:i\u22121 = \u03b81:i\u22121]. Similarly, sampling T according to{\u220f\nj\u2208T pi,j \u220f j\u2208[i]\\T (1\u2212 pi,j) } T\u2286[i] is equivalent to the same process, except we add j with probability pi,j . If we show that Pr[T \u222a {j} \u2286 Si|T \u2286 Si, \u03c41:i\u22121 = \u03b81:i\u22121] \u2264 pi,j for all T, j, then we can couple these sampling processes such that with probability 1, \u2211 j\u2208T Ci,j is at least as large for the second process as for the first, which implies the lemma. The posterior distribution of Si satisfies:\nPr \u03c4\u223c\u0398(D) [Si = T |\u03c41:i\u22121 = \u03b81:i\u22121] \u221d Pr \u03c4\u223c\u0398(D) [Si = T ] \u00b7 Pr \u03c4\u223c\u0398(D) [\u03c41:i\u22121 = \u03b81:i\u22121|Si = T ]\n\u221d p|T |(1\u2212 p)i\u2212|T | \u00b7 exp 2\u3008\u03b81:i\u22121, \u2211 j\u2208T C1:i\u22121,j\u3009 \u2212 \u2225\u2225\u2225\u2211j\u2208T C1:i\u22121,j\u2225\u2225\u22252 2\n2\u03c32  . Hence:\nPr[T \u222a {j} \u2286 Si|T \u2286 Si, \u03c41:i\u22121 = \u03b81:i\u22121] =\n\u2211 T \u2032\u2287T\u222a{j} p |T \u2032|(1\u2212 p)i\u2212|T \u2032| \u00b7 exp ( 2\u3008\u03b81:i\u22121, \u2211 j\u2208T \u2032 C1:i\u22121,j\u3009\u2212\u2016 \u2211 j\u2032\u2208T \u2032 C1:i\u22121,j\u2032\u201622 2\u03c32 ) \u2211 T \u2032\u2287T p |T \u2032|(1\u2212 p)i\u2212|T \u2032| \u00b7 exp ( 2\u3008\u03b81:i\u22121, \u2211 j\u2208T \u2032 C1:i\u22121,j\u3009\u2212\u2016 \u2211 j\u2032\u2208T \u2032 C1:i\u22121,j\u2032\u201622 2\u03c32\n) . Fix some T \u2032 \u2287 T \u222a {j}. Consider the term in the numerator sum corresponding to T \u2032, and the two terms in the denominator sum corresponding to T \u2032 and T \u2032 \\ {j}. The ratio of the numerator term to the sum of the two denominator terms is:\np \u00b7 exp ( 2\u3008\u03b81:i\u22121,C1:i\u22121,j\u3009\u2212\u2016\u2211j\u2032\u2208T \u2032 C1:i\u22121,j\u2032\u201622 2\u03c32 ) p \u00b7 exp ( 2\u3008\u03b81:i\u22121,C1:i\u22121,j\u3009\u2212\u2016\u2211j\u2032\u2208T \u2032 C1:i\u22121,j\u2032\u201622\n2\u03c32\n) + (1\u2212 p) \u00b7 exp ( \u2212\u2016\u2211j\u2032\u2208T \u2032\\{j}C1:i\u22121,j\u2032\u201622\n2\u03c32\n) .\nSince entries of C are non-negative, we have \u2225\u2225\u2225\u2211j\u2032\u2208T \u2032 C1:i\u22121,j\u2032\u2225\u2225\u22252\n2 \u2265 \u2225\u2225\u2225\u2211j\u2032\u2208T \u2032\\j C1:i\u22121,j\u2032\u2225\u2225\u22252 2 +\n\u2016C1:i\u22121,j\u2032\u201622, hence this ratio and thus Pr[T \u222a {j} \u2286 Si|T \u2286 Si, \u03c41:i\u22121 = \u03b81:i\u22121] are at most pi,j , which proves the lemma.\nStep 3 (replacing pi,j with p\u0303i,j via conditional composition): By Theorem C.2 and Cor. B.3, it now suffices to show that w.p. 1 \u2212 \u03b41, pi,j \u2264 p\u0303i,j for all i, j simultaneously. The bound trivially holds for entries where Ci,j = 0, so we only need the bound to hold for all nnz(C) pairs i, j such that Ci,j > 0. Furthermore, if Ci,j is the first non-zero entry of column j, then C1:i\u22121,j is the all zero-vector, so we get pi,j = p\u0303i,j = p.\nSo, there are only nnz(C) \u2212 n \u201cnon-trivial\u201d pairs we need to prove the tail bound for; by a union bound, we can show each of these bounds individually holds w.p. \u03b41nnz(C)\u2212n . By definition of pi,j , p\u0303i,j , this is equivalent to showing \u3008\u03b81:i\u22121,C1:i\u22121,j\u3009 \u2264 z \u2016C1:i\u22121,j\u20162 \u03c3 + si,j for each of these i, j pairs. We have:\n\u3008\u03b81:i\u22121,C1:i\u22121,j\u3009 = \u2211 j\u2032\u2208Si \u3008C1:i\u22121,j\u2032 ,C1:i\u22121,j\u3009+ \u3008z1:i\u22121,C1:i\u22121,j\u3009.\nThe first term is tail bounded by si,j with probability 1 \u2212 \u03b412(nnz(C)\u2212n) by definition, the second term is drawn from N(0, \u2016C1:i\u22121,j\u201622 \u03c3\n2) and thus tail bounded by z \u2016C1:i\u22121,j\u20162 \u03c3 with the same probability by definition. A union bound over these two events gives the desired tail bound on \u3008\u03b81:i\u22121,C1:i\u22121,j\u3009."
        },
        {
            "heading": "C.3 PROOF OF LEM. 5.1",
            "text": "Proof. Since each 0 \u2264 pi \u2264 1/n\u2032, the mechanism is the same as the following: For each example we choose a subset S \u2286 [n] of size n\u2032 according to some distribution that is a function of the pi, and then choose i uniformly at random from the elements of S, and include the example in the ith subset. By quasi-convexity of approximate DP, it suffices to prove the DP guarantee for a fixed choice of S. For any fixed choice of S, the mechanism is equivalent to the shuffled Gaussian mechanism over n\u2032 coordinates. Each unshuffled Gaussian mechanism satisfies ( \u221a 2 ln(1.25/\u03b40)\n\u03c3 , \u03b40)-DP, and then the lemma follows by the amplification via shuffling statement of Theorem 3.8 of (Feldman et al., 2022)."
        },
        {
            "heading": "C.4 PROOF OF THEOREM 5.2",
            "text": "We first analyze a simplified case where xi = 0 if i 6= i\u2217, and otherwise xi = 1 for D and xi = 0 for D\u2032. We later give a proof for the general case. Proof of Theorem 5.2 in simplified case. Let \u03c4j,k be the value of the noisy sum \u2211 k\u00b72j+1\u2264i\u2264(k+1)\u00b72j xi + zj,k, \u03c4 = {\u03c4j,k}0\u2264j\u2264logn,0\u2264k<n/2j and let \u0398(D) be the distribution of these values under dataset D. We consider a single sensitive example; let i\u2217 be the (random) coordinate of xi\u2217 that this example contributes to.\nNow, again abusing notation to let Pr denote a likelihood, we have for any j:\nPr \u03c4\u223c\u0398(D)\n[ {\u03c4j,k}0\u2264k<n/2j = {\u03b8j\u2032,k}j\u2032>j,0\u2264k<n/2j\u2032 \u2223\u2223\u2223{\u03c4j\u2032,k}j\u2032>j,0\u2264k<n/2j\u2032 = {\u03b8j\u2032,k}j\u2032>j,0\u2264k<n/2j\u2032 ] \u221d\u2211 0\u2264k\u2217\u2264n/2j Pr \u03c4\u223c\u0398(D) [ {\u03c4j,k}0\u2264k<n/2j = {\u03b8j\u2032,k}j\u2032>j,0\u2264k<n/2j\u2032\n\u2223\u2223\u2223k\u2217 \u00b7 2j + 1 \u2264 i\u2217 \u2264 (k\u2217 + 1) \u00b7 2j] \u00b7 Pr\n\u03c4\u223c\u0398(D)\n[ k\u2217 \u00b7 2j + 1 \u2264 i\u2217 \u2264 (k\u2217 + 1) \u00b7 2j \u2223\u2223\u2223{\u03c4j\u2032,k}j\u2032>j,0\u2264k<n/2j\u2032 = {\u03b8j\u2032,k}j\u2032>j,0\u2264k<n/2j\u2032 ] In other words, for any j, the distribution of the j-th level of the tree, {\u03c4j,k}0\u2264k\u2264n/2j , conditioned on the higher levels of the tree, {\u03c4j\u2032,k}j\u2032>j,0\u2264k\u2264n/2j\u2032 , is the output distribution of mechanism described in Lem. 5.1, where the probabilities are\npj,k := Pr \u03c4\u223c\u0398(D)\n[ k \u00b7 2j + 1 \u2264 i\u2217 \u2264 (k + 1) \u00b7 2j \u2223\u2223\u2223{\u03c4j\u2032,k}j\u2032>j,0\u2264k<n/2j\u2032 = {\u03b8j\u2032,k}j\u2032>j,0\u2264k<n/2j\u2032 ] . We now show a high probability bound on each of these probabilities. We have:\nPr \u03c4\u223c\u0398(D)\n[ k \u00b7 2j + 1 \u2264 i\u2217 \u2264 (k + 1) \u00b7 2j \u2223\u2223\u2223{\u03c4j\u2032,k}j\u2032>j,0\u2264k<n/2j\u2032 = {\u03b8j\u2032,k}j\u2032>j,0\u2264k<n/2j\u2032 ]\n=\n\u2211(k+1)\u00b72j i=k\u00b72j+1 Pr\u03c4\u223c\u0398(D) [ {\u03c4j\u2032,k}j\u2032>j,0\u2264k<n/2j\u2032 = {\u03b8j\u2032,k}j\u2032>j,0\u2264k<n/2j\u2032 \u2223\u2223\u2223i\u2217 = i]\u2211n i=1 Pr\u03c4\u223c\u0398(D) [ {\u03c4j\u2032,k}j\u2032>j,0\u2264k<n/2j\u2032 = {\u03b8j\u2032,k}j\u2032>j,0\u2264k<n/2j\u2032 \u2223\u2223\u2223i\u2217 = i]\n=\n\u2211(k+1)\u00b72j i=k\u00b72j+1 \u220f j\u2032>j,0\u2264k<n/2j\u2032 exp ( \u2212 ( \u03c4j\u2032,k\u22121(k\u00b72 j\u2032+1\u2264i\u2217\u2264(k+1)\u00b72j \u2032 ) )2 2\u03c32 ) \u2211n i=1 \u220f j\u2032>j,0\u2264k<n/2j\u2032 exp ( \u2212 (\u03c4j\u2032,k\u22121(k\u00b72 j\u2032+1\u2264i\u2217\u2264(k+1)\u00b72j\u2032 )) 2 2\u03c32 )\n=\n\u2211(k+1)\u00b72j i=k\u00b72j+1 \u220f j,k:k\u00b72j\u2032+1\u2264i\u2264(k+1)\u00b72j\u2032 exp ( \u2212 \u03c4j\u2032,k\u03c32 )\u2211n i=1 \u220f j,k:k\u00b72j\u2032+1\u2264i\u2264(k+1)\u00b72j\u2032 exp ( \u2212 \u03c4j\u2032,k\u03c32\n) \u2264 2 j\nn \u00b7\nmaxi\u2208[n] \u220f j,k:k\u00b72j\u2032+1\u2264i\u2264(k+1)\u00b72j\u2032 exp ( \u2212 \u03c4j\u2032,k\u03c32 ) mini\u2208[n] \u220f j,k:k\u00b72j\u2032+1\u2264i\u2264(k+1)\u00b72j\u2032 exp ( \u2212 \u03c4j\u2032,k\u03c32\n) \u2264 2 j\nn \u00b7 exp\n( (log n\u2212 j) maxj\u2032,k \u03c4j\u2032,k \u2212minj\u2032,k \u03c4j\u2032,k\n\u03c32\n) .\nWith probability 1 \u2212 \u03b4/2, by a union bound for all 2n pairs j, k we have |\u03c4j,k| \u2264 \u221a\n2 ln(4n/\u03b4)\u03c3, so the above bound is at most:\n2j n \u00b7 exp\n( (log n\u2212 j)2 \u221a 2 ln(4n/\u03b4)\n\u03c3\n) .\nIf \u03c3 \u2265 4 \u221a 2 ln(4n/\u03b4)\nln 2 in turn this is at most:\n2j n \u00b7 \u221a 2 logn\u2212j =\n\u221a 2j\nn .\nNow, by Theorem C.2 and Observation 3.2 it suffices to show that conditioned on this probability 1 \u2212 \u03b4/2 event, the binary tree mechanism satisfies ( O (\u221a log(1/\u03b4) log log(1/\u03b4)\n\u03c3\n) , \u03b4/2 ) -DP. For log n \u2212\n16e log log(16n/\u03b4) \u2264 j \u2264 log n, releasing \u03c4j,k satisfies ( O (\u221a log(1/\u03b4) log log(n/\u03b4)\n\u03c3\n) , \u03b4/4 ) -DP by the\nanalysis of the (unamplified) Gaussian mechanism. For levels 0 \u2264 j < log n \u2212 16e log log(16n/\u03b4), our upper bound on the conditional probabilities and Lem. 5.1 with \u03b40 = \u03b4/8n\u2032 log n shows that, conditioned on the high-probability event, the distribution of the privacy loss of outputting {\u03c4j,k}k conditioned on levels\nj\u2032 > j satisfies ( O (\u221a ln(n\u2032/\u03b4) ln(1/\u03b4)\n\u03c3 \u221a n\u2032\n) , \u03b4/4 log n ) -DP, with n\u2032 = \u2308\u221a n 2j \u2309 . By basic composition, the\noverall privacy loss distribution conditioned on the 1\u2212 \u03b4/2 probability event satisfies:\nO(\u221alog(1/\u03b4) log log(1/\u03b4) \u03c3 ) +O  0\u2211 j=logn\u221216e log log(16n/\u03b4) + 2j/4 ln(1/\u03b4) \u03c3n1/4  , \u03b4/2  -DP.\nHere we use the upper bound on \u03b4 which is equivalent to log(n/\u03b4) = O(log(1/\u03b4)). We conclude by bounding the sum as:\n0\u2211 j=logn\u221216e log log(16n/\u03b4) + 2j/4 ln(1/\u03b4) \u03c3n1/4\n\u2264 logn\u221216e log log(16n/\u03b4)\u2211\nl=0\n+ ln(1/\u03b4) \u03c32l/4 \u221a ln(1/\u03b4) =\n\u221a ln(1/\u03b4)\n\u03c3\nlogn\u221216e log log(16n/\u03b4)\u2211 l=0 1 2l/4 =\n\u221a ln(1/\u03b4)\n\u03c3(1\u2212 2\u22121/4) .\nWe now discuss how to extend the proof to a more general case. In other words, we choose some y with each row having 2-norm at most 1 for D, and then set y\u2032 for D\u2032 to be y with the first row zeroed out. Then, x is chosen by shuffling the rows of y or y\u2032.\nLemma C.4. Under the above setup, for some k that divides n, consider the mechanism that chooses a random size k equipartition of [n], P = (S1, S2, . . . Sk) of [n] according to some distribution and outputs (\u03b81, \u03b82, . . . , \u03b8k), \u03b8i \u223c N( \u2211 j\u2208Si yi, \u03c3\n2). Suppose for any two equipartitions P, P \u2032, the probability of choosing P is at most c times the probability of choosing P \u2032, and let n\u2032 = bk/cc.\nThen, for any \u03b4 \u2265 2e\u2212 n \u2032 16e , \u03b40 \u2265 0, if \u03c3 = \u2126( \u221a\nln(1/\u03b40)) then this mechanism satisfies( O (\u221a ln(1/\u03b40) ln(1/\u03b4)\n\u03c3 \u221a n\u2032\n) , \u03b4 + n\u2032\u03b40 ) -DP.\nProof. Recall that y1 is the example differing between D and D\u2032. By post-processing and quasi-convexity, we can instead analyze the mechanism that for each Si, also publishes all but one element in Si, and specifically for the Si including 1 (the sensitive element), the element of Si not published must be 1. This is equivalent to saying: without loss of generality we can assume n = k.\nNext, the assumption on the distribution over P implies that the distribution is in the convex hull of distributions over P that deterministically choose k \u2212 n\u2032 elements of P , with 1 being one of these n\u2032 unchosen elements, and then uniformly shuffle the remaining n\u2032 elements. In terms of privacy guarantees, each individual mechanism using one of these distributions is equivalent to n\u2032 Gaussian mechanisms on shuffled elements. Then, by quasi-convexity, the privacy guarantees of this mechanism are no worse than those of a Gaussian mechanism over n\u2032 shuffled elements. We conclude using the analysis of amplification by shuffling in (Feldman et al., 2022).\nNext, we use the following black-box reduction from (\u03b5, \u03b4)-DP guarantees to high-probability privacy loss bounds: Lemma C.5 ((Kasiviswanathan & Smith, 2014)). If a mechanism satisfies (\u03b5, \u03b4)-DP, then the probability the privacy loss of its output exceeds 2\u03b5 is at most \u03b4\u03b5e\u03b5 .\nNow, the high-level idea is that the (\u03b5, \u03b4)-DP guarantee on outputting levels j\u2032 > j implies a high-probability bound on the privacy loss of outputting these levels via Lem. C.5, which in turn implies a bound on c in Lem. C.4 if we use the posterior distribution over shuffles as the distribution in that lemma. Then, we can use Lem. C.4 to get an (\u03b5, \u03b4)-DP guarantee for round j conditioned on the previous rounds, and as before the resulting \u03b5 per level decays geometrically and we can use basic composition.\nProof of Theorem 5.2. By the upper bound on \u03b4, log(poly (n) /\u03b4) = O(log(1/\u03b4)). So, for any constant c1 and another constant c2 depending on c1, releasing levels log n \u2212 c1 log log 1/\u03b4 to log n satisfies( c2 \u221a log(1/\u03b4) log log(1/\u03b4)\n\u03c3 , \u03b4/n 2\n) -DP by analysis of the Gaussian mechanism.\nNow, we will show by induction that releasing levels j to log n, j \u2264 log n\u2212 c1 log log 1/\u03b4, satisfies (\u03b5j , \u03b4j)DP for:\n\u03b5j = c2 \u221a log(1/\u03b4) log log(1/\u03b4)\n\u03c3 + j\u2211 j\u2032=logn\u2212c1 log log(1/\u03b4) c3 log(1/\u03b4) \u03c3 \u221a 2logn\u2212j ,\n\u03b4j = \u03b4\nn2 \u00b7 j\u2211 j\u2032=logn\u2212c1 log log(1/\u03b4) (1 + 1/e)logn\u2212c1 log log(1/\u03b4)\u2212j .\nIn the inequality on \u03b5j we assume c1 is sufficiently large. The base case of j = log n \u2212 c1 log log 1/\u03b4 holds by the aforementioned analysis of the Gaussian mechanism. Now, assuming releasing levels j + 1 to log n satisfies (\u03b5j , \u03b4j)-DP, we will prove releasing levels j to log n satisfies (\u03b5j , \u03b4j)-DP. Consider the output distribution of level j, conditioned on the event that the privacy loss of releasing levels j + 1 to log n is at most 1. The privacy loss being at most 1 implies that conditioned on levels j+1 to log n\u2019s output, no shuffle is more than e times as likely as any other shuffle, and thus the same is true for equipartitions of the data into\nthe sums in level j. Then by Lem. C.4, level j satisfies, say, ( c3 \u221a log2(1/\u03b4)\n\u03c3 \u221a 2log n\u2212j , \u03b4/n2)-DP for some sufficiently large constant c3, assuming c1 is sufficiently large and \u03c3 \u2265 c4 \u221a\nlog(1/\u03b4) log log(1/\u03b4) for a sufficiently large constant c4. We have\n\u03b5j+1 \u2264 c2 \u221a log(1/\u03b4) log log(1/\u03b4) + 4c3 \u221a log(1/\u03b4)\n\u03c3 So \u03b5j < 1/2 for all j, again assuming \u03c3 \u2265 c4 \u221a\nlog(1/\u03b4) log log(1/\u03b4) for sufficiently large c4, by Lem. C.5 this event happens with probability at least 1 \u2212 \u03b4j+1/e. Then assuming releasing levels j + 1 to log n satisfies (\u03b5j+1, \u03b4j+1)-DP by Thm. 4.3 and basic composition, we have proven releasing levels j to log n satisfies (\u03b5j , \u03b4j)-DP for\n\u03b5j = \u03b5j+1 + c3 log(1/\u03b4)\n\u03c3 \u221a 2logn\u2212j , \u03b4j = \u03b4j+1(1 + 1/e) + \u03b4/n 2.\nThe claimed non-recursively defined values for \u03b5j , \u03b4j follow by unrolling the above recursive formula and plugging in the base case j = log n \u2212 c1 log log 1/\u03b4. Now, the full binary tree mechanism with shuffling satisfies (\u03b50, \u03b40)-DP for \u03b50 = O (\u221a log(1/\u03b4) log log(1/\u03b4)\n\u03c3\n) , \u03b40 \u2264 \u03b4 as desired. (Note that the between the\nconstants c1, c2, c3, c4 there are no circular dependencies, i.e. there does exist a set of constants satisfying the assumptions in the proof.)\nD EXTENDING MMCC TO \u201cb-MIN-SEP SAMPLING\u201d\n(Choquette-Choo et al., 2023a) analyzed the b-banded matrix mechanism under the following scheme, which we\u2019ll call \u201cb-min-sep sampling\u201d: We partition the dataset D into b equal-size subsets, D1, D2, . . . Db. To compute xi, we use independently include each element of Di (mod b) (where we say i (mod b) = b if b divides i) with probability bp; here, we write the sampling probability in these rounds as bp instead of p to reflect the fact that the average example still participates in fraction p of rounds in expectation for any choice of b.\nWe give a generalization of MMCC that analyzes the matrix mechanism under b-min-sep sampling, that matches the analysis of (Choquette-Choo et al., 2023a) when C is b-banded but can generalize to arbitrary lower triangular matrices. In other words, this generalization of MMCC subsumes the analysis in (ChoquetteChoo et al., 2023a).\nNote that if we want to analyze the privacy guarantee for an example inDi, i\u22121, this is the same as analyzing the privacy guarantee for an example in D1, if we use C with the first i \u2212 1 rows/columns cut off. Then, without loss of generality we only need to state a privacy analysis for examples in D1 - to get a privacy guarantee that holds for all examples simultaneously, for each Di we can compute a privacy guarantee using the above reduction, and then take the worst of these. Further, for some classes of matrices, such as Toeplitz matrices, the examples in D1 will have the worst privacy guarantee and thus it suffices to only analyze these examples.\nWe now show Generalized-MMCC, given in Fig. 6, computes a valid privacy guarantee under b-min-sep sampling.\nTheorem D.1. Let \u03b5 be the output of Generalized-MMCC. Then the matrix mechanism with matrix C, b-min-sep sampling, sampling probability p, noise level \u03c3 satisfies (\u03b5, \u03b41 + \u03b42)-DP (for examples in D1).\nAlgorithm 3 Generalized-MMCC 1: Input: Matrix C, sampling probability p, noise standard deviation \u03c3, probabilities \u03b41, \u03b42, min-sep b. 2: Delete all columns of C except columns 1, b+ 1, 2b+ 1 . . . 3: {p\u0303i,j}i\u2208[n],j\u2208[dn/be \u2190GeneralizedProbabilityTailBounds(C, bp, \u03c3, b\u03b41). . p\u0303i,j is a high-probability upper bound on the probability that an example participated in round j, conditioned on output in rounds 1 to i\u2212 1.\nAlgorithm 4 GeneralizedProbabilityTailBounds(C, p, \u03c3, \u03b41)\n1: Input: Matrix C \u2208 Rm\u00d7n, sampling probability p, noise standard deviation \u03c3, probability \u03b41. 2: \u03b4\u2032 = \u03b412\u00b7(nnz(C)\u2212n) . nnz is the number of non-zeros. 3: z = \u03a6\u22121(1\u2212 \u03b4\u2032) . Tail bound on normal distribution; here, \u03a6 is the standard normal CDF. 4: for i \u2208 [m], j \u2208 [n] do 5: if Ci,j = 0 then 6: p\u0303i,j = 1 7: else 8: si,j = minimum s s.t. Pr[ \u2211 j\u2032\u2264i xj\u2032\u3008C1:i\u22121,j ,C1:i\u22121,j\u2032\u3009 > s] \u2264 \u03b4\u2032, xj\u2032\ni.i.d.\u223c Bern(p) . si,j is a tail bound on the dot product of first i\u2212 1 entries of Cx and C1:i\u22121,j .\n9: \u03b5i,j = z\u2016C1:i\u22121,j\u20162 \u03c3 + 2si,j\u2212\u2016C1:i\u22121,j\u201622 2\u03c32\n. \u03b5i,j is a tail bound on the privacy loss of a participation in round j after outputting first i\u2212 1 rounds 10: p\u0303i,j =\np\u00b7exp(\u03b5i,j) p\u00b7exp(\u03b5i,j)+(1\u2212p)\n11: return {p\u0303i,j}i\u2208[m],j\u2208[n].\nFigure 7: Generalization of ProbabilityTailBounds.\nProof. The algorithm is almost the same as Thm. 4.3, so we just need to justify the key differences. In particular, we need to justify (1) the deletion of columns, (2) the choice of p\u0303(b)i,j , and (3) the choice of C (b).\n(1) is justified by the proof of Theorem 4 in (Choquette-Choo et al., 2023a), which observes that the products of columns j of C for which j (mod b) 6= 1 and the corresponding rows of x are independent of D1, i.e. we can treat their products as public information. So it does not affect the privacy analysis to delete these rows/columns from C/x, and then view the resulting x as generated by i.i.d sampling every round with probability bp.\n(2) and (3) are both justified if we use conditional composition over sequential mechanisms corresponding to b rows of Cx + z instead of a single row. Each of these sequential mechanisms is a VMoG mechanism, which Cor. B.6 allows us to reduce to the scalar PMoG mechanism defined in terms of C(b) in Generalized-MMCC. The probabilities p\u0303(b) are then valid to use in the conditional composition by the same argument as in Thm. 4.3, up to the adjustment to use b\u03b41 instead of \u03b41. This adjustment is valid, since we only use fraction 1/b of the values generated by GeneralizedProbabilityTailBounds, i.e. we are union bounding over 1/b as many \u201cbad\u201d events as in the original proof, so we can increase the allowed probability for each \u201cbad\u201d events by b (which is implicitly done by increasing \u03b41 by b).\nOne can verify that (i) for b = 1, Generalized-MMCC is equivalent to MMCC, and that (ii) if C is bbanded, Generalized-MMCC is equivalent to the privacy analysis in (Choquette-Choo et al., 2023a).\nE MORE EMPIRICAL \u03b5 COMPUTATIONS\n(Fichtenberger et al., 2023; Henzinger et al., 2023) showed that a post-processing of the matrix mechanism using the following lower-triangular matrix achieves 1 + o(1) times the optimal `22 error for prefix sums (without amplification): Ci,j = f(i\u2212 j), where f is defined as\nf(k) =  0, for k < 01, for k = 0f(k \u2212 1) \u00b7 (1\u2212 12k) , for k > 0 . Similarly to the binary tree mechanism, we will consider the unamplified single-participation setting as a baseline. In this case, the sensitivity of this matrix mechanism is \u2016Ce1\u20162, i.e. the `2-norm of the first column of C. So again, setting \u03c3 = c \u2016Ce1\u20162 results in a fixed \u03b5 for a fixed \u03b4. Our comparison will be applying the same matrix mechanism with subsampling probability 1/n and the same choice of \u03c3.\nIn Fig. 8, we reproduce the plots in Fig. 2 but for this matrix mechanism instead of the binary tree mechanism. The `2-norm of the columns of this matrix asymptotically are \u0398( \u221a log n); because of this, and to make a direct comparison to the binary tree mechanism easier, we use \u221a\nlog(n) + 1 as the x-axis and plot the least squares linear regression. Because the columns of this matrix are less orthogonal than those of the matrix for the binary tree mechanism, there is less benefit from amplification in this setting than the binary tree mechanism setting, so we use a larger range of values c \u2208 {10, 20, 40} for the noise multiplier to better demonstrate the behavior of the improvement in \u03b5. For sufficiently large \u03c3, the improvement in \u03b5 due to the amplification analysis is again roughly proportional to \u221a\nlog(n) + 1. For the same reasons as for the binary tree mechanism, the fit of the linear regression is better as \u03c3 increases: here, because the columns of this matrix are less orthogonal on average, a larger value of c is needed for the fit to improve. Here, the constant multiplier in the improvement is smaller; this makes sense as these matrices improve on the error of the binary tree mechanism by a constant, and thus the amount by which we can improve the privacy analysis of this matrix mechanism without violating lower bounds is smaller than for the binary tree mechanism.\nF IMPLEMENTATION DETAILS\nTo implement the MMCC algorithm, we use the open-source Python library dp accounting.pld8. We extend the class dp accounting.pld.pld mechanism.AdditiveNoisePrivacyLoss to create a class, MixtureGaussianPrivacyLoss that represents the privacy loss distribution of MMoG, which can be used along with other tools in the dp accounting.pld library to implement MMCC. We discuss our implementation and some challenges here. The dp accounting.pld library uses the convention that privacy losses are decreasing; we use the same convention in the discussions in this section for consistency. Our implementation is currently open-sourced as part of the dp accounting library, and PLD accounting for MoG mechanisms can be done using dp accounting.pld.PLDAccountant and dp accounting.dp event.MixtureOfGaussiansDpEvent.\nF.1 EXTENDING ADDITIVENOISEPRIVACYLOSS\nIn order to perform all the necessary computations in MMCC, we need to implement the following methods in MixtureGaussianPrivacyLoss:\n1. A method to compute the CDF of the mixture of Gaussians distribution. 2. A method to compute the privacy loss at x. 3. An inverse privacy loss method, i.e. a method which takes \u03b5 and computes the smallest x achieving\nthis \u03b5.\nGiven the probabilities and sensitivities {p1, p2, . . . , pk} and {c1, c2, . . . , ck}, as well as \u03c3, the first two can easily be done by just summing the PDFs/CDFs of the Gaussians in the mixture. This takes at most O(k) times the runtime of the corresponding method for the (subsampled) Gaussian mechanism.\nThe third is more problematic. For the subsampled Gaussian mechanism with sampling probability p and sensitivity 1, the privacy loss function (under the remove adjacency) is:\nln ( p exp ( \u22122x\u2212 1\n2\u03c32\n) + 1\u2212 p ) .\n8https://github.com/google/differential-privacy/tree/main/python/dp_ accounting/dp_accounting\nThis function is easily invertible. However, if we considerMMoG({p, 1\u2212 p}, {c1, c2}), the privacy loss at x is:\nln ( p exp ( \u22122c1x\u2212 c21\n2\u03c32\n) + (1\u2212 p) exp ( \u22122c2x\u2212 c22\n2\u03c32\n)) .\nBecause this function includes the sum of two exponential functions of x, it is not easy to invert. We instead use binary search to get the smallest multiple of \u22061 which achieves the desired privacy loss, where \u22061 is a parameter we choose that trades off between efficiency and accuracy. That is, if L is the privacy loss function, and we want to compute the inverse privacy loss of y, we return x = dL\u22121(y)/\u22061e \u00b7\u22061. Note that by overestimating x, we also overestimate the privacy loss since we assume the privacy loss is decreasing. Hence this approximation is \u201cpessimistic,\u201d i.e. does not cause us to report an (\u03b5, \u03b4)-DP guarantee that is not actually satisfied byMMoG. Note that using binary search requires aO(log(1/\u22061)) multiplicative dependence on \u22061, that is not incurred for e.g. the subsampled Gaussian for which we can quickly compute the exact inverse privacy loss. Indeed, we observed that this inverse privacy loss method is the bottleneck for our implementation."
        },
        {
            "heading": "F.2 EFFICIENTLY REPRESENTING PMOG AS MOG",
            "text": "As discussed in the previous section, the runtime of our implementation has a linear dependence on the number of components in the MoG. However, in MMCC, we are actually using PMoGs, which are MoGs with potentially 2n components. So, even just listing the components can be prohibitively expensive.\nWe instead choose another approximation parameter \u22062, and round each entry of C up to the nearest multiple of \u22062. By Lemma B.4, this only worsens the privacy guarantee, i.e. any privacy guarantee we prove for the rounded version of C also applies to the original C. After this rounding, the number of components in any MoG we compute the PLD of is at most dmaxi\n\u2225\u2225e>i C\u2225\u22251e/\u22062 +n (maxi \u2225\u2225e>i C\u2225\u22251 is the maximum row norm of C). Furthermore, we can compute the probabilities/sensitivities efficiently since we are working with PMoGs. In particular, for each p\u0303i,j ,Ci,j pair, we can construct the probability mass function (PMF) of the random variable that is Ci,j w.p. p\u0303i,j and 0 otherwise, and then take the convolution of all such PMFs for a row to get the PMF of the discretized sensitivity for the PMoG. For each row, this can be done in at most n \u2212 1 convolutions, each convolution between two PMFs that have support size at most 2 and maxid\n\u2225\u2225e>i C\u2225\u22251 /\u22062e + n. So the convolutions can be done in time O(maxid\u2225\u2225e>i C\u2225\u22251 /\u22062e + n), i.e. our overall runtime is O(n2 maxid\n\u2225\u2225e>i C\u2225\u22251 /\u22062e + n3), i.e. polynomial instead of exponential in n if e.g. all entries of C are bounded by a constant. By doing the convolutions in a divide-and-conquer fashion, and using FFT for the convolutions, we can further improve the runtime to O\u0303(nmaxid\n\u2225\u2225e>i C\u2225\u22251 /\u22062e+n2), i.e. nearly linear in the input size and 1/\u22062 if the entries of C are bounded by a constant.\nF.3 COMPUTING si,j\nSimilar to computing the probabilities and sensitivities for the PMoGs, any overestimate of si,j can be used in place of si,j to get a valid privacy guarantee from MMCC by Lemma B.3. Since si,j only appears in a lower order term in the definition of \u03b5i,j , a weaker tail bound will not affect the privacy guarantee as much. So, in our implementation, we use the following simple and efficient approximation: We use the binomial CDF to obtain an exact tail bound t on \u2016x1:i\u20161 = \u2211 j\u2032\u2264i xj\u2032 in the definition of si,j . We then take the sum of the t largest values of \u3008C1:i\u22121,j ,C1:i\u22121,j\u2032\u3009 to be our overestimate of si,j ."
        },
        {
            "heading": "F.4 COMPUTING ALL ROW PLDS",
            "text": "Putting this all together, we must compute n PLDs in MMCC, one for each row of C. Though only an O(n) overhead in runtime over computing a single PLD, this O(n) overhead is undesirable as each PLD computation is already quite expensive due to the aforementioned difficulties. However, this component is embarrassingly parallel, which we leverage to massively speed up runtimes.\nNote that for some special classes of matrices, we will have that multiple rows share the same PLD, which also allows us to dramatically speed up the calculation even without parallelization. For example, this is the case for the binary tree mechanism due to symmetry, as well for as b-banded Toeplitz C due to the fact that rows 2b\u2212 1 to n of p\u0303 and C are the same (up to an offset in indices that doesn\u2019t affect the PLD)."
        },
        {
            "heading": "F.5 APPLICATIONS BEYOND MATRIX MECHANISMS",
            "text": "We believe that MoG mechanisms/MixtureGaussianPrivacyLoss are useful analytic tools for privacy analysis of mechanisms beyond the matrix mechanism. We discuss two examples here.\nPrivacy amplification via iteration on linear losses: Consider running DP-SGD with sampled minibatches. To get a (\u03b5, \u03b4)-DP guarantee, we can compute the PLD for the subsampled Gaussian mechanism, and then compose this PLD with itself n times. For general non-convex losses, this accounting scheme is tight, even if we only release the last iterate.\nFor linear losses, we can give a better privacy guarantee for releasing only the last iterate, similarly to (Feldman et al., 2018): Releasing the last iterate is equivalent in terms of privacy guarantees to a Gaussian mechanism with random sensitivityBinom(n, p) and variance n\u03c32. Using MixtureGaussianPrivacyLoss we can get tight (\u03b5, \u03b4)-DP guarantees for this mechanism. Empirically, we found that these can be a lot tighter than composition of subsampled Gaussians. For example, using n = 128, p = 1/128, \u03c3 = 1 we found that composition of subsampled Gaussians gives a proof of (.806, 10\u22126)-DP, whereas analyzing the last iterate as a MoG mechanism gives a proof of (.291, 10\u22126)-DP. We conjecture a similar improvement is possible for all convex losses, rather than linear losses.\nTight group privacy guarantees for DP-SGD: Consider analyzing the privacy guarantees of DP-SGD under group privacy. That is, we want to give a privacy guarantee for pairs of databases differing in k > 1 examples. One way of doing this is to compute a DP guarantee for k = 1, then use an exampleto-group privacy theorem such as that of (Vadhan, 2017), which shows an (\u03b5, \u03b4)-DP mechanism satisfies (k\u03b5, k exp(k\u03b5)\u03b4)-DP for groups of size k. This is overly pessimistic, since the black-box theorem doesn\u2019t account for the specific structure of the mechanism. We can instead get relatively tight guarantees via MixtureGaussianPrivacyLoss: If each example is sampled independently, then the privacy loss of a group of k examples in each round of DP-SGD is dominated by a Gaussian mechanism with sensitivity Binom(k, p). Then, we can use MixtureGaussianPrivacyLoss to analyze the composition of n of these MoG mechanisms. Further, note that e.g. in the case where we instead sample a random batch of size B in each round (i.e. different examples\u2019 participations within the same round are no longer independent), we can still use MixtureGaussianPrivacyLoss to get a tight analysis by adjusting the sensitivity random variable used. See the follow-up note (Ganesh, 2024) for more details."
        }
    ],
    "title": "PRIVACY AMPLIFICATION FOR MATRIX MECHANISMS",
    "year": 2024
}