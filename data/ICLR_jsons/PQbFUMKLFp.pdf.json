{
    "abstractText": "The conjugate gradient method is a crucial first-order optimization method that generally converges faster than the steepest descent method, and its computational cost is much lower than that of second-order methods. However, while various types of conjugate gradient methods have been studied in Euclidean spaces and on Riemannian manifolds, there is little study for those in distributed scenarios. This paper proposes a decentralized Riemannian conjugate gradient descent (DRCGD) method that aims at minimizing a global function over the Stiefel manifold. The optimization problem is distributed among a network of agents, where each agent is associated with a local function, and the communication between agents occurs over an undirected connected graph. Since the Stiefel manifold is a non-convex set, a global function is represented as a finite sum of possibly non-convex (but smooth) local functions. The proposed method is free from expensive Riemannian geometric operations such as retractions, exponential maps, and vector transports, thereby reducing the computational complexity required by each agent. To the best of our knowledge, DRCGD is the first decentralized Riemannian conjugate gradient algorithm to achieve global convergence over the Stiefel manifold.",
    "authors": [
        {
            "affiliations": [],
            "name": "STIEFEL MANIFOLD"
        },
        {
            "affiliations": [],
            "name": "Jun Chen"
        },
        {
            "affiliations": [],
            "name": "Haishan Ye"
        },
        {
            "affiliations": [],
            "name": "Mengmeng Wang"
        },
        {
            "affiliations": [],
            "name": "Tianxin Huang"
        },
        {
            "affiliations": [],
            "name": "Guang Dai"
        },
        {
            "affiliations": [],
            "name": "Ivor W. Tsang"
        },
        {
            "affiliations": [],
            "name": "Yong Liu"
        }
    ],
    "id": "SP:38f2d1157850573c0986a6ad371c527744e9528c",
    "references": [
        {
            "authors": [
                "P-A Absil",
                "Robert Mahony",
                "Rodolphe Sepulchre"
            ],
            "title": "Optimization algorithms on matrix manifolds",
            "year": 2008
        },
        {
            "authors": [
                "Mehiddin Al-Baali"
            ],
            "title": "Descent property and global convergence of the fletcher\u2014reeves method with inexact line search",
            "venue": "IMA Journal of Numerical Analysis,",
            "year": 1985
        },
        {
            "authors": [
                "Sulaiman A Alghunaim",
                "Ernest K Ryu",
                "Kun Yuan",
                "Ali H Sayed"
            ],
            "title": "Decentralized proximal gradient algorithms with linear convergence rates",
            "venue": "IEEE Transactions on Automatic Control,",
            "year": 2020
        },
        {
            "authors": [
                "Necdet Serhat Aybat",
                "Zi Wang",
                "Tianyi Lin",
                "Shiqian Ma"
            ],
            "title": "Distributed linearized alternating direction method of multipliers for composite convex consensus optimization",
            "venue": "IEEE Transactions on Automatic Control,",
            "year": 2017
        },
        {
            "authors": [
                "MV Balashov",
                "RA Kamalov"
            ],
            "title": "The gradient projection method with armijo\u2019s step size on manifolds",
            "venue": "Computational Mathematics and Mathematical Physics,",
            "year": 2021
        },
        {
            "authors": [
                "Nicolas Boumal",
                "Pierre-Antoine Absil",
                "Coralia Cartis"
            ],
            "title": "Global rates of convergence for nonconvex optimization on manifolds",
            "venue": "IMA Journal of Numerical Analysis,",
            "year": 2019
        },
        {
            "authors": [
                "Stephen Boyd",
                "Persi Diaconis",
                "Lin Xiao"
            ],
            "title": "Fastest mixing markov chain on a graph",
            "venue": "SIAM review,",
            "year": 2004
        },
        {
            "authors": [
                "Shixiang Chen",
                "Alfredo Garcia",
                "Mingyi Hong",
                "Shahin Shahrampour"
            ],
            "title": "Decentralized riemannian gradient descent on the stiefel manifold",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Francis H Clarke",
                "Ronald J Stern",
                "Peter R Wolenski"
            ],
            "title": "Proximal smoothness and the lower-c2 property",
            "venue": "J. Convex Anal,",
            "year": 1995
        },
        {
            "authors": [
                "Yu-Hong Dai",
                "Yaxiang Yuan"
            ],
            "title": "A nonlinear conjugate gradient method with a strong global convergence property",
            "venue": "SIAM Journal on optimization,",
            "year": 1999
        },
        {
            "authors": [
                "Kangkang Deng",
                "Jiang Hu"
            ],
            "title": "Decentralized projected riemannian gradient method for smooth optimization on compact submanifolds",
            "venue": "arXiv preprint arXiv:2304.08241,",
            "year": 2023
        },
        {
            "authors": [
                "Persi Diaconis",
                "Daniel Stroock"
            ],
            "title": "Geometric bounds for eigenvalues of markov chains",
            "venue": "The annals of applied probability,",
            "year": 1991
        },
        {
            "authors": [
                "Alan Edelman",
                "Steven T Smith"
            ],
            "title": "On conjugate gradient-like methods for eigen-like problems",
            "venue": "BIT Numerical Mathematics,",
            "year": 1996
        },
        {
            "authors": [
                "Alan Edelman",
                "Tom\u00e1s A Arias",
                "Steven T Smith"
            ],
            "title": "The geometry of algorithms with orthogonality constraints",
            "venue": "SIAM journal on Matrix Analysis and Applications,",
            "year": 1998
        },
        {
            "authors": [
                "Sukru Burc Eryilmaz",
                "Aysegul Dundar"
            ],
            "title": "Understanding how orthogonality of parameters improves quantization of neural networks",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Reeves Fletcher",
                "Colin M Reeves"
            ],
            "title": "Function minimization by conjugate gradients",
            "venue": "The computer journal,",
            "year": 1964
        },
        {
            "authors": [
                "Roger Fletcher"
            ],
            "title": "Practical methods of optimization",
            "year": 2000
        },
        {
            "authors": [
                "Magnus R Hestenes",
                "Eduard Stiefel"
            ],
            "title": "Methods of conjugate gradients for solving linear systems",
            "venue": "Journal of research of the National Bureau of Standards,",
            "year": 1952
        },
        {
            "authors": [
                "Lei Huang",
                "Xianglong Liu",
                "Bo Lang",
                "Adams Yu",
                "Yongliang Wang",
                "Bo Li"
            ],
            "title": "Orthogonal weight normalization: Solution to optimization over multiple dependent stiefel manifolds in deep neural networks",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "Yann LeCun"
            ],
            "title": "The mnist database of handwritten digits. http://yann",
            "venue": "lecun. com/exdb/mnist/,",
            "year": 1998
        },
        {
            "authors": [
                "Y Liu",
                "C Storey"
            ],
            "title": "Efficient generalized conjugate gradient algorithms, part 1: theory",
            "venue": "Journal of optimization theory and applications,",
            "year": 1991
        },
        {
            "authors": [
                "Angelia Nedic",
                "Asuman Ozdaglar"
            ],
            "title": "Distributed subgradient methods for multi-agent optimization",
            "venue": "IEEE Transactions on Automatic Control,",
            "year": 2009
        },
        {
            "authors": [
                "Angelia Nedic",
                "Asuman Ozdaglar",
                "Pablo A Parrilo"
            ],
            "title": "Constrained consensus and optimization in multi-agent networks",
            "venue": "IEEE Transactions on Automatic Control,",
            "year": 2010
        },
        {
            "authors": [
                "Angelia Nedi\u0107",
                "Alex Olshevsky",
                "Michael G Rabbat"
            ],
            "title": "Network topology and communicationcomputation tradeoffs in decentralized optimization",
            "venue": "Proceedings of the IEEE,",
            "year": 2018
        },
        {
            "authors": [
                "Y Nesterov"
            ],
            "title": "Introductory Lectures on Convex Optimization: A Basic Course, volume 87",
            "venue": "Springer Science & Business Media,",
            "year": 2013
        },
        {
            "authors": [
                "Elijah Polak",
                "Gerard"
            ],
            "title": "Ribiere. Note sur la convergence de m\u00e9thodes de directions conjugu\u00e9es",
            "venue": "Revue franc\u0327aise d\u2019informatique et de recherche ope\u0301rationnelle. Se\u0301rie rouge,",
            "year": 1969
        },
        {
            "authors": [
                "Boris Teodorovich Polyak"
            ],
            "title": "The conjugate gradient method in extremal problems",
            "venue": "USSR Computational Mathematics and Mathematical Physics,",
            "year": 1969
        },
        {
            "authors": [
                "Guannan Qu",
                "Na Li"
            ],
            "title": "Harnessing smoothness to accelerate distributed optimization",
            "venue": "IEEE Transactions on Control of Network Systems,",
            "year": 2017
        },
        {
            "authors": [
                "Haroon Raja",
                "Waheed U Bajwa"
            ],
            "title": "Cloud k-svd: A collaborative dictionary learning algorithm for big, distributed data",
            "venue": "IEEE Transactions on Signal Processing,",
            "year": 2015
        },
        {
            "authors": [
                "Wolfgang Ring",
                "Benedikt Wirth"
            ],
            "title": "Optimization methods on riemannian manifolds and their application to shape space",
            "venue": "SIAM Journal on Optimization,",
            "year": 2012
        },
        {
            "authors": [
                "Hiroyuki Sakai",
                "Hideaki Iiduka"
            ],
            "title": "Hybrid riemannian conjugate gradient methods with global convergence properties",
            "venue": "Computational Optimization and Applications,",
            "year": 2020
        },
        {
            "authors": [
                "Hiroyuki Sakai",
                "Hideaki Iiduka"
            ],
            "title": "Sufficient descent riemannian conjugate gradient methods",
            "venue": "Journal of Optimization Theory and Applications,",
            "year": 2021
        },
        {
            "authors": [
                "Alain Sarlette",
                "Rodolphe Sepulchre"
            ],
            "title": "Consensus optimization on manifolds",
            "venue": "SIAM journal on Control and Optimization,",
            "year": 2009
        },
        {
            "authors": [
                "Hiroyuki Sato"
            ],
            "title": "Riemannian optimization and its applications, volume 670",
            "year": 2021
        },
        {
            "authors": [
                "Hiroyuki Sato"
            ],
            "title": "Riemannian conjugate gradient methods: General framework and specific algorithms with convergence analyses",
            "venue": "SIAM Journal on Optimization,",
            "year": 2022
        },
        {
            "authors": [
                "Hiroyuki Sato",
                "Toshihiro Iwai"
            ],
            "title": "A new, globally convergent riemannian conjugate gradient method",
            "year": 2015
        },
        {
            "authors": [
                "Suhail M Shah"
            ],
            "title": "Distributed optimization on riemannian manifolds for multi-agent networks",
            "venue": "arXiv preprint arXiv:1711.11196,",
            "year": 2017
        },
        {
            "authors": [
                "Wei Shi",
                "Qing Ling",
                "Kun Yuan",
                "Gang Wu",
                "Wotao Yin"
            ],
            "title": "On the linear convergence of the admm in decentralized consensus optimization",
            "venue": "IEEE Transactions on Signal Processing,",
            "year": 2014
        },
        {
            "authors": [
                "Wei Shi",
                "Qing Ling",
                "Gang Wu",
                "Wotao Yin"
            ],
            "title": "Extra: An exact first-order algorithm for decentralized consensus optimization",
            "venue": "SIAM Journal on Optimization,",
            "year": 2015
        },
        {
            "authors": [
                "Steven Smith"
            ],
            "title": "Optimization techniques on riemannian manifolds. Hamiltonian and Gradient Flows, Algorithms and Control, pp",
            "year": 1995
        },
        {
            "authors": [
                "Eugene Vorontsov",
                "Chiheb Trabelsi",
                "Samuel Kadoury",
                "Chris Pal"
            ],
            "title": "On orthogonality and learning recurrent networks with long term dependencies",
            "venue": "In International Conference on Machine Learning,",
            "year": 2017
        },
        {
            "authors": [
                "Lei Wang",
                "Xin Liu"
            ],
            "title": "Decentralized optimization over the stiefel manifold by an approximate augmented lagrangian function",
            "venue": "IEEE Transactions on Signal Processing,",
            "year": 2022
        },
        {
            "authors": [
                "Haishan Ye",
                "Tong Zhang"
            ],
            "title": "Deepca: Decentralized exact pca with linear convergence rate",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2021
        },
        {
            "authors": [
                "Kun Yuan",
                "Qing Ling",
                "Wotao Yin"
            ],
            "title": "On the convergence of decentralized gradient descent",
            "venue": "SIAM Journal on Optimization,",
            "year": 2016
        },
        {
            "authors": [
                "Kun Yuan",
                "Bicheng Ying",
                "Xiaochuan Zhao",
                "Ali H Sayed"
            ],
            "title": "Exact diffusion for distributed optimization and learning\u2014part i: Algorithm development",
            "venue": "IEEE Transactions on Signal Processing,",
            "year": 2018
        },
        {
            "authors": [
                "Jinshan Zeng",
                "Wotao Yin"
            ],
            "title": "On nonconvex decentralized gradient descent",
            "venue": "IEEE Transactions on signal processing,",
            "year": 2018
        },
        {
            "authors": [
                "Xiaojing Zhu"
            ],
            "title": "A riemannian conjugate gradient method for optimization on the stiefel manifold",
            "venue": "Computational optimization and Applications,",
            "year": 2017
        },
        {
            "authors": [
                "Xiaojing Zhu",
                "Hiroyuki Sato"
            ],
            "title": "Riemannian conjugate gradient methods with inverse retraction",
            "venue": "Computational Optimization and Applications,",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "In large-scale systems such as machine learning, control, and signal processing, data is often stored in a distributed manner across multiple nodes and it is also difficult for a single (centralized) server to meet the growing computing needs. Therefore, the decentralized optimization has gained significant attention in recent years because it can effectively address the above two potential challenges. In this paper, we consider the following distributed smooth optimization problem over the Stiefel manifold:\nmin 1\nn n\u2211 i=1 fi (xi) ,\ns.t. x1 = \u00b7 \u00b7 \u00b7 = xn, xi \u2208 M, \u2200i = 1, 2, . . . , n, (1)\nwhere n is the number of agents, fi is the local function at each agent, and M := St(d, r) = {x \u2208 Rd\u00d7r|x\u22a4x = Ir} is the Stiefel manifold (r \u2264 d) (Zhu, 2017; Sato, 2022). Many important largescale tasks can be written as the optimization problem (1), e.g., the principle component analysis (Ye & Zhang, 2021), eigenvalue estimation (Chen et al., 2021), dictionary learning (Raja & Bajwa, 2015), and deep neural networks with orthogonal constraint (Vorontsov et al., 2017; Huang et al., 2018; Eryilmaz & Dundar, 2022).\nThe decentralized optimization has recently attracted increasing attention in Euclidean spaces. Among the methods explored, the decentralized (sub)-gradient method stands out as a straightforward way combining local gradient descent and consensus error reduction (Nedic & Ozdaglar, 2009; Yuan et al., 2016). Further, in order to converge to a stationary point (i.e., exact convergence) with\n\u2217Corresponding author\nfixed step size, various algorithms have considered the local historical information, e.g., gradient tracking algorithm (Qu & Li, 2017; Yuan et al., 2018), primal-dual framework (Alghunaim et al., 2020), EXTRA (Shi et al., 2015), and ADMM (Shi et al., 2014; Aybat et al., 2017), when each local function is convex.\nHowever, none of the above studies can solve the problem (1) since the Stiefel manifold is a nonconvex set. Based on the viewpoint of Chen et al. (2021), the Stiefel manifold is an embedded sub-manifold in Euclidean space. Thus, with the help of Riemannian optimization (i.e., optimization on Riemannian manifolds) (Absil et al., 2008; Boumal et al., 2019; Sato, 2021), the problem (1) can be thought as a constrained problem in Euclidean space. The Riemannian optimization nature brings more challenges for consensus construction design. For instance, a straightforward way is to take the average 1n \u2211n i=1 xi in Euclidean space. However, the arithmetic average does not apply to the Riemannian manifold because the arithmetic average of points can be outside of the manifold. To address this problem, Riemannian consensus method has been developed (Shah, 2017), but it needs to use an asymptotically infinite number of consensus steps for convergence. Subsequently, Wang & Liu (2022) combined the gradient tracking algorithm with an augmented Lagrangian function to achieve the single step of consensus. Recently, Chen et al. (2021) proposed a decentralized Riemannian gradient descent algorithm over the Stiefel manifold, which also requires only the finite step of consensus to achieve the convergence rate of O(1/ \u221a K). Simultaneously, the corresponding gradient tracking version was presented to reach a stationary point with the convergence rate of O(1/K). On this basis, Deng & Hu (2023) replaced retractions with projection operators, thus establishing a decentralized projected Riemannian gradient descent algorithm over the compact submanifold to achieve the convergence rate of O(1/ \u221a K). Similarly, the corresponding gradient tracking version also achieved the convergence rate of O(1/K). In this paper, we address the decentralized conjugate gradient method on Riemannian manifolds, which we refer to as the decentralized Riemannian conjugate gradient descent (DRCGD) method. In essence, the conjugate gradient method is an important first-order optimization method, which generally converges faster than the steepest descent method, and its computational cost is much lower than that of second-order methods. As well, conjugate gradient methods are highly attractive for solving large-scale optimization problems (Sato, 2022). Recently, Riemannian conjugate gradient methods have been studied, however, expensive operations such as parallel translations, vector transports, exponential maps, and retractions are required. For instance, some studies use a theoretical approach, i.e., parallel translation along the geodesics (Smith, 1995; Edelman & Smith, 1996; Edelman et al., 1998), which hinders the practical applicability. More generally, other studies utilize a vector transport (Ring & Wirth, 2012; Sato & Iwai, 2015; Zhu, 2017; Sakai & Iiduka, 2020; 2021) or inverse retraction (Zhu & Sato, 2020) to simplify the execution of each iteration of Riemannian conjugate gradient methods. Nonetheless, there is still room for computational improvements.\nThis paper focuses on designing an efficient Riemannian conjugate gradient algorithm to solve the problem (1) over any undirected connected graph. Our contributions are summarized as follows:\n1. We propose a novel decentralized Riemannian conjugate gradient descent (DRCGD) method whose global convergence is established under an extended assumption. It is the first Riemannian conjugate gradient algorithm for distributed optimization.\n2. We further develop the projection operator for search directions such that the expensive retraction and vector transport are completely replaced. Therefore, the proposed method is retraction-free and vector transport-free, and achieves the consensus of search directions, giving rise to an appealing algorithm with low computational cost.\n3. Numerical experiments are implemented to demonstrate the effectiveness of the theoretical results. The experimental results are used to compare the performance of state-of-the-art ones on eigenvalue problems."
        },
        {
            "heading": "2 PRELIMINARIES",
            "text": ""
        },
        {
            "heading": "2.1 NOTATION",
            "text": "The undirected connected graph G = (V, E), where V = {1, 2, \u00b7 \u00b7 \u00b7 , n} is the set of agents and E is the set of edges. When W is the adjacency matrix of G, we have Wij = Wji and Wij > 0 if an\nedge (i, j) \u2208 E and otherwise Wij = 0. We use x to denote the collection of all local variables xi by stacking them, i.e., x\u22a4 := (x\u22a41 , x \u22a4 2 , \u00b7 \u00b7 \u00b7 , x\u22a4n ). Then define f(x) := 1n \u2211n i=1 fi(xi). We denote the n-fold Cartesian product of M with itself as Mn = M\u00d7 \u00b7 \u00b7 \u00b7 \u00d7M, and use [n] := {1, 2, \u00b7 \u00b7 \u00b7 , n}. For any x \u2208 M, we denote the tangent space and normal space of M at x as TxM and NxM, respectively. We mark \u2225 \u00b7 \u2225 as the Euclidean norm. The Euclidean gradient of f is \u2207f(x) and the Riemannian gradient of f is grad f(x). Let Id and 1n \u2208 Rn be the d\u00d7d identity matrix and a vector of all entries one, respectively. Let Wt := W t \u2297 Id, where t is a positive integer and \u2297 denotes the Kronecker product."
        },
        {
            "heading": "2.2 RIEMANNIAN MANIFOLD",
            "text": "We define the distance of a point x \u2208 Rd\u00d7r onto M by dist(x,M) := inf\ny\u2208M \u2225y \u2212 x\u2225,\nthen, for any radius R > 0, the R-tube around M can be defined as the set: UM(R) := {x : dist(x,M) \u2264 R}. Furthermore, we define the nearest-point projection of a point x \u2208 Rd\u00d7r onto M by PM(x) := arg min\ny\u2208M \u2225y \u2212 x\u2225.\nBased on Definition 1, it should be noted that a closed set M is R-proximally smooth if the projection PM(x) is a singleton whenever dist(x,M) < R. In particular, when M is the Stiefel manifold, it is a 1-proximally smooth set (Balashov & Kamalov, 2021). And these properties will be crucial for us to demonstrate the convergence.\nDefinition 1 Clarke et al. (1995) An R-proximally smooth set M satisfies that for any real \u03b3 \u2208 (0, R), the estimate holds:\n\u2225PM(x)\u2212 PM(y)\u2225 \u2264 R\nR\u2212 \u03b3 \u2225x\u2212 y\u2225, \u2200x, y \u2208 UM(\u03b3). (2)\nTo proceed the optimization on Riemannian manifolds, we introduce a key concept called the retraction operator in Definition 2. Obviously, the exponential maps (Absil et al., 2008) also satisfies this definition, so that the retraction operator is not unique.\nDefinition 2 Absil et al. (2008) A smooth map R : TM \u2192 M is called a retraction on a smooth manifold M if the retraction of R to the tangent space TxM at any point x \u2208 M, denoted by Rx, satisfies the following conditions: (i) R is continuously differentiable. (ii) Rx(0x) = x, where 0x is the zero element of TxM. (iii) DRx(0x) = idTxM, the identity mapping on TxM.\nFurthermore, we can introduce a well-known concept called a vector transport, which as a special case of parallel translation can be explicitly formulated on the Stiefel manifold. Compared to parallel translation, a vector transport is easier and cheaper to compute (Sato, 2021). Using the Whitney sum TM\u2295 TM := {(\u03b7, \u03be)|\u03b7, \u03be \u2208 TxM, x \u2208 M}, we can define a vector transport as follows.\nDefinition 3 Absil et al. (2008) A map T : TM \u2295 TM \u2192 TM : (\u03b7, \u03be) 7\u2192 T\u03b7(\u03be) is called a vector transport on M if there exists a retraction R on M and T satisfies the following conditions for any x \u2208 M: (i) T\u03b7(\u03be) \u2208 TRx(\u03b7)M, \u03b7, \u03be \u2208 TxM. (ii) T0x(\u03be) = \u03be, \u03be \u2208 TxM. (iii) T\u03b7(a\u03be + b\u03b6) = aT\u03b7(\u03be) + bT\u03b7(\u03b6), a, b \u2208 R, \u03b7, \u03be, \u03b6 \u2208 TxM .\nExample 1 Absil et al. (2008) On a Riemannian manifold M with a retraction R, we can construct a vector transport T R : TM\u2295 TM \u2192 TM : (\u03b7, \u03be) 7\u2192 T R\u03b7 (\u03be) defined by\nT R\u03b7 (\u03be) := DRx(\u03b7)[\u03be], \u03b7, \u03be \u2208 TxM, x \u2208 M, called the differentiated retraction."
        },
        {
            "heading": "3 CONSENSUS PROBLEM ON STIEFEL MANIFOLD",
            "text": "Let x1, \u00b7 \u00b7 \u00b7 , xn \u2208 M be the local variables of each agent, we denote the Euclidean average point of x1, \u00b7 \u00b7 \u00b7 , xn by\nx\u0302 := 1\nn n\u2211 i=1 xi. (3)\nIn Euclidean space, one can use \u2211n\ni=1 \u2225xi \u2212 x\u0302\u22252 to measure the consensus error. Instead, on the Stiefel manifold St(d, r), we use the induced arithmetic mean (Sarlette & Sepulchre, 2009), defined as follows:\nx\u0304 := arg min y\u2208St(d,r) n\u2211 i=1 \u2225y \u2212 xi\u22252 = PSt(x\u0302), (4)\nwhere PSt(\u00b7) is the orthogonal projection onto St(d, r). Considering the Riemannian optimization, the Riemannian gradient of fi(x) on St(d, r), endowed with the induced Riemannian metric from the Euclidean inner product \u27e8\u00b7, \u00b7\u27e9, is given by\ngrad fi(x) = PTxM(\u2207fi(x)), (5) where PTxM(\u00b7) is the orthogonal projection onto TxM. More specifically (Edelman et al., 1998; Absil et al., 2008), for any y \u2208 Rd\u00d7r, we have\nPTxM(y) = y \u2212 1\n2 x(x\u22a4y + y\u22a4x). (6)\nSubsequently, the \u03f5-stationary point of problem (1) is given by Definition 4.\nDefinition 4 Chen et al. (2021) The set of points x\u22a4 = (x\u22a41 x\u22a42 \u00b7 \u00b7 \u00b7x\u22a4n ) is called an \u03f5-stationary point of problem (1) if the following holds:\n1\nn n\u2211 i=1 \u2225xi \u2212 x\u0304\u22252 \u2264 \u03f5 and \u2225 grad f(x\u0304)\u22252 \u2264 \u03f5, (7)\nwhere f(x\u0304) = 1n \u2211n i=1 fi(x\u0304).\nTo achieve the stationary point given in Definition 4, the consensus problem over St(d, r) needs to be considered to minimize the following quadratic loss function\nmin\u03c6t(x) := 1\n4 n\u2211 i=1 n\u2211 j=1 W tij \u2225xi \u2212 xj\u2225 2 ,\ns.t. xi \u2208 M,\u2200i \u2208 [n], (8)\nwhere the positive integer t is used to indicate the t-th power of the doubly stochastic matrix W . Note that W tij is computed through performing t steps of communication on the tangent space, and satisfies the following assumption.\nAssumption 1 We assume that the undirected graph G is connected and W is doubly stochastic, i.e., (i) W = W\u22a4; (ii) Wij \u2265 0 and 0 < Wii < 1 for all i, j; (iii) Eigenvalues of W lie in (\u22121, 1]. The second largest singular value \u03c32 of W lies in [0, 1).\nThroughout the paper, we assume that the local function fi(x) is Lipschitz smooth, which is a standard assumption in theoretical analysis of the optimization problem (Jorge & Stephen, 2006; Zeng & Yin, 2018; Deng & Hu, 2023).\nAssumption 2 Each local function fi(x) has L-Lipschitz continuous gradient\n\u2225\u2207fi(x)\u2212\u2207fi(y)\u2225 \u2264 L\u2225x\u2212 y\u2225, i \u2208 [n], (9) and let Lf := maxx\u2208St(d,r) \u2225\u2207fi(x)\u2225. Therefore, \u2207f(x) is also L-Lipschitz continuous in the Euclidean space and Lf \u2265 maxx\u2208St(d,r) \u2225\u2207f(x)\u2225.\nWith the properties of projection operators, we can derive the similar Lipschitz inequality on the Stiefel manifold as the Euclidean-type one (Nesterov, 2013) in the following lemma.\nLemma 1 (Lipschitz-type inequality) Under Assumption 2, for any x, y \u2208 St(d, r), if f(x) is LLipschitz smooth in the Euclidean space, then there exists a constant Lg = L+ 2Lf such that\n\u2225 grad fi(x)\u2212 grad fi(y)\u2225 \u2264 Lg\u2225x\u2212 y\u2225, i \u2208 [n]. (10)\nProof. The proofs can be found in Appendix A. \u25a1\nFurthermore, since the Stiefel manifold is a 1-proximally smooth set (Balashov & Kamalov, 2021), the projection operator on St(d, r) has the following property based on Definition 1\n\u2225PM(x)\u2212 PM(y)\u2225 \u2264 1\n1\u2212 \u03b3 \u2225x\u2212 y\u2225, \u2200x, y \u2208 UM(\u03b3), \u03b3 \u2208 (0, 1). (11)\nThis inequality will be used to characterize the local convergence of the consensus problem."
        },
        {
            "heading": "4 DECENTRALIZED RIEMANNIAN CONJUGATE GRADIENT METHOD",
            "text": "In this section, we will present a decentralized Riemannian conjugate gradient descent (DRCGD) method for solving the problem (1) described in Algorithm 1 and yield the convergence analysis."
        },
        {
            "heading": "4.1 THE ALGORITHM",
            "text": "We now introduce conjugate gradient methods on a Riemannian manifold M. Our goal is to develop the decentralized version of Riemannian conjugate gradient methods on St(d, r). The generalized Riemannian conjugate gradient descent (Absil et al., 2008; Sato, 2021) iterates as\nxk+1 = Rxk(\u03b1k\u03b7k), (12) where \u03b7k is the search direction on the tangent space TxkM and \u03b1k > 0 is the step size. Then an operation called retraction Rxk is performed to ensure feasibility, whose definition is given in Definition 2. It follows from Definition 3 that we have T\u03b1k\u03b7k(\u03b7k) \u2208 Txk+1M. Thus, the search direction (Sato, 2021) can be iterated as\n\u03b7k+1 = \u2212 grad f(xk+1) + \u03b2k+1T\u03b1k\u03b7k(\u03b7k), k = 0, 1, \u00b7 \u00b7 \u00b7 , (13) where the scalar \u03b2k+1 \u2208 R. Since grad f(xk+1) \u2208 Txk+1M and \u03b2k+1\u03b7k \u2208 TxkM, they belong to different tangent spaces and cannot be added. Hence, the vector transport in Definition 3 needs to be used to map a tangent vector in TxkM to one in Txk+1M. However, vector transports are still computationally expensive, which significantly affects the efficiency of our algorithm. To extend search directions in the decentralized scenario together with computationally cheap needs, we perform the following update of decentralized search directions:\n\u03b7i,k+1 = \u2212 grad fi(xi,k+1) + \u03b2i,k+1PTxi,k+1M  n\u2211 j=1 W tij\u03b7j,k  , i \u2208 [n], (14) where grad fi(xi,k+1) \u2208 Txi,k+1M and \u03b7i,k \u2208 Txi,kM. Note that \u2211n j=1 W t ij\u03b7j,k is clearly not on the tangent space Txi,k+1M and even not on the tangent space Txi,kM. Therefore, it is important to define the projection PTxi,k+1M of \u2211n j=1 W t ij\u03b7j,k to Txi,k+1M so that we can compute the addition\nin the same tangent space Txi,k+1M to update the \u03b7i,k+1. Simultaneously, \u2211n j=1 W t ij\u03b7j,k also achieves the consensus of search directions. On the other hand, similar to the decentralized projected Riemannian gradient descent (Deng & Hu, 2023), the DRCGD performs the following update in the k-th iteration\nxi,k+1 = PM  n\u2211 j=1 W tijxj,k + \u03b1k\u03b7i,k  , i \u2208 [n]. (15) The Riemanian gradient step with a unit step size, i.e., PM (\u2211n j=1 W t ijxj,k ) , is utilized in the above iteration for the consensus problem (8). So far, we have presented the efficient method by replacing both retractions and vector transports with projection operators.\nRegarding \u03b2k+1, there are six standard types in the Euclidean space, which were proposed by Fletcher & Reeves (1964), Dai & Yuan (1999), Fletcher (2000), Polak & Ribiere (1969) and Polyak (1969), Hestenes et al. (1952), and Liu & Storey (1991), respectively. Furthermore, the Riemannian version of \u03b2k+1 was given in (Sato, 2022). Ring & Wirth (2012) analyzed the Riemannian conjugate gradient with a specific scalar \u03b2R\u2212FRk+1 , which is a natural generalization of \u03b2 FR k+1 in (Fletcher & Reeves, 1964). In this paper, we yield a naive extension of \u03b2R\u2212FRk+1 in terms of the decentralized type\n\u03b2R\u2212FRi,k+1 = \u27e8grad fi(xi,k+1), grad fi(xi,k+1)\u27e9xi,k+1\n\u27e8grad fi(xi,k), grad fi(xi,k)\u27e9xi,k = \u2225grad fi(xi,k+1)\u22252xi,k+1 \u2225grad fi(xi,k)\u22252xi,k , (16)\nwhere the \u201cR\u2212\u201d stands for \u201cRiemannian\u201d and \u201cFR\u201d stands for \u201cFletcher-Reeves\u201d type (Fletcher & Reeves, 1964). With the above preparations, we present the DRCGD method described in Algorithm 1. The step 3 first performs a consensus step and then updates the local variable using search directions \u03b7i,k. The step 4 uses the decentralized version of \u03b2R\u2212FRk+1 . The step 5 is to project the search direction onto the tangent space Txi,k+1M, which follows a projection update.\nAlgorithm 1 Decentralized Riemannian Conjugate Gradient Descent (DRCGD) for solving Eq.(1). Input: Initial point x0 \u2208 Mn, an integer t, set \u03b7i,0 = \u2212 grad fi(xi,0).\n1: for k = 0, \u00b7 \u00b7 \u00b7 do \u25b7 for each node i \u2208 [n], in parallel 2: Choose diminishing step size \u03b1k = O(1/ \u221a k)\n3: Update xi,k+1 = PM (\u2211n j=1 W t ijxj,k + \u03b1k\u03b7i,k ) 4: Compute \u03b2i,k+1 = \u2225 grad fi(xi,k+1)\u22252/\u2225 grad fi(xi,k)\u22252\n5: Update \u03b7i,k+1 = \u2212 grad fi(xi,k+1) + \u03b2i,k+1PTxi,k+1M (\u2211n j=1 W t ij\u03b7j,k ) 6: end for\nTo analyze the convergence of the proposed algorithm, the following assumptions on the step size \u03b1k are also needed (Sato, 2022).\nAssumption 3 The step size \u03b1k > 0 satisfies the following conditions: (i) \u03b1k is decreasing and bounded\nlim k\u2192\u221e \u03b1k = 0, lim k\u2192\u221e \u03b1k+1 \u03b1k = 1, 0 < \u03b1k \u2264 \u03b3(1\u2212 \u03b3) 4C . (17)\n(ii) For constant c1 and c2 with 0 < c1 < c2 < 1, the Armijo condition on M is fi(xi,k+1) \u2264 fi(xi,k) + c1\u03b1k\u27e8grad fi(xi,k), \u03b7i,k\u27e9xi,k . (18) (iii) The strong Wolfe condition is\u2223\u2223\u2223\u2223\u2329grad fi (xi,k+1) ,T R\u03b1k\u03b7i,k(\u03b7i,k)\u232axi,k+1 \u2223\u2223\u2223\u2223 \u2264 c2 \u2223\u2223\u2223\u27e8grad fi (xi,k) , \u03b7i,k\u27e9xi,k \u2223\u2223\u2223 . (19)"
        },
        {
            "heading": "4.2 CONVERGENCE ANALYSIS",
            "text": "This subsection focuses on the global convergence analysis of our DRCGD algorithm. Different from the bounded assumption of a vector transport in (Sato, 2022), we give an extended assumption about the projection operator in the decentralized scenario, where gi,k+1 := grad fi(xi,k+1). Specifically, we assume, for each k \u2265 0, that the following inequality holds\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2329 gi,k+1,PTxi,k+1M  n\u2211 j=1 W tij\u03b7j,k \u232a xi,k+1 \u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2264 \u2223\u2223\u2223\u2223\u2329gi,k+1,T R\u03b1k\u03b7i,k (\u03b7i,k)\u232axi,k+1\n\u2223\u2223\u2223\u2223 , (20) which will be used as a substitute to proceed the following demonstration. Next, we consider proving the convergence of the Fletcher-Reeves-type DRCGD method for each agent, i.e., we use \u03b2R\u2212FRi,k+1 in Eq.(16). See Al-Baali (1985) for its Euclidean version and Sato (2022) for its Riemannian version.\nAt last, we establish the global convergence based on Theorem 2 and Theorem 3, which give the locally linear convergence of consensus error and the convergence of each agent, respectively.\nTheorem 1 (Global convergence). Let {xk} be the sequence generated by Algorithm 1. Suppose that Assumptions 1 and 2 hold. If x0 \u2208 N := {x : \u2225x\u0302 \u2212 x\u0304\u2225 \u2264 \u03b3/2} and \u2225\u03b2i,k\u2225 \u2264 C (a constant C > 0), then\nlim k\u2192\u221e\ninf \u2225 grad f(x\u0304k)\u22252 = 0. (21)\nProof. The proofs can be found in Appendix D.1. \u25a1"
        },
        {
            "heading": "5 NUMERICAL EXPERIMENT",
            "text": "In this section, we compare our DRCGD method with DRDGD (Chen et al., 2021) and DPRGD (Deng & Hu, 2023), which are first-order decentralized Riemannian optimization methods using retraction and projection respectively, on the following decentralized eigenvector problem:\nmin x\u2208Mn \u2212 1 2n n\u2211 i=1 tr ( x\u22a4i A \u22a4 i Aixi ) , s.t. x1 = . . . = xn, (22)\nwhere Mn := St(d, r)\u00d7 \u00b7 \u00b7 \u00b7 \u00d7 St(d, r)\ufe38 \ufe37\ufe37 \ufe38 n , Ai \u2208 Rmi\u00d7d is the local data matrix for agent i and mi is the sample size. Note that A\u22a4 := [A\u22a41 , A \u22a4 2 , \u00b7 \u00b7 \u00b7 , A\u22a4n ] is the global data matrix. For any solution x\u2217 of Eq.(22), giving an orthogonal matrix Q \u2208 Rr\u00d7r, x\u2217Q is also a solution in essence. Then the distance between two points x and x\u2217 can be defined as\nds(x, x \u2217) = min Q\u22a4Q=QQ\u22a4=Ir \u2225xQ\u2212 x\u2217\u2225.\nWe employ fixed step sizes for all comparisons, i.e., the step size is set to \u03b1k = \u03b1\u0302\u221aK with K being the maximal number of iterations. We examine various graph matrices used to represent the topology across agents, i.e., the Erdos-Renyi (ER) network with probability p and the Ring network. It follows from (Chen et al., 2021) that W is the Metroplis constant matrix (Shi et al., 2015).\nWe measure algorithms by four metrics, i.e., the consensus error \u2225xk \u2212 x\u0304k\u2225, the gradient norm \u2225gradf(x\u0304k)\u2225, the objective function f(x\u0304k)\u2212f\u2217, and the distance to the global optimum ds(x\u0304k, x\u2217), respectively. The experiments are evaluated with the Intel(R) Core(TM) i7-12700 CPU. And the codes are implemented in Python with mpi4py."
        },
        {
            "heading": "5.1 SYNTHETIC DATA",
            "text": "We fix m1 = m2 = \u00b7 \u00b7 \u00b7 = mn = 1000, d = 10, and r = 5. Then we generate m1 \u00d7 n independent and identically distributed samples to obtain A by following standard multi-variate Gaussian distribution. Specifically, let A = U\u03a3V \u22a4 be the truncated SVD, where U \u2208 R1000n\u00d7d and V \u2208 Rd\u00d7d are orthogonal matrices, and \u03a3 \u2208 Rd\u00d7d is a diagonal matrix. Then we set the singular values of A to be \u03a3i,i = \u03a30,0\u00d7\u2206i/2 where i \u2208 [d] and eigengap \u2206 \u2208 (0, 1). We also fix the maximum iteration epoch to 200 and early terminate it if ds(x\u0304k, x\u2217) \u2264 10\u22125. The comparison results are shown in Figures 1, 2, and 3. It can be seen from Figure 1 that our DRCGD converges faster than DPRGD under different numbers of agents (n = 16 and n = 32). When n becomes larger, these two algorithms both converge slower. In Figure 2, DRDGD gives very similar performance under different numbers of consensus steps, i.e., t \u2208 {1, 10,\u221e}, which means that the numbers of consensus steps do not affect the performance of DRDGD much. A similar phenomenon can be observed in DPRGD. In contrast, as the communication rounds t increase, our DRCGD consistently achieves better performance. Note that one can achieve the case of t \u2192 \u221e through a complete graph with the equally weighted matrix. For Figure 3, we see DPRGD has very close trajectories under different graphs on the four metrics. In fact, this also occurs for DRDGD. However, the connected graph ER helps our DRCGD obtain a better final solution than the connected graph Ring because ER network with the probability of each edge is a better graph connection than Ring network. Moreover, our DRCGD with ER p = 0.6 performs better than that with ER p = 0.3. In conclusion, DRCGD always converges faster and performs better than both DRDGD and DPRGD under different network graphs because the search direction of conjugate gradient method we designed in Eq.(14) is not only vector transport-free, but also achieves the consensus."
        },
        {
            "heading": "5.2 REAL-WORLD DATA",
            "text": "We also present some numerical results on the MNIST dataset (LeCun, 1998). For MNIST, the samples consist of 60000 hand-written images where the dimension of each image is given by d = 784. And these samples make up the data matrix of 60000 \u00d7 784, which is randomly and evenly partitioned into n agents. We normalize the data matrix by dividing 255. Then each agent holds a local data matrix Ai of 60000n \u00d7 784. For brevity, we fix t = 1, r = 5, and d = 784, respectively. W is the Metroplis constant matrix and the graph is the Ring network. The step size of our DRCGD, DRDGD, and DPRGD is \u03b1k = \u03b1\u030260000 . We set the maximum iteration epoch to 1000 and early terminate it if ds(x\u0304k, x\u2217) \u2264 10\u22125. The results for MNIST data with n = 20 are shown in Figure 4. We see that the performance of DRDGD and DPRGD are almost the same. When \u03b1\u0302 becomes larger, all algorithms converge faster. And our DRCGD converges much faster than both DRDGD and DPRGD."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "We proposed the decentralized Riemannian conjugate gradient method for solving decentralized optimization over the Stiefel manifold. In particular, it is the first decentralized version of the Riemannian conjugate gradient. By replacing retractions and vector transports with projection operators, the global convergence was established under an extended assumption (20) on the basis of (Sato, 2021), thereby reducing the computational complexity required by each agent. Numerical results demonstrated the effectiveness of our proposed algorithm. In the future, we will further extend our algorithm to a compact sub-manifold. On the other hand, it will be interesting to develop the decentralized version of online optimization over Riemannian manifolds."
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "This work was supported by NSFC 62088101 Autonomous Intelligent Unmanned Systems."
        },
        {
            "heading": "A PROOFS FOR LEMMA 1",
            "text": "Proof. Since grad fi(x) = PTxM(\u2207fi(x)), we have \u2225grad fi(x)\u2212 grad fi(y)\u2225 = \u2225\u2225PTxM (\u2207fi(x))\u2212 PTyM (\u2207fi(y))\u2225\u2225\n= \u2225\u2225PTxM (\u2207fi(x))\u2212 PTxM (\u2207fi(y)) + PTxM (\u2207fi(y))\u2212 PTyM (\u2207fi(y))\u2225\u2225\n\u2264\u2225PTxM (\u2207fi(x)\u2212\u2207fi(y))\u2225+ \u2225\u2225PTxM (\u2207fi(y))\u2212 PTyM (\u2207fi(y))\u2225\u2225\n\u2264\u2225\u2207fi(x)\u2212\u2207fi(y)\u2225+ \u2225\u2225PTxM (\u2207fi(y))\u2212 PTyM (\u2207fi(y))\u2225\u2225\n\u2264\u2225\u2207fi(x)\u2212\u2207fi(y)\u2225+ 2Lf\u2225x\u2212 y\u2225 \u2264(L+ 2Lf )\u2225x\u2212 y\u2225,\n(23)\nwhere, by Eq.(6), the third inequality uses\u2225\u2225PTxM (\u2207fi(y))\u2212 PTyM (\u2207fi(y))\u2225\u2225 = 1\n2 \u2225\u2225x (x\u22a4\u2207fi(y) +\u2207fi(y)\u22a4x)\u2212 y (y\u22a4\u2207fi(y) +\u2207fi(y)\u22a4y)\u2225\u2225 \u22641 2\n(\u2225\u2225x ((x\u2212 y)\u22a4\u2207fi(y) +\u2207fi(y)\u22a4(x\u2212 y))\u2225\u2225+ \u2225\u2225(x\u2212 y) (y\u22a4\u2207fi(y) +\u2207fi(y)\u22a4y)\u2225\u2225) \u22641 2 (2\u2225x\u2225 \u00b7 \u2225x\u2212 y\u2225 \u00b7 \u2225\u2207fi(y)\u2225+ 2\u2225x\u2212 y\u2225 \u00b7 \u2225\u2207fi(y)\u2225 \u00b7 \u2225y\u2225) \u22642\u2225x\u2212 y\u2225 \u00b7 \u2225\u2207fi(y)\u2225 \u2264 2 max y\u2208St(d,r) \u2225\u2207fi(y)\u2225 \u00b7 \u2225x\u2212 y\u2225 = 2Lf\u2225x\u2212 y\u2225. (24)\nThe proof is completed. \u25a1"
        },
        {
            "heading": "B LINEAR CONVERGENCE OF CONSENSUS ERROR",
            "text": "Let us first present the linear convergence of consensus error. For the iteration scheme xi,k+1 = PM (\u2211n j=1 W t ijxj,k + \u03b1k\u03b7i,k ) where \u03b1k > 0 and \u03b7i,k \u2208 Txi,kM, the following lemma yields that, for xk in the neighborhood N , the iterates xk+1 also remain in this neighborhood N .\nLemma 2 Let xi,k+1 = PM (\u2211n j=1 W t ijxj,k + \u03b1k\u03b7i,k ) . On the basis of Assumption 1, if xk \u2208\nN := {x : \u2225x\u0302 \u2212 x\u0304\u2225 \u2264 \u03b3/2}, \u2225\u03b7i,k\u2225 \u2264 C, 0 < \u03b1k \u2264 \u03b3(1\u2212\u03b3)4C , and t \u2265 \u2308 log\u03c32 ( \u03b3(1\u2212\u03b3) 4 \u221a n\u03b6 )\u2309 with \u03b6 := maxx,y\u2208M \u2225x\u2212 y\u2225, then\nn\u2211 j=1 W tijxj,k + \u03b1k\u03b7i,k \u2208 UM(\u03b3), i = 1, \u00b7 \u00b7 \u00b7 , n, (25)\n\u2225x\u0302k+1 \u2212 x\u0304k+1\u2225 \u2264 1\n2 \u03b3. (26)\nProof. Since xk \u2208 N , we have\n\u2225x\u0302k+1 \u2212 x\u0304k+1\u2225 \u2264 \u2225x\u0302k+1 \u2212 x\u0304k\u2225 \u2264 1\nn n\u2211 i=1 \u2225xi,k+1 \u2212 x\u0304k\u2225\n= 1\nn n\u2211 i=1 \u2225\u2225\u2225\u2225\u2225\u2225PM  n\u2211 j=1 W tijxj,k + \u03b1k\u03b7i,k \u2212 PM (x\u0302k) \u2225\u2225\u2225\u2225\u2225\u2225\n\u2264 1 1\u2212 \u03b3 \u2225\u2225\u2225\u2225\u2225\u2225 n\u2211\nj=1\nW tijxj,k + \u03b1k\u03b7i,k \u2212 x\u0302k \u2225\u2225\u2225\u2225\u2225\u2225 \u2264 12\u03b3,\nwhere the third inequality uses Eq.(11) and the fourth inequality yields\u2225\u2225\u2225\u2225\u2225\u2225 n\u2211\nj=1\nW tijxj,k + \u03b1k\u03b7i,k \u2212 x\u0302k \u2225\u2225\u2225\u2225\u2225\u2225 \u2264 \u2225\u2225\u2225\u2225\u2225\u2225 n\u2211 j=1 W tijxj,k \u2212 x\u0302k \u2225\u2225\u2225\u2225\u2225\u2225+ \u2225\u03b1k\u03b7i,k\u2225 \u2264 \u2225\u2225\u2225\u2225\u2225\u2225 n\u2211\nj=1\n( W tij \u2212 1\nn\n) (xj,k \u2212 x\u0302k) \u2225\u2225\u2225\u2225\u2225\u2225+ \u03b1kC \u2264\nn\u2211 j=1 \u2223\u2223\u2223\u2223W tij \u2212 1n \u2223\u2223\u2223\u2223 \u2225xj,k \u2212 x\u0302k\u2225+ \u03b1kC\n\u2264 \u03b6max i n\u2211 j=1 \u2223\u2223\u2223\u2223W tij \u2212 1n \u2223\u2223\u2223\u2223+ \u03b1kC \u2264 \u221an\u03c3t2\u03b6 + \u03b1kC \u2264 \u03b3(1\u2212 \u03b3)2 ,\nwhere the fourth inequality uses that \u2225xj,k \u2212 x\u0302k\u2225 \u2264 1n \u2211n\ni=1 \u2225xj,k \u2212 xi,k\u2225 \u2264 \u03b6 (Deng & Hu, 2023) and the fifth inequality follows from the bound on the total variation distance between any row of W t and 1n1n (Diaconis & Stroock, 1991; Boyd et al., 2004). For any i \u2208 [n], since x\u0304k \u2208 M and \u03b3 \u2208 (0, 1), we have\u2225\u2225\u2225\u2225\u2225\u2225 n\u2211 j=1 W tijxj,k + \u03b1k\u03b7i,k \u2212 x\u0304k \u2225\u2225\u2225\u2225\u2225\u2225 \u2264 \u2225\u2225\u2225\u2225\u2225\u2225 n\u2211 j=1 W tijxj,k + \u03b1k\u03b7i,k \u2212 x\u0302k\n\u2225\u2225\u2225\u2225\u2225\u2225+ \u2225x\u0302k \u2212 x\u0304k\u2225 \u2264 \u03b3(1\u2212 \u03b3)\n2 +\n1 2 \u03b3 < \u03b3.\nThe proof is completed. \u25a1\nIn Lemma 2, the search direction \u03b7i,k is required to be bounded. Let \u03b7i,k = 0, then we can consider the convergence of consensus error.\nTheorem 2 (Linear convergence of consensus error). Let xi,k+1 = PM (\u2211n j=1 W t ijxj,k ) . On the basis of Assumption 1, if xk \u2208 N := {x : \u2225x\u0302 \u2212 x\u0304\u2225 \u2264 \u03b3/2} and t \u2265 max {\u2308 log\u03c32(1\u2212 \u03b3) \u2309 , \u2308 log\u03c32 ( \u03b3(1\u2212\u03b3) 4 \u221a n\u03b6 )\u2309} , then the following linear convergence with rate \u03c3t2/(1\u2212 \u03b3) < 1 holds\n\u2225xk+1 \u2212 x\u0304k+1\u2225 \u2264 \u03c3t2\n1\u2212 \u03b3 \u2225xk \u2212 x\u0304k\u2225\nProof. According to Lemma 2, \u2225x\u03020 \u2212 x\u03040\u2225 \u2264 12\u03b3 and xk \u2208 N for all k \u2265 0 holds, then it holds that n\u2211\nj=1\nW tijxj,k \u2208 UM(\u03b3), i = 1, \u00b7 \u00b7 \u00b7 , n.\nLet PMn(x)\u22a4 = [PM(x1)\u22a4, \u00b7 \u00b7 \u00b7 ,PM(xn)\u22a4], then with the iteration scheme xi,k+1 = PM (\u2211n j=1 W t ijxj,k ) we have\n\u2225xk+1 \u2212 x\u0304k+1\u2225 \u2264 \u2225xk+1 \u2212 x\u0304k\u2225 = \u2225\u2225PMn (Wtxk)\u2212 PMn (x\u0302k)\u2225\u2225\n\u2264 1 1\u2212 \u03b3 \u2225\u2225Wtxk \u2212 x\u0302k\u2225\u2225 = 1 1\u2212 \u03b3 \u2225\u2225(W t \u2297 Id)xk \u2212 x\u0302k\u2225\u2225 = 1\n1\u2212 \u03b3 \u2225\u2225\u2225\u2225((W t \u2212 1n1n1\u22a4n ) \u2297 Id ) (xk \u2212 x\u0302k) \u2225\u2225\u2225\u2225 \u2264 1\n1\u2212 \u03b3 \u03c3t2 \u2225xk \u2212 x\u0302k\u2225 \u2264\n1\n1\u2212 \u03b3 \u03c3t2 \u2225xk \u2212 x\u0304k\u2225 ,\n(27)\nwhere the second inequality uses Eq.(11). The proof is completed. \u25a1\nOn the Stiefel manifold, by utilizing the 1-proximally smooth property of projection operators, we establish the locally linear convergence of consensus error with a rate of \u03c3t2/(1\u2212 \u03b3), where t can be any positive integer, which is consistent with the cases in the Euclidean space (Nedic et al., 2010; Nedic\u0301 et al., 2018)."
        },
        {
            "heading": "C CONVERGENCE OF EACH AGENT",
            "text": "Lemma 3 In Algorithm 1 with \u03b2i,k+1 = \u03b2R\u2212FRi,k+1 in Eq. (16) and Eq. (20), assume that \u03b1k satisfies the strong Wolfe conditions in Eq.(18) and Eq.(19) with 0 < c1 < c2 < 1/2, for each k \u2265 0. If grad fi(xi,k) \u0338= 0 for each k \u2265 0, then \u03b7i,k as a descent direction satisfies\n\u2212 1 1\u2212 c2 \u2264 \u27e8grad fi(xi,k), \u03b7i,k\u27e9xi,k \u2225grad fi(xi,k)\u22252xi,k \u2264 \u22121\u2212 2c2 1\u2212 c2 . (28)\nProof. For ease of notation, we denote gi,k := grad fi(xi,k). When k = 0, \u03b7i,0 = \u2212gi,0 is the initial condition and we have\n\u27e8gi,0, \u03b7i,0\u27e9xi,0 \u2225gi,0\u22252xi,0 = \u27e8gi,0,\u2212gi,0\u27e9xi,0 \u2225gi,0\u22252xi,0 = \u22121.\nHence, Eq. (28) holds. Supposing that \u03b7i,k is a descent direction satisfying Eq. (28) for some k, we will prove that \u03b7i,k+1 is also a descent and satisfies Eq. (28) in which k is replaced with k+1. Based on Eq.(14) and Eq.(16), we yield\n\u27e8gi,k+1, \u03b7i,k+1\u27e9xi,k+1 \u2225gi,k+1\u22252xi,k+1 =\n\u2329 gi,k+1,\u2212gi,k+1 + \u03b2i,k+1PTxi,k+1M (\u2211n j=1 W t ij\u03b7j,k )\u232a xi,k+1\n\u2225gi,k+1\u22252xi,k+1\n= \u22121 +\n\u2329 gi,k+1,PTxi,k+1M (\u2211n j=1 W t ij\u03b7j,k )\u232a xi,k+1\n\u2225gi,k\u22252xi,k .\n(29)\nSimilar to (Sato, 2022), the assumption in Eq.(20) and the strong Wolfe condition in Eq.(19) yield\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2329 gi,k+1,PTxi,k+1M  n\u2211 j=1 W tij\u03b7j,k \u232a xi,k+1 \u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2264 c2 \u2223\u2223\u2223\u27e8gi,k, \u03b7i,k\u27e9xi,k \u2223\u2223\u2223 = \u2212c2 \u27e8gi,k, \u03b7i,k\u27e9xi,k . (30)\nIt follows from Eq.(29) and Eq.(30) that\n\u22121 + c2 \u27e8gi,k, \u03b7i,k\u27e9xi,k \u2225gi,k\u22252xi,k \u2264 \u27e8gi,k+1, \u03b7k+1\u27e9xi,k+1 \u2225gi,k+1\u22252xi,k+1 \u2264 \u22121\u2212 c2 \u27e8gi,k, \u03b7i,k\u27e9xi,k \u2225gi,k\u22252xi,k .\nFrom the induction hypothesis in Eq.(28), i.e., \u27e8gi,k, \u03b7i,k\u27e9xi,k/\u2225gi,k\u22252xi,k \u2265 \u2212(1 \u2212 c2) \u22121, and the assumption c2 > 0, we finally obtain the following inequality\n\u2212 1 1\u2212 c2\n\u2264 \u27e8gi,k+1, \u03b7i,k+1\u27e9xi,k+1 \u2225gi,k+1\u22252xi,k+1 \u2264 \u22121\u2212 2c2 1\u2212 c2 ,\nwhich also implies \u27e8gi,k+1, \u03b7i,k+1\u27e9xi,k+1 < 0. The proof is completed. \u25a1 Subsequently, we proceed to the convergence property of each agent. The proof below is based on the Riemannian version given in Sato (2022).\nTheorem 3 In Algorithm 1 with \u03b2i,k+1 = \u03b2R\u2212FRi,k+1 in Eq. (16) and Eq. (20), assume that \u03b1k satisfies the strong Wolfe conditions in Eq.(18) and Eq.(19) with 0 < c1 < c2 < 1/2, for each k \u2265 0. If fi is\nbounded below and is of class C1, and the Riemannian version (Ring & Wirth, 2012; Sato & Iwai, 2015) of Zoutendijk\u2019s Theorem (Nocedal & Wright, 1999) holds, then we yield\nlim k\u2192\u221e inf \u2225 grad fi(xi,k)\u2225xi,k = 0, i = 1, \u00b7 \u00b7 \u00b7 , n. (31)\nProof. We denote gi,k := grad fi(xi,k) again. If gi,k0 = 0 holds for some k0, then we have \u03b2i,k0 = 0 and \u03b7i,k0 = 0 from Eq.(16) and Eq.(14), which implies xi,k0+1 = PM (\u2211n j=1 W t ijxj,k0 ) . Based on Theorem 2, the consensus error converges such that xi,k0+1 \u2192 xi,k0 holds. Thus, we obtain gi,k = 0 for all k \u2265 k0 so that Eq.(31) holds. We next consider the case in which gi,k \u0338= 0 for all k \u2265 0. Let \u03b8i,k be the angle between \u2212gi,k and \u03b7i,k, i.e.,\ncos \u03b8i,k = \u27e8\u2212gi,k, \u03b7i,k\u27e9xi,k\n\u2225\u2212gi,k\u2225xi,k \u2225\u03b7i,k\u2225xi,k = \u2212 \u27e8gi,k, \u03b7i,k\u27e9xi,k \u2225gi,k\u2225xi,k \u2225\u03b7i,k\u2225xi,k . (32)\nIt follows from Eq.(32) and Eq.(28) that\ncos \u03b8i,k \u2265 1\u2212 2c2 1\u2212 c2 \u2225gi,k\u2225xi,k \u2225\u03b7i,k\u2225xi,k . (33)\nSince the search directions are descent directions from Lemma 3, Zoutendijk\u2019s Theorem together with Eq.(33) yields\n\u221e\u2211 k=0 \u2225gi,k\u22254xi,k \u2225\u03b7i,k\u22252xi,k < \u221e. (34)\nCombined Eq.(28) and Eq.(30), we have\u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2329 gi,k,PTxi,kM  n\u2211 j=1 W tij\u03b7j,k\u22121 \u232a xi,k \u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2264 \u2212c2 \u27e8gi,k\u22121, \u03b7i,k\u22121\u27e9xi,k\u22121 \u2264 c2 1\u2212 c2 \u2225gi,k\u22121\u22252xi,k\u22121 .\n(35)\nUsing Eq.(16), Eq.(20), and Eq.(35), we obtain the recurrence inequality for \u2225\u03b7i,k\u22252xi,k :\n\u2225\u03b7i,k\u22252xi,k\n= \u2225\u2225\u2225\u2225\u2225\u2225\u2212gi,k + \u03b2i,kPTxi,kM  n\u2211\nj=1\nW tij\u03b7j,k\u22121 \u2225\u2225\u2225\u2225\u2225\u2225 2\nxi,k\n\u2264 \u2225gi,k\u22252xi,k + 2\u03b2i,k \u2223\u2223\u2223\u2223\u2223\u2223\u2223 \u2329 gi,k,PTxi,kM  n\u2211 j=1 W tij\u03b7j,k\u22121 \u232a xi,k \u2223\u2223\u2223\u2223\u2223\u2223\u2223+ \u03b22i,k \u2225\u2225\u2225\u2225\u2225\u2225PTxi,kM  n\u2211 j=1 W tij\u03b7j,k\u22121 \u2225\u2225\u2225\u2225\u2225\u2225 2 xi,k\n\u2264 \u2225gi,k\u22252xi,k + 2c2 1\u2212 c2 \u03b2i,k \u2225gi,k\u22121\u22252xi,k\u22121 + \u03b2 2 i,k \u2225\u03b7i,k\u22121\u2225 2 xi,k\u22121 = \u2225gi,k\u22252xi,k + 2c2\n1\u2212 c2 \u2225gi,k\u22252xi,k + \u03b2 2 i,k \u2225\u03b7i,k\u22121\u2225 2 xi,k\u22121\n= c \u2225gi,k\u22252xi,k + \u03b2 2 i,k \u2225\u03b7i,k\u22121\u2225 2 xi,k\u22121 ,\n(36) where c := (1 + c2)/(1 \u2212 c2) > 1. Note that we assume in the second inequality, for each k \u2265 1, that \u2225\u2225\u2225\u2211nj=1 W tij\u03b7j,k\u22121\u2225\u2225\u2225 xi,k \u2264 \u2225\u03b7i,k\u22121\u2225xi,k\u22121 holds, which is similar to Formula (4.28) in (Sato,\n2021). We can successively use Eq.(36) with Eq.(16) as\n\u2225\u03b7i,k\u22252xi,k \u2264c ( \u2225gi,k\u22252xi,k + \u03b2 2 i,k \u2225gi,k\u22121\u2225 2 xi,k\u22121 + \u00b7 \u00b7 \u00b7+ \u03b22i,k\u03b22i,k\u22121 \u00b7 \u00b7 \u00b7\u03b22i,2 \u2225gi,1\u2225 2 xi,1 ) + \u03b22i,k\u03b2 2 i,k\u22121 \u00b7 \u00b7 \u00b7\u03b22i,1 \u2225\u03b7i,0\u2225 2 xi,0\n=c \u2225gi,k\u22254xi,k ( \u2225gi,k\u2225\u22122xi,k + \u2225gi,k\u22121\u2225 \u22122 xi,k\u22121 + \u00b7 \u00b7 \u00b7+ \u2225gi,1\u2225\u22122xi,1 ) + \u2225gi,k\u22254xi,k \u2225gi,0\u2225 \u22122 xi,0 <c \u2225gi,k\u22254xi,k k\u2211\nj=0\n\u2225gi,j\u2225\u22122xi,j .\n(37)\nWe can prove Eq.(31) by contradiction. We first assume that Eq.(31) does not hold. Then there exists a constant C > 0 such that \u2225gi,k\u2225xi,k \u2265 C > 0 for all k \u2265 0 because we also assume gi,k \u0338= 0 for all k \u2265 0 at the same time. Consequently, we have \u2211k j=0 \u2225gi,j\u22252xi,j \u2264 C\n\u22122(k + 1). Hence, based on Eq.(37), the left hand side of Eq.(34) is evaluated as\n\u221e\u2211 k=0 \u2225gi,k\u22254xi,k \u2225\u03b7i,k\u22252xi,k \u2265 \u221e\u2211 k=0 \u03f52 c 1 k + 1 = \u221e,\nwhich contradicts Eq.(34). The proof is completed. \u25a1"
        },
        {
            "heading": "D GLOBAL CONVERGENCE",
            "text": "An overview of this paper is shown in the Figure 5. We now investigate the uniform boundedness of \u2225\u03b7k\u2225 in the following lemma.\nLemma 4 Let {xk} be the sequence generated by Algorithm 1. Suppose that Assumptions 1 and 2 hold. If x0 \u2208 N , \u2225\u03b2i,k\u2225 \u2264 C, 0 < \u03b1k < min { 1\u2212\u03b3 8Lg , \u03b3(1\u2212\u03b3)4C } , and t \u2265\nmax {\u2308\nlog\u03c32 ( 1\u2212\u03b3 2 \u221a n\u03b6 )\u2309 , \u2308 log\u03c32 ( 1 8 \u221a nC )\u2309 , \u2308 log\u03c32 ( \u03b3(1\u2212\u03b3) 4 \u221a n\u03b6 )\u2309} , it follows that for all k, xk \u2208 N\nand\n\u2225\u03b7i,k\u2225 \u2264 2Lg, \u2200i \u2208 [n]. (38)\nProof. We prove it by induction on both \u2225\u03b7i,k\u2225 and \u2225x\u0302k \u2212 x\u0304k\u2225. Based on Assumption 2, we have \u2225 grad fi (xi,k) \u2225 \u2264 \u2225\u2207fi (xi,k) \u2225 \u2264 Lf \u2264 Lg due to Lg = L + 2Lf \u2265 Lf . Then we have \u2225\u03b7i,0\u2225 = \u2225 grad fi (xi,0) \u2225 \u2264 Lg for all i \u2208 [n] and \u2225x\u03020 \u2212 x\u03040\u2225 \u2264 12\u03b3. Suppose for some k \u2265 0\nthat \u2225\u03b7i,k\u2225 \u2264 2Lg and \u2225x\u0302k \u2212 x\u0304k\u2225 \u2264 12\u03b3. Since \u2225\u03b7i,k\u2225 \u2264 2Lg and \u03b1k < \u03b3(1\u2212\u03b3)\n4C , it follows from Lemma 2 that\nn\u2211 j=1 W tijxj,k + \u03b1k\u03b7i,k \u2208 UM(\u03b3), i = 1, \u00b7 \u00b7 \u00b7 , n, \u2225x\u0302k+1 \u2212 x\u0304k+1\u2225 \u2264 1 2 \u03b3.\nThen, we have\n\u2225\u03b7i,k+1 + grad fi (xi,k)\u2225\n= \u2225\u2225\u2225\u2225\u2225\u2225\u03b2i,k+1PTxi,k+1M  n\u2211\nj=1\nW tij\u03b7j,k \u2212 (grad fi (xi,k+1)\u2212 grad fi (xi,k)) \u2225\u2225\u2225\u2225\u2225\u2225\n\u2264 \u03b2i,k+1 \u2225\u2225\u2225\u2225\u2225\u2225PTxi,k+1M  n\u2211\nj=1\nW tij\u03b7j,k \u2225\u2225\u2225\u2225\u2225\u2225+ \u2225grad fi (xi,k+1)\u2212 grad fi (xi,k)\u2225 \u2264 C \u2225\u2225\u2225\u2225\u2225\u2225 n\u2211\nj=1\n( W tij \u2212 1\nn\n) \u03b7j,k \u2225\u2225\u2225\u2225\u2225\u2225+ Lg \u2225xi,k+1 \u2212 xi,k\u2225 \u2264 C\u03c3t2 \u221a nmax\ni \u2225\u03b7i,k\u2225+ Lg \u2225xi,k+1 \u2212 xi,k\u2225\n\u2264 C\u03c3t2 \u221a nmax\ni \u2225\u03b7i,k\u2225+ Lg 1\u2212 \u03b3 \u2225\u2225\u2225\u2225\u2225\u2225 n\u2211\nj=1\n( W tij \u2212 1\nn\n) xi,k + \u03b1k\u03b7i,k \u2225\u2225\u2225\u2225\u2225\u2225 \u2264 ( C\u03c3t2 \u221a n+ \u03b1k\nLg 1\u2212 \u03b3\n) max\ni \u2225\u03b7i,k\u2225+ Lg 1\u2212 \u03b3 \u03c3t2 \u221a n\u03b6\n\u2264 1 4 max i \u2225\u03b7i,k\u2225+ 1 2 Lg \u2264 1 2 Lg + 1 2 Lg \u2264 Lg,\n(39)\nwhere the second inequality uses Lemma 1 and the fourth inequality utilizes Eq.(11). Hence, \u2225\u03b7i,k+1\u2225 \u2264 \u2225\u03b7i,k+1 + grad fi (xi,k)\u2225+ \u2225grad fi (xi,k)\u2225 \u2264 2Lg . The proof is completed. \u25a1 With the above lemma, we can elaborate the relationship between the consensus error and step size.\nLemma 5 Let {xk} be the sequence generated by Algorithm 1. Suppose that Assumptions 1 and 2 hold. If x0 \u2208 N , \u2225\u03b7i,k\u2225 \u2264 2Lg , t \u2265 \u2308 log\u03c32(1\u2212 \u03b3) \u2309 , and 0 < \u03b1k \u2264 \u03b3(1\u2212\u03b3)8Lg , it follows that for all k, xk \u2208 N and\n1 n \u2225x\u0304k \u2212 xk\u22252 \u2264 C\n1\n(1\u2212 \u03b3)2 L2g\u03b1 2 k. (40)\nProof. Since \u2225 grad fi (xi,k) \u2225 \u2264 Lg and \u2225x\u03020 \u2212 x\u03040\u2225 \u2264 12\u03b3, it follows from Lemma 2 that for any k > 0, we have\nn\u2211 j=1 W tijxj,k + \u03b1k\u03b7i,k \u2208 UM(\u03b3), i = 1, \u00b7 \u00b7 \u00b7 , n,\nLet PMn(x)\u22a4 = [PM(x1)\u22a4, \u00b7 \u00b7 \u00b7 ,PM(xn)\u22a4]. By the definition of x\u0304k+1 and Theorem 2, then we yield\n\u2225xk+1 \u2212 x\u0304k+1\u2225 \u2264 \u2225xk+1 \u2212 x\u0304k\u2225 = \u2225\u2225PMn (Wtxk + \u03b1k\u03b7k)\u2212 PMn (x\u0302k)\u2225\u2225 \u2264 1\n1\u2212 \u03b3 \u2225\u2225Wtxk + \u03b1k\u03b7k \u2212 x\u0302k\u2225\u2225\n\u2264 1 1\u2212 \u03b3 \u03c3t2 \u2225xk \u2212 x\u0304k\u2225+ 2 1\u2212 \u03b3 \u221a n\u03b1kLg,\n(41)\nwhere the first inequality follows from the optimality of x\u0304k+1, the second inequality uses Eq.(11), and the third inequality utilizes the fact that \u2225\u03b7k\u2225 \u2264 2 \u221a nLg .\nLet \u03c1t = 11\u2212\u03b3\u03c3 t 2 where 0 < \u03c1t < 1, it follows from Eq.(42) that\n\u2225xk+1 \u2212 x\u0304k+1\u2225 \u2264 \u03c1t \u2225xk \u2212 x\u0304k\u2225+ 2 1\u2212 \u03b3 \u221a n\u03b1kLg\n\u2264 \u03c1k+1t \u2225x0 \u2212 x\u03040\u2225+ 2 \u221a nLg\n1\u2212 \u03b3 k\u2211 l=0 \u03c1k\u2212lt \u03b1l.\n(42)\nLet yk = \u2225xk\u2212x\u0304k\u2225\u221a\nn\u03b1k . For a positive integer K \u2264 k, it follows from Eq.(42) that\nyk+1 \u2264 \u03c1tyk + 2\n1\u2212 \u03b3 Lg \u03b1k \u03b1k+1 \u2264 \u03c1k+1\u2212Kt yK + 2 1\u2212 \u03b3 Lg k\u2211 l=0 \u03c1k\u2212lt \u03b1l \u03b1l+1 .\nSince \u03b1k = O(1/Lg) and \u2225x\u03040 \u2212 x0\u2225 \u2264 12 \u221a n\u03b3, one has that y0 \u2264 12\u03b3/\u03b10 = O(Lg). Since limk\u2192\u221e \u03b1k+1 \u03b1k\n= 1, there exists sufficiently large K such that \u03b1k/\u03b1k+1 \u2264 2,\u2200k \u2265 K. For 0 \u2264 k \u2264 K, there exists some C \u2032 > 0 such that y2k \u2264 C \u2032 1(1\u2212\u03b3)2L 2 g , where C\n\u2032 is independent of Lg and n. For k \u2265 K, one has that y2k \u2264 C 1(1\u2212\u03b3)2L 2 g , where C = 2C\n\u2032 + 32(1\u2212\u03c1t)2 . Hence, we get \u2225xk\u2212x\u0304k\u22252\nn \u2264 C 1 (1\u2212\u03b3)2L 2 g for all k \u2265 0, where C = O( 1(1\u2212\u03c1t)2 ). The proof is completed. \u25a1\nD.1 PROOFS FOR THEOREM 1\nProof. We have the following inequality:\n\u2225 grad f(x\u0304k)\u22252\n= \u2225\u2225\u2225\u2225\u2225 1n n\u2211\ni=1\ngrad fi(xi,k) + grad f(x\u0304k)\u2212 1\nn n\u2211 i=1 grad fi(xi,k) \u2225\u2225\u2225\u2225\u2225 2\n\u2264 2 \u2225\u2225\u2225\u2225\u2225 1n n\u2211\ni=1\ngrad fi(xi,k) \u2225\u2225\u2225\u2225\u2225 2 + 2 \u2225\u2225\u2225\u2225\u2225grad f(x\u0304k)\u2212 1n n\u2211\ni=1\ngrad fi(xi,k) \u2225\u2225\u2225\u2225\u2225 2\n\u2264 2 \u2225\u2225\u2225\u2225\u2225 1n n\u2211\ni=1\ngrad fi(xi,k) \u2225\u2225\u2225\u2225\u2225 2 + 2 n n\u2211 i=1 \u2225grad fi(x\u0304k)\u2212 grad fi(xi,k)\u22252\n\u2264 2 \u2225\u2225\u2225\u2225\u2225 1n n\u2211\ni=1\ngrad fi(xi,k) \u2225\u2225\u2225\u2225\u2225 2 + 2L2g n n\u2211 i=1 \u2225x\u0304k \u2212 xi,k\u22252\n= 2 \u2225\u2225\u2225\u2225\u2225 1n n\u2211\ni=1\ngrad fi(xi,k) \u2225\u2225\u2225\u2225\u2225 2 + 2L2g n \u2225x\u0304k \u2212 xk\u22252 ,\n(43)\nwhere the third inequality uses Lemma 1. Since limk\u2192\u221e inf \u2225 grad fi(xi,k)\u2225 = 0 based on Theorem 2 and \u2225x\u0304k \u2212 xk\u22252 \u2264 nC 1(1\u2212\u03b3)2L 2 g\u03b1 2 k based on Lemma 5, it follows from limk\u2192\u221e \u03b1k = 0 that\nlim k\u2192\u221e\n\u2225 grad f(x\u0304k)\u22252 \u2264 2 \u2225\u2225\u2225\u2225\u2225 1n n\u2211\ni=1\ngrad fi(xi,k) \u2225\u2225\u2225\u2225\u2225 2 + 2C 1 (1\u2212 \u03b3)2 L4g\u03b1 2 k = 0.\nThe proof is completed. \u25a1"
        }
    ],
    "year": 2024
}