{
    "abstractText": "We characterize the statistical efficiency of knowledge transfer through n samples from a teacher to a probabilistic student classifier with input space S over labels A. We show that privileged information at three progressive levels accelerates the transfer. At the first level, only samples with hard labels are known, via which the maximum likelihood estimator attains the minimax rate \u221a |S||A|/n. The second level has the teacher probabilities of sampled labels available in addition, which turns out to boost the convergence rate lower bound to |S||A|/n. However, under this second data acquisition protocol, minimizing a naive adaptation of the cross-entropy loss results in an asymptotically biased student. We overcome this limitation and achieve the fundamental limit by using a novel empirical variant of the squared error logit loss. The third level further equips the student with the soft labels (complete logits) onA given every sampled input, thereby provably enables the student to enjoy a rate |S|/n free of |A|. We find any Kullback-Leibler divergence minimizer to be optimal in the last case. Numerical simulations distinguish the four learners and corroborate our theory.",
    "authors": [
        {
            "affiliations": [],
            "name": "FINITE DOMAINS"
        },
        {
            "affiliations": [],
            "name": "Qingyue Zhao"
        },
        {
            "affiliations": [],
            "name": "Banghua Zhu"
        }
    ],
    "id": "SP:b989fde11048dad396025406672e5109f59651dc",
    "references": [
        {
            "authors": [
                "Pieter Abbeel",
                "Andrew Y Ng"
            ],
            "title": "Apprenticeship learning via inverse reinforcement learning",
            "venue": "In Proceedings of the twenty-first international conference on Machine learning,",
            "year": 2004
        },
        {
            "authors": [
                "Rishabh Agarwal",
                "Nino Vieillard",
                "Piotr Stanczyk",
                "Sabela Ramos",
                "Matthieu Geist",
                "Olivier Bachem"
            ],
            "title": "Gkd: Generalized knowledge distillation for auto-regressive sequence models",
            "venue": "arXiv preprint arXiv:2306.13649,",
            "year": 2023
        },
        {
            "authors": [
                "Zeyuan Allen-Zhu",
                "Yuanzhi Li"
            ],
            "title": "Towards understanding ensemble, knowledge distillation and self-distillation in deep learning",
            "venue": "arXiv preprint arXiv:2012.09816,",
            "year": 2020
        },
        {
            "authors": [
                "Ebtesam Almazrouei",
                "Hamza Alobeidli",
                "Abdulaziz Alshamsi",
                "Alessandro Cappelli",
                "Ruxandra Cojocaru",
                "Maitha Alhammadi",
                "Mazzotta Daniele",
                "Daniel Heslow",
                "Julien Launay",
                "Quentin Malartic",
                "Badreddine Noune",
                "Baptiste Pannier",
                "Guilherme Penedo"
            ],
            "title": "The falcon series of language models: Towards open frontier models",
            "year": 2023
        },
        {
            "authors": [
                "Zaid Alyafeai",
                "Maged Saeed AlShaibani",
                "Irfan Ahmad"
            ],
            "title": "A survey on transfer learning in natural language processing",
            "venue": "arXiv preprint arXiv:2007.04239,",
            "year": 2020
        },
        {
            "authors": [
                "Jimmy Ba",
                "Rich Caruana"
            ],
            "title": "Do deep nets really need to be deep",
            "venue": "Advances in neural information processing systems,",
            "year": 2014
        },
        {
            "authors": [
                "Rishi Bommasani",
                "Drew A Hudson",
                "Ehsan Adeli",
                "Russ Altman",
                "Simran Arora",
                "Sydney von Arx",
                "Michael S Bernstein",
                "Jeannette Bohg",
                "Antoine Bosselut",
                "Emma Brunskill"
            ],
            "title": "On the opportunities and risks of foundation models",
            "venue": "arXiv preprint arXiv:2108.07258,",
            "year": 2021
        },
        {
            "authors": [
                "Leo Breiman",
                "Nong Shang"
            ],
            "title": "Born again trees",
            "venue": "Technical Report,",
            "year": 1996
        },
        {
            "authors": [
                "Jean Bretagnolle",
                "Catherine Huber"
            ],
            "title": "Estimation des densit\u00e9s: risque minimax",
            "venue": "Zeitschrift fu\u0308r Wahrscheinlichkeitstheorie und verwandte Gebiete,",
            "year": 1979
        },
        {
            "authors": [
                "Daniel Brown",
                "Wonjoon Goo",
                "Prabhat Nagarajan",
                "Scott Niekum"
            ],
            "title": "Extrapolating beyond suboptimal demonstrations via inverse reinforcement learning from observations",
            "venue": "In International conference on machine learning,",
            "year": 2019
        },
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are few-shot learners",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "Yuheng Bu",
                "Weihao Gao",
                "Shaofeng Zou",
                "Venugopal Veeravalli"
            ],
            "title": "Information-theoretic understanding of population risk improvement with model compression",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "Christopher J Burges",
                "Bernhard Sch\u00f6lkopf"
            ],
            "title": "Improving the accuracy and speed of support vector machines",
            "venue": "Advances in neural information processing systems,",
            "year": 1996
        },
        {
            "authors": [
                "Cl\u00e9ment L Canonne"
            ],
            "title": "A short note on learning discrete distributions",
            "venue": "arXiv preprint arXiv:2002.11457,",
            "year": 2020
        },
        {
            "authors": [
                "Nicolo Cesa-Bianchi",
                "Yoav Freund",
                "David Haussler",
                "David P Helmbold",
                "Robert E Schapire",
                "Manfred K Warmuth"
            ],
            "title": "How to use expert advice",
            "venue": "Journal of the ACM (JACM),",
            "year": 1997
        },
        {
            "authors": [
                "Letian Chen",
                "Rohan Paleja",
                "Matthew Gombolay"
            ],
            "title": "Learning from suboptimal demonstration via self-supervised reward regression",
            "venue": "In Conference on robot learning,",
            "year": 2021
        },
        {
            "authors": [
                "Xu Cheng",
                "Zhefan Rao",
                "Yilan Chen",
                "Quanshi Zhang"
            ],
            "title": "Explaining knowledge distillation by quantifying the knowledge",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Jang Hyun Cho",
                "Bharath Hariharan"
            ],
            "title": "On the efficacy of knowledge distillation",
            "venue": "In Proceedings of the IEEE/CVF international conference on computer vision,",
            "year": 2019
        },
        {
            "authors": [
                "Tri Dao",
                "Govinda M Kamath",
                "Vasilis Syrgkanis",
                "Lester Mackey"
            ],
            "title": "Knowledge distillation as semiparametric inference",
            "venue": "arXiv preprint arXiv:2104.09732,",
            "year": 2021
        },
        {
            "authors": [
                "Rick Durrett"
            ],
            "title": "Probability: theory and examples, volume 49",
            "venue": "Cambridge university press,",
            "year": 2019
        },
        {
            "authors": [
                "Gongfan Fang",
                "Kanya Mo",
                "Xinchao Wang",
                "Jie Song",
                "Shitao Bei",
                "Haofei Zhang",
                "Mingli Song"
            ],
            "title": "Up to 100x faster data-free knowledge distillation",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2022
        },
        {
            "authors": [
                "Yoav Freund",
                "Robert E Schapire"
            ],
            "title": "A desicion-theoretic generalization of on-line learning and an application to boosting",
            "venue": "In European conference on computational learning theory,",
            "year": 1995
        },
        {
            "authors": [
                "Tommaso Furlanello",
                "Zachary Lipton",
                "Michael Tschannen",
                "Laurent Itti",
                "Anima Anandkumar"
            ],
            "title": "Born again neural networks",
            "venue": "In International Conference on Machine Learning,",
            "year": 2018
        },
        {
            "authors": [
                "Leo Gao",
                "Jonathan Tow",
                "Stella Biderman",
                "Sid Black",
                "Anthony DiPofi",
                "Charles Foster",
                "Laurence Golding",
                "Jeffrey Hsu",
                "Kyle McDonell",
                "Niklas Muennighoff",
                "Jason Phang",
                "Laria Reynolds",
                "Eric Tang",
                "Anish Thite",
                "Ben Wang",
                "Kevin Wang",
                "Andy Zou"
            ],
            "title": "A framework for few-shot language model evaluation",
            "venue": "URL https://doi.org/10.5281/zenodo.5371628",
            "year": 2021
        },
        {
            "authors": [
                "Leo Gao",
                "John Schulman",
                "Jacob Hilton"
            ],
            "title": "Scaling laws for reward model overoptimization",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Jianping Gou",
                "Baosheng Yu",
                "Stephen J Maybank",
                "Dacheng Tao"
            ],
            "title": "Knowledge distillation: A survey",
            "venue": "International Journal of Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Jiatao Gu",
                "Shuangfei Zhai",
                "Yizhe Zhang",
                "Lingjie Liu",
                "Joshua M Susskind"
            ],
            "title": "Boot: Data-free distillation of denoising diffusion models with bootstrapping",
            "venue": "In ICML 2023 Workshop on Structured Probabilistic Inference",
            "year": 2023
        },
        {
            "authors": [
                "Yuxian Gu",
                "Li Dong",
                "Furu Wei",
                "Minlie Huang"
            ],
            "title": "Knowledge distillation of large language models",
            "venue": "arXiv preprint arXiv:2306.08543,",
            "year": 2023
        },
        {
            "authors": [
                "Hyeongrok Han",
                "Siwon Kim",
                "Hyun-Soo Choi",
                "Sungroh Yoon"
            ],
            "title": "On the impact of knowledge distillation for model interpretability",
            "venue": "arXiv preprint arXiv:2305.15734,",
            "year": 2023
        },
        {
            "authors": [
                "Hrayr Harutyunyan",
                "Ankit Singh Rawat",
                "Aditya Krishna Menon",
                "Seungyeon Kim",
                "Sanjiv Kumar"
            ],
            "title": "Supervision complexity and its role in knowledge distillation",
            "venue": "arXiv preprint arXiv:2301.12245,",
            "year": 2023
        },
        {
            "authors": [
                "Geoffrey Hinton",
                "Oriol Vinyals",
                "Jeff Dean"
            ],
            "title": "Distilling the knowledge in a neural network",
            "venue": "arXiv preprint arXiv:1503.02531,",
            "year": 2015
        },
        {
            "authors": [
                "Daniel Hsu",
                "Ziwei Ji",
                "Matus Telgarsky",
                "Lan Wang"
            ],
            "title": "Generalization bounds via distillation",
            "venue": "arXiv preprint arXiv:2104.05641,",
            "year": 2021
        },
        {
            "authors": [
                "Zehao Huang",
                "Naiyan Wang"
            ],
            "title": "Like what you like: Knowledge distill via neuron selectivity transfer",
            "venue": "arXiv preprint arXiv:1707.01219,",
            "year": 2017
        },
        {
            "authors": [
                "Guangda Ji",
                "Zhanxing Zhu"
            ],
            "title": "Knowledge distillation in wide neural networks: Risk bound, data efficiency and imperfect teacher",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Haoming Jiang",
                "Pengcheng He",
                "Weizhu Chen",
                "Xiaodong Liu",
                "Jianfeng Gao",
                "Tuo Zhao"
            ],
            "title": "Smart: Robust and efficient fine-tuning for pre-trained natural language models through principled regularized optimization",
            "year": 1911
        },
        {
            "authors": [
                "Yuxin Jiang",
                "Chunkit Chan",
                "Mingyang Chen",
                "Wei Wang"
            ],
            "title": "Lion: Adversarial distillation of closed-source large language model",
            "venue": "arXiv preprint arXiv:2305.12870,",
            "year": 2023
        },
        {
            "authors": [
                "Taehyeon Kim",
                "Jaehoon Oh",
                "NakYil Kim",
                "Sangwook Cho",
                "Se-Young Yun"
            ],
            "title": "Comparing kullback-leibler divergence and mean squared error loss in knowledge distillation",
            "venue": "arXiv preprint arXiv:2105.08919,",
            "year": 2021
        },
        {
            "authors": [
                "Jinyu Li",
                "Rui Zhao",
                "Jui-Ting Huang",
                "Yifan Gong"
            ],
            "title": "Learning small-size dnn with output-distributionbased criteria",
            "venue": "In Fifteenth annual conference of the international speech communication association,",
            "year": 2014
        },
        {
            "authors": [
                "Xuechen Li",
                "Tianyi Zhang",
                "Yann Dubois",
                "Rohan Taori",
                "Ishaan Gulrajani",
                "Carlos Guestrin",
                "Percy Liang",
                "Tatsunori B. Hashimoto"
            ],
            "title": "Alpacaeval: An automatic evaluator of instruction-following models",
            "venue": "https://github.com/tatsu-lab/alpaca_eval,",
            "year": 2023
        },
        {
            "authors": [
                "Chen Liang",
                "Simiao Zuo",
                "Qingru Zhang",
                "Pengcheng He",
                "Weizhu Chen",
                "Tuo Zhao"
            ],
            "title": "Less is more: Task-aware layer-wise distillation for language model compression",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Haotian Liu",
                "Chunyuan Li",
                "Qingyang Wu",
                "Yong Jae Lee"
            ],
            "title": "Visual instruction tuning",
            "venue": "arXiv preprint arXiv:2304.08485,",
            "year": 2023
        },
        {
            "authors": [
                "Raphael Gontijo Lopes",
                "Stefano Fenu",
                "Thad Starner"
            ],
            "title": "Data-free knowledge distillation for deep neural networks",
            "venue": "arXiv preprint arXiv:1710.07535,",
            "year": 2017
        },
        {
            "authors": [
                "David Lopez-Paz",
                "L\u00e9on Bottou",
                "Bernhard Sch\u00f6lkopf",
                "Vladimir Vapnik"
            ],
            "title": "Unifying distillation and privileged information",
            "venue": "arXiv preprint arXiv:1511.03643,",
            "year": 2015
        },
        {
            "authors": [
                "David McAllester",
                "Luis Ortiz"
            ],
            "title": "Concentration inequalities for the missing mass and for histogram rule error",
            "venue": "Journal of Machine Learning Research,",
            "year": 2003
        },
        {
            "authors": [
                "Aditya Krishna Menon",
                "Ankit Singh Rawat",
                "Sashank J Reddi",
                "Seungyeon Kim",
                "Sanjiv Kumar"
            ],
            "title": "Why distillation helps: a statistical perspective",
            "venue": "arXiv preprint arXiv:2005.10419,",
            "year": 2020
        },
        {
            "authors": [
                "Michael Mitzenmacher",
                "Eli Upfal"
            ],
            "title": "Probability and computing: Randomization and probabilistic techniques in algorithms and data analysis",
            "year": 2017
        },
        {
            "authors": [
                "Hossein Mobahi",
                "Mehrdad Farajtabar",
                "Peter Bartlett"
            ],
            "title": "Self-distillation amplifies regularization in hilbert space",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Rafael M\u00fcller",
                "Simon Kornblith",
                "Geoffrey Hinton"
            ],
            "title": "Subclass distillation",
            "venue": "arXiv preprint arXiv:2002.03936,",
            "year": 2020
        },
        {
            "authors": [
                "Gaurav Kumar Nayak",
                "Konda Reddy Mopuri",
                "Vaisakh Shaj",
                "Venkatesh Babu Radhakrishnan",
                "Anirban Chakraborty"
            ],
            "title": "Zero-shot knowledge distillation in deep networks",
            "venue": "In International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "Andrew Y Ng",
                "Stuart Russell"
            ],
            "title": "Algorithms for inverse reinforcement learning",
            "venue": "In Icml,",
            "year": 2000
        },
        {
            "authors": [
                "Dang Nguyen",
                "Sunil Gupta",
                "Kien Do",
                "Svetha Venkatesh"
            ],
            "title": "Black-box few-shot knowledge distillation",
            "venue": "In European Conference on Computer Vision,",
            "year": 2022
        },
        {
            "authors": [
                "Tribhuvanesh Orekondy",
                "Bernt Schiele",
                "Mario Fritz"
            ],
            "title": "Knockoff nets: Stealing functionality of black-box models",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Long Ouyang",
                "Jeffrey Wu",
                "Xu Jiang",
                "Diogo Almeida",
                "Carroll Wainwright",
                "Pamela Mishkin",
                "Chong Zhang",
                "Sandhini Agarwal",
                "Katarina Slama",
                "Alex Ray"
            ],
            "title": "Training language models to follow instructions with human feedback",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Ashkan Panahi",
                "Arman Rahbar",
                "Chiranjib Bhattacharyya",
                "Devdatt Dubhashi",
                "Morteza Haghir Chehreghani"
            ],
            "title": "Analysis of knowledge transfer in kernel regime",
            "venue": "In Proceedings of the 31st ACM International Conference on Information & Knowledge Management,",
            "year": 2022
        },
        {
            "authors": [
                "Liam Paninski"
            ],
            "title": "A coincidence-based test for uniformity given very sparsely sampled discrete data",
            "venue": "IEEE Transactions on Information Theory,",
            "year": 2008
        },
        {
            "authors": [
                "Wonpyo Park",
                "Dongju Kim",
                "Yan Lu",
                "Minsu Cho"
            ],
            "title": "Relational knowledge distillation",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Baolin Peng",
                "Chunyuan Li",
                "Pengcheng He",
                "Michel Galley",
                "Jianfeng Gao"
            ],
            "title": "Instruction tuning with gpt-4",
            "venue": "arXiv preprint arXiv:2304.03277,",
            "year": 2023
        },
        {
            "authors": [
                "Mary Phuong",
                "Christoph Lampert"
            ],
            "title": "Towards understanding knowledge distillation",
            "venue": "In International conference on machine learning,",
            "year": 2019
        },
        {
            "authors": [
                "Yury Polyanskiy",
                "Yihong Wu"
            ],
            "title": "Information theory: From coding to learning",
            "venue": "Book draft,",
            "year": 2022
        },
        {
            "authors": [
                "Zengyu Qiu",
                "Xinzhu Ma",
                "Kunlin Yang",
                "Chunya Liu",
                "Jun Hou",
                "Shuai Yi",
                "Wanli Ouyang"
            ],
            "title": "Better teacher better student: Dynamic prior knowledge for knowledge distillation",
            "venue": "arXiv preprint arXiv:2206.06067,",
            "year": 2022
        },
        {
            "authors": [
                "Alec Radford",
                "Jeffrey Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "venue": "OpenAI blog,",
            "year": 2019
        },
        {
            "authors": [
                "Nived Rajaraman",
                "Lin F Yang",
                "Jiantao Jiao",
                "Kannan Ramachandran"
            ],
            "title": "Toward the fundamental limits of imitation learning",
            "venue": "arXiv preprint arXiv:2009.05990,",
            "year": 2020
        },
        {
            "authors": [
                "Aditya Ramesh",
                "Mikhail Pavlov",
                "Gabriel Goh",
                "Scott Gray",
                "Chelsea Voss",
                "Alec Radford",
                "Mark Chen",
                "Ilya Sutskever"
            ],
            "title": "Zero-shot text-to-image generation",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Aditya Ramesh",
                "Prafulla Dhariwal",
                "Alex Nichol",
                "Casey Chu",
                "Mark Chen"
            ],
            "title": "Hierarchical text-conditional image generation with clip latents",
            "venue": "arXiv preprint arXiv:2204.06125,",
            "year": 2022
        },
        {
            "authors": [
                "Paria Rashidinejad",
                "Banghua Zhu",
                "Cong Ma",
                "Jiantao Jiao",
                "Stuart Russell"
            ],
            "title": "Bridging offline reinforcement learning and imitation learning: A tale of pessimism",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Adriana Romero",
                "Nicolas Ballas",
                "Samira Ebrahimi Kahou",
                "Antoine Chassang",
                "Carlo Gatta",
                "Yoshua Bengio"
            ],
            "title": "Fitnets: Hints for thin deep nets",
            "venue": "arXiv preprint arXiv:1412.6550,",
            "year": 2014
        },
        {
            "authors": [
                "St\u00e9phane Ross",
                "Drew Bagnell"
            ],
            "title": "Efficient reductions for imitation learning",
            "venue": "In Proceedings of the thirteenth international conference on artificial intelligence and statistics,",
            "year": 2010
        },
        {
            "authors": [
                "Shai Shalev-Shwartz",
                "Shai Ben-David"
            ],
            "title": "Understanding machine learning: From theory to algorithms",
            "venue": "Cambridge university press,",
            "year": 2014
        },
        {
            "authors": [
                "Suraj Srinivas",
                "Fran\u00e7ois Fleuret"
            ],
            "title": "Knowledge transfer with jacobian matching",
            "venue": "In International Conference on Machine Learning,",
            "year": 2018
        },
        {
            "authors": [
                "Jiaxi Tang",
                "Rakesh Shivanna",
                "Zhe Zhao",
                "Dong Lin",
                "Anima Singh",
                "Ed H Chi",
                "Sagar Jain"
            ],
            "title": "Understanding and improving knowledge distillation",
            "venue": "arXiv preprint arXiv:2002.03532,",
            "year": 2020
        },
        {
            "authors": [
                "Yijun Tian",
                "Shichao Pei",
                "Xiangliang Zhang",
                "Chuxu Zhang",
                "Nitesh V Chawla"
            ],
            "title": "Knowledge distillation on graphs: A survey",
            "venue": "arXiv preprint arXiv:2302.00219,",
            "year": 2023
        },
        {
            "authors": [
                "Yonglong Tian",
                "Dilip Krishnan",
                "Phillip Isola"
            ],
            "title": "Contrastive representation distillation",
            "venue": "arXiv preprint arXiv:1910.10699,",
            "year": 2019
        },
        {
            "authors": [
                "Hugo Touvron",
                "Thibaut Lavril",
                "Gautier Izacard",
                "Xavier Martinet",
                "Marie-Anne Lachaux",
                "Timoth\u00e9e Lacroix",
                "Baptiste Rozi\u00e8re",
                "Naman Goyal",
                "Eric Hambro",
                "Faisal Azhar"
            ],
            "title": "Llama: Open and efficient foundation language models",
            "venue": "arXiv preprint arXiv:2302.13971,",
            "year": 2023
        },
        {
            "authors": [
                "Hugo Touvron",
                "Louis Martin",
                "Kevin Stone",
                "Peter Albert",
                "Amjad Almahairi",
                "Yasmine Babaei",
                "Nikolay Bashlykov",
                "Soumya Batra",
                "Prajjwal Bhargava",
                "Shruti Bhosale"
            ],
            "title": "Llama 2: Open foundation and fine-tuned chat models",
            "venue": "arXiv preprint arXiv:2307.09288,",
            "year": 2023
        },
        {
            "authors": [
                "Alexandre B Tsybakov"
            ],
            "title": "Optimal rates of aggregation",
            "venue": "In Learning Theory and Kernel Machines: 16th Annual Conference on Learning Theory and 7th Kernel Workshop,",
            "year": 2003
        },
        {
            "authors": [
                "Alexandre B. Tsybakov"
            ],
            "title": "Introduction to Nonparametric Estimation. Springer series in statistics",
            "year": 2009
        },
        {
            "authors": [
                "Frederick Tung",
                "Greg Mori"
            ],
            "title": "Similarity-preserving knowledge distillation",
            "venue": "In Proceedings of the IEEE/CVF international conference on computer vision,",
            "year": 2019
        },
        {
            "authors": [
                "Aad W Van der Vaart"
            ],
            "title": "Asymptotic statistics, volume 3",
            "venue": "Cambridge university press,",
            "year": 2000
        },
        {
            "authors": [
                "Aad W van der Vaart",
                "Jon"
            ],
            "title": "A Wellner. Springer series in statistics. Weak convergence and empirical processesSpringer",
            "venue": "New York,",
            "year": 1996
        },
        {
            "authors": [
                "Vladimir Vapnik",
                "Rauf Izmailov"
            ],
            "title": "Learning using privileged information: similarity control and knowledge transfer",
            "venue": "J. Mach. Learn. Res.,",
            "year": 2015
        },
        {
            "authors": [
                "Martin J Wainwright"
            ],
            "title": "High-dimensional statistics: A non-asymptotic viewpoint, volume 48",
            "year": 2019
        },
        {
            "authors": [
                "Dongdong Wang",
                "Yandong Li",
                "Liqiang Wang",
                "Boqing Gong"
            ],
            "title": "Neural networks are more productive teachers than human raters: Active mixup for data-efficient knowledge distillation from a blackbox model",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Guan Wang",
                "Sijie Cheng",
                "Qiying Yu",
                "Changling Liu"
            ],
            "title": "OpenChat: Advancing Open-source Language Models with Imperfect Data, 7 2023a. URL https://github.com/imoneoi/openchat",
            "year": 2023
        },
        {
            "authors": [
                "Lin Wang",
                "Kuk-Jin Yoon"
            ],
            "title": "Knowledge distillation and student-teacher learning for visual intelligence: A review and new outlooks",
            "venue": "IEEE transactions on pattern analysis and machine intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Yizhong Wang",
                "Hamish Ivison",
                "Pradeep Dasigi",
                "Jack Hessel",
                "Tushar Khot",
                "Khyathi Raghavi Chandu",
                "David Wadden",
                "Kelsey MacMillan",
                "Noah A. Smith",
                "Iz Beltagy",
                "Hannaneh Hajishirzi"
            ],
            "title": "How far can camels go? exploring the state of instruction tuning on open resources, 2023b",
            "year": 2023
        },
        {
            "authors": [
                "Zi Wang"
            ],
            "title": "Zero-shot knowledge distillation from a decision-based black-box model",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Karl Weiss",
                "Taghi M Khoshgoftaar",
                "DingDing Wang"
            ],
            "title": "A survey of transfer learning",
            "venue": "Journal of Big data,",
            "year": 2016
        },
        {
            "authors": [
                "Junho Yim",
                "Donggyu Joo",
                "Jihoon Bae",
                "Junmo Kim"
            ],
            "title": "A gift from knowledge distillation: Fast optimization, network minimization and transfer learning",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2017
        },
        {
            "authors": [
                "Hongxu Yin",
                "Pavlo Molchanov",
                "Jose M Alvarez",
                "Zhizhong Li",
                "Arun Mallya",
                "Derek Hoiem",
                "Niraj K Jha",
                "Jan Kautz"
            ],
            "title": "Dreaming to distill: Data-free knowledge transfer via deepinversion",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Ming Yin",
                "Yu Bai",
                "Yu-Xiang Wang"
            ],
            "title": "Near-optimal provable uniform convergence in offline policy evaluation for reinforcement learning",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2021
        },
        {
            "authors": [
                "Bin Yu"
            ],
            "title": "Assouad, fano, and le cam",
            "year": 1997
        },
        {
            "authors": [
                "Li Yuan",
                "Francis EH Tay",
                "Guilin Li",
                "Tao Wang",
                "Jiashi Feng"
            ],
            "title": "Revisiting knowledge distillation via label smoothing regularization",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2020
        },
        {
            "authors": [
                "Sergey Zagoruyko",
                "Nikos Komodakis"
            ],
            "title": "Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer",
            "venue": "arXiv preprint arXiv:1612.03928,",
            "year": 2016
        },
        {
            "authors": [
                "Aohan Zeng",
                "Xiao Liu",
                "Zhengxiao Du",
                "Zihan Wang",
                "Hanyu Lai",
                "Ming Ding",
                "Zhuoyi Yang",
                "Yifan Xu",
                "Wendi Zheng",
                "Xiao Xia"
            ],
            "title": "Glm-130b: An open bilingual pre-trained model",
            "venue": "arXiv preprint arXiv:2210.02414,",
            "year": 2022
        },
        {
            "authors": [
                "Borui Zhao",
                "Quan Cui",
                "Renjie Song",
                "Yiyu Qiu",
                "Jiajun Liang"
            ],
            "title": "Decoupled knowledge distillation",
            "venue": "In Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Lianmin Zheng",
                "Wei-Lin Chiang",
                "Ying Sheng",
                "Siyuan Zhuang",
                "Zhanghao Wu",
                "Yonghao Zhuang",
                "Zi Lin",
                "Zhuohan Li",
                "Dacheng Li",
                "Eric. P Xing",
                "Hao Zhang",
                "Joseph E. Gonzalez",
                "Ion Stoica"
            ],
            "title": "Judging llm-as-a-judge with mt-bench and chatbot arena, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Helong Zhou",
                "Liangchen Song",
                "Jiajie Chen",
                "Ye Zhou",
                "Guoli Wang",
                "Junsong Yuan",
                "Qian Zhang"
            ],
            "title": "Rethinking soft labels for knowledge distillation: A bias-variance tradeoff perspective",
            "venue": "arXiv preprint arXiv:2102.00650,",
            "year": 2021
        },
        {
            "authors": [
                "Banghua Zhu",
                "Jiantao Jiao",
                "Michael I Jordan"
            ],
            "title": "Principled reinforcement learning with human feedback from pairwise or k-wise comparisons",
            "venue": "arXiv preprint arXiv:2301.11270,",
            "year": 2023
        },
        {
            "authors": [
                "Banghua Zhu",
                "Hiteshi Sharma",
                "Felipe Vieira Frujeri",
                "Shi Dong",
                "Chenguang Zhu",
                "Michael I Jordan",
                "Jiantao Jiao"
            ],
            "title": "Fine-tuning language models with advantage-induced policy alignment",
            "venue": "arXiv preprint arXiv:2306.02231,",
            "year": 2023
        },
        {
            "authors": [
                "Zhuangdi Zhu",
                "Kaixiang Lin",
                "Anil K Jain",
                "Jiayu Zhou"
            ],
            "title": "Transfer learning in deep reinforcement learning: A survey",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
            "year": 2023
        },
        {
            "authors": [
                "Gou"
            ],
            "title": "A ADDITIONAL RELATED WORKS We review key paradigms closely related to our formulation, especially KD; and point the reader to Weiss et al",
            "venue": "Alyafeai et al",
            "year": 2024
        },
        {
            "authors": [
                "Nguyen"
            ],
            "title": "2022). However, after the debut of closed-source and game-changing foundation models, practitioners find it plausibly nice to train their own models to purely mimic the response of these strong teachers. For example, though OpenAI only exposes transparent APIs of ChatGPT & GPT-4 (OpenAI, 2023b) to customers, there has been a line of efforts towards distilling black-box language models without even accessing",
            "venue": "of open sourcing (Orekondy et al.,",
            "year": 2019
        },
        {
            "authors": [
                "last-layer logits (Zheng et al",
                "Wang"
            ],
            "title": "Some primary results (Wang et al., 2023a) show that only letting LLaMA (Touvron et al., 2023a) mimic about 6000 carefully chosen trajectories generated by human-GPT-4 interactions can drastically boost the performance of these open-source autoregressive language models on common evaluation benchmarks",
            "venue": "(Gao et al.,",
            "year": 2023
        },
        {
            "authors": [
                "Rajaraman"
            ],
            "title": "2020, Figure 1 (b)). Then it suffices to get a lower bound for a Bayes risk given a prior over P",
            "year": 2020
        },
        {
            "authors": [
                "Remark D"
            ],
            "title": "The empirical variant of vanilla SEL in our second case actually match the log probability, which is by definition normalized. Analyzing an unnormalized version, which is more relevant to the matching the logits in practice",
            "venue": "(Ba & Caruana,",
            "year": 2014
        },
        {
            "authors": [
                "Rajaraman"
            ],
            "title": "Theorem A.2). Given a distribution \u03bd on an alphabet S and n i.i.d. samples X i.i.d",
            "year": 2020
        }
    ],
    "sections": [
        {
            "text": "\u221a |S||A|/n. The second level\nhas the teacher probabilities of sampled labels available in addition, which turns out to boost the convergence rate lower bound to |S||A|/n. However, under this second data acquisition protocol, minimizing a naive adaptation of the cross-entropy loss results in an asymptotically biased student. We overcome this limitation and achieve the fundamental limit by using a novel empirical variant of the squared error logit loss. The third level further equips the student with the soft labels (complete logits) onA given every sampled input, thereby provably enables the student to enjoy a rate |S|/n free of |A|. We find any Kullback-Leibler divergence minimizer to be optimal in the last case. Numerical simulations distinguish the four learners and corroborate our theory."
        },
        {
            "heading": "1 INTRODUCTION",
            "text": "It has become common sense that transferring intrinsic information from teachers to the greatest extent can expedite a student\u2019s learning progress, especially in machine learning given versatile and powerful teacher models. Learning with their assistance has been coined knowledge distillation (KD) (Hinton et al., 2015; Lopez-Paz et al., 2015), a famous paradigm of knowledge transfer leading to remarkable empirical effectiveness in classification tasks across various downstream applications (Gou et al., 2021; Wang & Yoon, 2021; Gu et al., 2023b). The term distillation implies a belief that the inscrutable teacher(s) may possess useful yet complicated structural information, which we should be able to compress and inject into a compact one, i.e., the student model (Breiman & Shang, 1996; Bucilua\u030c et al., 2006; Li et al., 2014; Ba & Caruana, 2014; Allen-Zhu & Li, 2020). This has guided the community towards a line of knowledge transfer methods featuring the awareness of teacher training details or snapshots, such as the original training set, the intermediate activations, the last-layer logits (for a probabilistic classifier), the first- or second-order derivative or statistical information, and even task-specific knowledge (Hinton et al., 2015; Furlanello et al., 2018; Cho & Hariharan, 2019; Zhao et al., 2022; Romero et al., 2014; Zagoruyko & Komodakis, 2016; Yim et al., 2017; Huang & Wang, 2017; Park et al., 2019; Tian et al., 2019; Tung & Mori, 2019; Qiu et al., 2022; Srinivas & Fleuret, 2018; Cheng et al., 2020; Liang et al., 2023).\nHowever, in more general modes of knowledge transfer, the procedure- or architecture-specific information can be unavailable, irrelevant, or ill-defined. Modern proprietary large language models (LLMs) like GPT-4 (OpenAI, 2023b) and Claude 2 (Anthropic, 2023) strictly confine the data returned through their APIs except the generated tokens, not to mention their training sets. Therefore, there has been an effort towards distilling LLMs only through oracle queries via locally crafted prompts (Zheng et al., 2023; Peng et al., 2023). In denoising (Tsybakov, 2003), boosting (Freund & Schapire, 1995), and prediction with expert advice (Cesa-Bianchi et al., 1997), the teacher group itself is the classes of interest and the student only gets positive-valued feedback from the teacher group, so the teacher implementation is immaterial. In certain circumstances of robot learning (Abbeel & Ng, 2004; Ross & Bagnell, 2010), the teacher demonstration may come from threshold-based classifiers or even human experts, where no teacher probability is defined.\nTo unify different natures of teacher information acquisition in knowledge transfer and assess the technical barriers in a principled way, we decompose the transfer set1 into a generative model \u03c0\u22c6(\u00b7|\u00b7) giving one a in the label space A given a query s in the input space S and the additional information provided by the teacher for each sample pair (s,a).2 Take several LLMs as examples. In OpenAI\u2019s chat completion API3 for GPT-4, only responses are returned given a prompt s, in which no privileged information is accessible. An early completion API4 for GPT-3 (Brown et al., 2020), however, also returns the log-likelihood of every token in the generated response. If with open-sourced models like GPT-2 (Radford et al., 2019) in hand, practitioners can extract the last-layer logits of each position in the sampled sequence as the privileged information. These typical examples reveal a trend that the more powerful a foundation model (Bommasani et al., 2021) is, the less likely it is to release privileged information as a teacher model5, which naturally motivates a question:\nWhat is the fundamental limit of knowledge transfer given limited privileged information in general?\nIn this work, we answer this question with minimal inductive bias by analyzing three classic cases with easier difficulties in order over finite S and A. Concretely, for any learner \u03c0\u0302, we study the total variation between it and the reference policy \u03c0\u22c6 conditioned on an input distribution \u03c1, i.e.,\u2211\ns\u2208S \u03c1(s)TV(\u03c0\u0302(\u00b7|s),\u03c0\u22c6(\u00b7|s))=:TV(\u03c0\u0302,\u03c0\u22c6|\u03c1),\nwhere \u03c0\u0302 can access n samples {(si,ai)}ni=1 and optionally certain fraction of \u03c0\u22c6(\u00b7|si),\u2200i\u2208 [n]."
        },
        {
            "heading": "1.1 MAIN CONTRIBUTIONS & CLARIFICATIONS",
            "text": "Table 1 gives an overview of rate bounds in distinct data acquisition protocols. Hard Labels indicates \u03c0\u22c6 to be a black-box for \u03c0\u0302 throughout the learning process. Partial SLs stands for partial soft labels, which means the teacher provides the student with an extra (partial) ground truth \u03c0\u22c6(a|s) for every sample (s,a). Soft Labels is a synonym of the logits on the entire A exposed to \u03c0\u0302 given each s in {si}ni=1. Intuitively, each of the three levels discloses richer information than previous ones, which at least cannot make it harder to learn. Rigorously, progressively faster minimax rates are matching exactly at all levels6 and every high-probability upper bound has its upper confidence radius at most the same order of the corresponding expectation lower bound up to polylog factors.\nTechnically, the later two protocols are nonstandard in density estimation, especially in terms of the derivation of minimax lower bounds in that we assume the data generating process to be (\u03c1\u00d7\u03c0\u22c6)n. The\n1Here we mean the information a student has access to in total. 2Inspired by the learning using privileged information framework (Vapnik et al., 2015; Lopez-Paz et al., 2015). 3https://platform.openai.com/docs/api-reference/chat 4https://platform.openai.com/docs/api-reference/completions 5See, e.g., Ramesh et al. (2021; 2022); OpenAI (2023a) in computer vision for a similar tendency. 6We defer the matching expectation bounds to respective sections.\nconstructive proof (Appendix C.3) of Theorem 4.1 may be of independent interest. The performances at the second level are also more tricky. Theorem 4.3 sentences a naive adaptation of the cross-entropy loss (CEptl) to be a misfit with probability 1 when the privileged information is at a modest level.\nWe do not require \u03c0\u22c6 to be trained in any sense and assume \u03c0\u0302 to have no awareness of the teacher implementation, inspired by the aforementioned practical trend. Consequently, we do no distinguish the teacher probability from the Bayes probability (Menon et al., 2020; Dao et al., 2021) and \u03c1 can have no relation with teacher training. We idealize the samples to be i.i.d., while all the results already extend to the setting where different (s,a) pairs are mildly dependent, of which we refer the readers to Appendix G for detailed discussions.\nWe give more discussions on the connections between our framework and previous formulations in Appendix A.2 and review key related works aiming at the principles of knowledge transfer in the next subsection."
        },
        {
            "heading": "1.2 RELATED WORKS ON UNDERSTANDING KNOWLEDGE TRANSFER",
            "text": "Hinton et al. (2015) refers to the logits generated on a dataset by a teacher model, who has been trained using the same dataset, as soft labels; and refers to {ai}ni=1 in this dataset as hard labels. Our terms, however, pay no attention to whether \u03c1 matches the original dataset; and our Soft Labels strictly carry more information (of \u03c1\u00d7\u03c0\u22c6) than our Hard Labels, both of whose inputs {si}ni=1 are sampled from \u03c1. So the third column of Table 1 does not account for the class similarities argument (Furlanello et al., 2018), the regularization effect via label smoothing (LS) argument (Yuan et al., 2020; Tang et al., 2020), or the bias-variance trade-off argument (Zhou et al., 2021; Menon et al., 2020); all of which are classical wisdom explaining the benefit of soft labels in KD (Hinton et al., 2015).\nThese previous views are neither consistent nor complete for justifying why soft labels improves student training. (M\u00fcller et al., 2020) undermines the hypothesis that class similarities in soft labels are vital by the effectiveness of KD in binary classification. Han et al. (2023) challenges the regularization via LS thesis through better interpretablity-lifting effect of KD than LS. Dao et al. (2021) develops the bias-variance trade-off perspective in more complex scenarios. In contrast, we define Soft Labels (similarly Partial SLs) and tackle its boost over Hard Labels rigorously following the information-theoretic direction of the data processing inequality (Polyanskiy & Wu, 2022). We survey more works unraveling knowledge transfer. Other empirical and enlightening paradigms are deferred to Appendix A.\nMost analyses of KD with trained deep nets as the teacher (Phuong & Lampert, 2019; Ji & Zhu, 2020; Panahi et al., 2022; Harutyunyan et al., 2023) lie in the linear or kernel regime, notably except Hsu et al. (2021), which finds the student network to have fundamentally tighter generalization bound than the teacher network under several nonlinear function approximation schemes. There are also works analyzing knowledge transfer between neural networks of the same architecture (Mobahi et al., 2020; Allen-Zhu & Li, 2020). Our framework goes exactly in the reverse direction: our analysis is not restricted to parsimonious students, over-parameterized teachers; or the compression subconcept of knowledge transfer (Bucilua\u030c et al., 2006; Bu et al., 2020). For example, a human demonstrator, who does not learn only from data and is able to output probabilistic belief, can also fit into the first column of Table 1 as a kind of teacher under our specification of \u03c0\u22c6."
        },
        {
            "heading": "2 PRELIMINARIES",
            "text": "Notation. For two nonnegative sequences {an} and {bn}, we write an = O(bn) or an \u2272 bn if limsupan/bn < \u221e; equivalently, bn = \u2126(an) or bn \u2273 an. We write cn = \u0398(dn) if cn = O(dn) and cn = \u2126(dn). For a metric space (M,d), distd (\u00b7,N ) := infy\u2208N d(\u00b7,y) for any N \u2282 M. The term alphabet is a synonym of finite set. For a set or multiset C, let |C| denote its cardinality. For any alphabet X , on which given two distributions p, q, the total variation between them is TV (p,q) := 0.5\u2225p\u2212q\u22251, their Kullback-Leibler (KL) divergence is KL(p\u2225q) := Ep[logp\u2212 logq]; and we denote all |X | Dirac distributions on X by Dirac(X ), where Dirac(X ,x) stands for the one concentrated at x. For two alphabets X and Y , we denote by \u2206(Y) the probability simplex on Y and define \u2206(Y|X ) :={\u03c0(\u00b7|\u00b7) :X \u2192\u2206(Y)}\u21d2\u03c0(\u00b7|x)\u2208\u2206(Y),\u2200x\u2208X ."
        },
        {
            "heading": "2.1 COMMON SETUP",
            "text": "The teacher always exposes to the student a multiset D= {(si,ai)\u2208S\u00d7A}ni=1 consisting of n i.i.d. input-label tuples. To analyze D in a fine-grained way we introduce for Xn\u220bXn i.i.d.\u223c \u03bd the number of occurrences nx(Xn) of x and themissing mass m0(\u03bd,Xn), which measures the portion of X never observed in Xn (McAllester & Ortiz, 2003). We refer to the input (resp. label) component {si}ni=1 (resp. {ai}ni=1) of D as S(D) (resp. A(D)) and also define a multiset A(D,s) for every s\u2208S to denote the ai\u2019s in D that are associated with the visitations of s, taking into account multiplicity.7"
        },
        {
            "heading": "2.2 QUANTITY OF INTEREST",
            "text": "We assume D \u223c (\u03c1\u00d7 \u03c0\u22c6)n follows a product measure, where \u03c0\u22c6 \u2208 \u2206(A|S) is the ground truth distribution overA given s\u2208S the teacher holds and \u03c1 is some underlying input generating distribution. No assumption is imposed on the data generating process \u03c1\u00d7\u03c0\u22c6 except for belonging to\nP :={\u03c1\u00d7\u03c0\u22c6 :\u03c1\u2208\u2206(S),\u03c0\u22c6\u2208\u2206(A|S)}.\nIn this work, we evaluate the performance of a student \u03c0\u0302 based on theTV between \u03c0\u0302 and \u03c0\u22c6 conditioned on \u03c1 defined as\nTV(\u03c0\u0302,\u03c0\u22c6|\u03c1) :=Es\u223c\u03c1[TV(\u03c0\u0302,\u03c0\u22c6)], (2.1)\nthough the student is never allowed to access \u03c1 directly. We investigate the convergence rate of (2.1) among three categories of students told by the teacher\u2019s degree of openness in the tabular setting. Intuitively speaking, all the learning procedures of interest try to match the log-probability kernel log\u03c0, a notion of normalized logits, between the student and the teacher, especially via variants of the cross-entropy loss, which is standard in the study of classification both theoretically and practically (Paszke et al., 2019). Besides the universal definition CEful(p\u2225q) :=\u2212Ep[logq] of the cross-entropy between p\u226a q, a popular counterpart for hard labels specialized to classifiers is commonly defined as CEsgl(s,a;\u03c0) :=CEful(Dirac(A,a)\u2225\u03c0(\u00b7|s))=\u2212log\u03c0(a|s).\n3 TRANSFER VIA HARD LABELS\nThis is equivalent to the standard setting for estimating the conditional density \u03c0\u22c6(\u00b7|\u00b7)."
        },
        {
            "heading": "3.1 HARDNESS OF ESTIMATION",
            "text": "We first generalize the idea of constructing hard instances for learning discrete distributions on A (Paninski, 2008) to our nonsingleton S to understand the difficulty when only (s,a) paris are available. We remark that the proof of Theorem 3.1 (in Appendix C.2) is the only one in this work that utilizes Assouad\u2019s method (Yu, 1997) directly.\nTheorem 3.1. For nonempty S, A with |A|>1, and n\u2265 |S||A|/4,\ninf \u03c0\u0302\u2208\u03a0\u0302(D) sup \u03c1\u00d7\u03c0\u22c6\u2208P\nE(\u03c1\u00d7\u03c0\u22c6)nTV(\u03c0\u0302,\u03c0\u22c6|\u03c1)\u2273 \u221a\n|S||A| n , (3.1)\nwhere D\u223c(\u03c1\u00d7\u03c0\u22c6)n, \u03a0\u0302(D) denotes all (possibly random) estimators mapping D to \u2206(A|S). The \u221a |S| dependence in the lower bound intuitively makes sense because the classic lower bound\nfor |S|=1 is \u2126( \u221a |A|/n) and each input roughly get n/|S| samples when \u03c1 is distributed evenly."
        },
        {
            "heading": "3.2 MAXIMUM LIKELIHOOD ESTIMATION",
            "text": "We approximate the teacher \u03c0\u22c6 via minimizing the following negative log-likelihood loss:\n7See Appendix B for the rigorous definitions of nx(Xn), m0(\u03bd,Xn), and A(D,s).\n\u03c0\u0302CE,sgl\u2208 argmin \u03c0\u2208\u2206(A|S) CEsgl(D) := argmin \u03c0\u2208\u2206(A|S)\n\u2212 n\u2211\ni=1\nlog\u03c0(ai|si). (3.2)\nIt is possible to exactly attain the minimum 0 in (3.2). A refactoring detailed in Appendix B.1 indicates a natural relation between the hard version CEsgl and the soft version CEful, which leads to a neat closed-form solution for the optimization problem.\n\u03c0\u0302CE,sgl(a|s) { =n(s,a)(D)/ns(S(D)), s\u2208S(D), \u2208\u2206(A) arbitrarily, otherwise. (3.3)\nWe study the convergence behavior of \u03c0\u0302CE,sgl in a fine-grained way with its proof detailed in Appendix D.2: Theorem 3.2. For any \u03b4\u2208(0,1), with probability at least 1\u2212\u03b4,\nTV(\u03c0\u0302CE,sgl,\u03c0 \u22c6|\u03c1)\u2272\n\u221a |S|(|A|+log(|S|/\u03b4))\nn . (3.4) The upper bound in expectation E [TV(\u03c0\u0302CE,sgl,\u03c0\u22c6|\u03c1)] \u2272 \u221a\n|S||A|/n is no better than (3.4) up to log factors. An instance-dependent version in expectation is\nE[TV(\u03c0\u0302CE,sgl,\u03c0\u22c6|\u03c1)]\u2272 \u221a\n|S||A|\u03be(\u03c0\u22c6) n + |S| n , (3.5)\nwhere \u03be(\u03c0\u22c6) :=maxs\u2208SdistTV(\u03c0\u22c6(\u00b7|s),Dirac(A))=2maxs\u2208Smina\u2208A(1\u2212\u03c0\u22c6(a|s)).\nThus, \u03c0\u0302CE,sgl is worst-case optimal and may even have a n\u22121 rate in some benign cases with \u03c0\u22c6 close enough to vertices of the simplex \u2206(A).\n4 TRANSFER VIA PARTIAL SLS\nBesides D, we can also access R := {(si,ai,\u03c0\u22c6(ai|si))}ni=1 as Partial SLs. The introduction of R leads to a quadratic reduction of the learning difficulty."
        },
        {
            "heading": "4.1 BLESSING OF GROUND TRUTH",
            "text": "Theorem 4.1. For nonempty S, A with |A|>2, and n\u2265 |S|(|A|\u22121)/2\u22121,\ninf \u03c0\u0302\u2208\u03a0\u0302(D,R) sup \u03c1\u00d7\u03c0\u22c6\u2208P E(\u03c1\u00d7\u03c0\u22c6)nTV(\u03c0\u0302,\u03c0\u22c6|\u03c1)\u2273 |S||A| n , (4.1)\nwhere D\u223c (\u03c1\u00d7\u03c0\u22c6)n, R= {(s,a,\u03c0\u22c6(a|s)) : (s,a)\u2208D}, and \u03a0\u0302(D,R) denotes all (possibly random) learners mapping (D,R) to \u2206(A|S).\nWe provide a constructive proof of Theorem 4.1 in Appendix C.3, in which we resort to the power of randomized policy so as to reveal the linear in |A| dependence."
        },
        {
            "heading": "4.2 FAILURE OF EMPIRICAL CROSS-ENTROPY LOSS",
            "text": "The Partial SLs R motivates us to define a loss CEptl interpolating between CEsgl and CEful.\n\u03c0\u0302CE,ptl\u2208 argmin \u03c0\u2208\u2206(A|S) CEptl(D,R) := argmin \u03c0\u2208\u2206(A|S)\n\u2212 n\u2211\ni=1\n\u03c0\u22c6(ai|si)log\u03c0(ai|si). (4.2)\nWe can obtain the following exact solution to (4.2) by another technique detailed in Appendix B.2.\n\u03c0\u0302CE,ptl(a|s) { \u221dn(s,a)(D)\u03c0\u22c6(a|s), s\u2208S(D), \u2208\u2206(A) arbitrarily, s /\u2208S(D). (4.3)\nThe convergence analysis of \u03c0\u0302CE,ptl crucially relies on its relationship with \u03c0\u0302CE,sgl. For any s\u2208S(D), \u03c0\u0302CE,ptl can be reformulated as\n\u03c0\u0302CE,ptl(a|s)= \u03c0\u22c6(a|s)\u03c0\u0302CE,sgl(a|s)\u2211 b\u2208A\u03c0 \u22c6(b|s)\u03c0\u0302CE,sgl(b|s) . (4.4)\nLemma 4.2. For |S|=1,\n\u03c0\u0302CE,ptl(\u00b7|s) a.s.\u2212\u2192 [\u03c0\u22c6(\u00b7|s)]2/ \u2211 a\u2208A [\u03c0\u22c6(a|s)]2,\nunder \u2113\u221e in R|A| if \u03c1\u00d7\u03c0\u22c6 is independent of n.\nLemma 4.2 roughly means \u03c0\u0302CE,ptl \u221d (\u03c0\u22c6)2 approximately as n goes to infinity, which implies that small parts of \u03c0\u22c6 are underestimated and large parts of \u03c0\u22c6 are overestimated. We make this intuition technically right in Theorem 4.3, whose rigorous statement, mechanism, and proof are deferred to Appendix D.4. Theorem 4.3. If \u03c1\u00d7\u03c0\u22c6 does not vary with n, \u03c0\u0302CE,ptl coincides with \u03c0\u0302CE,sgl (and thus asymptotically unbiased8) only if \u03c0\u22c6(\u00b7|s)=Uniform(A) or \u03c0\u22c6(\u00b7|s)\u2208Dirac(A) for all s\u2208S. Even for |S|=1, \u03c0\u0302CE,ptl is asymptotically biased in general."
        },
        {
            "heading": "4.3 EMPIRICAL SQUARED ERROR LOGIT LOSS",
            "text": "Ba & Caruana (2014) suggests the practically promising SEL loss9:\nL(\u03c0,\u03c0\u22c6)= n\u2211\ni=1\n1\n2 \u2211 a\u2208A [log\u03c0(a|si)\u2212log\u03c0\u22c6(a|si)]2. (4.5)\nHere we analyze the minimization of its empirical variant with normalized logits under the second data acquisition protocol for simplicity:\nSELptl(D,R) := n\u2211\ni=1\n1 2 [log\u03c0(ai|si)\u2212log\u03c0\u22c6(ai|si)]2. (4.6)\nExact matching on the seen samples in (D,R) shows that \u03c0\u0302SEL,ptl\u2208argmin\u03c0\u2208\u2206(A|S)SELptl(D,R)\n\u21d4 \u03c0\u0302SEL,ptl(\u00b7|s)\u2208 { {p\u2208\u2206(A) :p(a)=\u03c0\u22c6(a|s),\u2200a\u2208A(D,s)}, s\u2208S(D), \u2206(A) arbitrarily, otherwise. (4.7)\nThe following three-fold Theorem 4.4 indicates that \u03c0\u0302SEL,ptl converges faster than \u03c0\u0302CE,sgl by a factor of\u221a n though its performance upper bound has worse dependence on |S||A| compared with that of \u03c0\u0302CE,sgl.\nTheorem 4.4. If |S|>1, for any \u03b4\u2208(0,min(1,(|S|+2)/10)), with probability at least 1\u2212\u03b4,\nTV(\u03c0\u0302SEL,ptl,\u03c0 \u22c6|\u03c1)\u2272\n|S| ( |A|+ \u221a |A|log(|S|/\u03b4) ) n log |S| \u03b4 . (4.8)\nIf |S|=1, for any \u03b4\u2208(0,1/10], with probability at least 1\u2212\u03b4,\nTV(\u03c0\u0302SEL,ptl,\u03c0 \u22c6|\u03c1)=TV(\u03c0\u0302SEL,ptl,\u03c0\u22c6)\u2272 |A| n + \u221a |A| n log 1 \u03b4 . (4.9)\nThe expected risk ETV(\u03c0\u0302SEL,ptl,\u03c0\u22c6|\u03c1)\u2272 |S||A|/n is not polynomially tighter than (4.8) or (4.9). 8Though \u03c0\u0302CE,ptl is not an estimator, we can discuss unbiasedness under a more general notion, i.e., for K constants {ci}Ki=1, the random variables {Xi,n}Ki=1 is called asymptotically unbiased if Xi,n\u2192ci in some mode of convergence as n\u2192\u221e for every i\u2208 [K].\n9Practical versions of SEL often allow unnormalized logits. See Remark D.1 for more discussions.\nRemark 4.5. Theorem 4.3 together with Theorem 4.4 manifests the advantage of employing the empirical SEL loss, which induces an alignment between the normalized logits of the learner and those of \u03c0\u22c6 under squared loss, over the empirical CE loss in offline distillation when the teacher is moderately reserved. A similar observation between these two style of empirical surrogate losses in online policy optimization is verfied in practice (Zhu et al., 2023b).\n5 TRANSFER VIA SOFT LABELS\nAt the lightest level, the student has the extra information Q={(s,\u03c0\u22c6(\u00b7|s) :s\u2208S(D)}. The availability of Q apparently eases the transfer process, especially when the support size |A| of the teacher classifier is huge. Such an intuition can be precisely depicted by a |A|-free minimax lower bound.\n5.1 |A|-FREE LOWER BOUND\nThe following lower bound roughly requires \u2126(|S|) burn-in cost, whose constructive proof is deferred to Appendix C.4. Theorem 5.1. For S with |S|>1, A with |A|>1, and n> |S|\u22121,\ninf \u03c0\u0302\u2208\u03a0\u0302(D,Q) sup \u03c1\u00d7\u03c0\u22c6\u2208P E(\u03c1\u00d7\u03c0\u22c6)nTV(\u03c0\u0302,\u03c0\u22c6|\u03c1)\u2273 |S| n , (5.1)\nwhere D \u223c (\u03c1\u00d7 \u03c0\u22c6)n, Q = {(s,\u03c0\u22c6(\u00b7|s)) :s\u2208S(D)}, and \u03a0\u0302(D,Q) denotes all (possibly random) learners mapping (D,Q) to \u2206(A|S).\nThis setting cannot have a rate better than n\u22121, which is consistent with the n\u22121 rate in Theorem 4.1 since the difficulties of the later two settings (intuitively, the information provided at these two levels) should be the same when \u03c0\u22c6(\u00b7|s)\u2208Dirac(A) for any s\u2208S ."
        },
        {
            "heading": "5.2 KULLBACK-LEIBLER DIVERGENCE MINIMIZATION",
            "text": "Cross-entropy loss minimization under full observation is equivalent to\n\u03c0\u0302CEful \u2208argmin \u03c0 n\u2211 i=1 KL(\u03c0\u22c6(\u00b7|si)\u2225\u03c0(\u00b7|si))\u21d2 \u03c0\u0302CEful(\u00b7|s) { =\u03c0\u22c6(\u00b7|s), if s\u2208S(D), \u2208\u2206(A) arbitrarily, otherwise. (5.2)\nWe give the missing-mass-based proof of the matching upper bounds for \u03c0\u0302CEful in Theorem 5.2 in Appendix D.6. Theorem 5.2. For any \u03b4\u2208(0,1/10], with probability at least 1\u2212\u03b4,\nTV(\u03c0\u0302CEful ,\u03c0 \u22c6|\u03c1)\u2272 |S|\nn + \u221a |S| n log 1 \u03b4 . (5.3)\nThe upper bound ETV(\u03c0\u0302CEful ,\u03c0\u22c6|\u03c1)\u2272 |S|/n on the expected risk for \u03c0\u0302CEful nearly matches (5.3).\nTheorem 5.2 guarantees the optimality of \u03c0\u0302CEful in that it maximally utilizes the given logits."
        },
        {
            "heading": "6 EXPERIMENTS",
            "text": "We conduct simulations to verify the intuitive performance rankings \u03c0\u0302CE,sgl\u2aaf \u03c0\u0302SEL,ptl\u2aaf \u03c0\u0302CEful given moderately large sample sizes and also numerically provide the asymptotical biasedness of \u03c0\u0302CE,ptl with a finite-sample counterpart. Moreover, we design adversarial data generating distributions inspired by the information-theoretic arguments (Appendix C) for the three types of reserved teachers respectively in the non-asymptotic regime, thereby accurately exhibiting the matching convergence rates of \u03c0\u0302CE,sgl, \u03c0\u0302SEL,ptl, and \u03c0\u0302CEful in terms of n.\nIn this section, we specify a fair inductive bias due to the tabular nature: if s /\u2208 S(D), \u03c0\u0302(\u00b7|s) is set to Uniform(A) for all learners; for \u03c0\u0302SEL,ptl(\u00b7|s), the missing mass is amortized uniformly among A\\A(D,s) if s\u2208S(D)."
        },
        {
            "heading": "6.1 CLASSIC REGIME: TELLING LEARNERS APART",
            "text": "In the classic regime, \u03c1\u00d7\u03c0\u22c6 stays invariant no matter whether n tends to infinity or not. An instance in this sense should not only expose the inferior of \u03c0\u0302CE,ptl but also showcase the hardness of |S|>1, i.e., \u03c1 should be strictly bounded away from zero in \u2126(|S|) inputs. To these ends, we specify Instance 0 in Appendix F. We simulate four typical realizations of it, whose estimated risks is presented in Figure 1. Each marker in Figure 1 represents the empirical mean ofTV(\u03c0\u0302,\u03c0\u22c6|\u03c1) in 100 independent repeats given the corresponding sample size n. Any broken line in Figure 1 has nothing to do with sequential design and our experiment is purely offline. As shown in Figure 1 (a, b), either in a general case with (|S|,|A|)= (100,25) or for a 100-armed rewardless bandit, E\u0302TV(\u03c0\u0302CE,ptl,\u03c0\u22c6|\u03c1) fails to converge but all other learners do, corroborating the asymptotically constant bias of \u03c0\u0302CE,ptl and the consistency of the others.\nThough Instance 0 is effectively so easy to learn for any of \u03c0\u0302CE,sgl, \u03c0\u0302SEL,ptl, and \u03c0\u0302CEful that none of the three worst-case upper bounds is tightly attained, the numerical performance rankings among them in Figure 1 coincides with our intuition and theoretical analysis. The \u201cbenign\u201d-case comparison in Figure 1 (c), where the sample sizes are small enough to make the worst-case lower bounds vacuous, still favors \u03c0\u0302CEful over \u03c0\u0302SEL,ptl in the large-|A| regime. Figure 1 (d) manifests that the \u221a |S||A| gap between the worst-case upper bounds for \u03c0\u0302CE,sgl and \u03c0\u0302SEL,ptl, which is reversely dominated by the exponential rate10 of \u03c0\u0302SEL,ptl in this Instance 0, may not be observed in general even for large |S||A| and small n. Remark 6.1. Direct calculations imply that if \u03c1 \u2265 cS > 0 for all inputs with cS irrespective of n when n is large enough, ETV(\u03c0\u0302CEful ,\u03c0\u22c6|\u03c1) can decay exponentially fast, exemplified by Figure 1 (a). ETV(\u03c0\u0302SEL,ptl,\u03c0\u22c6|\u03c1) will enjoy a similar linear convergence so long as we additionally require \u03c0\u22c6(\u00b7|s)\u2265 cA> 0 for all s\u2208S and all labels with cA independent of n for sufficiently large n, again exemplified by Figure 1 (a)."
        },
        {
            "heading": "6.2 NON-ASYMPTOTIC REGIME: ILLUSTRATION OF MATCHING RATES",
            "text": "Instance 0 serves as an intriguing average case, but we need to design worst-case instances that may vary with n (Wainwright, 2019) in the non-asymptotic regime for different data acquisition settings in order to verify the minimax optimalities. The adversarial Instance 1, 2, and 3 with their design insights are detailed in order in Appendix F for verification of matching rates at all three levels.\nSince \u03c0\u0302CE,sgl, \u03c0\u0302SEL,ptl, and \u03c0\u0302CEful enjoy optimal rates of ordern \u22121 orn\u22120.5, we can manifest them using lines in a log-log plot. More generally, if some notion of risk has risk=\u0398(n\u03b2 \u22c6\n) for some \u03b2\u22c6<0, logrisk\u2212\u03b2\u22c6logn will be at least bounded by two straight lines on a log-log scale. We instantiate the\n10See Remark 6.1 for details.\nabove idea for Instance 1, Instance 2, and Instance 3 in Figure 2, in which each marker represents the average of 64000 independent repeats. We also conduct linear regressions over logrisk\u223c logn for corresponding minimax learners and report the slope \u03b2\u0302 as estimated \u03b2\u22c6 in each subfigure of Figure 2.\nRemark 6.2. Regarding parameters other than n as constants, the \u03b2\u0302\u2019s precisely verify the worst-case rates ETV(\u03c0\u0302CE,sgl,\u03c0\u22c6|\u03c1)\u223cn\u22120.5 (Figure 2 (a, b)), ETV(\u03c0\u0302SEL,ptl,\u03c0\u22c6|\u03c1)\u223cn\u22121 (Figure 2 (c, d)), and ETV(\u03c0\u0302CEful ,\u03c0\u22c6|\u03c1)\u223cn\u22121 (Figure 2 (e, f)). Remark 6.3. All Instance 1, 2, and 3 happen to be too easy for \u03c0\u0302CE,ptl to be obviously biased. This phenomenon is actually predictable because \u03c0\u22c6(\u00b7|s) becomes very close to Uniform(A) in Instance 1, and to some one in Dirac(A) in both Instance 2 or 3 for all inputs when n is relatively large. In these cases, \u03c0\u0302CE,ptl largely coincides with \u03c0\u0302CE,sgl as predicted by Theorem 4.3. Remark 6.4. The risks of \u03c0\u0302SEL,ptl in Instance 1 and the risks of \u03c0\u0302CEful in Instance 1 and 2 decay exponentially fast, which is consistent with the arguemnts in Remark 6.1, i.e., only vanishing schemes like \u03c0\u22c6 in Instance 2 for \u03c0\u0302SEL,ptl and \u03c1 in Instance 3 for \u03c0\u0302CEful can force their risks to have a polynomial decay. Remark 6.5. We are able to provably explain the good performance (beyond worst cases) of \u03c0\u0302CE,sgl in Instance 2 and 3, in which \u03be(\u03c0\u22c6)=O(n\u22121). (Recall the definition of \u03be(\u00b7) in Theorem 3.2.) Thus, the instance-dependent bound in Theorem 3.2 indicates a benign-case rate of ETV(\u03c0\u0302CE,sgl,\u03c0\u22c6|\u03c1)\u2272n\u22121."
        },
        {
            "heading": "7 CONCLUSION",
            "text": "We embark on investigating knowledge transfer beyond pure black- or white-box regimes and settle its sample complexity, respectively; provided that the teacher can afford (1) only to act as a generative model, or (2) additionally the probabilities at sampled classes, or (3) additionally the logits conditioned on each sampled input. The theoretical analysis unveils a crucial insight that tailoring the idea of minimizing CE to new information acquisition scenarios may be sub-optimal in general, provably in knowledge transfer via Partial SLs. Several avenues remain to be further explored.\n\u2022 Huge S and A in practice (Zeng et al., 2022; Almazrouei et al., 2023) necessitate function approximation, which is also important to our analysis itself. For example, the equivalent effectiveness of minimizing the CE or SEL loss (with Soft Labels) from an alphabet-matching perspective may be incomplete after incorporating the approximation error, which may consequently corroborate the empirical superior of the vanilla SEL loss (Ba & Caruana, 2014).\n\u2022 All our upper bounds do not adapt to the student initialization strategy for unseen inputs or labels; while the student may be pre-trained in practice (Gu et al., 2023b; Jiang et al., 2023). Thus it is vital to incorporate the skillfulness of the student before transfer to the convergence analysis."
        },
        {
            "heading": "A ADDITIONAL RELATED WORKS",
            "text": "We review key paradigms closely related to our formulation, especially KD; and point the reader to Weiss et al. (2016); Gou et al. (2021); Alyafeai et al. (2020); Zhu et al. (2023c); Wang & Yoon (2021); Tian et al. (2023) for numerous algorithms of knowledge transfer on modalities like sequences, images, graphs, etc. We restrict our survey to the single task of interest: classification. 11\nA.1 INSPIRING PARADIGMS OF KNOWLEDGE TRANSFER IN MACHINE LEARNING\nParadigms of Knowledge Transfer. Knowledge transfer is not a patent of neural nets withsoftmax as their last layers. Similar ideas have realizations for ensemble of classification trees (Breiman & Shang, 1996) and even margin-based classifiers (Burges & Sch\u00f6lkopf, 1996). Since 2010s, there has been a line of work concentrating on the utilization of a trained teacher model and its original training set in a totally white-box manner with the purpose of student accuracy improvement (Hinton et al., 2015; Furlanello et al., 2018; Cho & Hariharan, 2019; Zhao et al., 2022; Romero et al., 2014; Yim et al., 2017; Huang & Wang, 2017; Park et al., 2019; Tian et al., 2019; Tung & Mori, 2019; Qiu et al., 2022). As the computation budget becomes relatively tight with respect to the scale of datasets, another line of works propose to avoid using of the full dataset for teacher pre-training during KD, and resort to architecturespecific metadata (Lopes et al., 2017), synthetic data (Nayak et al., 2019; Yin et al., 2020; Fang et al., 2022), or bootstrapping (Gu et al., 2023a) instead; which is dubbed the data-free approach. The sagacious vision that the teacher architecture may be agnostic or the teacher (log-)probability output may at least go through certain censorship does not receive enough attention from the community in the era of open sourcing (Orekondy et al., 2019; Wang et al., 2020; Wang, 2021; Nguyen et al., 2022). However, after the debut of closed-source and game-changing foundation models, practitioners find it plausibly nice to train their own models to purely mimic the response of these strong teachers. For example, though OpenAI only exposes transparent APIs of ChatGPT & GPT-4 (OpenAI, 2023b) to customers, there has been a line of efforts towards distilling black-box language models without even accessing the last-layer logits (Zheng et al., 2023; Wang et al., 2023b;a). Some primary results (Wang et al., 2023a) show that only letting LLaMA (Touvron et al., 2023a) mimic about 6000 carefully chosen trajectories generated by human-GPT-4 interactions can drastically boost the performance of these open-source autoregressive language models on common evaluation benchmarks (Gao et al., 2021; Li et al., 2023)."
        },
        {
            "heading": "A.2 OUR FORMULATION VERSUS PREVIOUS PARADIGMS",
            "text": "Motivated by the progress trend of knowledge transfer, we decouple the formulation of the input distribution \u03c1 from teacher training details and view the reference poicy \u03c0\u22c6 as the gold standard (ground truth), beyond just a proxy of it. In the following two paragraphs, we would like to also emphasize the distinctions between our formulations and 1) imitation learning (whose performance is measured by reward sub-optimality), or 2) the LUPI framework (Vapnik et al., 2015; Lopez-Paz et al., 2015), respectively.\nOptimality is not explicitly defined for \u03c0\u22c6 in our formulation, yet we solely want to mimic (the conditional density of) the teacher, so \u03c0\u22c6 is dubbed the reference policy. This view aligns with a recent belief that foundation models are by definition \u201cgood\u201d and in effect black-box teachers, judges, and raters of the student ones (Peng et al., 2023; Liu et al., 2023; Zheng et al., 2023). Generally speaking, optimal reward maximization is neither sufficient nor necessary for efficient knowledge transfer (\u21d4 accurate behavioral imitation), because an optimal policy can differ from teacher demonstrations (Ng et al., 2000), which may even be sub-optimal itself (Brown et al., 2019; Chen et al., 2021), and pure behavioral imitation can result in constant sub-optimality (Gao et al., 2023; Zhu et al., 2023a).\nRemark A.1. This work departs from Lopez-Paz et al. (2015, Section 4.1) essentially in several ways. First, our results hold for any legal data generating distribution \u03c1\u00d7\u03c0\u22c6 and do not need to assume data\u2192teacher, data\u2192student, teacher\u2192student transfer rates manually. Second, their result crucially hinges on the assumption that the teacher learns from data faster than the student, while we have clarified our formulation of \u03c0\u22c6 that differs completely. Finally, their transfer speed from the teacher to the student relies on the hardness of classification of each data point, e.g., the notion of linear separability (Shalev-Shwartz & Ben-David, 2014), yet we consider the product space of finite domains S\u00d7A, which does not have these issues.\n11Topics related to knowledge transfer across different tasks or modalities are beyond the scope.\nAdditional Notation in Appendix. For any event I, Ic denotes its complementary event. [K] := {1,...,K} and [K] :={0,...,K\u22121} for any positive integer K. We set (S,A)=(|S|,|A|) and index the input and label spaces by (S,A)=([S],[A]) when necessary. We also use a general notion of Dirac distribution in proving the lower bounds: given any measurable space (Z,\u03a3), we defineDirac(Z,z)(D) := 1{z\u2208D},\u2200D\u2208\u03a3. We denote by log the natural logarithm and adopt the convention 0log0=0."
        },
        {
            "heading": "B MISSING NOTATION, DEFINITIONS, AND DERIVATIONS",
            "text": "Additional Notation in Appendix. For any event I, Ic denotes its complementary event. [K] := {1,...,K} and [K] :={0,...,K\u22121} for any positive integer K. We set (S,A)=(|S|,|A|) and index the input and label spaces by (S,A)=([S],[A]) when necessary. We also use a general notion of Dirac distribution in proving the lower bounds: given any measurable space (Z,\u03a3), we defineDirac(Z,z)(D) := 1{z\u2208D},\u2200D\u2208\u03a3. We denote by log the natural logarithm and adopt the convention 0log0=0. Definition B.1. For n i.i.d. samples Xn drawn from a distribution \u03bd over an alphabet X , the number of occurrences of x is denoted by nx(Xn) := \u2211n i=11{Xi=x}, upon which we further measure the portion of X never observed in Xn by the missing mass\nm0(\u03bd,X n) := \u2211 x\u2208S \u03bd(x)1{nx(Xn)=0}. (B.1)\nIt is worth mentioning that, D, S(D), A(D), and A(D,s),\u2200s\u2208S are treated as multisets when fed into functionals likem0(\u03bd,\u00b7), nx(\u00b7), or the cardinality operator |\u00b7|, for example, |A(D,s)|=ns(S(D)); while in set operations like S\\S(D) or under the summation sign like \u2211 s\u2208S(D), where they act as ranges of enumeration, we slightly abuse the notations for simplicity to refer to their deduplicated counterparts. Definition B.2. All the ns(S(D)) labels in D mapped from si=s form a multiset\nA(D,s) :={a\u2208A : for all (x,a)\u2208D s.t. x=s}."
        },
        {
            "heading": "B.1 MAXIMUM LIKELIHOOD ESTIMATION",
            "text": "\u03c0\u0302CE,sgl\u2208 argmin \u03c0\u2208\u2206(A|S) CEsgl(D)\n= argmin \u03c0\u2208\u2206(A|S) n\u2211 i=1 CEsgl(si,ai;\u03c0)= argmin \u03c0\u2208\u2206(A|S) \u2212 \u2211 s\u2208S \u2211 a\u2208A n(s,a)(D)log(a|s)\n= argmin \u03c0\u2208\u2206(A|S)\n\u2212 \u2211\ns\u2208S(D) ns(S(D)) \u2211 a\u2208A n(s,a)(D) ns(S(D))\nlog\u03c0(a|s)\ufe38 \ufe37\ufe37 \ufe38 \u2212CEful(n(s,\u00b7)(D)/ns(S(D))\u2225\u03c0(\u00b7|s)) . (B.2)\nNoticing that (B.2) is the summation of the cross-entropy between n(s,\u00b7)(D)/ns(S(D)) and\u03c0(\u00b7|s)weighted by ns(S(D)) over S(D), we figure out the explicit solution of \u03c0\u0302CE,sgl as\n\u03c0\u0302CE,sgl(a|s) { =n(s,a)(D)/ns(S(D)), s\u2208S(D), \u2208\u2206(A) arbitrarily, otherwise."
        },
        {
            "heading": "B.2 EMPIRICAL CROSS-ENTROPY LOSS",
            "text": "\u03c0\u0302CE,ptl\u2208 argmin \u03c0\u2208\u2206(A|S) CEptl(D,R)= argmin \u03c0\u2208\u2206(A|S)\n\u2212 \u2211\ns\u2208S(D) Zs \u2211 a\u2208A n(s,a)(D)\u03c0\u22c6(a|s) Zs log\u03c0(a|s),\nwhere Zs := \u2211\na\u2208An(s,a)(D)\u03c0\u22c6(a|s). Therefore, by the same cross-entropy minimization argument, the explicit solution is\n\u03c0\u0302CE,ptl(a|s) = { n(s,a)(D)\u03c0\u22c6(a|s)/Zs, (s,a)\u2208D, 0, s\u2208S(D),a /\u2208A(D,s), } \u221dn(s,a)(D)\u03c0\u22c6(a|s);\n\u2208\u2206(A) arbitrarily, s /\u2208S(D).\nC INFORMATION-THEORETIC ARGUMENTS"
        },
        {
            "heading": "C.1 ADDITIONAL NOTATION IN APPENDIX C",
            "text": "We write KL(\u03c0\u2225\u03c0\u2032|\u03bb) := Ex\u223c\u03bb [KL(\u03c0(\u00b7|x)\u2225\u03c0\u2032(\u00b7|x))] for \u03bb \u2208\u2206(S) and \u03c0,\u03c0\u2032 \u2208\u2206(A|S) likewise for alphabets S,A to have notations concise. The values of \u25b3 in the proofs of Theorem 3.1, Theorem 4.1, and Theorem 5.1 are different under the same notation. A similar logic applies to the values of \u03c0\u03c4 in the proofs of Theorem 3.1 and Theorem 4.1."
        },
        {
            "heading": "C.2 PROOF OF THEOREM 3.1",
            "text": "Proof. We fix \u03c1 to be Uniform(S) and define a loss function over \u2206(A|S)\u00d7\u2206(A|S) as\nl(\u03c0,\u03c0\u2032) :=TV(\u03c0,\u03c0\u2032|\u03c1)= 1 S S\u22121\u2211 s=0 TV(\u03c0(\u00b7|s),\u03c0\u2032(\u00b7|s)). (C.1)\nObviously, (\u2206(A|S),l) becomes a metric space. Without loss of generality, suppose A is even, we decompose l as\ndsA/2+j(\u03c0,\u03c0 \u2032) := ls,j(\u03c0,\u03c0 \u2032) := |\u03c0(2j\u22121|s)\u2212\u03c0\u2032(2j\u22121|s)|+|\u03c0(2j|s)\u2212\u03c0\u2032(2j|s)|\n2S , (C.2)\nl(\u03c0,\u03c0\u2032)= S\u22121\u2211 s=0 A/2\u2211 j=1 ls,j(\u03c0,\u03c0 \u2032)= SA/2\u2211 i=1 di(\u03c0,\u03c0 \u2032). (C.3)\nInspired by Paninski\u2019s construction (Paninski, 2008), we define \u03c0\u03c4 as\n\u03c0\u03c4 (2j\u22121|s)= 1+\u03c4sA/2+j\u25b3\nA ,\u03c0\u03c4 (2j|s)= 1\u2212\u03c4sA/2+j\u25b3 A\n,\u2200(s,j)\u2208 [S]\u00d7 [ A\n2\n] ; (C.4)\nwhere \u03c4 \u2208{\u22121,+1}AS/2 and \u25b3 is to be specified later. For any \u03c4\u223ci \u03c4 \u2032, i.e., any pair in {\u22121,+1}AS/2 that differs only in the i-th coordinate, the construction of \u03c0\u03c4 leads to\ndi(\u03c0\u03c4 ,\u03c0\u03c4 \u2032)= 2\u25b3 SA . (C.5)\nWe thereby refer \u03c4\u223c\u03c4 \u2032 to any pair in {\u22121,+1}AS/2 that differs only in one coordinate and obtain LHS of (3.1)\u2265 inf\n\u03c0\u0302\u2208\u03a0\u0302(D) sup\n\u03c4\u2208{\u22121,+1}AS/2 \u03c1=Uniform(S)\nE(\u03c1\u00d7\u03c0\u03c4 )n l(\u03c0\u0302,\u03c0\u03c4 )\n\u2265 AS 2 \u00b7 2\u25b3/(SA) 2 min \u03c4\u223c\u03c4 \u2032 (1\u2212TV((\u03c1\u00d7\u03c0\u03c4 )n,(\u03c1\u00d7\u03c0\u03c4 \u2032)n)) \u2265\u25b3 4 min \u03c4\u223c\u03c4 \u2032 exp(\u2212KL((\u03c1\u00d7\u03c0\u03c4 )n\u2225(\u03c1\u00d7\u03c0\u03c4 \u2032)n)) = \u25b3 4 min \u03c4\u223c\u03c4 \u2032 exp(\u2212nKL(\u03c1\u00d7\u03c0\u03c4\u2225\u03c1\u00d7\u03c0\u03c4 \u2032))= \u25b3 4 min \u03c4\u223c\u03c4 \u2032 exp(\u2212nKL(\u03c0\u03c4\u2225\u03c0\u03c4 \u2032 |\u03c1))\n= \u25b3 4 exp ( \u2212 n SA \u00b72\u25b3log1+\u25b3 1\u2212\u25b3 ) \u2265\u25b3\n4 exp\n( \u22128 n\nSA \u25b32\n) , (C.6)\nwhere\n\u2022 the second inequality is by Assouad\u2019s lemma (Yu, 1997, Lemma 2),\n\u2022 the third inequality holds due to a variant (Lemma E.2) of the Bretagnolle\u2013Huber inequality,\n\u2022 the first equality holds due to the decomposable property ofKL (Tsybakov, 2009, Section 2.4),\n\u2022 the second equality follows from a basic property of f -divergence (Polyanskiy & Wu, 2022, Proposition 7.2.4),\n\u2022 the last equality is by the definition of \u03c0\u03c4 in (C.4) and \u03c1=Uniform(S),\n\u2022 the last inequality derives from log(1+x)\u2264 x,x> 0 and an additional constraint \u25b3\u2264 0.5 we impose.\nThe assignment \u25b3=0.25 \u221a\nSA/n with n\u2265SA/4 is a feasible choice for inequality (C.6) to hold, whose RHS further equals to\nexp(\u22120.5) 16\n\u221a SA\nn ."
        },
        {
            "heading": "C.3 PROOF OF THEOREM 4.1",
            "text": "Proof. Without loss of generality, we assume A>2 is odd, then for a fixed \u25b3 :=1, which does NOT vary with S, A, or n in THIS proof, we define \u03a0:= { \u03c0\u03c4 :\u03c4 \u2208{\u22121,+1}AS/2 } , where\n\u03c0\u03c4 (2j\u22121|s) := S(1+\u03c4sA/2+j\u25b3)\n2(n+1) ,\n\u03c0\u03c4 (2j|s) := S(1\u2212\u03c4sA/2+j\u25b3)\n2(n+1) ;\n\u03c0\u03c4 (A|s) :=1\u2212 S 2 \u00b7A\u22121 n+1 .\n (s,j)\u2208 [S]\u00d7 [ A\u22121 2 ] . (C.7)\nTo get a lower bound on a Bayes risk, we design a prior over P as\n\u039b:=Dirac(\u2206(S),Uniform(S))\u00d7\u0393, (C.8)\nwhere \u0393:=Uniform(\u03a0).\nIntuitively speaking, for any \u03c1\u00d7\u03c0 sampled from \u039b, \u03c1 must be uniform over S and \u03c0 must be some \u03c0\u03c4 with \u03c4 uniformly distributed over {\u22121,+1}SA/2.12 Therefore, if we let \u039b(D,R) be the corresponding posterior over P conditioned on (D,R) and \u0393(D,R) be the marginal posterior over \u2206(A|S), we can by the definition of \u0393 and \u03c0\u03c4 obtain \u039b(D,R)=Dirac(\u2206(S),Uniform(S))\u00d7\u0393(D,R) where for any (s,a)\u2208{0,...,S\u22121}\u00d7{1,...,A\u22121} and \u03c0\u223c\u0393(D,R), by the Bayes rule,{\n\u0393(D,R)[\u03c0(a|s)=\u03c0\u22c6(a|s)]=1,(s,a)\u2208D or (s,Buddy(a))\u2208D; \u0393(D,R) [ \u03c0(a|s)= S(1+\u25b3)2(n+1) ] =\u0393(D,R) [ \u03c0(a|s)= S(1\u2212\u25b3)2(n+1) ] = 12 ,otherwise;\n(C.9)\nwhere (recall that A>2 is assumed to be odd) we define the \u201cBuddy\u201d for a\u2208 [A\u22121]={1,...,A\u22121} as Buddy(a) := { a\u22121, a is even; a+1, a is odd. (C.10)\nThe intuition behind (C.9) is that if \u03c0\u223c\u0393(D,R), the marginal posterior of \u03c0(a|s) for any seen (s,a) in D must be a Dirac concentrated at \u03c0\u22c6(a|s) and by the design of \u03a0={\u03c0\u03c4}, \u03c0(a|s) is also determined if (s,Buddy(a))\u2208D.13 Note that the last label, A, is designed to be ignored, which we do not consider in both (C.9) and the following argument driven by Fubini\u2019s theorem. We define a event ED(s,a) for every (s,a) with a<A as\nED(s,a)=(s,a)\u2208D or (s,Buddy(a))\u2208D.\nNext, we can apply Fubini\u2019s theorem to the Bayes risk with \u039b as its prior. E\u03c1\u00d7\u03c0\u22c6\u223c\u039b [ E(\u03c1\u00d7\u03c0\u22c6)nTV(\u03c0\u0302,\u03c0\u22c6|\u03c1) ] 12To be technically rigorous, we say the prior for \u03c1 over \u2206(S) and the prior for \u03c0\u22c6 over \u2206(A|S) are assigned independently, similar assignment also appears in the proof of Theorem 5.1. 13Rigorously speaking, \u03c0\u22c6(a|s) in (C.9) refers to some concrete realization to some \u03c0\u03c4 (a|s), which is collected by R. It is a slight abuse of notation and a similar one appears in (C.15) in the proof of Theorem 5.1, too.\n= 1\nS \u2211 s\u2208S E\u03c0\u22c6\u223c\u0393ED\u223c(\u03c1\u00d7\u03c0\u22c6)nE\u03c0\u223c\u0393(D,Q)TV(\u03c0\u0302(\u00b7|s),\u03c0(\u00b7|s))\n\u2265 1 2S \u2211 s\u2208S E\u03c0\u22c6\u223c\u0393ED\u223c(\u03c1\u00d7\u03c0\u22c6)n \u2211 a<A E\u03c0\u223c\u0393(D,Q)|\u03c0\u0302(a|s)\u2212\u03c0(a|s)|\n= 1\n2S \u2211 s\u2208S E\u03c0\u22c6\u223c\u0393ED\u223c(\u03c1\u00d7\u03c0\u22c6)n \u2211 a<A {\nE\u03c0\u223c\u0393(D,Q)[|\u03c0\u0302(a|s)\u2212\u03c0(a|s)||ED(s,a)]E[1{ED(s,a)}|D] +E\u03c0\u223c\u0393(D,Q)[|\u03c0\u0302(a|s)\u2212\u03c0(a|s)||EcD(s,a)]E[1{EcD(s,a)}|D] }\n\u2265 1 2S \u2211 s\u2208S E\u03c0\u22c6\u223c\u0393ED\u223c(\u03c1\u00d7\u03c0\u22c6)n \u2211 a<A E\u03c0\u223c\u0393(D,Q)[|\u03c0\u0302(a|s)\u2212\u03c0(a|s)||EcD(s,a)]E[1{EcD(s,a)}|D]\n= 1\n2S \u2211 s\u2208S E\u03c0\u22c6\u223c\u0393ED\u223c(\u03c1\u00d7\u03c0\u22c6)n \u2211 a<A E[1{EcD(s,a)}|D]\u00b7{\n1\n2 \u2223\u2223\u2223\u2223\u03c0\u0302(a|s)\u2212S(1+\u25b3)2(n+1) \u2223\u2223\u2223\u2223+12 \u2223\u2223\u2223\u2223\u03c0\u0302(a|s)\u2212S(1\u2212\u25b3)2(n+1) \u2223\u2223\u2223\u2223\n}\n\u2265 1 2S \u2211 s\u2208S E\u03c0\u22c6\u223c\u0393ED\u223c(\u03c1\u00d7\u03c0\u22c6)n \u2211 a<A E[1{EcD(s,a)}|D] 1 2 \u00b7 S n+1\n(C.11)\n= 1\n4(n+1) \u2211 s,a:a<A P{(s,a) /\u2208D and (s,Buddy(a)) /\u2208D} (C.12)\n= 1\n4(n+1) \u2211 s,a:a<A ( 1\u2212\u03c1(s)\u00b7 S n+1 )n =\n1\n4(n+1) \u2211 s,a:a<A ( 1\u2212 1 S \u00b7 S n+1 )n = 1\n4(n+1) \u2211 s,a:a<A ( 1\u2212 1 n+1 )n \u2265 S(A\u22121)\n4e(n+1) \u2273\nSA\nn , (C.13)\nwhere the inequality in (C.11) holds because of the triangle inequality and \u25b3 = 1 by design, and the equality in (C.12) holds because for any possible value of \u03c0\u22c6 a priori, i.e., any \u03c0\u03c4 , P{EcD(s,a)} is always (1\u22121/(n+1))n by the design of \u03a0={\u03c0\u03c4}; the penultimate and the last equality hold due to the fact that the distribution of \u03c1 is always Dirac(\u2206(S),Uniform(S)) no matter whether a priori or a posteriori (conditioned on (D,R)). Since the minimax risk is bounded from below by the worst-case Bayes risk (Polyanskiy & Wu, 2022, Theorem 28.1), the proof is completed."
        },
        {
            "heading": "C.4 PROOF OF THEOREM 5.1",
            "text": "Proof. We assign \u03be= 1/(n+1) and design a p\u2208\u2206(S) as p(0)=1\u2212S\u22121/(n+1) and p= 1/(n+1) for all other inputs following Rajaraman et al. (2020, Figure 1 (b)). Then it suffices to get a lower bound for a Bayes risk given a prior over P , which we design as\n\u039b3 :=Dirac(\u2206(S),p)\u00d7\u03933, (C.14) where \u03933 :=Uniform(\u03a0det),\u03a0det :={\u03c0\u2208\u2206(A|S) :\u03c0(\u00b7|s)\u2208Dirac(A),\u2200s\u2208S}. Intuitively speaking, \u03c0\u22c6 is uniformly distributed over all deterministic policies, which indicates the marginal prior distribution of \u03c0\u22c6(\u00b7|s) for any s\u2208S is\n\u03933[\u03c0(\u00b7|s)=Dirac(A,a)]= 1\nA ,\u2200a\u2208A.\nWe abbreviate the corresponding posterior of \u039b3 (resp. \u03933) conditioned on (D,Q) as \u039b3(D,Q) (resp. \u03933(D,Q)), which by definition implies \u039b3(D,Q) = Dirac(\u2206(S),p)\u00d7\u03933(D,Q) and by the Bayes\nformula implies that for any s\u2208S and \u03c0\u223c\u03933(D,Q),{ \u03933(D,Q)[\u03c0(\u00b7|s)=\u03c0\u22c6(\u00b7|s)] =1,s\u2208S(D); \u03933(D,Q)[\u03c0(\u00b7|s)=Dirac(A,a)] =1/A,s\u2208S\\S(D).\n(C.15)\nWithout loss of generality, we assume A>1 is even and then by Fubini\u2019s theorem, E\u03c1\u00d7\u03c0\u22c6\u223c\u039b3 [ E(\u03c1\u00d7\u03c0\u22c6)nTV(\u03c0\u0302,\u03c0\u22c6|\u03c1) ] = \u2211 s\u2208S \u03c1(s)E\u03c0\u22c6\u223c\u03933ED\u223c(\u03c1\u00d7\u03c0\u22c6)nE\u03c0\u223c\u03933(D,Q)TV(\u03c0\u0302(\u00b7|s),\u03c0(\u00b7|s))\n= \u2211 s\u2208S \u03c1(s)E\u03c0\u22c6\u223c\u03933ED\u223c(\u03c1\u00d7\u03c0\u22c6)n { E\u03c0\u223c\u03933(D,Q) [ TV(\u03c0\u0302(\u00b7|s),\u03c0(\u00b7|s)) \u2223\u2223s\u2208S(D)]E[1(s\u2208S(D))|D] +E\u03c0\u223c\u03933(D,Q) [ TV(\u03c0\u0302(\u00b7|s),\u03c0(\u00b7|s))\n\u2223\u2223s /\u2208S(D)]E[1(s /\u2208S(D))|D]} \u2265 \u2211 s\u2208S \u03c1(s)E\u03c0\u22c6\u223c\u03933ED\u223c(\u03c1\u00d7\u03c0\u22c6)n { E[1(s /\u2208S(D))|D]E\u03c0\u223c\u03933(D,Q) [ TV(\u03c0\u0302(\u00b7|s),\u03c0(\u00b7|s))\n\u2223\u2223s /\u2208S(D)]} = \u2211 s\u2208S \u03c1(s)E\u03c0\u22c6\u223c\u03933E(\u03c1\u00d7\u03c0\u22c6)n { E[1(s /\u2208S(D))|D]\u00b7 1 A \u2211 a\u2208A TV(\u03c0\u0302(\u00b7|s),Dirac(A,a)) } ,\n= \u2211 s\u2208S \u03c1(s)E\u03c0\u22c6\u223c\u03933E(\u03c1\u00d7\u03c0\u22c6)n{\nE[1(s /\u2208S(D))|D]\u00b7 1 A A/2\u22121\u2211 a=0 [TV(\u03c0\u0302(\u00b7|s),Dirac(A,a))+TV(\u03c0\u0302(\u00b7|s),Dirac(A,a+A/2))]\n} \u2265 \u2211 s\u2208S \u03c1(s)P(s /\u2208S(D)) 1 A A/2\u22121\u2211 a=0 TV(Dirac(A,a),Dirac(A,a+A/2))\n= \u2211 s\u2208S \u03c1(s)P(s /\u2208S(D)) 1 A \u00b7A 2 = 1 2 \u2211 s\u2208S \u03c1(s)P(s /\u2208S(D)), (C.16)\nwhere the last inequality holds due to the triangle inequality of TV. Therefore, LHS of (C.16)\u22650.5 \u2211 s\u2208S \u03c1(s)P(s /\u2208S(D))=0.5 \u2211 s\u2208S \u03c1(s)(1\u2212\u03c1(s))n\n\u2265 S\u22121 2(n+1)\n( 1\u2212 1\nn+1\n)n \u2265 S\u22121\n2e(n+1) \u2273\nS n , (C.17)\nwhere the second inequality is by only considering the S\u2212 1 inputs with mass 1/(n+1). Since the minimax risk is bounded from below by the worst-case Bayes risk, the proof is completed."
        },
        {
            "heading": "D ARGUMENTS FOR SPECIFIC LEARNERS",
            "text": ""
        },
        {
            "heading": "D.1 ADDITIONAL DEFINITIONS IN APPENDIX D",
            "text": "In this section we denote the MLE of \u03c1 by\n\u03c1\u0302(\u00b7) := n(\u00b7)(S(D))\nn . (D.1)\nThe event Bs,i defined as follows will be used in the proofs of Theorem 3.2 and Theorem 4.4.\nBs,i :={ns(S(D))= i},\u2200(s,i)\u2208S\u00d7[n+1]. (D.2)"
        },
        {
            "heading": "D.2 PROOF OF THEOREM 3.2",
            "text": ""
        },
        {
            "heading": "D.2.1 PROOF OF THE HIGH-PROBABILITY BOUND",
            "text": "Proof. For |S|>1, we define\nus :=ns(S(D))TV(\u03c0\u0302CE,sgl(\u00b7|s),\u03c0\u22c6(\u00b7|s)),\u2200s\u2208S.\nWe decompose the LHS of (3.4) as\nLHS= \u2211 s\u2208S ( ns(S(D)) n +\u03c1(s)\u2212\u03c1\u0302(s) ) TV(\u03c0\u0302CE,sgl(\u00b7|s),\u03c0\u22c6(\u00b7|s))\n\u2264 \u2211 s\u2208S us n + \u2211 s\u2208S |\u03c1(s)\u2212\u03c1\u0302(s)|TV(\u03c0\u0302CE,sgl(\u00b7|s),\u03c0\u22c6(\u00b7|s))\n\u2264 1 n \u2211 s\u2208S\nus+2TV(\u03c1,\u03c1\u0302)\ufe38 \ufe37\ufe37 \ufe38 (i) , (D.3)\nwhere the first inequality is by triangle inequality and the second one holds due to the boundedness of TV. We define another two types of events to bound (i) in (D.3):\nDs := { us\u2264 \u221a ns(S(D))\n2\n( |A|log2+log |S|+1\n\u03b4\n)} ,\u2200s\u2208S; (D.4)\nE := { 2TV(\u03c1,\u03c1\u0302)\u2264 \u221a 2\nn\n( |S|log2+log |S|+1\n\u03b4\n)} . (D.5)\nNotice that P(Dcs|Bs,0) = 0 by the definition of Bs,i in (D.2) and for any i > 0, P(Dcs|Bs,i)\u2264 \u03b4/(|S|+1),\u2200s\u2208S by Lemma E.4; thus by the law of total probability,\nP(Ds)= n\u2211\ni=0\nP(Ds|Bs,i)P(Bs,i)\u2265 ( 1\u2212 \u03b4\n|S|+1 ) n\u2211 i=0 P(Bs,i)=1\u2212 \u03b4 |S|+1 ,\u2200s\u2208S. (D.6)\nAlso noticing that P(Ec)\u2264 \u03b4/(|S|+1) by Lemma E.4, we apply a union bound over Ec and {Dcs}s\u2208S for (i) in (D.3) to conclude that with probability at least 1\u2212\u03b4,\n(i)\u2264 \u221a\n|A|log2+log((|S|+1)/\u03b4) 2\n\u00b7 \u2211 s\u2208S \u221a ns(S(D)) n\ufe38 \ufe37\ufe37 \ufe38 \u2661 + \u221a 2 n ( |S|log2+log |S|+1 \u03b4 ) . (D.7)\nBy the Cauchy-Schwarz inequality,\n\u2661 in (D.7)\u2264 1 n\n\u221a |S| \u2211 s\u2208S ns(S(D))= \u221a |S| n . (D.8)\nSubstituting (D.8) back to the RHS of (D.7) yields the conclusion. The case of |S|=1 follows from Lemma E.4."
        },
        {
            "heading": "D.2.2 PROOF OF THE WORST-CASE UPPER BOUND IN EXPECTATION",
            "text": "Proof. Taking expectation on both sides of (D.3) yields\nE[TV(\u03c0\u0302CE,sgl,\u03c0\u22c6|\u03c1)]\u2264 1\nn \u2211 s\u2208S Eus+ \u221a |S| n\n= 1\nn \u2211 s\u2208S E ns(S(D))E[TV(\u03c0\u0302CE,sgl(\u00b7|s),\u03c0\u22c6(\u00b7|s))|ns(S(D))]\ufe38 \ufe37\ufe37 \ufe38 =:u\u0303s +\u221a |S| n , (D.9)\nwhere the inequality holds due to Lemma E.3. For every s, we trivially have u\u0303s\u2264 \u221a |A|ns(S(D))\n2 (D.10)\nif conditioned on Bs,0. If otherwise conditioned on Bcs,0, we still have u\u0303s\u2264 \u221a |A|ns(S(D))\n2 , (D.11)\nwhere the inequality follows from Lemma E.3. Therefore, substituting (D.10) and (D.11) back to (D.9) gives\nLHS of (D.9)\u2264 \u221a\n|A| 2n \u2211 s\u2208S E \u221a ns(S(D))+ \u221a |S| n \u2264 \u221a |A| 2n \u2211 s\u2208S \u221a \u03c1(s)+ \u221a |S| n\n\u2272 \u221a |S||A| n ,\nwhere the first inequality follows from the law of total expectation with respect to Bs,0 and Bcs,0, the second inequality follows from Jensen\u2019s inequality together with the definition of ns(S(D)), and the last inequality is by the Cauchy-Schwarz inequality."
        },
        {
            "heading": "D.2.3 PROOF OF THE INSTANCE-DEPEDENT UPPER BOUND IN EXPECTATION",
            "text": "Proof. We define the set of the numbers of occurences of all inputs as NS :={ns(S(D)) :s\u2208S}. (D.12) Then we decompose the LHS of (3.5) as\u2211 s\u2208S \u03c1(s)E[TV(\u03c0\u0302CE,sgl(\u00b7|s),\u03c0\u22c6(\u00b7|s))]\n=E[\u2211 s\u2208S(D) \u03c1(s)E [ TV(\u03c0\u0302CE,sgl(\u00b7|s),\u03c0\u22c6(\u00b7|s)) \u2223\u2223\u2223\u2223NS]\n+ \u2211\ns\u2208S\\S(D)\n\u03c1(s)E [ TV(\u03c0\u0302CE,sgl(\u00b7|s),\u03c0\u22c6(\u00b7|s)) \u2223\u2223\u2223\u2223NS] ]\n\u2264E  \u2211 s\u2208S(D) \u03c1(s)E [ TV(\u03c0\u0302CE,sgl(\u00b7|s),\u03c0\u22c6(\u00b7|s)) \u2223\u2223\u2223\u2223ns(S(D))] \n\ufe38 \ufe37\ufe37 \ufe38 I1\n+Em0(\u03c1,S(D))\ufe38 \ufe37\ufe37 \ufe38 I2 , (D.13)\nwhere the inequality is by the definition and boundedness of TV(\u03c0\u0302CE,sgl(\u00b7|s),\u03c0\u22c6(\u00b7|s)). We divide I1 and I2 so at to conquer them as follows.\nBounding I1. For every s\u2208S, we define I1(s) :=E [ TV(\u03c0\u0302CE,sgl(\u00b7|s),\u03c0\u22c6(\u00b7|s)) \u2223\u2223\u2223\u2223ns(S(D))]. Then we can bound I1(s) by Jensen\u2019s inequality for s\u2208S(D):\nI1(s)= 1\n2 \u2211 a\u2208A E [ |\u03c0\u0302CE,sgl(a|s)\u2212\u03c0\u22c6(a|s)| \u2223\u2223\u2223\u2223ns(S(D))]\n\u2264 1 2 \u2211 a\u2208A \u221a\u221a\u221a\u221aE[ (ns(S(D))\u03c0\u0302CE,sgl(a|s)\u2212ns(S(D))\u03c0\u22c6(a|s))2 [ns(S(D))]2 \u2223\u2223\u2223\u2223ns(S(D)) ]\n= 1\n2 \u2211 a\u2208A\n\u221a \u03c0\u22c6(a|s)(1\u2212\u03c0\u22c6(a|s))\nns(S(D)) , (D.14)\nwhere the last equality holds due to the observation that ns(S(D))\u03c0\u0302CE,sgl(a|s) \u2223\u2223ns(S(D))\u223cBinomial(ns(S(D)),\u03c0\u22c6(a|s)).\nTherefore, we can bound the summation inside the expectation of I1 as\u2211 s\u2208S(D) \u03c1(s)I1(s)= 1 2 \u2211 a\u2208A \u2211 s\u2208S(D) \u221a \u03c1(s) \u221a \u03c1(s) \u03c0\u22c6(a|s)(1\u2212\u03c0\u22c6(a|s)) ns(S(D))\n\u2264 1\u221a 2 \u2211 a\u2208A \u2211 s\u2208S \u221a \u03c1(s)\n\u221a \u03c1(s)\n\u03c0\u22c6(a|s)(1\u2212\u03c0\u22c6(a|s)) 1+ns(S(D))\n\u2264 1\u221a 2 \u2211 a\u2208A \u221a\u2211 s\u2208S \u03c1(s) \u03c0\u22c6(a|s)(1\u2212\u03c0\u22c6(a|s)) 1+ns(S(D)) , (D.15)\nwhere the first inequality holds due to ns(S(D)) \u2265 1,\u2200s \u2208 S(D) and the last inequality is by the Cauchy-Schwarz inequality. Substituting (D.15) into I1=E[ \u2211 s\u2208S(D)\u03c1(s)I1(s)] gives\nI1\u2264 1\u221a 2 \u2211 a\u2208A \u221a\u2211 s\u2208S \u03c0\u22c6(a|s)(1\u2212\u03c0\u22c6(a|s))E \u03c1(s) 1+ns(S(D))\n\u2264 1\u221a 2 \u2211 a\u2208A \u221a\u2211 s\u2208S \u03c0\u22c6(a|s)(1\u2212\u03c0\u22c6(a|s)) n+1 \u2264 1\u221a 2(n+1) \u2211 a\u2208A \u221a\u2211 s\u2208S min(\u03c0\u22c6(a|s),1\u2212\u03c0\u22c6(a|s)) \u2264 1\u221a 2(n+1) \u221a |A| \u2211 a\u2208A \u2211 s\u2208S min(\u03c0\u22c6(a|s),1\u2212\u03c0\u22c6(a|s))\n\u2264 \u221a |S||A| 2(n+1) \u00b7 \u221a\u221a\u221a\u221a\u221a\u221amaxs\u2208S \u2211 a\u2208A\nmin(\u03c0\u22c6(a|s),1\u2212\u03c0\u22c6(a|s))\ufe38 \ufe37\ufe37 \ufe38 \u03be\u0303(\u03c0\u22c6) , (D.16)\nwhere the first inequality is by Jensen\u2019s inequality, the second inequality derives from Lemma E.8, and the penultimate inequality holds due to the Cauchy-Schwarz inequality. \u03be\u0303(\u03c0\u22c6) in (D.16) can be further bounded from above by\nmax s\u2208S min b\u2208A 1\u2212\u03c0\u22c6(b|s)+ \u2211 a:a \u0338=b \u03c0\u22c6(a|s) =max s\u2208S min b\u2208A TV(\u03c0\u22c6(\u00b7|s),Dirac(A,b))\n=max s\u2208S\ndistTV(\u03c0 \u22c6(\u00b7|s),Dirac(A))=\u03be(\u03c0\u22c6).\nTo sum up, I1\u2272 \u221a \u03be(\u03c0\u22c6)|S||A|n\u22121.\nBounding I2. Explicit calculation yields\nI2= \u2211 s\u2208S \u03c1(s)(1\u2212\u03c1(s))n\u2264 4|S| 9n \u2272 |S| n ,\nwhere the inequality follows from Lemma E.5."
        },
        {
            "heading": "D.3 PROOF OF LEMMA 4.2",
            "text": "Proof. Since |S|=1, we omit the conditioning on s\u2208S for brevity in this proof. By Lemma E.1,\n\u03c0\u0302CE,sgl a.s.\u2212\u2192\u03c0\u22c6.\nTherefore, applying the continuous mapping theorem (Durrett, 2019, Theorem 3.2.10) to (4.4) gives\n\u03c0\u0302CE,ptl(a) a.s.\u2212\u2192 [\u03c0 \u22c6(a)] 2\u2211\nb\u2208A[\u03c0 \u22c6(b)]\n2\nuniformly for every a\u2208A."
        },
        {
            "heading": "D.4 PROOF OF THEOREM 4.3",
            "text": "Proof. By (3.3) and (4.3), \u03c0\u0302CE,sgl(\u00b7|s) \u221d ns(S(D)) and \u03c0\u0302CE,ptl(\u00b7|s) \u221d ns(S(D))\u03c0\u22c6(\u00b7|s) for any s\u2208S(D). Therefore, the solution set of \u03c0\u0302CE,ptl coincides with that of \u03c0\u0302CE,sgl only if \u03c0\u22c6=Uniform(A) or \u03c0\u22c6\u2208Dirac(A); otherwise Lemma 4.2 implies that\nliminf n\u2192\u221e\nTV(\u03c0\u0302CE,ptl,\u03c0 \u22c6|\u03c1)>0 almost surely,\nand we thus rigorously justify the \u2126(1) in Table 1 with probability one."
        },
        {
            "heading": "D.5 PROOF OF THEOREM 4.4",
            "text": ""
        },
        {
            "heading": "D.5.1 PROOF OF THE HIGH-PROBABILITY BOUNDS",
            "text": "Proof. For |S|>1, we define\nvs :=ns(S(D))TV(\u03c0\u0302SEL,ptl(\u00b7|s),\u03c0\u22c6(\u00b7|s))\nand decompose LHS of (4.8) into three terms as LHS\u2264 \u2211 s\u2208S \u03c1\u0302(s)TV(\u03c0\u0302SEL,ptl(\u00b7|s),\u03c0\u22c6(\u00b7|s))+ \u2211 s\u2208S |\u03c1(s)\u2212\u03c1\u0302(s)|TV(\u03c0\u0302SEL,ptl(\u00b7|s),\u03c0\u22c6(\u00b7|s)) (D.17)\n\u2264 1 n \u2211 s\u2208S vs+ 1 n \u2211 s\u2208S(D) \u2223\u2223\u2223\u2223\u03c1(s)\u03c1\u0302(s)\u22121 \u2223\u2223\u2223\u2223vs+ m0(\u03c1,S(D)), matches Definition B.1\ufe37 \ufe38\ufe38 \ufe37\u2211 s\u2208S\\S(D) \u03c1(s)\n\ufe38 \ufe37\ufe37 \ufe38 (ii)\n, (D.18)\nwhere \u03c1\u0302 is defined in (D.1) and the second inequality follows from \u03c1\u0302(s)=0,\u2200s\u2208S\\S(D) along with the boundedness of TV. We additionally define two kinds of events to bound (ii) in (D.18).\nD\u030cs= { vs\u2264 4\n9 |A|+3\n\u221a |A|log |S|+2\n\u03b4\n} ,\u2200s\u2208S;\nE\u030c= { m0(\u03c1,S(D))\u2264\n4|S| 9n + 3 \u221a |S| n log |S|+2 \u03b4 } .\nRecall Definition B.2 for A(D,s), if ns(S(D))>0, by (4.7), 2TV(\u03c0\u0302SEL,ptl(\u00b7|s),\u03c0\u22c6(\u00b7|s))= \u2211 a\u2208A |\u03c0\u0302SEL,ptl(a|s)\u2212\u03c0\u22c6(a|s)|\n= \u2211\na\u2208A\\A(D,s)\n|\u03c0\u0302SEL,ptl(a|s)\u2212\u03c0\u22c6(a|s)|\u22642m0(\u03c0\u22c6(\u00b7|s),A(D,s)), (D.19)\nwhere the inequality holds due to triangle inequality. Consequently,\nvs\u2264ns(S(D))m0(\u03c0\u22c6(\u00b7|s),A(D,s)),\u2200s\u2208S(D);\nto which we apply Lemma E.7 to obtain\nP(D\u030ccs|Bs,i)\u2264 \u03b4\n|S|+2 ,\u2200i>0;\nwhere Bs,i is defined in (D.2). Also noticing that P(D\u030ccs|Bs,0)=0 by definition, we can control P(D\u030cs) by\nP(D\u030cs)= n\u2211 i P(D\u030cs|Bs,i)P(Bs,i)\u2265 ( 1\u2212 \u03b4 |S|+2 ) n\u2211 i P(Bs,i)=1\u2212 \u03b4 |S|+2 ,\u2200s\u2208S.\nSince P(E\u030c)\u22651\u2212\u03b4/(|S|+2) by Lemma E.7, we apply a union bound over E\u030cc and {D\u030ccs}s\u2208S for (ii) in (D.18) to conclude that with probability at least 1\u2212(|S|+1)\u03b4/(|S|+2),\n(ii)\u2264 4|A|+3\n\u221a |A|log((|S|+2)/\u03b4)\n9n \u00b7\n|S|+ \u25b2\ufe37 \ufe38\ufe38 \ufe37\u2211\ns\u2208S(D) \u2223\u2223\u2223\u2223\u03c1(s)\u03c1\u0302(s)\u22121 \u2223\u2223\u2223\u2223\ufe38 \ufe37\ufe37 \ufe38\n=:os  + 4|S| 9n + 3 \u221a |S| n log |S|+2 \u03b4 .\n(D.20)\nWe further decompose \u25b2 in (D.20) in a pragmatically tight enough way as\n\u25b2\u2264|S|+ \u2211\ns\u2208S(D)\n\u03c1(s) \u03c1\u0302(s) = |S|+ \u2211 s\u2208S(D) n\u03c1(s) ns(S(D))\n= |S|+ \u2211\ns\u2208S(D)\n2n\u03c1(s)\nns(S(D))+ns(S(D)) \u2264|S|+2 \u2211 s\u2208S(D)\nn\u03c1(s)\nns(S(D))+1\n\u2264|S|+2 \u2211 s\u2208S\nn\u03c1(s)\nns(S(D))+1\n= |S|+ \u2211 s\u2208S\u0304\nn\u03c1(s)\nns(S(D))+1\ufe38 \ufe37\ufe37 \ufe38 \u25b2\u0304\n+ \u25b2\u0303\ufe37 \ufe38\ufe38 \ufe37\u2211 s\u2208S\u0303 n\u03c1(s)\nns(S(D))+1\ufe38 \ufe37\ufe37 \ufe38 rs , (D.21)\nwhere S\u0304 and S\u0303 are defined as S\u0304 := { s\u2208S :0<\u03c1(s)< log(|S|(|S|+2)/\u03b4)\nn \u00b7 200 99\n} , (D.22)\nS\u0303 := { s\u2208S :\u03c1(s)\u2265 log(|S|(|S|+2)/\u03b4)\nn \u00b7 200 99\n} . (D.23)\nBy the definition of S\u0304, all s\u2019s in S\u0304 have small enough \u03c1(s), and thus \u25b2\u0304 in (D.21) can be trivially bounded from above, i.e.,\n\u25b2\u0304\u2264 200 99 |S|log |S|(|S|+2) \u03b4 . (D.24)\nFor each s\u2208S\u0303, we define\n\u03b7s :=\n\u221a 2log(|S|(|S|+2)/\u03b4)\nn\u03c1(s) ,\nthen by the definition of S\u0303, 1\u2212\u03b7s\u22650.1. Therefore, noticing that ns(S(D))\u223cBinomial(n,\u03c1(s)), we can apply Corollary E.10 to each rs in (D.21) to conclude that for every s\u2208S\u0303 , with probability at least 1\u2212\u03b4/(|S|(|S|+2)),\nrs n\u03c1(s) \u2264 1 (1\u2212\u03b7s)n\u03c1(s)+1 \u2264 1 0.1n\u03c1(s)+1 \u2264 10 n\u03c1(s) , (D.25)\nwhich followed by a union bound argument within S\u0303 yields that with probability at least 1\u2212\u03b4/(|S|+2),\n\u25b2\u0303 in (D.21)\u226410|S|. (D.26)\nWe then denote by E\u0303 the event conditioned on which (D.26) holds and denote by E\u0307 the event conditioned on which (D.20) holds. A union bound argument over E\u0303c and E\u0307c shows that with probability at least 1\u2212\u03b4, the LHS of (4.8) is bounded from above by\n4|A|+3 \u221a |A|log((|S|+2)/\u03b4) 9n \u00b7 ( 12|S|+200 99 |S|log |S|(|S|+2) \u03b4 ) + 4|S| 9n + 3 \u221a |S| n log |S|+2 \u03b4 .\nFor |S|=1, invoking Lemma E.7 for (D.19) to draw the conclusion."
        },
        {
            "heading": "D.5.2 PROOF OF THE UPPER BOUND IN EXPECTATION",
            "text": "Proof. Substituting (D.19) into (D.17) yields an upper bound for ETV(\u03c0\u0302SEL,ptl,\u03c0\u22c6|\u03c1) as\n1\nn \u2211 s\u2208S Evs+ \u2211 s\u2208S E |\u03c1(s)\u2212\u03c1\u0302(s)|E[m0(\u03c0\u22c6(\u00b7|s),A(D,s))|ns(S(D))]\ufe38 \ufe37\ufe37 \ufe38 v\u0303s . (D.27) Each Evs in (D.27) can be bounded from above via (D.19) by\nE ns(S(D))E[m0(\u03c0\u22c6(\u00b7|s),A(D,s))|ns(S(D))]\ufe38 \ufe37\ufe37 \ufe38 v\u0304s . (D.28) Conditioned on Bcs,0, invoking Lemma E.5 to conclude\nv\u0304s\u2264 4|A| 9 . (D.29)\nThe above inequality trivially holds if otherwise conditioned on Bs,0. Similarly, we always have\nv\u0303s\u2264\u03c1(s) |A| ns(S(D))+1 + 4|A| 9n . (D.30)\nSubstituting (D.29) back to (D.28) gives\n1\nn \u2211 s\u2208S Evs\u2272 |S||A| n . (D.31)\nBy Lemma E.8, substituing (D.30) and (D.31) back to (D.27) yields\nETV(\u03c0\u0302SEL,ptl,\u03c0\u22c6|\u03c1)\u2272 |S||A| n +|A| \u2211 s\u2208S E \u03c1(s) ns(S(D))+1 \u2272 |S||A| n . (D.32)\nRemark D.1. The empirical variant of vanilla SEL in our second case actually match the log probability, which is by definition normalized. Analyzing an unnormalized version, which is more relevant to the matching the logits in practice (Ba & Caruana, 2014; Kim et al., 2021), in the second setting may call for new techniques. Also, some preliminary results on the empirical side manifest the difference between minimizing forward KL and reverse KL in scenarios related to our last setting (Jiang et al., 2019; Gu et al., 2023b; Agarwal et al., 2023), whose analysis are left are future work."
        },
        {
            "heading": "D.6 PROOF OF THEOREM 5.2",
            "text": "Proof. Since TV is bounded from above by 1 and TV(\u03c0\u0302CEful(\u00b7|s),\u03c0\u22c6(\u00b7|s))=0,\u2200s\u2208S(D), LHS= \u2211\ns\u2208S\\S(D) \u03c1(s)TV(\u03c0\u0302CEful(\u00b7|s),\u03c0\u22c6(\u00b7|s))\u2264 \u2211 s\u2208S \u03c1(s)1{s /\u2208S(D)}=:M. (D.33)\nNoticing that M realizes Definition B.1 to m0(\u03c1,S(D)), we invoke Lemma E.7 to get M\u2264EM+ 3 \u221a\n|S|log(1/\u03b4) n \u2264 4|S| 9n\n+ 3 \u221a\n|S|log(1/\u03b4) n . (D.34)\nSubstituting (D.34) back to (D.33) finishes the proof."
        },
        {
            "heading": "E AUXILIARY LEMMAS",
            "text": "In contrast with other non-asymptotic tools below, we must assume the mass p does not vary with n in the asymptotic guarantee Lemma E.1. Lemma E.1. Let p be a probability mass function over an alphabet S, whose empirical estimation from X1,...,Xn i.i.d.\u223c p is pn(\u00b7) := \u2211n i=1 1{Xi=\u00b7}/n, then\npn a.s.\u2212\u2192p,\nwhere the almost surely convergence is defined under the \u2113\u221e metric in R|S|.\nProof. Without loss of generality, we assume S = [|S|]; thereby inducing p(x) = F (x)\u2212F (x\u22121) for x \u2208 [|S|], where F (x) = P(X \u2264 x) is the distribution function of X \u223c p. Similarly, pn(x)=Fn(x)\u2212Fn(x\u22121) for\nFn(\u00b7)= n\u2211\ni=1\nP(Xi\u2264\u00b7) n .\nTherefore,\nmax x\u2208[|S|] |pn(x)\u2212p(x)|\u2264sup x\u2208R |Fn(x)\u2212F (x)\u2212(Fn(x\u22121)\u2212F (x\u22121))|\n\u22642sup x\u2208R |Fn(x)\u2212F (x)|=:2\u2225Fn\u2212F\u2225\u221e.\nThe proof is thus completed by invoking the Glivenko-Cantelli Theorem (Van der Vaart, 2000, Theorem 19.1)."
        },
        {
            "heading": "E.1 BOUNDING TV FROM ABOVE",
            "text": "Lemma E.2 (Bretagnolle\u2013Huber inequality (Bretagnolle & Huber, 1979)). If P and Q are two probability measures on the same measurable space, then\nTV(P,Q)\u22641\u2212 1 2 exp(\u2212KL(P\u2225Q)).\nLemma E.3. If a1,...,an i.i.d.\u223c \u03c0\u2208\u2206(A), whose MLE is \u03c0\u0302= \u03c0\u0302(a1,...,an); and |A|<\u221e, then\nETV(\u03c0\u0302,\u03c0)\u2264 1 2 \u221a |A| n .\nProof. We reproduce the proof of this standard result here for completeness.\nLHS= 1\n2 \u2211 a\u2208A E|\u03c0\u0302(a)\u2212\u03c0(a)|\u2264 1 2 \u2211 a\u2208A \u221a E(\u03c0\u0302(a)\u2212\u03c0(a))2\n= 1\n2 \u2211 a\u2208A\n\u221a 1\nn2 Var(n\u03c0\u0302(a))=\n1\n2 \u221a n \u2211 a\u2208A \u221a \u03c0(a)(1\u2212\u03c0(a))\n\u2264 1 2 \u221a n \u2211 a\u2208A \u221a \u03c0(a)\u2264 1 2 \u221a |A| n ,\nwhere the first inequality is by Jensen\u2019s inequality, the third equality holds due to n\u03c0\u0302(a)\u223cBinomail(n,\u03c0(a)), and the last inequality is by the Cauchy-Schwarz inequaity.\nLemma E.4. Under the same setting as Lemma E.3, for any \u03b4\u2208(0,1), with probability at least 1\u2212\u03b4, TV(\u03c0\u0302,\u03c0)\u2264 \u221a\n|A|log2+log(1/\u03b4) 2n .\nProof. This is a straightforward corollary of the Bretagnolle-Huber-Carol inequality (van der Vaart & Wellner, 1996, Proposition A.6.6) based on the relationship between TV and \u21131."
        },
        {
            "heading": "E.2 MISSING MASS ANALYSIS",
            "text": "Observations like Lemma E.5 are key and common in the analysis of learning from finite and static datasets (Rajaraman et al., 2020; Rashidinejad et al., 2021).\nLemma E.5. For all x\u2208 [0,1],n>0, x(1\u2212x)n\u2264(4/9)n.\nProof. By taking the derivative w.r.t. x,\nmax x\u2208[0,1]\nLHS= ( n\nn+1\n)n+1 1\nn \u2264 1 n lim n\u2192\u221e (1\u2212 1 n+1 )n+1= 1 en \u2264 4 9n .\nLemma E.6 (Rajaraman et al. 2020, Theorem A.2). Given a distribution \u03bd on an alphabet S and n i.i.d. samples Xn i.i.d.\u223c \u03bd, then for any \u03b4\u2208(0,1/10], with probability at least 1\u2212\u03b4,\nm0(\u03bd,X n)\u2212E[m0(\u03bd,Xn)]\u2264\n3 \u221a\n|S|log(1/\u03b4) n .\nLemma E.7. Under the same setting as Lemma E.6, for any \u03b4\u2208(0,1/10], with probability at least 1\u2212\u03b4,\nm0(\u03bd,X n)\u2264 4|S| 9n + 3 \u221a |S|log(1/\u03b4) n .\nProof. Em0(\u03bd,Xn)= \u2211 x\u2208S \u03bd(x)E1{x /\u2208Xn}= \u2211 x\u2208S \u03bd(x)P(x /\u2208Xn)\n= \u2211 x\u2208S \u03bd(x)(1\u2212\u03bd(x))n\u2264 4|S| 9n , (E.1)\nwhere the inequality holds due to Lemma E.5; we conclude that \u2200\u03b4\u2208(0,1/10], with probability at least 1\u2212\u03b4,\nm0(\u03bd,X n)\u2264 4|S| 9n + 3 \u221a |S|log(1/\u03b4) n\nby substituting (E.1) into Lemma E.6.\nE.3 UPPER BOUNDS FOR Binomial(n,p)\nThe following two bounds for X\u223cBinomial(n,p) both follow from E[zX ]=(1\u2212p+pz)n,\u2200z\u2208R. Lemma E.8. Let X\u223cBinomial(n,p). If p\u2208(0,1],\nE 1 X+1 \u2264 1 p(n+1) .\nProof. This folklore (Canonne, 2020) derives from an observation that by Fubini\u2019s Theorem,\nE 1\nX+1 = \u222b 1 0 E[zX ]dz,\nwhose RHS is \u222b 1 0 (1\u2212p+pz)ndz= (1\u2212p+pz) n+1 p(n+1) \u2223\u2223\u2223\u22231 0 = 1\u2212(1\u2212p)n+1 p(n+1) \u2264 1 p(n+1) .\nLemma E.9. Let X\u223cBinomial(n,p). For any \u03b7\u2208(0,1),\nP(X\u2264(1\u2212\u03b7)np)\u2264exp ( \u2212\u03b7 2np\n2\n) .\nProof. A combination of Mitzenmacher & Upfal (2017, Exercise 4.7) and the proof of Mitzenmacher & Upfal (2017, Theorem 4.5) yields the upper bound, which we provide here for completeness. For any t<0, by Markov\u2019s inequality,\nP(X\u2264(1\u2212\u03b7)np)=P ( etX \u2264et(1\u2212\u03b7)np ) \u2264 E[e tX ]\net(1\u2212\u03b7)np =\n(1+p(et\u22121))n\net(1\u2212\u03b7)np\n\u2264 exp(np(e t\u22121))\net(1\u2212\u03b7)np = ( exp(et\u22121) et(1\u2212\u03b7) )np = ( e\u2212\u03b7 (1\u2212\u03b7)1\u2212\u03b7 )np ,\nwhere the last inequality follows from 1+x\u2264ex,\u2200x\u2208R and in the last equality we set t=log(1\u2212\u03b7). It remains to show\n\u2212\u03b7\u2212(1\u2212\u03b7)log(1\u2212\u03b7)\u2264\u2212\u03b7 2\n2 ,\u2200\u03b7\u2208(0,1). (E.2)\nWe thereby define f(\u03b7) :=\u2212\u03b7\u2212(1\u2212\u03b7)log(1\u2212\u03b7)+0.5\u03b72. A direct calculation gives\nf \u2032(\u03b7)=log(1\u2212\u03b7)+\u03b7,f \u2032(0)=0;\nf \u2032\u2032(\u03b7)=\u2212 1 1\u2212\u03b7 +1<0,\u2200\u03b7\u2208(0,1);\nSo f is nonincreasing in [0,1) and thus (E.2) holds.\nLemma E.9 helps us obtain a high-probability counterpart of Lemma E.8.\nCorollary E.10. Let X\u223cBinomial(n,p) and p>0. For any \u03b4\u2208(0,1), if\n\u03b7=\n\u221a 2log(1/\u03b4)\nnp <1,\nthen with probability at least 1\u2212\u03b4,\n1 X+1 \u2264 1 (1\u2212\u03b7)np+1 .\nProof. By Lemma E.9, P ( 1\nX+1 >\n1\n(1\u2212\u03b7)np+1\n) \u2264P(X\u2264(1\u2212\u03b7)np)\u2264exp ( \u2212\u03b7 2np\n2\n) =\u03b4."
        },
        {
            "heading": "F HARD-TO-LEARN INSTANCES FOR EXPERIMENTS",
            "text": "Instance 0 For every s\u2208 S, \u03c0\u22c6(\u00b7|s) := 0.5Uniform(A)+0.5Dirac(A,s modA+1) because any reference policy far away from both Uniform(A) and any one in Dirac(A) is sufficient to reveal the disadvantage of \u03c0\u0302CE,ptl according to Theorem 4.3. \u03c1 := Uniform(S) is enough to ensure about n/S visitations of each input.\nInterestingly, we conjecture there does not exist a worst-of-three-worlds instance that can simultaneously expose the fundamental limits of \u03c0\u0302CE,sgl, \u03c0\u0302SEL,ptl, and \u03c0\u0302CEful , in that the constructive proofs (in Appendix C) of Theorem 3.1, Theorem 4.1, and Theorem 5.1 since the progressively richer information are substantially different from each other. Since our learners in this section is uniformly initialized over unseen labels, any single instance covered by the Bayes prior in the lower bound arguments of a setting14 is sufficient to numerically illustrate the corresponding difficulty of estimation (learning).\nInstance 1 To verify the minimax optimality of \u03c0\u0302CE,sgl with only samples avaiable, we adapt the proof of Theorem 3.1 (Appendix C.2), which is based on Assouad\u2019s hypercube reduction (Yu, 1997). In numerical simlations, any vertex of the hypercube is applicable since we have already enforced an uniform initialization of any \u03c0\u0302 in unseen inputs. We choose the teacher policy\n\u03c0\u22c6(2j\u22121|s)= 1+0.25\n\u221a SA/n A ,\u03c0\u22c6(2j|s)= 1\u22120.25 \u221a SA/n A ,\u2200(s,j)\u2208 [S]\u00d7 [ A 2 ] ;\nand \u03c1 = Uniform(S) for simplicity. The two key insights behind the design of Instance 1 are (1) \u03c1 must be nonvanishing in \u2126(|S|) inputs to manifest the hardness of |S| > 0, (2) TV(\u03c0\u22c6(\u00b7|s),Uniform(A))=\u0398(n\u22120.5) is crucial for Instance 1 to be hard enough for any minimax optimal learner. (If |A| is odd, simply let the last label A to have zero mass and replace A with A\u22121 here.)\nInstance 2 To verify the minimax optimality of \u03c0\u0302SEL,ptl with sampled odds avaiable, we adapt the proof of Theorem 4.1 (Appendix C.3), which is based on a carefully designd Bayes prior. Similarly, we can use any single instance covered by the support of the Bayes prior. We choose the teacher policy\n\u03c0\u22c6(2j\u22121|s)= S n+1 ,\u03c0\u22c6(2j|s)=0,\u03c0\u22c6(A|s)=1\u2212S 2 \u00b7A\u22121 n+1 ,\u2200(s,j)\u2208 [S]\u00d7 [ A\u22121 2 ] ;\nand \u03c1=Uniform(S) for simplicity. (If |A| is even, simply let the last label A to have zero mass and replace A with A\u22121 here.)\nInstance 3 To verify the minimax optimality of \u03c0\u0302CEful with complete logits avaiable, we adapt the proof of Theorem 5.1 (Appendix C.4), which includes a specialized \u03c1 to slow down the convergence of \u03c0\u0302CEful . Specifically, \u03c1=(n+1)\n\u22121 for all inputs except the last one. Theoretically, the assignment of \u03c0\u22c6 will not affect the convergence of \u03c0\u0302CEful , so we use a \u03c0\n\u22c6 same as that in Instance 3 only to ensure that \u03c0\u0302SEL,ptl is not able to converge too fast."
        },
        {
            "heading": "G DISCUSSIONS: DEPENDENT SAMPLES IN REWARDLESS MDPS",
            "text": "Besides the popular approach of fine-tuning LLMs (Ouyang et al., 2022; Touvron et al., 2023b) that interprets instructions as inputs and the entire response as a label, there is a more granular perspective where each token is considered a label ai (See, e.g., the logprobs option in the OpenAI completion API15.) and si+1 is simply the concatenation of si and ai, i.e., si+1 \u223c P(\u00b7|si,ai), where P is the deterministic transition kernel induced by concatenation. Our bounds for i.i.d. samples already subsume this plausible more involved case through lack of reward. The following reductions hold for any P\u2208\u2206(A|S\u00d7A) including the aforementioned concatenation kernel. The proof of any lower bound remains valid so long as P(\u00b7|s,a) := \u03c1(\u00b7),\u2200(s,a) \u2208 S \u00d7 A in the constructed hard-to-learn instance, making the samples i.i.d. Our upper bounds allow \u03c1 to explicitly depend on \u03c0\u22c6 and even P, so the samples can be viewed as i.i.d. samples from dP\u03c0\u22c6\u00d7\u03c0\u22c6 given the input\n14See, e.g., Appendix C.3 for a concrete Bayes prior in use. 15https://platform.openai.com/docs/api-reference/completions/create#\nlogprobs\noccupancy measure dP\u03c0\u22c6 \u2208\u2206(S) is well-defined. Hence, replacing \u03c1 with dP\u03c0\u22c6 validates all arguments for upper bounds. Intuitively, dP\u03c0\u22c6(s) is the probability of visiting s in a trajectory induced by the transition kernel P and reference policy \u03c0\u22c6. It is well-developed in either episodic MDPs (Yin et al., 2021) or discounted MDPs (Rashidinejad et al., 2021). These seamless reductions crucially hinge on the absence of value functions and any notion of reward signal in our theoretical framework.\nRemark G.1. Our analysis covers but is not specialized to the case where \u03c1 depends on \u03c0\u22c6 or vice versa. Therefore, the result remains unchanged regardless of the relation between \u03c1 and the original training set for training the teacher \u03c0\u22c6. (For example, \u03c1 may be the distribution of instructions selected by maintainers on the student side (Peng et al., 2023).) It will be intriguing if some further analysis can show any impact of teacher training or data quality on the students\u2019 statistical rate."
        },
        {
            "heading": "H DICUSSIONS ON FUNCTION APPROXIMATION",
            "text": ""
        },
        {
            "heading": "H.1 LOG-LINEAR AND GENERAL SOFTMAX CONDITIONAL DENSITIES",
            "text": "We discuss potential ways and obstacles of generalizing the results above to large or even uncountable (continuous) state space. First, we extend the concept of conditional probability space \u2206(\u00b7|\u00b7) to general spaces rigorously. In the following discussions, we assume the notation Y and A refer to finite sets for simplicity. \u2206(\u00b7) in this section receives any standard Borel space as input and returns the set of probability measures on it.\nDefinition H.1 (Polyanskiy & Wu 2022, Definition 2.8). Given two standard Borel spaces X ,Y , a conditional probability (the teacher/student we considered in this paper)\u03c0 :X \u2192Y is a bivariate function \u03c0(\u00b7|\u00b7), whose first argument is a measurable subset of Y and the second is an element of X , such that:\n\u2022 \u2200x\u2208X , \u03c0(\u00b7|x) is a probability measure on Y , and\n\u2022 \u2200 measurable A\u2282Y , x\u2192\u03c0(A|x) is a measurable function on X .\nThe following preliminary result (whose proof is deferred to Section H.3) may shed light on prospective approaches to the analysis of function approximation.\nProposition H.2. For standard Borel spaces X and Y , if both \u03c0\u0301, \u03c0\u0300 \u2208 \u2206(Y|X ) are log-linear, i.e., \u03c0\u0301=\u03a0(\u03d5,\u03b8\u0301),\u03c0\u0300=\u03a0(\u03d5,\u03b8\u0300), where\n\u2206(Y|X )\u220b\u03a0(\u03d5,\u03b8)\u221dexp(\u27e8\u03d5,\u03b8\u27e9),\u03d5 :X\u00d7Y\u2192Rd;\nand sup(x,y)\u2208X\u00d7Y\u2225\u03d5(x,y)\u22252\u2264M ; then for any \u03bd\u2208\u2206(X ),\nTV(\u03c0\u0301,\u03c0\u0300|\u03bd)\u2264M \u2225\u2225\u2225\u03b8\u0301\u2212\u03b8\u0300\u2225\u2225\u2225\n2 . (H.1)"
        },
        {
            "heading": "H.2 TAKE-HOME MESSAGES AND CONJECTURES",
            "text": "Obviously, any analysis leveraging Proposition H.2 can potentially generalize our results, since log-linear \u03c0\u22c6 subsumes tabular \u03c0\u22c6. Technically, (H.1) mainly hinges on the (uniform) M -Lipschitz continuity of \u27e8\u03d5,\u03b8\u27e9 with respect to \u03b8 for any \u03b8\u2208Rd, therefore, it is also conceptually straightforward to extend Proposition H.2 to general Sofxmax \u03c0\u22c6, which we omit here for brevity.\nBased on (H.1), we conjecture that a fine-grained analysis of the \u21132-norm of \u03b8\u0302\u2212\u03b8\u22c6 may be the key to bound TV(\u03c0\u0302,\u03c0\u22c6|\u03c1) from above for any \u03c0\u0302,\u03c0\u22c6 \u2208\u2206(A|S) and \u03c1\u2208\u2206(S). Since the tabular setting is a special case of the log-linear setting, we also conjecture that \u2225\u2225\u2225\u03b8\u0302\u2212\u03b8\u22c6\u2225\u2225\u2225 2 \u2273 \u221a d/n via Hard Labels\nand \u2225\u2225\u2225\u03b8\u0302\u2212\u03b8\u22c6\u2225\u2225\u2225\n2 \u2273d/n via Partial SLs."
        },
        {
            "heading": "H.3 PROOF OF PROPOSITION H.2",
            "text": "Proof of Proposition H.2. For any x\u2208X ,\nKL(\u03c0\u0301(\u00b7|x)\u2225\u03c0\u0300(\u00b7|x))= \u2211 y\u2208Y \u03c0\u0301(y|x)log \u03c0\u0301(y|x) \u03c0\u0300(y|x)\n= \u2211 i\u2208Y \u03c0\u0301(i|x)\n\u2329\u03d5(x,i),\u03b8\u0301\u2212\u03b8\u0300\u232a+log\u2211k\u2208Yexp (\u2329 \u03d5(x,k),\u03b8\u0300 \u232a)\n\u2211 j\u2208Yexp (\u2329 \u03d5(x,j),\u03b8\u0301\n\u232a) \n\u2264 \u2211 i\u2208Y \u03c0\u0301(i|x) \u2329 \u03d5(x,i),\u03b8\u0301\u2212\u03b8\u0300 \u232a + \u2211 j\u2208Y\nexp (\u2329 \u03d5(x,j),\u03b8\u0300 \u232a)\n\u2211 k\u2208Yexp (\u2329 \u03d5(x,k),\u03b8\u0300 \u232a)\u2329\u03d5(x,j),\u03b8\u0300\u2212\u03b8\u0301\u232a = \u2211 i\u2208Y (\u03c0\u0301(i|x)\u2212\u03c0\u0300(i|x)) \u2329 \u03d5(x,i),\u03b8\u0301\u2212\u03b8\u0300\n\u232a \u2264 \u2211 i\u2208Y |\u03c0\u0301(i|x)\u2212\u03c0\u0300(i|x)|\u2225\u03d5(x,i)\u22252 \u2225\u2225\u2225\u03b8\u0301\u2212\u03b8\u0300\u2225\u2225\u2225 2\n\u22642TV(\u03c0\u0301(\u00b7|x),\u03c0\u0300(\u00b7|x))\u00b7M \u00b7 \u2225\u2225\u2225\u03b8\u0301\u2212\u03b8\u0300\u2225\u2225\u2225\n2 ,\n(H.2) where the first inequality holds due to the log-sum inequality, the second inequality is a combination of triangle inequality and Cauchy\u2013Schwarz inequality, and the last inequality is by the boundedness of \u03d5 together with the well-known 2TV=\u21131 relation. We plug (H.2) into Pinsker\u2019s inequality to obtain\n[TV(\u03c0\u0301(\u00b7|x),\u03c0\u0300(\u00b7|x))]2\u2264 1 2 KL(\u03c0\u0301(\u00b7|x)\u2225\u03c0\u0300(\u00b7|x))\u2264MTV(\u03c0\u0301(\u00b7|x),\u03c0\u0300(\u00b7|x)) \u2225\u2225\u2225\u03b8\u0301\u2212\u03b8\u0300\u2225\u2225\u2225 2 .\nSo TV(\u03c0\u0301,\u03c0\u0300|\u03bd)= \u222b XTV(\u03c0\u0301(\u00b7|x),\u03c0\u0300(\u00b7|x))d\u03bd\u2264M \u2225\u2225\u2225\u03b8\u0301\u2212\u03b8\u0300\u2225\u2225\u2225 2 ."
        }
    ],
    "year": 2024
}