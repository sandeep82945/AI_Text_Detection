{
    "abstractText": "We address causal reasoning in multivariate time series data generated by stochastic processes. Existing approaches are largely restricted to static settings, ignoring the continuity and emission of variations across time. In contrast, we propose a learning paradigm that directly establishes causation between events in the course of time. We present two key lemmas to compute causal contributions and frame them as reinforcement learning problems. Our approach offers formal and computational tools for uncovering and quantifying causal relationships in diffusion processes, subsuming various important settings such as discrete-time Markov decision processes. Finally, in fairly intricate experiments and through sheer learning, our framework reveals and quantifies causal links, which otherwise seem inexplicable.",
    "authors": [
        {
            "affiliations": [],
            "name": "Mehdi Fatemi"
        },
        {
            "affiliations": [],
            "name": "Sindhu Gowda"
        }
    ],
    "id": "SP:66c86f7110b24d59ec3cb5b7e1aaca0f838fc356",
    "references": [
        {
            "authors": [
                "David Lewis"
            ],
            "title": "Counterfactual dependence and time\u2019s",
            "venue": "arrow. Nou\u0302s,",
            "year": 1979
        },
        {
            "authors": [
                "David Lewis"
            ],
            "title": "Postscripts to causation",
            "year": 1986
        },
        {
            "authors": [
                "David Lewis"
            ],
            "title": "Causation as influence",
            "venue": "J. Philos.,",
            "year": 2000
        },
        {
            "authors": [
                "Wesley C Salmon"
            ],
            "title": "Scientific explanation and the causal structure of the world",
            "year": 1984
        },
        {
            "authors": [
                "Peter Spirtes",
                "Clark N Glymour",
                "Richard Scheines"
            ],
            "title": "Causation, prediction, and search",
            "venue": "MIT press,",
            "year": 2000
        },
        {
            "authors": [
                "Judea Pearl"
            ],
            "title": "Models, reasoning and inference",
            "year": 2000
        },
        {
            "authors": [
                "JY Halpern",
                "J Pearl"
            ],
            "title": "Causes and explanations: Part 1: Causes",
            "venue": "In UAI,",
            "year": 2001
        },
        {
            "authors": [
                "Joseph Y Halpern",
                "Judea Pearl"
            ],
            "title": "Causes and explanations: A structural-model approach. part ii: Explanations",
            "venue": "The British journal for the philosophy of science,",
            "year": 2005
        },
        {
            "authors": [
                "Nancy Cartwright"
            ],
            "title": "Hunting causes and using them: Approaches in philosophy and economics",
            "year": 2007
        },
        {
            "authors": [
                "A Philip Dawid"
            ],
            "title": "Causal inference without counterfactuals",
            "venue": "Journal of the American statistical Association,",
            "year": 2000
        },
        {
            "authors": [
                "Carlo Berzuini",
                "Philip Dawid",
                "Luisa"
            ],
            "title": "Bernardinell. Causality: Statistical perspectives and applications",
            "year": 2012
        },
        {
            "authors": [
                "Peter Spirtes"
            ],
            "title": "An anytime algorithm for causal inference",
            "venue": "In International Workshop on Artificial Intelligence and Statistics,",
            "year": 2001
        },
        {
            "authors": [
                "David Fair"
            ],
            "title": "Causation and the flow of energy",
            "venue": "Erkenntnis, 14(3):219\u2013250,",
            "year": 1979
        },
        {
            "authors": [
                "Max Kistler"
            ],
            "title": "Causation and laws of nature",
            "venue": "Taylor & Francis,",
            "year": 2007
        },
        {
            "authors": [
                "Christopher Read Hitchcock"
            ],
            "title": "Discussion: Salmon on explanatory relevance",
            "venue": "Philosophy of Science,",
            "year": 1995
        },
        {
            "authors": [
                "Peter Fazekas",
                "Bal\u00e1zs Gyenis",
                "G\u00e1bor Hofer-Szab\u00f3",
                "Gergely Kert\u00e9sz"
            ],
            "title": "A dynamical systems approach to causation",
            "year": 2021
        },
        {
            "authors": [
                "R E Kalman"
            ],
            "title": "On the general theory of control systems",
            "venue": "IFAC Proceedings Volumes,",
            "year": 1960
        },
        {
            "authors": [
                "Samuel Karlin",
                "Howard M Taylor"
            ],
            "title": "A Second Course in Stochastic Processes",
            "year": 1981
        },
        {
            "authors": [
                "Nancy L. Stokey"
            ],
            "title": "The Economics of Inaction: Stochastic Control Models with Fixed Costs",
            "venue": "URL http://www.jstor.org/stable/j. ctt7sfgq",
            "year": 2009
        },
        {
            "authors": [
                "J. Dmitri"
            ],
            "title": "Gallow. The Metaphysics of Causation",
            "venue": "The Stanford Encyclopedia of Philosophy",
            "year": 2022
        },
        {
            "authors": [
                "Mehdi Fatemi",
                "Taylor W Killian",
                "Jayakumar Subramanian",
                "Marzyeh Ghassemi"
            ],
            "title": "Medical deadends and learning to identify High-Risk states and treatments",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "L A Paul"
            ],
            "title": "Keeping track of the time: Emending the counterfactual analysis of causation",
            "venue": "Analysis,",
            "year": 1998
        },
        {
            "authors": [
                "Daphne Koller",
                "Nir Friedman"
            ],
            "title": "Probabilistic graphical models: principles and techniques",
            "venue": "MIT press,",
            "year": 2009
        },
        {
            "authors": [
                "Jonas Peters",
                "Stefan Bauer",
                "Niklas Pfister"
            ],
            "title": "Causal models for dynamical systems",
            "venue": "In Probabilistic and Causal Inference: The Works of Judea Pearl,",
            "year": 2022
        },
        {
            "authors": [
                "Niels Hansen",
                "Alexander Sokol"
            ],
            "title": "Causal interpretation of stochastic differential equations",
            "year": 2014
        },
        {
            "authors": [
                "M.G. Bellemare",
                "Y. Naddaf",
                "J. Veness",
                "M. Bowling"
            ],
            "title": "The arcade learning environment: An evaluation platform for general agents",
            "venue": "Journal of Artificial Intelligence Research,",
            "year": 2013
        },
        {
            "authors": [
                "Volodymyr Mnih",
                "Koray Kavukcuoglu",
                "David Silver",
                "Andrei A Rusu",
                "Joel Veness",
                "Marc G Bellemare",
                "Alex Graves",
                "Martin Riedmiller",
                "Andreas K Fidjeland",
                "Georg Ostrovski",
                "Stig Petersen",
                "Charles Beattie",
                "Amir Sadik",
                "Ioannis Antonoglou",
                "Helen King",
                "Dharshan Kumaran",
                "Daan Wierstra",
                "Shane Legg",
                "Demis Hassabis"
            ],
            "title": "Human-level control through deep reinforcement learning",
            "year": 2015
        },
        {
            "authors": [
                "Boris P Kovatchev",
                "Marc Breton",
                "Chiara Dalla Man",
                "Claudio Cobelli"
            ],
            "title": "In silico preclinical trials: a proof of concept in closed-loop control of type 1 diabetes",
            "year": 2009
        },
        {
            "authors": [
                "Judea Pearl"
            ],
            "title": "Probabilities of causation: three counterfactual interpretations and their identification",
            "venue": "In Probabilistic and Causal Inference: The Works of Judea Pearl,",
            "year": 2022
        },
        {
            "authors": [
                "Jin Tian",
                "Judea Pearl"
            ],
            "title": "Probabilities of causation: Bounds and identification",
            "venue": "Annals of Mathematics and Artificial Intelligence,",
            "year": 2000
        },
        {
            "authors": [
                "A Philip Dawid",
                "Monica Musio",
                "Rossella Murtas"
            ],
            "title": "The probability of causation",
            "venue": "Law, Probability and Risk,",
            "year": 2017
        },
        {
            "authors": [
                "Scott Mueller",
                "Ang Li",
                "Judea Pearl"
            ],
            "title": "Causes of effects: Learning individual responses from population data",
            "venue": "arXiv preprint arXiv:2104.13730,",
            "year": 2021
        },
        {
            "authors": [
                "Sander Beckers"
            ],
            "title": "Causal sufficiency and actual causation",
            "venue": "Journal of Philosophical Logic,",
            "year": 2021
        },
        {
            "authors": [
                "Sander Beckers",
                "Joost Vennekens"
            ],
            "title": "A principled approach to defining actual causation",
            "year": 2018
        },
        {
            "authors": [
                "Joseph Y Halpern"
            ],
            "title": "A modification of the halpern-pearl definition of causality",
            "venue": "arXiv preprint arXiv:1505.00162,",
            "year": 2015
        },
        {
            "authors": [
                "Brad Weslake"
            ],
            "title": "A partial theory of actual causation",
            "venue": "British Journal for the Philosophy of Science,",
            "year": 2015
        },
        {
            "authors": [
                "Christopher Hitchcock"
            ],
            "title": "The intransitivity of causation revealed in equations and graphs",
            "venue": "The Journal of Philosophy,",
            "year": 2001
        },
        {
            "authors": [
                "Christopher Hitchcock"
            ],
            "title": "Prevention, preemption, and the principle of sufficient reason",
            "venue": "The Philosophical Review,",
            "year": 2007
        },
        {
            "authors": [
                "Clive WJ Granger"
            ],
            "title": "Investigating causal relations by econometric models and cross-spectral methods",
            "venue": "Econometrica: journal of the Econometric Society,",
            "year": 1969
        },
        {
            "authors": [
                "Halbert White",
                "Xun Lu"
            ],
            "title": "Granger causality and dynamic structural systems",
            "venue": "Journal of Financial Econometrics,",
            "year": 2010
        },
        {
            "authors": [
                "Jonas Peters",
                "Dominik Janzing",
                "Bernhard Sch\u00f6lkopf"
            ],
            "title": "Causal inference on time series using restricted structural equation models",
            "venue": "Advances in neural information processing systems,",
            "year": 2013
        },
        {
            "authors": [
                "Niklas Pfister",
                "Peter B\u00fchlmann",
                "Jonas Peters"
            ],
            "title": "Invariant causal prediction for sequential data",
            "venue": "Journal of the American Statistical Association,",
            "year": 2019
        },
        {
            "authors": [
                "Michael Eichler",
                "Vanessa Didelez"
            ],
            "title": "Causal reasoning in graphical time series models",
            "venue": "arXiv preprint arXiv:1206.5246,",
            "year": 2012
        },
        {
            "authors": [
                "Biwei Huang",
                "Kun Zhang",
                "Jiji Zhang",
                "Joseph Ramsey",
                "Ruben Sanchez-Romero",
                "Clark Glymour",
                "Bernhard Sch\u00f6lkopf"
            ],
            "title": "Causal discovery from heterogeneous/nonstationary data",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2020
        },
        {
            "authors": [
                "Joris M Mooij",
                "Dominik Janzing",
                "Bernhard Sch\u00f6lkopf"
            ],
            "title": "From ordinary differential equations to structural causal models: the deterministic case",
            "venue": "arXiv preprint arXiv:1304.7920,",
            "year": 2013
        },
        {
            "authors": [
                "Tineke Blom",
                "Joris M Mooij"
            ],
            "title": "Generalized structural causal models",
            "venue": "arXiv preprint arXiv:1805.06539,",
            "year": 2018
        },
        {
            "authors": [
                "Stephan Bongers",
                "Tineke Blom",
                "Joris M Mooij"
            ],
            "title": "Causal modeling of dynamical systems",
            "venue": "arXiv preprint arXiv:1803.08784,",
            "year": 2018
        },
        {
            "authors": [
                "Paul K Rubenstein",
                "Stephan Bongers",
                "Bernhard Sch\u00f6lkopf",
                "Joris M Mooij"
            ],
            "title": "From deterministic odes to dynamic structural causal models",
            "venue": "arXiv preprint arXiv:1608.08028,",
            "year": 2016
        },
        {
            "authors": [
                "James Woodward",
                "James Francis Woodward"
            ],
            "title": "Making things happen: A theory of causal explanation",
            "venue": "Oxford university press,",
            "year": 2005
        },
        {
            "authors": [
                "L. Ljung"
            ],
            "title": "System Identification: Theory for the User",
            "venue": "Bibliyografya ve I\u0307ndeks. Prentice-Hall,",
            "year": 1987
        },
        {
            "authors": [
                "S. Skogestad",
                "I. Postlethwaite"
            ],
            "title": "Multivariable Feedback Control: Analysis and Design. Wiley, 2005. ISBN 9780470011676",
            "venue": "URL https://books.google.ca/books?id=97iAEAAAQBAJ",
            "year": 2005
        },
        {
            "authors": [
                "Mehdi Fatemi",
                "Shikhar Sharma",
                "Harm Van Seijen",
                "Samira Ebrahimi Kahou"
            ],
            "title": "Dead-ends and secure exploration in reinforcement learning",
            "venue": "Proceedings of the 36th International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "Marc G Bellemare",
                "Will Dabney",
                "R\u00e9mi Munos"
            ],
            "title": "A distributional perspective on reinforcement learning",
            "venue": "Proceedings of the 34th International Conference on Machine Learning,",
            "year": 2017
        },
        {
            "authors": [
                "Richard S. Sutton",
                "Doina Precup",
                "Satinder Singh"
            ],
            "title": "Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning",
            "venue": "Artificial Intelligence,",
            "year": 1999
        },
        {
            "authors": [
                "Mehdi Fatemi",
                "Mary Wu",
                "Jeremy Petch",
                "Walter Nelson",
                "Stuart J Connolly",
                "Alexander Benz",
                "Anthony Carnicelli",
                "Marzyeh Ghassemi"
            ],
            "title": "Semi-Markov offline reinforcement learning for healthcare",
            "venue": "Proceedings of the Conference on Health, Inference, and Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Meng Cao",
                "Mehdi Fatemi",
                "Jackie C K Cheung",
                "Samira Shabanian"
            ],
            "title": "Systematic rectification of language models via dead-end analysis",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "Chiara Dalla Man",
                "Francesco Micheletto",
                "Dayu Lv",
                "Marc Breton",
                "Boris Kovatchev",
                "Claudio Cobelli"
            ],
            "title": "The uva/padova type 1 diabetes simulator: new features",
            "venue": "Journal of diabetes science and technology,",
            "year": 2014
        },
        {
            "authors": [
                "Roberto Visentin",
                "Enrique Campos-N\u00e1\u00f1ez",
                "Michele Schiavon",
                "Dayu Lv",
                "Martina Vettoretti",
                "Marc Breton",
                "Boris P Kovatchev",
                "Chiara Dalla Man",
                "Claudio Cobelli"
            ],
            "title": "The uva/padova type 1 diabetes simulator goes from single meal to single day",
            "venue": "Journal of diabetes science and technology,",
            "year": 2018
        },
        {
            "authors": [
                "Tom Schaul",
                "John Quan",
                "Ioannis Antonoglou",
                "David Silver"
            ],
            "title": "Prioritized experience replay",
            "venue": "arXiv preprint arXiv:1511.05952,",
            "year": 2015
        },
        {
            "authors": [
                "Dawid"
            ],
            "title": "sufficiency, and ways to calculate them from data (Pearl, 2022). Moreover, researchers have used the causal structure and the properties of the data to narrow the bounds of the above probabilities of causation Tian and Pearl",
            "venue": "Weslake",
            "year": 2021
        },
        {
            "authors": [
                "Peters"
            ],
            "title": "non-temporal data by making certain assumptions about the underlying process of data generation (causal graphs), which restricts the understanding of causation to static settings",
            "venue": "Dynamic Settings. Works like Granger (1969); White and Lu",
            "year": 2020
        },
        {
            "authors": [
                "Hansen",
                "Sokol",
                "Mooij"
            ],
            "title": "in time series data, but mostly consider discrete-time models. Moreover, they focus on finding causal dependencies between different variables in time series data while we try to find causation between events, defined by a change in variables during a homogeneous time interval",
            "venue": "Further, works like Peters et al",
            "year": 2016
        },
        {
            "authors": [
                "Spirtes"
            ],
            "title": "It does not concern itself with understanding the cause of an event in a specific context Halpern (2016). Further, all the above-mentioned methods deal with understanding causation from a counterfactualinterventionist perspective Woodward and Woodward (2005); Pearl (1980), while we follow the route of process theory of causation and emphasize system-level thinking to answer questions",
            "year": 2000
        },
        {
            "authors": [
                "causation Fazekas"
            ],
            "title": "2021) propose a philosophical framework for a dynamical systems approach to causation based on the process theory of causation Salmon (1984); Dowe (2000) and emphasize conceptually the importance of system-level thinking",
            "year": 2000
        },
        {
            "authors": [
                "Fatemi"
            ],
            "title": "We should mention here that similar results may be extended to distributional RL (Bellemare et al., 2017) or to the case of semi-Markov settings",
            "venue": "(Sutton et al.,",
            "year": 2019
        },
        {
            "authors": [
                "B. C"
            ],
            "title": "STRUCTURAL EQUATION MODELLING Before we look into the HP definitions we assume that the reader is familiar with the concept of structural equation modeling. To do so, we recommend the reader refer to (Beckers, 2021) section 2, so they are equipped with the basic tools needed to understand the HP definition",
            "venue": "For our discussion,",
            "year": 2021
        },
        {
            "authors": [
                "Mnih"
            ],
            "title": "In the plots, \u2207\u0393(x) is colour-coded by red shades for \u2207\u0393(x) > 0, blue shades for \u2207\u0393(x) < 0 and white for zero, with darkest red for \u2207\u0393(x) \u2265 +1 and darkest blue for \u2207\u0393(x) \u2264 \u22121. Values with |\u2207\u0393(x)| < 0.1 are set to zero to denoise",
            "year": 2015
        },
        {
            "authors": [
                "Man"
            ],
            "title": "The simulator models an insilicopatient\u2019s blood glucose level (BG) and 12 other body dynamics with real-valued elements representing glucose and insulin values in different compartments of the body. The glucose dynamics are captured by - plasma glucose, tissue glucose, glucose in stomach 1 (GS1), glucose in stomach 2 and gut. The insulin dynamics are captured by - insulin on glucose",
            "year": 2018
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Philosophers have long dreamed of discovering causal relationships from raw data. There are a wide variety of theories of causation, relevant to our discussion are the counterfactual theory (Lewis, 1973; 1979; 1986; 2000) and process-based theory of causation (Salmon, 1984; Dowe, 2000). The basic idea of counterfactual theories of causation is that the meaning of causal claims can be explained in terms of counterfactual conditionals of the form \u201cIf cause event A had not occurred, effect event B would not have occurred\u201d. The original counterfactual analysis of causation, most widely discussed in the philosophical literature, is provided by David Lewis (Lewis, 1979; 2000). Lewis\u2019s stated probability of causation between events as follows: \u201cThe effect event B depends probabilistically on a cause event A if and only if, given A, there is a chance x of B\u2019s occurring, and if A were not to occur, there would be a chance y of B\u2019s occurring, where x is much greater than y.\u201d\nWorks such as the Causal Bayes Net (Spirtes et al., 2000) or Structural Causal Model (Pearl et al., 2000) explored a counterfactual approach to causation that employs the structural equations framework to answer the causal question using interventionist/manipulationist approaches to find counterfactuals (HP setting, Halpern and Pearl (2001; 2005)). However, these approaches can have severe limitations, especially when applied to dynamical systems. Interventions are often infeasible in physical systems (Cartwright, 2007), and one can never observe counterfactuals nor assess empirically the validity of any modeling assumptions made about them, even though one\u2019s conclusions may be sensitive to these assumptions (Dawid, 2000; Berzuini et al., 2012). Moreover, these approaches ignore the dynamics as well as the possibility of other interventions between events (Dawid, 2000). Further, these frameworks assume knowledge of causal dependencies or structural information between various events in the system. Constructing detailed structural models can be hard, even for domain experts (Spirtes, 2001).\nOther philosophers have proposed an alternative conception of causality, featuring physical systems as causal processes (Salmon, 1984; Fair, 1979; Kistler, 2007). The cornerstone of Salmon\u2019s theory of causality is the notion of a causal process, defined as a spatiotemporal continuous entity having the capacity to transmit \u201cinformation, structure and causal influence\u201d (Salmon, 1984). He believed that processes are responsible for causal propagation, and provide the links connecting causes to effects. While this understanding of causation is meaningful on an abstract level, philosophers have argued that Salmon\u2019s causal mechanical explanation was too weak, because it envisaged a geometrical network of processes and interactions (transmission of marks (Salmon, 1984) or conserved quantities (Dowe, 2000)) but did not convey as to what properties should be taken as explanatory (Hitchcock, 1995). Further, the scenarios described by everyday and scientific causal claims (e.g. \u2018smoking causes\n*Equal contribution. Parts of this work were done during the authors\u2019 affiliation with Microsoft Research.\nlung cancer\u2019) are often rather complex such that the possibility of decomposing them into sets of individual interactions is clearly out of sight (Fazekas et al., 2021).\nAs a different example, consider playing a seemingly simple Atari game where losing a point prompts the question: what caused this outcome? In its most basic form, an Atari game encompasses nearly 30,000 variables at each time step, resulting in tens of millions of variables during a short gameplay, each assuming 256 discrete values. Beyond its staggering size, constructing a causal graph demands substantial domain knowledge to decipher the combinatorially larger number of graph connections. Moreover, interventions in an active game necessitate delving into the internal game engine to mechanically adjust state variables\u2014an impossible operation. This dynamic causal problem mirrors challenges found in diverse systems, such as pinpointing the reasons behind a patient\u2019s stroke in an ICU, understanding the cause of a nuclear reactor malfunction, or elucidating why a particular protein ceases development. An open question is how to uncover causal links in complex dynamical settings with no graph, no human-level knowledge beyond data, and no need for impossible interventions.\nInspired by the above theories of causality, our approach seeks to establish/validate causal assertions through the examination of underlying dynamics, placing a strong emphasis on spatiotemporal, system-level thinking. In a physical process, if events are seen as changes of state or action variables, we can naturally answer causal questions originating from the emission of changes in the state-space, across time. To this end, (i) we begin by defining causation from a process-based viewpoint. (ii) We then present two fundamental lemmas, which enable us to: (A) construct two reinforcement learning problems, whose optimal value functions yield core metrics to understand causation, and (B) isolate and quantitatively assess the individual contributions of each state or action component to the causal metrics. These lemmas reframe the notion of causation as a machine learning problem, making it amenable to analysis using raw observational data. (iii) We examine our methodology through a series of complex experiments1. We present a detailed account of related works in Appendix A."
        },
        {
            "heading": "2 BASICS AND PROBLEM FORMULATION",
            "text": "We adopt Kalman\u2019s definition of state: the smallest collection of numbers which must be specified at time t = t0 to enable predicting the system\u2019s behavior for any time t > t0. Any dynamical system can be described from the state viewpoint (Kalman, 1960). Formally, state is a n-dimensional vector-space and is either fully observable or reconstructable from observations. At any given time, each state component is a random variable, and the state vector\u2019s evolution across time forms a (stochastic) process. It is desirable to also include alterable inputs, i.e., action variables. The evolution of state is a function of both the intrinsic dynamics and the temporally selected (extrinsic) actions. We present our formal results for generic dynamical systems obeying (continuous) diffusion processes. We then derive our algorithmic machinery, which covers discrete cases and model-free settings.\nDiffusion Processes. Assume a filtered probability space (\u2126,F, P ). Let the state vector form a continuous-time random process X(t, \u03c9) over the mentioned probability space (we often suppress \u03c9 for brevity). The process X(t) is a diffusion if it possesses the strong Markov property and if its sample paths are continuous w.p. (with probability) one.\nMany physical, biological and economic phenomena are either reasonably modeled or wellapproximated by diffusion processes (Karlin and Taylor, 1981). Further, discrete-time Markov processes can be well-approximated by diffusion processes. Conversely, a diffusion process (continuoustime) can be discretized to make a discrete-time Markov process with arbitrary level of accuracy (for a formal discussion, see Karlin and Taylor (1981), pp. 168\u2013169). As a result, we will readily extend our formal results to design discrete-time algorithms, which are of special importance in practice.\nLet \u2206hX(t) = X(t + h) \u2212 X(t) be the change of state X(t) over a time interval of length h. We assume that the following limits exists: limh\u21930 1hE [ \u2206hX(t) | X(t) = x ] = \u00b5(x,u, t) and limh\u21930 1 hE [{ \u2206hX(t) }2 | X(t) = x] = \u03c3(x,u, t), where \u00b5 is a vector of size n and \u03c3 is a matrix of size n\u00d7 n (they are referred to as infinitesimal parameters), and u \u2208 U \u2286 Rm is a m-dimensional\n1In causal reasoning, two distinct (but related) classes of questions are intrinsically relevant: (1) a cause event is assumed and possible effects are in question \u2013 causal inference (what is the result of using a certain medication?). (2) An effect event is assumed and possible causes and the extent to which they contributed to the effect are in question (why did the Chernobyl reactor explode?). We primarily focus on the latter class; nevertheless, the present core concepts and technical results can readily be used for causal inference as well.\naction. We further assume that both \u00b5 and \u03c3 are continuous functions of their arguments, \u03c3 is positive definite, and all the higher moments are zero. The state evolution can therefore follow the following differential form (Stokey, 2009):\ndX(t, \u03c9) = \u00b5 ( X(t, \u03c9),u(t) ) dt+ \u03c3 ( X(t, \u03c9),u(t) ) dW(t, \u03c9), (1)\nwhere W(t, \u03c9) denotes the vector of standard Brownian motions. We assume u to be deterministic, bounded, and follow u\u0307 .= \u03d5(t). We let \u00b5 and \u03c3 be stationary, however, it is straight to extend to stochastic actions and/or non-stationary infinitesimals. Further, the time variable can be augmented to the state vector to simply accommodate for non-stationary cases. Placed with initial state distribution and reward function (and with an obvious abuse of terminology), we deem a Markov decision process (MDP) as a general term to refer to a (continuous-time) diffusion or a discrete-time Markov decision process. The MDP is formally defined as a tuple M = (X ,U , R,P0). X and U are sets of possible states and actions, R : X 7\u2192 R is a scalar reward function, and P0 is the distribution of initial states. Let actions be selected according to some policy u(t) = \u03c0(X(t), t). Starting from x, the random variable corresponding to the (undiscounted) accumulated future rewards is called return, and its expectation is called value function: V \u03c0(x) .= E{ \u222b T t R(X(t\u2032, \u03c9))dt\u2032|X(t) = x} with the trajectory terminating at time T > t. Further, V \u2217(x) .= max\u03c0 V \u03c0(x) is called optimal value function. Finally, we say that X admits one or more known components xj at time t iff Xj(t) = xj .\nProcess-based Causality. As mentioned earlier, we posit that causal relationships are based on temporal dynamics. Any causal relationship contains two events: cause (event A) and effect (event B). We argue that in all logical arguments on causation, the following axioms are true:\ni. Causality necessitates time: a causal relationship is realizable solely along the time axis. ii. Cause happens before effect and the relationship is unidirectional from cause to effect.\niii. A causal relationship may imply neither necessity nor sufficiency.\nThese axioms set the ground for a natural view of causation. Notably, (i) requires that an event must be associated with a point or an interval in time; otherwise, no causal argument can possibly be made about that event being the cause or effect of any other event. In the HP settings of causation, the time dependency often becomes implicit in the arguments (e.g., in causal graphs), but it may be a source of confusion; hence, we seek a formulation that inherently includes time. Therefore, we formally define an event as a change of one or more state or action components during a homogeneous time interval. The components involved in an event are called ruling variables. The time interval is assumed to be short enough such that the dynamics can be considered as monotone. This assumption highlights the fact that an event cannot be a long-term incident relative to the rate of changes in the environment. This definition further enables us to consider changes in the same variable happening at different points in time as different events, which can be very helpful in practical cases of interest. Next, (i) and (ii) necessitate that \u201cA causes B\u201d implies \u201cB cannot cause A\u201d; This helps resolve the question of what constitutes the direction of the causal relation between two events. Furthermore, (iii) necessitates that, in general, a causal relationship requires probabilistic views and non-binary measures. For example, if \u201cA causes B\u201d and if A does not happen, then in general, one cannot conclude B necessarily will not happen. By the same token, if A happens, it may not necessarily imply B will also happen. In other words, an event may partially contribute in the occurrence of another event in the future, although the case that A is a necessary and/or sufficient cause for B is a possibility. This further addresses the problem of pre-emption since cases of preemption show us that causes need not be necessary for their effects (Gallow, 2022).\nThe central idea behind Lewis definition is that causes, by themselves, increase the probability of their effects. In the presence of actions, the probability of a future event\u2019s occurrence is not well-defined. Considering arbitrary policies for action selection, one may devise different chains of events after A. Following each such policy incurs a different probability for event B\u2019s occurrence. Remark that if A causes B then under the most pessimistic version of such chains of events, still x must be greater than y in Lewis\u2019s definition. Hence, we set x to be the minimum probability of B\u2019s happening.\nWe define grit of a future event B at state X, denoted by \u0393B(X), as the minimum probability that B occurs if current state is X. As discussed, the minimum is taken over future courses of actions. Similarly, reachability of a future event B is denoted by \u039bB(X) and is defined as the maximum probability of B\u2019s occurrence starting from X. In discrete settings, it is helpful to extend the\ndefinitions to starting from a given state and a given action (with an overload of notation): \u0393B(X,u) and \u039bB(X,u).\nWe further argue that if the net impact of each variable is known (all ruling and non-ruling ones), then there is no need for the designed \u201cinterventions,\u201d (modifying the history), as the role of intervention is to mechanically separate the impact of a variable from the collective impact. We, therefore, postulate the following definition of causation: Definition 1 (Causation). In a stochastic process, A is a cause of B if and only if"
        },
        {
            "heading": "C1. Time-wise, conclusion of A happens at or before beginning of B;",
            "text": ""
        },
        {
            "heading": "C2. Expected grit of B strictly increases from before to after A. Moreover, until B\u2019s occurrence, it",
            "text": "never becomes the same or smaller than its value at A\u2019s beginning;"
        },
        {
            "heading": "C3. The contribution of A\u2019s ruling variables in the growth of B\u2019s expected grit is strictly positive",
            "text": "and is strictly larger in magnitude than that of non-ruling variables with negative impact.\nRemark that the non-ruling variables can have positive, zero, or negative impacts on the change of B\u2019s grit. The second part of condition C2 necessitates that a future event must not nullify the impact of a cause. Condition C3 above requires that the contribution of A\u2019s ruling variables must both be positive and overshadow the negative impact of non-ruling ones. It then follows that even in the absence of non-ruling variables with a positive impact, B\u2019s grit still increases by A; hence, A is a cause. Moreover, grit is a random variable due to non-ruling variables at the beginning of A. The expected grit asserts that causation must hold under the expected starting point. Of note, one can set forth a strong notion of causation by replacing C3 to assert that the contribution of A\u2019s ruling variables is strictly larger than that of all non-ruling variables. This notion helps to identify an event as a dominant cause. In any case, the yet-open question is how to compute individual contributions. In the next section, we will establish formal results to answer this question."
        },
        {
            "heading": "3 FUNDAMENTAL LEMMAS",
            "text": "We present two foundational lemmas. In a nutshell, the first lemma is a generalization of Lemma 2 in Fatemi et al. (2021), and it broadly states that grit and reachability can be computed by the optimal value functions corresponding to two easily constructed reward functions. This lemma establishes the learning of value functions (hence reinforcement learning) as the principal learning paradigm for dynamical causal problems. The second lemma decomposes expected change of grit and reachability to the contribution of state and action components, which inherently enables causal analysis. These lemmas are core to our theory in that they enable formal and computational reasoning about causality, which will be presented in the rest of this paper. All the proofs are deferred to Appendix B. Lemma 1 (Value Lemma). Let [T, T \u2032] be the duration of event B\u2019s occurrence, and the state only admits xB at t = T \u2032 (all states that admit xB are terminal). Define two MDPs M\u0393 and M\u039b identical to M with their rewards being zero if B does not happen. Otherwise, R\u0393(X(t)) = R\u039b(X(t)) = 0 for t < T ; \u222b T \u2032 T R\u0393(X(t))dt = \u22121; and \u222b T \u2032 T\nR\u039b(X(t))dt = 1. Let V \u2217\u0393 (x) and V \u2217\u039b (x) denote the optimal value functions (undiscounted) of M\u0393 and M\u039b, respectively. The followings hold for all X \u2208 X :\n1. \u0393B(X) = \u2212V \u2217\u0393 (X)\n2. \u039bB(X) = V \u2217\u039b (X) Lemma 2 (Decomposition Lemma). Fix a filtered probability space (\u2126,F,P). Let X = X(t, \u03c9) be a diffusion process with stationary infinitesimal parameters \u00b5 = \u00b5(X,u) and \u03c3 = \u03c3(X,u). Let grit and reachability exist and be differentiable twice in state. Let \u03c3i(X,u) denote the i-th row of the matrix \u03c3(X,u). Finally, let a fixed action u be applied from time t1 to t2 and the state admits occurance of event A between t1 and t2. The expected change of grit, E [\u2206A\u0393B ] = E [ \u0393B ( X(t2, \u03c9))\u2212 \u0393B(X(t1, \u03c9) ) |A ] , is expressed by the following formula:\nE [\u2206A\u0393B ] = n\u2211\nj=1\nE {gj |A}+ n\u2211\nj=1\nE {g\u0307j |A}+ n\u2211\nj=1 n\u2211 i=1 i\u0338=j E {g\u0308j,i|A} , (2)\ngj . = \u222b t2 t1 \u00b5j(X,u) \u00b7 \u2202\u0393B \u2202xj (X)dt (3)\ng\u0307j . =\n1\n2 \u222b t2 t1 \u03c3j(X,u) \u00b7 \u03c3Tj (X,u) \u00b7 \u22022\u0393B \u2202xj2 (X)dt (4)\ng\u0308i,j . =\n1\n2 \u222b t2 t1 \u03c3i(X,u) \u00b7 \u03c3Tj (X,u) \u00b7 \u22022\u0393B \u2202xi\u2202xj (X)dt (5)\nThe same formulation holds for reachablity.\nIf change of action variables is to be considered as an event, then u is allowed to change and a similar term is also required for actions. By assumption u is not a stochastic process; thus, it only adds a deterministic term. Let u\u0307(t) .= \u03d5(t) and \u03d5k be the k-th component of \u03d5. We need to consider \u0393B . = \u0393B(X,u), and the additional term \u2211m k=1 E{hk|A} will be added to equation 2 with\nhk . = \u222b t2 t1 \u03d5k(t) \u00b7 \u2202\u0393B \u2202uk (X,u) dt (6)\nRemark that u may take more complex forms or even be a stochiastic process. Then, other terms should also be added to decomposition lemma. Although such expansions are straightforward, we do not consider them here, since in practice, changes of u is often seen as extrinsic events.\nUsing fundamental lemmas, we next present certain basic properties for grit and reachibility: Proposition 1 (Unity Proposition). If grit of an event B is unity at some state x, then w.p.1 it will remain at unity. Moreover, this occurs if and only if B will happen w.p.1 from x regardless of future actions and stochasticity. Proposition 2 (Null Proposition). If reachablity of an event B is zero at some state x, then w.p.1 it will remain at zero. Moreover, this occurs if and only if B will almost surely never happen, regardless of future actions and stochasticity. Proposition 3. Let actions be selected according to a fixed policy u = \u03c0(X) over a fixed time interval. The resultant expected changes in grit and reachability of a future event B are bounded as follows: (1) min\u03c0 E [\u2206\u0393B ] \u2264 0, and (2) E [\u2206\u039bB ] \u2264 0 for all \u03c0. Further, the equality in both statements holds if transitions are deterministic.\nThe unity proposition states that one is the (only) sticky value for grit: once it is reached, grit will remain at one until B is forcefully reached, irrespective of any intrinsic or extrinsic future event. We will use this important property for proving the sufficiency of a cause. The null proposition, enables to reason about rejection of a future event. We will use this proposition to establish necessity of a cause. The third proposition provides anticipation for the expected change of grit and reachability (i.e., on average). Of note, in practice, a learned value function is often used in place of V \u2217, which may violate such properties to various degrees depending on the level of approximation errors."
        },
        {
            "heading": "4 FORMAL ESTABLISHMENT OF CAUSATION",
            "text": "Let \u03c6A(j) = E {gj |A}+ E {g\u0307j |A}+ \u2211n\ni=1 i \u0338=j E {g\u0308j,i|A} be the impact of component j on event B\u2019s grit during event A (likewise for actions). Using decomposition lemma, we can directly state the definition of causation in a mathematical form, which we call proposition of causation: Proposition 4 (Causation). Let A occurs over the interval [t1, t2] and DA be the set of A\u2019s ruling variables. A is a cause of B if and only if\n1. A happens before B 2. E{\u2206A(\u0393B)} > 0 and E{\u0393B ( X(t) ) } > E{\u0393B ( X(t1) ) } for all t > t2\n3. \u2211 j\u2208DA \u03c6A(j) > \u2212 \u2211 j \u0338\u2208DA min ( \u03c6A(j), 0 ) Proposition 4 judges A as a whole. If A contains more than one ruling variable, i.e., |DA| > 1, a comparison of their individual contributions will help discover spurious or redundant variables inside A. This can prove useful in the context of causal discovery.\nKey Properties of Causation Our proposition of causation induces various desired properties, we discuss a number of them herein. We, however, remark that no such statements as presented in this section are required and they are provided to grant certain plausibility to the theory. Nevertheless, the actual merit of our theory lends itself to its practical implications.\nWithout loss of generality, let event B have only one ruling variable, Xb, and if B occurs, it will be over the time interval [T, T \u2032]; hence, T \u2032 is either terminal or no reward afterwards. Using value lemma, decomposition lemma, the definition of value functions, and the fact that the reward function of B is only a function of Xb, i.e., rB(X) = rB(Xb), it follows that\n\u2202\u0393B(X(t)) \u2202Xj(t) = \u2212 \u2202V \u2217\u0393\n( X(t) ) \u2202Xj(t) = \u2212 \u2202 \u2202Xj(t) E \u222b \u221e t+ rB(X(t\u2032))dt\u2032 = \u2212 \u2202 \u2202Xj(t) E \u222b T \u2032 T rB(X(t\u2032))dt\u2032\n= \u2212E \u222b T \u2032 T \u2202rB(Xb(t \u2032)) \u2202Xj(t) dt\u2032 = \u2212E \u222b T \u2032 T drB(Xb(t\u2032)) dXb(t\u2032) \u2202Xb(t \u2032) \u2202Xj(t) dt\u2032 (7)\nSimilar equations can be derived for the second derivatives. These derivatives of \u0393B are still random variables due to X(t), as the expectation operators (from the definition of value functions) only affect stochasticity after t. If B happens, the term drB(Xb(t\u2032))/dXb(t\u2032) is nonzero (by construction) over [T, T \u2032]. Consequently, the driver terms are the derivatives (sensitivity) of Xb at a future time t\u2032 to the j-th state component at an earlier time t. If the sensitivity is zero, then the contribution of j in change of grit will render null.\nTo shed more light on this, let us expand the first derivative. Remark that X(\u00b7) is a diffusion; hence, there exists a sequence of m \u2265 0 stopping times from t to t\u2032, such that t \u2264 \u03c41 < \u03c42 < \u00b7 \u00b7 \u00b7 < \u03c4m \u2264 t\u2032. The strong Markov property of X asserts that state components at each stopping time are conditionally independent of their values at any time prior to the preceding stopping time. We therefore write\n\u2202Xb(t \u2032) \u2202Xj(t) = \u2211 i1\u2208D1 \u00b7 \u00b7 \u00b7 \u2211 im\u22121\u2208Dm\u22121 \u2211 im\u2208Dm \u2202Xb(t \u2032) \u2202Xim(\u03c4m) \u2202Xim(\u03c4m) \u2202Xim\u22121(\u03c4m\u22121) . . . \u2202Xi1(\u03c41) \u2202Xj(t) (8)\nwhere Dk is the set of all state variables, which appear in the (stochastic) differential equation of Xik+1 , with Dm corresponds to those of Xb. Equation equation 8 shows how a change in Xj at t propagates through other components across time until reaching Xb at t\u2032, thus causing Xb to change in a certain way during event B. This may also be seen as a formal materialization of what philosophers refer to as \u201cchain of events from A to B\u201d (Lewis, 1973; Paul, 1998). Plugging equation 8 into equation 7 and then into decomposition lemma, we see how this chain of events eventually changes the expected grit of B. Using these as well as previous results, we can prove various core properties:\ni. Efficiency: The collective contribution of all components during any time interval is equal to E \u2206\u0393B over that interval.\nii. Symmetry: If two variables are symmetrical w.r.t. Xb (i.e., having exactly the same impact on the dynamics of other variables, which ultimately reach Xb), then switching them does not impact \u2202j\u0393B . Furthermore, their contributions in \u2206\u0393B will be exactly the same provided that their respective \u00b5 and \u03c3 are the same during the given time interval.\niii. Null event: Contribution of Xj in \u2206\u0393B is zero if and only if at some stopping time through the propagation chain of equation 8, Dk is empty (meaning that there is no link between Xj at t and Xb at t\u2032). Such an event is called null event w.r.t. B.\niv. Linearity: Let Ai, Aj , and Ai,j be three events with the ruling variables Xi, Xj and {Xi, Xj}, respectively. Then, the contribution of Ai,j in \u2206\u0393B is sum of the contributions of Ai and Aj .\nCorrelations vs. Causation. Wrongly identifying correlations as causal links is a core problem in formal reasoning. We show that our theory nullifies such links. Consider three consecutive and non-overlapping events A, A\u2032, and B, which occur in this exact order and possess distinct ruling variables. Let A be the cause of both A\u2032 and B, and consider two cases: Case 1: A\u2032 also causes B, and Case 2: A\u2032 has nothing to do with B; however, they are still correlated due to having the same cause, i.e., A. Using equation 8, we observe that in Case 1, if both A and A\u2032 are causes of B, then all Dk\u2019s must be non-empty (otherwise they cannot be a cause due to the null-event property). As a result, in this case, change of grit will become non-zero, meaning that proposition of causation correctly asserts both A and A\u2032 as causes of B. In direct contrast, in Case 2, by assumption A\u2032 is\na null event for B and at some stopping time after the conclusion of A\u2032, the propagation of ruling variables of A\u2032 towards Xb is terminated (i.e., propagation of A toward A\u2032 and toward B happens through different collections of Dk\u2019s). Thus, equation 8 implies \u2202j\u0393B = 0 for j \u2208 DA\u2032 ; hence, proposition of causation will correctly reject A\u2032 as a cause. This same logic can be used to address the problem of late-preemption that counterfactual theories have difficulty handling (Gallow, 2022).\nSufficiency and Necessity of a Cause. There are two further results of practical importance, namely, sufficiency and necessity of a cause. A sufficient cause is one that forcefully makes the effect occur in finite time. According to unity proposition, the necessary and sufficient condition that B forcefully happens from state x is E \u0393B(x) = 1. Using this result, the following proposition is immediate: Proposition 5 (Sufficient Causation). Let X+ be the state at A\u2019s conclusion. Then, A is a sufficient cause for B if and only if A is a cause for B (proposition of causation holds) and E \u0393B(X+) = 1.\nA necessary cause is an event without which the effect will never happen from the current state. Occurrence of a necessary cause does not guarantee the effect\u2019s happening, but it is required for the effect to happen. More formally, if a state x does not admit the occurrence of A, then A is a necessary cause for B from the state x if every trajectory from x to B passes through A. That is, if A is not reachable from x, then so isn\u2019t B. Using null proposition, the following is therefore immediate: Proposition 6 (Necessary Causation). Let A be a unique event (i.e., ruling variables of A admit certain values \u201conly if\u201d A occurs) and let X not admit conclusion of A. A is a necessary cause at X for the event B if and only if A is a cause for B, and E \u039bA(X) = 0 =\u21d2 E \u039bB(X) = 0.\nComputational Machinery. We can approximate the integrals with summations of M points using the trapezoidal rule (M is a hyper-parameter). Let us use the first-order approximate of \u00b5, which only depends on applying u at the m-th point, corresponding to the time m \u00b7 (t2 \u2212 t1)/M . To simplify the notation, define X(m) .= X(m \u00b7 (t2 \u2212 t1)/M). Note that in discrete-time problems, we still need to interpolate these points between the actual time ticks of the environment. We use forward approximation of \u00b5 at m and backward approximation at m+ 1, which alleviates the need for triplepoint data of action u. This yields \u00b5j(X(m),u) \u2243 \u00b5j(X(m+ 1),u) \u2243 ( Xj(m+ 1)\u2212 Xj(m) ) /\u2206t. This formula approximates \u00b5 by the slope of the (hyper-)line segment between X(k) and X(k + 1). Using one-step trapezoidal rule and \u2206t = (t2 \u2212 t1)/M , it therefore follows (note that \u2206t cancels out): gj \u2243 12 \u2211M m=1 ( Xj(m + 1) \u2212 Xj(m) ) \u00b7 ( \u2202j\u0393B ( X(m) ) + \u2202j\u0393B ( X(m + 1) )) . We call this equation g-formula. Similar formulas can be derived for h, g\u0307, and g\u0308."
        },
        {
            "heading": "5 EXPERIMENTS",
            "text": "We present two illustrative examples that no existing method can tackle. Modeling dynamical systems as SCMs is computationally and memory intensive to a prohibitive degree, especially in systems with numerous variables (Koller and Friedman, 2009). Additionally, it typically requires causal discovery methods and domain expertise to establish causal graphs and system equations. In contrast, our method operates solely on raw observational data without accessing system equations or causal graphs. Furthermore, defining \u00acA events in interventionist frameworks is largely ambiguous, particularly in continuous spaces, and predicting intervention outcomes heavily relies on restrictive assumptions about interventions or system models (Peters et al., 2022; Hansen and Sokol, 2014). Consequently, existing methods are irrelevant for baseline comparisons.\nAtari Game of Pong. To understand causal reasoning in a real setting, we applied our theory to the Atari 2600 (Bellemare et al., 2013) game of Pong. Event B is losing a score, and the question is why B happens if the player does not move its paddle. For our study, we use the DQN architecture (Mnih et al., 2015), but set \u03b3 = 1 and r = \u22121 if losing a point (terminal state) and zero otherwise. The rest of hyper-parameters are similar to Mnih et al. (2015). We next use the Pytorch\u2019s autograd to compute the value function\u2019s gradient w.r.t. screen pixels, based on which we could compute g-formula with M = 10 computational micro-steps to compute the integral. Further details can be found in Appendix D. Illustrated in Fig. 1, the method accurately pinpoints not only the last steps where the paddle should have moved (49), but also the pixels corresponding to the ball\u2019s movement. From 48, at each step, the set of actions that can catch the ball increasingly shrinks and the expected grit of losing\na point increases. As all conditions in proposition of causation hold, these ball movements are the causes for B. Moreover, the change from 50 to 51 fulfills the proposition of sufficient causation. Playing the game step by step, one can easily confirm that 50 is the first frame, which is already too late and nothing can be done to catch the ball. Remark again that all these results are obtained through sheer learning with no access to system equations or human-level knowledge.\nReal-world Diabetes Simulator. In this experiment, we analyze multivariate medical time-series data using an open-source implementation of the FDA-approved Type-1 Diabetes Mellitus Simulator (T1DMS) (Kovatchev et al., 2009). The simulator models a patient\u2019s blood glucose (BG) level and 12 other real-valued signals representing glucose and insulin values in different body compartments. We control two actions: 1) insulin intake, to regulate insulin level 2) meal intake, to manage the amount of carbohydrates. More details on the data and experiment design can be found in Appendix E. This experiment helps us investigate the impact of insulin and carbohydrate intake on blood glucose levels. Meal intake increases the amount of glucose in the bloodstream, which for T1D patients, is regulated with external insulin intake. However, intensive control of blood glucose with insulin injections can increase the risk of hypoglycemia (BG level < 70 mg/dL), which is the effect event we aim to understand its causes (event B). We use Monte Carlo learning to estimate V\u0393(X) and thus \u0393B(X). Of note, the algorithm has only access to data. In our setting, we observe that intake of insulin causes an instantaneous spike in dynamics of subcutaneous insulin 1 (SI1), while intake of carbohydrates causes an instantaneous spike in glucose in stomach 1 (GS1). Since the previous action is considered as part of the current state, the spike in subcutaneous insulin just acts as a proxy for action insulin, similarly for action meal and GS1. We study two scenarios under event B:\n(A) Single intake of insulin: In the scenario described in Fig. 2-A, we wish to answer why event B (BG level < 70 over t \u2208 [312, 313]) did happen. Here we notice that \u2206\u0393B(X) > 0 over t \u2208 [180, 181]. Hence we can say that the change in state at t \u2208 [180, 181] contains possible causes for hypoglycemia. Now, we need to determine the change in which state component Xi could have led to \u2206\u0393B(X) > 0. To do this, we will decompose \u2206\u0393B(X) as individual contributions from each state variable. Using decomposition lemma, in Fig. 3-A we see the individual contributions of each variable towards the total grit as seen in gi. We notice that at the time interval t \u2208 [180, 181], the contribution to total grit only comes from variable SI1. Therefore, a change in variable SI1 at t \u2208 [180, 181] (event A) is considered cause of event B.\n(B) Multiple intakes of insulin and meal: In Fig. 2-B, following a similar drill, we notice that \u2206\u0393B(X) > 0 at t \u2208 [180, 181] and at t \u2208 [510, 511]. However, although \u2206\u0393B(X) > 0 at t \u2208 [180, 181], \u0393B decreases to levels before t=180, prior to reaching event B. Therefore, change in variables at t \u2208 [180, 181] cannot be a cause since it violates condition C2 of proposition of causation. This only leaves change in variables at t \u2208 [510, 511] as a possible cause. Using decomposition lemma, Fig. 3-B reveals that at time interval t \u2208 [510, 511] the contribution to total grit comes only from variable SI1 (event A2). Therefore event A2 is the only cause of event B."
        },
        {
            "heading": "6 CONCLUSIONS",
            "text": "We have presented a general theory for causation in dynamical settings, based on a direct analysis of the underlying process. We confined our exposition mostly to the case of given an event as effect, how to reason about possible causes. Our formal results enable a full framework, which can answer such causal questions directly from raw data. Further, we showed that various desired properties are immediate from our postulation, including the core conditions of counterfactual views. The main limitation of this work is two-fold: higher moments than two of the stochasticity are dismissed and the full information state is assumed. Relaxation of these assumptions are left for future work."
        },
        {
            "heading": "DATA AND CODE AVAILABILITY",
            "text": "Our code and pretrained models to replicate the analysis (including figures) presented in this paper is publicly available at: https://github.com/fatemi/dynamical-causality.\nFor the T1D experiment we have used an open-source implementation of the FDA-approved Type-1 Diabetes Mellitus Simulator (Kovatchev et al., 2009). The code is publicaly available at: https: //github.com/jxx123/simglucose"
        },
        {
            "heading": "ACKNOWLEDGMENTS",
            "text": "We express our sincere gratitude to our colleagues whose invaluable advice enhanced the quality of this work. Special thanks are extended to the former RL team and other colleagues at MSR Montreal for their pivotal suggestions during the early stages of this project. We are particularly grateful for the insightful feedback offered by Marzyeh Ghassemi, Elliot Creager, and Rahul G. Krishnan. Additionally, we would like to acknowledge the anonymous reviewers for their encouraging remarks and constructive suggestions, which helped to improve this paper.\nSindhu Gowda is supported by grants provided through Vector Institute and the University of Toronto. Special thanks is extended to her university advisor, Dr. Marzyeh Ghassemi, for all her supports and encouragements.\nResources used in performing this research were partially provided by Microsoft Research, the Province of Ontario, the Government of Canada through CIFAR, and companies sponsoring the Vector Institute: www.vectorinstitute.ai/#partners."
        },
        {
            "heading": "AUTHOR CONTRIBUTIONS",
            "text": "This paper is the culmination of an extensive collaborative effort. MF initiated, conceptualized, and led the project. MF designed and developed theoretical concepts, formulated proofs, and implemented the Atari experiment. SG contributed significantly to discussions, integrating concepts and ideas from established causal literature, and providing diverse comparisons and discussions presented in both the main text and the Appendix. SG implemented the T1D experiment. Both authors jointly analyzed the results, co-authored the manuscript, and finalized the paper. The authors declare equal contributions to this work."
        },
        {
            "heading": "A RELATED WORK",
            "text": "Static Settings. As noted above, philosophers have time and again proposed different theories trying to understand causation from raw data. Since the 80\u2019s, statisticians have tried to materialize this dream through mathematical reductions. The most popular framework for actual causation was purposed by Halpern and Pearl Halpern and Pearl (2001; 2005) following Pearl\u2019s influential book on causality that provided the first formal definition of causation Pearl et al. (2000). Pearl claimed that using causal models allows one to make the intuitive understanding of causation formally precise, whereas existing logical notions lack the resources to do so. Further, Pearl defined three basic probabilities of causation \u2013 the probability of necessity, of sufficiency, and of necessity and sufficiency, and ways to calculate them from data (Pearl, 2022). Moreover, researchers have used the causal structure and the properties of the data to narrow the bounds of the above probabilities of causation Tian and Pearl (2000); Dawid et al. (2017); Mueller et al. (2021). Needless to say, Pearl\u2019s account has come under criticism and revision \u2013 both from philosophers and researchers in AI Beckers (2021); Beckers and Vennekens (2018); Halpern (2015); Weslake (2015); Hitchcock (2001; 2007). However, all these works try to infer causal relationships from non-temporal data by making certain assumptions about the underlying process of data generation (causal graphs), which restricts the understanding of causation to static settings.\nDynamic Settings. Works like Granger (1969); White and Lu (2010); Peters et al. (2013); Pfister et al. (2019); Eichler and Didelez (2012); Huang et al. (2020) deal with understanding causal relations in time series data, but mostly consider discrete-time models. Moreover, they focus on finding causal dependencies between different variables in time series data while we try to find causation between events, defined by a change in variables during a homogeneous time interval. Further, works like Peters et al. (2022); Hansen and Sokol (2014); Mooij et al. (2013); Blom and Mooij (2018); Bongers et al. (2018); Rubenstein et al. (2016) focus on continuous time systems that are governed by ordinary differential equations and propose a framework to model dynamical systems as structural causal models (SCMs). Again, they focus on understanding the effect of interventions and on causal structure learning or causal discovery under various system-level assumptions and do not deal with understanding the causation of events itself. It\u2019s important to note that \u201ccausal discovery\u201d or structural learning as used in current literature deals with inferring the underlying causal structure or dependencies between variables from raw data Pearl (1980); Spirtes et al. (2000). It does not concern itself with understanding the cause of an event in a specific context Halpern (2016).\nFurther, all the above-mentioned methods deal with understanding causation from a counterfactualinterventionist perspective Woodward and Woodward (2005); Pearl (1980), while we follow the route of process theory of causation and emphasize system-level thinking to answer questions of causation Fazekas et al. (2021); Salmon (1984); Dowe (2000). Works like Fazekas et al. (2021) propose a philosophical framework for a dynamical systems approach to causation based on the process theory of causation Salmon (1984); Dowe (2000) and emphasize conceptually the importance of system-level thinking. However, the paper stops there, while we provide a formal framework that materializes this idea and enables computational machinery.\nSensitivity Analysis. Another related area from a different domain is sensitivity analysis. The primary goal of sensitivity analysis is to understand the sensitivity or responsiveness of a model\u2019s output to variations in its input factors Ljung (1987); Skogestad and Postlethwaite (2005). However, it should be highlighted that sensitivity does not imply causation and defining causation purely based on sensitivity results in wrong causal arguments. Additionally, no connection is made in sensitivity analysis with value functions and learning algorithms thereof.\nWe believe a side-by-side discussion of dynamical systems and the theory of causation will allow us to develop novel approaches, transfer expertise across communities, and enable us to overcome the current limitations of each perspective individually. Our goal is to cast causation as a learning problem from dynamic temporal data such that given sufficient data, one can reliably answer the question of why. Notably, our paradigm conveniently covers both cases of intrinsic causation (cause is a change in the environment itself) and extrinsic causation (cause is an action applied to the environment)."
        },
        {
            "heading": "B EXTENDED FORMAL RESULTS",
            "text": "Here, we present the proofs of formal claims from the paper with further discussions. The results are numbered as in the main paper.\nLemma 1 (Value Lemma). Define two MDPs M\u0393 and M\u039b to be identical to M with their corresponding reward kernels being R\u0393 = \u2212\u03b4(x\u2212 x\u0303) and R\u039b = \u03b4(x\u2212 x\u0303), where x\u0303 admits the occurrence of event B and \u03b4(\u00b7) denotes the Dirac delta function. Further, set all such x\u0303 as terminal states. Let V \u2217\u0393 (x) and V \u2217\u039b (x) denote the optimal value functions of M\u0393 and M\u039b, respectively, under \u03b3 = 1. Then, the followings hold for all x \u2208 X :\n1. \u0393B(x) = \u2212V \u2217\u0393 (x)\n2. \u039bB(x) = V \u2217\u039b (x)\nProof. For part 1, let \u03c0\u2217 denote an optimal policy of M\u0393. We note that since the only source of reward is when B is reached and it is negative, then \u03c0\u2217 maximally avoids reaching B (i.e., \u03c0\u2217 optimally chooses to reach anywhere but B). Hence, following \u03c0\u2217 results in the minimum probability of reaching B from any state. On the other hand, \u03b3 = 1 induces that the return of any sample path is precisely \u22121 if B is reached and zero otherwise. By definition, the optimal value of each state is the expectation of the return from all sample paths starting from that state and following \u03c0\u2217. Let T denote the set of all sample paths and partition it as T = TB \u222a TN , where TB and TN are disjoint sets corresponding to the paths which reach B and those which do not (whose length can be of finite or infinite, the finite case occurs when there are terminal states in M which may happen before ever reaching B or when by assumption time horizon is finite). Let further Z(\u03c3) represent the return of a sample path \u03c3 and P(\u03c3|x, \u03c0\u2217) denote the conditional probability that the sample path \u03c3 occurs if \u03c0\u2217 is followed starting from the state x. It then follows\nV \u2217\u0393 (x) . = E[Z | x, \u03c0\u2217] = \u222b \u03c3\u2208T Z(\u03c3)dP(\u03c3|x, \u03c0\u2217)\n= \u222b \u03c3\u2208TB \u22121 dP(\u03c3|x, \u03c0\u2217) + \u222b \u03c3\u2208TN 0 dP(\u03c3|x, \u03c0\u2217) = \u2212P \u2217B(x)\nwhere P \u2217B(x) = \u222b \u03c3\u2208TB dP(\u03c3|x, \u03c0\n\u2217) denotes the total probability of reaching B from x if \u03c0\u2217 is followed; that is, the minimum probability of reaching B from x, which by definition is \u0393B(x).\nSimilarly, for part 2, let \u03c0\u0304\u2217 denote an optimal policy of M\u039b. We write\nV \u2217\u039b (x) . = \u222b \u03c3\u2208T Z(\u03c3)dP(\u03c3|x, \u03c0\u0304\u2217)\n= \u222b \u03c3\u2208TB +1 dP(\u03c3|x, \u03c0\u0304\u2217) + \u222b \u03c3\u2208TN 0 dP(\u03c3|x, \u03c0\u0304\u2217) = P\u0304 \u2217B(x)\nHere, P\u0304 \u2217B(x) = \u222b \u03c3\u2208TB dP(\u03c3|x, \u03c0\u0304\n\u2217) represents the probability of reaching B from x if \u03c0\u0304\u2217 is followed. \u03c0\u0304\u2217 minimizes the chance of missing B due to its positive reward and being the only source of reward. However, it only cares about reaching B and it does not distinguish among various paths as long as they reach B. That is, \u03c0\u0304\u2217 does not induce a shortest path to B, but it maximized the chance of reaching B. Hence, P\u0304 \u2217B(x) would be the maximum probability of reaching B from x, which by definition is \u039bB(x), which completes the proof. We note that similar value functions, but for discrete time, state, and action, has also been introduced by (Fatemi et al., 2019; 2021).\nWe should mention here that similar results may be extended to distributional RL (Bellemare et al., 2017) or to the case of semi-Markov settings (Sutton et al., 1999). Such settings are of practical interest (see for example Fatemi et al. (2022)).\nLemma 2 (Decomposition Lemma). Fix a filtered probability space (\u2126,F,P). Let X = X(t, \u03c9) be a diffusion process with stationary infinitesimal parameters \u00b5 = \u00b5(x,u) and \u03c3 = \u03c3(x,u). Let grit and reachability be defined over X, and both be differentiable twice in state. Let \u03c3i(x,u) denote the i-th row of the matrix \u03c3(x,u). Finally, let a fixed action u be applied from time t1 to t2 and the state admits certain values at t1 and t2 for some of its components. The admissions correspond to an event A. The expected change of grit, E [\u2206A\u0393B ] = E [ \u0393B ( X(t2, \u03c9))\u2212 \u0393B(X(t1, \u03c9) ) |A ] , is expressed by the following formula:\nE [\u2206A\u0393B ] = n\u2211\nj=1\nE {gj |A}+ n\u2211\nj=1\nE {g\u0307j |A}+ n\u2211\nj=1 n\u2211 i=1 i\u0338=j E {g\u0308j,i|A} , (9)\ngj . = \u222b t2 t1 \u00b5j(X,u) \u00b7 \u2202\u0393B \u2202xj (X)dt (10)\ng\u0307j . =\n1\n2 \u222b t2 t1 \u03c3j(X,u) \u00b7 \u03c3Tj (X,u) \u00b7 \u22022\u0393B \u2202xj2 (X)dt (11)\ng\u0308i,j . =\n1\n2 \u222b t2 t1 \u03c3i(X,u) \u00b7 \u03c3Tj (X,u) \u00b7 \u22022\u0393B \u2202xi\u2202xj (X)dt (12)\nand the expectations are expressed on \u03c9. The same formulation holds for reachablity.\nProof. Conditioning on event A makes some components of X become deterministic and known, and the process is still a diffusion. Hence, the result follows from It\u00f4\u2019s lemma, then taking conditional expectation from both sides and rearranging the terms. Remark that for any integrable function Y(t, \u03c9), we have E{ \u222b t2 t1\nY(t, \u03c9) dW(t, \u03c9)|A} = 0 (see Theorem 3.1 in Stokey (2009)). As a result, the dW part in It\u00f4\u2019s lemma is eliminated and the stated result will follow.\nProposition 1 (Unity Proposition). If grit of B is unity at some state x, then with probability one it will remain at unity. Moreover, this occurs if and only if B will happen with probability one from x regardless of future actions and stochasticity.\nProof. We establish the proof under mild assumptions on the dynamics (that a small enough \u2206 exists). A more rigorous proof may be possible by relaxing such assumptions (like it is in the discrete cases). However, insofar as the goal being applying the theory to practical problems, which naturally involve discrete or discretized time, the present proof fully suffices.\nWe first prove that if grit is unity then B will happen w.p.1. and grit will remain at one until B occurs. Following the value lemma, \u0393B(x) = \u2212V \u2217\u0393 (x). We therefore show that if V \u2217\u0393 (x) = \u22121, it will then remain at -1 until B occurs. Remark that in the case of discrete state and discrete time, the result follows Lemma 1 of Fatemi et al. (2021) (similar ideas also exist in Fatemi et al. (2019) and Cao et al. (2023)). Here, using a similar line of argument, we present the proof for the general case of continuous time and state.\nRemark that both V \u2217\u0393 and Q \u2217 \u0393 are in [\u22121, 0] for all states and actions. Thus, \u22121 = V \u2217\u0393 (x) = maxu Q \u2217 \u0393(x,u) implies that Q\u2217\u0393(x,u) = \u22121 for all u. Therefore, if V \u2217\u0393 (x) remains at -1, so does Q\u2217\u0393(x,u) for all u and, as a result, we only require to show V \u2217\u0393 (x) remains at -1 with no reference to any particular policy for action selection. In other words, all actions are optimal at x (w.r.t. maximizing integration of R\u0393) and choice of u at x makes no difference.\nBy construction, any trajectory that includes B has a terminal state at the end of B. Let \u2206 be a small positive number such that it can cover the duration of B. We partition time into intervals of length \u2206. Starting from x at time 0, the world will be at a (random) state X\u2032(\u03c9) .= X(\u2206, \u03c9) at time t = \u2206. Let \u2206 be small enough such that selection of u \u2208 argmaxu\u2032 Q\u2217\u0393(x,u\u2032) at t = 0 and sticking to it for [0,\u2206] is almost the same as following argmaxQ\u2217\u0393(x, \u00b7) during [0,\u2206]. Such \u2206 exists due to the continuity of diffusion\u2019s sample paths and the assumption that duration of any event, including B, has to be short w.r.t. the rate of changes of the state.\nDuring the time interval [0,\u2206], exactly one of four possibilities could occur:\n1. a terminal state happens that admits B;\n2. a terminal state happens that does not admit B;\n3. no termination: X\u2032 is a non-terminal state with V \u2217\u0393 (X \u2032) = \u22121;\n4. no termination: X\u2032 is a non-terminal state with V \u2217\u0393 (X \u2032) = \u2212\u03b2 \u2208 (\u22121, 0].\nIn the first two cases, by the definition of terminal state, X\u2032 is also a terminal state with zero value. Let C1 to C4 represent the sets of all possible states X\u2032 corresponding to each of the four cases above. These sets are mutually disjoint. We then show that if V \u2217\u0393 (x) = \u22121, then only either of (1) or (3) can happen. We note that any sample path of a diffusion is continuous. Since R\u0393(\u00b7) is also a continuous function, its integral exists. We can therefore write:\n\u22121 = V \u2217\u0393 (x) = E [ \u222b \u2206\n0\nR\u0393(X(t, \u03c9))dt+ V \u2217\u0393 (X \u2032(\u03c9)) | X(0, \u00b7) = x ] = P[X\u2032 \u2208 C1] ( \u2212 1 + 0 ) + P[X\u2032 \u2208 C2] ( 0 + 0 ) + P[X\u2032 \u2208 C3] ( 0\u2212 1 ) + P[X\u2032 \u2208 C4] ( 0\u2212 \u03b2\n) = \u2212P[X\u2032 \u2208 C1 \u222a C3]\u2212 \u03b2P[X\u2032 \u2208 C4]\n= \u2212 ( 1\u2212 P[X\u2032 \u0338\u2208 C1 \u222a C3] ) \u2212 \u03b2P[X\u2032 \u2208 C4]\n= \u2212 ( 1\u2212 P[X\u2032 \u2208 C2 \u222a C4] ) \u2212 \u03b2P[X\u2032 \u2208 C4]\n= \u22121 + P[X\u2032 \u2208 C2] + ( 1\u2212 \u03b2 ) P[X\u2032 \u2208 C4]\nwhich deduces\nP[X\u2032 \u2208 C2] + ( 1\u2212 \u03b2 ) P[X\u2032 \u2208 C4] = 0\nWe remark that 1\u2212\u03b2 is strictly positive; thus we conclude both P[X\u2032 \u2208 C2] = 0 and P[X\u2032 \u2208 C4] = 0. Consequently, the resultant state is either a terminal state admitting B (i.e., X\u2032 \u2208 C1) or some state X\u2032 where V \u2217\u0393 (x\u2032) = \u22121 (i.e., X\n\u2032 \u2208 C3). Following the same line of argument on X\u2032 and noting that by assumption the time horizon is finite, we conclude that V \u2217\u0393 remains precisely at -1, and the path will eventually reach B with probability one, regardless of stochasticity and selected actions.\nConversely, if from a state x, event B is going to happen with probability one, then all possible future trajectories will reach a reward of \u22121, which makes their return also be \u22121. More precisely, those trajectories which end with a reward of zero will have zero probability. Hence, the expected return from (i.e., the value function of) state x would be \u22121 regardless of stochasticity; hence, V\u0393(x) = \u22121. It is then immediate from value lemma that \u0393B(x) = 1 if B occurs with probability one from x.\nProposition 2 (Null Proposition). If reachablity of an event B is zero at some state x, then w.p.1 it will remain at zero. Moreover, this occurs if and only if B will almost surely never happen, regardless of future actions and stochasticity.\nProof. The proof is similar to the previous proposition. In particular, during the time interval [0,\u2206], exactly one of three possibilities could occur:\n1. a terminal state happens that admits B;\n2. a terminal state happens that does not admit B;\n3. no termination: X\u2032 is a non-terminal state with V \u2217\u039b (X \u2032) = \u03b2 \u2208 [0, 1].\nNote that, compared to the proof of Proposition 1, here we combined the last two items, resulting in only three items. In the first two cases, by the definition of terminal state, X\u2032 is also a terminal state with zero value. Also note that in the case of reachability, the reward integrates to one over an interval where B occurs and is zero elsewhere. Similarly to the previous proposition, let C1 to C3 represent the sets of all possible states X\u2032 corresponding to each of the three cases above, and these\nsets are mutually disjoint. Here, we show that if V \u2217\u039b (x) = 0, then only either (2) can happen, or else (3) can happen, in which case \u03b2 has to be zero. We write\n0 = V \u2217\u039b (x) = E [ \u222b \u2206\n0\nR\u039b(X(t, \u03c9))dt+ V \u2217\u039b (X \u2032(\u03c9)) | X(0, \u00b7) = x ] = P[X\u2032 \u2208 C1] ( 1 + 0 ) + P[X\u2032 \u2208 C2] ( 0 + 0 ) + P[X\u2032 \u2208 C3] ( 0 + \u03b2\n) = P[X\u2032 \u2208 C1] + \u03b2P[X\u2032 \u2208 C3]\n= ( 1\u2212 P[X\u2032 \u0338\u2208 C1] ) + \u03b2P[X\u2032 \u2208 C3]\n= 1\u2212 P[X\u2032 \u2208 C2 \u222a C3] + \u03b2P[X\u2032 \u2208 C3] = 1\u2212 P[X\u2032 \u2208 C2] + ( \u2212 1 + \u03b2 ) P[X\u2032 \u2208 C3]\nwhich deduces\nP[X\u2032 \u2208 C2] + ( 1\u2212 \u03b2 ) P[X\u2032 \u2208 C3] = 1 (13)\nHence, the following cases are possible (note: P[X\u2032 \u2208 Ck] = 1 implies P[X\u2032 \u2208 Ck\u2032 ] = 0, k\u2032 \u0338= k):\n(i) P[X\u2032 \u2208 C2] = 1;\n(ii) P[X\u2032 \u2208 C3] = 1 with \u03b2 = 0 (otherwise the equality cannot hold);\n(iii) both P[X\u2032 \u2208 C2] \u0338= 1 and P[X\u2032 \u2208 C3] \u0338= 1, with \u03b2 \u0338= 1 (otherwise the equality cannot hold).\nNote that if \u03b2 \u0338= 0 then P[X\u2032 \u2208 C2] cannot be zero because 1 \u2212 \u03b2 < 1 and equation 13 would be violated. That is, in the case of P[X\u2032 \u2208 C3] = 1 (hence, P[X\u2032 \u2208 C2] = 0), \u03b2 has to be zero. On the other hand, if \u03b2 = 1, then P[X\u2032 \u2208 C2] must be one; hence, in (iii), \u03b2 = 1 must be excluded. Let both P[X\u2032 \u2208 C2] \u0338= 1 and P[X\u2032 \u2208 C3] \u0338= 1. Using the fact that P[X\u2032 \u2208 C2] + P[X\u2032 \u2208 C3] \u2264 1 and substituting from equation 13, it yields\nP[X\u2032 \u2208 C2] + 1\u2212 P[X\u2032 \u2208 C2]\n1\u2212 \u03b2 \u2264 1\nRe-arranging the terms and having note that \u03b2 \u0338= 1, it follows that 1/(1 \u2212 \u03b2) \u2264 1 or 1 \u2212 \u03b2 \u2265 1, which deduces \u03b2 = 0. Substituting \u03b2 = 0 in equation 13, it follows that\nP[X\u2032 \u2208 C2] + P[X\u2032 \u2208 C3] = 1\nwhich implies P[X\u2032 \u2208 C1] = 0. Thus, occurrence of a terminal state that admits B is improbable. Furthermore, in the case that both P[X\u2032 \u2208 C2] \u0338= 1 and P[X\u2032 \u2208 C3] \u0338= 1, \u03b2 must be zero. That is, the next state X\u2032 is (with probability one) either a terminal state not admitting occurrence of B, or else a non-terminal state with V\u039b(X\u2032) = 0. Continuing with this line of argument and knowing that by assumption the time horizon is finite, we conclude that V\u039b remains at zero until reaching a terminal state, which does not admit occurrence of B (hence, B never happens). Using value lemma, it then follows that \u039bB also remains at zero and B will never occur.\nConversely, if B never happens, then all possible trajectories will incur zero return; thus, the expected return is zero, i.e., V\u039b = 0, which deduces \u039bB = 0.\nProposition 3. Let action u be selected according to some policy \u03c0(x) over a time interval [t1, t2]. The resultant expected changes in grit and reachability of some future event B are bounded as follows:\n1. min\u03c0 E [\u2206\u0393B ] \u2264 0\n2. E [\u2206\u039bB ] \u2264 0 for all \u03c0\nwith the equality in both statements holds for deterministic environments.\nProof. As the argument goes for any arbitrary point before event B\u2019s occurrence, the reward of both MDP\u2019s are zero by definition. Also, remark that there is no discounting. Hence, the value functions in Lemma 1, V \u2217\u0393 and V \u2217 \u039b , admit HJB equation of the following form:\nmax u  n\u2211 j=1 \u00b5j(x,u) \u00b7 \u2202V \u2217\u0393 \u2202xj (x) + 1 2 n\u2211 i=1 n\u2211 j=1 \u03c3i(x,u)\u03c3Tj (x,u) \u00b7 \u22022V \u2217\u0393 \u2202xi\u2202xj (x)  = 0 (14) where x is any state that does not admit the occurrence of B. From the value lemma we have \u0393B(x) = \u2212V \u2217\u0393 (x). Let \u03c0 denote any arbitrary stationary policy to select u (not necessarily fixed) from time t1 to t2. We have:\nmin \u03c0 E [\u2206\u0393B ] = min \u03c0 E  \u222b t2 t1  n\u2211 j=1 \u00b5j(x,u) \u00b7 \u2202\u0393B \u2202xj (x) + 1 2 n\u2211 i=1 n\u2211 j=1 \u03c3i(x,u)\u03c3Tj (x,u) \u00b7 \u22022\u0393B \u2202xi\u2202xj (x)  dt \n= max \u03c0\nE  \u222b t2 t1  n\u2211 j=1 \u00b5j(x,u) \u00b7 \u2202V \u2217\u0393 \u2202xj (x) + 1 2 n\u2211 i=1 n\u2211 j=1 \u03c3i(x,u)\u03c3Tj (x,u) \u00b7 \u22022V \u2217\u0393 \u2202xi\u2202xj (x)  dt \n\u2264 E  \u222b t2 t1 max u  n\u2211 j=1 \u00b5j(x,u) \u00b7 \u2202V \u2217\u0393 \u2202xj (x) + 1 2 n\u2211 i=1 n\u2211 j=1 \u03c3i(x,u)\u03c3Tj (x,u) \u00b7 \u22022V \u2217\u0393 \u2202xi\u2202xj (x)  dt \n= 0 (15)\nThe first line follows from decomposition lemma and the second line follows from value lemma. Remark that the negative sign in value lemma switches min to max. Finally, the last line follows from equation 14. If the transitions are deterministic, then the expectation operators (as well as all the \u03c3 terms) will vanish. Hence, the inequality will also be replaced by an equal sign.\nThe proof for the second part follows a similar argument. We start with maxu E [\u2206\u039bB ] and then apply the value lemma similar to the above (remark that there is no negative sign for reachability in the value lemma). This yields maxu E [\u2206\u039bB ] \u2264 0, which induces E [\u2206\u039bB ] \u2264 0. Hence, for reachability, the stated bound holds regardless of the choice of u.\nProposition 4 (Causation). Let DA be the set of A\u2019s ruling variables. A is a cause of B if and only if\n1. A happens before B;\n2. E{\u2206A(\u0393B)} > 0; 3. \u2211 j\u2208DA \u03c6A(j) > \u2212 \u2211 j \u0338\u2208DA min ( \u03c6A(j), 0 ) Proof. This follows from a direct translation of Definition 1 into our formal concepts as well as using decomposition lemma to bring the individual contributions."
        },
        {
            "heading": "PROOF OF PROPERTIES FROM SECTION 4",
            "text": "i. Efficiency: The collective contribution of all components during any time interval is equal to \u2206\u0393B over that interval.\nProof. This is a direct result from decomposition lemma. ii. Symmetry: If two variables are symmetrical w.r.t. Xb (i.e., having exactly the same impact\non the dynamics of other variables, which ultimately reach Xb), then switching them does not impact \u2202j\u0393B . Furthermore, their contributions in \u2206\u0393B will be exactly the same provided that their respective \u00b5 and \u03c3 are the same during the given time interval.\nProof. It is immediate from equation 8 and decomposition lemma.\niii. Null event: Contribution of Xj in \u2206\u0393B is zero if and only if at some stopping time through the propagation chain of equation 8, Dk is empty (meaning that there is no link between Xj at t and Xb at t\u2032). Such an event is called null event w.r.t. B. Proof. If \u00b5 is non-zero for ruling variables of A, then decomposition lemma asserts that \u2202j\u0393B must be zero in order to render j-th contribution null. Assuming that event B is happening or has happened, the only way for that to become zero is that at least one of the Dk\u2019s in equation 8 is empty.\niv. Linearity: Let Ai, Aj , and Ai,j be three events with the ruling variables Xi, Xj and {Xi, Xj}, respectively. Then, the contribution of Ai,j in \u2206\u0393B is sum of the contributions of Ai and Aj . Proof. This follows from decomposition lemma.\nPropositions 5 and 6 These propositions summarize the explanation before them in a formal format. Note also that A should first be a cause for B, then other conditions should be checked."
        },
        {
            "heading": "C COMPARISON TO THE HP DEFINITIONS",
            "text": "In this section, we first provide an overview of how our framework varies from the HP framework broadly.\nWe then discuss and understand the HP definition of actual causation (Halpern and Pearl, 2001; 2005; Halpern, 2015; 2016), then provide a mapping to move between the HP framework and our framework and then compare and contrast our definition of causation and the HP definition of actual causation."
        },
        {
            "heading": "C.1 OVERVIEW",
            "text": "Broadly our framework differs from the HP framework in the following ways:\n\u2022 Time is an explicit factor in our formulation. It establishes the direction of causation between events and answers questions of causation in more practical and complicated scenarios. Since we define events as changes in variables over a homogeneous interval of time, it clears much of the confusion around the time of happening of an event and provides the flexibility to study multiple events that share the same ruling variables and admit the same changes but occur at different points in time.\n\u2022 Since we do not use interventions/manipulations to understand causation, we can make our conclusions from raw observational data without having to conduct interventions or worry about the kind of interventions, especially in complex systems.\n\u2022 Instead of considering actions under a fixed policy, restricting the chain of events between A and B, we examine if event A causes B under the most pessimistic version of such chains of events. Remark that adhering to a certain chain of actions can be readily considered in our framework. This respects the dynamics of the system between the events of interest and helps address more realistic scenarios.\n\u2022 Further, we argue that an event can contribute partially to the happening of the effect without being necessary or sufficient. Our framework argues that, while a cause can be a sufficient and/or necessary cause, it does not have to be a sufficient/necessary cause to qualify as a possible cause of event B."
        },
        {
            "heading": "C.2 STRUCTURAL EQUATION MODELLING",
            "text": "Before we look into the HP definitions we assume that the reader is familiar with the concept of structural equation modeling. To do so, we recommend the reader refer to (Beckers, 2021) section 2, so they are equipped with the basic tools needed to understand the HP definition. For our discussion, we will borrow heavily from this reference for notions and discussions necessary to define and understand structural causal modeling.\nMuch of the discussion and notation is taken from Halpern\u2019s actual causality (Halpern, 2016), as presented in Beckers (2021) with little change. Definition 2. (Beckers, 2021) A signature P is a tuple (U ,V,R), where U is a set of exogenous variables, V is a set of endogenous variables andR a function that associates with every variable Y \u2208 U \u222a V a nonempty set R(Y ) of possible values for Y (i.e., the set of values over which Y ranges). If X\u20d7 = (X1, . . . , Xn) ,R(X\u20d7) denotes the cross productR (X1)\u00d7 \u00b7 \u00b7 \u00b7 \u00d7 R (Xn).\nIt\u2019s important to recognize that exogenous variables are factors whose causes lie beyond the direct influence of the model, encompassing background conditions and noise. Conversely, the values of endogenous variables are causally influenced by other variables within the model, whether they are endogenous or exogenous. We refer to a collection u\u20d7 \u2208 R(U) of exogenous variable values as the contextual setup of the problem. Definition 3. (Beckers, 2021) A causal model M is a pair (P,F), where P is a signature and F defines a function that associates with each endogenous variable X a structural equation FX giving the value of X in terms of the values of other endogenous and exogenous variables. Formally, the equation FX mapsR(U \u222a V \u2212 {X}) toR(X), so FX determines the value of X , given the values of all the other variables in U \u222a V ."
        },
        {
            "heading": "C.3 HP DEFINITIONS",
            "text": "We now look at HP definitions of causation as presented in (Halpern, 2015). Halpern and Pearl (Halpern and Pearl, 2001; 2005) develop two of the initial HP definitions, whereas the third one is proposed solely by Halpern (Halpern, 2015). This will be the one we will discuss in detail since it builds on the limitations of the earlier proposed definitions. The relations between them are extensively discussed by Halpern Halpern (2016). We encourage the readers to read through this work to get a better insight into it.\nWe borrow on the notions used by (Beckers, 2021) in section 3 to discuss the HP definitions. Throughout our discussion, settings of variables V with\n\u2022 \u2217 i.e., v\u20d7\u2217 indicate that (M, u\u20d7) |= ( V\u20d7 = v\u20d7\u2217 ) .\n\u2022 \u2032 i.e., v\u20d7\u2032 indicate that (M, u\u20d7) |= ( V\u20d7 \u0338= v\u20d7\u2032 ) .\n\u2022 No subscripts can refer to any setting.\nGiven the notations, the modified HP definition Halpern (2015) is given as follows:\nDefinition 4 (Modified HP (Halpern, 2015)). Let event \u03c6 be Y\u20d7 = y\u20d7. X\u20d7 = x\u20d7 is an actual cause of \u03c6 in (M, u\u20d7) if the following conditions hold:\nAC1. (M, u\u20d7) |= (X\u20d7 = x\u20d7) \u2227 \u03c6\nAC2(a). There is a partition of V into two sets Z\u20d7 and W\u20d7 with X\u20d7 \u2286 Z\u20d7 and a setting x\u20d7\u2032 and w\u20d7 of the variables in X\u20d7 and W\u20d7 , respectively, such that (M, u\u20d7) |= [ X\u20d7 \u2190 x\u20d7\u2032, W\u20d7 \u2190 w\u20d7\u2217 ] \u00ac\u03c6 AC2(b). For all subsets Q\u20d7 of W\u20d7 and subsets O\u20d7 of Z\u20d7 \u2212 X\u20d7 , we have (M, u\u20d7) |= [ X\u20d7 \u2190 x\u20d7, Q\u20d7\u2190 q\u20d7, O\u20d7 \u2190\no\u20d7\u2217 ] \u03c6\nAC3. X\u20d7 is minimal; there is no strict subset X\u20d7 \u2032\u2032 of X\u20d7 such that X\u20d7 \u2032\u2032 = x\u20d7\u2032\u2032 satisfies AC2, where x\u20d7\u2032\u2032\nis the restriction of x\u20d7 to the variables in X\u20d7 \u2032\u2032\nWe designate W\u20d7 = w\u20d7 as a witness indicating that when X\u20d7 = x\u20d7, it causes the occurrence of \u03c6. The variables within Z\u20d7 are conceptualized as constituting the \"causal path\" from X\u20d7 to \u03c6. In essence, altering the value of a variable in X\u20d7 leads to changes in the value(s) of certain variable(s) in Z\u20d7, subsequently influencing the values of other variable(s) within Z\u20d7, ultimately resulting in a change in the truth value of \u03c6.\nAC1 stipulates the basic criterion that both the potential cause and effect must be events that occurred. AC3 is similarly straightforward, emphasizing the exclusion of redundant elements from the causal factors. However, the crux of the definition lies in AC2. Halpern categorizes conditions AC2(a) and AC2(b) as the \"necessity condition\" and the \"sufficiency condition,\" respectively (Halpern, 2015).\nAC2(a) asserts that the effect demonstrates counterfactual dependence on the cause, holding the witness fixed at their actual values, i.e, (M, u\u20d7) |= [X\u20d7 \u2190 x\u20d7, W\u20d7 \u2190 w\u20d7\u2217]\u03c6, and (M, u\u20d7) |= [X\u20d7 \u2190 x\u20d7\u2032, W\u20d7 \u2190 w\u20d7\u2217]\u00ac\u03c6. Consequently, AC2(a) can be interpreted as articulating a contrastive necessity condition: there exist contrasting values x\u20d7\u2032 such that altering X\u20d7 to x\u20d7\u2032 results in non-fulfillment of \u03c6.\nThe sufficiency condition, AC2(b), essentially stipulates that when the variables in X\u20d7 and any chosen subset O\u20d7 of other variables along the causal path (besides those in X\u20d7) retain their actual context values, then \u03c6 holds even if only a subset Q\u20d7 of the variables in W\u20d7 are set to their values in w\u20d7 (the setting for W\u20d7 utilized in AC2(a)). Notably, by fixing W\u20d7 to w\u20d7, alterations in the values of variables within Z\u20d7 may occur. AC2(b) asserts that these changes do not impact the truth of \u03c6; it remains valid. Consequently, in light of condition AC2(a), this implies that the variables in W\u20d7 \u2212 Q\u20d7, denoted as W\u20d7 \u2032, essentially operate as they do in reality; their values are determined by the structural equations, denoted as w\u20d7\u2032\u2217."
        },
        {
            "heading": "C.4 MAPPING FROM HP FORMULATION TO OUR FORMULATION",
            "text": "Mapping the problem from a static space to a dynamic space can be quite tricky because of the missing time component in the static setting. In fact, static formulations lacking time makes them particularly difficult to map into dynamical problems.\nRecapping from Def. 2 and Def. 3, in HP framework, a causal model is formally defined as,M = (P,F). P is a signature of tuple (U ,V,R), where U is a set of exogenous variables, V is a set of endogenous variables. F defines a function that associates with each endogenous variable X a structural equation FX giving the value of X in terms of the values of other endogenous and exogenous variables. Note that there are no functions associated with exogenous variables; their values are determined outside the model. We call a setting u\u20d7 \u2208 R(U) of values of exogenous variables a context. Because we are discussing causation in dynamical systems, we will restrict our discussion to strongly recursive (or strongly acyclic) causal models - where given context u\u20d7 the values of all remaining variables can be determined.\nIn our process-based formulation, the model under discussion is a Markov Decision Process (MDP), formally defined as a tuple M = (S,A, R,P0). S and A are sets of possible states and actions (intervenable inputs), R : S 7\u2192 R is a scalar reward function, and P0 is the distribution of initial states. We consider the state (S(t) \u2208 S), to be an n-dimensional vector space and is either fully observable or reconstructable from observations. At any given time, each state component (Sj(t)) is a random variable and the state vector\u2019s evolution across time forms a (stochastic) process. The evolution of state is, therefore, a function of both the intrinsic dynamics and the selected (extrinsic) actions across time. Therefore, the state component Sj(t) can be seen as a function of other state and action components from prior times. Further, we say that S(t) admits one or more known components sj at time t iff Sj(t) = sj .\nAs mentioned earlier, mapping from a static space to a dynamic space can be quite tricky because of the missing time component in the static setting. However, given our discussion so far, we can forge some associations.\nThe endogenous variables (V) of the causal modelM in HP setting can be analogous to the state variables of the MDP model M , but only at a certain time instance, S(t) (n-dimensional vector of random variables). It\u2019s important to note that, since each time instance of any state variable is an endogenous variable, the causal graph in the static sense can grow immensely even for a small MDP - with only a few state variables and time steps. Because we are discussing strongly recursive causal models, the exogenous variables U inM can be thought of as providing the initial conditions, P0 in the MDP model M .\nIn our framework, we formally define an event as a change of one or more state or action components during a homogeneous time interval. The components involved in an event A are called ruling variables of event A, or DA. State admits event A between time [t, t\u2032] if, DA admits a certain change of values between [t, t\u2032], say SDA(t\n\u2032) = x\u20d7 and SDA(t) admits values other than x\u20d7. In HP setting (Halpern, 2016), given a causal modelM, a primitive event is a formula of the form X\u20d7 = x\u20d7, for X \u2208 V and x \u2208 R(X). Since the HP definitions do not explicitly consider time in the definition of events, for simplicity let\u2019s assume that variables X\u20d7 admit values x\u20d7 only once during the observation period.\nTherefore, X\u20d7 = x\u20d7 implies DA, admits a certain change of values between [t, t\u2032], say SDA(t\u2032) = x\u20d7 (implying that in this case, for simplicity, we consider that SDA(t) admits some value of no consequential interest here). Note that we define every event w.r.t to both ruling variables and an associated time interval. This clears much of the confusion around the time of happening of an event and provides the flexibility to study multiple events that share the same ruling variables and admit the same changes but occur at different points in time.\nAs mentioned earlier, considering arbitrary policies for action selection, one may devise different chains of events after the cause event A. Following each such policy incurs a different probability of event B\u2019s occurrence. In our setting, we examine if event A causes B under the most pessimistic version of such chains of events. In the HP setting, we have already seen that exogenous variables U provide the context under which the events occur. Therefore, we can also assume that exogenous variables in U along with providing initial condition P0 also define a fixed policy. So given a context,\n(u\u20d7 \u2208 R(U)) the values of A are sampled based on a chosen policy. This is another distinction we hold to HP formulation, instead of considering actions under a fixed policy, restricting the chain of events between A and B, we examine if event A causes B under the most pessimistic version of such chains of events. Remark that adhering to a certain chain of actions can be readily considered in our framework. In that case, the actions after event A will simply become part of the dynamics and no longer exogenous variables.\nIn all HP definitions, the endogenous variables are divided into two disjoint subsets Z\u20d7 and W\u20d7 . In these settings, the endogenous variables X\u20d7 defining a event (X\u20d7 = x\u20d7) are a subset of endogenous variables Z\u20d7 (i.e., X\u20d7 \u2282 Z\u20d7). Let\u2019s call the remaining endogenous variables of Z\u20d7, as Z\u20d7 \u2032 (Z\u20d7 - X\u20d7). Further, Z\u20d7 \u2032 is a set of endogenous variables that form a causal path between X\u20d7 = x\u20d7 and the effect event, Y\u20d7 = y\u20d7. Therefore, the complete set of endogenous variables V can be broken into 3 disjoint subsets - X ,W and Z \u2032. As discussed before, endogenous variables can be mapped to the state variables of the MDP model M , but only at a certain time instance. For the purposes of this discussion, let\u2019s consider X\u20d7 = x\u20d7 as event A and \u03c6 or Y\u20d7 = y\u20d7 as event B. Therefore in our setting, X\u20d7 can be mapped to state components of ruling variables of the event of interest A at time tA, i.e., SDA(tA). Similarly, Z\u20d7 \u2032 to SDZ\u2032 (tZ\u2032). Since Z\u20d7 \u2032 are endogenous variables that form a causal path between event X\u20d7 = x\u20d7 and the effect event, Y\u20d7 = y\u20d7, we can assume that time of occurrence of these events tZ\u2032 \u2265 tX . Further, W\u20d7 can be denoted by state variables SDW (tW ). Since these variables do not form a causal path between cause and effect events, we can assume without harm that tW \u2264 tX . Even if some events defined by W\u20d7 \u2032, where W\u20d7 \u2032 \u2282 W\u20d7 , take place at tW \u2032 > tX , since they are not a part of the causal path between cause and effect events, they can safely be ignored for the purposes of our discussion. Similar conclusions can be drawn for the event Y\u20d7 = y\u20d7, i.e, it is mapped to SDB (tB). Since the effect event can only happen after the cause event tB > tA.\nWith these associations between the HP formulation and our formulation, we can move ahead to analyze the conditions of causation."
        },
        {
            "heading": "C.5 COMPARE AND CONTRAST WITH HP DEFINITION",
            "text": "Given the current understanding of the HP definitions, let us now compare and contrast the modified HP definition of actual causation (Def. 4) with our definition of causation (Def.1). For the purposes of this discussion, let\u2019s consider X\u20d7 = x\u20d7 as event A and \u03c6 or Y\u20d7 = y\u20d7 as event B. Also, since the HP definitions do not explicitly consider time in the definition of events, for simplicity let\u2019s assume that variables X\u20d7 admit values x\u20d7 only once during the observation period. The same applies to Y\u20d7 = y\u20d7. From discussed mapping in C.4, X\u20d7 = x\u20d7 implies SDA , admits a certain change of values between [tA, t \u2032 A], say SDA(t \u2032 A) = x\u20d7 (implying that in this case, for simplicity, we consider that SDA(tA) admits some value of no consequential interest here). Similar logic can be applied to event B.\nOur Definition: In a stochastic process, we define event A to be a cause of event B if and only if:\nC1. Time-wise, conclusion of A happens at or before beginning of B;\nC2. Expected grit of B strictly increases from before to after A. Moreover, until B\u2019s occurrence, it never becomes the same or smaller than its value at A\u2019s beginning;\nC3. The contribution of A\u2019s ruling variables in the growth of B\u2019s expected grit is strictly positive and is strictly larger in magnitude than that of non-ruling variables with negative impact.\nCondition AC1 AC1 represents the trivial requirement that the candidate cause and effect are among the events that took place. Our condition C1. implicity covers HP condition AC1 (Def. 4), adding additional clarity of direction of causation with a time arrow between the events.\nCondition AC2(a) Condition AC2(a) states that for X\u20d7 = x\u20d7 to be a cause, in causal modelM with context u\u20d7 and witness W\u20d7 (u) = w\u20d7\u2217, Y\u20d7 \u0338= y\u20d7, if we set X\u20d7 = x\u20d7\u2032 (x\u20d7\u2032 \u2208 R(X\u20d7 ) is value X\u20d7 does not take under the context u\u20d7). Note that w\u20d7\u2217 is the value W\u20d7 takes under u\u20d7 in causal modelM. This implies that there exist contrast values x\u20d7\u2032 such that if X\u20d7 is set to x\u20d7\u2032, \u03c6 no longer holds. We further note that setting X\u20d7 = x\u20d7\u2032 also implies possible changes in values of Z\u20d7 that form a causal path between X\u20d7 and \u03c6, (Y\u20d7 = y\u20d7).\nMapping to our framework: Condition AC2(a) implies that event A can be a cause of event B if, for any other value of the ruling variables( X\u20d7 = x\u20d7\u2032) i.e, SDA(t) = x\u20d7\n\u2032 leads to non-occurance of event B, implying non-occurrence of event A. All this while holding events SDW (tW ) at the same values as they were when event B occurs, while SDZ\u2032 (tZ\u2032) can change in the subsequent time steps. Shortcomings: This condition suffers from some major problems: 1) In a continuous setting, x\u20d7\u2032 can take infinitely many values even within the range of R(X\u20d7 ). Further setting X\u20d7 = x\u20d7\u2032 (value not achievable under context u\u20d7) while holding W\u20d7 = w\u20d7\u2217 (value achieved under context u\u20d7) while symbolically meaningful, can be impossible to achieve in most if not all dynamical systems of practical importance (Cartwright, 2007). For example, in the T1 diabetes example discussed in the experiment section, if event A is a spike in blood glucose levels to 120, what would event NOT A be? blood glucose spike to 80? 90? 100? Further, it would be impossible to make interventions and set the blood glucose to the desired values to understand their effect. When interventions are frequent and can take continuous values, finding patients with similar statistics but different interventions - to act as counterfactuals, would be like finding a needle in a haystack. 2) More importantly, under this condition, it is implied that when a cause event does not happen, then the effect event does not happen as well. This enforces that, for an event to be a cause it should also be a necessary cause. This contradicts our understanding of causation where we argue that an event can contribute partially to the happening of the effect without being necessary or sufficient. Our framework argues that, while a cause can be a necessary cause, it does not have to be a necessary cause to qualify as a possible cause of event B.\nComparison: We argue that the intent of condition AC2(a) in Def.4 is to understand the effect of event A (X\u20d7 = x\u20d7 or SDA(tA) = x\u20d7) in isolation. This condition looks at the effect of the non-happening of event A (X\u20d7 = x\u20d7\u2032 or SDA(tA) = x\u20d7\n\u2032) on event B, while witness W\u20d7 are held under the values of context u\u20d7, i.e, when event B (Y\u20d7 = y\u20d7) occurs. Our conditions C2 and C3 address this issue without having to take an interventionist approach to causation. In our formulation, we can compute the contribution of each event (defined by a subset of the state/action components over a homogenous time interval) towards increasing the minimum probability of the event B happening. This helps us talk about the individual contribution of each event of interest without the need to hold SDW (tW ) at the value achieved under context u\u20d7 while admitting a different value at SDA(tA), which might be physically impossible to achieve.\nCondition AC2(b) The sufficiency condition, as discussed in condition AC2(b) of Modified HP (Def. 4) roughly speaking mentions that if the variables in X\u20d7 and an arbitrary subset O\u20d7 of other variables on the causal path are held at their values in the actual context u\u20d7) (i.e, X\u20d7(u) = x\u20d7 and O\u20d7(u) = o\u20d7\u2217), then \u03c6 holds even if any subset of W\u20d7 , Q\u20d7 is set to q\u20d7\u2217. Therefore, this condition implies that once event X\u20d7 = x\u20d7 happens, then no matter what values the events on the causal path between event X\u20d7 = x\u20d7 and event \u03c6, (Y\u20d7 = y\u20d7) take, event Y\u20d7 = y\u20d7 still happens.\nMapping to our framework: Event A can be a cause of event B if, no matter the values the non-ruling variables (action or state variables), affected by event A and present in the causal path between event A and event B take in the subsequent time steps, event B will still happen.\nShortcomings: Similar to the previous case, this condition enforces that, for an event to be a cause it should also be a sufficient cause. This again contradicts our understanding of causation where we argue that an event can contribute partially to the happening of the effect without being necessary or sufficient.\nComparisons Our framework argues that, while a cause can be a sufficient cause, it does not have to be a sufficient cause to qualify as a possible cause of event B.\nCondition AC3 AC3 is also fairly straightforward: we should not consider redundant elements to be parts of causes. Further, any possible redundancies in ruling variables can be examined and eliminated, because, their individual contributions to the growth of B\u2019s expected grit will be zero. Hence we can also satisfy condition AC3."
        },
        {
            "heading": "D EXPERIMENT 1: ATARI GAME OF PONG",
            "text": "Both our network architecture and the base pipeline have the same structure as the original DQN paper Mnih et al. (2015). In particular, there are 3 convolutional layers followed by 2 fully-connected linear layers. The first convolutional layer has 32 8 \u00d7 8 filters with stride 4, the second 64 4 \u00d7 4 filters with stride 2, and the third and final convolutional layer contains 64 3\u00d7 3 filters with stride 1. Then, the first linear layer has 512 inner nodes, and the next linear layer maps these to the number of actions. All layers except the last one are followed by ReLU nonlinearities (the last layer is just a linear layer). The state includes 4 consecutive frames, each of which is a downsized of the actual Atari screen into 84\u00d7 84 pixels and then switched into grayscale. Thus, the actual state is a tensor of size 4\u00d7 84\u00d7 84. Important point: The screens shown in the main paper\u2019s Fig. 1 illustrate the last frame of these four at each step.\nFor the optimizer, we used Pytorch\u2019s implementation of Adam optimizer with the Huber loss function, and the results are obtained after training over 200 epochs of 250,000 steps each (each action is repeated 4 times, hence each epoch involves one million Atari frames). All the hyper-parameters are chosen similarly to Mnih et al. (2015).\nIn the plots, \u2207\u0393(x) is colour-coded by red shades for \u2207\u0393(x) > 0, blue shades for \u2207\u0393(x) < 0 and white for zero, with darkest red for \u2207\u0393(x) \u2265 +1 and darkest blue for \u2207\u0393(x) \u2264 \u22121. Values with |\u2207\u0393(x)| < 0.1 are set to zero to denoise. The plots for g are similar but using 0.05 rather than 1 to magnify the presentation. Additionally, g plots only depict g \u2265 0; since, by definition, only a positive change of grit induces a cause.\nFull details can be found in the ./atari folder of the code, available at https://github. com/fatemi/dynamical-causality."
        },
        {
            "heading": "E EXPERIMENT 2: TYPE-1 DIABETES",
            "text": ""
        },
        {
            "heading": "E.1 SETUP AND DETAILS",
            "text": "We use an open-source implementation2 of the FDA-approved Type-1 Diabetes Mellitus Simulator (T1DMS) Kovatchev et al. (2009) for modeling the dynamics of Type-1 diabetes. In version is the very first release of the simulator and assumes inter-subject variability to be the same (parameters are sampled from a distribution with same covariance matrix) and does not model intra-day variability of patient parameters which they do in future iterations Man et al. (2014); Visentin et al. (2018).\nThe simulator models an insilicopatient\u2019s blood glucose level (BG) and 12 other body dynamics with real-valued elements representing glucose and insulin values in different compartments of the body. The glucose dynamics are captured by - plasma glucose, tissue glucose, glucose in stomach 1 (GS1), glucose in stomach 2 and gut. The insulin dynamics are captured by - insulin on glucose production, insulin on glucose utilization, insulin action on liver, plasma insulin, liver insulin, sub-cutaneous insulin-1 (SI) and sub-cutaneous insulin-2. We control two actions: 1) Insulin intake, to regulate the amount of insulin 2) Meal intake, to regulate the amount of carbohydrates.\nMeal intake increases the amount of glucose in the bloodstream, for T1D patients, when unregulated without external insulin, this can lead to hyperglycemia - generally characterized by blood glucose levels shooting over 180 mg/dL. Tight blood glucose control with insulin injections can help, but intensive control of blood glucose with insulin injections can increase the risk of hypoglycemia - generally characterized by blood glucose levels less than 70 mg/dL.\nFor our experiment, we study the event of hypoglycemia (BG < 70 mg/dL).\nInsulin Dosing and Intake: Insulin dosing in T1D will vary based on the patient\u2019s age, weight, and residual pancreatic insulin activity. T1D patients will typically require a total daily insulin dose of 0.4 - 1.0 units/kg/day. For example, if a patient weighs 80 kg, the total daily dose = 80 kg X (0.5 units/kg/d) = 40 units per day. Typically this insulin is split into basal and bolus insulin. Usually,\n2https://github.com/jxx123/simglucose\nbasal insulin is the insulin taken to keep the blood glucose in a steady state when there is no meal intake. It is generally regulated through an insulin pump. Bolus insulin on the other hand is taken through insulin injections to explicitly regulate the rise in glucose levels with meal intake. For the purpose of our simulation, we focus on bolus insulin intake only. We consider a constant intake of 0.027 units/min of basal insulin. For our experiment bolus insulin intake takes on values from Ains = {0, 3, 7, 15} units. We note that since this version of the simulator does not model the intra-day variability of the patient parameters, the patient reaction to a given action is not dependent on the time of the day, i.e, 3 units of insulin intake at noon and 3 units of insulin intake at 6 pm should have the same effect on patient dynamics. To generate realistic daily insulin scenarios, we use a random scenario generator. Each scenario is associated with the time of intake, amount of intake, and probability of intake. To make the daily insulin intake more realistic, we add some stochasticity to the time of insulin intake, by modeling it with a truncated normal distribution, TN(\u00b5, \u03c3, lb, ub) centered around time \u00b5 with \u03c3 variance, lb lower bound and ub upper bound. choosing different probabilities of consumption helps generate realistic scenarios of excessive insulin intake leading to hypoglycemia, or excessive meal intake in the absence of insulin leading to hyperglycemia. We design six possible intakes of insulin roughly capturing insulin intakes at breakfast, snack1, lunch, snack2, dinner, and snack3.\nTime Amount (in units) Probability of Consumption TN(3, 1, 1, 5) 7 {0.95, 1} TN(5.5, .5, 5, 6) 3 0.3 TN(8, 1, 6, 10) 15 1 TN(11, .5, 10, 12) 3 0.3 TN(14, 1, 12, 16) 15 1 TN(17.5, 1, 16, 19) 3 0.3\n(16)\nMeal Intake: In our simulation, meal intake can take 4 different possible values, Ameal = {0, 5, 30, 60} grams. Similar to insulin intake, to generate realistic daily meal consumption scenarios, we use a random scenario generator. Each scenario is associated with the time of intake, amount of intake, and probability of intake. To add some stochasticity to the time of meal intake, by modeling it with a truncated normal distribution, TN(\u00b5, \u03c3, lb, ub) centered around time \u00b5 with \u03c3 variance, lb lower bound and ub upper bound. We design six possible intakes of meals roughly capturing breakfast, snack1, lunch, snack2, dinner, and snack3.\nTime Amount (in grams) Probability of Consumption TN(3.5, 1, 1, 5) 30 {0.95, 0} TN(6, .5, 5, 6) 5 {0.3, 0.5} TN(8.5, 1, 6, 10) 60 {0.5, 0, 1} TN(11.5, .5, 10, 12) 5 0.3 TN(14.5, 1, 12, 16) 50 {0.5, 1} TN(18, 1, 16, 19) 5 0.95\n(17)\nWe map every combination of insulin and carbohydrate intake (each of which takes 4 distinct values) into 16 different possible actions. For the purpose of our experiment, we sample from a single patient trajectory (adult003) over 24 hours with a 1-minute sampling interval. We start from the same initial conditions because the system becomes chaotic for different perturbations in initial conditions.\nFor our study, we use Monte Carlo estimation to estimate V\u0393(X) and therefore \u0393B(X). Given the exploration policy of the off-line data we generate using the simulator is close to optimal, we can safely assume this gives us V \u2217\u0393 (X). We set \u03b3 = 1 with no positive rewards, i.e., r = \u22121 if BG < 70 and zero otherwise. We terminate the episode if we hit either hyperglycemia (BG>180), or hypoglycemia (BG<70) or we reach the end of 24 hours. We use Pytorch\u2019s autograd to compute the value function\u2019s gradient w.r.t. different body dynamics, based on which we could compute g-formula with M = 50 computational micro-steps to compute the integral. In our setting, we observe that intake of insulin causes an instantaneous spike in dynamics of subcutaneous insulin 1 (SI1), while intake of carbohydrates causes an instantaneous spike in glucose in stomach 1 (GS1). Since the previous action is considered a part of the current state to keep the system Markovian, the spike in subcutaneous insulin just acts as a proxy for action insulin, similarly for action meal and GS1.\nWe use a simple deep network with 3 fully connected layers with GELU (Gaussian error linear unit) activation. In particular, we have 13\u00d7 30, 30\u00d7 30, and 30\u00d7 1 fully connected layers. The actual state is a tensor of 13 \u00d7 1. Since the signals have very different ranges, we normalize them (with population mean and standard deviation) before passing them through the network.\nWe use a learning rate of 0.00001 and minibatch size of 128. In each minibatch, we select 64 transitions by sampling from a prioritized experience replay (PER) butter Schaul et al. (2015). For the remaining 64 samples, we choose 32 samples uniformly from the train data and append it with 6 uniformly selected event B, hypoglycemia transitions (r = \u22121 and terminal state = True), 2 uniformly selected hyperglycemia transitions (r = 0 and terminal state = True), and remaining samples are sampled from non-zero action samples. All other chosen hyper-parameters can be found in the config.yaml file in the root directory of our code."
        },
        {
            "heading": "E.2 SYSTEM DYNAMICS MODEL",
            "text": "We use the ODE\u2019s provided by Kovatchev et al. (2009) to generate the signals. We notice that some of these are different from the ones provided in the open-source implementation repository simglucose and make the changes accordingly in our implementation."
        },
        {
            "heading": "E.2.1 THE ORAL GLUCOSE SUBSYSTEM THAT CONTROLS RATE OF GLUCOSE APPEARANCE",
            "text": "Stomach compartment 1\nx1(t) = Q\u0307sto1(t) = \u2212kmax \u00b7Qsto1(t) +D D = CHO - carbohydrate intake from meal consumption\n(18)\nStomach compartment 2\nx2(t) = Q\u0307sto2(t) = \u2212kgut (Qsto) \u00b7Qsto2(t) + kmax \u00b7Qsto1(t) (19)\nGut x3(t) = Q\u0307gut(t) = \u2212kabs \u00b7Qgut(t) + kgut (Qsto) (20)\nQsto(t) = Qsto1(t) +Qsto2(t) (21)\nGlucose rate of appearance\nRa(t) = f \u00b7 kabs \u00b7Qgut(t)\nBW (22)"
        },
        {
            "heading": "E.2.2 GLUCOSE SUBSYSTEM - GLUCOSE KINETICS",
            "text": "Plasma Glucose\nx4(t) = G\u0307p(t) = max(EGP (t), 0) +Ra(t)\u2212 Uii(t)\u2212 E(t)\u2212 k1 \u00b7Gp(t) + k2 \u00b7Gt(t) (23)\nTissue Glucose x5(t) = G\u0307t(t) = \u2212Uid(t) + k1 \u00b7Gp(t)\u2212 k2 \u00b7Gt(t) (24)\nSubcutaneous Glucose\nx13(t) = G\u0307s(t) = \u2212 1\nTs \u00b7Gs(t) +\n1\nTs \u00b7Gp(t)\nG\u0307s(t) = (Gs(t) \u2265 0)(G\u0307s(t)) G(t) = Gp(t)/VG\n(25)\nEndogenous glucose production EGP (t) = kp1 \u2212 kp2 \u00b7Gp(t)\u2212 kp3 \u00b7XL(t)\nInsulin independent utilization Uii(t) = Fcns\nInsulin dependent utilization\nUid(t) = (Vm0 + Vmx \u00b7X(t)) \u00b7Gt(t)\nKm0 +Gt(t)\n(26)\nE.2.3 INSULIN KINETICS\nPlasma Insulin\nx6(t) = I\u0307p(t) = \u2212 (m2 +m4) \u00b7 Ip(t) +m1 \u00b7 Il(t) + ka1 \u00b7 Isc1(t) + ka2 \u00b7 Isc2(t) (27)\nInsulin action on glucose utilization\nx7(t) = X\u0307(t) = \u2212p2U \u00b7X(t) + p2U (I(t)\u2212 Ib) (28)\nDelayed insulin action in the liver\nx8(t) = X\u0307L(t) = \u2212ki \u00b7 (XL(t)\u2212 I(t)) (29)\nInsulin action on glucose production\nI(t) = Ip(t)\nVI x9(t) = \u02d9\u0303I(t) = \u2212ki \u00b7 (I\u0303(t)\u2212 I(t)) (30)\nLiver insulin x10(t) = I\u0307l(t) = \u2212 (m1 +m3) \u00b7 Il(t) +m2 \u00b7 Ip(t) (31)\nSubcutaneous insulin 1\nx11(t) = I\u0307sc1(t) = \u2212 (kd + ka1) \u00b7 Isc1(t) + Insulin(t) (32)\nSubcutaneous insulin 2\nx12(t) = I\u0307sc2(t) = kd \u00b7 Isc1(t)\u2212 ka2 \u00b7 Isc2(t) (33)"
        }
    ],
    "year": 2024
}