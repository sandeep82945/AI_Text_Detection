{
    "abstractText": "With the widespread adoption of machine learning systems, the need to curtail their behavior has become increasingly apparent. This is evidenced by recent advancements towards developing models that satisfy robustness, safety and fairness requirements. Imposing these requirements leads to constrained learning problems, which can be tackled with dual ascent methods. However, convergence guarantees for dual ascent algorithms typically involve a randomized or averaged sequence of primal iterates. These solutions are impractical, since they require storing an ever growing sequence of models. Although it has been observed that final iterates perform well in practice, theoretical guarantees for their optimality and feasibility have remained elusive. In this work, we characterize the infeasibility of Lagrangian minimizers associated with optimal dual variables, which leads to a sub-optimality bound for best primal iterates. To do this, we leverage the fact that constrained learning problems are parametrized versions of convex functional programs. This bound sheds light on how the richness of the parametrization and the curvature of the objective impact the convergence of primal iterates. We empirically validate this finding in learning problems with fairness constraints.",
    "authors": [],
    "id": "SP:6bcb0d2f1b045357fbba4070e815823042493283",
    "references": [
        {
            "authors": [
                "Alekh Agarwal",
                "Alina Beygelzimer",
                "Miroslav Dud\u0131\u0301k",
                "John Langford",
                "Hanna Wallach"
            ],
            "title": "A reductions approach to fair classification",
            "venue": "In International conference on machine learning,",
            "year": 2018
        },
        {
            "authors": [
                "Tamer Ba\u015far",
                "Pierre Bernhard"
            ],
            "title": "H-infinity optimal control and related minimax design problems: a dynamic game approach",
            "venue": "Springer Science & Business Media,",
            "year": 2008
        },
        {
            "authors": [
                "Alain Berlinet",
                "Christine Thomas-Agnan"
            ],
            "title": "Reproducing kernel Hilbert spaces in probability and statistics",
            "venue": "Springer Science & Business Media,",
            "year": 2011
        },
        {
            "authors": [
                "J. Fr\u00e9d\u00e9ric Bonnans",
                "Alexander Shapiro"
            ],
            "title": "Optimization problems with perturbations: A guided tour",
            "venue": "SIAM Review,",
            "year": 1998
        },
        {
            "authors": [
                "Luiz Chamon",
                "Alejandro Ribeiro"
            ],
            "title": "Probably approximately correct constrained learning",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Luiz F.O. Chamon",
                "Santiago Paternain",
                "Miguel Calvo-Fullana",
                "Alejandro Ribeiro"
            ],
            "title": "Constrained learning with non-convex losses",
            "venue": "IEEE Transactions on Information Theory,",
            "year": 2023
        },
        {
            "authors": [
                "Andrew Cotter",
                "Maya R. Gupta",
                "Heinrich Jiang",
                "Nathan Srebro",
                "Karthik Sridharan",
                "Serena Lutong Wang",
                "Blake E. Woodworth",
                "Seungil You"
            ],
            "title": "Training well-generalizing classifiers for fairness metrics and other data-dependent constraints",
            "venue": "In International Conference on Machine Learning,",
            "year": 2018
        },
        {
            "authors": [
                "Andrew Cotter",
                "Heinrich Jiang",
                "Taman Narayan",
                "Seungil You",
                "Karthik Sridharan"
            ],
            "title": "Optimization with non-differentiable constraints with applications to fairness, recall, churn, and other goals",
            "venue": "J. Mach. Learn. Res.,",
            "year": 2019
        },
        {
            "authors": [
                "Constantinos Daskalakis",
                "Stratis Skoulakis",
                "Manolis Zampetakis"
            ],
            "title": "The complexity of constrained min-max optimization",
            "venue": "In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing,",
            "year": 2021
        },
        {
            "authors": [
                "Juan Elenter",
                "Navid NaderiAlizadeh",
                "Alejandro Ribeiro"
            ],
            "title": "A lagrangian duality approach to active learning, 2022",
            "year": 2022
        },
        {
            "authors": [
                "Matthew M. Engelhard",
                "Ricardo Henao",
                "Samuel I. Berchuck",
                "Junya Chen",
                "Brian Eichner",
                "Darby Herkert",
                "Scott H. Kollins",
                "Andrew Olson",
                "Eliana M. Perrin",
                "Ursula Rogers",
                "Connor Sullivan",
                "YiQin Zhu",
                "Guillermo Sapiro",
                "Geraldine Dawson"
            ],
            "title": "Predictive Value of Early Autism Detection Models Based on Electronic Health Record Data Collected Before Age 1 Year",
            "venue": "JAMA Network Open, 6(2):e2254303\u2013e2254303,",
            "year": 2023
        },
        {
            "authors": [
                "Ferdinando Fioretto",
                "Pascal Van Hentenryck",
                "Terrence W.K. Mak",
                "Cuong Tran",
                "Federico Baldo",
                "Michele Lombardi"
            ],
            "title": "Lagrangian duality for constrained deep learning",
            "venue": "Applied Data Science and Demo Track,",
            "year": 2021
        },
        {
            "authors": [
                "Rafal Goebel",
                "R Tyrrell Rockafellar"
            ],
            "title": "Local strong convexity and local lipschitz continuity of the gradient of convex functions",
            "venue": "Journal of Convex Analysis,",
            "year": 2008
        },
        {
            "authors": [
                "Gabriel Goh",
                "Andrew Cotter",
                "Maya Gupta",
                "Michael P Friedlander"
            ],
            "title": "Satisfying real-world goals with dataset constraints",
            "venue": "Advances in neural information processing systems,",
            "year": 2016
        },
        {
            "authors": [
                "Vincent Guigues"
            ],
            "title": "Inexact stochastic mirror descent for two-stage nonlinear stochastic programs, 2020",
            "year": 2020
        },
        {
            "authors": [
                "Kurt Hornik"
            ],
            "title": "Approximation capabilities of multilayer feedforward networks",
            "venue": "Neural networks,",
            "year": 1991
        },
        {
            "authors": [
                "Ignacio Hounie",
                "Luiz F.O. Chamon",
                "Alejandro Ribeiro"
            ],
            "title": "Automatic data augmentation via invariance-constrained learning, 2022",
            "year": 2022
        },
        {
            "authors": [
                "Sham Kakade",
                "Shai Shalev-Shwartz",
                "Ambuj Tewari"
            ],
            "title": "On the duality of strong convexity and strong smoothness: Learning applications and matrix regularization",
            "venue": "Unpublished Manuscript, http://ttic. uchicago. edu/shai/papers/KakadeShalevTewari09. pdf,",
            "year": 2009
        },
        {
            "authors": [
                "Michael Kearns",
                "Seth Neel",
                "Aaron Roth",
                "Zhiwei Steven Wu"
            ],
            "title": "Preventing fairness gerrymandering: Auditing and learning for subgroup fairness",
            "venue": "In International conference on machine learning,",
            "year": 2018
        },
        {
            "authors": [
                "B Ravi Kiran",
                "Ibrahim Sobh",
                "Victor Talpaert",
                "Patrick Mannion",
                "Ahmad A Al Sallab",
                "Senthil Yogamani",
                "Patrick P\u00e9rez"
            ],
            "title": "Deep reinforcement learning for autonomous driving: A survey",
            "venue": "IEEE Transactions on Intelligent Transportation Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Andrew J Kurdila",
                "Michael Zabarankin"
            ],
            "title": "Convex functional analysis",
            "venue": "Springer Science & Business Media,",
            "year": 2006
        },
        {
            "authors": [
                "Angelia Nedi\u0107",
                "Asuman Ozdaglar"
            ],
            "title": "Approximate primal solutions and rate analysis for dual subgradient methods",
            "venue": "SIAM Journal on Optimization,",
            "year": 2009
        },
        {
            "authors": [
                "Alejandro Ribeiro"
            ],
            "title": "Ergodic stochastic optimization algorithms for wireless communication and networking",
            "venue": "IEEE Transactions on Signal Processing,",
            "year": 2010
        },
        {
            "authors": [
                "Alexander Robey",
                "Luiz Chamon",
                "George J. Pappas",
                "Hamed Hassani",
                "Alejandro Ribeiro"
            ],
            "title": "Adversarial robustness with semi-infinite constrained learning",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "R Tyrrell Rockafellar"
            ],
            "title": "Conjugate duality and optimization",
            "year": 1974
        },
        {
            "authors": [
                "Zebang Shen",
                "Juan Cervino",
                "Hamed Hassani",
                "Alejandro Ribeiro"
            ],
            "title": "An agnostic approach to federated learning with class imbalance",
            "venue": "In International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "N.Z. Shor"
            ],
            "title": "Nondifferentiable Optimization and Polynomial Problems. Nonconvex Optimization and Its Applications",
            "venue": "URL https://books. google.com/books?id=_L_VBwAAQBAJ",
            "year": 2013
        },
        {
            "authors": [
                "Victor Solo",
                "Xuan Kong"
            ],
            "title": "Adaptive signal processing algorithms: Stability and performance",
            "year": 1994
        },
        {
            "authors": [
                "Cuong Tran",
                "Ferdinando Fioretto",
                "Pascal Van Hentenryck"
            ],
            "title": "Differentially private and fair deep learning: A lagrangian dual approach",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "V.N. Vapnik"
            ],
            "title": "An overview of statistical learning theory",
            "venue": "IEEE Transactions on Neural Networks,",
            "year": 1999
        },
        {
            "authors": [
                "Alexandre Velloso",
                "Pascal Van Hentenryck"
            ],
            "title": "Combining deep learning and optimization for security-constrained optimal power flow",
            "venue": "arXiv preprint arXiv:2007.07002,",
            "year": 2020
        },
        {
            "authors": [
                "Lemma A"
            ],
            "title": "Let h be a closed convex function defined on a subset of the vector space X ; h is \u03bc\u2212strongly convex if and only if h\u2020 has \u03bc\u2212Lipschitz continuous gradients",
            "year": 2008
        },
        {
            "authors": [
                "function P"
            ],
            "title": "\u03b5) is lower semi continuous at 0 (see (Bonnans",
            "venue": "Note that P\u0303 (\u03b5) = P \u2217(\u03b5+ \u03b5). Thus, P (\u03b5)",
            "year": 1998
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Machine learning (ML) has become a core technology of information systems, reaching critical applications from medical diagnostics (Engelhard et al., 2023) to autonomous driving (Kiran et al., 2021). Consequently, it has become paramount to develop ML models that not only excel at a main task, but also adhere to requirements such as fairness and robustness.\nSince virtually all ML models are trained using Empirical Risk Minimization (ERM) (Vapnik, 1999), a natural way to impose requirements is to explicitly add constraints to these optimization problems (Fioretto et al., 2021; Velloso & Van Hentenryck, 2020; Cotter et al., 2018; Chamon et al., 2023). Recent works (Chamon & Ribeiro, 2020) have shown that from a PAC (Probably Approximately Correct) perspective, learning under requirements is essentially as hard as classical learning and that it can be done by means of dual ascent methods, which only involve solving a sequence of regularized, unconstrained ERM problems. This gave rise to applications across several areas such as federated learning (Shen et al., 2022), fairness (Cotter et al., 2019; Tran et al., 2021), active learning (Elenter et al., 2022), adversarial robustness (Robey et al., 2021) and data augmentation (Hounie et al., 2022).\nDespite these statistical guarantees, duality-based algorithms suffer from a severe limitation in terms of recovering feasible solutions. Indeed, dual ascent iterates need not remain in the feasibility set or converge to a fixed point, displaying ciclostationary behaviour. For convex problems, this issue can be tackled using averaging (Nedic\u0301 & Ozdaglar, 2009). In contrast, the non-convex case requires randomization (Kearns et al., 2018; Agarwal et al., 2018; Goh et al., 2016). These solutions are not only impractical, given the need to store an ever-growing sequence of primal iterates, but also raise ethical considerations. For instance, when selecting job candidates, giving medical diagnosis or deciding whether to give bank loans, randomizing over various predictors could be undesirable from an explainability standpoint.\nIn fact, this problem is even hard from an algorithmic complexity point of view (Daskalakis et al., 2021). While it has been observed that taking the last or best iterate, can perform well in practice (Cotter et al., 2018; Chamon et al., 2023; Robey et al., 2021; Elenter et al., 2022; Hounie et al., 2022;\nShen et al., 2022), these predictors can also fail miserably, severely violating the requirements that are being imposed.\nThis work adresses this gap between theory and practice by characterizing the infeasibility of primal iterates associated with optimal dual variables. To do so, we observe that many optimization problems can be seen as parametrized versions of very benign functional optimization problems. We show that for sufficiently rich parametrizations, duality-based solutions are able to closely approximate the feasibilibility of these functional solutions. This implies that dual ascent methods can yield solutions with guaranteed near-feasibility without randomization and despite non-convexity."
        },
        {
            "heading": "2 PROBLEM FORMULATION",
            "text": ""
        },
        {
            "heading": "2.1 CONSTRAINED LEARNING",
            "text": "Constrained learning can be formulated as a statistical optimization problem, namely,\nP \u22c6p =min \u03b8\u2208\u0398 \u21130(f\u03b8)\ns. to: \u2113i(f\u03b8) \u2264 0, i = 1, ..,m (Pp)\nwhere f\u03b8 : X \u2192 Y is a function associated with the parameter vector \u03b8 \u2208 \u0398 \u2286 Rp and the hypothesis class F\u03b8 = {f\u03b8 : \u03b8 \u2208 \u0398} induced by these functions is a subset of a compact functional space F \u2286 L2(\u2126). The use of the subscript p, for \u201dparametrized\u201d, will later become evident. The functionals \u2113i : F \u2192 R denote expected risks: E(x,y)[\u2113\u0303i(f\u03b8(x), y)], where \u2113\u0303i is typically a loss function such as mean squared error or cross entropy loss. In this setting, \u21130 can be interpreted as a top-line metric (e.g., accuracy), while the functional \u2113 = (\u21131(f\u03b8), \u00b7 \u00b7 \u00b7 , \u2113m(f\u03b8)) encodes the statistical requirements that the solution must satisfy (see example below). It is important to note that the functionals \u2113i are typically non-convex with respect to \u03b8.\nLearning under Counterfactual Fairness Constraints. In ProPublica\u2019s COMPAS dataset, the goal is to predict recidivism based on an individual\u2019s past offense data while controlling for gender and racial bias. Let \u2113\u03030 denote the negative log-likelihood function: \u2212 log[f\u03b8(x)]y . The problem of learning a predictor insensitive to perturbations of these protected variables can be formulated as an invariance constrained learning problem:\nP \u2217p = min \u03b8\u2208Rp\nE [ \u2113\u03030 (f\u03b8(x), y) ] s. to: E(x,y) [DKL(f\u03b8(x, z)||f\u03b8(x, \u03c1i(z))] \u2264 c, for all i\nwhere z contains the protected variables (gender and race), c > 0 determines the sensitivity level and the transformations \u03c1i encompass all possible single variable modifications of z. This constrained optimization problem is non-convex for many parametrizations (e.g., neural networks) and there is typically no straightforward way to project onto the feasibility set (i.e. the set of classifiers insensitive to gender and race). In light of these challenges, we turn to Lagrangian Duality."
        },
        {
            "heading": "2.2 DUAL CONSTRAINED LEARNING",
            "text": "The Lagrangian L : F \u00d7 Rm \u2192 R is defined as:\nL(\u03d5, \u03bb) = \u21130(\u03d5) + \u03bb T \u2113(\u03d5), (1)\nwith \u03d5 \u2208 F and \u03bb \u2208 Rm+ . For reasons that will become apparent later we define L over F rather than F\u03b8. For a fixed dual variable \u03bb, the Lagrangian L(\u03d5, \u03bb) is a regularized objective, where \u2113 acts as a regularizing functional. This leads to the dual function of problem Pp:\ngp(\u03bbp) = min \u03b8\u2208\u0398 L(f\u03b8, \u03bbp), (2)\nand to the definition of the dual problem,\nD\u22c6p = max \u03bbp\u2ab00 gp(\u03bbp). (Dp)\nAlgorithm 1 Dual Constrained Learning 1: Inputs: number of iterations T \u2208 N, step size \u03b7 > 0. 2: Initialize: \u03bb(1) = 0 3: for t = 1, . . . , T do 4: Obtain f\u03b8(t) such that\nf\u03b8(t) \u2208 argmin \u03b8\u2208\u0398 \u21130(f\u03b8) + \u03bb(t) T \u2113(f\u03b8)\n5: Update dual variables\n\u03bbi(t+ 1) = max[0, \u03bbi(t) + \u03b7 \u2113i(f\u03b8(t))]\n6: end for\nThis saddle-point problem can be viewed as a two-player game or as a regularized minimization, where the regularization weight is also an optimization variable, updated according to the degree of constraint satisfaction or violation.\nThe dual function gp is concave, irrespective of whether Pp is convex. Indeed, it is the pointwise minimum of a family of affine functions on \u03bb. As such, though gp may not be differentiable, it can be equipped with supergradients, that may be used to determine ascent directions. Explicitly, a vector s \u2208 Rm is a supergradient of the concave function h : Rm \u2192 R at a point x if h(z)\u2212h(x) \u2265 sT (z\u2212x) for all z. The set of all supergradients of h at x is called the superdifferential and is denoted \u2202h(x). When the losses \u2113i are continuous, the superdifferential of gp admits a simple description, namely:\n\u2202gp(\u03bbp) = conv{\u2113(f\u03b8(\u03bbp)) : f\u03b8(\u03bbp) \u2208 F\u22c6\u03b8 (\u03bbp)}.\nwhere conv(S) denotes the convex hull of the set S and F\u22c6\u03b8 (\u03bbp) denotes the set of Lagrangian minimizers f\u03b8(\u03bbp) associated to the multiplier \u03bbp:\nF\u22c6\u03b8 (\u03bbp) = argmin \u03b8\u2208\u0398 L(f\u03b8, \u03bbp). (3)\nWe can then proceed to obtain an algorithm for solving Dp, updating dual variables in the ascent direction indicated by a supergradient \u2113(f\u03b8(\u03bbp)) and projecting the resulting iterates into the nonnegative orthant. This procedure, referred to as projected supergradient ascent (Polyak, 1987), is presented in Algorithm 1.\nObserve that as dual iterates \u03bbp(t) approach the set \u039b\u22c6p = argmax\u03bbp\u2ab00 gp(\u03bbp) of solutions of Dp, a sequence of primal iterates {f\u03b8(t) \u2208 F\u22c6\u03b8 (\u03bbp(t))}Tt=1 is obtained as a by-product. In general, however, the Lagrangian minimizers are not unique. In particular, for an optimal dual variable \u03bb\u22c6p \u2208 \u039b\u22c6p, the set F\u22c6\u03b8 (\u03bb\u22c6p) is typically not a singleton and could contain infeasible elements (i.e, \u2113i(f\u03b8(\u03bb \u22c6 p)) > 0 for some i \u2265 1). Even more so, as \u03bbp(t) approaches \u039b\u22c6p, the constraint satisfaction of primal iterates can exhibit pathological cyclostationary behaviour, where one or more constraints oscillate between feasibility and infeasibility. The experiment in Figure 1 showcases this behaviour and illustrates that, in general, one can not simply stop the dual ascent algorithm at an iteration t and expect the primal iterate f\u03b8(\u03bbp(t)) to be feasible. This is why, in these type of non-convex problems, guarantees usually pertain a probability distribution over (a subset of) the sequence {f\u03b8(t)}Tt=1 (see e.g, (Agarwal et al., 2018) Theorem 2, (Kearns et al., 2018) Theorem 4.1, (Cotter et al., 2019) Theorem 2, (Chamon et al., 2023))."
        },
        {
            "heading": "3 NEAR-OPTIMAL SOLUTIONS OF CONSTRAINED LEARNING PROBLEMS",
            "text": "Final primal iterates obtained as a by-product of dual ascent methods can fail at solving problem Pp. However, constrained learning problems arise as parametrized versions of very benign convex functional programs, which are ammenable to a Lagrangian relaxation."
        },
        {
            "heading": "3.1 THE UNPARAMETRIZED PROBLEM",
            "text": "The unparametrized constrained learning problem is defined as:\nP \u22c6u = min \u03d5\u2208F \u21130(\u03d5)\ns.to : \u2113i(\u03d5) \u2264 0 i = 1, ..,m (Pu)\nwhere F is a convex, compact subset of an L2(\u2126) space, \u2126 being a Lebesgue measurable subset of Rd. For instance, F can be the space of continuous functions or a reproducing kernel Hilbert space (RKHS) and F\u03b8 can be a neural network or a finite linear combinations of kernels, both of which meet the uniform approximation assumption (Hornik, 1991; Berlinet & Thomas-Agnan, 2011). Analogously to the definitions presented in section 2.1, gu(\u03bbu) := min\u03d5\u2208F L(\u03d5, \u03bbu) denotes the unparametrized dual function, \u03a6\u22c6(\u03bbu) = argmin\u03d5\u2208F L(\u03d5, \u03bbu) denotes the set of unparametrized Lagrangian minimizers associated with \u03bbu and\nD\u22c6u = max \u03bbu\u2ab00 gu(\u03bbu) (Du)\nis the unparametrized dual problem. We now present two assumptions that allow us to characterize the relation between the dual and primal solutions of problem Du.\nAssumption 3.1 The functionals \u2113i , i = 0, . . . ,m, are convex and M\u2212Lipschitz continuous in F . Additionally, \u21130 is \u00b50\u2212strongly convex.\nAssumption 3.2 There exists \u03d5 \u2208 F such that \u2113(\u03d5) \u227a min[0, \u2113(\u03d5(\u03bb\u22c6p)), \u2113(f\u03b8(\u03bb\u22c6p))], where the minimum is taken coordinate-wise.\nNote that we require convexity of the objective with respect to the functionals, but not model parameters, which holds for both mean squared error and cross-entropy loss. Assumption 3.2 is a stronger version of Slater\u2019s constraint qualification, since it requires strict feasibility in a set of perturbed versions of the unparametrized problem. It will later allow us to analyze the variations of the optimal value P \u22c6u as a function of the constraint tightness.\nAs will be explained in section 3.3, under these assumptions, the unparametrized Lagrangian minimizer is unique. This makes the superdifferential of the dual function a singleton at every \u03bbu: \u2202gu(\u03bbu) = {\u2113(\u03d5(\u03bbu))}, which means that the dual function gu(\u03bbu) is differentiable. Let \u03d5\u22c6 be a solution of problem Pu. Assumptions 3.1 and 3.2 imply that strong duality (i.e, P \u2217u = D \u22c6 u) holds in this problem, and that at \u03bb\u22c6u, there is a unique Lagrangian minimizer \u03d5 \u22c6(\u03bb\u22c6u) = \u03d5\n\u22c6 which is, by definition, feasible.\nNote that the only difference between problems Pp and Pu is the nature of the set over which the optimization is carried out. Thus, if the parametrization \u0398 is rich (e.g, deep neural networks), the set F\u03b8 is close to F , and we can expect the properties of the solutions to problems Dp and Du to be similar. This insight leads us to the \u03bd\u2212near universality of the parametrization assumption.\nAssumption 3.3 For all \u03d5 \u2208 F , there exists \u03b8 \u2208 \u0398 such that \u2225\u03d5\u2212 f\u03b8\u2225L2 \u2264 \u03bd.\nGiven the properties of the problems presented, it is legitimate to ask: how close are f\u03b8(\u03bb\u22c6p) and \u03d5 \u22c6 in terms of their constraint satisfaction ? Should a tight bound exist, then averaging and randomization would not be necessary."
        },
        {
            "heading": "3.2 FEASIBILITY APPROXIMATION",
            "text": "We will characterize the constraint violation of the Lagrangian minimizers f\u03b8(\u03bb\u22c6p) \u2208 F\u03b8(\u03bb\u22c6p) by comparing these primal variables with the solution of the unparametrized problem: \u03d5\u22c6. Since the problem is feasible, \u2113(\u03d5\u22c6) is non-positive and, due to complementary slackness, it is a null vector when all constraints are active.\nThe curvature of the unparametrtized dual function gu(\u03bbu) around the optimum is central in this analysis. We will first provide a result assuming this curvature is known, and will later describe its connection to the properties of Problem Pp. Let B\u03bb := {\u03b3\u03bb\u22c6u + (1\u2212 \u03b3)\u03bb\u22c6p : \u03b3 \u2208 [0, 1]} denote the segment connecting \u03bb\u22c6u and \u03bb \u22c6 p.\nAssumption 3.4 The dual function gu is \u00b5g\u2212strongly concave on B\u03bb and \u03b2g\u2212smooth.\nWe now state the main result of this section, characterizing the constraint satisfaction of any Lagrangian minimizer of the constrained learning problem at an optimal dual variable \u03bb\u22c6p \u2208 \u039b\u22c6p with respect to that of the optimal, feasible solution of the unparametrized problem.\nTheorem 3.5 Under assumptions 3.1-3.4, for any f\u03b8(\u03bb\u22c6p) \u2208 F\u22c6\u03b8 (\u03bb\u22c6p), the distance between the unparametrized and parametrized constraint violations is bounded by:\n\u2225\u2113(f\u03b8(\u03bb\u22c6p))\u2212 \u2113(\u03d5\u22c6)\u222522 \u2264 2\u03b2gM\u03bd(1 + \u2225\u03bb\u22c6p\u22251) ( 1 + \u221a \u03b2g \u00b5g )2\nThe ratio \u03b2g\u00b5g , which corresponds to the condition number of the Hessian of gu(\u03bb), can be used to determine optimal step sizes in dual ascent methods (Polyak, 1987), and plays a crucial role in this bound. As will be shown in Section 3.3 if the dual function is steeply curved (i.e, \u00b5g is large) then \u03bb\u22c6p and \u03bb \u22c6 u are not too far apart. However, as \u00b5g increases so does \u03b2g , which increases the sensitivity of the optimum P \u2217u with respect to constraint perturbations and loosens the bound.\nThe constant \u03bd indicates how rich the parametrization is in terms of approximating the functions of F . Thus, it is reasonable that as the model capacity increases and \u03bd goes to 0, the distance between constraint violations decreases. In the extreme, if all functions in F can be exactly approximated by an element of F\u03b8 (\u03bd = 0), the problems Pp and Pu are equivalent and trivially \u03d5\u22c6 = f\u03b8(\u03bb\u22c6p). To better understand how the properties of problem Pp impact the feasibility approximation bound in Theorem 3.5, we now the relate the curvature of gu(\u03bbu) to the properties of the losses \u2113i.\nAssumption 3.6 The functionals \u2113i , i = 0, . . . ,m are \u03b2-smooth in F .\nAssumption 3.7 The Jacobian D\u03d5\u2113(\u03d5\u22c6) is full-row rank at the optimum, i.e: \u2203\u03c3 > 0 such that inf\u2225\u03bb\u2225=1 \u2225\u03bbTD\u03d5\u2113(\u03d5\u22c6)\u2225L2 \u2265 \u03c3, where D\u03d5\u2113(\u03d5\u22c6) denotes the Frechet derivative of the functional \u2113 at \u03d5\u22c6 (see Appendix A.1).\nAssumption 3.7, which lower-bounds the singular values of the constraint Jacobian, is customary in constrained optimization and is related to the Linear independence constraint qualification (LICQ).\nLemma 3.8 Under assumptions 3.1, 3.2, 3.6 and 3.7, the unparametrized dual function gu(\u03bbu) is \u00b5g\u2212strongly concave on B\u03bb and \u03b2g\u2212smooth with:\n\u00b5g = \u00b50 \u03c3\n2\n\u03b22(1 + \u2206)2 , \u03b2g =\n\u221a mM2\n\u00b50 (4)\nwhere \u2206 = max{\u2225\u03bb\u22c6u\u22251, \u2225\u03bb\u22c6p\u22251}.\nFrom Lemma 3.8, we have that \u03b2g\u00b5g = \u221a mM 2 \u03c32 \u03b22 \u00b520 (1 + \u2206)2. Therefore, the condition numbers \u03ba1 = M \u03c3 and \u03ba2 = \u03b2 \u00b50\nof the constraint Jacobian and the objective\u2019s Hessian impact how far the constraint violations of f\u03b8(\u03bb\u22c6p) are to that of \u03d5\n\u22c6. Combining this with Theorem 3.5, we obtain the following infinity norm bound:\nCorollary 3.9 Under assumptions 3.1, 3.2, 3.3, 3.6 and 3.7, the maximum distance between the parametrized and unparametrized contraints violations is characterized by:\n\u2225\u2113(f\u03b8(\u03bb\u22c6p))\u2212 \u2113(\u03d5\u22c6)\u2225\u221e \u2264 M [1 + \u03ba1\u03ba2(1 + \u2206)] \u221a 2m M\u03bd\n\u00b50 (1 + \u2225\u03bb\u22c6p\u22251) (5)\nwith \u03ba1 = M\u03c3 , \u03ba2 = \u03b2 \u00b50 and \u2206 = max{\u2225\u03bb\u22c6u\u22251, \u2225\u03bb\u22c6p\u22251}.\nThis bound can be split into three main components. The condition numbers \u03ba1 = M\u03c3 and \u03ba2 = \u03b2 \u00b50 of the constraint Jacobian and the objective\u2019s Hessian are present in the term [1 + \u03ba1\u03ba2(1 + \u2206)]. Thus, it can be thought of as the baseline effect, capturing how well-conditioned the problem is. Furthermore, the term \u221a 2mM\u03bd\u00b50 (1 + \u2225\u03bb\u22c6p\u22251) contains the approximation error in PACC learning ( see (Chamon & Ribeiro, 2020), Theorem 2). Although the number of constraints m naturally appears in this bound, it can be integrated into the term M if one makes the stronger assumption that \u2113 is M\u2212Lipschitz, as opposed to assuming this of each individual \u2113i."
        },
        {
            "heading": "3.3 DUAL VARIABLE AND HYPOTHESIS CLASS PERTURBATIONS",
            "text": "In this section, we give an outline on the results that build up to Theorem 3.5. We will focus on the properties that shed light on the nature of the Lagrangian minimizers f\u03b8(\u03bb\u22c6p) \u2208 F\u22c6\u03b8 (\u03bb\u22c6p). For clarity, we will sometimes write \u03d5\u22c6 as \u03d5(\u03bb\u22c6u) to emphasize the dependence on \u03bb \u22c6 u. We start by decomposing the distance between parametrized and unparametrized contraints violations using a triangle inequality:\n\u2225\u2113(f\u03b8(\u03bb\u22c6p))\u2212 \u2113(\u03d5(\u03bb\u22c6u))\u22252 = \u2225\u2113(f\u03b8(\u03bb\u22c6p))\u2212 \u2113(\u03d5(\u03bb\u22c6p)) + \u2113(\u03d5(\u03bb\u22c6p))\u2212 \u2113(\u03d5(\u03bb\u22c6u))\u22252 \u2264 \u2225\u2113(\u03d5(\u03bb\u22c6p))\u2212 \u2113(\u03d5(\u03bb\u22c6u))\u22252 + \u2225\u2113(f\u03b8(\u03bb\u22c6p))\u2212 \u2113(\u03d5(\u03bb\u22c6p))\u22252\nThe first term captures the impact of the perturbation of dual variables in the unparametrized problem. The second one captures the effect of parametrizating the hypothesis class for a fixed dual variable. For conciseness, technical definitions used in this section are deferred to Appendix A.1."
        },
        {
            "heading": "3.3.1 DUAL VARIABLE PERTURBATION",
            "text": "In the unparametrized problem the Lagrangian minimizer \u03d5(\u03bbu) is unique at each \u03bbu, which implies that gu(\u03bb) is everywhere differentiable with gradient \u2207\u03bbgu(\u03bb) = \u2113(\u03d5(\u03bb)) (see Appendix A.3). In this setting, analyzing the term \u2113(\u03d5(\u03bb\u22c6p)) \u2212 \u2113(\u03d5(\u03bb\u22c6u)) is equivalent to studying the distance between the gradients of gu at \u03bb\u22c6p and \u03bb \u22c6 u. Furthermore, leveraging the \u03bd\u2212near universality of the parametrization we can show that the maximizers of gu and gp cannot be too far apart. In fact, as shown in Appendix A.4, their distance is characterized by:\n\u2225\u03bb\u22c6p \u2212 \u03bb\u22c6u\u222522 \u2264 2 M\u03bd\n\u00b5g (1 + \u2225\u03bb\u22c6p\u22251). (6)\nOptimal dual variables indicate the sensitivity of the optimal value with respect to constraint perturbations. Thus, the term (1+\u2225\u03bb\u22c6p\u22251) can be seen as an indicator of the sensitivity of the optimization\nproblem. Combining the bound in equation in equation 6 with the \u03b2g-smoothness of gu, we can characterize the impact of going from \u03bb\u22c6u to \u03bb \u22c6 p in the unparametrized problem.\nProposition 3.10 Under assumptions 3.1-3.4, the distance between the constraint violations \u03d5(\u03bb\u22c6p) and \u03d5(\u03bb\u22c6u) is bounded by:\n\u2225\u2113(\u03d5(\u03bb\u22c6p))\u2212 \u2113(\u03d5(\u03bb\u22c6u))\u222522 \u2264 2 \u03b22g \u00b5g M\u03bd(1 + \u2225\u03bb\u22c6p\u22251) (7)\nAs the constant \u03b2g\u00b5g grows, and the Hessian of gu becomes ill-conditioned, the bound becomes looser. As shown in Lemma 3.8, this occurs if the number of constraints grows, or if the curvature of the objective \u21130 decreases."
        },
        {
            "heading": "3.3.2 HYPOTHESIS CLASS PERTURBATION",
            "text": "We now consider a perturbed version of the unparametrized problem. Its optimal value - or perturbation- function is defined as:\nP \u22c6(\u03f5) =min \u03d5\u2208F \u21130(\u03d5)\ns.to : \u2113(\u03d5) + \u03f5 \u2aaf 0 (P\u03f5)\nfor a perturbation \u03f5 \u2208 Rm. Intuitively, increasing \u03f5 (coordinate-wise) tightens the constraint, making the feasible set smaller and potentially increasing P \u22c6(\u03f5). Note that by setting \u03f5 = 0, we recover the unparametrized problem: P \u2217(0) = P \u2217u .\nBy focusing on particular instances of this problem with perturbations \u03f5u = \u2212\u2113(\u03d5(\u03bb\u22c6p)) and \u03f5p = \u2212\u2113(f\u03b8(\u03bb\u22c6p)) we can bound the distance between the constraint violations of the Lagrangian minimizers associated to \u03bb\u2217p \u2208 \u039b\u2217p in the parametrized and unparametrized problems. To do this, we start by analyzing the variations of the optimal value function P \u22c6(\u03f5) using a well-known result from conjugate duality: for every \u03bb \u2208 Rm+ we have that P \u2020(\u03bb) = \u2212gu(\u03bb), where P \u2020 denotes the Fenchel conjugate of the perturbation function P \u2217(\u03f5). In fact, the dual problem is sometimes defined as the maximization of \u2212P \u2020(\u03bb) (Rockafellar, 1974). This result is impactful, because it allows us to relate the curvature of gu(\u03bb), which we know from Lemma 3.8, to the variations of P \u2217(\u03f5). Specifically, we leverage the duality between smoothness and strong convexity.\nInformally, a closed convex function h is strongly convex with constant \u00b5 if and only if its Fenchel conjugate h\u2020 is 1\u00b5\u2212smooth (Kakade et al., 2009). Since gu is \u03b2g-smooth, this implies that P \u2217(\u03f5) is 1/\u03b2g\u2212strongly convex in the region of interest (see Appendix A.8). However, for this result to hold, the strict feasibility assumption 3.2 is indispensable. Indeed, the fact that the perturbed problems are strictly feasible implies that perturbation function P \u22c6(\u03f5) is closed, a property needed to characterize its variations (see Appendix A.8).\nFurthermore, since we know that f\u03b8(\u03bb\u22c6p) is feasible for the problem with perturbation \u03f5p, we can use weak duality to bound the distance between P \u2217(\u03f5p) and P \u2217(\u03f5u) (see Appendix A.10). Combining these results, we can describe the impact of the parametrizion for a fixed dual variable \u03bb\u22c6p \u2208 \u039b\u22c6p.\nProposition 3.11 Under assumptions 3.1-3.4, the distance between constraint violation associated to the parametrization of the hypothesis class is given by:\n\u2225\u2113(\u03d5(\u03bb\u22c6p))\u2212 \u2113(f\u03b8(\u03bb\u22c6p))\u222522 \u2264 2\u03b2gM\u03bd(1 + \u2225\u03bb\u22c6p\u22251)\nIn contrast to Proposition 3.10, the strong concavity of the dual function is not present in Proposition 3.11, which means that the smoothness of the losses \u2113i does not play a role in this bound."
        },
        {
            "heading": "4 BEST ITERATE CONVERGENCE",
            "text": "As described in section 2.1, in constrained learning, the objective \u21130 and the constraints \u2113 are statistical in nature: \u2113i(f\u03b8) = E(x,y)[\u2113\u0303i(f(x), y)] where (x, y) is sampled from a distribution D. In practice,\nwe do not have access to D, but to a set of samples D = {(x1, y1), . . . , (xn, yn)}, assumed iid. We will denote by \u2113\u0302i(f\u03b8) an estimate of \u2113i(f\u03b8) using the dataset D: \u2113\u0302i(f\u03b8) := 1n \u2211n k=1 \u2113\u0303i(f\u03b8(xk), yk).\nEstimating expectations with sample means does not modify Algorithm 1 significantly. Since \u2113\u0302i(f\u03b8(t)) is an unbiased estimator of \u2113i(f\u03b8(t)), a stochastic supergradient s\u0302(t) := \u2113\u0302i(f\u03b8(t)) of gp can be obtained using samples from D. Thus, in the stochastic version of the supergradient ascent algorithm (Shor, 2013), the dual update can be written as:\n\u03bbp(t+ 1) = [\u03bbp(t) + \u03b7 s\u0302(t)]+ (8)\nObserve that since E(x,y){s\u0302(t)|\u03bb(t)} \u2208 \u2202gp(\u03bb(t)), dual variables will move, on average, towards the optimal set \u039b\u22c6.\nWe now analyze the convergence of the best dual iterate, that is, the dual variable which evaluates to the largest dual function encountered so far. More precisely, we show that best dual iterates enter a near-optimality ball infinitely often. Since the dual function can be evaluated, this translates into a practical algorithm, analogous to a validation step in standard supervised learning. We then use Propositions 3.10 and 3.11 to obtain a bound on the infeasibility of primal variables associated to the best dual iterate.\nLemma 4.1 Let gbestp (t|\u03bb(t0)) = maxs\u2208[t0,t] gp(\u03bb(s)) be the maximum value of the parametrized dual function up to time t. Then,\nlim t\u2192\u221e\ngbestp (t|\u03bb(t0)) \u2265 D\u22c6p \u2212 \u03b7S2\n2 a.s.\nwhere S2 > E[\u2225s\u0302(t)\u22252|\u03bb(t)] is an upper bound on the norm of the second order moment of the stochastic supergradients.\nObserve that the existence of S2 is guaranteed by the Lipschitz continuity of the losses \u2113i and the boundedness of the set F\u03b8 \u2286 F . Since S2 is finite, one can reduce the step size \u03b7 to make gbestp arbitrarily close to D\u22c6p , with the potential cost of increasing the time of occurrence of such proximity.\nLemma 4.1 implies that for almost every realization, and arbitrary \u03b4 > 0, as t grows gbestp (t|\u03bb(t0)) is \u03b7S 2\n2 + \u03b4 close to D \u22c6 p at least once. Since t0 is arbitrary, this occurs infinitely often. Let \u03bb best be\na dual iterate such that: gp(\u03bbbest) \u2265 D\u22c6p \u2212 (\u03b7S 2 2 + \u03b4). The near-optimality of \u03bb best) and the results from section 3.3 allow us to derive a bound on the constraint violation of primal iterates associated to \u03bbbest in the parametrized and unparametrized problems.\nProposition 4.2 Let \u03bbbest be a dual iterate such that: gp(\u03bbbest) \u2265 D\u22c6p \u2212 (\u03b7S 2\n2 + \u03b4). Under assumptions 3.1, 3.3, 3.3, 3.7 and assuming that there exists \u03d5 \u2208 F such that \u2113(\u03d5) \u227a min{0, \u2113(\u03d5(\u03bbbest)), \u2113(f\u03b8(\u03bbbest))} we have:\n\u2225\u2113(\u03d5\u22c6)\u2212 \u2113(f\u03b8(\u03bbbest)))\u222522 \u2264 2\u03b2gM\u03bd(1 + \u2225\u03bbbest\u22251) ( 1 + (1 + \u03b7S2\n2 + \u03b4) \u221a \u03b2g \u00b5\u0303g )2\nwhere \u00b5\u0303g = \u00b50 \u03c3 2\n\u03b22(1+max{\u2225\u03bb\u22c6u\u22251,\u2225\u03bbbest\u22251})2\nThe main difference between Proposition 4.2 and the main Theorem 3.5 is that the condition number \u03b2g \u00b5\u0303g gets amplified by the sub-optimality of \u03bbbest with respect to \u03bb\u22c6p."
        },
        {
            "heading": "5 EXPERIMENTAL VALIDATION",
            "text": "To validate the theoretical findings of sections 3 and 4 we return to example 2.1, a constrained learning problem with counterfactual fairness requirements. In the COMPAS dataset, the protected variables gender and race can take the values [\u201dMale\u201d, \u201dFemale\u201d] and [\u201dAfrican American\u201d, \u201dHispanic\u201d, \u201dCaucasian\u201d, \u201dOther\u201d] respectively. We use a two-layer neural network with 64 nodes and\nsigmoid activations. The training objective \u21130 is the negative log-likelihood and the constraint upper bound is set to 0.001. We train this model over T = 400 iterations using a ADAM, with batch size 256, primal learning rate 0.1, and dual variable learning rate 2. The objective \u21130 is the negative log-likelihood. We use the same data pre-processing steps as in (Chamon & Ribeiro, 2020).\nIn this setting, we compare the performance and constraint satisfaction of three predictors. An Unconstrained predictor: trained without contemplating the fairness requirements through empirical risk minimization. The Last predictor: corresponding to the final iterate f\u03b8(\u03bb(T )) of the stochastic dual supergradient ascent method. The Randomized predictor: which takes the sequence of primal iterates {f\u03b8(\u03bb(t))}Tt=t0 and samples a learner uniformly from this sequence in order to make a prediction. We take t0 as the iteration where training accuracy settles, which corresponds to around half of the training iterations.\nAs shown in Figure 2, the unconstrained model is slightly better than the constrained ones, although this difference is small (< 1%). Furthermore, the unconstrained model is significantly worse in terms of counterfactual fairness than both the Last and Randomized Predictors, which are always close, in agreement with Theorem 3.5. We also perform an ablation on how the richness of the parametrization impacts the maximum violation of primal iterates. To control the richness of the parametrization we project the input samples into a space of lower-dimension with a fixed, random linear map. These lower-dimensional vectors are then used to train the neural network. As the richness of the parametrization increases, \u03bd decreases, reducing the upper bound in Theorem 3.5. This is illustrated by the right-most plot in Figure 2, where the maximum constraint violation (i.e: magnitude of the feasibility oscillations) decreases by an order of magnitude as we progressively increase the capacity of the model."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "We analyzed the feasibility of primal iterates obtained from a dual ascent method when solving the Lagrangian dual of a primal non-convex constrained learning problem. The primal problem in question is the parametrized version of a convex functional program, which is amenable to a Lagrangian relaxation. Specifically, we characterized how far these predictors are from a solution of the unparametrized problem in terms of their constraint violations. This result led to a characterization of the infeasibility of best primal iterates and elucidated the role of the capacity of the model and the curvature of the objective. These guarantees bridge a gap between theory and practice in constrained learning, shedding light on when and why randomization is unnecessary.\nThe findings presented in this work can be extended in several ways. For instance, the estimation error incurred by using samples to estimate statistical losses can be included in the main analysis. Moreover, feasibility results studying the primal iterates directly, and not on their distance to the solution of the unparametrized problem can be obtained. Finally, it might be possible to lift one or more assumptions about the unparametrized problem."
        },
        {
            "heading": "A APPENDIX",
            "text": ""
        },
        {
            "heading": "A.1 ADDITIONAL DEFINITIONS",
            "text": "Definition A.1 We say that a functional \u2113i : F \u2192 R is Fre\u0301chet differentiable at \u03d50 \u2208 F if there exists an operator D\u03d5\u2113i(\u03d50) \u2208 B(F ,R) such that:\nlim h\u21920 |\u2113i(\u03d50 + h)\u2212 \u2113i(\u03d50)\u2212 \u27e8D\u03d5\u2113i(\u03d50), h\u27e9| \u2225h\u2225L2 = 0\nwhere B(F ,R) denotes the space of bounded linear operators from F to R.\nThe space B(F ,R), algebraic dual of F , is equipped with the corresponding dual norm: \u2225B\u2225L2 = sup { |\u27e8B,\u03d5\u27e9|\n\u2225\u03d5\u2225L2 : \u03d5 \u2208 F , \u2225\u03d5\u2225L2 \u0338= 0 } which coincides with the L2\u2212norm through Riesz\u2019s Representation Theorem: there exists a unique g \u2208 F such that B(\u03d5) = \u27e8\u03d5, g\u27e9 for all \u03d5 and \u2225B\u2225L2 = \u2225g\u2225L2 .\nDefinition A.2 A function h : X \u2192 R is said to be closed if for each \u03b1 \u2208 R, the sublevel set {h(x) \u2264 \u03b1 : x \u2208 X} is a closed set.\nDefinition A.3 A convex function h : X \u2192 R is proper if h(x) > \u2212\u221e for all x \u2208 X and there exists x0 \u2208 X such that h(x0) < +\u221e.\nDefinition A.4 Let X be an Euclidean vector space. Given a convex function h : X \u2192 R \u222a {\u221e}, its Fenchel conjugate h\u2020 : X \u2192 R \u222a {\u221e} is defined as:\nh\u2020(y) = sup x\u2208X \u27e8x, y\u27e9 \u2212 h(x)"
        },
        {
            "heading": "A.2 PROOF LEMMA A.5",
            "text": "Lemma A.5 The point-wise distance between the parametrized and unparametrized dual functions is bounded by:\n0 \u2264 gp(\u03bb)\u2212 gu(\u03bb) \u2264 M\u03bd(1 + \u2225\u03bb\u22251) \u2200 \u03bb \u2ab0 0 (9)\nAs defined in section 2.1, \u03d5(\u03bb) denotes the Lagrangian minimizer associated to the multiplier \u03bb in the unparametrized problem.\nBy the near-universality assumption, \u2203 \u03b8\u0303 \u2208 \u0398 such that \u2225\u03d5(\u03bb)\u2212 f\u03b8\u0303\u2225L2 \u2264 \u03bd. Note that, L(f\u03b8\u0303, \u03bb)\u2212 L(\u03d5(\u03bb), \u03bb) = \u21130(f\u03b8\u0303)\u2212 \u2113(\u03d5(\u03bb)) + \u03bbT ( \u2113(f\u03b8\u0303)\u2212 \u2113(\u03d5(\u03bb)) ) \u2264 \u2225\u21130(f\u03b8\u0303)\u2212 \u2113(\u03d5(\u03bb))\u22252 +\nm\u2211 i=1 [\u03bb]i\u2225\u2113(f\u03b8\u0303)\u2212 \u2113(\u03d5(\u03bb))\u22252\nwhere we used the triangle inequality twice. Then, using the M\u2212Lipschitz continuity of the functionals \u2113i and the fact that \u2225\u03d5(\u03bb)\u2212 f\u03b8\u0303\u22252 \u2264 \u03bd, we obtain:\nL(f\u03b8\u0303, \u03bb)\u2212 L(\u03d5(\u03bb), \u03bb) \u2264 M\u2225f\u03b8\u0303 \u2212 \u03d5(\u03bb)\u2225L2 +M m\u2211 i=1 [\u03bb]i\u2225f\u03b8\u0303 \u2212 \u03d5(\u03bb)\u2225L2\n\u2264 M\u03bd +M\u03bd m\u2211 i=1 [\u03bb]i = M\u03bd(1 + \u2225\u03bb\u22251)\nSince f\u03b8(\u03bb) \u2208 F\u22c6\u03b8 (\u03bb) is a Lagrangian minimizer, we know that L(f\u03b8(\u03bb), \u03bb) \u2264 L(f\u03b8\u0303, \u03bb). Thus, 0 \u2264 L(f\u03b8(\u03bb), \u03bb)\u2212 L(\u03d5(\u03bb), \u03bb) \u2264 L(f\u03b8\u0303, \u03bb)\u2212 L(\u03d5(\u03bb), \u03bb) where the non-negativity comes from the fact that F\u0398 \u2286 F . This implies: 0 \u2264 gp(\u03bb)\u2212 gu(\u03bb) \u2264 M\u03bd(\u2225\u03bb\u22251 + 1) \u2200 \u03bb \u2ab0 0\nwhich conludes the proof.\nA.3 LEMMA A.6: DIFFERENTIABILITY OF gu(\u03bbu)\nLemma A.6 Under assumption 3.1, the unparametrized dual function gu(\u03bb) is everywhere differentiable with gradient \u2207\u03bbgu(\u03bb) = \u2113(\u03d5(\u03bb)).\nFrom assumption 3.1, \u2113(\u03d5) is strongly convex and \u03bbT \u2113(\u03d5) is a non-negative combination of convex functions. Thus, the Lagrangian L(f, \u03bb) is strongly convex on \u03d5 for any fixed dual variable \u03bb \u2208 Rm+ . The convexity and compactness of F imply that, in the unparametrized problem, the Lagrangian functional attains its minimizer \u03d5(\u03bb) for each \u03bb. (see e.g, (Kurdila & Zabarankin, 2006) Theorem 7.3.1.) Then, by the strong convexity of L(\u03d5, \u03bb), this minimizer is unique.\nSince L(f, \u03bb) is affine on \u03bb, it is differentiable on \u03bb. Then, by application of the Generalized Danskin\u2019s Theorem (see e.g: (Bas\u0327ar & Bernhard, 2008) Corollary 10.1) to gu(\u03bb) and using that the set of minimizers \u03d5(\u03bb) of L(f, \u03bb) is a singleton, we obtain:\n\u2207\u03bbgu(\u03bb) = \u2113(\u03d5(\u03bb)), which completes the proof."
        },
        {
            "heading": "A.4 PROOF LEMMA A.7",
            "text": "Lemma A.7 Under assumptions 3.1, 3.2, 3.3, 3.4, the proximity between the unparametrized and parametrized optimal dual variables is characterized by:\n\u2225\u03bb\u22c6p \u2212 \u03bb\u22c6u\u222522 \u2264 2 M\u03bd\n\u00b5g (1 + \u2225\u03bb\u22c6p\u22251) (10)\nSince gu(\u03bb) is differentiable (see A.6) and \u00b5g\u2212strongly concave for \u03bb \u2208 B\u03bb :\ngu(\u03bb) \u2264 gu(\u03bb\u22c6u) +\u2207gu(\u03bb\u22c6u)T (\u03bb\u2212 \u03bb\u22c6u)\u2212 \u00b5g 2 \u2225\u03bb\u2212 \u03bb\u22c6u\u222522 \u2200\u03bb \u2208 B\u03bb\nFrom Lemma A.6 we have that \u2207gu(\u03bb\u22c6u) = \u2113(\u03d5(\u03bb\u22c6u))), then evaluating at \u03bb\u22c6p we obtain:\ngu(\u03bb \u22c6 p) \u2264 gu(\u03bb\u22c6u) + \u2113(\u03d5(\u03bb\u22c6u))T (\u03bb\u22c6p \u2212 \u03bb\u22c6u)\u2212 \u00b5g 2 \u2225\u03bb\u22c6p \u2212 \u03bb\u22c6u\u222522\nBy complementary slackness, \u2113(\u03d5(\u03bb\u22c6u)) T\u03bb\u22c6u = 0. Then, since \u03d5(\u03bb \u22c6 u) is feasible and \u03bb \u22c6 p \u2265 0: \u2113(\u03d5(\u03bb\u22c6u)) T\u03bb\u22c6p \u2264 0. Thus,\ngu(\u03bb \u22c6 p) \u2264 gu(\u03bb\u22c6u)\u2212 \u00b5g 2 \u2225\u03bb\u22c6p \u2212 \u03bb\u22c6u\u222522\nBy Proposition 1: gp(\u03bb\u22c6p)\u2212M\u03bd(1 + \u2225\u03bb\u22c6p\u22251) \u2264 gu(\u03bb\u22c6p), which implies:\ngp(\u03bb \u22c6 p)\u2212M\u03bd(1 + \u2225\u03bb\u22c6p\u22251) \u2264 gu(\u03bb\u22c6u)\u2212 \u00b5g 2 \u2225\u03bb\u22c6p \u2212 \u03bb\u22c6u\u222522\nThus,\n\u2225\u03bb\u22c6p \u2212 \u03bb\u22c6u\u222522 \u2264 2\n\u00b5g\n[ gu(\u03bb \u22c6 u)\u2212 gp(\u03bb\u22c6p) ] + 2\n\u00b5g M\u03bd(1 + \u2225\u03bb\u22c6p\u22251) (11)\nFinally, since F\u03b8 \u2286 F we have that : gu(\u03bb) \u2264 gp(\u03bb) \u2200 \u03bb. Evaluating at \u03bb\u22c6u and using that \u03bb\u22c6p maximizes gp we obtain:\ngu(\u03bb \u22c6 u) \u2264 gp(\u03bb\u22c6u)\n\u2264 gp(\u03bb\u22c6p)\nUsing this in equation 11 we obtain,\n\u2225\u03bb\u22c6p \u2212 \u03bb\u22c6u\u222522 \u2264 2\n\u00b5g M\u03bd(1 + \u2225\u03bb\u22c6p\u22251)"
        },
        {
            "heading": "A.5 PROOF THEOREM 3.10",
            "text": "The proof follows from straightforward applications of Lemma A.6, Proposition and Proposition A.7:\n\u2225L(\u03d5(\u03bb\u22c6p))\u2212 \u2113(\u03d5(\u03bb\u22c6u))\u222522 = \u2225\u2207\u03bbgu(\u03bb\u22c6p)\u2212\u2207\u03bbgu(\u03bb\u22c6u)\u222522 \u2264 \u03b22g\u2225\u03bb\u22c6p \u2212 \u03bb\u22c6u\u222522\n\u2264 2\u03b2 2 g\n\u00b5g M\u03bd(1 + \u2225\u03bb\u22c6p\u22251)"
        },
        {
            "heading": "A.6 PROOF LEMMA 3.8",
            "text": "A.6.1 STRONG CONCAVITY CONSTANT \u00b5g\nAs argued in Lemma A.6, the unparametrized Lagrangian has a unique minimizer \u03d5(\u03bb) for each \u03bb \u2208 Rm+ . Let \u03bb1, \u03bb2 \u2208 B\u03bb and \u03d51 = \u03d5(\u03bb1), \u03d52 = \u03d5(\u03bb2). By convexity of the functions \u2113i : F \u2192 R for i = 1, . . . ,m, we have:\n\u2113i(\u03d52) \u2265 \u2113i(\u03d51) + \u27e8D\u03d5\u2113i(\u03d51), \u03d52 \u2212 \u03d51\u27e9, \u2113i(\u03d51) \u2265 \u2113i(\u03d52) + \u27e8D\u03d5\u2113i(\u03d52), \u03d51 \u2212 \u03d52\u27e9\nMultiplying the above inequalities by [\u03bb1]i \u2265 0 and [\u03bb2]i \u2265 0 respectively and adding them, we obtain:\n\u2212\u27e8\u2113(\u03d52)\u2212 \u2113(\u03d51), \u03bb2 \u2212 \u03bb1\u27e9 \u2265 \u27e8\u03bbT1 D\u03d5\u2113(\u03d51)\u2212 \u03bbT2 D\u03d5\u2113(\u03d52), \u03d52 \u2212 \u03d51\u27e9 (12)\nSince \u2207gu(\u03bb) = L(\u03d5(\u03bb)), we have that:\n\u2212\u27e8\u2207gu(\u03bb2)\u2212\u2207gu(\u03bb2), \u03bb2 \u2212 \u03bb1\u27e9 \u2265 \u27e8\u03bbT1 D\u03d5L(\u03d51)\u2212 \u03bbT2 D\u03d5L(\u03d52), \u03d52 \u2212 \u03d51\u27e9 (13)\nMoreover, first order optimality conditions yield:\nD\u03d5\u21130(\u03d51) + \u03bb T 1 D\u03d5\u2113(\u03d51) = 0,\nD\u03d5\u21130(\u03d52) + \u03bb T 2 D\u03d5\u2113(\u03d52) = 0\n(14)\nwhere 0 denotes the null-opereator from F to R (see e.g: (Kurdila & Zabarankin, 2006) Theorem 5.3.1).\nCombining equations 13 and 14 we obtain:\n\u2212\u27e8\u2207gu(\u03bb2)\u2212\u2207gu(\u03bb2), \u03bb2 \u2212 \u03bb1\u27e9 \u2265 \u27e8D\u03d5\u21130(\u03d52)\u2212D\u03d5\u21130(\u03d51), \u03d52 \u2212 \u03d51\u27e9 \u2265 \u00b50\u2225\u03d52 \u2212 \u03d51\u22252L2\n(15)\nwhere we used the \u00b50\u2212strong convexity of the operator \u21130. We will now obtain a lower bound on \u2225\u03d52 \u2212 \u03d51\u2225L2 , starting from the \u03b2\u2212smoothness of \u21130:\n\u2225\u03d52 \u2212 \u03d51\u22252 \u2265 1\n\u03b2 \u2225D\u03d5\u21130(\u03d52)\u2212D\u03d5\u21130(\u03d51)\u2225L2\n= 1\n\u03b2 \u2225\u03bbT2 D\u03d5\u2113(\u03d52)\u2212 \u03bbT1 D\u03d5\u2113(\u03d51)\u2225L2\n= 1\n\u03b2 \u2225(\u03bb2 \u2212 \u03bb1)TD\u03d5\u2113(\u03d52)\u2212 \u03bbT1 (D\u03d5\u2113(\u03d51)\u2212D\u03d5\u2113(\u03d52))\u2225L2\n(16)\nThen, second term in the previous equality can be characterized using assumption 3.7:\n\u2225(\u03bb2 \u2212 \u03bb1)TD\u03d5\u2113(\u03d52)\u2225L2 \u2265 \u03c3\u2225\u03bb2 \u2212 \u03bb1\u22252 (17)\nFor the second term, using the \u03b2\u2212smoothness of \u2113i we can derive:\n\u2225\u03bbT1 (D\u03d5\u2113(\u03d51)\u2212D\u03d5\u2113(\u03d52))\u2225L2 = \u2225 m\u2211 i=1 [\u03bb1]i(D\u03d5\u2113i(\u03d51)\u2212D\u03d5\u2113i(\u03d52))\u2225L2\n\u2264 m\u2211 i=1 [\u03bb1]i\u2225D\u03d5\u2113i(\u03d51)\u2212D\u03d5\u2113i(\u03d52)\u2225L2\n\u2264 m\u2211 i=1 [\u03bb1]i\u03b2\u2225\u03d51 \u2212 \u03d52\u2225L2 = \u03b2\u2225\u03bb1\u22251\u2225\u03d51 \u2212 \u03d52\u2225L2\n(18)\nThen, using the reverse triangle inequality:\n\u2225(\u03bb2 \u2212 \u03bb1)TD\u03d5\u2113(\u03d52)\u2212\u03bbT1 (D\u03d5\u2113(\u03d51)\u2212D\u03d5\u2113(\u03d52))\u2225L2 \u2265 \u2225(\u03bb2 \u2212 \u03bb1)TD\u03d5\u2113(\u03d52)\u2225L2 \u2212 \u2225\u03bbT1 (D\u03d5\u2113(\u03d51)\u2212D\u03d5\u2113(\u03d52))\u2225L2 \u2265 \u03c3\u2225\u03bb2 \u2212 \u03bb1\u22252 \u2212 \u03b2\u2225\u03bb1\u22251\u2225\u03d52 \u2212 \u03d51\u2225L2\n(19)\nCombining this with equation 16 we obtain:\n\u2225\u03d52 \u2212 \u03d51\u22252 \u2265 1\n\u03b2 (\u03c3\u2225\u03bb2 \u2212 \u03bb1\u22252 \u2212 \u03b2\u2225\u03bb1\u22251\u2225\u03d52 \u2212 \u03d51\u2225L2)\n\u2212\u2192 \u2225\u03d52 \u2212 \u03d51\u2225L2 \u2265 \u03c3\n\u03b2(1 + \u2225\u03bb1\u22251) \u2225\u03bb2 \u2212 \u03bb1\u22252\n(20)\nThis means that we can write equation 15 as:\n\u2212\u27e8\u2207gu(\u03bb2)\u2212\u2207gu(\u03bb1), \u03bb2 \u2212 \u03bb1\u27e9 \u2265 \u00b50 \u03c3\n2\n\u03b22(1 + \u2225\u03bb1\u22251)2 \u2225\u03bb2 \u2212 \u03bb1\u222522\nLetting \u03bb2 = \u03bb\u22c6u, we obtain that the strong concavity constant of gu in B\u03bb is \u00b5g = \u00b50 \u03c3 2 \u03b22(1+max{\u2225\u03bb\u22c6u\u22251,\u2225\u03bb\u22c6p\u22251})2 . A similar proof in the finite dimensional case can be found in (Guigues, 2020).\nA.6.2 SMOOTHNESS CONSTANT \u03b2g\nSet \u03bb1, \u03bb2 \u2208 Rm+ , and let \u03d51 = \u03d5(\u03bb1) and \u03d52 = \u03d5(\u03bb2) denote the Lagrangian minimizers associated to these multipliers.\nSince the unparametrized Lagrangian is differentiable and \u00b50-strongly convex we have:\nL(f, \u03bb) \u2265 L(\u03d5(\u03bb), \u03bb) + \u27e8D\u03d5L(\u03d5(\u03bb), \u03bb)), f \u2212 \u03d5(\u03bb)\u27e9+ \u00b50 2 \u2225f \u2212 \u03d5(\u03bb)\u22252L2\nUsing that \u03d5(\u03bb) is a minimizer, we obtain (see e.g: (Kurdila & Zabarankin, 2006) Theorem 5.3.1) :\nL(\u03d5(\u03bb), \u03bb) \u2264 L(f, \u03bb)\u2212 \u00b50 2 \u2225f \u2212 \u03d5(\u03bb)\u222522,\u2200f \u2208 F\nApplying this to \u03d52 and \u03d51 we obtain:\n\u21130(\u03d52) + \u03bb T 2 \u2113(\u03d52) \u2264 \u21130(\u03d51) + \u03bbT2 \u2113(\u03d51)\u2212 \u00b50 2 \u2225\u03d52 \u2212 \u03d51\u22252L2\n\u21130(\u03d51) + \u03bb T 1 \u2113(\u03d51) \u2264 \u21130(\u03d52) + \u03bbT1 \u2113(\u03d52)\u2212 \u00b50 2 \u2225\u03d52 \u2212 \u03d51\u22252L2\nSumming the above inequalities and applying Cauchy-Schwarz:\n\u00b50\u2225\u03d52 \u2212 \u03d51\u222522 \u2264 (\u03bb2 \u2212 \u03bb1)T (\u2113(\u03d51)\u2212 \u2113(\u03d52)) \u2264 \u2225\u03bb2 \u2212 \u03bb1\u22252\u2225\u2113(\u03d51)\u2212 \u2113(\u03d52)\u22252 \u2264 \u221amM\u2225\u03bb2 \u2212 \u03bb1\u22252\u2225\u03d51 \u2212 \u03d52\u2225L2\nwhere the last inequality follows from assumption 3.1. Then, applying Lemma A.6 we obtain:\n\u2225\u2207\u03bbgu(\u03bb2)\u2212\u2207\u03bbgu(\u03bb1)\u22252 = \u2225\u2113(\u03d52)\u2212 \u2113(\u03d51)\u22252 \u2264 M\u2225\u03d52 \u2212 \u03d51\u2225L2\n\u2264 \u221amM 2\n\u00b50 \u2225\u03bb2 \u2212 \u03bb1\u22252\nwhich means that gu has a smoothness constant \u03b2g = \u221a mM 2\n\u00b50 ."
        },
        {
            "heading": "A.7 PROOF LEMMA A.8",
            "text": "Lemma A.8 Let P \u2020 denote the Fenchel conjugate of the perturbation function P \u2217(\u03f5). For every \u03bb \u2208 Rm+ we have that P \u2020(\u03bb) = \u2212gu(\u03bb).\nBy definition of Fenchel conjugate:\nP \u2020(\u03bb) = sup \u03f5 \u03bbT \u03f5\u2212 P \u22c6(\u03f5) (21)\nUsing the definition of P \u2217(\u03f5):\nP \u2020(\u03bb) = sup \u03d5\u2208F,\u03f5 \u03bbT \u03f5\u2212 \u21130(\u03d5)\ns.t: \u2113(\u03d5) + \u03f5 \u2aaf 0 (22)\nApplying the change of variable z = \u2113(\u03d5) + \u03f5, P \u2020(\u03bb) can be written as:\nP \u2020(\u03bb) = sup \u03d5\u2208F,z \u03bbT z\u2212 \u03bbT \u2113(\u03d5)\u2212 \u21130(\u03d5)\ns. to: z \u2aaf 0 (23)\nSince z \u2aaf 0, the term \u03bbT z is unbounded above for \u03bb \u227a 0. Thus, we restrict the domain of P \u2020(\u03bb) to \u03bb \u2ab0 0. In this region, maximizing over z \u2208 Rm\u2212 yields z\u2217 = 0. We can thus write P \u2020(\u03bb) as:\nP \u2020(\u03bb) = sup \u03d5\u2208F \u2212\u03bbT \u2113(\u03d5)\u2212 \u21130(\u03d5), \u03bb \u2ab0 0\n=\u2212 inf \u03d5\u2208F\n\u03bbT \u2113(\u03d5) + \u21130(\u03d5), \u03bb \u2ab0 0 (24)\nTherefore, P \u2020(\u03bb) = \u2212gu(\u03bb), \u03bb \u2ab0 0.\nSee for instance: (Rockafellar, 1997), Section 28, (Guigues, 2020), Lemma 2.9 or (Rockafellar, 1974), Theorem 7."
        },
        {
            "heading": "A.8 PROOF COROLLARY A.9",
            "text": "Corollary A.9 Let B\u03f5 = {\u03b3\u03f5u + (1\u2212 \u03b3)\u03f5p : \u03b3 \u2208 [0, 1]} denote the segment connecting \u03f5u and \u03f5p. The perturbation function P \u2217(\u03f5) is \u00b5\u03f5\u2212strongly convex on B\u03f5 with constant: \u00b5\u03f5 = 1/\u03b2g .\nLemma A.10 Let h be a closed convex function defined on a subset of the vector space X ; h is \u00b5\u2212strongly convex if and only if h\u2020 has \u00b5\u2212Lipschitz continuous gradients. (See e.g, (?) or (Goebel & Rockafellar, 2008)).\nIn order to apply Lemma A.10 we need to show that the perturbation function P (\u03f5) is convex and closed in the region of interest.\nConvexity of P \u22c6(\u03f5) for convex functional programs is shown in (Bonnans & Shapiro, 1998) or (Rockafellar, 1997) Theorem 29.1. Now we will show that P \u22c6(\u03f5) is proper and lower semi continuous in the region of interest, which implies that it is closed.\nThe functional \u21130, defined on the compact set F , is smooth. Thus, it is bounded on F . From assumption 3.2 we have that the problem is feasible for \u03f5 = 0. Therefore, P (0) < +\u221e. Moreover, by boundedness of \u21130, P (\u03f5) > \u2212\u221e \u2200\u03f5, implying that P (\u03f5) is proper. Now, fix \u03f50 \u2208 B\u03f5. Assumption 3.2 implies that the perturbed problem with constraint: L(f)+\u03f50 \u2aaf 0 is strictly feasible. Since this perturbed problem is convex and strictly feasible, its perturbation function P\u0303 (\u03f5) is lower semi continuous at 0 (see (Bonnans & Shapiro, 1998) Theorem 4.2). Note that P\u0303 (\u03f5) = P \u2217(\u03f5+ \u03f50). Thus, P \u22c6(\u03f5) is lower semi continuous at \u03f50.\nWe conclude that P \u22c6(\u03f5) is proper and lower semi continuous for all \u03f5 \u2208 B\u03f5. On the other hand, from Corollary 3.8 P \u2020(\u03bb) = \u2212gu(\u03bb) is \u03b2g-smooth on Rm+ . Thus, we are in the hypothesis of proposition A.8, which implies that P \u22c6(\u03f5) is strongly convex on B\u03f5 with constant 1\u03b2g ."
        },
        {
            "heading": "A.9 PROOF PROPOSITION A.11",
            "text": "Proposition A.11 Under assumptions 3.1 and 3.2, \u03bb\u22c6p is a subgradient of the perturbation function at \u03f5u. That is, \u03bb\u22c6p \u2208 \u2202P \u2217(\u03f5u).\nThe conjugate nature of the dual function gu(\u03bb) and the perturbation function P \u22c6(\u03f5) also establishes a dependence between their first order variations. This dependence is captured in the following lemma.\nLemma A.12 If h is a closed convex function, the subdifferential \u2202h\u2020 is the inverse of \u2202h in the sense of multivalued mappings (see (Rockafellar, 1997) Corollary 23.5.1):\nx \u2208 \u2202h\u2020(y) \u21d0\u21d2 y \u2208 \u2202h(x)\nOn one hand, from Lemma A.6, we have that \u2207\u03bbgu(\u03bb\u22c6p) = \u2113(\u03d5(\u03bb\u22c6p)) = \u2212\u03f5u. On the other hand, from Lemma A.8, P \u2020(\u03bb) = \u2212gu(\u03bb) for all \u03bb \u2208 Rm+ . Taking the gradient with respect to \u03bb and evaluating at \u03bb\u22c6p we obtain: \u2207\u03bbP \u2020(\u03bb\u22c6p) = \u2212\u03f5u. Then, Lemma A.12, yields the wanted sensitivity result:\n\u03bb\u22c6p \u2208 \u2202P \u2217(\u03f5u)."
        },
        {
            "heading": "A.10 PROOF PROPOSITION A.13",
            "text": "Proposition A.13 Under assumptions 3.3 and 3.1, the difference between the optimal values of problems perturbed by \u03f5p and \u03f5u is bounded:\nP \u2217(\u03f5p)\u2212 P \u2217(\u03f5u) \u2264 M\u03bd(1 + \u2225\u03bb\u22c6p\u2225) + \u03bb\u2217Tp (\u03f5p \u2212 \u03f5u)\nRecall that \u03f5u = \u2212\u2113(\u03d5(\u03bb\u22c6p)) and \u03f5p = \u2212\u2113(f\u03b8(\u03bb\u22c6p)). We want to show that: P \u2217(\u03f5p)\u2212 P \u2217(\u03f5u) \u2264 L\u03bd(1 + \u2225\u03bb\u22c6p\u2225) + \u03bb\u2217Tp (\u03f5p \u2212 \u03f5u)\nWe start by showing that P \u2217(\u03f5p) \u2264 \u21130(f\u03b8(\u03bb\u22c6p)). Note that f\u03b8(\u03bb\u22c6p) is feasible in the perturbed problem, since its constraint value is \u2212\u03f5p. Then,\nP (\u03f5p) = min f\n{L0(f) : L(f) + \u03f5p \u2aaf 0} \u2264 L0(f\u03b8(\u03bb\u22c6p))\nTherefore, P \u2217(\u03f5p)\u2212 P \u2217(\u03f5u) \u2264 \u21130(f\u03b8(\u03bb\u22c6p))\u2212 P \u2217(\u03f5u). (25)\nNote that the dual function of the problem perturbed by \u03f5u is g\u0303u(\u03bb, \u03f5u) := min\u03d5\u2208F {\u21130(f) + \u03bbT (\u2113(\u03d5) + \u03f5u)}. Then, weak duality implies that P \u2217(\u03f5u) \u2265 g\u0303u(\u03bb, \u03f5u) for all \u03bb. Evaluating at \u03bb\u22c6p we obtain:\nP \u2217(\u03f5u) \u2265 min \u03d5\u2208F {L0(f) + \u03bb\u2217Tp (L(f) + \u03f5u)}\n= min \u03d5\u2208F\n{\u21130(\u03d5) + \u03bb\u2217Tp \u2113(\u03d5)}+ \u03bb\u2217Tp \u03f5u\n= gu(\u03bb \u22c6 p) + \u03bb \u2217T p \u03f5u\n(26)\nCombining equations 26 and 25 we obtain:\nP \u2217(\u03f5p)\u2212 P \u2217(\u03f5u) \u2264 \u21130(f\u03b8(\u03bb\u22c6p))\u2212 gu(\u03bb\u22c6p)\u2212 \u03bb\u2217Tp \u03f5u = \u21130(f\u03b8(\u03bb \u22c6 p))\u00b1 \u03bb\u2217Tp \u03f5p \u2212 gu(\u03bb\u22c6p)\u2212 \u03bb\u2217Tp \u03f5u\nUsing that \u03f5p = \u2212\u2113(f\u03b8(\u03bb\u22c6p)) we obtain: P \u2217(\u03f5p)\u2212 P \u2217(\u03f5u) \u2264 gp(\u03bb\u22c6p)\u2212 gu(\u03bb\u22c6p) + \u03bb\u2217Tp (\u03f5p \u2212 \u03f5u)\nFinally, using Propostion we obtain:\nP \u2217(\u03f5p)\u2212 P \u2217(\u03f5u) \u2264 M\u03bd(1 + \u2225\u03bb\u22c6p\u22251) + \u03bb\u2217Tp (\u03f5p \u2212 \u03f5u), which conludes the proof."
        },
        {
            "heading": "A.11 PROOF THEOREM 3.11",
            "text": "Let \u2206\u03f5 = \u03f5p \u2212 \u03f5u, using the strong convexity constant obtained in Proposition A.9 we have that:\nP \u2217(\u03f5p) \u2265 P \u2217(\u03f5u) + sT\u2206\u03f5+ 1\n2\u03b2g \u2225\u2206\u03f5\u222522\nwhere s \u2208 \u2202P \u2217(\u03f5u) is a subgradient of P \u2217(\u03f5) at \u03f5u. From Proposition A.11 we know that: \u03bb\u22c6p \u2208 \u2202P \u2217(\u03f5u). Thus,\nP \u2217(\u03f5p) \u2265 P \u2217(\u03f5u) + \u03bb\u2217Tp \u2206\u03f5+ 1\n2\u03b2g \u2225\u2206\u03f5\u222522\nUsing the bound on P \u2217(\u03f5p)\u2212 P \u2217(\u03f5u) obtained in proposition A.13 we can write:\nM\u03bd(1 + \u2225\u03bb\u22c6p\u22251) + \u03bb\u22c6 T p \u2206\u03f5 \u2265 \u03bb\u22c6 T p \u2206\u03f5+ 1\n2\u03b2g \u2225\u2206\u03f5\u222522\n\u2212\u2192M\u03bd(1 + \u2225\u03bb\u22c6p\u22251) \u2265 1\n2\u03b2g \u2225\u2206\u03f5\u222522\nThis implies:\n\u2225\u2206\u03f5\u222522 \u2264 2\u03b2gM\u03bd(1 + \u2225\u03bb\u22c6p\u22251) \u2212\u2192\u2225\u2113(\u03d5)\u2212 \u2113(f\u03b8(\u03bb\u22c6p))\u222522 \u2264 2\u03b2gM\u03bd(1 + \u2225\u03bb\u22c6p\u22251)\nwhich concludes the proof."
        },
        {
            "heading": "A.12 PROOF PROPOSITION 3.5",
            "text": "From Corollary 3.10 and Proposition 3.11 we have that: \u2225\u2113(\u03d5(\u03bb\u22c6p))\u2212 \u2113(\u03d5\u22c6)\u22252 \u2264 \u221a\n2 \u03b22g \u00b5g M\u03bd(1 + \u2225\u03bb\u22c6p\u22251) (27)\n\u2225\u2113(\u03d5(\u03bb\u22c6p))\u2212 \u2113(f\u03b8(\u03bb\u22c6p))\u22252 \u2264 \u221a 2\u03b2gM\u03bd(1 + \u2225\u03bb\u22c6p\u22251) (28)\nCombining the two equations above we obtain: \u2225\u2113(f\u03b8(\u03bb\u22c6p))\u2212 \u2113(\u03d5(\u03bb\u22c6u))\u22252 \u2264 \u221a 2 \u03b22g \u00b5g M\u03bd(1 + \u2225\u03bb\u22c6p\u22251) + \u221a 2\u03b2gM\u03bd(1 + \u2225\u03bb\u22c6p\u22251) (29)\n\u2264 \u221a 2\u03b2gM\u03bd(1 + \u2225\u03bb\u22c6p\u22251) ( 1 + \u221a \u03b2g \u00b5g ) (30)\nTaking squares on both sides yields the desired result."
        },
        {
            "heading": "A.13 PROOF COROLLARY 3.9",
            "text": "Proposition 3.8 characterizes the strong concavity \u00b5g and smoothness \u03b2g of the dual function in terms of the properties of the losses \u2113i and the functional space F . The proof of this corollary stems from applying proposition 3.8 to the 2-norm bound in Theorem 3.5.\nWe start by observing that:\n\u2225\u2113(f\u03b8(\u03bb\u22c6p))\u2212 \u2113(\u03d5(\u03bb\u22c6u))\u2225\u221e \u2264 \u2225\u2113(f\u03b8(\u03bb\u22c6p))\u2212 \u2113(\u03d5(\u03bb\u22c6u))\u22252 (31)\n\u2264 \u221a 2\u03b2gM\u03bd(1 + \u2225\u03bb\u22c6p\u22251)(1 + \u221a \u03b2g \u00b5g ) (32)\nFrom proposition 3.8, we have that \u00b5g = \u00b50 \u03c3 2 \u03b22(1+\u2206)2 and \u03b2g = \u221a mM2 \u00b50 . This implies that\n\u03b2g \u00b5g\n= \u221a m M2 \u03c32 \u03b22 \u00b520 (1 + \u2206)2\nwhere \u2206 = max{\u2225\u03bb\u22c6u\u22251, \u2225\u03bb\u22c6p\u22251}. Plugging this into equation 32, we obtain: \u2225\u2113(f\u03b8(\u03bb\u22c6p))\u2212 \u2113(\u03d5(\u03bb\u22c6u))\u2225\u221e \u2264 Mm1/4 \u221a 2 M\u03bd\n\u00b50 (1 + \u2225\u03bb\u22c6p\u22251)\n[ 1 +m1/4 M\n\u03c3\n\u03b2\n\u00b50 (1 + \u2206)\n]\n\u2264 M \u221a 2 M\u03bd\n\u00b50 (1 + \u2225\u03bb\u22c6p\u22251)\n[ 1 + M\n\u03c3\n\u03b2\n\u00b50 (1 + \u2206)\n]\u221a m\nFinally, using the definitions of the condition numbers \u03ba1 = M\u03c3 , \u03ba2 = \u03b2 \u00b50 we obtain:\n\u2225\u2113(f\u03b8(\u03bb\u22c6p))\u2212 \u2113(\u03d5(\u03bb\u22c6u))\u2225\u221e \u2264 M [1 + \u03ba1\u03ba2(1 + \u2206)] \u221a 2m M\u03bd\n\u00b50 (1 + \u2225\u03bb\u22c6p\u22251) (33)\nwhich conludes the proof."
        },
        {
            "heading": "A.14 PROOF PROPOSITION 4.1",
            "text": "A similar proof in the context of resource allocation for wireless communications can be found in (Ribeiro, 2010), Theorem 2. To ease the notation, we will denote the value of the parametrized dual function at iteration t by g(t) := gp(\u03bb(t)). Similarly, gbest(t) will denote the largest value of g(t) encountered so far. As described in section 4, expected values are taken with respect to (x, y) \u223c Di. We start by deriving a recursive inequality between the distances of iterates \u03bb(t) and an optimal dual variable \u03bb\u22c6p \u2208 argmax\u03bb\u2ab00 gp(\u03bb).\nProposition A.14 Consider the dual ascent algorithm described in Section 4 using a constant step size \u03b7 > 0. Then,\nE{\u2225\u03bb(t+ 1)\u2212 \u03bb\u22c6p\u22252|\u03bb(t)} \u2264 \u2225\u03bb(t)\u2212 \u03bb\u22c6p\u22252 + \u03b72S2 \u2212 2\u03b7(D\u22c6p \u2212 g(t)) (34)\nWe can observe that as the optimality gap D\u22c6p \u2212 g(t) decreases, the term 2\u03b7(D\u22c6p \u2212 g(t)) eventually becomes smaller than the fixed term \u03b72S2, suggesting convergence of \u03bb(t) only to a neighborhood of \u03bb\u22c6p. In order to show this, the main obstacle is that Proposition A.14 bounds the expected value of \u2225\u03bb(t + 1) \u2212 \u03bb\u22c6p\u22252 and we wish to establish almost sure convergence. This can be addressed by leveraging the Supermartingale Convergence Theorem (see e.g, (Solo & Kong, 1994) Theorem E7.4), which we state here for completeness.\nTheorem A.15 Consider nonnegative stochastic processes A(N) and B(N) with realizations \u03b1(N) and \u03b2(N) having values \u03b1(t) \u2265 0 and \u03b2(t) \u2265 0 and a sequence of nested \u03c3-algebras A(0 : t) measuring at least \u03b1(0 : t) and \u03b2(0 : t). If\nE[\u03b1(t+ 1) | A(0 : t)] \u2264 \u03b1(t)\u2212 \u03b2(t) (35)\nthe sequence \u03b1(t) converges almost surely and \u03b2(t) is almost surely summable, i.e., \u2211\u221e\nu=1 \u03b2(u) < \u221e a.s.\nWe define \u03b1(t) and \u03b2(t) as follows, \u03b1(t) := \u2225\u03bb(t)\u2212 \u03bb\u22c6p\u22252 I { D\u22c6p \u2212 gbest(t) > \u03b7S2\n2 } \u03b2(t) := [2\u03b7(D\u22c6p \u2212 g(t))\u2212 \u03b72S2] I { D\u22c6p \u2212 gbest(t) > \u03b7S2\n2 } Note that \u03b1(t) tracks \u2225\u03bb(t)\u2212 \u03bb\u22c6p\u22252 until the optimality gap D\u22c6p \u2212 gbest(t) falls bellow the threshold \u03b7S2\n2 and is then set to 0. Similarly, \u03b2(t) tracks 2\u03b7(D \u22c6 p \u2212 g(t)) \u2212 \u03b72S2 until the optimality gap D\u22c6p \u2212 gbest(t) falls bellow the same threshold and is then set to 0. It is clear that \u03b1(t) \u2265 0, since it is the product of a norm and an indicator function. The same holds for \u03b2(t), since the indicator evaluates to 0 whenever 2\u03b7(D\u22c6p \u2212 g(t)) \u2212 \u03b72S2 \u2264 0. We thus have, \u03b1(t), \u03b2(t) \u2265 0 for all t. In what follows, we will leverage Theorem A.15 to show that \u03b2(t) is almost surely summable, which will lead to the wanted result.\nLet A(0 : t) be a sequence of \u03c3-algebras measuring \u03b1(0 : t), \u03b2(0 : t) and \u03bb(0 : t). We will show that \u03b1(t) and \u03b2(t) satisfy the hypothesis of Theorem A.15 with respect to A(0 : t). Note that at each iteration, \u03b1(t) and \u03b2(t) are fully determined by \u03bb(t). Therefore, conditioning on A(0 : t) is equivalent to conditioning on \u03bb(t), i.e: E{\u03b1(t)|A(0 : t)} = E{\u03b1(t)|\u03bb(t)}. Then we can write,\nE{\u03b1(t)|A(0 : t)} =E{\u03b1(t)|\u03bb(t), \u03b1(t) = 0}P{\u03b1(t) = 0} + E{\u03b1(t)|\u03bb(t), \u03b1(t) > 0}P{\u03b1(t) > 0} (36)\nFrom equation 36, we will derive that E{\u03b1(t)|A(0 : t)} \u2264 \u03b1(t) \u2212 \u03b2(t) which is the remaining hypothesis in Theorem A.15.\nOn one hand, observe that if \u03b1(t) = 0 we have that I{D\u22c6p \u2212 gbest(t) \u2264 \u03b7S 2 2 } = 0. This is because in the case where \u2225\u03bb(t)\u2212 \u03bb\u22c6p\u22252 = 0, the indicator function also evaluates to 0. Therefore, if \u03b1(t) = 0, it must be that \u03b2(t) = 0. Then, trivially, E{\u03b1(t)|\u03bb(t), \u03b1(t) = 0} = \u03b1(t)\u2212 \u03b2(t). On the other hand, when \u03b1(t) > 0:\nE[\u03b1(t+ 1) | \u03bb(t), \u03b1(t) > 0] (37)\n= E {\u2225\u2225\u03bb(t+ 1)\u2212 \u03bb\u22c6p\u2225\u22252 I { D\u22c6p \u2212 gbest(t+ 1) > \u03b7S\u03022\n2\n} | \u03bb(t) } (38)\n= E {\u2225\u2225\u03bb(t+ 1)\u2212 \u03bb\u22c6p\u2225\u22252 | \u03bb(t)} (39)\nwhere we used the definition of \u03b1(t+ 1) and the fact the the indicator function needs to evaluate to 1 since \u03b1(t) > 0. Then, from proposition A.14 we have:\nE[\u03b1(t+ 1) | \u03bb(t), \u03b1(t) > 0] \u2264 \u2225\u2225\u03bb(t)\u2212 \u03bb\u22c6p\u2225\u22252 + \u03b72S2 \u2212 2\u03b7(D\u22c6p \u2212 g(t)) (40)\n= \u03b1(t)\u2212 \u03b2(t). (41) where the last equality comes from the fact that \u03b1(t) > 0 implies I { D\u22c6p \u2212 gbest(t+ 1) > \u03b7S\u0302 2\n2\n} = 1.\nThis means that we can write equation 36 as:\nE{\u03b1(t)|A(0 : t)} \u2264 [\u03b1(t)\u2212 \u03b2(t)](P{\u03b1(t) = 0}+ P{\u03b1(t) > 0}) = \u03b1(t)\u2212 \u03b2(t) (42)\nwhich shows that \u03b1(t) and \u03b2(t) satisfy the hypothesis of Theorem A.15. Then, we have that \u03b2(t) is almost surely summable, which implies,\nlim inf t\u2192\u221e\n[ 2\u03b7(D\u22c6p \u2212 g(t))\u2212 \u03b72S2 ] I{D\u22c6p \u2212 gbest(t) > \u03b7S\u03022/2} = 0 a.s.\nThis is true if either D\u22c6p\u2212gbest(t) \u2264 \u03b7S 2 2 for some t, or if lim inft\u2192\u221e [ 2\u03b7(D\u22c6p \u2212 g(t))\u2212 \u03b72S2 ] = 0, which concludes the proof."
        },
        {
            "heading": "A.14.1 PROOF PROPOSITION A.14",
            "text": "We want to show that\nE{\u2225\u03bb(t+ 1)\u2212 \u03bb\u22c6p\u22252|\u03bb(t)} \u2264 \u2225\u03bb(t)\u2212 \u03bb\u22c6p\u22252 + \u03b72S2 \u2212 2\u03b7(D\u22c6p \u2212 g(t)) (43)\nWe start from the definition of \u03bb(t+ 1):\n\u2225\u03bb(t+ 1)\u2212 \u03bb\u22c6p\u22252 = \u2225[\u03bb(t) + \u03b7s\u0302(t)]+ \u2212 \u03bb\u22c6p\u22252\n\u2264 \u2225\u03bb(t)\u2212 \u03bb\u22c6p + \u03b7s\u0302(t)\u22252 = \u2225\u03bb(t)\u2212 \u03bb\u22c6p\u22252 + \u03b72\u2225s\u0302(t)\u22252 + 2\u03b7s\u0302(t)T (\u03bb(t)\u2212 \u03bb\u22c6p) (44)\nwhere we used the fact that setting the negative components of \u03bb(t)+\u03b7s\u0302(t) to 0 decreases its distance to the positive vector \u03bb\u22c6p and then expanded the square.\nNote that for a given \u03bb(t), the relations in 44 hold for all realizations of s\u0302(t). Thus, the expectation of \u2225\u03bb(t+ 1)\u2212 \u03bb\u22c6p\u2225, conditioned on \u03bb(t) satisifes:\nE{\u2225\u03bb(t+1)\u2212\u03bb\u22c6p\u22252|\u03bb(t)} \u2264 \u2225\u03bb(t)\u2212\u03bb\u22c6p\u22252+\u03b72E{\u2225s\u0302(t)\u22252|\u03bb(t)}+2\u03b7E{s\u0302(t)|\u03bb(t)}(\u03bb(t)\u2212\u03bb\u22c6p) (45)\nFinally, recall that E{s\u0302(t)|\u03bb(t)} is a supergradient of the concave dual function gp(\u03bb), that is: E{s\u0302(t)|\u03bb(t)}(\u03bb(t)\u2212 \u03bb) \u2264 g(t)\u2212 gp(\u03bb) . (46)\nEvaluating the previous inequality at \u03bb\u22c6p and combining it with equation 45 we obtain:\nE{\u2225\u03bb(t+ 1)\u2212 \u03bb\u22c6p\u22252|\u03bb(t)} \u2264 \u2225\u03bb(t)\u2212 \u03bb\u22c6p\u22252 + \u03b72S2 + 2\u03b7(g(t)\u2212D\u22c6p) (47) which concludes the proof."
        },
        {
            "heading": "A.15 PROOF PROPOSITION 4.2",
            "text": "We will bound the distance between \u2113(\u03d5(\u03bb\u22c6u)) and L(f\u03b8(\u03bb best))) by partioning it into terms that are similar to those we have previously analyzed in Corollary 3.10 and Proposition 3.11:\n\u2225\u2113(\u03d5(\u03bb\u22c6u))\u2212 \u2113(f\u03b8(\u03bbbest)))\u22252 \u2264 \u2225\u2113(\u03d5(\u03bb\u22c6u))\u2212 \u2113(\u03d5(\u03bbbest))\u22252 + \u2225\u2113(\u03d5(\u03bbbest))\u2212 \u2113(f\u03b8(\u03bbbest))\u22252\nThe first term is of the same nature as the one analyzed in Corollary 3.10, since it is characterizes a perturbation in dual variables in the unparametrized problem. Thus, using the characterization of the curvature of the dual function from proposition A.7 and the sub-optimality of \u03bbbest with respect to \u03bb\u22c6p, this term can be bounded.\nWe will denote by B\u03bbbest the segment connecting \u03bbbest and \u03bb\u22c6u and by \u00b5\u0303g the strong concavity constant of gu in B\u03bbbest . Proceeding exactly as in the proof of Propositon A.7 we obtain:\n\u2225\u03bbbest \u2212 \u03bb\u22c6u\u222522 \u2264 2\n\u00b5\u0303g (gu(\u03bb\n\u22c6 u)\u2212 gu(\u03bbbest))\n\u2264 2 \u00b5\u0303g (gp(\u03bb \u22c6 p)\u2212\n( gp(\u03bb best)\u2212M\u03bd(1 + \u2225\u03bbbest\u22251) )\nwhere we used Lemma A.5 and the fact that gp(\u03bb\u22c6p) \u2265 gu(\u03bb\u22c6u).\nThen, leveraging the almost sure convergence shown in Proposition 4.1 we have:\n\u2225\u03bbbest \u2212 \u03bb\u22c6u\u222522 \u2264 2\n\u00b5\u0303g\n( M\u03bd(1 + \u2225\u03bbbest\u22251) + \u03b7S2\n2 + \u03b4\n) (48)\nThus,\n\u2225\u2113(\u03d5(\u03bbbest))\u2212 \u2113(\u03d5(\u03bb\u22c6u))\u222522 = \u2225\u2207\u03bbgu(\u03bbbest)\u2212\u2207\u03bbgu(\u03bb\u22c6u)\u222522 (49) \u2264 \u03b22g\u2225\u03bbbest \u2212 \u03bb\u22c6u\u222522 (50)\n\u2264 2\u03b2 2 g\n\u00b5\u0303g\n( M\u03bd(1 + \u2225\u03bbbest\u22251) + \u03b7S2\n2 + \u03b4\n) (51)\nwhich completes the first part of the proof.\nThe term \u2225\u2113(\u03d5(\u03bbbest))\u2212 \u2113(f\u03b8(\u03bbbest))\u22252 captures a perturbation in the function class for a fixed dual variable, and can be analyzed similarly to Proposition 3.11. Let \u03f5\u0303u = \u2212\u2113(\u03d5(\u03bbbest)) and \u03f5\u0303p = \u2212\u2113(f\u03b8(\u03bbbest)). Using the same arguments as in Lemma A.11, Proposition A.13 and Corollary A.9 we have that:\n1. P \u2217(\u03f5) is strongly convex with constant 1\u03b2g on B\u03bbbest 2. \u03bbbest \u2208 \u2202P (\u03f5\u0303u) 3. P \u2217(\u03f5\u0303p)\u2212 P \u2217(\u03f5\u0303u) \u2264 M\u03bd(1 + \u2225\u03bbbest\u22251) + \u03bbbest T (\u03f5\u0303p \u2212 \u03f5\u0303u)\nLet \u2206\u03f5\u0303 = \u03f5\u0303p \u2212 \u03f5\u0303u. Combining the aforementioned properties as done in Theorem 3.11 yields:\nM\u03bd(1 + \u2225\u03bbbest\u22251) + \u03bbbest T \u2206\u03f5\u0303 \u2265 \u03bbbestT\u2206\u03f5\u0303+ 1 2\u03b2g \u2225\u2206\u03f5\u0303\u222522 (52)\nwhich implies:\n\u2225\u2206\u03f5\u0303\u222522 \u2264 2\u03b2gM\u03bd(1 + \u2225\u03bbbest\u22251) (53)\nCombining the bounds in equations 51 and 53 we obtain:\n\u2225\u2113(\u03d5(\u03bb\u22c6u))\u2212 \u2113(f\u03b8(\u03bbbest)))\u22252 (54)\n\u2264 \u221a 2\u03b2gM\u03bd(1 + \u2225\u03bbbest\u22251) + \u221a\n2\u03b22g \u00b5\u0303g\n( M\u03bd(1 + \u2225\u03bbbest\u22251) + \u03b7S2\n2 + \u03b4\n) (55)\n= \u221a 2\u03b2gM\u03bd(1 + \u2225\u03bbbest\u22251) ( 1 + (1 + \u03b7S2\n2 + \u03b4) \u221a \u03b2g \u00b5g ) (56)\nTaking squares on both sides concludes the proof."
        }
    ],
    "year": 2023
}