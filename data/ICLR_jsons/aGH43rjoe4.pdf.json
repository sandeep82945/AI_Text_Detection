{
    "abstractText": "Characterizing the relationship between neural population activity and behavioral data is a central goal of neuroscience. While latent variable models (LVMs) are successful in describing high-dimensional time-series data, they are typically only designed for a single type of data, making it difficult to identify structure shared across different experimental data modalities. Here, we address this shortcoming by proposing an unsupervised LVM which extracts temporally evolving shared and independent latents for distinct, simultaneously recorded experimental modalities. We do this by combining Gaussian Process Factor Analysis (GPFA), an interpretable LVM for neural spiking data with temporally smooth latent space, with Gaussian Process Variational Autoencoders (GP-VAEs), which similarly use a GP prior to characterize correlations in a latent space, but admit rich expressivity due to a deep neural network mapping to observations. We achieve interpretability in our model by partitioning latent variability into components that are either shared between or independent to each modality. We parameterize the latents of our model in the Fourier domain, and show improved latent identification using this approach over standard GP-VAE methods. We validate our model on simulated multi-modal data consisting of Poisson spike counts and MNIST images that scale and rotate smoothly over time. We show that the multi-modal GP-VAE (MM-GPVAE) is able to not only identify the shared and independent latent structure across modalities accurately, but provides good reconstructions of both images and neural rates on held-out trials. Finally, we demonstrate our framework on two real world multimodal experimental settings: Drosophila whole-brain calcium imaging alongside tracked limb positions, and Manduca sexta spike train measurements from ten wing muscles as the animal tracks a visual stimulus.",
    "authors": [],
    "id": "SP:35f49bbb9e88db5487a11130654ef640e0606931",
    "references": [
        {
            "authors": [
                "M. Aoi",
                "J.W. Pillow"
            ],
            "title": "Scalable bayesian inference for high-dimensional neural receptive fields. bioRxiv, page 212217",
            "year": 2017
        },
        {
            "authors": [
                "M.C. Aoi",
                "V. Mante",
                "J.W. Pillow"
            ],
            "title": "Prefrontal cortex exhibits multidimensional dynamic encoding during decision-making",
            "venue": "Nature neuroscience,",
            "year": 2020
        },
        {
            "authors": [
                "G. Bahg",
                "D.G. Evans",
                "M. Galdo",
                "B.M. Turner"
            ],
            "title": "Gaussian process linking functions for mind, brain, and behavior",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 2020
        },
        {
            "authors": [
                "E. Balzani",
                "J.P. Noel",
                "P. Herrero-Vidal",
                "D.E. Angelaki",
                "C. Savin"
            ],
            "title": "A probabilistic framework for task-aligned intra-and inter-area neural manifold estimation",
            "venue": "arXiv preprint arXiv:2209.02816",
            "year": 2022
        },
        {
            "authors": [
                "M. Brenner",
                "G. Koppe",
                "D. Durstewitz"
            ],
            "title": "Multimodal teacher forcing for reconstructing nonlinear dynamical systems",
            "venue": "arXiv preprint arXiv:2212.07892",
            "year": 2022
        },
        {
            "authors": [
                "F.P. Casale",
                "A.V. Dalca",
                "L. Saglietti",
                "J. Listgarten",
                "N. Fusi"
            ],
            "title": "Gaussian process prior variational autoencoders",
            "venue": "arXiv preprint arXiv:1810.11738",
            "year": 2018
        },
        {
            "authors": [
                "L. Duncker",
                "M. Sahani"
            ],
            "title": "Temporal alignment and latent gaussian process factor inference in population spike trains",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2018
        },
        {
            "authors": [
                "V. Fortuin",
                "D. Baranchuk",
                "G. R\u00e4tsch",
                "S. Mandt"
            ],
            "title": "Gp-vae: Deep probabilistic time series imputation",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2020
        },
        {
            "authors": [
                "G. Gundersen",
                "B. Dumitrascu",
                "J.T. Ash",
                "B.E. Engelhardt"
            ],
            "title": "End-to-end training of deep probabilistic cca on paired biomedical observations",
            "venue": "In Uncertainty in artificial intelligence",
            "year": 2019
        },
        {
            "authors": [
                "J. Hensman",
                "N. Durrande",
                "A. Solin"
            ],
            "title": "Variational fourier features for gaussian processes",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2017
        },
        {
            "authors": [
                "D. Hernandez",
                "A.K. Moretti",
                "Z. Wei",
                "S. Saxena",
                "J. Cunningham",
                "L. Paninski"
            ],
            "title": "Nonlinear evolution via spatially-dependent linear dynamics for electrophysiology and calcium",
            "year": 2018
        },
        {
            "authors": [
                "C. Hurwitz",
                "A. Srivastava",
                "K. Xu",
                "J. Jude",
                "M. Perich",
                "L. Miller",
                "M. Hennig"
            ],
            "title": "Targeted neural dynamical modeling",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "S. Keeley",
                "M. Aoi",
                "Y. Yu",
                "S. Smith",
                "J.W. Pillow"
            ],
            "title": "Identifying signal and noise structure in neural population activity with gaussian process factor models",
            "venue": "Advances in neural information processing systems,",
            "year": 2020
        },
        {
            "authors": [
                "S. Keeley",
                "D. Zoltowski",
                "Y. Yu",
                "S. Smith",
                "J. Pillow"
            ],
            "title": "Efficient non-conjugate gaussian process factor models for spike count data using polynomial approximations",
            "venue": "In International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "D.P. Kingma",
                "M. Welling"
            ],
            "title": "Auto-encoding variational bayes",
            "venue": "arXiv preprint arXiv:1312.6114",
            "year": 2013
        },
        {
            "authors": [
                "M. Kleinman",
                "A. Achille",
                "S. Soatto",
                "J. Kao"
            ],
            "title": "Gacs-korner common information variational autoencoder",
            "venue": "arXiv preprint arXiv:2205.12239",
            "year": 2022
        },
        {
            "authors": [
                "S. Linderman",
                "M. Johnson",
                "A. Miller",
                "R. Adams",
                "D. Blei",
                "L. Paninski"
            ],
            "title": "Bayesian learning and inference in recurrent switching linear dynamical systems",
            "venue": "In Artificial Intelligence and Statistics,",
            "year": 2017
        },
        {
            "authors": [
                "J. Loper",
                "D. Blei",
                "J.P. Cunningham",
                "L. Paninski"
            ],
            "title": "A general linear-time inference method for gaussian processes on one dimension",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2021
        },
        {
            "authors": [
                "V. Mante",
                "D. Sussillo",
                "K.V. Shenoy",
                "W.T. Newsome"
            ],
            "title": "Context-dependent computation by recurrent dynamics in prefrontal cortex",
            "year": 2013
        },
        {
            "authors": [
                "A. Mathis",
                "P. Mamidanna",
                "K.M. Cury",
                "T. Abe",
                "V.N. Murthy",
                "M.W. Mathis",
                "M. Bethge"
            ],
            "title": "Deeplabcut: markerless pose estimation of user-defined body parts with deep learning",
            "venue": "Nature neuroscience,",
            "year": 2018
        },
        {
            "authors": [
                "C.J. Paciorek"
            ],
            "title": "Bayesian smoothing with gaussian processes using fourier basis functions in the spectralgp package",
            "venue": "Journal of statistical software,",
            "year": 2007
        },
        {
            "authors": [
                "F. Pei",
                "J. Ye",
                "D. Zoltowski",
                "A. Wu",
                "R.H. Chowdhury",
                "H. Sohn",
                "J.E. O\u2019Doherty",
                "K.V. Shenoy",
                "M.T. Kaufman",
                "M Churchland"
            ],
            "title": "Neural latents benchmark\u201921: evaluating latent variable models of neural population activity",
            "venue": "arXiv preprint arXiv:2109.04463",
            "year": 2021
        },
        {
            "authors": [
                "J. Putney",
                "R. Conn",
                "S. Sponberg"
            ],
            "title": "Precise timing is ubiquitous, consistent, and coordinated across a comprehensive, spike-resolved flight motor program",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 2019
        },
        {
            "authors": [
                "S. Ramchandran",
                "G. Tikhonov",
                "K. Kujanp\u00e4\u00e4",
                "M. Koskinen",
                "H. L\u00e4hdesm\u00e4ki"
            ],
            "title": "Longitudinal variational autoencoder",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2021
        },
        {
            "authors": [
                "O.G. Sani",
                "H. Abbaspourazad",
                "Y.T. Wong",
                "B. Pesaran",
                "M.M. Shanechi"
            ],
            "title": "Modeling behaviorally relevant neural dynamics enabled by preferential subspace identification",
            "venue": "Nature Neuroscience,",
            "year": 2021
        },
        {
            "authors": [
                "S. Saxena",
                "J.P. Cunningham"
            ],
            "title": "Towards the neural population doctrine",
            "venue": "Current opinion in neurobiology,",
            "year": 2019
        },
        {
            "authors": [
                "E.S. Schaffer",
                "N. Mishra",
                "M.R. Whiteway",
                "W. Li",
                "M.B. Vancura",
                "J. Freedman",
                "K.B. Patel",
                "V. Voleti",
                "L. Paninski",
                "Hillman",
                "E. M"
            ],
            "title": "Flygenvectors: the spatial and temporal structure of neural activity across the fly brain. bioRxiv, pages 2021\u201309",
            "year": 2021
        },
        {
            "authors": [
                "S. Schneider",
                "J.H. Lee",
                "M.W. Mathis"
            ],
            "title": "Learnable latent embeddings for joint behavioural and neural analysis",
            "year": 2023
        },
        {
            "authors": [
                "Y. Shi",
                "B. Paige",
                "P Torr"
            ],
            "title": "Variational mixture-of-experts autoencoders for multi-modal deep generative models",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "U.B. Sikandar",
                "H. Choi",
                "J. Putney",
                "H. Yang",
                "S. Ferrari",
                "S. Sponberg"
            ],
            "title": "Predicting visually-modulated precisely-timed spikes across a coordinated and comprehensive motor program",
            "year": 2023
        },
        {
            "authors": [
                "J. Singh Alvarado",
                "J. Goffinet",
                "V. Michael",
                "W. Liberti III",
                "J. Hatfield",
                "T. Gardner",
                "J. Pearson",
                "R. Mooney"
            ],
            "title": "Neural dynamics underlying birdsong practice and performance",
            "year": 2021
        },
        {
            "authors": [
                "J.D. Sprayberry",
                "T.L. Daniel"
            ],
            "title": "Flower tracking in hawkmoths: behavior and energetics",
            "venue": "Journal of Experimental Biology,",
            "year": 2007
        },
        {
            "authors": [
                "V. Voleti",
                "K.B. Patel",
                "W. Li",
                "C. Perez Campos",
                "S. Bharadwaj",
                "H. Yu",
                "C. Ford",
                "M.J. Casper",
                "R.W. Yan",
                "W Liang"
            ],
            "title": "Real-time volumetric microscopy of in vivo dynamics and large-scale samples with scape 2.0",
            "venue": "Nature methods,",
            "year": 2019
        },
        {
            "authors": [
                "M.R. Whiteway",
                "E.S. Schaffer",
                "A. Wu",
                "E.K. Buchanan",
                "O.F. Onder",
                "N. Mishra",
                "L. Paninski"
            ],
            "title": "Semi-supervised sequence modeling for improved behavioral segmentation",
            "year": 2021
        },
        {
            "authors": [
                "A. Wilson",
                "R. Adams"
            ],
            "title": "Gaussian process kernels for pattern discovery and extrapolation",
            "venue": "In International conference on machine learning,",
            "year": 2013
        },
        {
            "authors": [
                "A. Wu",
                "N.A. Roy",
                "S. Keeley",
                "J.W. Pillow"
            ],
            "title": "Gaussian process based nonlinear latent structure discovery in multivariate spike train data",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "M. Wu",
                "N. Goodman"
            ],
            "title": "Multimodal generative models for scalable weakly-supervised learning",
            "venue": "Advances in neural information processing systems,",
            "year": 2018
        },
        {
            "authors": [
                "B. Yu",
                "J. Cunningham",
                "G. Santhanam",
                "S. Ryu",
                "K. Shenoy",
                "M. Sahani"
            ],
            "title": "Gaussianprocess factor analysis for low-d single-trial analysis of neural population activity",
            "venue": "In Frontiers in Systems Neuroscience. Conference Abstract: Computational and systems neuroscience",
            "year": 2009
        },
        {
            "authors": [
                "B.M. Yu",
                "J.P. Cunningham",
                "G. Santhanam",
                "S. Ryu",
                "K.V. Shenoy",
                "M. Sahani"
            ],
            "title": "Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity",
            "venue": "Advances in neural information processing systems,",
            "year": 2008
        },
        {
            "authors": [
                "C. Yu",
                "H. Soulat",
                "N. Burgess",
                "M. Sahani"
            ],
            "title": "Amortised inference in structured generative models with explaining away",
            "venue": "arXiv preprint arXiv:2209.05212",
            "year": 2022
        },
        {
            "authors": [
                "Y. Zhao",
                "I.M. Park"
            ],
            "title": "Variational latent gaussian process for recovering single-trial dynamics from population spike trains",
            "venue": "Neural computation,",
            "year": 2017
        },
        {
            "authors": [
                "D. Zhou",
                "Wei",
                "X.-X"
            ],
            "title": "Learning identifiable and interpretable latent models of highdimensional neural activity using pi-vae",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Recent progress in experimental neuroscience has enabled researchers to record from a large number of neurons while animals perform naturalistic behaviors in sensory-rich environments. An important prerequisite to analyzing these data is to identify how the high-dimensional neural data is related to the corresponding behaviors and environmental settings. Traditionally, researchers often employ a two-step approach, involving first dimensionality reduction on neural data followed by a post-hoc investigation of the latent structure of neural recordings with respect to experimental variables of interest such as stimuli or behavior (Wu et al., 2017; Zhao and Park, 2017; Saxena and Cunningham, 2019; Bahg et al., 2020; Pei et al., 2021). Researchers may also specifically design latent variable models (LVMs) that extract low-dimensional structure in neural data using these experimental variables of interest (Aoi et al., 2020; Mante et al., 2013; Zhou and Wei, 2020; Hernandez et al., 2018). However, recent deep learning advancements allow for both experimental and behavioral variables to be part of a single latent-variable model (Schneider et al., 2023; Hurwitz et al., 2021; Sani et al., 2021; Singh Alvarado et al., 2021), thus opening a new avenue for unsupervised discoveries on the relationship between neural activity and behavior.\nThe existing approaches that jointly model neural activity and behavior are limited in that they often rely on a single latent space to describe data from both modalities (Schneider et al., 2023; Hurwitz et al., 2021), making it difficult for practitioners to isolate latent features that are shared across and independent to neural activity or behavior. Approaches that do isolate modality specific and shared latent structure either do so with no temporal structure (Gundersen et al., 2019; Kleinman et al., 2022;\nSingh Alvarado et al., 2021; Wu and Goodman, 2018; Shi et al., 2019; Brenner et al., 2022), or use a relatively inflexible linear dynamical system (Sani et al., 2021). Moreover, because of the deep neural network mapping from latents to observations, such existing multi-modal approaches generate latent spaces that are not obviously related to experimental variables of interest, and so additional ad hoc model features are often added to aid in interpretability and analysis in neuroscience settings (Schneider et al., 2023; Hurwitz et al., 2021; Zhou and Wei, 2020).\nHowever, LVMs developed for neural data often are able to uncover interpretable features using neural activity alone in an unsupervised fashion with minimal a priori assumptions. One example of these is Gaussian Process Factor Analysis (GPFA), a widely used LVM in neuroscience that finds smoothly evolving latent dynamics in neural population activity, and can illustrate different aspects of neural processing (Yu et al., 2008; Duncker and Sahani, 2018; Keeley et al., 2020a;b; Balzani et al., 2022). GPFA constrains the latent space of neural activity through the use of a Gaussian Process (GP) prior. GP priors have also been adapted to regularize the latent space of variational autoencoders (GP-VAE or GP-prior VAE) with a variety of applications (Casale et al., 2018; Fortuin et al., 2020; Ramchandran et al., 2021; Yu et al., 2022). In each of these approaches, the GP prior provides a flexible constraint in the latent dimension, specifying correlations across auxiliary observations like viewing angle, lighting, or time. The GP prior often is used for out-of-sample prediction in GP-VAEs, but in GPFA is frequently used to visualize latent structure in noisy neural population activity on a trial-by-trial basis (Duncker and Sahani, 2018; Zhao and Park, 2017; Keeley et al., 2020a). Here, we wish to leverage the interpretability seen in unsupervised GPFA models with the power of GP-VAEs to use with multi-modal time-series datasets in neuroscience.\nWe propose a model for jointly observed neural and behavioral data that partitions shared and independent latent subspaces across data modalities while flexibly preserving temporal correlations using a GP prior. We call this the multi-modal Gaussian Process variational autoencoder (MMGPVAE). Our first innovation is to parameterize the latent space time-series in terms of a small number of Fourier frequencies, an approach that has been used before in the linear GPFA setting (Paciorek, 2007; Aoi and Pillow, 2017; Keeley et al., 2020a). We show that the Fourier representation dramatically improves latent identification for the standard GP-VAE. Our second innovation is to augment our new Fourier GP-VAE model to describe two data modalities simultaneously by mapping the latents linearly to neural data (like in GPFA), as well as nonlinearly to another experimental variable via a deep neural network (like a GP-VAE). We leave the specific identity of this other experimental modality intentionally vague - it could be keypoints of limb positions as animals freely move or visual stimuli across time. Because this observation modality is characterized by a deep neural network, our model can be adapted to any additional experimental variable of interest.\nWe validate our MM-GPVAE model on a simulated dataset of a smoothly rotating and scaling MNIST digit alongside simulated Poisson neural activity, whereby the digit data and the spiking data share latent structure. We show that the MM-GPVAE model is able to recover both shared and independent latent structures while simultaneously providing accurate reconstructions of data from both modalities. Lastly, we demonstrate the utility of our model by fitting the MM-GPVAE to two real-world multi-modal neural datasets: 1) Drosophila (fly) whole-brain calcium imaging alongside tracked 16 limb positions, and 2) Manduca sexta (hawkmoth) spike train measurements from ten wing muscles alongside a continuously moving visual stimulus. In the former case, we demonstrate that the neural and shared subspaces best separate Drosophila behavioral conditions and in the latter case, we show distinct time-varying latent components tracking muscle and stimuli movement in the experiment. By showing the MM-GPVAE in these two domains, we demonstrate that our model is adaptable to a range of diverse experimental preparations in systems neuroscience."
        },
        {
            "heading": "2 THE GAUSSIAN PROCESS VARIATIONAL AUTOENCODER",
            "text": "The Gaussian Process variational autoencoder (GPVAE) uses high-dimensional data (e.g. images) accompanied by auxiliary information, like viewing angle, lighting, object identity, or observation time. This auxiliary information provides the indices in the GP prior latent representation, specifying correlations across the latent space and allowing for out-of-sample predictions at new auxiliary values (Casale et al., 2018; Fortuin et al., 2020; Ramchandran et al., 2021). However, in our case we consider continuously observed time-series data in experimental neuroscience experiments, so our auxiliary\ninformation here are evenly sampled time-bins. Because of this, we can leverage the advantages of the Fourier-domain GP representation (Aoi and Pillow, 2017; Keeley et al., 2020b; Paciorek, 2007).\nFormally, consider smoothly-varying image data across timepoints, represented by the pixels-by-time matrix Y \u2208 NN\u00d7T . For latent variable z(t) \u2208 IRP each latent zp(t) (t \u2208 {1, 2 . . . T}) evolves according to a Gaussian process, zp(t) \u223c GP(0, k\u03b8(\u00b7, \u00b7)), with covariance kernel k\u03b8. The time-bytime covariance matrix of each zp(t) is then given by the Gram matrix K\u03b8 corresponding to k\u03b8. We use a squared exponential (RBF) kernel for K governed by a marginal variance and length scale \u03b8 = {\u03c1, \u2113} with an additive diagonal term \u03b1I to help with inference (Yu et al., 2009; Casale et al., 2018). The likelihood of the image data is Gaussian with mean given by the latent values at any timepoint t passed through a deep neural network g\u03c8(\u00b7) with parameters \u03c8 and whose covariance is \u03c32yI .\nThe GP-VAE is learned using standard VAE amortized inference (Kingma and Welling, 2013), where the parameters \u00b5\u03c8 and \u03c32\u03c8 of a variational distribution q\u03d5 are given as neural network functions of the observed data Y. Here, the evidence lower bound (ELBO) is maximized with respect to the variational parameters \u03d5, model parameters \u03c8, and GP hyperparameters. In this work, \u03b1 is set to a fixed value of 1e\u22122 for all experiments except for the final data analysis example, where it is set to a value of 1e\u22124. While the ELBO may be expressed in a variety of ways, we will follow the form that includes the variational entropy term. For details about this approach for the standard GP-VAE, see (Casale et al., 2018)."
        },
        {
            "heading": "2.1 FOURIER-DOMAIN REPRESENTATION OF THE GP-VAE",
            "text": "We consider a version of the GP-VAE whose auxiliary variables are a Fourier frequency representation of the time domain, as opposed to timepoints sampled on a regular lattice. This allows us to parameterize a frequency representation of the latent variables that is Gaussian distributed according to a z\u0303(\u03c9) \u223c N (0, K\u0303p) where the original RBF GP covariance matrix K may be diagonalized by K\u0303 = BKB\u22a4 Here, B is the orthonormal discrete Fourier transform matrix and \u03c9 \u2208 0, 1, 2 . . .F represents the frequency. The model prior can now be written as\np(Z\u0303 | \u03c9,\u03b8, \u03b1) = P\u220f p=1 N ( z\u0303p | 0, K\u0303\u03b8(\u03c9) + \u03b1IF ) (1)\nWhere \u03c9 represents a F -values long vector of Fourier frequencies, and Z\u0303 represents a P \u00d7 F matrix of the frequency representation of the P latent variables at the F frequencies. The model likelihood retains the same form as the standard GP-VAE.\np(Y |Z, \u03d5, \u03c32) = T\u220f t=1 N (g\u03d5(zt), \u03c32IT ) (2)\nWhere zt represents the tth time index of Z, a P \u00d7 T matrix where each row is the time-domain representation of the pth latent, given by zp = Bz\u0303p.\nWe define the variational posterior so that it factorizes over the Fourier frequencies. The variational distribution can be written as\nq\u03c8(Z\u0303 i | Y i) = \u220f \u03c9 N ( z\u0303i\u03c9 | \u00b5\u0303\u03c8 ( Y i ) ,diag ( \u03c3\u03032\u03c8 ( Y i ))) , (3)\nwhere i indexes a trial of times-series images Y . Training is done by batches over a subset of trials. In contrast to the standard GP-VAE (Casale et al., 2018), the Fourier representation requires that, for each trial, images at all timepoints are mapped to a single P \u00d7 F -dimensional Fourier representation. We accomplish this in two steps - first, we use a deep neural network for each image at each time point yit, which will result in T total network embeddings for a single trial, each of dimension P . We follow that with a single linear layer each for the mean and variance of the variational distribution, l\u00b5\u0303(\u00b7), l\u03c3\u03032(\u00b7), that will map from the number of timepoints to the number of Fourier frequencies. l\u00b5\u0303, l\u03c3\u03032 : IRP\u00d7T \u2192 IRP\u00d7F . A schematic for the Fourier domain variational and generative architecture is displayed in Figure 1(a).\nThere are a number of advantages to representing the GP-VAE latents and variational parameters in the Fourier domain. For one, the diagonal representation of K means we avoid a costly matrix inversion when evaluating the GP prior (Aoi and Pillow, 2017; Paciorek, 2007; Hensman et al., 2017; Wilson and Adams, 2013; Loper et al., 2021). Secondly, we can prune the high frequencies in the Fourier domain, effectively sparsifying the variational parameters, and hence frequencies (F < T ), while enforcing a smooth latent representation. Though this is a free parameter in our model thus if the user would like to model steady-states they are able to easily adjust this. Lastly, the Fourier representation of the variational parameters mean we can retain both temporal correlations and the advantages of using a mean-field approximation for the variational posterior q\u03d5 (Keeley et al., 2020a).These advantages have been seen in simpler GP models. For more information, see (Aoi and Pillow, 2017; Keeley et al., 2020a).\nThe Fourier-represented GP-VAE dramatically improves the ability of the GP-VAE to learn a true underlying smoothly evolving latent for high-dimension data in a non-linear model. We demonstrate this on a simulated example using an MNIST digit that rotates by a time-varying angle given by a draw from a GP with an RBF kernel. We fit our Fourier GP-VAE model as well as the standard VAE and standard GP-VAE models to these trials. In each case, we are looking to recover the true underlying generative latent angle and hence we assert a one-dimensional latent dimensionality for the model. For more information on training and testing, see appendix.\nBecause the Fourier variational distribution preserves temporal correlations and prunes the highfrequency components of the latents z, the Fourier GP-VAE model shows much smoother underlying latent representations on held-out trials (Fig 1 (c)), though each model retains the ability to accurately reconstruct the images through the network mapping from the latent space (Fig 1(b)). When the latent space is mapped through an affine transform to align latents on held-out trials to the true latent space, the Fourier domain GP-VAE does much better uncovering the true smoothly evolving latent angle (Fig 1 (c), (d))."
        },
        {
            "heading": "3 THE MULTI-MODAL GAUSSIAN PROCESS VARIATIONAL AUTOENCODER",
            "text": "We now focus on extending the GP-VAE to model data of two modalities simultaneously. The examples we will emphasize here involve neural activity alongside some other experimental variable such as naturalistic movement or high-dimensional stimuli. The observations of our model are two distinct data modalities represented by matrices y(i)A \u2208 IRN\u00d7T and y (i) B \u2208 IRM\u00d7T . Here, t \u2208 (1, 2 . . . T ) denotes time-bin indices, i denotes trials, and N and M denote the dimension of the observations for each modality. We assume, as before, that all data are generated by smoothly varying low-dimensional latent variables that are now either independent to, or shared between data modalities. As before, latents are initially parameterized in a pruned Fourier representation before\nbeing mapped to the time domain. The latents are then partitioned by a loadings matrix W which linearly combines the shared latent representation with the independent latents.[\nxA xB\n] = [ WA WS1 0 0 WS2 WB ] [zA zS zB ] + d (4)\nHere, zS refers to latents that are shared between regions, while zA and zB denote region-specific latent variables and d represents an additive offset. The outputs after this linear mixing result in modality-specific embeddings which we call xA and xB . Here, modality A, the \u2019behavioral modality\u2019 is passed through a deep neural network, and modality B, the \u2019neural modality\u2019, is passed through a pointwise nonlinearity f to enforce non-negativity of Poisson rates. The likelihood of the data given the embedding is:\np(yA|xA) \u223c N (g\u03c8(xA), \u03c32yIN ), p(yB |xB) \u223c P(f(xB)), (5)\nWhere the function g\u03c8(\u00b7) represents a decoder neural network for the experimental data and we use the exponential nonlinearity for f . Learning is performed as before - the mean and variance of a mean-field Gaussian variational distribution is given by the data passed through a neural network with parameters \u03d5. Here, our lower bound is similar to that found in Casale et al. (2018) with an additional term for the neural data modality.\nELBO = EZ\u0303\u223cq\u03d5 [ Gaussian Likelihood (other modality)\ufe37 \ufe38\ufe38 \ufe37\u2211\nt\nlogN ( yA | g\u03c8 (xA) , \u03c32yIN ) +\nPoisson Likelihood (Neural Rates)\ufe37 \ufe38\ufe38 \ufe37\u2211 t log(P(yB |f(xB)) + GP Prior\ufe37 \ufe38\ufe38 \ufe37 log p(Z\u0303 | T ,\u03b8) ] + Entropy\ufe37 \ufe38\ufe38 \ufe37 H(q\u03d5)\n(6)\nThe expectation with respect to the variational distribution is performed by drawing stochastic samples \u03f5 from a standard normal and using the variational mean and variance to get a sample from q\u03d5 (the so-called reparameterization trick (Kingma and Welling, 2013)). However, because we use a mean-field Gaussian variational distribution, both the Poisson log-likelihood and the GP prior terms in the expectation can be computed in closed-form and preclude the need for sampling for these terms. For clarity, we omit that closed-form expression here. See the appendix for details.\nA graphical depiction of the generative model of the MM-GPVAE is shown in figure 2(a). The hyperparameters of the model are the latent-specific kernel parameters \u03b8 that provide the GP covariance structure as well as a constant \u03b1 additive diagonal offset (fixed during inference). The entire schematic of the MM-GPVAE model, including the generative and variational distributions, is depicted in figure 2(b)."
        },
        {
            "heading": "4 EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "4.1 SIMULATED DATA",
            "text": "We first assess the performance of the MM-GPVAE model using a simulated dataset of two modalities: a smoothly rotating and scaling MNIST digit, and simultaneously accompanied Poisson spike counts from 100 neurons. A total of three latents were drawn from an underlying GP kernel to generate single-dimensional shared, neural, and image subspaces. There were a total of 300 trials, each trial consisting of 60 timebins. The data was split into 80% for training and 20% for testing. For this simulated example, one latent represents an interpretable modulation of the image as it directly effects the scaling of the MNIST digit. So as the latent values change along the trial, the image scales smaller and larger continuously. Another latent, corresponding to the independent component of the neural modality, provides one component of the log-rates of the Poisson spiking data. The final latent reflects the shared variability between both modalities. Here, the latent is again interpretable with respect to the image in that this latent corresponds to the angle of the smoothly rotating MNIST digit. This shared latent also linearly combines with the neural-only subspace to provide the the log-rates of the spiking Poisson population. The MM-GPVAE trained simultaneously on both images and spikes can successfully recover the three-dimensional latent structure across these two modalities. Figure 3(a) shows the underlying true latent in a held-out trial alongside the estimated latent structure extracted from the MM-GPVAE. As before, the held-out latent space is scaled to align with the true latent space as closely as possible, as the MM-GPVAE model latent space is invariant to scaling transform. In addition to accurately extracting the latent structure, the MM-GPVAE also has the ability to accurately reconstruct both neural rates and images across the time-series from the latent space. Four example images and three example neural rates are show in Figure 3 (b). For more examples, see the appendix.\nThe MM-GPVAE is also able to exploit information across modalities to better model the observed data. The left side of 3(c) shows the mean squared error (MSE) across pixels for reconstructed images in held-out trials. By leveraging latent information from the spiking modality, the MM-GPVAE is able to reconstruct the images better than a single-modality GP-VAE trained on the images alone (Casale et al., 2018). Similarly, the held-out neural rates are better estimated when the image data is included, though the effect here is more modest than for the image modality. Finally, we also show that the shared latent variable can be more accurately identified when data from both modalities is used (Figure 3(c)). Here we assess the accuracy of the shared latent estimate on test trials when we use data from each modality alone (GPVAE and GPFA) compared to both modalities simultaneously\n(MM-GPVAE). As expected, data from both modalities better identifies shared structure across the data types. The settings for all three models were exactly the same for these comparisons. We only ablated the models to make it into uni-modal settings. For additional details please see the appendix."
        },
        {
            "heading": "4.2 APPLICATION TO FLY EXPERIMENTAL DATA",
            "text": "Next we look to evaluate the MM-GPVAE on a real-world multi-modal dataset. Here, we consider a whole-brain calcium imaging from an adult, behaving Drosophila (Schaffer et al., 2021). We isolate 1000 calcium traces recorded using SCAPE microscopy (Voleti et al., 2019) from an animal while it performs a variety of distinct behaviors fixed on a spherical treadmill. These 1000 calcium traces are dispersed widely and uniformly across the central fly brain and were randomly picked from the dataset to use in our model. Alongside the neural measurements, eight 2-d limb positions are extracted from a recorded video using the software tool DeepLabCut (Mathis et al., 2018). These simultaneously recorded calcium traces and limb position measurements are split into 318 trials of 35 time-bins sampled at 70hz. Each trial has one of 5 corresponding behavioral labels (still, running, front grooming, back grooming and abdomen bending) determined via a semi-supervised approach from the tracked limb position measurements (Whiteway et al., 2021). Importantly, these behavioral labels are not used when fitting the MM-GPVAE. For additional information on how we isolate this behavioral data and neural traces, see the appendix. We consider a 7-dimensional latent behavioral subspace and 26 dimensional neural subspace, with 5 of these dimensions being shared across modalities. These choices were made through initial exploration of the model and examining cross-validated model performance (see appendix), though the results we show are robust to a wide range of dimensionality choices for each of the subspaces .\nThe MM-GPVAE is able to successfully reconstruct both behavioral trajectories and calcium traces in held-out trials for these data. The top of Figure 4(c) shows the true and decoded 16 limb position measurements with 3 highlighted for clarity. The bottom part of figure 4(c) shows 6 randomly selected calcium traces alongside their model reconstructions. In each case, the MM-GPVAE can roughly capture the temporal trends in this multi-modal dataset. To analyze the shared and independent latent subspaces of these data we consider a 2d projection of each latent space, and plot the mean latent value in that subspace calculated each trial. We additionally color-code the trial according to the behavioral label. In these shared and independent latent subspaces, we find that the \"still\" behavioral state is well separated from many of the other behavioral conditions in the neural and shared subspaces. Here, we show two others (bending and running) as an illustration (Figure 4(d)). We refer the reader to the appendix for visualizing all 5 behaviors in the latent space. Lastly, we illustrate how much each subspace contributes to the overall variability of neural and behavioral data.\nFigure 4(b) shows the variance of the neural (left) and behavioral (right) data calculated for each trial where the reconstruction of the data is generated either from the shared subspace, or either of the independent subspaces. We find that the shared subspace for each modalities contributes more to the overall variability in the data than either of the independent subspaces, suggesting a large fraction of shared variability between the data modalities."
        },
        {
            "heading": "4.3 APPLICATION TO MOTH EXPERIMENTAL DATA",
            "text": "Next, we evaluate the MM-GPVAE on a dataset of a hawkmoth (Manduca sexta) tracking a moving flower. The hawkmoth is an agile flier that is able to closely follow swiftly moving targets while hovering in midair, making it a model organism for the study of sensorimotor control (Sprayberry and Daniel, 2007). The modalities in our dataset consist of a time-series of images of a visual stimulus temporally paired with electromyography (EMG) signals recorded during 20-second experimental trials. Each image is an event-based reconstruction (inspired by insect visual system) of a white floral target moving laterally during a trial as viewed in the hawkmoth\u2019s frame of reference (Sikandar et al., 2023) (Fig 5(a)). The floral target moves sinusoidally at 1 Hz against a black background. Each pixel in a video frame can occupy a polarity of -1, 0 or +1 based on whether its luminosity has respectively decreased, unchanged or increased as compared to the previous frame in the temporal sequence. Temporally paired with the floral stimulus, EMG recordings are precisely measured spike trains from the 10 major flight muscles of the hawkmoth responding to the floral target while flying on a tether and flapping at about 22 Hz. Altogether, the 10-muscle recordings form a near-complete motor program that controls its flight during target tracking response (Putney et al., 2019).\nWe fit the MM-GPVAE model to these data using a 2-dimensional latent space to describe the moving visual stimulus and a 3-dimensional latent space to describe the Poisson rates from the 10 motor units. Of these, one latent dimension is shared between modalities. Here, a small number of dimensions are used both because only a few dimensions were needed to be able to accurately reconstruct the data of each modality (for more information about dimensionality selection, see appendix).\nWe find that the MM-GPVAE is able to accurately reconstruct both the neural rates (Fig 5(b)) and visual stimulus (Fig 5(c)) from its low dimensional latent space. We see that the neural rates are strongly modulated by the wing-flap oscillation at approximately 22 Hz. This is of course also seen in the neural latent space identified by the MM-GPVAE. At the bottom of Figure 5(b) we see that the first PC of the 2-dimensional latent space closely aligns with the torque measurement along the z-axis of the moth motion, a measurement previously identified to be closely associated with wing beating (Putney et al., 2019). The MM-GPVAE is also able to reconstruct the visual stimulus data, as seen in 5(c). When viewing the latent space corresponding to the visual stimulus modality, we find that the value of the smoothly evolving latent variable closely tracks the position of the stimulus in x dimension (the only dimension along which it moves, see Figure 5(e)). Finally, the shared latent dimension shows some modulation with wing-flapping, but exhibits temporal structure\nnot obviously related to the flapping frequency or stimulus motion. This may correspond to a longer-timescale motor behavior such as the variation in how strongly the hawkmoth is responding to track the stimulus, which could depend on the degree of its attention to the stimulus and its state of motivation. Importantly, we find that including a shared dimension better reconstructs the data than not including one, suggesting that there is a component of neural dynamics shared with stimulus dynamics. Specifically, we find that if we remove the shared latent we see approximately a 70% drop in mse in reconstruction of the image modality and about a 5% drop for reconstruction of the rates. Because the neural rates have such a strong wing-flapping modulation, we expect the slower-moving dynamics to account for only a small amount of the variability here. Lastly, we emphasize added interpretability in the MMGPVAE we get from the linear decoder layer used in the neural likelihood (GPFA). In our model, we can visualize how each of the 10 motor neurons is loaded onto either the neural-only dynamics or the dynamics shared with the moving stimulus 5(d). Future analysis of these data may help us further uncover how these shared and independent latent dynamics relate to the hawkmoth tracking and specific sensorimotor neurons and function in this experiment."
        },
        {
            "heading": "5 CONCLUSION",
            "text": "In this work, we have introduced the multi-modal Gaussian Process variational autoencoder (MMGPVAE) to identify temporally evolving latent variables for jointly recorded neural activity and behavioral or stimulus measurements. We parameterized the model in the Fourier domain to better extract identifiable temporal structure from high-dimensional time-series data. We first demonstrated that the Fourier-mean field representation is able to better recover the true latent variables in a single-modality setting compared to previous approaches in the time domain. We then show that our multi-modal GPVAE can also accurately recover latent structure across data modalities, which we demonstrate using a smoothly rotating and scaling MNIST digit alongside simulated neural spike trains. We then show that the model can be flexibly adapted to multiple real-world multi-modal behavioral settings. We implement the MM-GPVAE on calcium imaging traces and tracked limb positions of Drosophila and visualize the latent embeddings of distinct fly behaviors in shared and independent latent subspaces. We also use the MM-GPVAE on spikes from hawkmoth flight muscles as the animal tracks an oscillating visual stimulus. Here, our model extracted latent variables from each modality that corresponds to distinct experimentally relevant variables - wing flapping and a much slower stimulus movement. Here, we also demonstrated that the MM-GPVAE can be adapted to long time-series data to identify latent variables at widely varying timescales.\nExisting work: Our work contrasts in important ways with similar recently-developed multi-modal latent variable models for neural time series experiments. One closely related model, Targeted Neural Dynamical Modeling (TNDM) (Hurwitz et al., 2021), was specifically designed to nonlinearly separate the neural latent representation into behaviorally relevant and irrelevant subspaces. However, this work was evaluated on a dataset with a relatively simple behavioral paradigm, and fails when modalities are more complex. Another related multi-modal time-series neuroscience model, Preferential Subspace Identification (PSID) (Sani et al., 2021), was designed to linearly separate the neural latent representation into behaviorally relevant and irrelevant subspaces. However, PSID is restricted in its ability to describe more complex dynamics, and similarly to TNDM only performs well when behavioral or stimulus modalities have simple structure due to lack of a DNN decoder. For a thorough comparison and discussion of the MM-GPVAE to these competing models in neuroscience, please see the appendix.\nChoice of prior: In this work we focus on the use of GP priors to describe dynamics, though many other choices could have been made. As stated above, the existing multi-modal time-series models in neuroscience using linear dynamics and RNNs have limitations when compared with the MM-GPVAE. However, other dynamical approaches such as switching linear dynamical systems or non-linear dynamics models exist in neuroscience and are powerful in single modality settings (Hernandez et al., 2018; Linderman et al., 2017). Such models contain dependencies across the latent dynamical variables, and so require reformulation and developing new inference to adapt them to multi-modal settings, and do not afford the interpretability and scalability gains seen with the Fourier approach. Thus, development of multi-modal versions of different dynamical models and evaluating their strengths and limitations alongside the MM-GPVAE remains an important avenue of future work in neuroscience."
        },
        {
            "heading": "6 REPRODUCIBILITY STATEMENT",
            "text": "All models in this manuscript were trained end-to-end in PyTorch using the ADAM optimizer. Training was done on a Macbook Pro with Apple M1 max chip and all evaluations took less than an hour to fit. All encoder and decoder neural networks were standard feedforward neural networks with ELU activation functions. Additional details on neural network architectures for the experiments and example code can be found in the appendix."
        },
        {
            "heading": "7 ETHICS STATEMENT",
            "text": "Our work provides a general model for exploratory data analysis for multi-modal time-series data. Though we develop the model with neuroscience experiments in mind, in principle the model could be adapted to other settings where the assumption of smoothly evolving latent dynamics holds across distinct data modalities. We do not anticipate any potential negative societal impacts of our work."
        }
    ],
    "year": 2023
}