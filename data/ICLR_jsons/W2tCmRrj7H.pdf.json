{
    "abstractText": "Realistic synthetic electronic health records (EHRs) can be leveraged to accelerate methodological developments for research purposes while mitigating privacy concerns associated with data sharing. However, the training of Generative Adversarial Networks remains challenging, often resulting in issues like mode collapse. While diffusion models have demonstrated progress in generating quality synthetic samples for tabular EHRs given ample denoising steps, their performance wanes when confronted with missing modalities in heterogeneous tabular EHRs data. For example, some EHRs contain solely static measurements, and some contain only contain temporal measurements, or a blend of both data types. To bridge this gap, we introduce FLEXGEN-EHR\u2013 a versatile diffusion model tailored for heterogeneous tabular EHRs, equipped with the capability of handling missing modalities in an integrative learning framework. We define an optimal transport module to align and accentuate the common feature space of heterogeneity of EHRs. We empirically show that our model consistently outperforms existing state-of-the-art synthetic EHR generation methods both in fidelity by up to 3.10% and utility by up to 7.16%. Additionally, we show that our method can be successfully used in privacy-sensitive settings, where the original patient-level data cannot be shared.",
    "authors": [],
    "id": "SP:ee5bedacbd23cd9328931a4bf826d7716205ced5",
    "references": [
        {
            "authors": [
                "Simon Bing",
                "Andrea Dittadi",
                "Stefan Bauer",
                "Patrick Schwab"
            ],
            "title": "Conditional generation of medical time series for extrapolation to underrepresented populations",
            "venue": "PLOS Digital Health,",
            "year": 2022
        },
        {
            "authors": [
                "Siddharth Biswal",
                "Soumya Ghosh",
                "Jon Duke",
                "Bradley Malin",
                "Walter Stewart",
                "Cao Xiao",
                "Jimeng Sun"
            ],
            "title": "Eva: Generating longitudinal electronic health records using conditional variational autoencoders",
            "venue": "In Machine Learning for Healthcare Conference,",
            "year": 2021
        },
        {
            "authors": [
                "Taha Ceritli",
                "Ghadeer O. Ghosheh",
                "Vinod Kumar Chauhan",
                "Tingting Zhu",
                "Andrew P. Creagh",
                "David A. Clifton"
            ],
            "title": "Synthesizing mixed-type electronic health records using diffusion models",
            "year": 2023
        },
        {
            "authors": [
                "Nanxin Chen",
                "Yu Zhang",
                "Heiga Zen",
                "Ron J. Weiss",
                "Mohammad Norouzi",
                "William Chan"
            ],
            "title": "Wavegrad: Estimating gradients for waveform generation",
            "venue": "In Proc. of ICLR,",
            "year": 2021
        },
        {
            "authors": [
                "Edward Choi",
                "Siddharth Biswal",
                "Bradley Malin",
                "Jon Duke",
                "Walter F. Stewart",
                "Jimeng Sun"
            ],
            "title": "Generating multi-label discrete patient records using generative adversarial networks",
            "venue": "In Proceedings of the 2nd Machine Learning for Healthcare Conference,",
            "year": 2017
        },
        {
            "authors": [
                "Khaled El Emam",
                "Sam Rodgers",
                "Bradley Malin"
            ],
            "title": "Anonymising and sharing individual patient",
            "venue": "data. BMJ,",
            "year": 2015
        },
        {
            "authors": [
                "Milena A Gianfrancesco",
                "Neal D. Goldstein"
            ],
            "title": "A narrative review on the validity of electronic health record-based research in epidemiology",
            "venue": "BMC Medical Research Methodology,",
            "year": 2021
        },
        {
            "authors": [
                "Sebastien J-P A Haneuse",
                "David E Arterburn",
                "Michael J. Daniels"
            ],
            "title": "Assessing missing data assumptions in ehr-based studies: A complex and underappreciated task",
            "venue": "JAMA network open,",
            "year": 2021
        },
        {
            "authors": [
                "Jamie Hayes",
                "Luca Melis",
                "George Danezis",
                "Emiliano De Cristofaro"
            ],
            "title": "Membership inference attacks against generative models. 2018",
            "venue": "URL https://api.semanticscholar.org/CorpusID:",
            "year": 2025
        },
        {
            "authors": [
                "Huan He",
                "Shifan Zhao",
                "Yuanzhe Xi",
                "Joyce C Ho"
            ],
            "title": "Meddiff: Generating electronic health records using accelerated denoising diffusion model",
            "year": 2023
        },
        {
            "authors": [
                "Jonathan Ho"
            ],
            "title": "Classifier-free diffusion guidance",
            "venue": "ArXiv, abs/2207.12598,",
            "year": 2022
        },
        {
            "authors": [
                "Alistair Johnson",
                "Tom Pollard",
                "Lu Shen",
                "Li-wei Lehman",
                "Mengling Feng",
                "Mohammad Ghassemi",
                "Benjamin Moody",
                "Peter Szolovits",
                "Leo Celi",
                "Roger Mark"
            ],
            "title": "Mimic-iii, a freely accessible critical care database",
            "venue": "Scientific Data,",
            "year": 2016
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Jimmy Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "In Proc. of ICLR,",
            "year": 2015
        },
        {
            "authors": [
                "Diederik P Kingma",
                "Max Welling"
            ],
            "title": "Auto-encoding variational bayes, 2022",
            "year": 2022
        },
        {
            "authors": [
                "Akim Kotelnikov",
                "Dmitry Baranchuk",
                "Ivan Rubachev",
                "Artem Babenko"
            ],
            "title": "Tabddpm: Modelling tabular data with diffusion models",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Jin Li",
                "Benjamin J. Cairns",
                "Jingsong Li",
                "Tingting Zhu"
            ],
            "title": "Generating synthetic mixed-type longitudinal electronic health records for artificial intelligent applications",
            "venue": "NPJ Digital Medicine,",
            "year": 2021
        },
        {
            "authors": [
                "Jin Li",
                "Benjamin J. Cairns",
                "Jingsong Li",
                "Tingting Zhu"
            ],
            "title": "Generating synthetic mixed-type longitudinal electronic health records for artificial intelligent applications",
            "venue": "NPJ Digital Medicine,",
            "year": 2021
        },
        {
            "authors": [
                "Wei Li",
                "Li Fan",
                "Zhenyu Wang",
                "Chao Ma",
                "Xiaohui Cui"
            ],
            "title": "Tackling mode collapse in multigenerator gans with orthogonal vectors",
            "venue": "Pattern Recognit.,",
            "year": 2021
        },
        {
            "authors": [
                "Scott McLachlan",
                "Kudakwashe Dube",
                "Thomas Gallagher"
            ],
            "title": "Using the caremap with health incidents statistics for generating the realistic synthetic electronic healthcare",
            "venue": "IEEE International Conference on Healthcare Informatics (ICHI),",
            "year": 2016
        },
        {
            "authors": [
                "Riccardo Miotto",
                "Li Li",
                "Brian A. Kidd",
                "Joel T. Dudley"
            ],
            "title": "Deep patient: An unsupervised representation to predict the future of patients from the electronic health records",
            "venue": "Scientific Reports,",
            "year": 2016
        },
        {
            "authors": [
                "Olof Mogren"
            ],
            "title": "C-rnn-gan: Continuous recurrent neural networks with adversarial training",
            "venue": "ArXiv, abs/1611.09904,",
            "year": 2016
        },
        {
            "authors": [
                "Arvind Narayanan",
                "Vitaly Shmatikov"
            ],
            "title": "Robust de-anonymization of large sparse datasets",
            "venue": "IEEE Symposium on Security and Privacy,",
            "year": 2008
        },
        {
            "authors": [
                "Tom J. Pollard",
                "Alistair E.W. Johnson",
                "Jesse Daniel Raffa",
                "Leo Anthony Celi",
                "Roger G. Mark",
                "Omar Badawi"
            ],
            "title": "The eicu collaborative research database, a freely available multi-center database for critical care research",
            "venue": "Scientific Data,",
            "year": 2018
        },
        {
            "authors": [
                "Mohamed Ragab",
                "Emadeldeen Eldele",
                "Wee Ling Tan",
                "Chuan-Sheng Foo",
                "Zhenghua Chen",
                "Min Wu",
                "C. Kwoh",
                "Xiaoli Li"
            ],
            "title": "Adatime: A benchmarking suite for domain adaptation on time series data",
            "venue": "ACM Transactions on Knowledge Discovery from Data,",
            "year": 2022
        },
        {
            "authors": [
                "Howell",
                "Claire Cui",
                "Greg S. Corrado",
                "Jeffrey Dean"
            ],
            "title": "Scalable and accurate deep learning with electronic health",
            "venue": "records. npj Digital Medicine,",
            "year": 2018
        },
        {
            "authors": [
                "Robin Rombach",
                "Andreas Blattmann",
                "Dominik Lorenz",
                "Patrick Esser",
                "Bj\u00f6rn Ommer"
            ],
            "title": "Highresolution image synthesis with latent diffusion models",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Robin Rombach",
                "Andreas Blattmann",
                "Dominik Lorenz",
                "Patrick Esser",
                "Bj\u00f6rn Ommer"
            ],
            "title": "Highresolution image synthesis with latent diffusion models, 2022b",
            "year": 2022
        },
        {
            "authors": [
                "Jascha Sohl-Dickstein",
                "Eric A. Weiss",
                "Niru Maheswaranathan",
                "Surya Ganguli"
            ],
            "title": "Deep unsupervised learning using nonequilibrium thermodynamics",
            "venue": "In Proc. of ICML,",
            "year": 2015
        },
        {
            "authors": [
                "Shengpu Tang",
                "Parmida Davarmanesh",
                "Yanmeng Song",
                "Danai Koutra",
                "Michael W. Sjoding",
                "Jenna Wiens"
            ],
            "title": "Democratizing ehr analyses with fiddle: a flexible data-driven preprocessing pipeline for structured clinical data",
            "venue": "Journal of the American Medical Informatics Association : JAMIA,",
            "year": 1934
        },
        {
            "authors": [
                "Brandon Theodorou",
                "Cao Xiao",
                "Jimeng Sun"
            ],
            "title": "Synthesize high-dimensional longitudinal electronic health records via hierarchical autoregressive language model",
            "venue": "Nature Communications,",
            "year": 2023
        },
        {
            "authors": [
                "Amirsina Torfi",
                "Edward A. Fox"
            ],
            "title": "Corgan: Correlation-capturing convolutional generative adversarial networks for generating synthetic healthcare records",
            "venue": "In FLAIRS Conference,",
            "year": 2020
        },
        {
            "authors": [
                "Arash Vahdat",
                "Karsten Kreis",
                "Jan Kautz"
            ],
            "title": "Score-based generative modeling in latent space",
            "venue": "In NeurIPS,",
            "year": 2021
        },
        {
            "authors": [
                "Chao Yan",
                "Ziqi Zhang",
                "Steve Nyemba",
                "Bradley A. Malin"
            ],
            "title": "Generating electronic health records with multiple data types and constraints",
            "venue": "In AMIA Annual Symposium Proceedings,",
            "year": 2020
        },
        {
            "authors": [
                "Jinsung Yoon",
                "Daniel Jarrett",
                "Mihaela van der Schaar"
            ],
            "title": "Time-series generative adversarial networks",
            "venue": "In Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Jinsung Yoon",
                "Michel Mizrahi",
                "Nahid Farhady Ghalaty",
                "Thomas Dunn Jarvinen",
                "Ashwin S. Ravi",
                "Peter Brune",
                "Fanyu Kong",
                "Dave Anderson",
                "George Lee",
                "Arie Meir",
                "Farhana Bandukwala",
                "Elli Kanal",
                "Sercan \u00d6. Arik",
                "Tomas Pfister"
            ],
            "title": "Ehr-safe: generating high-fidelity and privacypreserving synthetic electronic health records",
            "venue": "NPJ Digital Medicine,",
            "year": 2023
        },
        {
            "authors": [
                "Ziqi Zhang",
                "Chao Yan",
                "Diego A. Mesa",
                "Jimeng Sun",
                "Bradley A. Malin"
            ],
            "title": "Ensuring electronic medical record simulation through better training, modeling, and evaluation",
            "venue": "Journal of the American Medical Informatics Association : JAMIA,",
            "year": 2019
        },
        {
            "authors": [
                "P. Zhou",
                "Wei Shi",
                "Jun Tian",
                "Zhenyu Qi",
                "B. Li",
                "Hongwei Hao",
                "Bo Xu"
            ],
            "title": "Attention-based bidirectional long short-term memory networks for relation classification",
            "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics",
            "year": 2016
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "The widespread digitization of health data has enabled the training of deep learning models for precision medicine, in the form of personalized prediction of risks and health trajectories (Rajkomar et al., 2018; Miotto et al., 2016). However, there are various concerns over patient privacy that need to be accounted for in order to collect the large quantities of data needed to train robust models. As such, it is challenging for researchers to obtain access to real electronic health records (EHRs). One approach to mitigate privacy risks is through the practice of de-identification in the form of data perturbation and randomization (El Emam et al., 2015; McLachlan et al., 2016). However, the blind application of de-identification leads to records that are vulnerable to re-identification attacks (Narayanan & Shmatikov, 2008). An alternative approach that is receiving increasing attention is the creation and dissemination of synthetic datasets that aim to capture many of the complexities of the original data set (e.g., distributions, non-linear relationships, and noise). Synthetic data can yield records that are robust against re-identification. To support the creation of realistic and synthetic data, generative models have emerged as the key element to advance precision medicine.\nAlthough several distinguished efforts for synthetic EHR generation exist (Bing et al., 2022; Choi et al., 2017; Torfi & Fox, 2020; Yan et al., 2020; Li et al., 2021a; Theodorou et al., 2023), designing an effective generative model for EHRs remains a challenging task for two key reasons: (1) heterogeneous features encompassing both static and temporal measurements and (2) missing data. EHRs consist of diverse and multi-dimensional data that contain static features (e.g., race and gender) and temporal measurements (e.g., heart rate, temperature, blood pressure). We refer to this as heterogeneous tabular EHRs (i.e., not including unstructured text). Existing works (Choi et al., 2017; Torfi & Fox, 2020; He et al., 2023) extended classical deep generative models to EHRs, building upon generative adversarial networks (GANs), autoencoders, or diffusion models. However, these methods are limited to generating static measurements including billing codes, and ignore the temporal features (e.g., lab results repeated over time), hindering their utility for downstream tasks. On the other hand, (Biswal et al., 2021) focused on generating temporal features only. EHR-M-GAN (Li\net al., 2021b) circumvents this problem by training two separate encoders for each modality (static and temporal features), but it lacks the capability of training using data with missing modality.\nMissing data, is a complex and pervasive problem in medical records and public health research, affecting both randomized trials and observational studies (Haneuse et al., 2021). Nevertheless, existing methods assume completeness of the data, yielding less reliable generation when facing missing data. Reasons for missing data can vary substantially across studies because of dropout or loss to follow-up, missed study visits, or an unrecorded measurement during an office visit. Merely removing missing data is not feasible because the learned generative model is likely to suffer from selection bias, whereby the results downstream utility (ie, to the intended or target patient population) is compromised). This underscores the need for generative methods for EHRs that 1) handle heterogeneous (or mixed-type) EHRs and 2) expand the scope of existing generative methods by supporting missing observations of EHRs. A clear articulation of assumptions is critical because of the different mechanisms that can induce missing data. We consider the scenario of missing modality not at random (MMCAR) in work suggested by Tang et al. (2020); Haneuse et al. (2021); Gianfrancesco & Goldstein (2021). In this scenario, not every record will have data associated with each modality. For example, medications (documented as static data) may not have corresponding records of the measurements of patients physiological status due to loss of records. Another example is protecting patient privacy by omitting one modality where they can be easily identified (e.g., a woman above 100 with otherwise similar temporal features to the population).\nPresent Work. To address the aforementioned limitations, for the first time, we introduce FLEXGEN-EHR, a flexible generative framework for simultaneously synthesizing heterogeneous longitudinal EHR data. Specifically, we focus on generating both static and temporal records jointly. Patient trajectories with high-dimensionality and heterogeneous data types (both continuousvalued and discrete-valued timeseries) are generated while the underlying temporal dependencies and temporal-static correlations are captured.\nIn summary, our contributions are as follows: 1\u00a9 We formalize the challenge of generating heterogeneous Electronic Health Records (EHR) in the presence of missing modality.\n2\u00a9 We present FLEXGEN-EHR1, a latent diffusion method demonstrating superior generation fidelity, evidenced by a reduction of Maximum Mean Discrepancy (MMD) by up to 3.10%, and enhanced utility, with an increase in Area Under the Precision-Recall Curve (AUPR) by up to 7.16%.\n3\u00a9 We introduce an innovative solution to the missing modality issue by formulating an optimal transport problem in the embedding space, enabling the construction of meaningful and reasonable latent embedding pairs to solve the missing correspondence in the data.\n4\u00a9 We empirically verify that FLEXGEN-EHR maintains high standards of generation and utility even in instances of missing modality, solidifying its applicability and reliability in practical, realworld scenarios involving incomplete data."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "Here, we discuss the related works on synthetic EHR generation and diffusion-based models.\nIn this context, we use \u2019categorical\u2019 and \u2019static\u2019 interchangeably, both referring to features that fall within defined categories and remain consistent. Similarly, \u2019numerical\u2019 and \u2019temporal\u2019 are used synonymously, denoting features that can vary over time.\nSynthetic EHR Generation. The predominant approaches for EHR tabular generation currently rely on GAN-based methods, which utilize two neural networks: the generator and the discriminator. MedGAN (Choi et al., 2017), CorGAN(Torfi & Fox, 2020), and EHR-WGAN (Zhang et al., 2019) utilize GANs for generating patient feature matrices (diagnosis only). However, challenges still remain for GAN-based methods, such as the mode collapse problem (Li et al., 2021c) and the alignment between heterogeneous data types.\nWhile several works focus on static data generation such as MedGAN and CorGAN, it\u2019s essential to note that real-world EHRs encompass a mixture of heterogeneous data types. These include temporal features (e.g., blood test results) and static features (e.g., sex and ethnicity), also denoted\n1The code is accessible at https://anonymous.4open.science/r/FlexGen-4546/.\nas numerical and categorical features. Although VAE performs the common method for static feature generation, when it comes to synthesizing temporal features, current GAN-based models, such as C-RNN-GAN (Mogren, 2016), TimeGAN (Yoon et al., 2019), rely heavily on adopting recurrent neural networks (RNNs) for both their generator and discriminator components. Therefore, in the context of heterogeneous Tabular EHR data generation, GAN-based methods face challenges in learning joint distribution representation due to the diverse structures of their generators.\nVery recently, EHR-M-GAN (Li et al., 2021b) is proposed as a method for synthesizing heterogeneous EHR data. However, it operates under the assumption that representations learned by autoencoders can seamlessly integrate with those from bidirectional Long Short-Term Memory(BLSTM) (Zhou et al., 2016), a premise that might not be reliable given the inherent structural differences between the models. In contrast, FLEXGEN-EHR introduces a integrative learning framework. For both static and temporal features, they are learned under a separate VAE architecture, which naturally aligns common feature space of heterogeneity for EHR Tabular datas.\nTabular Diffusion. First proposed in (Sohl-Dickstein et al., 2015), diffusion models are a family of latent variable generative models characterized by a forward and a reverse Markov process. Diffusion models have excelled in various image-generation tasks and now extended beyond computer visions (Chen et al., 2021; Vahdat et al., 2021). However, only few works have been proposed to introducing diffusion models for tabular data generation so far, especially when encompassing with heterogenous datasets like EHRs.\nAs an early adopter of diffusion models for EHR generation, MedDiff (He et al., 2023) primarily focuses on utilizing Gaussian diffusion process to generate numerical EHR data. But it is important to note that real-world EHRs is formed by a mixture of numerical features (eg., respiration rate) and categorical features (eg., LOS and mortality). MedDiff generates diagnosis count matrix only, leaving out numerical features unsolved. The more recent model, TabDDPM (Kotelnikov et al., 2023), addresses this problem by generating heterogeneous tabular data encompassing both static and temporal features, which could be denoted as numerical and categorical as well. It employs Gaussian quantile transformation for temporal features, and a one-hot encoder for each static features. A recent study (Ceritli et al., 2023) evaluates the performance of implementing TabDDPM into EHR generation, which out performs other contemporary models.\nA common observation among existing diffusion-based EHR models is their inability to generate categorical features or their tendency to treat numerical and categorical features independently. Yet, in practical scenarios like bedside data analysis in hospitals, numerical features (eg., respiration rate)\nand categorical features (eg., diagnosis and admission type) often have intrinsic logical relationships. For a synthetic model to generate a realistic heterogeneous tabular EHR dataset, it must adeptly discern and represent the underlying relationships between numerical and categorical features. Under this context, FLEXGEN-EHRstands as the sole diffusion-based heterogeneous tabular EHR generation model, adept at learning the latent relationship within a unified latent space accommodating both static and temporal features."
        },
        {
            "heading": "3 PRELIMINARIES",
            "text": "Diffusion. Diffusion models leverage a pre-defined forward process in training, where a clean distribution q(x0) can be corrupted to a noisy distribution q(xt|x0) at a specified timestep t. Given a pre-defined variance schedule {\u03b2t}1:T , the noisy distribution at any intermediate timestep is given by:\nq(xt|x0) = N (\u221a \u03b1\u0304tx0, (1\u2212 \u03b1\u0304t)I ) ; \u03b1\u0304t =\nt\u220f\ni=1\n(1\u2212 \u03b2i).\nTo reverse such forward process, a generative model \u03b8 learns to estimate the analytical true posterior in order to recover xt\u22121 from xt as follows:\nmin \u03b8 DKL[q(xt\u22121|xt, x0)||p\u03b8(xt\u22121|xt)]; \u2200t \u2208 {1, ..., T},\nand such an objective can be reduced to a simple denoising estimation loss []:\nLDDPM = Et,x0\u223cq(x0),\"\u223cN (0,I) [ \u2016$\u2212 $\u03b8( \u221a \u03b1\u0304x0 + \u221a 1\u2212 \u03b1\u0304t$, t)\u20162 ] (1)\nFor the case where label information is available, the model is trained to estimate the noise as above in both conditional cases $\u03b8(xt, y, t) with data-label pairs (x0, y) and unconditional case $\u03b8(xt, t). In the sampling, the label-guided model estimates the noise with a linear interpolation\n$\u0302 = (1 + \u03c9)$\u03b8(xt, y, t)\u2212 \u03c9$\u03b8(xt, t) to recover xt\u22121, which is often referred to as Classifier-Free Guidance (CFG) (Ho, 2022).\nLatent Diffusion Model. To improve the efficiency, the Latent Diffusion Model (LDM) (Rombach et al., 2022b) introduces an explicit separation between the compressive and generative learning phases of training diffusion models. Central to this approach is the use of an autoencoding model, consisting of an encoder E(\u00b7) and a decoder D(\u00b7). This autoencoder is designed to capture a compressed latent space for diffusion model, which, upon decoding, closely resembles the original data space in its perceptual attributes.\nGiven a tabular data entry x with dimensions x \u2208 RH\u00d7W , the encoder E maps x into a latent representation denoted by z = E(x). Subsequently, the decoder D reconstructs the original data entry from zz, resulting in x\u0303 = D(z) = D(E(x)). This latent space, with dimensions z \u2208 Rh\u00d7w, offers the advantage of reduced computational demands while preserving the perceptual integrity of the regenerated samples.\nThe objective function tailored for training the LDM is expressed as: L(\u03b8) = Ezt\u223cq(zt|z),z=E(x),t\u223c[0,1] [ \u03c9t \u00b7 \u2016F\u03b8(zt, t)\u2212 z\u201622 ] (2)\nHere, the latent representation z is derived during the training process using Encoder E. Once generated, z can be decoded back to its original data form using D."
        },
        {
            "heading": "3.1 OPTIMAL TRANSPORT",
            "text": "Optimal transport formalizes the problem of finding a minimum cost mapping between two point sets, viewed as discrete distributions. Specifically, we assume two empirical distributions over embeddings, e.g., embeddings of static features zSi and embeddings of temporal features zTi\n\u00b5 = I\u2211\ni=1\npzTi and \u03bd = J\u2211\nj=1\nqzTj (3)\nHere, p and q are non-negative vectors of length I and J that sum up to 1. We denote their probabilistic couplings, set \u03a0 and cost matrix C, as: We find a transportation map \u0393 realizing :\ninf T\n{\u222b\nX c(x,\u0393(x))d\u00b5(x) | \u0393#\u00b5 = \u03bd\n} , (4)\nwhere the cost c(x,\u0393(x)) is typically just \u2016x\u2212 \u0393(x)\u2016 and \u0393#\u00b5 = \u03bd implies that the source points must exactly map to the targets."
        },
        {
            "heading": "4 FLEXGEN-EHR",
            "text": ""
        },
        {
            "heading": "4.1 PROBLEM FORMULATION",
            "text": "Heterogeneous Tabular EHR Generation. Given heterogeneous tabular EHR data D ={( xSi ,x T i , yi )}N i=1\nof N electronic records where xTi \u2208 Rm contains time-invariant features, xTi \u2208 RT\u00d7d contains time-dependent features, and yi represents the label information of interest. Here, N refers to the number of examples (unique IDs in the data table), T is the number of timesteps after \"discretizing\" the observation period into time bins of size. The dimensionalities of the time-invariant and time-dependent features are denoted by m and d, respectively. The goal is to generate synthetic EHR data D\u0302 such that L(D, D\u0302) is minimized where L is any divergence measurement, such as mean-squared loss and maximum mean discrepancy (MMD).\nHeterogeneous Tabular EHR Generation with missing modalities. The above problem can be extended to the setting where not every record will have data associated with each modality. Thus, the heterogeneous tabular EHR data can take the form D = {( xSi , yi ) , ( xTj , yj ) , ( xSk ,x T k , yk )} for i = 1, \u00b7 \u00b7 \u00b7 , I, j = 1, \u00b7 \u00b7 \u00b7 J, k = 1, \u00b7 \u00b7 \u00b7 ,K. Here, I, J,K represent the number of records containing only static, only temporal, and both types of information, respectively."
        },
        {
            "heading": "4.2 LATENT DIFFUSION MODEL ON EHRS",
            "text": "Given a sample ( xSi ,x T i , yi ) , FLEXGEN-EHR utilizes a dual encoder-decoder framework to independently obtain static and temporal latent embeddings, denoted as zSi and zTi . Specifically, an encoder EncS operates on static features, embedding the patient information as zTi = EncS(xSi ), while another encoder, EncT , is specialized for temporal features, representing repeated measurements. The implementation of two distinct encoders is motivated by the fact that a single encoder is inadequate to capture meaningful embeddings for both feature types due to the distinctive domains of static and temporal features. Our empirical investigations confirm that utilizing an LSTM encoder for temporal features and an MLP encoder for static ones yields superior quality embeddings. Following the encoding phase, these separately constructed latent representations are concatenated to construct a fused latent representation, represented as zi = [zT ; zS ]. A latent diffusion model G is then trained on this unified representation zi.\nThe choice of using a latent diffusion model is significant not only because generation with diffusion on a compact scale is more expedient, but also due to our observations that, given the high-dimension of EHR data (d > 5000), leveraging diffusion models or even the recently proposed TabDDPM tends to encounter training failures and generates samples at least 5 times slower. Thus the integration of a dual-encoder-decoder framework and a latent diffusion model is synergistic, culminating in the achievement of hyper-parameter robustness, high-quality synthetic samples, and more efficient generation procedures. This optimized combination ensures the precise and coherent embedding of both static and temporal features, and provides a comprehensive and nuanced representation of the complex, multifaceted data encountered in healthcare settings."
        },
        {
            "heading": "4.3 LATENT SPACE ALIGNMENT",
            "text": "The above section assumes that both modalities are present, which cannot readily handle the missing modality. Here, we define the optimal transport problem for solving data with missing modalities such that xi = ( xSi ,NA, yi ) or xi = ( NA,xTi , yi ) , where NA denotes not available. Instead of mapping-based methods, which rely on nearest-neighbor computation to infer the NA data, we observed that latent space embedding models, trained on disparate features, manifested analogous\ngeometric patterns and behaviors. This drives us to posit that the latent embedding spaces of heterogeneous EHRs can potentially be transformed reciprocally through linear transformations. Specifically, suppose the sample size of zSi and zTi are identical, let ZT = [ zT1 , . . . , z T I ] \u2208 Rlt\u00d7I\nand ZS = [ zS1 , . . . , z S J ] \u2208 Rls\u00d7I represent the embedding matrices of temporal and static features, respectively. Here, lt and ls denote the size of the embeddings and I represents the number of samples. A viable solution entails solving the following linear system:\nmin A\u2208O(l)\n\u2016ZS \u2212AZT \u20162F , (5)\nwhere O(l) = { A \u2208 Rls\u00d7lt | A%A = I } . This formulation has a closed-form solution that can be easily obtained. However, the linear system approach only solves the supervised version of the problem as it requires a known correspondence between the columns of ZS and ZT . Clearly, it cannot solve the alignment problem without the correspondence caused by the missing modalities.\nWe solve this issue by \"imputing\" the correspondence via a modified Gromov-Wasserstein-based manifold alignment algorithm. The algorithm exploits the inner structure of the embedding space and uses the available label information as global correspondence between two spaces. We consider two measure spaces expressed in terms of within-embedding space similarity (cosine similarity used here) matrices CT \u2208 RI\u00d7I and CS \u2208 RJ\u00d7J . For clarity, we represent i, j, k, and l as indices for individual samples, acknowledging a slight abuse of notation herein. We now define a loss function between similarity pairs: L : R\u00d7 R \u2192 R, where L ( CTik,C S jl ) measures the discrepancy between\nthe distances CTik and C S jl. In this work, we define L ( CTik,C S jl ) = 12 (yiykC T ik \u2212 yjylCSjl)2. It can be understood as the cost of \"matching\" i to j and k to l. In addition, it avoids misalignment by penalizing the mis-correspondence when pairs have similarities between the embedding space but have different outcomes. All the relevant values of L(\u00b7, \u00b7) can be put in a 4-th order tensor L \u2208 RI\u00d7I\u00d7J\u00d7J , where Lijkl = L ( CTik,C S jl ) . Similar to the definition 3.1, we seek a coupling \u0393 \u2208 RI\u00d7J specifying how much mass to transfer between each pair of points from the two embedding spaces. The Gromov-Wasserstein problem is then defined as solving\nGW ( CT ,CS ,p,q ) = min\n\u0393\u2208\u03a0(p,q)\n\u2211\ni,j,k,l\nLijkl\u0393ij\u0393kl \u2212 $H(\u0393), (6)\nwhere \u0393ij is the relative probability that matches embedding zTi to zSj . We add an entropic regularization penalty to solve the problem faster. Once we have solved equation 6, the optimal transport coupling \u0393 provides an explicit (soft) matching between temporal and static features, which can be interpreted as a probabilistic translation: for every pair of embeddings, it provides a likelihood that these two embeddings are correspondent of each other. Now, we can solve the least square problem with full correspondence information:\nmin A\n\u2016ZS\u0393\u2212AZT \u20162F (7)\nInstead of equation 5, this formulation can achieve alignment when the sample sizes between static and temporal aren\u2019t the same. Suppose static features in xi are not available, we can obtain the most likely latent embedding zSi by running a simple transformation A:izTi \u0393 \u22121 i: . To obtain z T i from zSi , resolving the problem considering zSi as the source and zTi as the target is necessary to obtain a reliable and accurate solution.\nGeneration. Next, we elucidate the procedure for generation. Whether a modality is missing or present, we demonstrate that FLEXGEN-EHR can train a latent diffusion model using fused representations zi = [ zT ; zS ] , as shown in equation 2. If there is missing data, FLEXGEN-EHRcan \"impute\" the full representations by solve the OT problem equation 6 to find reasonable corresponding features.\nUpon the successful training of the diffusion model, our first step is to generate synthetic fused representations. Subsequently, decoupled embeddings (by simply splitting) into respective decoders as follows:\nx\u0302Ti = Dec T (zT ), x\u0302Si = Dec S(zS) The overview of FLEXGEN-EHRis presented in Figure 1."
        },
        {
            "heading": "5 EXPERIMENTS",
            "text": ""
        },
        {
            "heading": "5.1 EXPERIMENTAL SETUP",
            "text": "Baselines. In our study, we consider six methods as baselines: i) VAE (Kingma & Welling, 2022), a Variational Autoencoder model, traditionally used in generating high-dimensional data; ii) MEDGAN (Choi et al., 2017) 2, a GAN-based model that generates low-dimensional synthetic records and decoded with an autoencoder; iii) CORGAN (Torfi & Fox, 2020) 3, another GAN-based model that, akin to MedGAN, amalgamates Convolutional Generative Adversarial Networks (ConvGANs) and Convolutional Autoencoders to synthesize and reconstruct medical records; iv) EHRM-GAN (Li et al., 2021b) 4, a GAN-based model tailored for longitudinal heterogeneous EHRs; v) TABDDPM (Kotelnikov et al., 2023) 5, a diffusion model specialized in handling tabular data with the unique capability of addressing the challenges presented by the heterogeneous nature of EHRs; and vi) LDM (Rombach et al., 2022a) 6, a latent diffusion model that decomposes the generation process into a sequence of autoencoders and diffusion models (DMs).\nThese models introduce unique methodologies and focus on varying aspects of EHR data synthesis and reconstruction, providing a comprehensive perspective on the potential approaches and their efficacy in handling heterogeneous medical records. More details are available in Appendix B.1.\nDatasets. We use two real-world de-identified EHR datasets, MIMIC-III (Johnson et al., 2016) and eICU (Pollard et al., 2018). Both are inpatient datasets that consist of varying lengths of sequences and include multiple static and temporal features with missing components.\nMIMIC-III is an extensive database that houses anonymized data related to around sixty thousand critical care unit admissions from Beth Israel Deaconess Medical Center, gathered between 2001 and 2012. eICU is a large-scale, multi-center collection of anonymized health-related data, encompassing over 200,000 admissions to intensive care units throughout the United States from 2014-2015. We adopted the preprocessed datasets from FIDDLE (Tang et al., 2020). The cohort numbers and dimensionalities of extracted features are summarized in Table 1, where m and d denote the dimensions of static and temporal features respectively. More details on datasets and preprocessing are available at Appendix B.2.\nEvaluation. We evaluate the effectiveness of FLEXGEN-EHR on fidelity, utility on downstream machine learning tasks, and also demonstrate its ability to preserve privacy. Fidelity: We evaluate the quality of synthetic data through various metrics that assess how closely the synthetic data resembles real data. Following Li et al. (2021b); Yoon et al. (2023), we report R2 values (the higher the better) and maximum mean discrepancy (the lower the better). The details can be found in B.3. Utility: We focus on prediction tasks and train a random forest (RF). We report the area under the ROC and PR curves (AUROC and AUPR, respectively) using test datasets. Privacy: Unlike de-identified data, there is no straightforward one-to-one mapping between real and synthetic data (generated from random vectors). However, there may be some indirect privacy leakage risks built on correlations between the synthetic data and partial information from real data. Following Torfi & Fox (2020); Theodorou et al. (2023), we consider the membership inference attack that adversaries may apply to de-anonymize private data.\nImplementation Details.\n2Code available at https://github.com/mp2893/medgan 3Code available at https://github.com/astorfi/cor-gan 4Code available at https://github.com/jli0117/ehrMGAN 5Code available at https://github.com/yandex-research/tab-ddpm 6Code available at https://github.com/CompVis/latent-diffusion\nWe perform experiments on two settings: i) an easier setting where we train models on data without missing modality, and ii) a harder setting where we randomly delete p% static samples and q% temporal features. We implemented FLEXGEN-EHR with PyTorch. For training the models, we used Adam (Kingma & Ba, 2015) with the learning rate set to 0.001, and a mini-batch of 128 on a machine equipped with one Nvidia GeForce RTX 3090 and CUDA 11.2. Hyperparamters of FLEXGEN-EHR are selected after grid search. We use a timestep of 50 and a noise scheduling \u03b2 from 1\u00d7 10\u22124 to 1\u00d7 10\u22122."
        },
        {
            "heading": "5.2 Q1: RESULTS-COMPARISON IN FIDELITY",
            "text": "We first evaluates the statistical similarity of the generated and real data. For each method, we generate a synthetic dataset of the same size as the training dataset. We calculate the probabilities for each feature (dimension-wise) within the real and synthetic datasets and then compute R2 and MMD values. Results are presented in Table 2. Across all methods, we find that FLEXGEN-EHR consistently outperforms baselines by making an average improvement of R2 (0.025) and MMD (0.031). In terms of correlation, FLEXGEN-EHR improves R2 by 0.027, 0.019, 0.019, and 0.032 over the strongest baseline on each dataset respectively. In terms of distance, FLEXGEN-EHR reduces MMD by 0.030, 0.028, 0.014, and 0.049 over the strongest baseline on each dataset respectively. Although it is not our main contribution, results demonstrated that the improvement can be attributed to the dual encoder-decoder with latent diffusion."
        },
        {
            "heading": "5.3 Q2: RESULTS-COMPARISON IN UTILITY",
            "text": "Following the experimental setup in (Tang et al., 2020), we trained ML models to predict inhospital mortality and acute respiratory failure (ARF) in our evaluation of utility. Overall, FLEXGENEHR has won 4 out of 4 tests (2 metrics in 4 datasets) and makes an average improvement of AUROC (6.37%) and AUPR (7.16%) over with the strongest baseline across datasets."
        },
        {
            "heading": "5.4 Q3: RESULTS-COMPARISON IN PRIVACY",
            "text": "In this section, we quantify the vulnerability of all methods to adversarys membership inference attacks (Hayes et al., 2018). As shown in Table 4, there is not much difference in the privacy metrics (e.g., the accuracy of an attacker changed from 0.482 to 0.513 on MIMIC-Mortality). It demonstrates that FLEXGEN-EHRachieves comparable empirical privacy results compared to baselines."
        },
        {
            "heading": "5.5 Q4: RESULTS-HETEROGENEOUS TABULAR EHR GENERATION WITH MISSING MODALITY",
            "text": "We investigate the capability of FLEXGEN-EHR to generate with missing modality effectively. We randomly designate p% of samples as lacking temporal features and q% samples as lacking temporal features. We compare with EHR-M-GAN, the strongest baseline selected for this study. In the case of the baseline, we impute samples with absent modality using kNN and proceed to train both the generative and classification models, as EHR-M-GAN is not able to handle such scenarios. Investigation into Generation Fidelity. We report the fidelity metrics (R2) in Figure 2 and 3. It can be observed that FLEXGEN-EHR maintains high generation fidelity even when number of samples with missing modality increases. Examination of Generation Utility. Subsequently, we assess the generation utility. The outcomes shown in Figure 4 demonstrate that the simple imputation of samples notably diminishes discriminative capability, whereas FLEXGEN-EHR can alleviate this problem, delivering performance that is comparable with full samples."
        },
        {
            "heading": "6 CONCLUSION",
            "text": "We introduce FLEXGEN-EHR, a novel generative model that is both flexible and easy-to-use, and can be trained on data with missing modality. We introduce an innovative solution to the missing modality issue by formulating an optimal transport problem in the embedding space, enabling the construction of meaningful and reasonable latent embedding pairs to solve the missing correspondence in the data. By constructing reasonable fused representations for data with missing modality, FLEXGEN-EHR is able to training using all samples without requiring removing then or other imputation techniques. We evaluate FLEXGEN-EHR across a wide range of evaluation metrics including fidelity, utility, and privacy and demonstrate that it outperforms existing generative models for tabular EHRs. Results demonstrate the potential of FLEXGEN-EHR as a general strategy for EHR generative models."
        }
    ],
    "year": 2023
}