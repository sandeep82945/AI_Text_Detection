{
    "abstractText": "This paper introduces GenCorres, a novel unsupervised joint shape matching (JSM) approach. Our key idea is to learn a mesh generator to fit an unorganized deformable shape collection while constraining deformations between adjacent synthetic shapes to preserve geometric structures such as local rigidity and local conformality. GenCorres presents three appealing advantages over existing JSM techniques. First, GenCorres performs JSM among a synthetic shape collection whose size is much bigger than the input shapes and fully leverages the datadriven power of JSM. Second, GenCorres unifies consistent shape matching and pairwise matching (i.e., by enforcing deformation priors between adjacent synthetic shapes). Third, the generator provides a concise encoding of consistent shape correspondences. However, learning a mesh generator from an unorganized shape collection is challenging, requiring a good initialization. GenCorres addresses this issue by learning an implicit generator from the input shapes, which provides intermediate shapes between two arbitrary shapes. We introduce a novel approach for computing correspondences between adjacent implicit surfaces, which we use to regularize the implicit generator. Synthetic shapes of the implicit generator then guide initial fittings (i.e., via template-based deformation) for learning the mesh generator. Experimental results show that GenCorres considerably outperforms state-of-the-art JSM techniques. The synthetic shapes of GenCorres also achieve salient performance gains against state-of-the-art deformable shape generators.",
    "authors": [],
    "id": "SP:b66385b144b395a000aa3de410ef8df77faf1f32",
    "references": [
        {
            "authors": [
                "Panos Achlioptas",
                "Olga Diamanti",
                "Ioannis Mitliagkas",
                "Leonidas J. Guibas"
            ],
            "title": "Learning representations and generative models for 3d point clouds",
            "venue": "In ICML,",
            "year": 2018
        },
        {
            "authors": [
                "Noam Aigerman",
                "Roi Poranne",
                "Yaron Lipman"
            ],
            "title": "Lifted bijections for low distortion surface mappings",
            "venue": "ACM Trans. Graph.,",
            "year": 2014
        },
        {
            "authors": [
                "Marc Alexa",
                "Daniel Cohen-Or",
                "David Levin"
            ],
            "title": "As-rigid-as-possible shape interpolation",
            "venue": "Proceedings of the 27th Annual Conference on Computer Graphics and Interactive Techniques,",
            "year": 2000
        },
        {
            "authors": [
                "Thiemo Alldieck",
                "Hongyi Xu",
                "Cristian Sminchisescu"
            ],
            "title": "imghum: Implicit generative models of 3d human shape and articulated pose",
            "venue": "In ICCV,",
            "year": 2021
        },
        {
            "authors": [
                "Matan Atzmon",
                "Yaron Lipman"
            ],
            "title": "Sal: Sign agnostic learning of shapes from raw data",
            "venue": "In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2020
        },
        {
            "authors": [
                "Matan Atzmon",
                "Yaron Lipman"
            ],
            "title": "SALD: sign agnostic learning with derivatives",
            "venue": "In 9th International Conference on Learning Representations,",
            "year": 2021
        },
        {
            "authors": [
                "Matan Atzmon",
                "David Novotn\u00fd",
                "Andrea Vedaldi",
                "Yaron Lipman"
            ],
            "title": "Augmenting implicit neural shape representations with explicit deformation fields, 2021",
            "year": 2021
        },
        {
            "authors": [
                "Chandrajit Bajaj",
                "Tingran Gao",
                "Zihang He",
                "Qixing Huang",
                "Zhenxiao Liang"
            ],
            "title": "SMAC: simultaneous mapping and clustering using spectral decompositions",
            "venue": "In Proceedings of the 35th International Conference on Machine Learning,",
            "year": 2018
        },
        {
            "authors": [
                "Jan Bednarik",
                "Vladimir G. Kim",
                "Siddhartha Chaudhuri",
                "Shaifali Parashar",
                "Mathieu Salzmann",
                "Pascal Fua",
                "Noam Aigerman"
            ],
            "title": "Temporally-coherent surface reconstruction via metric-consistent atlases",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV),",
            "year": 2021
        },
        {
            "authors": [
                "Mirela Ben-Chen",
                "Adrian Butscher",
                "Justin Solomon",
                "Leonidas J. Guibas"
            ],
            "title": "On discrete killing vector fields and patterns on surfaces",
            "venue": "Comput. Graph. Forum,",
            "year": 2010
        },
        {
            "authors": [
                "Federica Bogo",
                "Javier Romero",
                "Matthew Loper",
                "Michael J. Black"
            ],
            "title": "FAUST: Dataset and evaluation for 3D mesh registration",
            "venue": "In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2014
        },
        {
            "authors": [
                "Federica Bogo",
                "Javier Romero",
                "Gerard Pons-Moll",
                "Michael J. Black"
            ],
            "title": "Dynamic FAUST: registering human bodies in motion",
            "venue": "In CVPR,",
            "year": 2017
        },
        {
            "authors": [
                "Ruojin Cai",
                "Guandao Yang",
                "Hadar Averbuch-Elor",
                "Zekun Hao",
                "Serge Belongie",
                "Noah Snavely",
                "Bharath Hariharan"
            ],
            "title": "Learning gradient fields for shape generation",
            "venue": "In Computer Vision\u2013ECCV 2020: 16th European Conference,",
            "year": 2020
        },
        {
            "authors": [
                "Dongliang Cao",
                "Paul Roetzer",
                "Florian Bernard"
            ],
            "title": "Unsupervised learning of robust spectral shape matching",
            "venue": "ACM Trans. Graph.,",
            "year": 2023
        },
        {
            "authors": [
                "Yuxin Chen",
                "Leonidas J. Guibas",
                "Qi-Xing Huang"
            ],
            "title": "Near-optimal joint object matching via convex relaxation",
            "venue": "In ICML, volume 32 of JMLR Workshop and Conference Proceedings,",
            "year": 2014
        },
        {
            "authors": [
                "Zhiqin Chen",
                "Hao Zhang"
            ],
            "title": "Learning implicit fields for generative shape modeling",
            "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Yu Deng",
                "Jiaolong Yang",
                "Xin Tong"
            ],
            "title": "Deformed implicit field: Modeling 3d shapes with learned dense correspondence",
            "venue": "In CVPR,",
            "year": 2021
        },
        {
            "authors": [
                "Nicolas Donati",
                "Abhishek Sharma",
                "Maks Ovsjanikov"
            ],
            "title": "Deep geometric functional maps: Robust feature learning for shape correspondence",
            "venue": "In CVPR,",
            "year": 2020
        },
        {
            "authors": [
                "Marvin Eisenberger",
                "Daniel Cremers"
            ],
            "title": "Hamiltonian dynamics for real-world shape interpolation",
            "venue": "Computer Vision - ECCV 2020 - 16th European Conference,",
            "year": 2020
        },
        {
            "authors": [
                "Marvin Eisenberger",
                "Zorah L\u00e4hner",
                "Daniel Cremers"
            ],
            "title": "Divergence-free shape correspondence by deformation",
            "venue": "Comput. Graph. Forum,",
            "year": 2019
        },
        {
            "authors": [
                "Marvin Eisenberger",
                "Zorah Lahner",
                "Daniel Cremers"
            ],
            "title": "Smooth shells: Multi-scale shape registration with functional maps",
            "venue": "In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2020
        },
        {
            "authors": [
                "Marvin Eisenberger",
                "Aysim Toker",
                "Laura Leal-Taix\u00e9",
                "Daniel Cremers"
            ],
            "title": "Deep shells: Unsupervised shape correspondence with optimal transport",
            "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems",
            "year": 2020
        },
        {
            "authors": [
                "Marvin Eisenberger",
                "David Novotny",
                "Gael Kerchenbaum",
                "Patrick Labatut",
                "Natalia Neverova",
                "Daniel Cremers",
                "Andrea Vedaldi"
            ],
            "title": "Neuromorph: Unsupervised shape interpolation and correspondence in one go",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 7473\u20137483,",
            "year": 2021
        },
        {
            "authors": [
                "Haoqiang Fan",
                "Hao Su",
                "Leonidas J. Guibas"
            ],
            "title": "A point set generation network for 3d object reconstruction from a single image",
            "venue": "In CVPR,",
            "year": 2017
        },
        {
            "authors": [
                "Maolin Gao",
                "Zorah Lahner",
                "Johan Thunberg",
                "Daniel Cremers",
                "Florian Bernard"
            ],
            "title": "Isometric multishape matching",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 14183\u201314193,",
            "year": 2021
        },
        {
            "authors": [
                "Michael Garland",
                "Paul S. Heckbert"
            ],
            "title": "Surface simplification using quadric error metrics",
            "venue": "In Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques,",
            "year": 1997
        },
        {
            "authors": [
                "Amos Gropp",
                "Lior Yariv",
                "Niv Haim",
                "Matan Atzmon",
                "Yaron Lipman"
            ],
            "title": "Implicit geometric regularization for learning shapes",
            "venue": "In Proceedings of the 37th International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Thibault Groueix",
                "Matthew Fisher",
                "Vladimir G. Kim",
                "Bryan C. Russell",
                "Mathieu Aubry"
            ],
            "title": "3dcoded: 3d correspondences by deep deformation",
            "venue": "Lecture Notes in Computer Science,",
            "year": 2018
        },
        {
            "authors": [
                "Oshri Halimi",
                "Or Litany",
                "Emanuele Rodol\u00e0",
                "Alexander M. Bronstein",
                "Ron Kimmel"
            ],
            "title": "Unsupervised learning of dense shape correspondence",
            "venue": "In CVPR,",
            "year": 2019
        },
        {
            "authors": [
                "Qi-Xing Huang",
                "Leonidas J. Guibas"
            ],
            "title": "Consistent shape maps via semidefinite programming",
            "venue": "Comput. Graph. Forum,",
            "year": 2013
        },
        {
            "authors": [
                "Qi-Xing Huang",
                "Martin Wicke",
                "Bart Adams",
                "Leonidas Guibas"
            ],
            "title": "Shape Decomposition using Modal Analysis",
            "venue": "Computer Graphics Forum,",
            "year": 2009
        },
        {
            "authors": [
                "Qi-Xing Huang",
                "Guo-Xin Zhang",
                "Lin Gao",
                "Shi-Min Hu",
                "Adrian Butscher",
                "Leonidas Guibas"
            ],
            "title": "An optimization approach for extracting and encoding consistent maps in a shape collection",
            "venue": "ACM Trans. Graph.,",
            "year": 2012
        },
        {
            "authors": [
                "Qixing Huang",
                "Bart Adams",
                "Martin Wicke",
                "Leonidas J. Guibas"
            ],
            "title": "Non-rigid registration under isometric deformations",
            "venue": "Comput. Graph. Forum,",
            "year": 2008
        },
        {
            "authors": [
                "Qixing Huang",
                "Fan Wang",
                "Leonidas J. Guibas"
            ],
            "title": "Functional map networks for analyzing and exploring large shape collections",
            "venue": "ACM Trans. Graph.,",
            "year": 2014
        },
        {
            "authors": [
                "Qixing Huang",
                "Zhenxiao Liang",
                "Haoyun Wang",
                "Simiao Zuo",
                "Chandrajit Bajaj"
            ],
            "title": "Tensor maps for synchronizing heterogeneous shape collections",
            "venue": "ACM Trans. Graph.,",
            "year": 2019
        },
        {
            "authors": [
                "Qixing Huang",
                "Xiangru Huang",
                "Bo Sun",
                "Zaiwei Zhang",
                "Junfeng Jiang",
                "Chandrajit Bajaj"
            ],
            "title": "Arapreg: An as-rigid-as possible regularization loss for learning deformable shape generators",
            "venue": "In Proceedings of the IEEE/CVF international conference on computer vision,",
            "year": 2021
        },
        {
            "authors": [
                "Ruqi Huang",
                "Jing Ren",
                "Peter Wonka",
                "Maks Ovsjanikov"
            ],
            "title": "Consistent zoomout: Efficient spectral map synchronization",
            "venue": "Comput. Graph. Forum,",
            "year": 2020
        },
        {
            "authors": [
                "Xiangru Huang",
                "Zhenxiao Liang",
                "Chandrajit Bajaj",
                "Qixing Huang"
            ],
            "title": "Translation synchronization via truncated least squares",
            "venue": "Advances in Neural Information Processing Systems",
            "year": 2017
        },
        {
            "authors": [
                "Xiangru Huang",
                "Zhenxiao Liang",
                "Xiaowei Zhou",
                "Yao Xie",
                "Leonidas J. Guibas",
                "Qixing Huang"
            ],
            "title": "Learning transformation synchronization",
            "venue": "In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2019
        },
        {
            "authors": [
                "Xiangru Huang",
                "Zhenxiao Liang",
                "Qixing Huang"
            ],
            "title": "Uncertainty quantification for multi-scan registration",
            "venue": "ACM Trans. Graph.,",
            "year": 2020
        },
        {
            "authors": [
                "Vladimir G. Kim",
                "Yaron Lipman",
                "Thomas Funkhouser"
            ],
            "title": "Blended intrinsic maps",
            "venue": "ACM Trans. Graph.,",
            "year": 2011
        },
        {
            "authors": [
                "Vladimir G. Kim",
                "Wilmot Li",
                "Niloy J. Mitra",
                "Stephen DiVerdi",
                "Thomas Funkhouser"
            ],
            "title": "Exploring collections of 3d models using fuzzy correspondences",
            "venue": "ACM Trans. Graph.,",
            "year": 2012
        },
        {
            "authors": [
                "Vladislav Kraevoy",
                "Alla Sheffer"
            ],
            "title": "Cross-parameterization and compatible remeshing of 3d models",
            "venue": "ACM Trans. Graph.,",
            "year": 2004
        },
        {
            "authors": [
                "Lei Li",
                "Nicolas Donati",
                "Maks Ovsjanikov"
            ],
            "title": "Learning multi-resolution functional maps with spectral attention for robust shape matching",
            "venue": "In Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems",
            "year": 2022
        },
        {
            "authors": [
                "Ruihui Li",
                "Xianzhi Li",
                "Chi-Wing Fu",
                "Daniel Cohen-Or",
                "Pheng-Ann Heng"
            ],
            "title": "PU-GAN: A point cloud upsampling adversarial network",
            "venue": "In ICCV, pp. 7202\u20137211,",
            "year": 2019
        },
        {
            "authors": [
                "Or Litany",
                "Tal Remez",
                "Emanuele Rodol\u00e0",
                "Alexander M. Bronstein",
                "Michael M. Bronstein"
            ],
            "title": "Deep functional maps: Structured prediction for dense shape correspondence",
            "venue": "In ICCV,",
            "year": 2017
        },
        {
            "authors": [
                "Or Litany",
                "Alexander M. Bronstein",
                "Michael M. Bronstein",
                "Ameesh Makadia"
            ],
            "title": "Deformable shape completion with graph convolutional autoencoders",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2018
        },
        {
            "authors": [
                "William E. Lorensen",
                "Harvey E. Cline"
            ],
            "title": "Marching cubes: A high resolution 3d surface construction algorithm",
            "venue": "Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques,",
            "year": 1987
        },
        {
            "authors": [
                "Shitong Luo",
                "Wei Hu"
            ],
            "title": "Diffusion probabilistic models for 3d point cloud generation",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Haggai Maron",
                "Nadav Dym",
                "Itay Kezurer",
                "Shahar Z. Kovalsky",
                "Yaron Lipman"
            ],
            "title": "Point registration via efficient convex relaxation",
            "venue": "ACM Trans. Graph.,",
            "year": 2016
        },
        {
            "authors": [
                "Simone Melzi",
                "Jing Ren",
                "Emanuele Rodol\u00e0",
                "Abhishek Sharma",
                "Peter Wonka",
                "Maks Ovsjanikov"
            ],
            "title": "Zoomout: spectral upsampling for efficient shape correspondence",
            "venue": "ACM Trans. Graph.,",
            "year": 2019
        },
        {
            "authors": [
                "Lars M. Mescheder",
                "Michael Oechsle",
                "Michael Niemeyer",
                "Sebastian Nowozin",
                "Andreas Geiger"
            ],
            "title": "Occupancy networks: Learning 3d reconstruction in function space",
            "venue": "In CVPR,",
            "year": 2019
        },
        {
            "authors": [
                "Sanjeev Muralikrishnan",
                "Siddhartha Chaudhuri",
                "Noam Aigerman",
                "Vladimir G. Kim",
                "Matthew Fisher",
                "Niloy J. Mitra"
            ],
            "title": "Glass: Geometric latent augmentation for shape spaces",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2022
        },
        {
            "authors": [
                "Andy Nguyen",
                "Mirela Ben-Chen",
                "Katarzyna Welnicka",
                "Yinyu Ye",
                "Leonidas J. Guibas"
            ],
            "title": "An optimization approach to improving collections of shape maps",
            "venue": "Comput. Graph. Forum,",
            "year": 2011
        },
        {
            "authors": [
                "Maks Ovsjanikov",
                "Mirela Ben-Chen",
                "Justin Solomon",
                "Adrian Butscher",
                "Leonidas Guibas"
            ],
            "title": "Functional maps: A flexible representation of maps between shapes",
            "venue": "ACM Trans. Graph.,",
            "year": 2012
        },
        {
            "authors": [
                "Jeong Joon Park",
                "Peter Florence",
                "Julian Straub",
                "Richard A. Newcombe",
                "Steven Lovegrove"
            ],
            "title": "Deepsdf: Learning continuous signed distance functions for shape representation",
            "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Sida Peng",
                "Yuanqing Zhang",
                "Yinghao Xu",
                "Qianqian Wang",
                "Qing Shuai",
                "Hujun Bao",
                "Xiaowei Zhou"
            ],
            "title": "Neural body: Implicit neural representations with structured latent codes for novel view synthesis of dynamic humans",
            "venue": "In CVPR,",
            "year": 2021
        },
        {
            "authors": [
                "Charles R. Qi",
                "Hao Su",
                "Kaichun Mo",
                "Leonidas J. Guibas"
            ],
            "title": "Pointnet: Deep learning on point sets for 3d classification and segmentation",
            "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2017
        },
        {
            "authors": [
                "Marie-Julie Rakotosaona",
                "Maks Ovsjanikov"
            ],
            "title": "Intrinsic point cloud interpolation via dual latent space navigation",
            "venue": "Computer Vision - ECCV 2020 - 16th European Conference,",
            "year": 2020
        },
        {
            "authors": [
                "Anurag Ranjan",
                "Timo Bolkart",
                "Soubhik Sanyal",
                "Michael J. Black"
            ],
            "title": "Generating 3d faces using convolutional mesh autoencoders",
            "venue": "Computer Vision - ECCV 2018 - 15th European Conference,",
            "year": 2018
        },
        {
            "authors": [
                "Jing Ren",
                "Adrien Poulenard",
                "Peter Wonka",
                "Maks Ovsjanikov"
            ],
            "title": "Continuous and orientationpreserving correspondences via functional maps",
            "venue": "ACM Trans. Graph.,",
            "year": 2018
        },
        {
            "authors": [
                "Yusuf Sahillioglu"
            ],
            "title": "Recent advances in shape correspondence",
            "venue": "Vis. Comput.,",
            "year": 2020
        },
        {
            "authors": [
                "Shunsuke Saito",
                "Zeng Huang",
                "Ryota Natsume",
                "Shigeo Morishima",
                "Hao Li",
                "Angjoo Kanazawa"
            ],
            "title": "Pifu: Pixel-aligned implicit function for high-resolution clothed human digitization",
            "venue": "In ICCV,",
            "year": 2019
        },
        {
            "authors": [
                "Shunsuke Saito",
                "Tomas Simon",
                "Jason M. Saragih",
                "Hanbyul Joo"
            ],
            "title": "Pifuhd: Multi-level pixel-aligned implicit function for high-resolution 3d human digitization",
            "venue": "In CVPR,",
            "year": 2020
        },
        {
            "authors": [
                "John Schreiner",
                "Arul Asirvatham",
                "Emil Praun",
                "Hugues Hoppe"
            ],
            "title": "Inter-surface mapping",
            "venue": "In ACM SIGGRAPH 2004 Papers,",
            "year": 2004
        },
        {
            "authors": [
                "Abhishek Sharma",
                "Maks Ovsjanikov"
            ],
            "title": "Weakly supervised deep functional maps for shape matching",
            "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems",
            "year": 2020
        },
        {
            "authors": [
                "Miroslava Slavcheva",
                "Maximilian Baust",
                "Daniel Cremers",
                "Slobodan Ilic"
            ],
            "title": "Killingfusion: Nonrigid 3d reconstruction without correspondences",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2017
        },
        {
            "authors": [
                "Justin Solomon",
                "Mirela Ben-Chen",
                "Adrian Butscher",
                "Leonidas J. Guibas"
            ],
            "title": "As-killing-as-possible vector fields for planar deformation",
            "venue": "Comput. Graph. Forum,",
            "year": 2011
        },
        {
            "authors": [
                "Olga Sorkine",
                "Marc Alexa"
            ],
            "title": "As-rigid-as-possible surface modeling",
            "venue": "In Proceedings of the Fifth Eurographics Symposium on Geometry Processing,",
            "year": 2007
        },
        {
            "authors": [
                "Jos Stam",
                "Ryan M. Schmidt"
            ],
            "title": "On the velocity of an implicit surface",
            "venue": "ACM Trans. Graph.,",
            "year": 2011
        },
        {
            "authors": [
                "Robert W Sumner",
                "Jovan Popovi\u0107"
            ],
            "title": "Deformation transfer for triangle meshes",
            "venue": "ACM Transactions on graphics (TOG),",
            "year": 2004
        },
        {
            "authors": [
                "Ramana Sundararaman",
                "Gautam Pai",
                "Maks Ovsjanikov"
            ],
            "title": "Implicit field supervision for robust non-rigid shape matching",
            "venue": "Computer Vision - ECCV 2022 - 17th European Conference,",
            "year": 2022
        },
        {
            "authors": [
                "Qingyang Tan",
                "Lin Gao",
                "Yu-Kun Lai",
                "Shihong Xia"
            ],
            "title": "Variational autoencoders for deforming 3d mesh models",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2018
        },
        {
            "authors": [
                "Michael Tao",
                "Justin Solomon",
                "Adrian Butscher"
            ],
            "title": "Near-isometric level set tracking",
            "venue": "Comput. Graph. Forum,",
            "year": 2016
        },
        {
            "authors": [
                "Edgar Tretschk",
                "Ayush Tewari",
                "Michael Zollh\u00f6fer",
                "Vladislav Golyanik",
                "Christian Theobalt"
            ],
            "title": "DEMEA: deep mesh autoencoders for non-rigidly deforming objects",
            "venue": "Computer Vision - ECCV 2020 - 16th European Conference,",
            "year": 2020
        },
        {
            "authors": [
                "Oliver van Kaick",
                "Hao Zhang",
                "Ghassan Hamarneh",
                "Daniel Cohen-Or"
            ],
            "title": "A survey on shape correspondence",
            "venue": "In Helwig Hauser and Erik Reinhard (eds.), 31st Annual Conference of the European Association for Computer Graphics, Eurographics 2010 - State of the Art Reports, Norrko\u0308ping,",
            "year": 2010
        },
        {
            "authors": [
                "Nitika Verma",
                "Edmond Boyer",
                "Jakob Verbeek"
            ],
            "title": "Feastnet: Feature-steered graph convolutions for 3d shape analysis",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2018
        },
        {
            "authors": [
                "Lanhui Wang",
                "Amit Singer"
            ],
            "title": "Exact and stable recovery of rotations for robust synchronization",
            "venue": "Information and Inference: A Journal of the IMA,",
            "year": 2013
        },
        {
            "authors": [
                "Yaoqing Yang",
                "Chen Feng",
                "Yiru Shen",
                "Dong Tian"
            ],
            "title": "Foldingnet: Point cloud auto-encoder via deep grid deformation",
            "venue": "In CVPR,",
            "year": 2018
        },
        {
            "authors": [
                "Yusuke Yoshiyasu",
                "Wan-Chun Ma",
                "Eiichi Yoshida",
                "Fumio Kanehiro"
            ],
            "title": "As-conformal-as-possible surface registration",
            "venue": "In Proceedings of the Symposium on Geometry Processing,",
            "year": 2014
        },
        {
            "authors": [
                "Yi Zhou",
                "Chenglei Wu",
                "Zimo Li",
                "Chen Cao",
                "Yuting Ye",
                "Jason M. Saragih",
                "Hao Li",
                "Yaser Sheikh"
            ],
            "title": "Fully convolutional mesh autoencoder using efficient spatially varying kernels",
            "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems",
            "year": 2020
        },
        {
            "authors": [
                "Silvia Zuffi",
                "Angjoo Kanazawa",
                "David W. Jacobs",
                "Michael J. Black"
            ],
            "title": "3d menagerie: Modeling the 3d shape and pose of animals",
            "venue": "In CVPR,",
            "year": 2017
        },
        {
            "authors": [
                "PyTorch Paszke"
            ],
            "title": "2019) B DETAILS OF MESH GENERATOR INITIALIZATION B.1 TEMPLATE-BASED REGISTRATION In order to register the template mesh M to the input shape Si, we first generate T intermediate shape",
            "year": 2019
        },
        {
            "authors": [
                "Gropp"
            ],
            "title": "Under review as a conference",
            "year": 2020
        },
        {
            "authors": [
                "Gropp"
            ],
            "title": "C DETAILS OF DATASETS There are approximately 41k shapes in the original DFAUST dataset. Since there is low variety between the adjacent shapes, recent works Atzmon",
            "year": 2020
        },
        {
            "authors": [
                "D shapes"
            ],
            "title": "MORE RESULTS OF SHAPE SPACE LEARNING We show the shape interpolation results of the state-of-the-art implicit generator Atzmon & Lipman (2021) and our method in Figure 7 and Figure 8. We show 30 interpolated shapes. By adding the proposed geometric deformation regularization loss and cycle-consistency regularization loss",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "Shape matching is a long-standing problem with rich applications in texture transfer Schreiner et al. (2004), compatible remeshing Kraevoy & Sheffer (2004), shape morphing Eisenberger et al. (2021), deformation transfer Sumner & Popovic\u0301 (2004), to name just a few. It also provides foundations for analyzing and processing shape collections Kim et al. (2012); Huang et al. (2014; 2019a). As the sizes and variations of geometric shape collections continue to grow, there are fundamental challenges in formulating and solving the shape matching problems. Pairwise approaches work for similar shape pairs and become less effective on less similar shapes. The real difficulties lie in developing suitable matching potentials (that factor out usually unknown inter-shape variations) and non-convexity in the induced non-convex optimization problems.\nIn contrast to pairwise matching, joint shape matching (JSM) simultaneously optimizes consistent correspondences among a shape collection Nguyen et al. (2011); Huang et al. (2012); Kim et al. (2012); Huang & Guibas (2013); Wang & Singer (2013); Huang et al. (2014; 2019b; 2020b;a). These techniques bypass the difficulty of matching two different shapes through paths of similar shape pairs. Despite significant advances on this topic, existing approaches present three challenges. The first is to obtain a sufficiently large dataset so that each shape has neighboring shapes where shape matching succeeds. The second is that pairwise inputs are usually detached from joint matching. Third, encoding consistent dense correspondences is costly for large shape collections.\nThis paper presents GenCorres for solving the JSM problem. GenCorres takes motivations from recent advances in neural shape generators. Given a collection of shapes with no inter-shape correspondences, GenCorres seeks to learn a mesh generator to fit the input shapes while constraining deformations between adjacent synthetic shapes to preserve geometric structures such as local rigidity and conformality (See Figure 1). Interestingly, this simple framework addresses all the challenges of JSM. GenCorres performs JSM among synthetic shapes, whose size is much larger than the number of input shapes. Second, shape matching is done among neighboring shapes through the local\nrigidity and local conformality potentials, bypassing the difficulty of crafting a non-linear objective function between less similar shapes. In addition, GenCorres unifies pairwise matching (i.e., through deformation priors between adjacent shapes) and consistent matching (i.e., through the generator). Furthermore, the mesh generator provides an efficient encoding of shape correspondences.\nHowever, learning the mesh generator directly from the input shapes is challenging as it requires good initializations. Moreover, optimization procedures, e.g., that minimize the earthmover distances between synthetic shapes and training shapes Fan et al. (2017); Achlioptas et al. (2018), can easily get trapped into local minimums. GenCorres addresses this issue by learning an implicit shape generator from the input shapes. The formulation builds on a novel approach for establishing dense correspondences between adjacent implicit surfaces defined by the shape generator. GenCorres enforces these correspondences to preserve local rigidity and conformality between pairs of adjacent shapes and satisfy the cycle consistency constraint among adjacent shape triplets. These constraints are modeled as regularization terms for learning the implicit shape generator. GenCorres then converts the learned implicit generator into an explicit mesh generator. The implicit generator offers initial consistent correspondences by guiding templatebased registration.\nWe have evaluated GenCorres on various deformable shape collections, including humans and animals. Experimental results show that GenCorres outperforms state-of-the-art JSM approaches and implicit and point cloud shape generators, making GenCorres a universal framework for computing JSM and learning deformable implicit shape generators. An ablation study justifies the importance of different components of GenCorres."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "We discuss relevant work under five topics, which are described below.\nPairwise shape matching. Pairwise shape matching has been studied extensively in the literature Sahillioglu (2020); van Kaick et al. (2010); Kim et al. (2011); Ovsjanikov et al. (2012); Aigerman et al. (2014); Maron et al. (2016); Melzi et al. (2019); Bednarik et al. (2021). A recent line of papers establishes a learning framework under the functional map representation Litany et al. (2017); Halimi et al. (2019); Donati et al. (2020); Sharma & Ovsjanikov (2020); Cao et al. (2023). However, existing techniques still do not work well for less similar shape pairs, where it is challenging to learn suitable matching objective functions.\nNeuroMorph Eisenberger et al. (2021) combines a correspondence module with a shape interpolation module. The network is trained in an unsupervised manner. Several other methods Eisenberger et al. (2019); Eisenberger & Cremers (2020) also optimize interpolation paths to establish correspondences. While GenCorres is relevant to these approaches, GenCorres is a data-driven approach that uses an implicit generator with learned feature representations from all input shapes to drive pairwise matching.\nJoint shape matching. The underlying principle of joint shape matching (JSM) techniques Nguyen et al. (2011); Huang et al. (2012); Kim et al. (2012); Huang & Guibas (2013); Wang & Singer (2013); Huang et al. (2014); Chen et al. (2014); Huang et al. (2019b; 2020b;a) is cycle-consistency. State-of-the-art JSM techniques use the equivalence between the cycle-consistency constraint and the data matrix\u2019s low-rank property, which encodes pairwise maps in blocks (c.f. Huang & Guibas (2013)). This leads to constrained low-rank matrix recovery approaches Huang & Guibas (2013); Wang & Singer (2013); Chen et al. (2014); Huang et al. (2017); Bajaj et al. (2018); Huang et al. (2019b), which possess strong theoretical guarantees.\nGenCorres advances JSM in multiple ways. First, JSM\u2019s performance improves when the input collection size increases, as each shape can have more similar shapes for pairwise shape matching Nguyen\net al. (2011); Huang et al. (2012); Kim et al. (2012); Huang & Guibas (2013). The advantage of GenCorres is that it utilizes a large collection of synthetic shapes and fully leverages the data-driven behavior of JSM. Second, in prior methods, joint matching and pairwise matching are typically decoupled. CZO Huang et al. (2020a) is an exception, yet it still requires good initializations, e.g., Kim et al. (2011). In contrast, GenCorres unifies pairwise matching and joint matching under a simple formulation. Cycle consistency is automatically enforced through the generator. Moreover, JSM performs pairwise matching among neighboring shapes through simple geometric regularizations. Finally, JSM still requires storing consistent matches across the input shape collection Huang et al. (2012); Kim et al. (2012); Huang et al. (2014). GenCorres addresses this issue using a shape generator to compress consistent correspondences effectively.\nGenerative model based correspondences. Generative models under explicit representations provide inter-shape correspondences, making them appealing for practical applications. However, existing methods are sub-optimal for high-fidelity correspondence computation. Most mesh-based generators Tan et al. (2018); Verma et al. (2018); Litany et al. (2018); Tretschk et al. (2020); Rakotosaona & Ovsjanikov (2020); Muralikrishnan et al. (2022) require consistent dense correspondences as input. In contrast to mesh-based generators, point-based generators Fan et al. (2017); Achlioptas et al. (2018); Yang et al. (2018); Li et al. (2019a;b) do not require inter-shape correspondences. The downside is that a point cloud is permutation-invariant. Therefore, the point indices in a point cloud do not always reflect meaningful correspondences. GenCorres addresses these limitations by performing shape matching under implicit representations using shape-preserving potentials.\n3D-CODED Groueix et al. (2018) adopts an auto-encoder to deform a template shape for shape matching. The training combines the Chamfer distance for shape alignment and regularizations on Laplacian operators and edge lengths. As the regularizations of 3D-CODED are designed for isometric deformations, and the Chamfer distance drives training, it mainly applies to minor intershape variations. In contrast, GenCorres applies to shape collections under large deformations.\nMatching under implicit surfaces. A fundamental problem for neural implicit shape representation is defining inter-shape correspondences. The technical challenge is that there is only one constraint along the normal direction at each surface point, c.f., Stam & Schmidt (2011). GenCorres solves a constrained optimization problem to obtain inter-shape correspondences. A relevant formulation has been studied in Tao et al. (2016). Under the implicit representation, a popular way to regularize local rigidity is the Killing vector field approach Ben-Chen et al. (2010); Solomon et al. (2011); Tao et al. (2016); Slavcheva et al. (2017), which is correspondence-free. In contrast, the correspondences computed by GenCorres allow us to introduce the cycle-consistency regularization.\nImplicit neural representations Neural implicit representations have received significant interest on modeling 3D shapes, including man-made objects Park et al. (2019); Mescheder et al. (2019); Chen & Zhang (2019); Deng et al. (2021) and deformable objects Saito et al. (2019; 2020); Alldieck et al. (2021); Peng et al. (2021). Unlike developing novel implicit network architectures, GenCorres focuses on regularization losses that enforce geometric priors for deformable objects.\nDeveloping regularization losses for training implicit neural networks has also been studied recently Gropp et al. (2020); Atzmon et al. (2021). GenCorres is most relevant to Atzmon et al. (2021), which uses an as-killing-as-possible regularization loss to preserve global rigidity. In contrast, GenCorres focuses on maintaining local rigidity/conformality.\nGenCorres is also relevant to ARAPReg Huang et al. (2021). However, defining a suitable loss under the implicit representation has to address the fundamental challenge of determining inter-shape correspondences. GenCorres also enforces the cycle-consistency constraint among induced shape correspondences to enhance the implicit generator."
        },
        {
            "heading": "3 PROBLEM STATEMENT AND APPROACH OVERVIEW",
            "text": "Problem statement. The input to GenCorres is a shape collection S = {S1, \u00b7 \u00b7 \u00b7 , Sn} \u2282 S , where S is the underlying shape space. Each shape Si can be a raw mesh or a raw point cloud.\nGenCorres seeks to learn a mesh generator m\u03b8 : Z \u2192 S, where \u03b8 are the network parameters, Z := Rd is the latent space. Our goal is to align each input shape Si with the corresponding synthetic shape m\u03b8(zi) where zi \u2208 Rd is the latent code of Si. The mesh generator then provides consistent inter-shape correspondences.\nApproach overview. As illustrated in Fig. 2, GenCorres proceeds in three stages. The first two stages provide initializations for the third stage, which learns the mesh generator. Specifically, the first stage adopts variational auto-encoder (VAE) to learn an implicit generator f\u03d5 : R3 \u00d7Z \u2192 R and an\nencoder h\u03c8 from the input shapes:\nmin \u03d5,\u03c8\nlVAE ( f\u03d5, h\u03c8 ) + \u03bbgeorgeo(f \u03d5) + \u03bbcycrcyc(f \u03d5) (1)\nwhere \u03d5 and \u03c8 are the network parameters, lVAE is a VAE loss on the training shapes, \u03bbgeo and \u03bbcyc are the weights of the regularization terms. rgeo(f\u03d5) and rcyc(f\u03d5), which are key contributions of this paper, build on induced correspondences between adjacent implicit shapes defined by f\u03d5. Specifically, rgeo(f\n\u03d5) enforces that the induced correspondences preserve local geometric structures. rcyc(f\u03d5) enforces that the induced correspondences are cycle-consistent. In other words, rgeo(f\u03d5) and rcyc(f\u03d5) perform pairwise matching and consistent matching, respectively. The second stage of GenCorres fits a template mesh to all input shapes along paths of interpolated shapes provided by the implicit shape generator. The resulting correspondences are used to learn an initial mesh generator m\u03b8. The third stage of GenCorres refines the mesh generator by solving another optimization problem:\nmin \u03b8 dexp\n( m\u03b8,S ) + \u03bbdrd(m \u03b8) (2)\nwhere dexp ( m\u03b8,S ) aligns the explicit generator with the input shape collection; rd(m\u03b8) enforces as-conformal-as-possible deformation prior among adjacent shapes; \u03bbd is the weight of rd(m\u03b8)."
        },
        {
            "heading": "4 STAGE I: IMPLICIT SHAPE GENERATOR",
            "text": "This section introduces how to learn the implicit shape generator f\u03d5. We begin with a novel approach for computing dense correspondences between adjacent implicit surfaces in Section 4.1. Based on the induced correspondences, we introduce two regularization terms rgeo(f\u03d5) and rcyc(f\u03d5) in Section 4.2 and Section 4.3, respectively. Finally, Section 4.4 elaborates on the implementation details."
        },
        {
            "heading": "4.1 INDUCED SHAPE CORRESPONDENCES",
            "text": "Our goal is to compute the dense correspondences between the implicit surface f\u03d5(x, z) = 0 and an adjacent implicit surface f\u03d5(x, z+ \u03f5v) = 0, where x \u2208 R3, v \u2208 Rd is a direction in the unit ball Bd and \u03f5 is an infinitesimal value. The computation is nontrivial because of the difficulties in representing correspondences for the implicit surfaces. To this end, we first discretize f\u03d5(x, z) = 0 using a mesh with n vertices g\u03d5(z) \u2208 R3n, e.g., via Marching cube Lorensen & Cline (1987). We then formulate the corresponding vertices of g\u03d5(z) on f\u03d5(x, z+ \u03f5v) = 0 as g\u03d5(z+ \u03f5v) := g\u03d5(z) +dv(z) \u2208 R3n. With this formulation, the goal of computing correspondences between two implicit surfaces is to compute dv(z). As discussed in Stam & Schmidt (2011); Tao et al. (2016), for each vertex g\u03d5i (z) \u2208 R3, the implicit representation offers one constraint on its corresponding d v i (z) \u2208 R3 along the normal direction:\n\u2202f\u03d5\n\u2202x (g\u03d5i (z), z)\nTdvi (z) + \u03f5 \u2202f\u03d5\n\u2202z (g\u03d5i (z), z) Tv = 0. (3)\nTo introduce extra constraints on dv(z), we enforce that the displacements of the 1-ring patch at each vertex g\u03d5i (z) are as-rigid-as possible (ARAP) Alexa et al. (2000); Huang et al. (2009; 2021)\nand as-conformal-as possible (ACAP) Yoshiyasu et al. (2014). In the infinitesimal regime, we can approximate the latent rotation at g\u03d5i (z) as I3 + ci\u00d7. This leads to an ARAP potential on d\nv(z) as n\u2211 i=1 min ci \u2211 j\u2208Ni \u2225ci \u00d7 ( g\u03d5i (z)\u2212 g \u03d5 j (z) ) \u2212 ( dvi (z)\u2212 d v j (z)) \u2225\u22252 = dv(z)TLarap(g\u03d5(z))dv(z) (4) where the expression of L arap (g\u03d5(z)) is in the supp. material.\nSimilarly, we can parameterize the latent similarity transformation at g\u03d5i (z) as (1 + si)I3 + ci\u00d7 and define the ACAP potential as n\u2211 i=1 min si,ci \u2211 j\u2208Ni \u2225(siI3 + ci\u00d7) ( g\u03d5i (z)\u2212 g \u03d5 j (z) ) \u2212 ( dvi (z)\u2212 d v j (z)) \u2225\u22252 = dv(z)TLacap(g\u03d5(z))dv(z) (5)\nwhere the expression of L acap (g\u03d5(z)) is in the supp. material.\nDenote L \u03d5 (z) = \u03b1L arap (g\u03d5(z)) + L acap (g\u03d5(z)) where \u03b1 is a tradeoff parameter (\u03b1 = 10 in our experiments). We compute dv(z) via linearly constrained quadratic programming:\ndv(z) := lim \u00b5\u21920 argmin d dTL \u03d5 (z)d+ \u00b5\u2225d\u22252 s.t. C\u03d5(z)d = \u2212\u03f5F\u03d5(z)v (6)\nwhere C\u03d5(z)d = \u2212\u03f5F\u03d5(z)v is the matrix representation of (3), C\u03d5(z) \u2208 Rn\u00d73n is a block diagonal sparse matrix, F\u03d5(z) \u2208 Rn\u00d7d, \u00b5 is used to avoid degenerate cases, e.g., a rotating sphere. The expressions of C\u03d5(z) and F\u03d5(z) are in the supp. material. It is easy to check that\ndv(z) = \u2212\u03f5G\u03d5(z)v, G\u03d5(z) := L\u03d5(z) + C\u03d5(z)T ( C\u03d5(z)L \u03d5 (z) + C\u03d5(z)T )+ F\u03d5(z) (7)\nwhere A+ denotes the Moore\u2013Penrose inverse of A."
        },
        {
            "heading": "4.2 GEOMETRIC DEFORMATION REGULARIZATION LOSS",
            "text": "We proceed to introduce the first regularization loss rgeo(f\u03d5), which penalizes local rigidity and local conformality distortions of the induced correspondences from f\u03d5(x, z) = 0 to f\u03d5(x, z + \u03f5v) = 0:\nrgeo(z,v) := d v(z) T L \u03d5 (z)dv(z) = \u03f52vTE\u03d5(z)v (8) E\u03d5(z) := F\u03d5(z) T ( C\u03d5(z)L \u03d5 (z)+C\u03d5(z) T )+ F\u03d5(z)\nIntegrating v over the unit ball Bd in Rd Huang et al. (2021) and omitting the constant \u03f52, we define\nrgeo(f \u03d5) = Ez\u223cNd \u222b v\u2208Bd vTE\u03d5(z)vdv = Ez\u223cNd Vol(Bd) d Tr(E\u03d5(z)) (9)\nFigure 3 (Left) shows that rgeo(f\u03d5) can improve the quality of the implicit shape generator. The interpolated shapes are smoother and more shape-preserving, leading to a better shape space ."
        },
        {
            "heading": "4.3 CYCLE-CONSISTENCY REGULARIZATION LOSS",
            "text": "The induced correspondences defined in (7) enable us to compute correspondences between two shapes by composing induced correspondences along a path of intermediate shapes. An additional regularization we can enforce is that the induced correspondences are cycle-consistent. To this end, we constrain 3-cycle consistency Huang & Guibas (2013) among three neighboring synthetic shapes f\u03d5(x, z) = 0, f\u03d5(x, z + \u03f5v) = 0, and f\u03d5(x, z + \u03f5v\u2032) = 0, where v and v\u2032 are two different displacement vectors. Formally speaking, we model 3-cycle distortion as\nrv,v \u2032 (z) := dv(z) + dv \u2032\u2212v(z + \u03f5v)\u2212 dv \u2032 (z) \u2248 \u2212\u03f52 ( vT \u2202G\u03d5(z)\n\u2202z\n) (v \u2212 v\u2032). (10)\nBased on (10), we define the cycle-consistency regularization term as\nrcyc(f \u03d5) = Ez\u223cNd \u222b v\u2208Bd \u2225\u2202G \u03d5(z) \u2202z \u22252F \u00b7 dv (11)\nwhere \u2225 \u00b7 \u2225F is the tensor Frobienus norm. We use finite-difference to compute rcyc(f\u03d5). Specifically, we compute 1\u03f5 \u2225G\n\u03d5(z + \u03f5cycei)\u2212G\u03d5(z)\u22252F as an approximation of rcyc(f\u03d5), where ei is a random standard basis in Rd. In Section 7, we quantitatively show that rcyc(f\u03d5) further enhances the shape space."
        },
        {
            "heading": "4.4 IMPLEMENTATION DETAILS",
            "text": "We use the VAE network proposed in SALD Atzmon & Lipman (2021), where the encoder h\u03c8 is a modified PointNet Qi et al. (2017) and the decoder f\u03d5 is an 8-layer MLP. The data loss lVAE is the VAE loss of SALD. We set \u03bbgeo = 1e\u22123, \u03bbcyc = 1e\u22124, and \u03f5 = 1e\u22123. We use autograd in PyTorch Paszke et al. (2019) to compute F\u03d5(z) and C\u03d5(z). For other derivative computations, we use finite-difference for approximation. More details are deferred to the supp. material."
        },
        {
            "heading": "5 STAGE II: MESH GENERATOR INITIALIZATION",
            "text": "The second stage initializes the mesh generator m\u03b8 using the implicit shape generator f\u03d5 obtained in the previous stage. GenCorres uses the same mesh generator as ARAPReg Huang et al. (2021), which maps the latent code z to displacement vectors associated with vertices of a template mesh M. We use the learned encoder h\u03c8 to find the latent code ztemp of M. Let zi = h\u03c8(Si) be the latent code of the input shape Si. We generate T intermediate shapes g\u03d5(z j i ), 1 \u2264 j \u2264 T (T = 10 in our experiments) by linearly interpolating ztemp and zi: z j i = ztemp + j zi\u2212ztemp T+1 . We then apply non-rigid registration to align the template mesh M with each intermediate shape g\u03d5(zji ) in order, i.e., the alignment of one intermediate shape provides the initialization for aligning the next intermediate shape. Non-rigid alignment adopts an ARAP deformation energy, and the details are deferred to the supp. material.\nAfter propagating the correspondences along the interpolation path in the shape space, we obtain the deformed template miniti for each input shape Si. We then initialize the mesh generator m\n\u03b8 using the standard regression loss:\n\u03b8init = argmin \u03b8 n\u2211 i=1 \u2225miniti \u2212m\u03b8(zi)\u22252. (12)"
        },
        {
            "heading": "6 STAGE III: MESH GENERATOR REFINEMENT",
            "text": "The third stage refines the mesh generator m\u03b8(z) by solving (2). To this end, we define the distance between the mesh generator and the input shape collection as\ndexp ( m\u03b8,S ) := 1\nn n\u2211 i=1 lCD ( m\u03b8(zi),Si), (13)\nwhere m\u03b8(zi) is the i-th generated mesh, lCD is the Chamfer loss. The loss can be optimized robustly thanks to the good initialization of the mesh generator from the first two stages. As (13)\nonly constrains that vertices of the mesh generator lie on the surface, merely minimizing it does not avoid drifting. To address this issue, we define the regularization term rd(m\u03b8) to enforce that the deformations between meshes with similar latent codes preserve geometric structures. We enforce the deformations to be ACAP, which allows the mesh generator to capture large non-rigid deformations. Based on (5), we define\nrd(m \u03b8) = Ez\u223cNd \u222b v\u2208Bd vT \u2202m\u03b8(z) \u2202z T Lacap(m\u03b8(z)) \u2202m\u03b8(z) \u2202z vdv. (14)\nWe then substitute (13) and (14) into (2) to refine the mesh generator. As shown in Figure 4, the mesh generator can improve the shape quality from the implicit generator. Higher shape generation quality implies better inter-shape correspondences since the mesh generator directly provides consistent correspondences."
        },
        {
            "heading": "7 EXPERIMENTAL EVALUATION",
            "text": "This section presents an experimental evaluation of GenCorres. We begin with the experimental setup in Section 7.1. Section 7.2 evaluates the shape generation quality of GenCorres. We proceed to compare GenCorres with state-of-the-art joint shape matching approaches in Section 7.3. Section 7.4 evaluate GenCorres on FAUST Bogo et al. (2014); Ren et al. (2018). Section 7.5 presents an ablation study."
        },
        {
            "heading": "7.1 EXPERIMENTAL SETUP",
            "text": "Datasets. We evaluate GenCorres on two categories of deformable shape collections, i.e., Human and Animal. The Human category considers DFAUST Bogo et al. (2017) and FAUST Bogo et al. (2014). We use the registered SMPL model from the original DFAUST dataset. Since there is low variety between the adjacent shapes, we subsample 2000 meshes from the original dataset. For FAUST, we use the re-meshed version Ren et al. (2018), which contains 100 meshes with different topologies. Animal category has one dataset of 383 shapes Huang et al. (2021), which is generated from SMAL Zuffi et al. (2017). Due to space constraints, we defer the details of dataset processing to the supp. material.\nEvaluation protocols. We evaluate the shape generation quality via reconstruction errors of testing shapes, which use the Chamfer distance between the reconstructed mesh and the raw testing shape. For correspondence evaluation, we report the mean and median geodesic errors of the predicted correspondences between involved shape pairs."
        },
        {
            "heading": "7.2 EVALUATION ON SHAPE GENERATION QUALITY",
            "text": "We compare with the state-of-the-art shape generation approaches that do not rely on pre-defined ground-truth correspondences. Those include implicit shape generators DeepSDF Park et al. (2019) and SALD Atzmon & Lipman (2021), point-based generators, such as LGF Cai et al. (2020) and DPM Luo & Hu (2021). For Human category, we train the shape generator from 1000 shapes and evaluate them on the remaining 1000 shapes. For the Animal category, we use 289 shapes for training and 94 shapes for testing .\nTable 1 provides quantitative comparisons between GenCorres and baseline shape generators. Figure 5 shows the qualitative results. More comparisons are in the supp. material. GenCorres is superior to all baselines in terms of both reconstruction errors and plausibility of synthetic shapes. Quantitatively, the reductions in mean/median reconstruction errors are 2.7%/10.6%, 2.3%/7.0% on DFAUST and SMAL, respectively. Qualitatively, GenCorres provides much better interpolation results compared\nto SALD, especially in preserving the rigidity of arms and legs of the humans. These performance gains mainly come from the geometric regularization losses employed by GenCorres."
        },
        {
            "heading": "7.3 EVALUATION ON JOINT SHAPE MATCHING",
            "text": "Table 2 reports statistics of GenCorres for JSM on DFAUST and SMAL. For baseline comparison, we choose consistent zoom out (CZO) Huang et al. (2020a) and multiple isometric matching (MIM) Gao et al. (2021), which are two state-of-the-art JSM approaches. We evaluate the methods by computing the correspondence error between a template shape to rest of the shapes. We also report the performance of the top-performing pair-wise matching approach NeuroMorph Eisenberger et al. (2021) on these pairs. Note that NeuroMorph is originally not designed for JSM problem. Overall, GenCorres outperforms both JSM baselines by large margins. Specifically, GenCorres reduces the mean/median errors by 62.0%/66.8% and 14.3%/58.0% on DFAUST and SMAL, respectively. The performance gains come from two aspects. First, enforcing ARAP and ACAP deformations in the shape space locally is superior to applying sophisticated deformation models between pairs of shapes directly. Second, GenCorres performs map synchronization on synthetic shapes of the generator whose size is much larger than the input shape collection used by JSM baselines."
        },
        {
            "heading": "7.4 EVALUATION ON PAIR-WISE SHAPE MATCHING",
            "text": "Most of the shape matching approaches are evaluated on the pairwise benchmark FAUST Bogo et al. (2014) with 80/20 training/testing split. As GenCorres is a data-driven approach, directly\napplying it on 80 shapes of FAUST does not offer satisfactory results since learning a deformable shape generator from few training shapes is very difficult. To show the advantage of GenCorres, we augment the training data of FAUST with the DFAUST dataset, resulting in 1080 shapes. The inter-shape correspondences between two testing shapes are given by the correspondences induced from the template model.\nQuantitative results are shown in Table 3. We mainly compare with state-of-the-art template based approaches, including 3D-CODED Groueix et al. (2018) and IFS Sundararaman et al. (2022). For completeness, we also provide the results of the axiomatic methods, including BCICP Ren et al. (2018), ZO Melzi et al. (2019), and S-Shells Eisenberger et al. (2020a); and the spectral learning methods, including GeoFM Donati et al. (2020), AFmap Li et al. (2022), ULRSSM Cao et al. (2023), D-Shells Eisenberger et al. (2020b) and NM Eisenberger et al. (2021). Note that template based methods do not utilize intrinsic features, thus they usually have worse performance compared to spectral learning methods, especially in the region of self-intersection. GenCorres (Ours) outperforms all template based methods. It also achieves comparable performances to spectral learning methods. How to incorporate intrinsic features into our pipeline is left for future research."
        },
        {
            "heading": "7.5 ABLATION STUDY",
            "text": "This section presents an ablation study on different components of GenCorres. As the main purpose of GenCorres is inter-shape correspondences, we focus on how the correspondence quality changes when varying different components of GenCorres (See Table 2).\nWithout the cycle-consistency. Dropping this term hurts the implicit generator. This issue cannot be recovered when converting it into the mesh generator. Quantitatively, the correspondence errors increase by 8.4%/7.9% and 8.8%/8.5% in mean/median on DFAUST and SMAL.\nWithout the geometric regularization. The performance of GenCorres drops considerably when removing the geometric regularization term. The mean/median geodesic errors increase by 488%/549% and 515%/982% on DFAUST and SMAL. This shows that even the cycle-consistency constraint is enforced on the correspondences computed from optimizing ARAP and ACAP losses, constraining that these correspondences minimize ARAP and ACAP losses is critical.\nACAP versus ARAP. GenCorres-NoACAP replaces ACAP regularization with the ARAP regularization. As shown in Table 2, the performance of GenCorres slightly decreases. In particular, on DFAUST that exhibit large inter-shape deformations, i.e., thin versus fat and low versus tall, the performance drops are noticeable. Such performance gaps show that the ACAP regularization loss is important for modeling large non-isometric inter-shape deformations.\nNo explicit generator. Finally, we drop the explicit generator and use the implicit shape generator to propagate correspondences computed along linearly interpolated intermediate shapes, i.e., GenCorres-Imp. The correspondences of the explicit generator (GenCorres) is superior to propagated correspondences of the implicit generator, i.e., 50.4%/37.6% and 17.7%/11.3% of error reductions on DFAUST and SMAL, respectively. Such improvements are expected as the cycle-consistency constraint is only enforced locally, and propagated correspondences between shapes that undergo large deformations may drift."
        },
        {
            "heading": "8 CONCLUSIONS, LIMITATIONS, AND FUTURE WORK",
            "text": "This paper shows that learning shape generators from a collection of shapes leads to consistent inter-shape correspondences that considerably outperform state-of-the-art JSM approaches. The key novelties of GenCorres are the idea of using a mesh generator to formulate JSM and two regularization losses that enforce geometric structures are preserved and induced correspondences are cycle-consistent. We present extensive experimental results to justify the effectiveness of these two regularization terms. Besides high-quality inter-shape correspondences, GenCorres also outperforms state-of-the-art deformable shape generators trained from unorganized shape collections.\nOne limitation of GenCorres is that it requires a reasonably large training dataset to train the shape generator and does not work with few training shapes. In this latter regime, learning pairwise matching has the advantage over GenCorres. This issue may be partially addressed by using a more advanced implicit generator for deformable shapes, which is an area for future research.\nThere are ample future directions. So far, the regularization terms are based on discretizing implicit surfaces into meshes. An interesting question is how to define them without mesh discretization. Another direction is to explore regularization terms for man-made shapes, e.g., to enhance topological generalization and promote physical stability."
        },
        {
            "heading": "A DETAILS OF REGULARIZATION LOSS",
            "text": "A.1 EXPRESSION OF L arap (g\u03d5(z))\nL arap (g\u03d5(z)) =2L\u2297 I3 \u2212Barap ( g\u03d5(z) ) Darap ( g\u03d5(z) ) Barap ( g\u03d5(z) )T ,\nwhere L is the graph Laplacian of the mesh, and Barap ( g\u03d5(z) ) \u2208 R3n\u00d73n is a sparse block matrix\ndefined as\nBarapij ( g\u03d5(z) ) =  \u2211 k\u2208Ni e\u03d5ik(z)\u00d7 i = j\ne\u03d5ij(z)\u00d7 j \u2208 Ni 0 else\nwhere e\u03d5ij(z) = g \u03d5 i (z)\u2212 g \u03d5 j (z) and D\narap ( g\u03d5(z) ) \u2208 R3n\u00d73n is a diagonal block matrix defined as\nDarapii ( g\u03d5(z) ) = ( \u2211 j\u2208Ni ( \u2225e\u03d5ij(z)\u2225 2I3 \u2212 e\u03d5ij(z)e \u03d5 ij(z) T ))\u22121\nA.2 EXPRESSION OF L acap (g\u03d5(z))\nL acap (g\u03d5(z)) =2L\u2297 I3 \u2212Bacap ( g\u03d5(z) ) Dacap ( g\u03d5(z) ) Bacap ( g\u03d5(z) )T ,\nwhere Bacap ( g\u03d5(z) ) \u2208 R3n\u00d74n is a sparse block matrix defined as\nBacapij ( g\u03d5(z) ) =  \u2211 k\u2208Ni ( \u2212e\u03d5ik(z) e \u03d5 ik(z)\u00d7 ) i = j( \u2212e\u03d5ij(z) e \u03d5 ij(z)\u00d7 ) j \u2208 Ni\n0 else and Dacap ( g\u03d5(z) ) \u2208 R4n\u00d74n is a diagonal block matrix defined as\nDacapii ( g\u03d5(z) ) = ( \u2211 j\u2208Ni ( \u2225e\u03d5ij(z)\u2225 2I4 \u2212 diag(0, e\u03d5ij(z)e \u03d5 ij(z) T ))\u22121\nA.3 EXPRESSION OF C\u03d5(z) AND F\u03d5(z)\nConsidering all vertices, the matrix representation of\n\u2202f\u03d5\n\u2202x (g\u03d5i (z), z)\nTdvi (z) + \u03f5 \u2202f\u03d5\n\u2202z (g\u03d5i (z), z) Tv = 0.\ncan be written as C\u03d5(z)d = \u2212\u03f5F\u03d5(z)v, where\nd =  dv1 (z) dv2 (z)\n... dvn(z)\n \u2208 R3n,\nC\u03d5(z) =  \u2202f\u03d5 \u2202x (g \u03d5 1 (z), z) T \u2202f\u03d5 \u2202x (g \u03d5 2 (z), z) T\n. . . \u2202f\u03d5\n\u2202x (g \u03d5 n(z), z) T\n \u2208 Rn\u00d73n,\nF\u03d5(z) =  \u2202f\u03d5 \u2202z (g \u03d5 1 (z), z) T \u2202f\u03d5 \u2202z (g \u03d5 2 (z), z) T\n... \u2202f\u03d5\n\u2202z (g \u03d5 n(z), z) T\n \u2208 Rn\u00d7d,\nA.4 IMPLEMENTATION DETAILS\nBoth the geometric deformation regularization rgeo(f\u03d5) and the cycle-consistency regularization rcyc(f\n\u03d5) rely on the mesh with n vertices that is discretized from f\u03d5(x, z) = 0. We use Marching Cube for discretization. For the human category, we use a voxel grid with size 64\u00d7 77\u00d7 64. For the animal category, the size of the voxel grid is 82\u00d7 50\u00d7 71. The output mesh from the Marching Cube algorithm typically contains more than 5000 vertices. To reduce the computation complexity, we simplify the output mesh into 2000 faces Garland & Heckbert (1997) before computing rgeo(f\u03d5) and\nrcyc(f \u03d5). The number of vertices n is around 1000, thus the size of L \u03d5 (z) is around 3000\u00d7 3000. Computing (L \u03d5 (z))+ only takes about 40ms in PyTorch Paszke et al. (2019)"
        },
        {
            "heading": "B DETAILS OF MESH GENERATOR INITIALIZATION",
            "text": "B.1 TEMPLATE-BASED REGISTRATION\nIn order to register the template mesh M to the input shape Si, we first generate T intermediate shape g\u03d5(zji ), where z j i = ztemp + j zi\u2212ztemp T+1 , 1 \u2264 j \u2264 T . Instead of directly register M to Si, we first register M to g\u03d5(z1i ) with ARAP deformation energy Sorkine & Alexa (2007); Huang et al. (2008). Since M and g\u03d5(z1i ) are very close, we directly apply nearest neighbor search to compute the correspondence for the data term. The registration gives the resulting deformed template M1. We then register M1 to g\u03d5(z2i ) and get the deformed template M2, register M2 to g\u03d5(z3i ) and get the deformed template M3, and so on and so forth. Finally we get the deformed template Mm, which is well-aligned with Si.\nThe interpolation-guided registration typically works well but might fail when the template M is too far from Si, i.e. the two shapes have very different poses. The reason is that the intermediate shapes on the interpolation path might not have good quality. The make full use of the learned shape space, we add shapes from the input shape collection to the interpolation path in these cases. First, we compute the distance between each pair of shape Si and Sj using the distance of their embedded latent codes \u2225zi \u2212 zj\u2225. Based on this distance metric, we build a K-NN graph among the input shape collection. We set K = 25 for the human dataset and K = 40 for the animal dataset. We then perform interpolation-guided registration on each edge (i, j) of the graph and obtain the correspondences between Si and Sj . We use the distortion of the mapped edges Huang et al. (2008) as the weights in the K-NN graph. Finally we compute the shortest path from the template to each shape Si and get the correspondence by composing the correspondences along the shortest path.\nB.2 MESH GENERATOR ARCHITECTURE\nThe network architecture of m\u03b8 follows from that in Huang et al. (2021), which outputs displacements of vertex positions of the template mesh M. We sample 4 resolutions of the mesh connections of the template mesh. The network architecture stacks 4 blocks of convolution + up-sampling layers. The convolution layer employs Chebyshev convolutional filters with 6 Chebyshev polynomials Ranjan et al. (2018). Similar to Zhou et al. (2020), there is a fully connected layer between the latent code and the input to the first convolution layer."
        },
        {
            "heading": "C DETAILS OF DATASETS",
            "text": "There are approximately 41k shapes in the original DFAUST dataset. Since there is low variety between the adjacent shapes, recent works Atzmon & Lipman (2021; 2020); Gropp et al. (2020) create a new training/testing split by uniformly sample 20% shapes from the original dataset. However, we notice that there are still many similar shapes in the splits. For example, almost all motion sequences start from shapes with very similar rest pose. In order to make the dataset more challenging, we further select 1000 shapes from the training split. Specifically, we first learn a VAE Atzmon & Lipman (2021) to embed all the shapes from the training split into different latent vectors. We find that the latent vectors of similar shapes are typically closer. Then we apply farthest point sampling (FPS) to the latent vectors and select the first 1000 shapes. An example is shown in Figure 6. We apply the same approach to the testing split and select another 1000 shapes for testing.\nThe original SMAL dataset from Huang et al. (2021) contains 300 training shapes and 100 testing shapes. We filter out the shapes that have unreasonable self-intersection, leading to 289 training shapes and 94 testing shapes.\nFor both DFAUST and SMAL dataset, we evaluate the correspondences from a template shape to the remaining shapes."
        },
        {
            "heading": "D MORE RESULTS OF SHAPE SPACE LEARNING",
            "text": "We show the shape interpolation results of the state-of-the-art implicit generator Atzmon & Lipman (2021) and our method in Figure 7 and Figure 8. We show 30 interpolated shapes. By adding the proposed geometric deformation regularization loss and cycle-consistency regularization loss, our generator gives more meaningful interpolation results, which are important to the interpolation-guided registration."
        },
        {
            "heading": "E MORE RESULTS OF SHAPE MATCHING",
            "text": "We show the correspondence results of NeuroMorph Eisenberger et al. (2021) and our method in Figure 9 and Figure 10. Our method has lower errors compared to NeuroMorph."
        }
    ],
    "title": "GENCORRES: CONSISTENT SHAPE MATCHING VIA COUPLED IMPLICIT-EXPLICIT SHAPE GENERATIVE MODELS",
    "year": 2023
}