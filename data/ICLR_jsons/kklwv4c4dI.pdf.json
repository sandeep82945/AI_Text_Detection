{
    "abstractText": "Distributed optimization (DO) approaches for saddle point problems (SPP) have recently gained in popularity due to the critical role they play in machine learning (ML). Existing works mostly target smooth unconstrained objectives in Euclidean space, whereas ML problems often involve constraints or non-smooth regularization, which results in a need for composite optimization. Moreover, although non-smooth regularization often serves to induce structure (e.g., sparsity), standard aggregation schemes in distributed optimization break this structure. Addressing these issues, we propose Federated Dual Extrapolation (FeDualEx), an extra-step primal-dual algorithm with local updates, which is the first of its kind to encompass both saddle point optimization and composite objectives under the distributed paradigm. Using a generalized notion of Bregman divergence, we analyze its convergence and communication complexity in the homogeneous setting. Furthermore, the empirical evaluation demonstrates the effectiveness of FeDualEx for inducing structure in these challenging settings.",
    "authors": [
        {
            "affiliations": [],
            "name": "Brian Bullins"
        }
    ],
    "id": "SP:cc9832c0d66292893347e8ce3d9c270b0008d5ca",
    "references": [
        {
            "authors": [
                "Jacob Abernethy",
                "Kevin A. Lai",
                "Kfir Y. Levy",
                "Jun-Kun Wang"
            ],
            "title": "Faster rates for convex-concave games",
            "venue": "Proceedings of the 31st Conference On Learning Theory,",
            "year": 2018
        },
        {
            "authors": [
                "Kimon Antonakopoulos",
                "Veronica Belmega",
                "Panayotis Mertikopoulos"
            ],
            "title": "An adaptive mirror-prox method for variational inequalities with singular operators",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "K.J. Arrow",
                "L. Hurwicz",
                "H. Uzawa"
            ],
            "title": "Studies in linear and non-linear programming",
            "year": 1958
        },
        {
            "authors": [
                "Jean-Fran\u00e7ois Aujol",
                "Antonin Chambolle"
            ],
            "title": "Dual norms and image decomposition models",
            "venue": "International journal of computer vision,",
            "year": 2005
        },
        {
            "authors": [
                "Necdet Serhat Aybat",
                "Erfan Yazdandoost Hamedani"
            ],
            "title": "A primal-dual method for conic constrained distributed optimization problems",
            "venue": "Advances in neural information processing systems,",
            "year": 2016
        },
        {
            "authors": [
                "Site Bai",
                "Chuyang Ke",
                "Jean Honorio"
            ],
            "title": "On the dual problem of convexified convolutional neural networks",
            "venue": "Transactions on Machine Learning Research,",
            "year": 2024
        },
        {
            "authors": [
                "Amir Beck",
                "Marc Teboulle"
            ],
            "title": "Mirror descent and nonlinear projected subgradient methods for convex optimization",
            "venue": "Operations Research Letters,",
            "year": 2003
        },
        {
            "authors": [
                "Aleksandr Beznosikov",
                "Alexander Gasnikov"
            ],
            "title": "Similarity, compression and local steps: Three pillars of efficient communications for distributed variational inequalities",
            "venue": "arXiv preprint arXiv:2302.07615,",
            "year": 2023
        },
        {
            "authors": [
                "Aleksandr Beznosikov",
                "Valentin Samokhin",
                "Alexander Gasnikov"
            ],
            "title": "Distributed saddle-point problems: Lower bounds, optimal and robust algorithms",
            "venue": "arXiv preprint arXiv:2010.13112,",
            "year": 2020
        },
        {
            "authors": [
                "Aleksandr Beznosikov",
                "Gesualdo Scutari",
                "Alexander Rogozin",
                "Alexander Gasnikov"
            ],
            "title": "Distributed saddle-point problems under data similarity",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Aleksandr Beznosikov",
                "Pavel Dvurechenskii",
                "Anastasiia Koloskova",
                "Valentin Samokhin",
                "Sebastian U Stich",
                "Alexander Gasnikov"
            ],
            "title": "Decentralized local stochastic extra-gradient for variational inequalities",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Ekaterina Borodich",
                "Vladislav Tominin",
                "Yaroslav Tominin",
                "Dmitry Kovalev",
                "Alexander Gasnikov",
                "Pavel Dvurechensky"
            ],
            "title": "Accelerated variance-reduced methods for saddle-point problems",
            "venue": "EURO Journal on Computational Optimization,",
            "year": 2022
        },
        {
            "authors": [
                "Ekaterina Borodich",
                "Georgiy Kormakov",
                "Dmitry Kovalev",
                "Aleksandr Beznosikov",
                "Alexander Gasnikov"
            ],
            "title": "Optimal algorithm with complexity separation for strongly convex-strongly concave composite saddle point problems",
            "venue": "arXiv preprint arXiv:2307.12946,",
            "year": 2023
        },
        {
            "authors": [
                "Kristian Bredies",
                "Dirk A Lorenz",
                "Stefan Reiterer"
            ],
            "title": "Minimization of non-smooth, non-convex functionals by iterative thresholding",
            "venue": "Journal of Optimization Theory and Applications,",
            "year": 2015
        },
        {
            "authors": [
                "L.M. Bregman"
            ],
            "title": "The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming",
            "venue": "USSR Computational Mathematics and Mathematical Physics,",
            "year": 1967
        },
        {
            "authors": [
                "Antoni Buades",
                "Bartomeu Coll",
                "Jean-Michel Morel"
            ],
            "title": "A review of image denoising algorithms, with a new one",
            "venue": "Multiscale modeling & simulation,",
            "year": 2005
        },
        {
            "authors": [
                "S\u00e9bastien Bubeck"
            ],
            "title": "Convex optimization: Algorithms and complexity",
            "venue": "Foundations and Trends\u00ae in Machine Learning,",
            "year": 2015
        },
        {
            "authors": [
                "Brian Bullins",
                "Kevin A Lai"
            ],
            "title": "Higher-order methods for convex-concave min-max optimization and monotone variational inequalities",
            "venue": "SIAM Journal on Optimization,",
            "year": 2022
        },
        {
            "authors": [
                "Brian Bullins",
                "Kshitij Patel",
                "Ohad Shamir",
                "Nathan Srebro",
                "Blake E Woodworth"
            ],
            "title": "A stochastic newton algorithm for distributed convex optimization",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Jian-Feng Cai",
                "Emmanuel J Cand\u00e8s",
                "Zuowei Shen"
            ],
            "title": "A singular value thresholding algorithm for matrix completion",
            "venue": "SIAM Journal on optimization,",
            "year": 1956
        },
        {
            "authors": [
                "Xuanyu Cao",
                "Tamer Ba\u015far",
                "Suhas Diggavi",
                "Yonina C Eldar",
                "Khaled B Letaief",
                "H Vincent Poor",
                "Junshan Zhang"
            ],
            "title": "Communication-efficient distributed learning: An overview",
            "venue": "IEEE journal on selected areas in communications,",
            "year": 2023
        },
        {
            "authors": [
                "Y Censor",
                "SA Zenios"
            ],
            "title": "Proximal minimization algorithm with d-functions",
            "venue": "Journal of Optimization Theory and Applications,",
            "year": 1992
        },
        {
            "authors": [
                "A. Chambolle",
                "Thomas Pock"
            ],
            "title": "A first-order primal-dual algorithm for convex problems with applications to imaging",
            "venue": "Journal of Mathematical Imaging and Vision,",
            "year": 2011
        },
        {
            "authors": [
                "Antonin Chambolle",
                "Thomas Pock"
            ],
            "title": "On the ergodic convergence rates of a first-order primal\u2013dual algorithm",
            "venue": "Mathematical Programming,",
            "year": 2016
        },
        {
            "authors": [
                "Cheng Chen",
                "Luo Luo",
                "Weinan Zhang",
                "Yong Yu"
            ],
            "title": "Efficient projection-free algorithms for saddle point problems",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Pin-Yu Chen",
                "Cho-Jui Hsieh"
            ],
            "title": "Chapter 12 - adversarial training",
            "venue": "doi: https://doi.org/10.1016/B978-0-12-824020-5.00023-5. URL https: //www.sciencedirect.com/science/article/pii/B9780128240205000235",
            "year": 2023
        },
        {
            "authors": [
                "Michael B. Cohen",
                "Aaron Sidford",
                "Kevin Tian"
            ],
            "title": "Relative lipschitzness in extragradient methods and a direct recipe for acceleration",
            "venue": "12th Innovations in Theoretical Computer Science Conference, ITCS 2021,",
            "year": 2021
        },
        {
            "authors": [
                "Patrick L Combettes",
                "Jean-Christophe Pesquet"
            ],
            "title": "Primal-dual splitting algorithm for solving inclusions with mixtures of composite, lipschitzian, and parallel-sum type monotone operators",
            "venue": "Set-Valued and variational analysis,",
            "year": 2012
        },
        {
            "authors": [
                "Alexandros G Dimakis",
                "Anand D Sarwate",
                "Martin J Wainwright"
            ],
            "title": "Geographic gossip: Efficient aggregation for sensor networks",
            "venue": "In Proceedings of the 5th international conference on Information processing in sensor networks,",
            "year": 2006
        },
        {
            "authors": [
                "John C Duchi",
                "Shai Shalev-Shwartz",
                "Yoram Singer",
                "Ambuj Tewari"
            ],
            "title": "Composite objective mirror descent",
            "venue": "In Conference on Learning Theory (COLT),",
            "year": 2010
        },
        {
            "authors": [
                "John C Duchi",
                "Alekh Agarwal",
                "Martin J Wainwright"
            ],
            "title": "Dual averaging for distributed optimization: Convergence analysis and network scaling",
            "venue": "IEEE Transactions on Automatic control,",
            "year": 2011
        },
        {
            "authors": [
                "Nicolas Flammarion",
                "Francis Bach"
            ],
            "title": "Stochastic composite least-squares regression with convergence rate o(1/n)",
            "venue": "In Conference on Learning Theory (COLT),",
            "year": 2017
        },
        {
            "authors": [
                "Margalit R Glasgow",
                "Honglin Yuan",
                "Tengyu Ma"
            ],
            "title": "Sharp bounds for federated averaging (local sgd) and continuous perspective",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2022
        },
        {
            "authors": [
                "Ian Goodfellow",
                "Jean Pouget-Abadie",
                "Mehdi Mirza",
                "Bing Xu",
                "David Warde-Farley",
                "Sherjil Ozair",
                "Aaron Courville",
                "Yoshua Bengio"
            ],
            "title": "Generative adversarial nets",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2014
        },
        {
            "authors": [
                "Vipul Gupta",
                "Avishek Ghosh",
                "Micha\u0142 Derezi\u0144ski",
                "Rajiv Khanna",
                "Kannan Ramchandran",
                "Michael W. Mahoney"
            ],
            "title": "Localnewton: Reducing communication rounds for distributed learning",
            "venue": "Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Farzin Haddadpour",
                "Mohammad Mahdi Kamani",
                "Mehrdad Mahdavi",
                "Viveck Cadambe"
            ],
            "title": "Local sgd with periodic averaging: Tighter analysis and adaptive synchronization",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Trevor Hastie",
                "Robert Tibshirani",
                "Martin Wainwright"
            ],
            "title": "Statistical learning with sparsity: the lasso and generalizations",
            "venue": "CRC press,",
            "year": 2015
        },
        {
            "authors": [
                "Niao He",
                "Anatoli Juditsky",
                "Arkadi Nemirovski"
            ],
            "title": "Mirror prox algorithm for multi-term composite minimization and semi-separable problems",
            "venue": "Computational Optimization and Applications,",
            "year": 2015
        },
        {
            "authors": [
                "Yunlong He",
                "Renato DC Monteiro"
            ],
            "title": "Accelerating block-decomposition first-order methods for solving composite saddle-point and two-player nash equilibrium problems",
            "venue": "SIAM Journal on Optimization,",
            "year": 2015
        },
        {
            "authors": [
                "Yunlong He",
                "Renato DC Monteiro"
            ],
            "title": "An accelerated hpe-type algorithm for a class of composite convex-concave saddle-point problems",
            "venue": "SIAM Journal on Optimization,",
            "year": 2016
        },
        {
            "authors": [
                "Jean-Baptiste Hiriart-Urruty",
                "Claude Lemar\u00e9chal"
            ],
            "title": "Fundamentals of convex analysis",
            "venue": "Springer Science & Business Media,",
            "year": 2004
        },
        {
            "authors": [
                "Charlie Hou",
                "Kiran K Thekumparampil",
                "Giulia Fanti",
                "Sewoong Oh"
            ],
            "title": "Efficient algorithms for federated saddle point optimization",
            "venue": "arXiv preprint arXiv:2102.06333,",
            "year": 2021
        },
        {
            "authors": [
                "Ruichen Jiang",
                "Aryan Mokhtari"
            ],
            "title": "Generalized optimistic methods for convex-concave saddle point problems",
            "venue": "arXiv preprint arXiv:2202.09674,",
            "year": 2022
        },
        {
            "authors": [
                "Anatoli Juditsky",
                "Arkadi Nemirovski",
                "Claire Tauvel"
            ],
            "title": "Solving variational inequalities with stochastic mirror-prox algorithm",
            "venue": "Stochastic Systems,",
            "year": 2011
        },
        {
            "authors": [
                "Peter Kairouz",
                "H Brendan McMahan",
                "Brendan Avent",
                "Aur\u00e9lien Bellet",
                "Mehdi Bennis",
                "Arjun Nitin Bhagoji",
                "Kallista Bonawitz",
                "Zachary Charles",
                "Graham Cormode",
                "Rachel Cummings"
            ],
            "title": "Advances and open problems in federated learning",
            "venue": "Foundations and Trends\u00ae in Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Sai Praneeth Karimireddy",
                "Satyen Kale",
                "Mehryar Mohri",
                "Sashank Reddi",
                "Sebastian Stich",
                "Ananda Theertha Suresh"
            ],
            "title": "Scaffold: Stochastic controlled averaging for federated learning",
            "venue": "In International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Ahmed Khaled",
                "Konstantin Mishchenko",
                "Peter Richt\u00e1rik"
            ],
            "title": "Tighter theory for local sgd on identical and heterogeneous data",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2020
        },
        {
            "authors": [
                "Jakub Kone\u010dn\u1ef3",
                "H Brendan McMahan",
                "Felix X Yu",
                "Peter Richt\u00e1rik",
                "Ananda Theertha Suresh",
                "Dave Bacon"
            ],
            "title": "Federated learning: Strategies for improving communication efficiency",
            "venue": "NeurIPS Private Multi-Party Machine Learning Workshop,",
            "year": 2016
        },
        {
            "authors": [
                "G.M. Korpelevich"
            ],
            "title": "The extragradient method for finding saddle points and other problem",
            "venue": "Ekonomika i Matematicheskie Metody,",
            "year": 1976
        },
        {
            "authors": [
                "Georgios Kotsalis",
                "Guanghui Lan",
                "Tianjiao Li"
            ],
            "title": "Simple and optimal methods for stochastic variational inequalities, i: operator extrapolation",
            "venue": "SIAM Journal on Optimization,",
            "year": 2073
        },
        {
            "authors": [
                "D. Kovalev",
                "Elnur Gasanov",
                "Peter Richt\u00e1rik",
                "Alexander V. Gasnikov"
            ],
            "title": "Lower bounds and optimal algorithms for smooth and strongly convex decentralized optimization over time-varying networks",
            "venue": "In Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Dmitry Kovalev",
                "Egor Shulgin",
                "Peter Richt\u00e1rik",
                "Alexander V Rogozin",
                "Alexander Gasnikov. Adom"
            ],
            "title": "Accelerated decentralized optimization method for time-varying networks",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Dmitry Kovalev",
                "Aleksandr Beznosikov",
                "Ekaterina Borodich",
                "Alexander Gasnikov",
                "Gesualdo Scutari"
            ],
            "title": "Optimal gradient sliding and its application to optimal distributed optimization under similarity",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Sucheol Lee",
                "Donghwan Kim"
            ],
            "title": "Fast extra gradient methods for smooth structured nonconvexnonconcave minimax problems",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Guoyin Li",
                "Ting Kei Pong"
            ],
            "title": "Global convergence of splitting methods for nonconvex composite optimization",
            "venue": "SIAM Journal on Optimization,",
            "year": 2015
        },
        {
            "authors": [
                "Li Li",
                "Yuxi Fan",
                "Mike Tse",
                "Kuo-Yi Lin"
            ],
            "title": "A review of applications in federated learning",
            "venue": "Computers & Industrial Engineering,",
            "year": 2020
        },
        {
            "authors": [
                "Xiang Li",
                "Kaixuan Huang",
                "Wenhao Yang",
                "Shusen Wang",
                "Zhihua Zhang"
            ],
            "title": "On the convergence of fedavg on non-iid data",
            "venue": "In International Conference on Learning Representations,",
            "year": 2020
        },
        {
            "authors": [
                "Tianyi Lin",
                "Chi Jin",
                "Michael I Jordan"
            ],
            "title": "Near-optimal algorithms for minimax optimization",
            "venue": "In Conference on Learning Theory,",
            "year": 2020
        },
        {
            "authors": [
                "Changxin Liu",
                "Zirui Zhou",
                "Jian Pei",
                "Yong Zhang",
                "Yang Shi"
            ],
            "title": "Decentralized composite optimization in stochastic networks: A dual averaging approach with linear convergence",
            "venue": "IEEE Transactions on Automatic Control,",
            "year": 2022
        },
        {
            "authors": [
                "Weijie Liu",
                "Aryan Mokhtari",
                "Asuman Ozdaglar",
                "Sarath Pattathil",
                "Zebang Shen",
                "Nenggan Zheng"
            ],
            "title": "A decentralized proximal point-type method for saddle point problems",
            "venue": "Annual Workshop on Optimization for Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Aleksander Madry",
                "Aleksandar Makelov",
                "Ludwig Schmidt",
                "Dimitris Tsipras",
                "Adrian Vladu"
            ],
            "title": "Towards deep learning models resistant to adversarial attacks",
            "venue": "In International Conference on Learning Representations,",
            "year": 2018
        },
        {
            "authors": [
                "Brendan McMahan",
                "Eider Moore",
                "Daniel Ramage",
                "Seth Hampson",
                "Blaise Aguera y Arcas"
            ],
            "title": "Communication-Efficient Learning of Deep Networks from Decentralized Data",
            "venue": "Proceedings of the 20th International Conference on Artificial Intelligence and Statistics,",
            "year": 2017
        },
        {
            "authors": [
                "Panayotis Mertikopoulos",
                "Bruno Lecouat",
                "Houssam Zenati",
                "Chuan-Sheng Foo",
                "Vijay Chandrasekhar",
                "Georgios Piliouras"
            ],
            "title": "Optimistic mirror descent in saddle-point problems: Going the extra(gradient) mile",
            "venue": "In International Conference on Learning Representations,",
            "year": 2019
        },
        {
            "authors": [
                "Konstantin Mishchenko",
                "Dmitry Kovalev",
                "Egor Shulgin",
                "Peter Richt\u00e1rik",
                "Yura Malitsky"
            ],
            "title": "Revisiting stochastic extragradient",
            "venue": "In International Conference on Artificial Intelligence and Statistics,",
            "year": 2020
        },
        {
            "authors": [
                "Konstantin Mishchenko",
                "Grigory Malinovsky",
                "Sebastian Stich",
                "Peter Richt\u00e1rik"
            ],
            "title": "Proxskip: Yes! local gradient steps provably lead to communication acceleration! finally",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Seyed-Mohsen Moosavi-Dezfooli",
                "Alhussein Fawzi",
                "Pascal Frossard"
            ],
            "title": "Deepfool: A simple and accurate method to fool deep neural networks",
            "venue": "In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2016
        },
        {
            "authors": [
                "Seyed-Mohsen Moosavi-Dezfooli",
                "Alhussein Fawzi",
                "Omar Fawzi",
                "Pascal Frossard"
            ],
            "title": "Universal adversarial perturbations",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2017
        },
        {
            "authors": [
                "Angelia Nedich"
            ],
            "title": "Convergence rate of distributed averaging dynamics and optimization in networks",
            "venue": "Foundations and Trends\u00ae in Systems and Control,",
            "year": 2015
        },
        {
            "authors": [
                "Arkadi Nemirovski"
            ],
            "title": "Prox-method with rate of convergence o (1/t) for variational inequalities with lipschitz continuous monotone operators and smooth convex-concave saddle point problems",
            "venue": "SIAM Journal on Optimization,",
            "year": 2004
        },
        {
            "authors": [
                "Arkadij Semenovi\u010d Nemirovskij",
                "David Borisovich Yudin"
            ],
            "title": "Problem complexity and method efficiency in optimization",
            "year": 1983
        },
        {
            "authors": [
                "Yu Nesterov"
            ],
            "title": "Smooth minimization of non-smooth functions",
            "venue": "Mathematical programming,",
            "year": 2005
        },
        {
            "authors": [
                "Yurii Nesterov"
            ],
            "title": "Dual extrapolation and its applications to solving variational inequalities and related problems",
            "venue": "Mathematical Programming,",
            "year": 2007
        },
        {
            "authors": [
                "Yurii Nesterov"
            ],
            "title": "Primal-dual subgradient methods for convex problems",
            "venue": "Mathematical programming,",
            "year": 2009
        },
        {
            "authors": [
                "Yuyuan Ouyang",
                "Yangyang Xu"
            ],
            "title": "Lower complexity bounds of first-order methods for convexconcave bilinear saddle-point problems",
            "venue": "Mathematical Programming,",
            "year": 2021
        },
        {
            "authors": [
                "Leonid Denisovich Popov"
            ],
            "title": "A modification of the arrow-hurwicz method for search of saddle points",
            "venue": "Mathematical notes of the Academy of Sciences of the USSR,",
            "year": 1980
        },
        {
            "authors": [
                "Michael Rabbat"
            ],
            "title": "Multi-agent mirror descent for decentralized stochastic optimization",
            "venue": "IEEE 6th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP),",
            "year": 2015
        },
        {
            "authors": [
                "Ali Ramezani-Kebrya",
                "Kimon Antonakopoulos",
                "Igor Krawczuk",
                "Justin Deschenaux",
                "Volkan Cevher"
            ],
            "title": "Distributed extra-gradient with optimal complexity and communication guarantees",
            "venue": "In The Eleventh International Conference on Learning Representations,",
            "year": 2023
        },
        {
            "authors": [
                "R. Tyrrell Rockafellar"
            ],
            "title": "Convex Analysis. Princeton Landmarks in Mathematics and Physics",
            "year": 1970
        },
        {
            "authors": [
                "Alexander Rogozin",
                "Aleksandr Beznosikov",
                "Darina Dvinskikh",
                "Dmitry Kovalev",
                "Pavel Dvurechensky",
                "Alexander Gasnikov"
            ],
            "title": "Decentralized distributed optimization for saddle point problems",
            "venue": "arXiv preprint arXiv:2102.07758,",
            "year": 2021
        },
        {
            "authors": [
                "Mher Safaryan",
                "Rustem Islamov",
                "Xun Qian",
                "Peter Richtarik"
            ],
            "title": "Fednl: Making newton-type methods applicable to federated learning",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Arda Sahiner",
                "Tolga Ergen",
                "Batu Ozturkler",
                "Burak Bartan",
                "John M. Pauly",
                "Morteza Mardani",
                "Mert Pilanci"
            ],
            "title": "Hidden convexity of wasserstein GANs: Interpretable generative models with closed-form solutions",
            "venue": "In International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Ali Shafahi",
                "Mahyar Najibi",
                "Zheng Xu",
                "John Dickerson",
                "Larry S Davis",
                "Tom Goldstein"
            ],
            "title": "Universal adversarial training",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "Ohad Shamir",
                "Nati Srebro",
                "Tong Zhang"
            ],
            "title": "Communication-efficient distributed optimization using an approximate newton-type method",
            "venue": "In International conference on machine learning,",
            "year": 2014
        },
        {
            "authors": [
                "Pranay Sharma",
                "Rohan Panda",
                "Gauri Joshi",
                "Pramod Varshney"
            ],
            "title": "Federated minimax optimization: Improved convergence analyses and algorithms",
            "venue": "In International Conference on Machine Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Pranay Sharma",
                "Rohan Panda",
                "Gauri Joshi"
            ],
            "title": "Federated minimax optimization with client heterogeneity",
            "venue": "arXiv preprint arXiv:2302.04249,",
            "year": 2023
        },
        {
            "authors": [
                "Yan Shen",
                "Jian Du",
                "Han Zhao",
                "Benyu Zhang",
                "Zhanghexuan Ji",
                "Mingchen Gao"
            ],
            "title": "Fedmm: Saddle point optimization for federated adversarial domain adaptation",
            "venue": "In The 22nd International Conference on Autonomous Agents and Multiagent Systems (AAMAS),",
            "year": 2023
        },
        {
            "authors": [
                "Zhan Shi",
                "Xinhua Zhang",
                "Yaoliang Yu"
            ],
            "title": "Bregman divergence for stochastic variance reduction: saddle-point and adversarial prediction",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2017
        },
        {
            "authors": [
                "Mircea Sofonea",
                "Andaluzia Matei"
            ],
            "title": "Variational inequalities with applications: a study of antiplane frictional contact problems, volume 18",
            "venue": "Springer Science & Business Media,",
            "year": 2009
        },
        {
            "authors": [
                "Mikhail V. Solodov",
                "Benar Fux Svaiter"
            ],
            "title": "A hybrid approximate extragradient \u2013 proximal point algorithm using the enlargement of a maximal monotone operator",
            "venue": "Set-Valued Analysis,",
            "year": 1999
        },
        {
            "authors": [
                "Chaobing Song",
                "Zhengyuan Zhou",
                "Yichao Zhou",
                "Yong Jiang",
                "Yi Ma"
            ],
            "title": "Optimistic dual extrapolation for coherent non-monotone variational inequalities",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Sebastian U. Stich"
            ],
            "title": "Local SGD converges fast and communicates little",
            "venue": "In International Conference on Learning Representations,",
            "year": 2019
        },
        {
            "authors": [
                "Gilbert Strang"
            ],
            "title": "Linear algebra and its applications",
            "year": 2006
        },
        {
            "authors": [
                "Robert Tibshirani"
            ],
            "title": "Regression shrinkage and selection via the lasso",
            "venue": "Journal of the Royal Statistical Society. Series B (Methodological),",
            "year": 1996
        },
        {
            "authors": [
                "Vladislav Tominin",
                "Yaroslav Tominin",
                "Ekaterina Borodich",
                "Dmitry Kovalev",
                "Alexander Gasnikov",
                "Pavel Dvurechensky"
            ],
            "title": "On accelerated methods for saddle-point problems with composite structure",
            "venue": "arXiv preprint arXiv:2103.09344,",
            "year": 2021
        },
        {
            "authors": [
                "Qianqian Tong",
                "Guannan Liang",
                "Tan Zhu",
                "Jinbo Bi"
            ],
            "title": "Federated nonconvex sparse learning",
            "venue": "arXiv preprint arXiv:2101.00052,",
            "year": 2020
        },
        {
            "authors": [
                "Quoc Tran Dinh",
                "Nhan H Pham",
                "Dzung Phan",
                "Lam Nguyen"
            ],
            "title": "Feddr\u2013randomized douglasrachford splitting algorithms for nonconvex federated composite optimization",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Paul Tseng"
            ],
            "title": "On accelerated proximal gradient methods for convex-concave optimization",
            "venue": "SIAM Journal on Optimization,",
            "year": 2008
        },
        {
            "authors": [
                "Hoi-To Wai",
                "Zhuoran Yang",
                "Zhaoran Wang",
                "Mingyi Hong"
            ],
            "title": "Multi-agent reinforcement learning via double averaging primal-dual optimization",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2018
        },
        {
            "authors": [
                "Jianyu Wang",
                "Zachary Charles",
                "Zheng Xu",
                "Gauri Joshi",
                "H Brendan McMahan",
                "Maruan Al-Shedivat",
                "Galen Andrew",
                "Salman Avestimehr",
                "Katharine Daly",
                "Deepesh Data"
            ],
            "title": "A field guide to federated optimization",
            "venue": "arXiv preprint arXiv:2107.06917,",
            "year": 2021
        },
        {
            "authors": [
                "Blake Woodworth",
                "Kumar Kshitij Patel",
                "Sebastian Stich",
                "Zhen Dai",
                "Brian Bullins",
                "Brendan Mcmahan",
                "Ohad Shamir",
                "Nathan Srebro"
            ],
            "title": "Is local sgd better than minibatch sgd",
            "venue": "In International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Blake E Woodworth",
                "Kumar Kshitij Patel",
                "Nati Srebro"
            ],
            "title": "Minibatch vs local sgd for heterogeneous distributed learning",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Lin Xiao"
            ],
            "title": "Dual averaging methods for regularized stochastic learning and online optimization",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2010
        },
        {
            "authors": [
                "Tesi Xiao",
                "Xuxing Chen",
                "Krishnakumar Balasubramanian",
                "Saeed Ghadimi"
            ],
            "title": "A one-sample decentralized proximal algorithm for non-convex stochastic composite optimization",
            "venue": "Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence,",
            "year": 2023
        },
        {
            "authors": [
                "Jinming Xu",
                "Ye Tian",
                "Ying Sun",
                "Gesualdo Scutari"
            ],
            "title": "Distributed algorithms for composite optimization: Unified framework and convergence analysis",
            "venue": "IEEE Transactions on Signal Processing,",
            "year": 2021
        },
        {
            "authors": [
                "Yonggui Yan",
                "Jie Chen",
                "Pin-Yu Chen",
                "Xiaodong Cui",
                "Songtao Lu",
                "Yangyang Xu"
            ],
            "title": "Compressed decentralized proximal stochastic gradient method for nonconvex composite problems with heterogeneous data",
            "venue": "In International Conference on Machine Learning,",
            "year": 2023
        },
        {
            "authors": [
                "Hao Yu",
                "Sen Yang",
                "Shenghuo Zhu"
            ],
            "title": "Parallel restarted sgd with faster convergence and less communication: Demystifying why model averaging works for deep learning",
            "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2019
        },
        {
            "authors": [
                "Honglin Yuan",
                "Tengyu Ma"
            ],
            "title": "Federated accelerated stochastic gradient descent",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Honglin Yuan",
                "Manzil Zaheer",
                "Sashank Reddi"
            ],
            "title": "Federated composite optimization",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Fan Zhou",
                "Guojing Cong"
            ],
            "title": "On the convergence properties of a k-step averaging stochastic gradient descent algorithm for nonconvex optimization",
            "venue": "In Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "Kang Zhou",
                "Shenghua Gao",
                "Jun Cheng",
                "Zaiwang Gu",
                "Huazhu Fu",
                "Zhi Tu",
                "Jianlong Yang",
                "Yitian Zhao",
                "Jiang Liu"
            ],
            "title": "Sparse-gan: Sparsity-constrained generative adversarial network for anomaly detection in retinal oct image",
            "venue": "IEEE 17th International Symposium on Biomedical Imaging (ISBI),",
            "year": 2020
        },
        {
            "authors": [
                "Martin Zinkevich",
                "Markus Weimer",
                "Lihong Li",
                "Alex Smola"
            ],
            "title": "Parallelized stochastic gradient descent",
            "venue": "Advances in neural information processing systems,",
            "year": 2010
        },
        {
            "authors": [
                "Khaled"
            ],
            "title": "2020b) and non-i.i.d. data (Li et al., 2020b) or in light propose improvements (Karimireddy et al., 2020). Recently, the idea of DO is further extended to higher-order methods (Bullins et al., 2021",
            "venue": "Safaryan et al.,",
            "year": 2022
        },
        {
            "authors": [
                "Ouyang",
                "Xu",
                "Lin"
            ],
            "title": "Mirror prox inspired many papers (Antonakopoulos et al., 2019; Chen et al., 2020) and is later extended to the stochastic setting (Juditsky et al., 2011; Mishchenko et al., 2020), the higher-order setting (Bullins & Lai, 2022), and even the composite setting",
            "venue": "(He et al.,",
            "year": 2020
        },
        {
            "authors": [
                "Kotsalis"
            ],
            "title": "2022) recently studied optimal methods for stochastic variational inequalities, yet their result is limited to smooth VIs, not composite ones. From the perspective of distributed optimization, several works have made preliminary progress for smooth and unconstrained SPP in the Euclidean space",
            "venue": "VIs (Song et al.,",
            "year": 2020
        },
        {
            "authors": [
                "addition",
                "(Ramezani-Kebrya"
            ],
            "title": "2023) studies the problem from the information compression perspective with the measure of communication bits. The topic of distributed or federated saddle point optimization is also found in recent applications of interest, e.g. adversarial domain adaptation (Shen et al., 2023). Yet, none of the existing works includes the study for SPP with constraints or composite possibly non-smooth regularization",
            "year": 2023
        },
        {
            "authors": [
                "Yuan"
            ],
            "title": "Federated Mirror Descent, a natural extension of FedAvg that adapts to composite optimization under the convex setting. Along the way, they identified the \u201ccurse of primal averaging\u201d specific to composite optimization in the DO paradigm, where the regularization-imposed structure on the client models may no longer hold after server primal averaging",
            "year": 2021
        },
        {
            "authors": [
                "Tran Dinh"
            ],
            "title": "Averaging which brings the averaging step to the dual",
            "year": 2020
        },
        {
            "authors": [
                "Xiao"
            ],
            "title": "Classic algorithms mentioned previously are widely applied as well under this paradigm, for example, decentralized mirror descent (Rabbat, 2015) and decentralized (composite) dual averaging over networks (Duchi et",
            "year": 2022
        },
        {
            "authors": [
                "Rogozin"
            ],
            "title": "point-type methods (Liu et al., 2020) and extra-gradient methods (Rogozin et al., 2021",
            "year": 2021
        },
        {
            "authors": [
                "Yuan"
            ],
            "title": "2021), non-convex optimization for composite possibly non-smooth functions is in itself intricate even for sequential optimization, involving additional assumptions and sophisticated algorithm design (Li & Pong, 2015; Bredies et al., 2015), let alone distributed learning of SPP",
            "year": 2015
        },
        {
            "authors": [
                "Shi"
            ],
            "title": "z\u2032(z) := l(z)\u2212 l(z\u2032)\u2212 \u27e8\u2207l(z\u2032), z \u2212 z\u2032\u27e9. Notice that our notion of l is not a saddle function, slightly different from that in Shi et al. (2017), but the Bregman divergence defined is the same as Eq",
            "year": 2007
        },
        {
            "authors": [
                "Cohen"
            ],
            "title": "T ) convergence rate as its original non-composite smooth version (Nesterov, 2007), as well as composite mirror prox (CoMP) (He et al., 2015). We do so with a very simple proof based on the recently proposed notion of relative Lipschitzness (Cohen et al., 2021). We start by introducing the definition of relative Lipschitzness and a relevant lemma",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "A notable fraction of machine learning (ML) problems belong to saddle point problems (SPP), including adversarial robustness (Madry et al., 2018; Chen & Hsieh, 2023), generative adversarial networks (GAN) (Goodfellow et al., 2014), matrix games (Abernethy et al., 2018), multi-agent reinforcement learning (Wai et al., 2018), among others. These applications call for effective distributed saddle point optimization as their scale evolves beyond centralized learning. In typical distributed optimization (DO) approaches, a central server coordinates collaborative learning among clients through rounds of communication. In each round, clients learn a synchronized global model locally without sharing their private data, then send the model to the server for aggregation, usually through averaging (McMahan et al., 2017; Stich, 2019), to produce a new global model. The cost of communication is known to dominate the optimization process (Konec\u030cny\u0300 et al., 2016).\nAlthough preliminary progress has been made in distributed saddle point optimization (Beznosikov et al., 2020; Hou et al., 2021), we would note that machine learning problems are commonly associated with task-specific constraints or non-smooth regularization, which results in a need for composite optimization (CO). Moreover, a common purpose for non-smooth regularization is to induce structure. Typical ones include \u21131 norm for sparsity and nuclear norm for low-rankness, which show up in examples spanning from classical LASSO (Tibshirani, 1996), sparse regression (Hastie et al., 2015) to deep learning such as adversarial example generation (Moosavi-Dezfooli et al., 2016), sparse GAN (Zhou et al., 2020), convexified learning (Sahiner et al., 2022; Bai et al., 2024) and others.\nMeanwhile, Yuan et al. (2021) identified the \u201ccurse of primal averaging\u201d in standard aggregation schemes of DO, where the specific regularization-imposed structure on the client models may no longer hold after direct averaging on the server. For instance, each client may be able to obtain a sparse solution, yet averaging the solutions across clients yields a dense solution. To address this issue for convex optimization, they adopted the dual averaging technique (Nesterov, 2009), but this approach is not specifically designed for SPP. Even in the sequential deterministic setting, dual averaging or mirror descent (Nemirovskij & Yudin, 1983) achieve only a O(1/ \u221a T ) rate for SPP (Bubeck et al., 2015), whereas extra-step methods achieve a O(1/T ) rate (Nemirovski, 2004; Nesterov, 2007). At the same time, existing distributed methods for SPP fail to cover these composite scenarios and address associated challenges, as summarized in Table 1.\nWe present the distributed paradigm for composite saddle point optimization defined in (1). In particular, we propose Federated Dual Extrapolation (FeDualEx) (Algorithm 1), which builds on Nesterov\u2019s dual extrapolation (Nesterov, 2007), a classic extra-step algorithm suited for SPP. It carries out a two-step evaluation of a proximal operator (Censor & Zenios, 1992) defined by the Bregman Divergence (Bregman, 1967), which allows for SPP beyond the Euclidean space. To adapt to composite regularization, FeDualEx also draws inspiration from recent progress in composite convex optimization (Yuan et al., 2021) and adopts the notion of generalized Bregman divergence (Flammarion & Bach, 2017) instead, which merges the regularization into its distance-generating function. With some novel technical accommodations, we provide the convergence rate for FeDualEx under the homogeneous setting, which is, to the best of our knowledge, the first convergence rate for composite saddle point optimization under the DO paradigm. In support of the proposed method, we conduct numerical evaluations to verify the effectiveness of FeDualEx on composite SPP.\nTo further demonstrate the quality of the induced structure, we include the primal twin of FeDualEx based on mirror prox (Nemirovski, 2004), namely \u201cFederated Mirror Prox (FedMiP)\u201d, as a baseline for comparison in Appendix H. This is in line with the dichotomy between Federated Mirror Descent (FedMiD) and Federated Dual Averaging (FedDualAvg) (Yuan et al., 2021), from which Yuan et al. (2021) identified the \u201ccurse of primal averaging\u201d in DO, i.e., the specific regularization-imposed structure on the client models may no longer hold after primal averaging on the server. It highlights that FeDualEx naturally inherits the merit of dual aggregation from FedDualAvg. In addition, we analyze FeDualEx for federated composite convex optimization and show that FeDualEx recovers the same convergence rate as FedDualAvg under the convex setting.\nLast but not least, by reducing the number of clients to one, we show for the sequential version of FeDualEx that the analysis naturally yields a convergence rate for stochastic composite saddle point optimization which, to our knowledge, is the first such algorithm for non-Euclidean settings and matches the O( 1\u221a\nT ) rate in general stochastic saddle point optimization (Mishchenko et al., 2020;\nJuditsky et al., 2011). Further removing the noise from gradient estimates, FeDualEx still generalizes dual extrapolation to deterministic composite saddle point optimization with a O( 1T ) convergence rate that matches the smooth case and also the pioneering composite mirror prox (CoMP) (He et al., 2015) as presented in Table 2."
        },
        {
            "heading": "Our Contributions:",
            "text": "\u2022 We propose FeDualEx for distributed learning of SPP with composite possibly non-smooth\nregularization (Section 4.1). In support of the proposed algorithm, we provide a convergence rate for FeDualEx under the homogeneous setting (Section 4.2). To the best of our knowledge, FeDualEx is the first of its kind that encompasses composite possibly non-smooth regularization for SPP under a distributed paradigm, as shown in Table 1.\n\u2022 Additionally, we showcase the structure-preserving (e.g., sparsity) advantage of FeDualEx achieved through dual-space averaging. In particular, we present its primal twin FedMiP as a baseline to highlight this contrast (Appendix H).\n\u2022 FeDualEx produces several byproducts in the CO realm, as demonstrated in Table 2 : (1) The sequential version of FeDualEx leads to the stochastic dual extrapolation for CO and yields, to our knowledge, the first convergence rate for the stochastic optimization of composite SPP in non-Euclidean settings . (2) Further removing the noise leads to its deterministic version, with rates matching existing ones in smooth and composite saddle point optimization (Section 5).\n\u2022 We demonstrate experimentally the effectiveness of FeDualEx on various composite saddle point tasks, including bilinear problems on synthetic data with \u21131 and nuclear norm regularization, as well as the universal adversarial training of logistic regression with MNIST and CIFAR-10 (Section 6)."
        },
        {
            "heading": "2 RELATED WORK",
            "text": "We provide a brief overview of some related work and defer extended discussions to Appendix B.\nThe distributed optimization paradigm we consider aligns with that in Local SGD (Stich, 2019), which is also the homogeneous setting of Federated Averaging (FedAvg) (McMahan et al., 2017). Stich (2019) provides the first convergence rate for FedAvg, and it has been improved with tighter analysis and also analyzed under heterogeneity (e.g., (Khaled et al., 2020; Woodworth et al., 2020b)). Recently, Yuan et al. (2021) extended FedAvg to composite convex optimization and proposed FedDualAvg that aggregates learned parameters in the dual space and overcomes the \u201ccurse of primal averaging\u201d in federated composite optimization.\nFor SPP, Beznosikov et al. (2020) investigate the distributed extra-gradient method for stronglyconvex strongly-concave SPP in the Euclidean space. Hou et al. (2021) propose FedAvg-S and SCAFFOLD-S based on FedAvg (McMahan et al., 2017) and SCAFFOLD (Karimireddy et al., 2020) for SPP, which yields similar convergence rate to (Beznosikov et al., 2020). In addition, Ramezani-Kebrya et al. (2023) study the problem from the information compression perspective with the measure of communication bits. Yet, the aforementioned works are limited to smooth and unconstrained SPP in the Euclidean space. The more general setting of composite SPP is only found in sequential optimization literature, where the representative composite mirror prox (CoMP) (He et al., 2015) generalizes the classic mirror prox (Nemirovski, 2004) yet keeps the O( 1T ) convergence rate. In the stochastic setting, Mishchenko et al. (2020) analyzed a variant of stochastic mirror prox (Juditsky et al., 2011), which is then capable of handling composite terms in the Euclidean space. We will later show that the sequential analysis of our proposed algorithm also yields the same rate for dual extrapolation (Nesterov, 2007) in composite optimization, utilizing different proving techniques. As a result, we focus on the distributed optimization of composite SPP and propose FeDualEx."
        },
        {
            "heading": "3 PRELIMINARIES AND DEFINITIONS",
            "text": "We provide some preliminaries and definitions necessary for introducing FeDualEx. More details are included in Appendix C.1. To begin with, we lay out the notations.\nNotations. We use [n] to represent the set {1, 2, ..., n}. We use \u2225 \u00b7 \u2225 to denote an arbitrary norm, \u2225 \u00b7 \u2225\u2217 to denote the dual norm, and \u2225 \u00b7 \u22252 to denote the Euclidean norm. We use \u2207 for gradients, \u2202 for subgradients, and \u27e8\u00b7, \u00b7\u27e9 for inner products. Related to the algorithm, we use English letters (e.g., z, x, y) to denote primal variables, Greek letters (e.g., \u03c9, \u03c2 , \u00b5, \u03bd) to denote dual variables. We use R for communication rounds, K for local updates, B for diameter bound, G for gradient bound, \u03b2 for smoothness constant, \u03c3 for standard deviation, \u03be for random samples. We use h\u2217 to denote the convex conjugate of a function h.\nComposite Saddle Point Optimization. We study composite saddle point optimization. Its objective is formally given in the following definition. Definition 1 (Composite SPP). The objective of composite saddle point optimization is defined as\nmin x\u2208X max y\u2208Y\n\u03d5(x, y) = f(x, y) + \u03c81(x)\u2212 \u03c82(y) (1)\nwhere f(x, y) = 1M \u2211M m=1 fm(x, y) and \u03c81(x), \u03c82(y) are possibly non-smooth.\nIt is typically evaluated by the duality gap: Gap(x\u0302, y\u0302) = maxy\u2208Y \u03d5(x\u0302, y)\u2212minx\u2208X \u03d5(x, y\u0302).\nMirror Prox and Dual Extrapolation. Mirror prox (Nemirovski, 2004) and dual extrapolation (Nesterov, 2007) are classic methods for convex-concave SPP. Both are proximal algorithms based on the proximal operator defined as Prox hx\u2032(\u00b7) = argminx{\u27e8\u00b7, x\u27e9 + V hx\u2032(x)}, in which V hx\u2032(x) = h(x)\u2212 h(x\u2032)\u2212 \u27e8\u2207h(x\u2032), x\u2212 x\u2032\u27e9 is the Bregman divergence generated by some closed, strongly convex, and differentiable\nfunction h. Both algorithms conduct two evaluations of the proximal operator, while dual extrapolation carries out updates in the dual space. Figure 1 gives a brief illustration of dual extrapolation with the proximal operator as in (Cohen et al., 2021), with details in Appendix C.1.\nGeneralized Bregman Divergence. Recent advances in composite convex optimization (Yuan et al., 2021) have utilized the Generalized Bregman Divergence (Flammarion & Bach, 2017) for analyzing composite objectives. It incorporates the composite term into the distance-generating function of the vanilla Bregman divergence, and measures the distance in terms of one variable and the dual image of the other, with the key insight being the conjugate of a non-smooth generalized distance-generating function is differentiable. Definition 2 (Generalized Bregman Divergence (Flammarion & Bach, 2017)). Generalized Bregman divergence is defined to be V\u0303 ht\u00b5\u2032 (x) = ht(x)\u2212ht(\u2207h\u2217t (\u00b5\u2032))\u2212\u27e8\u00b5\u2032, x\u2212\u2207h\u2217t (\u00b5\u2032)\u27e9, where ht = h+t\u03b7\u03c8 is a generalized distance-generating function that is closed and strongly convex, t is the current number of iterations, \u03b7 is the step size, h\u2217t is the convex conjugate of ht, and \u00b5\n\u2032 is the dual image of x\u2032, i.e., \u00b5\u2032 \u2208 \u2202ht(x\u2032) and x\u2032 = \u2207h\u2217t (\u00b5\u2032). Generalized Bregman divergence is suitable not only for non-smooth regularization but also for any convex constraints C, taking \u03c8(x) = 0 if x \u2208 C and +\u221e otherwise."
        },
        {
            "heading": "4 FEDERATED DUAL EXTRAPOLATION (FEDUALEX)",
            "text": "To tackle composite SPP in the DO paradigm, we acknowledge the challenges from several aspects. Specifically, the generality afforded by composite and/or saddle point problems results in a need for more sophisticated techniques that work with this additional structure. These concerns are further complicated by the challenges that arise for DO, where communication and aggregation need to be carefully handled under the distributed mechanism. In particular, Yuan et al. (2021) identified the \u201cthe curse of primal averaging\u201d in composite federated optimization and advocated for dual aggregation. Dealing with these challenges altogether is rather non-trivial, as the techniques that are naturally suited for one would fail for another. In this regard, we first present FeDualEx (Algorithm 1) and several relevant novel definitions proposed for its adaptation to composite SPP. Then we analyze the convergence rate in the homogeneous setting."
        },
        {
            "heading": "4.1 THE FEDUALEX ALGORITHM",
            "text": "FeDualEx builds its core on the classic dual extrapolation, an extra-step algorithm geared for saddle point optimization. Its effectiveness has been widely verified in vanilla smooth convex-concave SPP. Furthermore, its updating sequence lies in the dual space which would naturally inherit the advantage of dual aggregation in composite federated optimization. The challenge remains for composite optimization, as relevant work is limited, and the existing composite extension for the extra-step method (He et al., 2015) is quite technically involved. Given that the smooth analysis of dual extrapolation is already non-trivial (Nesterov, 2007), no attempts were previously made for generalizing dual extrapolation to the composite optimization realm.\nAlgorithm 1 FEDERATED-DUAL-EXTRAPOLATION (FeDualEx) for Composite SPP Input: \u03d5(z) = f(x, y)+\u03c81(x)\u2212\u03c82(y) = 1M \u2211M\nm=1 fm(x, y)+\u03c81(x)\u2212\u03c82(y): objective function; \u2113(z): distance-generating function; gm(z) = (\u2207xfm(x, y),\u2212\u2207yfm(x, y)): gradient operator. Hyperparameters: R: number of communication rounds; K: number of local update iterations; \u03b7s: server step size; \u03b7c: client step size. Dual Initialization: \u03c20 = 0: initial dual variable, \u03c2\u0304: fixed point in the dual space. Output: Approximate solution z = (x, y) to minx\u2208X maxy\u2208Y \u03d5(x, y)\n1: for r = 0, 1, . . . , R\u2212 1 do 2: Sample a subset of clients Cr \u2286 [M ] 3: for m \u2208 Cr in parallel do 4: \u03c2mr,0 = \u03c2r 5: for k = 0, 1, . . . ,K \u2212 1 do 6: zmr,k = \u02dcProx \u2113r,k \u03c2\u0304 (\u03c2 m r,k) \u25b7 Two-step evaluation of the generalized proximal operator\n7: zmr,k+1/2 = \u02dcProx \u2113r,k+1 \u03c2\u0304\u2212\u03c2mr,k (\u03b7cgm(z m r,k; \u03be m r,k)) 8: \u03c2mr,k+1 = \u03c2 m r,k + \u03b7 cgm(z m r,k+1/2; \u03be m r,k+1/2) \u25b7 Dual variable update\n9: end for 10: end parallel for 11: \u2206r =\n1 |Cr| \u2211 m\u2208Cr (\u03c2 m r,K \u2212 \u03c2mr,0)\n12: \u03c2r+1 = \u03c2r + \u03b7s\u2206r \u25b7 Server dual update 13: end for 14: Return: 1RK \u2211R\u22121 r=0 \u2211K\u22121 k=0 \u0302zr,k+1/2 with \u0302zr,k+1/2 defined in (4).\nInspired by recent advances in composite convex optimization, we recognize the Generalized Bregman Divergence (Flammarion & Bach, 2017) as a powerful tool for analyzing proximal methods for composite objectives. Adapting to the context of composite SPP, we make an extension to the Generalized Bregman Divergence for saddle functions, and provide the definition below. Definition 3 (Generalized Bregman Divergence for Saddle Functions). The generalized distancegenerating function for the optimization of (1) is \u2113t(z) = \u2113(z)+t\u03b7\u03c8(z), where \u2113(z) = h1(x)+h2(y), h1 and h2 are distance-generating functions for x and y, \u03c8(z) = \u03c81(x) + \u03c82(y), \u03b7 is the step size, and t is the current number of iterations. It generates the following generalized Bregman divergence:\nV\u0303 \u2113t\u03c2\u2032 (z) = \u2113t(z)\u2212 \u2113t(z \u2032)\u2212 \u27e8\u03c2 \u2032, z \u2212 z\u2032\u27e9,\nwhere \u03c2 \u2032 is the preimage of z\u2032 with respect to the gradient of the conjugate of \u2113t, i.e., z\u2032 = \u2207\u2113\u2217t (\u03c2 \u2032).\nYet as we notice in previous works (Flammarion & Bach, 2017; Yuan et al., 2021), generalized Bregman divergence is applied only for theoretical analysis. In terms of algorithm design, the previous proximal operator for composite convex optimization is based on the vanilla Bregman divergence plus the composite term, specifically, argminx{\u27e8\u00b7, x\u27e9+V hx\u2032(x)+ \u03b7\u03c8(x)} in (Duchi et al., 2010; He et al., 2015), and argminx{\u27e8\u00b7, x\u27e9+ h(x) + \u03b7t\u03c8(x)} in (Xiao, 2010; Flammarion & Bach, 2017). However, we find this definition insufficient for dual extrapolation, as its dual update and the composite term from the extra step break certain parts of the analysis. In this effort, we propose a novel technical change to the proximal operator, directly replacing the Bregman divergence in the proximal operator with the generalized Bregman divergence. Definition 4 (Generalized Proximal Operator for Saddle Functions). A proximal operation in the composite setting with generalized Bregman divergence for Saddle Functions is defined to be\n\u02dcProx \u2113t \u03c2\u2032 (g) := argmin z {\u27e8g, z\u27e9+ V\u0303 \u2113t\u03c2\u2032 (z)},\nwhere \u03c2 \u2032 is the dual image of z\u2032, i.e., z\u2032 = \u2207\u2113\u2217t (\u03c2 \u2032), and \u03c2 \u2032 \u2208 \u2202\u2113t(z\u2032) = \u2207\u2113(z\u2032) + \u03b7t\u2202\u03c8(z\u2032). Compared with the vanilla proximal operator in Section 3, this novel design for the composite adaptation of dual extrapolation is quite natural. It is different from previous proximal operators, which after expanding take the form argminz{\u27e8\u00b7 \u2212 \u2207\u2113(z\u2032), z\u27e9 + \u2113t(z)} (Duchi et al., 2010) or argminz{\u27e8\u00b7, z\u27e9+ \u2113t(z)} (Xiao, 2010), whereas ours is \u02dcProx h\n\u03c2\u2032(\u00b7) = argminz{\u27e8\u00b7 \u2212 \u03c2 \u2032, z\u27e9+ \u2113t(z)}. These adaptations are necessary for technical reasons, as our algorithm involves prox operators on both the clients and the server to induce structure in the aggregated solution, which would otherwise\nbreak the conventional analysis. (Specifically, using these previous notions yields extra composite terms in the analysis that do not cancel out but rather accumulate, thus hindering the convergence.)\nWith the novel definitions above, we are able to formally present FeDualEx in Algorithm 1. It follows the general structure of DO. For each client, the two-step evaluation of the generalized proximal operator and the final dual update are highlighted in green , which resembles the classic dual extrapolation updates in Figure 1. To align with our generalized proximal operator, we also move the primal initialization x\u0304 in the original dual extrapolation to the dual space as \u03c2\u0304 . On the server, the dual variables from clients are aggregated first in the dual space, then projected to the primal with a mechanism later defined in (4)."
        },
        {
            "heading": "4.2 CONVERGENCE ANALYSIS OF FEDUALEX",
            "text": "In this section, we provide the convergence analysis of FeDualEx for the homogeneous DO of composite SPP. We further assume the full participation of clients in each round for simplicity, but this condition can be trivially removed by lengthy analysis. We start by showing the equivalence between primal-dual projection and the generalized proximal operator, and for the convenience of analysis, reformulating the updating sequences with another pair of auxiliary dual variables.\nProjection Reformulation. Generalized proximal operators can be presented as projections, i.e., the gradient of the conjugate of the generalized distance-generating function in Appendix C.2. Thus, line 6 to 8 in Algorithm 1 can be expanded by Definition 4, and rewrite as: (1) zmr,k = \u2207\u2113\u2217r,k(\u03c2\u0304 \u2212 \u03c2mr,k); (2) zmr,k+1/2 = \u2207\u2113 \u2217 r,k+1((\u03c2\u0304 \u2212 \u03c2mr,k)\u2212 \u03b7cgm(zmr,k; \u03bemr,k)); (3) \u03c2mr,k+1 = \u03c2mr,k + \u03b7cgm(zmr,k+1/2; \u03be m r,k+1/2).\nFurther define auxiliary dual variable \u03c9mr,k = \u03c2\u0304\u2212\u03c2mr,k. It satisfies immediately that zmr,k = \u2207\u2113\u2217r,k(\u03c9mr,k), in which \u2113\u2217r,k is the conjugate of \u2113r,k = \u2113 + (\u03b7\nsrK + k)\u03b7c\u03c8. And define \u03c9mr,k+1/2 to be the dual image of the intermediate variable zmr,k+1/2 such that z m r,k+1/2 = \u2207\u2113 \u2217 r,k+1(\u03c9 m r,k+1/2). Then we get an equivalent updating sequence with the auxiliary dual variables.\n\u03c9mr,k+1/2 = \u03c9 m r,k \u2212 \u03b7gm(zmr,k; \u03bemr,k), \u03c9mr,k+1 = \u03c9mr,k \u2212 \u03b7gm(zmr,k+1/2; \u03be m r,k+1/2) Define their average across clients, \u03c9r,k = 1M \u2211M m=1 \u03c9 m r,k, gr,k = 1 M \u2211M m=1 gm(z m r,k; \u03be m r,k). Then we can analyze the following averaged dual shadow sequences:\n\u03c9r,k+1/2 = \u03c9r,k \u2212 \u03b7cgr,k, (2) \u03c9r,k+1 = \u03c9r,k \u2212 \u03b7cgr,k+1/2. (3) In the meantime, their shadow primal projections on the server are defined as\nz\u0302r,k = \u2207\u2113\u2217r,k(\u03c9r,k), \u0302zr,k+1/2 = \u2207\u2113\u2217r,k+1(\u03c9r,k+1/2). (4) Next, we list the key assumptions. Detailed presentation and additional remarks that ease the understanding of proofs are also provided in Appendix C.3. Assumptions For the composite saddle function \u03d5(x, y) = 1M \u2211M m=1 fm(x, y) + \u03c81(x)\u2212 \u03c82(y),\nits gradient operator is given by g = (\u2207xf,\u2212\u2207yf) and g = 1M \u2211M m=1 gm. We assume that\na.(Convexity of f ) \u2200m \u2208 [M ], fm(x, y) is convex in x and concave in y. b.(Convexity of \u03c8) \u03c81(x) is convex in x, and \u03c82(y) is convex in y.\nc. (Lipschitzness of g) gm(z) = [\n\u2207xfm(x,y) \u2212\u2207yfm(x,y)\n] is \u03b2-Lipschitz: \u2225gm(z)\u2212 gm(z\u2032)\u2225\u2217 \u2264 \u03b2\u2225z \u2212 z\u2032\u2225\nd.(Unbiased Estimate and Bounded Variance) \u2200m \u2208 [M ], for random sample \u03bem, E\u03be[gm(zm; \u03bem)] = gm(zm), and E\u03be [ \u2225gm(zm; \u03bem)\u2212 gm(zm)\u22252\u2217 ] \u2264 \u03c32 e. (Bounded Gradient) \u2200m \u2208 [M ], \u2225gm(zm; \u03bem)\u2225\u2217 \u2264 G f. The distance-generating function \u2113 is a Legendre function that is 1-strongly convex, i.e., \u2200z, z\u2032,\n\u2113(z\u2032)\u2212 \u2113(z)\u2212 \u27e8\u2207\u2113(z), z\u2032 \u2212 z\u27e9 \u2265 12\u2225z \u2032 \u2212 z\u22252.\ng.The optimization domain Z is compact w.r.t. Bregman divergence, i.e., \u2200z, z\u2032 \u2208 Z , V \u2113z\u2032(z) \u2264 B.\nWe would note that Assumption e (bounded gradient) is a standard assumption in classic distributed composite optimization (Duchi et al., 2011), and is made in other DO analysis (Stich, 2019; Li et al., 2020b; Yu et al., 2019; Yuan et al., 2021).\nMain Theorem. Under the aforementioned assumptions, we present the following theorem that provides the convergence rate of FeDualEx in terms of the duality gap.\nTheorem 1 (Main). Under assumptions, the duality gap evaluated with the ergodic sequence generated by the intermediate steps of FeDualEx in Algorithm 1 is bounded by\nE [ Gap ( 1 RK R\u22121\u2211 r=0 K\u22121\u2211 k=0 \u0302zr,k+1/2 )] \u2264 B \u03b7cRK + 20\u03b22(\u03b7c)3K2G2 + 5\u03c32\u03b7c M + 2 3 2 \u03b2\u03b7cKGB 1 2 .\nChoosing step size \u03b7c = min{ 1 5 1 2 \u03b2 , B\n1 4\n20 1 4 \u03b2 1 2 G 1 2 K 3 4 R 1 4 , B\n1 2 M 1 2\n5 1 2 \u03c3R 1 2 K 1 2 , B\n1 4\n2 3 4 \u03b2 1 2 G 1 2 KR 1 2 },\nE [ Gap ( 1 RK R\u22121\u2211 r=0 K\u22121\u2211 k=0 \u0302zr,k+1/2 )] \u2264 5 1 2 \u03b2B RK + 20 1 4 \u03b2 1 2G 1 2B 3 4 K 1 4R 3 4 + 5 1 2\u03c3B 1 2 M 1 2R 1 2K 1 2 + 2 3 4 \u03b2 1 2G 1 2B 3 4 R 1 2 .\nTo the best of our knowledge, this is the first convergence rate for federated composite saddle point optimization. The O( 1RK ) and O( 1\u221a MRK ) terms roughly match previous DO algorithms, where the noise term decays with the number of clients M . If M is large enough, then the O(1/R 12 ) term takes domination in terms of communication complexity. The convergence analysis further validates the effectiveness of FeDualEx, which then advances distributed optimization to a broad class of composite saddle point problems. The complete proof of Theorem 1 can be found in Appendix E.\nOn Composite Convex Optimization. We also analyze the convergence rate for FeDualEx under the federated composite convex optimization setting. As the following theorem shows, FeDualEx achieves the same O(1/R 23 ) as in (Yuan et al., 2021). The proof is provided in Appendix F. Theorem 2. Under the convex counterparts of previous assumptions, choosing step size \u03b7c = min{ 1\n5 1 2 \u03b2 , B\n1 4\n20 1 4 \u03b2 1 2 G 1 2 K 3 4 R 1 4 , B\n1 2 M 1 2\n5 1 2 \u03c3R 1 2 K 1 2 , B\n1 3\n2 1 3 \u03b2 1 3 G 2 3 KR 1 3 }, the ergodic intermediate sequence gener-\nated by FeDualEx for composite convex objectives satisfies E [ \u03d5( 1\nRK R\u22121\u2211 r=0 K\u22121\u2211 k=0 \u0302xr,k+1/2)\u2212 \u03d5(x) ] \u2264 5 1 2 \u03b2B RK + 20 1 4 \u03b2 1 2G 1 2B 3 4 K 1 4R 3 4 + 5 1 2\u03c3B 1 2 M 1 2R 1 2K 1 2 + 2 1 3 \u03b2 1 3G 2 3B 2 3 R 2 3 .\nEven though this rate is not preserved in composite saddle point optimization, we note that the optimization of SPP is much more general, and convexity itself is a stronger assumption. More specifically, the complicated setting, including the non-smooth term, the primal-dual projection, the extra-step saddle point optimization, etc., together limit the tools available for analysis.\nRemark On Heterogeneity. Even for federated composite optimization (Yuan et al., 2021), the heterogeneous setting presents significant hurdles. Specifically, the involvement of heterogeneity is limited to quadratic functions, under which assumption the is gradient linear, and this simplifies the analysis. It further relies on the norm generated by its Hessian. For saddle functions, \u201cquadraticity\u201d (as well as a matrix-induced norm) is less well-defined, as the Jacobian of their gradient operator is not (symmetric) positive semidefinite in general. Such further advancements go beyond the scope of this paper. Thus, we regard Theorem 1 as a significant start for federated learning of composite SPP."
        },
        {
            "heading": "5 FEDUALEX IN SEQUENTIAL SETTINGS",
            "text": "Stochastic Composite Saddle Point Optimization FeDualEx can be naturally reduced to sequential stochastic optimization of composite SPP, which we term as Sequential FeDualEx or Stochastic Dual Extrapolation. By reducing the number of clients to one, thus eliminating the need for communication, the convergence analysis follows through smoothly and yields O( 1\u221a\nT ) rate (denoting K as T )\nexpected for first-order stochastic algorithms. This is the first such rate in the non-Euclidean setting, matching the previous Euclidean rate (Mishchenko et al., 2020) and non-composite rate (Juditsky et al., 2011). Theorem 3 gives the result with proof in Appendix G.1.\nTheorem 3. Under the sequential versions of previous assumptions, \u2200z \u2208 Z , choosing step size \u03b7 = min{ 1\n3 1 2 \u03b2 , B\n1 2 3 1 2 \u03c3T 1 2 }, the ergodic intermediate sequence of stochastic dual extrapolation satisfies\nE [ Gap( 1T \u2211T\u22121 t=0 zt+1/2) ] \u2264 3 1 2 \u03b2B T + 3 1 2 \u03c3B 1 2\nT 1 2\n.\nmin x\u2208X max y\u2208Y \u27e8Ax\u2212 b,y\u27e9+ \u03bb\u2225x\u22251 \u2212 \u03bb\u2225y\u22251\nA \u2208 Rn\u00d7m, X = {Rm : \u2225x\u2225\u221e \u2264 D}, b \u2208 Rn, Y = {Rn : \u2225y\u2225\u221e \u2264 D}.\nFigure 2: The composite SPP with \u21131 regularization for sparsity (Jiang & Mokhtari, 2022).\nmin X\u2208X max Y\u2208Y\nTr ( (AX\u2212B)\u22a4Y ) + \u03bb\u2225X\u2225\u2217 \u2212 \u03bb\u2225Y\u2225\u2217\nA \u2208 Rn\u00d7m, X = {Rm\u00d7p : \u2225X\u22252 \u2264 D}, B \u2208 Rn\u00d7p, Y = {Rn\u00d7p : \u2225Y\u22252 \u2264 D}.\nFigure 3: The composite SPP with nuclear norm lowrank regularization.\nDeterministic Composite Saddle Point Optimization Further removing the noise in gradient, FeDualEx reduces to a deterministic algorithm for composite SPP. Even so, we are still generalizing the classic dual extrapolation algorithm to CO, and thus term the algorithm Deterministic FeDualEx or Composite Dual Extrapolation. Following a similar analysis, we are able to get the O( 1T ) rate as in previous work for CO (He et al., 2015) as well as the smooth dual extrapolation (Nesterov, 2007). The proof for Theorem 4 is in Appendix G.2, which is a much simpler one based on the recently proposed Relative Lipschitzness (Cohen et al., 2021). Theorem 4. Under the basic convexity assumption and \u03b2-Lipschitzness of g, \u2200z \u2208 Z and \u03b7 \u2264 1\u03b2 , composite dual extrapolation satisfies Gap( 1T \u2211T\u22121 t=0 zt+1/2) \u2264 \u03b2B T ."
        },
        {
            "heading": "6 EXPERIMENTS",
            "text": "To complement our largely theoretical results, we verify in this section the effectiveness of FeDualEx by numerical evaluation. Additional experiments and detailed settings are deferred to Appendix A.\nComposite Bilinear SPP. We first test FeDualEx on composite bilinear problems with synthetic data. The problems considered are demonstrated in Figure 2 and 3, in which m = 600, n = 300, p = 20, \u03bb = 0.1, D = 0.05. The corresponding composite terms are \u21131 regularization with \u2113\u221e ball constraint and nuclear regularization with spectral constraint. The purpose of \u21131 regularization is to encourage sparsity and nuclear regularization to encourage a solution with low rank.\nWe compare FeDualEx against FedDualAvg, FedMiD (Yuan et al., 2021), and FedMiP proposed in Algorithm 2 in Appendix H. We note that methods like Extra Step Local SGD (Beznosikov et al., 2020) and SCAFFOLD-S (Karimireddy et al., 2020) are not suited to problems with nonsmooth terms, but we include one of them for completeness, given that their rates are similar. For such a comparison, one can only compute the sub-gradient instead of the gradient (which does not everywhere exist). Projection needs to be applied as well to account for the constraints.\n(a) FeDualEx (b) PGDA\nFigure 7: Attack generated from the universal-adversarially trained logistic regression on MNIST and CIFAR-10.\nWe evaluate the convergence in terms of the duality gap and also demonstrate the structure of the solution, i.e., sparsity or low-rankness. The duality gap of the problems of interest can be evaluated in closed form, which is derived in Appendix A.1 and A.2. The sparsity is measured by the ratio of non-zero entries to the parameter size, and we regard numbers less than 10\u22125 as zeros. For DO, we simulate M = 100 clients. For the gradient query of each client in each local update, we inject a Gaussian noise from N (0, \u03c32), where \u03c3 = 0.1. The evaluation is conducted for two different settings: (a) K = 1 local update (b) K = 10 local updates. The results are demonstrated in Figure 4 and 5.\nFrom the duality gap curves in Figure 4, we see that extra-step methods, i.e., FeDualEx and FedMiP converge to the order of 10\u22121 whereas FedDualAvg and FedMiD stay above 100. Thus, it is evident that methods for composite convex optimization are no longer suited for composite saddle point optimization, and FeDualEx provides the first effective solution addressing the challenge. From the sparsity of the solution, we see that the dual methods demonstrate better adherence to regularization. Among the methods superior in saddle point optimization, FeDualEx reaches a sparsity of around 0.7 while FedMiP is around 0.95. This aligns with the previous analysis on the advantage of dual aggregation and further validates the effectiveness of FeDualEx for solving composite SPP. In addition, methods for smooth unconstrained optimization like ExtraStepLocalSGD do not converge for SPP with composite non-smooth terms, nor does it impose any desired structure, e.g., sparsity. We observe similar advantages of FeDualEx in convergence and inducing low-rankness from Figure 5 as well.\nUniversal Adversarial Training of Logistic Regression. We also consider the task of universal adversarial training (Shafahi et al., 2020) of logistic regression, i.e. the adversarial training against a universal adversarial perturbation (Moosavi-Dezfooli et al., 2017) targeted for all images in the dataset. In order to encourage the sparsity of the attack, we also impose an l1 regularization on the attack. The problem formulation is given in Appendix A.3. We compare FeDualEx against direct aggregation of projected gradient descent ascent (PGDA) proposed in (Shafahi et al., 2020) Alg. 3.\nWe evaluate convergence with training loss, which is by no means an exact reflection of the duality gap. Still, we observe in Figure 6 that FeDualEx converges faster and delivers a better-hardened model with higher validation accuracy on unattacked data. Meanwhile, the vanilla aggregation of PGDA solutions yields a dense attack whereas FeDualEx achieves much better sparsity, as visualized in Figure 7. Furthermore, we observe that the attack generated by distributed PGDA is not only dense but also smoothed out to small values close to zero, averaged by the number of clients."
        },
        {
            "heading": "7 CONCLUSION AND FUTURE WORK",
            "text": "We advance distributed optimization to the broad class of composite SPP by proposing FeDualEx and providing, to our knowledge, the first convergence rate of its kind. We demonstrate the effectiveness of FeDualEx for inducing structures with empirical evaluation. We also show that the sequential version of FeDualEx provides a solution to composite stochastic saddle point optimization in the nonEuclidean setting. We recognize further study of the heterogeneous federated setting of composite saddle point optimization would be a challenging direction for future work."
        },
        {
            "heading": "Appendices",
            "text": "In Appendix A, we provide details on experiment settings and additional experiments on the universal adversarial training of non-convex convolutional neural networks. In Appendix B, an extended literature review on various related subfields is included. Appendix C and D provide additional theoretical background, including relevant preliminaries, definitions, remarks, and technical lemmas. Appendix E, F, and G provide the convergence rates and complete proofs for FeDualEx in federated composite saddle point optimization, federated composite convex optimization, sequential stochastic composite optimization, and sequential deterministic composite optimization respectively. Finally, the algorithm of FedMiP is presented in Appendix H."
        },
        {
            "heading": "A Additional Experiments and Setup Details 18",
            "text": "A.1 Setup Details for Saddle Point Optimization with Sparsity Regularization . . . . . 18\nA.2 Saddle Point Optimization with Low-Rank Regularization . . . . . . . . . . . . . 19\nA.3 Universal Adversarial Training of Logistic Regression . . . . . . . . . . . . . . . . 20\nA.4 Universal Adversarial Training of Neural Networks . . . . . . . . . . . . . . . . . 21"
        },
        {
            "heading": "B Extended Literature Review 21",
            "text": "B.1 Distributed Optimization / Federated Learning . . . . . . . . . . . . . . . . . . . . 21\nB.2 Saddle Point Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\nB.3 Composite Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\nB.4 Other Tangentially Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . 23"
        },
        {
            "heading": "C Additional Preliminaries, Definitions, and Remarks on Assumptions 23",
            "text": "C.1 Additional Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\nC.1.1 Mirror Descent and Dual Averaging . . . . . . . . . . . . . . . . . . . . . 24\nC.1.2 Mirror Prox and Dual Extrapolation . . . . . . . . . . . . . . . . . . . . . 25\nC.2 Additional Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\nC.3 Formal Assumptions and Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . 26"
        },
        {
            "heading": "D Additional Technical Lemmas 27",
            "text": ""
        },
        {
            "heading": "E Complete Analysis of FeDualEx for Composite Saddle Point Problems 29",
            "text": "E.1 Main Theorem and Proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\nE.2 Helping Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33"
        },
        {
            "heading": "F Complete Analysis of FeDualEx for Composite Convex Optimization 36",
            "text": ""
        },
        {
            "heading": "G FeDualEx in Other Settings 39",
            "text": "G.1 Stochastic Dual Extrapolation for Composite Saddle Point Optimization . . . . . . 39\nG.2 Deterministic Dual Extrapolation for Composite Saddle Point Optimization . . . . 41\nH Federated Mirror Prox 42"
        },
        {
            "heading": "A ADDITIONAL EXPERIMENTS AND SETUP DETAILS",
            "text": ""
        },
        {
            "heading": "A.1 SETUP DETAILS FOR SADDLE POINT OPTIMIZATION WITH SPARSITY REGULARIZATION",
            "text": "We provide additional details for the SPP with the sparsity regularization demonstrated in the main text. We start by restating its formulation below:\nmin x\u2208X max y\u2208Y \u27e8Ax\u2212 b,y\u27e9+ \u03bb\u2225x\u22251 \u2212 \u03bb\u2225y\u22251\nA \u2208 Rn\u00d7m, X = {Rm : \u2225x\u2225\u221e \u2264 D}, b \u2208 Rn, Y = {Rn : \u2225y\u2225\u221e \u2264 D}.\nSoft-Thresholding Operator for \u21131 Norm Regularization. By choosing the distance-generating function to be \u2113 = 12\u2225x\u2225 2 2+ 1 2\u2225y\u2225 2 2, the projection \u2207\u2113\u2217r,k(\u00b7) instantiates to the following element-wise soft-thresholding operator (Hastie et al., 2015; Jiang & Mokhtari, 2022):\nT\u03bb\u2032(\u03c9) :=  0 if |\u03c9| \u2264 \u03bb\u2032 (|\u03c9| \u2212 \u03bb\u2032) \u00b7 sgn(\u03c9) if \u03bb\u2032 < |\u03c9| \u2264 \u03bb\u2032 +D D \u00b7 sgn(\u03c9) otherwise ,\nin which \u03bb\u2032 = \u03bb\u03b7c(\u03b7srK + k).\nClosed-Form Duality Gap. The closed-form duality gap is given by\nGap(x,y) = D\u2225(|Ax\u2212 b| \u2212 \u03bb)+\u22251 + \u03bb\u2225x\u22251 +D\u2225(|A\u22a4y| \u2212 \u03bb)+\u22251 + \u27e8b,y\u27e9+ \u03bb\u2225y\u22251,\nwhere | \u00b7 | and ()+ = max{\u00b7, 0} are element-wise. We provide a brief derivation below. Since a constraint is equivalent to an indicator regularization, we move the \u2113\u221e constraint into the objective\nand denote g1(\u00b7) = \u2225 \u00b7 \u22251, g2(\u00b7) = { 0 if \u2225 \u00b7 \u2225\u221e \u2264 D \u221e otherwise . By the definitions of duality gap in\nDefinition 1 and convex conjugate in Definition 9, the duality gap equals to\nGap(x,y) = max y \u03bb{\u27e8 1 \u03bb (Ax\u2212 b),y\u27e9 \u2212 g1(y)\u2212 g2(y) + \u2225x\u22251}\n\u2212min x \u03bb{\u27e8 1 \u03bb (A\u22a4y),x\u27e9+ g1(x) + g2(x)\u2212 \u2225y\u22251 \u2212 1 \u03bb b\u22a4y}\n= \u03bb(g1 + g2) \u2217(\n1 \u03bb (Ax\u2212 b)) + \u03bb(g1 + g2)\u2217( 1 \u03bb (A\u22a4y)) + \u03bb\u2225x\u22251 + \u03bb\u2225y\u22251 + b \u22a4y\n= inf u {\u03bbg\u22171(u) + \u03bbg\u22172(\n1 \u03bb (Ax\u2212 b)\u2212 u)}+ inf v {\u03bbg\u22171(v) + \u03bbg\u22172( 1 \u03bb (A\u22a4y)\u2212 v)}\n+ \u03bb\u2225x\u22251 + \u03bb\u2225y\u22251 + b \u22a4y,\nin which the last equality holds by Theorem 2.3.2, namely infimal convolution, in Chapter E of Hiriart-Urruty & Lemar\u00e9chal (2004). By definition of the convex conjugate, the convex conjugate of a norm g(\u00b7) = \u2225 \u00b7 \u2225p is defined to be g\u2217(\u00b7) = { 0 if \u2225 \u00b7 \u2225q \u2264 1 \u221e otherwise , in which \u2225 \u00b7 \u2225q is the dual\nnorm of \u2225 \u00b7 \u2225p. Given that \u21131 and \u2113\u221e are dual norms to each other, g\u22171(\u00b7) = { 0 if \u2225 \u00b7 \u2225\u221e \u2264 1 \u221e otherwise , g\u22172(\u00b7) = D\u2225 \u00b7 \u22251. Therefore the infimum is achieved when \u2200i \u2208 [m], \u2200j \u2208 [n],\nui =\n{ 1 \u03bb (Ax\u2212 b)i if | 1 \u03bb (Ax\u2212 b)i| \u2264 1\nsgn( 1\u03bb (Ax\u2212 b)i) otherwise , vj =\n{ 1 \u03bb (A \u22a4y)j if | 1\u03bb (A \u22a4y)j | \u2264 1\nsgn( 1\u03bb (A \u22a4y)j) otherwise\n,\nwhich yields the closed-form duality gap.\nAdditional Experiment Details. We generate a fixed pair of A and b with each entry independently following the uniform distribution U[\u22121,1]. Each entry of the variables x and y is initialized independently from the distribution U[\u2212D,D]. As in (Jiang & Mokhtari, 2022), we take m = 600, n = 300, \u03bb = 0.1, D = 0.05. For DO, we simulate M = 100 clients. For the gradient query of each client\nin each local update, we inject a Gaussian noise from N (0, \u03c32). All M = 100 clients participate in each round; noise on each client is i.i.d. with \u03c3 = 0.1.\nWe only tune the global step size \u03b7s and the local step size \u03b7c. For all experiments, the parameters are searched from the combination of \u03b7s \u2208 {1, 3e \u2212 1, 1e \u2212 1, 3e \u2212 2, 1e \u2212 2} and \u03b7c \u2208 {1, 3e \u2212 1, 1e \u2212 1, 3e \u2212 2, 1e \u2212 2, 3e \u2212 3, 1e \u2212 3}. We run each setting for 10 different random seeds and report the mean and standard deviation in Figure 4."
        },
        {
            "heading": "A.2 SADDLE POINT OPTIMIZATION WITH LOW-RANK REGULARIZATION",
            "text": "We test FeDualEx on the following SPP with nuclear norm regularization for low-rankness, in which we overuse the notation \u2225 \u00b7 \u2225\u2217 for the matrix nuclear norm and \u2225 \u00b7 \u22252 for the matrix spectral norm. We use Tr(\u00b7) to denote the trace of a square matrix. And for the purpose of feasibility and convenience, we impose spectral norm constraints on the variables as well.\nmin X\u2208X max Y\u2208Y\nTr ( (AX\u2212B)\u22a4Y ) + \u03bb\u2225X\u2225\u2217 \u2212 \u03bb\u2225Y\u2225\u2217\nA \u2208 Rn\u00d7m, X = {Rm\u00d7p : \u2225X\u22252 \u2264 D}, B \u2208 Rn\u00d7p, Y = {Rn\u00d7p : \u2225Y\u22252 \u2264 D}.\nSoft-Thresholding Operator for Nuclear Norm Regularization. By choosing the distancegenerating function to be \u2113 = 12\u2225X\u2225 2 F + 1 2\u2225Y\u2225 2 F where \u2225 \u00b7 \u2225F denotes the Frobenius norm, the projection \u2207\u2113\u2217r,k(\u00b7) instantiates to the following element-wise singular value soft-thresholding operator (Cai et al., 2010):\nT\u03bb\u2032(W) := UT\u03bb\u2032(\u03a3)V \u22a4, T\u03bb\u2032(\u03a3) = diag(sgn(\u03c3i(W)) \u00b7min{max{\u03c3i(W)\u2212 \u03bb\u2032, 0}, D}),\nin which \u03bb\u2032 = \u03bb\u03b7c(\u03b7srK + k), W = U\u03a3V\u22a4 is the singular value decomposition (SVD) of W, and we overuse the notation \u03c3i(\u00b7) to represent the singular values. Closed-Form Duality Gap. The closed-form duality gap is given by\nGap(X,Y) = D\u2225diag ( (|\u03c3i(AX\u2212B)| \u2212 \u03bb)+ ) \u2225\u2217 + \u03bb\u2225X\u2225\u2217\n+D\u2225diag ( (|\u03c3j(A\u22a4Y)| \u2212 \u03bb)+ ) \u2225\u2217 +Tr ( B\u22a4Y ) + \u03bb\u2225Y\u2225\u2217,\nWe provide a brief derivation below. Since a constraint is equivalent to an indicator regularization, we move the spectral norm constraint into the objective and denote g1(\u00b7) = \u2225 \u00b7 \u2225\u2217, g2(\u00b7) = { 0 if \u2225 \u00b7 \u22252 \u2264 D \u221e otherwise . By the definitions of duality gap in Definition 1 and convex conjugate\nin Definition 9, the duality gap equals to\nGap(X,Y) = max Y \u03bb{Tr ( 1 \u03bb (AX\u2212B)\u22a4Y ) \u2212 g1(Y)\u2212 g2(Y) + \u2225X\u2225\u2217}\n\u2212min X \u03bb{{Tr ( 1 \u03bb (A\u22a4Y)\u22a4X ) + g1(X) + g2(X)\u2212 \u2225Y\u2225\u2217 \u2212 1 \u03bb Tr ( B\u22a4Y ) }\n= \u03bb(g1 + g2) \u2217(\n1 \u03bb (AX\u2212B)) + \u03bb(g1 + g2)\u2217( 1 \u03bb (A\u22a4Y))\n+ \u03bb\u2225X\u2225\u2217 + \u03bb\u2225Y\u2225\u2217 +Tr ( B\u22a4Y ) = inf\nP {\u03bbg\u22171(P) + \u03bbg\u22172(\n1 \u03bb (AX\u2212B)\u2212P)}+ inf Q {\u03bbg\u22171(Q) + \u03bbg\u22172( 1 \u03bb (A\u22a4Y)\u2212Q)}\n+ \u03bb\u2225X\u2225\u2217 + \u03bb\u2225Y\u2225\u2217 +Tr ( B\u22a4Y ) ,\nin which the last equality holds by Theorem 2.3.2, namely infimal convolution, in Chapter E of Hiriart-Urruty & Lemar\u00e9chal (2004). By definition of the dual norm, we know that the nuclear norm and the spectral norm are dual norms to each other. Therefore, g\u22171(\u00b7) = { 0 if \u2225 \u00b7 \u22252 \u2264 1 \u221e otherwise ,\ng\u22172(\u00b7) = D\u2225 \u00b7 \u2225\u2217. And the infimum is achieved when\n\u03c3i(P) =\n{ \u03c3i ( 1 \u03bb (Ax\u2212B) ) if |\u03c3i ( 1 \u03bb (Ax\u2212B) ) | \u2264 1\nsgn ( \u03c3i ( 1 \u03bb (Ax\u2212B) )) otherwise\n,\n\u03c3j(Q) =\n{ \u03c3j ( 1 \u03bb (A \u22a4y) )\nif |\u03c3j ( 1 \u03bb (A \u22a4y) ) | \u2264 1\nsgn ( \u03c3j ( 1 \u03bb (A \u22a4y) )) otherwise ,\nwhich yields the closed-form duality gap.\nExperiment Settings. We generate a fixed pair of A and B. Each entry of A and half of the columns in B follows the uniform distribution U[\u22121,1] independently. Each entry of the variables X and Y is initialized independently from the distribution U[\u22121,1]. We take m = 600, n = 300, p = 20, \u03bb = 0.1, D = 0.05. For DO, we simulate M = 100 clients. For the gradient query of each client in each local update, we inject a Gaussian noise from N (0, \u03c32). All M = 100 clients participate in each round; noise on each client is i.i.d. with \u03c3 = 0.1. We only tune the global step size \u03b7s and the local step size \u03b7c. For all experiments, the parameters are searched from the combination of \u03b7s \u2208 {1, 3e\u22121, 1e\u22121, 3e\u22122, 1e\u22122} and \u03b7c \u2208 {10, 3, 1, 3e\u22121, 1e\u22121, 3e\u22122, 1e\u22122, 3e\u22123, 1e\u22123}. We run each setting for 10 different random seeds and plot the mean and the standard deviation.\nWe evaluate the convergence in terms of the duality gap and also demonstrate the rank of the solution, for both X and Y. For the feasibility of low-rankness, we generate B to be of rank p2 , i.e. half of the columns of B is linearly dependent on the other half. With p = 20, the optimal rank for the solution would most likely be 10. The evaluation is conducted for two different settings: (a) K = 1 local update for R = 100 rounds; (b) K = 10 local updates for R = 20 rounds. The results are demonstrated in Figure 5 correspondingly.\nDiscussions. From Figure 5, we can see that in the setting for low-rankness regularization, dual methods tend to perform better both in minimizing the duality gap and in encouraging a low-rank solution. In particular, FeDualEx, as a method geared for saddle point optimization, demonstrates better convergence in the duality gap than FedDualAvg. In the meantime, the solution given by FeDualEx quickly reaches the optimal rank of 10. This further reveals the potential of FeDualEx in coping with a variety of regularization and constraints."
        },
        {
            "heading": "A.3 UNIVERSAL ADVERSARIAL TRAINING OF LOGISTIC REGRESSION",
            "text": "We provide the problem formulation and detailed experiment setting for the universal adversarial training of logistic regression demonstrated in the main text.\nProblem Formulation. As introduced, we impose an l1 regularization on the attack to encourage sparsity in addition to the ball constraint. The problem can be formulated as the following SPP:\nmin w\u2208Rd max \u2225\u03b4\u2225\u221e\u2264D\n1\nn n\u2211 i=1 \u2113(w\u22a4(xi + \u03b4), yi) + \u03bb\u2225\u03b4\u22251\nin which \u2113 is the cross-entropy loss for multiclass logistic regression; w \u2208 Rd is the parameter; xi \u2208 Rd is the data and yi is the label; \u03b4 \u2208 Rd is the attack. Experiment Settings. The training data for MNIST is evenly distributed across M = 100 clients, each possessing 600. The client makes K = 5 local updates and communicates for R = 20 rounds. For the CIFAR-10 experiments, each of the 100 clients holds 500 of the training data. The client makes K = 5 local updates and communicates for R = 40 rounds. D = 0.05 for data normalized between 0 and \u03bb = 0.1. Validation is done on the whole validation dataset on the server with unattacked data. As before, the hyper-parameters are searched from the combination of \u03b7s \u2208 {1, 3e\u22121, 1e\u22121, 3e\u22122, 1e\u22122} and \u03b7c \u2208 {10, 3, 1, 3e\u22121, 1e\u22121, 3e\u22122, 1e\u22122, 3e\u22123, 1e\u22123}. We run each setting for 10 different random seeds and plot the mean and the standard deviation in Figure 6.\nAttack Visualization. The attack for MNIST has only one channel and is directly visualized with the color map from blue to red rescaled between the range of the attack, with blue being negative, red being positive, and purple being zero. The attack for CIFAR-10 contains 3 channels and can be directly visualized with RGB mode rescaled between 0 and 255. For the attack to be visible, we divide the value by its maximum then times the result by 4."
        },
        {
            "heading": "A.4 UNIVERSAL ADVERSARIAL TRAINING OF NEURAL NETWORKS",
            "text": "Even though the theoretical result is derived with respect to convex functions, we experimentally demonstrate the convergence FeDualEx for non-convex functions with the adversarial training of neural networks on CIFAR-10. The model tested is a 3-layer convolutional neural network (CNN) with 16, 32, and 64 filters of size 3 \u00d7 3, each layer followed by a relu activation and a 2 \u00d7 2 max-pooling. The performance is demonstrated in Figure 8. The loss value is by no means an exact reflection of the duality gap, nevertheless, FeDualEx also converges for non-convex functions, yielding faster numerical convergence and better-hardened models in terms of validation accuracy on unattacked data. In addition, the sparsity of the attack generated by FeDualEx is 50.38%, whereas that by the vanilla distributed version of projected gradient descent ascent is 99.31%."
        },
        {
            "heading": "B EXTENDED LITERATURE REVIEW",
            "text": ""
        },
        {
            "heading": "B.1 DISTRIBUTED OPTIMIZATION / FEDERATED LEARNING",
            "text": "In recent years, distributed learning has received increasing attention in practice and theory. Earlier works in the field were known as \u201cparallel\u201d (Zinkevich et al., 2010) or \u201clocal\u201d (Zhou & Cong, 2018; Stich, 2019), which are later recognized as the homogeneous case, where data across clients are assumed to be balanced and i.i.d. (independent and identically distributed), of federated learning (FL), specifically, Federated Averaging (FedAvg) (McMahan et al., 2017), DO or FL has been found appealing in various applications (Li et al., 2020a). On the theoretical front, Stich (2019) provides the first convergence rate for Local SGD, or, FedAvg under the homogeneous setting. The distributed optimization paradigm we consider aligns with that in Local SGD (Stich, 2019). The rate for LocalSGD has been improved with tighter analysis (Haddadpour et al., 2019; Khaled et al., 2020; Woodworth et al., 2020a; Glasgow et al., 2022) and acceleration techniques (Yuan & Ma, 2020; Mishchenko et al., 2022). Others also analyze FedAvg under heterogeneity (Haddadpour et al., 2019; Khaled et al., 2020; Woodworth et al., 2020b) and non-i.i.d. data (Li et al., 2020b) or in light propose improvements (Karimireddy et al., 2020). Recently, the idea of DO is further extended to higher-order methods (Bullins et al., 2021; Gupta et al., 2021; Safaryan et al., 2022). Due to the page limit, we refer the readers to (Cao et al., 2023; Wang et al., 2021; Kairouz et al., 2021) for more comprehensive reviews of DO and FL. In the meantime, we point out that none of the work mentioned above covers saddle point problems or non-smooth composite or constrained problems. For distributed saddle point optimization and federated composite optimization, we defer to the following subsections."
        },
        {
            "heading": "B.2 SADDLE POINT OPTIMIZATION",
            "text": "The study of Saddle Point Optimization dates back to the very early gradient descent ascent (Arrow et al., 1958). It was later improved by the important ideas of extra-gradient (Korpelevich, 1976) and optimism (Popov, 1980). In light of these ideas, many algorithms were proposed for SPP (Solodov & Svaiter, 1999; Nemirovski, 2004; Nesterov, 2007; Chambolle & Pock, 2011; Mertikopoulos et al., 2019; Jiang & Mokhtari, 2022). Among them, in the convex-concave setting in particular, the most relevant and prominent ones are Nemirovski\u2019s mirror prox Nemirovski (2004) and Nesterov\u2019s dual extrapolation Nesterov (2007). They generalize respectively Mirror Descent (Nemirovskij & Yudin, 1983) and Dual Averaging (Nesterov, 2009) from convex optimization to monotone variational inequalities (VIs) which include SPP as one realization. Along with Tseng\u2019s Accelerated Proximal\nGradient (Tseng, 2008), they are the three methods that converge to an \u03f5-approximate solution in terms of duality gap at O( 1T ), the known best rate for a general convex-concave SPP (Ouyang & Xu, 2021; Lin et al., 2020). Mirror prox inspired many papers (Antonakopoulos et al., 2019; Chen et al., 2020) and is later extended to the stochastic setting (Juditsky et al., 2011; Mishchenko et al., 2020), the higher-order setting (Bullins & Lai, 2022), and even the composite setting (He et al., 2015), whose introduction we defer to the review of composite optimization. Dual extrapolation is later extended to non-monotone VIs (Song et al., 2020), yet its stochastic and composite versions are, to the best of our knowledge, not found. Kotsalis et al. (2022) recently studied optimal methods for stochastic variational inequalities, yet their result is limited to smooth VIs, not composite ones.\nFrom the perspective of distributed optimization, several works have made preliminary progress for smooth and unconstrained SPP in the Euclidean space. Beznosikov et al. (2020) investigate the distributed extra-gradient method under various conditions and provide upper and lower bounds under strongly-convex strongly-concave and non-convex non-concave assumptions. Hou et al. (2021) propose FedAvg-S and SCAFFOLD-S based on FedAvg (McMahan et al., 2017) and SCAFFOLD (Karimireddy et al., 2020) for SPP, which achieves similar convergence rate to the distributed extragradient algorithm (Beznosikov et al., 2020) under the strong-convexity-concavity assumption. In addition, (Ramezani-Kebrya et al., 2023) studies the problem from the information compression perspective with the measure of communication bits. The topic of distributed or federated saddle point optimization is also found in recent applications of interest, e.g. adversarial domain adaptation (Shen et al., 2023). Yet, none of the existing works includes the study for SPP with constraints or composite possibly non-smooth regularization. Outside of our setting, Borodich et al. (2023) also studies composite SPP, but assumes composite terms to be smooth as well."
        },
        {
            "heading": "B.3 COMPOSITE OPTIMIZATION",
            "text": "Composite optimization has been an important topic due to its reflection of real-world complexities. Representative works include composite mirror descent (Duchi et al., 2010) and regularized dual averaging (Xiao, 2010; Flammarion & Bach, 2017) that generalize mirror descent (Nemirovskij & Yudin, 1983) and dual averaging (Nesterov, 2009) in the context of composite convex optimization. Composite saddle point optimization, in comparison, appears dispersedly in early-day problems in practice (Buades et al., 2005; Aujol & Chambolle, 2005), often as a primal-dual reformulation of composite convex problems. Solving techniques such as smoothing (Nesterov, 2005) and primal-dual splitting (Combettes & Pesquet, 2012) were proposed, and numerical speed-ups were studied (He & Monteiro, 2015; 2016), while systematic convergence analysis on general composite SPP came later in time (He et al., 2015; Chambolle & Pock, 2016; Jiang & Mokhtari, 2022). Recently, Tominin et al. (2021); Borodich et al. (2022) also proposed acceleration techniques for composite SPP.\nMost related among them, the pioneering composite mirror prox (CoMP) (He et al., 2015) constructs auxiliary variables for the composite regularization terms as an upper bound and thus moves the non-smooth term into the problem domain. Observing that the gradient operator for the auxiliary variable is constant, CoMP operates \u201cas if\u201d there were no composite components at all (He et al., 2015), and exhibits a O( 1T ) convergence rate that matches its smooth version (Nemirovski, 2004). In the stochastic setting, Mishchenko et al. (2020) analyzed a variant of stochastic mirror prox (Juditsky et al., 2011), which is then capable of handling composite terms in the Euclidean space. In this paper, we take a different approach that utilizes the generalized Bregman divergence and get the same rate for composite dual extrapolation.\nFor distributed composite optimization with local updates, Yuan et al. (2021) study Federated Mirror Descent, a natural extension of FedAvg that adapts to composite optimization under the convex setting. Along the way, they identified the \u201ccurse of primal averaging\u201d specific to composite optimization in the DO paradigm, where the regularization-imposed structure on the client models may no longer hold after server primal averaging. To resolve this issue, they further proposed Federated Dual Averaging which brings the averaging step to the dual space. Tran Dinh et al. (2021) proposes a federated Douglas-Rachford splitting algorithm for nonconvex composite optimization. On the less related constrained optimization topic, Tong et al. (2020) proposed a federated learning algorithm for nonconvex sparse learning under \u21130 constraint. To the best of our knowledge, the field of distributed optimization for composite SPP remains blank, which we regard as the main focus of this paper."
        },
        {
            "heading": "B.4 OTHER TANGENTIALLY RELATED WORK",
            "text": "Decentralized Optimization. Parallel to FL or DO with local updates, there is another line of work that studies decentralized optimization or consensus optimization over networks, in which machines communicate directly with each other based on their topological connectivity (Nedich et al., 2015). Classic algorithms mentioned previously are widely applied as well under this paradigm, for example, decentralized mirror descent (Rabbat, 2015) and decentralized (composite) dual averaging over networks (Duchi et al., 2011; Liu et al., 2022). Further in the context of composite optimization, Yan et al. (2023); Xiao et al. (2023) focus on composite non-convex objectives under the decentralized setting. Saddle point optimization has also been studied for decentralized optimization, including for proximal point-type methods (Liu et al., 2020) and extra-gradient methods (Rogozin et al., 2021; Beznosikov et al., 2021; 2022). In particular, Rogozin et al. (2021) studies decentralized \u201cmirror prox\u201d in the Euclidean space. We would like to point out that mirror prox in the Euclidean space reduces to vanilla extra-gradient methods. In addition, Aybat & Yazdandoost Hamedani (2016); Xu et al. (2021) study the saddle point reformulation for composite convex objectives over decentralized networks, which essentially focus on composite convex optimization. In the general context of distributed learning of composite SPP, by the judgment of the authors, we came across no paper in decentralized optimization similar to ours. More importantly, decentralized optimization focuses on topics like time-varying network topology (Kovalev et al., 2021a;b) or gossip schema (Dimakis et al., 2006), which are fundamentally different from our setting in terms of motivations, communication protocols, and techniques (Kairouz et al., 2021).\nNonconvex-Nonconcave Saddle Point Problems. For nonconvex-nonconcave SPP, several distributed learning methods have recently been proposed, including extra-gradient methods (Lee & Kim, 2021) and the Local Stochastic Gradient Descent Ascent (Local SGDA) (Sharma et al., 2022; 2023). Yet we emphasize that our object of analysis is composite SPP with possibly non-smooth regularization, and as remarked by Yuan et al. (2021), non-convex optimization for composite possibly non-smooth functions is in itself intricate even for sequential optimization, involving additional assumptions and sophisticated algorithm design (Li & Pong, 2015; Bredies et al., 2015), let alone distributed learning of SPP. Thus we focus on convex-concave analysis in this paper.\nFinite-Sum Optimization with Function Similarity. Another line of work considers finite-sum optimization with function similarity, following the setting similar to DANE (Shamir et al., 2014). In this setting, each machine is assumed to maintain a fixed set of data so that the functions across machines can be \u03b4-similar with a high probability by large-sample concentration inequalities. In the context of distributed saddle points optimization, examples include (Kovalev et al., 2022) and (Beznosikov & Gasnikov, 2023). This setting is significantly different from ours because we do not consider \u03b4-similarity, and our optimization procedure is presented in an online scheme. In (Beznosikov & Gasnikov, 2023) in particular, local steps are also considered, but we would note that Beznosikov & Gasnikov (2023) require the server to take local steps instead of the clients, which also requires the presence of data on the server. This is done by making the first client the server and is in line with the setting in DANE (Shamir et al., 2014). In contrast, the server in our setting only aggregates the model and does not access any data, which also aligns with the privacy-preserving purpose in FL."
        },
        {
            "heading": "C ADDITIONAL PRELIMINARIES, DEFINITIONS, AND REMARKS ON ASSUMPTIONS",
            "text": "In this section, we provide supplementary theoretical backgrounds for the algorithm and the convergence analysis of FeDualEx. We start by providing a more detailed introduction to the related algorithms, then list additional definitions necessary for the analysis. Before moving on to the main proof for FeDualEx, we state formally the assumptions made and provide additional remarks on the assumptions that better link them to their usage in the proof."
        },
        {
            "heading": "C.1 ADDITIONAL PRELIMINARIES",
            "text": "To make this paper as self-contained as possible, in this section, we provide a brief overview of mirror descent, dual averaging, and their advancement in saddle point optimization, i.e., mirror prox and\ndual extrapolation. More comprehensive introductions can be found in the original papers and in (Bubeck et al., 2015; Cohen et al., 2021). We slide into mirror descent from the simple and widely known projected gradient descent, namely vanilla gradient descent with constraint, therefore plus another projection of the updated sequence back to the feasible set."
        },
        {
            "heading": "C.1.1 MIRROR DESCENT AND DUAL AVERAGING",
            "text": "We start by introducing projected gradient descent. Projected gradient descent first takes the gradient update, then projects the updated point back to the constraint by finding a feasible solution within the constraint that minimizes its Euclidean distance to the current point. The updating sequence is given below: \u2200t \u2208 [T ], xt \u2208 X whereas not necessarily for x\u2032t,\nx\u2032t+1 = xt \u2212 \u03b7g(xt)\nxt+1 = argmin x\u2208X\n1 2 \u2225x\u2212 x\u2032t+1\u222522.\nMirror Descent (Nemirovskij & Yudin, 1983). Mirror descent generalizes projected gradient descent to non-Euclidean space with the Bregman divergence (Bregman, 1967). We provide the definition of the Bregman divergence below. Definition 5 (Bregman Divergence (Bregman, 1967)). Let h : Rd \u2192 R \u222a {\u221e} be a prox function or a distance-generating function that is closed, strictly convex, and differentiable in int domh. The Bregman divergence for x \u2208 domh and y \u2208 int domh is defined to be\nV hy (x) = h(x)\u2212 h(y)\u2212 \u27e8\u2207h(y), x\u2212 y\u27e9.\nMirror descent regards \u2207h as a mirror map to the dual space, and follows the procedure below:\n\u2207h(x\u2032t+1) = \u2207h(xt)\u2212 \u03b7g(xt) xt+1 = argmin\nx\u2208X V hx\u2032t+1(x).\nBy choosing h(\u00b7) = 12\u2225 \u00b7 \u2225 2 2 in the Euclidean space whose dual space is itself, mirror descent reduces to projected gradient descent.\nMirror descent can be presented from a proximal point of view, or in the online setting as in Beck & Teboulle (2003):\nxt+1 = argmin x\u2208X\n\u27e8\u03b7g(xt), x\u27e9+ V hxt(x).\nSuch proximal operation with Bregman divergence is studied by others (Censor & Zenios, 1992), and is recently represented by a neatly defined proximal operator (Cohen et al., 2021). Definition 6 (Proximal Operator (Cohen et al., 2021)). The Bregman divergence defined proximal operator is given by\nProx hx\u2032(\u00b7) := argmin x\u2208X {\u27e8\u00b7, x\u27e9+ V hx\u2032(x)}.\nIn this spirit, the mirror descent algorithm can be written with one proximal operation:\nxt+1 = Prox h xt(\u03b7g(xt)).\nComposite Mirror Descent (Duchi et al., 2010). Mirror descent was later generalized to composite convex functions, i.e., the ones with regularization. The key modification is to include the regularization term in the proximal operator, yet not linearize the regularization term, since it could be non-smooth and thus non-differentiable. The updating sequence is given by\nxt+1 = argmin x\u2208X\n\u27e8\u03b7g(xt), x\u27e9+ V hxt(x) + \u03b7\u03c8(x).\nIt can also be represented with a composite mirror map as in (Yuan et al., 2021):\nxt+1 = \u2207(h+ \u03b7\u03c8)\u2217(\u2207h(xt)\u2212 \u03b7g(xt)).\nDual Averaging (Nesterov, 2009). Compared with mirror descent, dual averaging moves the updating sequence to the dual space. The procedure of dual averaging is as follows (Bubeck et al., 2015):\n\u2207h(x\u2032t+1) = \u2207h(x\u2032t)\u2212 \u03b7g(xt) xt+1 = argmin\nx\u2208X V hx\u2032t+1(x),\nor equivalently as presented in (Nesterov, 2009) with the sequence of dual variables: \u2200t \u2208 [T ], xt \u2208 X , \u00b5t \u2208 X \u2217,\n\u00b5t+1 = \u00b5t \u2212 \u03b7g(xt) xt+1 = \u2207h\u2217(\u00b5t+1).\nThis can be further simplified to\nxt+1 = argmin x\u2208X\n\u27e8\u03b7 t\u2211\n\u03c4=0\ng(xt), x\u27e9+ h(x).\nComposite Dual Averaging (Xiao, 2010). Around the same time as composite mirror descent, composite dual averaging, also known as regularized dual averaging, was proposed with a similar idea of including the regularization term in the proximal operator. As presented in the original paper (Xiao, 2010):\nxt+1 = argmin x\u2208X\n\u27e8\u03b7 t\u2211\n\u03c4=0\ng(x\u03c4 ), x\u27e9+ \u03b7\u03b2th(x) + t\u03b7\u03c8(x),\nin which {\u03b2t}t\u22651 is a non-negative and non-decreasing input sequence. Flammarion & Bach (2017) adopted the case with constant sequence \u03b2t = 1\u03b7 ,\nxt+1 = argmin x\u2208X\n\u27e8\u03b7 t\u2211\n\u03c4=0\ng(x\u03c4 ), x\u27e9+ h(x) + t\u03b7\u03c8(x),\nand equivalently with composite mirror map:\n\u00b5t+1 = \u00b5t \u2212 \u03b7g(xt) xt+1 = \u2207(h+ t\u03b7\u03c8)\u2217(\u00b5t+1),\nwhich is also presented in (Yuan et al., 2021)."
        },
        {
            "heading": "C.1.2 MIRROR PROX AND DUAL EXTRAPOLATION",
            "text": "Mirror Prox (Nemirovski, 2004). Mirror prox generalizes the extra-gradient method to nonEuclidean space as mirror descent compared with projected gradient descent. It was proposed for variational inequalities (VIs), including SPP. We first present the corresponding Bregman divergence in the saddle point setting, whose definition was not included in detail in (Nemirovski, 2004) but was later more clearly stated in (Nesterov, 2007; Shi et al., 2017). Definition 7 (Bregman Divergence for Saddle Functions (Nesterov, 2007)). Let \u2113 : X\u00d7Y \u2192 R\u222a{\u221e} be a distance-generating function that is closed, strictly convex, and differentiable in int dom \u2113. For z = (x, y) \u2208 Z = X \u00d7 Y , the function and its gradient are defined as\n\u2113(z) = h1(x) + h2(y), \u2207\u2113(z) = [ \u2207xh1(x) \u2207yh2(y) ] .\nThe Bregman divergence for z = (x, y) \u2208 dom \u2113 and z\u2032 = (x\u2032, y\u2032) \u2208 int dom \u2113 is defined to be\nV \u2113z\u2032(z) := \u2113(z)\u2212 \u2113(z\u2032)\u2212 \u27e8\u2207\u2113(z\u2032), z \u2212 z\u2032\u27e9.\nNotice that our notion of \u2113 is not a saddle function, slightly different from that in Shi et al. (2017), but the Bregman divergence defined is the same as Eq. (6) in Shi et al. (2017) and Eq. (4.9) in Nesterov (2007).\nMirror prox can also be viewed as an extra-step mirror descent. Most intuitively, by introducing an intermediate variable zt+1/2, its procedure is as follows:\n\u2207h(z\u2032t+1/2) = \u2207h(zt)\u2212 \u03b7g(zt)\nzt+1/2 = argmin z\u2208Z\nV hz\u2032 t+1/2 (z)\n\u2207h(z\u2032t+1) = \u2207h(zt)\u2212 \u03b7g(zt+1/2) zt+1 = argmin\nz\u2208Z V hz\u2032t+1(z).\nAnd it can be represented with the proximal operator in Definition 6 as well. Following (Cohen et al., 2021), \u2200t \u2208 [T ], zt, zt+1/2 \u2208 Z ,\nzt+1/2 = Prox \u2113 zt(\u03b7g(zt))\nzt+1 = Prox \u2113 zt(\u03b7g(zt+1/2)).\nDual Extrapolation (Nesterov, 2007). As in dual averaging, dual extrapolation moves the updating sequence of mirror prox to the dual space. Slightly different from a two-step dual averaging, dual extrapolation further initialize a fixed point in the primal space z\u0304, and as presented in (Cohen et al., 2021), its procedure is as follows: \u2200t \u2208 [T ], zt, zt+1/2 \u2208 Z , \u03c9t \u2208 Z\u2217,\nzt = Prox \u2113 z\u0304(\u03c9t)\nzt+1/2 = Prox \u2113 zt(\u03b7g(zt))\n\u03c9t+1 = \u03c9t + \u03b7g(zt+1/2).\nThe updating sequence presented above is equivalent to that defined in the original paper (Nesterov, 2007), simply replacing the argmax with argmin, and the dual variables with its additive inverse in the dual space."
        },
        {
            "heading": "C.2 ADDITIONAL DEFINITIONS",
            "text": "In this subsection, we list additional definitions involved in the theoretical analysis in subsequent sections. Definition 8 (Legendre function (Rockafellar, 1970)). A proper, convex, closed function h : Rd \u2192 R \u222a {\u221e} is called a Legendre function or a function of Legendre-type if (a) h is strictly convex; (b) h is essentially smooth, namely h is differentiable on int dom h, and \u2225\u2207h(xt)\u2225 \u2192 \u221e for every sequence {xt}\u221et=0 \u2282 int dom h converging to a boundary point of dom h as t\u2192 \u221e. Definition 9 (Convex Conjugate or Legendre\u2013Fenchel Transformation (Boyd & Vandenberghe, 2004)). The convex conjugate of a function h is defined as\nh(s) = sup z {\u27e8s, z\u27e9 \u2212 h(z)}.\nDefinition 10 (Differentiability of the conjugate of strictly convex function (Chapter E, Theorem 4.1.1 in Hiriart-Urruty & Lemar\u00e9chal (2004))). For a strictly convex function h, int domh\u2217 \u0338= \u2205 and h\u2217 is continuously differentiable on int domh\u2217, with gradient defined as:\n\u2207h\u2217(s) = argmin z {\u27e8\u2212s, z\u27e9+ h(z)} (5)"
        },
        {
            "heading": "C.3 FORMAL ASSUMPTIONS AND REMARKS",
            "text": "In this subsection, we state the assumptions formally and provide additional remarks that may help in understanding the theoretical analysis. Assumption 1 (Assumptions on the objective function). For the composite saddle function \u03d5(z) = f(x, y) + \u03c81(x)\u2212 \u03c82(y) = 1M \u2211M m=1 fm(x, y) + \u03c81(x)\u2212 \u03c82(y), we assume that\na.(Local Convexity of f ) \u2200m \u2208 [M ], fm(x, y) is convex in x and concave in y.\nb.(Convexity of \u03c8) \u03c81(x) is convex in x, and \u03c82(y) is convex in y.\nAssumption 2 (Assumptions on the gradient operator). For f in the objective function, its gradient operator is given by g = [ \u2207xf \u2212\u2207yf ] . By the linearity of gradient operators, g = 1M \u2211M m=1 gm, and we assume that\na.(Local Lipschitzness of g) \u2200m \u2208 [M ], gm(z) = [\n\u2207xfm(x,y) \u2212\u2207yfm(x,y)\n] is \u03b2-Lipschitz:\n\u2225gm(z)\u2212 gm(z\u2032)\u2225\u2217 \u2264 \u03b2\u2225z \u2212 z\u2032\u2225\nb.(Local Unbiased Estimate and Bounded Variance) For any client m \u2208 [M ], the local gradient queried by some local random sample \u03bem is unbiased and also bounded in variance, i.e., E\u03be[gm(zm; \u03bem)] = gm(zm), and\nE\u03be [ \u2225gm(zm; \u03bem)\u2212 gm(zm)\u22252\u2217 ] \u2264 \u03c32\nc. (Bounded Gradient) \u2200m \u2208 [M ], \u2225gm(zm; \u03bem)\u2225\u2217 \u2264 G\nAssumption 3 (Assumption on the distance-generating function). The distance-generating function h is a Legendre function that is 1-strongly convex, i.e., \u2200x, y,\nh(y)\u2212 h(x)\u2212 \u27e8\u2207h(x), y \u2212 x\u27e9 \u2265 1 2 \u2225y \u2212 x\u22252.\nAssumption 4. The domain of the optimization problem Z is compact in terms of Bregman Divergence, i.e., \u2200z, z\u2032 \u2208 Z , V \u2113z\u2032(z) \u2264 B. Remark 1. An immediate result of Assumption 1a is that, \u2200z = (x, y), z\u2032 = (x\u2032, y\u2032) \u2208 Z\nf(x\u2032, y\u2032)\u2212 f(x, y\u2032) \u2264 \u27e8\u2207xf(x\u2032, y\u2032), x\u2032 \u2212 x\u27e9, f(x\u2032, y)\u2212 f(x\u2032, y\u2032) \u2264 \u27e8\u2212\u2207yf(x\u2032, y\u2032), y\u2032 \u2212 y\u27e9.\nSumming them up,\nf(x\u2032, y)\u2212 f(x, y\u2032) \u2264 \u27e8g(z\u2032), z\u2032 \u2212 z\u27e9. Remark 2. For any sequence of i.i.d. random variables \u03bem0,0, \u03bem0,1/2, ..., \u03be m 1,0, \u03be m 1,1/2, ..., \u03be m r,k, \u03be m r,k+1/2, let Fr,k denote the \u03c3-field generated by the set {\u03bemj,t : \u2200m \u2208 [M ] and ((j = r, t \u2264 k) or (j < r, k \u2208 {0, 1/2, ...,K \u2212 1,K \u2212 1/2}))}. Then any \u03bemr,k is independent of Fr,k\u22121/2, and Assumption 2b implies\nEFr,k [ \u2225gm(zmr,k; \u03bemr,k)\u2212 gm(zmr,k)\u22252\u2217 | Fr,k\u22121/2 ] \u2264 \u03c32.\nRemark 3 (Corollary 23.5.1. and Theorem 26.5. in Rockafellar (1970)). For a closed convex (not necessarily differentiable) function h, \u2202h is the inverse of \u2202h\u2217 in the sense of multi-valued mappings, i.e., z \u2208 \u2202h\u2217(\u03c2) if and only if \u03c2 \u2208 \u2202h(z). Furthermore, if h is of Legendre-type, meaning it is essentially strictly convex and essentially smooth, then \u2202h yields a well-defined \u2207h that acts as a bijection, i.e., (\u2207h)\u22121 = \u2207h\u2217. Remark 4. Assumption 3 and Remark 3 also trivially hold for \u2113 from Definition 7 in the saddle point setting, and eventually, the generalized distance-generating function \u2113t from Definition 3. Due to the strong convexity of \u2113t, \u2207\u2113\u2217t is well-defined as noted in Definition 10. Together with the potential non-smoothness of \u2113t, Remark 3 implies that z = \u2207\u2113\u2217t (\u03c2) if and only if \u03c2 \u2208 \u2202\u2113t(z)."
        },
        {
            "heading": "D ADDITIONAL TECHNICAL LEMMAS",
            "text": "In this section, we list some technical lemmas that are referenced in the proofs of the main theorem and its helping lemmas. Lemma 4 (Jensen\u2019s inequality). For a convex function \u03c6(x), variables x1, ..., xn in its domain, and positive weights a1, ..., an,\n\u03c6 (\u2211n\ni=1 aixi\u2211n i=1 ai\n) \u2264 \u2211n i=1 ai\u03c6(xi)\u2211n\ni=1 ai ,\nand the inequality is reversed if \u03c6(x) is concave.\nLemma 5 (Cauchy-Schwarz inequality (Strang, 2006)). For any x and y in an inner product space,\n\u27e8x, y\u27e9 \u2264 \u2225x\u2225\u2225y\u2225.\nLemma 6 (Young\u2019s inequality (Lemma 1.45. in Sofonea & Matei (2009))). Let p, q \u2208 R be two conjugate exponents, that is 1 < p <\u221e, and 1p + 1 q = 1. Then \u2200a, b \u2265 0,\nab \u2264 a p p + bq q .\nLemma 7 (AM-QM inequality). For any set of positive integers x1, ..., xn,\n( n\u2211 i=1 xi )2 \u2264 n n\u2211 i=1 x2i . (6)\nLemma 8 (Lemma 2.3 in Jiang & Mokhtari (2022)). Suppose Assumption 1 and 2 hold, then \u2200z = (x, y), z1, ..., zT \u2208 Z and \u03b81, ..., \u03b8T \u2265 0 with \u2211T t=1 \u03b8t = 1, we have\n\u03d5( T\u2211 t=1 \u03b8txt, y)\u2212 \u03d5(x, T\u2211 t=1 \u03b8tyt) \u2264 T\u2211 t=1 \u03b8t[\u27e8g(zt), zt \u2212 z\u27e9+ \u03c8(zt)\u2212 \u03c8(z)],\nin which \u03c8(z) = \u03c81(x) + \u03c82(y).\nProof. For \u03c8(z) = \u03c81(x) + \u03c82(y),\n\u03d5(xt, y)\u2212 \u03d5(x, yt) = f(xt, y) + \u03c81(xt)\u2212 \u03c82(y)\u2212 f(x, yt)\u2212 \u03c81(x) + \u03c82(yt) = f(xt, y)\u2212 f(x, yt) + \u03c8(zt)\u2212 \u03c8(z) \u2264 \u27e8g(zt), zt \u2212 z\u27e9+ \u03c8(zt)\u2212 \u03c8(z),\nwhere the inequality holds by convexity-concavity of f(x, y), i.e. Remark 1. Then sum the inequality over t = 1, ..., T ,\nT\u2211 t=1 \u03d5(\u03b8txt, y)\u2212 T\u2211 t=1 \u03d5(x, \u03b8tyt) \u2264 T\u2211 t=1 [ \u27e8g(zt), zt \u2212 z\u27e9+ \u03c8(zt)\u2212 \u03c8(z) ] .\nFinally, by Jensen\u2019s inequality in Lemma 4,\nT\u2211 t=1 \u03d5(\u03b8txt, y) \u2265 \u03d5 ( T\u2211 t=1 \u03b8txt, y ) ,\nT\u2211 t=1 \u03d5(x, \u03b8tyt) \u2264 \u03d5 ( x, T\u2211 t=1 \u03b8tyt ) ,\nwhich completes the proof.\nLemma 9 (Theorem 4.2.1 in Hiriart-Urruty & Lemar\u00e9chal (2004)). The conjugate of an \u03b1-strongly convex function is 1\u03b1 -smooth. That is, for h that is strongly convex with modulus \u03b1 > 0, \u2200x, x \u2032,\n\u2225\u2207h\u2217(x)\u2212\u2207h\u2217(x\u2032)\u2225 \u2264 1 \u03b1 \u2225x\u2212 x\u2032\u2225.\nLemma 10 (Lemma 2 in Flammarion & Bach (2017)). Generalized Bregman divergence upperbounds the Bregman divergence. That is, under Assumption 1 and 3, \u2200x \u2208 dom h, \u2200\u00b5\u2032 \u2208 int dom h\u2217t where ht = h+ t\u03b7\u03c8,\nV\u0303 ht\u00b5\u2032 (x) \u2265 V h x\u2032(x),\nin which x\u2032 = \u2207h\u2217t (\u00b5\u2032)."
        },
        {
            "heading": "E COMPLETE ANALYSIS OF FEDUALEX FOR COMPOSITE SADDLE POINT PROBLEMS",
            "text": "We begin by reformulating the updating sequences with another pair of auxiliary dual variables. Expand the prox operator in Algorithm 1 line 6 to 8 by Definition 4, and rewrite by the gradient of the conjugate function in Definition 10,\nzmr,k = argmin z {\u27e8\u03c2mr,k \u2212 \u03c2\u0304 , z\u27e9+ \u2113r,k(z)} = \u2207\u2113\u2217r,k(\u03c2\u0304 \u2212 \u03c2mr,k)\nzmr,k+1/2 = argmin z {\u27e8\u03b7cgm(zmr,k; \u03bemr,k)\u2212 (\u03c2\u0304 \u2212 \u03c2mr,k), z\u27e9+ \u2113r,k+1(z)} = \u2207\u2113\u2217r,k+1((\u03c2\u0304 \u2212 \u03c2mr,k)\u2212 \u03b7cgm(zmr,k; \u03bemr,k))\n\u03c2mr,k+1 = \u03c2 m r,k + \u03b7 cgm(z m r,k+1/2; \u03be m r,k+1/2)\nDefine auxiliary dual variable \u03c9mr,k = \u03c2\u0304 \u2212 \u03c2mr,k. It satisfies immediately that zmr,k = \u2207\u2113\u2217r,k(\u03c9mr,k), in which \u2113\u2217r,k is the conjugate of \u2113r,k = \u2113+ (\u03b7\nsrK + k)\u03b7c\u03c8. And define \u03c9mr,k+1/2 to be the dual image of the intermediate variable zmr,k+1/2 such that z m r,k+1/2 = \u2207\u2113 \u2217 r,k+1(\u03c9 m r,k+1/2). Then from the above updating sequence, we get an equivalent updating sequence for the auxiliary dual variables.\n\u03c9mr,k+1/2 = \u03c9 m r,k \u2212 \u03b7gm(zmr,k; \u03bemr,k)\n\u03c9mr,k+1 = \u03c9 m r,k \u2212 \u03b7gm(zmr,k+1/2; \u03be m r,k+1/2)\nNow we analyze the following shadow sequences. Define\n\u03c9r,k = 1\nM M\u2211 m=1 \u03c9mr,k, gr,k = 1 M M\u2211 m=1 gm(z m r,k; \u03be m r,k),\nthen\n\u03c9r,k+1/2 = \u03c9r,k \u2212 \u03b7cgr,k, (2) \u03c9r,k+1 = \u03c9r,k \u2212 \u03b7cgr,k+1/2. (3)\nIn the meantime,\nz\u0302r,k = \u2207\u2113\u2217r,k(\u03c9r,k), \u0302zr,k+1/2 = \u2207\u2113\u2217r,k+1(\u03c9r,k+1/2). (4)"
        },
        {
            "heading": "E.1 MAIN THEOREM AND PROOF",
            "text": "Theorem 1 (Main). Under assumptions, the duality gap evaluated with the ergodic sequence generated by the intermediate steps of FeDualEx in Algorithm 1 is bounded by\nE [ Gap ( 1 RK R\u22121\u2211 r=0 K\u22121\u2211 k=0 \u0302zr,k+1/2 )] \u2264 B \u03b7cRK + 20\u03b22(\u03b7c)3K2G2 + 5\u03c32\u03b7c M + 2 3 2 \u03b2\u03b7cKGB 1 2 .\nChoosing step size \u03b7c = min{ 1 5 1 2 \u03b2 , B\n1 4\n20 1 4 \u03b2 1 2 G 1 2 K 3 4 R 1 4 , B\n1 2 M 1 2\n5 1 2 \u03c3R 1 2 K 1 2 , B\n1 4\n2 3 4 \u03b2 1 2 G 1 2 KR 1 2 },\nE [ Gap ( 1 RK R\u22121\u2211 r=0 K\u22121\u2211 k=0 \u0302zr,k+1/2 )] \u2264 5 1 2 \u03b2B RK + 20 1 4 \u03b2 1 2G 1 2B 3 4 K 1 4R 3 4 + 5 1 2\u03c3B 1 2 M 1 2R 1 2K 1 2 + 2 3 4 \u03b2 1 2G 1 2B 3 4 R 1 2 .\nProof. The proof of the main theorem relies on Lemma 1, the bound for the non-smooth term, and Lemma 2, the bound for the smooth term. These two lemmas are combined in Lemma 3 and then yield the per-step progress for FeDualEx. The three lemmas are listed and proved right after this theorem. Here, we finish proving the main theorem from the per-step progress.\nStarting from Lemma 3, we telescope for all local updates k \u2208 {0, ...,K \u2212 1} after the same communication round r.\n\u03b7cE [K\u22121\u2211\nk=0\n[ \u27e8g( \u0302zr,k+1/2), \u0302zr,k+1/2 \u2212 z\u27e9+ \u03c8( \u0302zr,k+1/2)\u2212 \u03c8(z) ]]\n\u2264 V\u0303 \u2113r,0\u03c9r,0 (z)\u2212 V\u0303 \u2113r,K \u03c9r,K\n(z) + 5\u03c32(\u03b7c)2K\nM + 20 K\u22121\u2211 k=0 \u03b22(\u03b7c)4(k + 1)2G2 + 2 3 2 K\u22121\u2211 k=0 \u03b2(\u03b7c)2(k + 1)GB 1 2\n\u2264 V\u0303 \u2113r,0\u03c9r,0 (z)\u2212 V\u0303 \u2113r,K \u03c9r,K\n(z) + 5\u03c32(\u03b7c)2K\nM + 20 K\u22121\u2211 k=0 \u03b22(\u03b7c)4K2G2 + 2 3 2 K\u22121\u2211 k=0 \u03b2(\u03b7c)2KGB 1 2\n\u2264 V\u0303 \u2113r,0\u03c9r,0 (z)\u2212 V\u0303 \u2113r,K \u03c9r,K\n(z) + 5\u03c32(\u03b7c)2K\nM + 20\u03b22(\u03b7c)4K3G2 + 2\n3 2 \u03b2(\u03b7c)2K2GB 1 2 .\nAs we initialize the local dual updates on all clients after each communication with the dual average of the previous round\u2019s last update, \u2200r \u2208 {1, ..., R}, the first variable in this round \u03c9r,0 is the same as the last variable \u03c9r\u22121,0 in the previous round. As a result, taking the server step size \u03b7s = 1, we can further telescope across all rounds and have\n\u03b7cE [R\u22121\u2211\nr=0 K\u22121\u2211 k=0 [ \u27e8g( \u0302zr,k+1/2), \u0302zr,k+1/2 \u2212 z\u27e9+ \u03c8( \u0302zr,k+1/2)\u2212 \u03c8(z) ]] \u2264 V\u0303 \u21130,0\u03c90,0 (z)\u2212 V\u0303 \u2113R,K \u03c9R,K (z) + 5\u03c32(\u03b7c)2KR\nM + 20\u03b22(\u03b7c)4K3RG2 + 2 3 2 \u03b2(\u03b7c)2K2RGB 1 2 .\nNotice that the generalized Bregman divergence V\u0303 \u21130,0\u03c90,0 (z) = V\u0303 \u21130,0 \u03c2\u0304\u2212\u03c20(z) = V\u0303 \u2113 \u03c2\u0304 (z) = V \u2113 z0(z), where z0 = \u2207\u2113\u2217(\u03c2\u0304). Thus, by Assumption 4, V\u0303 \u21130,0 \u03c90,0\n(z) \u2264 B. Dividing \u03b7cKR on both sides of the equation, we get\n\u03b7cE [ 1 RK R\u22121\u2211 r=0 K\u22121\u2211 k=0 [ \u27e8g( \u0302zr,k+1/2), \u0302zr,k+1/2 \u2212 z\u27e9+ \u03c8( \u0302zr,k+1/2)\u2212 \u03c8(z) ]] \u2264 B \u03b7cRK + 5\u03c32\u03b7c M + 20\u03b22(\u03b7c)3K2G2 + 2 3 2 \u03b2\u03b7cKGB 1 2 .\nFinally, applying Lemma 8 completes the proof.\nLemma 1 (Bounding the Regularization Term). \u2200z, \u03b7c [ \u03c8( \u0302zr,k+1/2)\u2212 \u03c8(z) ] = V\u0303 \u2113r,k \u03c9r,k (z)\u2212 V\u0303 \u2113r,k+1\u03c9r,k+1 (z)\u2212 V\u0303 \u2113r,k \u03c9r,k ( \u0302zr,k+1/2)\u2212 V\u0303 \u2113r,k+1 \u03c9r,k+1/2 (z\u0302r,k+1)\n+ \u03b7c\u27e8gr,k+1/2 \u2212 gr,k, \u0302zr,k+1/2 \u2212 z\u0302r,k+1\u27e9+ \u03b7c\u27e8gr,k+1/2, z \u2212 \u0302zr,k+1/2\u27e9\nProof. By the definition of generalized Bregman divergence and the updating sequence in Eq. (2), \u2200z,\nV\u0303 \u2113r,k+1 \u03c9r,k+1/2 (z) = \u2113r,k+1(z)\u2212 \u2113r,k+1( \u0302zr,k+1/2)\u2212 \u27e8\u03c9r,k+1/2, z \u2212 \u0302zr,k+1/2\u27e9\n= \u2113r,k+1(z)\u2212 \u2113r,k+1( \u0302zr,k+1/2)\u2212 \u27e8\u03c9r,k \u2212 \u03b7cgr,k, z \u2212 \u0302zr,k+1/2\u27e9 = \u2113r,k(z)\u2212 \u2113r,k( \u0302zr,k+1/2) + \u03b7c [ \u03c8(z)\u2212 \u03c8( \u0302zr,k+1/2) ] \u2212 \u27e8\u03c9r,k, z \u2212 \u0302zr,k+1/2\u27e9+ \u03b7c\u27e8gr,k, z \u2212 \u0302zr,k+1/2\u27e9. (7)\nSimilarly, we can have for the updating sequence in Eq. (3) that \u2200z,\nV\u0303 \u2113r,k+1 \u03c9r,k+1 (z) = \u2113r,k(z)\u2212 \u2113r,k(z\u0302r,k+1) + \u03b7c [ \u03c8(z)\u2212 \u03c8(z\u0302r,k+1) ] \u2212 \u27e8\u03c9r,k, z \u2212 z\u0302r,k+1\u27e9+ \u03b7c\u27e8gr,k+1/2, z \u2212 z\u0302r,k+1\u27e9. (8)\nPlug z = z\u0302r,k+1 into Eq. (7),\nV\u0303 \u2113r,k+1 \u03c9r,k+1/2 (z\u0302r,k+1) = \u2113r,k(z\u0302r,k+1)\u2212 \u2113r,k( \u0302zr,k+1/2) + \u03b7c [ \u03c8(z\u0302r,k+1)\u2212 \u03c8( \u0302zr,k+1/2) ] \u2212 \u27e8\u03c9r,k, z\u0302r,k+1 \u2212 \u0302zr,k+1/2\u27e9+ \u03b7c\u27e8gr,k, z\u0302r,k+1 \u2212 \u0302zr,k+1/2\u27e9.\nAdd this up with Eq. (8),\nV\u0303 \u2113r,k+1 \u03c9r,k+1/2 (z\u0302r,k+1) + V\u0303 \u2113r,k+1 \u03c9r,k+1 (z) = \u2113r,k(z)\u2212 \u2113r,k( \u0302zr,k+1/2)\u2212 \u27e8\u03c9r,k, z \u2212 \u0302zr,k+1/2\u27e9\ufe38 \ufe37\ufe37 \ufe38 A1\n+ \u03b7c [ \u03c8(z)\u2212 \u03c8( \u0302zr,k+1/2) ] + \u03b7c\u27e8gr,k, z\u0302r,k+1 \u2212 \u0302zr,k+1/2\u27e9+ \u03b7c\u27e8gr,k+1/2, z \u2212 z\u0302r,k+1\u27e9\ufe38 \ufe37\ufe37 \ufe38\nA2\n.\nFor A1 we have\nA1 = \u2113r,k(z)\u2212 \u2113r,k(z\u0302r,k)\u2212 \u27e8\u03c9r,k, z \u2212 z\u0302r,k\u27e9 \u2212 \u2113r,k( \u0302zr,k+1/2) + \u2113r,k(z\u0302r,k) + \u27e8\u03c9r,k, \u0302zr,k+1/2 \u2212 z\u0302r,k\u27e9\n= V\u0303 \u2113r,k \u03c9r,k (z)\u2212 V\u0303 \u2113r,k\u03c9r,k ( \u0302zr,k+1/2).\nFor A2 we have\nA2 = \u03b7c\u27e8gr,k, z\u0302r,k+1 \u2212 \u0302zr,k+1/2\u27e9+ \u03b7c\u27e8gr,k+1/2, \u0302zr,k+1/2 \u2212 z\u0302r,k+1\u27e9+ \u03b7c\u27e8gr,k+1/2, z \u2212 \u0302zr,k+1/2\u27e9 = \u03b7c\u27e8gr,k+1/2, z \u2212 \u0302zr,k+1/2\u27e9+ \u03b7c\u27e8gr,k+1/2 \u2212 gr,k, \u0302zr,k+1/2 \u2212 z\u0302r,k+1\u27e9\nPlug A1 and A2 back in completes the proof.\nFor the purpose of clarity, we demonstrate how we generate the terms to be separately bounded for the smooth part with the following Lemma 2, which holds trivially by the linearity of the gradient operator g = 1M \u2211M m=1 gm and then direct cancellation. Lemma 2 (Bounding the Smooth Term). \u2200z,\n\u27e8g( \u0302zr,k+1/2), \u0302zr,k+1/2 \u2212 z\u27e9 = \u27e8gr,k+1/2, \u0302zr,k+1/2 \u2212 z\u27e9+ \u27e8 1\nM M\u2211 m=1 gm(z m r,k+1/2)\u2212 gr,k+1/2, \u0302zr,k+1/2 \u2212 z\u27e9\n+ \u27e8 1 M M\u2211 m=1 [gm( \u0302zr,k+1/2)\u2212 gm(zmr,k+1/2)], \u0302zr,k+1/2 \u2212 z\u27e9\nBased on the previous two lemmas, we arrive at the following lemma that bounds the per-step progress of FeDualEx.\nLemma 3 (Per-step Progress for FeDualEx in Saddle Point Setting). For \u03b7c \u2264 1 5 1 2 \u03b2 ,\n\u03b7cE [ \u27e8g( \u0302zr,k+1/2), \u0302zr,k+1/2 \u2212 z\u27e9+ \u03c8( \u0302zr,k+1/2)\u2212 \u03c8(z) ] \u2264 V\u0303 \u2113r,k\u03c9r,k (z)\u2212 V\u0303 \u2113r,k+1 \u03c9r,k+1 (z) + 5\u03c32(\u03b7c)2\nM + 20\u03b22(\u03b7c)4(k + 1)2G2 + 2 3 2 \u03b2(\u03b7c)2(k + 1)GB 1 2 .\nProof. Based on the previous two lemmas, we can get the following simply by summing them up, in which we denote the left-hand side as LHS for simplicity.\nLHS := \u03b7c [ \u27e8g( \u0302zr,k+1/2), \u0302zr,k+1/2 \u2212 z\u27e9+ \u03c8( \u0302zr,k+1/2)\u2212 \u03c8(z) ] \u2264 V\u0303 \u2113r,k\u03c9r,k (z)\u2212 V\u0303 \u2113r,k+1 \u03c9r,k+1 (z)\u2212V\u0303 \u2113r,k\u03c9r,k ( \u0302zr,k+1/2)\u2212 V\u0303 \u2113r,k+1 \u03c9r,k+1/2\n(z\u0302r,k+1)\ufe38 \ufe37\ufe37 \ufe38 A3\n+ \u03b7c\u27e8gr,k+1/2 \u2212 gr,k, \u0302zr,k+1/2 \u2212 z\u0302r,k+1\u27e9\n+ \u03b7c\u27e8 1 M M\u2211 m=1 gm(z m r,k+1/2)\u2212 gr,k+1/2, \u0302zr,k+1/2 \u2212 z\u27e9\n+ \u03b7c\u27e8 1 M M\u2211 m=1 [gm( \u0302zr,k+1/2)\u2212 gm(zmr,k+1/2)], \u0302zr,k+1/2 \u2212 z\u27e9\nFor the two generalized Bregman divergence terms in A3, we bound them by Lemma 10 and the strong convexity of \u2113 in Remark 4,\nA3 \u2264 \u2212V \u2113z\u0302r,k( \u0302zr,k+1/2)\u2212 V \u2113 \u0302zr,k+1/2(z\u0302r,k+1)\n\u2264 \u22121 2 \u2225z\u0302r,k \u2212 \u0302zr,k+1/2\u22252 \u2212 1 2 \u2225 \u0302zr,k+1/2 \u2212 z\u0302r,k+1\u22252\nAs a result,\nLHS \u2264 V\u0303 \u2113r,k\u03c9r,k (z)\u2212 V\u0303 \u2113r,k+1 \u03c9r,k+1 (z)\u2212 1 2 \u2225z\u0302r,k \u2212 \u0302zr,k+1/2\u22252\n\u22121 2 \u2225 \u0302zr,k+1/2 \u2212 z\u0302r,k+1\u22252 + \u03b7c\u27e8gr,k+1/2 \u2212 gr,k, \u0302zr,k+1/2 \u2212 z\u0302r,k+1\u27e9\ufe38 \ufe37\ufe37 \ufe38\nA4\n+ \u03b7c\u27e8 1 M M\u2211 m=1 gm(z m r,k+1/2)\u2212 gr,k+1/2, \u0302zr,k+1/2 \u2212 z\u27e9\n+ \u03b7c\u27e8 1 M M\u2211 m=1 [gm( \u0302zr,k+1/2)\u2212 gm(zmr,k+1/2)], \u0302zr,k+1/2 \u2212 z\u27e9.\nA4 can be bounded with Cauchy-Schwarz (Lemma 5) inequality and Young\u2019s inequality (Lemma 6).\nA4 \u2264 \u22121 2 \u2225 \u0302zr,k+1/2 \u2212 z\u0302r,k+1\u22252 + \u03b7c\u2225gr,k+1/2 \u2212 gr,k\u2225\u2217\u2225 \u0302zr,k+1/2 \u2212 z\u0302r,k+1\u2225\n\u2264 \u22121 2 \u2225 \u0302zr,k+1/2 \u2212 z\u0302r,k+1\u22252 +\n(\u03b7c)2\n2 \u2225gr,k+1/2 \u2212 gr,k\u22252\u2217 +\n1 2 \u2225 \u0302zr,k+1/2 \u2212 z\u0302r,k+1\u22252\n= (\u03b7c)2\n2 \u2225gr,k+1/2 \u2212 gr,k\u22252\u2217.\nThen we have \u03b7c ( \u03d5( \u0302zr,k+1/2)\u2212 \u03d5(z) ) \u2264 V\u0303 \u2113r,k\u03c9r,k (z)\u2212 V\u0303 \u2113r,k+1 \u03c9r,k+1 (z)\u2212 1 2 \u2225z\u0302r,k \u2212 \u0302zr,k+1/2\u22252 + (\u03b7c)2 2 \u2225gr,k+1/2 \u2212 gr,k\u22252\u2217\n+ \u03b7c\u27e8 1 M M\u2211 m=1 gm(z m r,k+1/2)\u2212 gr,k+1/2, \u0302zr,k+1/2 \u2212 z\u27e9\n+ \u03b7c\u27e8 1 M M\u2211 m=1 [gm( \u0302zr,k+1/2)\u2212 gm(zmr,k+1/2)], \u0302zr,k+1/2 \u2212 z\u27e9.\nTaking expectations on both sides we get\n\u03b7cE [ \u03d5( \u0302zr,k+1/2)\u2212 \u03d5(z) ] \u2264 V\u0303 \u2113r,k\u03c9r,k (z)\u2212 V\u0303 \u2113r,k+1 \u03c9r,k+1 (z)\n\u22121 2 E [ \u2225z\u0302r,k \u2212 \u0302zr,k+1/2\u22252 ] \ufe38 \ufe37\ufe37 \ufe38\nB1\n+ (\u03b7c)2 2 E [ \u2225gr,k+1/2 \u2212 gr,k\u22252\u2217 ] \ufe38 \ufe37\ufe37 \ufe38\nB2 + \u03b7cE [ \u27e8 1 M M\u2211 m=1 gm(z m r,k+1/2)\u2212 gr,k+1/2, \u0302zr,k+1/2 \u2212 z\u27e9 ] \ufe38 \ufe37\ufe37 \ufe38\nB3 + \u03b7cE [ \u27e8 1 M M\u2211 m=1 [gm( \u0302zr,k+1/2)\u2212 gm(zmr,k+1/2)], \u0302zr,k+1/2 \u2212 z\u27e9 ]\n\ufe38 \ufe37\ufe37 \ufe38 B4\n.\nB2 is bounded in Lemma 14. Therefore, we have\nB1 +B2 \u2264 (\u03b7 c)2\n2 (10\u03c32 M + 40\u03b22(\u03b7c)2(k + 1)2G2 ) + 5(\u03b7c)2\u03b22 2 E [ \u2225 \u0302zr,k+1/2 \u2212 z\u0302r,k\u22252 ] \u2212 1 2 E [ \u2225z\u0302r,k \u2212 \u0302zr,k+1/2\u22252\n] = (\u03b7c)2\n2 (10\u03c32 M + 40\u03b22(\u03b7c)2(k + 1)2G2 ) + 5(\u03b7c)2\u03b22 \u2212 1 2 E [ \u2225 \u0302zr,k+1/2 \u2212 z\u0302r,k\u22252 ] \u2264 5\u03c3 2(\u03b7c)2\nM + 20\u03b22(\u03b7c)4(k + 1)2G2,\nfor \u03b7c \u2264 1 5 1 2 \u03b2 .\nB3 is zero after taking the expectation as shown in Lemma 11. B4 is bounded in Lemma 13. Plugging the bounds for B1 +B2, B3, and B4 back in completes the proof."
        },
        {
            "heading": "E.2 HELPING LEMMAS",
            "text": "In this section, we list the helping lemmas that were referenced in the proof of Lemma 1, 2, and 3. Lemma 11 (Unbiased Gradient Estimate). Under Assumption 1 and 2,\n\u03b7cEFr,k+1/2 [ \u27e8 1 M M\u2211 m=1 gm(z m r,k+1/2)\u2212 gr,k+1/2, \u0302zr,k+1/2 \u2212 z\u27e9 ] = 0\nProof. By the unbiased gradient estimate in Assumption 2b and its following Remark 2,\n\u03b7cEFr,k+1/2 [ \u27e8 1 M M\u2211 m=1 gm(z m r,k+1/2)\u2212 gr,k+1/2, \u0302zr,k+1/2 \u2212 z\u27e9 ] = \u03b7cEFr,k [ EFr,k+1/2 [ \u27e8 1 M M\u2211 m=1 gm(z m r,k+1/2)\u2212 gr,k+1/2, \u0302zr,k+1/2 \u2212 z\u27e9\n\u2223\u2223Fr,k]] = 0.\nLemma 12 (Bounded Client Drift under Assumption 2c). \u2200m \u2208 [M ], \u2200k \u2208 {0, ...,K \u2212 1}, \u2225 \u0302zr,k+1/2 \u2212 zmr,k+1/2\u2225 \u2264 2\u03b7 c(k + 1)G\n\u2225z\u0302r,k \u2212 zmr,k\u2225 \u2264 2\u03b7ckG\nProof. By the smoothness of the conjugate of a strongly convex function, i.e., Lemma 9, \u2225 \u0302zr,k+1/2 \u2212 zmr,k+1/2\u2225 = \u2225\u2207\u2113 \u2217 r,k(\u03c9r,k+1/2)\u2212\u2207\u2113\u2217r,k(\u03c9mr,k+1/2)\u2225\n\u2264 \u2225\u03c9r,k+1/2 \u2212 \u03c9mr,k+1/2\u2225\u2217 After the same round of communication, by the updating sequence, we have \u2200m \u2208 [M ]:\n\u03c9mr,k+1/2 = \u03c9 m r,k \u2212 \u03b7cgm(zmr,k; \u03bemr,k)\n= \u2212\u03b7c k\u22121\u2211 \u2113=0 gm(z m r,\u2113+1/2; \u03be m r,\u2113+1/2)\u2212 \u03b7 cgm(z m r,k; \u03be m r,k)\nImmediately after each round of communication, all machines are synchronized, i.e., \u2200m1,m2 \u2208 [M ], \u03c9m1r,0 = \u03c9 m2 r,0 . Therefore, \u2200k \u2208 {0, ...,K \u2212 1},\n\u03c9m1r,k+1/2 \u2212 \u03c9 m2 r,k+1/2 = \u2212\u03b7 c k\u22121\u2211 \u2113=0 gm1(z m1 r,\u2113+1/2; \u03be m1 r,\u2113+1/2)\u2212 \u03b7 cgm1(z m1 r,k ; \u03be m1 r,k )\n+ \u03b7c k\u22121\u2211 \u2113=0 gm2(z m2 r,\u2113+1/2; \u03be m2 r,\u2113+1/2) + \u03b7 cgm2(z m2 r,k ; \u03be m2 r,k )\nThen \u2200m1,m2 \u2208 [M ], \u2200k \u2208 {0, ...,K \u2212 1}, by triangle inequality, Jensen\u2019s inequality, and the bounded gradient Assumption 2c,\n\u2225\u03c9m1r,k+1/2 \u2212 \u03c9 m2 r,k+1/2\u2225\u2217 \u2264 \u03b7 c ( k\u22121\u2211 \u2113=0 \u2225gm1(z m1 r,\u2113+1/2; \u03be m1 r,\u2113+1/2)\u2225\u2217 + \u2225gm1(z m1 r,k ; \u03be m1 r,k )\u2225\u2217\n+ k\u22121\u2211 \u2113=0 \u2225gm2(z m2 r,\u2113+1/2; \u03be m2 r,\u2113+1/2)\u2225\u2217 + \u2225gm2(z m2 r,k ; \u03be m2 r,k )\u2225\u2217 ) \u2264 2\u03b7c(k + 1)G.\nAs a result,\n\u2225 \u0302zr,k+1/2 \u2212 zmr,k+1/2\u2225 \u2264 \u2225\u03c9r,k+1/2 \u2212 \u03c9 m r,k+1/2\u2225\u2217\n\u2264 sup m1,m2 \u2225\u03c9m1r,k+1/2 \u2212 \u03c9 m2 r,k+1/2\u2225\u2217 \u2264 2\u03b7c(k + 1)G.\nSimilarly, we can show that\n\u2225z\u0302r,k \u2212 zmr,k\u2225 \u2264 2\u03b7ckG.\nLemma 13. Under Assumption 1-4,\n\u03b7cE [ \u27e8 1 M M\u2211 m=1 [gm( \u0302zr,k+1/2)\u2212 gm(zmr,k+1/2)], \u0302zr,k+1/2 \u2212 z\u27e9 ] \u2264 2 32 \u03b2(\u03b7c)2(k + 1)GB 12 .\nProof. The proof of this lemma relies on the bounded client drift in Lemma 12. We start by splitting the inner product using Cauchy-Schwarz inequality in Lemma 5, and state the reference for the following derivation in the parenthesis.\n\u03b7cE [ \u27e8 1 M M\u2211 m=1 [gm( \u0302zr,k+1/2)\u2212 gm(zmr,k+1/2)], \u0302zr,k+1/2 \u2212 z\u27e9 ]\n\u2264 \u03b7cE [ \u2225 1 M M\u2211 m=1 [gm( \u0302zr,k+1/2)\u2212 gm(zmr,k+1/2)]\u2225\u2217\u2225 \u0302zr,k+1/2 \u2212 z\u2225 ] \u2264 \u03b7cE [ 1 M M\u2211 m=1 \u2225gm( \u0302zr,k+1/2)\u2212 gm(zmr,k+1/2)\u2225\u2217\u2225 \u0302zr,k+1/2 \u2212 z\u2225 ]\n(Jensen\u2019s)\n\u2264 \u03b7cE [ 1 M M\u2211 m=1 \u03b2\u2225 \u0302zr,k+1/2 \u2212 zmr,k+1/2\u2225\u2217\u2225 \u0302zr,k+1/2 \u2212 z\u2225 ]\n(Smoothness)\n\u2264 \u03b7cE [ 1 M M\u2211 m=1 2\u03b2\u03b7c(k + 1)G\u2225 \u0302zr,k+1/2 \u2212 z\u2225 ]\n(Lemma 12)\n\u2264 \u03b7cE [ 2\u03b2\u03b7c(k + 1)G \u00b7 \u221a 2V \u2113z ( \u0302zr,k+1/2) ] (Strong-convexity of \u2113)\n\u2264 2 32 \u03b2(\u03b7c)2(k + 1)GB 12 (Assumption 4)\nLemma 14 (Difference of Gradient and Extra-gradient). Under Assumption 1-4,\nE [ \u2225gr,k+1/2 \u2212 gr,k\u22252\u2217 ] \u2264 10\u03c3 2\nM + 40\u03b22(\u03b7c)2(k + 1)2G2 + 5\u03b22E\n[ \u2225 \u0302zr,k+1/2 \u2212 z\u0302r,k\u22252 ] .\nProof. By Lemma 7, EFr,k+1/2 [ \u2225gr,k+1/2 \u2212 gr,k\u22252\u2217 ] = E [\u2225\u2225[gr,k+1/2 \u2212 1 M M\u2211 m=1 gm(z m r,k+1/2)\n] + [ 1 M M\u2211 m=1 gm(z m r,k)\u2212 gr,k ] + 1 M M\u2211 m=1 [ gm(z m r,k+1/2)\u2212 gm( \u0302zr,k+1/2)\n] + 1\nM M\u2211 m=1 [ gm(z\u0302r,k)\u2212 gm(zmr,k) ] + 1 M M\u2211 m=1 [ gm( \u0302zr,k+1/2)\u2212 gm(z\u0302r,k) ]\u2225\u22252 \u2217 ] \u2264 5E [ \u2225gr,k+1/2 \u2212 1\nM M\u2211 m=1 gm(z m r,k+1/2)\u2225 2 \u2217 ] \ufe38 \ufe37\ufe37 \ufe38\nC1\n+5E [ \u2225 1 M M\u2211 m=1 gm(z m r,k)\u2212 gr,k\u22252\u2217 ] \ufe38 \ufe37\ufe37 \ufe38\nC2 + 5E [ \u2225 1 M M\u2211 m=1 [ gm(z m r,k+1/2)\u2212 gm( \u0302zr,k+1/2) ] \u22252\u2217 ]\n\ufe38 \ufe37\ufe37 \ufe38 C3\n+ 5E [ \u2225 1 M M\u2211 m=1 [ gm(z\u0302r,k)\u2212 gm(zmr,k) ] \u22252\u2217 ]\n\ufe38 \ufe37\ufe37 \ufe38 C4\n+5E [ \u2225 1 M M\u2211 m=1 [ gm( \u0302zr,k+1/2)\u2212 gm(z\u0302r,k) ] \u22252\u2217 ]\n\ufe38 \ufe37\ufe37 \ufe38 C5\nFor C1, by Assumption 2b and its following Remark 2, C1 = EFr,k+1/2 [ \u2225 1 M M\u2211 m=1 gm(z m r,k+1/2; \u03be m r,k+1/2)\u2212 1 M M\u2211 m=1 gm(z m r,k+1/2)\u2225 2 \u2217 ] = 1\nM2 EFr,k+1/2\n[ \u2225 M\u2211 m=1 [ gm(z m r,k+1/2; \u03be m r,k+1/2)\u2212 gm(z m r,k+1/2) ] \u22252\u2217 ]\n= 1\nM2 VarFr,k+1/2 [ M\u2211 m=1 [ gm(z m r,k+1/2; \u03be m r,k+1/2)\u2212 gm(z m r,k+1/2) ]] = 1\nM2 M\u2211 m=1 VarFr,k+1/2 [[ gm(z m r,k+1/2; \u03be m r,k+1/2)\u2212 gm(z m r,k+1/2) ]] (i.i.d.)\n= 1\nM2 M\u2211 m=1 EFr,k+1/2 [ \u2225gm(zmr,k+1/2; \u03be m r,k+1/2)\u2212 gm(z m r,k+1/2)\u2225 2 \u2217 ] = 1\nM2 M\u2211 m=1 EFr,k [ EFr,k+1/2 [ \u2225gm(zmr,k+1/2; \u03be m r,k+1/2)\u2212 gm(z m r,k+1/2)\u2225 2 \u2217 \u2223\u2223Fr,k]]\n\u2264 \u03c3 2\nM\nSimilarly, we have C2 \u2264 \u03c3 2\nM .\nFor C3, by Lemma 7, \u03b2-smoothness of fm, and finally Lemma 12, we have C3 \u2264 E [ 1 M2 \u00b7M M\u2211\nm=1\n\u2225gm(zmr,k+1/2)\u2212 gm( \u0302zr,k+1/2)\u2225 2 \u2217 ] \u2264 \u03b2 2\nM M\u2211 m=1 E [ \u2225zmr,k+1/2 \u2212 \u0302zr,k+1/2\u2225 2 ]\n\u2264 4\u03b22(\u03b7c)2(k + 1)2G2\nSimilarly for C4, we have C4 \u2264 4\u03b22(\u03b7c)2k2G2. For C5, by Lemma 7, \u03b2-smoothness of fm from Assumption 2a, and finally Lemma 12,\nC5 = E [ 1 M2 \u2225 M\u2211\nm=1\n[ gm( \u0302zr,k+1/2)\u2212 gm(z\u0302r,k) ] \u22252\u2217 ]\n\u2264 E [ 1 M2 \u00b7M M\u2211\nm=1\n\u2225gm( \u0302zr,k+1/2))\u2212 gm(z\u0302r,k)\u22252\u2217 ]\n\u2264 \u03b22E [ \u2225 \u0302zr,k+1/2 \u2212 z\u0302r,k\u22252 ] .\nPlugging the bounds for C1, C2, C3, C4, and C5 back in completes the proof."
        },
        {
            "heading": "F COMPLETE ANALYSIS OF FEDUALEX FOR COMPOSITE CONVEX OPTIMIZATION",
            "text": "In this section, we reduce the problem to composite convex optimization in the following form: min x\u2208X \u03d5(x) = f(x) + \u03c8(x) (9)\nwhere f(x) = 1M \u2211M\nm=1 fm(x). The analysis builds upon the strong-convexity of the distancegenerating function h in Assumption 3 and the following set of assumptions in the convex optimization setting: Assumption 5. We make the following assumptions:\na.(Convexity of f ) \u2200m \u2208 [M ], fm is convex. That is, \u2200x, x\u2032 \u2208 X , fm(x)\u2212 fm(x\u2032) \u2264 \u27e8fm(x), x\u2212 x\u2032\u27e9.\nb.(Local Smoothness of f ) \u2200m \u2208 [M ], fm is \u03b2-smooth: \u2200x, x\u2032 \u2208 X ,\nfm(x) \u2264 fm(x\u2032) + \u27e8fm(x\u2032), x\u2212 x\u2032\u27e9+ \u03b2\n2 \u2225x\u2212 x\u2032\u2225.\nc. (Convexity of \u03c8) \u03c8(x) is convex.\nd.(Local Unbiased Estimate and Bounded Variance) For any client m \u2208 [M ], the local gradient queried by some local random sample \u03bem is unbiased and also bounded in variance, i.e., E\u03be[gm(xm; \u03bem)] = gm(xm) and E\u03be[\u2225gm(xm; \u03bem)\u2212 gm(xm)\u22252\u2217] \u2264 \u03c32.\ne. (Bounded Gradient) \u2200m \u2208 [M ], \u2225gm(xm; \u03bem)\u2225\u2217 \u2264 G.\nFederated dual extrapolation for composite convex optimization is to replace the part of Algorithm 1 highlighted in green with the following updating sequence, where we overuse \u03c2 now as the notation for dual variables in the convex setting as well.\n\u03c2mr,0 = \u03c2r\nfor k = 0, 1, . . . ,K \u2212 1 do\nxmr,k = \u02dcProx hr,k \u03c2\u0304 (\u03c2 m r,k)\nxmr,k+1/2 = \u02dcProx hr,k+1 \u03c2\u0304\u2212\u03c2mr,k (\u03b7cgm(x m r,k; \u03be m r,k)) \u03c2mr,k+1 = \u03c2 m r,k + \u03b7 cgm(x m r,k+1/2; \u03be m r,k+1/2)\nend for For the proximal operator defined by hr,k, reformulating from its Definition 4 to \u2207h\u2217r,k in Definition 10 yields\nxmr,k = argmin x {\u27e8\u03c2mr,k \u2212 \u03c2\u0304 , x\u27e9+ hr,k(x)} = \u2207h\u2217r,k(\u03c2\u0304 \u2212 \u03c2mr,k)\nxmr,k+1/2 = argmin x {\u27e8\u03b7cgm(xmr,k; \u03bemr,k)\u2212 (\u03c2\u0304 \u2212 \u03c2mr,k), x\u27e9+ hr,k+1(x)} = \u2207h\u2217r,k+1((\u03c2\u0304 \u2212 \u03c2mr,k)\u2212 \u03b7cgm(xmr,k; \u03bemr,k))\n\u03c2mr,k+1 = \u03c2 m r,k + \u03b7 cgm(x m r,k+1/2; \u03be m r,k+1/2)\nSimilarly, we define auxiliary dual variable \u00b5mr,k = \u03c2\u0304 \u2212 \u03c2mr,k and \u00b5mr,k+1/2 the dual image of xmr,k+1/2. Then by definition, x m r,k = \u2207h\u2217r,k(\u00b5mr,k) and xmr,k+1/2 = \u2207h \u2217 r,k+1(\u00b5 m r,k+1/2). The updating sequence is equivalent to \u00b5mr,k+1/2 = \u00b5 m r,k \u2212 \u03b7gm(xmr,k; \u03bemr,k) followed by \u00b5mr,k+1 = \u00b5mr,k \u2212 \u03b7gm(x m r,k+1/2; \u03be m r,k+1/2). For the shadow sequence of averaged variables \u00b5r,k = 1 M \u2211M m=1 \u00b5 m r,k and gr,k = 1 M \u2211M m=1 gm(x m r,k; \u03be m r,k),\n\u00b5r,k+1/2 = \u00b5r,k \u2212 \u03b7cgr,k, (10) \u00b5r,k+1 = \u00b5r,k \u2212 \u03b7cgr,k+1/2. (11)\nFinally, the projections of the averaged dual back to the primal space are x\u0302r,k = \u2207h\u2217r,k(\u00b5r,k) and \u0302xr,k+1/2 = \u2207h\u2217r,k+1(\u00b5r,k+1/2) Theorem 2. Under Assumption 5, the ergodic intermediate sequence generated by FeDualEx for composite convex objectives satisfies\nE [ \u03d5( 1\nRK R\u22121\u2211 r=0 K\u22121\u2211 k=0 \u0302xr,k+1/2)\u2212 \u03d5(x) ] \u2264 B \u03b7cRK + 20\u03b22(\u03b7c)3K2G2 + 5\u03c32\u03b7c M + 2\u03b2(\u03b7c)3K2G2.\nChoosing step size\n\u03b7c = min{ 1 5 1 2 \u03b2 ,\nB 1 4\n20 1 4 \u03b2 1 2G 1 2K 3 4R 1 4\n, B\n1 2M 1 2\n5 1 2\u03c3R 1 2K 1 2\n, B\n1 3\n2 1 3 \u03b2 1 3G 2 3KR 1 3\n}\nfurther yields the following convergence rate: E [ \u03d5( 1\nRK R\u22121\u2211 r=0 K\u22121\u2211 k=0 \u0302xr,k+1/2)\u2212 \u03d5(x) ] \u2264 5 1 2 \u03b2B RK + 20 1 4 \u03b2 1 2G 1 2B 3 4 K 1 4R 3 4 + 5 1 2\u03c3B 1 2 M 1 2R 1 2K 1 2 + 2 1 3 \u03b2 1 3G 2 3B 2 3 R 2 3 .\nProof. As the proof for Theorem 1, the proof for this theorem depends on Lemma 15 and Lemma 16, which further yield Lemma 17. These lemmas are presented and proved right after this theorem. Here, we start from Lemma 17. Telescoping over all k \u2208 {0, ...,K \u2212 1} and all r \u2208 {0, ..., R\u2212 1} assuming \u03b7s = 1 yields\n\u03b7cE [R\u22121\u2211 r=0 K\u22121\u2211 k=0 \u03d5( \u0302xr,k+1/2)\u2212RK\u03d5(x) ] \u2264 V\u0303 h0,0\u00b50,0 (x)\u2212 V\u0303 hR,K \u00b5R,K (x) + 5\u03c32(\u03b7c)2KR M\n+ 20\u03b22(\u03b7c)4K3RG2 + 2\u03b2(\u03b7c)3K3RG2.\nBy Assumption 4, V\u0303 h0,0\u00b50,0 (x) = V h x0(x) \u2264 B, where x0 = \u2207h \u2217(\u03c2\u0304). Dividing both sides by \u03b7cKR followed by applying Jensen\u2019s inequality (Lemma 4) completes the proof.\nLemma 15 (Bounding the Regularization Term). \u2200x, \u03b7c [ \u03c8( \u0302xr,k+1/2)\u2212 \u03c8(x) ] = V\u0303 hr,k \u00b5r,k (x)\u2212 V\u0303 hr,k+1\u00b5r,k+1 (x)\u2212 V\u0303 hr,k \u00b5r,k ( \u0302xr,k+1/2)\u2212 V\u0303 hr,k+1 \u00b5r,k+1/2 (x\u0302r,k+1)\n+ \u03b7c\u27e8gr,k+1/2 \u2212 gr,k, \u0302xr,k+1/2 \u2212 x\u0302r,k+1\u27e9+ \u03b7c\u27e8gr,k+1/2, x\u2212 \u0302xr,k+1/2\u27e9\nProof. The proof of this Lemma is almost identical to the proof of Lemma 1 with a mere change of variables and distance-generating function from saddle point setting to convex setting.\nThe following Lemma highlights the primary difference in the analysis of convex optimization and saddle point optimization. The smoothness of fm provides an alternative presentation to gradient Lipschitzness that establishes the connection between \u0302xr,k+1/2, the primal projection of averaged dual on the central server, and xmr,k+1/2 on each client.\nLemma 16 (Bounding the Smooth Term). \u2200x,\nf( \u0302xr,k+1/2)\u2212 f(x) \u2264 \u27e8gr,k+1/2, \u0302xr,k+1/2 \u2212 x\u27e9+ \u27e8 1\nM M\u2211 m=1 gm(x m r,k+1/2)\u2212 gr,k+1/2, \u0302xr,k+1/2 \u2212 x\u27e9\n+ \u03b2\n2M M\u2211 m=1 \u2225 \u0302xr,k+1/2 \u2212 xmr,k+1/2\u2225 2.\nProof. By the smoothness fm in the form of Assumption 5b and then the convexity of fm in the form of Assumption 5a,\nfm( \u0302xr,k+1/2) \u2264 fm(xmr,k+1/2) + \u27e8gm(x m r,k+1/2), \u0302xr,k+1/2 \u2212 x m r,k+1/2\u27e9+\n\u03b2 2 \u2225 \u0302xr,k+1/2 \u2212 xmr,k+1/2\u2225 2\n\u2264 fm(xmr,k+1/2) + \u27e8gm(x m r,k+1/2), \u0302xr,k+1/2 \u2212 x m r,k+1/2\u27e9+\n\u03b2 2 \u2225 \u0302xr,k+1/2 \u2212 xmr,k+1/2\u2225 2\n+ fm(x)\u2212 fm(xmr,k+1/2) + \u27e8gm(x m r,k+1/2), x m r,k+1/2 \u2212 x\u27e9\n\u2264 fm(x) + \u27e8gm(xmr,k+1/2), \u0302xr,k+1/2 \u2212 x\u27e9+ \u03b2\n2 \u2225 \u0302xr,k+1/2 \u2212 xmr,k+1/2\u2225 2\nThen for function f = 1M \u2211M m=1 fm,\nf( \u0302xr,k+1/2)\u2212 f(x) \u2264 1\nM M\u2211 m=1 [ fm( \u0302xr,k+1/2)\u2212 fm(x) ] \u2264 \u27e8 1\nM M\u2211 m=1 gm(x m r,k+1/2), \u0302xr,k+1/2 \u2212 x\u27e9+ 1 M M\u2211 m=1 \u03b2 2 \u2225 \u0302xr,k+1/2 \u2212 xmr,k+1/2\u2225 2\n= \u27e8gr,k+1/2, \u0302xr,k+1/2 \u2212 x\u27e9+ \u27e8 1\nM M\u2211 m=1 gm(x m r,k+1/2)\u2212 gr,k+1/2, \u0302xr,k+1/2 \u2212 x\u27e9\n+ \u03b2\n2M M\u2211 m=1 \u2225 \u0302xr,k+1/2 \u2212 xmr,k+1/2\u2225 2.\nNow we are ready to present the main lemma that combines Lemma 15 and Lemma 16. For the proof, we utilize again Lemma 11, Lemma 12, and Lemma 14, all of which we claim to hold trivially in the composite convex optimization setting.\nLemma 17 (Main Lemma for FeDualEx in Composite Convex Optimization). Under Assumption 5,\n\u03b7cE [ \u03d5( \u0302xr,k+1/2)\u2212 \u03d5(x) ] \u2264 V\u0303 hr,k\u00b5r,k (x)\u2212 V\u0303 hr,k+1 \u00b5r,k+1 (x) + 5\u03c32\u03b7c\nM + 10\u03b22(\u03b7c)3(2k2 + 2k + 1)G2\n+ (\u03b7c)2\u03c32\n2M(1\u2212 \u03b7c) + 2\u03b2(\u03b7c)3(k + 1)2G2.\nProof. Summing the results in Lemma 15 and Lemma 16:\n\u03b7c ( \u03d5( \u0302xr,k+1/2)\u2212 \u03d5(x) ) \u2264 V\u0303 hr,k\u00b5r,k (x)\u2212 V\u0303 hr,k+1 \u00b5r,k+1 (x)\u2212 V\u0303 hr,k\u00b5r,k ( \u0302xr,k+1/2)\u2212 V\u0303 hr,k+1 \u00b5r,k+1/2 (x\u0302r,k+1)\n+ \u03b7c\u27e8gr,k+1/2 \u2212 gr,k, \u0302xr,k+1/2 \u2212 x\u0302r,k+1\u27e9+ \u03b7c\u03b2\n2M M\u2211 m=1 \u2225 \u0302xr,k+1/2 \u2212 xmr,k+1/2\u22252\n+ \u03b7c\u27e8 1 M M\u2211 m=1 gm(x m r,k+1/2)\u2212 gr,k+1/2, \u0302xr,k+1/2 \u2212 x\u27e9.\nFor the latter two generalized Bregman divergence terms \u2212V\u0303 hr,k\u00b5r,k ( \u0302xr,k+1/2)\u2212 V\u0303 hr,k+1 \u00b5r,k+1/2\n(x\u0302r,k+1), we bound them by Lemma 10 and the strong convexity of h in Assumption 3. As a result,\n\u03b7c ( \u03d5( \u0302xr,k+1/2)\u2212 \u03d5(x) ) \u2264 V\u0303 hr,k\u00b5r,k (x)\u2212 V\u0303 hr,k+1 \u00b5r,k+1 (x)\u2212 1 2 \u2225x\u0302r,k \u2212 \u0302xr,k+1/2\u22252\n\u22121 2 \u2225 \u0302xr,k+1/2 \u2212 x\u0302r,k+1\u22252 + \u03b7c\u27e8gr,k+1/2 \u2212 gr,k, \u0302xr,k+1/2 \u2212 x\u0302r,k+1\u27e9\ufe38 \ufe37\ufe37 \ufe38\nA\n+ \u27e8 \u03b7 c\nM M\u2211 m=1 gm(x m r,k+1/2)\u2212 gr,k+1/2, \u0302xr,k+1/2 \u2212 x\u27e9\n+ \u03b7c\u03b2\n2M M\u2211 m=1 \u2225 \u0302xr,k+1/2 \u2212 xmr,k+1/2\u2225 2.\nA can be bounded with Cauchy-Schwarz inequality (Lemma 5) and Young\u2019s inequality (Lemma 6).\nA \u2264 \u22121 2 \u2225 \u0302xr,k+1/2 \u2212 x\u0302r,k+1\u22252 + \u03b7c\u2225gr,k+1/2 \u2212 gr,k\u2225\u2217\u2225 \u0302xr,k+1/2 \u2212 x\u0302r,k+1\u2225\n\u2264 \u22121 2 \u2225 \u0302xr,k+1/2 \u2212 x\u0302r,k+1\u22252 +\n(\u03b7c)2\n2 \u2225gr,k+1/2 \u2212 gr,k\u22252\u2217 +\n1 2 \u2225 \u0302xr,k+1/2 \u2212 x\u0302r,k+1\u22252\n= (\u03b7c)2\n2 \u2225gr,k+1/2 \u2212 gr,k\u22252\u2217.\nTaking expectations on both sides we get \u03b7cE [ \u03d5( \u0302xr,k+1/2)\u2212 \u03d5(x) ] \u2264 V\u0303 hr,k\u00b5r,k (x)\u2212 V\u0303 hr,k+1 \u00b5r,k+1 (x)\n\u22121 2 E [ \u2225x\u0302r,k \u2212 \u0302xr,k+1/2\u22252 ] \ufe38 \ufe37\ufe37 \ufe38\nB1\n+ (\u03b7c)2 2 E [ \u2225gr,k+1/2 \u2212 gr,k\u22252\u2217 ] \ufe38 \ufe37\ufe37 \ufe38\nB2 + E [ \u27e8 \u03b7 c\nM M\u2211 m=1 gm(x m r,k+1/2)\u2212 gr,k+1/2, \u0302xr,k+1/2 \u2212 x\u27e9 ] \ufe38 \ufe37\ufe37 \ufe38\nB3\n+ \u03b7c\u03b2\n2M M\u2211 m=1 E [ \u2225 \u0302xr,k+1/2 \u2212 xmr,k+1/2\u2225 2 ]\n\ufe38 \ufe37\ufe37 \ufe38 B4\n.\nB2 is bounded in Lemma 14. Therefore, for \u03b7c \u2264 1 5 1 2 \u03b2 ,\nB1 +B2 \u2264 5\u03c3 2(\u03b7c)2\nM + 20\u03b22(\u03b7c)4(k + 1)2G2.\nB3 is zero after taking the expectation by Lemma 11. B4 is bounded in Lemma 12. Plugging the bounds for B1 +B2, B3, and B4 back in completes the proof."
        },
        {
            "heading": "G FEDUALEX IN OTHER SETTINGS",
            "text": "In this section, we provide the algorithm along with the convergence rate for sequential versions of FeDualEx. The proofs in this section rely only on the Lipschitzness of the gradient operator. As a result, the analysis applies to both composite saddle point optimization and composite convex optimization."
        },
        {
            "heading": "G.1 STOCHASTIC DUAL EXTRAPOLATION FOR COMPOSITE SADDLE POINT OPTIMIZATION",
            "text": "The sequential version of FeDualEx immediately yields Algorithm 3, stochastic dual extrapolation for Composite SPP. This algorithm generalizes dual extrapolation to both composite and smooth\nAlgorithm 3 STOCHASTIC-DUAL-EXTRAPOLATION for Composite SPP Input: \u03d5(z) = f(x, y) + \u03c81(x) \u2212 \u03c82(y): objective function; \u2113(z): distance-generating function; g(z) = (\u2207xf(x, y),\u2212\u2207yf(x, y)): gradient operator. Hyperparameters: T : number of iterations; \u03b7: step size. Dual Initialization: \u03c20 = 0: initial dual variable, \u03c2\u0304 \u2208 S: fixed point in the dual space. Output: Approximate solution z = (x, y) to minx\u2208X maxy\u2208Y \u03d5(x, y)\nfor t = 0, 1, . . . , T \u2212 1 do zt = \u02dcProx \u2113t \u03c2\u0304 (\u03c2t) \u25b7 Two-step evaluation of the generalized proximal operator\nzt+1/2 = \u02dcProx \u2113t \u03c2\u0304\u2212\u03c2t(\u03b7\ncg(zt; \u03bet)) \u03c2t+1 = \u03c2t + \u03b7\ncg(zt+1/2; \u03bet+1/2) \u25b7 Dual variable update end for Return: 1T \u2211T\u22121 t=0 zt+1/2.\nstochastic saddle point optimization with the latter taking \u03c8(z) = 0. Its convergence rate is analyzed in the following theorem, which to the best of our knowledge, is the first one for stochastic composite saddle point optimization.\nTheorem 3. Under the sequential version of Assumption 1-4, namely with M = 1, \u2200z \u2208 Z , the ergodic intermediate sequence generated by Algorithm 3 satisfies\nE [ Gap( 1\nT T\u22121\u2211 t=0 zt+1/2) ] \u2264 B \u03b7T + 3\u03c32\u03b7.\nChoosing step size\n\u03b7 = min{ 1 3 1 2 \u03b2 ,\nB 1 2\n3 1 2\u03c3T 1 2\n},\nfurther yields the following convergence rate:\nE [ Gap( 1\nT T\u22121\u2211 t=0 zt+1/2) ] \u2264 3 1 2 \u03b2B T + 3 1 2\u03c3B 1 2 T 1 2 .\nProof. By proof similar to Lemma 1, we have \u03b7 [ \u03c8(zt+1/2)\u2212 \u03c8(z) ] = V\u0303 \u2113t\u03c9t (z)\u2212 V\u0303 \u2113t+1 \u03c9t+1 (z)\u2212 V\u0303 \u2113t \u03c9t (zt+1/2)\u2212 V\u0303 \u2113t+1 \u03c9t+1/2 (zt+1)\n+ \u03b7\u27e8gt+1/2 \u2212 gt, zt+1/2 \u2212 zt+1\u27e9+ \u03b7\u27e8gt+1/2, z \u2212 zt+1/2\u27e9 \u2264 V\u0303 \u2113t\u03c9t (z)\u2212 V\u0303 \u2113t+1 \u03c9t+1 (z)\n\u22121 2 \u2225zt \u2212 zt+1/2\u22252 \u2212 1\n2 \u2225zt+1/2 \u2212 zt+1\u22252 + \u03b7\u27e8gt+1/2 \u2212 gt, zt+1/2 \u2212 zt+1\u27e9\ufe38 \ufe37\ufe37 \ufe38\nA\n+ \u03b7\u27e8g(zt+1/2)\u2212 gt+1/2, zt+1/2 \u2212 z\u27e9\ufe38 \ufe37\ufe37 \ufe38 B \u2212\u03b7\u27e8g(zt+1/2), zt+1/2 \u2212 z\u27e9.\nwhere the inequality holds by Lemma 10 and the strong convexity of \u2113 in Remark 4, and then simply expanding the last term to build a connection between the stochastic gradient and true gradient. By\nAlgorithm 4 COMPOSITE-DUAL-EXTRAPOLATION Input: \u03d5(z) = f(x, y) + \u03c81(x) \u2212 \u03c82(y): objective function; \u2113(z): distance-generating function; g(z) = (\u2207xf(x, y),\u2212\u2207yf(x, y)): gradient operator. Hyperparameters: T : number of iterations; \u03b7: step size. Dual Initialization: \u03c20 = 0: initial dual variable, \u03c2\u0304 \u2208 S: fixed point in the dual space. Output: Approximate solution z = (x, y) to minx\u2208X maxy\u2208Y \u03d5(x, y)\nfor t = 0, 1, . . . , T \u2212 1 do zt = \u02dcProx \u2113t \u03c2\u0304 (\u03c2t) \u25b7 Two-step evaluation of the generalized proximal operator\nzt+1/2 = \u02dcProx \u2113t \u03c2\u0304\u2212\u03c2t(\u03b7\ncg(zt)) \u03c2t+1 = \u03c2t + \u03b7\ncg(zt+1/2) \u25b7 Dual variable update end for Return: 1T \u2211T\u22121 t=0 zt+1/2.\nCauchy-Schwarz inequality (Lemma 5), Young\u2019s inequality (Lemma 6), and Lemma 7,\nA \u2264 \u22121 2 \u2225zt \u2212 zt+1/2\u22252 \u2212 1 2 \u2225zt+1/2 \u2212 zt+1\u22252 +\n\u03b72\n2 \u2225gt+1/2 \u2212 gt\u22252\u2217 +\n1 2 \u2225zt+1/2 \u2212 zt+1\u22252\n= \u22121 2 \u2225zt \u2212 zt+1/2\u22252 +\n\u03b72\n2 \u2225[gt+1/2 \u2212 g(zt+1/2)] + [g(zt)\u2212 gt] + [g(zt+1/2)\u2212 g(zt)]\u22252\u2217\n\u2264 \u22121 2 \u2225zt \u2212 zt+1/2\u22252 +\n3\u03b72\n2 \u2225g(zt+1/2)\u2212 g(zt)\u22252\u2217\n+ 3\u03b72\n2 \u2225gt+1/2 \u2212 g(zt+1/2)\u22252\u2217 +\n3\u03b72\n2 \u2225g(zt)\u2212 gt\u22252\u2217\n\u2264 3\u03b7 2\u03b22 \u2212 1 2 \u2225zt \u2212 zt+1/2\u22252 + 3\u03b72 2 \u2225gt+1/2 \u2212 g(zt+1/2)\u22252\u2217 + 3\u03b72 2 \u2225g(zt)\u2212 gt\u22252\u2217,\nwhere the last inequality holds by the \u03b2-Lipschitzness of the gradient operator. After taking expectations, the last two terms are bounded by the variance of the gradient \u03c32, and B becomes zero by proof similar to Lemma 11. Therefore, for \u03b7 \u2264 1\u221a\n3\u03b2 \u03b7E [ \u27e8g(zt+1/2), zt+1/2 \u2212 z\u27e9+ \u03c8(zt+1/2)\u2212 \u03c8(z) ] \u2264 V\u0303 \u2113t\u03c9t (z)\u2212 V\u0303 \u2113t+1 \u03c9t+1 (z) + 3\u03b7 2\u03c32.\nTelescoping over all t \u2208 {0, ..., T \u2212 1} and dividing both sides by \u03b7T completes the proof."
        },
        {
            "heading": "G.2 DETERMINISTIC DUAL EXTRAPOLATION FOR COMPOSITE SADDLE POINT OPTIMIZATION",
            "text": "Further removing the data-dependent noise in the gradient, we present the deterministic sequential version of FeDualEx, which still generalizes Nesterov\u2019s dual extrapolation (Nesterov, 2007) to composite saddle point optimization. As a result, we term this algorithm composite dual extrapolation, as presented in Algorithm 4.\nWe also provide a convergence analysis, which shows that composite dual extrapolation achieves the O( 1T ) convergence rate as its original non-composite smooth version (Nesterov, 2007), as well as composite mirror prox (CoMP) (He et al., 2015). We do so with a very simple proof based on the recently proposed notion of relative Lipschitzness (Cohen et al., 2021). We start by introducing the definition of relative Lipschitzness and a relevant lemma. Definition 11 (Relative Lipschitzness (Definition 1 in Cohen et al. (2021))). For convex distancegenerating function h : Z \u2192 R, we call operator g : Z \u2192 Z\u2217 \u03bb-relatively Lipschitz with respect to h if \u2200z, w, u \u2208 Z ,\n\u27e8g(w)\u2212 g(z), w \u2212 u\u27e9 \u2264 \u03bb(V hz (w) + V hw (u)). Lemma 18 (Lemma 1 in Cohen et al. (2021)). If g is \u03b2-Lipschitz and h is \u03b1-strongly convex, g is \u03b2 \u03b1 -relatively Lipschitz with respect to h. Theorem 4. Under the basic convexity assumption and \u03b2-Lipschitzness of g, \u2200z \u2208 Z and \u03b7 \u2264 1\u03b2 , composite dual extrapolation satisfies Gap( 1T \u2211T\u22121 t=0 zt+1/2) \u2264 \u03b2B T .\nProof. By proof similar to Lemma 1, we have \u03b7 [ \u03c8(zt+1/2)\u2212 \u03c8(z) ] = V\u0303 \u2113t\u03c9t (z)\u2212 V\u0303 \u2113t+1 \u03c9t+1 (z)\u2212 V\u0303 \u2113t \u03c9t (zt+1/2)\u2212 V\u0303 \u2113t+1 \u03c9t+1/2 (zt+1)\n+ \u03b7\u27e8g(zt+1/2)\u2212 g(zt), zt+1/2 \u2212 zt+1\u27e9+ \u03b7\u27e8g(zt+1/2), z \u2212 zt+1/2\u27e9.\nBy Lemma 18, we know that g is \u03b2-relatively Lipschitz with respect to \u2113 under the \u03b2-Lipschitzness assumption of g and 1-strong convexity assumption of \u2113. Then by Definition 11, we have\n\u03b7 [ \u03c8(zt+1/2)\u2212 \u03c8(z) + \u27e8g(zt+1/2), zt+1/2 \u2212 z\u27e9 ] \u2264 V\u0303 \u2113t\u03c9t (z)\u2212 V\u0303 \u2113t+1 \u03c9t+1 (z)\u2212 V\u0303 \u2113t \u03c9t (zt+1/2)\u2212 V\u0303 \u2113t+1 \u03c9t+1/2 (zt+1) + \u03b7 c\u27e8g(zt+1/2)\u2212 g(zt), zt+1/2 \u2212 zt+1\u27e9\n\u2264 V\u0303 \u2113t\u03c9t (z)\u2212 V\u0303 \u2113t+1 \u03c9t+1 (z)\u2212 V\u0303 \u2113t \u03c9t (zt+1/2)\u2212 V\u0303 \u2113t+1 \u03c9t+1/2 (zt+1) + \u03b7 c\u03b2 [ V \u2113zt(zt+1/2) + V \u2113 zt+1/2 (zt+1) ]\n\u2264 V\u0303 \u2113t\u03c9t (z)\u2212 V\u0303 \u2113t+1 \u03c9t+1 (z).\nwhere the last inequality holds for \u03b7 \u2264 1\u03b2 by Lemma 10. Telescoping over all t \u2208 {0, ..., T \u2212 1} and dividing both sides by \u03b7T completes the proof."
        },
        {
            "heading": "H FEDERATED MIRROR PROX",
            "text": "We present Federated Mirror Prox (FedMiP) here in Algorithm 2 as a baseline. The part highlighted in green resembles the mirror prox algorithm introduced in Section C.1.2. We use the composite mirror map representation introduced in Section C.1.1 to avoid confusion, as the composite proximal operator we proposed for FeDualEx is slightly different from that used in composite mirror descent as discussed in Section 4.1.\nAlgorithm 2 FEDERATED-MIRROR-PROX (FedMiP) for Composite SPP Input: \u03d5(z) = f(x, y) + \u03c81(x)\u2212 \u03c82(y) = 1M \u2211M\nm=1 fm(\u00b7) + \u03c81(x)\u2212 \u03c82(y): objective function; \u2113(z): distance-generating function; gm(z) = (\u2207xfm(x, y),\u2212\u2207yfm(x, y)): gradient operator. Hyperparameters: R: number of rounds of communication; K: number of local update iterations; \u03b7s: server step size; \u03b7c: client step size. Primal Initialization: z0: initial primal variable. Output: Approximate solution z = (x, y) to minx\u2208X maxy\u2208Y \u03d5(x, y)\n1: for r = 0, 1, . . . , R\u2212 1 do 2: Sample a subset of clients Cr \u2286 [M ] 3: for m \u2208 Cr in parallel do 4: zmr,0 = zr 5: for k = 0, 1, . . . ,K \u2212 1 do 6: zmr,k+1/2 = \u2207(\u2113+ \u03b7\nc\u03c8)\u2217(\u2207h(zmr,k)\u2212 \u03b7cg(zmr,k; \u03bemr,k)) 7: zmr,k+1 = \u2207(\u2113+ \u03b7c\u03c8)\u2217(\u2207h(zmr,k)\u2212 \u03b7cg(zmr,k+1/2; \u03be m r,k+1/2)) 8: end for 9: end parallel for\n10: \u2206r = 1 |Cr| \u2211 m\u2208Cr (z m r,K \u2212 zmr,0) 11: zr+1 = \u2207(\u2113+ \u03b7s\u03b7cK\u03c8)\u2217(\u2207h(zr) + \u03b7s\u2206r) 12: end for 13: Return: 1RK \u2211R\u22121 r=0 \u2211K\u22121 k=0 zr,k+1/2."
        }
    ],
    "title": "LOCAL COMPOSITE SADDLE POINT OPTIMIZATION",
    "year": 2024
}