{
    "abstractText": "Posterior sampling, i.e., exponential mechanism to sample from the posterior distribution, provides \u03b5-pure differential privacy (DP) guarantees and does not suffer from potentially unbounded privacy breach introduced by (\u03b5, \u03b4)-approximate DP. In practice, however, one needs to apply approximate sampling methods such as Markov chain Monte Carlo (MCMC), thus re-introducing the unappealing \u03b4-approximation error into the privacy guarantees. To bridge this gap, we propose the Approximate SAample Perturbation (abbr. ASAP) algorithm which perturbs an MCMC sample with noise proportional to its Wasserstein-infinity (W\u221e) distance from a reference distribution that satisfies pure DP or pure Gaussian DP (i.e., \u03b4 = 0). We then leverage a Metropolis-Hastings algorithm to generate the sample and prove that the algorithm converges in W\u221e distance. We show that by combining our new techniques with a careful localization step, we obtain the first nearly linear-time algorithm that achieves the optimal rates in the DP-ERM problem with strongly convex and smooth losses.",
    "authors": [],
    "id": "SP:6cfb9426a00e92079c2b9d4b42a68f580020bef0",
    "references": [
        {
            "authors": [
                "Martin Abadi",
                "Andy Chu",
                "Ian Goodfellow",
                "H Brendan McMahan",
                "Ilya Mironov",
                "Kunal Talwar",
                "Li Zhang"
            ],
            "title": "Deep learning with differential privacy",
            "venue": "In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security,",
            "year": 2016
        },
        {
            "authors": [
                "David Applegate",
                "Ravi Kannan"
            ],
            "title": "Sampling and integration of near log-concave functions",
            "venue": "In Proceedings of the twenty-third annual ACM symposium on Theory of computing,",
            "year": 1991
        },
        {
            "authors": [
                "Raef Bassily",
                "Adam Smith",
                "Abhradeep Thakurta"
            ],
            "title": "Private empirical risk minimization: Efficient algorithms and tight error bounds",
            "venue": "In 2014 IEEE 55th Annual Symposium on Foundations of Computer Science,",
            "year": 2014
        },
        {
            "authors": [
                "Zhiqi Bu",
                "Yu-Xiang Wang",
                "Sheng Zha",
                "George Karypis"
            ],
            "title": "Automatic clipping: Differentially private deep learning made easier and stronger",
            "venue": "arXiv preprint arXiv:2206.07136,",
            "year": 2022
        },
        {
            "authors": [
                "George Casella",
                "Christian P Robert",
                "Martin T Wells"
            ],
            "title": "Generalized accept-reject sampling schemes",
            "venue": "Lecture Notes-Monograph Series,",
            "year": 2004
        },
        {
            "authors": [
                "Kamalika Chaudhuri",
                "Claire Monteleoni",
                "Anand D Sarwate"
            ],
            "title": "Differentially private empirical risk minimization",
            "venue": "Journal of Machine Learning Research,",
            "year": 2011
        },
        {
            "authors": [
                "Rishav Chourasia",
                "Jiayuan Ye",
                "Reza Shokri"
            ],
            "title": "Differential privacy dynamics of langevin diffusion and noisy gradient descent",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Etienne De Klerk",
                "Monique Laurent"
            ],
            "title": "Comparison of lasserre\u2019s measure-based bounds for polynomial optimization to bounds obtained by simulated annealing",
            "venue": "Mathematics of Operations Research,",
            "year": 2018
        },
        {
            "authors": [
                "Christos Dimitrakakis",
                "Blaine Nelson",
                "Zuhe Zhang",
                "Aikateirni Mitrokotsa",
                "Benjamin IP Rubinstein"
            ],
            "title": "Differential privacy for bayesian inference through posterior sampling",
            "venue": "Journal of machine learning research,",
            "year": 2017
        },
        {
            "authors": [
                "Jinshuo Dong",
                "David Durfee",
                "Ryan Rogers"
            ],
            "title": "Optimal differential privacy composition for exponential mechanisms",
            "venue": "In International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Jinshuo Dong",
                "Aaron Roth",
                "Weijie J Su"
            ],
            "title": "Gaussian differential privacy",
            "venue": "Journal of the Royal Statistical Society Series B: Statistical Methodology,",
            "year": 2022
        },
        {
            "authors": [
                "Raaz Dwivedi",
                "Yuansi Chen",
                "Martin J Wainwright",
                "Bin Yu"
            ],
            "title": "Log-concave sampling: Metropolis-Hastings algorithms are fast",
            "venue": "Journal of Machine Learning Research,",
            "year": 2019
        },
        {
            "authors": [
                "Cynthia Dwork",
                "Frank McSherry",
                "Kobbi Nissim",
                "Adam Smith"
            ],
            "title": "Calibrating noise to sensitivity in private data analysis",
            "venue": "In Theory of cryptography conference,",
            "year": 2006
        },
        {
            "authors": [
                "Cynthia Dwork",
                "Aaron Roth"
            ],
            "title": "The algorithmic foundations of differential privacy",
            "venue": "Foundations and Trends\u00ae in Theoretical Computer Science,",
            "year": 2014
        },
        {
            "authors": [
                "Vitaly Feldman",
                "Ilya Mironov",
                "Kunal Talwar",
                "Abhradeep Thakurta"
            ],
            "title": "Privacy amplification by iteration",
            "venue": "IEEE 59th Annual Symposium on Foundations of Computer Science (FOCS),",
            "year": 2018
        },
        {
            "authors": [
                "Vitaly Feldman",
                "Tomer Koren",
                "Kunal Talwar"
            ],
            "title": "Private stochastic convex optimization: optimal rates in linear time",
            "venue": "In Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing,",
            "year": 2020
        },
        {
            "authors": [
                "Guillaume Garrigos",
                "Robert M Gower"
            ],
            "title": "Handbook of convergence theorems for (stochastic) gradient methods",
            "venue": "arXiv preprint arXiv:2301.11235,",
            "year": 2023
        },
        {
            "authors": [
                "Joseph Geumlek",
                "Shuang Song",
                "Kamalika Chaudhuri"
            ],
            "title": "Renyi differential privacy mechanisms for posterior sampling",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2017
        },
        {
            "authors": [
                "Sivakanth Gopi",
                "Yin Tat Lee",
                "Daogao Liu"
            ],
            "title": "Private convex optimization via exponential mechanism",
            "venue": "In Conference on Learning Theory,",
            "year": 2022
        },
        {
            "authors": [
                "Roger Iyengar",
                "Joseph P Near",
                "Dawn Song",
                "Om Thakkar",
                "Abhradeep Thakurta",
                "Lun Wang"
            ],
            "title": "Towards practical differentially private convex optimization",
            "venue": "IEEE Symposium on Security and Privacy (SP),",
            "year": 2019
        },
        {
            "authors": [
                "Sai Praneeth Karimireddy",
                "Sebastian U Stich",
                "Martin Jaggi"
            ],
            "title": "Global linear convergence of newton\u2019s method without strong-convexity or lipschitz gradients",
            "venue": "arXiv preprint arXiv:1806.00413,",
            "year": 2018
        },
        {
            "authors": [
                "Daniel Kifer",
                "Adam Smith",
                "Abhradeep Thakurta"
            ],
            "title": "Private convex empirical risk minimization and highdimensional regression",
            "venue": "In Conference on Learning Theory,",
            "year": 2012
        },
        {
            "authors": [
                "Simon Lacoste-Julien",
                "Mark Schmidt",
                "Francis Bach"
            ],
            "title": "A simpler approach to obtaining an o (1/t) convergence rate for the projected stochastic subgradient method",
            "venue": "arXiv preprint arXiv:1212.2002,",
            "year": 2012
        },
        {
            "authors": [
                "Beatrice Laurent",
                "Pascal Massart"
            ],
            "title": "Adaptive estimation of a quadratic functional by model selection",
            "venue": "Annals of Statistics,",
            "year": 2000
        },
        {
            "authors": [
                "Yi-An Ma",
                "Yuansi Chen",
                "Chi Jin",
                "Nicolas Flammarion",
                "Michael I. Jordan"
            ],
            "title": "Sampling can be faster than optimization",
            "venue": "Proceedings of the National Academy of Sciences,",
            "year": 2019
        },
        {
            "authors": [
                "Eric Mazumdar",
                "Aldo Pacchiano",
                "Yi-An Ma",
                "Michael Jordan",
                "Peter Bartlett"
            ],
            "title": "On approximate Thompson sampling with Langevin algorithms",
            "venue": "International Conference on Machine Learning,",
            "year": 2020
        },
        {
            "authors": [
                "Frank McSherry",
                "Kunal Talwar"
            ],
            "title": "Mechanism design via differential privacy",
            "venue": "In Symposium on Foundations of Computer Science",
            "year": 2007
        },
        {
            "authors": [
                "Kentaro Minami",
                "HItomi Arai",
                "Issei Sato",
                "Hiroshi Nakagawa"
            ],
            "title": "Differential privacy without sensitivity",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2016
        },
        {
            "authors": [
                "Darakhshan J Mir"
            ],
            "title": "Information-theoretic foundations of differential privacy",
            "venue": "In Foundations and Practice of Security: 5th International Symposium,",
            "year": 2012
        },
        {
            "authors": [
                "Rachel Redberg",
                "Antti Koskela",
                "Yu-Xiang Wang"
            ],
            "title": "Improving the privacy and practicality of objective perturbation for differentially private linear learners",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2023
        },
        {
            "authors": [
                "Th\u00e9o Ryffel",
                "Francis Bach",
                "David Pointcheval"
            ],
            "title": "Differential privacy guarantees for stochastic gradient langevin dynamics",
            "venue": "arXiv preprint arXiv:2201.11980,",
            "year": 2022
        },
        {
            "authors": [
                "Jeremy Seeman",
                "Matthew Reimherr",
                "Aleksandra Slavkovi\u0107"
            ],
            "title": "Exact privacy guarantees for markov chain implementations of the exponential mechanism with artificial atoms",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Volker Strassen"
            ],
            "title": "The existence of probability measures with given marginals",
            "venue": "The Annals of Mathematical Statistics,",
            "year": 1965
        },
        {
            "authors": [
                "2024 Notably",
                "Feldman"
            ],
            "title": "norm-aware\u201d statistical distance and establish the shift reduction lemma. However, the primary focus of Feldman et al. (2018) is on Renyi Differential Privacy, and the proof techniques employed differ. To prove Theorem 2, we leveraged Lemma 14, a measure-theoretic adaptive composition theorem of privacy profiles",
            "year": 2018
        },
        {
            "authors": [
                "Dwivedi"
            ],
            "title": "2019), we know that the MALA algorithm with the number of iterations",
            "year": 2019
        },
        {
            "authors": [
                "Dong"
            ],
            "title": "2022), it suffices to show that f\u03b5,0(x) \u2265 G\u03bc(x), for all 0 \u2264 x \u2264 1. By the concavity of G\u03bc and the piece-wise linearity of f\u03b5,0, it suffices to show that G\u03bc(x0) \u2264 f\u03b5,0(x0)",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "The strongest form of differential privacy (DP) is \u03b5-pure DP, which provides an inviolable bound of \u03b5 \u2265 0 on an algorithm\u2019s privacy loss. The posterior sampling mechanism associated with the loss functions (Wang et al., 2015; Dimitrakakis et al., 2017; Gopi et al., 2022) is known to achieve near-optimal privacy-utility tradeoff for learning under pure DP \u2014 in theory. In practice, sampling from a general posterior distribution is typically either intractable or inefficient. Both issues can be solved by approximating the posterior, e.g. via MCMC sampling. But of course there is no free lunch: the approximation error introduced by this approach now degrades the privacy guarantee to the weaker notion of (\u03b5, \u03b4)-approximate DP, under which we risk a catastrophic privacy breach with some small probability \u03b4. Our paper bridges the gap between theory and practice \u2014 thus alleviating a common growing pain of DP research \u2014 by proposing an efficient MCMC-based algorithm that samples from an approximate posterior while satisfying pure DP.\nRecent strides in research have explored diverse implementations of posterior sampling mechanisms, but a recurring challenge remains \u2014 each approach grapples with either a compromise on the DP guarantee or extended computational runtimes. As demonstrated by Wang et al. (2015); Gopi et al. (2022), applying approximate posterior sampling and directly analyzing the sampling error in terms of the total variation (TV) distance leads back to an irremovable failure probability, ultimately reducing the privacy guarantee to approximate DP. In contrast, Seeman et al. (2021) show that it is possible to sample from the exact posterior with pure DP. But the runtime of their sampler (while finite) may be exponentially large since they use a rejection sampling scheme where the probability of an accepted sample is, in the worst case, exponentially small.\nThis motivates the following question:\nCan we obtain pure DP guarantees with an efficient MCMC algorithm?\nIn this paper, we answer the question in the affirmative by developing the Approximate Sample Perturbation (ASAP) algorithm."
        },
        {
            "heading": "1.1 OUR CONTRIBUTIONS",
            "text": "The main results of our paper are threefold.\n1. We propose Approximate Sample Perturbation (Algorithm 2), a novel MCMC-type method designed to maintain pure DP and pure Gaussian DP by perturbing an MCMC sample. We substantiate, through Theorem 2, that the pure DP and Gaussian DP guarantees are maintained when the distribution of the MCMC sample closely approximates the exact posterior, quantified in terms of the Wasserstein-infinity (W\u221e) distance.\n2. We establish a novel generic lemma, Lemma 8, which provides a systematic method for converting Total Variation (TV) distance into Wasserstein-infinity distance. This transformation enables us to uphold pure DP guarantees, even when utilizing MCMC samplers with convergence measured in TV distance. Notably, this lemma holds its own significance and is of independent interest.\n3. We introduce the Metropolis adjusted Langevin algorithm (MALA) with constraint (Algorithm 1) that converges in terms of W\u221e distance. When employed in conjunction with a preceding localization step, detailed in Algorithm 3, it empowers our ASAP framework to achieve optimal rates in nearly linear time while ensuring pure DP and pure Gaussian DP within the Differential Privacy - Empirical Risk Minimization (DP-ERM) setting, for strongly convex and smooth losses."
        },
        {
            "heading": "1.2 RELATED WORK",
            "text": "Posterior sampling mechanism, i.e., outputting a sample \u03b8\u0302 \u223c p(\u03b8) \u221d exp(\u2212\u03b3(F (\u03b8) + 12\u03bb||\u03b8|| 2 2)) is a popular method for DP-ERM and private Bayesian learning. It was initially analyzed under pure DP (Mir, 2013; Dimitrakakis et al., 2017; Wang et al., 2015), then later under approximate DP (Minami et al., 2016), Renyi DP(Geumlek et al., 2017) and Gaussian DP (Gopi et al., 2022). In each case, it is known that with appropriate choices of \u03b3, \u03bb parameters, it achieves the optimal rate (Bassily et al., 2014) under each privacy definition. However, the computational complexity of the MCMC methods has been a major challenge for this problem. To the best of our knowledge, Bassily et al. (2014); Chourasia et al. (2021); Ryffel et al. (2022) are the only known results that obtain DP guarantees using MCMC methods without having \u03b4 > 0. Bassily et al. (2014)\u2019s sampler (a variant of Applegate & Kannan (1991)) runs in O(n4) and requires explicit discretization. Chourasia et al. (2021); Ryffel et al. (2022)\u2019s algorithms run in nearly linear time (for strongly convex DP-ERM) and enjoy pure Renyi DP, but their utility bound is a factor of condition number \u03ba worse than the statistical limit. Our work is the first that archives the optimal rate for Strongly-Convex DP-ERM under pure-DP and pure-Gaussian DP with a nearly linear time algorithm (for \u03ba = polylog(n)).\nDP-ERM can also be solved using other methods that do not require MCMC sampling. However, these methods either do not achieve optimal rates (output perturbation (Chaudhuri et al., 2011)) or are computationally less efficient (Noisy SGD (Bassily et al., 2014; Abadi et al., 2016)) or require the model to be (generalized) linear (e.g., objective perturbation (Chaudhuri et al., 2011; Kifer et al., 2012; Redberg et al., 2023))."
        },
        {
            "heading": "2 PROBLEM SETUP AND PRELIMINARIES",
            "text": "Symbols and notations. Let X be the space of data points, X \u2217 := \u222a\u221en=0Xn be the data space, and D \u2208 X \u2217 be a dataset with an unspecified number of data points. Let the parameter space U \u2286 Rd and for each x \u2208 X and \u03b8 \u2208 U , \u2113x(\u03b8) denotes the loss function (or negative log-likelihood function). When D = {x1, ..., xn}, we denote \u2113xi(\u03b8) by \u2113i(\u03b8) as a short hand. Denote the total loss L = \u2211n i=1 \u2113i. For any set S, we denote the set of all probability distributions as \u2206S or PS , so that a mechanismM : X \u2217 \u2192 \u2206U is a randomized algorithm. We useM(D) to denote the probability distribution as well as the corresponding random variable returned by the mechanism. For a set S, we denote Diam(S) := supx,y\u2208S \u2225x\u2212 y\u22252, and \u2225S\u2225 := supx\u2208S \u2225x\u22252."
        },
        {
            "heading": "2.1 DIFFERENTIAL PRIVACY EMPIRICAL RISK MINIMIZATION (DP-ERM)",
            "text": "Empirical risk minimization (ERM) is a classic learning framework which casts the problem of finding a \u201cgood\u201d model into an optimization task. Our goal is to find the parameter \u03b8\u2217 in the parameter space U \u2286 Rd which minimizes the empirical risk:\n\u03b8\u2217 = argmin \u03b8\u2208U (\u2211n i=1 \u2113i(\u03b8) ) .\nThe problem setting of our paper is differentially private empirical risk minimization (DP-ERM): empirical risk minimization under a privacy constraint."
        },
        {
            "heading": "2.2 DIFFERENTIAL PRIVACY DEFINITIONS",
            "text": "Definition 1 (Differential privacy (Dwork et al., 2006; 2014)). MechanismM satisfies (\u03b5, \u03b4)-DP if for all neighboring datasets D \u2243 D\u2032 and for any measurable set S \u2286 Range(M),\nP[M(D) \u2208 S] \u2264 e\u03b5P[M(D\u2032) \u2208 S] + \u03b4.\nWhen \u03b4 = 0,M satisfies \u03b5-(pure) DP. Differential privacy (DP) provably bounds the privacy loss of an algorithm. Approximate DP (\u03b4 > 0) is a practical and popular DP variant which allows a \u201cfailure\u201d event \u2014 where the privacy loss exceeds the bound \u2014 to occur with some probability. Beware: approximate DP does not bound the severity of a privacy breach. The privacy loss under a failure event could be arbitrarily large. Avoiding this risk requires pure DP (\u03b4 = 0), which provides a deterministic bound on the privacy loss.\nIn comparison to approximate DP, Gaussian DP is a more \u201ccontrolled\u201d relaxation of pure DP which does not have an unbounded failure mode. We can define Gaussian DP via the hockey-stick divergence.\nDefinition 2 (Hockey-Stick Divergence). The Hockey Stick-Divergence of distributions P,Q H\u03b1(P\u2225Q) := Eo\u223cQ [( dP dQ (o)\u2212 \u03b1 ) + ] where (\u00b7)+ := max{0, \u00b7} and dPdQ denotes the Radon-Nikodym derivative.\nDefinition 3 (Gaussian Differential Privacy (Dong et al., 2022)). We say that a mechanism M satisfies \u00b5-Gaussian differential privacy if for any neighboring dataset D,D\u2032\nHe\u03b5(M(D)\u2225M(D\u2032)) \u2264 He\u03b5(N (0, 1)\u2225N (\u00b5, 1)) \u2200\u03b5 \u2208 R.\nNotice that this is an equivalent definition to the dual definition from the hypothesis testing point of view from (Dong et al., 2022, Definition 2.6). The statement naturally provides a \u201cdominating pair\u201d of distributions that are convenient for adaptive composition, amplification by sampling and efficient numerical computation (Zhu et al., 2022)."
        },
        {
            "heading": "2.3 EXACT POSTERIOR SAMPLING: DP AND UTILITY GUARANTEES",
            "text": "The primary algorithm we consider is a variant of the classical exponential mechanism (EM) known as posterior sampling. The posterior sampling algorithm instantiates the exponential mechanism by taking the quality score to be a scaled and regularized log-likelihood function with parameter \u03b3, \u03bb, i.e.,\n\u03b8\u0302 \u223c p(\u03b8) \u221d exp ( \u2212\u03b3 (\u2211n\ni=1 \u2113i(\u03b8) + \u03bb\u2225\u03b8\u22252\n)) 1(\u03b8 \u2208 \u0398). (1)\nFor an appropriate choice of \u03b3, \u03bb parameters and domain \u0398, this mechanism enjoys both pure-DP and Gaussian DP.\nLemma 4 (GDP of posterior sampling (Gopi et al., 2022, Theorem 4)). Assume the loss function is GLipschitz, posterior sampling mechanism with parameter \u03b3, \u03bb > 0 satisfying \u03b3 \u2264 \u00b52\u03bb/G2 satisfies \u00b5-GDP. Lemma 5 (Pure DP of posterior sampling). Assume the loss function is G-Lipschitz, posterior sampling mechanism with parameter \u03b3 > 0 (any of \u03bb) in a domain \u0398 satisfies \u03b5-pure DP if \u03b3 \u2264 \u03b5G\u00b7Diam(\u0398) .\nThe above lemma slightly improves existing analysis (Wang et al., 2015; Dimitrakakis et al., 2017) using the bounded range analysis from Dong et al. (2020), hence avoids assuming a potentially large bound on the loss in the privacy calculations.\nRegarding utility, Gopi et al. (2022) showed that the posterior sampling mechanism achieves a minimax optimal rate for DP-ERM for Lipschitz convex losses. We will discuss these results in the appendix in more detail, but focus on a narrower setting with strongly convex losses in which the rate is faster. We have the following lemma for the utility of posterior sampling.\nLemma 6 (De Klerk & Laurent (2018, Corollary 1)). For a convex function F (\u03b8), and a convex set \u0398 \u2282 Rd, \u03b8\u0302 \u223c p(\u03b8) \u221d exp(\u2212\u03b3F (\u03b8)) satisfies that\nE[F (\u03b8\u0302)] \u2264 min \u03b8\u2208\u0398\nF (\u03b8) + d\n\u03b3 ."
        },
        {
            "heading": "3 TECHNICAL TOOLS",
            "text": "In this section, we introduce tools that make MCMC sampling for pure DP possible. These tools are novel and of independent interest as well. Our contributions consist of an innovative conversion lemma, transitioning from Total Variation (TV) distance to Wasserstein-Infinity (W\u221e) distance (Lemma 8), and the introduction of the Metropolis-adjusted Langevin algorithm (MALA) with constraint (Algorithm 1), specifically designed to guarantee W\u221e distance."
        },
        {
            "heading": "3.1 OVERVIEW: WHY DO WE USE W\u221e DISTANCE?",
            "text": "Suppose p\u2217 is a Gibbs posterior that satisfies pure DP. When MCMC samplers are applied, they generate an approximate sample \u03b8\u0303 from an approximate distribution p\u0303 with dTV (p\u0303, p\u2217) < \u03be, where dTV represents the TV-distance. Notice that this TV-distance guarantee does not grant pure DP for sampling from p\u0303. Instead, it provides only (\u03b5, \u03b4)-DP with \u03b4 = (1 + e\u03b5)\u03be > 0, as elucidated in Proposition 3 of Wang et al. (2015).\nTo circumvent this challenge, ASAP (Algorithm 2) adopts a two-part approach to address the privacy of \u03b8\u0303. First, we decompose \u03b8\u0303 into two components:\n\u03b8\u0303 = \u03b8\u2217 + (\u03b8\u0303 \u2212 \u03b8\u2217), where \u03b8\u2217 \u223c p\u2217. Note that \u03b8\u2217 \u223c p\u2217 satisfies pure DP by existing works Wang et al. (2015). Now, our goal is to ensure that the perturbed difference (\u03b8\u0303 \u2212 \u03b8\u2217) + noise exhibits pure DP. This enables us to leverage the composition lemma (Lemma 14) and establish an MCMC sampling methodology that guarantees pure DP.\nHowever, to release (\u03b8\u0303\u2212\u03b8\u2217) with pure DP by adding noise, it becomes paramount to establish an upper bound on the sensitivity of this quantity with a certainty of 1. This necessitates bounding \u2225\u03b8\u0303\u2212 \u03b8\u2217\u22251 (or \u2225\u03b8\u0303\u2212 \u03b8\u2217\u22252 in the context of Gaussian DP) with a probability of 1. Achieving this stronger notion of privacy hinges on the Wasserstein-Infinity distance. Refer to Appendix E for a visualization illustrating the W\u221e distance.\nHence, an MCMC sampling approach that guarantees an error bound in Wasserstein-Infinity distance is indispensable. Our work addresses this need through the instantiation of MALA with constraint, a method meticulously tailored to ensure strong Wasserstein-Infinity distance guarantees.\nIn the following sections, we delve into the details of our conversion lemma and present the MALA algorithm with constraints, demonstrating their efficacy in achieving pure DP through MCMC sampling."
        },
        {
            "heading": "3.2 TV DISTANCE TO W\u221e DISTANCE",
            "text": "Consider two distributions P and Q on the same metric space (\u0398,dist). We sample x \u223c P and y \u223c Q. When P and Q are relatively \u201cclose\u201d to each other, dist(x, y) is expected to be small. Motivated by our preceding discussion of MCMC for pure DP, a natural question arises: Is there a way to define a distance for distributions P and Q, such that it provides an upper bound for dist(x, y) with probability 1? Wasserstein-infinity distance provides an affirmative response to this question by constructing an appropriate coupling \u03b6 between P and Q, which is defined as follows.\nDefinition 7. Let \u0398 \u2286 Rd be a domain equipped with a metric dist. Consider two probability measures, P and Q, defined on \u0398. The Wasserstein-infinity distance between P and Q with respect to dist, denoted as W\u221e(P,Q), is defined as\nW\u221e(P,Q) := inf \u03b6\u2208\u0393(P,Q) ess sup (x,y)\u2208(\u0398\u00d7\u0398,\u03b6) dist(x, y) = inf \u03b6\u2208\u0393(P,Q)\n{c \u2265 0|\u03b6({(x, y) \u2208 \u03982|dist(x, y) \u2264 c}) = 1},\nwhere \u0393(P,Q) is the set of all couplings of P and Q, i.e., the set of all joint probability distributions \u03b6 with marginals P and Q respectively.\nOur pursuit for strong privacy guarantees hinges on the W\u221e distance to achieve pure Differential Privacy (DP). However, practical MCMC samplers primarily provide guarantees based on the convergence of Total Variation (TV) distance. Regrettably, relying solely on TV distance would result in a weaker privacy guarantee, approximate (\u03b5, \u03b4)-Differential Privacy with a \u03b4 > 0.\nTo reconcile this discrepancy, we present a versatile lemma that enables the conversion from TV distance to the W\u221e distance.\nLemma 8 (Converting TV distance to W\u221e distance). Consider two probability measures, P and Q, both supported on a bounded closed 2-norm-ball \u0398 \u2286 Rd. On this domain \u0398, suppose that the density of Q is lower-bounded by a constant pmin. We establish the following results based on the choice of metric for W\u221e:\n1. Suppose W\u221e is metric with the 1-norm, i.e., dist(x, y) = \u2225x\u2212 y\u22251.\nIf dTV (P,Q) < pmin \u00b7 \u03c0d/2\n2d+1 \u00b7 \u0393(d2 + 1) \u00b7 dd/2 \u2206d, then W\u221e(P,Q) \u2264 \u2206.\n2. Suppose W\u221e is metric with the 2-norm, i.e., dist(x, y) = \u2225x\u2212 y\u22252.\nIf dTV (P,Q) < pmin \u00b7 \u03c0d/2\n2d+1 \u00b7 \u0393(d2 + 1) \u2206d, then W\u221e(P,Q) \u2264 \u2206.\nIn both cases, \u0393 represents the gamma function.\nThe results naturally extend to the case where \u0398 is a bounded open 2-norm ball.\nThis lemma provides a powerful tool to bridge the gap between TV distance and W\u221e distance, ensuring that we can maintain pure DP guarantees even when dealing with TV distance-based MCMC samplers.\nNote that to convert from TV distance to W\u221e distance, additional assumptions about the probability measures are required. We introduce a supporting lemma to ensure the conditions for the conversion procedure are met. This lemma establishes a lower bound on the density of distributions that are log-concave and log-Lipschitz continuous or smooth.\nLemma 9. Consider a distribution with density p(\u03b8) = 1Z e \u2212\u03b3J(\u03b8) supported on a bounded convex domain \u0398 with 2-norm diameter R, where Z = \u222b \u0398 e\u2212\u03b3J(\u03b8)d\u03b8 is the normalization constant.\nAssuming that J is convex and G\u0303-Lipschitz continuous, we establish the following bound on the density:\ninf \u03b8\u2208\u0398\np(\u03b8) \u2265 e\u2212\u03b3G\u0303R \u00b7 \u0393(d2 + 1)\n\u03c0d/2(R/2)d .\nAlternatively, if J is convex and \u03b2-Lipschitz smooth, the density bound holds for any \u03b8\u0303 \u2208 \u0398:\ninf \u03b8\u2208\u0398\np(\u03b8) \u2265 e\u2212\u03b3(R\u2225\u2207J(\u03b8\u0303)\u2225+\u03b2R 2/2) \u00b7\n\u0393(d2 + 1)\n\u03c0d/2(R/2)d .\nThese lemmas together provide a comprehensive framework for translating TV distance to W\u221e distance while maintaining crucial assumptions about the underlying probability measures.\nBy incorporating these results into our privacy framework, we can navigate the challenges of MCMC samplers, ensuring pure differential privacy guarantees even when operating in a TV distance-based setting."
        },
        {
            "heading": "3.3 MALA WITH CONSTRAINT",
            "text": "From our previous discussion, we know that to maintain the pure and Gaussian-DP guarantee, the distance between the distribution of the approximate sample and the target one needs to be small in the Wasserstein-\u221e distance. From Lemma 8, that translates into an exponentially small error in terms of the total variation distance. Hence we apply MALA, an asymptotically unbiased sampler that converges exponentially fast in terms of the accuracy requirements in TV distance. Furthermore, Lemma 8 underscores the necessity of drawing samples from a bounded set. Consequently, we reject the samples outside of the prescribed domain, as outlined in Algorithm 1. We prove in Theorem 1 that with 1 \u2212 q probability, the samples are accepted within ln(1/q) trials.\nNotations. Let J(\u03b8) = \u2211n\ni=1 \u2113i(\u03b8) be the objective function, where \u2113i\u2019s satisfy G-Lipschitz continuity. Let \u03c0 and p\u2217 be the unconstrained and constrained Gibbs distribution respectively with density \u03c0(\u03b8) \u221d e\u2212\u03b3J(\u03b8), and p\u2217(\u03b8) \u221d e\u2212\u03b3J(\u03b8)1(\u03b8 \u2208 \u0398). Let \u03ba = \u03b2/\u03b1 be the condition number, where \u03b2 and \u03b1 are defined in Assumption 1 and 2 respectively.\nAssumption 1 (Smoothness). Function J is n\u03b2-Lipschitz smooth.\nAssumption 2 (Strong-Convexity). Function J is n\u03b1-strongly convex. Assumption 3 (Domain bound). The domain \u0398 is a convex set such that B(\u03b8\u2217, R1) \u2282 \u0398, for R1 \u2265 8 \u221a d \u03b3n\u03b1 , where \u03b8\u2217 = argmin\u03b8\u2208Rd J(\u03b8).\nTheorem 1 (Mixing time in TV-distance). Under Assumptions 1, 2, and 3, Algorithm 1 with initial distribution p0 \u223c N (0, 1\u03b3n\u03b2 I) and step size h k = \u0398 ( min { \u03ba\u22121/2(\u03b3n\u03b2)\u22121(d ln\u03ba+ ln 1/\u03be)\u22121/2, 1\u03b3n\u03b2d }) converges to \u03be-accuracy in dTV (pK , p\u2217) with\n\u03c4 ( \u03be, p0, p\u2217 ) \u223c \u2126 ( (d ln\u03ba+ ln 1/\u03be)max { \u03ba3/2 \u221a d ln\u03ba+ ln 1/\u03be, d\u03ba } ln 1\nq ) number of gradient queries to J , with probability 1\u2212 q. Corollary 10 (Mixing time in W\u221e distance). Consider the W\u221e distance with respect to the 1-norm. Define \u03b80, B, \u03b3, \u03bb,\u2206 as Table 2. Let \u0398 = B(\u03b80, B). Under the same assumptions, initial distribution, and step size as Theorem 1, Algorithm 1 achieves convergence with the following number of gradient queries to J to reach an accuracy of \u2206 in W\u221e(pK , p\u2217), with probability 1\u2212 q:\n\u2126 ( d (ln\u03ba+ \u03ba ln(d/\u03c1) + lnn)max { \u03ba3/2 \u221a d (\u03ba ln(d/\u03c1) + lnn), d\u03ba } ln 1\nq\n) .\nEach gradient query to the empirical risk J translates to n queries to the individual losses \u2113i\u2019s.\nRemark 11. We note that the dependence on d is \u2126\u0303(d2), and the number of queries to the individual losses \u2113i\u2019s is \u2126\u0303(n).\nIn comparison, if we employ vanilla rejection sampling (Casella et al., 2004) with a proposal distribution of N (0, 1\u03b3n\u03b2 I), then the convergence time scales as e\n\u03b3n(\u03b2\u2212\u03b1)R21 \u2265 e64(\u03ba\u22121)d, where R1 is defined according to Assumption 3. This factor scales exponentially with the condition number \u03ba and the dimension d.\nAlgorithm 1 Metropolis-adjusted Langevin algorithm (MALA) with constraint\n1: Input: Stepsizes {hk}, number of iterations K, objective function J , domain \u0398, parameter \u03b3. 2: Sample \u03b80 according to distribution p0 3: for k = 0, 1, 2, . . . ,K \u2212 1 do 4: Sample \u03b8k+1 \u223c N ( \u03b8k \u2212 hk\u03b3\u2207J(\u03b8k), 2hkI\n) 5: Sample uk+1 \u223c U [0, 1], denote p(\u00b7|\u03b8) as the density of N ( \u03b8 \u2212 hk\u03b3\u2207J(\u03b8), 2hkI\n) 6: if p ( \u03b8k|\u03b8k+1 ) \u03c0(\u03b8k)\np (\u03b8k+1|\u03b8k)\u03c0 (\u03b8k+1) < uk+1 then\n7: \u03b8k+1 \u2190 \u03b8k 8: end if 9: end for\n10: if \u03b8K /\u2208 \u0398 then \u25b7 Reject the sample 11: Jump to Line 2 12: end if 13: Return \u03b8K"
        },
        {
            "heading": "4 MAIN RESULTS: APPROXIMATE SAMPLE PERTURBATION (ASAP)",
            "text": "This section introduces our main result, Approximate Sample Perturbation (ASAP), along with the end-to-end localized ASAP."
        },
        {
            "heading": "4.1 APPROXIMATE SAMPLE PERTURBATION (ASAP)",
            "text": "ASAP (Algorithm 2) is designed to maintain pure DP and pure Gaussian DP by smoothing out an MCMC sample. Theorem 2 establishes the pure DP and pure GDP guarantee for the ASAP algorithm.\nTo clarify, suppose that we have a reference randomized mechanismM and another randomized mechanism M\u0303. We have a pure DP (or pure GDP) guarantee forM and no privacy guarantee for M\u0303. Theorem 2 tells us that if the distance of the output distributions of these two mechanisms is bounded in W\u221e-distance, then we can satisfy pure GDP (or pure DP) by sampling from M\u0303 and subsequently adding noise whose scale is proportional to the bound on the W\u221e-distance.\nAlgorithm 2 Approximate SAmple Perturbation (ASAP) 1: Input: Dataset D, reference randomized mechanism M : X \u2217 \u2192 PU . Wasserstein-infinity error \u2206,\na black box sampler M\u0303 such that W\u221e(M\u0303(D),M(D)) \u2264 \u2206. Privacy parameter \u03b5\u2032 if pure DP (\u00b5\u2032 if Gaussian DP).\n2: Run the MCMC sampler: \u03b8\u0303 \u223c M\u0303(D). 3: Return \u03b8\u0302 = \u03b8\u0303 +N (0, 4\u2206 2\n\u00b5\u20322 Id) if GDP (or \u03b8\u0302 = \u03b8\u0303 + Z with Zi i.i.d.\u223c Lap( 2\u2206\u03b5\u2032 ), i = 1, ..., d if pure DP.)\nTheorem 2 (DP Guarantees for Approximate SAmple Perturbation). LetM,M\u0303 be randomized algorithms with output space \u0398 \u2282 Rd that satisfy the following for any input dataset D:\nW\u221e(M(D),M\u0303(D)) \u2264 \u2206. 1. Suppose we define W\u221e with the 2-norm. If M satisfies \u00b5-GDP, then the procedure M\u0303(D) + N (0, 4\u2206 2 (\u00b5\u2032)2 Id) satisfies \u221a \u00b52 + \u00b5\u20322-GDP.\n2. Suppose we define W\u221e with the 1-norm. IfM satisfies \u03b5-DP, then the procedure M\u0303(D) + Z with Zi \u223c Lap( 2\u2206\u03b5\u2032 ) i.i.d. for i = 1, ..., d, satisfies (\u03b5+ \u03b5 \u2032)-DP.\nAs it is made clear in the proof and in Section 3.1, a W\u221e distance guarantee is essential for us to obtain pure-DP and pure-GDP with ASAP. Other weaker distance metrics such as TV-distance and W2-distance are not useful for this purpose in general. Interestingly, as we establish in Lemma 8, when the domain is a bounded ball and the density is bounded away from zero, we can convert a weak TV-distance bound into a strong W\u221e distance bound, which allows us to apply Algorithm 2 in a wide range of applications."
        },
        {
            "heading": "4.2 LOCALIZED ASAP AND THE END-TO-END GUARANTEES",
            "text": "Lemma 8 implies that we should sample from a bounded 2-norm ball. So before sampling, we should first localize to a bounded ball centered at the initial point \u03b80, i.e., \u0398 = B(\u03b80, B) = {\u03b8 | \u2225\u03b8 \u2212 \u03b80\u22252 \u2264 B}. We then run ASAP on this bounded ball; we call this \u201cLocalized-ASAP\u201d.\nAlgorithm 3 End-to-End Localized ASAP 1: Input: Parameters \u03b3, \u03bb = 0, B as given in Table 2. Wasserstein-infinity error \u2206. Dataset D, individual\nloss \u2113i\u2019s satisfying G Lipschitz continuity, \u03b2-smoothness, and \u03b1-strong convexity. Privacy parameter \u00b5\u2032 for GDP (or \u03b5\u2032 for pure DP) for ASAP. Denote J(\u03b8) = \u2211n i=1 \u2113i(\u03b8) + \u03bb 2 \u2225\u03b8 \u2212 \u03b80\u2225\n2. 2: Run the localization Algorithm 4, and assign its output to \u03b80. 3: Call ASAP (Algorithm 2) with inputs \u2206, D, \u03b3, privacy parameter \u03b5\u2032 if pure DP (\u00b5\u2032 if Gaussian DP)\nM\u0303 \u2190 Algorithm 1 on the domain \u0398 = {\u03b8|\u2225\u03b8 \u2212 \u03b80\u22252 \u2264 B}, M\u2190 Reference distribution with density pM(D)(\u03b8) \u221d e\u2212\u03b3J(\u03b8)1{\u2225\u03b8 \u2212 \u03b80\u2225 \u2264 B},\nand assign the output to \u03b8\u0302. 4: Return \u03b8\u0302.\nThe computational efficiency of the sampler depends on the choices of B and \u03b3, as well as assumptions on the loss functions. The quality of the solution from the localized ASAP depends on how the initialization \u03b80 is obtained and the associated choice of B. We instantiate these parameters concretely in Appendix B and C and obtain a formal computational guarantee for a DP-ERM problem.\nWe then provide the privacy, utility, and computational guarantees for the end-to-end Algorithm 3.\nTheorem 3 (Guarantees for localized-ASAP). Let \u03c1 \u2208 (0, 1) and set \u03b80, B, \u03b3, \u03bb as Table 2. Let \u03b8\u0302 be the output of Algorithm 3. Set the pure-DP (or Gaussian DP) parameters for the output perturbation, approximate-MCMC sampler, and the ASAP to be \u03b5 (or \u00b5). Then\n1. \u03b8\u0302 satisfies 3\u03b5-pure DP (or \u221a 3\u00b5-Gaussian DP).\n2. In pure DP case, the empirical (total) risk satisfies E[L(\u03b8\u0302)]\u2212 L(\u03b8\u2217) \u2264 O (\nd2G2(ln d+ln(1/\u03c1)+\u03c1\u03ba) \u03b1n\u03b52\n) .\nIn the Gaussian DP case, the empirical (total) risk satisfies E[L(\u03b8\u0302)]\u2212 L(\u03b8\u2217) \u2264 O ( dG2\n\u03b1n\u00b52\n) .\n3. With probability 1\u2212 \u03c1, the overall runtime time of the algorithm is \u2126 ( dn (ln\u03ba+ \u03ba ln(d/\u03c1) + lnn)max { \u03ba3/2 \u221a d (\u03ba ln(d/\u03c1) + lnn), d\u03ba } ln(1/\u03c1) ) .\nRemark 12. The suboptimality bound matches the information-theoretic limit for this problem in (Bassily et al., 2014) up to a constant factor. Notably, taking \u03c1 = O(1/\u03ba), we obtain the excess empirical risk bound O (\nd2G2(ln d+ln\u03ba) \u03b1n\u03b52\n) . This enhances the \u03ba dependence, reducing it from O(\u03ba) to O(log \u03ba). To the best of our\nknowledge, this is the first O\u0303(n) time algorithm (using incremental gradient oracle, assume \u03ba = polylog(n)) for DP-ERM (Lipschitz, smooth, strong convex losses) that achieves the optimal rates under pure differential privacy. The closest is the algorithm from (Bassily et al., 2014), which runs in O(n4) time. To avoid any confusion, a nearly linear-time algorithm for DP-SCO in the smooth / strongly convex setting that achieves optimal rates exists (Feldman et al., 2020). But to the best of our knowledge, the problem remains open for DP-ERM until this paper.\nRemark 13 (Improvement under Gaussian DP). By the conversion from pure-DP to Gaussian DP (Lemma 15), the bound for pure DP in Theorem 3 directly implies a DP-ERM learner under Gaussian DP with suboptimality OP ( d 2G2\n\u03b1n\u00b52 ). However, we obtain an improved dimension dependence and achieve the optimal suboptimality\nbound of OP ( dG 2\n\u03b1n\u00b52 ) under Gaussian DP with the same runtime.\nComparing to the existing work. To the best of our knowledge, no existing pure-DP or pure-Gaussian DP learner achieves the optimal strongly convex rate in nearly linear time. The closest is Noisy Gradient Descent, which runs in O\u0303(n) time for strongly convex and smooth problems (runs in \u03ba log n iterations) but is a factor of \u03ba log n worse in the excess empirical risk it obtains. An alternative parameter regime that runs Noisy Gradient Descent for O(n2) iterations (i.e., O(n3) time) achieves the optimal rate (without additional \u03ba or log n dependence) albeit much slower and does not take advantage of the smoothness. We include more information about this in Appendix K.\nOther works either operate in a different setting or do not apply to all problems that we consider. For example, objective perturbation with approximate minima perturbation Iyengar et al. (2019) runs in O\u0303(n) time but applies only to generalized linear losses. Feldman et al. (2020) obtain nearly linear time private learner using a \u201cprivacy amplification by iteration\u201d technique, but it works under the DP Stochastic Convex Optimization setting, which is different from DP-ERM that we are considering. The same algorithm for DP-ERM requires O\u0303(n2) time still. In addition, (Feldman et al., 2020) focused on (\u03b5, \u03b4)-DP too. The sampler from (Gopi et al., 2022) (without combining with Localized-ASAP) runs in O\u0303(n\u03b1 log(d/\u03b4)) time but becomes vacuous when we want \u03b4 = 0 for either pure-DP or pure Gaussian DP."
        },
        {
            "heading": "5 CONCLUSION",
            "text": "Our proposed sampler Approximate SAample Perturbation (abbr. ASAP) perturbs an MCMC sample with noise proportional to its Wasserstein-\u221e distance from a reference distribution that satisfies pure DP or pure Gaussian DP (i.e., \u03b4 = 0). We show that our sampler obtains the first nearly linear-time end-to-end algorithm that achieves the optimal rate in the DP-ERM problem with strongly convex and smooth losses. The new techniques we developed might be of independent interest elsewhere that rely on approximate sampling. Limitations. While the posterior sampling mechanism is known to achieve optimal rates in the general convex Lipschitz loss cases under pure-DP and pure-Gausssian DP (Gopi et al., 2022), our techniques are insufficient for obtaining optimal rates with faster computation in these broader families of DP-ERM problems than what is known in the literature. It remains an intriguing open problem to characterize the optimal computational complexity when we do not have either smoothness or strong convexity."
        },
        {
            "heading": "A Additional Preliminaries 14",
            "text": ""
        },
        {
            "heading": "B Localization Techniques 14",
            "text": ""
        },
        {
            "heading": "C Parameters in Localized-ASAP 15",
            "text": ""
        },
        {
            "heading": "D Experiments 16",
            "text": "D.1 Theoretical lower bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 D.2 Empirical Risks on Real Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18"
        },
        {
            "heading": "E Supplementary Discussion on Wasserstein-Infinity Distance 19",
            "text": ""
        },
        {
            "heading": "F Proof the Conversion Lemma 8 20",
            "text": "F.1 A Key Lemma: Another Characterization of W\u221e Distance . . . . . . . . . . . . . . . . . 20 F.2 Proof of Lemma 8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20"
        },
        {
            "heading": "G Proofs of Theorem 1 and Corollary 10 22",
            "text": ""
        },
        {
            "heading": "H Proof of Theorem 2 25",
            "text": ""
        },
        {
            "heading": "I Proof of Theorem 3 26",
            "text": ""
        },
        {
            "heading": "J Deferred Proofs of the Supporting Lemmas and Corollaries 28",
            "text": "J.1 Proof of Lemma 9 and Corollary 20 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 J.2 Proof of Lemma 18 and Lemma 19 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 J.3 Proof of Lemma 14 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 J.4 Proof of Lemma 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 J.5 Proof of Lemma 15 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 J.6 Proof of Lemma 22 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\nK Facts about Noisy Gradient Descent 36"
        },
        {
            "heading": "A ADDITIONAL PRELIMINARIES",
            "text": "Lemma 14 (Adaptive Composition). Let M1 : X \u2217 \u2192 \u2206\u03981 satisfies \u03b51-DP (or \u00b51-GDP) and M2 : \u03981 \u00d7X \u2217 \u2192 \u2206\u03982 : satisfies \u03b52-DP (or \u00b52-GDP) with probability 1 when its first input \u03b81 \u223cM1(D) for any dataset D \u2208 X \u2217, thenM1 \u00d7M2 satisfies (\u03b51 + \u03b52)-DP (or \u221a \u00b521 + \u00b5 2 2-GDP).\nThe composition theorem traditionally requires M2 to satisfy DP (or GDP) for all \u03b82 \u2208 \u03982. What is stated above is slightly weaker in the sense that we can ignore a measure 0 set. We defer the proof to Appendix J.3.\nLemma 15 (Conversion between pure DP and GDP). With \u03a6 denoting the cumulative distribution function of the standard normal, an \u03b5-pure DP mechanism also satisfies \u00b5-GDP with\n\u00b5 = 2\u03a6\u22121 ( e\u03b5\n1 + e\u03b5\n) .\nWe defer the proof to Appendix J.5.\nDefinition 16 (Exponential Mechanism McSherry & Talwar (2007)). For a quality score u, the exponential mechanismMu : X \u2192 \u2206\u0398 samples an outcome \u03b8 \u2208 \u0398 with probability proportional to exp ( \u03b5u(x,\u03b8) 2\u2206u ) , and is \u03b5-DP, where \u2206u is the global sensitivity.\nAdditional Notation. For a set S, we denote \u2225S\u2225 := supx\u2208S \u2225x\u22252."
        },
        {
            "heading": "B LOCALIZATION TECHNIQUES",
            "text": "The choice for the algorithm for providing \u03b80 and the associated B parameter in Algorithm 3 is delicate. We construct an appropriate algorithm to find \u03b80 in this section. In particular, we use approximate output perturbation.\nFor the general Lipschitz loss setting, output perturbation does not quite work as it does not even achieve minimax rate. But if individual loss function \u2113 satisfies \u03b1-strongly convexity, Bassily et al. (2014) showed that one can obtain a localization using output perturbation that qualifies such that the downstream exponential mechanism on the localized set is optimal. The key observation is that under strong convexity, the sensitivity of \u03b8\u2217 = argmin\u03b8 \u2211n i=1 \u2113i(\u03b8) can be shown to be G/(\u03b1n) and output perturbation satisfies pure-DP, also it satisfies (with high probability)\n\u2225\u03b80 \u2212 \u03b8\u2217\u2225 \u2264 2Gd log(\u00b7)\n\u03b1n\u03b5 .\nThis order suffices for the posterior sampling to achieve the optimal rate.\nWe provide the following Approximate Output Perturbation algorithm, wherein we introduce perturbations to the approximate optimizer.\nAlgorithm 4 Approximate Output Perturbation 1: Input: individual losses {\u2113i}ni=1 satisfying G-Lipschitz continuity and \u03b2-smoothness; strong convexity\nparameter \u03b1. Privacy parameter \u00b5 for GDP (or \u03b5 for pure DP). 2: Denote L(\u03b8) := \u2211n i=1 \u2113i(\u03b8), and \u03b8 \u2217 := argmin\u03b8 L(\u03b8). Set \u2206\u0303 := 2\u03c4n + 2G \u03b1n . 3: Solve for \u03b8\u0303 that satisfies \u2225\u03b8\u0303 \u2212 \u03b8\u2217\u22252 \u2264 \u03c4n . \u25b7 Instantiation: Gradient Descent or Newton Descent. 4: Output \u03b80 = \u03b8\u0303 +Z, where Zi \u223c Lap( \u221a d\u2206\u0303 \u03b5 ) for \u03b5-pure DP (Zi \u223c N (0, \u2206\u03032 \u00b52 ) for \u00b5-GDP).\nRemark 17. For step 3, we make the optimization oracle a black-box algorithm that enjoys a linear convergence rate. Instantiation of the optimization oracle could be the Gradient Descent or the Newton Descent, which enjoy a linear convergence rate under the assumptions of strong convexity and Lipschitz smoothness (or c-stable Hessian by the Theorem 2 of Karimireddy et al. (2018)). Note that \u2225\u03b8\u0303 \u2212 \u03b8\u2217\u22252 \u2264 \u03c4n is not a stopping criteria of the optimization algorithm. Instead, it is a property that \u03b8\u0303 would fulfill under the stopping criteria the additional assumption on L. The following lemma provides the bound for the sensitivity of the minimizer \u03b8\u2217, which helps bound the sensitivity of the approximate minimizer \u03b8\u0303.\nLemma 18. Let D \u2208 X \u2217. Let D\u2032 \u2208 X \u2217 be a neighbor such that LD\u2032 \u2212 LD = \u00b1\u2113x for some x \u2208 X , then\n\u2225\u03b8\u2217(D)\u2212 \u03b8\u2217(D\u2032)\u22252 \u2264 2G\n\u03b1n .\nWith Lemma 18, we can bound the sensitivity of \u03b8\u0303, thus providing the following differential privacy guarantees.\nLemma 19. Algorithm 4 satisfies \u03b5-differential privacy (or \u00b5-Gaussian DP).\nWe defer the proofs of Lemma 18 and 19 to Appendix J.2."
        },
        {
            "heading": "C PARAMETERS IN LOCALIZED-ASAP",
            "text": "The choice of \u03b3 and \u03bb. Larger \u03b3 provides a better utility guarantee but a weaker privacy guarantee. We choose \u03b3 by the following fact so that the posterior sampling mechanism \u03b8 \u223c p\u2217(\u03b8) satisfies \u03b5-pure DP or \u00b5-GDP.\nFact 1 (Optimal rates for strongly convex problems). The optimal (expected) excess empirical risks for G-Lipschitz continuous and \u03b1-strongly convex (individual) losses is d 2G2\n\u03b1n\u03b52 and dG2\n\u03b1n\u00b52 for \u03b5-DP and \u00b5-GDP respectively. For posterior sampling, choosing\n\u03b3 = \u00b52\u03b1n\nG2 , \u03bb = 0\nyields the optimal rate under \u00b5-GDP. Unfortunately, there are no parameter choices for \u03b3, \u03bb that can yield the optimal rate under pure-DP, unless \u0398 is already localized such that it satisfies that Diam(\u0398) \u2264 dG\u03b1n\u03b5 . Then the choice of \u03b3 = \u03b5G\u00b7Diam(\u0398) works.\nThe choice of B (the radius of the localized domain). For desirable the utility and computational guarantees in sampling, we hope that B is large enough such that the mode \u03b8\u2217 and the mean \u03b8\u0304 are in the localized domain \u0398, i.e., \u03b8\u2217 \u2208 \u0398 and \u03b8\u0304 \u2208 \u0398, where \u03b8\u2217 := argmin\u03b8\u2208Rd J(\u03b8), and \u03b8\u0304 := E\u03b8\u223c\u03c0(\u03b8)\u221de\u2212\u03b3J(\u03b8)\u03b8. Moreover, Assumption 3 requires B(\u03b8\u2217, R1) \u2282 \u0398 for efficient constrained MALA, where R1 \u2265 8 \u221a d\n\u03b3\u03b1n . However, by Corollary 20 and the discussion after Theorem 1, we know that an excessively large B should be avoided. This is because a large B leads to a reduced pmin, which in turn necessitates a greater number of steps for constrained MALA to achieve the desired accuracy. Also, note that by Fact 1, for \u03b5-pure DP guarantee, we set \u03b3 = \u03b52GB , which is dependent of B.\nIn pure DP case, suppose \u03b80 is the output of Alogrithm 4, then we have \u03b80 = \u03b8\u0303+Z, where Zi \u223c Lap(C/n\u03b5), C = \u221a d ( 2\u03c4 + G\u03b1 ) , and \u2225\u03b8\u0303 \u2212 \u03b8\u0303\u2217\u22252 \u2264 \u03c4n . Therefore we have\n\u2225\u03b80 \u2212 \u03b8\u2217\u2225 \u2264 \u2225\u03b80 \u2212 \u03b8\u0303\u22252 + \u2225\u03b8\u0303 \u2212 \u03b8\u2217\u22252 = \u2225Z\u22252 + \u2225\u03b8\u0303 \u2212 \u03b8\u2217\u22252 \u2264 C \u221a d ln(d/\u03c1)\nn\u03b5 +\n\u03c4 n ,\nwith probability 1\u2212 \u03c1. In the last inequality, we apply the fact that\nP ( \u2225Z\u22252 \u2265 C \u221a d ln(d/\u03c1)\nn\u03b5\n) = P ( d\u2211\ni=1\nZ2i \u2265 d( C ln(d/\u03c1) n\u03b5 ) 2\n) \u2264\nd\u2211 i=1 P ( |Zi| \u2265 C ln(d/\u03c1) n\u03b5 ) \u2264 \u03c1.\nIn order to fulfill the condition B(\u03b8\u2217, R1) \u2282 \u0398, where R1 = 8 \u221a d \u03b3\u03b1n , note that \u03b3 = \u03b5 2GB , the following inequality should hold:\nB \u2212 8 \u221a\n2dGB \u03b5\u03b1n \u2265\nC \u221a d ln(d/\u03c1)\nn\u03b5 +\n\u03c4 n .\nThe above inequality is satisfied with B \u2265 4(32dG+(2\u03b1\u03c4+G)d ln(d/\u03c1)+\u03c4\u03b5\u03b1)\u03b1n\u03b5 . For the sake of simplicity, we let \u03c4 be sufficiently small and set B = C1dG ln(d/\u03c1)\u03b1n\u03b5 .\nIn GDP case, similarly, we have \u03b80 = \u03b8\u0303 + Z, where Zi \u223c N (0, (2\u03c4 + G\u03b1 ) 2/n2\u00b52), and \u2225\u03b8\u0303 \u2212 \u03b8\u0303\u2217\u22252 \u2264 \u03c4n . Therefore we have\n\u2225\u03b80 \u2212 \u03b8\u2217\u2225 \u2264 \u2225\u03b80 \u2212 \u03b8\u0303\u22252 + \u2225\u03b8\u0303 \u2212 \u03b8\u2217\u22252 \u2264 \u2225Z\u22252 + \u03c4 n \u2264 \u221a 2(2\u03c4\u03b1+G)( \u221a d+\n\u221a ln(1/\u03c1))\n\u03b1n\u00b5 +\n\u03c4 n ,\nwith probability 1 \u2212 \u03c1. In the last inequality where we use the tail bound for chi-square distributions by Lemma 1 in (Laurent & Massart, 2000). Again we need B \u2212 R1 \u2265 \u2225\u03b80 \u2212 \u03b8\u2217\u2225, where R1 = 8\n\u221a d\n\u03b3\u03b1n and\n\u03b3 = \u00b5 2\u03b1n G2 . This is satisfied with B \u2265\n\u221a 2(2\u03c4\u03b1+G)( \u221a d+ \u221a ln(1/\u03c1))+8G \u221a d+\u03c4\u03b1\u00b5\n\u03b1n\u00b5 . Again, we let \u03c4 be sufficiently\nsmall and set B = C2G( \u221a d+ \u221a ln(1/\u03c1))\n\u03b1n\u00b5\nCalculation of pmin Lemma 9 implies that the choices of pmin in Algorithm 3 are valid lower bounds of the density function. We have the following corollary.\nCorollary 20. Consider probability with density\np(\u03b8) \u221d exp ( \u2212\u03b3 ( n\u2211\ni=1\n\u2113i(\u03b8) + \u03bb\n2 \u2225\u03b8 \u2212 \u03b80\u22252\n)) 1{\u2225\u03b8 \u2212 \u03b80\u2225 \u2264 B}.\n1. If \u2113i is G-Lipschitz for all i, then min\u03b8 p(\u03b8) \u2265 e\u2212\u03b3(2nGB+2\u03bbB 2) \u0393(\nd 2+1)\n\u03c0d/2Bd .\n2. If \u2113i is convex and \u03b2-smooth for all i, then for all \u03b8\u0303 \u2208 \u0398, we have\nmin \u03b8\np(\u03b8) \u2265 e\u2212\u03b3(2B\u2225\u2207J(\u03b8\u0303)\u2225+2(n\u03b2+\u03bb)B 2) \u00b7\n\u0393(d2 + 1)\n\u03c0d/2Bd .\nApplying Corollary 20, we calculate pmin as follows: Take any \u03b8\u2032 such that \u2225\u03b8\u2032\u2212 \u03b80\u22252 \u2264 B. Compute\npmin \u2190 e\u2212\u03b3 min{2nGB+2\u03bbB 2, 2\u2225\u2207L\u03bb(\u03b8\u2032)\u2225B+2(n\u03b2+\u03bb)B2} \u0393( d2+1)\n\u03c0d/2Bd ."
        },
        {
            "heading": "D EXPERIMENTS",
            "text": "D.1 THEORETICAL LOWER BOUNDS We visualize the excess empirical risks in Figure 1and demonstrate that \u03b5-(pure) DP can outperform (\u03b5, \u03b4)-DP in theory, especially when the sample size n is large.\nTable 1: Summary of our results for the \u03b1n-strong convex DP-ERM problem with G-Lipschitz and \u03b2-smooth losses and that the total loss satisfies \u03b1n-strong convexity. The utility measures the expected excess empirical (total) risk. The polylog(n) factors are ignored from the computation. Observe that we are the first algorithms that achieve the nearly linear time computation under pure-DP and pure-Gaussian DP while still obtaining the optimal excess empirical risk.\nPrivacy Excess Empirical risk Computation\nNoisyGD (see Appendix K) \u00b5-GDP dG2/\u03b1n\u00b52 n3\nNoisySGD (Bassily et al., 2014) (\u03b5, \u03b4)-DP dG2 log(1/\u03b4)/\u03b1n\u03b52 n2\nPosteriorSample (Gopi et al., 2022) \u03b4-approx \u00b5-GDP dG2/\u03b1n\u00b52 n/\u03b1\nExponentialMechanism (Bassily et al., 2014) \u03b5-DP d2G2/\u03b1n\u03b52 n4\nLocalized-PS-ASAP (This paper) \u00b5-GDP dG2/\u03b1n\u00b52 n/\u03b12 or n/\u03b15/2\nLocalized-EM-ASAP (This paper) \u03b5-DP d2G2/\u03b1n\u03b52 n/\u03b12 or n/\u03b15/2\nTable 2: The choice of \u03b3,B, \u03bb, \u03b80,\u2206 when instantiating Algorithm 3 for pure DP or Gaussian DP learning.The choices of \u03b3 ensure the DP and GDP guarantee respectively and the choice of B ensures sufficient localization such that the sampling Algorithm 1 run in O\u0303(n) time (condition on the high-prob event that \u03b8\u2217 is inside the localized set \u0398. Polynomial dependence in d and other parameters are hidden in O\u0303). For pure-DP, the choice of B has the additional purpose of achieving the optimal rate for DP-ERM \u2014 L(\u03b8\u0302)\u2212L(\u03b8\u2217) = O( d 2G2\n\u03b1n\u03b52 ). For GDP, the choice of B only affects computation.\nThe optimal rate L(\u03b8\u0302)\u2212 L(\u03b8\u2217) = O( dG 2\n\u03b1n\u00b52 ) is always attained.\nD.2 EMPIRICAL RISKS ON REAL DATASETS\nSetup. We experiment on two real datasets: Red Wine Quality and White Wine Quality from UCI repository (https://archive.ics.uci.edu/dataset/186/wine+quality). The Red Wine Quality dataset contains 1599 samples with 11 features. We standardize the data and learn a regression task via \u2113i(\u03b8) = 1 2 (x T i \u03b8 \u2212 yi)2 + \u03b12 \u2225\u03b8\u2225\n2, which is a strongly convex problem under \u03b1 = 100 and \u03c1 = 0.01. The White Wine Quality dataset contains 4898 samples with 11 features. We standardize the data and learn a regression task via \u2113i = 12 (x T i \u03b8 \u2212 yi)2 + \u03b12 \u2225\u03b8\u2225\n2, which is a strongly convex problem under \u03b1 = 32 and \u03c1 = 0.01.\nResults. We compare with the theoretical lower bounds in Table 1 (up to a constant), the output perturbation in Algorithm 4, and DP-GD with per-sample gradient clipping (no need to set the clipping threshold) by Bu et al. (2022). The experiments are conducted under both \u03b5-DP and \u00b5-GDP. We consistently observe that our algorithms outperform the existing ones.\nWe also visualize the random MALA results (marked as orange dots) by Algorithm 1 in Figure 4, displaying the first 2 dimensions, conditioned on the same initialization \u03b80 (marked as a black dot) and \u03b5 = 0.1. Notice that the contours calculated from the reference distribution pM(D)(\u03b8) \u221d e\u2212\u03b3J(\u03b8)1{\u2225\u03b8 \u2212 \u03b80\u2225 \u2264 B}, whose mean is marked as a red dot. It is clear that MALA converges to the correct distribution. We confirm that the convergence is consistent when MALA starts from different \u03b80."
        },
        {
            "heading": "E SUPPLEMENTARY DISCUSSION ON WASSERSTEIN-INFINITY DISTANCE",
            "text": "Building on the insights from Section 3.1, we provide Figure 5 to enhance intuition on W\u221e distance. The visualization demonstrates that the optimal coupling is highly concentrated near the line y = x and sparser in other areas compared to the independent coupling.\nNotably, Feldman et al. (2018) also explore this \u201cnorm-aware\u201d statistical distance and establish the shift reduction lemma. However, the primary focus of Feldman et al. (2018) is on Renyi Differential Privacy, and the proof techniques employed differ. To prove Theorem 2, we leveraged Lemma 14, a measure-theoretic adaptive composition theorem of privacy profiles that we proved in this paper, which allows the exclusion of a measure 0 set."
        },
        {
            "heading": "F PROOF THE CONVERSION LEMMA 8",
            "text": "F.1 A KEY LEMMA: ANOTHER CHARACTERIZATION OF W\u221e DISTANCE To establish Lemma 8, we commence by furnishing an equivalent characterization for the W\u221e distance. We also demonstrate the attainability of the infimum in Lemma 22. Our exposition begins with the introduction of the concept of tightness.\nDefinition 21 (Tightness). A probability measure P on \u0398 is called tight if for any \u03f5 > 0, there exists a compact set K \u2282 \u0398, such that\nP (\u0398 \\K) \u2264 \u03f5,\nLemma 22. Let (\u0398,dist) be a complete separable metric space. Let P and Q be two tight probability measures on \u0398. The Wasserstein-\u221e distance has the following characterization: W\u221e(P,Q) = inf{r > 0 : P (U) \u2264 Q(Ur), for all open subsets U \u2282 \u0398}, where the r-expansion of U is denoted by Ur := {x \u2208 \u0398 : dist(x, U) \u2264 r}. Furthermore, the infimum in the Definition 7 can be attained, i.e., there exists \u03b6\u2217 \u2208 \u0393(P,Q) such that\nW\u221e(P,Q) = ess sup (x,y)\u2208(\u0398\u00d7\u0398,\u03b6\u2217) dist(x, y) = inf \u03b6\u2208\u0393(P,Q) ess sup (x,y)\u2208(\u0398\u00d7\u0398,\u03b6) dist(x, y).\nThe proof of this lemma is presented in Appendix J.6.\nF.2 PROOF OF LEMMA 8 Proof of Lemma 8 First note that \u2225x\u2212 y\u22251 \u2264 \u221a d\u2225x\u2212 y\u22252, for all x, y. Therefore, it suffices to prove the lemma when dist is the \u21132 metric.\nFix \u2206 and set \u03be = pmin \u00b7 \u03c0 d/2 2d+1\u00b7\u0393(d/2+1)\u2206 d, so that dTV(P,Q) < \u03be.\nTo prove the result that W\u221e \u2264 \u2206, we use the equivalent definition of W\u221e in Lemma 22. By this definition, to prove W\u221e(P,Q) \u2264 \u2206, it suffices to show that P (A) \u2264 Q(A\u2206), for all open set A \u2286 \u0398, where we re-define A\u2206 := {x \u2208 Rd | dist(x,A) \u2264 \u2206}. Note that by this definition, A\u2206 might extend beyond \u0398. However, we still have Q(A\u2206) = Q(A\u2206 \u2229\u0398), since Q is supported on \u0398. Note that if Q(A\u2206) = 1, it is obvious that P (A) \u2264 Q(A\u2206). When A is an empty set, the proof is trivial. So we only consider nonempty open set A \u2286 \u0398 with Q(A\u2206) < 1. Note that for an arbitrary open set A \u2286 \u0398, we have\nP (A) \u2264 Q(A) + dTV (P,Q) < Q(A) + \u03be. Thus to prove P (A) \u2264 Q(A\u2206), it suffices to prove Q(A) + \u03be \u2264 Q(A\u2206), i.e., Q(A\u2206 \\A) \u2265 \u03be. To prove Q(A\u2206 \\A) \u2265 \u03be, we construct an \u21132-ball U \u2282 Rd of radius \u2206/2 satisfying the properties:\n1. U is contained in the set A\u2206 \\A, i.e., U \u2282 A\u2206 \\A, and 2. Q(U) = Q(U \u2229\u0398) \u2265 \u03be\nNotice that we only consider nonempty open set A \u2286 \u0398 with Q(A\u2206) < 1, we construct U as follows.\nIntuition and Overview of the construction of U . The construction of the ball U involves determining two pivotal points, y\u2206 and yA, located at the \u201cboundaries\u201d of A\u2206 and A, respectively. We then define U as U := Bdist ( y\u2206+yA 2 , dist(y\u2206,yA) 2 ) . Note that by the definition of A\u2206, dist(y\u2206, yA) \u2265 \u2206. To guarantee Property 1 (i.e., U \u2282 A\u2206 \\A), yA is chosen such that dist(y\u2206, yA) = \u2206. Additionally, to ensure Property 2 (i.e., Q(U) \u2265 \u03be), since Q(U) = Q(U \u2229 \u0398), our aim is to maximize the \u201csize\u201d of U \u2229 \u0398. Therefore, we specifically require y\u2206 to belong to \u0398, while noting that A\u2206 might extend beyond \u0398. The detailed selection process of y\u2206 and yA, and the subsequent construction of U , are presented below.\nExistence and Construction of y\u2206. To find the above discussed y\u2206 \u2208 \u0398, we first show that:"
        },
        {
            "heading": "If Q(A\u2206) < 1, then \u2202(A\u2206) \u2229\u0398 \u0338= \u2205,",
            "text": "where we re-define the boundary of A\u2206 as \u2202(A\u2206) := {x \u2208 R | dist(x,A) = \u2206}.\nWe prove it by contradiction. If instead \u2202(A\u2206) \u2229 \u0398 = \u2205, then for all x \u2208 \u0398, dist(x,A) \u0338= \u2206. Due to the continuity of dist and the convexity of \u0398, we know that only one of these two statements holds:\n\u2022 dist(x,A) < \u2206, for all x \u2208 \u0398.\n\u2022 dist(x,A) > \u2206, for all x \u2208 \u0398.\nSince \u2205 \u0338= A \u2286 \u0398, there exist x\u2032 \u2208 A \u2208 \u0398, such that dist(x\u2032, A) = 0. Therefore, the first statement holds. Thus \u0398 \u2286 A\u2206, which contradicts to Q(A\u2206) < 1.\nTherefore, \u2202(A\u2206) \u2229 \u0398 \u0338= \u2205. Then there exists y\u2206 \u2208 \u2202(A\u2206) \u2229 \u0398. Thus there exist y\u2206 \u2208 \u0398, such that dist(y\u2206, A) = \u2206.\nConstruction of yA. Note that by the definition of dist(\u00b7, A) and that dist(y\u2206, A) = \u2206, there exist yA \u2208 A (the closure of A), such that dist(y\u2206, yA) = \u2206.\nConstruction of U . Let y0 = y\u2206+yA2 and let U be the closed ball U = B(y0,\u2206/2) := {x \u2208 Rd | dist(x, y0) \u2264 \u2206/2}. We now prove that U \u2286 A\u2206 \\ A and that Q(U) \u2265 \u03be, and then the proof is concluded.\n1. To prove U \u2282 A\u2206 \\A, let x \u2208 U . We show that x \u2208 A\u2206 and x /\u2208 A. Since x, y\u2206, yA \u2208 U and U is a ball with diameter \u2206, we have\ndist(x, y\u2206) \u2264 \u2206, and dist(x, yA) \u2264 \u2206 (2)\n\u2022 (x /\u2208 A). If x \u2208 A, since A is an open set and dist(y\u2206, A) = \u2206, we have that dist(x, y\u2206) > \u2206, which contradicts to (2). Therefore x /\u2208 A.\n\u2022 (x \u2208 A\u2206). Note that yA \u2208 A\u0304, thus dist(x,A) \u2264 dist(x, yA) (2) \u2264 \u2206, implying that x \u2208 A\u2206.\n2. To prove Q(U) \u2265 \u03be, note that we assume the domain \u0398 to be an \u21132 ball. Since yA, y\u2206 \u2208 \u0398, by Lemma 24, we know that Vol(U \u2229\u0398) \u2265 12Vol(U). Thus\nQ(U) = Q(U \u2229\u0398) \u2265 pminVol(U \u2229\u0398) \u2265 1\n2 pminVol(U) = \u03be,\nwhich completes the proof.\nRemark 23. It is worth noting that Lemma 8 and Lemma 24 extend naturally to open balls. The necessary modifications in the proof involve changing certain inequalities: \u201c\u2264\u201d becomes \u201c<\u201d, and \u201c>\u201d becomes \u201c\u2265.\u201d\n\u25a0\nLemma 24. Suppose \u03b8 \u2208 Rd, and R > 0. If there exists a \u2208 Rd such that a \u2208 B\u21132(\u03b8,R), and that \u2212a \u2208 B\u21132(\u03b8,R). Then\nVol (B\u21132(0, \u2225a\u22252) \u2229 B\u21132(\u03b8,R)) Vol (B\u21132(0, \u2225a\u22252)) \u2265 1 2 .\nProof Since a,\u2212a \u2208 B\u21132(\u03b8,R), we have\n\u2225a\u2212 \u03b8\u222522 \u2264 R2, and \u2225 \u2212 a\u2212 \u03b8\u222522 \u2264 R2,\nwhich implies \u2225a\u222522 \u2212 2\u27e8a, \u03b8\u27e9+ \u2225\u03b8\u222522 \u2264 R2, and \u2225a\u222522 + 2\u27e8a, \u03b8\u27e9+ \u2225\u03b8\u222522 \u2264 R2. Thus, \u2225a\u222522 + \u2225\u03b8\u222522 \u2264 R2. Denote S = B\u21132(0, \u2225a\u22252)\\B\u21132(\u03b8,R). We first prove that\u2212S := {\u2212x | x \u2208 S} \u2286 B\u21132(\u03b8,R). For an arbitrary x \u2208 S, since x \u2208 B\u21132(0, \u2225a\u22252), we have \u2225x\u22252 \u2264 \u2225a\u22252, thus \u2225x\u222522+\u2225\u03b8\u222522 \u2264 \u2225a\u222522+\u2225\u03b8\u222522 \u2264 R2. On the other hand, since x /\u2208 B\u21132(\u03b8,R), we have \u2225x\u2212\u03b8\u222522 > R2. Thus \u2225\u2212x\u2212\u03b8\u222522 = 2 ( \u2225x\u222522 + \u2225\u03b8\u222522 ) \u2212\u2225x\u2212\u03b8\u222522 < R2, which implies \u2212x \u2208 B\u21132(\u03b8,R). Therefore \u2212S \u2286 B\u21132(\u03b8,R). Since S = B\u21132(0, \u2225a\u22252) \\ B\u21132(\u03b8,R) and \u2212S \u2286 B\u21132(\u03b8,R), we know that S \u2229 (\u2212S) = \u2205. Therefore,\n2Vol(S) = Vol(S) + Vol(\u2212S) = Vol (S \u222a (\u2212S)) \u2264 Vol (B\u21132(0, \u2225a\u22252)) .\nTherefore\nVol (B\u21132(0, \u2225a\u22252) \u2229 B\u21132(\u03b8,R)) = Vol (B\u21132(0, \u2225a\u22252))\u2212Vol(S) \u2265 1\n2 Vol (B\u21132(0, \u2225a\u22252)) .\n\u25a0"
        },
        {
            "heading": "G PROOFS OF THEOREM 1 AND COROLLARY 10",
            "text": "In this section, we provide the omitted proofs and supplementary facts for the Metropolis-adjusted Langevin algorithm (MALA) with constraint in Section 3.3.\nWe first provide the definition of mixing time. Given an error tolerance \u03be \u2208 (0, 1) and an initial distribution p0, define the \u03be-mixing time in total variation distance as\n\u03c4 ( \u03be, p0, p\u2217 ) = min{k | \u2225pk \u2212 p\u2217\u2225TV \u2264 \u03be}\nFor simplicity, we denote L = n\u03b2 and m = n\u03b1 in this proof.\nProof of Theorem 1 We separate the proof of Theorem 1 into two parts via splitting of Algorithm 1 into two loops. We note that in the inner loop, Algorithm 1 is performing the MALA algorithm on the unconstrained space Rd. In the outer loop, it performs a rejection sampling step that takes in independent samples from MALA and keeps rejecting samples outside of the domain \u0398 until one sample falls inside \u0398.\nFor the first part, we cite the previous results. Consider the MALA algorithm on Rd with a step size of\nh = \u0398 ( min { \u03ba\u22121/2(\u03b3L)\u22121(ln\u03b20/\u03be) \u22121/2, 1\n\u03b3Ld\n}) ,\nand an initial distribution \u00b50 satisfying \u03b20-warmness assumption that supA\u2282Rd ( \u00b50(A) \u03c0(A) ) \u2264 \u03b20. Then by Theorem 1 of Dwivedi et al. (2019), we know that the MALA algorithm with the number of iterations\nK = \u2126 ( ln ( \u03b20 \u03be ) max { \u03ba3/2 \u221a ln\u03b20/\u03be, d\u03ba }) ,\nconverges to \u03be accuracy in terms of the TV distance: dTV (\u00b50, \u03c0) \u2264 \u03be. By Lemma 8 of Ma et al. (2019), we also know that on the unconstrained space, the Gaussian distributionN (0, 1\u03b3L I) is (2\u03ba)\nd/2 warm with respect to the posterior distribution \u03c0 with condition number \u03ba. Plugging in this warmness constant, we obtain that\nK = \u2126 ( (d ln\u03ba+ ln 1/\u03be)max { \u03ba3/2 \u221a d ln\u03ba+ ln 1/\u03be, d\u03ba }) ,\nThen for the rejection sampling part, we know that for each individual trial, the rejection probability equals the probability mass outside of \u0398. Invoking Lemma 25 below, we obtain that for \u03b8\u0302 \u223c \u03c0,\nP (\u2225\u2225\u2225\u03b8\u0302 \u2212 E\u03b8\u223cp(\u03b8)[\u03b8]\u2225\u2225\u2225 \u2265 r) \u2264 2e\u2212 r2\u03b3m8d ,\nand that for \u03b8\u2217 being the mode of \u03c0,\n\u2225\u2225E\u03b8\u223cp(\u03b8)[\u03b8]\u2212 \u03b8\u2217\u2225\u22252 \u2264 3 \u03b3m .\nOn the other hand, B(\u03b8\u2217, R1) \u2282 \u0398. Since R1 \u2265 8 \u221a d \u03b3m \u2265 2 \u221a 3 \u03b3m , B(E\u03b8\u223cp(\u03b8)[\u03b8], R1/2) \u2282 B(\u03b8 \u2217, R1) \u2282 \u0398.\nHence, applying the concentration argument above for \u03b8\u0302 \u223c \u03c0,\nP ( \u03b8\u0302 /\u2208 \u0398 ) \u2264 2e\u2212 \u03b3mR21 32d .\nCombining with the definition of the TV-distance, we know that for \u03b8\u0302K \u223c p\u0302K obtained by running the MALA algorithm (on Rd) for K steps,\nP ( \u03b8\u0302K /\u2208 \u0398 ) \u2264 P ( \u03b8\u0302 /\u2208 \u0398 ) + dTV (p\u0302 K , \u03c0) \u2264 2e\u2212 \u03b3mR21 32d + \u03be.\nHence with \u03c4 independent trials, probability that none of the \u03c4 trials belong to \u0398 is\nP (None of the \u03c4 trials belong to \u0398) = ( P ( \u03b8\u0302K /\u2208 \u0398 ))\u03c4 \u2264 ( 2e\u2212 \u03b3mR21 32d + \u03be )\u03c4 .\nTherefore with 1 \u2212 q probability, our MALA with constraint algorithm converges in \u03c4 =( ln 1\n2e\u2212 \u03b3mR21 32d +\u03be\n)\u22121 ln(1/q) runs of the MALA algorithm. Plugging in our choice of R1 and without\nloss of generality, assume that \u03be \u2264 1/16, we obtain that \u03c4 = ln(1/q). At last, we note that if dTV ( p\u0302K(\u03b8), \u03c0(\u03b8) ) \u2264 \u03be, then we also obtain a bound for dTV ( pK(\u03b8), p\u2217(\u03b8) ) , where pK(\u03b8) \u221d p\u0302K(\u03b8)1 {\u03b8 \u2208 \u0398} and p\u2217(\u03b8) \u221d \u03c0(\u03b8)1 {\u03b8 \u2208 \u0398}. Normalizing the density gives that p\u2217(\u03b8) = \u03c0(\u03b8)1{\u03b8\u2208\u0398}\u222b \u03c0(\u03b8)1{\u03b8\u2208\u0398}d\u03b8 . Applying the concentration argument above provides the bound: \u222b \u03c0(\u03b8)1 {\u03b8 \u2208 \u0398}d\u03b8 \u2265\n1 \u2212 2 exp ( \u2212\u03b3mR 2 1\n32d ) \u2265 12 , where the last inequality follows by plugging in our choice of R1. From the\ndefinition of the TV-distance, we know that dTV ( pK(\u03b8), p\u2217(\u03b8) ) =\n\u222b \u03b8\u2208\u0398 |pK(\u03b8)\u2212 p\u2217(\u03b8)|d\u03b8\n= \u222b \u03b8\u2208\u0398 \u2223\u2223\u2223\u2223\u2223 p\u0302K(\u03b8)\u222b \u03b8\u2208\u0398 p\u0302 K(\u03b8)d\u03b8 \u2212 p \u2217(\u03b8)\u222b \u03b8\u2208\u0398 \u03c0(\u03b8)d\u03b8 \u2223\u2223\u2223\u2223\u2223d\u03b8 \u2264 \u222b \u03b8\u2208\u0398 \u2223\u2223\u2223\u2223\u2223 p\u0302K(\u03b8)\u222b \u03b8\u2208\u0398 p\u0302 K(\u03b8)d\u03b8 \u2212 p\u0302 K(\u03b8)\u222b \u03b8\u2208\u0398 \u03c0(\u03b8)d\u03b8 \u2223\u2223\u2223\u2223\u2223d\u03b8 + \u222b \u03b8\u2208\u0398 \u2223\u2223\u2223\u2223\u2223 p\u0302K(\u03b8)\u222b \u03b8\u2208\u0398 \u03c0(\u03b8)d\u03b8 \u2212 p \u2217(\u03b8)\u222b \u03b8\u2208\u0398 \u03c0(\u03b8)d\u03b8\n\u2223\u2223\u2223\u2223\u2223d\u03b8 = \u2223\u2223\u2223\u2223\u22231\u2212 \u222b \u03b8\u2208\u0398 p\u0302 K(\u03b8)d\u03b8\u222b \u03b8\u2208\u0398 \u03c0(\u03b8)d\u03b8 \u2223\u2223\u2223\u2223\u2223+ 1\u222b \u03b8\u2208\u0398 \u03c0(\u03b8)d\u03b8 \u222b \u03b8\u2208\u0398 |p\u0302K(\u03b8)\u2212 \u03c0(\u03b8)|d\u03b8\n(i) \u2264 2 \u03be\u222b \u03b8\u2208\u0398 \u03c0(\u03b8)d\u03b8 \u2264 4\u03be,\nwhere (i) follows from the definition of the TV-distance. Replacing \u03be by \u03be/4 finishes the proof. \u25a0\nThe universal constants regarding the number of iterations can be found in the proof of Lemma 7 in Ma et al. (2019).\nLemma 25. In Rd, if a distribution p is \u03b3m-strongly log-concave, then\u2225\u2225E\u03b8\u223cp(\u03b8)[\u03b8]\u2212 \u03b8\u2217\u2225\u2225 \u2264\u221a 3 \u03b3m ,\nwhere \u03b8\u2217 denotes the mode of the distribution p(\u03b8). We also have that for \u03b8\u0302 \u223c p, P (\u2225\u2225\u2225\u03b8\u0302 \u2212 E\u03b8\u223cp(\u03b8)[\u03b8]\u2225\u2225\u2225 \u2265 r) \u2264 2e\u2212 r2\u03b3m8d .\nProof We prove this Lemma following the proof of Lemma 10 in Mazumdar et al. (2020). For \u2225\u2225E\u03b8\u223cp(\u03b8)[\u03b8]\u2212 \u03b8\u2217\u2225\u2225, we use the fact that p(\u03b8) is \u03b3m-strongly log-concave and consequently unimodal, and that \u2225\u2225E\u03b8\u223cp(\u03b8)[\u03b8]\u2212 \u03b8\u2217\u2225\u22252 \u2264 3 \u03b3m .\nFor \u2225\u2225\u2225\u03b8\u0302 \u2212 E\u03b8\u223cp(\u03b8)[\u03b8]\u2225\u2225\u2225, we note that p(\u03b8) being \u03b3m-strongly log-concave implies that the random variable\n\u03b8 \u223c p is a sub-Gaussian random vector with parameter \u03c32v = 12\u03b3m . Consequently, it is a norm-sub-Gaussian random variable with constant \u03c32n = 4d \u03b3m . Plugging into the definition of norm-sub-Gaussian random variable, we obtain that for \u03b8\u0302 \u223c \u03c0, P (\u2225\u2225\u2225\u03b8\u0302 \u2212 E\u03b8\u223cp(\u03b8)[\u03b8]\u2225\u2225\u2225 \u2265 r) \u2264 2e\u2212 r2\u03b3m8d .\n\u25a0\nProof of Corollary 10 Applying Lemma 8, to obtain \u2206-accuracy in W\u221e distance, we want that\n\u03be < pmin \u00b7 \u03c0d/2\n2d+1 \u00b7 \u0393(d2 + 1)dd/2 \u2206d,\nwhere pmin \u2264 min\u03b8 p\u2217(\u03b8) and p\u2217(\u03b8) \u221d e\u2212\u03b3J(\u03b8)1(\u03b8 \u2208 \u0398) as defined in Section 3.3.\nSince \u03b8\u2217 \u2208 \u0398 by Assumption 3, applying Corollary 20, we obtain that\nmin \u03b8\np\u2217(\u03b8) \u2265 e\u22122\u03b3n\u03b2B 2 \u00b7 \u0393(d2 + 1)\n\u03c0d/2Bd .\nSet B = C1Gd ln(d/\u03c1)\u03b1n\u03b5 , as given in Table 2. We then set\n\u03be = e\u22122\u03b3n\u03b2B 2 \u00b7 \u0393(d2 + 1)\n\u03c0d/2Bd \u00b7 \u03c0\nd/2\n2d+1 \u00b7 \u0393(d2 + 1)dd/2 \u2206d (pmin = e\u22122\u03b3n\u03b2B\n2 \u00b7 \u0393( d 2+1)\n\u03c0d/2Bd )\n= e\u2212 \u03b5n\u03b2B G \u00b7 1 2d+1 \u00b7 dd/2Bd \u2206d (\u03b3 = \u03b52GB )\n= e\u2212C1\u03bad ln(d/\u03c1) \u00b7 1 2d+1 \u00b7 dd/2\n( \u03b1n\u03b5\nC1Gd ln(d/\u03c1)\n)d \u2206d (B = C1Gd ln(d/\u03c1)\u03b1n\u03b5 , \u03ba = \u03b2 \u03b1 )\nTherefore, we have ln 1/\u03be \u223c O ( \u03bad ln(d/\u03c1) + d ln d+ d ln ( Gd ln(d/\u03c1)\n\u03b1n\u03b5\n) + d ln 1\n\u2206 ) \u223c O ( \u03bad ln(d/\u03c1) + d ln ( Gd ln(d/\u03c1)\n\u03b1n\u03b5\u2206\n)) (\u03ba = \u03b2\u03b1 > 1, \u03c1 < 1)\nTherefore, applying Theorem 1, we obtain that Algorithm 1 converges to \u2206-accuracy in W\u221e(pK , p\u2217) with the following number of gradient queries to J , with probability 1\u2212 q:\n\u2126 ( d ( ln\u03ba+ \u03ba ln(d/\u03c1) + ln ( Gd ln(d/\u03c1)\n\u03b1n\u03b5\u2206\n)) max { \u03ba3/2 \u221a d ( \u03ba ln(d/\u03c1) + ln ( Gd ln(d/\u03c1)\n\u03b1n\u03b5\u2206\n)) , d\u03ba } ln 1\nq\n) .\nPlugging in \u2206 = Gd log(d/\u03c1)2n2\u03b1\u03b5 as given in Table 2, it translates into\n\u2126 ( d (ln\u03ba+ \u03ba ln(d/\u03c1) + lnn)max { \u03ba3/2 \u221a d (\u03ba ln(d/\u03c1) + lnn), d\u03ba } ln 1\nq\n) .\n\u25a0"
        },
        {
            "heading": "H PROOF OF THEOREM 2",
            "text": "We first provide the following lemma that converts the distance between probability measures to the distance between random variables.\nLemma 26. Let P,Q be two distributions defined on \u0398 such that W\u221e(P,Q) \u2264 \u2206 under a metric dist : \u0398\u00d7\u0398\u2192 R+. Let X \u223c P , there exists a random variable Y \u223c Q such that P[dist(X,Y ) \u2264 \u2206] = 1.\nThe proof of this lemma is deferred to the end of this section.\nProof of Theorem 2 Let x \u223c M\u0303(D), by Lemma 26 and the condition on W\u221e distance, there is a coupling \u03b6 such that random variable y \u223cM(D), (x, y) \u223c \u03b6, and dist(x, y) \u2264 \u2206 with probability 1 (with respect to \u03b6). The distribution of x is equivalent to the following two-step procedure\n(1) y \u223cM(D) (2) x \u223c \u03b6(\u00b7|y)\nThe second step can be further viewed as first sampling u \u223c Uniform([0, 1]) and then mapping u to x deterministically by a data-dependent function x = g(u) where g is completely determined by \u03b6(\u00b7|y) via the inverse integral transform. g depends on D and y through \u03b6.\nDefine query fu,y(D) = g\u03b6(u) \u2212 y and on a neighbor dataset D\u2032, fu,y(D\u2032) = g\u03b6\u2032(u) \u2212 y where \u03b6 \u2032 is the resulting coupling under D\u2032. With probability 1 under \u03b6, \u2225g\u03b6(u) \u2212 y\u2225 \u2264 \u2206. Similarly with probability 1, under \u03b6 \u2032, \u2225g\u03b6\u2032(u)\u2212 y\u2225 \u2264 \u2206. By a union bound, with probability 1 (under \u03b6(\u00b7|y)\u00d7 \u03b6 \u2032(\u00b7|y)), the global sensitivity of this query fu,y satisfies \u2225fu,y(D)\u2212 fu,y(D\u2032)\u2225 \u2264 \u2225g\u03b6(u)\u2212 y\u2225+ \u2225g\u03b6\u2032(u)\u2212 y\u2225 \u2264 2\u2206. Recall that ASAP returns x\u0303 = x+ Z = y + (x\u2212 y) + Z. In the above, x\u2212 y = fu,y(D). By choosing Z appropriately as the Gaussian mechanism (or Laplace mechanism) and the adaptive composition theorem (of GDP and pure-DP), we establish the two stated claims. \u25a0\nProof of Lemma 26 By the attainability of infimum for W\u221e stated in Lemma 22 and that W\u221e(P,Q) \u2264 \u2206, we know that there exists a joint distribution \u03b6(x, y), such that the marginals in x and y follow P and Q respectively, and that ess sup(x,y)\u2208(\u0398\u00d7\u0398,\u03b6) dist(x, y) = W\u221e(P,Q) \u2264 \u2206. For given X \u223c P , we define a conditional distribution \u03b6(\u00b7|x), then taking Y \u223c \u03b6(\u00b7|x) statisfies P[dist(X,Y ) \u2264 \u2206] = 1.\n\u25a0"
        },
        {
            "heading": "I PROOF OF THEOREM 3",
            "text": "Proof of Theorem 3 We divide the proof into three parts: privacy, accuracy, and computation. We first present the proof for pure DP case.\nPrivacy. The privacy analysis follows from the adaptive composition (Lemma 14) of output perturbation \u03b5-DP and ASAP (2\u03b5-DP, Theorem 2).\nAccuracy. Let the event E be the event \u03b8\u2217 \u2208 \u0398local. By Lemma 17 of (Chaudhuri et al., 2011), with probability greater than 1 \u2212 \u03c1, \u2225\u03b80 \u2212 \u03b8\u2217\u2225 \u2264 2dG log(d/\u03c1)\u03b1n\u03b5 , thus under the same high probability event \u03b8\u2217 \u2208 \u0398local, i.e., P(E) \u2265 1\u2212 \u03c1.\nDenote \u03b8\u0303 the output of MALA with constraint (Algorithm 1), and denote p\u2217 the exact posterior. Since W\u221e(p\u0303, p\n\u2217) \u2264 \u2206, applying Lemma 22, there exist a coupling of p\u0303 and p\u2217, denoted as \u03b6\u2217, such that ess sup(x,y)\u2208(\u0398\u00d7\u0398,\u03b6)\u2225x \u2212 y\u22251 \u2264 \u2206, thus ess sup(x,y)\u2208(\u0398\u00d7\u0398,\u03b6)\u2225x \u2212 y\u22252 \u2264 \u2206. Take \u03b8exact|\u03b8\u0303 \u223c \u03b6(\u00b7|\u03b8\u0303), then we know \u03b8exact \u223c p\u2217. We then divide the risk into three parts\nE [ L(\u03b8\u0302) ] \u2212 L(\u03b8\u2217) = E [ L(\u03b8\u0302)\u2212 L(\u03b8\u0303) ] + E [ L(\u03b8\u0303)\u2212 L(\u03b8exact) ] + (E [L(\u03b8exact)]\u2212 L(\u03b8\u2217)) . (3)\nFor the first part, note that \u03b8\u0302 = \u03b8\u0303 + Z, where Zi i.i.d.\u223c Lap(\u2206/\u03b5), i = 1, ..., d, thus we have that\nE [ \u2225\u03b8\u0302 \u2212 \u03b8\u0303\u22252 ] Jensen\u2019s inequality \u2264 \u221a E [ \u2225\u03b8\u0302 \u2212 \u03b8\u0303\u222522 ] = \u221a E [\u2211d\ni=1 Z2i\n] = \u221a 2d \u2206\n\u03b5\nWith the nG-Lipschitz continuity of L, we have E [ L(\u03b8\u0302)\u2212 L(\u03b8\u0303) ] \u2264 nGE [ \u2225\u03b8\u0302 \u2212 \u03b8\u0303\u22252 ] \u2264 \u221a 2dnG\u2206\n\u03b5 (4)\nWith the nG-Lipschitz continuity of L, the second part of the right-hand side of the equation (3) is bounded by E(\u03b8\u0303,\u03b8exact)\u223c\u03b6 [ L(\u03b8\u0303)\u2212 L(\u03b8exact) ] \u2264 nGE(\u03b8\u0303,\u03b8exact)\u223c\u03b6 [ \u2225\u03b8\u0303 \u2212 \u03b8exact\u22252 ] \u2264 nG\u2206, (5) which is dominated by (4).\nFor the third part of the right-hand side of the equation (3), we consider two cases:\n1. Under the event E. by Lemma 6, we have\nE[L(\u03b8exact)|E]\u2212 L(\u03b8\u2217) \u2264 d\n\u03b3 (6)\n2. Under the complementary event Ec. For simplicity, we set \u03c4 in Algorithm 4 to be sufficiently small and exclude this factor. Since \u03b80 \u2208 \u0398local, by Lemma 6, conditioned on \u03b80 we have\nE\u03b8\u0303|\u03b80 [L(\u03b8exact)|E c]\u2212 L(\u03b80) \u2264 E\u03b8\u0303|\u03b80 [L(\u03b8exact)|E c]\u2212min \u03b8\u2208\u0398 L(\u03b8) \u2264 d \u03b3 .\nTaking the expectation of \u03b80, we thus have\nE[L(\u03b8exact)|Ec]\u2212 E[L(\u03b80)] \u2264 d\n\u03b3 . (7)\nBy the n\u03b2-Lipschitz smooth of L and the first-order condition, we have E [L(\u03b80)]\u2212 L(\u03b8\u2217) \u2264 E [ n\u03b2\n2 \u2225\u03b80 \u2212 \u03b8\u2217\u222522\n] = 4G2\u03b2d2\nn\u03b12\u03b52 . (8)\nAdding (7) and (8), and plugging in \u03ba = \u03b2/\u03b1, we obtain that\nE[L(\u03b8exact)|Ec]\u2212 L(\u03b8\u2217) \u2264 d\n\u03b3 +\n4G2\u03bad2\nn\u03b1\u03b52 . (9)\nTherefore, adding (4), (5), and (6), as well as adding (4), (5), and (9), respectively, we obtain E [ L(\u03b8\u0302)|E ] \u2212 L(\u03b8\u2217) \u2264 \u221a 2dnG\u2206\n\u03b5 +\nd \u03b3 = O\n( d2G2 ln(d/\u03c1)\n\u03b1n\u03b52\n) , and (10)\nE [ L(\u03b8\u0302)|Ec ] \u2212 L(\u03b8\u2217) \u2264 \u221a 2dnG\u2206\n\u03b5 +\nd \u03b3 +\n4G2\u03bad2\nn\u03b1\u03b52 = O\n( d2G2 (ln(d/\u03c1) + \u03ba)\n\u03b1n\u03b52\n) , (11)\nwhere we instantiated our choice of \u03b3 = \u03b5GDiam(\u0398local) with Diam(\u0398local) = 2B = 2CdG log(d/\u03c1) \u03b1n\u03b5 , and\n\u2206 = dG log(d/\u03c1)2n2\u03b1\u03b5 \u2264 d\n3 2 G log(d/\u03c1)\n2n2\u03b1\u03b5 .\nWith (10) and (11), we have E [ L(\u03b8\u0302) ] \u2212 L(\u03b8\u2217) = P(E) \u00b7 E [ L(\u03b8\u0302)|E ] + (1\u2212 P(E)) \u00b7 E [ L(\u03b8\u0302)|Ec ] \u2212 L(\u03b8\u2217)\n\u2264 O ( d2G2 ln(d/\u03c1)\n\u03b1n\u03b52\n) + \u03c1 \u00b7 O ( d2G2 (ln(d/\u03c1) + \u03ba)\n\u03b1n\u03b52 ) = O ( d2G2 (ln d+ ln(1/\u03c1) + \u03c1\u03ba)\n\u03b1n\u03b52\n) .\nTaking \u03c1 = O (1/\u03ba), we obtain E [ L(\u03b8\u0302) ] \u2212 L(\u03b8\u2217) = O ( d2G2 (ln d+ ln\u03ba)\n\u03b1n\u03b52\n) .\nComputation. The optimization oracle (e.g., Newton\u2019s method or Gradient Descent) runs in O(n log n) time for getting a solution satisfying \u2225\u03b80 \u2212 \u03b8\u2217\u2225 \u2264 1/n2. For the samplying step, applying Corollary 10 with taking q = \u03c1, we obtain the computation complexity\nO ( nd (ln\u03ba+ \u03ba ln(d/\u03c1) + lnn)max { \u03ba3/2 \u221a d (\u03ba ln(d/\u03c1) + lnn), d\u03ba } ln 1\n\u03c1\n) ,\nwith probability 1\u2212 2\u03c1. Replacing \u03c1 by \u03c1/2 finishes the proof.\nGaussain DP case. The analysis of Gaussian DP closely parallels the proof of pure DP case except for the slight difference in the accuracy analysis. Here, we present a simplified proof for accuracy. Let the event E be the event \u03b8\u2217 \u2208 \u0398local. Applying the tail bound for chi-square distributions by Lemma 1 in (Laurent & Massart, 2000), with probability 1\u2212\u03c1, \u2225\u03b80\u2212 \u03b8\u2217\u2225 \u2264 \u221a 2G( \u221a d+ \u221a ln(1/\u03c1))\n\u03b1n\u00b5 , thus under the same high probability event \u03b8\u2217 \u2208 \u0398local. Under this event, by Lemma 6, we have that conditioned on an event E that happens with probability 1\u2212 \u03c1,\nE[L(\u03b8\u0302)|E]\u2212 L(\u03b8\u2217) \u2264 d \u03b3 +O\n(\u221a dnG\u2206\n\u00b5\n) = O ( dG2\n\u03b1n\u00b52\n) ,\nwhere we instantiated our choice of \u03b3 = \u00b5 2\u03b1n G2 , and \u2206 =\n\u221a dG\u221a\n2n2\u03b1\u00b5 .\nOn the other hand,\nE[L(\u03b8\u0302)|Ec]\u2212 L(\u03b8\u2217) \u2264 d \u03b3 + \u221a dnG\u2206\u221a 2\u00b5 + \u03baG2d \u03b1n\u00b52 = O\n( \u03badG2\n\u03b1n\u00b52\n) .\nTherefore, by combining the two cases, we have E[L(\u03b8\u0302)]\u2212 L(\u03b8\u2217) \u2264 O ( (1 + \u03c1\u03ba)dG2\n\u03b1n\u00b52\n) .\nTaking \u03c1 = O(1/\u03ba), we obtain that E[L(\u03b8\u0302)]\u2212 L(\u03b8\u2217) \u2264 O ( dG2\n\u03b1n\u00b52\n) .\n\u25a0"
        },
        {
            "heading": "J DEFERRED PROOFS OF THE SUPPORTING LEMMAS AND COROLLARIES",
            "text": "J.1 PROOF OF LEMMA 9 AND COROLLARY 20\nProof of Lemma 9 Denote \u03b8\u2217 as the minimizer of J on \u0398. Then\nZ = \u222b \u0398 e\u2212\u03b3J(\u03b8)d\u03b8 \u2264 e\u2212\u03b3J(\u03b8 \u2217) \u222b \u0398 d\u03b8 = e\u2212\u03b3J(\u03b8 \u2217) \u00b7 \u03c0 d/2(R/2)d \u0393(d/2 + 1) .\nOn the other hand, by the Lipschitz continuity assumption, J(\u03b8)\u2212 J(\u03b8\u2217) \u2264 G \u00b7 \u2225\u03b8 \u2212 \u03b8\u2217\u2225 \u2264 GR. Hence\n1 Z e\u2212\u03b3J(\u03b8) \u2265 e\u2212\u03b3GR \u00b7 \u0393(d/2 + 1) \u03c0d/2(R/2)d .\nIf J instead satisfies the \u03b2-Lipschitz smoothness and convextiy assumptions, then for all \u03b8\u0303 \u2208 \u0398\nJ(\u03b8)\u2212 J(\u03b8\u2217) = J(\u03b8)\u2212 J(\u03b8\u0303) + J(\u03b8\u0303)\u2212 J(\u03b8\u2217)\n\u2264 \u27e8J(\u03b8\u0303), \u03b8 \u2212 \u03b8\u0303\u27e9+ \u03b2 2 \u2225\u03b8 \u2212 \u03b8\u0303\u22252 \u2212 \u27e8\u2207J(\u03b8\u0303), \u03b8\u2217 \u2212 \u03b8\u0303\u27e9 = \u27e8J(\u03b8\u0303), \u03b8 \u2212 \u03b8\u2217\u27e9+ \u03b2 2 \u2225\u03b8 \u2212 \u03b8\u0303\u22252 \u2264 \u2225J(\u03b8\u0303)\u2225R+ 1 2 \u03b2R2\nHence\ninf \u03b8\u2208\u0398\np(\u03b8) \u2265 e\u2212\u03b3(R\u2225\u2207J(\u03b8\u0303)\u2225+\u03b2R 2/2) \u00b7\n\u0393(d2 + 1)\n\u03c0d/2(R/2)d , \u2200\u03b2\u0303 \u2208 \u0398.\nFurthermore, if \u03b8\u2217 is the global minimizer, i.e.,\u2207J(\u03b8\u2217) = 0, then\ninf \u03b8\u2208\u0398\np(\u03b8) \u2265 e\u2212\u03b3\u03b2R 2/2 \u00b7\n\u0393(d2 + 1)\n\u03c0d/2(R/2)d , \u2200\u03b8\u0303 \u2208 \u0398.\n\u25a0 Proof of Corollary 20 It suffices to invoke Lemma 9 by setting J(\u03b8) := \u2211n\ni=1 \u2113i(\u03b8) + \u03bb 2 \u2225\u03b8 \u2212 \u03b80\u2225 2 and \u0398 := {\u03b8|\u2225\u03b8 \u2212 \u03b80\u2225 \u2264 B}, notice that the diameter of \u0398 is 2B. \u25a0\nJ.2 PROOF OF LEMMA 18 AND LEMMA 19 Proof of Lemma 18 By the \u03b1-strong convexity of LD and first-order optimality conditions for \u03b8\u2217(D)\nLD(\u03b8\u2217(D\u2032)) \u2265 LD(\u03b8\u2217(D)) + \u27e8\u03b8\u2217(D\u2032)\u2212 \u03b8\u2217(D),\u2207LD(\u03b8\u2217(D))\u27e9+ \u03b1n\n2 \u2225\u03b8\u2217(D)\u2212 \u03b8\u2217(D\u2032)\u22252\n\u2265 LD(\u03b8\u2217(D)) + \u03b1n\n2 \u2225\u03b8\u2217(D)\u2212 \u03b8\u2217(D\u2032)\u22252.\nOn the other side, by the \u03b1-strong convexity of LD\u2032 and first-order optimality conditions for \u03b8\u2217(D\u2032)\nLD\u2032(\u03b8\u2217(D)) \u2265 LD\u2032(\u03b8\u2217(D\u2032)) + \u27e8\u03b8\u2217(D)\u2212 \u03b8\u2217(D\u2032),\u2207LD\u2032(\u03b8\u2217(D\u2032))\u27e9+ \u03b1n\n2 \u2225\u03b8\u2217(D\u2032)\u2212 \u03b8\u2217(D)\u22252\n\u2265 LD\u2032(\u03b8\u2217(D\u2032)) + \u03b1n\n2 \u2225\u03b8\u2217(D)\u2212 \u03b8\u2217(D\u2032)\u22252.\nAdd the two inequalities we get\n\u03b1n\u2225\u03b8\u2217(D)\u2212 \u03b8\u2217(D\u2032)\u22252 \u2264 LD(\u03b8\u2217(D\u2032))\u2212 LD\u2032(\u03b8\u2217(D\u2032)) + LD\u2032(\u03b8\u2217(D))\u2212 LD(\u03b8\u2217(D)) \u2264 |\u2113x(\u03b8\u2217(D\u2032))\u2212 \u2113x(\u03b8\u2217(D))| \u2264 G\u2225\u03b8\u2217(D)\u2212 \u03b8\u2217(D\u2032)\u2225.\nThe proof is complete by dividing both sides by \u2225\u03b8\u2217(D)\u2212 \u03b8\u2217(D\u2032)\u2225. \u25a0\nProof of Lemma 19 It suffices to show the sensitivity of \u03b8\u0303(D) is bounded by \u2206\u0303. Applying Lemma 18,the sensitivity of \u03b8\u0303(D) is bounded by\nmax D\u2243D\u2032 ||\u03b8\u0303(D)\u2212 \u03b8\u0303(D\u2032)||2 = max D\u2243D\u2032 ||\u03b8\u0303(D)\u2212 \u03b8\u2217(D) + \u03b8\u2217(D)\u2212 \u03b8\u2217(D\u2032) + \u03b8\u2217(D\u2032)\u2212 \u03b8\u0303(D\u2032)||2\n\u2264 ||\u03b8\u0303(D)\u2212 \u03b8\u2217(D)||2 + max D\u2243D\u2032 ||\u03b8\u2217(D)\u2212 \u03b8\u2217(D\u2032)||2 + ||\u03b8\u2217(D\u2032)\u2212 \u03b8\u0303(D\u2032)||2\n\u2264 2\u03c4 n + 2G \u03b1n = \u2206\u0303.\n\u25a0\nJ.3 PROOF OF LEMMA 14\nProof of Lemma 14 First, observe that pure-DP (with any \u03b5 <\u221e) by definition implies absolute continuity. Let \u00b5, \u03bd be the two measures induced by a pure-DP mechanism on dataset D,D\u2032 respectively. DP implies that for any measurable set S, \u00b5(S) \u2264 e\u03b5\u03bd(S). This inequality implies that if \u03bd(S) = 0 then \u00b5(S) = 0, which verifies the definition of absolute continuity, i.e., \u00b5\u226a \u03bd.\nBy our assumption, M1 satisfies DP, thus PM1(D) absolutely continuous w.r.t. PM1(D\u2032). Similarly, M2(o1, D) satisfies DP for all o1 except when o1 belongs to a measure 0 set, thus with probability 1, PM2(O1,D) is absolutely continuous w.r.t. PM2(O1,D\u2032). It follows that the \u201cdensity\u201d function (technically, Radon-Nikodym derivative) dPM1(D)dPM1(D\u2032) exists and dPM2(O1,D)dPM2(O1,D\u2032) exists almost surely. In addition, by taking S = { dPM1(D)dPM1(D\u2032) > e \u03b5} the DP definition, by a proof by contradiction1, we have\nPO1\u223cM1(D\u2032)[ dPM1(D) dPM1(D\u2032) (O1) \u2264 e\u03b51 ] = 1 (12)\nand\nPO2\u223cM2(o1,D\u2032)[ dPM2(o1,D) dPM2(o1,D\u2032) (O2) \u2264 e\u03b52 ] = 1 (13)\nalmost surely under o1 \u223cM1(D\u2032).\nLet O1 \u223cM1(D) and O2 \u223cM2(O1, D). Similarly, let O\u03031 \u223cM1(D\u2032) and O\u03032 \u223cM2(O\u03032, D\u2032). Consider any measurable set S \u2282 \u03981 \u00d7\u03982, by the Lebesgue integral\nP[(O1, O2) \u2208 S]\n= \u222b \u222b 1((u1, u2) \u2208 S)dPM2(u1,D)(u2)dPM1(D)(u1)\n= \u222b \u222b 1((u1, u2) \u2208 S)\ndPM2(u1,D) dPM2(u1,D\u2032) (u2) \u00b7 dPM2(u1,D\u2032)(u2) \u00b7 dPM1(D) dPM1(D\u2032) (u1) \u00b7 dPM1(D\u2032)(u1)\n\u2264 \u222b \u222b\n1((u1, u2) \u2208 S)e\u03b52 \u00b7 dPM2(u1,D\u2032)(u2) \u00b7 e \u03b51 \u00b7 dPM1(D\u2032)(u1)\n=e\u03b51+\u03b52P[(O\u03031, O\u03032) \u2208 S].\nThe inequality above follows from equation 12 and equation 13.\nFor Gaussian DP, let P1 and Q1 be the probability measures of M1(D) and M1(D\u2032) respectively, and P2(\u00b7|x = o) and Q2(\u00b7|x = o) be the probability measures of M2(o,D) and M2(o,D\u2032) respectively. Let P and Q be the probability measures of M(D) and M(D\u2032).\nWe first show that P is absolutely continuous w.r.t Q. Noting that by the definition of Gaussian DP and Hockeystick divergence, P1 is absolutely continuous w.r.t. Q1 and P2(\u00b7|x = o) is continuous w.r.t. Q2(\u00b7|x = o) with\n1Assume S is not measure 0. By definition of DP P[M1(D\u2032) \u2208 S] \u2264 e\u03b5P[M1(D\u2032) \u2208 S] which contradicts with the definition of S unless S has measure 0.\nprobability 1. Then, for arbitrary Q-measureable set A, we have that\nP (A) = \u222b \u222b 1{(x, y) \u2208 A}dP (x, y)\n= \u222b \u222b 1{(x, y) \u2208 A}dP2(y|x)dP1(x)\n= \u222b \u222b 1{(x, y) \u2208 A}dP2(y|x)dP1(x)\n= \u222b \u222b 1{(x, y) \u2208 A} dP2\ndQ2 (y|x)dQ2(y|x) dP1 dQ1 (x)dQ1(x)\n= \u222b \u222b 1{(x, y) \u2208 A} dP2\ndQ2 (y|x) dP1 dQ1 (x)dQ(x, y)\nSo Q(A) = 0 implies P (A) = 0, thus P is absolutely continuous w.r.t Q. Moreover, from the above equity, we know that the Radon-Nikodym derivative dPdQ (x, y) = dP2 dQ2 (y|x) \u00b7 dP1dQ1 (x).\nSince P is absolutely continuous w.r.t Q, their Hockey-stick distance can be defined. We then have for \u03b1 > 0,\nH\u03b1(M(D)\u2225M(D\u2032)) = H\u03b1(P\u2225Q)\n=\n\u222b \u222b [ dP\ndQ (x, y)\u2212 \u03b1 ] + dQ(x, y)\n= \u222b \u222b 1 { dP\ndQ (x, y) \u2265 \u03b1\n}( dP\ndQ (x, y)\u2212 \u03b1\n) dQ(x, y)\n= \u222b \u222b 1 { dP2 dQ2 (y|x) \u00b7 dP1 dQ1 (x) \u2265 \u03b1 }( dP2 dQ2 (y|x) \u00b7 dP1 dQ1 (x)\u2212 \u03b1 ) dQ2(y|x)dQ1(x)\n= \u222b \u222b 1 { dP2 dQ2 (y|x) \u00b7 dP1 dQ1 (x) \u2265 \u03b1 } 1 { dP1 dQ1 (x) > 0 }( dP2 dQ2 (y|x) \u00b7 dP1 dQ1 (x)\u2212 \u03b1 ) dQ2(y|x)dQ1(x)\n= \u222b \u222b 1 { dP2 dQ2 (y|x) \u00b7 dP1 dQ1 (x) \u2265 \u03b1 ( dP1 dQ1 (x) )\u22121}( dP2 dQ2 (y|x)\u2212 \u03b1 ( dP1 dQ1 (x) )\u22121) dQ2(y|x)\n\u00b7 1 { dP1 dQ1 (x) > 0 } dP1 dQ1 (x)dQ1(x)\n= \u222b H\n\u03b1 (\ndP1 dQ1\n(x) )\u22121 (dP2(\u00b7|x)\u2225dQ2(\u00b7|x))1 { dP1 dQ1 (x) > 0 } dP1 dQ1 (x)dQ1(x)\n\u2264 \u222b\nH \u03b1 (\ndP1 dQ1\n(x) )\u22121 (N (0, 1)\u2225N (\u00b52, 1))1 { dP1 dQ1 (x) > 0 } dP1 dQ1 (x)dQ1(x)\n=\n\u222b \u222b [ dPN (0,1)\ndPN (\u00b52,1) (z)\u2212 \u03b1 ( dP1 dQ1 (x) )\u22121] + dPN (\u00b52,1)(z) 1 { dP1 dQ1 (x) > 0 } dP1 dQ1 (x)dQ1(x)\n=\n\u222b \u222b [ dPN (0,1)\ndPN (\u00b52,1) (z) dP1 dQ1 (x)\u2212 \u03b1 ] + dPN (\u00b52,1)(z)dQ1(x)\n= H\u03b1 (P1 \u00d7N(0, 1) \u2225 Q1 \u00d7N (\u00b52, 1))\nContinuing this argument, we have\nH\u03b1 (P1 \u00d7N(0, 1) \u2225 Q1 \u00d7N (\u00b52, 1))\n= \u222b \u222b [ dP1 dQ1 (x)\u2212 \u03b1 \u00b7 dPN (\u00b52,1) dPN (0,1) (z) ] + dPN (0,1) dPN (\u00b52,1) (z)dQ1(x)dPN (\u00b52,1)(z)\n= \u222b H\n\u03b1\u00b7 dPN(\u00b52,1) dPN(0,1)\n(z) (P1\u2225Q1)\ndPN (0,1)\ndPN (\u00b52,1) (z)dPN (\u00b52,1)(z) \u2264 \u222b\nH \u03b1\u00b7\ndPN(\u00b52,1) dPN(0,1)\n(z) (N (0, 1)\u2225N (\u00b51, 1))\ndPN (0,1)\ndPN (\u00b52,1) (z)dPN (\u00b52,1)(z)\n=\n\u222b \u222b [ dPN (0,1)\ndPN (\u00b51,1) (w)\u2212 \u03b1 \u00b7\ndPN (\u00b52,1)\ndPN (0,1) (z) ] + dPN (0,1) dPN (\u00b52,1) (z)dPN (\u00b51,1)(w)dPN (\u00b52,1)(z)\n=\n\u222b \u222b [ dPN (0,1)\ndPN (\u00b51,1) (w)\ndPN (0,1)\ndPN (\u00b52,1) (z)\u2212 \u03b1 ] + dPN (\u00b51,1)(w)dPN (\u00b52,1)(z)\n= H\u03b1 (N (0, 1)\u00d7N(0, 1) \u2225 N (\u00b51, 1)\u00d7N (\u00b52, 1))\nBy taking s = (\u00b51w + \u00b52z)/ \u221a \u00b521 + \u00b5 2 2, t = (\u00b51w \u2212 \u00b52z)/ \u221a \u00b521 + \u00b5 2 2, we have,\nH\u03b1 (N (0, 1)\u00d7N(0, 1) \u2225 N (\u00b51, 1)\u00d7N (\u00b52, 1))\n=\n\u222b \u222b [ exp(\u2212(w2 + z2))\nexp(\u2212((w \u2212 \u00b51)2 + (z \u2212 \u00b52)2)) \u2212 \u03b1 ] + 1 2\u03c0 exp(\u2212((w \u2212 \u00b51)2 + (z \u2212 \u00b52)2))dwdz\n= \u222b \u222b [ exp(\u22122(\u00b51w + \u00b52z) + \u00b521 + \u00b522)\u2212 \u03b1 ] + 1 2\u03c0 exp(\u2212(w2 + z2 \u2212 2(\u00b51w + \u00b52z) + \u00b521 + \u00b522))dwdz\n= \u222b \u222b [ exp(\u22122s \u221a \u00b521 + \u00b5 2 2 + \u00b5 2 1 + \u00b5 2 2)\u2212 \u03b1 ] + 1 2\u03c0 exp(\u2212(s2 + t2 \u2212 2s \u221a \u00b521 + \u00b5 2 2 + \u00b5 2 1 + \u00b5 2 2))dtds\n= \u222b \u222b [ exp(\u22122s \u221a \u00b521 + \u00b5 2 2 + \u00b5 2 1 + \u00b5 2 2)\u2212 \u03b1 ] + 1\u221a 2\u03c0 exp(\u2212(s2 \u2212 2s \u221a \u00b521 + \u00b5 2 2 + \u00b5 2 1 + \u00b5 2 2))ds\n= H\u03b1\n( N (0, 1) \u2225 N ( \u221a \u00b521 + \u00b5 2 2, 1) ) The proof is completed. \u25a0\nJ.4 PROOF OF LEMMA 5\nProof of Lemma 5 (Dong et al., 2020) showed that exponential sampling with utility function q(D, \u03b8) that satisfies a property called bounded range is differentially private even if the sensitivity is not bounded (unlike the original exponential mechanism).\nrange(q) := sup D,D\u2032are neighbors (max \u03b8\u2208\u0398 \u2212min \u03b8\u2208\u0398 )[q(D, \u03b8)\u2212 q(D\u2032, \u03b8)].\nIn our problem, q is the (regularized) sum of loss functions, and the difference in q between two neighbor datasets created by adding or removing a datapoint is simply the loss of one data point. q(D, \u03b8)\u2212 q(D\u2032, \u03b8) = \u00b1\u2113(\u03b8). It is easy to see that the range(q) \u2264 GDiam(\u0398). By (Dong et al., 2020), we get that choosing \u03b3 \u2264 \u03b5GDiam(\u0398) gives \u03b5-DP. \u25a0\nJ.5 PROOF OF LEMMA 15 Proof Denote f\u03b5,0(x) = max{0, 1\u2212 e\u03b5x, e\u2212\u03b5(1\u2212 x)}, for 0 \u2264 x \u2264 1, and\nG\u00b5(x) = \u03a6 ( \u03a6\u22121(1\u2212 x)\u2212 \u00b5 ) , for 0 \u2264 x \u2264 1.\nBy Definition 3, Proposition 3 and Definition 4 of Dong et al. (2022), it suffices to show that\nf\u03b5,0(x) \u2265 G\u00b5(x), for all 0 \u2264 x \u2264 1. By the concavity of G\u00b5 and the piece-wise linearity of f\u03b5,0, it suffices to show that G\u00b5(x0) \u2264 f\u03b5,0(x0), with x0 = 1 1+e\u03b5 satisfying 1\u2212e \u03b5x0 = e \u2212\u03b5(1\u2212x0) = x0. Taking \u00b5 = 2\u03a6\u22121 ( e\u03b5 1+e\u03b5 ) , we have G\u00b5(x0) = f\u03b5,0(x0), which finishes the proof. \u25a0\nJ.6 PROOF OF LEMMA 22 Proof of Lemma 22 Denote \u2225dist(\u00b7, \u00b7)\u2225L\u221e(\u03982,\u03b6) = ess sup(x,y)\u2208(\u0398\u00d7\u0398,\u03b6) dist(x, y).\nTo prove the lemma, it suffices to show these two inequalities both hold:\ninf \u03b6\u2208\u0393(P,Q) ess sup (x,y)\u2208(\u0398\u00d7\u0398,\u03b6)\ndist(x, y) \u2264 inf{\u03b1 > 0 : P (U) \u2264 Q(U\u03b1), \u2200 open U \u2282 \u0398} (14)\ninf \u03b6\u2208\u0393(P,Q) ess sup (x,y)\u2208(\u0398\u00d7\u0398,\u03b6)\ndist(x, y) \u2265 inf{\u03b1 > 0 : P (U) \u2264 Q(U\u03b1), \u2200 open U \u2282 \u0398} (15)\nFor the sake of clarity, we denote\nWLHS = inf \u03b6\u2208\u0393(P,Q) ess sup (x,y)\u2208(\u0398\u00d7\u0398,\u03b6) dist(x, y) = inf \u03b6\u2208\u0393(P,Q) \u2225dist(\u00b7, \u00b7)\u2225L\u221e(\u03982,\u03b6), and\nWRHS = inf{\u03b1 > 0 : P (U) \u2264 Q(U\u03b1), \u2200 open U \u2282 \u0398}.\nWe first prove (14). To prove (14), it suffices to show that for any \u03b1 > WRHS, the relationship \u03b1 \u2265 WLHS inherently holds.\nIn particular, we leverage the following Strassen\u2019s theorem and prove that both constants \u03b2 and \u03b5 can be driven to zero.\nLemma 27 (Strassen\u2019s Theorem, Strassen (1965)). Suppose that (\u0398,dist) is a separable metric space and \u03b1, \u03b2 > 0. Suppose the laws P and Q are such that, for all open sets U \u2282 \u0398,\nP (U) \u2264 Q(U\u03b1) + \u03b2 where U\u03b1 = {x \u2208 \u0398 : dist(x, U) \u2264 \u03b1}. Then for any \u03b5 > 0 there exist a law \u03b6 on \u0398\u00d7\u0398 with marginals P and Q, such that\n\u03b6(dist(x, y) > \u03b1+ \u03b5) \u2264 \u03b2 + \u03b5. (16)\nTake an arbitrary \u03b1 > WRHS. Our goal is to prove \u03b1 \u2265WLHS. By the definition of infimum, we have P (U) \u2264 Q(U\u03b1), \u2200 open U \u2282 \u0398,\nFor arbitrary \u03b2, \u03b5, by Strassen\u2019s theorem, (plugging in (16)) there exist \u03b6\u03b2,\u03b5 \u2208 \u0393(P,Q) such that \u03b6\u03b2,\u03b5 (dist(x, y) > \u03b1+ \u03b5) \u2264 \u03b2 + \u03b5.\nWe are going to choose \u03b2, \u03b5 to be sufficiently small (both go to zero) and take the limits using Prohorov\u2019s Theorem and Portmanteau theorem.\nTaking \u03b2 = \u03b5 = 1n , by Strassen\u2019s theorem, there exists \u03b6n \u2208 \u0393(P,Q) such that\n\u03b6n\n( dist(x, y) > \u03b1+ 1\nn\n) \u2264 2\nn .\nSince P,Q are tight, for any \u03f5 > 0, there exists two compact sets K1,K2 \u2282 \u0398, such that\nP (\u0398 \\K1) \u2264 \u03f5, Q(\u0398 \\K2) \u2264 \u03f5\nNote that \u03b6n \u2208 \u0393(P,Q), we have (since 1{(x, y) /\u2208 K1 \u00d7K2} \u2264 1{x /\u2208 K1}+ 1{y /\u2208 K2})\n\u03b6n ((\u0398\u00d7\u0398) \\ (K1 \u00d7K2)) \u2264 \u03b6n ((\u0398 \\K1)\u00d7\u0398) + \u03b6n (\u0398\u00d7 (\u0398 \\K2)) \u2264 2\u03f5\nthus {\u03b6n}\u221en=1 is a tight sequence of probability measures.\nSince {\u03b6n}\u221en=1 is tight, by Prohorov\u2019s Theorem, there exists a weakly convergent subsequence \u03b6n(k) \u21d2 \u03b6. We have \u03b6 \u2208 \u0393(P,Q) because \u03b6(A \u00d7 \u0398) = limk\u2192\u221e \u03b6n(k)(A \u00d7 \u0398) = P (A), and that \u03b6(\u0398 \u00d7 A) = limk\u2192\u221e \u03b6n(k)(\u0398\u00d7A) = Q(A).\nFor arbitrary \u03b4 > 0, the set {(x, y) \u2208 \u0398\u00d7\u0398 : dist(x, y) > \u03b1+\u03b4} is a open set in \u0398\u00d7\u0398. By the Portmanteau Theorem,\n\u03b6 (dist(x, y) > \u03b1+ \u03b4) \u2264 lim inf k\u2192\u221e \u03b6n(k) (dist(x, y) > \u03b1+ \u03b4)\n\u2264 lim inf k\u2192\u221e \u03b6n(k)\n( dist(x, y) > \u03b1+ 1\nn(k) ) \u2264 lim inf\nk\u2192\u221e\n( 2\nn(k)\n) = 0,\nwhere the first inequality is by Portmanteau Theorem. The second inequality holds because there exist k0 such that \u03b4 > 1n(k0) . The third inequality holds due to the construction of \u03b6n.\nSince \u03b4 is arbitrary, (taking \u03b4 = 1n and by Fatou\u2019s Lemma,) we have that\n\u03b6 (dist(x, y) > \u03b1) = 0. (17)\nTherefore, \u03b1 \u2265 ess sup(x,y)\u2208(\u0398\u00d7\u0398,\u03b6) dist(x, y) = WLHS. Thus (14) is proved.\nNext, we show that (15) holds. Similarly, to prove (14), it suffices to show that for any t > WLHS, the relationship t \u2265WRHS inherently holds.\nTake an arbitrary t > WLHS, our goal is then to prove that t \u2265 WRHS. By the definition of infimum, there exists a \u03b6 \u2208 \u0393(P,Q), such that\ness sup (x,y)\u2208(\u0398\u00d7\u0398,\u03b6) dist(x, y) < t.\nTherefore, \u03b6 ( {(x, y) \u2208 \u03982 : dist(x, y) > t} ) = 0, which translate into\u222b\n1{dist(x, y) > t}d\u03b6(x, y) = 0. (18)\nThus, we obtain that\nQ(U t) = Q ({y \u2208 \u0398 : dist(y, U) \u2264 t})\n= \u222b 1{x \u2208 \u0398}1{dist(y, U) \u2264 t}d\u03b6(x, y)\n\u2265 \u222b 1{x \u2208 U}1{dist(y, U) \u2264 t}d\u03b6(x, y)\n= \u222b 1{x \u2208 U}1{y \u2208 \u0398}d\u03b6(x, y)\u2212 \u222b 1{x \u2208 U}1{dist(y, U) > t}d\u03b6(x, y)\n(If x \u2208 U and dist(y, U) > t, then dist(x, y) > t.) \u2265 \u222b 1{x \u2208 U}1{y \u2208 \u0398}d\u03b6(x, y)\u2212 \u222b 1{dist(x, y) > t}d\u03b6(x, y) (Plug in (18))\n= \u222b 1{x \u2208 U}1{y \u2208 \u0398}d\u03b6(x, y)\n= P (U).\nSince Q(U t) \u2265 P (U), we have\nt \u2208 {r > 0 : P (U) \u2264 Q(Ur),\u2200 open U \u2282 \u0398}.\nThus t \u2265 inf{\u03b1 > 0 : P (U) \u2264 Q(U\u03b1), \u2200 open U \u2282 \u0398} = WRHS.\nTherefore, (15) holds.\nSince (14) and (15) hold, we have\ninf \u03b6\u2208\u0393(P,Q) ess sup (x,y)\u2208(\u0398\u00d7\u0398,\u03b6)\ndist(x, y) = inf{\u03b1 > 0 : P (U) \u2264 Q(U\u03b1), \u2200 open U \u2282 \u0398},\nwhich demonstrates the equivalence of the two definitions.\nWe now prove the attainability of the infimum in Definition 7 by repeating the above construction of \u03b6 in the first part of our proof. We provide a simplified proof as follows.\nThe above construction of \u03b6 before (17) tells us that for an arbitrary \u03b1 > W\u221e(P,Q), there exists a \u03b6 \u2208 \u0393(P,Q) such that \u03b6 (dist(x, y) > \u03b1) = 0. Taking \u03b1m = W\u221e(P,Q) + 1m , there exists a sequence {\u03b6m} \u2282 \u0393(P,Q) such that \u03b6m ( dist(x, y) > \u03b1+ 1m ) = 0. Since {\u03b6m} \u2282 \u0393(P,Q), likewise, we obtain that {\u03b6m} is tight. By Prohorov\u2019s Theorem, there exists a weakly convergent subsequence \u03b6m(k) \u21d2 \u03b6\u2217. Similarly, \u03b6\u2217 \u2208 \u0393(P,Q). By the same token, for arbitrary \u03b4 > 0, we have\n\u03b6\u2217 (dist(x, y) > W\u221e(P,Q) + \u03b4) \u2264 lim inf k\u2192\u221e \u03b6m(k) (dist(x, y) > W\u221e(P,Q) + \u03b4)\n\u2264 lim inf k\u2192\u221e \u03b6m(k)\n( dist(x, y) > W\u221e(P,Q) + 1\nm(k) ) = 0,\nwhere the first inequality is by the Portmanteau Theorem. The second inequality holds because there exist k0 such that \u03b4 > 1m(k0) . The third inequality holds due to the construction of \u03b6m.\nSince \u03b4 is arbitrary, (taking \u03b4 = 1n and by Fatou\u2019s Lemma,) we have that\n\u03b6\u2217 (dist(x, y) > W\u221e(P,Q)) = 0.\nThat is, \u03b6\u2217 (dist(x, y) \u2264W\u221e(P,Q)) = 1.\nTherefore, W\u221e(P,Q) \u2265 ess sup\n(x,y)\u2208(\u0398\u00d7\u0398,\u03b6\u2217) dist(x, y).\nOn the other hand, by the definition of W\u221e, since \u03b6\u2217 \u2208 \u0393(P,Q), we have\nW\u221e(P,Q) \u2264 inf \u03b6\u2208\u0393(P,Q) ess sup (x,y)\u2208(\u0398\u00d7\u0398,\u03b6) dist(x, y) \u2264 ess sup (x,y)\u2208(\u0398\u00d7\u0398,\u03b6\u2217) dist(x, y).\nTherefore, W\u221e(P,Q) = ess sup(x,y)\u2208(\u0398\u00d7\u0398,\u03b6\u2217) dist(x, y), for \u03b6 \u2217 \u2208 \u0393(P,Q), which proves the attainability of the infimum in the definition of W\u221e. \u25a0"
        },
        {
            "heading": "K FACTS ABOUT NOISY GRADIENT DESCENT",
            "text": "Noisy gradient descent is an alternative algorithm that can be used to obtain pure-DP or pure-Gaussian DP under the same assumptions we have. While it uses full batch gradients, its analysis relies on the theory of stochastic gradient descent since the full gradients in each iteration are perturbed by either the Laplace mechanism or the Gaussian mechanism. We explicitly write out the guarantees of noisy gradient descent in this section so as to substantiate our discussion related to our computational guarantee of localized-ASAP with MALA. We focus the discussion on Gaussian DP in the \u03b1n-strongly convex setting.\nTheorem 4 (Noisy Gradient Descent for Lipschitz and strongly Convex Losses). Assume the loss function \u2113(\u03b8, (x, y)) is G-Lipschitz for any data point (x, y). Assume \u2211 i \u2113i(\u03b8) is \u03b1n-strongly convex on \u0398. Consider the following (projected) noisy gradient descent algorithm that initializes at \u03b80 and update the parameter by T rounds using\n\u03b8t = Proj\u0398(\u03b8t\u22121 \u2212 \u03b7t( n\u2211\ni=1\n\u2207\u2113i(\u03b8t\u22121) +N (0, TG2\n2\u00b52 Id)))\nwith \u03b7t = 1\u03bbt . Let \u03b8 \u2217 \u03bb be the minimizer of the regularized ERM problem and \u03b8 \u2217 to be the minimizer of the unregularized ERM problem.\n1. This algorithm that releases the whole trajectory \u03b81, ..., \u03b8T satisfies satisfies \u00b5-GDP.\n2. It also satisfies that\nE [ L ( T\u2211\nt=1\n2t\nT (T + 1) \u03b8t\n)] \u2212 L(\u03b8\u2217\u03bb) \u2264 4n2G2\n\u03b1n(T + 1) +\ndG2\n2\u03b1n\u00b52 .\n3. If T \u2265 8n 2\u00b52 d , then it achieves an excess empirical risk of dG2 \u03b1n\u00b52 .\nProof Observe that the G-Lipschitz loss says that the global sensitivity of the gradient is G. The privacy analysis follows from the composition of Gaussian mechanism via Gaussian DP for T rounds (Dong et al., 2022). This releases the entire sequence of parameters. The weighted average of the parameters over time is post-processing. The second statement follows from Section 3.2 of (Lacoste-Julien et al., 2012) by choosing the noise level and other parameters appropriately. The last statement is corollary by choosing T to be large. \u25a0\nIn the above, the excess empirical risk achieves the optimal rates but requires the algorithm to run for O(n2) iterations. In the smooth case, one can obtain faster convergence but at the cost of the resulting excess empirical risk.\nTheorem 5 (Noisy Gradient Descent for smooth and strongly convex Losses). Consider the same algorithm and assume all assumptions from Theorem 4. In addition, assume individual loss functions \u2113x are \u03b2-smooth.\n1. This algorithm that releases the whole trajectory \u03b81, ..., \u03b8T satisfies satisfies \u00b5-GDP.\n2. Choose a constant learning rate \u03b7 \u2264 1n\u03b2 , run for T iterations\nE [L (\u03b8T )]\u2212 L(\u03b8\u2217\u03bb) \u2264 n\u03b2 2 (1\u2212 \u03b7\u03b1n)TDiam(\u0398)2 + \u03b7n\u03b2dTG\n2\nn\u03b1\u00b52\n3. Choose \u03b7 = 1/(n\u03b2) and T = O(\u03b2\u03b1 log n), the excess risk is\nE [L (\u03b8T )]\u2212 L(\u03b8\u2217\u03bb) \u2264 O( \u03b2dG2 log n\nn\u03b12\u00b52 ).\nProof From Theorem 5.7 of (Garrigos & Gower, 2023) we can derive the convergence in various regimes. \u25a0\nIt is not hard to see that there isn\u2019t a good choice of the learning rate parameter \u03b7 based on the bound above that can get rid of the additional \u03b2 logn\u03b1 factor."
        }
    ],
    "year": 2023
}