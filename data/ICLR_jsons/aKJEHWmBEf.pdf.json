{
    "abstractText": "Integrating a notion of symmetry into point cloud neural networks is a provably effective way to improve their generalization capability. Of particular interest are E(3) equivariant point cloud networks where Euclidean transformations applied to the inputs are preserved in the outputs. Recent efforts aim to extend networks that are equivariant with respect to a single global E(3) transformation, to accommodate inputs made of multiple parts, each of which exhibits local E(3) symmetry. In practical settings, however, the partitioning into individually transforming regions is unknown a priori. Errors in the partition prediction would unavoidably map to errors in respecting the true input symmetry. Past works have proposed different ways to predict the partition, which may exhibit uncontrolled errors in their ability to maintain equivariance to the actual partition. To this end, we introduce APEN: a general framework for constructing approximate piecewise-E(3) equivariant point networks. Our framework offers an adaptable design to guaranteed bounds on the resulting piecewise E(3) equivariance approximation errors. Our primary insight is that functions which are equivariant with respect to a finer partition (compared to the unknown true partition) will also maintain equivariance in relation to the true partition. Leveraging this observation, we propose a compositional design for a partition prediction model. It initiates with a fine partition and incrementally transitions towards a coarser subpartition of the true one, consistently maintaining piecewise equivariance in relation to the current partition. As a result, the equivariance approximation error can be bounded solely in terms of (i) uncertainty quantification of the partition prediction, and (ii) bounds on the probability of failing to suggest a proper subpartition of the ground truth one. We demonstrate the practical effectiveness of APEN using two data types exemplifying part-based symmetry: (i) real-world scans of room scenes containing multiple furniture-type objects; and, (ii) human motions, characterized by articulated parts exhibiting rigid movement. Our empirical results demonstrate the advantage of integrating piecewise E(3) symmetry into network design, showing a distinct improvement in generalization over prior works in terms of generalization accuracy for both classification and segmentation tasks.",
    "authors": [],
    "id": "SP:753bf65382d6ee94d17bbcf24612d2722b7789fb",
    "references": [
        {
            "authors": [
                "Ijaz Akhter",
                "Michael J Black"
            ],
            "title": "Pose-conditioned joint angle limits for 3d human pose reconstruction",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2015
        },
        {
            "authors": [
                "Cem Anil",
                "James Lucas",
                "Roger Grosse"
            ],
            "title": "Sorting out lipschitz function approximation",
            "venue": "In International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "Serge Assaad",
                "Carlton Downey",
                "Rami Al-Rfou",
                "Nigamaa Nayakanti",
                "Ben Sapp"
            ],
            "title": "Vn-transformer: Rotation-equivariant attention for vector neurons, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Matan Atzmon",
                "Niv Haim",
                "Lior Yariv",
                "Ofer Israelov",
                "Haggai Maron",
                "Yaron Lipman"
            ],
            "title": "Controlling neural level sets",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Matan Atzmon",
                "Koki Nagano",
                "Sanja Fidler",
                "Sameh Khamis",
                "Yaron Lipman"
            ],
            "title": "Frame averaging for equivariant shape space learning",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Shaojie Bai",
                "J Zico Kolter",
                "Vladlen Koltun"
            ],
            "title": "Deep equilibrium models",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Alberto Bietti",
                "Luca Venturi",
                "Joan Bruna"
            ],
            "title": "On the sample complexity of learning with geometric stability",
            "venue": "arXiv preprint arXiv:2106.07148,",
            "year": 2021
        },
        {
            "authors": [
                "Christopher M Bishop",
                "Nasser M Nasrabadi"
            ],
            "title": "Pattern recognition and machine learning, volume",
            "year": 2006
        },
        {
            "authors": [
                "Federica Bogo",
                "Javier Romero",
                "Gerard Pons-Moll",
                "Michael J. Black"
            ],
            "title": "Dynamic FAUST: Registering human bodies in motion",
            "venue": "In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR),",
            "year": 2017
        },
        {
            "authors": [
                "Angel X Chang",
                "Thomas Funkhouser",
                "Leonidas Guibas",
                "Pat Hanrahan",
                "Qixing Huang",
                "Zimo Li",
                "Silvio Savarese",
                "Manolis Savva",
                "Shuran Song",
                "Hao Su"
            ],
            "title": "Shapenet: An information-rich 3d model repository",
            "venue": "arXiv preprint arXiv:1512.03012,",
            "year": 2015
        },
        {
            "authors": [
                "Evangelos Chatzipantazis",
                "Stefanos Pertigkiozoglou",
                "Edgar Dobriban",
                "Kostas Daniilidis"
            ],
            "title": "Se (3)-equivariant attention networks for shape reconstruction in function space",
            "venue": "arXiv preprint arXiv:2204.02394,",
            "year": 2022
        },
        {
            "authors": [
                "Chao Chen",
                "Guanbin Li",
                "Ruijia Xu",
                "Tianshui Chen",
                "Meng Wang",
                "Liang Lin"
            ],
            "title": "Clusternet: Deep hierarchical cluster network with rigorously rotation-invariant representation for point cloud analysis",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Haiwei Chen",
                "Shichen Liu",
                "Weikai Chen",
                "Hao Li",
                "Randall Hill"
            ],
            "title": "Equivariant point network for 3d point cloud analysis",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Yunlu Chen",
                "Basura Fernando",
                "Hakan Bilen",
                "Matthias Nie\u00dfner",
                "Efstratios Gavves"
            ],
            "title": "3d equivariant graph implicit functions",
            "venue": "In European Conference on Computer Vision,",
            "year": 2022
        },
        {
            "authors": [
                "Christopher Choy",
                "JunYoung Gwak",
                "Silvio Savarese"
            ],
            "title": "4d spatio-temporal convnets: Minkowski convolutional neural networks",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Arthur P Dempster",
                "Nan M Laird",
                "Donald B Rubin"
            ],
            "title": "Maximum likelihood from incomplete data via the em algorithm. Journal of the royal statistical society: series B (methodological)",
            "year": 1977
        },
        {
            "authors": [
                "Congyue Deng",
                "Or Litany",
                "Yueqi Duan",
                "Adrien Poulenard",
                "Andrea Tagliasacchi",
                "Leonidas J Guibas"
            ],
            "title": "Vector neurons: A general framework for so (3)-equivariant networks",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2021
        },
        {
            "authors": [
                "Congyue Deng",
                "Jiahui Lei",
                "Bokui Shen",
                "Kostas Daniilidis",
                "Leonidas Guibas"
            ],
            "title": "Banana: Banach fixed-point network for pointcloud segmentation with inter-part equivariance",
            "venue": "arXiv preprint arXiv:2305.16314,",
            "year": 2023
        },
        {
            "authors": [
                "Haowen Deng",
                "Tolga Birdal",
                "Slobodan Ilic"
            ],
            "title": "Ppf-foldnet: Unsupervised learning of rotation invariant 3d local descriptors",
            "venue": "In Proceedings of the European conference on computer vision (ECCV),",
            "year": 2018
        },
        {
            "authors": [
                "Bryn Elesedy",
                "Sheheryar Zaidi"
            ],
            "title": "Provably strict generalisation benefit for equivariant models",
            "venue": "In International Conference on Machine Learning,",
            "year": 2021
        },
        {
            "authors": [
                "Carlos Esteves",
                "Christine Allen-Blanchette",
                "Ameesh Makadia",
                "Kostas Daniilidis"
            ],
            "title": "Learning so (3) equivariant representations with spherical cnns",
            "venue": "In Proceedings of the European Conference on Computer Vision (ECCV),",
            "year": 2018
        },
        {
            "authors": [
                "Haiwen Feng",
                "Peter Kulits",
                "Shichen Liu",
                "Michael J Black",
                "Victoria Fernandez Abrevaya"
            ],
            "title": "Generalizing neural human fitting to unseen poses with articulated se (3) equivariance",
            "venue": "In Proceedings of the IEEE/CVF International Conference on Computer Vision,",
            "year": 2023
        },
        {
            "authors": [
                "Fabian Fuchs",
                "Daniel Worrall",
                "Volker Fischer",
                "Max Welling"
            ],
            "title": "Se (3)-transformers: 3d rototranslation equivariant attention networks",
            "venue": "Advances in neural information processing systems,",
            "year": 1970
        },
        {
            "authors": [
                "Zan Gojcic",
                "Caifa Zhou",
                "Jan D Wegner",
                "Andreas Wieser"
            ],
            "title": "The perfect match: 3d point cloud matching with smoothed densities",
            "venue": "In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,",
            "year": 2019
        },
        {
            "authors": [
                "Carolina Higuera",
                "Siyuan Dong",
                "Byron Boots",
                "Mustafa Mukadam"
            ],
            "title": "Neural contact fields: Tracking extrinsic contact with tactile sensing",
            "venue": "IEEE International Conference on Robotics and Automation (ICRA),",
            "year": 2023
        },
        {
            "authors": [
                "Jiahui Huang",
                "He Wang",
                "Tolga Birdal",
                "Minhyuk Sung",
                "Federica Arrigoni",
                "Shi-Min Hu",
                "Leonidas J Guibas"
            ],
            "title": "Multibodysync: Multi-body segmentation and motion estimation via 3d scan synchronization",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Qixing Huang",
                "Xiangru Huang",
                "Bo Sun",
                "Zaiwei Zhang",
                "Junfeng Jiang",
                "Chandrajit Bajaj"
            ],
            "title": "Arapreg: An as-rigid-as possible regularization loss for learning deformable shape generators",
            "venue": "In Proceedings of the IEEE/CVF international conference on computer vision,",
            "year": 2021
        },
        {
            "authors": [
                "Oren Katzir",
                "Dani Lischinski",
                "Daniel Cohen-Or"
            ],
            "title": "Shape-pose disentanglement using se (3)equivariant vector neurons",
            "venue": "In European Conference on Computer Vision,",
            "year": 2022
        },
        {
            "authors": [
                "Diederik P Kingma",
                "Jimmy Ba"
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "arXiv preprint arXiv:1412.6980,",
            "year": 2014
        },
        {
            "authors": [
                "Jiahui Lei",
                "Congyue Deng",
                "Karl Schmeckpeper",
                "Leonidas Guibas",
                "Kostas Daniilidis"
            ],
            "title": "Efem: Equivariant neural field expectation maximization for 3d object segmentation without scene supervision, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Xiaolong Li",
                "Yijia Weng",
                "Li Yi",
                "Leonidas Guibas",
                "A. Lynn Abbott",
                "Shuran Song",
                "He Wang"
            ],
            "title": "Leveraging se(3) equivariance for self-supervised category-level object pose estimation, 2021",
            "year": 2021
        },
        {
            "authors": [
                "Cheng-Wei Lin",
                "Tung-I Chen",
                "Hsin-Ying Lee",
                "Wen-Chin Chen",
                "Winston H Hsu"
            ],
            "title": "Coarse-tofine point cloud registration with se (3)-equivariant representations",
            "venue": "IEEE International Conference on Robotics and Automation (ICRA),",
            "year": 2023
        },
        {
            "authors": [
                "Min Liu",
                "Fupin Yao",
                "Chiho Choi",
                "Ayan Sinha",
                "Karthik Ramani"
            ],
            "title": "Deep learning 3d shapes using alt-az anisotropic 2-sphere convolution",
            "venue": "In International Conference on Learning Representations,",
            "year": 2018
        },
        {
            "authors": [
                "Xueyi Liu",
                "Ji Zhang",
                "Ruizhen Hu",
                "Haibin Huang",
                "He Wang",
                "Li Yi"
            ],
            "title": "Self-supervised category-level articulated object pose estimation with part-level",
            "venue": "equivariance,",
            "year": 2023
        },
        {
            "authors": [
                "Francesco Locatello",
                "Dirk Weissenborn",
                "Thomas Unterthiner",
                "Aravindh Mahendran",
                "Georg Heigold",
                "Jakob Uszkoreit",
                "Alexey Dosovitskiy",
                "Thomas Kipf"
            ],
            "title": "Object-centric learning with slot attention",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Matthew Loper",
                "Naureen Mahmood",
                "Javier Romero",
                "Gerard Pons-Moll",
                "Michael J. Black"
            ],
            "title": "SMPL: A skinned multi-person linear model",
            "venue": "ACM Trans. Graphics (Proc. SIGGRAPH Asia),",
            "year": 2015
        },
        {
            "authors": [
                "Naureen Mahmood",
                "Nima Ghorbani",
                "Nikolaus F Troje",
                "Gerard Pons-Moll",
                "Michael J Black"
            ],
            "title": "Amass: Archive of motion capture as surface shapes",
            "venue": "In Proceedings of the IEEE/CVF international conference on computer vision,",
            "year": 2019
        },
        {
            "authors": [
                "Haggai Maron",
                "Or Litany",
                "Gal Chechik",
                "Ethan Fetaya"
            ],
            "title": "On learning sets of symmetric elements",
            "venue": "In International conference on machine learning,",
            "year": 2020
        },
        {
            "authors": [
                "Haoran Pan",
                "Jun Zhou",
                "Yuanpeng Liu",
                "Xuequan Lu",
                "Weiming Wang",
                "Xuefeng Yan",
                "Mingqiang Wei"
            ],
            "title": "So (3)-pose: So (3)-equivariance learning for 6d object pose estimation",
            "venue": "In Computer Graphics Forum,",
            "year": 2022
        },
        {
            "authors": [
                "Adam Paszke",
                "Sam Gross",
                "Francisco Massa",
                "Adam Lerer",
                "James Bradbury",
                "Gregory Chanan",
                "Trevor Killeen",
                "Zeming Lin",
                "Natalia Gimelshein",
                "Luca Antiga"
            ],
            "title": "Pytorch: An imperative style, high-performance deep learning library",
            "venue": "Advances in neural information processing systems,",
            "year": 2019
        },
        {
            "authors": [
                "Adrien Poulenard",
                "Leonidas J Guibas"
            ],
            "title": "A functional approach to rotation equivariant non-linearities for tensor field networks",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2021
        },
        {
            "authors": [
                "Omri Puny",
                "Matan Atzmon",
                "Edward J. Smith",
                "Ishan Misra",
                "Aditya Grover",
                "Heli Ben-Hamu",
                "Yaron Lipman"
            ],
            "title": "Frame averaging for invariant and equivariant network design",
            "venue": "In International Conference on Learning Representations,",
            "year": 2022
        },
        {
            "authors": [
                "Charles R Qi",
                "Hao Su",
                "Kaichun Mo",
                "Leonidas J Guibas"
            ],
            "title": "Pointnet: Deep learning on point sets for 3d classification and segmentation",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2017
        },
        {
            "authors": [
                "Rahul Sajnani",
                "Adrien Poulenard",
                "Jivitesh Jain",
                "Radhika Dua",
                "Leonidas J Guibas",
                "Srinath Sridhar"
            ],
            "title": "Condor: Self-supervised canonicalization of 3d pose for partial shapes",
            "venue": "In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Anthony Simeonov",
                "Yilun Du",
                "Andrea Tagliasacchi",
                "Joshua B Tenenbaum",
                "Alberto Rodriguez",
                "Pulkit Agrawal",
                "Vincent Sitzmann"
            ],
            "title": "Neural descriptor fields: Se (3)-equivariant object representations for manipulation",
            "venue": "In 2022 International Conference on Robotics and Automation (ICRA),",
            "year": 2022
        },
        {
            "authors": [
                "Behrooz Tahmasebi",
                "Stefanie Jegelka"
            ],
            "title": "The exact sample complexity gain from invariances for kernel regression on manifolds, 2023",
            "year": 2023
        },
        {
            "authors": [
                "Nathaniel Thomas",
                "Tess Smidt",
                "Steven Kearnes",
                "Lusann Yang",
                "Li Li",
                "Kai Kohlhoff",
                "Patrick Riley"
            ],
            "title": "Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds",
            "venue": "arXiv preprint arXiv:1802.08219,",
            "year": 2018
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Yue Wang",
                "Yongbin Sun",
                "Ziwei Liu",
                "Sanjay E Sarma",
                "Michael M Bronstein",
                "Justin M Solomon"
            ],
            "title": "Dynamic graph cnn for learning on point clouds",
            "venue": "Acm Transactions On Graphics (tog),",
            "year": 2019
        },
        {
            "authors": [
                "Maurice Weiler",
                "Mario Geiger",
                "Max Welling",
                "Wouter Boomsma",
                "Taco Cohen"
            ],
            "title": "3d steerable cnns: Learning rotationally equivariant features in volumetric data, 2018",
            "year": 2018
        },
        {
            "authors": [
                "Daniel E Worrall",
                "Stephan J Garbin",
                "Daniyar Turmukhambetov",
                "Gabriel J Brostow"
            ],
            "title": "Harmonic networks: Deep translation and rotation equivariance",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2017
        },
        {
            "authors": [
                "Zhengrong Xue",
                "Zhecheng Yuan",
                "Jiashun Wang",
                "Xueqian Wang",
                "Yang Gao",
                "Huazhe Xu"
            ],
            "title": "Useek: Unsupervised se (3)-equivariant 3d keypoints for generalizable manipulation",
            "venue": "IEEE International Conference on Robotics and Automation (ICRA),",
            "year": 2023
        },
        {
            "authors": [
                "Hong-Xing Yu",
                "Jiajun Wu",
                "Li Yi"
            ],
            "title": "Rotationally equivariant 3d object detection",
            "venue": "In Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition,",
            "year": 2022
        },
        {
            "authors": [
                "Zhiyuan Zhang",
                "Binh-Son Hua",
                "David W Rosen",
                "Sai-Kit Yeung"
            ],
            "title": "Rotation invariant convolutions for 3d point clouds deep learning",
            "venue": "In 2019 International conference on 3d vision (3DV),",
            "year": 2019
        },
        {
            "authors": [
                "Minghan Zhu",
                "Maani Ghaffari",
                "Huei Peng"
            ],
            "title": "Correspondence-free point cloud registration with so (3)-equivariant implicit shape representations",
            "venue": "In Conference on Robot Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Hedi Zisling",
                "Andrei Sharf"
            ],
            "title": "Vnt-net: Rotational invariant vector neuron transformers, 2022",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 INTRODUCTION",
            "text": "In recent years, there has been an ongoing research effort on the modeling of neural networks for 3D recognition tasks. Point clouds, as a simple and prevalent 3D input representation, have received substantial focus, leading to point networks: specialized neural network architectures operating on point clouds (Qi et al., 2017; Zaheer et al., 2017). Since many point cloud recognition tasks can be characterized as equivariant functions, modeling them with an equivariant point network has been shown to be an effective approach. Indeed, equivariant modeling can simplify a learning problem: knowledge learned from one input, automatically propagates to all input\u2019s symmetries(Bietti et al., 2021; Elesedy & Zaidi, 2021; Tahmasebi & Jegelka, 2023).\nOne important symmetry exhibited in point clouds is the Euclidean motions, E(3), consisting of all the possible rigid motions in space. Building on the demonstrated success of E(3) equivariant point networks in prior research (Thomas et al., 2018), recent efforts have been dedicated to extending E(3) symmetry to model piecewise rigid motions symmetry as well (Yu et al., 2022; Lei et al., 2023; Deng et al., 2023). This extension is valuable since some recognition tasks can\nbe better characterized as piecewise E(3) equivariant functions. To support this claim, we turn to the task of instance segmentation within a scene, illustrated by a 2D toy example in the right inset. In the leftmost column, we visualize segmentation predictions by distinct colors. In the middle column, we observe the expected invariant predictions under a global Euclidean motion of the entire scene. Finally, in the right column, we showcase invariant predictions under a piecewise deformation that allows individual objects to move independently in a rigid manner, decoupled from the overall scene\u2019s motion.\nIncorporating piecewise E(3) symmetry to point networks presents several challenges. The primary hurdle is the unknown partitioning of the input point cloud into its moving parts. While having such a partition makes it possible to implement equivariant design using a E(3) equivariant siamese network across parts (Atzmon et al., 2022), this is often infeasible in real-world applications. For instance, in the segmentation task shown in the inset, the partition is inherently tied to the model\u2019s segmentation predictions. Thus, in cases where the underlying partition is not predefined but rather predicted by a (non-degenerated) model, any suggested piecewise equivariant model will introduce an approximation error in satisfying the equivariance constraint. We will use the term equivariance approximation error to refer to the error that arises when a function is unable to satisfy the piecewise E(3) equivariance constraint (w.r.t. the true unknown partition); see Definition 1.This equivariance approximation error is inherent unless the partition prediction remains perfectly consistent under the input symmetries. This implies it must be invariant to the very partition it seeks to identify. So far in the literature, less attention has been given to piecewise equivariant network designs that offer means to control the network\u2019s equivariance approximation error. For example, Liu et al. (2023) suggests an initial partition prediction model based on input points\u2019 global E(3) invariant and equivariant features. In Yu et al. (2022), local-context invariant features are used for the partition prediction model. In both cases, it is unclear how failures in the underlying partition prediction model will affect the equivariance approximation error. Notably, the concurrent work of Deng et al. (2023) also observes the equivariance approximation error. Their work suggests an optimization-based partition prediction model based on (approximately) contractive steps, striving to achieve exact piecewise equivariance; errors in the partition prediction model arising from expanding steps and their impact on the resulting equivariance approximation error are not discussed.\nIn this paper, we propose a novel framework for the design of approximately piecewise equivariant networks, called APEN. Our goal is to suggest a practical design that can serve as a backbone for piecewise E(3) equivariant tasks, while identifying how elements in the design control the piecewise equivariance approximation error. Our framework is built on the following simple fact. Let G and G\u2032 be two symmetry groups for which each symmetry inG\u2032 is also inG, i.e., G\u2032 \u2a7d G. Then, anyG equivariant function is also a G\u2032 equivariant function. Thus, we can have an exact piecewise equivariant model, as long as the model partition is a proper subpartition of the (unknown) ground-truth one. The right inset illustrates this fact: the piecewise equivariant predictions of vote targets, marked as black dots, are accurate for a subpartition of the ground-truth partition (left column), whereas an equivariant approximation error arises for a partition that includes a bad part consisting of points mixed from two different parts in the ground truth partition (i.e., the red dots in the right column). This observation may lead to the following simple model for partition prediction \u2013 drawing a random partition from the distribution of non-degenerated partitions of size k (i.e., all k parts get at least one point). For such a model, the probability of drawing a bad part reaches 0 as k increases. In turn, the probability of drawing a bad partition can be used to bound the equivariance approximation error of a piecewise equivariant function, as good sub-partitions induce no equivariance approximation error. Importantly, this approach alleviates the need for additional constraints on the underlying model function to control the equivariance approximation error.\nHowever, this approach needs to be pursued with caution, as increasing the complexity of the possible partitions reduces the expressivity of the resulting piecewise equivariant point network model class. This caveat is especially relevant to the common design using a shared (among parts) E(3) equivariant backbone. Indeed, at the limit where each point belongs to a distinct part, the only shared backbone E(3) equivariant functions are constant. To mitigate potential expressivity issues, our APEN framework employs a compositional network architecture. This architecture comprises a sequence of piecewise equivariant layers, with the complexity of their underlying partition decreasing gradually. Each layer is defined as a piecewise E(3) equivariant function, which not only predicts\nlayer-specific features but also parametrizes a prediction of a coarser partition. This coarser partition serves as the basis for the subsequent layer\u2019s piecewise E(3) symmetry group. The goal of this \u201cbottom-up\u201d approach is to allow the network to overcome the issue of ambiguous predictions in earlier layers by learning to merge parts that are likely to transform together, resulting in a simpler partition in the subsequent equivariant layer. Importantly, this design also provides bounds for the piecewise equivariant approximation error of each layer, resulting solely from two sources in the design: (i) uncertainty in the partition prediction model, and (ii) the probability of drawing a bad partition.\nWe instantiated our APEN framework for two different recognition tasks: classification and part segmentation. We conducted experiments using datasets comprising of (i) articulated objects consisting of human subjects performing various sequence movements (Bogo et al., 2017), and (ii) real-world room scans of furniture-type objects (Huang et al., 2021a). The results validate the efficacy of our framework and support the notion of potential benefits in incorporating piecewise E(3) deformations to point networks."
        },
        {
            "heading": "2 METHOD",
            "text": ""
        },
        {
            "heading": "2.1 BACKGROUND: EQUIVARIANT POINT NETWORKS",
            "text": "We will consider point networks as functions h \u2236 U \u2192 W , where U and W denote the vector spaces for the input and output domains, respectively. The input vector space U takes the form U = Rn\u00d7(2\u00d7d), with n denoting the number of points in the input point cloud, d is the point embedding space dimension (usually d = 3), and 2 per-point features: spatial location and an oriented normal vector. Depending on the task at hand, classification, or segmentation, the output vector space W can be W = Rc or W = Rn\u00d7c. To incorporate symmetries into a point network, we consider a group G , along with its action g on the vector spaces U and W . Of particular interest in our work is the Euclidean motions groupG = E(d) defined by rotations, reflections and translations in d-dimensional space. The group action on X \u2208 U is defined by g \u22c5X = XRT + 1tT , with g = (R, t) being an element in E(d)1, while the action on the output Y \u2208W varies depending on the task (e.g., g \u22c5Y = Y for classification). An important property for our networks h to satisfy is equivariance with respect to G:\nh(g \u22c5X) = g \u22c5 h(X) \u2200g \u2208 G,X \u2208 U. (1)\nWe consider the typical case of networks h which follow an encoder-decoder structure, i.e., h = d \u25cb e. The encoder e \u2236 U \u2192 V transforms an input into a learnable latent representation V . In our case, V is an E(3) equivariant latent space, up to order type 1, of the form V = Ra+b\u00d73, with a, b being positive integers. The decoder d \u2236 V \u2192W decodes the latent representation to produce the expected output response which can be invariant or equivariant to the input. Both e and d are modeled as a composition of multiple invariant or equivariant layers. Having covered the basics of equivariant point networks, we will now proceed to describe our proposed framework, starting with the formulation of a piecewise E(d) equivariant layer.\n2.2 PIECEWISE E(d) EQUIVARIANCE LAYER\nWe start this section by describing the settings for which we model a piecewise E(d) equivariant layer. Let X \u2208 U be the input to the layer. Our assumption is that the partition prediction is modeled as a (conditional) probability distribution, QZ\u2223X \u2208 (\u03a3k)n over the k parts partitions X can exhibit. Here \u03a3k denotes the k probability simplex. Let Z = [zT1 ,\u22ef,zTn ]\nT \u2208 {0,1}n\u00d7k with Z1 = 1, denote a realization of a partition from QZ\u2223X , i.e., Z \u223c QZ\u2223X . Let Z\u2217 be the unknown ground truth partition of X . An important quantity of interest is\n\u03bb(Q) = PZ\u223cQZ\u2223X (\u2203 1 \u2264 i, j \u2264 n s.t. (ZZ T )ij > (Z\u2217ZT\u2217 )ij), (2)\nmeasuring the probability of drawing a \u201cbad\u201d partition from Q, i.e., a non-proper subpartition of Z\u2217. In that context, a reference partition prediction model is Qsimple which is defined by a uniform draw\n1Note that in fact g = (R,0) on the input normals features.\nof a partition satisfying Zej > 0 for each j \u2208 [k]. An important property of Qsimple is \u03bb(Qsimple)\u2192 0 as k \u2192 n. To better understand this claim about \u03bb(Qsimple), one can consider the sequential process generating a random k parts partition. Clearly, larger values of k result in each part containing fewer points. Since the probability of drawing the next point from mixed ground-truth parts is independent of k, determined solely by the number of input points and the ground-truth partition, the probability that the next drawn point generated a bad part lowers as k increases. In turn, \u03bb(Qsimple) can serve as a useful bound for the resulting equivariance approximation error. Consequently, we opt for a model Q that satisfies lim inf \u03bb(Q) = \u03bb(Qsimple) as a function of a hyper-parameter selection in the design of Q.\nMore precisely, we suggest the following characterization for Q. Let \u03b4 \u2236 (\u03a3k)n \u2192 R+, satisfying\n\u03b4(Q)\u2192 0, whenever Q\u2192 Qv (3)\nwith Qv \u2208 {0,1}n\u00d7k \u2229 (\u03a3k)n. That is, \u03b4 measures the uncertainty in the model\u2019s prediction. Our design requirement is that\nlim inf \u03bb(Q) = \u03bb(Qsimple), as \u03b4(Q)\u2192 0. (4)\nFigure 1: The functional bound \u03b4. Green colors indicate values close to 0.\nIn other words, we suggest constraining a Q model to behave in a way such that, as it becomes more certain in how it draws its predictions, the probability of drawing a \u201cbad\u201d partition converges to be no worse than the one of the simple model. The functional \u03b4 measures the uncertainty of Q, and is considered as one of the design choices in the modeling of Q. In turn, it will be used to bound the equivariance approximation error. Fig. 1 illustrates the qualitative behavior of \u03b4.\nWe defer the discussion on how we provide a model for Q supporting these ideas for later. Instead, we start by describing how QZ\u2223X is incorporated to model a piecewise equivariant layer.\nFixed partition. To facilitate discussion, we first assume that Z is fixed, and we will start by describing a piecewise E(d) equivariant layer with respect to Z partition. Let G = E(d)\u00d7\u22ef\u00d7E(d) be the product consisting of k copies of the Euclidean motions group. For g = (g1\u22ef, gk) \u2208 G, we define\ng \u22c5 (X,Z) = k\n\u2211 j=1 (gj \u22c5X)\u2299 (Zej1Td ), (5)\nwhere gj \u22c5X =XRTj + 1ntTj , {ej} k j=1 is the standard basis in R k, 1d is the vector of all ones in Rd, and \u2299 denotes the Hadamard product between two matrices.\nOne appealing way to model a piecewise E(d) equivariant function, \u03c8 \u2236 U \u00d7 {0,1}n\u00d7k \u2192 U \u2032, which also respects the inherited order symmetry of the part\u2019s assignments, is by employing an E(d)equivariant backbone \u03c8b \u2236 U \u2192 U \u2032 shared among the parts (Atzmon et al., 2022; Deng et al., 2023), taking the form:\n\u03c8(X,Z) = k\n\u2211 j=1 \u03c8b(X \u2299Zej1Td )\u2299Zej1T . (6)\nThe following lemma, whose proof can be found in the Appendix, verifies these properties for \u03c8.\nLemma 1. Let \u03c8 \u2236 U \u00d7{0,1}n\u00d7k \u2192 U \u2032 be a function as in Eq. (6). Let g \u2208 G and \u03c3k(\u22c5) a permutation on [k]. Then,\n\u03c8(g \u22c5 (X,Z),Z) = g \u22c5 (\u03c8(X,Z),Z), \u03c8(X,Z\u2032) = \u03c8(X,Z)\nfor any X \u2208 U , Z \u2208 {0,1}n\u00d7k, and Z\u2032 = Z\u2236,\u03c3(i).\nNote that one can consider augmenting the design of Eq. (6) with a function over orderless representation of parts E(d) invariant features (Maron et al., 2020). Equipped with the construction in Eq. (6), we will now move on to the case where Z is uncertain.\nUncertain partition. Incorporating QZ\u2223X into a layer can be done by marginalizing over the possible Z. Some simple options for marginalization are i) \u03d5I(X) = \u03c8(X,EQZ) as implemented in Atzmon et al. (2022); ii) \u03d5II(X) = EQ\u03c8(X,Z); and iii) \u03d5III(X) = \u03c8 (X,Z\u2020), where (Z\u2020)i,\u2236 = eargmaxj Q(Z\u2223X)ij . Unfortunately, however, all of these options are merely an approximation of a piecewise E(d) equivariant function. The scheme \u03d5I relies on scaling, which can be an arbitrarily bad approximation to the input\u2019s geometry. The scheme \u03d5II relies on the averaging of equivariant point features, which is not stable under a realization of a particular partition Z \u223c Q. Similarly, \u03d5III is also not equivariant under all possible realizations of Z. However, the equivariance approximation error \u03d5III induces can be controlled, as we discuss next.\nBounding the equivariant approximation error. In this work, we advocate for layers of the form \u03d5III. The motivation for doing so is that it enables a uniform control over the equivariant approximation error as a function of Q, crucially, without relying on bounding the variation of \u03d5. This advantage is especially prominent for neural networks, as existing techniques for bounding network\u2019s bounded variation, e.g., by controlling the network\u2019s Lipshitz constant, impose additional complexity to the network architecture and may hinder the training process (Anil et al., 2019). On the other hand, as we will see in the next section, the approximation error Q induces can be controlled explicitly by a choice of hyper-parameters in the parametrization of Q.\nThe next definition captures our suggested characterization for an approximation error of a desired piecewise E(d) equivariant layer: Definition 1. Let \u03d5 \u2236 U \u2192 U \u2032 be a bounded function with \u2225\u03d5\u2225 \u2264M . Let \u03b4 \u2236 (\u03a3k)n \u2192 R+, satisfying Eq. (3) and Eq. (4) w.r.t. Q. Then, \u03d5 is a (G,Q) equivariant function if and only if for any given X \u2208 U , the following is satisfied\nEQZ\u2223X \u2225\u03d5 (g \u22c5 (X,Z)) \u2212 g \u22c5 (\u03d5(X),Z)\u2225 \u2264 (\u03bb(Qsimple) + \u03b4(Q))M (7)\nfor all g \u2208 G. We denote the set of (G,Q) equivariant functions by FQ.\nThe above characterization for the equivariance approximation error can be seen as resulting from two different sources of properties in the partition prediction model: (i) an intrinsic source, as captured by \u03b4, which measures the uncertainty of the model Q, and (ii) an extrinsic source, determined by a measure independent from Q as captured by \u03bb. In addition, the above definition generalizes the notion of exact equivariant function classes. For instance, consider Z\u2217 satisfying Z\u2217ej = 1 for some fixed j; setting \u03b4 \u2261 0 yields that FQ coincides with the class of global E(d) equivariant functions. To conclude this section, we verify in the following theorem that our construction of \u03d5 indeed falls under the suggested characterization of approximate piecewise E(d) equivariant functions. Proof details are in the Appendix.\nTheorem 1. Let \u03d5 \u2236 U \u2192 U \u2032 be of the form\n\u03d5(X) = k\n\u2211 j=1 \u03c8b(X \u2299Z\u2020ej1Td )\u2299Z\u2020ej1T , (8)\nwhere (Z\u2020)i,\u2236 = eargmaxj Q(Z\u2223X)ij , and \u03c8b \u2236 U \u2192 U \u2032 is an E(d) equivariant backbone. Then,\n\u03d5 \u2208 FQ."
        },
        {
            "heading": "2.3 Q PREDICTION",
            "text": "So far, we have treated Q as a given input to the layer. In fact, we suggest that Q results from a piecewise equivariant prediction of a prior layer. Exceptional is the first layer, for which Q = Qsimple. Given a layer output of the form in Eq. (8), we will next describe how Qpred is inferred. Note that Q still denotes the given input partition prediction model.\nModeling considerations. As a first attempt, one might consider parametrizing Qpred as the softmax of a per-point Q piecewise invariant layer prediction. However, this approach introduces several difficulties, causing it to be unfeasible. Firstly, it is unclear how to supervise Q during training to predict good sub-partitions of the ground-truth partition. Secondly, network optimization could be tricky, since the domain of possible partition solutions has a high dimensional combinatorial structure,\nespecially due to our design bias for a large number of parts in early network layers. Lastly, there is a need to model the merging of parts in the input partition to generate a coarser one.\nTo address these challenges, we propose a geometric approach to model Qpred. Our suggestion is to set Qpred as the assignment scores resulting from the partitioning (i.e., clustering) in Rd of Q piecewise equivariant per-point predictions. Notably, this suggestion falls under the well-known attention layer (Vaswani et al., 2017; Locatello et al., 2020; Liu et al., 2023) following a query, key, and value structure with \u03d5(X) being the values and queries, part centers being the keys, and the predictionQpred is proportional to the matching score of a query to a key. One of the advantages of this approach is that Qpred emerges as an orderless prediction with respect to possible parts assignments, thus simplifying the optimization domain. However, it is not clear how this model can (i) control the resulting \u03b4(Qpred) by means of its design; and (ii) support the merging of parts to constitute a prediction of a coarser partition. To this end, we suggest that the part center (keys) predictions are set as the minimizers of an energy that is invariant to Q piecewise E(d) deformations of \u03d5(X) (values). We formalize this idea in the next paragraph.\nQ Prediction. Let Y = [y1,\u22ef,yn]T \u2208 Rn\u00d7d denote the first equivariant per-point prediction in \u03d5(X) \u2208 U \u2032. Let [\u00b5\u2217j ] k j=1 \u2208 R d\u00d7k denote the underlying predicted part centers with which the score of Qpred is defined. We define [\u00b5\u2217j ] k\nj=1 as the minimizers of an energy consisting of the negative log-likelihood of a Gaussian Mixture Model and a regularization term that constraints the KL distance between all pairs of Gaussians to be greater than some threshold. Let P (Y ;\u03b1 = (\u00b5j , \u03c0j ;\u03c3)kj=1) denote the mixture distribution, parametrized by \u03b1. Then, the log-likelihood is logP (Y ;\u03b1) = \u2211ni=1 log(\u2211 k j=1 \u03c0jN (yi;\u00b5j , \u03c3)) where N (\u22c5;\u00b5j , \u03c3) denotes the density of an isotropic Gaussian random variable, centered at \u00b5j with variance \u03c32I . Note that \u03c3 is fixed and is considered as a hyper-parameter. Then, [\u00b5\u2217j ] k j=1 are defined as\n(\u00b5\u2217j , \u03c0\u2217j ) = argmin \u03b1 \u2212 logP (Y ;\u03b1) \u2212 \u03c4 \u2211 j\u2260j\u2032 \u03c0j\u03c0 \u2032 j logDKL(N (\u22c5;\u00b5j)\u2223\u2223N (\u22c5;\u00b5\u2032j)). (9)\nIn turn, the prediction Qpredij is defined as\nQpredij = N (yi;\u00b5\u2217j , \u03c3)\u03c0\u2217j\n\u2211kj=1N (yi;\u00b5\u2217j , \u03c3)\u03c0\u2217j . (10)\nImportantly, the above construction yields that as \u03c3 \u2192 0: i) \u03bb(Qpred)\u2192 \u03bb(Qsimple) since each random partition is a minimizer of the likelihood functional, and ii) \u03b4(Qpred)\u2192 0. In addition, \u03c3 also controls the sensitivity of Gaussians to merge (under a fixed coefficient \u03c4), where larger values encourage Gaussians to explain wider distribution of values yi. Thus, setting an increasing sequence of \u03c3 values across layers supports the gradual coarsening of partitions design. Lastly, note that differentiating the prediction of Qpred w.r.t its inputs is not trivial; these details are covered in the next section."
        },
        {
            "heading": "2.4 IMPLEMENTATION DETAILS",
            "text": "Network architecture. We start by sharing the details about the construction of the layer \u03c8 in Eq. (6) given a known partition Z. For that end, we used Frame Averaging (FA) (Puny et al., 2022) with a shared pointnet (Qi et al., 2017) network, \u03c8\u0303. We define our shared equivariant backbone by\n\u03c8b(X \u2299Zej1Td ) = \u27e8\u03c8\u0303(X \u2299Zej1Td )\u27e9F (X\u2299Zej1Td ) where F (X \u2299Zej1Td ) is the same PCA based construction for an E(d) frame suggested in Puny et al. (2022), and \u27e8\u22c5\u27e9 is the FA symmetrization operator. Then, \u03c8(X,Z) is defined exactly as in Eq. (6). Since this construction needs to support layers with a relatively large number of parts k, we implement the network \u03c8b using the sparse linear layers from Choy et al. (2019).\nIn all our experiments, we implemented the encoder as a composition of L layers, e = \u03d5L \u25cb\u22ef \u25cb\u03d51, with L = 4; see Fig. 2. Qsimple is set as the input to \u03d51. In fact, Qsimple can be further regulated than the naive suggestion. In practice, we set Qsimple by a Voronoi partition resulting from k furthest point samples from the input X . The exact analysis of \u03bb(Qsimple) as a function of n and k is out of the scope of this work \u2013 we only rely on Eq. (4).\nQ prediction. For finding a minimizer of Eq. (9), we used a slight modification of the well-known EM algorithm (Dempster et al., 1977) that supports the merging of centers closer than the threshold \u03c4 . Note that during training, the backward calculation requires the derivative of \u2202Q\n\u2202\u03d5 . Since the EM is\nin an iterative algorithm, this might unnecessarily increase the computational graph of the backward computation. To mitigate this, we use the following construction, based on implicit differentiation (Atzmon et al., 2019; Bai et al., 2019). Let \u03b1\u0303 be a minimizer Eq. (9) that is detached from the computational graph and Y . Then, s(Y ; \u03b1\u0303) = 0 where s(Y ; \u03b1\u0303) = \u2207\u03b1 logP (Y ;\u03b1), known in the literature as the score function (Bishop & Nasrabadi, 2006). We define\n\u03b1 = \u03b1\u0303 + I\u22121 (\u03b1\u0303) s (Y ; \u03b1\u0303) , (11)\nwhere I\u22121(\u03b1\u0303) = Var (s(Y ; \u03b1\u0303)) is the fisher information matrix (Bishop & Nasrabadi, 2006) calculated at \u03b1\u0303. Importantly, I only depends on s and does not involve second derivative calculations. It can be easily verified that \u03b1 is a minimizer of Eq. (9) and that \u2202\u03b1\n\u2202Y = \u2202(argmin\u03b1(E(\u03b1,Y ))) \u2202Y , where\nE(\u22c5) denotes the energy defined in Eq. (9). This is summarized in Alg. 1, found in the Appendix.\nTraining details. Our framework requires supervision in order to train Qpred to approximate the ground-truth partition. To that end, we compute the ground-truth YGT \u2208 Rn\u00d7d to supervise the parts center vote predictions Yl \u2208 Rn\u00d7d of the lth layer. We utilize the given segmentation information, to calculate YGT = ZCT \u2212X , where Z \u2208 {0,1}n\u00d7k are the ground-truth assignments of X \u2208 Rn\u00d7d and C \u2208 Rd\u00d7k is calculated as the center of the minimal bounding box encompassing each of the input parts. Then, a standard L1 loss is added to optimization,\nlossA = L\n\u2211 l=1 \u2225Yl \u2212YGT\u2225 ."
        },
        {
            "heading": "3 EXPERIMENTS",
            "text": "We evaluate our method on two types of datasets that fit piecewise E(3) symmetry: (i) scans of human subjects performing various sequences of movements (Loper et al., 2015; Bogo et al., 2017; Mahmood et al., 2019), and (ii) real-world rooms scans of furniture-type objects (Huang et al., 2021a). In all of our experiments, we used the ground-truth segmentation maps to extract YGT supervision as described in Sec. 2.4."
        },
        {
            "heading": "3.1 HUMAN SCANS",
            "text": "We start by evaluating our framework for the task of point part segmentation, a basic computer-vision task with many downstream applications. Specifically, we consider human body parts segmentation, where the goal is to assign each of the input scan points to a part chosen from a predefined list. In our case, the list consists of 24 body parts.\nTo evaluate different aspects of our framework, we use three different train/test splits. The first consists of a random (90%/10%) train/test split of 41,461 human models from the SMPL dataset (Loper et al., 2015) consisting of 10 different human subjects as in (Huang et al., 2021b). This experiment acts as a sanity test and ensure our method does not underperform compared to baselines. The second and third splits use the scans from the Dynamic FAUST (DFAUST) dataset (Bogo et al., 2017), consisting of 10 to 12 different sequences of motions (e.g., jumping jacks, punching, etc.) for each of the 10 human subjects. In the second split, we divide the data by a random choice of a different\naction sequences for each human. This experiment ensures our method can generalize knowledge of action sequences seen in training from one human subject to other human subjects at test time. Finally, in the third split we choose the same sequence of movements (e.g., the one-leg jump sequence) to be removed from the training set and be placed as the test set. The last test evaluates the effect of the piecewise E(3) prior, as implemented in our method, to generalize to unseen movement.\nIn Tab. 1, we report the mean IoU(%) score for all 3 tests. As baseline models, we opt for PointNet (Qi et al., 2017) and DGCNN (Wang et al., 2019) as order invariant point networks. For E(3) invariant networks, our baselines selection includes Vector Neurons (VN) (Deng et al., 2021), VN-Transformer (VN-T) (Assaad et al., 2023), FrameAveraging (FA) (Puny et al., 2022), and Equivariant Point Network (EPN) Chen et al. (2021) backbone as implemented in the human body part segmentation network de-\nscribed in Feng et al. (2023). Fig. 4 shows qualitative test results of an unseen random seq. pose (first row) and an unseen random pose (second row). We conclude from the results that (i) our framework is a valid backbone with similar expressive power as common point network baselines, (ii) our framework utilizes piecewise E(3) equivariance to gain better generalization across human subjects than baseline approaches and, (iii) piecewise E(3) equivariant prior can help to generalize to unseen movements.\nLastly, to test the versatility of our framework, we evaluate it on a point cloud classification task. On that hand, we consider the DFaust subset of AMASS (Mahmood et al., 2019), consisting of 9 human subjects. We define the task of classifying a model to a subject. For testing, we use an \"out of distribution\" test set from PosePrior (Akhter & Black, 2015). The results from this experiment support the usability of our framework for classification tasks as well. The detailed report can be found in the Appendix, including all the hyper-parameters used for the experiments in this section."
        },
        {
            "heading": "3.2 ROOM SCANS",
            "text": "In this section, we test the potential of our framework for one-shot generalization. To that end, we employ a dataset of 8 scenes capturing a real-world room where the furniture in the room has been positioned differently in each of the 8 scans for each scene. Within each scan, there are 3 to 4 labeled furniture-type objects, including the floor. The task objective is to assign each input point to one of the object instances composing the scene. In addition to the difficulty of segmenting moving objects in the scene, solutions to this task must handle noise and sampling artifacts arising from the scanning procedure. For instance, scans of objects occasionally contain holes or exhibit ghost geometry. Here\nwe compare two alternative solutions this this task: (1) we only train our method using a single scan, and test its generalization to the other seven scans of the same scene. (2) We train baseline networks on the large-scale synthetic shape segmentation dataset from Huang et al. (2021a), which randomly samples independent motions for multiple objects taken from ShapeNet (Chang et al., 2015).\nIn Tab. 2 we report the mean IoU(%) test score for each of the scenes. Fig. 3 shows qualitative results for 2 rooms. Despite only training on a single scan, our model outperforms baselines trained on a large synthetic dataset in 7 out of the 8 test scenes. These results suggest potential advantages of using piecewise E(3) equivariant architectures in a single shot setting over the use of large-scale synthetic data. Furthermore, to make baseline approaches work, we employed a RANSAC algorithm to identify the ground plane, with an inlier distance threshold of 0.02 and 1000 RANSAC iterations. In contrast, our method requires no preprocessing since the network can treat the floor as it would for any other part of the input data."
        },
        {
            "heading": "4 RELATED WORK",
            "text": "Global Equivariance. We introduce a novel method for piecewise E(3) equivariance in point networks. Euclidean group symmetry has been studied in point networks mainly in describing architectures that accommodate global transformations (Chen et al., 2019; Thomas et al., 2018; Fuchs et al., 2020; Chen et al., 2021; Deng et al., 2021; Assaad et al., 2023; Zisling & Sharf, 2022; Katzir et al., 2022; Poulenard & Guibas, 2021; Puny et al., 2022). These was shown to perform well in various applications including reconstruction (Deng et al., 2021; Chatzipantazis et al., 2022; Chen et al., 2022), pose estimation (Li et al., 2021; Lin et al., 2023; Pan et al., 2022; Sajnani et al., 2022; Zhu et al., 2022), and robot manipulation (Simeonov et al., 2022; Higuera et al., 2023; Xue et al., 2023) tasks. Some works have dealt with respecting the symmetry by manipulating their input representation (Deng et al., 2018; Zhang et al., 2019; Gojcic et al., 2019). A popular line of work utilizes the theory of spherical harmonics to achieve equivariance (Worrall et al., 2017; Esteves et al., 2018; Liu et al., 2018; Weiler et al., 2018; Cohen et al., 2018). Object-Level and Part-Based Equivariance Several works have studied the equivariance of parts. EON (Yu et al., 2022) and EFEM (Lei et al., 2023) both studied object-level equivariance in scenes. EON used a manually tuned \u2018suspension\u2019 to compute an equivariant object frame in which the context is aggregated. In EFEM, instance segmentation is achieved by training a shape prior using a shape collection, and employing it to refine scene regions. Instead, we do not assume prior knowledge of the underlying partition. Equivariance for per-part pose estimation in articulated shape was devised in Liu et al. (2023). Yet their self-supervised approach relies on part grouping according to features that are invariant to global rotations which may result in unknown errors when local transformations are introduced. Part-based equivariance was also studied for segmentation in Deng et al. (2023), relying on an intriguing fixed-point convergence procedure."
        },
        {
            "heading": "5 CONCLUSION",
            "text": "We presented APEN, a point network design for approximately piecewise E(3) equivariant models. We implemented APEN networks to tackle recognition tasks such as point cloud segmentation, and classification, demonstrating superior generalization over common baselines. On the theoretical side, our work lays the ground for an analysis of piecewise equivariant networks in terms of their equivariance approximation error. The bounds we present in this study serve as merely initial insights on the possibility of controlling the equivariance approximation error, and further analysis of our suggested bounds is marked as an interesting future work. Further extending this framework for other 3D tasks, e.g., generative modeling and reconstruction is another interesting research venue."
        },
        {
            "heading": "A APPENDIX",
            "text": ""
        },
        {
            "heading": "A.1 PROOFS",
            "text": ""
        },
        {
            "heading": "A.1.1 PROOF OF LEMMA 1",
            "text": "Proof. (Lemma 1) Let X \u2208 U , Z \u2208 {0,1}n\u00d7k, and g \u2208 G. Then,\n\u03c8(g \u22c5 (X,Z),Z) = k\n\u2211 j=1 \u03c8b(g \u22c5 (X,Z)\u2299Zej1Td )\u2299Zej1T =\nk\n\u2211 j=1\n\u03c8b( k\n\u2211 j=1 (gj \u22c5X)\u2299 (Zej1Td ))\u2299Zej1T =\nk\n\u2211 j=1 gj \u22c5 \u03c8b(X \u2299Zej1Td )\u2299Zej1T\nwhere the last equality follows from the fact the \u03c8b is E(d) equivariant and the second equality from the fact that Zej \u2299Ze\u2032j = 0 for j \u2260 j\u2032. Lastly, for any permutation \u03c3k(\u22c5), we have,\nk\n\u2211 j=1 \u03c8b(X \u2299Ze\u03c3k(j)1 T d )\u2299Ze\u03c3k(j)1\nT = k\n\u2211 j=1 \u03c8b(X \u2299Zej)1Td )\u2299Zej1T"
        },
        {
            "heading": "A.1.2 PROOF OF THEOREM 1",
            "text": "Proof. (Theorem 1) Let \u03d5 \u2236 U \u2192 U \u2032 be of the form\n\u03d5(X) = k\n\u2211 j=1 \u03c8b(X \u2299Z\u2020ej1Td )\u2299Z\u2020ej1T , (12)\nwhere (Z\u2020)i,\u2236 = eargmaxj Q(Z\u2223X)ij , and \u03c8b \u2236 U \u2192 U \u2032 is an E(d) equivariant backbone.\nLet A = {Z \u2260 Z\u2020}. Then,\nQ(A) \u2264 n\n\u2211 i=1 (1 \u2212Q(eiZ = eiZ\u2020)) =\nn\n\u2211 i=1 (1 \u2212Qij(i)\u2217)\nwhere j(i)\u2217 = argmaxj Qij . Then, we set\n\u03b4(Q) = n\n\u2211 i=1 (1 \u2212Qij(i)\u2217).\nClearly \u03b4 satisfies conditon 3. Now, Let Q satisfying condition 4 w.r.t. to \u03bb. Let B = {Z \u2223 \u2225ZZT \u2212Z\u2217ZT \u2225 > 0}. Then,\n{Z} = (B \u2229A) \u222a (B \u2229AC) \u222a (BC \u2229A) \u222a (BC \u2229AC).\nNote that for BC \u2229AC there is no equivariance approximation error. For (B \u2229A), and (BC \u2229A) we can bound using \u03b4(Q). Lastly, Z \u2208 (B \u2229AC) means Z\u2020 is a \"bad\" partition, thus \u03bb(Q) \u2264 \u03bb(Qsimple). To conclude, we use a union bound composed of the decomposition above to get that,\nEQZ\u2223X \u2225\u03d5 (g \u22c5 (X,Z)) \u2212 g \u22c5 (\u03d5(X),Z)\u2225 \u2264 (\u03bb(Qsimple) + \u03b4(Q))M.\nA.2 Q PREDICTION\nIn this section we provide an empirical validation to the expected behavior of \u03bb(Qsimple) as k \u2192 n. To that end, we examine a 2D toy example, featuring n = 14 points partitioned to 3 groups. Figure 5 shows this toy example, with distinct colors denoting the ground truth partition. Figure 6 shows a plot of \u03bb(Q) values for k \u2208 [1,14]. The green line shows \u03bb(Q) for the simple Q model, defined by a uniform draw of k parts partition, where each part includes at least one point. The red line shows \u03bb(Q) for a Q model, defined by a Voronoi partition with centers drawn randomly proportionally to k furthest point sampling. Note that as expected, \u03bb(Q)\u2192 0 as k \u2192 n. Next, we provide in Alg. 1 a detailed description of our Q prediction algorithm."
        },
        {
            "heading": "A.3 ADDITIONAL IMPLEMENTATION DETAILS",
            "text": ""
        },
        {
            "heading": "A.3.1 ARCHITECTURE",
            "text": "We start by describing our concrete construction for the encoder, e and d used in our experiments. The network consists of APEN layers of the form,\nAPEN(n, ain, bin, aout, bout) \u2236 Rn\u00d7(ain+3\u00d7bin) \u2192 Rn\u00d7(aout+3\u00d7bout)\nThen, the encoder consists of the following blocks:\nAPEN(n,0,2,17,5)\u2192 APEN(n,17,5,17,5)\u2192 APEN(n,0,2,17,5)\u2192 APEN(n,0,2,65,21).\nThe decoder consists of the following block for the segmentation task:\nAPEN(n,65,21,24,0),\nand for the classification task:\nAPEN(1,65,21,9,0).\nEach APEN block is built on equivariant backbone, implemented with Frame Averaging. In turn, the backbone symmetrize a pointnet network \u03c8. We now describe its details.\nThe network consists of layers of the form\nFC(n, din, dout) \u2236X \u21a6 \u03bd (XW + 1bT ) MaxPool(n, din) \u2236X \u21a6 1[maxXei]\nwhere X \u2208 Rn\u00d7din , W \u2208 Rdin\u00d7dout , b \u2208 Rdout are the learnable parameters, 1 \u2208 Rn is the vector of all ones, [\u22c5] is the concatenation operator, ei is the standard basis in Rdin , and \u03bd is the ReLU activation. We used the following architecture for the first APEN layer:\nFC(n,6,96) L1\u2192 FC(n,96,128) L2\u2192 FC(n,128,160) L3\u2192 FC(n,160,192) L4\u2192\nFC(n,192,224) L5\u2192 MaxPool(n,224) L6\u2192 [L1, L2, L3, L4, L5, L6] L7\u2192\nFC(n,1024,256) L8\u2192 FC(n,256,256) L9\u2192 FC(n,128,32).\nFor the second and third,\nFC(n,32,96) L1\u2192 FC(n,96,128) L2\u2192 FC(n,128,160) L3\u2192 FC(n,160,192) L4\u2192\nFC(n,192,224) L5\u2192 MaxPool(n,224) L6\u2192 [L1, L2, L3, L4, L5, L6] L7\u2192\nFC(n,1024,256) L8\u2192 FC(n,256,256) L9\u2192 FC(n,128,32).\nAlgorithm 1 Q prediction Input: Y ; \u03c4 > 0 merge threshold and f merge frequency\ni\u2190 0 (\u00b5j)\u2190 random furthest point sample of k points from Y \u03c0j \u2190 1k while i < max iter do\n\u03b3ij \u2190 \u03c0jN (Yi;\u00b5j)\u2211l \u03c0lN (Yi;\u00b5l) \u00b5j \u2190 \u2211i\n\u03b3ij \u2211i\u2032 \u03b3i\u2032j Yi\n\u03c0j \u2190 \u2211i \u03b3ijn if i mod f == 0 then (j, j\u2032)\u2190 argmin\n{j,j\u2032}\u2208{j\u2223\u03c0j>0} DKL(N (\u22c5;\u00b5j)\u2223\u2223N (\u22c5;\u00b5\u2032j))\nd\u2190DKL(N (\u22c5;\u00b5j)\u2223\u2223N (\u22c5;\u00b5\u2032j)) while d < \u03c4 do\n\u03c0j \u2190 \u03c0j + \u03c0\u2032j \u03c0\u2032j \u2190 0 (j, j\u2032)\u2190 argmin\n{j,j\u2032}\u2208{j\u2223\u03c0j>0} DKL(N (\u22c5;\u00b5j)\u2223\u2223N (\u22c5;\u00b5\u2032j))\nd\u2190DKL(N (\u22c5;\u00b5j)\u2223\u2223N (\u22c5;\u00b5\u2032j)) end while\nend if i\u2190 i + 1\nend while (\u00b5\u0303j , \u03c0\u0303j)\u2190 (\u00b5j , \u03c0j) (\u00b5\u2217j , \u03c0\u2217j )\u2190 (\u00b5\u0303j , \u03c0\u0303j) + I\u22121(\u00b5\u0303j , \u03c0\u0303j)s(Y ; (\u00b5\u0303j , \u03c0\u0303j)) Qpredij \u2190 N (yi;\u00b5\u2217j ,\u03c3)\u03c0 \u2217 j\n\u2211kj=1N (yi;\u00b5\u2217j ,\u03c3)\u03c0\u2217j Output: Qpred, a (differential) minimizer of E(Y )\nAnd lastly,\nFC(n,32,96) L1\u2192 FC(n,96,128) L2\u2192 FC(n,128,160) L3\u2192 FC(n,160,192) L4\u2192\nFC(n,192,224) L5\u2192 MaxPool(n,224) L6\u2192 [L1, L2, L3, L4, L5, L6] L7\u2192\nFC(n,1024,256) L8\u2192 FC(n,256,256) L9\u2192 FC(n,128,128)."
        },
        {
            "heading": "A.3.2 HYPER PARAMETERS AND TRAINING DETAILS",
            "text": "We set \u03c3l = (0.002,0.005,0.008,0.1). The number of iterations for the EM was 16. We trained our networks using the ADAM (Kingma & Ba, 2014) optimizer, setting the batch size to 8. We set a fixed learning rate of 0.001. All models were trained for 3000 epochs. Training was done on a single Nvidia V-100 GPU, using PYTORCH deep learning framework (Paszke et al., 2019)."
        },
        {
            "heading": "A.4 ADDITIONAL RESULTS",
            "text": "In this section, we present visualizations of the learned partitions Qpred across layers in the APEN encoder. Figure 7 shows the learned APEN encoder layers partitions from the experiment in section 3.1, while Figure 8 shows partitions from the experiment in section 3.2. Each input point is assigned distinctive colors according to argmaxj Q pred ij . It is worth noting that progressing from left to right, the predicted partitions tend to become coarser, a behavior encouraged by setting the hyper-parameter \u03c3l+1 > \u03c3l."
        },
        {
            "heading": "A.5 SUBJECT CLASSIFICATION EXPERIMENT",
            "text": "Here we provide the results of the point cloud classification experiment described in the main text. Fig. 9 shows several typical examples from the considered split. Note the relatively large difference in the distribution of poses. Tab. 3 logs the quantitative evaluation, validating our framework\u2019s superiority in this case as well."
        }
    ],
    "year": 2023
}