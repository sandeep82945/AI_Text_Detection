{
    "abstractText": "Reasoning over Temporal Knowledge Graphs (TKGs) that predicts temporal facts (e.g., events) in the future is crucial for many applications. The temporal facts in existing TKGs only contain their core entities (i.e., the entities playing core roles therein) and formulate them as quadruples, i.e., (subject entity, predicate, object entity, timestamp). This formulation oversimplifies temporal facts and inevitably causes information loss. Therefore, we propose to describe a temporal fact more accurately as an ntuple, containing not only its predicate and core entities, but also its auxiliary entities, as well as the roles of all entities. By so doing, TKGs are augmented to N-tuple Temporal Knowledge Graphs (N-TKGs). To conduct reasoning over N-TKGs, we further propose N-tuple Evolutional Network (NE-Net). It recurrently learns the evolutional representations of entities and predicates in temporal facts at different timestamps in the history via modeling the relations among those entities and predicates. Based on the learned representations, reasoning tasks at future timestamps can be realized via taskspecific decoders. Experiment results on two newly built datasets demonstrate the superiority of N-TKG and the effectiveness of NE-Net.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zhongni Hou"
        },
        {
            "affiliations": [],
            "name": "Xiaolong Jin"
        },
        {
            "affiliations": [],
            "name": "Zixuan Li"
        },
        {
            "affiliations": [],
            "name": "Long Bai"
        },
        {
            "affiliations": [],
            "name": "Saiping Guan"
        },
        {
            "affiliations": [],
            "name": "Yutao Zeng"
        },
        {
            "affiliations": [],
            "name": "Jiafeng Guo"
        },
        {
            "affiliations": [],
            "name": "Xueqi Cheng"
        }
    ],
    "id": "SP:4e0eeb84a7ee347d16a9ebf98328a9b87b0df94b",
    "references": [
        {
            "authors": [
                "Johan Bollen",
                "Huina Mao",
                "Xiaojun Zeng."
            ],
            "title": "Twitter mood predicts the stock market",
            "venue": "Journal of computational science, 2(1):1\u20138.",
            "year": 2011
        },
        {
            "authors": [
                "Antoine Bordes",
                "Nicolas Usunier",
                "Alberto GarciaDuran",
                "Jason Weston",
                "Oksana Yakhnenko."
            ],
            "title": "Translating embeddings for modeling multirelational data",
            "venue": "Advances in neural information processing systems, pages 2787\u20132795.",
            "year": 2013
        },
        {
            "authors": [
                "Shib Sankar Dasgupta",
                "Swayambhu Nath Ray",
                "Partha Talukdar."
            ],
            "title": "Hyte: Hyperplane-based temporally aware knowledge graph embedding",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2001\u2013",
            "year": 2018
        },
        {
            "authors": [
                "Songgaojun Deng",
                "Huzefa Rangwala",
                "Yue Ning."
            ],
            "title": "Learning dynamic context graphs for predicting social events",
            "venue": "Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 1007\u20131016.",
            "year": 2019
        },
        {
            "authors": [
                "Tim Dettmers",
                "Pasquale Minervini",
                "Pontus Stenetorp",
                "Sebastian Riedel."
            ],
            "title": "Convolutional 2d knowledge graph embeddings",
            "venue": "Thirty-Second AAAI Conference on Artificial Intelligence.",
            "year": 2018
        },
        {
            "authors": [
                "Crist\u00f3bal Esteban",
                "Volker Tresp",
                "Yinchong Yang",
                "Stephan Baier",
                "Denis Krompa\u00df."
            ],
            "title": "Predicting the co-evolution of event and knowledge graphs",
            "venue": "2016 19th International Conference on Information Fusion (FUSION), pages 98\u2013105. IEEE.",
            "year": 2016
        },
        {
            "authors": [
                "Bahare Fatemi",
                "Perouz Taslakian",
                "David Vazquez",
                "David Poole."
            ],
            "title": "Knowledge hypergraphs: prediction beyond binary relations",
            "venue": "Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Mikhail Galkin",
                "Priyansh Trivedi",
                "Gaurav Maheshwari",
                "Ricardo Usbeck",
                "Jens Lehmann."
            ],
            "title": "Message passing for hyper-relational knowledge graphs",
            "venue": "arXiv preprint arXiv:2009.10847.",
            "year": 2020
        },
        {
            "authors": [
                "Rishab Goel",
                "Seyed Mehran Kazemi",
                "Marcus Brubaker",
                "Pascal Poupart."
            ],
            "title": "Diachronic embedding for temporal knowledge graph completion",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 3988\u20133995.",
            "year": 2020
        },
        {
            "authors": [
                "Saiping Guan",
                "Xiaolong Jin",
                "Jiafeng Guo",
                "Yuanzhuo Wang",
                "Xueqi Cheng."
            ],
            "title": "Neuinfer: Knowledge inference on n-ary facts",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6141\u20136151.",
            "year": 2020
        },
        {
            "authors": [
                "Saiping Guan",
                "Xiaolong Jin",
                "Yuanzhuo Wang",
                "Xueqi Cheng."
            ],
            "title": "Link prediction on n-ary relational data",
            "venue": "The World Wide Web Conference, pages 583\u2013593.",
            "year": 2019
        },
        {
            "authors": [
                "Zhen Han",
                "Peng Chen",
                "Yunpu Ma",
                "Volker Tresp."
            ],
            "title": "Dyernie: Dynamic evolution of riemannian manifold embeddings for temporal knowledge graph completion",
            "venue": "arXiv preprint arXiv:2011.03984.",
            "year": 2020
        },
        {
            "authors": [
                "Zhen Han",
                "Peng Chen",
                "Yunpu Ma",
                "Volker Tresp."
            ],
            "title": "Explainable subgraph reasoning for forecasting on temporal knowledge graphs",
            "venue": "International Conference on Learning Representations.",
            "year": 2020
        },
        {
            "authors": [
                "Zhen Han",
                "Zifeng Ding",
                "Yunpu Ma",
                "Yujia Gu",
                "Volker Tresp."
            ],
            "title": "Learning neural ordinary equations for forecasting future links on temporal knowledge graphs",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Process-",
            "year": 2021
        },
        {
            "authors": [
                "Zhen Han",
                "Zifeng Ding",
                "Yunpu Ma",
                "Yujia Gu",
                "Volker Tresp."
            ],
            "title": "Temporal knowledge graph forecasting with neural ode",
            "venue": "arXiv preprint arXiv:2101.05151.",
            "year": 2021
        },
        {
            "authors": [
                "Woojeong Jin",
                "Meng Qu",
                "Xisen Jin",
                "Xiang Ren."
            ],
            "title": "Recurrent event network: Autoregressive structure inference over temporal knowledge graphs",
            "venue": "EMNLP.",
            "year": 2020
        },
        {
            "authors": [
                "Woojeong Jin",
                "Changlin Zhang",
                "Pedro Szekely",
                "Xiang Ren."
            ],
            "title": "Recurrent event network for reasoning over temporal knowledge graphs",
            "venue": "arXiv preprint arXiv:1904.05530.",
            "year": 2019
        },
        {
            "authors": [
                "Julien Leblay",
                "Melisachew Wudage Chekol."
            ],
            "title": "Deriving validity time in knowledge graph",
            "venue": "Companion Proceedings of the The Web Conference 2018, pages 1771\u20131776. International World Wide Web Conferences Steering Committee.",
            "year": 2018
        },
        {
            "authors": [
                "Yujia Li",
                "Shiliang Sun",
                "Jing Zhao."
            ],
            "title": "Tirgn: time-guided recurrent graph network with localglobal historical patterns for temporal knowledge graph reasoning",
            "venue": "Proceedings of the Thirty-First International Joint Conference on Artificial Intelli-",
            "year": 2022
        },
        {
            "authors": [
                "Zixuan Li",
                "Saiping Guan",
                "Xiaolong Jin",
                "Weihua Peng",
                "Yajuan Lyu",
                "Yong Zhu",
                "Long Bai",
                "Wei Li",
                "Jiafeng Guo",
                "Xueqi Cheng."
            ],
            "title": "Complex evolutional pattern learning for temporal knowledge graph reasoning",
            "venue": "arXiv preprint arXiv:2203.07782.",
            "year": 2022
        },
        {
            "authors": [
                "Zixuan Li",
                "Xiaolong Jin",
                "Saiping Guan",
                "Wei Li",
                "Jiafeng Guo",
                "Yuanzhuo Wang",
                "Xueqi Cheng."
            ],
            "title": "Search from history and reason for future: Two-stage reasoning on temporal knowledge graphs",
            "venue": "arXiv preprint arXiv:2106.00327.",
            "year": 2021
        },
        {
            "authors": [
                "Zixuan Li",
                "Xiaolong Jin",
                "Wei Li",
                "Saiping Guan",
                "Jiafeng Guo",
                "Huawei Shen",
                "Yuanzhuo Wang",
                "Xueqi Cheng."
            ],
            "title": "Temporal knowledge graph reasoning based on evolutional representation learning",
            "venue": "Proceedings of the 44th International ACM SIGIR",
            "year": 2021
        },
        {
            "authors": [
                "Yu Liu",
                "Quanming Yao",
                "Yong Li."
            ],
            "title": "Roleaware modeling for n-ary relational knowledge bases",
            "venue": "Proceedings of the Web Conference 2021, pages 2660\u20132671.",
            "year": 2021
        },
        {
            "authors": [
                "Namyong Park",
                "Fuchen Liu",
                "Purvanshi Mehta",
                "Dana Cristofor",
                "Christos Faloutsos",
                "Yuxiao Dong."
            ],
            "title": "Evokg: Jointly modeling event time and network structure for reasoning over temporal knowledge graphs",
            "venue": "Proceedings of the Fifteenth ACM Interna-",
            "year": 2022
        },
        {
            "authors": [
                "Paolo Rosso",
                "Dingqi Yang",
                "Philippe Cudr\u00e9Mauroux."
            ],
            "title": "Beyond triplets: hyper-relational knowledge graph embedding for link prediction",
            "venue": "Proceedings of The Web Conference 2020, pages 1885\u20131896.",
            "year": 2020
        },
        {
            "authors": [
                "Ali Sadeghian",
                "Miguel Rodriguez",
                "Daisy Zhe Wang",
                "Anthony Colas."
            ],
            "title": "Temporal reasoning over event knowledge graphs",
            "venue": "Workshop on Knowledge Base Construction, Reasoning and Mining.",
            "year": 2016
        },
        {
            "authors": [
                "Michael Schlichtkrull",
                "Thomas N Kipf",
                "Peter Bloem",
                "Rianne Van Den Berg",
                "Ivan Titov",
                "Max Welling."
            ],
            "title": "Modeling relational data with graph convolutional networks",
            "venue": "European Semantic Web Conference, pages 593\u2013607. Springer.",
            "year": 2018
        },
        {
            "authors": [
                "Alessio Signorini",
                "Alberto Maria Segre",
                "Philip M Polgreen."
            ],
            "title": "The use of twitter to track levels of disease activity and public concern in the us during the influenza a h1n1 pandemic",
            "venue": "PloS one, 6(5):e19467.",
            "year": 2011
        },
        {
            "authors": [
                "Eleftherios Spyromitros",
                "Grigorios Tsoumakas",
                "Ioannis Vlahavas."
            ],
            "title": "An empirical study of lazy multilabel classification algorithms",
            "venue": "Hellenic conference on artificial intelligence, pages 401\u2013406. Springer.",
            "year": 2008
        },
        {
            "authors": [
                "Haohai Sun",
                "Shangyi Geng",
                "Jialun Zhong",
                "Han Hu",
                "Kun He."
            ],
            "title": "Graph hawkes transformer for extrapolated reasoning on temporal knowledge graphs",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages",
            "year": 2022
        },
        {
            "authors": [
                "Haohai Sun",
                "Jialun Zhong",
                "Yunpu Ma",
                "Zhen Han",
                "Kun He."
            ],
            "title": "Timetraveler: Reinforcement learning for temporal knowledge graph forecasting",
            "venue": "arXiv preprint arXiv:2109.04101.",
            "year": 2021
        },
        {
            "authors": [
                "Shikhar Vashishth",
                "Soumya Sanyal",
                "Vikram Nitin",
                "Partha Talukdar."
            ],
            "title": "Composition-based multirelational graph convolutional networks",
            "venue": "International Conference on Learning Representations.",
            "year": 2019
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems, 30.",
            "year": 2017
        },
        {
            "authors": [
                "Zhen Wang",
                "Jianwen Zhang",
                "Jianlin Feng",
                "Zheng Chen."
            ],
            "title": "Knowledge graph embedding by translating on hyperplanes",
            "venue": "Proceedings of the AAAI conference on artificial intelligence, volume 28.",
            "year": 2014
        },
        {
            "authors": [
                "Jianfeng Wen",
                "Jianxin Li",
                "Yongyi Mao",
                "Shini Chen",
                "Richong Zhang."
            ],
            "title": "On the representation and embedding of knowledge bases beyond binary relations",
            "venue": "arXiv preprint arXiv:1604.08642.",
            "year": 2016
        },
        {
            "authors": [
                "Yi Xu",
                "Junjie Ou",
                "Hui Xu",
                "Luoyi Fu."
            ],
            "title": "Temporal knowledge graph reasoning with historical contrastive learning",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 4765\u20134773.",
            "year": 2023
        },
        {
            "authors": [
                "Donghan Yu",
                "Yiming Yang."
            ],
            "title": "Improving hyper-relational knowledge graph completion",
            "venue": "arXiv preprint arXiv:2104.08167.",
            "year": 2021
        },
        {
            "authors": [
                "Min-Ling Zhang",
                "Zhi-Hua Zhou."
            ],
            "title": "Ml-knn: A lazy learning approach to multi-label learning",
            "venue": "Pattern recognition, 40(7):2038\u20132048.",
            "year": 2007
        },
        {
            "authors": [
                "Richong Zhang",
                "Junpeng Li",
                "Jiajie Mei",
                "Yongyi Mao."
            ],
            "title": "Scalable instance reconstruction in knowledge bases via relatedness affiliated embedding",
            "venue": "Proceedings of the 2018 World Wide Web Conference, pages 1185\u20131194.",
            "year": 2018
        },
        {
            "authors": [
                "Ling Zhao",
                "Yujiao Song",
                "Chao Zhang",
                "Yu Liu",
                "Pu Wang",
                "Tao Lin",
                "Min Deng",
                "Haifeng Li."
            ],
            "title": "T-gcn: A temporal graph convolutional network for traffic prediction",
            "venue": "IEEE Transactions on Intelligent Transportation Systems, 21(9):3848\u20133858.",
            "year": 2019
        },
        {
            "authors": [
                "Cunchao Zhu",
                "Muhao Chen",
                "Changjun Fan",
                "Guangquan Cheng",
                "Yan Zhan."
            ],
            "title": "Learning from history: Modeling temporal knowledge graphs with sequential copy-generation networks",
            "venue": "arXiv preprint arXiv:2012.08492.",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Knowledge Graphs (KGs), which represent facts in the form of triples (Bordes et al., 2013; Dettmers et al., 2018), i.e., (subject entity, predicate, object entity), have attracted increasing research attention in recent years. As the validity of facts can change over time, Temporal Knowledge Graphs (TKGs) extend triples into quadruples (Han et al., 2020b; Park et al., 2022), i.e., (subject entity, predicate, object entity, timestamp), to represent temporal facts, such as events. Reasoning over TKGs aims to answer queries about future temporal facts, such as (America, Sanction, ?, 2024-1-10), based on the\n\u2217Corresponding authors.\nobserved history. Such task can be applied to many practical applications, including disaster relief (Signorini et al., 2011), financial analysis (Bollen et al., 2011), etc.\nActually, besides its core entities (i.e., subject entity and object entity), a temporal fact often involves other auxiliary roles and the corresponding arguments (i.e., entities). As illustrated in Figure 1, the \u201cDemand\u201d event involves not only the core roles and entities, but also the auxiliary role \u201cDemand Content\u201d and its corresponding entity \u201cOil\u201d. Moreover, the number of roles in temporal facts may be variable. For example, the \u201cHold a Visit\u201d event contains two roles, while the \u201cCriticize\u201d event has three. Above all, the existing quadruple-based formulation cannot describe temporal facts accurately, thus limiting the applications of TKGs.\nMotivated by these, we propose to describe temporal facts more accurately as n-tuples and correspondingly augment TKGs as N-tuple Temporal Knowledge Graphs (N-TKGs), so as not to cause information loss. Specifically, each ntuple in N-TKGs is denoted in form of (predicate, role1:entity1, ..., timestamp). For example, the event \u201cConsult\u201d in Figure 1 is described as (Consult, Client: Germany, Consultant: France, Consult Content: Iran, t2).\nSimilar to that of TKGs, reasoning over N-TKGs is an important task for their practical applications. However, existing methods for the reasoning task on either TKGs with quadruples or static KGs with n-tuples have limitations when facing N-TKGs. In more detail, the reasoning methods for quadruplebased TKGs (Dasgupta et al., 2018; Goel et al., 2020; Jin et al., 2020; Han et al., 2020b; Park et al., 2022) cannot be directly applied to n-tuples and have to take adaptation measures. Those reasoning methods for static n-tuple KGs (Rosso et al., 2020; Guan et al., 2020; Liu et al., 2021; Guan et al., 2019) cannot capture temporal information contained in those facts at different timestamps.\nTo solve the above problems, we propose a model called N-tuple Evolutional Network (NENet) to conduct reasoning tasks over N-TKGs. NENet consists of an entity-predicate encoder and task-specific decoders. The entity-predicate encoder is used to learn the evolutional representations of entities and predicates in different temporal facts. Specifically, at each timestamp, it employs an entity-predicate unit to capture the relations among entities and predicates formed upon concurrent facts. It also adopts a core-entity unit to emphasize and more directly model the relations between core entities (in terms of predicates) of individual temporal facts, as such relations contain the most primary information of the facts. Next, an aggregation unit is utilized to integrate the outputs of these two units so as to obtain more accurate representations of entities and predicates. Note that the encoder employs a recurrent mechanism to autoregressively learn the evolutional representations from the facts at temporally adjacent timestamps, and thus implicitly reflects temporal behavioral patterns of entities in their evolutional representations.\nNE-Net finally leverages task-specific decoders to conduct different reasoning tasks, namely, predicate reasoning and entity reasoning, respectively, based on the learned representations of entities and predicates. In addition, as there is no N-TKG dataset publicly available, we construct two new datasets, named NWIKI and NICE, to facilitate the research on reasoning over N-TKGs.\nIn summary, our contributions are as follows: (1) We propose to use n-tuples to describe temporal facts more accurately, and further enhance TKGs as N-TKGs; (2) We propose NE-Net to conduct the reasoning tasks over N-TKGs. It leverages an entity-predicate encoder to learn accurate evolu-\ntional representations via capturing the relations among entities and predicates formed upon concurrent facts and simultaneously emphasizing the relations between core entities. NE-Net further utilizes task-specific decoders to address different reasoning tasks; (3) Experiments on the two new datasets demonstrate the superiority of N-TKG and the effectiveness of NE-Net."
        },
        {
            "heading": "2 Related Works",
            "text": "Static N-tuple KG Reasoning. Static n-tuple KG reasoning aims to infer the missing elements of a given n-tuple. Existing methods can be divided into three categories, namely, hyperplane methods, multi-linear methods and neural methods. Hyperplane methods (Wen et al., 2016; Zhang et al., 2018) project entities into relation hyperplanes to calculate the plausibility scores for ntuples. Multi-linear methods (Liu et al., 2021) apply the multi-linear product to measure the plausibility scores. Neural methods (Guan et al., 2019; Galkin et al., 2020) leverage CNN or GCN to capture the relatedness scores of role-entity pairs in n-tuples. Particularly, NeuInfer (Guan et al., 2020) and HINGE (Rosso et al., 2020) notice that different elements in n-tuples are of different importance and propose to represent an n-tuple as a main triplet along with auxiliary role-entity pairs. However, the occurrence time of temporal facts is viewed as a common kind of information about the facts and is usually ignored by the above methods (Rosso et al., 2020). Therefore, these methods cannot model the temporal behavioral patterns across adjacent timestamps and are not effective enough to exploit historical data for future predictions. TKG Reasoning. There are two different task settings for TKG reasoning, namely, interpolation and extrapolation (Li et al., 2022c; Han et al., 2021b; Sun et al., 2021; Li et al., 2022b,a). TKG reasoning under the former setting is to infer missing elements of facts at known timestamps (i.e., the history) (Sadeghian et al., 2016; Esteban et al., 2016; Han et al., 2020a; Leblay and Chekol, 2018). Under the interpolation setting, HyTE (Dasgupta et al., 2018) extends the idea of TransH (Wang et al., 2014) and associates each timestamp with a corresponding hyperplane. DE-DistMult (Goel et al., 2020) and DE-SimplE (Goel et al., 2020) both utilize a diachronic embedding for entities and relations, dividing the representations of entities into a static segment and a time-varying seg-\nment. TKG reasoning under the latter setting, which this paper focuses on, is to infer missing elements of facts at future timestamps (Han et al., 2020b, 2021a; Park et al., 2022). RE-Net (Jin et al., 2020) and REGCN (Li et al., 2021b) both adopt a relation-aware GCN and a recurrent component to capture temporal associations within the history. CyGNet (Zhu et al., 2020) applies a timeaware copy-generation network to model the repetitive pattern of frequently occurring facts. Focusing on the explainable TKG reasoning methods, TITer (Sun et al., 2021) and CluSTeR (Li et al., 2021a) employ reinforcement learning to adaptively search informational facts in the history. More recently, CEN (Li et al., 2022b) utilizes a length-aware CNN to mine complex temporal patterns of different lengths. CENET (Xu et al., 2023) employs the contrastive learning strategy to identify potential entities from historical and non-historical dependency. In the above methods, the facts are all in the form of quadruples. Therefore, they cannot directly model the temporal associations involving auxiliary entities."
        },
        {
            "heading": "3 Problem Formulation",
            "text": "N-TKG. An N-TKG G can be formalized as a sequence of KGs with timestamps, i.e., G = {G1,G2, ...,Gt, ...}. The KG, Gt, at timestamp t can be denoted as Gt=(Vpred, Vent, V\u03c1, Ft), where Vpred, Vent, V\u03c1, Ft are the sets of predicates, entities, roles and temporal facts (hereinafter referred to as facts if not causing any confusion) occurring at timestamp t, respectively. Each fact f \u2208 Ft is denoted as (pred, \u03c11 :e1, ..., \u03c1i : ei, ...,\u03c1n : en, t), where pred \u2208 Vpred is its predicate; each ei \u2208 Vent (1 \u2264 i \u2264 n) is an entity involved in this fact, where\nit plays the role as \u03c1i \u2208 V\u03c1; n and t are the total number of role-entity pairs and the timestamp of the n-tuple f , respectively. Note that in any fact f \u2208 Ft, e1 and e2 are the two core entities, corresponding to its subject and object ones, respectively. Moreover, in this paper, the same type of facts is denoted with the same predicate. Therefore, pred also denotes the type of f . Predicate reasoning. It aims to predict the type of the fact (i.e., predicate) that will occur on the given entity es at the next timestamp t+1. In other words, it aims to answer the query like (?, - : -, ..., - : es, ...,- : -, t+1). Here, only the target entity es is available and it can be any entity in the fact. Entity reasoning. It aims to predict the unknown entity playing the given role \u03c1q in a fact of the type specified by predicate pred at the next timestamp t+ 1. Formally, this task aims to answer the query like (pred, \u03c11 :e1, \u03c12 :e2, ..., \u03c1q :?, ..., \u03c1n :en, t+1). Here, all \u03c1i and ei (1 \u2264 i \u2264 n and i \u0338= q) are given."
        },
        {
            "heading": "4 The NE-Net Model",
            "text": "As illustrated in Figure 2, NE-Net consists of an entity-predicate encoder and task-specific decoders. The entity-predicate encoder recurrently models the relations among entities and predicates generated by concurrent facts in the history and outputs the evolutional representations of all entities and predicates. Based on the learned representations, task-specific decoders are adopted to conduct different reasoning tasks."
        },
        {
            "heading": "4.1 The Entity-Predicate Encoder",
            "text": "There are mainly two kinds of information in historical facts, namely, the explicit relations among entities and predicates in concurrent facts at the\nsame timestamp, and the implicit temporal behavioral patterns of entities reflected in different timestamps. The entity-predicate encoder incorporates these two kinds of information into the representations of entities and predicates, via recurrently modeling the KG sequences. In this paper, we consider the history at the latest m timestamps, i.e., {Gt\u2212m+1,Gt\u2212m+2, ...,Gt}, where t is the current timestamp."
        },
        {
            "heading": "4.1.1 Entity-Predicate Modeling in Concurrent Facts",
            "text": "In this paper, by denoting a temporal fact f as (pred, \u03c11 :e1, ..., \u03c1i : ei, ...,\u03c1n : en, t), its predicate pred forms natural relations with its all entities ei (1 \u2264 i \u2264 n) specified by \u03c1i, respectively. Such relations between the entities and predicate preserve the relatively complete information of the fact and are referred to as the entity-predicate relations. Among these relations, those between the predicate and core entities are more important than others, as they reflect the primary information of the fact and should thus be given more attention. Besides these relations within a fact, by sharing the same entity, the predicates and entities in different facts, being concurrent in the same timestamp, may form more complicated structures.\nTo capture the above relations and structures so as to finally learn the representations of entities and predicates, the encoder first utilizes an EntityPredicate unit (\u201cEP unit\u201d in Figure 2) to model the relatively complete entity-predicate relations in concurrent facts. It then utilizes a Core-Entity unit (\u201cCE unit\u201d in Figure 2) to highlight the relations between core entities. Finally, the above relational information captured by the EP and CE units is integrated via an Attention-based Aggregation unit (\u201cAA unit\u201d in Figure 2) to obtain more accurate evolutional representations of entities and predicates.\nThe Entity-Predicate Unit. In order to employ the EP unit to model the relatively complete entity-predicate relations in all concurrent facts at timestamp \u03c4 (t \u2212m \u2264 \u03c4 < m), we first need to construct an Entity-Predicate Graph (\u201cEPG\u201d in Figure 2) based on them. To do so, for each fact, we denote its predicate and all entities as the nodes of the EPG and the entity-predicate relations as its edges. As aforesaid, in this paper, the facts of the same type use the same predicate. Therefore, in order to avoid confusion between different facts of the same type, we create the same num-\nber of predicate instance nodes in the EPG, each of which corresponds to a specific fact. By so doing, the EPG at timestamp \u03c4 can be formulated as G\u03c4 = (Vent \u222a V\u0302 \u03c4pred, E\u03c4 ), where Vent, V\u0302 \u03c4pred and E\u03c4 are the sets of entity nodes, predicate instance nodes, and edges, respectively. Here, each predicate instance node is only associated with the entities in the corresponding fact. And, there is a mapping function \u03c6(\u00b7) : V\u0302 \u03c4pred\u2192Vpred, which maps the predicate instance node v to its type \u03c6(v)\u2208Vpred to indicate which kind of predicate it belongs to. Each edge eij = (vi, \u03c1, vj) \u2208 E\u03c4 links the entity node vi and the predicate instance node vj via the corresponding role \u03c1. Note that for those entities and predicates not involved in any fact at timestamp \u03c4 , self-loop edges are added.\nUpon the EPG, the EP unit works with two steps, namely, the message-passing step and the predaggregation step. It finally updates and outputs the entity representation matrix H\u0302\u03c4ent and the predicate representation matrix H\u03c4pred at timestamp \u03c4 .\nThe message-passing step employs a CompGCN (Vashishth et al., 2019) with \u03c91 layers, to update the representations of entities and predicate instances. Specifically, the representation of the node v at layer l \u2208 [0, \u03c91 \u2212 1] is obtained as follows:\nh\u03c4,l+1v = \u03c8  \u2211 (u,\u03c1,v)\u2208G\u03c4 Wl0(h \u03c4,l u +\u03c1)+W l 1h \u03c4,l v  , (1) where h\u03c4,lv denotes the representation of node v obtained after l layers; \u03c1 denotes the representation of the role \u03c1; Wl0 and W l 1 are the parameters in the l-th layer; \u03c8(\u00b7) is an activation function. The representations of predicate instance nodes at the first layer are obtained by looking up the input evolutional representation matrix of predicates H\u03c4\u22121pred according to its type. In particularly, at the first timestamp t\u2212m+1, the randomly initialized predicate representation matrix Hpred is used as the input. The representations of entity nodes at the first layer are calculated by the CE unit, which will be introduced in the following. The representations of roles are obtained from the role representation matrix H\u03c1, which is randomly initialized and shared across timestamps.\nAt timestamp \u03c4 , the pred-aggregation step updates the evolutional representation of a predicate h\u03c4pred by aggregating the information of all related nodes. For a predicate pred, after the message passing step, its different predicate instance nodes have different representations due to the different\ninvolving entities. NE-Net utilizes the mean pooling (MP) operation to summarize the information of its predicate instance nodes h\u0302 \u03c4\npred:\nh\u0302 \u03c4\npred =MP  \u2211 v\u2208{v|\u03c6(v)=pred} h\u03c4v,pred  . (2) Besides, for a predicate pred, to preserve the inherent semantic information, NE-Net further incorporates the initial representation hpred, into its evolutional representation h\u03c4pred at timestamp \u03c4 as:\nh\u03c4pred = g(h\u0302pred,hpred) = W2(h\u0302 \u03c4 pred||hpred), (3)\nwhere W2 is a learnable parameter matrix and || denotes the concatenation operation.\nThe Core-Entity Unit. As aforementioned, the most important information in a fact is the relation between its two core entities in terms of the predicate, which is more important than other relations. To emphasize these relations between core entities more directly, this unit views predicates as edges, and constructs the Core Entity Graph (\u201cCEG\u201d in Figure 2) for concurrent facts at timestamp \u03c4 . Specifically, the CEG at timestamp \u03c4 can be formulated as G\u0303\u03c4 = (Vent, E\u0303\u03c4 ), where Vent and E\u0303\u03c4 are the sets of core entity nodes and edges, respectively. Each edge eik = (vi, pred, vk) \u2208 E\u0303\u03c4 links the two core entity nodes vi and vk corresponding to a certain fact occurring at timestamp \u03c4 via its predicate pred of an n-tuple. Similarly, for those entities not involved in any fact, self-loop edges are added.\nBased on the constructed CEG G\u0303\u03c4 and the input representation matrix of entities H\u03c4\u22121ent at timestamp \u03c4 \u2212 1, this unit leverages an RGCN (Schlichtkrull et al., 2018) with \u03c92 layers to encode the relations between core entities into the updated entity representation matrix H\u0303\u03c4ent:\nH\u0303\u03c4,l+1ent = RGCN(H\u0303 \u03c4,l ent, G\u0303\u03c4 ), (4)\nwhere H\u0303\u03c4,lent denotes the updated entity representation matrix obtained at the l-th layer. The representations of entity nodes at the first layer are obtained by looking up the input evolutional representation matrix of entities H\u03c4\u22121ent . For the first timestamp t \u2212 m + 1, the randomly initialized entity representation matrix Hent is used as the input. As the relations between core entities maintain the most primary information of temporal facts, NE-Net directly uses the output of this unit, i.e., H\u0303\u03c4ent, as the input entity representation matrix of the entitypredicate unit to emphasizing such information.\nThe Attention-based Aggregation Unit. To integrate the information in the above two kinds of relations, i.e., H\u0303ent and H\u0302ent, the attentionbased aggregation unit is utilized to learn importance weights of the two kinds of information, and adaptively combine them in order to obtain the final evolutional representations of entities H\u03c4ent at timestamp \u03c4 . Specifically, take the entity i as an example, its evolutional representation h\u03c4i,ent is calculated as follows:\nh\u03c4i,ent = a\u0303 \u03c4 i,enth\u0303\n\u03c4 i,ent + a\u0302 \u03c4 i,enth\u0302 \u03c4 i,ent, (5)\nwhere h\u0303i,ent and h\u0302 \u03c4\ni,ent are the updated representations of entity i outputted by the above two units, a\u0303i,ent and a\u0302i,ent measure the importance weights of two representations. Taking the representation h\u0303 \u03c4 i,ent as an example, NE-Net first gets its importance value w\u0303\u03c4i,ent: w\u0303\u03c4i,ent = f(h\u0303 \u03c4 i,ent) = qtanh(W3h\u0303 \u03c4 i,ent + b), (6)\nwhere W3 is the weight matrix, q is the learnable importance gate. Similarly, w\u0302\u03c4i,ent = f(h\u0302 \u03c4\ni,ent). After obtaining the importance values of each representation, NE-Net normalizes them to get the final importance weights, i.e., a\u0303\u03c4i,ent and a\u0302 \u03c4 i,ent, via the softmax function."
        },
        {
            "heading": "4.1.2 Entity-Predicate Modeling across Different Timestamps",
            "text": "The temporal patterns hidden in the historical facts of a specific entity implicitly reflect its behavioral trends and preferences. As the temporal facts at a specific timestamp are already modeled in the evolutional representations of entities and predicates via the above three units, NE-Net directly uses the evolutional representations of entities and predicates learned from timestamp \u03c4 \u22121, namely, H\u03c4\u22121ent and H\u03c4\u22121pred, as the input of interaction modeling step for concurrent facts. By recurrently modeling on KGs at adjacent timestamps, the temporal behavioral patterns of entities can be modeled."
        },
        {
            "heading": "4.2 Task-specific Decoders",
            "text": "Based on the evolutional representations of entities and predicates at timestamp t, NE-Net utilizes task-specific decoders to conduct different types of reasoning tasks."
        },
        {
            "heading": "4.2.1 Predicate Reasoning Decoder",
            "text": "Give the query of predicate reasoning (?,- : -, ..., -: es, ..., - : -, t+ 1), NE-Net multiplies the evolutional representation of es at timestamp t with the evolutional representations of predicates Htpred,\nto generate the conditional probability vector p(pred|es,G1:t):\np(pred|es,G1:t) = \u03c3(H\u03c4predets), (7)\nwhere \u03c3(\u00b7) is the sigmoid function."
        },
        {
            "heading": "4.2.2 Entity Reasoning Decoder",
            "text": "To deal with queries having a varied number of role-entity pairs and capture the relations among elements within the query, NE-Net reorganizes role-entity pairs in a query as a sequence and then designs a Transformer-based decoder for the entity reasoning task. Specifically, given a query (pred, \u03c11 : e1, ..., \u03c1q :?, ..., \u03c1n : en, t+1), NE-Net first replaces the missing entity with a special token [MASK], and linearize the query as: X = (pred, \u03c11,e1, ..., \u03c1q, [MASK], ..., \u03c1n,en). To identify which kind of element the model is dealing with, each element xi \u2208 X is assigned with a type typei \u2208 {0, 1, 2}, where 0 represents a predicate, 1 represents a role, and 2 represents an entity. The input representation of the i-th element in the sequence, i.e., h0i , is calculated by:\nh0i = x t i + typei, (8)\nwhere xti is generated by looking up the evolutional representation matrices of entities and predicates, i.e., Htent and H t pred, and the role representation matrix, i.e., H\u03c1; typei is obtained by looking up the learnable type representation matrix Htype. Then, all input representations are fed into a stack of L successive Transformer blocks (Vaswani et al., 2017). Based on the output of Transformer, the final representation of [MASK], i.e., hLq , can be obtained, and is multiplied with the evolutional representations of entities Htent to obtain a probability vector over all entities.\np(e|pred, \u03c11,e1,...,\u03c1q, ...,\u03c1n,en,G1:t) =\u03c3(HtenthLq ), (9)\nwhere \u03c3(\u00b7) is the sigmoid function."
        },
        {
            "heading": "4.3 Model Learning",
            "text": "Given a factf = (pred, \u03c11 :e1, ..., \u03c1n : en, t+1) \u2208 Ft+1, let e denotes any entity in f , T denotes the number of timestamps in the training set. The objective of the predicate reasoning task is to minimize the following cross-entropy loss:\nLpred=\u2212 T\u22121\u2211 t=0 \u2211 f\u2208Ft+1 |Vpred|\u22121\u2211 i=0 ypredt+1,i log pi(pred|e,G1:t), (10) where ypredt+1,i is a 0/1 value, denoting whether the i-th predicate occurs on e at timestamp t + 1,\npi(pred|e,G1:t) represents the probability score of the i-th predicate.\nSimilarly, the objective of the entity reasoning task is to minimize the following loss:\nLent= \u2212 T\u22121\u2211 t=0 \u2211 f\u2208Ft+1 |Vent|\u22121\u2211 i=0 yentt+1,i log pi(e|\npred, \u03c11, e1, ..., \u03c1q, ..., \u03c1n, en,G1:t),\n(11)"
        },
        {
            "heading": "5 Experiments",
            "text": ""
        },
        {
            "heading": "5.1 Experimental Setup",
            "text": ""
        },
        {
            "heading": "5.1.1 Datasets",
            "text": "Since there is no N-TKG dataset available for experiments, we build two datasets, namely NWIKI and NICE.\nAbout NWIKI: (1) We downloaded the Wikidata dump dump1 and extracted the facts which contain the timestamp information and involve human entities; (2) To extract n-tuple facts, we selected predicates with more than 3 role types and retained their corresponding facts; (3) We filtered out entities of low frequency, as their behaviors are difficult to learn and predict for most data-driven based methods. Correspondingly, facts involving these entities were also filtered out; (4) The fact related to the \u201cPosition Held\u201d predicate comprise over 50% of the dataset. However, the filtering operation in the previous step could impair connectivity. To maintain a robust connection with other predicates, we retained facts that are associated with other predicates and share core entities with the facts related to the \u201cPosition Held\u201d predicate; (5) Following RENET (Jin et al., 2020), all facts were split into the training set, the validation set, and the test set by a proportion of 80%:10%:10% according to the time ascending order.\nAbout NICE: (1) We collected the raw event records from ICEWS 2 from Jan 1, 2005 to Dec 31, 2014; (2) From these raw event records, we extracted core entities, timestamps, and partial auxiliary information, i.e., the occurrence places. (3) We observed that the predicate names contain additional auxiliary information. For example, the predicate names \u201cCooperate Economically\u201d and \u201cEngage in Judicial Cooperation\u201d contain the specified cooperation aspects of the general predicate \u201cEngaged in Cooperation\u201d, namely \u201cEconomic\u201d and\n1https://archive.org/details/wikibase-wikidatawiki20171120\n2https://dataverse.harvard.edu/dataverse/icews\n\u201cMilitarily\u201d, respectively. To obtain such auxiliary information, we designed rule templates to extract them from the specified predicate names and merged these specified predicates into the general ones. (4) Considering the absence of role information in the raw event records, we manually assigned role names to each predicate. (5) Similar to NWIKI, NICE was also split into the training set, the validation set, and the test set by a proportion of 80%:10%:10%."
        },
        {
            "heading": "5.1.2 Evaluation Metrics",
            "text": "We employ F1, recall, and precision as metrics for the predicate reasoning task. We adopt Hits@{1, 3, 10} and MRR as metrics for the entity reasoning task. Following Han et al. (2021a), we report the results under the time filter setting."
        },
        {
            "heading": "5.1.3 Baselines",
            "text": "For the predicate reasoning task, we compare NENet with temporal reasoning models, including RENET (Jin et al., 2019) and T-GCN (Zhao et al., 2019). Following Deng et al. (2019), we further compare NE-Net with DNN, MLkNN (Zhang and Zhou, 2007), BRkNN (Spyromitros et al., 2008), MLARAM (Deng et al., 2019). These four models are simple DNN or KNN-based methods, which use basic count features to conduct reasoning tasks.\nFor the entity reasoning task, we compare NENet with static n-tuple KG reasoning methods and TKG reasoning methods. The static n-tuple KG reasoning methods include: NALP (Guan et al., 2019), NeuInfer (Guan et al., 2020), HypE (Fatemi et al., 2021), HINGE (Rosso et al., 2020), HyTransformer (Yu and Yang, 2021), RAM (Liu et al., 2021). Since these methods are not able to model the temporal information, we construct a cumulative graph for all the training facts. The TKG rea-\nsoning methods include DE-DistMult (Goel et al., 2020), DE-SimplE (Goel et al., 2020), HyTE (Dasgupta et al., 2018), RE-NET (Jin et al., 2020), CyGNet (Zhu et al., 2020), REGCN (Li et al., 2021b), GHT (Sun et al., 2022), CEN (Li et al., 2022b) and TiRGN (Li et al., 2022a). To facilitate this kind of methods to N-TKG, we convert the historical n-tuples into a KG sequence. In each KG, we view both entities and predicate as nodes, and link entity nodes with fact nodes via roles. Such KG sequence is taken as the input of TKG reasoning methods."
        },
        {
            "heading": "5.1.4 Implementation Details",
            "text": "For the evolution encoder, the history length m on two datasets is set to 2; the number of Transformer blocks L for NICE and NWIKI is set to 1 and 2, respectively. For all datasets, the numbers, \u03c91 and \u03c92, of GCN layers in the entity-predicate and coreentity units are set to 4 and 2, respectively; the number of self-attention heads is set to 4."
        },
        {
            "heading": "5.2 Experimental Results",
            "text": ""
        },
        {
            "heading": "5.2.1 Results on Predicate Reasoning",
            "text": "To analyze the effectiveness of NE-Net on predicate reasoning task, we compare NE-Net with baselines on both datasets. The results are presented in Table 2. It is shown that NE-Net outperforms baselines across all datasets in terms of F1 and Recall. Notably, the counting-based methods have the worst performance on both datasets, indicating the importance of modeling the relations among entities and predicates at different timestamps in the predicate reasoning task. It can be particularly observed that NE-Net shows lower performance on the precision metric in NWIKI, as compared with RENET. This is because RENET focuses on a target entity to retrieve historical facts, enabling it to utilize a longer history, while NE-Net solely considers the history in the latest timestamps."
        },
        {
            "heading": "5.2.2 Results on Entity Reasoning",
            "text": "To investigate the effectiveness of NE-Net, we divide the test set into core and auxiliary categories (denoted as C and AUX) based on the role to be predicted, and conduct the entity reasoning task\non two datasets. Comprehensive results on these two categories are presented in Table 3. Especially, we only report the results of TKG reasoning methods on the core category, as they only focus on quadruples.\nAs shown in Tables 3, NE-Net consistently significantly outperforms static n-tuple KG reasoning methods across all metrics on both datasets. This can be attributed to the capacity of NE-Net to model the rich relations among entities and predicates at different timestamps. On the core category, we observe that TKG reasoning methods under the interpolation setting, perform worse than NE-Net. These methods focus on predicting facts occurring at known timestamps, and can not capture the relations between entities and predicates within newlyemerged temporal facts. Moreover, NE-Net shows better performance than TKG reasoning methods under the extrapolation setting. Different from these methods, NE-Net learns the representations of the predicates as they dynamic evolve, and emphasizes the relations between core entities within facts containing various numbers of auxiliary entities. Besides, NE-Net can capture information of elements within queries. In short, these results convincingly suggest that NE-Net is effective in conducting the reasoning task over N-TKGs."
        },
        {
            "heading": "5.3 Ablation Study",
            "text": "To study the effectiveness of each module of NENet, we conduct ablation studies on all datasets. The results are summarized in Table 4.\nIt can be observed that removing the core-entity unit (denoted as -CE) results in worse performance on both datasets, which illustrates that additionally capturing the relations between core entities can help NE-Net learn more precise representa-\ntions. Notably, -CE has a more significant impact on the core category when compared with that on the auxiliary category, as CEGs predominantly emphasize entities playing core roles in n-tuples. Furthermore, -CE has a greater performance drop on NWIKI in comparison to NICE. Notably, NWIKI has a higher proportion of facts that involve three or more role-entity pairs (46.32%), as compared to NICE (30.97%). As a result, NWIKI exhibits richer relations among entities and predicates. -CE makes it more difficult for the model to distinguish the most important information contained in the relations among core entities in NWIKI.\nTo verify the necessity of the attention-based aggregation unit (denoted as -AA), we simply use the max pooling operation to integrate the outputs of the entity-predicate unit and the core-entity unit. It can be seen that -AA yields worse results compared to NE-Net, which demonstrates the necessity of adaptively integrating the information learned from the entity-predicte unit and the core-entity unit. Also, the removal of the pred-aggregation\noperation (denoted as -PredAgg) also results in worse performance than NE-Net, which demonstrates that aggregating the influence of predicate instances and the inherent representations can help learn better representations of predicates. To verify the necessity of the Transformer-based decoder on the entity reasoning task, we replace this decoder with ConvTransE (Dettmers et al., 2018), denoted as -Trans. It can be seen that removing the transformer decoder leads to a decrease in performance, which demonstrates the effectiveness of our entity reasoning decoder."
        },
        {
            "heading": "5.4 Detailed Analysis",
            "text": "To illustrate the superiority of N-TKGs, we investigate the performance of NE-Net with different ratios of auxiliary information. We provide NENet with histories containing varying ratios (0%, 30%, 60%,100%) of auxiliary information. Here, the auxiliary information in the history is randomly selected, and we run NE-Net three times and report the averaged results.\nFrom Table 5, it can be observed that the performance of NE-Net is positively correlated with the amount of auxiliary information utilized. This suggests that providing more precise descriptions of temporal facts can enhance the performance of TKG reasoning, thereby demonstrating the superiority of the proposed N-TKGs. Additionally, we notice that the ratio of auxiliary information has a greater impact on NWIKI than NICE. Actually, the types of auxiliary roles in NICE are limited, while in NWIKI, there are more diverse types of auxiliary roles, including occupation, employer, winners, and more. These richer types of auxiliary roles in NWIKI can better help with predictions."
        },
        {
            "heading": "5.5 Case Studies",
            "text": "We present two cases in Table 6 where NE-Net correctly predicts the answer entity. In this table, t\u2212 1 and t represent historical timestamps, while t+ 1 represents the query timestamp. In the first case, the correct answer to the query plays as an auxiliary entity in the latest historical fact. It is hard for the model to predict the correct answer without such auxiliary information. In the second case, the auxiliary entity \u201cHumanitarian Aid\u201d helps the model establish a connection between the query and the most informative historical fact, and thereby enabling more accurate predictions."
        },
        {
            "heading": "6 Conclusions",
            "text": "In this paper, we proposed to utilize n-tuples to represent temporal facts more precisely, and correspondingly enhanced TKGs as N-TKGs. We further introduced a model called NE-Net, to conduct reasoning over N-TKGs. NE-Net learns evolutional representations of entities and predicates, via modeling the relations among entities and predicates, and highlighting the relations among core entities. Further, it adopts task-specific decoders to conduct different reasoning tasks. Experimental results on two new datasets show the superiority of N-TKG and the effectiveness of NE-Net."
        },
        {
            "heading": "7 Acknowledgments",
            "text": "The work is supported by the National Natural Science Foundation of China under grant U1911401, the National Key Research and Development Project of China, the JCJQ Project of China, Beijing Academy of Artificial Intelligence under grant BAAI2019ZD0306, and the Lenovo-CAS Joint Lab Youth Scientist Project. We thank anonymous reviewers for their insightful comments and suggestions."
        },
        {
            "heading": "8 Limitations",
            "text": "The proposed NE-Net model cannot handle temporal facts that involve roles with multiple entities, such as the temporal fact \u201c(Attack, Attacker: {entity1, entity2}, Victim: {entity3, entity4}, 2026- 10-01)\u201d. Furthermore, it is unable to model long history, as the use of deep GCN layers can bring the over-smoothing problem."
        }
    ],
    "title": "Temporal Knowledge Graph Reasoning Based on N-tuple Modeling",
    "year": 2023
}