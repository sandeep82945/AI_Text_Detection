{
    "abstractText": "Task-Oriented Dialogue (TOD) systems have become crucial components in interactive artificial intelligence applications. While recent advances have capitalized on pre-trained language models (PLMs), they exhibit limitations regarding transparency and controllability. To address these challenges, we propose a novel approach focusing on inferring the TOD-Flow graph from dialogue data annotated with dialog acts, uncovering the underlying task structure in the form of a graph. The inferred TOD-Flow graph can be easily integrated with any dialogue model to improve its prediction performance, transparency, and controllability. Our TOD-Flow graph learns what a model can, should, and should not predict, effectively reducing the search space and providing a rationale for the model\u2019s prediction. We show that the proposed TODFlow graph better resembles human-annotated graphs compared to prior approaches. Furthermore, when combined with several dialogue policies and end-to-end dialogue models, we demonstrate that our approach significantly improves dialog act classification and end-to-end response generation performance in the MultiWOZ and SGD benchmarks. Code available at: https://github.com/srsohn/TOD-Flow",
    "authors": [
        {
            "affiliations": [],
            "name": "Sungryull Sohn"
        },
        {
            "affiliations": [],
            "name": "Yiwei Lyu"
        },
        {
            "affiliations": [],
            "name": "Anthony Zhe Liu"
        },
        {
            "affiliations": [],
            "name": "Lajanugen Logeswaran"
        },
        {
            "affiliations": [],
            "name": "Dong-Ki Kim"
        },
        {
            "affiliations": [],
            "name": "Dongsub Shim"
        },
        {
            "affiliations": [],
            "name": "Honglak Lee"
        }
    ],
    "id": "SP:640d5617784c0e0a55b4b07c90de0a45881cb539",
    "references": [
        {
            "authors": [
                "Jacob Andreas",
                "Dan Klein",
                "Sergey Levine."
            ],
            "title": "Modular Multitask Reinforcement Learning with Policy Sketches",
            "venue": "ICML.",
            "year": 2017
        },
        {
            "authors": [
                "Vevake Balaraman",
                "Seyedmostafa Sheikhalishahi",
                "Bernardo Magnini."
            ],
            "title": "Recent neural methods on dialogue state tracking for task-oriented dialogue systems: A survey",
            "venue": "Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse",
            "year": 2021
        },
        {
            "authors": [
                "Craig Boutilier",
                "Richard Dearden",
                "Mois\u00e9s Goldszmidt"
            ],
            "title": "Exploiting Structure in Policy Construction",
            "year": 1995
        },
        {
            "authors": [
                "Pawe\u0142 Budzianowski",
                "Tsung-Hsien Wen",
                "Bo-Hsiang Tseng",
                "I\u00f1igo Casanueva",
                "Stefan Ultes",
                "Osman Ramadan",
                "Milica Ga\u0161i\u0107"
            ],
            "title": "Multiwoz \u2013 a largescale multi-domain wizard-of-oz dataset for taskoriented dialogue modelling",
            "year": 2020
        },
        {
            "authors": [
                "Wenhu Chen",
                "Jianshu Chen",
                "Pengda Qin",
                "Xifeng Yan",
                "William Yang Wang"
            ],
            "title": "Semantically conditioned dialog response generation via hierarchical disentangled self-attention",
            "year": 2019
        },
        {
            "authors": [
                "Sung-Kwon Choi",
                "Oh-Woog Kwon",
                "Young-Kil Kim",
                "Yun-Kyung Lee"
            ],
            "title": "Using a dialogue system",
            "year": 2016
        },
        {
            "authors": [
                "Jason Wei"
            ],
            "title": "Scaling instruction-finetuned language models",
            "year": 2022
        },
        {
            "authors": [
                "Gabriel Gordon-Hall",
                "Philip John Gorinski",
                "Shay B. Cohen."
            ],
            "title": "Learning Dialog Policies from Weak Demonstrations",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1394\u20131405, Online. Association for",
            "year": 2020
        },
        {
            "authors": [
                "Bradley Hayes",
                "Brian Scassellati."
            ],
            "title": "Autonomously Constructing Hierarchical Task Networks for Planning and Human-Robot Collaboration",
            "venue": "ICRA.",
            "year": 2016
        },
        {
            "authors": [
                "Wanwei He",
                "Yinpei Dai",
                "Min Yang",
                "Jian Sun",
                "Fei Huang",
                "Luo Si",
                "Yongbin Li."
            ],
            "title": "Unified dialog model pre-training for task-oriented dialog understanding and generation",
            "venue": "Proceedings of the 45th International ACM SIGIR Conference on Research and",
            "year": 2022
        },
        {
            "authors": [
                "Wanwei He",
                "Yinpei Dai",
                "Yinhe Zheng",
                "Yuchuan Wu",
                "Zheng Cao",
                "Dermot Liu",
                "Peng Jiang",
                "Min Yang",
                "Fei Huang",
                "Luo Si"
            ],
            "title": "Galaxy: A generative pre-trained model for task-oriented dialog with semisupervised learning and explicit policy injection",
            "year": 2022
        },
        {
            "authors": [
                "De-An Huang",
                "Suraj Nair",
                "Danfei Xu",
                "Yuke Zhu",
                "Animesh Garg",
                "Li Fei-Fei",
                "Silvio Savarese",
                "Juan Carlos Niebles."
            ],
            "title": "Neural task graphs: Generalizing to unseen tasks from a single video demonstration",
            "venue": "Proceedings of the IEEE/CVF conference on com-",
            "year": 2019
        },
        {
            "authors": [
                "Vojt\u011bch Hude\u010dek",
                "Ond\u0159ej Du\u0161ek"
            ],
            "title": "Are llms all you need for task-oriented dialogue? arXiv preprint arXiv:2304.06556",
            "year": 2023
        },
        {
            "authors": [
                "Yunseok Jang",
                "Sungryull Sohn",
                "Lajanugen Logeswaran",
                "Tiange Luo",
                "Moontae Lee",
                "Honglak Lee."
            ],
            "title": "Multimodal subtask graph generation from instructional videos",
            "venue": "arXiv preprint arXiv:2302.08672.",
            "year": 2023
        },
        {
            "authors": [
                "Wai-Chung Kwan",
                "Hong-Ru Wang",
                "Hui-Min Wang",
                "Kam-Fai Wong"
            ],
            "title": "A survey on recent advances and challenges in reinforcement learning methods",
            "year": 2023
        },
        {
            "authors": [
                "Oh-Woog Kwon",
                "Young-Kil Kim",
                "Yun-Kyung Lee."
            ],
            "title": "Task graph based task-oriented dialogue system using dialogue map for second language learning",
            "venue": "Future-proof CALL: language learning as exploration and encounters \u2013 short papers from EURO-",
            "year": 2018
        },
        {
            "authors": [
                "Tiziano Labruna",
                "Sofia Brenna",
                "Andrea Zaninello",
                "Bernardo Magnini"
            ],
            "title": "Unraveling chatgpt: A critical analysis of ai-generated goal-oriented dialogues and annotations",
            "year": 2023
        },
        {
            "authors": [
                "Issam H Laradji",
                "Stefania Raimondo",
                "David Vazquez",
                "Pau Rodriguez",
                "Christopher Pal"
            ],
            "title": "Workflow discovery from dialogues in the low data regime",
            "venue": "Transactions on Machine Learning Research",
            "year": 2023
        },
        {
            "authors": [
                "Zachary C. Lipton",
                "Xiujun Li",
                "Jianfeng Gao",
                "Lihong Li",
                "Faisal Ahmed",
                "Li Deng"
            ],
            "title": "Bbq-networks: Efficient exploration in deep reinforcement learning for task-oriented dialogue systems",
            "year": 2017
        },
        {
            "authors": [
                "Anthony Z. Liu",
                "Sungryull Sohn",
                "Mahdi Qazwini",
                "Honglak Lee."
            ],
            "title": "Learning Parameterized Task Structure for Generalization to Unseen Entities",
            "venue": "AAAI.",
            "year": 2022
        },
        {
            "authors": [
                "Lajanugen Logeswaran",
                "Sungryull Sohn",
                "Yunseok Jang",
                "Moontae Lee",
                "Honglak Lee."
            ],
            "title": "Unsupervised task graph generation from instructional video transcripts",
            "venue": "arXiv preprint arXiv:2302.09173.",
            "year": 2023
        },
        {
            "authors": [
                "Shrikant Malviya",
                "Piyush Kumar",
                "Suyel Namasudra",
                "Uma Shanker Tiwary."
            ],
            "title": "Experience replaybased deep reinforcement learning for dialogue management optimisation",
            "venue": "ACM Trans. Asian LowResour. Lang. Inf. Process. Just Accepted.",
            "year": 2022
        },
        {
            "authors": [
                "Donald Michie",
                "Michael Bain",
                "J Hayes-Miches."
            ],
            "title": "Cognitive models from subcognitive skills",
            "venue": "IEE control engineering series, 44:71\u201399.",
            "year": 1990
        },
        {
            "authors": [
                "Tom\u00e1\u0161 Nekvinda",
                "Ond\u0159ej Du\u0161ek"
            ],
            "title": "Shades of bleu, flavours of success: The case of multiwoz",
            "year": 2021
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311\u2013318, Philadelphia,",
            "year": 2002
        },
        {
            "authors": [
                "F. Pedregosa",
                "G. Varoquaux",
                "A. Gramfort",
                "V. Michel",
                "B. Thirion",
                "O. Grisel",
                "M. Blondel",
                "P. Prettenhofer",
                "R. Weiss",
                "V. Dubourg",
                "J. Vanderplas",
                "A. Passos",
                "D. Cournapeau",
                "M. Brucher",
                "M. Perrot",
                "E. Duchesnay"
            ],
            "title": "Scikit-learn: Machine learning",
            "year": 2011
        },
        {
            "authors": [
                "Baolin Peng",
                "Xiujun Li",
                "Jianfeng Gao",
                "Jingjing Liu",
                "Kam-Fai Wong",
                "Shang-Yu Su"
            ],
            "title": "Deep dynaq: Integrating planning for task-completion dialogue policy learning",
            "year": 2018
        },
        {
            "authors": [
                "Dinesh Raghu",
                "Shantanu Agarwal",
                "Sachindra Joshi"
            ],
            "title": "End-to-end learning of flowchart grounded task-oriented dialogs",
            "venue": "In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2021
        },
        {
            "authors": [
                "Abhinav Rastogi",
                "Xiaoxue Zang",
                "Srinivas Sunkara",
                "Raghav Gupta",
                "Pranav Khaitan."
            ],
            "title": "Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, vol-",
            "year": 2020
        },
        {
            "authors": [
                "Keisuke Sakaguchi",
                "Chandra Bhagavatula",
                "Ronan Le Bras",
                "Niket Tandon",
                "Peter Clark",
                "Yejin Choi."
            ],
            "title": "proScript: Partially Ordered Scripts Generation",
            "venue": "Findings of EMNLP.",
            "year": 2021
        },
        {
            "authors": [
                "Sungryull Sohn",
                "Junhyuk Oh",
                "Honglak Lee."
            ],
            "title": "Hierarchical Reinforcement Learning for Zero-shot Generalization with Subtask Dependencies",
            "venue": "NeurIPS.",
            "year": 2018
        },
        {
            "authors": [
                "Sungryull Sohn",
                "Hyunjae Woo",
                "Jongwook Choi",
                "Honglak Lee."
            ],
            "title": "Meta Reinforcement Learning with Autonomous Inference of Subtask Dependencies",
            "venue": "ICLR.",
            "year": 2020
        },
        {
            "authors": [
                "Sungryull Sohn",
                "Hyunjae Woo",
                "Jongwook Choi",
                "Lyubing Qiang",
                "Izzeddin Gur",
                "Aleksandra Faust",
                "Honglak Lee."
            ],
            "title": "Fast Inference and Transfer of Compositional Task Structures for Few-shot Task Generalization",
            "venue": "UAI.",
            "year": 2022
        },
        {
            "authors": [
                "Jianhong Wang",
                "Yuan Zhang",
                "Tae-Kyun Kim",
                "Yunjie Gu."
            ],
            "title": "Modelling hierarchical structure between dialogue policy and natural language generator with option framework for task-oriented dialogue system",
            "venue": "arXiv preprint arXiv:2006.06814.",
            "year": 2020
        },
        {
            "authors": [
                "Weizhi Wang",
                "Zhirui Zhang",
                "Junliang Guo",
                "Yinpei Dai",
                "Boxing Chen",
                "Weihua Luo."
            ],
            "title": "Task-oriented dialogue system as natural language generation",
            "venue": "Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Infor-",
            "year": 2022
        },
        {
            "authors": [
                "Chien-Sheng Wu",
                "Steven Hoi",
                "Richard Socher",
                "Caiming Xiong."
            ],
            "title": "Tod-bert: Pre-trained natural language understanding for task-oriented dialogue",
            "venue": "arXiv preprint arXiv:2004.06871.",
            "year": 2020
        },
        {
            "authors": [
                "Jen-Chieh Yang",
                "Jia-Yan Wu",
                "Sung-Ping Chang",
                "YaChieh Huang"
            ],
            "title": "Gks: Graph-based knowledge selector for task-oriented dialog system",
            "year": 2021
        },
        {
            "authors": [
                "Shiquan Yang",
                "Rui Zhang",
                "Sarah Erfani."
            ],
            "title": "GraphDialog: Integrating graph knowledge into endto-end task-oriented dialogue systems",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Task-Oriented Dialogue (TOD) systems have attracted significant attention due to their potential applications in personal assistants, customer support, and other interactive systems that necessitate human-like conversation (Balaraman et al., 2021; Zhang et al., 2020). Many of the recent advances in TOD have heavily leaned on pre-trained language models (PLMs) (He et al., 2022b; Wu et al., 2020) that are first pre-trained on a large corpus of data in an unsupervised manner, and then either fine-tuned (He et al., 2022b; Chen et al., 2019;\n*Equal Contribution\nWang et al., 2020) or subjected to few-shot prompting (Hudec\u030cek and Du\u0161ek, 2023; Labruna et al., 2023) to adapt them to specific dialogue domains. While these approaches have yielded commendable performance, they have limitations. Few-shot prompted models have been challenged by issues of transparency, controllability, and adaptability to specific domains, especially when working with only a few examples. The lack of understanding of their decision-making processes and finegrained control over their output is often inadequate, which can result in sub-optimal conversational experiences. On the other hand, fine-tuned models are confronted with their own unique challenges. While they offer improved performance by aligning the model with task-specific semantics, this approach typically requires large annotated datasets and resources which can be a limiting factor in practice. Furthermore, these models often lack transparency, making it challenging to understand the reasons behind their decisions or predictions.\nSome prior works (Raghu et al., 2021; Laradji et al., 2023) introduced workflow-based dialog models to handle the challenges in existing TOD models. These methods aim to explicitly model the structure of dialog in a graph format. Grounding the dialog in the graph offers benefits in terms of 1) elucidating the reasoning of system\u2019s decisions in terms of the relationships (i.e., transparency); 2) allow human manipulation of the dialogue model via graph modification (i.e., controllability) without retraining the dialog model. However, realworld dialogues were often unstructured, making it non-trivial to be modeled as a workflow, and the necessity of manually designing the domainspecific workflow or its elements limits its practical applicability.\nTo tackle these challenges, we propose to learn the subtask graph (Sohn et al., 2018) from taskoriented dialog data. Intuitively, the subtask graph\ncan predict the affordance (i.e., availability) of the action from the status of environment and agent (i.e., the progress of completing a task or the subtasks). The subtask graph framework has two major benefits: i) subtask graphs can be inferred from the demonstrations without any direct supervision (e.g., video (Jang et al., 2023) or transcript (Logeswaran et al., 2023)), ii) subtask graphs can be combined with the base prediction model to improve its prediction since the subtask graph does not decide what to predict but instead suggests the affordable candidates of prediction.\nContributions. The main contribution of this work is generalizing the subtask graph framework into task-oriented dialog settings. To this end, we propose the TOD-Flow graph, which extends the subtask graph framework in three major aspects. First, we show that subtask graph can infer the relationship between dialog state and dialog acts without requiring any manual definition of nodes and edges in graphs. Second, in addition to the precondition (or can relationship), we present learning algorithms to model two novel relationships, should and should not, which provide more fine-grained control and improved prediction. For instance, a can relationship may represent that the system can make a payment only if the user confirms the payment. The should relationship may learn that if a user ask about the address of the hotel, the system should reply back. Conversely, a should not relationship may dictate that the system usually does not predict a farewell if the user\u2019s last utterance\nimplies a question. Third, we demonstrate that the inferred TOD-Flow graphs can enhance any dialog policy or end-to-end dialog system, whether fine-tuned or prompted, without the necessity of retraining."
        },
        {
            "heading": "2 Background",
            "text": "Our main contribution, the TOD-Flow graph, is an extension of the subtask graph framework (Sohn et al., 2018, 2020), which describes the causal dependency structure of a compositional task \u03c4 consisting of a set of subtasks. In the context of task-oriented dialogue, dialog acts can be seen as subtasks. Each subtask has a precondition that must be satisfied before the subtask can be performed. Note that the precondition is not the only relationship between subtask, and in Section 3.2 we extend it by incorporating other types of relationships. Since precondition describes the causal relationship between subtasks, it imposes a constraint on the order in which subtasks can be performed (e.g., the system can make a payment only after the user confirms the payment). Formally, we define the precondition as a Boolean expression consisting of Boolean constants (e.g., True or False), Boolean variables and logical connectives (e.g., and (&), or (|)). To illustrate, consider the precondition of subtask C: fC = &(A, B), where the subtasks A and B must be completed before C is completed. It can be equivalently viewed as a Boolean function where inputs are Boolean variables indicating whether subtasks A and B are completed, and the output\nrepresents whether the precondition fC is satisfied: fC(A = True, B = False) = True & False = False. Also, the boolean expression fC = &(A, B) can be viewed as a graph with vertices consisting of subtasks and logical operators V = {A, B, C,&} and edges E = {A \u2192 &, B \u2192 &, & \u2192 C} that represent preconditions. We will use these different views of the precondition (i.e., as a boolean expression, graph or function) interchangeably. The subtask graph visualizes the preconditions f1, . . . of the subtasks (see Figure 1 for examples). We note that the subtask graph has been adopted in various settings (Liu et al., 2022; Sohn et al., 2020, 2022) and subsumes other task graph formats (Andreas et al., 2017; Boutilier et al., 1995; Sakaguchi et al., 2021), flowchart (Raghu et al., 2021), and workflow (Laradji et al., 2023)."
        },
        {
            "heading": "3 TOD-Flow Graph Learning",
            "text": ""
        },
        {
            "heading": "3.1 Problem Formulation",
            "text": "For dialogue turn t, let ut be the user input and rt be the corresponding system response. The user inputs and system responses are represented as a set of dialog acts that labels the raw language utterance at each turn according to its category of meaning: ut, rt \u2282 A, where A is the set of dialog acts. Let dt be the database query result that can be obtained through querying the database. Then, the dialog data D is a set of dialog trajectories D\u03c4 = {(u0, r0, d0, u1, . . .), . . .}. Given the dialog data D\u03c4 , the goal is to generate the TOD-Flow graph G that models the dependency between system acts, user acts, and database results in graph format.\nChallenges. There are two main challenges in tackling this task. First, the information in the dialogue is noisy due to annotation errors such as missing or ambiguous dialog acts, slots, and values. Second, these dialog annotations only provide partial information about the underlying relationships between subtasks. Thus, we need to infer whether each relationship is satisfied or not from the dialogue annotations. We describe how we overcome these challenges in Section 3.3."
        },
        {
            "heading": "3.2 TOD-Flow Graph",
            "text": "For each dialog act a, the TOD-Flow graph is defined in terms of three conditions: Cana, Shda, and Shdnta. Intuitively, Cana, Shda and Shdnta condition respectively defines whether the dialog act a\ncan, should, and should not be performed by the agent (user or system) at a given status. Similar to the precondition in subtask graph framework (see Section 2), each condition is defined as a Boolean expression. Also, it can be equivalently viewed as a Boolean function fCan, fShd, fShdnt : c 7\u2192 {0, 1} or a graph (see Section 2), where c \u2208 {0, 1}N\u03c4 is the subtask completion (or dialog state) vector indicating whether nth subtask has been achieved (i.e., c[n] = 1) or not (i.e., c[n] = 0)."
        },
        {
            "heading": "3.3 Learning TOD-Flow Graphs",
            "text": "Dataset. Given the dialogue data D = {(ut, dt, rt)}, we aim to build the graph inference dataset DG = {(ct,at)}, from which we can infer the TOD-Flow graph fCan, fShd, and fShdnt. The action set at is the set of dialog acts that were performed at turn t: at = ut \u222a rt. The completion set ct is the set of dialog acts and database query that has ever been performed before turn t: ct = ct\u22121 \u222a at\u22121 \u222a {dt\u22121}.\nShd inference. When should condition is satisfied (i.e., fShdn (c)=1), the agent is required to perform the nth dialog act (i.e., a[n] = 1). When the should condition is not satisfied (i.e., fShdn (c)=0), the should relationship has no effect on the policy. This relationship can be represented as the confusion matrix shown in the first two rows in Table 1. Accordingly, we maximize the true positive, while minimizing the false positive by maximizing the objective JShd in Equation (1).\nJShd = E(c,a[n]) [ I(a[n] = 1|fShdn (c) = 1) ] (1)\nShdnt inference. Similar to Shd, when the shoudnot condition is satisfied, (i.e., fShdntn (c) = 1), the agent is required not to perform the nth dialog act (i.e., a[n] = 0), and agent has a freedom to execute the nth dialog act when the condition is not satisfied (i.e., fShdntn (c) = 0). Table 1 summarizes the relationship between Shdnt and a[n]. We learn fShdntn by maximizing the following objective:\nJShdnt = E(c,a[n]) [ I(a[n] = 0|fShdntn (c) = 1) ] .\n(2)\nCan inference. By definition of Can (or precondition), a dialog act can only be performed (an = 1) if its Can condition is satisfied (i.e., fCann (c) = 1): a true positive case in Table 1. On the contrary, it is a contradiction if a dialog act an is performed while its Can is not satisfied (i.e., fCann (c) = 0): a false negative case in Table 1. Thus, the fCan can be learned by maximizing the following objective:\nJCan = E(c,a[n]) [ I[fCann (c) = 1|a[n] = 1] ] . (3)\nHowever, different from Shd and Shdnt, inferring Can is nontrivial, because if we maximize JCan, we get the trivial precondition: always true (i.e., fCann (c) = 1 for all c). Previous works handled this issue by either making additional assumptions (Hayes and Scassellati, 2016; Huang et al., 2019) or applying regularization (Jang et al., 2023).\nAlgorithm 1 TOD-flow Graph-conditioned Dialogue Model\nRequire: Dialogue model \u03c0, TOD-flow graph fCan, fShd, fShdnt, Completion c Ensure: Sampled dialog acts a 1: a \u223c \u03c0 \u25b7 Sample dialog acts from \u03c0 2: a\u2190 a \u222a {a\u2032|fShda\u2032 (c) = 1} \u25b7 Apply Shd 3: a\u2190 a \u2229 {a\u2032|fCan\u2227\u00acShdnta\u2032 (c) = 1} 4: \u25b7 Apply Can \u2227 \u00acShdnt 5: return a\nHowever, these approaches unavoidably introduces noise in learning, and require careful hyperparameter tuning to balance between objective and regularization. Instead, inspired by the fact that Can and \u00acShdnt (i.e., negation of Shdnt) applies to the policy in the same manner (i.e., the dialog act a can be performed if both fCann = 1 and f \u00acShdnt n = 1), we propose to infer Can and Shdnt simultaneously as follows:\nJCan\u2227\u00acShdnt = E(c,a[n]) [ I[fCan\u2227\u00acShdntn (c) = 1|a[n] = 1]\n+ \u03b1 I[fCan\u2227\u00acShdntn (c) = 0|a[n] = 0] ] , (4)\nwhere \u03b1 determines the relative weight between Can and Shdnt in optimization. Intuitively, the agent can perform nth dialog act only if Can is satisfied and Shdnt is not satisfied.\nBaseline. As an ablation model, we consider the behavioral cloning (BC) (Michie et al., 1990) objective, which tries to mimic the demonstration behavior:\nJBC = E(c,a[n]) [ I [ fBCn (c) = a[n] ]] (5)\nThe confusion matrix is shown at the bottom of Table 1.\nWe can use any binary classification models to optimize the objectives (1), (4), and (5). We used the decision tree models in the experiment following the previous works (Boutilier et al., 1995; Huang et al., 2019; Sohn et al., 2020)."
        },
        {
            "heading": "4 Graph-conditioned Dialog Modeling",
            "text": "We describe how the inferred TOD-flow graph G can enhance the prediction performance of any offthe-shelf dialogue policies and end-to-end dialog systems."
        },
        {
            "heading": "4.1 Graph-conditioned Dialog Policy",
            "text": "The inferred TOD-flow graph (Shd and Can \u2227 \u00acShdnt) can propose the dialog acts that can, should, and should not be performed given the current dialog history (or completion set). Figure 2 and Algorithm 1 describes the entire process. Given a base dialogue policy \u03c0DP, we sample the system acts from the policy a \u223c \u03c0DP, and filter, add and remove acts from the sampled system acts according to the Can, Shd, and Shdnt, respectively.\nWe can further improve the prediction performance if our baseline dialog model can be sampled multiple times with different results, as illustrated in Figure 2. We use the graph to condition each candidate result, then select the best one using a selection method such as most number of actions in set, candidate with least graph violations, etc. We empirically found that simply choosing the result with the most actions works best."
        },
        {
            "heading": "4.2 Graph-conditioned End-to-end Response Generation",
            "text": "End-to-end dialogue system directly reads and outputs the utterances in natural language form. Given the base end-to-end model \u03c0e2e, we sample multiple system utterances from the base model (mostly via beam-search alternates, see Appendix A.2.1 for details). Then, we use a few-shot prompted GPT-3.5-turbo model to annotate each generated candidate utterance with the dialog act (see Appendix A.2.3 for details). Finally, we use the inferred graph to choose the best utterance that has the least violation rate (i.e., portion of dialog acts that violates the inferred Can, Shd, and Shdnt conditions). Note that with this approach, all final responses still comes from the base end-to-end model, so the improvement is still upper-bounded by the capabilities of the model. Our graph simply presents a better candidate selection method."
        },
        {
            "heading": "5 Experiments",
            "text": "We perform experiments to show that (1) the TODflow graph can be accurately predicted without any supervision, (2) our graph can improve the accuracy of dialog policy models, and (3) our graph can improve the quality of response generation in end-to-end dialog models."
        },
        {
            "heading": "5.1 Dataset",
            "text": "We used two standard TOD benchmarks. SchemaGuided Dialogue (SGD) (Rastogi et al., 2020) has over 20k task-oriented simulated conversations based on human-designed schema. SGD covers a wide range of domains (i.e., different dialog acts and goals). We use 24 domains in SGD, and did not use the schema for experiment. MultiWOZ (Budzianowski et al., 2020) has 10k humanhuman conversations on 14 domains. Since MultiWOZ is collected from human-human conversations, the utterances are much more linguistically diverse than SGD. Also, different from SGD where the annotations are generated from the schema, annotations in MultiWOZ are labeled by human. Therefore, the annotations in MultiWOZ are often noisy (i.e., inconsistent, wrong, or missing), which present additional challenge compared to SGD.\nFor both datasets, we obtain train/test splits of the dialogs within each domain (see Appendix A.1.1 for details). The training set is used for 1) inferring TOD-Flow graph, 2) building demonstration for few-shot prompted models, and 3) finetuning the finetuning-based models. The test set is only used for evaluation. For graph inference, we map the dialog act of user, database, and system to completion c and dialog act a vectors as described in Section 3.3."
        },
        {
            "heading": "5.2 Baselines",
            "text": "We compare three graph inference algorithms:\n\u2022 BC learns to imitate the demonstration via behavioral cloning (see Section 3.3)\n\u2022 MSG2 (Jang et al., 2023) learns the subtask graph by optimizing the JCan (see Equation (3)) with complexity regularization.\n\u2022 TOD-Flow (ours) is our TOD-Flow graph learning algorithm.\nFor fair comparison, we used the scikit-learn decision tree model (Pedregosa et al., 2011) for all the graph inference algorithms."
        },
        {
            "heading": "5.3 TOD-Flow Graph Inference",
            "text": "We first qualitatively compare the inferred graphs with the human-drawn graphs on RentalCars_1 domain in SGD dataset. We found that in general TOD-Flow produces graphs that agree with the human-drawn graphs much more often compared to baselines (BC and MSG2). Figure 3 illustrates the subpart of the inferred and human-drawn graph, where TOD-Flow inferred the graph perfectly matches the human-drawn graph, while the baselines missed important information (such as not requiring all 4 required slots to be informed before performing the query)."
        },
        {
            "heading": "5.4 Task 1: Dialog Policy Learning",
            "text": "Base Models. We use two instruction-tuned large language models (LLM) as baseline dialog policy: FLAN-T5-xxl (Chung et al., 2022) and GPT-turbo1. At each turn, we prompt the LLM with five demonstration dialogues from train split of the same domain followed by the dialogue history, and ask the model to predict next system dialog acts. See Appendix A.1.2 for more details on prompting the LLM.\n1https://platform.openai.com/docs/models/gpt-3-5\nEvaluation Protocol. We sample 10 candidate predictions from the base models, which is filtered and ranked based on the graph (see Section 4.1) to choose the best prediction.\nMetric. We measure F-1 score between the ground-truth and predicted system dialog acts at each turn and average over entire domains.\nResults. Table 2 summarizes the F-1 score of each model on SGD and MultiWOZ. Overall, we observe that TOD-Flow consistently improves the prediction accuracy with a significant margin compared to other baselines BC and MSG2 on all base models and all dataset. We also found that the improvements are bigger on FLAN-T5 compared to GPT-turbo. This indicates that the GPT-turbo already models the Can, Shd, and Shdnt to some extent, so that augmenting it with the graph provide less benefits. Since BC learns to mimic the exact behavior in demonstration, BC tends to dictate the base policy more aggressively and hurts the performance when combined with strong base model GPT-turbo. MSG2 correctly models the precondition of dialog acts, but provides less benefit compared to TOD-Flow due to the conservative graph learning (i.e., complexity regularization) and lacking the ability to model Shd and Shdnt relations.\nAblations. To further justify our design choices, we performed ablation studies on two key components of TOD-Flow: the graphs and the ranking method after graph-conditioning. For filtering graphs, we examined the effect of Can-Shdnt and Shd graphs. Regarding the ranking method, we\ncompare the proposed ranking approach (i.e., Compliance) against various alternatives:\n\u2022 Greedy ranks by likelihood of base LLM. \u2022 Compliance ranks predictions by larger num-\nber of actions complying with the graph (i.e. rank by size in Figure 2).\n\u2022 Majority chooses the majority prediction among the multi-sampled predictions.\n\u2022 Violation ranks predictions by least number of actions filtered, added, and removed in graph conditioning.\n\u2022 Uniform randomly chooses one of the multisampled predictions.\nThe results are shown in Table 3, and TOD-Flow outperformed all ablations, showing the necessity of all graphs and ranking by largest set."
        },
        {
            "heading": "5.5 Task 2: End-to-end Response Generation",
            "text": "Base Models. We use the three SOTA end-toend dialogue models finetuned on MultiWOZ: GALAXY (He et al., 2022b), HDNO (Wang et al., 2020), and HDSA (Chen et al., 2019) as base models. \u2018 Note that for GALAXY, since we were unable to reproduce the official prediction using the official repository, we report the result with both official prediction (GALAXY) and the greedy (i.e., beam search with beam width=1) prediction we obtained by running the official repository (GALAXY\u2217).\nEvaluation protocol. From each model, we first sample five system response utterances: one from official prediction2 (Nekvinda and Du\u0161ek, 2021)\n2https://github.com/Tomiinek/MultiWOZ_Evaluation/tree/ master/predictions\nand four from the model downloaded from the official implementation (see appendix A.2.1 for details). The graph conditioning process follows Section 4.2. As an ablation, we also evaluated our method without conditioning on Shd graphs.\nMetric. We follow the standard evaluation metric using the official code (Nekvinda and Du\u0161ek, 2021), which computes three metrics on the MultiWOZ test set: BLEU (average BLEU (Papineni et al., 2002) scores between generated and ground truth response), Info (percentage of dialogs where the system presents an appropriate entity) and\nSucc (percentage of dialogs where the task goals are achieved). The combined score is computed as Score =BLEU + (Info + Succ)/2. See Appendix A.2.2 for details on computing these metrics. We report all four metrics of the compared methods.\nResult. We show the results in Table 4. We found that TOD-Flow can consistently improve Info and Succ metrics for all the base end-to-end dialog models. BLEU score fluctuates because it depends a lot on the exact wording of each response, which our graphs have no control over. The combined score consistently improves by 0.72, 0.49, 0.58, and 1.24 for HDSA, HDNO, GALAXY, and GALAXY\u2217, respectively by conditioning with our TOD-Flow. Note that these score improvements are actually quite significant, as the difference between top and second top SOTA methods (GALAXY and HDNO) is only 0.74.\nNext, we compare different graph generation methods: BC, MSG2, and TOD-Flow. Overall, TOD-Flow consistently outperforms other baselines, MSG2 and BC. In fact, the MSG2 and BC often underperforms the greedy prediction without graph conditioning (i.e., (no graph). Since the sampled predictions are in general much worse than the greedy prediction, unless the graph-based ranking is highly accurate, it often samples the prediction that is worse than greedy prediction. On the contrary, TOD-Flow is often able to accurately pick out the non-greedy better alternative to outperform the greedy predictions. We show one such example in Table 5. We also found that excluding Shd graphs (i.e., TOD-Flow\u2020) significantly reduced the improvement in all base models except HDNO. This shows that, while using only Can-Shdnt graphs also consistently improves performance of all base models, including Shd graphs can generally get even better results."
        },
        {
            "heading": "6 Related Work",
            "text": "Task-oriented Dialog Systems. There are two main classes of task-oriented dialog systems: pipeline systems and end-to-end systems. In pipeline approaches, the dialog system is segmented into various modules such as natural language understanding (NLU), dialog state tracking (DST), dialog policy and natural language generation (NLG) (Zhang et al., 2020). The NLU module first converts user language input into standardized dialog acts, slots and values. The DST module\nkeeps track of the current dialog state in terms of the dialog acts, slots and values. Based on the current dialog state, the dialog policy module predicts the next action. Previous works have viewed the dialog policy task as a Markov Decision Process (MDP) (Kwan et al., 2023). Common approaches include reinforcement learning methods such as Q-learning, policy gradient (Lipton et al., 2017; Zhou et al., 2017; Gordon-Hall et al., 2020) with experience-replay (Malviya et al., 2022), or modelbased planning (Peng et al., 2018). Lastly, given the current dialog states and the predicted dialog acts, the NLG module generates a response in natural language. We integrate the TOD-Flow graph into the dialogue policy module to improve its action prediction performance by learning what a model can, should and should not predict.\nOn the other hand, end-to-end systems integrate all functionalities into one module. Many end-toend models employ a singular language model to execute all four steps (He et al., 2022a). Alternatively, other methods bypass certain steps, generating the final response directly (He et al., 2022b; Wang et al., 2022). Pipeline systems are more interpretable and modular, allowing independent updates for enhanced control. Ours work uses the TOD-Flow graph to enhance end-to-end model responses by selecting the best one based on alignment with learned Can, Shd and Shdnt conditions.\nGraph-based Dialog Systems. There has also been previous works attempting to integrate graphs into task-oriented dialog systems. Most of them focused on using graphs to represent or select information from a knowledge base (Yang et al., 2020,\n2021). TGDM (Choi et al., 2016) attempted to create a dialog policy through manually constucted graphs, while a followup work (Kwon et al., 2018) proposed a rule-based system for automatically inferring these graphs given a working dialog policy. Raghu et al. (2021) tackles the task-oriented dialogue problem where the system must ground dialog utterances to the manually-defined flowcharts describing the procedure and adapt to unseen ones during testing. Laradji et al. (2023) aims to discover the workflow, a sequence of dialog acts with their respective slot values, from unseen conversation. Our TOD-Flow graph is constructed from labeled dialogue data without any human supervision. And our graph models the relationship between dialog acts and slots; e.g., what dialog act or updates in slot values can happen or not."
        },
        {
            "heading": "7 Conclusion",
            "text": "This work introduced a novel framework for improving the efficiency and predictive accuracy of task-oriented dialogues models. By leveraging the concept of subtask graph and generalizing it to a TOD-flow graph, we accurately inferred the latent task structure within a dialogue. As showcased through extensive experimentation with two public TOD datasets, the proposed technique has been proven to effectively generate accurate and human-interpretable graphs. Importantly, we have integrated these inferred graphs with a range of dialogue models, without necessitating retraining, resulting in a substantial enhancement in performance in both dialog act classification and end-toend response generation.\nLimitations\nAlthough our method can be directly used when there are multiple domains involved in a single dialog (by treating combination of domains as a single separate domain and creating graphs using dialogs that has the same combination of domains, similar to what we did for MultiWOZ), this approach is limited in that (1) we need to infer a graph for every combination of domains that is present (such as the multi-domain dialogs in SGD, where there are 24 different single-domains alone), and (2) we cannot easily generalize to unseen domain combinations (even if we have graphs for each individual domain). In the future, we would like to explore ways to directly combine graphs for individual domains into multi-domain graphs and thus address the two limitations above.\nWe also relied on action annotations from the datasets to infer graphs, which limits the applicability of our approach. It would be interesting to extend our approach to unannotated raw dialogues."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was supported in part by grants from LG AI Research."
        },
        {
            "heading": "A Experiment Details",
            "text": "A.1 Next Action Prediction A.1.1 Dataset Preprocessing details In the next action prediction experiment, we are using 2 datasets: MultiWOZ (Budzianowski et al., 2020) and SGD (Rastogi et al., 2020). We first split each dataset into domains and train/test splits. For MultiWOZ, the dataset has an official splitting of train/val/test splits, so we follow the same splits; while MultiWOZ contains dialogs from 7 domains, 2 of them (police, hospital) have no test dialogs, thus we split MultiWOZ dialogs into 14 domains, including 5 single-domains (i.e. dialogs that only involves one of the 5 domains) and 9 multi-domains (i.e. dialogs that involves multiple domains, such as Hotel+Train). For SGD, since the official train/val/test splits often involves test schemas that does not exist in the train set, we decided to create our own train/test splits from the official training set. There are 24 different schemas that have single-schema dialogs in the official training set, so we treat each of these schemas as a separate domain and randomly split dialogs within each domain into train/test splits at a 9:1 ratio.\nWe then turn each dialog into a trajectory (as defined in section 3.1). Below is how we define the dialog actions within each domain of each dataset:\nFor SGD, since there are already very comprehensive dialog acts and slot annotations, we directly use the acts defined in the dataset (with a few renaming) plus the slot annotations to build our set of all possible actions. In addition, since SGD provides explicit annotations about system\u2019s database queries, whenever the system queries database, we add an additional turn in our trajectory with one action \"SYSTEM query <Intent>\" and the status update would be either query success or query failure.\nFor MultiWOZ, we mostly also directly use the acts and slots in the dataset annotation to build\nour set of all possible actions, but we did some re-naming and re-organization to remove some redundant combinations of acts and slots (for example, \"SYSTEM Booking-Inform <slot>\" was changed into \"SYSTEM OfferBook + SYSTEM inform <slot>\"). Since there are no explicit annotation about database querying, we simply assume that the system looks up information before each \"book/nobook\" operation and add a corresponding status update to the utterance before these actions. We do not explicitly add \"query\" actions or additional turns to the trajectories.\nThen, within each domain, we will use the trajectories of the train split dialogs to obtain graphs and also act as demonstrations for LLMs, and use the graphs to improve next action predictions on the test dialogs.\nA.1.2 Large Language Model Prompting Details\nIn this experiment, we used GPT-turbo-3.5 as well as FLAN-T5 (Chung et al., 2022) as baseline next action predictors. We prompt the two LLMs using the exact same prompting method. For each domain, we first randomly select 10 dialogs from the training split, and then use their trajectories (i.e. actions and statuses of each turn) as demonstrations. Then for every system utterance in the test-split dialogs in the domain, we include as many of the demonstration trajectories as possible without exceeding the max token limit of the LLMs, and then we include the partial trajectory of the test dialog up to the turn where the next system actions needs to be predicted. Lastly, we ask the LLM to predict the next system actions, and we programmatically parse the results into individual action items. See Figure 4 for example prompt for SGD and MultiWOZ dataset.\nWhen obtaining the baseline result for each model, we use the top prediction by probability by setting temperature to zero (thus the language model\u2019s generation is deterministic). When we need to multiple predictions for graph filtering, for FLAM-T5-xxl we simply do a beam-search of size 10; for GPT-turbo-3.5 we set temperature to 1 and sample 10 times.\nA.2 Response Generation A.2.1 Getting Alternates from each model For Galaxy (He et al., 2022b), we used the top choice of beam-size-1 as well as the top 3 choices of beam-size-5 as alternates. The overall ranking\nof the 5 choices from highest to lowest are baseline, beam-size-1, beam-size-5 top choice, beam-size-5 second choice, beam-size-5 third choice.\nFor HDNO (Wang et al., 2020), since the official prediction baseline is the top choice of beam-size5, we use the two choices from beam-size-2 and the second and third choice from beam-size-5 as alternates. The overall ranking of the 5 choices from highest to lowest are baseline (i.e. beam-size5 top choice), beam-size-2 top choice, beam-size-5 second choice, beam-size-2 second choice, beamsize-5 third choice.\nFor HDSA (Chen et al., 2019) the process is slightly different. HDSA model consists of 2 parts: the first part (predictor) predicts the actions the system will perform (although in a very different format than what we do in our next action prediction experiment, so not directly comparable), and the second part (generator) uses the output of the predictor to generate the response. If we fix the predictor output and do beam-search on the generator only, the actions within the generated response will almost always be identical, which renders our method useless. Therefore, we created our alternates by tweaking a hyperparameter in the predictor a little bit. The output of the predictor is a binary vector, and the post-sigmoid logits of the predictor is converted to the binary vector by a threshold. The HDSA official code repository has 0.4 as the default threshold, and we changed the threshold around that value and used the different generated vectors as inputs to the generator to obtain our alternates. The overall ranking of the 5 choices from highest to lowest are baseline, threshold-0.4, threshold-0.375, threshold-0.35, threshold-0.325.\nA.2.2 Evaluation Details We use the official MultiWOZ_Evaluation repository to evaluate the BLEU/INFORM/SUCCESS metrics. Since our policy-learning setting assumes that we have access to the ground truth dialog state before the utterance, we use the ground truth dialog state and active domains in the evaluation scripts (by removing dialog state / active domain predictions and only including the response in the prediction file). This is necessary because we found that active domain predictions affect the INFORM/SUCCESS metrics, and incorrect active domain can increase/decrease INFORM/SUCCESS randomly. Therefore, to ensure fairness and consistency, we always use the ground truth active domain during evaluation.\nA.2.3 Using GPT as NLU unit We prompt GPT-turbo-3.5 to convert the candidate responses into action sets. For responses for dialogs in each domain, We first provide randomly selected dialogs from the training split of the same domain together with their ground truth system actions as demonstrations. Then, we specify the desired output format and provide an example of the output format. Lastly, we provide the dialog history of the current candidate responses, and ask GPT to give us actions to all candidate responses (i.e. the baseline + 4 sampled from the models). We start with 6 demonstrations, and we reduce the number of demonstrations by one iteratively if the total number of tokens exceeds the maximum token limit of the model (4097). We show one example prompt for responses from Galaxy (He et al., 2022b) together with the GPT completion in Figure 5.\nWe evaluated the quality of this NLU process by using this process to predict actions of the ground truth responses and compare the predicted actions to the ground truth actions on a subset of the test dialogs. We found that on average our NLU\u2019s predicted actions achieves an average F-1 score of 77.6%, which is okay but far from perfect, and the imperfectness of our NLU brings additional challenge to our task."
        },
        {
            "heading": "B Human-drawn GT graphs for SGD",
            "text": "In order to perform qualitative assessment of the quality of our graphs, we manually drew graphs for 10 domains in SGD. We show 2 such graphs in Figure 6 for RideSharing_1 schema and Figure 7 for RentalCars_1 schema respectively."
        }
    ],
    "title": "TOD-Flow: Modeling the Structure of Task-Oriented Dialogues",
    "year": 2023
}