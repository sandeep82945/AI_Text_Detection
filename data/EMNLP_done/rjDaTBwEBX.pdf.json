{
    "abstractText": "Multilingual generative language models (LMs) are increasingly fluent in a large variety of languages. Trained on the concatenation of corpora in multiple languages, they enable powerful transfer from high-resource languages to low-resource ones. However, it is still unknown what cultural biases are induced in the predictions of these models. In this work, we focus on one language property highly influenced by culture: formality. We analyze the formality distributions of XGLM and BLOOM\u2019s predictions, two popular generative multilingual language models, in 5 languages. We classify 1,200 generations per language as formal, informal, or incohesive and measure the impact of the prompt formality on the predictions. Overall, we observe a diversity of behaviors across the models and languages. For instance, XGLM generates informal text in Arabic and Bengali when conditioned with informal prompts, much more than BLOOM. In addition, even though both models are highly biased toward the formal style when prompted neutrally, we find that the models generate a significant amount of informal predictions even when prompted with formal text. We release with this work 6,000 annotated samples, paving the way for future work on the formality of generative multilingual LMs.",
    "authors": [
        {
            "affiliations": [],
            "name": "As\u0131m Ersoy"
        },
        {
            "affiliations": [],
            "name": "Gerson Vizcarra"
        },
        {
            "affiliations": [],
            "name": "Tasmiah Tahsin Mayeesha"
        },
        {
            "affiliations": [],
            "name": "Benjamin Muller"
        }
    ],
    "id": "SP:4e5d61ba2974b507977953e7e438edf155e81f94",
    "references": [
        {
            "authors": [
                "Abubakar Abid",
                "Maheen Farooqi",
                "James Zou."
            ],
            "title": "Persistent anti-muslim bias in large language models",
            "venue": "Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society, AIES \u201921, page 298\u2013306, New York, NY, USA. Association for Computing",
            "year": 2021
        },
        {
            "authors": [
                "Fadi Abu Sheikha",
                "Diana Inkpen."
            ],
            "title": "Automatic classification of documents by formality",
            "venue": "Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010), pages 1\u20135.",
            "year": 2010
        },
        {
            "authors": [
                "David H Ackley",
                "Geoffrey E Hinton",
                "Terrence J Sejnowski."
            ],
            "title": "A learning algorithm for boltzmann machines",
            "venue": "Cognitive science, 9(1):147\u2013169.",
            "year": 1985
        },
        {
            "authors": [
                "Kamel Gaanoun",
                "Khalid Elmadani",
                "Mustafa Ghaleb",
                "Nouamane Tazi",
                "Raed Alharbi",
                "Zaid Alyafeai"
            ],
            "title": "Masader plus: A new interface for exploring +500 arabic nlp datasets",
            "year": 2022
        },
        {
            "authors": [
                "Zaid Alyafeai",
                "Maraim Masoud",
                "Mustafa Ghaleb",
                "Maged S. Al-shaibani"
            ],
            "title": "Masader: Metadata sourcing for arabic text and speech data resources",
            "year": 2021
        },
        {
            "authors": [
                "Qiaoling Zhang",
                "Steven Zheng",
                "Ce Zheng",
                "Wei Zhou",
                "Denny Zhou",
                "Slav Petrov",
                "Yonghui Wu."
            ],
            "title": "Palm 2 technical report",
            "venue": "ArXiv, abs/2305.10403.",
            "year": 2023
        },
        {
            "authors": [
                "As-Said Muh\u00e1mmad Badawi."
            ],
            "title": "Mustawayat alarabiyya al-muasira fi Misr",
            "venue": "Dar al-maarif.",
            "year": 1973
        },
        {
            "authors": [
                "Francesco Barbieri",
                "Luis Espinosa Anke",
                "Jose Camacho-Collados."
            ],
            "title": "Xlm-t: Multilingual language models in twitter for sentiment analysis and beyond",
            "venue": "Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 258\u2013",
            "year": 2022
        },
        {
            "authors": [
                "Soumya Barikeri",
                "Anne Lauscher",
                "Ivan Vuli\u0107",
                "Goran Glava\u0161."
            ],
            "title": "RedditBias: A real-world resource for bias evaluation and debiasing of conversational language models",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Lin-",
            "year": 2021
        },
        {
            "authors": [
                "Kate Beeching",
                "Fran\u00e7oise Gadet",
                "Nigel Armstrong."
            ],
            "title": "Sociolinguistic variation in contemporary french",
            "venue": "Sociolinguistic Variation in Contemporary French, pages 1\u2013272.",
            "year": 2009
        },
        {
            "authors": [
                "Emily M. Bender",
                "Timnit Gebru",
                "Angelina"
            ],
            "title": "McMillanMajor, and Shmargaret Shmitchell",
            "venue": "In Proceedings of the 2021 ACM Conference on Fairness, Accountability,",
            "year": 2021
        },
        {
            "authors": [
                "Su Lin Blodgett",
                "Solon Barocas",
                "Hal Daum\u00e9 III",
                "Hanna Wallach."
            ],
            "title": "Language (technology) is power: A critical survey of \u201cbias\u201d in NLP",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5454\u2013",
            "year": 2020
        },
        {
            "authors": [
                "Rishi Bommasani",
                "Drew A Hudson",
                "Ehsan Adeli",
                "Russ Altman",
                "Simran Arora",
                "Sydney von Arx",
                "Michael S Bernstein",
                "Jeannette Bohg",
                "Antoine Bosselut",
                "Emma Brunskill"
            ],
            "title": "On the opportunities and risks of foundation models",
            "year": 2021
        },
        {
            "authors": [
                "Eleftheria Briakou",
                "Sweta Agrawal",
                "Joel Tetreault",
                "Marine Carpuat."
            ],
            "title": "Evaluating the evaluation metrics for style transfer: A case study in multilingual formality transfer",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Lan-",
            "year": 2021
        },
        {
            "authors": [
                "Eleftheria Briakou",
                "Di Lu",
                "Ke Zhang",
                "Joel Tetreault."
            ],
            "title": "Ol\u00e1, bonjour, salve! XFORMAL: A benchmark for multilingual formality style transfer",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computa-",
            "year": 2021
        },
        {
            "authors": [
                "Julian Brooke",
                "Tong Wang",
                "Graeme Hirst."
            ],
            "title": "Automatic acquisition of lexical formality",
            "venue": "Coling 2010: Posters, pages 90\u201398.",
            "year": 2010
        },
        {
            "authors": [
                "Roger Brown",
                "Albert Gilman"
            ],
            "title": "The pronouns of power and solidarity",
            "venue": "Style in language,",
            "year": 1960
        },
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "2020b. Language models are few-shot learners. Advances in neural information processing",
            "year": 2020
        },
        {
            "authors": [
                "Yang Trista Cao",
                "Hal Daum\u00e9 III."
            ],
            "title": "Toward gender-inclusive coreference resolution",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4568\u20134595, Online. Association for Computational Linguistics.",
            "year": 2020
        },
        {
            "authors": [
                "Jos\u00e9 Ca\u00f1ete"
            ],
            "title": "Compilation of large spanish unannotated corpora= https://doi.org/10.5281/ zenodo.3247731",
            "year": 2019
        },
        {
            "authors": [
                "P. C\u00e9peda",
                "E. Tavera."
            ],
            "title": "Redacci\u00f3n de textos formales: manual de consulta y modelos de redacci\u00f3n para escolares de 5\u00b0 de secundaria",
            "venue": "PUCP. Oficina Central de Adminsi\u00f3n.",
            "year": 2007
        },
        {
            "authors": [
                "Aakanksha Chowdhery",
                "Sharan Narang",
                "Jacob Devlin",
                "Maarten Bosma",
                "Gaurav Mishra",
                "Adam Roberts",
                "Paul Barham",
                "Hyung Won Chung",
                "Charles Sutton",
                "Sebastian Gehrmann"
            ],
            "title": "Palm: Scaling language modeling with pathways",
            "year": 2022
        },
        {
            "authors": [
                "Shaika Chowdhury",
                "Wasifa Chowdhury."
            ],
            "title": "Performing sentiment analysis in bangla microblog posts",
            "venue": "2014 International Conference on Informatics, Electronics & Vision (ICIEV), pages 1\u20136. IEEE.",
            "year": 2014
        },
        {
            "authors": [
                "Paul F Christiano",
                "Jan Leike",
                "Tom Brown",
                "Miljan Martic",
                "Shane Legg",
                "Dario Amodei."
            ],
            "title": "Deep reinforcement learning from human preferences",
            "venue": "Advances in neural information processing systems, 30.",
            "year": 2017
        },
        {
            "authors": [
                "Samuel Rhys Cox",
                "Wei Tsang Ooi."
            ],
            "title": "Does chatbot language formality affect users\u2019 self-disclosure? In Proceedings of the 4th Conference on Conversational User Interfaces, CUI \u201922, New York, NY, USA",
            "venue": "Association for Computing Machinery.",
            "year": 2022
        },
        {
            "authors": [
                "Isak Czeresnia Etinger",
                "Alan W Black."
            ],
            "title": "Formality style transfer for noisy, user-generated conversations: Extracting labeled, parallel data from unlabeled corpora",
            "venue": "Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019),",
            "year": 2019
        },
        {
            "authors": [
                "Shishir Kumar Das."
            ],
            "title": "Forms of address and terms of reference in bengali",
            "venue": "Anthropological Linguistics, 10(4):19\u201331.",
            "year": 1968
        },
        {
            "authors": [
                "Anne Boyle David."
            ],
            "title": "Descriptive Grammar of Bangla",
            "venue": "De Gruyter Mouton, Berlin, M\u00fcnchen, Boston.",
            "year": 2015
        },
        {
            "authors": [
                "Thomas Davidson",
                "Debasmita Bhattacharya",
                "Ingmar Weber."
            ],
            "title": "Racial bias in hate speech and abusive language detection datasets",
            "venue": "Proceedings of the Third Workshop on Abusive Language Online, pages 25\u201335, Florence, Italy. Association for Com-",
            "year": 2019
        },
        {
            "authors": [
                "Daryna Dementieva",
                "Ivan Trifinov",
                "Andrey Likhachev",
                "Alexander Panchenko."
            ],
            "title": "Detecting text formality: A study of text classification approaches",
            "venue": "arXiv preprint arXiv:2204.08975.",
            "year": 2022
        },
        {
            "authors": [
                "Weston Feely",
                "Eva Hasler",
                "Adri\u00e0 de Gispert."
            ],
            "title": "Controlling Japanese honorifics in Englishto-Japanese neural machine translation",
            "venue": "Proceedings of the 6th Workshop on Asian Translation, pages 45\u201353, Hong Kong, China. Association for Computa-",
            "year": 2019
        },
        {
            "authors": [
                "Virginia K. Felkner",
                "Ho-Chun Herbert Chang",
                "Eugene Jang",
                "Jonathan May."
            ],
            "title": "Towards winoqueer: Developing a benchmark for anti-queer bias in large language models",
            "venue": "ArXiv, abs/2206.11484.",
            "year": 2022
        },
        {
            "authors": [
                "Fran\u00e7oise Gadet."
            ],
            "title": "Research on sociolinguistic style/Soziolinguistische Stilforschung",
            "venue": "Ulrich Ammon, Norbert Dittmar, Karl Mattheier, and Peter Trudgill, editors, Sociolinguistics-Soziolinguistik, An International Handbook of the Science of Language",
            "year": 2005
        },
        {
            "authors": [
                "Samarjit Ghosh",
                "Souvik Mukherjee",
                "Debojyoti Roy",
                "Sumit Sarkar",
                "Debranjan Sarkar."
            ],
            "title": "Bangla language processing: Sandhi",
            "venue": "2022 IEEE India Council International Subsections Conference (INDISCON), pages 1\u20135. IEEE.",
            "year": 2022
        },
        {
            "authors": [
                "Kilem L Gwet."
            ],
            "title": "Handbook of inter-rater reliability: The definitive guide to measuring the extent of agreement among raters",
            "venue": "Advanced Analytics, LLC.",
            "year": 2014
        },
        {
            "authors": [
                "S\u00f8gaard."
            ],
            "title": "Challenges and strategies in crosscultural NLP",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 6997\u20137013, Dublin, Ireland. Association for Computational Lin-",
            "year": 2022
        },
        {
            "authors": [
                "Francis Heylighen",
                "Jean-Marc Dewaele."
            ],
            "title": "Formality of language: definition, measurement and behavioral determinants",
            "venue": "Interner Bericht, Center \u201cLeo Apostel\u201d, Vrije Universiteit Br\u00fcssel, 4.",
            "year": 1999
        },
        {
            "authors": [
                "Ari Holtzman",
                "Jan Buys",
                "Li Du",
                "Maxwell Forbes",
                "Yejin Choi."
            ],
            "title": "The curious case of neural text degeneration",
            "venue": "International Conference on Learning Representations.",
            "year": 2019
        },
        {
            "authors": [
                "Dirk Hovy",
                "Diyi Yang."
            ],
            "title": "The importance of modeling social factors of language: Theory and practice",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
            "year": 2021
        },
        {
            "authors": [
                "Xiaoze Jiang",
                "Yaobo Liang",
                "Weizhu Chen",
                "Nan Duan."
            ],
            "title": "Xlm-k: Improving cross-lingual language model pre-training with multilingual knowledge",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 10840\u201310848.",
            "year": 2022
        },
        {
            "authors": [
                "Elizaveta Korotkova",
                "Agnes Luhtaru",
                "Maksym Del",
                "Krista Liin",
                "Daiga Deksne",
                "Mark Fishel."
            ],
            "title": "Grammatical error correction and style transfer via zero-shot monolingual translation",
            "venue": "arXiv preprint arXiv:1903.11283.",
            "year": 2019
        },
        {
            "authors": [
                "Kalpesh Krishna",
                "Deepak Nathani",
                "Xavier Garcia",
                "Bidisha Samanta",
                "Partha Talukdar."
            ],
            "title": "Fewshot controllable style transfer for low-resource multilingual settings",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Lin-",
            "year": 2022
        },
        {
            "authors": [
                "Shibamouli Lahiri."
            ],
            "title": "Squinky! a corpus of sentence-level formality, informativeness, and implicature",
            "venue": "arXiv preprint arXiv:1506.02306.",
            "year": 2015
        },
        {
            "authors": [
                "Paul Pu Liang",
                "Chiyu Wu",
                "Louis-Philippe Morency",
                "Ruslan Salakhutdinov."
            ],
            "title": "Towards understanding and mitigating social biases in language models",
            "venue": "International Conference on Machine Learning.",
            "year": 2021
        },
        {
            "authors": [
                "Cassi L Liard\u00e9t",
                "Sharyn Black",
                "Vani Sharren Bardetta."
            ],
            "title": "Defining formality: Adapting to the abstract demands of academic discourse",
            "venue": "Journal of English for Academic Purposes, 38:146\u2013158.",
            "year": 2019
        },
        {
            "authors": [
                "Jind\u0159ich Libovick\u00fd",
                "Rudolf Rosa",
                "Alexander Fraser."
            ],
            "title": "On the language neutrality of pre-trained multilingual representations",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1663\u20131674, Online. Association for Computa-",
            "year": 2020
        },
        {
            "authors": [
                "moyer",
                "Zornitsa Kozareva",
                "Mona Diab",
                "Ves Stoyanov",
                "Xian Li"
            ],
            "title": "2021a. Few-shot learning with multilingual language models. ArXiv, abs/2112.10668",
            "year": 2021
        },
        {
            "authors": [
                "Xi Victoria Lin",
                "Todor Mihaylov",
                "Mikel Artetxe",
                "Tianlu Wang",
                "Shuohui Chen",
                "Daniel Simig",
                "Myle Ott",
                "Naman Goyal",
                "Shruti Bhosale",
                "Jingfei Du"
            ],
            "title": "2021b. Few-shot learning with multilingual language models. arXiv preprint arXiv:2112.10668",
            "year": 2021
        },
        {
            "authors": [
                "Aman Madaan",
                "Amrith Setlur",
                "Tanmay Parekh",
                "Barnabas Poczos",
                "Graham Neubig",
                "Yiming Yang",
                "Ruslan Salakhutdinov",
                "Alan W Black",
                "Shrimai Prabhumoye."
            ],
            "title": "Politeness transfer: A tag and generate approach",
            "venue": "Proceedings of the 58th Annual Meet-",
            "year": 2020
        },
        {
            "authors": [
                "Vijit Malik",
                "Sunipa Dev",
                "Akihiro Nishi",
                "Nanyun Peng",
                "Kai-Wei Chang."
            ],
            "title": "Socially aware bias measurements for Hindi language representations",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computa-",
            "year": 2022
        },
        {
            "authors": [
                "Benjamin Muller",
                "Yanai Elazar",
                "Beno\u00eet Sagot",
                "Djam\u00e9 Seddah."
            ],
            "title": "First align, then predict: Understanding the cross-lingual ability of multilingual BERT",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Computa-",
            "year": 2021
        },
        {
            "authors": [
                "Samuel Mu\u00f1oz."
            ],
            "title": "9322 letras de rap en espa\u00f1ol, version 1",
            "venue": "https://www.kaggle.com/datasets/ smunoz3801/9325-letras-de-rap-en-espaol.",
            "year": 2018
        },
        {
            "authors": [
                "Moin Nadeem",
                "Anna Bethke",
                "Siva Reddy."
            ],
            "title": "StereoSet: Measuring stereotypical bias in pretrained language models",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference",
            "year": 2021
        },
        {
            "authors": [
                "Maria Nadejde",
                "Anna Currey",
                "Benjamin Hsu",
                "Xing Niu",
                "Marcello Federico",
                "Georgiana Dinu."
            ],
            "title": "CoCoA-MT: A dataset and benchmark for contrastive controlled MT with application to formality",
            "venue": "Findings of the Association for Computational Linguistics:",
            "year": 2022
        },
        {
            "authors": [
                "Hemalatha Nagarajan."
            ],
            "title": "Constraints through the ages: Loan words in bangla",
            "venue": "The EFL Journal, 5(1):41\u201363.",
            "year": 2014
        },
        {
            "authors": [
                "Nikita Nangia",
                "Clara Vania",
                "Rasika Bhalerao",
                "Samuel R. Bowman."
            ],
            "title": "CrowS-pairs: A challenge dataset for measuring social biases in masked language models",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language",
            "year": 2020
        },
        {
            "authors": [
                "Aur\u00e9lie N\u00e9v\u00e9ol",
                "Yoann Dupont",
                "Julien Bezan\u00e7on",
                "Kar\u00ebn Fort."
            ],
            "title": "French CrowS-Pairs: Extending a challenge dataset for measuring social bias in masked language models to a language other than English",
            "venue": "ACL 2022 - 60th Annual Meeting of the Association",
            "year": 2022
        },
        {
            "authors": [
                "Xing Niu",
                "Marine Carpuat."
            ],
            "title": "Controlling neural machine translation formality with synthetic supervision",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 8568\u20138575.",
            "year": 2020
        },
        {
            "authors": [
                "Xing Niu",
                "Marianna Martindale",
                "Marine Carpuat."
            ],
            "title": "A study of style in machine translation: Controlling the formality of machine translation output",
            "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages",
            "year": 2017
        },
        {
            "authors": [
                "Long Ouyang",
                "Jeff Wu",
                "Xu Jiang",
                "Diogo Almeida",
                "Carroll L Wainwright",
                "Pamela Mishkin",
                "Chong Zhang",
                "Sandhini Agarwal",
                "Katarina Slama",
                "Alex Ray"
            ],
            "title": "Training language models to follow instructions with human feedback",
            "year": 2022
        },
        {
            "authors": [
                "Hemanta Ranjan Panda."
            ],
            "title": "Rule based\" Sandhi Bicched\"(de-euphonization) of Bengali",
            "venue": "Ph.D. thesis, Indian Statistical Institute-Kolkata.",
            "year": 1992
        },
        {
            "authors": [
                "Ellie Pavlick",
                "Joel Tetreault."
            ],
            "title": "An empirical analysis of formality in online communication",
            "venue": "Transactions of the Association for Computational Linguistics, 4:61\u201374.",
            "year": 2016
        },
        {
            "authors": [
                "Telmo Pires",
                "Eva Schlinger",
                "Dan Garrette."
            ],
            "title": "How multilingual is multilingual BERT? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4996\u20135001, Florence, Italy",
            "venue": "Association for Computational Linguis-",
            "year": 2019
        },
        {
            "authors": [
                "Alec Radford",
                "Jeffrey Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "venue": "OpenAI blog,",
            "year": 2019
        },
        {
            "authors": [
                "Sudha Rao",
                "Joel Tetreault."
            ],
            "title": "Dear sir or madam, may I introduce the GYAFC dataset: Corpus, benchmarks and metrics for formality style transfer",
            "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computa-",
            "year": 2018
        },
        {
            "authors": [
                "Punya Sloka Ray"
            ],
            "title": "Bengali language handbook",
            "year": 1966
        },
        {
            "authors": [
                "Jack C Richards",
                "Richard W Schmidt."
            ],
            "title": "Longman dictionary of language teaching and applied linguistics",
            "venue": "Routledge.",
            "year": 2013
        },
        {
            "authors": [
                "Elijah Rippeth",
                "Sweta Agrawal",
                "Marine Carpuat."
            ],
            "title": "Controlling translation formality using pretrained multilingual language models",
            "venue": "arXiv preprint arXiv:2205.06644.",
            "year": 2022
        },
        {
            "authors": [
                "Danica Salazar",
                "Aaron Ventura",
                "Isabel Verdaguer."
            ],
            "title": "A cross-disciplinary analysis of personal and impersonal features in english and spanish scientific writing",
            "venue": "Biomedical English: A corpus-based approach, 56:121.",
            "year": 2013
        },
        {
            "authors": [
                "Teven Le Scao",
                "Angela Fan",
                "Christopher Akiki",
                "Ellie Pavlick",
                "Suzana Ili\u0107",
                "Daniel Hesslow",
                "Roman Castagn\u00e9",
                "Alexandra Sasha Luccioni",
                "Fran\u00e7ois Yvon",
                "Matthias Gall\u00e9"
            ],
            "title": "Bloom: A 176bparameter open-access multilingual language model",
            "year": 2022
        },
        {
            "authors": [
                "Andrea Schioppa",
                "David Vilar",
                "Artem Sokolov",
                "Katja Filippova."
            ],
            "title": "Controlling machine translation for multiple attributes with additive interventions",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages",
            "year": 2021
        },
        {
            "authors": [
                "Rico Sennrich",
                "Barry Haddow",
                "Alexandra Birch."
            ],
            "title": "Controlling politeness in neural machine translation via side constraints",
            "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human",
            "year": 2016
        },
        {
            "authors": [
                "Emily Sheng",
                "Kai-Wei Chang",
                "Prem Natarajan",
                "Nanyun Peng."
            ],
            "title": "Societal biases in language generation: Progress and challenges",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International",
            "year": 2021
        },
        {
            "authors": [
                "Eric Michael Smith",
                "Melissa Hall",
                "Melanie Kambadur",
                "Eleonora Presani",
                "Adina Williams."
            ],
            "title": "I\u2019m sorry to hear that\u201d: Finding new biases in language models with a holistic descriptor dataset",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods",
            "year": 2022
        },
        {
            "authors": [
                "Miranda Stewart"
            ],
            "title": "Pronouns of power and solidarity: The case of spanish first person plural nosotros",
            "year": 2001
        },
        {
            "authors": [
                "Nisan Stiennon",
                "Long Ouyang",
                "Jeffrey Wu",
                "Daniel Ziegler",
                "Ryan Lowe",
                "Chelsea Voss",
                "Alec Radford",
                "Dario Amodei",
                "Paul F Christiano."
            ],
            "title": "Learning to summarize with human feedback",
            "venue": "Advances in Neural Information Processing Systems, 33:3008\u2013",
            "year": 2020
        },
        {
            "authors": [
                "Asifa Sultana"
            ],
            "title": "Description of verb morphology in colloquial bangla",
            "year": 2016
        },
        {
            "authors": [
                "Tony Sun",
                "Andrew Gaut",
                "Shirlyn Tang",
                "Yuxin Huang",
                "Mai ElSherief",
                "Jieyu Zhao",
                "Diba Mirza",
                "Elizabeth Belding",
                "Kai-Wei Chang",
                "William Yang Wang."
            ],
            "title": "Mitigating gender bias in natural language processing: Literature review",
            "venue": "Proceedings of the",
            "year": 2019
        },
        {
            "authors": [
                "Tunuguntla",
                "Oskar van der Wal."
            ],
            "title": "You reap what you sow: On the challenges of bias evaluation under multilingual settings",
            "venue": "Proceedings of BigScience Episode #5 \u2013 Workshop on Challenges & Perspectives in Creating Large Language Models.",
            "year": 2022
        },
        {
            "authors": [
                "Md Afaz Uddin."
            ],
            "title": "Second person pronouns as person deixis in bengali and english: Linguistic forms and pragmatic functions",
            "venue": "International Journal of English Linguistics, 10(1):345\u2013351.",
            "year": 2019
        },
        {
            "authors": [
                "Aditi Viswanathan",
                "Varden Wang",
                "Antonina Kononova."
            ],
            "title": "Controlling formality and style of machine translation output using automl",
            "venue": "Information Management and Big Data, pages 306\u2013313, Cham. Springer International Publishing.",
            "year": 2020
        },
        {
            "authors": [
                "Yunli Wang",
                "Yu Wu",
                "Lili Mou",
                "Zhoujun Li",
                "Wenhan Chao."
            ],
            "title": "Harnessing pre-trained neural networks with rules for formality style transfer",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
            "year": 2019
        },
        {
            "authors": [
                "Yunli Wang",
                "Yu Wu",
                "Lili Mou",
                "Zhoujun Li",
                "WenHan Chao."
            ],
            "title": "Formality style transfer with shared latent space",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 2236\u20132249, Barcelona, Spain (Online). International",
            "year": 2020
        },
        {
            "authors": [
                "Janet Watson"
            ],
            "title": "Arabic dialects (general article)",
            "year": 2011
        },
        {
            "authors": [
                "Zonghai Yao",
                "Hong Yu."
            ],
            "title": "Improving formality style transfer with context-aware rule injection",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Lan-",
            "year": 2021
        },
        {
            "authors": [
                "Omar F. Zaidan",
                "Chris Callison-Burch."
            ],
            "title": "The Arabic online commentary dataset: an annotated dataset of informal Arabic with high dialectal content",
            "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Hu-",
            "year": 2011
        },
        {
            "authors": [
                "Susan Zhang",
                "Stephen Roller",
                "Naman Goyal",
                "Mikel Artetxe",
                "Moya Chen",
                "Shuohui Chen",
                "Christopher Dewan",
                "Mona Diab",
                "Xian Li",
                "Xi Victoria Lin"
            ],
            "title": "Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068",
            "year": 2022
        },
        {
            "authors": [
                "Ruiqi Zhong",
                "Kristy Lee",
                "Zheng Zhang",
                "Dan Klein."
            ],
            "title": "Adapting language models for zero-shot learning by meta-tuning on dataset and prompt collections",
            "venue": "arXiv preprint arXiv:2104.04670.",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Natural Language Processing (NLP) systems are used worldwide across multiple cultures, audiences, contexts, communication goals, demographics, and languages. Thus, it is essential that these models be able to adapt to the sociocultural context of its users. As described by Hershcovich et al. (2022), linguistic style is one of the major dimensions by which cultures vary in NLP technologies.\nIn this work, we focus on formality. Formality is a stylistic property of language that can impact how we perceive a text. It typically carries information about the culture of the speaker (or writer), is constrained by the context of the message, and can impact the communicative goal of a text (Heylighen and Dewaele, 1999). Generating text with a desired\n\u2217Equal contribution. This work was done as part of the Fatima Fellowship mentoring program.\nlevel of formality can be useful for different NLP applications (Hovy and Yang, 2021). For example, controlling the tone of machine translation models (Sennrich et al., 2016; Niu et al., 2017; Feely et al., 2019), designing chatbots with formality awareness to respond to user-preferred conversational style (Cox and Ooi, 2022), or assisting users to change the formality level of their writings (Rao and Tetreault, 2018; Wang et al., 2019, 2020).\nGenerative language models have demonstrated capabilities in producing cohesive texts and solving NLP tasks with zero/few-shot learning (Radford et al., 2019; Brown et al., 2020b; Chowdhery et al., 2022; Zhang et al., 2022), even in multilingual scenarios (Lin et al., 2021b; Scao et al., 2022; Barbieri et al., 2022; Jiang et al., 2022; Anil et al., 2023). Multilingual language models are trained with large amounts of text from different sources. That training process could make the model biased towards a certain level of formality because of the data of each language as well as cross-lingual transfer (Pires et al., 2019; Libovick\u00fd et al., 2020; Muller et al., 2021), limiting the capabilities of the model to adapt to the different cultures of an NLP application.\nThis work analyzes the formality level of two multilingual language models: XGLM (Lin et al., 2021b) and BLOOM (Scao et al., 2022), across five languages, namely Arabic, Bengali, English, French, and Spanish. To do so, a native/proficient speaker of each language evaluates the generation outputs of each model into three categories: formal, informal, and incohesive. This evaluation allows us to analyze the generations across three different dimensions: the cohesiveness of the generations,1 the formality bias given neutral prompts, and the formality preservation given formal/informal prompts. As an example, we show in Table 1 the predictions of BLOOM and XGLM conditioned on the same\n1In short, we define a sequence as incohesive if it cannot be evaluated as formal/informal. More details in Section 4.3\nprompt in Bengali but generating text of different formality level. Overall, our contributions are the following:\n\u2022 To the best of our knowledge, this is the first work to analyze the formality of generative multilingual language models across multiple languages. While we have focused on specific models and languages in this work, the procedures followed to define formality, prompt sourcing, language generation, and measurement of how formality is preserved from prompts are generalizable to any generative system and language. We open-source 1,200 generations,2 per language, manually annotated as formal, informal, or incohesive.\n\u2022 We find that BLOOM generates about twice as long texts as XGLM. Besides, almost all the generated formal sentences are longer than the informal ones. Also, informal generations in English, French, and Spanish are characterized by being more conversational, and in Bengali, by having more punctuation marks.\n\u2022 We find that BLOOM is significantly more cohesive than XGLM in English, French, and Spanish and performs similarly in other languages.\n\u2022 Both XGLM and BLOOM are generally biased toward formal text when prompted in a\n2https://github.com/asimokby/ formality-bias-analysis\nneutral way. However, both models are very sensitive to the formality of the prompt and will generate informal text if conditioned with an informal prompt. This is particularly striking for Arabic: BLOOM generates dialectal Arabic (considered informal) when prompted with informal text while being extremely biased toward Modern-Standard Arabic (considered formal)."
        },
        {
            "heading": "2 Formality Across Different Languages",
            "text": "We start by defining formality in the five languages of our study.\nArabic The Arabic language is spoken in many dialects (Watson, 2011). These dialects are variants of classical or standard Arabic, which has a modernized version of it called Modern Standard Arabic (MSA). Badawi (1973), in his famous book \u201cMustawayat Al-arabiyya Al-muasira Fi Misr\u201d The levels of contemporary Arabic in Egypt, presents a theory on the relationship between standard Arabic (Fusha) and vernacular Arabic (Ammiya) in Egypt. His theory describes the situation as a continuum with 5 major divisions: illiterate colloquial Arabic, educated colloquial Arabic, elevated colloquial Arabic, modern standard Arabic, and classical Arabic. The first three divisions are Ammiya, which is considered informal and not necessarily grammatically correct. The last two divisions are Fusha, which is considered formal. However, the definition of what is formal and what is informal could depend on the problem at hand; for example, in one\ncase, elevated colloquial Arabic could be considered formal, while illiterate colloquial Arabic as informal. In our work, we define formality for Arabic as follows: a piece of text is formal if it contains no words coming from any Arabic dialect which is not considered as Fusha, following (Badawi, 1973)\u2019s definition of Fusha. For example, the following sentence: ?d s r \u00a7 (where is the closest mosque?) is formed of only Fasih, formal, words. Similarly, a piece of text is informal if it contains a word coming from any dialect and not Fusha. For example, ?d s r y \u2014 (where is the closest mosque?) is informal because of the word y \u2014 (where) which is Egyptian Arabic.\nBengali Bengali has a complex and elaborate system of using pronouns to express the degrees of familiarity and formality between the participants in a conversation (Das, 1968; Uddin, 2019). TV distinction (Brown et al., 1960) or the contextual usage of pronouns to convey varying levels of formality, familiarity, and politeness, which is found in many Romance languages (French, Italian, Spanish, etc.), can also be seen in Bengali. Bengali follows a tripartite form of second-person pronouns: / Apni (formal) for respected elders and strangers, / Tumi (polite) for siblings/friends or familiar people and / Tui (informal) for those who are younger, children or very close friends. The third person he / she can be translated to / Tini (formal) vs / Se (informal), which encodes two levels of formality \u2013 honorific and non-honorific. Bengali pronouns can encode numbers such as singular/plural, but the notion of formality is not changed by gender or numerical properties (David, 2015).\nThe following are other considerations of formality in Bengali: (i) Texts containing a high frequency of Sanskrit-originated words can be considered formal. Agglutination/Compound words can be considered more formal compared to their analytical or elaborated forms. For instance, the words (formal) / (informal) \u2014 death have the same meaning, but a different formality (Panda, 1992; Nagarajan, 2014; Ghosh et al., 2022). (ii) Bengali pronouns agree with the verb in levels of formality and there are formal and informal variations of the same verb (David, 2015; Sultana, 2016). For instance, verbs like Give, Eat, Go can be written as (formal) or (informal) depending on the context. (iii) Among Bengali speakers in Bangladesh, regional dialects\nlike Sylheti, Chakma, and Chittagonian are generally considered informal while classical Bengali dialect (Sa\u0304dhubha\u0304sa\u0304) or standardized Bengali dialect (Cholito vasha) is considered formal (Ray et al., 1966).\nEnglish Formality in English is commonly defined as the language style used in a given situation. A formal speech, for instance, has a very careful selection of pronunciation, words, and structure (Richards and Schmidt, 2013). Heylighen and Dewaele (1999) divide English formality into two dimensions: a deep formality, characterized by the understanding of the precise meaning, avoiding ambiguity; and a surface formality which focuses on the rigorous selection of manners. Some recent works focus on the latter to evaluate formality using the selection of words (Brooke et al., 2010) and discarding the topic (Pavlick and Tetreault, 2016). Following Liard\u00e9t et al. (2019), we use the following rules below to evaluate cohesive English text as informal: (i) Presence of contractions, abbreviations, and colloquial expressions; (ii) presence of grammar infelicities, that is, unsuitable expressions, inconsistencies in writing, and misspellings; (iii) high occurrence of delexical verbs and phrasal verbs; and (iv) higher involvement of human participants and subjective judgments, such as opinions.\nFrench Formality is typically classified in French into three classes: soutenu, courant and familier (Gadet, 2005; Beeching et al., 2009). The register soutenu is reserved for legal documents, literature, or when addressing someone we want to show particular respect (e.g., a judge). It usually involves addressing someone with the second person plural (called vousvo\u00eement). The register courant corresponds to the one used in day-to-day life, for instance, when we talk to someone new which is typically neutral and includes few grammatical errors. The register familier is the one used with friends, or within a family circle. It usually involves addressing someone with the second singular person tu. It can include a large portion of grammatical errors. Finally, it can also include slang and insults in its most vulgar form. In this work, following what was done in the XFORMAL work (Briakou et al., 2021b), we classify generated text into two classes. Soutenu is associated with the formal class while familier and courant with the informal class.\nSpanish Formality in Spanish is commonly described by the T-V distinctions in the singular\nsecond-person pronoun derived from Latin. Specifically, there are two possible translations for the English pronoun \u201cyou\u201d: t\u00fa is considered informal, and usted is formal. Both pronouns have different conjugations. The formality in sentences that use the singular second person is easily recognizable.\nIn the case of the other pronouns, the first person is often considered less polite than the third one (Stewart, 2001). For that reason, the third person is commonly used in scientific texts (Salazar et al., 2013). Aside from the pronouns and their conjugations, according to C\u00e9peda and Tavera (2007), a formal text in Spanish should accomplish other characteristics such as: (i) Having no typographical or grammatical errors. (ii) Being a set of sentences referring to the same topic. (iii) Being arranged in paragraphs and having a coherent correlation between ideas using appropriate connectors.\nIn our work, we check the presence of slang or offensive terms in a sequence to classify text as informal. Then, T/V distinction in sentences written using the second person defines the formality level. In a similar way, sentences written in the third person have a bigger probability of being classified as formal compared to the ones written in the first person. The final priority is the layout: paragraphstructured sequences are considered formal in more scenarios than conversational-structured ones."
        },
        {
            "heading": "3 Related Work",
            "text": "Biases of Generative LMs Recent literature on Large Language Models (LLMs) demonstrated social bias and prejudice against minorities (Sheng et al., 2021; Blodgett et al., 2020; Bender et al., 2021; Bommasani et al., 2021; Liang et al., 2021) in terms of many categories including gender (Sun et al., 2019; Cao and Daum\u00e9 III, 2020; Felkner et al., 2022), race (Davidson et al., 2019), religion (Abid et al., 2021; Malik et al., 2022), occupation, politics and disabilities which result in the production of damaging content. To create multilingual bias evaluation frameworks, it has been argued that careful curation of culturally aware datasets is needed (Talat et al., 2022).\nMany papers have focused on measuring social biases and stereotypes against historically disadvantaged groups and counteracting them for a limited number of languages like English (Nadeem et al., 2021; Nangia et al., 2020; Barikeri et al., 2021; Smith et al., 2022), French (N\u00e9v\u00e9ol et al., 2022), Hindi (Malik et al., 2022), but similar work has not\nbeen done for low-resource languages like Bengali. To our knowledge, the evaluation of multilingual models for measuring cultural biases like formality has not been attempted so far.\nFormality Analysis Previous work in formality analysis has focused on formality classification (Heylighen and Dewaele, 1999; Abu Sheikha and Inkpen, 2010; Pavlick and Tetreault, 2016; Dementieva et al., 2022), formality style transfer in English (Rao and Tetreault, 2018; Wang et al., 2019, 2020; Czeresnia Etinger and Black, 2019; Madaan et al., 2020; Yao and Yu, 2021; Briakou et al., 2021a), and in the multilingual setting (Korotkova et al., 2019; Briakou et al., 2021b; Krishna et al., 2022). Formality-sensitive machine translation to control the generation of machine translation models to target formality has received attention in recent years (Sennrich et al., 2016; Niu et al., 2017; Feely et al., 2019; Viswanathan et al., 2020; Niu and Carpuat, 2020; Schioppa et al., 2021) and benchmark MT datasets and models have been published (Nadejde et al., 2022; Rippeth et al., 2022).\nRecently, several datasets with formality annotations have been introduced in English (Lahiri, 2015; Pavlick and Tetreault, 2016; Rao and Tetreault, 2018). XFORMAL (Briakou et al., 2021b), TAOCD (Zaidan and Callison-Burch, 2011) and InFormal (Krishna et al., 2022) extended formality style transfer to the multilingual setting. In the following sections, we describe our experiments and results for different languages."
        },
        {
            "heading": "4 Experiments",
            "text": "We evaluate different dimensions of formality of the generations of two popular generative multilingual language models: XGLM (Lin et al., 2021b) and BLOOM (Scao et al., 2022), in five languages: Arabic, Bengali, English, Spanish, and French. We hypothesize that the influence of high-resource languages in the corpus can involve biases in the formality of the whole models. To see their behavior in different scenarios, we employ distinct variations of prompt lengths and formality. In addition, we tweak some parameters when generating to avoid incohesive outputs.\nXGLM (Lin et al., 2021b) is a multilingual language model trained with 500 billion tokens belonging to 30 languages of Common Crawl. XGLM has five sizes ranging from 564 million to 7.5 billion parameters.\nBLOOM (Scao et al., 2022) is also a multilingual generative language model trained on around 341 billion tokens from a corpus of 59 languages (13 of them are programming ones) to democratize huge pre-trained language models. BLOOM was released in different sizes ranging from 560 million to 176 billion parameters.\nXLGM and BLOOM are decoder-only transformers pre-trained on a similar set of languages with a comparable amount of data. We compare checkpoints of similar size (i.e. we compare XGLM 2.9B with BLOOM 3B and XGLM 7.5B and BLOOM 7.1B3). Regarding the proportion and data sources on which both models were trained, BLOOM was trained on a more varied set of domains than XGLM in spite of the XGLM corpus being larger. In addition, the BLOOM corpus has a more balanced distribution of the amount of data of the languages evaluated in this study. More details about the quantity and sources of both models can be found in Appendix C."
        },
        {
            "heading": "4.1 Prompting for Formality Evaluation",
            "text": "We employ two prompting strategies to condition the generation of the models. In that way, the behavior of the model in different scenarios can be assessed.\nShort Neutral Prompts A short prompt is composed of up to three words to condition the language of the output without giving any context that could impact the formality level. That allows us to measure the models\u2019 tendency to produce a certain formality level with a neutral input. For the lexicon of each language, we pick a set of common words4 (or a combination of them to avoid the confusion of languages when generating) that can be used in both formal and informal sentences.\nLong Informal/Formal Prompts This set of prompts is composed of truncated sentences extracted from existing formal/informal sources. Using these prompts, we can verify how much the models preserve the formality level of their in-\n3We use the checkpoints and implementations from https: //huggingface.co/models\n4http://corpus.rae.es/lfrecuencias.html, https://www.pinhok.com/kb/bengali/98/ 100-basic-bengali-vocabularies/, https://talkinarabic.com/arabic-words/, https://en.wikipedia.org/wiki/Most_common_words_ in_English https://strommeninc.com/ 1000-most-common-french-words-frequency-vocabulary/\nput. The sources of the prompts include formality datasets such as GYAFC (Rao and Tetreault, 2018), XFORMAL (Briakou et al., 2021b), InFormal (Krishna et al., 2022). We also include datasets crawled from the web (Zaidan and Callison-Burch, 2011; Ca\u00f1ete, 2019) and informal songs (Mu\u00f1oz, 2018).\nTable 2 presents the details of which words/group of words we use as short prompts, and the dataset sources of the formal/informal prompts for each language."
        },
        {
            "heading": "4.2 Generation Parameters",
            "text": "Decoding parameters are essential because they can directly affect a language model\u2019s output. For each language, we select a set of parameters to produce fluent text that can be appropriately evaluated. All selections were chosen to impact the formality\nlevel of models as little as possible. This subsection presents our list of generation parameters to reproduce our experiments.\nGlobal generation parameters We modified the decoding procedures to avoid very short sentences, code snippets, and outputs in other languages to produce an assessable amount of outputs with a significant length to be evaluated. The parameters are listed in Appendix A.\nRegarding the total number of evaluated outputs, we generated three sets for each evaluated model and language: 100 with short prompts, 100 with formal prompts, and 100 with informal prompts. That resulted in 1200 generated outputs for each language.\nLanguage-specific generation parameters Before generating the sequences for formality evaluation, we tweaked some logit parameters for each language. All modifications were done to obtain more fluent sequences and reduce incohesive outputs such as ones with generation repetitions or non-understandable text. This process was done with a varied set of prompts regardless of length and formality level.\nWe use sampling to obtain the generation outputs for both models. Three specific parameters were set for both models: We set top-k to 50, which truncates the number of tokens to sample from. We set a high top-p (Holtzman et al., 2019) to generate diverse sampled tokens by cumulative frequency, and a high temperature (Ackley et al., 1985), which does not skew the distribution towards high probability tokens. The specific details of the parameters to reproduce our experiments can be found in Appendix A."
        },
        {
            "heading": "4.3 Formality Evaluation",
            "text": "We assessed the formality of all generated outputs. To do so, one native/proficient speaker of each lan-\nguage classified all 1200 generated sequences individually. We opted for this evaluation procedure because, at the time of performing the experiments, to our knowledge, there were no multilingual formality classifier models that included Arabic, Bengali, English, Spanish, and French. To avoid possible biases, each generated output was annotated without looking at its prompt and in a randomized order. All annotations were done by the authors themselves who are native speakers of the languages.\nTo validate the quality of our annotation process, we also collect 3 ratings (collecting the annotations from 2 extra annotators) per sample for 50 samples and report the observed inter-annotator agreement in the Appendix in Table 7. We find the interannotator agreement to be above 59% for all the languages reported.\nThe classification categories for all languages are formal, informal, and incohesive. A sequence is classified as formal or informal according to the rules of each language described in section 2. The \"Incohesive\" label is only assigned under certain conditions, such as sequences written in other languages, non-understandable text (with e.g. many repeated symbol/blank tokens) that cannot be evaluated for formality level, or code snippets."
        },
        {
            "heading": "5 Results & Analysis",
            "text": "We start by analyzing the cohesiveness of each model. We then focus on the cohesive text for analyzing formality."
        },
        {
            "heading": "5.1 Cohesiveness of Generation",
            "text": "As seen in Table 3, BLOOM(7.1B) generates significantly more cohesive texts than XGLM(7.5B) for English, French, and Spanish with p-values under 5%, of a permutation-based statistical test.\nInterestingly, the results in Table 3 also show that a larger model does not necessarily lead to more cohesive generations. For example, BLOOM(3B)\nprompts. Light Gray indicates a bias toward formal generations and Dark Gray indicates a bias toward informal generations. Bolded values show that the corresponding model is significantly better (i.e. closer to 0) than the other model of the same size (based on a permutation-based test with p-value \u22645%).\ngenerates more cohesive texts than BLOOM(7.1B) for Bengali and English. XGLM(2.9B) also generates more cohesive texts than XGLM(7.5B) for English, French, and Spanish. Is worth noting that we are only evaluating cohesiveness in a binary way (cohesive vs. incohesive) and are not judging the quality of the predictions beyond that.\nBesides, the percentage of incohesive texts is noticeably higher for some languages than others for both BLOOM and XGLM. For example, the highest percentage of incohesive texts in the case of Bengali, English, and Spanish is less than or equal to 10%, while that percentage is higher in the case of Arabic and French."
        },
        {
            "heading": "5.2 Formality-Level Bias",
            "text": "Neutral prompts, given to an assumingly unbiased model, should lead to equal distributions of formal and informal generations with a difference close to zero between both generations. However, this is not the case here, as shown in Table 4. In the case of Bengali, we see that XGLM(2.9B), BLOOM(3B), and BLOOM(7.1B) are almost neutral with minor differences of -3% -6% and -3%, respectively, showing bias toward informal generations. On the other hand, we see XGLM(7.5B), surprisingly, showing significantly more bias toward formal generations than BLOOM(7.1B) with a difference of 33%. Upon qualitative analysis, we found that many of the generations of XGLM(7.5B) had Bengali religious Islamic text-like attributes that were considered formal during annotation, and the usage of hashtags or emojis was also less than the smaller model for neutral prompts.\nBLOOM, for French, continues to show less bias showing only a bias of 1% toward informal generations in the case of BLOOM(3B) and 14% towards formal generations in the case of BLOOM(7.1B). On the other hand, XGLM(2.9B) shows significantly more bias than BLOOM(3B) toward formal\ngenerations with a difference of 41%. For English, XGLM and BLOOM both show a small bias (in terms of percentages) towards different directions. XGLM(2.9B) and XGLM(7.5B) show bias towards formal generations by 14% and 8% respectively. However, BLOOM(3B) and BLOOM(7.1B) display bias towards informal generations by 6% and 13% respectively. After a careful review of the predictions, we find that French and English informal predictions of BLOOM are due to a large proportion of informal generated dialogs.\nBLOOM, this time for Spanish, shows extreme bias towards the formal generations with a difference of 79% for BLOOM(3B) and 67% for BLOOM(7.1B). On the other hand, XGLM exhibits less bias towards formal generations with a difference of 58% for XGLM(2.9B) and 45% for XGLM(7.5B). These values indicate that both models are influenced by formal sources. In fact, most of the generated sequences with short prompts have the style of news and Wikipedia articles.\nA biased distribution of outputs could be reasoned by the data the model was trained on. As stated in BLOOM (Scao et al., 2022), the biggest part of the corpus for Arabic was the Arabicfocused Masader repository (Alyafeai et al., 2021; Altaher et al., 2022), which is dominated by Modern Standard Arabic (MSA) that is considered formal (cf. section 2). This explains the extreme bias BLOOM(3B) and BLOOM(7.1B) show towards formal generations with a bias of 100%. XGLM(7.5B) similarly shows an extreme bias toward formal generations, but significantly less than BLOOM(7.1B) with a difference of 83%.\nIn terms of model size, we notice that XGLM(2.9B) shows more bias towards formal or informal generations than XGLM(7.5B) for all the languages except Bengali, which could indicate that the bigger the XGLM model\u2019s size, the less biased it is. On the other hand, this isn\u2019t the case for\nBLOOM as BLOOM(3B) is only expressing more bias for Bengali and Spanish, while BLOOM(7.1B) shows more bias for English and French.\nIn summary, the models show moderate bias for some languages such as English and Bengali, except for XGLM(7.5B) in the case of Bengali, while also showing extreme bias for other languages such as Arabic, French, and Spanish. This difference might be caused by the fact that every language is present in the data with a different percentage and is coming from different sources as shown in Table 8. Overall, it is noticeable that the bias is mostly toward formal generations for all the models and for all the languages."
        },
        {
            "heading": "5.3 Formality-Level Preservation",
            "text": "In this experiment, we measure how well the formality of a generation is the same as the formality level of the prompt (i.e. how well the model preserves the formality-level of the prompt). We find that the formality style of the prompts is preserved efficiently for some languages by some models while being almost ignored in some other cases.\nFor Arabic, as we show in Table 5, BLOOM(3B) and BLOOM(7.1B) preserve the formality style of 94.2% and 93.5%, respectively, of the samples when the given prompt is formal. We note that despite being highly biased toward formal text in Arabic (as seen in section 5.2), both models are able to preserve the style of informal prompts, at least 51.1% of the time.\nXGLM(2.9B), for Bengali, preserves the style of the informal prompts of significantly more samples than BLOOM(3B) with a percentage of 100%. BLOOM pays attention to the informal style of the prompts as well, unlike the case for Arabic, and preserves the style of 87.1% of the samples generated with BLOOM(3B) and 91.9% of the samples generated with BLOOM(7.1B).\nBoth BLOOM and XGLM, this time for English, do not preserve the formal style of the prompts for more than 34.4% of the samples for any model. However, they both preserve the informal style in at least 84.7% of the generated samples with BLOOM(7.1B) preserving significantly more samples than XGLM(7.5B). A similar trend follows for French with both BLOOM and XGLM unable to preserve the formal style for more than 32.0% of the samples in the case of XGLM(2.9B), BLOOM(3B) and BLOOM(7.1B). On the other hand, XGLM(7.5) preserves the formal style significantly better than BLOOM(7.1B) with a percentage of 54.0%. And again the informal style is being preserved better with, specifically, BLOOM(3B) which preserves the style better than XGLM(2.9B) with a percentage of 82%.\nThe formal and informal styles in Spanish are preserved consistently across the models to at least 77.8% of the samples with formal prompts and at least 75.8% with informal prompts with BLOOM(7.1B) preserving the style in significantly more samples than XGLM(7.5B).\nIn terms of model size, we notice that the size of the model is not an indicator of how well the model can preserve the formality style. For example, BLOOM(3B) preserves the formal style better than BLOOM(7.1B) for all languages except Spanish. In summary, we see that the informal style is mostly preserved well for most languages except with BLOOM for Arabic. The formal style, on the other hand, is mostly preserved well for all languages except English and French."
        },
        {
            "heading": "5.4 Typographic and Lexical Differences between Formal/Informal Generations",
            "text": "We report in Table 9 general statistics about the generated texts of each model and language by formality level. Results show that BLOOM gener-\nates about twice longer texts as XGLM. In terms of the average number of sentences per generation, BLOOM, when the generation is informal, generates more and shorter sentences than when the generation is formal. Also, informal generations tend to have emojis as expected, especially in the case of Bengali. Besides, informal generations tend to have more punctuation marks than formal ones. Finally, the results of the average number of new lines and the average number of \u201c-\u201d, which are used to signal dialogues, support what we mentioned earlier about BLOOM\u2019s tendency to generate conversational text."
        },
        {
            "heading": "6 Discussion",
            "text": "Formality bias when present in multilingual models, which are increasingly popular nowadays, can lead to undesirable outcomes. For example, using \"please\" is common among North American English native speakers in requests, even among close friends, while in Arabic, it could be considered awkward, if not rude, in conversations among close friends (Hovy and Yang, 2021). A usage example of language models is solving downstream tasks using prompting techniques for zero-shot learning, such as (Zhong et al., 2021)\u2019s work on questionanswering. Prompting has also been used with large language models for conversational chatbots such as ChatGPT (Ouyang et al., 2022). As prompting is becoming popular, we must understand that prompting a model that exhibits formality bias could be a barrier to getting the expected output. Furthermore, depending on the application, formality bias could even lead to sometimes unwanted misunderstandings (Hershcovich et al., 2022) and conflicts if the models, for example, are not able to generate text in the formality style of the users\u2019 expectations.\nControlling LLMs generations has been taken into consideration in recent work, such as in (Ouyang et al., 2022), where they fine-tune a language model (Brown et al., 2020a) intending to align the model with the intent of the users using reinforcement learning from human feedback (RLHF) (Christiano et al., 2017; Stiennon et al., 2020). Future work could analyze the impact of RLHF on the formality distributions present in language models. Furthermore, our work focused only on two pre-trained models with up to 7B parameters. The same analysis could be conducted for larger models such as GPT-3 and BLOOM(175B).\nFinally, the increase in the number of multilingual language models calls for more work on their biases."
        },
        {
            "heading": "7 Conclusion",
            "text": "In conclusion, we analyzed the formality level of the generations of two large-scale generative language models, XGLM and BLOOM, ranging from 2B parameters to 7B parameters. We first observed the cohesiveness of the predictions. We found that BLOOM(7.1B) predicts significantly more cohesive text than XGLM(7.5B) for English, French, and Spanish. Second, we showed that, across all five languages, both models tend to generate formal text when prompted neutrally. Finally, we found that the formality of the prompt highly impacts both models. In most cases, they generate the same style as the prompt, with slight differences between the models depending on the language. Our analysis is based on the annotations of 1,200 generations in Arabic, Bengali, English, French, and Spanish. We release them with this paper opening future avenues for modeling the formality of generative multilingual language models."
        },
        {
            "heading": "8 Limits",
            "text": "In this work, we experiment only with two models, XGLM and BLOOM. The limitation of computing resources tied us with models that have 7.5B parameters or less and the limitation of financial resources and manpower held us back from experimenting with more languages. Furthermore, the generated samples of each language were annotated by only one annotator, except for English. To validate our methodology we asked two extra native speakers of each language to annotate 50 samples per language. We share the observed inter-annotator agreement values in Table 7 (Gwet, 2014). We find the observed agreement to be above 59% for all the reported languages, supporting the quality of our annotation process. Finally, we note that despite the aforementioned limitations, the methodology used in this study can be applied to any generative system and language."
        },
        {
            "heading": "9 Acknowledgment",
            "text": "We thank the Fatima Fellowship5 and Hugging Face for organizing and sponsoring the Fatima Research Fellowship program.\n5cf. https://www.fatimafellowship.com/"
        },
        {
            "heading": "A Generation parameters",
            "text": "We list here the decoding parameters for both models:"
        },
        {
            "heading": "B Descriptive statistics of the generations",
            "text": "General statistics of the generations are in Table 9 reported per language for each model and generation label pair. The table contains the following statistics: the average length of the generation, the average number of sentences in a generation, the average length of the sentences, the average number of emojis per generation, the average number of punctuation marks per generation, the average number of new lines per generation, and finally, the average number of the dialogue mark/dash (-) per generation.\nC XGLM and BLOOM training corpora\nWe show in Table 8 details of the languages used in our analysis in the training corpus of BLOOM and XGLM."
        },
        {
            "heading": "D Formality Distribution",
            "text": "We visualize the annotated data for each language to help in seeing an overview of all the results. Each language is represented by a plot, see Figures 1, 2, 3, 4, and 5, with 12 bars with 3 bars corresponding to each model representing the 3 prompts types: formal informal, and neutral. Each bar in the plot represents 100 texts generated with the corresponding model when prompted with the corresponding prompt type. The colors in each bar represent the 3 possible annotations: formal, informal, and incohesive.\n0.0 0.2 0.4 0.6 0.8 1.0\nBLOOM(7.1B)\nBLOOM(3B)\nXGLM(7.5B)\nXGLM(2.9B)\nArabic Formal Informal Incohesive Formal Prompt Informal Prompt Neutral Prompt\nFigure 1: Plot of the distribution of the generations for Arabic, for each prompt type, according to their labeled categories: Formal, Informal, and Incohesive. Each bar in the plot represents 100 generations.\n0.0 0.2 0.4 0.6 0.8 1.0\nBLOOM(7.1B)\nBLOOM(3B)\nXGLM(7.5B)\nXGLM(2.9B)\nBengali Formal Informal Incohesive Formal Prompt Informal Prompt Neutral Prompt\nFigure 2: Plot of the distribution of the generations for Bengali, for each prompt type, according to their labeled categories: Formal, Informal, and Incohesive. Each bar in the plot represents 100 generations.\n0.0 0.2 0.4 0.6 0.8 1.0\nBLOOM(7.1B)\nBLOOM(3B)\nXGLM(7.5B)\nXGLM(2.9B)\nEnglish Formal Informal Incohesive Formal Prompt Informal Prompt Neutral Prompt\nFigure 3: Plot of the distribution of the generations for English, for each prompt type, according to their labeled categories: Formal, Informal, and Incohesive. Each bar in the plot represents 100 generations.\n0.0 0.2 0.4 0.6 0.8 1.0\nBLOOM(7.1B)\nBLOOM(3B)\nXGLM(7.5B)\nXGLM(2.9B)\nFrench Formal Informal Incohesive Formal Prompt Informal Prompt Neutral Prompt\nFigure 4: Plot of the distribution of the generations for French, for each prompt type, according to their labeled categories: Formal, Informal, and Incohesive. Each bar in the plot represents 100 generations.\n0.0 0.2 0.4 0.6 0.8 1.0\nBLOOM(7.1B)\nBLOOM(3B)\nXGLM(7.5B)\nXGLM(2.9B)\nSpanish Formal Informal Incohesive Formal Prompt Informal Prompt Neutral Prompt\nFigure 5: Plot of the distribution of the generations for Spanish, for each prompt type, according to their labeled categories: Formal, Informal, and Incohesive. Each bar in the plot represents 100 generations."
        }
    ],
    "title": "In What Languages are Generative Language Models the Most Formal? Analyzing Formality Distribution across Languages",
    "year": 2023
}