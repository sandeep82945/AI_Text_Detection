{
    "abstractText": "The most meaningful connections between people are often fostered through expression of shared vulnerability and emotional experiences in personal narratives. We introduce a new task of identifying similarity in personal stories based on empathic resonance, i.e., the extent to which two people empathize with each others\u2019 experiences, as opposed to raw semantic or lexical similarity, as has predominantly been studied in NLP. Using insights from social psychology, we craft a framework that operationalizes empathic similarity in terms of three key features of stories: main events, emotional trajectories, and overall morals or takeaways. We create EMPATHICSTORIES, a dataset of 1,500 personal stories annotated with our empathic similarity features, and 2,000 pairs of stories annotated with empathic similarity scores. Using our dataset, we finetune a model to compute empathic similarity of story pairs, and show that this outperforms semantic similarity models on automated correlation and retrieval metrics. Through a user study with 150 participants, we also assess the effect our model has on retrieving stories that users empathize with, compared to naive semantic similarity-based retrieval, and find that participants empathized significantly more with stories retrieved by our model. Our work has strong implications for the use of empathy-aware models to foster human connection and empathy between people.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jocelyn Shen"
        },
        {
            "affiliations": [],
            "name": "Maarten Sap"
        },
        {
            "affiliations": [],
            "name": "Pedro Colon-Hernandez"
        },
        {
            "affiliations": [],
            "name": "Hae Won Park"
        },
        {
            "affiliations": [],
            "name": "Cynthia Breazeal"
        }
    ],
    "id": "SP:29be231fed20de55dc5cf960a64d66800539901b",
    "references": [
        {
            "authors": [
                "Herv\u00e9 Abdi."
            ],
            "title": "The kendall rank correlation coefficient",
            "venue": "Encyclopedia of Measurement and Statistics. Sage, Thousand Oaks, CA, pages 508\u2013510.",
            "year": 2007
        },
        {
            "authors": [
                "Mary E. Andrews",
                "Bradley D. Mattan",
                "Keana Richards",
                "Samantha L. Moore-Berg",
                "Emily B. Falk."
            ],
            "title": "Using first-person narratives about healthcare workers and people who are incarcerated to motivate helping behaviors during the COVID-19 pandemic",
            "venue": "So-",
            "year": 2022
        },
        {
            "authors": [
                "P. Matthijs Bal",
                "Martijn Veltkamp."
            ],
            "title": "How Does Fiction Reading Influence Empathy? An Experimental Investigation on the Role of Emotional Transportation",
            "venue": "PLOS ONE, 8(1):e55341.",
            "year": 2013
        },
        {
            "authors": [
                "Satanjeev Banerjee",
                "Alon Lavie."
            ],
            "title": "Meteor: An automatic metric for mt evaluation with improved correlation with human judgments",
            "venue": "Proceedings",
            "year": 2005
        },
        {
            "authors": [
                "Jiajun Bao",
                "Junjie Wu",
                "Yiming Zhang",
                "Eshwar Chandrasekharan",
                "David Jurgens."
            ],
            "title": "Conversations Gone Alright: Quantifying and Predicting Prosocial Outcomes in Online Conversations",
            "venue": "Proceedings of the Web Conference 2021, pages",
            "year": 2021
        },
        {
            "authors": [
                "Clara Berridge",
                "Yuanjin Zhou",
                "Julie M. Robillard",
                "Jeffrey Kaye."
            ],
            "title": "Companion robots to mitigate loneliness among older adults: Perceptions of benefit and possible deception",
            "venue": "Frontiers in Psychology, 14:1106633.",
            "year": 2023
        },
        {
            "authors": [
                "Antoine Bosselut",
                "Hannah Rashkin",
                "Maarten Sap",
                "Chaitanya Malaviya",
                "Asli Celikyilmaz",
                "Yejin Choi"
            ],
            "title": "COMET: Commonsense Transformers for Automatic Knowledge Graph Construction",
            "year": 2019
        },
        {
            "authors": [
                "Hana Boukricha",
                "Ipke Wachsmuth",
                "Maria Nella Carminati",
                "Pia Knoeferle."
            ],
            "title": "A Computational Model of Empathy: Empirical Evaluation",
            "venue": "2013 Humaine Association Conference on Affective Computing and Intelligent Interaction, pages 1\u20136,",
            "year": 2013
        },
        {
            "authors": [
                "Guilherme Brockington",
                "Ana Paula Gomes Moreira",
                "Maria Stephani Buso",
                "S\u00e9rgio Gomes da Silva",
                "Edgar Altszyler",
                "Ronald Fischer",
                "Jorge Moll"
            ],
            "title": "Storytelling increases oxytocin and positive emotions and decreases cortisol and pain in hospitalized",
            "year": 2021
        },
        {
            "authors": [
                "Amodei."
            ],
            "title": "Language Models are Few-Shot Learners",
            "venue": "arXiv:2005.14165 [cs].",
            "year": 2020
        },
        {
            "authors": [
                "Susanne Buecker",
                "Marcus Mund",
                "Sandy Chwastek",
                "Melina Sostmann",
                "Maike Luhmann."
            ],
            "title": "Is loneliness in emerging adults increasing over time? A preregistered cross-temporal meta-analysis and systematic review",
            "venue": "Psychological Bulletin, 147:787\u2013",
            "year": 2021
        },
        {
            "authors": [
                "Rijul Chaturvedi",
                "Sanjeev Verma",
                "Ronnie Das",
                "Yogesh K. Dwivedi."
            ],
            "title": "Social companionship with artificial intelligence: Recent trends and future avenues",
            "venue": "Technological Forecasting and Social Change, 193:122634.",
            "year": 2023
        },
        {
            "authors": [
                "Snigdha Chaturvedi",
                "Shashank Srivastava",
                "Dan Roth."
            ],
            "title": "Where Have I Heard This Story Before? Identifying Narrative Similarity in Movie Remakes",
            "venue": "Proceedings of the 2018 Conference of",
            "year": 2018
        },
        {
            "authors": [
                "Eun Cho",
                "Soohyun Jeon."
            ],
            "title": "The role of empathy and psychological need satisfaction in pharmacy students\u2019 burnout and well-being",
            "venue": "BMC Medical Education, 19(1):43.",
            "year": 2019
        },
        {
            "authors": [
                "Jay S. Coke",
                "C. Daniel Batson",
                "Katherine McDavis."
            ],
            "title": "Empathic mediation of helping: A two-stage model",
            "venue": "Journal of Personality and Social Psychology, 36(7):752\u2013766.",
            "year": 1978
        },
        {
            "authors": [
                "Marc Damashek."
            ],
            "title": "Gauging Similarity with nGrams: Language-Independent Categorization of Text",
            "venue": "Science, 267(5199):843\u2013848. Publisher: American Association for the Advancement of Science.",
            "year": 1995
        },
        {
            "authors": [
                "Scott Deerwester",
                "Susan T. Dumais",
                "George W. Furnas",
                "Thomas K. Landauer",
                "Richard Harshman."
            ],
            "title": "Indexing by latent semantic analysis",
            "venue": "Journal of the American Society for Information Science, 41(6):391\u2013407.",
            "year": 1990
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "venue": "arXiv:1810.04805 [cs]. ArXiv: 1810.04805.",
            "year": 2019
        },
        {
            "authors": [
                "Karthik Dinakar",
                "Birago Jones",
                "Henry Lieberman",
                "Rosalind Picard",
                "Carolyn Rose",
                "Matthew Thoman",
                "Roi Reichart."
            ],
            "title": "You Too?! Mixed-Initiative LDA Story Matching to Help Teens in Distress",
            "venue": "Proceedings of the International AAAI Conference on",
            "year": 2012
        },
        {
            "authors": [
                "Sarah Fabi",
                "Lydia Anna Weber",
                "Hartmut Leuthold."
            ],
            "title": "Empathic concern and personal distress depend on situational but not dispositional factors",
            "venue": "PLoS ONE, 14(11):e0225102\u2013e0225102.",
            "year": 2019
        },
        {
            "authors": [
                "Fabrizio Gilardi",
                "Meysam Alizadeh",
                "Ma\u00ebl Kubli."
            ],
            "title": "ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks",
            "venue": "ArXiv:2303.15056 [cs].",
            "year": 2023
        },
        {
            "authors": [
                "Vasu Goel",
                "Dhruv Sahnan",
                "Subhabrata Dutta",
                "Anil Bandhakavi",
                "Tanmoy Chakraborty."
            ],
            "title": "Hatemongers ride on echo chambers to escalate hate speech diffusion",
            "venue": "PNAS Nexus, 2(3):pgad041.",
            "year": 2023
        },
        {
            "authors": [
                "Melanie C. Green",
                "Timothy C. Brock."
            ],
            "title": "The role of transportation in the persuasiveness of public narratives",
            "venue": "Journal of Personality and Social Psychology, 79(5):701\u2013721.",
            "year": 2000
        },
        {
            "authors": [
                "Maarten Grootendorst"
            ],
            "title": "Keybert: Minimal keyword extraction with bert",
            "year": 2020
        },
        {
            "authors": [
                "Laura Hanu",
                "Unitary team."
            ],
            "title": "Detoxify",
            "venue": "Github. https://github.com/unitaryai/detoxify.",
            "year": 2020
        },
        {
            "authors": [
                "Sara D. Hodges",
                "Kristi J. Kiel",
                "Adam D.I. Kramer",
                "Darya Veach",
                "B. Renee Villanueva."
            ],
            "title": "Giving Birth to Empathy: The Effects of Similar Experience on Empathic Accuracy, Empathic Concern, and Perceived Empathy",
            "venue": "Personality and Social Psychol-",
            "year": 2010
        },
        {
            "authors": [
                "Christopher J. Honey",
                "Christopher R. Thompson",
                "Yulia Lerner",
                "Uri Hasson."
            ],
            "title": "Not Lost in Translation: Neural Responses Shared Across Languages",
            "venue": "The Journal of Neuroscience, 32(44):15277\u201315283.",
            "year": 2012
        },
        {
            "authors": [
                "Jena D. Hwang",
                "Chandra Bhagavatula",
                "Ronan Le Bras",
                "Jeff Da",
                "Keisuke Sakaguchi",
                "Antoine Bosselut",
                "Yejin Choi"
            ],
            "title": "On Symbolic and Neural Commonsense Knowledge Graphs",
            "venue": "COMET-ATOMIC",
            "year": 2021
        },
        {
            "authors": [
                "Hyunwoo Kim",
                "Youngjae Yu",
                "Liwei Jiang",
                "Ximing Lu",
                "Daniel Khashabi",
                "Gunhee Kim",
                "Yejin Choi",
                "Maarten Sap"
            ],
            "title": "ProsocialDialog: A Prosocial Backbone for Conversational Agents",
            "year": 2022
        },
        {
            "authors": [
                "Hannah Rose Kirk",
                "Bertie Vidgen",
                "Paul R\u00f6ttger",
                "Scott A. Hale."
            ],
            "title": "Personalisation within bounds: A risk taxonomy and policy framework for the alignment of large language models with personalised feedback",
            "venue": "ArXiv:2303.05453 [cs].",
            "year": 2023
        },
        {
            "authors": [
                "Sara Konrath."
            ],
            "title": "The Empathy Paradox: Increasing Disconnection in the Age of Increasing Connection",
            "venue": "https://www.igiglobal.com/chapter/content/www.igiglobal.com/chapter/content/70356.",
            "year": 2013
        },
        {
            "authors": [
                "Sara H. Konrath",
                "Edward H. O\u2019Brien",
                "Courtney Hsing"
            ],
            "title": "Changes in Dispositional Empathy in American College Students Over Time: A MetaAnalysis",
            "venue": "Personality and Social Psychology",
            "year": 2011
        },
        {
            "authors": [
                "Dennis Krebs."
            ],
            "title": "Empathy and altruism",
            "venue": "Journal of Personality and Social Psychology, 32(6):1134.",
            "year": 1976
        },
        {
            "authors": [
                "William Labov",
                "Joshua Waletzky."
            ],
            "title": "Narrative analysis: Oral versions of personal experience",
            "venue": "Journal of Narrative & Life History, 7(1-4):3\u201338.",
            "year": 1997
        },
        {
            "authors": [
                "Allison Lahnala",
                "Charles Welch",
                "Lucie Flek."
            ],
            "title": "CAISA at WASSA 2022: Adapter-Tuning for Empathy Prediction",
            "venue": "Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis, pages 280\u2013285,",
            "year": 2022
        },
        {
            "authors": [
                "Allison Lahnala",
                "Charles Welch",
                "David Jurgens",
                "Lucie Flek."
            ],
            "title": "A Critical Reflection and Forward Perspective on Empathy and Natural Language Processing",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022, pages 2139\u2013",
            "year": 2022
        },
        {
            "authors": [
                "Thomas K. Landauer",
                "Susan T. Dumais."
            ],
            "title": "A solution to Plato\u2019s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge",
            "venue": "Psychological Review, 104:211\u2013 240. Place: US Publisher: American Psychological",
            "year": 1997
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdelrahman Mohamed",
                "Omer Levy",
                "Ves Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "BART: Denoising Sequence-to-Sequence Pretraining for Natural Language Generation, Transla",
            "year": 2019
        },
        {
            "authors": [
                "Lucas Lima",
                "Julio C.S. Reis",
                "Philipe Melo",
                "Fabricio Murai",
                "Leandro Araujo",
                "Pantelis Vikatos",
                "Fabricio Benevenuto."
            ],
            "title": "Inside the Right-Leaning Echo Chambers: Characterizing Gab, an Unmoderated Social System",
            "venue": "2018 IEEE/ACM Interna-",
            "year": 2018
        },
        {
            "authors": [
                "Chin-Yew Lin."
            ],
            "title": "ROUGE: A Package for Automatic Evaluation of Summaries",
            "venue": "Text Summarization Branches Out, pages 74\u201381, Barcelona, Spain. Association for Computational Linguistics.",
            "year": 2004
        },
        {
            "authors": [
                "Yung-Shen Lin",
                "Jung-Yi Jiang",
                "Shie-Jue Lee."
            ],
            "title": "A Similarity Measure for Text Classification and Clustering",
            "venue": "IEEE Transactions on Knowledge and Data Engineering, 26(7):1575\u20131590.",
            "year": 2014
        },
        {
            "authors": [
                "Dan P McAdams."
            ],
            "title": "The Life Story Interview \u2013 II",
            "venue": "page 5.",
            "year": 2007
        },
        {
            "authors": [
                "Sylvia A. Morelli",
                "Matthew D. Lieberman",
                "Jamil Zaki."
            ],
            "title": "The Emerging Study of Positive Empathy",
            "venue": "Social and Personality Psychology Compass, 9(2):57\u201368.",
            "year": 2015
        },
        {
            "authors": [
                "Sylvia A. Morelli",
                "Desmond C. Ong",
                "Rucha Makati",
                "Matthew O. Jackson",
                "Jamil Zaki."
            ],
            "title": "Empathy and well-being correlate with centrality in different social networks",
            "venue": "Proceedings of the National Academy of Sciences, 114(37):9843\u20139847.",
            "year": 2017
        },
        {
            "authors": [
                "Nasrin Mostafazadeh",
                "Aditya Kalyanpur",
                "Lori Moon",
                "David Buchanan",
                "Lauren Berkowitz",
                "Or Biran",
                "Jennifer Chu-Carroll."
            ],
            "title": "GLUCOSE: GeneraLized and COntextualized Story Explanations",
            "venue": "Proceedings of the 2020 Conference on Empirical",
            "year": 2020
        },
        {
            "authors": [
                "Dong Nguyen",
                "Dolf Trieschnigg",
                "Mari\u00ebt Theune."
            ],
            "title": "Using Crowdsourcing to Investigate Perception of Narrative Similarity",
            "venue": "Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, CIKM",
            "year": 2014
        },
        {
            "authors": [
                "Oren Etzioni"
            ],
            "title": "Three rules of Artificial Intelligence",
            "year": 2018
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a Method for Automatic Evaluation of Machine Translation",
            "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311\u2013318, Philadelphia,",
            "year": 2002
        },
        {
            "authors": [
                "Hannah Rashkin",
                "Antoine Bosselut",
                "Maarten Sap",
                "Kevin Knight",
                "Yejin Choi."
            ],
            "title": "Modeling Naive Psychology of Characters in Simple Commonsense Stories",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational",
            "year": 2018
        },
        {
            "authors": [
                "Hannah Rashkin",
                "Maarten Sap",
                "Emily Allaway",
                "Noah A. Smith",
                "Yejin Choi"
            ],
            "title": "Event2Mind: Commonsense Inference on Events, Intents, and Reactions",
            "year": 2019
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych"
            ],
            "title": "SentenceBERT: Sentence Embeddings using Siamese BERTNetworks",
            "year": 2019
        },
        {
            "authors": [
                "Mahnaz Roshanaei",
                "Christopher Tran",
                "Sylvia Morelli",
                "Cornelia Caragea",
                "Elena Zheleva."
            ],
            "title": "Paths to Empathy: Heterogeneous Effects of Reading Personal Stories Online",
            "venue": "2019 IEEE International Conference on Data Science and Advanced Analyt-",
            "year": 2019
        },
        {
            "authors": [
                "Paul Rottger",
                "Bertie Vidgen",
                "Dirk Hovy",
                "Janet Pierrehumbert."
            ],
            "title": "Two Contrasting Data Annotation Paradigms for Subjective NLP Tasks",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computa-",
            "year": 2022
        },
        {
            "authors": [
                "Mary Fabiola Sagayaraj",
                "Ignisha Rajathi George",
                "R. Vedhapriyavadhana",
                "L.R. Priya."
            ],
            "title": "Artificial Intelligence to Combat the Sting of the Pandemic on the Psychological Realms of Human Brain",
            "venue": "SN Computer Science, 3(3):182.",
            "year": 2022
        },
        {
            "authors": [
                "Belen Saldias",
                "Deb Roy"
            ],
            "title": "Exploring aspects of similarity between spoken personal narratives by disentangling them into narrative clause types",
            "year": 2020
        },
        {
            "authors": [
                "Gerard Salton",
                "Amit Singhal",
                "Mandar Mitra",
                "Chris Buckley."
            ],
            "title": "Automatic text structuring and summarization",
            "venue": "Information Processing & Management, 33(2):193\u2013207.",
            "year": 1997
        },
        {
            "authors": [
                "Maarten Sap",
                "Dallas Card",
                "Saadia Gabriel",
                "Yejin Choi",
                "Noah A. Smith."
            ],
            "title": "The Risk of Racial Bias in Hate Speech Detection",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1668\u20131678, Florence,",
            "year": 2019
        },
        {
            "authors": [
                "Maarten Sap",
                "Eric Horvitz",
                "Yejin Choi",
                "Noah A. Smith",
                "James Pennebaker."
            ],
            "title": "Recollection versus Imagination: Exploring Human Memory and Cognition via Neural Language Models",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for",
            "year": 2020
        },
        {
            "authors": [
                "Maarten Sap",
                "Ronan Le Bras",
                "Emily Allaway",
                "Chandra Bhagavatula",
                "Nicholas Lourie",
                "Hannah Rashkin",
                "Brendan Roof",
                "Noah A. Smith",
                "Yejin Choi."
            ],
            "title": "ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning",
            "venue": "Proceedings of the",
            "year": 2019
        },
        {
            "authors": [
                "Maarten Sap",
                "Ronan LeBras",
                "Daniel Fried",
                "Yejin Choi"
            ],
            "title": "Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs",
            "year": 2022
        },
        {
            "authors": [
                "Maarten Sap",
                "Marcella Cindy Prasettio",
                "Ari Holtzman",
                "Hannah Rashkin",
                "Yejin Choi."
            ],
            "title": "Connotation Frames of Power and Agency in Modern Films",
            "venue": "page 6.",
            "year": 2017
        },
        {
            "authors": [
                "Maarten Sap",
                "Hannah Rashkin",
                "Derek Chen",
                "Ronan LeBras",
                "Yejin Choi"
            ],
            "title": "2019c. SocialIQA: Commonsense Reasoning about Social Interactions",
            "year": 2019
        },
        {
            "authors": [
                "Patrick Schober",
                "Christa Boer",
                "Lothar A Schwarte."
            ],
            "title": "Correlation coefficients: appropriate use and interpretation",
            "venue": "Anesthesia & analgesia, 126(5):1763\u20131768.",
            "year": 2018
        },
        {
            "authors": [
                "Ashish Sharma",
                "Adam S. Miner",
                "David C. Atkins",
                "Tim Althoff"
            ],
            "title": "A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support",
            "year": 2020
        },
        {
            "authors": [
                "Lijiang Shen."
            ],
            "title": "On a Scale of State Empathy During Message Processing",
            "venue": "Western Journal of Communication, 74(5):504\u2013524.",
            "year": 2010
        },
        {
            "authors": [
                "Seema Vinayak",
                "Jotika Judge."
            ],
            "title": "Resilience and Empathy as Predictors of Psychological Wellbeing among Adolescents",
            "venue": "International Journal of Health Sciences, (4):10.",
            "year": 2018
        },
        {
            "authors": [
                "Kiran Vodrahalli",
                "Po-Hsuan Chen",
                "Yingyu Liang",
                "Christopher Baldassano",
                "Janice Chen",
                "Esther Yong",
                "Christopher Honey",
                "Uri Hasson",
                "Peter Ramadge",
                "Kenneth A. Norman",
                "Sanjeev Arora"
            ],
            "title": "Mapping between fMRI responses to movies",
            "year": 2018
        },
        {
            "authors": [
                "Caren M. Walker",
                "Tania Lombrozo."
            ],
            "title": "Explaining the moral of the story",
            "venue": "Cognition, 167:266\u2013281.",
            "year": 2017
        },
        {
            "authors": [
                "Zhilin Wang",
                "Anna Jafarpour",
                "Maarten Sap."
            ],
            "title": "Uncovering Surprising Event Boundaries in Narratives",
            "venue": "page 12.",
            "year": 2022
        },
        {
            "authors": [
                "Peter West",
                "Chandra Bhagavatula",
                "Jack Hessel",
                "Jena D. Hwang",
                "Liwei Jiang",
                "Ronan Le Bras",
                "Ximing Lu",
                "Sean Welleck",
                "Yejin Choi"
            ],
            "title": "Symbolic Knowledge Distillation: from General Language Models to Commonsense Models",
            "year": 2022
        },
        {
            "authors": [
                "Joshua D. Wondra",
                "Phoebe C. Ellsworth."
            ],
            "title": "An appraisal theory of empathy and other vicarious emotional experiences",
            "venue": "Psychological Review, 122(3):411\u2013428.",
            "year": 2015
        },
        {
            "authors": [
                "Kevin Wright."
            ],
            "title": "Motives for communication within on-line support groups and antecedents for interpersonal use",
            "venue": "Communication Research Reports, 19(1):89\u201398.",
            "year": 2002
        },
        {
            "authors": [
                "Tianyi Zhang",
                "Varsha Kishore",
                "Felix Wu",
                "Kilian Q. Weinberger",
                "Yoav Artzi"
            ],
            "title": "BERTScore: Evaluating Text Generation with BERT",
            "year": 2020
        },
        {
            "authors": [
                "Naitian Zhou",
                "David Jurgens."
            ],
            "title": "Condolence and Empathy in Online Communities",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 609\u2013626, Online. Association for Computational",
            "year": 2020
        },
        {
            "authors": [
                "Zhang"
            ],
            "title": "2020), taking the human-written free-text annotations as gold references",
            "year": 2020
        },
        {
            "authors": [
                "selections (Sap"
            ],
            "title": "2019a), we err on the side of removing any stories",
            "year": 2019
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Through personal experience sharing, humans are able to feel the sting of another person\u2019s pain and the warmth of another person\u2019s joy. This process of empathy is foundational in the ability to connect with others, develop emotional resilience, and take prosocial actions in the world (Coke et al., 1978; Morelli et al., 2015; Vinayak and Judge, 2018; Cho and Jeon, 2019). Today, there is more visibility into the lives of others than ever before, yet loneliness\nand apathy are widespread (Buecker et al., 2021; Konrath, 2013; Konrath et al., 2011). While these challenges cannot be solved with technology alone, AI systems can be developed to bolster emotional support, empathy, and truly meaningful connections through fostering personal experience sharing (Sagayaraj et al., 2022; Chaturvedi et al., 2023; Berridge et al., 2023). In order to do so, these systems must be able to reason about complex social and emotional phenomena between people.\nIn this work, we introduce the task of modeling empathic similarity, which we define as people\u2019s perceived similarity and resonance to others\u2019 experiences. For example, in Figure 1, empathic similarity aims to capture that Narrator A, who feels lonely in their small town, is likely to empathize with Narrator B, who is feeling isolated at their new job. Crucially, empathic similarity differs from traditional notions of textual similarity that have been the main focus of NLP work (e.g., semantic similarity; Reimers and Gurevych, 2019); Narrator A will likely not empathize with Narrator C, despite both stories having higher semantic similarity.\nWe operationalize empathic similarity around alignment in three features of a personal story\n(highlighted in Figure 1): its main event, its emotional reaction, and its overall moral or story takeaway (Hodges et al., 2010; Morelli et al., 2017; Krebs, 1976; Wondra and Ellsworth, 2015; Bal and Veltkamp, 2013; Walker and Lombrozo, 2017; Labov and Waletzky, 1997), as motivated by social psychology and narratology literature. From our definition, empathic similarity arises from the interplay of the main events, emotions, and morals in story, where some components or all components must be similar in order for two narrators to resonate with one another. For example, Narrator A and B both experience loneliness, even though their actual situations are different (living in a small town versus working at a company).\nTo enable machines to model empathic similarity, we introduce EMPATHICSTORIES,1 a corpus of 1,500 personal stories, with crowdsourced annontations of the free-text summaries of the main event, emotion, and moral of the stories, as well as an empathic similarity score between 2,000 pairs of stories. We find that finetuning on our paired stories dataset to predict empathic similarity improves performance on automatic metrics as compared to off-the-shelf semantic similarity methods.\nWhile automatic evaluation a valuable signal of model quality, it is crucial to showcase the realworld impact of our task on improving empathy towards people\u2019s stories. As such, we conducted a full user study with 150 participants who wrote their own personal journal entries and were presented stories retrieved by our model (and by a semantic similarity baseline). Our results show that users empathize significantly more with stories retrieved by our finetuned empathic similarity model compared to those from a semantic similarity baseline (SBERT; Reimers and Gurevych, 2019). Our findings highlight the applicability of our framework, dataset, and model towards fostering meaningful human-human connections by enabling NLP systems to reason about complex interpersonal social-emotional phenomena."
        },
        {
            "heading": "2 Related Work",
            "text": "Document similarity is a well-defined task in NLP (Salton et al., 1997; Damashek, 1995; Deerwester et al., 1990; Landauer and Dumais, 1997), but few have applied this work to matching personal\n1We publicly release our dataset, annotation procedure, model, and user study at https://github.com/ mitmedialab/empathic-stories\nnarratives based on shared emotional experiences (Chaturvedi et al., 2018; Lin et al., 2014). One study used Latent Dirichlet Allocation (LDA) to cluster cyberbullying stories and match these stories based on similarity in theme (Dinakar et al., 2012), but discovered that only 58.3% found the matched story to be helpful if provided to the narrator of the original story.\nOther work has explored ways to bridge the features of a story and human-perceived similarity of stories (Nguyen et al., 2014). Saldias and Roy (2020) found that people use Labov\u2019s action (series of events) and evaluation (narrator\u2019s needs and desires) clauses to identify similarity in personal narratives (Labov and Waletzky, 1997). Their findings support our decision to focus on modeling events, emotions, and morals within stories.\nMost relevant to our work are recent advances in social and emotional commonsense reasoning using using language models. Specifically, prior methods have used finetuning of language models such as BERT (Devlin et al., 2019; Reimers and Gurevych, 2019) and GPT-2 (Radford et al.) to model events and the emotional reactions caused by everyday events (Rashkin et al., 2019, 2018; Sap et al., 2019b; Bosselut et al., 2019; Wang et al., 2022; West et al., 2022; Mostafazadeh et al., 2020) as well as predicting empathy, condolence, or prosocial outcomes (Lahnala et al., 2022a; Kumano et al.; Boukricha et al., 2013; Zhou and Jurgens, 2020; Bao et al., 2021). Understanding the emotional reactions elicited by events is a challenging task for many NLP systems, as it requires commonsense knowledge and extrapolation of meanings beyond the text alone. Prior works use commonsense knowledge graphs to infer and automatically generate commonsense knowledge of emotional reactions and reasoning about social interactions (Sap et al., 2019c,b; Bosselut et al., 2019; Hwang et al., 2021). However, there are still many under-explored challenges in developing systems that have social intelligence and the ability to infer states between people (Sap et al., 2022).\nIn contrast to previous works, we present a task for reasoning between pairs of stories, beyond predicting social commonsense features of texts alone. Our work builds on top of prior work by developing a framework around empathic resonance in personal narratives in addition to assessing the human effect of AI-retrieved stories on empathic response beyond automatic metrics. Unlike previous\nworks, our human evaluation is a full user study to see how the model performs given a story that the users told themselves, which is much more aligned with real-world impact."
        },
        {
            "heading": "3 Empathic Aspects of Personal Stories",
            "text": "Modeling empathic similarity of stories requires reasoning beyond their simple lexical similarities (see Figure 1). In this section, we briefly discuss how social science scholars have conceptualized empathy (\u00a73.1) and draw on empathy definitions relevant for the NLP domain (Lahnala et al., 2022b). Then, we introduce our framework for modeling empathic similarity of stories and its three defining features (\u00a73.2)."
        },
        {
            "heading": "3.1 Background on Empathy and Stories",
            "text": "Empathy, broadly defined as the ability to feel or understand what a person is feeling, plays a crucial role in human-human connections. Many prior works in social psychology and narrative psychology find that the perceived similarity of a personal experience has effects on empathy (Roshanaei et al., 2019; Hodges et al., 2010; Wright, 2002; Morelli et al., 2017; Krebs, 1976; Wondra and Ellsworth, 2015). For example, Hodges et al. (2010) found that women who shared similar life events to speakers expressed greater empathic concern and reported greater understanding of the speaker.\nAs with these prior works, our work uses sharing of personal stories as a means to expressing similarity in shared experiences. Personal storytelling as a medium itself has the ability to reduce stress, shift attitudes, elicit empathy, and connect others (Green and Brock, 2000; Andrews et al., 2022; Brockington et al., 2021). In fact, some research has shown that when telling a story to a second listener, speakers and listeners couple their brain activity, indicating the neurological underpinnings of these interpersonal communications (Honey et al., 2012; Vodrahalli et al., 2018)."
        },
        {
            "heading": "3.2 Empathic Similarity in Personal Stories",
            "text": "We define empathic similarity as a measure of how much the narrators of a pair of stories would empathize with one another. While there are many ways to express empathy, we focus specifically on situational empathy, which is empathy that occurs in response to a social context, conveyed through text-based personal narratives (Fabi et al., 2019).\nWe operationalize an empathic similarity framework grounded in research from social and narrative psychology discussed in \u00a73.1. Our framework differs from prior work (Sharma et al., 2020) in that it is expanded to the relationship between two people\u2019s experiences, rather than how empathetically someone responds, and focuses on learning a continuous similarity signal as opposed to detecting the presence of empathy. This distinction is important, as someone may be able to express condolences to a personal experience, but not necessarily relate to the experience itself. The core features of empathic similarity we identify are explained below, and we show how these features contribute to empathic similarity in Appendix A. (1) Main event. Prior work demonstrates that people empathize more with experiences that are similar to their own (Hodges et al., 2010; Morelli et al., 2017; Krebs, 1976). We formalize this as the main event of the story expressed in a short phrase (e.g. \u201cliving in a small town\u201d). (2) Emotional Reaction. Although two people may relate over an experience, they may differ in how they emotionally respond to the experience (e.g. \u201coverwhelmed with fear of being all alone\u201d vs \u201cloneliness of not having a real connection\u201d). Prior work shows that people have a harder time empathizing with others if they felt that the emotional response to an event was inappropriate (Wondra and Ellsworth, 2015). (3) Moral. Readers are able to abstract a higherlevel meaning from the story, often referred to as the moral of the story (Walker and Lombrozo, 2017) (e.g. \u201cthe importance of having people around\u201d). In studying fictional narratives, prior work has found that people can empathize with the takeaway of a story, despite its fictional nature (Bal and Veltkamp, 2013)."
        },
        {
            "heading": "4 EMPATHICSTORIES Dataset",
            "text": "We introduce EMPATHICSTORIES, a corpus of personal stories containing 3,568 total annotations. Specifically, the corpus includes empathic similarity annotations of 2,000 story pairs, and the main events, emotions, morals, and empathy reason annotations for 1,568 individual stories. An overview of our data annotation pipeline is shown in Figure 2 and data preprocessing steps are included in Appendix D. In Appendix H, we show that using LLMs for human annotation is not viable for our task."
        },
        {
            "heading": "4.1 Data Sources",
            "text": "We collect a diverse set of stories from sources including social media sites, spoken narratives, and crowdsourced stories. We take approximately 500 stories from each of the following sources (for a full breakdown see Appendix F). These sources contain English-written stories revolving around deep emotional experiences and open-ended conversation starters.\n(1) Online Personal Stories. We scrape stories from subreddits2 about personal experiences (r/offmychest, r/todayiamhappy, and r/casualconversation). We also include a small set of stories from a public college confessions forum.\n(2) Crowdsourced Personal Stories. We use a subset of autobiographical stories from the existing Hippocorpus dataset (Sap et al., 2020), which contains recalled and imagined diary-like personal stories obtained from crowdworkers.\n(3) Spoken Personal Narratives. We use stories from the Roadtrip Nation corpus (Saldias and Roy, 2020), which contains transcribed personal stories about people\u2019s career trajectories and life stories."
        },
        {
            "heading": "4.2 Individual Story Annotation",
            "text": "Using these stories, we designed an annotation framework on Amazon Mechanical Turk (MTurk) that asks workers to label individual story features. Then, we asked for short free responses on (1) the\n2https://api.pushshift.io/\nmain event of the story, (2) the main emotional state induced by the main event, and (3) moral(s) of the story. The story and annotated summary statistics are shown in Table 1. The themes from stories are shown in Table 2, and themes for annotated summaries as well as our topic modeling approach are presented in Appendix E."
        },
        {
            "heading": "4.3 Paired Story Annotation",
            "text": "Sampling Empathic Story Pairs. We devise a sampling method to create a sample of balanced empathically similar and dissimilar story pairs, since random sampling across all possible pairs would likely result in an unbalanced dataset with more dissimilar stories than similar stories. First, we split the 1,568 stories into a train, dev, and test set using a 75/5/20 split. Using SBERT (Reimers and Gurevych, 2019), we compute a composite similarity score using average cosine similarity of the embeddings for the story and our 3 empathy features for every possible story pair within the dataset. We randomly sample stories from each bin such that bins with higher composite similarity scores are more likely to be chosen.\nAnnotation Procedure With the sampled story pairs, we released an annotation task on Amazon\nMTurk, asking workers to read pairs of stories and rate various aspects of empathic similarity between the stories. Two annotators rated each story pair. From early testing, we found that the task was difficult because of the large amount of text in the stories and the cognitive load of projecting into two narrator\u2019s mental states. To simplify the task, we used ChatGPT (gpt-3.5-turbo) to summarize all the stories before presenting the pairs to annotators. While summarization may remove specific details of the stories, we find that the main event, emotion, and moral takeaway are still present.3\nAt the beginning of the task, we first provide the annotator with 6 examples of empathically similar stories: one positive and one negative example for stories that are empathically similar/dissimilar based on each feature: main event, emotion, and moral of the story. After reading the two stories, we ask workers to provide explanations of whether and why the narrators would empathize with one another, to prime annotators to think about the empathic relationship between the stories. We then ask workers to provide four similarity ratings on a 4-point Likert scale (1 = strongly disagree, 4 = strongly agree): (1) overall empathic similarity (how likely the two narrators would empathize with each other), (2) similarity in the main events, (3) emotions, and (4) morals of the stories.\nAgreement We aggregate annotations by averaging between the 2 raters. Agreement scores for em-\n3By comparing the cosine similarity of human annotated event, emotion, and moral to the ChatGPT summarized stories, we find that there is high semantic overlap of the human ground-truths to the automatically generated summaries (0.66 for event, 0.64 for emotion, and 0.49 for moral).\npathy, event, emotion, and moral similarity across the entire dataset are shown in Table 3. While these agreement scores are seemingly on the lower side, using a softer constraint, we see that most common disagreements are at most 1 likert point away (73% of points are at most 1 distance away). We are aiming for a more descriptive annotation paradigm and thus do not expect annotators to perfectly agree (Rottger et al., 2022). Furthermore, our agreement rates are in line with other inherently personal and affect-driven annotation tasks (Sap et al., 2017; Rashkin et al., 2018). Given the difficulty of our task (reading longer stories and projecting the mental state of 2 characters), our agreement is in line with prior work, which achieve around 0.51 - 0.91 PPA and 0.29 - 0.34 KA."
        },
        {
            "heading": "5 Modeling Empathic Similarity",
            "text": "To enable the retrieval and analysis of empathically similar stories, we design a task detailed below. In Appendix B, we also propose an auxiliary reasoning task to automatically extract event, emotion, and moral features from stories, which could be used in future work to quickly generate story annotations."
        },
        {
            "heading": "5.1 Task Formulation",
            "text": "Our ultimate retrieval task is given a query story Q and selects a story Si from a set of N stories {S1, S2, ..., SN} such that i = argmaxi sim(f\u03b8(Si), f\u03b8(Q)). Here, sim(\u00b7, \u00b7) is a similarity metric (e.g. cosine similarity) between two story representations f\u03b8(Si) and f\u03b8(Q) that are learned from human ratings of empathic similarity.\nEmpathic Similarity Prediction. The overall task is, given a story pair (S1, S2), return a similarity score sim(f\u03b8(Si), f\u03b8(Q)) such that sim(\u00b7, \u00b7) is large for empathically similar stories and small for empathically dissimilar stories."
        },
        {
            "heading": "5.2 Models",
            "text": "We propose finetuning LLMs to learn embeddings that capture empathic similarity using cosine distance, for efficient retrieval at test time. In contrast, a popular approach is to use few-shot prompting of very large language models (e.g., GPT-3 and ChatGPT), which have shown impressive performance across a variety of tasks (Brown et al., 2020). However, in a real deployment setting, retrieval through prompting every possible pair of stories is expensive and inefficient.\nBaseline Models. We compare performance to finetuning with SBERT (multi-qa-mpnet-base-dotv1) (Reimers and Gurevych, 2019; Brown et al., 2020) and BART model (bart-base) (Lewis et al., 2019). As a few-shot baseline, we evaluate GPT-3 (text-davinci-003) and ChatGPT\u2019s (gpt-3.5-turbo) ability to distinguish empathically similar stories by using a k-shot prompting setup as done in Sap et al. (2022); Brown et al. (2020). For the query story pair, we ask for an empathic similarity score from 1-4. We compare across k = 0 examples and k = 5 examples from the training set. We also evaluate these models\u2019 ability to generate humanlike main event, emotion description, and moral summaries for each story. Again, we use a k-shot prompting setup, comparing across k = 0 and k = 10 examples. See Appendix G and Appendix C for prompts used and finetuning details.\nEmpathy Similarity Prediction. We propose a biencoder architecture finetuned with mean-squared error (MSE) loss of the cosine-similarity between story pairs, as compared to the empathic similarity gold labels. For each of the encoders, we use a shared pretrained transformer-based model and further finetune on the 1,500 annotated story pairs in our training set. We obtain the final embedding using mean pooling of the encoder last hidden state."
        },
        {
            "heading": "6 Automatic Evaluation",
            "text": "To evaluate the quality of empathic similarity predictions, we first compare the Spearman\u2019s and Pearson\u2019s correlations between the cosine similarity of the sentence embeddings and the gold empathic similarity labels. Next, we bin scores into binary similar/dissimilar categories (> 2.5 and \u2264 2.5 respectively) compute the accuracy, precision, recall, and F1 scores. Finally, we compute a series of retrieval-based metrics including precision at\nk = 1 (what proportion of the top-ranked stories by our model are the top-ranked story as rated by human annotators), Kendall\u2019s Tau (Abdi, 2007), and Spearman\u2019s correlation (Schober et al., 2018) for the ranking of the stories (how close the overall rankings are).\nShown in Table 4, our results indicate that finetuning SBERT and BART with EMPATHICSTORIES results in performance gains across all metrics. SBERT has relatively high off-the-shelf performance, as it is trained with 215M examples specifically for semantic similarity tasks. However, we see that finetuning with our dataset, which contains far fewer training examples relative to SBERT\u2019s pretraining corpus, improves performance. (+ 5.35 \u03c1, +2 accuracy). BART, which is not specifically pre-trained for semantic similarity tasks, shows even greater gains across retrieval metrics when finetuned on our dataset. (22.89 \u03c1, +7.75 accuracy). We find that for BART models, fine tuning improvements (p = 0.02, p = 0.0006 respectively), as measured with McNemar\u2019s test on the accuracy scores and Fisher\u2019s transformation on correlations, are significantly higher than baselines.\nWhile GPT-3 and ChatGPT have high performance on the precision at k retrieval metric, in practice, it is not feasible to prompt the models with every pair of stories in the retrieval corpus."
        },
        {
            "heading": "7 User Study",
            "text": "Prior work\u2019s versions of human evaluations (Zhou and Jurgens, 2020; Bao et al., 2021; Sharma et al., 2020) are humans verifying or ranking model outputs based on inputs from test data. This provides a valuable signal of model quality, but isn\u2019t representative of how a model could be used in real-world applications due to input distribution mismatch and lack of personal investment in the task. Our hu-\nman evaluation is a full user study to see how the model performs in retrieving a story that is empathically similar to a story that the users told themselves. Through our user study, we demonstrate the applicability of the task to improve empathy towards retrieval of human stories, as well as how our dataset was used to develop the empathic similarity retrieval task and why the task matters in the real-world. Our hypothesis is: Users will empathize more with stories retrieved by our model (BART finetuned on EMPATHICSTORIES) than stories retrieved by SBERT."
        },
        {
            "heading": "7.1 Participants and Recruitment",
            "text": "We recruited a pool of 150 participants from Prolific. Participants were primarily women (58%, 38% men, 3% non-binary, 1% undisclosed) and white (73%, 8% Black, 9% other or undisclosed, 4% Indian, 3% Asian, 2 % Hispanic, 1% Native American). The mean age for participants was 37 (s.d. 11.6), and participants on average said they would consider themselves empathetic people (mean 4.3, s.d. 0.81 for Likert scale from 1-5)."
        },
        {
            "heading": "7.2 Study Protocol",
            "text": "Participants rated their mood, wrote a personal story, then rated their empathy towards the stories retrieved by the baseline and proposed models. They additionally answered questions about the story they wrote (main event, emotion, and moral of the story) and their demographic information (age, ethnicity, and gender).\nUser Interface. We designed a web interface similar to a guided journaling app and distributed the link to the interface during the study. The interface connects to a server run on a GPU machine\n(4x Nvidia A40s, 256GB of RAM, and 64 cores), which retrieves story responses in real time. Writing Prompts and Stories Retrieved. We carefully designed writing prompts to present to the participants to elicit highly personal stories, inspired by questions from the Life Story Interview (McAdams, 2007), an approach from social science to gather key moments from a person\u2019s life. Conditions. We used a within-subject study design, where each participant was exposed to 2 conditions presented in random order. In Condition 1, participants read a story retrieved by our best performing model on the empathic similarity task (BART + finetuning). In Condition 2, participants read a story retrieved by SBERT. For both models, we select the best response that minimizes cosine distance. Measures. To measure empathy towards each story, we used a shortened version of the State Empathy Survey (Shen, 2010), which contains 7 questions covering affective (sharing of others\u2019 feelings), cognitive (adopting another\u2019s point of view), and associative (identification with others) aspects of situational empathy. We also ask users to provide a free-text explanation of whether and why they found the retrieved story empathically resonant, to gain qualitative insights into their experience."
        },
        {
            "heading": "7.3 Effects on Empathy",
            "text": "With our results shown in Figure 3, we found through a paired t-test (N = 150) that users significantly empathized more with stories retrieved by our model finetuned on EMPATHICSTORIES than off-the-shelf SBERT (t(149) = 2.43, p < 0.01, Cohen\u2019s d = 0.26), validating our hypothesis. In addition, this effect was present across all three dimensions of empathy: affective (t(149) = 1.87, p = 0.03, Cohen\u2019s d = 0.21), cognitive (t(149) =\n2.05, p = 0.02, Cohen\u2019s d = 0.21), and associative empathy (t(149) = 2.61, p = 0.005, Cohen\u2019s d = 0.27), as shown in Figure 4 (empathy values are the summed scores from the empathy survey). Interestingly, the difference in empathic response across conditions is strongest for associative empathy, which measures how much the user can identify with the narrator of the story.\nWe examine reasons why users empathized with retrieved stories across conditions (Figure 5). Across both conditions, empathy towards a story was often related to how well-read, genuine, and consistent the story was, and if the user could empathize with the narrator\u2019s emotional reactions. When participants did not empathize with a retrieved story, this was more often than not due to stark differences in the main events of their own story and the model\u2019s selected story. This effect was strongest for our finetuned model, as it was trained on data with a more open definition of empathy than just sharing the same situation. In certain cases, this could result in the events being too different for the user to empathize with.\nInterestingly, we see that our model chose stories that aligned better on events and emotions with respect to the story they wrote, and participants thought the stories were more original compared to SBERT-retrieved stories. In cases where the participant did not empathize with the retrieved story, SBERT-retrieved stories were considered less consistent, less genuine, less, original, did not read as well, and did not match on emotions as well compared to our model.\nFrom qualitative responses, we see that our model retrieved stories that user empathized with based on the situation described, the emotions the\nnarrator felt, and the takeaway of the story. For example, one participant shared that \u201cI found no moment where I didn\u2019t fully understand the author, and I share a very similar story about my father...its absolutely amazing...I enjoyed this study very much.\u201d Other participants wrote, \u201cI empathize heavily with this story because it has many similarities to my own. Kind of a \u2018started from the bottom, now we\u2019re here\u2019 vibe, which I love to see\u201d and \u201cI can relate to the feelings of abandonment and regret expressed.\u201d"
        },
        {
            "heading": "8 Future Directions for Empathic Similarity",
            "text": "In summary, few prior works on text-based empathy have looked at modeling empathy in two-way interpersonal settings for human-to-human connection, as most focus on detecting empathy or generating empathetic utterances, and even fewer of these works have shown tangible outcomes in human studies. With increasing polarization, loneliness, and apathy (Buecker et al., 2021), personal experiences are a fundamental way people connect, yet existing social recommendation is not targeted for human-human connectivity and empathy. Empathically encoded story embeddings could be useful for a variety of NLP tasks, including retrieval, text generation, dialogue, and translation, for example in the following settings:\n\u2022 Using empathic reasoning to incorporate story retrieval in dialogue generation.\n\u2022 Generating stories that users resonate with more in conversational AI\n\u2022 Extending this work to multilingual settings and better understand translating experiences\nin ways that preserve empathic meaning\n\u2022 Better understand cognitive insights, such as linguistic patterns of emotion-driven communication\n\u2022 Applications and building interactions that foster story sharing across geographic, ethnic, and cultural bridges, such as developing better social media recommendation or personalization.\nWe encourage future works to explore these directions in developing more human-centered approaches for interactions with NLP systems."
        },
        {
            "heading": "9 Conclusion",
            "text": "This work explores how we can model empathic resonance between people\u2019s personal experiences. We focused specifically on unpacking empathy in text-based narratives through our framework of the events, emotions, and moral takeaways from personal narratives. We collected EMPATHICSTORIES, a diverse dataset of high-quality personal narratives with rich annotations on individual story features and empathic resonance between pairs of stories. We presented a novel task for retrieval of empathically similar stories and showed that large-language models finetuned on our dataset can achieve considerable performance gains in our task. Finally, we validated the real-world efficacy of our BARTfinetuned retrieval model in a user study, demonstrating significant improvements in feelings of empathy towards stories retrieved by our model compared to off-the-shelf semantic similarity retrieval.\nEmpathy is a complex and multi-dimensional phenomenon, intertwined with affective and cognitive states, and it is foundational in our ability to form social relationships and develop meaningful connections. In a world where loneliness and apathy are increasingly present despite the numerous ways we are now able to interact with technologybased media, understanding empathy, developing empathic reasoning in AI agents, and building new interactions to foster empathy are imperative challenges. Our work lays the groundwork towards this broader vision and demonstrates that AI systems that can reason about complex interpersonal dynamics have the potential to improve empathy and connection between people in the real-world.\nLimitations\nWith regards to our data collection and annotation framework, our annotations for empathic similarity are not first-person, which are sub-optimal given that it may be difficult for annotator\u2019s to project the emotional states of two narrators. In addition, because of the complexity of our annotation task, we opted to use ChatGPT summaries of the stories during our paired story annotation, which could introduce biases depending on the quality of the generated summaries. However, given the inherent difficulty of the task, we found this reduction necessary to achieve agreement and reduce noise in our dataset, and we found that important features will still present in the summaries. Future work could use our human experimental setup to collect first person labels over the entire stories, rather than the automatic summaries.\nAnother limitation of our modeling approach is that our finetuned model takes in data that captures empathic relations across our framework of events, emotions, and morals. However, the learned story representations are general purpose and are not personalized to a user\u2019s empathic preferences. Personalization could improve model performance across automatic and human evaluation metrics, as there may exist finer-grained user preferences in how users empathize with certain stories, and what aspects users focus on. Furthermore, future work could explore training using a contrastive setup to learn more contextualized story embeddings.\nLastly, future work should explore longitudinal effects of recieving stories retrieved by our system. Our survey measures (State Empathy Scale) are used for short, quick assessments of immediate empathy rather than \u201cfixed\u201d or \u201ctrait\u201d empathy. While our model might perform well in this one-shot interaction settings, it is also important to study the last empathic effects of reading stories retrieved by the model and measure changes in a user\u2019s longer term empathy, mood, and feelings of connection.\nEthics Statement\nWhile such a system might foster empathy and connectedness, it is important to consider the potential harms brought about by this work. As with many recommenders, our model is susceptible to algorithmic biases in the types of stories it retrieves, as well as creating an echo chamber for homogeneous perspectives (Kirk et al., 2023). Embedding diversity in the recommended stories is important in both\nbroadening the perspective of users and preventing biases.\nMany social platforms struggle with the issue of content moderation and content safety. In its proposed state, our model does not do anything to guarantee the safety of content that is shared with users. Hateful speech and triggering experiences should not be propagated by our model regardless of the extent to which users relate to these stories (Goel et al., 2023; Lima et al., 2018).\nFinally, the goal of our work is to connect people to other human experiences. Story generation and NLG that aims to mimic or appropriate human experiences is not something we endorse, and we encourage the use of machine-text detectors in systems that retrieve empathic stories. In line with Oren Etzioni (2018)\u2019s three rules of AI, we also discourage presenting humans with machinegenerated stories without disclosing that the story is written by an AI author."
        },
        {
            "heading": "Acknowledgements",
            "text": "We would like to thank all of our participants, annotators, and teammates for their invaluable contributions to this project. Special thanks to Sharifa Algohwinem and Wonjune Kang for their technical feedback throughout the project and thanks to Ji Min Mun, Akhila Yerukola, and Ishaan Grover for paper feedback. This work was supported by an NSF GRFP under Grant No. 2141064 and the IITP grant funded by the Korean Ministry of Science and ICT No.2020-0-00842."
        },
        {
            "heading": "A Understanding Aspects of Empathic Similarity",
            "text": "Before training any models to learn empathic similarity ratings, it is important to understand the mechanisms behind empathic similarity in textbased personal narratives. In particular, we are interested in how structural elements of stories (events, emotional trajectories, and morals) relate to empathy. The question we aim to answer through our analysis of the text is what qualities of personal experiences people resonate with most and how does this relate to the personal experience they self disclose.\nFirst, we look at the correlation between humanrated similarity in event, emotion, and moral of the stories to the empathic similarity rating. We show in Table 5 that the correlation of the similarity between events, emotions, and morals to the empathic similarity rating is high for all three features. This indicates that similarity in these components is related to similarity in empathic resonance between stories. Using a paired t-test between high and low empathically similar story pairs, we find that empathically similar story pairs have statistically significantly higher similarities in events, emotions, and morals, with the largest increase in moral similarity and roughly equivalent increases in event and emotion similarities.\nNext, we look at the differences between semantic similarity and human-rated empathic similarity. As shown in Figure 6, we can see that the distributions of similarity scores are different for human-rated empathic similarity scores as compared to semantic similarity scores obtained from SBERT. Semantic similarity of stories is\nweakly positively correlated with empathic similarity (\u03c1 = 0.17), with event-based features correlating the most (\u03c1 = 0.067), followed by emotionbased features (\u03c1 = 0.0069) and lastly moral features (\u03c1 = \u22120.048). These results indicate that semantic similarity is naturally related to empathic similarity, but might not capture relationships between emotions and takeaways in pairs of stories."
        },
        {
            "heading": "B Empathy Reasoning Task",
            "text": "Empathy Reasoning Task Definition. Given a story context c, we finetune a sequence-to-sequence (seq2seq) model to generate an event (v), emotion (e), and moral (m), concatenating annotated summaries to construct the gold label and modeling p(v, e,m|c) (Kim et al., 2022). The model is trained to minimize negative log likelihood of predicting each word in the constructed gold label.\nEmpathy Reasoning Results. We evaluate empathy reasoning performance using BLEU (Papineni et al., 2002), ROUGE (Lin, 2004), METEOR (Banerjee and Lavie, 2005), and BertScore (Zhang et al., 2020), taking the human-written free-text annotations as gold references. From Ta-\nble 6, we see that finetuning BART with humanwritten story summaries improves performance across all metrics. The BART model finetuned on EMPATHICSTORIES demonstrates improved performance across 3/4 metrics in event and moral reasons. For emotion reasons, ChatGPT demonstrates better performance in 2/4 metrics, with the finetuned BART model close behind. We note that the BART-base model has 140M parameters, whereas ChatGPT has upwards of 175B parameters."
        },
        {
            "heading": "C Finetuned Model Training Details",
            "text": "We use a 75:5:20 train:dev.:test split on both individual stories and pairs of stories. For the empathic similarity prediction task, we use learning rates of 1e-6 and 5e-6 for SBERT and BART respectively, and a linear scheduler with warmup. For the empathic reasoning task, we use a learning rate of 1e-5. For both tasks, we use a batch size of 8 and finetune for 30-50 epochs, monitoring correlation and validation loss to select the best-performing models. We trained all models on 4x Nvidia A40s with 256GB of RAM and 64 cores, and all model training times were under 12 hours."
        },
        {
            "heading": "D Data Pre-Processing",
            "text": "For all of the data sources, we remove stories that are shorter than 5 sentences long, longer than 500 words, and which have a severe toxicity score of less than 0.005 using Detoxify (Hanu and Unitary team, 2020). While the latter step may filter out meaningful stories and introduce bias in the story selections (Sap et al., 2019a), we err on the side of removing any stories that could be potentially harmful, even if not severely so.\nOur research team then selected stories that were appropriate to share (did not contain excessive profanity or explicit sexual content), and which had a first-person narrator and concrete resolution to the story. We chose stories with a concrete resolution in order to avoid rant posts, which were common on social media pages. In addition, we manually corrected overt grammatical errors as well as references to the platform the story was shared on (e.g. addressing Redditors). Our final set of stories contains 1,568 curated, high-quality personal narratives."
        },
        {
            "heading": "E Story and Annotation Themes",
            "text": "Below we show the top themes across each story\u2019s emotion (Table 7) and moral (Table 8) annotations.\nNote that we did not include topics for the events since these were similar to Table 2. To identify these topics, we use Latent Dirichlet Allocation (LDA) and KeyBERT on the clusters (Grootendorst, 2020)."
        },
        {
            "heading": "F Collected Stories Breakdown",
            "text": "A breakdown of the amount of stories per source can be found in Table 9."
        },
        {
            "heading": "G GPT-3 and ChatGPT Prompts",
            "text": "Below are prompts we fed to GPT-3 and ChatGPT for our few-shot baselines. Note that in addition to the prompts, we provided sampled examples from our training corpus.\n\u2022 Event summary: What is the main event being described in the story? Response must be at least 1 sentence and 50-1000 characters including spaces.\n\u2022 Emotion summary: Describe the emotions the narrator feels before and after the main event and why they feel this way. Answer as though you were explaining how the narrator felt to someone who knew nothing about the situation. Response must be at least 2\nsentences and 150-1000 characters including spaces.\n\u2022 Moral summary: What is the high-level lesson or takeaway (ie. moral) of the story? Response must be at least 1 sentence and 100- 1000 characters including spaces.\n\u2022 Empathic similarity: Rate the extent to which you agree with the statement \"the narrators of the two stories would empathize with each other.\" We define empathy as feeling, understanding, and relating to what another person is experiencing. Note that it is possible to have empathy even without sharing the exact same experience or circumstance. Importantly, for two stories to be empathetically similar, both narrators should be able to empathize with each other (if narrator A\u2019s story was shared in response to narrator B\u2019s story, narrator B would empathize with narrator A and vice versa). Give your answer on a scale from 1-4 (1 - not at all, 2 - not so much, 3 - very much, 4 - extremely)"
        },
        {
            "heading": "H Using LLMs as a Proxy for Human Annotations",
            "text": "Recent works raise the question of whether LLMs can be used to proxy human annotations (Gilardi et al., 2023). The motivation behind this method is that obtaining human labels across many pairs of stories is costly, and this cost only compounds as the number of stories in the corpus increases. As such, we provide additional analyses as to whether or not these models can truly perform at the same level as human annotators for our task, which involves heavy empathy and emotion reasoning.\nH.1 Individual Story Annotation\nWe prompt ChatGPT (gpt-3.5-turbo) to generate summaries of each story\u2019s main event, emotion, and moral, in addition to a list of reasons why a narrator might empathize with the story. We compare these summaries against human-written summaries using BLEU, ROUGE, METEOR, and BertScore (Table 10), showing that ChatGPT has relatively low performance across all four metrics.\nH.2 Paired Story Annotation\nWe feed the same prompt given to human annotators into ChatGPT, asking for a Likert score from\n1-4 for the empathic similarity between two stories. The Spearman\u2019s correlation between human and ChatGPT generated labels is 0.22 (p < 0.001), indicating weakly positive correlation between human annotations and ChatGPT annotations. In addition, we perform a one-sample t-test on the meansquared error between automatically generated labels and human annotations across all story pairs in the training data, obtaining a p-value < 0.001, indicating that the mean of all the errors is nonzero with statistical significance.\nFinally, we bin the ChatGPT annotations into agree/disagree categories, and compute the classification precision (0.59), recall (0.40), F1 score (0.48), and accuracy (0.59) as compared to human gold labels. These scores offer insight as to how well ChatGPT predicts the direction of the empathic similarity annotation, but we see that accuracy is low when comparing to human labels. In Figure 7, we see that ChatGPT similarity scores are skewed to the left, indicating that humans are more likely to find empathic similarities between experiences. These results are also supported by the higher number of false negatives when comparing ChatGPT classification to human gold labels."
        }
    ],
    "title": "Modeling Empathic Similarity in Personal Narratives",
    "year": 2023
}