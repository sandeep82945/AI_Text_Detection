{
    "abstractText": "Listeners recognize and integrate words in rapid and noisy everyday speech by combining expectations about upcoming content with incremental sensory evidence. We present a computational model of word recognition which formalizes this perceptual process in Bayesian decision theory. We fit this model to explain scalp EEG signals recorded as subjects passively listened to a fictional story, revealing both the dynamics of the online auditory word recognition process and the neural correlates of the recognition and integration of words. The model reveals distinct neural processing of words depending on whether or not they can be quickly recognized. While all words trigger a neural response characteristic of probabilistic integration \u2014 voltage modulations predicted by a word\u2019s surprisal in context \u2014 these modulations are amplified for words which require more than roughly 150 ms of input to be recognized. We observe no difference in the latency of these neural responses according to words\u2019 recognition times. Our results are consistent with a two-part model of speech comprehension, combining an eager and rapid process of word recognition with a temporally independent process of word integration. However, we also developed alternative models of the scalp EEG signal not incorporating word recognition dynamics which showed similar performance improvements. We discuss potential future modeling steps which may help to separate these hypotheses. Psycholinguistic studies at the neural and behavioral levels have detailed how listeners actively predict upcoming content at many levels of linguistic representation (Kuperberg and Jaeger, 2016), and use these predictions to drive their behavior far before the relevant linguistic input is complete (Allopenna et al., 1998). One wellstudied neural correlate of this prediction-driven Code to reproduce our analyses is available at github.com/hans/word-recognition-and-integration. comprehension process is the N400 ERP, a centroparietally distributed negative voltage modulation measured at the scalp by electroencephalogram (EEG) which peaks around 400 ms after the onset of a word. This negative component is amplified for words which are semantically incompatible with their sentence or discourse context (Kutas and Hillyard, 1984; Brown and Hagoort, 1993; Kutas and Federmeier, 2011; Heilbron et al., 2022). This effect has been taken as evidence that comprehenders actively predict features of upcoming words (DeLong et al., 2005; Kuperberg and Jaeger, 2016; Kuperberg et al., 2020). On one popular account, predictions about upcoming content are used to pre-activate linguistic representations likely to be used when that content arrives. The N400 reflects the integration of a recognized word with its context, and this integration is facilitated just when the computational paths taken by the integration process align with those already pre-activated by the listener (Kutas and Federmeier, 2011; Federmeier, 2007). Despite the extensive research on the N400 and its computational interpretation, its relationship with the upstream process of word recognition is still not well understood. Some authors have argued that integration processes should be temporally yoked to word recognition: that is, comprehenders should continue gathering acoustic evidence as to the identity of a word until they are sufficiently confident to proceed with subsequent integration processes (Marslen-Wilson, 1987). It is also possible, however, that integration processes are insensitive to the progress of word recognition: that integration is a temporally regular semantic operation which begins regardless of the listener\u2019s confidence about the word being spoken (Hagoort, 2008; Federmeier and Laszlo, 2009). Experimental studies have attempted to assess the link between these two processes, modeling the timing of word recognition through an offline behavioral paradigm known as gating (Grosjean, 1980): by presenting incrementally longer clips of speech to subjects and asking them to predict what word is being spoken, authors estimate the time point at which there is sufficient information to identify a word from its acoustic form. Several EEG studies have asked whether the N400 response varies with respect to this estimate of word recognition time, but have arrived at contradictory answers to this question (van den Brink et al., 2006; O\u2019Rourke and Holcomb, 2002). In this paper, we introduce a computational model which targets these dynamics of word recognition, and their manifestation in neural EEG signals recorded during naturalistic listening. The model allows us to connect trial-level variation in word recognition times to aspects of the neural response to words. We use the model to address two cross-cutting questions: \u2022 Onset: Are words integrated only after they are successfully recognized, or is the timing of integration insensitive to the state of word",
    "authors": [
        {
            "affiliations": [],
            "name": "Jon Gauthier"
        },
        {
            "affiliations": [],
            "name": "Roger Levy"
        }
    ],
    "id": "SP:500ee02a8e9801bc52d8457ca9b689640c76bd34",
    "references": [
        {
            "authors": [
                "Takuya Akiba",
                "Shotaro Sano",
                "Toshihiko Yanase",
                "Takeru Ohta",
                "Masanori Koyama."
            ],
            "title": "Optuna: A next-generation hyperparameter optimization framework",
            "venue": "Proceedings of the 25th ACM SIGKDD International Conference on Knowledge",
            "year": 2019
        },
        {
            "authors": [
                "Paul D Allopenna",
                "James S Magnuson",
                "Michael K Tanenhaus."
            ],
            "title": "Tracking the time course of spoken word recognition using eye movements: Evidence for continuous mapping models",
            "venue": "Journal of memory and language, 38(4):419\u2013439.",
            "year": 1998
        },
        {
            "authors": [
                "James Bergstra",
                "R\u00e9mi Bardenet",
                "Yoshua Bengio",
                "Bal\u00e1zs K\u00e9gl."
            ],
            "title": "Algorithms for hyper-parameter optimization",
            "venue": "Advances in neural information processing systems, 24.",
            "year": 2011
        },
        {
            "authors": [
                "Sid Black",
                "Leo Gao",
                "Phil Wang",
                "Connor Leahy",
                "Stella Biderman"
            ],
            "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with MeshTensorflow",
            "year": 2021
        },
        {
            "authors": [
                "Trevor Brothers",
                "Gina R Kuperberg."
            ],
            "title": "Word predictability effects are linear, not logarithmic: Implications for probabilistic models of sentence comprehension",
            "venue": "Journal of Memory and Language, 116:104174.",
            "year": 2021
        },
        {
            "authors": [
                "Trevor Brothers",
                "Emily Morgan",
                "Anthony Yacovone",
                "Gina Kuperberg"
            ],
            "title": "Multiple predictions during language comprehension: Friends, foes, or indifferent companions? Cognition, 241:105602",
            "year": 2023
        },
        {
            "authors": [
                "Colin Brown",
                "Peter Hagoort."
            ],
            "title": "The Processing Nature of the N400: Evidence from Masked Priming",
            "venue": "Journal of Cognitive Neuroscience, 5(1):34\u201344.",
            "year": 1993
        },
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are few-shot learners. Advances in neural information processing",
            "year": 2020
        },
        {
            "authors": [
                "Marc Brysbaert",
                "Boris New."
            ],
            "title": "Moving beyond Ku\u010dera and Francis: A critical evaluation of current word frequency norms and the introduction of a new and improved word frequency measure for American English",
            "venue": "Behavior Research Methods,",
            "year": 2009
        },
        {
            "authors": [
                "Charlotte Caucheteux",
                "Jean-R\u00e9mi King."
            ],
            "title": "Brains and algorithms partially converge in natural language processing",
            "venue": "Communications biology, 5(1):134.",
            "year": 2022
        },
        {
            "authors": [
                "Michael J. Crosse",
                "Giovanni M. Di Liberto",
                "Adam Bednar",
                "Edmund C. Lalor."
            ],
            "title": "The multivariate temporal response function (mtrf) toolbox: A matlab toolbox for relating neural signals to continuous stimuli",
            "venue": "Frontiers in Human Neuroscience, 10.",
            "year": 2016
        },
        {
            "authors": [
                "Katherine A. DeLong",
                "Thomas P. Urbach",
                "Marta Kutas."
            ],
            "title": "Probabilistic word pre-activation during language comprehension inferred from electrical brain activity",
            "venue": "Nature Neuroscience, 8(8):1117\u2013 1121.",
            "year": 2005
        },
        {
            "authors": [
                "Peter W. Donhauser",
                "Sylvain Baillet."
            ],
            "title": "Two Distinct Neural Timescales for Predictive Speech Processing",
            "venue": "Neuron, 105(2):385\u2013393.e9.",
            "year": 2020
        },
        {
            "authors": [
                "Kara D Federmeier."
            ],
            "title": "Thinking ahead: The role and roots of prediction in language comprehension",
            "venue": "Psychophysiology, 44(4):491\u2013505.",
            "year": 2007
        },
        {
            "authors": [
                "Kara D Federmeier",
                "Marta Kutas."
            ],
            "title": "A rose by any other name: Long-term memory structure and sentence processing",
            "venue": "Journal of memory and Language, 41(4):469\u2013495.",
            "year": 1999
        },
        {
            "authors": [
                "Kara D Federmeier",
                "Sarah Laszlo."
            ],
            "title": "Time for meaning: Electrophysiology provides insights into the dynamics of representation and processing in semantic memory",
            "venue": "Psychology of learning and motivation, 51:1\u201344.",
            "year": 2009
        },
        {
            "authors": [
                "Stefan L. Frank",
                "Leun J. Otten",
                "Giulia Galli",
                "Gabriella Vigliocco."
            ],
            "title": "The ERP response to the amount of information conveyed by words in sentences",
            "venue": "Brain and Language, 140:1\u201311.",
            "year": 2015
        },
        {
            "authors": [
                "Marlies Gillis",
                "Jonas Vanthornhout",
                "Jonathan Z. Simon",
                "Tom Francart",
                "Christian Brodbeck."
            ],
            "title": "Neural Markers of Speech Comprehension: Measuring EEG Tracking of Linguistic Speech Representations, Controlling the Speech Acoustics",
            "venue": "Journal of",
            "year": 2021
        },
        {
            "authors": [
                "Hasson."
            ],
            "title": "Shared computational principles for language processing in humans and deep language models",
            "venue": "Nature Neuroscience, 25(3):369\u2013380.",
            "year": 2022
        },
        {
            "authors": [
                "Fran\u00e7ois Grosjean."
            ],
            "title": "Spoken word recognition processes and the gating paradigm",
            "venue": "Perception & Psychophysics, 28(4):267\u2013283.",
            "year": 1980
        },
        {
            "authors": [
                "Peter Hagoort."
            ],
            "title": "The fractionation of spoken language understanding by measuring electrical and magnetic brain signals",
            "venue": "Philosophical Transactions of the Royal Society B: Biological Sciences, 363(1493):1055\u20131069.",
            "year": 2008
        },
        {
            "authors": [
                "Micha Heilbron",
                "Kristijan Armeni",
                "Jan-Mathijs Schoffelen",
                "Peter Hagoort",
                "Floris P De Lange."
            ],
            "title": "A hierarchy of linguistic predictions during natural language comprehension",
            "venue": "Proceedings of the National Academy of Sciences, 119(32):e2201968119.",
            "year": 2022
        },
        {
            "authors": [
                "Gina R Kuperberg",
                "Trevor Brothers",
                "Edward W Wlotko."
            ],
            "title": "A tale of two positivities and the n400: Distinct neural signatures are evoked by confirmed and violated predictions at different levels of representation",
            "venue": "Journal of Cognitive Neuroscience,",
            "year": 2020
        },
        {
            "authors": [
                "Gina R. Kuperberg",
                "T. Florian Jaeger"
            ],
            "title": "What do we mean by prediction in language comprehension? Language, Cognition and Neuroscience, 31(1):32\u201359",
            "year": 2016
        },
        {
            "authors": [
                "Marta Kutas",
                "Kara D. Federmeier."
            ],
            "title": "Thirty Years and Counting: Finding Meaning in the N400 Component of the Event-Related Brain Potential (ERP)",
            "venue": "Annual Review of Psychology, 62(1):621\u2013 647.",
            "year": 2011
        },
        {
            "authors": [
                "Marta Kutas",
                "Steven A. Hillyard."
            ],
            "title": "Brain potentials during reading reflect word expectancy and semantic association",
            "venue": "Nature, 307(5947):161\u2013163.",
            "year": 1984
        },
        {
            "authors": [
                "Edmund C. Lalor",
                "Alan J. Power",
                "Richard B. Reilly",
                "John J. Foxe."
            ],
            "title": "Resolving precise temporal processing properties of the auditory system using continuous stimuli",
            "venue": "Journal of Neurophysiology, 102(1):349\u2013359. PMID: 19439675.",
            "year": 2009
        },
        {
            "authors": [
                "Falk Lieder",
                "Thomas L Griffiths."
            ],
            "title": "Resourcerational analysis: Understanding human cognition as the optimal use of limited computational resources",
            "venue": "Behavioral and brain sciences, 43:e1.",
            "year": 2020
        },
        {
            "authors": [
                "William D Marslen-Wilson."
            ],
            "title": "Functional parallelism in spoken word-recognition",
            "venue": "Cognition, 25(12):71\u2013102.",
            "year": 1987
        },
        {
            "authors": [
                "D. Norris",
                "J. McQueen."
            ],
            "title": "Shortlist B: A Bayesian model of continuous speech recognition",
            "venue": "Psychological review.",
            "year": 2008
        },
        {
            "authors": [
                "Timothy B O\u2019Rourke",
                "Phillip J Holcomb"
            ],
            "title": "Electrophysiological evidence for the efficiency of spoken word processing",
            "venue": "Biological psychology,",
            "year": 2002
        },
        {
            "authors": [
                "Alec Radford",
                "Jeffrey Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "venue": "OpenAI blog,",
            "year": 2019
        },
        {
            "authors": [
                "Martin Schrimpf",
                "Idan Asher Blank",
                "Greta Tuckute",
                "Carina Kauf",
                "Eghbal A Hosseini",
                "Nancy Kanwisher",
                "Joshua B Tenenbaum",
                "Evelina Fedorenko."
            ],
            "title": "The neural architecture of language: Integrative modeling converges on predictive processing",
            "venue": "Pro-",
            "year": 2021
        },
        {
            "authors": [
                "Herbert A Simon."
            ],
            "title": "A behavioral model of rational choice",
            "venue": "The quarterly journal of economics, pages 99\u2013118.",
            "year": 1955
        },
        {
            "authors": [
                "Nathaniel J Smith",
                "Roger Levy."
            ],
            "title": "The effect of word predictability on reading time is logarithmic",
            "venue": "Cognition, 128(3):302\u2013319.",
            "year": 2013
        },
        {
            "authors": [
                "Darren Tanner",
                "Kara Morgan-Short",
                "Steven J Luck."
            ],
            "title": "How inappropriate high-pass filters can produce artifactual effects and incorrect conclusions in erp studies of language and cognition",
            "venue": "Psychophysiology, 52(8):997\u20131009.",
            "year": 2015
        },
        {
            "authors": [
                "Louis Ten Bosch",
                "Lou Boves",
                "Mirjam Ernestus."
            ],
            "title": "Diana, a process-oriented model of human auditory word recognition",
            "venue": "Brain Sciences, 12(5):681.",
            "year": 2022
        },
        {
            "authors": [
                "Benjamin V. Tucker",
                "Dan Brenner",
                "D. Kyle Danielson",
                "Matthew C. Kelley",
                "Filip Nenadi\u0107",
                "Michelle Sims."
            ],
            "title": "The massive auditory lexical decision (mald) database",
            "venue": "Behavior Research Methods, 51:1187 \u2013 1204.",
            "year": 2018
        },
        {
            "authors": [
                "Dani\u00eblle van den Brink",
                "Colin M. Brown",
                "Peter Hagoort."
            ],
            "title": "The cascaded nature of lexical selection and integration in auditory sentence processing",
            "venue": "Journal of Experimental Psychology: Learning, Memory, and Cognition, 32(2):364\u2013372.",
            "year": 2006
        },
        {
            "authors": [
                "Eline Verschueren",
                "Marlies Gillis",
                "Lien Decruy",
                "Jonas Vanthornhout",
                "Tom Francart."
            ],
            "title": "Speech understanding oppositely affects acoustic and linguistic neural tracking in a speech rate manipulation paradigm",
            "venue": "Journal of Neuroscience, 42(39):7442\u2013",
            "year": 2022
        },
        {
            "authors": [
                "Lin Wang",
                "Gina Kuperberg",
                "Ole Jensen."
            ],
            "title": "Specific lexico-semantic predictions are associated with unique spatial and temporal patterns of neural activity",
            "venue": "Elife, 7:e39061.",
            "year": 2018
        },
        {
            "authors": [
                "Andrea Weber",
                "Roel Smits."
            ],
            "title": "Consonant And Vowel Confusion Patterns By American English Listeners",
            "venue": "page 4.",
            "year": 2003
        }
    ],
    "sections": [
        {
            "text": "The model reveals distinct neural processing of words depending on whether or not they can be quickly recognized. While all words trigger a neural response characteristic of probabilistic integration \u2014 voltage modulations predicted by a word\u2019s surprisal in context \u2014 these modulations are amplified for words which require more than roughly 150 ms of input to be recognized. We observe no difference in the latency of these neural responses according to words\u2019 recognition times. Our results are consistent with a two-part model of speech comprehension, combining an eager and rapid process of word recognition with a temporally independent process of word integration. However, we also developed alternative models of the scalp EEG signal not incorporating word recognition dynamics which showed similar performance improvements. We discuss potential future modeling steps which may help to separate these hypotheses.\nPsycholinguistic studies at the neural and behavioral levels have detailed how listeners actively predict upcoming content at many levels of linguistic representation (Kuperberg and Jaeger, 2016), and use these predictions to drive their behavior far before the relevant linguistic input is complete (Allopenna et al., 1998). One wellstudied neural correlate of this prediction-driven\nCode to reproduce our analyses is available at github.com/hans/word-recognition-and-integration.\ncomprehension process is the N400 ERP, a centroparietally distributed negative voltage modulation measured at the scalp by electroencephalogram (EEG) which peaks around 400 ms after the onset of a word. This negative component is amplified for words which are semantically incompatible with their sentence or discourse context (Kutas and Hillyard, 1984; Brown and Hagoort, 1993; Kutas and Federmeier, 2011; Heilbron et al., 2022). This effect has been taken as evidence that comprehenders actively predict features of upcoming words (DeLong et al., 2005; Kuperberg and Jaeger, 2016; Kuperberg et al., 2020). On one popular account, predictions about upcoming content are used to pre-activate linguistic representations likely to be used when that content arrives. The N400 reflects the integration of a recognized word with its context, and this integration is facilitated just when the computational paths taken by the integration process align with those already pre-activated by the listener (Kutas and Federmeier, 2011; Federmeier, 2007).\nDespite the extensive research on the N400 and its computational interpretation, its relationship with the upstream process of word recognition is still not well understood. Some authors have argued that integration processes should be temporally yoked to word recognition: that is, comprehenders should continue gathering acoustic evidence as to the identity of a word until they are sufficiently confident to proceed with subsequent integration processes (Marslen-Wilson, 1987). It is also possible, however, that integration processes are insensitive to the progress of word recognition: that integration is a temporally regular semantic operation which begins regardless of the listener\u2019s confidence about the word being spoken (Hagoort, 2008; Federmeier and Laszlo, 2009).\nExperimental studies have attempted to assess the link between these two processes, modeling the timing of word recognition through an offline\nbehavioral paradigm known as gating (Grosjean, 1980): by presenting incrementally longer clips of speech to subjects and asking them to predict what word is being spoken, authors estimate the time point at which there is sufficient information to identify a word from its acoustic form. Several EEG studies have asked whether the N400 response varies with respect to this estimate of word recognition time, but have arrived at contradictory answers to this question (van den Brink et al., 2006; O\u2019Rourke and Holcomb, 2002).\nIn this paper, we introduce a computational model which targets these dynamics of word recognition, and their manifestation in neural EEG signals recorded during naturalistic listening. The model allows us to connect trial-level variation in word recognition times to aspects of the neural response to words. We use the model to address two cross-cutting questions:\n\u2022 Onset: Are words integrated only after they are successfully recognized, or is the timing of integration insensitive to the state of word recognition?\n\u2022 Response properties: Does the shape of the neural response to words differ based on their recognition times? If so, this could indicate distinct inferential mechanisms deployed for words depending on their ease of recognition.\nWe jointly optimize the cognitive and neural parameters of this model to explain EEG data recorded as subjects listened to naturalistic English speech. Model comparison results suggest that semantic integration processes are not temporally yoked to the status of word recognition: the neural traces of word integration have just the same temporal structure, regardless of when words are successfully recognized. However, the neural correlates of word integration qualitatively differ based on the status of word recognition: words not yet recognized by the onset of word integration exhibit significantly different neural responses.\nThese results suggest a two-part model of word recognition and integration. First, the success of our word recognition model in predicting the neural response to words suggests that there exists a rapid lexical interpretation process which integrates prior expectations and acoustic evidence in order to pre-activate specific lexical items in memory. Second, an independent integration process composes these memory contents with a model of\nthe context, following a clock which is insensitive to the specific state of word recognition.\nIt is necessary to moderate these conclusions, however: we also develop alternative models of the neural correlates of word integration which improve beyond the performance of our baselines, without incorporating facts about the dynamics of word recognition. We discuss in Section 4 how more elaborate neural linking theories will be necessary to better separate these very different cognitive pictures of the process of word recognition and its neural correlates."
        },
        {
            "heading": "1 Model",
            "text": "Our model consists of two interdependent parts: a cognitive model of the dynamics of word recognition, and a neural model that estimates how these dynamics drive the EEG response to words."
        },
        {
            "heading": "1.1 Cognitive model",
            "text": "We first design a cognitive model of the dynamics of word recognition in context, capturing how a listener forms incremental beliefs about the word they are hearing wi as a function of the linguistic context C and some partial acoustic evidence I\u2264k. We formalize this as a Bayesian posterior (Norris and McQueen, 2008):\nP (wi | C, I\u2264k) \u221d P (wi | C) P (I\u2264k | wi) (1)\nwhich factorizes into a prior expectation of the word wi in context (first term) and a likelihood of the partial evidence of k phonemes I\u2264k (second term). This model thus asserts that the context C and the acoustic input I\u2264k are conditionally independent given wi. We parameterize the prior P (wi | C) = P (wi | w<i) using a left-to-right neural network language model. The likelihood is a noisy-channel phoneme recognition model:\nP (I\u2264k | wi) \u221d \u220f\n1\u2264j\u2264k P (Ij | wij)\n1 \u03bb (2)\nwhere per-phoneme confusion probabilities are drawn from prior phoneme recognition studies (Weber and Smits, 2003) and reweighted by a temperature parameter \u03bb.\nWe evaluate this posterior for every word with each incremental phoneme, from k = 0 (no input) to k = |wi| (conditioning on all of the word\u2019s phonemes). We define a hypothetical cognitive event of word recognition which is time-locked to the phoneme k\u2217i where this posterior first exceeds a confidence threshold \u03b3:\nk\u2217i = min 0\u2264k\u2264|wi| {k | P (wi | C, I\u2264k) > \u03b3} (3)\nWe define a word\u2019s recognition time \u03c4i to be a fraction \u03b1 of the span of the k\u2217i -ith phoneme. In the special case where k\u2217i = 0 and the word is confidently identified prior to acoustic input, we take \u03c4i to be a fraction \u03b1p of its first phoneme\u2019s duration (visualized in Figure 1a):\n\u03c4i =\n{ onsi(k\u2217i ) + \u03b1 duri(k \u2217 i ) if k \u2217 i > 0\n\u03b1p duri(1) if k\u2217i = 0 (4)\nwhere onsi(k) and duri(k) are the onset time (relative to word onset) and duration of the k-th phoneme of word i, and \u03b1, \u03b1p are free parameters fitted jointly with the rest of the model."
        },
        {
            "heading": "1.2 Neural model",
            "text": "We next define a set of candidate linking models which describe how the dynamics of the cognitive model (specifically, word recognition times \u03c4i) affect observed neural responses. These models are all variants of a temporal receptive field model (TRF; Lalor et al., 2009; Crosse et al., 2016), which predicts scalp EEG data over S sensors and T samples, Y \u2208 RS\u00d7T , as a convolved set of linear responses to lagged features of the stimulus:\nYst = \u2211 f \u03c4f\u2211 \u2206=0 \u0398f,s,\u2206 \u00d7Xf,t\u2212\u2206 + \u03f5st (5)\nwhere \u03c4f is the maximum expected lag (in seconds) between the onset of a feature f and its correlates in the neural signal; and the inner sum is accumulated in steps of the relevant neural sampling rate. This deconvolutional model estimates a characteristic linear response linking each feature of the stimulus to the neural data over time. The model allows us to effectively uncover the neural response to individual stimulus features in naturalistic data, where stimuli (words) arrive at a fast\nrate, and their neural responses are likely highly convolved as a consequence (Crosse et al., 2016).\nWe define a feature time series Xt \u2208 Rdt\u00d7T containing dt features of the objective auditory stimulus, such as acoustic and spectral features, resampled to match the T samples of the neural time series. We also define a word-level feature matrix Xv \u2208 Rdw\u00d7nw for the nw words in the stimulus. Crucially, Xv contains estimates of each word\u2019s surprisal (negative log-probability) in context. Prior studies suggest that surprisal indexes the peak amplitude of the naturalistic N400 (Frank et al., 2015; Gillis et al., 2021; Heilbron et al., 2022).\nWe assume that Xt causes a neural response independent of word recognition dynamics, while the neural response to features Xv may vary as a function of recognition dynamics. These two feature matrices will be merged together to yield the design matrix X in Equation 5.\nWe enumerate several possible classes of neural models which describe different ways that a word\u2019s recognition time \u03c4i may affect the neural response. Each model class constitutes a different answer to our framing questions of onset and response properties (Table 2 and Figure 1b), by specifying different featurizations of word-level properties Xv in the TRF design matrix X:\n1. Unitary response aligned to word onset (baseline model): All words exhibit a unitary linear neural response to recognition and integration, time-locked to the word\u2019s onset in the stimulus. This baseline model, which does not incorporate the cognitive dynamics of recognition in any way, is what has been assumed by prior naturalistic modeling work.\nThis model asserts that each word\u2019s features\n0.00 0.25sec after word onset\nfk = 1 k = 2 k = 3 %\n0.00 0.25sec after word onset\nfk = 1 k = 2 k = 3 p%\n(a) Computation of recognition time \u03c4i for a recognition point after phoneme k\u2217i = 2 (left) or recognition prior to input, k\u2217i = 0 (right) for a spoken word fish /fIS/. See eq. 4.\nXvi trigger a neural response beginning at the onset of word i, and that this neural response can be captured by a single characteristic response to all words.\n2. Unitary response aligned to recognition time (shift model): All words exhibit a unitary linear neural response to recognition and integration, time-locked to the word\u2019s recognition time \u03c4i.\nThis model asserts that each word\u2019s features Xvi trigger a neural response beginning at \u03c4i seconds after word onset, and that this neural response can be captured by a single characteristic response to all words.\n3. Variable response by recognition time, aligned to word onset (variable model): Words exhibit a differential neural response to recognition and integration based on their recognition time. The temporal onset of these integration processes is insensitive to the progress of word recognition.\nWe account for variable responses by defining a quantile split Q : \u03c4 \u2192 N on the inferred recognition times \u03c4i. We then estimate distinct TRF parameters for the features of\nwords in each quantile.\nThis model thus asserts that it is possible to group words by their recognition dynamics such that they have a characteristic neural response within-group, but differ freely between groups.\n4. Variable response by word surprisal, aligned to word onset (prior-variable model): This model is identical to the above variable model, except that words are divided into quantiles based on their surprisal in context rather than their recognition time.\nThis model instantiates the hypothesis that the shape of the neural response to words varies based on listeners\u2019 expectations, but only those driven by the preceding linguistic context. On this reading, words are preactivated according to their prior probability, rather than their rapidly changing posterior probability under some acoustic input.1\nFor a set of recognition time predictions \u03c4i, we estimate within-subject TRFs under each of these linking models, yielding per-subject parameters \u0398j , describing the combined neural response to objective stimulus features and wordlevel features. This estimation procedure allows for within-subject variation in the shape of the neural response."
        },
        {
            "heading": "2 Methods and dataset",
            "text": "We jointly infer2 across-subject parameters of the cognitive model (Table 1) and within-subject parameters of the neural model in order to minimize regularized L2 loss on EEG data, estimated by 4-fold cross-validation. We then compare the fit models on held-out test data, containing 25% of the neural time series data for each subject. For each comparison of models m1,m2, we compute the Pearson correlation coefficient r between the predicted and observed neural response for each subject at each EEG sensor s. We then use paired t-tests to ask whether the within-subject difference\n1This reading is compatible with pre-activation theories (e.g. Brothers and Kuperberg, 2021). At their present level of specificity, it is unclear whether this focus on prior probability is a substantive commitment, or simply a choice of modeling expediency.\n2We conduct tree-structured Parzen estimator random search (Bergstra et al., 2011) with Optuna (Akiba et al., 2019).\nin r pooled across sensors significantly differs between m1 and m2:\n1\nS S\u2211 s=1 r ( Ys, Y\u0302m1,s ) ? > 1 S S\u2211 s=1 r ( Ys, Y\u0302m2,s ) (6)\nDataset We analyze EEG data recorded as 19 subjects listened to Hemingway\u2019s The Old Man and the Sea, published in Heilbron et al. (2022). The 19 subjects each listened to the first hour of the recorded story while maintaining fixation. We analyze 5 sensors distributed across the centroparietal scalp: one midline sensor and two lateral sensors per hemisphere at central and posterior positions. The EEG data were acquired using a 128- channel ActiveTwo system at a rate of 512 Hz, and down-sampled offline to 128 Hz and re-referenced to the mastoid channels. We follow the authors\u2019 preprocessing method, which includes band-pass filtering the EEG signal between 0.5 and 8 Hz, visual annotation of bad channels, and removal of eyeblink components via independent component analysis.3 The dataset also includes force-aligned annotations for the onsets and durations of both words and phonemes in these time series.\nWe generate a predictor time series Xt aligned with this EEG time series (Appendix B), ranging from stimulus features (features of the speech envelope and spectrogram) to sublexical cognitive features (surprisal and entropy over phonemes). By including these control features in our models, we can better understand whether or not there is a cognitive and neural response to words distinct from responses to their constituent properties (see Section 4.2 for further discussion). We generate in addition a set of word-level feature vectors Xv \u2208 R3\u00d7nw , consisting of an onset feature and\n1. word surprisal in context, computed with GPT Neo 2.7B (Black et al., 2021),4 and 2. word unigram log-frequency, from SUBTLEXus 2 (Brysbaert and New, 2009).\nLikelihood estimation Our cognitive model requires an estimate of the confusability between English phonemes (Equation 2). We draw on the experimental data of Weber and Smits (2003),\n3See Appendix E for further details on our choice of bandpass filter width.\n4Preliminary experiments using our baseline model showed that surprisal estimates from GPT Neo 2.7B best explained held-out EEG signals, compared among other sizes of GPT Neo and OpenAI GPT-2 models (Radford et al., 2019; Brown et al., 2020).\nwho estimated patterns of confusion in phoneme recognition within English consonants and vowels by asking subjects to transcribe spoken syllables. Their raw data consists of count matrices \u03c8c, \u03c8v for consonants and vowels, respectively, where each cell \u03c8[ij] denotes the number of times an experimental subject transcribed phoneme j as phoneme i, summing over different phonological contexts (syllable-initial or -final) and different levels of acoustic noise in the stimulus presentation. We concatenate this confusion data into a single matrix, imputing a count of 1 for unobserved confusion pairs, and normalize each column to yield the required conditional probability distributions."
        },
        {
            "heading": "3 Results",
            "text": "We first evaluate the baseline model relative to a TRF model which incorporates no word-level features Xv except for a word onset feature, and find that this model significantly improves in held-out prediction performance (t = 4.91, p = 0.000113). The model recovers a negative response to word surprisal centered around 400 ms post word onset (Figure 6), which aligns with recent EEG studies of naturalistic language comprehension in both listening (Heilbron et al., 2022; Gillis et al., 2021; Donhauser and Baillet, 2020) and reading (Frank et al., 2015).\nWe next separately infer optimal model parameters for the shift and variable models, and evaluate their error on held-out test data. We find that the variable model significantly exceeds the baseline model (t = 5.15, p = 6.70\u00d710\u22125), while the shift\nmodel does not (t = 2.23, p = 0.039).5 This suggests that neural responses to words are not simply temporally yoked to their recognition times.\nWe next investigate the parameters of the optimal variable model. Figure 2 shows the distribution of predicted word recognition times \u03c4i under the optimal variable model on stimulus data from the held-out test set, charted relative to the onset of a word. Our model predicts that one third of words are recognized prior to 64 ms post word onset, another third are recognized between 64 ms and 159 ms, and a long tail are recognized after 159 ms post word onset. This entails that at least a third of words are recognized prior to any meaningful processing of acoustic input. This prediction aligns with prior work in multiple neuroimaging modalities, which suggests that listeners preactivate features of lexical items far prior to their acoustic onset in the stimulus (Wang et al., 2018; Goldstein et al., 2022).\nThese inferred recognition times maximize the likelihood of the neural data under the linking variable model parameters \u0398. Figure 3 shows the variable model\u2019s parameters describing a neural response to word surprisal for each of three recognition time quantiles, time locked to word onset. We see two notable trends in the N400 response\n5A direct comparison of the variable model and shift model performance also favors the variable model (t = 5.49, p = 3.24\u00d7 10\u22125).\nwhich differ as a function of recognition time:\n1. Figure 3 shows word surprisal modulations estimated at a centro-parietal site for the three recognition time quantiles. Words recognized late (159 ms or later post word onset) show an exaggerated modulation due to word surprisal. The peak negative amplitude of this response is significantly more negative than the peak negative response to early words (fig. 3, green line peak minus blue line peak in the shaded region; within-subject paired t = \u22125.23, p = 5.71 \u00d7 10\u22125). This modulation is spatially distributed similarly to the modulation for early-recognized words (compare the green inset scalp distribution to that of the blue and orange scalps). 2. There is no significant difference in the latency of the N400 response for words recognized early vs. late. The time at which the surprisal modulation peaks negatively does not significantly differ between early and late words (fig. 3, green line peak time minus blue line peak time; within-subject paired t = 2.17, p = 0.0440).\nThese model comparisons and analyses of optimal parameters yield answers to our original questions about the dynamics of word recognition and integration:\nResponse properties: Neural modulations due to surprisal are exaggerated for words recognized late after their acoustic onset.\nOnset: The variable model, which asserted integration processes are initiated relative to words\u2019 onsets rather than their recognition times, demonstrated a better fit to the data. The optimal parameters under the variable model further showed that while word recognition times seem to affect the amplitude of neural modulations due to surprisal, they do not affect their latency."
        },
        {
            "heading": "3.1 Prior-variable model",
            "text": "We compute a surprisal-based quantile split over words in the training dataset. The first third of low-surprisal words had a surprisal lower than 1.33 bits, while the last third of high-surprisal words had a surprisal greater than 3.71 bits.\nWe next estimate the prior-variable neural model parameters, which describe independent neural responses to words in low-, mid-, and highsurprisal quantiles. This model also significantly exceeds the baseline model (t = 7.78, p = 3.64\u00d7 10\u22127; see Appendix C for inferred model parameters). Figure 4 shows a comparison of the way the prior-variable model and the variable model sorted words into different quantiles. While the two models rarely made predictions at the opposite extremes (labeling a low-surprisal word as late-recognized, or a high-surprisal word as earlyrecognized; bottom left and upper right black corners in fig. 4a), there were many disagreements involving sorting words into neighboring time bins (off-diagonal in fig. 4a). Figures 4b and 4c show some meaningful cases in which the models disagree to be due to differences in the relevant phonological neighborhood early in the onset of a word. Figure 4c shows the recognition model\u2019s posterior belief over words (eq. 1) given the incremental phonetic input at the top of the graph. The left panel of Figure 4c shows how the word disgust is recognized relatively late due to a large number of contextually probable phonological neighbors (such as dismay and despair); the right panel shows how the word knelt is recognizable relatively early, since most of the contextually probable completions (took, had) are likely to be ruled out after the presentation of a second phone.\nThe variable model\u2019s generalization performance is not significantly different than that of this prior-variable model (t = \u22120.422, p = 0.678).\nFuture work will need to leverage other types of neural data to distinguish these models. We discuss this further in Section 4 and the Limitations section."
        },
        {
            "heading": "4 Discussion",
            "text": "This paper presented a cognitive model of word recognition which yielded predictions about the recognition time of words in context \u03c4i. A second neural linking model, the variable model, estimated the neural response to words recognized at early, intermediate, and late times according to the cognitive model\u2019s predictions. This latter model significantly improved in held-out generalization performance over a baseline model which did not allow for differences in the neural signal as a function of a word\u2019s recognition time. We also found, however, that a neural model which estimated distinct shapes of the neural response to words based on their surprisal \u2014 not their recognition times \u2014 also improved beyond our baseline, and was indistinguishable from the variable model. More elaborate neural linking theories describing how words\u2019 features drive the neural response will be necessary to distinguish these models (see e.g. the encoding model of Goldstein et al., 2022).\nOur positive findings are consistent with a twopart model of auditory word recognition and integration, along the lines suggested by van den Brink et al. (2006) and Hagoort (2008, \u00a73c). In this model, listeners continuously combine their expectations with evidence from sensory input in order to load possible lexical interpretations of the current acoustic input into a memory buffer. Our model\u2019s prediction of a word\u2019s recognition time \u03c4i measures the time at which this buffer resolves in a clear lexical inference.\nA second integration process reads out the contents of this buffer and merges them with representations of the linguistic context. Our latency results show that the timing of this process is independent of a listener\u2019s current confidence in their lexical interpretations, instead time-locked to word onset. This integration process thus exhibits two distinct modes depending on the listener\u2019s buffer contents: one standard, in which the buffer is clearly resolved, and one exceptional, in which the buffer contents are still ambiguous, and additional inferential or recovery processes must be deployed in order to proceed with integration. Future work could spell out this distinction mech-\nanistically in order to explain how buffers in the \u201cexceptional\u201d state elicit these distinct neural responses."
        },
        {
            "heading": "4.1 What determines integration timing?",
            "text": "Our findings on the stable timing of the naturalistic N400 align with some prior claims in the experimental ERP literature (Federmeier and Laszlo, 2009, \u00a75).6 These results strengthen the notion that, even in rapid naturalistic environments, the timing of the early semantic integration of word meanings is driven not by when words are recognized, but rather by the tick of an external clock.\nIf this integration process is not sensitive to the status of word recognition, then what drives its dynamics? Federmeier and Laszlo (2009) argue that this regularly timed integration process is language-external, functioning to bind early representations of word meaning with existing cognitive representations of the context via temporal synchrony (see also Kutas and Federmeier, 2011). However, other language-internal mechanisms are also compatible with the data. Listeners may adapt to low-level features of the stimulus, such as their counterpart\u2019s speech rate or prosodic cues, manipulating the timing of integration to maximize the\n6This is a claim about the within-subject consistency of N400 timing, despite substantial between-subject variability, for example, by age and language experience (Federmeier and Laszlo, 2009).\nchances of success in the expected case.7\nAlternatively, listeners may use the results of the word recognition process to schedule upcoming attempts at word integration. After recognizing each word wi, listeners may form an expectation about the likely onset time of word wi+1, using knowledge about the form ofwi and the speech rate. Listeners could instantiate a clock based on this prediction, counting down to a time some fixed distance from the expected onset of wi+1, at which semantic integration would be most likely to succeed on average. Such a theory could explain how word recognition and integration are at least approximately optimal given limited cognitive resources (Simon, 1955; Lieder and Griffiths, 2020): they are designed to successfully process linguistic inputs in expectation, under the architectural constraint of a fixed integration clock."
        },
        {
            "heading": "4.2 Words as privileged units of processing",
            "text": "Our results suggest that words exist at a privileged level of representation and prediction during speech processing. This is not a necessary property of language processing: it is possible that word-level processing effects (neural or behavioral responses to word-level surprisal) could emerge as an epiphenomenon of lower-level pre-\n7See Verschueren et al. (2022, Figure 6 and Table 4) for evidence against this point, demonstrating that controlled variation in stimulus speech rate does not affect the latency of the N400 response.\ndiction and integration of sublexical units, e.g., graphemes or phonemes. Smith and Levy (2013, \u00a72.4) illustrate how a \u201chighly incremental\u201d model which is designed to predict and integrate sublexical units (grapheme- or phoneme-based prediction) but which is measured at higher levels (in word-level reading times or word-level neural responses) could yield apparent contrasts that are suggestive of word-level prediction and integration. On this argument, neural responses to wordlevel surprisal are not alone decisive evidence for word-level prediction and integration (versus the prediction and integration of sub-lexical units).\nOur results add a critical orthogonal piece of evidence in favor of word-level integration: we characterized an integration architecture whose timing is locked to the appearance of word units in the stimulus. While the present results cannot identify the precise control mechanism at play here (section 4.1), the mere fact that words are the target of this timing process indicates an architecture strongly biased toward word-level processing."
        },
        {
            "heading": "4.3 Prospects for cognitive modeling",
            "text": "The cognitive model of word recognition introduced in this paper is an extension of Shortlist B (Norris and McQueen, 2008), a race architecture specifying the dynamics of single-word recognition within sentence contexts. We used neural network language models to scale this model to describe naturalistic speech comprehension. While we focus here on explaining the neural response to words, future work could test the predictions of this model in behavioral measures of the dynamics of word recognition, such as lexical decision tasks (Tucker et al., 2018; Ten Bosch et al., 2022)."
        },
        {
            "heading": "5 Conclusion",
            "text": "This paper presented a model of the cognitive and neural dynamics of word recognition and integration. The model recovered the classic N400 integration response, while also detecting a distinct treatment of words based on how and when they are recognized: words not recognized until more than 150 ms after their acoustic onset exhibit significantly amplified neural modulations by surprisal. Despite this processing difference, we found no distinction in the latency of integration depending on a word\u2019s recognition time.\nHowever, we developed an alternative model of the neural signal not incorporating word recog-\nnition dynamics which also exceeded baseline models describing the N400 integration response. More substantial linking hypotheses bridging between the cognitive state of the word recognition model and the neural signal will be necessary to separate these distinct models.\nLimitations\nThere are several important methodological limitations to the analyses in this paper.\nWe assume for the sake of modeling expediency that all listeners experience the same word recognition dynamics in response to a linguistic stimulus. Individual differences in contextual expectations, attention, and language knowledge certainly modulate this process, and these differences should be accounted for in an elaborated model.\nWe also assume a relatively low-dimensional neural response to words, principally asserting that the contextual surprisal of a word drives the neural response. This contrasts with other recent brain mapping evaluations which find that high-dimensional word representations also explain brain activation during language comprehension (Goldstein et al., 2022; Caucheteux and King, 2022; Schrimpf et al., 2021). A more elaborate neural linking model integrating higherdimensional word representations would likely allow us to capture much more granular detail at the cognitive level, describing how mental representations of words are retrieved and integrated in real time. Such detail may also allow us to separate the two models (the variable and prior-variable models) which were not empirically distinguished by the results of this paper."
        },
        {
            "heading": "Acknowledgments",
            "text": "We thank Aixiu An, Jacob Andreas, Canaan Breiss, Trevor Brothers, Tyler Brooke Wilson, Samer Nour Eddine, Evelina Fedorenko, Micha Heilbron, Shailee Jain, Peng Qian, Cory Shain, Jakub Szewczyk, and Josh Tenenbaum for comments on earlier versions of this paper. We thank Micha Heilbron, Marlies Gillis, and Tamar Regev for invaluable advice on EEG data analysis, and for sharing analysis code and data. JG gratefully acknowledges support from the Open Philanthropy Project and RPL gratefully acknowledges support from a Newton Brain Science Research Seed Award."
        },
        {
            "heading": "A Relation to pre-activation accounts",
            "text": "Our theoretical account discussed in Section 4 is partly compatible with pre-activation accounts of prediction in language comprehension, which likewise suggest that listeners eagerly pre-activate features at multiple levels of linguistic representation, according to both contextual expectations and partial sensory input (see e.g. Federmeier (2007); Federmeier and Laszlo (2009); Kutas and Federmeier (2011); Kuperberg and Jaeger (2016) for reviews). Our cognitive model of word recognition provides a mechanism for the temporal dynamics of this pre-activation process. This mechanism is an aggressively incremental process, depending on a probabilistic inference which repeatedly integrates novel acoustic evidence with existing expectations drawn from the context.\nPre-activation accounts suggest that what is pre-activated are abstract semantic features rather than specific lexical items (Federmeier and Kutas, 1999; Kuperberg and Jaeger, 2016). The present\nmodel is stated at the computational level and is thus not directly comparable in this respect. Future modeling work can instantiate specific representational alternatives within this predictive word recognition model and explore how their predictions might settle these questions."
        },
        {
            "heading": "B Model featurization",
            "text": "We use a subset of the sublexical features from Heilbron et al. (2022) in our TRF models (named as Xt in Section 1.2). These features are shared across all models tested in our main and baseline analysis:\n\u2022 onset features for each phoneme in the audio stimulus;\n\u2022 phoneme-onset aligned features:\n\u2013 acoustic control features, averaged within the span of a phoneme: average variance in the broadband envelope, and spectral power measures averaged within eight bins spaced evenly on a log-mel scale\n\u2013 the entropy over a next-phoneme distribution P (pj | wi,<j) and the surprisal of the ground-truth phoneme, using the hierarchical predictive model of Heilbron et al. (2022) (see below).\nB.1 Phoneme probability estimator The phoneme model of Heilbron et al. (2022), whose surprisal and entropy measures we use as control predictors, combines a word-level language model prior and a cohort-based likelihood. For some prior phoneme sequence p1, . . . , pt\u22121 and some incoming phoneme pt in a linguistic context C, we define\nP (pt | p1, . . . , pt\u22121, C) \u221d \u2211 w\u2208V P (w | C, p1, . . . , pt\u22121)P (pt | w)\n= \u2211 w\u2208V P (w | C)1{w \u2208 Coh(p1, . . . , pt\u22121, pt}\n(7)\nwhere V is a vocabulary of all possible word forms, and Coh(p1, . . . , pt) denotes the cohort of a phoneme sequence p1, . . . , pt \u2014 i.e., all the words which share the given prefix of phonemes.\nThis model thus effectively renormalizes a language model\u2019s word-level prior P (w | C) among\nwords which are exactly phonologically compatible with an observed prefix. See Heilbron et al. (2022) for further details on the model specification.\nC Inferred neural response under the prior-variable model\nFigure 5 shows the inferred neural response to words of different surprisal quantiles under the prior-variable model described in Section 3.1. We see an amplified negative peak in high-surprisal words, similar to that in Figure 3 for laterecognized words."
        },
        {
            "heading": "D Baseline estimates of the neural response to surprisal",
            "text": "Figure 6 shows the baseline model\u2019s estimated response to a word\u2019s surprisal. The model recovers the standard broad negative response centered around 400 ms post word onset, which aligns with recent EEG studies of naturalistic language comprehension in both listening (Heilbron et al., 2022; Gillis et al., 2021; Donhauser and Baillet, 2020) and reading (Frank et al., 2015).\nFigure 7 shows estimates of the neural response to phoneme surprisal from both the baseline model and the optimal variable model. All models tested in this paper included this phoneme surprisal predictor; the main results of the paper thus target neural activity above and beyond what is explained by phoneme-level responses. See Section 4.2 for further discussion."
        },
        {
            "heading": "E Choice of band-pass filter",
            "text": "A critical preprocessing step in our data analysis is to band-pass filter the raw EEG signal, retaining signals within a frequency window of 0.5\u2013 8 Hz. This choice of filter parameters is similar to that of other recent studies of naturalistic language comprehension which use temporal receptive field models (see e.g. Gillis et al., 2021; Heilbron et al., 2022). A reviewer points out, however, that this filter window is substantially narrower than that of classic controlled studies of the evoked N400 based on trial-averaging ERP analyses (e.g. Kutas and Hillyard, 1984; Brown and Hagoort, 1993; Brothers et al., 2023). This choice of narrow filter parameters for our temporal receptive field analysis has several motivations:\n1. We wish to focus on evoked responses timelocked to events (e.g. onsets of words and\nphonemes, and changes in cognitive state due to those stimuli) with rates around this frequency range. Including a wider spectrum adds variance to the signal which we cannot explain using our features of interest,\n2. A high low-cut (more aggressive high-pass filter) allows us to account for signal drift; while this is handled through baselining and detrending in classic ERP analyses, temporal receptive field models have no equivalent ca-\npacity to explain drift in the signal.\nHowever, it is possible that this choice of filter parameters could introduce artifacts in the filtered signal which affect the outcomes of our N400-focused analysis. In particular, Tanner et al. (2015) point out that aggressive high-pass filters (\u223c 0.5 Hz and above) can conflate evoked N400 responses with later ERPs such as the P600, and yield inflated estimates of N400 amplitude.\nE.1 Stability of the baseline model We thus conducted a post-hoc stability analysis to better understand the sensitivity of this paradigm\nto our choice of band-pass filter parameters. We first repeated our initial model comparison on EEG data preprocessed with different band-pass filter parameters. This model comparison evaluates the improvement in predictive performance of a temporal receptive field model which incorporates control acoustic-phonetic features and word-level features (word surprisal and frequency) above a model which does not include these wordlevel features. (This is the same model comparison described in the beginning of Section 3.) Table 3 shows the results of this evaluation.\nWe find that the predictive power of these wordlevel features diminishes as we decrease the lowcut frequency: beneath 0.3 Hz, this model comparison no longer shows a significant improvement in prediction due to word-level features. We do not take this result to invalidate the claim that word surprisal yields an evoked EEG response in naturalistic comprehension, since this has been supported in other studies of naturalistic comprehension with classic trial-averaging methods (Frank et al., 2015).\nHowever, it is important to check whether the central finding of this paper \u2014 which rests on an inflated N400 amplitude in response to some types of words \u2014 is sensitive to these parameter changes. In the next section, we reproduce our main qualitative findings for those preprocessing parameters which yield a clear positive baseline outcome of the evoked N400 response to surprisal.\nE.2 Stability of our main findings\nThe argument of Tanner et al. (2015) would predict that the inflated N400 amplitude we observe in response to late-recognized words could be explained away as an artifact of the high-pass filter, which could confound the N400 with a later evoked response (such as the P600). If this finding were purely artifactual, then if we were to relax this high-pass filter, we should see an attenuation\nof the inflated N400 response and an amplification of a P600 response.\nWe thus re-fit the temporal receptive field parameters of the optimal variable model described in this paper on EEG data preprocessed with a low-cut of 0.3 Hz, the lowest frequency cut at which the baseline model clearly establishes that an evoked surprisal response is readable in the signal. Figure 8 shows the estimated neural modulation by word surprisal in these preprocessed data.\nWe found that this variable model displayed the same qualitative patterns in neural parameters. Quantitatively, we found a similar effect size of inflated N400 amplitude (fig. 8 green line peak minus blue line peak in the shaded region; withinsubject paired t = \u22125.03, p = 8.71\u00d7 10\u22125).8\nThese supplementary analyses suggest that our main findings are stable to different parameterizations of a high-pass filter in EEG preprocessing."
        },
        {
            "heading": "F Reproducibility information",
            "text": "We jointly estimated the parameters of the cognitive model together with the hyperparameters and parameters of the neural linking model using multivariate tree-structured Parzen estimator random search (Bergstra et al., 2011) with Optuna (Akiba et al., 2019). For subjects i = 1, . . . , N , sensors s = 1, . . . , S, and held-out EEG time series data for subject i at sensor s Yi,s, we maximized the value V :\nV = 1\nN N\u2211 i=1 ( max s\u2208{1,...,S} r(Yi,s, Y\u0302i,s) ) (8)\nwhich is the average across subjects of the maximal Pearson correlation of predicted and observed EEG response among all sensors. Table 4 shows the precise bounds for each parameter and hyperparameter in this search procedure. We evaluated 20 trials (random settings of parameters) for the baseline model (which only incorporated the L2 coefficient), and 500 trials for all other models. The model results presented in this paper (in visualizations and statistical tests) correspond to the highest-performing outcome of each grid search.\nTable 5 shows the total count of free parameters under optimization. These counts do not include the parameters of the language model used to compute word surprisal, or the word recognition model\n8Our latency foundings also held null (green line peak time minus blue line peak time; within-subject paired t = 2.17, p = 0.043).\nlikelihood parameters, since these were kept fixed during optimization.\nAll temporal receptive field models were fit with a receptive field ranging from 0 ms to 750 ms post word onset.\nWe implemented all training and inference with GPU operations in PyTorch. Due to the large memory requirements of the EEG time series data and the lagged regression computations, we deployed each model fit on two NVIDIA A100 GPUs. Each of the model fits completed in two days or fewer."
        }
    ],
    "title": "The neural dynamics of auditory word recognition and integration",
    "year": 2023
}