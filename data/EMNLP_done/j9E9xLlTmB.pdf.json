{
    "abstractText": "Subword tokenization has become the de-facto standard for tokenization, although comparative evaluations of subword vocabulary quality across languages are scarce. Existing evaluation studies focus on the effect of a tokenization algorithm on the performance in downstream tasks, or on engineering criteria such as the compression rate. We present a new evaluation paradigm that focuses on the cognitive plausibility of subword tokenization. We analyze the correlation of the tokenizer output with the response time and accuracy of human performance on a lexical decision task. We compare three tokenization algorithms across several languages and vocabulary sizes. Our results indicate that the UnigramLM algorithm yields less cognitively plausible tokenization behavior and a worse coverage of derivational morphemes, in contrast with prior work.",
    "authors": [
        {
            "affiliations": [],
            "name": "Lisa Beinborn"
        },
        {
            "affiliations": [],
            "name": "Yuval Pinter"
        }
    ],
    "id": "SP:d68e01659752c99e0ecc06e9752f20654b877710",
    "references": [
        {
            "authors": [
                "Jose Armando Aguasvivas",
                "Manuel Carreiras",
                "Marc Brysbaert",
                "Pawe\u0142 Mandera",
                "Emmanuel Keuleers",
                "Jon Andoni Du\u00f1abeitia."
            ],
            "title": "Spalex: A spanish lexical decision database from a massive online data collection",
            "venue": "Frontiers in Psychology, 9.",
            "year": 2018
        },
        {
            "authors": [
                "John Aldrich."
            ],
            "title": "Correlations genuine and spurious in pearson and yule",
            "venue": "Statistical science, pages 364\u2013 376.",
            "year": 1995
        },
        {
            "authors": [
                "Simona Amenta",
                "Davide Crepaldi."
            ],
            "title": "Morphological processing as we know it: An analytical review of morphological effects in visual word identification",
            "venue": "Frontiers in psychology, 3:232.",
            "year": 2012
        },
        {
            "authors": [
                "Elisabeth Beyersmann",
                "Petroula Mousikou",
                "Ludivine Javourey-Drevet",
                "Sascha Schroeder",
                "Johannes C Ziegler",
                "Jonathan Grainger."
            ],
            "title": "Morphological processing across modalities and languages",
            "venue": "Scientific Studies of Reading, 24(6):500\u2013519.",
            "year": 2020
        },
        {
            "authors": [
                "Chris Biemann",
                "Gerhard Heyer",
                "Uwe Quasthoff",
                "Matthias Richter."
            ],
            "title": "The leipzig corpora collection-monolingual corpora of standard size",
            "venue": "Proceedings of Corpus Linguistic, 2007.",
            "year": 2007
        },
        {
            "authors": [
                "Kaj Bostrom",
                "Greg Durrett."
            ],
            "title": "Byte pair encoding is suboptimal for language model pretraining",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 4617\u20134624, Online. Association for Computational Linguistics.",
            "year": 2020
        },
        {
            "authors": [
                "Hyung Won Chung",
                "Dan Garrette",
                "Kiat Chuan Tan",
                "Jason Riesa."
            ],
            "title": "Improving multilingual models with language-clustered vocabularies",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages",
            "year": 2020
        },
        {
            "authors": [
                "Jonathan H. Clark",
                "Dan Garrette",
                "Iulia Turc",
                "John Wieting."
            ],
            "title": "Canine: Pre-training an efficient tokenization-free encoder for language representation",
            "venue": "Transactions of the Association for Computational Linguistics, 10:73\u201391.",
            "year": 2022
        },
        {
            "authors": [
                "Nicola Dawson",
                "Kathleen Rastle",
                "Jessie Ricketts."
            ],
            "title": "Finding the man amongst many: A developmental perspective on mechanisms of morphological decomposition",
            "venue": "Cognition, 211:104605.",
            "year": 2021
        },
        {
            "authors": [
                "Ludovic Ferrand",
                "Boris New",
                "Marc Brysbaert",
                "Emmanuel Keuleers",
                "Patrick Bonin",
                "Alain M\u00e9ot",
                "Maria Augustinova",
                "Christophe Pallier."
            ],
            "title": "The french lexicon project: Lexical decision data for 38,840 french words and 38,840 pseudowords",
            "venue": "Be-",
            "year": 2010
        },
        {
            "authors": [
                "Philip Gage."
            ],
            "title": "A new algorithm for data compression",
            "venue": "C Users Journal, 12(2):23\u201338.",
            "year": 1994
        },
        {
            "authors": [
                "Matthias Gall\u00e9."
            ],
            "title": "Investigating the effectiveness of BPE: The power of shorter sequences",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Pro-",
            "year": 2019
        },
        {
            "authors": [
                "Valentin Hofmann",
                "Janet Pierrehumbert",
                "Hinrich Sch\u00fctze."
            ],
            "title": "Superbizarre is not superb: Derivational morphology improves BERT\u2019s interpretation of complex words",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Lin-",
            "year": 2021
        },
        {
            "authors": [
                "Valentin Hofmann",
                "Hinrich Schuetze",
                "Janet Pierrehumbert."
            ],
            "title": "An embarrassingly simple method to mitigate undesirable properties of pretrained language model tokenizers",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational",
            "year": 2022
        },
        {
            "authors": [
                "Emmanuel Keuleers",
                "Kevin Diependaele",
                "Marc Brysbaert."
            ],
            "title": "Practice effects in large-scale visual word recognition studies: A lexical decision study on 14,000 dutch mono- and disyllabic words and nonwords",
            "venue": "Frontiers in Psychology, 1.",
            "year": 2010
        },
        {
            "authors": [
                "Emmanuel Keuleers",
                "Paula Lacey",
                "Kathleen Rastle",
                "Marc Brysbaert."
            ],
            "title": "The british lexicon project: Lexical decision data for 28,730 monosyllabic and disyllabic english words",
            "venue": "Behavior research methods, 44:287\u2013304.",
            "year": 2012
        },
        {
            "authors": [
                "Evan Kidd",
                "Seamus Donnelly",
                "Morten H Christiansen."
            ],
            "title": "Individual differences in language acquisition and processing",
            "venue": "Trends in cognitive sciences, 22(2):154\u2013169.",
            "year": 2018
        },
        {
            "authors": [
                "Stav Klein",
                "Reut Tsarfaty"
            ],
            "title": "Getting the ##life",
            "year": 2020
        },
        {
            "authors": [
                "Katharina Kann",
                "Thang Vu."
            ],
            "title": "BPE vs",
            "venue": "mor-",
            "year": 2022
        },
        {
            "authors": [
                "Sch\u00fctze."
            ],
            "title": "Wine is not v i n",
            "venue": "on the compatibility",
            "year": 2021
        },
        {
            "authors": [
                "Barbara Plank",
                "Dirk Hovy",
                "Anders S\u00f8gaard"
            ],
            "title": "Linguistically debatable or just plain wrong? In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume",
            "year": 2014
        },
        {
            "authors": [
                "Alec Radford",
                "Jeffrey Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "venue": "OpenAI blog,",
            "year": 2019
        },
        {
            "authors": [
                "Phillip Rust",
                "Jonas F. Lotz",
                "Emanuele Bugliarello",
                "Elizabeth Salesky",
                "Miryam de Lhoneux",
                "Desmond Elliott."
            ],
            "title": "Language modelling with pixels",
            "venue": "The Eleventh International Conference on Learning Representations.",
            "year": 2023
        },
        {
            "authors": [
                "Phillip Rust",
                "Jonas Pfeiffer",
                "Ivan Vuli\u0107",
                "Sebastian Ruder",
                "Iryna Gurevych."
            ],
            "title": "How good is your tokenizer? on the monolingual performance of multilingual language models",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational",
            "year": 2021
        },
        {
            "authors": [
                "Mike Schuster",
                "Kaisuke Nakajima."
            ],
            "title": "Japanese and korean voice search",
            "venue": "2012 IEEE international conference on acoustics, speech and signal processing (ICASSP), pages 5149\u20135152. IEEE.",
            "year": 2012
        },
        {
            "authors": [
                "Rico Sennrich",
                "Barry Haddow",
                "Alexandra Birch."
            ],
            "title": "Neural machine translation of rare words with subword units",
            "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1715\u20131725,",
            "year": 2016
        },
        {
            "authors": [
                "Patience Stevens",
                "David C Plaut."
            ],
            "title": "From decomposition to distributed theories of morphological processing in reading",
            "venue": "Psychonomic Bulletin & Review, 29(5):1673\u20131702.",
            "year": 2022
        },
        {
            "authors": [
                "Linting Xue",
                "Aditya Barua",
                "Noah Constant",
                "Rami AlRfou",
                "Sharan Narang",
                "Mihir Kale",
                "Adam Roberts",
                "Colin Raffel."
            ],
            "title": "Byt5: Towards a token-free future with pre-trained byte-to-byte models",
            "venue": "Transactions of the Association for Computational Linguis-",
            "year": 2022
        },
        {
            "authors": [
                "Jinbiao Yang",
                "Antal van den Bosch",
                "Stefan L. Frank."
            ],
            "title": "Unsupervised text segmentation predicts eye fixations during reading",
            "venue": "Frontiers in Artificial Intelligence, 5.",
            "year": 2022
        },
        {
            "authors": [
                "Shaked Yehezkel",
                "Yuval Pinter."
            ],
            "title": "Incorporating context into subword vocabularies",
            "venue": "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 623\u2013635, Dubrovnik, Croatia. Association for Com-",
            "year": 2023
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "When we develop natural language processing (NLP) models, we first need to segment a stream of text into small processable units. This preparatory step is known as tokenization and it is more challenging than the segmentation of continuous sensor signals because human language uses symbolic representations. Traditionally, the space-delimited word was considered a meaningful basic unit, but the concept cannot intuitively be mapped to languages with a rich morphological structure such as Turkish or Finnish, or to languages that use a writing system without white spaces such as Chinese.\nMore recently, the focus has shifted to smaller character sequences known as subwords, with the explicit goal of limiting the necessary vocabulary size (which affects model size and performance), and the implicit hope of better approximating semantically-meaningful linguistic units below the word level, i.e., morphemes. In practice, today\u2019s dominant subword tokenization algorithms are purely data-driven. They treat frequent\nsequences as single tokens (e.g., seafood), and split less frequent ones into multiple tokens composed of frequently occurring character sequences (e.g., seabirds \u2192 seab-ird-s). Subword splits might coincide with morpheme boundaries (the plural marker s), but not necessarily (seab).\nPrevious comparisons of tokenization algorithms focused on engineering-oriented desiderata such as processing speed and encoding efficiency, and on the performance of models on downstream NLP tasks (Rust et al., 2021). In this paper, we evaluate subword tokenizers from a cognitive perspective, utilizing lexical decision task measures as a proxy for the processing complexity of individual words. We evaluate the split rates of three tokenization algorithms on various languages. We find significant correlations in line with cognitive expectations, allowing systematic analyses of the influence of parameters such as vocabulary size. We observe that the UnigramLM tokenization algorithm (Kudo, 2018) produces less correlative splits than BPE (Sennrich et al., 2016) and WordPiece (Schuster and Nakajima, 2012), in contrast with previous evaluations made over corpus statistics and downstream tasks (Bostrom and Durrett, 2020). In further experiments, we find that multilingual token vocabularies inhibit tokenizers\u2019 ability to predict cognitive performance as well as signs that current popular vocabulary sizes are insuffi-\ncient for morphologically-rich languages, echoing recent findings (Liang et al., 2023).1"
        },
        {
            "heading": "2 Self-Supervised Tokenization",
            "text": "A tokenizer takes as input a sequence S of characters [c1, . . . , cn] and splits it into non-overlapping substrings, the tokens [t1, . . . , tk], where k \u2264 n. Each token ti consists of a variable number of j consecutive characters (1 \u2264 j \u2264 n), such that the concatenation of the tokens ti yields the sequence S. A tokenizer consists of a vocabulary consisting of m tokens and an algorithm that determines the best splits of the input S into vocabulary items ti. See Mielke et al. (2021) for a detailed survey of tokenization approaches.\nEvaluating Vocabularies Comparative evaluations of tokenization algorithms commonly focus on downstream performance and on cross-lingual differences. Maronikolakis et al. (2021) calculate the tokenization compatibility for pairs of languages and find that the vocabulary size of a tokenizer needs to be adapted to the characteristics of the language. Multilingual language models use a single shared vocabulary for a large number of languages to facilitate cross-lingual transfer, however, Rust et al. (2021) find improvements when these are replaced with targeted monolingual tokenizers. Liang et al. (2023) propose to increase the vocabulary size for multilingual models and assign per-language budgets in a dynamic manner, in order to mitigate effects on the splitting ratio for languages less represented in the vocabularies. They de-emphasize token sharing between languages with little lexical overlap, in line with Chung et al. (2020). Yehezkel and Pinter (2023) propose to incorporate context sensitivity in order to generate more cohesive tokenization and show that their approach leads to increased downstream performance for both English, and the morphologically more complex language Turkish.\nMorphological Evaluation More linguistically motivated evaluations of subword tokenization focus on morphological plausibility. Bostrom and Durrett (2020) compare the BPE and UnigramLM algorithms for English and Japanese and find that the segmentation produced by the latter aligns more closely with morphology and leads to better results on downstream tasks, especially for Japanese. In\n1All analyses are available on github: https://github. com/clap-lab/cogtok\na similar vein, Park et al. (2021) find that BPE does not properly reflect morphological complexity and that enriching the model with explicit morphological information leads to reduced language modeling surprisal. Hofmann et al. (2022) show that a vocabulary with better morphological coverage leads to better performance in genre classification of English titles, and might lead to better generalization capabilities (Hofmann et al., 2021). Other studies have shown that these consistent results in English do not necessarily generalize to other languages (Mager et al., 2022), particularly morphologically-rich ones (Klein and Tsarfaty, 2020).\nMorphological segmentation is related to tokenization, but it is sensitive to phonotactic variations, e.g., discernible is segmented into discern and -able (Batsuren et al., 2022). Nevertheless, the winning system at the SIGMORPHON shared task was based on subword tokenization and outperformed character-based approaches, indicating that subwords can approximate morphological boundaries (Peters and Martins, 2022).\nCognitive Plausibility From a cognitive perspective, it remains an open question to which extent lexical processing is driven by morphological units. One of the most robust effects in lexical decision tasks (Amenta and Crepaldi, 2012) is that morphologically structured non-words cause longer response times and lead to decreased accuracy in word detection. Beyersmann et al. (2020) find that this effect is stronger for German than for French, and suggest that this is due to its larger degree of morphological productivity. Dawson et al. (2021) compare lexical decision times for English words and find that priming with morphological components (teach) leads to faster responses (teacher) even if the prime has no semantic relation (corn \u2192 corner). (Yang et al., 2022) show that the prediction of eye fixations is facilitated for English and Dutch readers by operating on subtokens determined by unsupervised tokenizers instead of word units. Stevens and Plaut (2022) claim that effects attributed to morphological decomposition cannot be easily disentangled from frequency effects, and urge NLP researchers to integrate response times into the evaluation of distributional approaches."
        },
        {
            "heading": "3 Experimental Setup",
            "text": "We train three tokenization algorithms on 100,000 sentences from the news domain of the Leipzig\ncorpus (Biemann et al., 2007),2 and introduce the chunkability metric to evaluate tokenizer output against cognitive data from a lexical decision task.\nTokenization Models We use the Huggingface implementations of three corpus-based subword algorithms: byte-pair encoding (BPE), WordPiece (WPC), and Unigram (UNI).3\nBPE originated as a compression algorithm (Gage, 1994; Sennrich et al., 2016) and has been used in large pre-trained language models such as GPT-2 (Radford et al., 2019). BPE vocabularies are built bottom-up, starting with an initial vocabulary of all characters. The algorithm then iteratively merges sequences of characters frequent in the corpus and adds them as tokens to the vocabulary until reaching the maximum size. During inference, an input sequence is greedily split into tokens aiming for a minimum number of splits, see Gall\u00e9 (2019) for a more detailed description. WordPiece (Schuster and Nakajima, 2012) is a variant of BPE which adds tokens to the vocabulary when they maximally increase the likelihood of an n-gram-based language model in the corpus, and is decoded greedily left-to-right to find the locally longest token available at each step. The UnigramLM (Kudo, 2018) algorithm, in contrast, takes a top-down approach starting with an overly large vocabulary of all possible tokens, followed by iteratively pruning those that lead to minimal loss of likelihood over the corpus when they are removed from a token-unigram language model.\nCognitive Data We use data from lexical decision tasks in British English (Keuleers et al., 2012), Dutch (Keuleers et al., 2010), French (Ferrand et al., 2010), and Spanish (Aguasvivas et al., 2018). In these tasks, participants are presented with a sequence of characters, e.g., thornier, and decide whether the sequence forms a valid word in\n2In pilot experiments, we explored larger training sizes but did not observe relevant differences.\n3https://github.com/huggingface/tokenizers. We focus on character-segment models, while other approaches operate on the single character, byte, or pixel level (Clark et al., 2022; Xue et al., 2022; Rust et al., 2023).\ntheir first language. The datasets contain information about the average response time (i.e., the number of milliseconds it took the participants to make a decision)4 and accuracy for each stimulus. Table 2 provides an overview of the number of participants and stimuli for each dataset. Each participant only saw a subset of the stimuli; further details about the data collection are available in the original references. Since the Spanish study was a crowd-sourcing project, we removed outliers with a reported response time in the first and last percentiles (<484 and >7,753 ms, respectively).\nMetric A sequence of characters [c1, . . . , cn] is split into tokens [t1, . . . , tk]. We base our metric on the intuition that fewer splits generally indicate a better fit and that longer sequences are more likely to be split. Our metric therefore takes both n and k into account to measure how well the tokenizer handles the sequence. We define the chunkability of a sequence as a value that decreases as the ratio of tokens over characters increases:\nchunkability = 1\u2212 #tokens #chars = 1\u2212 k n . (1)\nIf a token is split into individual characters, chunkability is zero. For tokens that are not split, chunkability approaches one as the number of characters increases, reflecting the increasing challenge of fitting long words into the vocabulary.5"
        },
        {
            "heading": "4 Results",
            "text": "We test the hypothesis that sequences with higher chunkability are easier to process for humans and are more likely to be considered words. Figure 1 visualizes Pearson\u2019s correlation between the chunkability of a sequence and the response time and accuracy observed from humans rating the sequence, and Table 1 illustrates some typical examples. We can see that for a sequence that qualifies as a word, like seafood, a higher chunkability score (i.e., easier processing by the tokenizer) is likely to co-occur with higher accuracy and a lower response time. For non-words, we observe the reverse tendencies: non-word sequences with a high chunkability such as catchwind require longer response times and\n4While this duration is usually characterized as reading time in the resources, we agree with the observation of a reviewer that it remains unclear how much time the participants spend reading and use the term response time instead.\n5For comparison, we also ran our experiments by using the number of splits (without normalization) as our metric, see Appendix B.\nare less accurately identified as non-words than an unusual sequence such as brithbloom. These patterns are consistent across algorithms and languages, whereas a baseline that only considers character length cannot capture the effect (longer sequences generally lead to longer response times). The correlation for the UnigramLM algorithm is systematically lower than for the other two algorithms, suggesting a contrast with morphology- and corpus-based measures considered by Bostrom and Durrett (2020). For French, chunkability seems to be less correlated with human responses, echoing findings related to cognitive performance in a morphologically-primed environment (Beyersmann et al., 2020).\nWhile the absolute correlation scores might be of limited explanatory value, we find the relative differences between conditions a relevant point of information for further development.6\n6For a complementary perspective, we ran a linear regression analysis on the words to compare to a frequency measure which can be found in Appendix C. We are also considering alternative correlation metrics such as Spearman\u2019s, Kendall\u2019s, and Goodman-Kruskal. Initial analyses indicate that they capture similar tendencies.\nCross-lingual Vocabulary It has been shown that the \u201ccurse of multilinguality\u201d reduces the performance of multilingual models compared to their monolingual counterparts (Conneau et al., 2020). Rust et al. (2021) show that this difference in performance is strongly related to the tokenizer. We compare cognitive plausibility of monolingual and cross-lingual tokenizers of pretrained models in Figure 2, and affirm that the monolingual tokenizer aligns much better with human responses than the cross-lingual ones.7 See also Appendix D.\nVocabulary Size and Morphology The chunkability values vary with the size of the vocabulary of the tokenizers. Figure 3 shows how the correlation with human responses increases with the vocabulary size of the WordPiece tokenizer until\n7We use the following huggingface models: GroNLP/bertbase-dutch-cased (Dutch), bert-base-uncased (English), camembert-base (French), dccuchile/bert-base-spanish-wwmuncased (Spanish), bert-base-multilingual-uncased and xlmroberta-base (crosslingual). BERT-based models use WordPiece tokenization, XLM-RoBERTa uses BPE.\nit plateaus for most languages at 50,000.8 To test whether this effect may be related to morphological coverage, we use morphological annotations for 13 languages from the SIGMORPHON shared task (Batsuren et al., 2022) and extract an inventory of derivational morphemes for each language. We only used derivational morphemes which occur in at least 0.1% of the annotations (to avoid rare morphemes such as oculo), yielding between 80 and 140 derivational morphemes per language. From the coverage curves in Figure 4, we see that derivational coverage increases with vocabulary size, but morphologically-rich languages such as Russian, Polish, and Mongolian remain unsaturated even with a vocabulary size of 50,000. This suggests that previous work on morphological segmentation which used significantly smaller vocabulary sizes (e.g., Peters and Martins, 2022) did not uncover the full potential of the approach. We also see that WordPiece tokens overall provide better coverage of morphemes than UnigramLM, reinforcing our findings from the previous experiments."
        },
        {
            "heading": "5 Conclusion",
            "text": "We propose a new evaluation paradigm for comparing subword tokenization algorithms using cognitive data. We introduce a novel metric to capture the chunkability of a sequence that correlates with cognitive phenomena of lexical recognition. The overall trends suggest that the connection between plausibility tasks and segmentation is meaningful enough to be used as a benchmark. We find a lower cognitive correlation for the UnigramLM algorithm than for WordPiece and BPE, which does not nec-\n8The tendencies for BPE and UNI are comparable.\nessarily align with previous work evaluating tokenizers on morphological segmentation and downstream performance, suggesting that our framework provides a complementary perspective to tokenizer vocabulary evaluation. Our analyses on vocabulary size and morphological coverage provide initial insights towards the development of cognitively and linguistically more plausible tokenizers.\nLimitations\nOur cognitive analyses are limited to two Romance and two Germanic languages. The response times were collected as separate experiments with slight variations in the data collection procedure (i.e., number of stimuli per participant, background of participants) and might not be directly comparable. We average over the responses, which may conceal individual differences between respondents (Plank et al., 2014; Kidd et al., 2018; Pavlick and Kwiatkowski, 2019). Pearson\u2019s \u03c1 has a tendency to pick up spurious correlations (Aldrich, 1995), which is why we abstract from absolute values and focus on relative differences between conditions. The quality of the selection of derivational morphemes is determined by the characteristics of the SIGMORPHON datatset.\nEthics Statement\nWe use datasets that have been fully anonymized and adhere to ethical guidelines for data collection. Our analyses do not reveal metadata of the participants that would enable identification. Claims about cognitive plausibility need to be made with caution because the procedural patterns underlying human language processing still remain an open research question. We have therefore paid special attention to a realistic interpretation of our results and avoid overpromising messages (Lipton and Steinhardt, 2019)."
        },
        {
            "heading": "Acknowledgements",
            "text": "Lisa Beinborn\u2019s work was supported by the Dutch National Science Organisation (NWO) through the VENI program (Vl.Veni.211C.039). Yuval Pinter\u2019s work was supported by a Google gift intended for work on Meaningful Subword Text Tokenization. We thank the reviewers for their thoughtful comments. We thank Joshua Snell and Omri Uzan for comments on early drafts."
        },
        {
            "heading": "A Language Codes",
            "text": "The abbreviations used in Figure 4 correspond to ISO 639-3 codes and are mapped as follows: swe = Swedish, deu= German, eng= English, cat= Catalan, spa= Spanish, fra= French, ita= Italian, por= Portuguese, hbs= Serbo-Croatian, ces= Czech, rus= Russian, pol= Polish, hun= Hungarian, fin= Finnish, mon= Mongolian."
        },
        {
            "heading": "B Number of Splits",
            "text": "In the chunkability metric, we normalize by the length of the sequence. For comparison, we also ran our experiments by simply using the number of splits as a metric. The tendencies in the results in Figure 5 are comparable for the two metrics except for the correlations with the response time for nonwords which are substantially less consistent with cognitive phenomena for the number-of-splits measure. We assume that this can be explained through the finer range of values afforded by chunkability."
        },
        {
            "heading": "C Regression Analysis",
            "text": "In this paper, we focus on the evaluation of subword tokenizers and not on predicting cognitive phenomena. However, one of the reviewers inspired us to run a demonstrative linear regression analysis for the words in the dataset. For all four languages, we found that both chunkability and\nfrequency obtained similar low mean squared error (0.00\u20130.06) on the test data for both response time and accuracy. However, all explained variance scores are negative (with systematically higher scores when predicting with frequency and particularly low scores for French and Dutch response times). We assume that the low explained variance is related to the finegrained cognitive signal and to individual differences in the responses. Prediction would probably be easier when predicting classes (e.g., high/low) instead of absolute values. We are interested in diving deeper into these pilot analyses in cooperation with cognitive scientists. Finally, we note that while frequency is only available for true words, chunkability can be a proxy for frequency effects in non-words as well."
        },
        {
            "heading": "D Four-lingual Vocabulary",
            "text": "In order to better control the effect of vocabulary sharing, we also trained tokenizers on all the English, Dutch, French, and Spanish training data jointly. Figure 6 illustrates the results for the WordPiece tokenizer and shows that the correlation is lower for multilingual models but improves when increasing the vocabulary."
        }
    ],
    "title": "Analyzing Cognitive Plausibility of Subword Tokenization",
    "year": 2023
}