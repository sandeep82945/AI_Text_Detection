{
    "abstractText": "Continual learning for named entity recognition (CL-NER) aims to enable models to continuously learn new entity types while retaining the ability to recognize previously learned ones. However, the current strategies fall short of effectively addressing the catastrophic forgetting of previously learned entity types. To tackle this issue, we propose the SKD-NER model, an efficient continual learning NER model based on the span-based approach, which innovatively incorporates reinforcement learning strategies to enhance the model\u2019s ability against catastrophic forgetting. Specifically, we leverage knowledge distillation (KD) to retain memory and employ reinforcement learning strategies during the KD process to optimize the soft labeling and distillation losses generated by the teacher model to effectively prevent catastrophic forgetting during continual learning. This approach effectively prevents or mitigates catastrophic forgetting during continuous learning, allowing the model to retain previously learned knowledge while acquiring new knowledge. Our experiments on two benchmark datasets demonstrate that our model significantly improves the performance of the CLNER task, outperforming state-of-the-art methods.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Yi Chen"
        },
        {
            "affiliations": [],
            "name": "Liang He"
        },
        {
            "affiliations": [],
            "name": "Lei Wang"
        },
        {
            "affiliations": [],
            "name": "Zhenxiang Han"
        }
    ],
    "id": "SP:0fba2b3fa673ca8bae14c4a5571851f9d96b157f",
    "references": [
        {
            "authors": [
                "Wen Bo",
                "Honglei Li",
                "Shiyu Wang",
                "Jun Guo",
                "Tongliang Liu",
                "Dacheng Tao."
            ],
            "title": "A minimax game for instance based selective transfer learning",
            "venue": "KDD, pages 34\u201343.",
            "year": 2019
        },
        {
            "authors": [
                "Liang Chen",
                "Alessandro Moschitti."
            ],
            "title": "Transfer learning for sequence labeling using source model and target data",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 6260\u20136267.",
            "year": 2019
        },
        {
            "authors": [
                "Sarkar Snigdha Sarathi Das",
                "Arzoo Katiyar",
                "Rebecca Passonneau",
                "Rui Zhang."
            ],
            "title": "CONTaiNER: Few-shot named entity recognition via contrastive learning",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics",
            "year": 2022
        },
        {
            "authors": [
                "Matthias De Lange",
                "Rahaf Aljundi",
                "Marc Masana",
                "Sarah Parisot",
                "Xu Jia",
                "Ales Leonardis",
                "Gregory Slabaugh",
                "Tinne Tuytelaars."
            ],
            "title": "Continual learning: A comparative study on how to defy forgetting in classification tasks",
            "venue": "arXiv preprint arXiv:1909.08383,",
            "year": 2019
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "arXiv preprint arXiv:1810.04805.",
            "year": 2018
        },
        {
            "authors": [
                "Ning Ding",
                "Guangwei Xu",
                "Yulin Chen",
                "Xiaobin Wang",
                "Xu Han",
                "Pengjun Xie",
                "Haitao Zheng",
                "Zhiyuan Liu."
            ],
            "title": "Few-NERD: A Few-shot Named Entity Recognition Dataset",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational",
            "year": 2021
        },
        {
            "authors": [
                "Jinlan Fu",
                "Xuanjing Huang",
                "Pengfei Li."
            ],
            "title": "Spanner: Named entity re-/recognition as span prediction",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 6718\u20136726.",
            "year": 2021
        },
        {
            "authors": [
                "Prakhar Gupta",
                "Yatin Chaudhary",
                "Thomas A Runkler",
                "Hinrich Sch\u00fctze."
            ],
            "title": "Neural topic modeling with continual lifelong learning",
            "venue": "International Conference on Machine Learning, pages 3907\u20133917.",
            "year": 2019
        },
        {
            "authors": [
                "Geoffrey Hinton",
                "Oriol Vinyals",
                "Jeff Dean."
            ],
            "title": "Distilling the knowledge in a neural network",
            "venue": "arXiv preprint arXiv:1503.02531, 2(7).",
            "year": 2015
        },
        {
            "authors": [
                "Eduard Hovy",
                "Mitchell Marcus",
                "Martha Palmer",
                "Lance Ramshaw",
                "Ralph Weischedel."
            ],
            "title": "OntoNotes: The 90% Solution",
            "venue": "Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, pages 57\u201360, New",
            "year": 2006
        },
        {
            "authors": [
                "Xinting Hu",
                "Kaihua Tang",
                "Chunyan Miao",
                "Xian-Sheng Hua",
                "Hanwang Zhang."
            ],
            "title": "Distilling causal effect of data in class-incremental learning",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3957\u20133966.",
            "year": 2021
        },
        {
            "authors": [
                "Fei Yuan||Linjun"
            ],
            "title": "Shou||Jian Pei||Wutao Lin||Ming Gong||Yan Fu||Daxin Jiang",
            "year": 2023
        },
        {
            "authors": [
                "Xisen Jin",
                "Dejiao Zhang",
                "Henghui Zhu",
                "Wei Xiao",
                "Shang-Wen Li",
                "Xiaokai Wei",
                "Andrew Arnold",
                "Xiang Ren."
            ],
            "title": "Lifelong pretraining: Continually adapting language models to emerging corpora",
            "venue": "Proceedings of the 2022 Conference of the North",
            "year": 2022
        },
        {
            "authors": [
                "Diederik P Kingma",
                "Jimmy Lei Ba."
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "International Conference on Learning Representations.",
            "year": 2015
        },
        {
            "authors": [
                "Y. Lecun",
                "L. Bottou",
                "Y. Bengio",
                "P. Haffner."
            ],
            "title": "Gradient-based learning applied to document recognition",
            "venue": "Proceedings of the IEEE, 86(11):2278\u20132324.",
            "year": 1998
        },
        {
            "authors": [
                "Michael McCloskey",
                "Neal J. Cohen."
            ],
            "title": "Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem",
            "venue": "Gordon H. Bower, editor, Psychology of Learning and Motivation, volume 24, pages 109\u2013165. Academic Press.",
            "year": 1989
        },
        {
            "authors": [
                "Natawut Monaikul",
                "Giuseppe Castellucci",
                "Simone Filice",
                "Oleg Rokhlenko."
            ],
            "title": "Continual learning for named entity recognition",
            "venue": "Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications",
            "year": 2021
        },
        {
            "authors": [
                "German I. Parisi",
                "Ronald Kemker",
                "Jose L. Part",
                "Christopher Kanan",
                "Stefan Wermter."
            ],
            "title": "Continual lifelong learning with neural networks: A review",
            "venue": "Neural Networks: The Official Journal of the International Neural Network Society, 113:54\u201371.",
            "year": 2019
        },
        {
            "authors": [
                "Rajkumar Ramamurthy",
                "Prithviraj Ammanabrolu",
                "Kiant\u00e9 Brantley",
                "Jack Hessel",
                "Rafet Sifa",
                "Christian Bauckhage",
                "Hannaneh Hajishirzi",
                "Yejin Choi"
            ],
            "title": "Is reinforcement learning (not) for natural language processing?",
            "year": 2022
        },
        {
            "authors": [
                "Anthony Robins."
            ],
            "title": "Catastrophic forgetting, rehearsal and pseudorehearsal",
            "venue": "Connection Science, 7(2):123\u2013146.",
            "year": 1995
        },
        {
            "authors": [
                "Chuck Rosenberg",
                "Martial Hebert",
                "Henry Schneiderman."
            ],
            "title": "Semi-supervised self-training of object detection models",
            "venue": "Proceedings of the Seventh IEEE Workshops on Application of Computer Vision (WACV/MOTION\u201905)-Volume 1-Volume 01, pages",
            "year": 2005
        },
        {
            "authors": [
                "Sebastian Ruder"
            ],
            "title": "Neural machine translation and sequence-to-sequence models: A tutorial using examples from numerous languages",
            "year": 2019
        },
        {
            "authors": [
                "Hanul Shin",
                "Jung Kwon Lee",
                "Jaehong Kim",
                "Jiwon Kim."
            ],
            "title": "Continual learning with deep generative replay",
            "venue": "Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS\u201917, page 2994\u20133003, Red Hook, NY, USA.",
            "year": 2017
        },
        {
            "authors": [
                "Jianlin Su",
                "Ahmed Murtadha",
                "Shengfeng Pan",
                "Jing Hou",
                "Jun Sun",
                "Wanwei Huang",
                "Bo Wen",
                "Yunfeng Liu"
            ],
            "title": "Global pointer: Novel efficient span-based approach for named entity recognition",
            "year": 2022
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Proceedings of the 31st International Conference on Neural Information Processing Sys-",
            "year": 2017
        },
        {
            "authors": [
                "Yu Xia",
                "Quan Wang",
                "Yajuan Lyu",
                "Yong Zhu",
                "Wenhao Wu",
                "Sujian Li",
                "Dai Dai."
            ],
            "title": "Learn and review: Enhancing continual named entity recognition via reviewing synthetic samples",
            "venue": "Findings of the Association for Computational Linguistics: ACL 2022,",
            "year": 2022
        },
        {
            "authors": [
                "Yuanmeng Zhang",
                "Qianqian Yang",
                "Yanghua Liu",
                "Maosong Sun."
            ],
            "title": "Syntax-enhanced entity and relation extraction with graph convolutional networks",
            "venue": "Proceedings of the Thirty-Fifth AAAI Conference on Artificial Intelligence, pages 7255\u20137263.",
            "year": 2021
        },
        {
            "authors": [
                "Yunan Zhang",
                "Qingcai Chen."
            ],
            "title": "A neural spanbased continual named entity recognition model",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence.",
            "year": 2023
        },
        {
            "authors": [
                "Junhao Zheng",
                "Zhanxian Liang",
                "Haibin Chen",
                "Qianli Ma."
            ],
            "title": "Distilling causal effect from miscellaneous other-class for continual named entity recognition",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "The introduction of continual learning methods has enabled systems to continuously learn from new data and reduce their dependence on initial training data. Moreover, these methods facilitate model updates and fine-tuning, enhancing their scalability (Shin et al., 2017). By combining continual learning with NER tasks, systems can significantly improve their ability to perceive the constantly changing real world amidst the emergence of new tasks and data sources, these functionalities can be formulated as paradigms of continual learning (Jin\n\u2217Corresponding author. 1Code is available at https://github.com/YChen2637/SKD\net al., 2022; Parisi et al., 2019). However, continual learning has always faced catastrophic forgetting, which has become a pervasive issue for continual learning NER tasks (McCloskey and Cohen, 1989; Robins, 1995; Kirkpatrick et al., 2017). Specifically, simply fine-tuning the NER system based on new data often results in a significant drop in performance on previously learned tasks, which poses a major challenge for achieving human-level intelligence in continual learning for NER (CL-NER). This is in contrast to the natural ability of humans to learn new entity categories without forgetting previously learned ones.\nIn the context of continual learning, the model training process is typically divided into n CL steps, with each step being specific to the current task. In the case of CL-NER, only new entity types are recognized in each CL step. However, this approach can lead to a situation that is easily overlooked, whereby entity types that are not required to be recognized in the current step (e.g., ORG) may need to be learned in the future or have been learned in\nthe past. In traditional sequence labeling methods,\nan entity that is not a required type in the current step is assigned a global O tag to indicate that the model does not need to recognize this type in the current task(refer to Figure1). However, this can result in each entity\u2019s category needing frequent parameter updates in each different CL step, due to this incoherent optimization. We believe this exacerbates catastrophic forgetting and label noise interference. To test this hypothesis, we conducted experiments, the results of which are presented in Figure2.\nWith the goal of addressing the issues of catastrophic forgetting and label noise in CL-NER (Lecun et al., 1998), we propose SKD-NER. To mitigate the adverse effects of frequent parameter updates due to incoherent optimization in continuous learning, our model first computes an entity classification matrix for each segment of text to be processed, inspired by the multi-headed attention mechanism (Vaswani et al., 2017). This matrix computes a score for the different entity classes to be recognized, thereby converting the entity recognition problem into a binary classification problem. In the CL setting, we enable the model to perform well in multi-label learning on the span classification, while equipping it with knowledge distillation at the span entity level based on the Bernoulli distribution it produces. To address the label noise problem in the incremental learning process, we introduce a reinforcement learning strategy for the student model in the knowledge distillation process (Jiang, 2023), using the most suitable knowledge distillation method for the current student model. For model prediction, we introduce a multi-label classification loss function (Su et al., 2022), which\nfits well with our sequence labeling approach. This approach offers several advantages: 1) It allows for knowledge distillation and retention of old knowledge during the CL process. 2) The introduction of reinforcement learning effectively reduces label noise while also addressing the issue of catastrophic forgetting that arises due to frequent weight updates for the same entity in different steps based on different categories. 3) The proposed framework of the model can be used as a reusable framework for continuous learning knowledge distillation and applied to other model migration or continuous learning domains.\nWe evaluated our model on two Named Entity Recognition (NER) datasets, namely OntoNotes5(Hovy et al., 2006), and Fewnerd(Ding et al., 2021). The experimental results demonstrate that our proposed SKD-NER model significantly outperforms existing continuous learning NER models and achieves a new state-of-the-art (SOTA) performance. Notably, SKD-NER almost eliminates catastrophic forgetting on relatively simple OntoNotes, thereby achieving \"continuous learning\" in the true sense. Our contributions can be summarized as follows:\n\u2022 We propose a Continual Named Entity Recognition model and a reinforcement learningbased knowledge distillation framework that ensures the model\u2019s effectiveness for continuous learning, which can be further leveraged in other fields of continuous learning or knowledge transfer. \u2022 Innovatively introduce reinforcement learning strategies to support Continual Named Entity Recognition, while optimizing traditional sequence labeling methods and loss functions to address catastrophic forgetting and label noise problems in continuous learning. \u2022 Through extensive experiments, we demonstrate that our approach achieves state-of-theart performance in Continual Named Entity Recognition and can be seamlessly integrated as a plug-and-play module to further enhance the performance of other Continual Named Entity Recognition models."
        },
        {
            "heading": "2 Related Work",
            "text": ""
        },
        {
            "heading": "2.1 Continual Learning NER",
            "text": "Recent research has expanded the application of Continual Learning (CL) from Computer Vision to Natural Language Processing (NLP) tasks, par-\nticularly NER. While most CL-related works in computer vision focus on accuracy-oriented tasks like image classification, their direct application to CL-NER has shown unsatisfactory performance due to challenges in preserving old knowledge in Other-class samples.\nChen and Moschitti (2019) pioneered the study of knowledge transfer in sequence labeling NER models from source to target domains with new entities, using a neural adapter module to handle diverse entity distributions. Following this, AddNER, ExtendNER (Monaikul et al., 2021), and LR (Xia et al., 2022) were developed under a classincremental setting for CL-NER, employing sequence labeling methods with knowledge distillation. AddNER uses a multi-head approach, while ExtendNER and LR employ single-head layouts with different strategies for handling O tags and old entity mentions. However, current methods such as AddNER and ExtendNER still face forward incompatibility issues and require cumbersome cooperation with knowledge distillation. SpanKL(Zhang and Chen, 2023) explores the potential of spanbased models for solving CL-NER with Excellent forward compatibility to solve this problem.\nIn the context of CL-NER, token-noise is also a very important issue to be concerned about, selftraining (Rosenberg et al., 2005; De Lange et al., 2019) has been a straightforward solution for learning old knowledge from Other-class samples. However, this approach suffers from error propagation between models. Recently, Das et al. (2022) have proposed contrastive learning and pretraining techniques to address the problem of token-noise in few-shot NER. CFNER (Zheng et al., 2022) proposes a causal framework in CL-NER that explicitly addresses the challenges posed by token-noise. In contrast, Our approach utilizes reinforcement learning strategies to adjust the process of knowledge distillation, optimizing the process and ensuring the forward compatibility of the model, while also addressing the issue of token-noise to some extent."
        },
        {
            "heading": "2.2 Reinforcement learning",
            "text": "Reinforcement learning has found wide application in natural language processing, including machine translation, dialogue systems, and text summarization. More recently, researchers have focused on the potential of RL in the field of continuous learning for natural language processing, with the aim of\ndeveloping models that can learn new tasks while retaining the memory of previously learned knowledge. For example, Ruder (2019) uses RL to finetune pre-trained models with a combination of different reinforcement learning strategies to adapt them to new tasks. Bo et al. (2019) leverages a selector to choose source domain data that is close to the target and accepts rewards from both the discriminator and transfer learning module. Ramamurthy et al. (2022) present NLPO (Natural Language Policy Optimization), a policy optimizationbased RL algorithm that dynamically learns taskspecific constraints on language distribution.\nInspired by these studies, in this work, we use RL to expertly select appropriate distillation temperature and loss weights for knowledge distillation to support continuous learning. This approach successfully mitigates the impact of catastrophic forgetting on model recognition accuracy during continuous learning."
        },
        {
            "heading": "3 Our Approach",
            "text": "In this section, we will first introduce the task setting for Continual Learning Named Entity Recognition (NER). After presenting the overall structure of the SKD-NER model, we provide a detailed explanation of how the model integrates reinforcement learning strategies."
        },
        {
            "heading": "3.1 Problem Formulation",
            "text": "Taking into account the non-overlapping nature of entity types in continual learning NER tasks, we follow recent work and propose CL-NER (Xia et al., 2022) in an incremental setting. Given a series of tasks T1, T2, ..., Tn and their corresponding training sets D1, D2, ..., Dn, for each task Tn, a new entity type to be recognized and its training set Dn with annotations for the current entity type are defined.\nSpecifically, we first define a task T1 and train a model M1 on the dataset D1 to recognize the entity type E1. Then, task T2 defines the model M2 to recognize a new entity type E2 on the dataset D2. It is noteworthy that M2 is obtained through knowledge distillation with reinforcement learning based on M1 to achieve the ability to recognize entity type E2 while retaining the ability to recognize entity type E1. Similarly, in the following n incremental steps, we train the previous model Mn \u2212 1 on the dataset Dn to obtain the new model Mn, while incorporating a reinforcement learning\nstrategy into the knowledge distillation process to ensure the recognition of all entity types defined so far and to reduce catastrophic forgetting and the impact of label noise on the model."
        },
        {
            "heading": "3.2 SKD-NER Model",
            "text": "We have introduced an innovative and effective SKD-NER model (refer to Fig. 3) that can learn diverse entity types in a sequential manner for each task. The model takes an input sentence X comprising n tokens: [x1, x2, ..., xn]. We define a \"span\" as a cohesive sequence of tokens that initiate with xi and culminate with xj , where 1 \u2264 i \u2264 j \u2264 n. At the l-th incremental step, the SKD-NER model endeavors to represent each span in a matrix hk. In this matrix, each span consisting of contiguous tokens sij is assigned a label corresponding to the current K-th entity class. The SKD-NER model consists of the contextual encoder, Span prediction layer, label loss layer, and the RL-KD (reinforcement learning for knowledge distillation) strategy layer. Contextual Encoder. Given an input sentence X comprising n tokens [x1, x2, ..., xn], to capture the dependence between tokens within input sentences, we link each token in X with its corresponding representation in a pre-training language model (e.g., BERT). We define E = [e1, e2, . . . , en] \u2208 Rn\u00d7de to represent the embedded vectors of input X . After PLM processing, We end up with a new\nmatrix H \u2208 Rn\u00d7dh , for each token as:\nh1, h2, . . . , hn = PLM(x1, x2, . . . , xn) (1)\nSpan Prediction Layer. Many scholars have thoroughly explored the generation of Span Prediction from tokens and have achieved quite effective results. However, due to the structural bias of Span Prediction which has not been fully understood, Fu et al. (2021) treated span prediction as a system combiner to re-identify named entities from the outputs of different systems. In order to further improve the recognition accuracy of NER models for nested or overlapping discontinuous entities, Zhang et al. (2021) used text syntax dependency to guide the construction of a graph convolutional model to achieve Span Prediction, while Su et al. (2022) employed a multi-head attention mechanism to compute the span matrix. We adopted the latter method, using the starting position token and ending position token of the entity processed by two feedforward layers for dot product calculation to obtain the prediction of the span. Now that we have obtained the representation hn of the sentence, the process of representing spans can be described as follows:\ns(i, j) = SpanPre[hi, hi+1, . . . , hj ] (2)\nsa(i, j) = FFNi,a(hi)\u22a4FFNj,a(hj) (3)\nWhere a represents the a-th type of entity to be identified, i represents the starting position token, and j represents the ending position token. In order to fully utilize boundary information, we introduced the Relative Position Encoding (ROPE) during the span prediction process Su et al. (2022). This encoding explicitly injects relative position information into the model. Specifically, after injecting ROPE position encoding, span sa(i, j) can be represented as follows:\nsa(i, j) = FFNi,a(hiRi)\u22a4FFNj,a(hjRj)\n= FFNi,a(hi)\u22a4R(j\u2212i)FFNj,a(hj) (4)\nLabel Loss Layer. Building on the span-based method, we generated a marked global uppertriangle matrix for each sentence to be learned. To address this upper-triangle matrix, we devised a scoring function to characterize the relationship between span and the current entity type as follows:\n\u2126i,j =  1 i \u2264 j \u2227 (i, j) \u2208 Pa 0 i \u2264 j \u2227 (i, j) /\u2208 Na\n\u2212 inf i > j; (5)\nHere, Pa represents the positive set of entities of type a and Na represents the negative set of entities of type a. To enhance the ability of continuous learning NER to recognize entities in the current task, we introduced a span-based cross-entropy loss. This loss not only encourages the model to better learn boundary information but also ensures forward comparability of the model\u2019s predictions during the continuous learning process.\nLspan = log 1 + \u2211 1\u2264i\u2264j\u2264L exp ( (\u22121)\u2126i,j sa(i, j) ) (6)"
        },
        {
            "heading": "3.3 RL-KD strategy layer",
            "text": "To preserve the model\u2019s recognition ability for previously learned entity types, we employ knowledge distillation (Gupta et al., 2019; Hinton et al., 2015) to prevent catastrophic forgetting. Specifically, in the K-th incremental step (K > 1), we first use the previously learned model Mk (teacher model) to make a one-pass prediction on the entire current training set Dl, up to the entity type Ek learned in the previous step of the current task. During this process, we introduce a reinforcement learning strategy to optimize the distillation temperature\n(see Fig.4), which will act on the Bernoulli distributions qi of soft distillation labels for each span of each old entity type. Specifically, during the soft distillation process, the original probability distribution zi is typically normalized by the softmax and then multiplied by a temperature factor T to obtain a smoothed probability distribution:\nqi = exp (zi/T )\u2211 j exp (zj/T )\n(7)\nThese pseudo-labels are used to compute the Bernoulli KL divergence loss of the current model Mk + 1 (student model):\nLSKDKD = KL ( pMk Ek , p Mk+1 Ek ) (8)\nHere, Ek denotes all the learned entity recognition types up to the current step, pMk represents the soft distillation labels generated by the teacher model, and pMk+1 represents the labels produced by the student model for the previous entity types.\nAs with all knowledge distillation works, after onepass prediction at each step, the final knowledge distillation loss is:\nL = \u03b1Lspan + \u03b2LKD (9) State. Our reinforcement learning approach maintains a sequence of environment states\ns1, s2, ..., sj . They summarize the input instance and the features of the teacher model, enabling wise decisions to be made accordingly. We design sj as a vector of real numbers F (sj), which includes the concatenation of three features. The first feature is the vector representation R(xi) \u2208 Rd of the input instance xi. In this paper, we use the score matrix obtained by the span prediction layer as the semantic representation input. The second feature is the prediction by the teacher model Mk on the current input text sequence xi for all k types already identified before the (k + 1)-th task. The third feature is the loss of the student model on the input text sequence xi, which is the actual loss of the new entity types that the student model needs to recognize for the current task. Action. The soft labels generated by the teacher model are associated with the distillation temperature and the distillation loss weight during the knowledge distillation process. The agent adjusts the distillation temperature and the weight of the distillation loss for the current teacher model. The policy function \u03c0\u03b8(sj , aj) determines a distribution over actions on a state, from which an action value aj \u2208 {0, 1} is sampled. \u03b8 represents the trainable parameters in the policy function.\n\u03c0\u03b8 (sj , aj) = [ temp (sj , aj) , klweight (sj , aj)] (10)\ntemp (sj , aj) = aj [T +AF (sj)] + (1\u2212 aj)T (11)\nklweight (sj , aj) = min [aj(weight\n+BF (sj)) + (1\u2212 aj)weight, 0.1] (12)\nwhere F (sj) \u2208 Rd+(C+1) is the state vector and trainable parameter \u03b8 = {A \u2208 Rd+(C+1), b \u2208 R1} The result of the above strategy function definition is an adjusted value assigned to two key parameters in the knowledge distillation process. Reward. The reward function is related to the performance of the student model trained from the distillation of the teacher model. We define a batch of training instances, denoted as \u03beb = {xi, xi+1, . . . , xi+m\u22121}, where b represents the batch ID and m represents the batch size. For each instance xj(i \u2264 j \u2264 i + m \u2212 1), we construct a state vector sjk for each teacher model Mk, and sample an action ajk according to the policy \u03c0\u03b8(skj , a k j ) (Eq.10). For all sampled ajk, we integrate the average of the KL loss (Eq.8) into\nthe distillation loss KD (Eq.7) to train the student model. To incentivize better model generalization, we use the accuracy metric on the development set D0 and the student model loss as the reward, where \u03b3 is a hyperparameter balancing the reward from the training set and the development set. Note that the reward is not given immediately after each step is taken. Instead, it is deferred until the completion of the entire batch training.\nreward =\u03b3 \u2217 (\u2212LCE \u2212 LDL) + (1\u2212 \u03b3) \u2217 Accuracy on D0 (13)"
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Settings",
            "text": "Datasets. We conduct experiments on two widely used datasets, i.e., OntoNotes5 (Hovy et al., 2006), (Ding et al., 2021). Meanwhile, we follow recent works (Monaikul et al., 2021; Xia et al., 2022) to convert the widely used standard NER corpora into separated datasets acting as a series of CL synthetic tasks in class-incremental setting. Both datasets, OntoNotes5 and FewNerd, reflect the model\u2019s performance in continual learning tasks to some extent. OntoNotes5 requires only one entity type to be learned for each task, which can reflect the model\u2019s performance in simple continual learning tasks. FewNerd, on the other hand, requires multiple entity types to be learned for each task, thereby reflecting the model\u2019s performance in more complex continual learning tasks closer to real-world scenarios. We placed the more detailed dataset settings in the appendixA. Training. We use bert-large-cased (Devlin et al., 2018) as the contextual encoder for our model. To split the original training/development set into a series of CL tasks, we randomly divide the samples into unrelated tasks, following previous work (Monaikul et al., 2021). We pre-define a fixed order of classes as the setting for the CL order, as in previous CL work (Hu et al., 2021). However, to avoid excessive randomness in the experiments, we pre-define multiple entity class learning orders for both datasets, and the final experimental results are the average of the results under multiple learning orders. The pre-defined entity class learning orders and more detailed training settings are listed in the appendixB. Metrics. Due to the class imbalance problem in NER, we use Micro F1 and Macro F1 to measure the model performance. We report the Micro F1 and Macro F1 of all learned types up to each step,\nand unless otherwise noted, these results are the average of the results obtained from all pre-defined learning orders.\nBaselines. We consider five baselines in this work: ExtendNER and AddNER (Monaikul et al., 2021), L&R(Xia et al., 2022), CFNER(Zheng et al., 2022), and SpanKL(Zhang and Chen, 2023). ExtendNER was the previous state-of-the-art method in CL-NER, and L&R was the recent state-of-theart method in CL-NER. CFNER extracts causal effects in CL-NER tasks and achieves advanced performance in multi-entity type tasks. SpanKL also uses a span-level named entity recognition model for continuous learning, and it performs well in terms of forgetfulness resistan. It is worth noting that these baselines use different dataset splitting methods, and we believe that the dataset splitting method is an extremely important but easily overlooked issue in continual learning tasks. To better approximate real-world scenarios, we randomly divide the samples into unrelated tasks."
        },
        {
            "heading": "4.2 Results",
            "text": "Comparisons with State-Of-The-Art. We adopt a more realistic dataset scenario by randomly dividing the samples into unrelated tasks, and we compare our method with previous baselines on these datasets. The experimental results on OntoNotes5 are summarized in Table 1, and Figure 5 . In most cases, our method achieves the best performance. In particular, we use a delta value to quantify the difference between the final results of each model\u2019s continual learning and the results of the first step of learning, which largely represents the model\u2019s antiforgetting ability. Our model outperforms the previous state-of-the-art by a large margin in this metric. Additionally, in Figure 6, we observe an interesting phenomenon that for a particular entity, the prediction accuracy of our model on distilled models after one or even two steps of distillation is higher than the accuracy on the previous predictions made on the same entity. We attribute this improvement in generalization ability to the knowledge distillation\nunder reinforcement learning, where future distillation labels may be more accurate and consistent than the originally learned labels. Due to space constraints, we have included the results on the Fewnerd dataset in the appendixD. Ablation Study. We ablate our method, and the results are summarized in Table 2. To validate the effectiveness of the proposed reinforcement learning knowledge distillation method, we also apply this method to traditional sequence labeling methods and BCE-loss methods. Specifically, in w/o SL and w/o SPL, our model still applies the reinforcement learning knowledge distillation method, while in w/o SL RL, we remove both the reinforcement learning policy and the span sequence labeling method. The results show that the reinforcement learning policy plays a significant role in our framework. Additionally, the new sequence labeling method also helps the model further combat catastrophic forgetting. Due to the space limitation of the article, we put the results of FewNerD into the appendix D.\nAnti-CF performance analysis. We perform Anti-CF performance analysis on the model under OntoNotes5, and the results can be seen in Table 3. For three entities, we track the forgetting situation after 6 steps compared to the initial state. In most cases, our model achieves the best performance. The experimental results demonstrate that our model essentially solves the CF problem on OntoNotes5, which is a relatively simple dataset. We also put FewNerd\u2019s results in the appendix D, its results also prove the validity of our method. Label noise reduction. To validate our hypothesis that SKD-NER alleviates the label noise problem in continual learning and leads to improvements, we plot the normalized confusion matrix between different entity types based on the final predictions (Figure 6). Specifically, we use the \u2032B\u2212X \u2032 (X denotes a specific entity type) labels in the ground truth as the true labels and the \u2032B \u2212X \u2032\nlabels in the model predictions as the predicted labels. From the figure, we can see that compared with ExtendNER, SKD-NER has higher values on the diagonal of the confusion matrix. This indicates that SKD-NER is less affected by incorrectly propagated labels and has more accurate discrimination between different entity types than ExtendNER. These results are consistent with the improvements shown in Table 1."
        },
        {
            "heading": "5 Conclusion",
            "text": "This paper proposes an effective continual learning named entity recognition (NER) model, SKD-NER, aiming to maintain high accuracy for existing entity types while identifying new entity types. We propose a continual learning NER model based on the span method, SKD-NER, which combines reinforcement learning policy. We use knowledge distillation (KD) to preserve memories in the continual learning process and adopt a reinforcement learning policy with a multi-label classification loss for prediction, effectively alleviating the impact of label noise in continual learning. The experimental results demonstrate that the proposed model not only outperforms state-of-the-art methods but also almost solves the catastrophic forgetting problem on OntoNotes5."
        },
        {
            "heading": "6 Ethics Statement",
            "text": "For ethical considerations, we provide the following clarifications: (1) We conduct all experiments on existing datasets sourced from public scientific research. (2) We describe the statistical data of the datasets and the hyperparameter settings of our method. Our analysis and experimental results are consistent. (3) Our work does not involve sensitive data or sensitive tasks."
        },
        {
            "heading": "7 Limitations",
            "text": "Although the proposed model can partially solve the catastrophic forgetting problem, there is still significant room for improvement in more complex dataset testing. Additionally, due to the introduction of knowledge distillation with a reinforcement learning policy, the training time of our model is slightly longer than that of baselines."
        },
        {
            "heading": "A Detailed dataset settings",
            "text": "OntoNotes5 annotates 18 entity types, but in practice, to ensure sufficient training samples for each entity type, we filtered out entity types with less than 50 training samples and selected the following types for training: Organization (ORG), Person (PER), Geo-Political Entity (GPE), Date (DATE), Cardinal (CARD), and Nationalities and Religious Political Group (NORP). For FewNerd, we followed recent research to construct each task by using a coarse-grained type, and each task contains multiple fine-grained entity types related to the coarse-grained type. The coarse-grained types include Location (LOC), Person (PER), Organization (ORG), Other (OTH), Product (PROD), Building (BUID), Art (ART), and Event (EVET). Each coarse-grained type contains roughly 10 finegrained types within it. For example, Product (PROD) contains the following fine-grained entity types: airplane, car, food, game, other, ship, software, train, weapon."
        },
        {
            "heading": "B Detailed training settings",
            "text": "The experiments are run on GeForce RTX 3080 Ti GPU. Each experiment is repeated 5 times. During the evaluation process, we only retain the labels of new entity types and set the other labels in the validation set as other classes. For example, we erase the annotations of PER on the samples assigned to the LOC task learning. At each CL step, we select\nthe model with the best validation performance for testing and the next step of learning. For testing, we retain the labels of all entity types identified until the current task. The pre-defined entity class learning orders are showen in the table 4."
        },
        {
            "heading": "C Hyper-parameters",
            "text": "In the experiments, we set the dropout rate to 0.1, and we use do = 50 for all subsequent feedforward networks in span predictions. For the initial model loss, we set \u03b1 = \u03b2 = 1, and we set the initial distillation temperature to 1. All parameters are fine-tuned using the Adam optimizer (Kingma and Ba, 2015), with a learning rate (lr) of 5\u00d7 10\u22125 for the bert encoder and 1\u00d710\u22123 for the remaining networks. After BPE tokenization widely used in PLMs, we limit the maximum sentence length to 256, and we only use the representation of the first subword piece to represent the word after the Bert contextual encoder."
        },
        {
            "heading": "D Additional Experimental Results",
            "text": "We conducted comparative experiments, ablation studies, and other key experiments on SKDNER model on the FewNERD dataset. The experimental results demonstrate that our model achieves state-of-the-art performance in mitigating catastrophic forgetting and entity recognition accuracy in CL-NER, outperforming baselines in most cases."
        }
    ],
    "title": "SKD-NER: Continual Named Entity Recognition via Span-based Knowledge Distillation with Reinforcement Learning",
    "year": 2023
}