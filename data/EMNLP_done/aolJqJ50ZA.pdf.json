{
    "abstractText": "Cross-document relation extraction (CodRED) task aims to infer the relation between two entities mentioned in different documents within a reasoning path. Previous studies have concentrated on merely capturing implicit relations between the entities. However, humans usually utilize explicit information chains such as hyperlinks or additional searches to find the relations between two entities. Inspired by this, we propose Path wIth expLOraTion (PILOT) that provides the enhanced reasoning path by exploring the explicit clue information within the documents. PILOT finds the bridging entities that directly guide the model with paths between the given entities and then employs them as stepstones to navigate desirable paths. We show that models with PILOT outperform the baselines in the CodRED task. Furthermore, we provide a variety of analyses to verify the validity of the reasoning paths constructed through PILOT, including evaluations using large language models such as ChatGPT.",
    "authors": [
        {
            "affiliations": [],
            "name": "Junyoung Son"
        },
        {
            "affiliations": [],
            "name": "Jinsung Kim"
        },
        {
            "affiliations": [],
            "name": "Jungwoo Lim"
        },
        {
            "affiliations": [],
            "name": "Yoonna Jang"
        },
        {
            "affiliations": [],
            "name": "Heuiseok Lim"
        }
    ],
    "id": "SP:7b3145902c286811bfbb5d93a90fdc300e7fda7d",
    "references": [
        {
            "authors": [
                "Ting Chen",
                "Simon Kornblith",
                "Mohammad Norouzi",
                "Geoffrey Hinton."
            ],
            "title": "A simple framework for contrastive learning of visual representations",
            "venue": "International conference on machine learning, pages 1597\u20131607. PMLR.",
            "year": 2020
        },
        {
            "authors": [
                "Joe Ellis"
            ],
            "title": "Overview of the tac 2010 knowledge base population track",
            "venue": "In Third text analysis conference (TAC 2010),",
            "year": 2010
        },
        {
            "authors": [
                "Vladimir Karpukhin",
                "Barlas Oguz",
                "Sewon Min",
                "Patrick Lewis",
                "Ledell Wu",
                "Sergey Edunov",
                "Danqi Chen",
                "Wen-tau Yih."
            ],
            "title": "Dense passage retrieval for opendomain question answering",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural",
            "year": 2020
        },
        {
            "authors": [
                "Keming Lu",
                "I Hsu",
                "Wenxuan Zhou",
                "Mingyu Derek Ma",
                "Muhao Chen"
            ],
            "title": "Multi-hop evidence retrieval for cross-document relation extraction",
            "venue": "arXiv preprint arXiv:2212.10786",
            "year": 2022
        },
        {
            "authors": [
                "Junyoung Son",
                "Jinsung Kim",
                "Jungwoo Lim",
                "Heuiseok Lim."
            ],
            "title": "GRASP: Guiding model with RelAtional semantics using prompt for dialogue relation extraction",
            "venue": "Proceedings of the 29th International Conference on Computational Linguistics,",
            "year": 2022
        },
        {
            "authors": [
                "Kumutha Swampillai",
                "Mark Stevenson."
            ],
            "title": "Intersentential relations in information extraction corpora",
            "venue": "Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC\u201910).",
            "year": 2010
        },
        {
            "authors": [
                "Fengqi Wang",
                "Fei Li",
                "Hao Fei",
                "Jingye Li",
                "Shengqiong Wu",
                "Fangfang Su",
                "Wenxuan Shi",
                "Donghong Ji",
                "Bo Cai."
            ],
            "title": "Entity-centered cross-document relation extraction",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language",
            "year": 2022
        },
        {
            "authors": [
                "Haoran Wu",
                "Xiuyi Chen",
                "Zefa Hu",
                "Jing Shi",
                "Shuang Xu",
                "Bo Xu."
            ],
            "title": "Local-to-global causal reasoning for cross-document relation extraction",
            "venue": "IEEE/CAA Journal of Automatica Sinica, 10(7):1608\u20131621.",
            "year": 2023
        },
        {
            "authors": [
                "Hang Yang",
                "Dianbo Sui",
                "Yubo Chen",
                "Kang Liu",
                "Jun Zhao",
                "Taifeng Wang."
            ],
            "title": "Document-level event extraction via parallel prediction networks",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th",
            "year": 2021
        },
        {
            "authors": [
                "Yuan Yao",
                "Jiaju Du",
                "Yankai Lin",
                "Peng Li",
                "Zhiyuan Liu",
                "Jie Zhou",
                "Maosong Sun."
            ],
            "title": "Codred: A crossdocument relation extraction dataset for acquiring knowledge in the wild",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Lan-",
            "year": 2021
        },
        {
            "authors": [
                "Yuan Yao",
                "Deming Ye",
                "Peng Li",
                "Xu Han",
                "Yankai Lin",
                "Zhenghao Liu",
                "Zhiyuan Liu",
                "Lixin Huang",
                "Jie Zhou",
                "Maosong Sun."
            ],
            "title": "Docred: A large-scale document-level relation extraction dataset",
            "venue": "Proceedings of the 57th Annual Meeting of the Associa-",
            "year": 2019
        },
        {
            "authors": [
                "Ningyu Zhang",
                "Xiang Chen",
                "Xin Xie",
                "Shumin Deng",
                "Chuanqi Tan",
                "Mosha Chen",
                "Fei Huang",
                "Luo Si",
                "Huajun Chen."
            ],
            "title": "Document-level relation extraction as semantic segmentation",
            "venue": "Proceedings of the Thirtieth International Joint Conference on Artificial",
            "year": 2021
        },
        {
            "authors": [
                "Yuhao Zhang",
                "Victor Zhong",
                "Danqi Chen",
                "Gabor Angeli",
                "Christopher D. Manning."
            ],
            "title": "Position-aware attention and supervised data improve slot filling",
            "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages",
            "year": 2017
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "The relation extraction (RE) task aims to predict relations between two entities in a given text and is an essential basis for application tasks such as knowledge base construction (KBC) and question answering (QA) (Swampillai and Stevenson, 2010; Ji et al., 2010; Son et al., 2022). Although the sentence-level and document-level RE have achieved substantial performance (Zhang et al., 2017; Yao et al., 2019; Yang et al., 2021; Zhang et al., 2021), it is still challenging to identify the relations across multiple documents. Since the relations between the entities can be inferred from the multiple documents in the wild, cross-document relation extraction (CodRED) is suggested by Yao et al. (2021) which provides the relation between two entities (i.e., head and tail) across the multiple documents (Wu et al., 2023).1\n\u2217Corresponding author 1In the vast knowledge repository of Wikidata, more than 57.6% of the facts are not encapsulated within single\nTo implement the cross-document RE model, Wang et al. (2022) has enhanced the method of capturing bridging entities by entity-based documentcontext filter and utilizes a cross-document entity relation attention module for enhanced connection awareness between the reasoning paths. On the contrary, Lu et al. (2022) focuses on extracting evidence path and ranking with dense retrieval without explicit consideration for the bridging entity. Likewise, previous studies have only attempted to model the bridging entities implicitly, neglecting to exploit the potentially valuable additional information that bridging entities can provide.\nHowever, utilizing the explicit information relevant to bridging entities, which can provide a definitive guide in the exploration of reasoning paths, is crucial for identifying the correct relation. When inferring relations between entities using multiple documents, humans may not follow arbitrary in-\nWikipedia documents but are instead distributed across multiple documents.\nformation. Instead, they instinctively draw upon explicitly linked information from the bridging entity between documents - that which connects a path to the tail entity and provides structural clues about the relation.\nIn this paper, we introduce Path wIth expLOraTion (PILOT), an effective way of constructing explicit and structural reasoning path utilizing bridging entities. According to PILOT, it first finds the bridging entities with structural entity information, such as intra-document relation, and retrieves the documents that are related to the bridging entities. Afterward, we rerank the documents by entity-aware scoring function and leverage the highscored documents as the stepstones connecting the head and tail. The RE models with PILOT showed consistent improvement in performance compared to the baselines in the CodRED task. In addition, we provide an analysis with a large language model (LLM) such as ChatGPT (OpenAI-Blog, 2022) on whether our enhanced reasoning path leads to more knowledgeable and relevant information."
        },
        {
            "heading": "2 Method",
            "text": "Our proposed method revolves around leveraging the most significant bridging entities to construct a reasoning path between the head and tail entities. Initially, we employ structural information (i.e., intra-document relations) and the dense retriever to assemble a set of candidate bridging entities and their corresponding documents. Subsequently, we select the most relevant among these candidates through entity-based filtering and scoring methods. Finally, we utilize the final bridging entities to construct an expanded reasoning path."
        },
        {
            "heading": "2.1 Preliminaries",
            "text": "Task Definition In cross-document RE, a head entity and a tail entity are denoted as h, and t, respectively. P = {pi}Ni=1 is a set of reasoning paths, and each reasoning path pi has two documents (dhi , d t i), including h and t. The task aims to infer the relation r \u2208 R between two entities where R is a pre-defined relation set. If a particular entity is mentioned in both dhi and d t i, it can consider this entity as a bridging entity between them. According to Yao et al. (2021), There are potential bridging entities that establish the relation between the documents (4.7 on average). We denote a set of the bridging entities as Eb = {ebi}Mi=1 between two documents."
        },
        {
            "heading": "2.2 PILOT",
            "text": ""
        },
        {
            "heading": "2.2.1 Bridging Document Retrieval",
            "text": "Entity-aware Retriever To find the relevant documents De = {de}Li=1 when given entity e as a query, we train a dense retriever (Karpukhin et al., 2020). We first collect the entities which have their corresponding Wikipedia page from CodRED and Wikidata to construct the dataset for training the retriever. Afterward, we regard the Wikipedia page of the entity e as a positive example p+ and Wikipedia pages extracted from BM25 following Karpukhin et al. (2020) as the negative examples {p\u2212j }Jj=1. The training objective follows contrastive learning (Chen et al., 2020), as shown in Equation 1.\nl(e,p+, {pj}Jj=1) =\n\u2212 log expsim(e,p\n+ i )\nexpsim(e,p + i ) + \u2211J j=1 exp sim(e,p\u2212j ) . (1)\nBridging Candidate Construction To build a set of candidate bridging entities between two documents, we first utilize the shared entity set Ecand = Eh \u222a Et, where (Eh, Et) is the set of all entities that exist in (dh, dt) respectively. With the dense retriever, we retrieve a set of documents Dcand = {dcand}|D\ncand| i=1 by using e\ncand \u2208 Ecand as a query.\nEntity-based Filtering After retrieving the set of documents, we filter out the documents to preserve more relevant documents to the ecand. In detail, we exclude dcand if ecand is not mentioned in dcand. We further validate ecand exploiting structural information from Wikidata. If the ecand is connected to the h and t according to the Wikidata, we use them as a bridging entity candidate or, otherwise, filter out.\nBridging Entity Scoring To quantify the relevance of candidate entities linked to the head and tail entities, we score each entity based on the given document. In detail, given an entity ecand and the document d, we find the entities in the d and count the number of occurrences of ecand as follows:\nN(ecand, d) = \u2211 e\u2208Ed \u03b4(ecand, e), (2)\nwhere \u03b4(e1, e2) returns 1 if e1 = e2 otherwise 0. Based on this score, we get the top-k bridging entities E\u0302b and employ them to construct a path.\nI(ecand) = (N(ecand, dh) +N(h, dcand)) \u2217 (N(ecand, dt) +N(t, dcand)),\n(3)\nBased on this score, we get the top-k bridging entities E\u0302b and employ them to construct a path."
        },
        {
            "heading": "2.2.2 Path Construction",
            "text": "Finally, we construct an expanded reasoning path P \u2032 by employing the existing reasoning path P = {pi}|P |i=1 and E\u0302bi = {e\u0302bij} |E\u0302bi | j=1 . The detailed equation constructing P \u2032 is as follows:\nP \u2032 = |P |\u22c3 i=1 |E\u0302bi |\u22c3 j=1 {(dhi , d e\u0302bij , dti) | (dhi , dti) \u2208 P}, (4)\nwhere de\u0302 b ij is a document retrieved by Entity-aware\nretriever using query as e\u0302bij ."
        },
        {
            "heading": "3 Experiments and Analysis",
            "text": "We apply PILOT to the existing reasoning path provided by (Yao et al., 2021) to construct an extended reasoning path. For the experiment, we utilize Endto-End (Yao et al., 2021) and ECRIM (Wang et al., 2022) models as baselines. The detailed experimental settings are described in 4."
        },
        {
            "heading": "3.1 Experimental Results in CodRED",
            "text": "We show the experimental results of PILOT method on the CodRED task in Table 1. These results demonstrated a consistent enhancement in the performance across all baselines when they were incorporated with PILOT method. In the End-toEnd baseline, PILOT significantly improves performance across both the development and test sets. In particular, the substantial performance gain with 6.5% in the test set shows the generalization ability of our method. Even with the state-of-the-art model ECRIM, we observed a consistent improvement in\nperformance. Specifically, we witnessed accuracy improvements of up to 3.54% in the development set and 2.23% in the test set, validating the broad applicability of PILOT. When Wikidata filtering is removed, the performance decreases 0.4% for the End-to-End and 0.52% for the ECRIM in the development set, respectively. Especially in ECRIM, the f1 score drops 1.43% in the test set. These results suggest the central role of Wikidata filtering in PILOT, underlining the importance of structured information in navigating relational information for cross-document reasoning."
        },
        {
            "heading": "3.2 Experimental Results for Entity-aware Retriever",
            "text": "The experimental results of the Entity-aware Retriever used for bridging document retrieval in PILOT are presented in Table 2. This process is significant since retrieving documents with low relevance to the entity could lead to a substantial performance decrease, creating a potential bottleneck. The Entity-aware Retriever, with an accuracy of 94.41% and 94.03%, hints at its pivotal role in PILOT, suggesting its ability to provide relevant bridging context to the bridging entities."
        },
        {
            "heading": "3.3 Evaluating the Capability to Distinguish Correct Reasoning Paths",
            "text": "We evaluate path-level accuracy rather than entity pair-level to validate the proposed method\u2019s capability to distinguish correct reasoning paths despite\nextremely noisy settings. Because CodRED consists of only 6.7% of positive reasoning paths and the remaining 93.3% of N/A reasoning paths, we assume that the path-level evaluation can be used to estimate this ability. As shown in Table 3, we can\nobserve that the path-level accuracy improves when the bridged reasoning paths expanded by PILOT are applied to the original reasoning paths despite their highly noised setting."
        },
        {
            "heading": "3.4 Quantity of Bridging Entities Explored",
            "text": "As shown in Figure 2, the RE performance initially improves with more bridging entities. However, as the number of these entities continues to rise, a performance drop is observed. This suggests that using too many bridging entities can introduce more noise, leading to decreased effectiveness. In addition, the performance greatly drops when the number of bridging entities is 5. This result reflects the fact of exceeding the average number of potential bridging entities (4.7 on average (Yao et al., 2021))."
        },
        {
            "heading": "3.5 Bridging Entity Type Selection",
            "text": "We demonstrate the cross-document RE performance based on the type of score function as in Figure 3. We compare four settings. \u2018w/o bridging\u2019 is the setting where only (dh, dt) is given as a reasoning path. \u2018All entities\u2019 indicates the setting where the bridging entities are randomly selected from\nthe set of entities that appear in (dh, dt). \u2018Shared entities\u2019 is the setting where the bridging entities are randomly selected from the set of entities commonly appearing in dh and dt.\nAs shown in Figure 3, the reasoning path constructed by PILOT shows the most outstanding performance. The performance of random entities (\u2018All entities\u2019) is significantly worse than when the bridging entity is not utilized. It indicates that the performance improvement is not simply due to an increase in the amount of information in the bridging entity, but rather to the importance of finding genuinely relevant information."
        },
        {
            "heading": "3.6 ChatGPT Evaluation",
            "text": "To show the efficacy of our reasoning path from PILOT method, we ask ChatGPT to evaluate between the cases where the path is explored by PILOT and the path is constructed with random entities.2 The evaluation criteria are as follows: 1) Informativeness indicates how many clues the provided bridging entity information contains to infer a relation, and 2) Relevancy indicates how much relevant the\n2The evaluation prompt template using ChatGPT is illustrated in Appendix 8.\ngiven reasoning path, including the bridging entity, is with the given pair of entities (head, tail). Figure 4 illustrates that our reasoning paths got higher win proportion compared to both types of random paths by 64.96%p and 65.46%p, respectively, and this tendency is also similar in relevancy. In addition, Ours vs. All has a higher win rate than Shared vs. All. These results imply that our reasoning paths with PILOT method include more information for relation inference and act as the relevant evidence to explain the relation between head and tail."
        },
        {
            "heading": "3.7 Human Evaluation",
            "text": "To support the results mentioned in the ChatGPT Evaluation, we conducted a human evaluation by employing three individuals. More specifically, we presented each participant with 30 text snippets extracted from randomly sampled reasoning paths and had them undergo an AB test in comparison with the random baselines. As shown in Table 4, the results of the human evaluation exhibited a trend similar to that of the ChatGPT Evaluation. Notably, Our method demonstrated a win rate of 61.1% against Shared and 67.7% against All in Informativeness. In terms of Relevancy, it showed a win rate of 58.9% versus Shared and 65.5% against All. Additionally, the lower Lose rate in comparison to the Win and Tie ratios suggests that our methodology has significantly enhanced the quality of the reasoning path."
        },
        {
            "heading": "4 Conclusion",
            "text": "We proposed PILOT, which is the method that explores the reasoning path by utilizing the bridging entities and their documents for the CodRED task. Based on the filtering and scoring, PILOT exploits the explicit and structural information from metadata such as Wikidata, and constructs the enhanced reasoning path. In the experiments, the models with PILOT showed improvements compared to the baselines and outperformed the existing state-ofthe-art model. Moreover, we provided additional experiments and extensive analyses to validate the efficacy of explored reasoning path and analysis.\nLimitations\nBecause PILOT constructs an expanded version of the reasoning path based on the given reasoning path which is a document pair (dh, dt) for h and t entities, it requires an initial reasoning path to build an expanded one. This suggests that regardless of how well the bridging context is selected, the performance could be compromised if the quality of the initial reasoning path is not adequate, implying a dependency on the initial path. This factor should be taken into account when building paths in the open-settings in the future. In addition, the scoring function in PILOT is calculated using the number of mentions in each document, neglecting potentially important context which is infrequent but has a critical role between the entities. As Table 7 demonstrated, the bridging entities chosen from PILOT between entities can be nothing when the retrieved and filtered results return nothing. In other words, while this approach effectively filters out some irrelevant paths, it also carries the potential downside of losing valuable information that could contribute to inferring the relations between the entities."
        },
        {
            "heading": "Acknowledgements",
            "text": "This research was supported by the MSIT(Ministry of Science and ICT), Korea, under the ITRC(Information Technology Research Center) support program(IITP-2023-2018-0-01405) supervised by the IITP(Institute for Information & Communications Technology Planning & Evaluation). This work was supported by Institute of Information & communications Technology Planning & Evaluation(IITP) grant funded by the Korea government(MSIT) (No. 2020-0-00368, A Neural-Symbolic Model for Knowledge Acquisition and Inference Techniques). Also, this research was supported by Basic Science Research Program through the National Research Foundation of Korea(NRF) funded by the Ministry of Education(NRF-2021R1A6A1A03045425)."
        },
        {
            "heading": "A Experimental Setup",
            "text": "A.1 Hyperparameters We conduct our experiments using the closedsetting of CodRED. We employ the cased version of BERT-base model as the encoder. We use a learning rate of 3e-5 and apply a linear warm-up and learning rate schedule with the weight decay value 0.01. The batch size is 4. We train the baseline models on 4 NVIDIA RTX A6000 GPUs for 10 epochs.\nA.2 Implementation Details To select a text snippet from the reasoning path, we follow the previous method (Yao et al., 2021), which extracts text snippets from the first mention of head and tail entities in each document. A slight difference from the previous method lies in our use of the bridging entity\u2019s document. In order to extract additional text snippets from the bridging entity\u2019s document as well, we augment the original text snippets by incorporating sections where the head and tail mentions first appear from the bridging entity\u2019s document.\nA.3 Evaluation Metrics As evaluation metrics, we utilize F1/AUC/P@500/P@1000 for the development set and F1/AUC for the test set following the previous studies (Yao et al., 2021; Wang et al., 2022). All of the test results are obtained from the official website of CodRED on Codalab.\nA.4 Dataset Statistics"
        },
        {
            "heading": "40221 519",
            "text": "B ChatGPT Evaluation Prompt Template"
        },
        {
            "heading": "2) the case where the \u2019Relation\u2019 and the \u2019Text snippet\u2019 are more relevant.",
            "text": ""
        }
    ],
    "title": "Explore the Way: Exploring Reasoning Path by Bridging Entities for Effective Cross-Document Relation Extraction",
    "year": 2023
}