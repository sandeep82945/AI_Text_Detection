{
    "abstractText": "In this work, we focus on the task of determining the public attitude toward various social issues discussed on social media platforms. Platforms such as Twitter, however, are often used to spread misinformation, fake news through polarizing views. Existing literature suggests that higher levels of toxicity prevalent in Twitter conversations often spread negativity and delay addressing issues. Further, the embedded moral values and speech acts specifying the intention of the tweet correlate with public opinions expressed on various topics. However, previous works, which mainly focus on stance detection, either ignore the speech act, toxic, and moral features of these tweets that can collectively help capture public opinion or lack an efficient architecture that can detect the attitudes across targets. Therefore, in our work, we focus on the main task of stance detection by exploiting the toxicity, morality, and speech act as auxiliary tasks. We propose a multitasking model TWISTED that initially extracts the valence, arousal, and dominance aspects hidden in the tweets and injects the emotional sense into the embedded text followed by an efficient attention framework to correctly detect the tweet\u2019s stance by using the shared features of toxicity, morality, and speech acts present in the tweet. Extensive experiments conducted on 4 benchmark stance detection datasets (SemEval-2016, P-Stance, COVID19Stance, and ClimateChange) comprising different domains demonstrate the effectiveness and generalizability of our approach.",
    "authors": [
        {
            "affiliations": [],
            "name": "Apoorva Upadhyaya"
        },
        {
            "affiliations": [],
            "name": "Marco Fisichella"
        },
        {
            "affiliations": [],
            "name": "Wolfgang Nejdl"
        }
    ],
    "id": "SP:cabc96d0734d6293a6819f41e96b736dc7649c68",
    "references": [
        {
            "authors": [
                "chos",
                "Kalina Bontcheva"
            ],
            "title": "2016. Stance detection",
            "year": 2016
        },
        {
            "authors": [
                "Maryam Badar",
                "Wolfgang Nejdl",
                "Marco Fisichella."
            ],
            "title": "Fac-fed: Federated adaptation for fairness and concept drift aware stream classification",
            "venue": "Machine Learning, pages 1\u201326.",
            "year": 2023
        },
        {
            "authors": [
                "Xingyu Chen",
                "Lei Zou",
                "Bo Zhao."
            ],
            "title": "Detecting climate change deniers on twitter using a deep neural network",
            "venue": "Proceedings of the 2019 11th International Conference on Machine Learning and Computing, pages 204\u2013210.",
            "year": 2019
        },
        {
            "authors": [
                "Justin Cheng",
                "Michael Bernstein",
                "Cristian DanescuNiculescu-Mizil",
                "Jure Leskovec."
            ],
            "title": "Anyone can become a troll: Causes of trolling behavior in online discussions",
            "venue": "Proceedings of the 2017 ACM conference on computer supported cooperative work",
            "year": 2017
        },
        {
            "authors": [
                "Uthsav Chitra",
                "Christopher Musco."
            ],
            "title": "Analyzing the impact of filter bubbles on social network polarization",
            "venue": "Proceedings of the 13th International Conference on Web Search and Data Mining, pages 115\u2013123.",
            "year": 2020
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Jiachen Du",
                "Ruifeng Xu",
                "Yulan He",
                "Lin Gui."
            ],
            "title": "Stance classification with target-specific neural attention networks",
            "venue": "International Joint Conferences on Artificial Intelligence.",
            "year": 2017
        },
        {
            "authors": [
                "Subhabrata Dutta",
                "Samiya Caur",
                "Soumen Chakrabarti",
                "Tanmoy Chakraborty."
            ],
            "title": "Semi-supervised stance detection of tweets via distant network supervision",
            "venue": "Proceedings of the fifteenth ACM international conference on web search and data mining,",
            "year": 2022
        },
        {
            "authors": [
                "Yujie Fu",
                "Xiaoli Li",
                "Yang Li",
                "Suge Wang",
                "Deyu Li",
                "Jian Liao",
                "Jianxing Zheng."
            ],
            "title": "Incorporate opinion-towards for stance detection",
            "venue": "KnowledgeBased Systems, 246:108657.",
            "year": 2022
        },
        {
            "authors": [
                "Venkata Rama Kiran Garimella",
                "Ingmar Weber."
            ],
            "title": "A long-term analysis of polarization on twitter",
            "venue": "Proceedings of the International AAAI Conference on Web and Social Media, volume 11.",
            "year": 2017
        },
        {
            "authors": [
                "Kyle Glandt",
                "Sarthak Khanal",
                "Yingjie Li",
                "Doina Caragea",
                "Cornelia Caragea."
            ],
            "title": "Stance detection in covid-19 tweets",
            "venue": "Proceedings of the",
            "year": 2021
        },
        {
            "authors": [
                "Jesse Graham",
                "Jonathan Haidt",
                "Sena Koleva",
                "Matt Motyl",
                "Ravi Iyer",
                "Sean P Wojcik",
                "Peter H Ditto."
            ],
            "title": "Moral foundations theory: The pragmatic validity of moral pluralism",
            "venue": "Advances in experimental social psychology, volume 47, pages 55\u2013130.",
            "year": 2013
        },
        {
            "authors": [
                "Zihao He",
                "Negar Mokhberian",
                "Kristina Lerman."
            ],
            "title": "Infusing knowledge from wikipedia to enhance stance detection",
            "venue": "Proceedings of the 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis, WASSA@ACL",
            "year": 2022
        },
        {
            "authors": [
                "Daniel Hickey",
                "Matheus Schmitz",
                "Daniel Fessler",
                "Paul E Smaldino",
                "Goran Muric",
                "Keith Burghardt."
            ],
            "title": "Auditing elon musk\u2019s impact on hate speech and bots",
            "venue": "Proceedings of the International AAAI Conference on Web and Social Media, volume 17, pages 1133\u2013",
            "year": 2023
        },
        {
            "authors": [
                "Frederic R Hopp",
                "Jacob T Fisher",
                "Devin Cornell",
                "Richard Huskey",
                "Ren\u00e9 Weber."
            ],
            "title": "The extended moral foundations dictionary (emfd): Development and applications of a crowd-sourced approach to extracting moral intuitions from text",
            "venue": "Be-",
            "year": 2021
        },
        {
            "authors": [
                "Hossein Hosseini",
                "Sreeram Kannan",
                "Baosen Zhang",
                "Radha Poovendran."
            ],
            "title": "Deceiving google\u2019s perspective api built for detecting toxic comments",
            "venue": "arXiv preprint arXiv:1702.08138.",
            "year": 2017
        },
        {
            "authors": [
                "Homa Hosseinmardi",
                "Sabrina Arredondo Mattson",
                "Rahat Ibn Rafiq",
                "Richard Han",
                "Qin Lv",
                "Shivakant Mishra."
            ],
            "title": "Analyzing labeled cyberbullying incidents on the instagram social network",
            "venue": "International conference on social informatics, pages 49\u201366.",
            "year": 2015
        },
        {
            "authors": [
                "Binxuan Huang",
                "Kathleen M. Carley."
            ],
            "title": "Parameterized convolutional neural networks for aspect level sentiment classification",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 -",
            "year": 2018
        },
        {
            "authors": [
                "Chuma Kabaghe",
                "Jason Qin."
            ],
            "title": "Classifying tweets based on climate change stance",
            "venue": "Training, 66(60.9):61.",
            "year": 2020
        },
        {
            "authors": [
                "Amandeep Kaur",
                "HS Chahal."
            ],
            "title": "Role of social media in increasing environmental issue awareness",
            "venue": "Researchers World, 9(1):19\u201327.",
            "year": 2018
        },
        {
            "authors": [
                "Alexandre Lacoste",
                "Alexandra Luccioni",
                "Victor Schmidt",
                "Thomas Dandres."
            ],
            "title": "Quantifying the carbon emissions of machine learning",
            "venue": "CoRR, abs/1910.09700.",
            "year": 2019
        },
        {
            "authors": [
                "Manyu Li",
                "Nadia Turki",
                "Cassandra R Izaguirre",
                "Chloe DeMahy",
                "Brooklyn Labery Thibodeaux",
                "Taylor Gage."
            ],
            "title": "Twitter as a tool for social movement: An analysis of feminist activism on social media communities",
            "venue": "Journal of community psychology,",
            "year": 2021
        },
        {
            "authors": [
                "Yingjie Li",
                "Cornelia Caragea."
            ],
            "title": "Multi-task stance detection with sentiment and stance lexicons",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language",
            "year": 2019
        },
        {
            "authors": [
                "Yingjie Li",
                "Tiberiu Sosea",
                "Aditya Sawant",
                "Ajith Jayaraman Nair",
                "Diana Inkpen",
                "Cornelia Caragea."
            ],
            "title": "P-stance: A large dataset for stance detection in political domain",
            "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,",
            "year": 2021
        },
        {
            "authors": [
                "Maurice Lineman",
                "Yuno Do",
                "Ji Yoon Kim",
                "Gea-Jae Joo."
            ],
            "title": "Talking about climate change and global warming",
            "venue": "PloS one, 10(9):e0138996.",
            "year": 2015
        },
        {
            "authors": [
                "Zhengyuan Liu",
                "Yong Keong Yap",
                "Hai Leong Chieu",
                "Nancy F Chen."
            ],
            "title": "Guiding computational stance detection with expanded stance triangle framework",
            "venue": "arXiv preprint arXiv:2305.19845.",
            "year": 2023
        },
        {
            "authors": [
                "Sudhanshu Mishra",
                "Shivangi Prasad",
                "Shubhanshu Mishra."
            ],
            "title": "Exploring multi-task multi-lingual learning of transformer models for hate speech and offensive speech identification in social media",
            "venue": "SN Computer Science, 2:1\u201319.",
            "year": 2021
        },
        {
            "authors": [
                "Saif Mohammad."
            ],
            "title": "Obtaining reliable human ratings of valence, arousal, and dominance for 20,000 english words",
            "venue": "Proceedings of the 56th annual meeting of the association for computational linguistics (volume 1: Long papers), pages 174\u2013184.",
            "year": 2018
        },
        {
            "authors": [
                "Saif Mohammad",
                "Svetlana Kiritchenko",
                "Parinaz Sobhani",
                "Xiaodan Zhu",
                "Colin Cherry."
            ],
            "title": "Semeval2016 task 6: Detecting stance in tweets",
            "venue": "Proceedings of the 10th international workshop on semantic evaluation (SemEval-2016), pages 31\u201341.",
            "year": 2016
        },
        {
            "authors": [
                "Saif M. Mohammad."
            ],
            "title": "Ethics sheet for automatic emotion recognition and sentiment analysis",
            "venue": "Comput. Linguistics, 48(2):239\u2013278.",
            "year": 2022
        },
        {
            "authors": [
                "Lili Mou",
                "Rui Men",
                "Ge Li",
                "Yan Xu",
                "Lu Zhang",
                "Rui Yan",
                "Zhi Jin."
            ],
            "title": "Natural language inference by tree-based convolution and heuristic matching",
            "venue": "arXiv preprint arXiv:1512.08422.",
            "year": 2015
        },
        {
            "authors": [
                "Dat Quoc Nguyen",
                "Thanh Vu",
                "Anh Tuan Nguyen."
            ],
            "title": "BERTweet: A pre-trained language model for English tweets",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Online. Associ-",
            "year": 2020
        },
        {
            "authors": [
                "Charles Egerton Osgood",
                "George J Suci",
                "Percy H Tannenbaum"
            ],
            "title": "The measurement of meaning",
            "year": 1957
        },
        {
            "authors": [
                "John Pavlopoulos",
                "Nithum Thain",
                "Lucas Dixon",
                "Ion Androutsopoulos."
            ],
            "title": "Convai at semeval-2019 task 6: Offensive language identification and categorization with perspective and bert",
            "venue": "Proceedings of the 13th international Workshop on Semantic Evaluation,",
            "year": 2019
        },
        {
            "authors": [
                "Shalini Priya",
                "Apoorva Upadhyaya",
                "Manish Bhanu",
                "Sourav Kumar Dandapat",
                "Joydeep Chandra."
            ],
            "title": "Endea: Ensemble based decoupled adversarial learning for identifying infrastructure damage during disasters",
            "venue": "Proceedings of the 29th ACM in-",
            "year": 2020
        },
        {
            "authors": [
                "Maud Reveilhac",
                "Gerold Schneider."
            ],
            "title": "Replicable semi-supervised approaches to state-of-the-art stance detection of tweets",
            "venue": "Information Processing Management, 60(2):103199.",
            "year": 2023
        },
        {
            "authors": [
                "Rezvaneh Rezapour",
                "Ly Dinh",
                "Jana Diesner."
            ],
            "title": "Incorporating the measurement of moral foundations theory into analyzing stances on controversial topics",
            "venue": "Proceedings of the 32nd ACM conference on hypertext and social media, pages 177\u2013188.",
            "year": 2021
        },
        {
            "authors": [
                "James A Russell."
            ],
            "title": "A circumplex model of affect",
            "venue": "Journal of personality and social psychology, 39(6):1161.",
            "year": 1980
        },
        {
            "authors": [
                "James A Russell."
            ],
            "title": "Core affect and the psychological construction of emotion",
            "venue": "Psychological review, 110(1):145.",
            "year": 2003
        },
        {
            "authors": [
                "Tulika Saha",
                "Apoorva Upadhyaya",
                "Sriparna Saha",
                "Pushpak Bhattacharyya."
            ],
            "title": "A multitask multimodal ensemble model for sentiment-and emotionaided tweet act classification",
            "venue": "IEEE Transactions on Computational Social Systems.",
            "year": 2021
        },
        {
            "authors": [
                "Parinaz Sobhani",
                "Saif Mohammad",
                "Svetlana Kiritchenko."
            ],
            "title": "Detecting stance in tweets and analyzing its interaction with sentiment",
            "venue": "Proceedings of the fifth joint conference on lexical and computational semantics, pages 159\u2013169.",
            "year": 2016
        },
        {
            "authors": [
                "Robert L Spitzer",
                "Jacob Cohen",
                "Joseph L Fleiss",
                "Jean Endicott."
            ],
            "title": "Quantification of agreement in psychiatric diagnosis: A new approach",
            "venue": "Archives of General Psychiatry, 17(1):83\u201387.",
            "year": 1967
        },
        {
            "authors": [
                "Apoorva Upadhyaya",
                "Marco Fisichella",
                "Wolfgang Nejdl."
            ],
            "title": "Intensity-valued emotions help stance detection of climate change twitter data",
            "venue": "Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, IJCAI 2023, 19th-25th",
            "year": 2023
        },
        {
            "authors": [
                "Apoorva Upadhyaya",
                "Marco Fisichella",
                "Wolfgang Nejdl."
            ],
            "title": "A multi-task model for emotion and offensive aided stance detection of climate change tweets",
            "venue": "Proceedings of the ACM Web Conference 2023, pages 3948\u20133958.",
            "year": 2023
        },
        {
            "authors": [
                "Apoorva Upadhyaya",
                "Marco Fisichella",
                "Wolfgang Nejdl."
            ],
            "title": "A multi-task model for sentiment aided stance detection of climate change tweets",
            "venue": "Proceedings of the International AAAI Conference on Web and Social Media, volume 17, pages 854\u2013865.",
            "year": 2023
        },
        {
            "authors": [
                "Apoorva Upadhyaya",
                "Marco Fisichella",
                "Wolfgang Nejdl."
            ],
            "title": "Towards sentiment and temporal aided stance detection of climate change tweets",
            "venue": "Information Processing & Management, 60(4):103325.",
            "year": 2023
        },
        {
            "authors": [
                "Roopal Vaid",
                "Kartikey Pant",
                "Manish Shrivastava."
            ],
            "title": "Towards fine-grained classification of climate change related social media text",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop,",
            "year": 2022
        },
        {
            "authors": [
                "Ameya Vaidya",
                "Feng Mai",
                "Yue Ning."
            ],
            "title": "Empirical analysis of multi-task learning for reducing identity bias in toxic comment detection",
            "venue": "Proceedings of the International AAAI Conference on Web and Social Media, volume 14, pages 683\u2013693.",
            "year": 2020
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems, pages 5998\u20136008.",
            "year": 2017
        },
        {
            "authors": [
                "Oxana Vitman",
                "Yevhen Kostiuk",
                "Grigori Sidorov",
                "Alexander Gelbukh."
            ],
            "title": "Sarcasm detection framework using emotion and sentiment features",
            "venue": "arXiv preprint arXiv:2211.13014.",
            "year": 2022
        },
        {
            "authors": [
                "Sergey Vychegzhanin",
                "Evgeny Kotelnikov."
            ],
            "title": "A new method for stance detection based on feature selection techniques and ensembles of classifiers",
            "venue": "IEEE Access, 9:134899\u2013134915.",
            "year": 2021
        },
        {
            "authors": [
                "Limin Wang",
                "Dexin Wang."
            ],
            "title": "Solving stance detection on tweets as multi-domain and multi-task text classification",
            "venue": "IEEE Access, 9:157780\u2013157789.",
            "year": 2021
        },
        {
            "authors": [
                "Zhongqing Wang",
                "Qingying Sun",
                "Shoushan Li",
                "Qiaoming Zhu",
                "Guodong Zhou."
            ],
            "title": "Neural stance detection with hierarchical linguistic representations",
            "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing, 28:635\u2013645.",
            "year": 2020
        },
        {
            "authors": [
                "Wei Xue",
                "Tao Li."
            ],
            "title": "Aspect based sentiment analysis with gated convolutional networks",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers,",
            "year": 2018
        },
        {
            "authors": [
                "Raneen Younis",
                "Zahra Ahmadi",
                "Abdul Hakmeh",
                "Marco Fisichella."
            ],
            "title": "Flames2graph: An interpretable federated multivariate time series classification framework",
            "venue": "Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and",
            "year": 2023
        },
        {
            "authors": [
                "Kai Zheng",
                "Qingfeng Sun",
                "Yaming Yang",
                "Fei Xu."
            ],
            "title": "Knowledge stimulated contrastive prompting for low-resource stance detection",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022, pages 1168\u20131178.",
            "year": 2022
        },
        {
            "authors": [
                "Yiwei Zhou",
                "Alexandra I Cristea",
                "Lei Shi."
            ],
            "title": "Connecting targets to tweets: Semantic attentionbased model for target-specific stance detection",
            "venue": "International Conference on Web Information Systems Engineering, pages 18\u201332. Springer.",
            "year": 2017
        },
        {
            "authors": [
                "Spitzer"
            ],
            "title": "toxic, moral, and speech acts, respectively, indicating that the labels predicted by semi-supervised approaches are of considerably good quality",
            "venue": "C Environment Details",
            "year": 1967
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Social media platforms are often used to express public opinions and raise awareness about various issues and current problems in society (Lineman et al., 2015; Kaur and Chahal, 2018; Li et al., 2021a). However, conversations on platforms like Twitter can lead to users being exposed to false, misinformed messages, often resulting in polarizing beliefs and echo chambers (Garimella and\nWeber, 2017; Li et al., 2021a). A recent American Press article1 claims that misinformation about climate is widespread on Twitter and often delays appropriate climate action. In addition, a study conducted by MIT researchers2 showed that false news spread 6 times faster on Twitter than truthful news. Therefore, it is necessary to recognize the attitudes of the posts so as to curb the spread of misinformation. In our work, we perform stance detection of tweets to detect the opinion of the post, whether it is in favor, against, or none toward a target topic. There is a wealth of research on identifying attitudes in social media. Several popular and benchmark stance datasets exist in the literature such as SemEval-2016 (Mohammad et al., 2016), P-Stance (Li et al., 2021b), COVID-19 (Glandt et al., 2021), and ClimateChange (Upadhyaya et al., 2023b) that focus on various social issues such as feminism, abortion, COVID19, climate, and many current crises whose public opinions need to be identified in order to address these issues and change society for the better. We also use these 4 benchmark datasets in our study, which covers different domains, to get an assessment of generalizability of our approach.\nExisting literature suggests that the tweet content consists of abusive and insulting statements, leading to the spread of hatred, bullying, and negativity in the public sphere, often disturbing social peace (Hosseinmardi et al., 2015; Cheng et al., 2017; Pavlopoulos et al., 2019). Moreover, the moral values in the tweets correlate with the different public opinions, which helps to understand the intentions behind each expressed attitude, which in turn helps to culturally integrate society and mitigate such differences (Rezapour et al., 2021). In the popular benchmark datasets, we also note\n1https://apnews.com/article/elon-musktwitter-inc-technology-science-social-mediaa7e2e3214abb4470dcb6e2837aa39c2e\n2https://news.mit.edu/2018/study-twitter-false-newstravels-faster-true-stories-0308\nthat the speech act of the tweets, i.e., the form of expression, statement, question, or thought, also differs significantly across viewpoints on different topics (refer Appendix B.2), which helps to determine the communicative intent of the viewpoint, further supporting the stance task. The following are few examples of tweets from public datasets: (ii)Feminism (against):\u201c@HiddenTara No one wants to see Feminists naked, so the petty, vindictive bit**** want to drag everyone else down to their level (toxic,harm,expression)\"; (ii)Biden (favor): \u201cLets Go Joe #TeamJoe #GoJoe #Biden2020 (non_toxic, care, loyalty, suggestion)\". These relationships between toxic, moral, and speech act labels associated with the tweets\u2019 stances led us to use them to decipher their underlying attitudes.\nWhile several works (Vychegzhanin and Kotelnikov, 2021; Wang et al., 2020; Li and Caragea, 2019) focused on the linguistic properties of the input text for stance, they often lack an advanced architecture in the form of a better encoder trained exclusively on tweets, thus failing to extract the masked toxic and moral aspects from tweets in a multi-tasking form. Other recent works such as MEMOCLiC (Upadhyaya et al., 2023b), SP-AMT (Upadhyaya et al., 2023c) have used sentiment, emotion, and toxicity aspects for stance detection, but these models focus primarily on climate change and often suffer from the drawbacks of detecting overall stance in the case of composite tweets with contrasting emotions or complexity of tweet content due to sarcasm. It has been proven that the valence, arousal, and dominance features help in analyzing emotional tone and its intensity (Osgood et al., 1957; Russell, 1980, 2003; Mohammad, 2022), which eventually supports the detection of hidden intent or any sarcasm present in the tweet (Vitman et al., 2022). Therefore, our approach leverages these interdependencies to extract additional features of valence, arousal, and dominance (VAD) along with insult, morality, and speech act to understand the psychology of the tweet and gain emotional insights. These features can then ultimately help identify the collective meaning and intent of the tweet, aiding in the detection of attitudes and thus addressing the drawbacks of the presence of sarcasm and implicit stance from previous works.\nThe main contributions of our work are as follows: (i.) To the best of our knowledge, this is the\nfirst cross-sectional study to incorporate toxicity, morality, and speech act to determine the tweet\u2019s stance. This opens a new dimension in psychological and social science research to investigate in-depth the interdependencies between these toxic, moral, speech acts and public opinion. (ii.) We propose a multi-tasking system TWISTED that performs the main task of stance detection (SD) by using toxicity detection (TD), morality classification (MC), and speech act classification (AC) as auxiliary tasks. Our TWISTED model first extracts the VAD features to capture the associated emotions and intentions of the tweet. EmoSenseInjector then induces the emotional sense to the tweet by integrating the embedded text with the VAD vectors. The emotionally enriched tweet is followed by an efficient attention framework that uses the task-specific and shared toxic, moral, and act features to identify the attitude of the tweet (favor/against/none). (iii.) Extensive experiments are conducted on 4 benchmark stance detection datasets (SemEval-2016, P-Stance, ClimateChange, COVID-19-Stance) and the reported experimental results demonstrate the usefulness of our approach. The code and datasets with annotations are available here3."
        },
        {
            "heading": "2 Related Works",
            "text": "Stance detection has been investigated in a number of studies. Some of the existing works focus on exploring the impact and influence of polarizing attitudes (Chitra and Musco, 2020), while others use the characteristics of tweet texts or networks to classify attitudes towards a target domain by developing machine and deep learning algorithms (Dutta et al., 2022; Upadhyaya et al., 2023d). Since it is critical to understand public attitudes toward any pressing issue, our study also focuses on detecting the stance of a tweet text toward an urgent social issue. This can help technology companies and government agencies monitor public opinions and intervene to curb the spread of fake news, misinformation, or online hatred that can harm the peace.\nPrevious works have enriched the stance task with popular datasets covering controversial topics such as feminism, abortion, political leaders, COVID-19, and the climate crisis (Mohammad et al., 2016; Glandt et al., 2021). Various existing studies have primarily focused on the SemEval\n3https://osf.io/en4rd/?view_only= 86e383c5bf1441d0a19f7a968ddbd6e6\n2016 dataset (Vychegzhanin and Kotelnikov, 2021; Wang and Wang, 2021) while others have focused on political and COVID domains (Zheng et al., 2022; He et al., 2022). The climate change domain, which focuses on the climate crisis, has also been recently explored for stance task (Upadhyaya et al., 2023a,b). However, in our study, we use these 4 benchmark datasets and investigate the performance of stance task that span a variety of contrasting domains with different embedding spaces of toxic, moral, and act features to understand the practicality of our approach.\nRecently, research has explored multitasking and federated learning for various classification tasks such as hate speech, toxicity detection, and infrastructure damage identification, as the MTL paradigm aims to improve generalization performance by learning multiple related tasks at once (Priya et al., 2020; Vaidya et al., 2020; Mishra et al., 2021; Badar et al., 2023; Younis et al., 2023). However, as far as we know, this is the first crosssectional study to utilize toxicity, morality, and speech act detection tasks in a multitask learning framework to identify the attitude of a tweet.\nIn addition, the existing literature pointing to the correlation between toxic and moral aspects in relation to public opinions expressed on Twitter motivated us to use these features as auxiliary tasks (Rezapour et al., 2021; Upadhyaya et al., 2023b). Different forms of speech act further help to decode the pragmatics of the author of the tweet and to identify the attitude encoded in the tweet (Saha et al., 2021). Models such as ESD (Vychegzhanin and Kotelnikov, 2021) and HAN (Wang et al., 2020) exploit the linguistic characteristics of tweets by incorporating sentiments, stylistic, and stanceindicative features. However, these earlier studies did not use the better embedding techniques by using the BERTweet encoder along with extracting VAD features that provide the emotional tone and intensity that better identify different attitudes even when similar emotions or feelings are present. Recent climate stance models use emotion and toxicity to identify stance (Upadhyaya et al., 2023b) but suffer from problems with the presence of contrasting emotions or sarcasm in the stances. However, our model addresses these problems by extracting the VAD features along with the toxic and moral aspects, which together understand the overall intent of expressed public opinion and aid the stance task."
        },
        {
            "heading": "3 Methodology",
            "text": "Problem Definition Given a tweet, we propose a stance detection approach that combines the tweet text with the extracted valence, arousal, and dominance features while taking advantage of toxic, moral, and speech act aspects associated with the tweet to efficiently detect the stance toward a target (favor/against/none). Our proposed framework TWISTED comprises of the model components: BERTweet-Encoder, VADEmbedder, EmoSense-Injector, MultiHeadAttention, and Output Layer. Figure 1 represents the overview of our TWISTED approach. The tweet is passed in parallel to the BERTweet Encoder to generate the embedding of the tweet text, and to the VAD Embedder to extract the valence, arousal, and dominance features related to the tweet. The encoded text and the VAD features are passed through the EmoSense-Injector which is responsible for integrating the emotional sense in the tweet and obtaining the emotionally intelligent representation of the input tweet. This emotion-aware tweet is then followed by the MultiHeadAttention layer to focus on the most relevant input features, followed by the task-specific dense and output layers to finally obtain the outputs of the main task of SD and the secondary tasks of TD, MC, and AC."
        },
        {
            "heading": "3.1 BERTweet Encoder",
            "text": "The input tweet text is converted into a sequence of vectors using the BERTweet encoder (Nguyen et al., 2020), which is specially trained on tweets to embed each word in the tweet text. First, the tweets are tokenized and divided into sequences of tokens of the form [CLS] t1,t2..tn, where [CLS] is a special token that marks the beginning of a tweet. In each minibatch, the input tokens are padded to a maximum sequence length (say m). The final state corresponding to the first token [CLS] is used as the overall representation of a tweet. BERTweet Encoder generates embeddings of size 768 dimensions (dt) for each input token, which is then flattened, resulting in Ft \u2208 Rm(dt)."
        },
        {
            "heading": "3.2 VAD Embedder",
            "text": "We employ NRC-VAD Lexicon (Mohammad, 2018) to acquire the valence, arousal, and dominance (VAD) features of the input tweet. The preprocessed input text (the preprocessing steps are described in the Appendix B.1) consists of tokens generated by the NLTK TweetTokenizer and then passed to the NRC-VAD lexicon. The lexicon consists of 20,000 English words, with each word having a probabilistic score for all three aspects of valence, arousal, and dominance. The VAD scores of each token in the input text are then multiplied by the occurrence of that token for all 3 dimensions (V, A, and D), summed, and aggregated to create a single vector of dimension 3 (dv) for each input tweet. The final feature representing the VAD embedding space for each input tweet is thus Fv \u2208 Rdv ."
        },
        {
            "heading": "3.3 EmoSense-Injector",
            "text": "The component is accountable for incorporating the emotional sense and intensity extracted from the VAD features into the embedded tweet text to obtain an overall representation of the input tweet in accordance with the associated emotions. The text (Ft) and VAD (Fv) feature vectors are initially passed through a fully connected layer of dimension de. The resulting text and VAD vectors are then fused using absolute difference and elementwise product (refer Equation 1), as the fusion technique has been proven efficient in various classification studies (Mou et al., 2015). The integrated output is then reshaped (Eeit \u2208 R1\u00d74(de)) and finally represents the emotionally intelligent tweet that captures the essence of the emotions present along with the semantic and syntactic contextual\ntext representation.\nEeit = [Ft;Fv;Ft \u2212 Fv;Ft \u2299 Fv] (1)"
        },
        {
            "heading": "3.4 MultiHeadAttention",
            "text": "We use the MultiHeadAttention similar to (Vaswani et al., 2017) based on the concept of query (Q), key (K), and value (V) to jointly capture the most relevant parts of the input feature from different representation subspaces. Instead of performing a single attention layer (refer Equation 3), Q, K, and V are linearly projected h times (where h denotes the number of heads) and Attention function (Equation 3) is performed in these different learned projections of Q, K, and V in parallel. These outputs of parallel attention functions are concatenated and once again projected, resulting in the final attention vector. To perform MHA, we employ tfa.layers.MultiHeadAttention layer4, where the output of EmoSense-Injector (Eeit) is fed as query, key, and value to the MultiHeadAttention layer of TensorFlow.\nQ = Eeit,K = Eeit, V = Eeit (2)\nAttention = softmax(QKT )V (3)\nmha = MultiHeadAttention(hs, h) (4)\nMHAop = mha([Q,K, V ]) (5)\nEquations 4 and 5 represent the MultiHeadAttention TensorFlow layer being implemented where h denotes the number of heads indicating the number of times the single Attention function (shown in Equation 3) is performed, hs specify the size of the head, and Eeit is used as query, key, and value, resulting in MHAop \u2208 R1\u00d74(de)."
        },
        {
            "heading": "3.5 Output Layer",
            "text": "The shared output of MultiHeadAttention (MHAop) component is passed through the taskspecific dense layers of dimension [dd] (Densesd, Densetd, Densemc, Denseac) followed by four softmax layers for capturing the final output specific to each task of SD (Osd), TD (Otd), MC (Omc), and AC (Oac) separately. The integrated loss function (L) of our TWISTED framework is realized in equation 6 indicating loss for each specific task of SD (Lsd), TD (Ltd), MC (Lmc), and AC (Lac):\nL = p \u2217 Lsd + q \u2217 Ltd + r \u2217 Lmc + s \u2217 Lac (6) 4https://www.tensorflow.org/addons/api_docs/\npython/tfa/layers/MultiHeadAttention\nwhere p, q, r, and s are the values between 0 and 1 and show the ratio of loss of each task to total loss."
        },
        {
            "heading": "4 Experimental Set-up",
            "text": ""
        },
        {
            "heading": "4.1 Datasets",
            "text": "We use the 4 benchmark datasets of stance detection containing different targets: (i) SemEval-2016 (Mohammad et al., 2016): is a popular dataset used in SemEval-2016 shared task 6.A that covers Atheism, Climate Change is a Real Concern, Feminist Movement, Hillary Clinton, and Abortion as targets with tweets having favor, against, or neutral stances. (ii) P-Stance (Li et al., 2021b): is a political stance dataset containing 7, 953 annotated tweets for \u201cDonald Trump\u201d, 7, 296 for \u201cJoe Biden\u201d and 6,325 for \u201cBernie Sanders\u201d as target domains with favor and against stances. (ii) ClimateChange (Upadhyaya et al., 2023b): In this benchmark dataset, 8, 881 climate tweets are included that have believe, deny, and ambiguous views regarding climate change. (iv) COVID-19-Stance (Glandt et al., 2021) is a dataset of pandemicrelated 6, 133 tweets on four controversial topics (\"Anthony S. Fauci, M.D (Director of the National Institute of Allergy and Infectious Diseases),\" \"stay at home orders\" \"wearing a face mask,\" and \"keeping schools closed\") and consists of stances (\"FAVOR\", \"AGAINST\", \"NONE\") on these topics."
        },
        {
            "heading": "4.1.1 Data Annotation",
            "text": "All publicly available datasets consist of annotations of stances, however, to find the toxic, moral, and speech act labels, we follow the below weaksupervised approaches. Toxicity Detection (TD) Similar to previous works (Hickey et al., 2023; Upadhyaya et al., 2023b), the Perspective API developed by Jigsaw and Google\u2019s Counter Abuse Technology team in ConversationAI (Hosseini et al., 2017) is used to provide labels for the TD task. We use the probability value (0-1) for the \"toxicity\" metric returned by the API. After careful analysis of various thresholds and in-line with existing literature (Upadhyaya et al., 2023b), we decided that if the value of the \"toxicity\" attribute is \u2265 0.5, we consider the tweet to be toxic so as not to miss any toxic content, otherwise, the tweet will be labeled as non_toxic. Morality Classification (MC) We leverage the extended version of the Moral Foundation Dictionary (eMFD) (Hopp et al., 2021) for MC task annotation. The open-source Python library \"eMFD-\nscore\"5 provides the scores for the 10 moral classes according to the sociological theory of Moral Foundations Theory (MFT), which identifies morality as a set of vice virtues, including care\u2013harm, fairness\u2013cheating, loyalty\u2013betrayal, authority\u2013subversion, and purity\u2013degradation (Graham et al., 2013). The tweet text is fed into the eMFDScore library (with DICT_TYPE =\u2018emfd\u2019, PROB_ MAP = \u2018all\u2019, SCORE_ METHOD = \u2018bow\u2019, OUT_ METRICS = \u2018vice-virtue\u2019 as parameter values), which first preprocesses the text and assigns a list of 10 foundation scores indicating the degree to which each tweet reflects the moral values. To facilitate the performance of morality as a multilabel classification task, in our study, after manual review and careful analysis, we convert the list of probabilistic scores into a list of 0s and 1s indicating the presence/absence of the corresponding moral attribute. To achieve this, we first compute the mean (mean) and standard deviation (\u03c3) of the list of 10 moral scores and consider threshold as (mean + \u03c3). If the value of an attribute is > threshold, we marked the presence of the corresponding attribute as \"1\", otherwise as \"0\". The final label of each tweet for the MC task results in the list of 10 elements being 0 or 1 (for example: MC label=[1,0,1,0,0,0,0,0,1,0], suggesting the presence of the moral values care, fairness, and purity/sanctity). Speech Act Classification (SC) We use the pretrained benchmark speech act classifier trained on the gold-standard speech act tweet corpus (Saha et al., 2021), which contains 6749 tweets, to provide weak speech act labels for the instances of the 4 stance datasets used in our study. Since the pre-trained classifier performs better on the 5-class classification of speech acts, we also extract the speech act labels for the tweets of the 4 stance datasets in the form of expression, question, statement, suggestion, and others. The data pre-processing, % distribution of auxiliary features, and manual verification of labels generated by weakly supervised approaches are mentioned in Appendix B."
        },
        {
            "heading": "4.2 Implementation Details",
            "text": "Hyperparameters: maximum sequence length (m): 128; BERTweet embedding dimension (dt): 768; VAD feature dimension (dv): 3; EmoSense-\n5https://github.com/medianeuroscience/ emfdscore\nInjector dense layer dimension (de) [with ReLu activation]: 128; MultiHeadAttention parameters: 8 [number of heads (h)], 64 [head_size (hs)]; taskspecific dense layer dimension (dd) [with ReLu activation]: 128, output neurons/channels for auxiliary tasks: 2 [softmax activation] (TD), 10 [sigmoid activation] (MC), and 5 [softmax activation] (AC), loss function for auxiliary: categorical crossentropy for TD (Ltd) and AC (Lac); binary crossentropy for MC (Lmc), output neurons for main SD task: P-Stance dataset= 2 output neurons and binary cross-entropy for SD (presence of \"favor\" and \"against\" stances); SemEval, ClimateChange, COVID datasets= 3 output channels and categorical cross-entropy loss for SD (Lsd), Optimizer: Adam (0.0001 learning rate), batch_size: 32. The best parameter values are selected using TPE in the Python library Hyperopt6, which minimizes loss functions. The loss weights for all tasks are fine-tuned using Grid Search from Scikit-learn (SD (p)=1, TD (q)=0.5, MC (r)=0.3, and AC (s)=0.4). Evaluation Metrics: We use already available train, validation, and test splits of the SemEval2016, P-Stance, and COVID-19-Stance datasets, perform 5 independent runs of our framework to account for variability, and report the macro-average of the F1-score as the evaluation metric. For SemEVAL-2016 (does not consider None stance label for performance evaluation) and P-Stance (consists of 2 stance labels), Favg = (Ffavor + Fagainst)/2, similar to their proposed works (Mohammad et al., 2016; Li et al., 2021b) and Favg = (Ffavor + Fagainst + Fnone)/3 for COVID-19Stance dataset (Glandt et al., 2021; He et al., 2022). In-line with existing work that proposed ClimateChange data (Upadhyaya et al., 2023b), we implement our TWISTED approach with 5-fold crossvalidation technique and report the average and standard deviation of macro-variant of precision, recall, F1-score as the performance metrics. Environment Details: described in Appendix C."
        },
        {
            "heading": "4.3 Baselines",
            "text": "All experimental results of the baselines used on all the datasets are retrieved from the original papers. SemEval-2016 We compare TWISTED with the recent works that use this dataset: SemiSupervised(Model3) (Reveilhac and Schneider, 2023), MEMOCLiC (Upadhyaya et al., 2023b), SPAMT (Upadhyaya et al., 2023c), MT-LRM-BERT\n6http://hyperopt.github.io/hyperopt/\n(Fu et al., 2022), MDMT (Wang and Wang, 2021), ESD (Vychegzhanin and Kotelnikov, 2021), HAN (Wang et al., 2020), AT-JSS-LEX(Li and Caragea, 2019), and SVM-ngram (Sobhani et al., 2016). P-Stance We take the baseline and best-performing models reported in recent works (Liu et al., 2023; Zheng et al., 2022; He et al., 2022): In-Domain Intarget variant RoBERTa-base (Liu et al., 2023) (we re-run the model with respect to \"Trump\", \"Biden\", and \"Bernie\" separately as results reported in the paper are on the complete dataset), WS-BERT-Dual (He et al., 2022), BERTweet (Nguyen et al., 2020), BERT (Devlin et al., 2019), PGNN (Huang and Carley, 2018), TAN (Du et al., 2017), and BiCE (Augenstein et al., 2016). ClimateChange We use the baselines as is from the work that proposed data (Upadhyaya et al., 2023b) and report average of macro-variant of precision, recall, and F1-score: SP-AMT (Upadhyaya et al., 2023c), RoBERTa-Base (Vaid et al., 2022), MTLRM BERT (Fu et al., 2022), S-MDMT (Wang and Wang, 2021), ESD (Vychegzhanin and Kotelnikov, 2021), HAN (Wang et al., 2020), MNB (Kabaghe and Qin, 2020), and DNN (Chen et al., 2019). COVID-19-Stance Below are best-performing and baseline models mentioned in recent literature (Upadhyaya et al., 2023d; Zheng et al., 2022; He et al., 2022): STASY (Upadhyaya et al., 2023d), WS-BERT-Dual (He et al., 2022), CT-BERT-DAN (Glandt et al., 2021), GCAE (Xue and Li, 2018), ATGRU (Zhou et al., 2017), and TAN (Du et al., 2017)."
        },
        {
            "heading": "5 Results",
            "text": "Please note that we report the results of the main task SD as we aim to improve the performance of the primary task by using other auxiliary tasks in our current study. SemEval-2016 Table 1 shows that our TWISTED\nmodel outperforms the other baselines with a overall Mac-Favg of 77.87, resulting in an average F1 score performance improvement of 3.22% to 34.24%. This demonstrates the importance of using features such as toxicity, morality, and speech act in the context of the SD task. In addition, we find that TWISTED performs better, especially in the feminism, Hillary, and abortion domains, because of a clearer separation between favor, against, and none stances in terms of their hidden offensive and moral aspects (see Table 6 in Appendix). However, our approach does not beat the Model3 baseline on \"atheism\" domain and performs second best, although the tasks TD and AC contributed well due to the clear distinction in their embedding spaces with respect to the different attitudes, but the moral values between the 3 stance classes are much more closely aligned, making it difficult for TWISTED to distinguish between all stance classes (refer Appendix Table 6). WKNN achieves a slightly better result than TWISTED (78.74) with 79.95 Favg on \"climate\". This is due to the fact that the dataset contains only 29 tweets from deniers, which makes it difficult to capture different speech act and moral labels such as betrayal, subversion, purity, and question (Appendix Table 6) due to the very low availability of token words, however, the significant differences in VAD features (see VAD features in the dataset3) between stance labels and the clearer separation between toxic and non-toxic content embedded using the BERTweet model trained exclusively on tweets contribute to TWISTED being the second best performer among baselines on \"climate\" target domain.\nP-Stance From Table 2, our TWISTED model performs better than Trump in Sanders and Biden, as shown by the 1.7%, 7.1%, and 7.4% improvement in F1 results, respectively, compared to the secondbest performing baseline (WS-BERT-Dual). This is mainly due to the fact that supporters and opponents in Sanders (28.98 diff.) and Biden (26.14\ndiff.) domains show a better-dividing line in terms of toxic characteristics than Trump (17.23 diff.) (refer Appendix Table 7). Nevertheless, TWISTED, with an average macro-F1 score of 87.2 and an overall average improvement of 11.61%, outperforms the baselines, justifying the usefulness of our multitasking approach in inducing emotional meaning in tweets using VAD feature extraction and an efficient attention framework in the political domain. ClimateChange Table 3 indicates that TWISTED performs better than the other baselines with an average percentage improvement of 13.14% in the F1 score. Although MEMOCLiC extracts the emotional and toxic features in a multitasking environment to identify the underlying attitude of the tweet, but the performance power of our EmoSense injector, which injects the VAD features, understanding not only the emotional quotient of the tweet, but also the intensity and tone along with the hidden moral and linguistic features, is one of the main reasons contributing to the success of TWISTED compared to the recent works MEMOCLiC, SPAMT. We note that deniers\u2019 tweets have a high proportion of bad moral values (harm, betrayal, and humiliation) and toxic content (Appendix Table 8), demonstrating the usefulness of our approach for government agencies or technology companies that need to monitor such content before it leads to a delay in appropriate climate action. Models such as MEMOCliC, SP-AMT, and MT-LRM-BERT, which take advantage of toxicity, emotion, sentiment, or opinion formation tasks, perform better than other baselines, proving the effectiveness of these auxiliary tasks for the SD. COVID-19-Stance Table 4 proves the efficacy of our TWISTED model in detecting attitudes that occurred during the controversial COVID topics\n\"Fauci\", \"Home\", and \"Schools\" with the exception of the topic \"wearing a face mask (Mask)\". We note that WS-BERT-DUAL performs better on the \"MASK \"topic than TWISTED, as the data distribution of the aspects of \"toxic\", \"non-toxic\", and \"expression of speech act\" are close among supporters and opponents, and the percentage of vices in the form of \"harm\", \"cheating,\" and \"degradation\" are similar among the against and none stance labels (see Appendix Table 9), which prevents the TWISTED approach from clearly distinguishing the polarized labels for the SD task. It can also be seen from Table 4 that the STASY model, which uses the sentiments and temporal aspects present in the tweets belonging to different public opinions, gives better results than other baselines, proving the need to identify hidden aspects in the tweets that can be used for the task SD. However, the average macro F1 score of 89.44 achieved by TWISTED suggests that our approach is also well suited for the important social issues in the domain COVID.\nCompared with the baselines, the results of TWISTED were statistically significant (under t-tests (p <0.05). The better performance of TWISTED in various target areas such as feminism, abortion, politics, climate, and COVID and comparable performance in other subject domains proves the usefulness of our approach and the generalizability of our system.\nAblation Study Here we examine the effects of single-task, all the auxiliary tasks and their combinations for the stance task as part of the ablation study. Figure 2 shows the macro-average F1 score of all 4 datasets when performing the main task SD with different combinations of auxiliary tasks such as SD (Single-task), SD+TD, SD+MC, SD+AC, SD+TD+MC, SD+TC+AC, SD+AC+MC, SD+TD+MC+AC (all). Figure 2 clearly shows that the single-task variant of our TWISTED approach is the worst performer when compared with other auxiliary task combinations, suggesting the potency of using auxiliary tasks for SD. It is fur-\nther evident from the figure, toxic and non-toxic features associated with tweet text help the attitude task more effectively than the other tasks MC and AC due to their significant differences in distribution among \"favor\", \"against\", and \"none\" stances (see Appendix Tables 6, 7, 8, and 9). This also justifies the assignment of higher loss weight to TD task than MC and AC tasks. Moreover, the 3-task combination SD+TD+AC contributes more than the tasks SD+TD+MC and SD+MC+AC, further proving that expression, statement, query, and other speech acts are more consistent with the toxic aspects of tweets. However, the performance improvement of TWISTED on all 4 data sets when all 3 secondary tasks are used (SD+TD+MC+AC) confirms the importance of all 3 tasks for main SD.\nThe case studies and possible error scenarios of our framework are described in Appendix A and Table 5. Furthermore, the ablation study showing the importance of our proposed components for the ClimateChange and COVID-19 datasets is mentioned in the Appendix D."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this work, we present the first cross-sectional study focusing on the problem of stance detection using the associated toxic, moral, and speech act traits present in tweets. Our proposed approach is enriched with the emotional quotient of the tweet by extracting the VAD features and further integrating them into the embedded tweet, thus evoking the emotional intent of the tweet. The experimental results on 4 benchmark datasets indicate that multitasking enhances the performance of the stance\ntask by exploiting the efficient attention and encoder frameworks along with the auxiliary tasks. This demonstrates that the model is widely applicable in multiple domains, proving the generalizability of our proposed approach. In the future, we plan to include additional tasks such as entityrecognition and aspect-based sentiment detection, which could help disambiguate the attitudes and conflicting emotions in a tweet to predict a more accurate classification of polarized attitudes toward a target domain."
        },
        {
            "heading": "Limitations",
            "text": "The error scenarios listed in Appendix A.1 (Table 5), which arise from the proximity of auxiliary features between stance categories and the ambiguity in stances, primarily describe the limitations of our approach. However, we plan to focus on the categorization of tweets, entity detection for identifying targets, and extraction of causes behind the stances in our future work to further improve the performance of the classification task. Moreover, in our current work, we do not investigate the SD task with the advancement of large language models such as ChatGPT. However, it would be interesting to investigate the performance of ChatGPT with chain-of-thought (CoT) prompting and find out if there are inherent biases in LLMs toward a particular target domain for the task SD, which would lead us in future research direction."
        },
        {
            "heading": "Ethics Statement",
            "text": "Our study uses publicly available datasets and we only extend the datasets with the toxicity, morality, and speech act annotations. We obeyed the restrictions on data use and did not violate any copyright issues. Since the datasets are online-generated content, we only share the tweet IDs and annotations to comply with the terms of use and protect individual privacy."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was partly funded by the SoMeCliCS project under the Volkswagen Stiftung and Nieders\u00e4chsisches Ministerium f\u00fcr Wissenschaft und Kultur."
        },
        {
            "heading": "A Case Studies",
            "text": "To gain insight into the predictive performance of our approach, we present some of the predictions by different variants of our approach in Table 5. The red markers in the labels indicate incorrect predictions. Examples 1 and 3 are correctly detected by our model. The tweets do contain contrasting emotions, with the first sentence being positive but the second part containing negative emotions, leading to a hint of sarcasm in the tweet. However, the presence of dominant toxic, moral, and linguistic features found in the tweets of \"Sanders against attitude\" and \"climate denier\" correctly captures the overall intent and attitude of the tweet, thus eliminating the drawbacks of the previous works. In Example 2, it can be seen that the combination of SD +TD+ MC is not able to correctly identify the stance, as the moral features \" harm\" and \"degradation\" are more common in the \"none\" and \"favor\" stance categories of the \"feminism\" domain. Due to the toxic and suggestive language that is more prevalent in the \"Against\" and \"Climate Denier\" categories, SD +TD+ AC and the combinations of all tasks correctly predict attitude, justifying the higher loss weight for the tweet act than for the moral classification task. We list some possible reasons for the errors in the SD task."
        },
        {
            "heading": "A.1 Error Scenarios",
            "text": "(i) Close Proximity of auxiliary features among stances: As shown in Examples 4 and 5, TWISTED does not correctly identify stances due to the close correspondence of attitudes with respect to the extracted virtue, vice, toxic, or act features, especially in the atheism and mask domains, which lead to scenarios in which auxiliary tasks are not helpful. The toxic, harm, subversion, and degradation features, as well as the speech act expression in Example 4, are more prevalent in the favor attitude category, while Example 5 contains\nthe non_toxic, harm, betrayal features that are common in the none stance category of the face_masks domain. This leads to poor performance of our TWISTED approach in these target domains compared to other basic tasks. (ii) Ambiguity/Conflicting Stances: Some tweets have a contradictory attitude, either toward a single target or toward multiple targets. In Example 6, we can see that the tweeter believes that climate change is real, but does not believe in climate action by government officials. Such scenarios are misclassified by our approach, although further categorization of the target or identification of multiple targets could be further helpful for the task SD."
        },
        {
            "heading": "B Dataset",
            "text": ""
        },
        {
            "heading": "B.1 Data Pre-processing",
            "text": "Since removing query hashtags may result in the tweet not expressing the same attitude, we first also remove the query hashtags from the datasets in accordance with previous literature (Mohammad et al., 2016). We then clean up the tweets by removing URLs, punctuation, spaces, stop words, and unwanted characters like RT and CC. To tokenize tweets, we use the NLTK-based TweetTokenizer. Tokens are converted to lowercase and then stemmed with PorterStemmer, which reduces words to their stems and suffixes."
        },
        {
            "heading": "B.2 Percentage Distribution of features in Datasets",
            "text": "Tables 6, 7, 8, and 9 represent the percentage distribution of toxic (toxic/non_toxic), moral (care, harm, fairness, cheating, loyalty, betrayal, authority, subversion, purity, degradation) and speech act (expression, others, question, statement, suggestion) among the different categories of attitudes ( favor, against, none) corresponding to the SemEval-2016, P-Stance, ClimateChange, and COVID -19-Stance datasets respectively."
        },
        {
            "heading": "B.3 Manual Verification",
            "text": "To examine the annotations of weakly supervised approaches, three trained annotators randomly selected 200 tweets from 4 datasets used in our study, yielding a total of 1000 tweets, and performed manual annotations to provide toxic, moral, and speech act labels (the inter-annotator agreement was calculated using the Fleiss-Kappa score and was 0.82). We then matched these manual annotations with\nAttribute ClimateChange\nbelieve deny ambiguous Toxicity Detection\ntoxic 3.94 21.65 5.34 non_toxic 96.06 78.35 94.66 Moral Classification care 18.67 14.68 18.15 harm 38.78 45.09 42.78 fairness 14.77 9.41 13.97 cheating 16.06 15.9 14.48 loyalty 22.38 20.88 19.44 betrayal 8.41 9.2 8.82 authority 12.9 14.27 8.76 subversion 15.6 15.8 18.44 purity 10.25 9.2 9.19 degradation 11.91 16.36 14.06 Speech Act Classification expression 44.8 46.45 37.63 others 16.3 14.75 12.6 question 3.78 3.83 3.77 statement 24.94 29.12 35.94 suggestion 10.17 5.84 10.06\nTable 8: Percentage distribution of toxic, moral, and act features in ClimateChange dataset"
        },
        {
            "heading": "Multi Task Set-up",
            "text": ""
        },
        {
            "heading": "Component Fauci Home Mask Schools Single Task Set-up",
            "text": ""
        },
        {
            "heading": "Multi Task Set-up",
            "text": "labels generated by semi-supervised approaches for the same 1000 tweets and found Fleiss-Kappa (Spitzer et al., 1967) scores of 0.81, 0.76, and 0.79 for toxic, moral, and speech acts, respectively, indicating that the labels predicted by semi-supervised approaches are of considerably good quality."
        },
        {
            "heading": "C Environment Details",
            "text": "GPU Model: NVIDIA GeForce GTX 1080Ti GPU servers (TDP of 250W) with carbon efficiency of 0.38 kgCO2eq/kWh, Library Version: Tensorflow 2.12.0, Keras 2.12.0, Transformers 4.30.2, Computational Cost: On an average, 30 minutes training time for TWISTED for one round. Average 5 rounds for each reported result for SemEval, P-Stance, and COVID, while the 5-fold cross-validation technique in Climate takes approximately 2 hours executing time, resulting in a total of 10 hours of computation, leading to \u2248 0.95 kgCO2eq carbon emissions. Carbon footprint is calculated using the Machine Learning Impact calculator (Lacoste et al., 2019)."
        },
        {
            "heading": "D Significance of Components",
            "text": "Tables 10 and 11 justify the significance of each proposed component of our TWISTED approach. In addition, the tables 10 and 11 present the results of single-task and multi-task setups for detecting stance on the ClimateChange and COVID-19 datasets, respectively, and show the improvement in the performance of the model in addition to each component."
        }
    ],
    "title": "Toxicity, Morality, and Speech Act Guided Stance Detection",
    "year": 2023
}