{
    "abstractText": "Online forums encourage the exchange and discussion of different stances on many topics. Not only do they provide an opportunity to present one\u2019s own arguments, but may also gather a broad cross-section of others\u2019 arguments. However, the resulting long discussions are difficult to overview. This paper presents a novel unsupervised approach using large language models (LLMs) to generating indicative summaries for long discussions that basically serve as tables of contents. Our approach first clusters argument sentences, generates cluster labels as abstractive summaries, and classifies the generated cluster labels into argumentation frames resulting in a two-level summary. Based on an extensively optimized prompt engineering approach, we evaluate 19 LLMs for generative cluster labeling and frame classification. To evaluate the usefulness of our indicative summaries, we conduct a purpose-driven user study via a new visual interface called DISCUSSION EXPLORER: It shows that our proposed indicative summaries serve as a convenient navigation tool to explore long discussions.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Shahbaz Syed"
        },
        {
            "affiliations": [],
            "name": "Dominik Schwabe"
        },
        {
            "affiliations": [],
            "name": "Khalid Al-Khatib"
        },
        {
            "affiliations": [],
            "name": "Martin Potthast"
        }
    ],
    "id": "SP:4195328048c7aceb4c6ae19c6fd517abb6b67fc7",
    "references": [
        {
            "authors": [
                "Yamen Ajjour",
                "Milad Alshomary",
                "Henning Wachsmuth",
                "Benno Stein."
            ],
            "title": "Modeling frames in argumentation",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natu-",
            "year": 2019
        },
        {
            "authors": [
                "Christopher Akiki",
                "Odunayo Ogundepo",
                "Aleksandra Piktus",
                "Xinyu Zhang",
                "Akintunde Oladipo",
                "Jimmy Lin",
                "Martin Potthast."
            ],
            "title": "Spacerini: Plug-andplay search engines with pyserini and hugging face",
            "venue": "CoRR, abs/2302.14534.",
            "year": 2023
        },
        {
            "authors": [
                "Maged S. Al-shaibani",
                "Shanya Sharma",
                "Urmish Thakker",
                "Khalid Almubarak",
                "Xiangru Tang",
                "Mike Tian-Jian Jiang",
                "Alexander M. Rush"
            ],
            "title": "Promptsource: An integrated development environment and repository for natural language",
            "year": 2022
        },
        {
            "authors": [
                "Roy Bar-Haim",
                "Lilach Eden",
                "Roni Friedman",
                "Yoav Kantor",
                "Dan Lahav",
                "Noam Slonim."
            ],
            "title": "From arguments to key points: Towards automatic argument summarization",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Lin-",
            "year": 2020
        },
        {
            "authors": [
                "Roy Bar-Haim",
                "Yoav Kantor",
                "Lilach Eden",
                "Roni Friedman",
                "Dan Lahav",
                "Noam Slonim."
            ],
            "title": "Quantitative argument summarization and beyond: Crossdomain key point analysis",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural",
            "year": 2020
        },
        {
            "authors": [
                "Sumit Bhatia",
                "Prakhar Biyani",
                "Prasenjit Mitra"
            ],
            "title": "Summarizing online forum discussions \u2013 can dialogue acts of individual messages help",
            "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
            "year": 2014
        },
        {
            "authors": [
                "Sid Black",
                "Leo Gao",
                "Phil Wang",
                "Connor Leahy",
                "Stella Biderman"
            ],
            "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with MeshTensorflow",
            "year": 2021
        },
        {
            "authors": [
                "Amber E. Boydstun",
                "Dallas Card",
                "Justin Gross",
                "Paul Resnick",
                "Noah A. Smith"
            ],
            "title": "Tracking the development of media frames within and across policy issues",
            "year": 2014
        },
        {
            "authors": [
                "Xiaoyan Cai",
                "Wenjie Li",
                "Ouyang You",
                "Hong Yan."
            ],
            "title": "Simultaneous ranking and clustering of sentences: A reinforcement approach to multi-document summarization",
            "venue": "COLING 2010, 23rd International Conference on Computational Linguistics, Pro-",
            "year": 2010
        },
        {
            "authors": [
                "Ricardo J.G.B. Campello",
                "Davoud Moulavi",
                "J\u00f6rg Sander."
            ],
            "title": "Density-based clustering based on hierarchical density estimates",
            "venue": "Advances in Knowledge Discovery and Data Mining, 17th Pacific-Asia Conference, PAKDD 2013, Gold Coast, Australia,",
            "year": 2013
        },
        {
            "authors": [
                "Wei-Lin Chiang",
                "Zhuohan Li",
                "Zi Lin",
                "Ying Sheng",
                "Zhanghao Wu",
                "Hao Zhang",
                "Lianmin Zheng",
                "Siyuan Zhuang",
                "Yonghao Zhuang",
                "Joseph E. Gonzalez",
                "Ion Stoica",
                "Eric P. Xing"
            ],
            "title": "Vicuna: An opensource chatbot impressing gpt-4 with 90%* chatgpt",
            "year": 2023
        },
        {
            "authors": [
                "Gordon V. Cormack",
                "Charles L.A. Clarke",
                "Stefan B\u00fcttcher."
            ],
            "title": "Reciprocal rank fusion outperforms condorcet and individual rank learning methods",
            "venue": "Proceedings of the 32nd Annual International ACM SIGIR Conference on Research and Development",
            "year": 2009
        },
        {
            "authors": [
                "Charlie Egan",
                "Advaith Siddharthan",
                "Adam Wyner."
            ],
            "title": "Summarising the points made in online political debates",
            "venue": "Proceedings of the Third Workshop on Argument Mining (ArgMining2016), pages 134\u2013 143, Berlin, Germany. Association for Computational",
            "year": 2016
        },
        {
            "authors": [
                "Robert M Entman."
            ],
            "title": "Framing: Towards clarification of a fractured paradigm",
            "venue": "McQuail\u2019s reader in mass communication theory, 390:397.",
            "year": 1993
        },
        {
            "authors": [
                "Ori Ernst",
                "Avi Caciularu",
                "Ori Shapira",
                "Ramakanth Pasunuru",
                "Mohit Bansal",
                "Jacob Goldberger",
                "Ido Dagan."
            ],
            "title": "Proposition-level clustering for multidocument summarization",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of",
            "year": 2022
        },
        {
            "authors": [
                "Tanvir Ahmed Fuad",
                "Mir Tafseer Nayeem",
                "Asif Mahmud",
                "Yllias Chali."
            ],
            "title": "Neural sentence fusion for diversity driven abstractive multi-document summarization",
            "venue": "Comput. Speech Lang., 58:216\u2013230.",
            "year": 2019
        },
        {
            "authors": [
                "Tim Gollub",
                "Matthias Busse",
                "Benno Stein",
                "Matthias Hagen."
            ],
            "title": "Keyqueries for clustering and labeling",
            "venue": "Information Retrieval Technology - 12th Asia Information Retrieval Societies Conference, AIRS 2016, Beijing, China, November 30 - December 2, 2016,",
            "year": 2016
        },
        {
            "authors": [
                "Maarten Grootendorst."
            ],
            "title": "Bertopic: Neural topic modeling with a class-based TF-IDF procedure",
            "venue": "CoRR, abs/2203.05794.",
            "year": 2022
        },
        {
            "authors": [
                "Felix Hamborg",
                "Anastasia Zhukova",
                "Bela Gipp."
            ],
            "title": "Automated identification of media bias by word choice and labeling in news articles",
            "venue": "19th ACM/IEEE Joint Conference on Digital Libraries, JCDL 2019, Champaign, IL, USA, June 2-6, 2019,",
            "year": 2019
        },
        {
            "authors": [
                "Felix Hamborg",
                "Anastasia Zhukova",
                "Bela Gipp."
            ],
            "title": "Illegal aliens or undocumented immigrants? towards the automated identification of bias by word choice and labeling",
            "venue": "Information in Contemporary Society - 14th International Conference, iConference",
            "year": 2019
        },
        {
            "authors": [
                "Philipp Heinisch",
                "Philipp Cimiano."
            ],
            "title": "A multitask approach to argument frame classification at variable granularity levels",
            "venue": "it - Information Technology, 63(1):59\u201372.",
            "year": 2021
        },
        {
            "authors": [
                "Ryuji Kano",
                "Yasuhide Miura",
                "Motoki Taniguchi",
                "YanYing Chen",
                "Francine Chen",
                "Tomoko Ohkuma."
            ],
            "title": "Harnessing popularity in social media for extractive summarization of online conversations",
            "venue": "Proceedings of the 2018 Conference on Empir-",
            "year": 2018
        },
        {
            "authors": [
                "Maurice George Kendall"
            ],
            "title": "Rank correlation methods",
            "year": 1948
        },
        {
            "authors": [
                "Mike Klaas."
            ],
            "title": "Toward indicative discussion fora summarization",
            "venue": "UBC CS TR-2005, 4.",
            "year": 2005
        },
        {
            "authors": [
                "Christoph Schuhmann",
                "Huu Nguyen",
                "Alexander Mattick."
            ],
            "title": "Openassistant conversations - democratizing large language model alignment",
            "venue": "CoRR, abs/2304.07327.",
            "year": 2023
        },
        {
            "authors": [
                "Yuhui Zhang",
                "Yuta Koreeda."
            ],
            "title": "Holistic evaluation of language models",
            "venue": "CoRR, abs/2211.09110.",
            "year": 2022
        },
        {
            "authors": [
                "Siyi Liu",
                "Lei Guo",
                "Kate K. Mays",
                "Margrit Betke",
                "Derry Tanti Wijaya"
            ],
            "title": "Detecting frames in news headlines and its application to analyzing news framing trends surrounding U.S. gun violence",
            "venue": "In Proceedings of the 23rd Conference on Computational",
            "year": 2019
        },
        {
            "authors": [
                "Christopher D. Manning",
                "Prabhakar Raghavan",
                "Hinrich Sch\u00fctze."
            ],
            "title": "Introduction to information retrieval",
            "venue": "Cambridge University Press.",
            "year": 2008
        },
        {
            "authors": [
                "Leland McInnes",
                "John Healy",
                "sk Steve Astels"
            ],
            "title": "hdbscan: Hierarchical density based clustering",
            "venue": "J. open-source Softw.,",
            "year": 2017
        },
        {
            "authors": [
                "Rada Mihalcea",
                "Paul Tarau."
            ],
            "title": "TextRank: Bringing order into text",
            "venue": "Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 404\u2013411, Barcelona, Spain. Association for Computational Linguistics.",
            "year": 2004
        },
        {
            "authors": [
                "Amita Misra",
                "Pranav Anand",
                "Jean E. Fox Tree",
                "Marilyn Walker."
            ],
            "title": "Using summarization to discover argument facets in online idealogical dialogue",
            "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computa-",
            "year": 2015
        },
        {
            "authors": [
                "Fred Morstatter",
                "Liang Wu",
                "Uraz Yavanoglu",
                "Steven R. Corman",
                "Huan Liu."
            ],
            "title": "Identifying framing bias in online news",
            "venue": "ACM Trans. Soc. Comput., 1(2):5:1\u20135:18.",
            "year": 2018
        },
        {
            "authors": [
                "Nona Naderi",
                "Graeme Hirst."
            ],
            "title": "Classifying frames at the sentence level in news articles",
            "venue": "Proceedings of the International Conference Recent Advances in Natural Language Processing, RANLP 2017, pages 536\u2013542, Varna, Bulgaria. INCOMA",
            "year": 2017
        },
        {
            "authors": [
                "Ramesh Nallapati",
                "Bowen Zhou",
                "C\u00edcero Nogueira dos Santos",
                "\u00c7aglar G\u00fcl\u00e7ehre",
                "Bing Xiang."
            ],
            "title": "Abstractive text summarization using sequence-tosequence rnns and beyond",
            "venue": "Proceedings of the",
            "year": 2016
        },
        {
            "authors": [
                "Mir Tafseer Nayeem",
                "Tanvir Ahmed Fuad",
                "Yllias Chali."
            ],
            "title": "Abstractive unsupervised multidocument summarization using paraphrastic sentence fusion",
            "venue": "Proceedings of the 27th International Conference on Computational Linguistics, COLING",
            "year": 2018
        },
        {
            "authors": [
                "der",
                "Paul F. Christiano",
                "Jan Leike",
                "Ryan Lowe"
            ],
            "title": "Training language models to follow instructions with human feedback",
            "venue": "NeurIPS",
            "year": 2022
        },
        {
            "authors": [
                "Guilherme Penedo",
                "Quentin Malartic",
                "Daniel Hesslow",
                "Ruxandra Cojocaru",
                "Alessandro Cappelli",
                "Hamza Alobeidli",
                "Baptiste Pannier",
                "Ebtesam Almazrouei",
                "Julien Launay"
            ],
            "title": "The refinedweb dataset for falcon LLM: outperforming curated corpora",
            "year": 2023
        },
        {
            "authors": [
                "Hanieh Poostchi",
                "Massimo Piccardi."
            ],
            "title": "Cluster labeling by word embeddings and wordnet\u2019s hypernymy",
            "venue": "Proceedings of the Australasian Language Technology Association Workshop 2018, Dunedin, New Zealand, ALTA 2018, December 10-12, 2018,",
            "year": 2018
        },
        {
            "authors": [
                "Cristian Popa",
                "Traian Rebedea."
            ],
            "title": "BART-TL: weakly-supervised topic label generation",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021, Online, April 19",
            "year": 2021
        },
        {
            "authors": [
                "Dragomir R. Radev",
                "Hongyan Jing",
                "Magorzata Sty",
                "Daniel Tam."
            ],
            "title": "Centroid-based summarization of multiple documents",
            "venue": "Inf. Process. Manag., 40(6):919\u2013938.",
            "year": 2004
        },
        {
            "authors": [
                "Sarvesh Ranade",
                "Jayant Gupta",
                "Vasudeva Varma",
                "Radhika Mamidi."
            ],
            "title": "Online debate summarization using topic directed sentiment analysis",
            "venue": "Proceedings of the Second International Workshop on Issues of Sentiment Discovery and Opinion Mining,",
            "year": 2013
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych."
            ],
            "title": "Sentence-bert: Sentence embeddings using siamese bert-networks",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.",
            "year": 2019
        },
        {
            "authors": [
                "Gurevych."
            ],
            "title": "Classification and clustering of arguments with contextualized word embeddings",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 567\u2013 578, Florence, Italy. Association for Computational",
            "year": 2019
        },
        {
            "authors": [
                "Zhaochun Ren",
                "Jun Ma",
                "Shuaiqiang Wang",
                "Yang Liu."
            ],
            "title": "Summarizing web forum threads based on a latent topic propagation process",
            "venue": "Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM \u201911, page",
            "year": 2011
        },
        {
            "authors": [
                "Fran\u00e7ois Role",
                "Mohamed Nadif."
            ],
            "title": "Beyond cluster labeling: Semantic interpretation of clusters\u2019 contents using a graph representation",
            "venue": "Knowl. Based Syst., 56:141\u2013155.",
            "year": 2014
        },
        {
            "authors": [
                "drea Santilli",
                "Thibault F\u00e9vry",
                "Jason Alan Fries",
                "Ryan Teehan",
                "Teven Le Scao",
                "Stella Biderman",
                "Leo Gao",
                "Thomas Wolf",
                "Alexander M. Rush"
            ],
            "title": "Multitask prompted training enables zero-shot task generalization",
            "year": 2022
        },
        {
            "authors": [
                "Christopher Klamm",
                "Colin Leong",
                "Daniel van Strien",
                "David Ifeoluwa Adelani"
            ],
            "title": "BLOOM: A 176b-parameter open-access multilingual language model. CoRR, abs/2211.05100",
            "year": 2022
        },
        {
            "authors": [
                "Qingyi Si",
                "Zheng Lin."
            ],
            "title": "Alpaca-cot: An instruction fine-tuning platform with instruction data collection and unified large language models interface",
            "venue": "https://github.com/PhoebusSi/alpaca-CoT.",
            "year": 2023
        },
        {
            "authors": [
                "Chenhao Tan",
                "Vlad Niculae",
                "Cristian DanescuNiculescu-Mizil",
                "Lillian Lee."
            ],
            "title": "Winning arguments: Interaction dynamics and persuasion strategies in good-faith online discussions",
            "venue": "Proceedings of the 25th International Conference on World Wide",
            "year": 2016
        },
        {
            "authors": [
                "Rohan Taori",
                "Ishaan Gulrajani",
                "Tianyi Zhang",
                "Yann Dubois",
                "Xuechen Li",
                "Carlos Guestrin",
                "Percy Liang",
                "Tatsunori B. Hashimoto."
            ],
            "title": "Stanford alpaca: An instruction-following llama model",
            "venue": "https://github. com/tatsu-lab/stanford_alpaca.",
            "year": 2023
        },
        {
            "authors": [
                "Sansiri Tarnpradab",
                "Fei Liu",
                "Kien A Hua."
            ],
            "title": "Toward extractive summarization of online forum discussions via hierarchical attention networks",
            "venue": "The Thirtieth International Flairs Conference.",
            "year": 2017
        },
        {
            "authors": [
                "Almer S. Tigelaar",
                "Rieks op den Akker",
                "Djoerd Hiemstra."
            ],
            "title": "Automatic summarisation of discussion fora",
            "venue": "Nat. Lang. Eng., 16(2):161\u2013192.",
            "year": 2010
        },
        {
            "authors": [
                "Marilyn A. Walker",
                "Jean E. Fox Tree",
                "Pranav Anand",
                "Rob Abbott",
                "Joseph King."
            ],
            "title": "A corpus for research on deliberation and debate",
            "venue": "Proceedings of the Eighth International Conference on Language Resources and Evaluation, LREC 2012, Is-",
            "year": 2012
        },
        {
            "authors": [
                "Xiaojun Wan",
                "Jianwu Yang."
            ],
            "title": "Multi-document summarization using cluster-based link analysis",
            "venue": "Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2008, Singapore, July",
            "year": 2008
        },
        {
            "authors": [
                "Yizhong Wang",
                "Yeganeh Kordi",
                "Swaroop Mishra",
                "Alisa Liu",
                "Noah A. Smith",
                "Daniel Khashabi",
                "Hannaneh Hajishirzi."
            ],
            "title": "Self-instruct: Aligning language model with self generated instructions",
            "venue": "CoRR, abs/2212.10560.",
            "year": 2022
        },
        {
            "authors": [
                "Canwen Xu",
                "Daya Guo",
                "Nan Duan",
                "Julian McAuley."
            ],
            "title": "Baize: An open-source chat model with parameter-efficient tuning on self-chat data",
            "venue": "arXiv preprint arXiv:2304.01196.",
            "year": 2023
        },
        {
            "authors": [
                "Amy X. Zhang",
                "Lea Verou",
                "David R. Karger."
            ],
            "title": "Wikum: Bridging discussion forums and wikis using recursive summarization",
            "venue": "Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing, CSCW 2017,",
            "year": 2017
        },
        {
            "authors": [
                "har",
                "Tianlu Wang",
                "Luke Zettlemoyer"
            ],
            "title": "OPT: open pre-trained transformer language models. CoRR, abs/2205.01068",
            "year": 2022
        },
        {
            "authors": [
                "Tianyi Zhang",
                "Varsha Kishore",
                "Felix Wu",
                "Kilian Q. Weinberger",
                "Yoav Artzi."
            ],
            "title": "Bertscore: Evaluating text generation with BERT",
            "venue": "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenRe-",
            "year": 2020
        },
        {
            "authors": [
                "Yang Zhang",
                "Yunqing Xia",
                "Yi Liu",
                "Wenmin Wang."
            ],
            "title": "Clustering sentences with density peaks for multi-document summarization",
            "venue": "NAACL HLT 2015, The 2015 Conference of the North American Chapter of the Association for Computational Lin-",
            "year": 2015
        },
        {
            "authors": [
                "BLOOM (Scao"
            ],
            "title": "2022) is an autoregressive LLM with 176B parameters, which specializes in prompt-based text completion for multiple languages",
            "year": 2022
        },
        {
            "authors": [
                "OPT (Zhang"
            ],
            "title": "2022) is an autoregressive LLM with 66B parameters from the suite of decoder-only pre-trained transformers. These models offer similar performance and sizes as GPT-3 while employing more efficient practices",
            "year": 2022
        },
        {
            "authors": [
                "Brown et al",
                "Ouyang"
            ],
            "title": "2022) is an instruction-following LLM with 175B parameters that outperforms the GPT-3 model across several tasks by consistently adhering to user-provided instructions and gener",
            "year": 2022
        },
        {
            "authors": [
                "Pythia (Biderman"
            ],
            "title": "2023) is a suite of LLMs trained on public data to study the impact of training and scaling on various model properties. We used the 12B variant finetuned on the OpenAssistant Conversations dataset (K\u00f6pf",
            "year": 2023
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Online discussion forums are a popular medium for discussing a wide range of topics. As the size of a community grows, so does the average length of the discussions held there, especially when current controversial topics are discussed. On ChangeMyView (CMV),2 for example, discussions often go into the hundreds of arguments covering many perspectives on the topics in question. Initiating, participating in, or reading discussions generally has two goals: to learn more about others\u2019 views on a topic and/or to share one\u2019s own.\nTo help their users navigate large volumes of arguments in long discussions, many forums offer basic features to sort them, for example, by time of creation or popularity. However, these alternative views may not capture the full range of perspectives\n*Equal contribution. 1Code: https://github.com/webis-de/EMNLP-23 2https://www.reddit.com/r/changemyview/\nexchanged, so it is still necessary to read most of them for a comprehensive overview. In this paper, we depart from previous approaches to summarizing long discussions by using indicative summaries instead of informative summaries.3 Figure 1 illustrates our three-step approach: first, the sentences of the arguments are clustered according to their latent subtopics. Then, a large language model generates a concise abstractive summary for each cluster as its label. Finally, the argument frame (Chong and Druckman, 2007; Boydstun et al., 2014) of each cluster label is predicted as a generalizable operationalization of perspectives on a discussion\u2019s topic. From this, a hierarchical summary is created in the style of a table of contents, where frames act as headings and cluster labels as subheadings. To our knowledge, indicative summaries of this type have not been explored before (see Section 2).\nOur four main contributions are: (1) A fully unsupervised approach to indicative summarization of long discussions (Section 3). We develop robust prompts for generative cluster labeling and frame assignment based on extensive empirical evaluation and best practices (Section 4). (2) A comprehensive evaluation of 19 state-of-the-art, prompt-based, large language models (LLMs) for both tasks, supported by quantitative and qualitative assessments (Section 5). (3) A user study of the usefulness of indicative summaries for exploring long discussions (Section 5). (4) DISCUSSION EXPLORER, an interactive visual interface for exploring the indicative summaries generated by our approach and the corresponding discussions.4 Our results show that the GPT variants of OpenAI (GPT3.5, ChatGPT, and GPT4) outperform all other open source models at the time of writing. LLaMA and T0 perform well, but are not competitive with the GPT models. Regarding the usefulness of the summaries, users preferred our summaries to alternative views to explore long discussions with hundreds of arguments. 3Unlike an informative summary, an indicative summary does not capture as much information as possible from a text, but only its gist. This makes them particularly suitable for long documents like books in the form of tables of contents. 4https://discussion-explorer.web.webis.de/"
        },
        {
            "heading": "2 Related Work",
            "text": "Previous approaches to generating discussion summaries have mainly focused on generating extractive summaries, using two main strategies: extracting significant units (e.g., responses, paragraphs, or sentences), or grouping them into specific categories, which are then summarized. In this section, we review the relevant literature."
        },
        {
            "heading": "2.1 Extractive Summarization",
            "text": "Extractive approaches use supervised learning or domain-specific heuristics to extract important entities from discussions as extractive summaries. For example, Klaas (2005) summarized UseNet newsgroup threads by considering thread structure and lexical features to measure message importance. Tigelaar et al. (2010) identified key sentences based on author names and citations, focusing on coherence and coverage in summaries. Ren et al. (2011) developed a hierarchical Bayesian model for tracking topics, using a random walk algorithm to select representative sentences. Ranade et al. (2013) extracted topic-relevant and emotive sentences, while Bhatia et al. (2014) and Tarnpradab et al. (2017) used dialogue acts to summarize question-answering forum discussions. Egan et al. (2016) extracted key points using dependency parse graphs, and Kano et al. (2018) summarized Reddit discussions using local and global context features. These approaches generate informative summaries, substituting discussions without backreferencing to them."
        },
        {
            "heading": "2.2 Grouping-based Summarization",
            "text": "Grouping-based approaches group discussion units like posts or sentences, either implicitly or explicitly. The groups are based on queries, aspects, topics, dialogue acts, argument facets, or key points annotated by experts. Once the units are grouped, individual summaries are generated for each group by selecting representative members, respectively.\nThis grouping-then-summarization paradigm has been primarily applied to multi-document summarization of news articles (Radev et al., 2004). Follow-up work proposed cluster link analysis (Wan and Yang, 2008), cluster sentence ranking (Cai et al., 2010), and density peak identification in clusters (Zhang et al., 2015). For abstractive multidocument summarization, Nayeem et al. (2018) clustered sentence embeddings using a hierarchical agglomerative algorithm, identifying representative sentences from each cluster using TextRank (Mihalcea and Tarau, 2004) on the induced sentence graph. Similarly, Fuad et al. (2019) clustered sentence embeddings and selected subsets of clusters based on importance, coverage, and variety. These subsets are then input to a transformer model trained on the CNN/DailyMail dataset (Nallapati et al., 2016) to generate a summary. Recently, Ernst et al. (2022) used agglomerative clustering of salient statements to summarize sets of news articles, involving a supervised ranking of clusters by importance.\nFor Wikipedia discussions, Zhang et al. (2017) proposed the creation of a dynamic summary tree to ease subtopic navigation at different levels of detail, requiring editors to manually summarize each\ntree node\u2019s cluster. Misra et al. (2015) used summarization to identify arguments with similar aspects in dialogues from the Internet Argument Corpus (Walker et al., 2012). Similarly, Reimers et al. (2019) used agglomerative clustering of contextual embeddings and aspects to group sentence-level arguments. Bar-Haim et al. (2020a,b) examined the mapping of debate arguments to key points written by experts to serve as summaries.\nOur approach clusters discussion units, but instead of a supervised selection of key cluster members, we use vanilla LLMs for abstractive summarization. Moreover, our summaries are hierarchical, using issue-generic frames as headings (Chong and Druckman, 2007; Boydstun et al., 2014) and generating concise abstractive summaries of corresponding clusters as subheadings. Thus our approach is unsupervised, facilitating a scalable and generalizable summarization of discussions."
        },
        {
            "heading": "2.3 Cluster Labeling",
            "text": "Cluster labeling involves assigning representative labels to document clusters to facilitate clustering exploration. Labeling approaches include comparing term distributions (Manning et al., 2008), selecting key terms closest to the cluster centroid (Role and Nadif, 2014), formulating key queries (Gollub et al., 2016), identify keywords through hypernym relationships (Poostchi and Piccardi, 2018), and weak supervision to generate topic labels Popa and Rebedea (2021). These approaches often select a small set of terms as labels that do not describe a cluster\u2019s contents in closed form. Our approach overcomes this limitation by treating cluster labeling as a zero-shot abstractive summarization task."
        },
        {
            "heading": "2.4 Frame Assignment",
            "text": "Framing involves emphasizing certain aspects of a topic for various purposes, such as persuasion (Entman, 1993; Chong and Druckman, 2007). Frame analysis for discussions provides insights into different perspectives on a topic (Morstatter et al., 2018; Liu et al., 2019). It also helps to identify biases in discussions resulting, e.g., from word choice (Hamborg et al., 2019b,a). Thus, frames can serve as valuable reference points for organizing long discussions. We use a predefined inventory of media frames (Boydstun et al., 2014) for discussion summarization. Instead of supervised frame assignment (Naderi and Hirst, 2017; Ajjour et al., 2019; Heinisch and Cimiano, 2021), we use prompt-based LLMs for more flexibility."
        },
        {
            "heading": "3 Indicative Discussion Summarization",
            "text": "Our indicative summarization approach takes the sentences of a discussion as input and generates a summary in the form of a table of contents, as shown in Figure 1. Its three steps consist of clustering discussion sentences, cluster labeling, and frame assignment to cluster labels."
        },
        {
            "heading": "3.1 Unit Clustering",
            "text": "Given a discussion, we extract its sentences as discussion units. The set of sentences is then clustered using the density-based hierarchical clustering algorithm HDBSCAN (Campello et al., 2013). Each sentence is embedded using SBERT (Reimers and Gurevych, 2019) and these embeddings are then mapped to a lower dimensionality using UMAP (McInnes et al., 2017).5 Unlike previous approaches that rank and filter clusters to generate informative summaries (Ernst et al., 2022; Syed et al., 2023), our summaries incorporate all clusters. The sentences of each cluster are ranked by centrality, which is determined by the \u03bb value of HDBSCAN. A number of central sentences per cluster are selected as input for cluster labeling by abstractive summarization.\nMeta-sentence filtering Some sentences in a discussion do not contribute directly to the topic, but reflect the interaction between its participants. Examples include sentences such as \u201cI agree with you.\u201d or \u201cYou are setting up a straw man.\u201d Pilot experiments have shown that such meta-sentences may cause our summarization approach to include them in the final summary. As these are irrelevant to our goal, we apply a corpus-specific and channel-specific meta-sentence filtering approach, respectively. Corpus-specific filtering is based on a small set of frequently used meta-sentences M in a large corpus (e.g., on Reddit). It is bootstrapped during preprocessing, and all sentences in it are omitted by default.6\nOur pilot experiments revealed that some sentences in discussions are also channel-specific (e.g., for the ChangeMyView Subreddit). Therefore, we augment our sentence clustering approach by adding a random sample M \u2032 \u2282 M to the set of sentences D of each individual discussion before clustering, where |M \u2032| = max{300, |D|}. The maximum value for the number of meta-sentences |M \u2032| 5Implementation details are given in Appendix B. 6The set is used like a typical stop word list, only for sentences.\nis chosen empirically, to maximize the likelihood that channel-specific meta-sentences are clustered with corpus-specific ones. After clustering the joint set of meta-sentences and discussion sentences D \u222a M \u2032, we obtain the clustering C. Let mC = |C \u2229 M \u2032| denote the number of metasentences and dC = |C \u2229D| the number of discussion sentences in a cluster C \u2208 C. The proportion of meta-sentences in a cluster is then estimated as P (M \u2032|C) = mCmC+dC .\nA cluster C is classified as a meta-sentence cluster if P (M \u2032|C) > \u03b8\u00b7P (M \u2032), where P (M \u2032) = |M\n\u2032| |D|\nassumes that meta-sentences are independent of others in a discussion. The noise threshold \u03b8 = 23 was chosen empirically. Sentences in a discussion that either belong to a meta-sentence cluster or whose nearest cluster is considered to be one are omitted. In our evaluation, an average of 23% of sentences are filtered from discussions. Figure 2 illustrates the effect of meta-sentence filtering on a discussion\u2019s set of sentence."
        },
        {
            "heading": "3.2 Generative Cluster Labeling",
            "text": "Most cluster labeling approaches extract keywords or key phrases as labels, which limits their fluency. These approaches may also require training data acquisition for supervised learning. We formulate cluster labeling as an unsupervised abstractive summarization task. We experiment with prompt-based large language models in zero-shot and few-shot settings. This enables generalization across multiple domains, the elimination of supervised learning, and fluent cluster labels with higher readability in comparison to keywords or phrases.\nWe develop several prompt templates specifically tailored for different types of LLMs. For encoder-decoder models, we carefully develop appropriate prompts based on PromptSource (Bach et al., 2022), a toolkit that provides a comprehensive collection of natural language prompts for various tasks across 180 datasets. In particular, we analyze prompts for text summarization datasets with respect to (1) descriptive words for the generation of cluster labels using abstractive summarization, (2) commonly used separators to distinguish instructions from context, (3) the position of instructions within prompts, and (4) the granularity level of input data (full text, document title, or sentence). Since our task is about summarizing groups of sentences, we chose prompts that require the full text as input to ensure that enough contextual\ninformation is provided (within the limits of each model\u2019s input size). Section 4.1 provides details on the prompt engineering process."
        },
        {
            "heading": "3.3 Frame Assignment",
            "text": "Any controversial topic can be discussed from different perspectives. For example, \u201cthe dangers of social media\u201d can be discussed from a moral or a health perspective, among others. In our indicative summaries, we use argumentation frame labels as top-level headings to operationalize different perspectives. An argumentation frame may include one or more groups of relevant arguments. We assign frame labels from the issue-generic frame inventory shown in Table 1 (Boydstun et al., 2014) to each cluster label derived in the previous step.7\nWe use prompt-based models in both zero-shot and few-shot settings for frame assignment. In our experiments with instruction-tuned models, we designed two types of instructions, shown in Figure 10, namely direct instructions for models trained on instruction\u2013response samples, and dialog instructions for chat models. The instructions are included along with the cluster labels in the prompts. Moreover, including the citation of the frame inventory used in our experiments has a positive effect on the effectiveness of some models (see Appendix D.1 for details)."
        },
        {
            "heading": "3.4 Indicative Summary Presentation",
            "text": "Given the generated labels of all sentence clusters and the frame labels assigned to each cluster label, our indicative summary groups the cluster labels by their respective frame labels. The cluster label groups of each frame label are then ordered by cluster size. This results in a two-level indicative summary, as shown in Figures 1 and 4."
        },
        {
            "heading": "4 Prompt Engineering",
            "text": "Using prompt-based LLMs for generative cluster labeling and frame assignment requires modelspecific prompt engineering as a preliminary step. We explored the 19 model variants listed in Table 2. To select the most appropriate models for our task, we consulted the HELM benchmark (Liang et al., 2022), which compares the effectiveness of different LLMs for different tasks. Further, we have included various recently released open source models (with optimized instructions) as they were released. Since many of them were released during our research, we reuse prompts previously optimized prompts for the newer models.8\n7For detailed label descriptions see Table 6 in the Appendix. 8See Appendices C and D for details.\nModel Variants\nDescription\nPre-InstructGPT\nT0 vanilla\nEncoder-decoder model trained on datasets transformed as task-specific prompts.\nBLOOM vanilla\nA multlingual autoregressive model with 176B parameters for prompt-based text completion.\nGPT-NeoX 20B\nOpen source alternative to GPT-3.\nOPT 66B\nAutoregressive model with similar effectiveness to GPT-3, but more efficient data collection and training.\nDirect Instruction\nLLaMA-CoT vanilla LLaMA-30B fine-tuned on chain-of-thought and reasoning samples (Si and Lin, 2023).\nAlpaca 7B\nLLaMA-7B fine-tuned based on 52k selfinstruct responses (Wang et al., 2022).\nOASST vanilla\nLLaMA-30B fine-tuned on the OpenAssistant Conversations dataset (K\u00f6pf et al., 2023) using reinforcement learning.\nPythia 12B\nSuite of LLMs trained on public data to investigate the effects of training and scaling on various model properties.\nGPT* 3.5, Chat, 4 OpenAI models GPT3.5 (text-davinci-003), ChatGPT (gpt-3.5-turbo), and GPT4.\nDialogue Instruction\nLLaMA 30B, 65B\nSuite of open-source LLMs from Meta AI trained on public datasets.\nVicuna 7B, 13B\nLLaMA models fine-tuned using conversations collected by ShareGPT (https://sharegpt. com)\nBaize 7B, 13B\nOpen source chat model trained on 100k dialogues generated by letting ChatGPT (GPT 3.5-turbo) talk to itself.\nFalcon 40B, 40B-Instruct Trained on the RefinedWeb corpus (Penedo et al., 2023), which was obtained by filtering and deduplication of public web data."
        },
        {
            "heading": "4.1 Cluster Labeling",
            "text": "The prompts for the encoder-decoder model T0 are based on the PROMPTSOURCE (Bach et al., 2022) toolkit. We have experimented with different prompt templates and tried different combinations of input types (e.g. \u201ctext\u201d, \u201cdebate\u201d, \u201cdiscussion\u201d, and \u201cdialogue\u201d) and output types (e.g. \u201ctitle\u201d, \u201ctopic\u201d, \u201csummary\u201d, \u201ctheme\u201d, and \u201cthesis\u201d). The position of the instruction within a prompt was also varied, taking into account prefix and suffix positions. For decoder-only models like BLOOM, GPT-NeoX, OPT-66B, and OPT, we experimented with hand-crafted prompts. For GPT3.5, we followed the best practices described in OpenAI\u2019s API and created a single prompt.\nPrompts were evaluated on a manually annotated set of 300 cluster labels using BERTScore (Zhang et al., 2020). We selected the most effective prompt for each of the above models for cluster labeling. Our evaluation in Section 5 shows that GPT3.5 performs best in this task. Figure 3 (top) shows the best prompt for this model.9"
        },
        {
            "heading": "4.2 Frame Assignment",
            "text": "For frame assignment, models were prompted to predict a maximum of three frame labels for a given cluster label, ordered by relevance. Experiments were conducted with both direct instructions and dialogue prompts in zero-shot and few-shot set9ChatGPT and GPT4 were released after our evaluation.\ntings. In the zero-shot setting, we formulated three prompts containing (1) only frame labels, (2) frame labels with short descriptions, and (3) frame labels with full text descriptions (see Appendix D.2 for details). For the few-shot setting, we manually annotated up to two frames from the frame inventory of Table 1 for each of the 300 cluster labels generated by the best model GPT3.5 in the previous step. We included 42 examples (3 per frame) in the few-shot prompt containing the frame label, its full-text description, and three examples. The remaining 285 examples were used for subsequent frame assignment evaluation. Our evaluation in Section 5 shows that GPT4 performs best on this task. Figure 3 (bottom) shows its best prompt."
        },
        {
            "heading": "5 Evaluation",
            "text": "To evaluate our approach, we conducted automatic and manual evaluations focused on the cluster labeling quality and the frame assignment accuracy. We also evaluated the utility of our indicative summaries in a purpose-driven user study in which participants had the opportunity to explore long discussions and provide us with feedback."
        },
        {
            "heading": "5.1 Data and Preprocessing",
            "text": "We used the \u201cWinning Arguments\u201d corpus from Tan et al. (2016) as a data source for long discussions. It contains 25,043 discussions from the ChangeMyView Subreddit that took place between 2013 and 2016. The corpus was preprocessed by first removing noise replies and then meta-sentences. Noise replies are marked in the metadata of the corpus as \u201cdeleted\u201d by their respective authors, posted by bots, or removed by moderators. In addition, replies that referred to the Reddit guidelines or forum-specific moderation were removed using pattern matching (see Appendix A for details). The remaining replies were split into a set of sentences using Spacy (Honnibal et al., 2020). To enable the unit clustering (of sentences) as described in Section 3.1, the set of meta-sentences M is bootstrapped by first clustering the entire set of sentences from all discussions in the corpus and then manually examining the clusters to identify those that contain meta-sentences, resulting in |M | = 955 meta-sentences. After filtering out channel-specific noise, the (cleaned) sets of discussion sentences are clustered as described.\nEvaluation Data From the preprocessed discussions, 300 sentence clusters were randomly se-\nlected. Then, we manually created a cluster label and up to three frame labels for each cluster. Due to the short length of the cluster labels, up to two frames per label were sufficient. After excluding 57 examples with ambiguous frame assignments, we obtained a reference set of 243 cluster label samples, each labeled with up to two frames."
        },
        {
            "heading": "5.2 Generative Cluster Labeling",
            "text": "The results of the automatic cluster labeling evaluation using BERTScore and ROUGE are shown in (Appendix) Tables 7 and 8, respectively. We find that ChatGPT performs best. To manually evaluate the quality of the cluster labels, we used a rankingbased method in which four annotators scored the generated cluster labels against the manually annotated reference labels of each of the 300 clusters. To provide additional context for the cluster content, the five most semantically similar sentences to the reference label from each cluster were included, as well as five randomly selected sentences from the cluster. To avoid possible bias due to the length of the cluster labels by different models, longer labels were truncated to 15 tokens.10 To determine an annotator\u2019s model ranking, we merged the preference rankings for all clusters using reciprocal rank fusion (Cormack et al., 2009). Annotator agreement was calculated using Kendall\u2019s W for rank correlation (Kendall, 1948), which yielded a value of 0.66, indicating substantial agreement.\nThe average ranking of each model is shown in Table 3 along with the length distributions of the generated cluster labels.11 GPT3.5 showed supe10Figure 9 in the Appendix shows the annotation interfaces. 11As newer models were published after our manual evalua-\ntion, we show an automatic evaluation of all models using human and GPT3.5-based reference labels in the Appendix\ntion. Model types are also indicated: Pre-InstructGPT , Direct / Dialogue . Missing values are model inferences that exceed our computational resources.\nrior effectivenss in generating high-quality cluster labels. It ranked first in 225 out of 300 comparisons, with an average score of 1.38 by the four annotators. The cluster labels generated by GPT3.5 were longer on average (9.4 tokens) and thus more informative than those generated by the other models, which often generated disjointed or incomplete labels. In particular, T0 generated very short labels on average (3.1 tokens) that were generic/non-descriptive."
        },
        {
            "heading": "5.3 Frame Assignment",
            "text": "In the zero-/few-shot frame assignment settings described in Section 4.2, we prompted the models to predict three frames per cluster label in order of relevance. Using the manually annotated reference set of 243 cluster labels and their frame labels, we evaluated the accuracy of the frames predicted for each cluster label that matched the reference frames. The results for the first predicted frame\nin Tables 7 and 8.\nare shown in Table 4. In most cases, GPT4 outperforms all other models in the various settings, with the exception of the zero-shot setting with a short prompt, where GPT3.5 narrowly outperforms GPT4 with 60.9% accuracy versus 60.5%. Among the top five models, the GPT* models that follow direct user instructions perform consistently well, with the LLaMA-/65B/-CoT and T0 models showing strong effectiveness among the open-source LLMs. Conversely, the OPT model performs consistently worse in all settings. The few-shot setting shows greater variance in results, suggesting that the models are more sensitive to the labeled examples provided in the prompts. Including a citation to the frame inventory paper in the instructions (see Figure 10) significantly improved the effectiveness of Falcon-40B (12%) and LLaMA-65B (9%) in the zero-shot setting (see Appendix D.1 for details)."
        },
        {
            "heading": "5.4 Usefulness Evaluation",
            "text": "In addition to assessing each step of our approach, we conducted a user study to evaluate the effectiveness of the resulting indicative summaries. In this study, we considered two key tasks: exploration and participation. With respect to exploration, our goal was to evaluate the extent to which the summaries help users explore the discussion and discover new perspectives. With respect to participation, we wanted to assess how effectively the summaries enabled users to contribute new arguments by identifying the appropriate context and location for a response.\nWe asked five annotators to explore five randomly selected discussions from our dataset, for which we generated indicative summaries using our approach with GPT3.5. To facilitate intuitive exploration, we developed DISCUSSION EXPLORER (see Section 5.5), an interactive visual interface for the evaluated discussions and their indicative summaries. In addition to our summaries, two baselines were provided to annotators for comparison: (1) the original web page of the discussion on ChangeMyView, and (2) a search engine interface powered by Spacerini (Akiki et al., 2023). The search engine indexed the sentences within a discussion using the BM25 retrieval model. This allowed users to explore interesting perspectives by selecting self-selected keywords as queries, as opposed to the frame and cluster labels that our summaries provide. Annotators selected the best of these interfaces for exploration and participation.\nResults With respect to the exploration task, the five annotators agreed that our summaries outperformed the two baselines in terms of discovering arguments from different perspectives presented by participants. The inclusion of argumentation frames proved to be a valuable tool for the annotators, facilitating the rapid identification of different perspectives and the accompanying cluster labels showing the relevant subtopics in the discussion. For the participation task, three annotators preferred the original web page, while our summaries and the search engine were preferred by the remaining two annotators (one each) when it came to identifying the appropriate place in the discussion to put their arguments. In a post-study questionnaire, the annotators revealed that the original web page was preferred because of its better display of the various response threads, a feature not comparably reimplemented in DISCUSSION EXPLORER. The original web page felt \u201cmore familiar.\u201d However, we anticipate that this limitation can be addressed by seamlessly integrating our indicative summaries into a given discussion forum\u2019s web page, creating a consistent experience and a comprehensive and effective user interface for discussion participation."
        },
        {
            "heading": "5.5 DISCUSSION EXPLORER",
            "text": "Our approach places emphasis on summary presentation by structuring indicative summaries into a table of contents for discussions (see Section 3). To demonstrate the effectiveness of this presentation style in exploring long discussions, we have developed an interactive tool called DISCUSSION EXPLORER.12 This tool illustrates how such summaries can be practically applied. Users can participate in discussions by selecting argumentation frames or cluster labels. Figure 4 presents indicative summaries generated by different models, providing a quick overview of the different perspectives. This two-level table of contents-like summary provides effortless navigation, allowing users to switch between viewing all arguments in a frame and understanding the context of sentences in a cluster of the discussion (see Figure 5)."
        },
        {
            "heading": "6 Conclusion",
            "text": "We have developed an unsupervised approach to generating indicative summaries of long discussions to facilitate their effective exploration and navigation. Our summaries resemble tables of con12https://discussion-explorer.web.webis.de/\ntents, which list argumentation frames and concise abstractive summaries of the latent subtopics for a comprehensive overview of a discussion. By analyzing 19 prompt-based LLMs, we found that GPT3.5 and GPT4 perform impressively, with LLaMA fine-tuned using chain-of-thought being the second best. A user study of long discussions showed that our summaries were valuable for exploring and uncovering new perspectives in long discussions, an otherwise tedious task when relying solely on the original web pages. Finally, we presented DISCUSSION EXPLORER, an interactive visual tool designed to navigate through long discussions using the generated indicative summaries. This serves as a practical demonstration of how indicative summaries can be used effectively."
        },
        {
            "heading": "7 Limitations",
            "text": "We focused on developing a technology that facilitates the exploration of long, argumentative discussions on controversial topics. We strongly believe that our method can be easily generalized to other types of discussions, but budget constraints prevented us from exploring these as well. We also investigated state-of-the-art language models to summarize these discussions and found that commercial models (GPT3.5, GPT4) outperformed opensource models (LLaMA, T0) in generating indicative summaries. Since the commercial models are regularly updated, it is important to note that the results of our approach may differ in the future. Although one can define a fixed set of prompts for each model, our systematic search for the optimal prompts based on an evaluation metric is intended to improve the reproducibility of our approach as newer models are released regularly.\nTo evaluate the effectiveness of the generated summaries, we conducted a user study with five participants that demonstrated their usefulness in exploring discussions. Further research is needed on how to effectively integrate summaries of this type into discussion platform interfaces, which was beyond the scope of this paper."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was partially supported by the European Commission under grant agreement GA 101070014 (OpenWebSearch.eu)"
        },
        {
            "heading": "A Preprocessing",
            "text": "Deleted posts were matched using: \"[deleted]\", \"[removed]\", \"[Wiki][Code][/r/DeltaBot]\", \"[History]\". To remove posts from moderators, we used:\n\u2022 \"hello, users of cmv! this is a footnote from your moderators\"\n\u2022 \"comment has been remove\"\n\u2022 \"comment has been automatically removed\"\n\u2022 \"if you would like to appeal, please message the moderators by clicking this link.\"\n\u2022 \"this comment has been overwritten by an open source script to protect\"\n\u2022 \"then simply click on your username on reddit, go to the comments tab, scroll down as far as possibe (hint:use res), and hit the new overwrite button at the top.\"\n\u2022 \"reply to their comment with the delta symbol\""
        },
        {
            "heading": "B Clustering Implementation",
            "text": "We employed HDBSCAN, a soft clustering algorithm (Campello et al., 2013) to cluster the contextual sentence embeddings from SBERT (Reimers and Gurevych, 2019). As these embeddings are high dimensional, we follow Grootendorst (2022) and apply dimensionality reduction on these embeddings via UMAP (McInnes et al., 2017) and cluster them based on their euclidean distance. Most parameters were selected according to official recommendations for UMAP,13 and HDBSCAN.14\nUMAP Parameters\nmetric We set this to \u201ccosine\u201d because this is the natural metric for SBERT embeddings.\nn_neighbors We set this to 30 instead of the default value of 15 because this makes the reduction focus more on the global structure. This is important since the local structure is more sensitive to noise.\nn_components We set this value to 10.\nmin_dist We set this value to 0 because this allows the points to be packed closer together which makes separating the clusters easier.\nHDBSCAN Parameters\nmetric We set this to \u201ceuclidean\u201d because this the target metric that UMAP uses for reducing the points.\ncluster_selection_method We set this value to \u201cleaf\u201d. An alternative choice for this options is \u201ceom\u201d. This option has the tendency to create unreasonably large clusters. There are instances where it creates only two or three clusters even for very large discussions. The \u201cleaf\u201d method does not suffer from this problem but it is more dependent on the \u201cmin_cluster_size\u201d parameter.\nmin_cluster_size This parameter is the most important one for this approach. It is also not straight forward to find a value for this since the sizes of the main subtopics of a discussion depend on the size of the discussion. To find a good value, we sampled 50 discussion randomly and 50 discussion stratified by discussion length from all discussions. We compute the clustering for all 100 13https://umap-learn.readthedocs.io/en/latest/clustering.html 14https://hdbscan.readthedocs.io/en/latest/parameter_\nselection.html\ndiscussion for different values for min_cluster_size and manually determine a lower and upper bound for min_cluster_size that give a good clustering. We computed a regression model using the following function family as a basis: f(x|a, b) = a \u00b7 xb The input variable x is the number of sentences in the discussion and the output variable is the average of the upper and lower bound. This yields the following function for computing min_cluster_size: f(x) = 0.421 \u00b7 x0.559. Figure 6 visualizes upper and lower bounds as well as the found model."
        },
        {
            "heading": "C Generative Cluster Labeling",
            "text": "Model Descriptions Given the large number of models investigated in the paper for both the tasks, we categorized them based on their release timelines. Models older than GPT3.5 are listed under Pre-InstructGPT such as T0, BLOOM, GPT-NeoX, and OPT. The Direct and Dialogue labels refer to models released after GPT3.5 which differ in their prompt styles as shown in Figure 7. Best prompts for the manually evaluated models (Section 5.2) are shown in Figure 8.\n1. T0 (Sanh et al., 2022) is a prompt-based encoderdecoder model, fine-tuned on multiple tasks in-\ncluding summarization, and surpasses GPT-3 in some tasks despite being much smaller. It was trained on prompted datasets where supervised datasets were transformed into prompts.\n2. BLOOM (Scao et al., 2022) is an autoregressive LLM with 176B parameters, which specializes in prompt-based text completion for multiple languages. It also supports instruction-based\ntask completions for previously unseen tasks.\n3. GPT-NeoX (Black et al., 2021) is an opensource, general-purpose alternative to the GPT-3 model (Ouyang et al., 2022) containing 20B parameters.\n4. OPT (Zhang et al., 2022) is an autoregressive LLM with 66B parameters from the suite of decoder-only pre-trained transformers. These models offer similar performance and sizes as GPT-3 while employing more efficient practices for data collection and model training.\n5. GPT3.5 (Brown et al., 2020; Ouyang et al., 2022) is an instruction-following LLM with 175B parameters that outperforms the GPT-3 model across several tasks by consistently adhering to user-provided instructions and generating high-quality, longer outputs. We used the text-davinci-003 variant. In contrast to the other open-source models, it is accessible exclusively through the OpenAI API.15\nPrompt Descriptions We investigated several prompt templates for each model and selected the best performing one. All the prompts investigated for the encoder-decoder T0 model are shown in Table 11. Prompt templates for the decoder-only PreInstructGPT models (BLOOM, OPT, GPT-NeoX) are listed in Table 12. Prompt templates for the instruction-following LLMs are listed in Table 13.\nAutomatic Evaluation For the sake of completion, we automatically evaluated the recently released (at the time of writing) instruction-following models. To adapt them to generative cluster labeling, we devised two instructions (Figure 7) similar to the direct and dialogue style instructions used for frame assignment (Section 3.3). Next, we computed BERTScore and ROUGE against two sets of references: (1) manually annotated ground-truth labels for 300 clusters, and (2) cluster labels from GPT3.5 which was the best model as per our manual evaluation (Section 5.2, Table 3). Complete results for BERTScore along with length distributions for the generated cluster labels are shown in Table 7, while results for ROUGE are shown in Table 8.\nManual Evaluation Table 9 shows the guideline provided to the annotators. Figure 9 shows the 15https://platform.openai.com/docs/models/gpt-3-5\nannotation interface used to collect the rankings for cluster label quality."
        },
        {
            "heading": "D Frame Assignment",
            "text": "Model Descriptions We categorize the models according to the instruction style followed for finetuning and generation. Instructions for each type are shown in Figure 10. The best prompts for each model are listed in Figure 11.\nDirect Instruction Models\n1. LLaMA-COT16 is a finetuned model on datasets inducing chain-of-thought and logical deductions (Si and Lin, 2023).\n2. Alpaca (Taori et al., 2023) is finetuned from the LLaMA 7B model (Touvron et al., 2023) using 52K self-instructed instruction-following examples (Wang et al., 2022).\n3. OASST 17 is finetuned from LLaMA 30B on the OpenAssistant Conversations dataset (K\u00f6pf et al., 2023) using reinforcement learning.\n4. Pythia (Biderman et al., 2023) is a suite of LLMs trained on public data to study the impact of training and scaling on various model properties. We used the 12B variant finetuned on the OpenAssistant Conversations dataset (K\u00f6pf et al., 2023).\n5. GPT* includes models such as text-davinci-003, gpt-3.5-turbo (ChatGPT), and GPT-4 (Bubeck\n16https://huggingface.co/ausboss/llama-30b-supercot 17https://huggingface.co/OpenAssistant/\noasst-rlhf-2-llama-30b-7k-steps-xor\net al., 2023) from the OpenAI API. These models are not open-source but have demonstrated state-of-the-art performance across various tasks.\nDialogue Instruction Models\n1. LLaMA (Touvron et al., 2023) is a suite of opensource LLMs trained on public datasets. We utilized the 30B and 65B variants.\n2. Vicuna (Chiang et al., 2023) is finetuned from LLaMA using user-shared conversations collected from ShareGPT.18 It has shown competitive performance when evaluated using GPT-4 as a judge. We used the 7B and 13B variants of this model.\n3. Vicuna (Xu et al., 2023) is an open-source chat model trained on 100k dialogues generated by allowing ChatGPT (GPT 3.5-turbo) to converse with itself. We used the 7B and 13B variants of this model.\n18https://sharegpt.com/\n4. Falcon19 is trained on the RefinedWeb dataset (Penedo et al., 2023), which is derived through extensive filtering and deduplication of publicly available web data. It is currently the state-ofthe-art (at the time of writing) on the open-llmleaderboard.20 We utilized the 40B and 40BInstruct variants of this model.\nD.1 Citation Impact on Frame Assignment We conducted additional experiments to evaluate the impact of providing the citation of the media frames corpus paper by Boydstun et al. (2014) as additional information in the instructions shown in Section 3.3. This piece of information was provided after the substring \u201cdefined by\u201d in the prompt template. Table 5 shows the results. We note that providing the citation information has a positive 19https://falconllm.tii.ae/ 20https://huggingface.co/spaces/HuggingFaceH4/open_llm_\nleaderboard\nimpact on the performance of the models. The improvement is up to 12% for Falcon-40B and 9% for LLaMA-65B under zero-shot setting (only frame labels without descriptions in the prompt). This improvement can be attributed to the models being trained on a large text corpus, with the citation serving as a strong signal for generating more accurate labels. However, ChatGPT is only slightly affected.\nD.2 Zero-Shot and Few-Shot Prompts for Frame Assignment\nD.2.1 Zero-Shot (short) [\n\"economic\", \"capacity and resources\", \"morality\", \"fairness and equality\",\n\"legality, constitutionality and jurisprudence\",\u21aa\u2192 \"policy prescription and evaluation\", \"crime and punishment\", \"security and defense\", \"health and safety\", \"quality of life\", \"cultural identity\", \"public opinion\", \"political\", \"external regulation and reputation\"\n]\nD.2.2 Zero-Shot {\n\"economic\": { \"description\": \"costs, benefits, or other\nfinancial implications\"\u21aa\u2192 }, \"capacity and resources\": {\n\"description\": \"availability of physical, human or financial resources, and capacity of current systems\" \u21aa\u2192 \u21aa\u2192\n}, \"morality\": { \"description\": \"religious or ethical implications\" },\u21aa\u2192 \"fairness and equality\": {\n\"description\": \"balance or distribution of rights, responsibilities, and resources\"\u21aa\u2192\n}, \"legality, constitutionality and jurisprudence\": {\u21aa\u2192 \"description\": \"rights, freedoms, and\nauthority of individuals, corporations, and government\" \u21aa\u2192 \u21aa\u2192\n}, \"policy prescription and evaluation\": {\n\"description\": \"discussion of specific policies aimed at addressing problems\"\u21aa\u2192\n}, \"crime and punishment\": {\n\"description\": \"effectiveness and implications of laws and their enforcement\" \u21aa\u2192 \u21aa\u2192\n}, \"security and defense\": {\n\"description\": \"threats to welfare of the individual, community, or nation\"\u21aa\u2192\n}, \"health and safety\": {\n\"description\": \"health care, sanitation, public safety\"\u21aa\u2192\n}, \"quality of life\": { \"description\": \"threats and opportunities for\nthe individual's wealth, happiness, and well-being\" \u21aa\u2192 \u21aa\u2192\n}, \"cultural identity\": {\n\"description\": \"traditions, customs, or values of a social group in relation to a policy issue\" \u21aa\u2192 \u21aa\u2192 }, \"public opinion\": { \"description\": \"attitudes and opinions of the\ngeneral public, including polling and demographics\" \u21aa\u2192 \u21aa\u2192\n}, \"political\": {\n\"description\": \"considerations related to politics and politicians, including lobbying, elections, and attempts to sway voters\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n}, \"external regulation and reputation\": {\n\"description\": \"international reputation or foreign policy of the U.S.\"\u21aa\u2192\n} }\nD.2.3 Zero-Shot (full) {\n\"economic\": { \"description\": \"The costs, benefits, or\nmonetary/financial implications of the issue (to an individual, family, community, or to the economy as a whole).\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n}, \"capacity and resources\": {\n\"description\": \"The lack of or availability of physical, geographical, spatial, human, and financial resources, or the capacity of existing systems and resources to implement or carry out policy goals.\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n}, \"morality\": {\n\"description\": \"Any perspective or policy objective or action (including proposed action) that is compelled by religious doctrine or interpretation, duty, honor, righteousness or any other sense of ethics or social responsibility.\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n}, \"fairness and equality\": {\n\"description\": \"Equality or inequality with which laws, punishment, rewards, and resources are applied or distributed among individuals or groups. Also the balance between the rights or interests of one individual or group compared to another individual or group.\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n}, \"legality, constitutionality and jurisprudence\": {\u21aa\u2192 \"description\": \"The constraints imposed on or\nfreedoms granted to individuals, government, and corporations via the Constitution, Bill of Rights and other amendments, or judicial interpretation. This deals specifically with the authority of government to regulate, and the authority of individuals/corporations to act independently of government.\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n}, \"policy prescription and evaluation\": {\n\"description\": \"Particular policies proposed for addressing an identified problem, and figuring out if certain policies will work, or if existing policies are effective.\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n}, \"crime and punishment\": {\n\"description\": \"Specific policies in practice and their enforcement, incentives, and implications. Includes stories about enforcement and interpretation of laws by individuals and law enforcement, breaking laws, loopholes, fines, sentencing and punishment. Increases or reductions in crime.\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n}, \"security and defense\": {\n\"description\": \"Security, threats to security, and protection of one's person, family, in-group, nation, etc. Generally an action or a call to action that can be taken to protect the welfare of a person, group, nation sometimes from a not yet manifested threat.\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n}, \"health and safety\": {\n\"description\": \"Healthcare access and effectiveness, illness, disease, sanitation, obesity, mental health effects, prevention of or perpetuation of gun violence, infrastructure and building safety.\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n}, \"quality of life\": {\n\"description\": \"The effects of a policy on individuals' wealth, mobility, access to resources, happiness, social structures, ease of day-to-day routines, quality of community life, etc.\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n}, \"cultural identity\": {\n\"description\": \"The social norms, trends, values and customs constituting culture(s), as they relate to a specific policy issue.\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n}, \"public opinion\": {\n\"description\": \"References to general social attitudes, polling and demographic information, as well as implied or actual consequences of diverging from or \\\"getting ahead of\\\" public opinion or polls.\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n}, \"political\": {\n\"description\": \"Any political considerations surrounding an issue. Issue actions or efforts or stances that are political, such as partisan filibusters, lobbyist involvement, bipartisan efforts, deal-making and vote trading, appealing to one's base, mentions of political maneuvering. Explicit statements that a policy issue is good or bad for a particular political party.\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n}, \"external regulation and reputation\": {\n\"description\": \"The United States' external relations with another nation; the external relations of one state with another; or relations between groups. This includes trade agreements and outcomes, comparisons of policy outcomes or desired policy outcomes.\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n} }\nD.2.4 Few-Shot {\n\"economic\": { \"description\": \"The costs, benefits, or\nmonetary/financial implications of the issue (to an individual, family, community, or to the economy as a whole).\", \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \"examples\": [ \"Necessity of minimum wage laws and their\neffects on the labor market.\",\u21aa\u2192 \"Consequences of unregulated capitalism and\nthe potential of a libertarian society.\", \u21aa\u2192 \u21aa\u2192 \"Risk-based insurance premiums determined\nby complex modeling of probability and cost factors.\" \u21aa\u2192 \u21aa\u2192\n] }, \"capacity and resources\": {\n\"description\": \"The lack of or availability of physical, geographical, spatial, human, and financial resources, or the capacity of existing systems and resources to implement or carry out policy goals.\", \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \"examples\": [ \"Potential of biofuels as an alternative to\nfossil fuels.\",\u21aa\u2192 \"Physical fitness tests measure upper body\nstrength and running ability for military service.\", \u21aa\u2192 \u21aa\u2192 \"Physical strength and endurance needed for\nmodern combat.\"\u21aa\u2192 ]\n}, \"morality\": {\n\"description\": \"Any perspective or policy objective or action (including proposed action) that is compelled by religious doctrine or interpretation, duty, honor, righteousness or any other sense of ethics or social responsibility.\", \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \"examples\": [\n\"Fighting for the weak and vulnerable despite the odds.\",\u21aa\u2192 \"Victim-blaming debate on police brutality.\",\u21aa\u2192 \"Potential corruption of some native canadian bands and the need for transparency.\" \u21aa\u2192 \u21aa\u2192\n] }, \"fairness and equality\": {\n\"description\": \"Equality or inequality with which laws, punishment, rewards, and resources are applied or distributed among individuals or groups. Also the balance between the rights or interests of one individual or group compared to another individual or group.\", \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \"examples\": [ \"Differences between humanism and feminism\nand their respective goals.\",\u21aa\u2192 \"Disparities in scholarship opportunities for minority students.\",\u21aa\u2192 \"Violent suppression of native american\npopulations for centuries leading to a lack of advocacy and rights.\" \u21aa\u2192 \u21aa\u2192\n] }, \"legality, constitutionality and jurisprudence\": {\u21aa\u2192 \"description\": \"The constraints imposed on or\nfreedoms granted to individuals, government, and corporations via the Constitution, Bill of Rights and other amendments, or judicial interpretation. This deals specifically with the authority of government to regulate, and the authority of individuals/corporations to act independently of government.\", \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \"examples\": [\n\"Guns acquired through legal and illegal channels for criminal use.\",\u21aa\u2192 \"Importance of the 2nd amendment and the implications of gun ownership in a democracy.\",\n\u21aa\u2192 \u21aa\u2192 \"Relevance of sexual history in rape cases.\"\n] }, \"policy prescription and evaluation\": {\n\"description\": \"Particular policies proposed for addressing an identified problem, and figuring out if certain policies will work, or if existing policies are effective.\",\n\u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \"examples\": [\n\"Religious scientists making major contributions to the world despite majority of scientists being agnostic atheists.\",\n\u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \"Pros and cons of voluntary registration.\", \"Collective ownership of production for the\nbetterment of society, with workers profiting from the sale of their labor.\" \u21aa\u2192 \u21aa\u2192 \u21aa\u2192\n] }, \"crime and punishment\": { \"description\": \"Specific policies in practice\nand their enforcement, incentives, and implications. Includes stories about enforcement and interpretation of laws by individuals and law enforcement, breaking laws, loopholes, fines, sentencing and punishment. Increases or reductions in crime.\", \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \"examples\": [\n\"Complexities of police shootings and race.\",\u21aa\u2192 \"Men are more likely to commit violent crimes than women.\",\u21aa\u2192 \"Punishment as a response to crime debated, with consideration of morality, severity, and aims.\" \u21aa\u2192 \u21aa\u2192\n] }, \"security and defense\": {\n\"description\": \"Security, threats to security, and protection of one's person, family, in-group, nation, etc. Generally an action or a call to action that can be taken to protect the welfare of a person, group, nation sometimes from a not yet manifested threat.\", \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \"examples\": [\n\"Protective physical self-defense in a fight.\",\u21aa\u2192\n\"Powerful military technology making infantry obsolete in war.\",\u21aa\u2192 \"Protection of infants and mentally disabled through social policy.\"\u21aa\u2192\n] }, \"health and safety\": {\n\"description\": \"Healthcare access and effectiveness, illness, disease, sanitation, obesity, mental health effects, prevention of or perpetuation of gun violence, infrastructure and building safety.\", \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \"examples\": [\n\"Complexities of food choices and their effects on health.\",\u21aa\u2192 \"Potentially fatal consequences of taking too much acetaminophen.\",\u21aa\u2192 \"Encouraging healthy habits without shaming or pressuring people to lose weight.\"\u21aa\u2192\n] }, \"quality of life\": {\n\"description\": \"The effects of a policy on individuals' wealth, mobility, access to resources, happiness, social structures, ease of day-to-day routines, quality of community life, etc.\",\n\u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \"examples\": [ \"Differences between adults and children in\nterms of understanding and perception.\", \u21aa\u2192 \u21aa\u2192 \"Importance of extracurriculars and academics for college admissions.\",\u21aa\u2192 \"Appropriate times to yell at customer\nservice workers.\"\u21aa\u2192 ]\n}, \"cultural identity\": {\n\"description\": \"The social norms, trends, values and customs constituting culture(s), as they relate to a specific policy issue.\",\n\u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \"examples\": [ \"Rapid shift in acceptance of homosexuality\nin the u.s.\",\u21aa\u2192 \"Collective action necessary for social progress and change.\",\u21aa\u2192 \"Complexities of gender identity and\nexpression.\"\u21aa\u2192 ]\n}, \"public opinion\": {\n\"description\": \"References to general social attitudes, polling and demographic information, as well as implied or actual consequences of diverging from or \\\"getting ahead of\\\" public opinion or polls.\", \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \"examples\": [ \"Gender roles and expectations are socially\nconstructed and changing.\",\u21aa\u2192 \"Pros and cons of the 40-hour work week.\", \"Potential appeal of a political\ncandidate.\"\u21aa\u2192 ]\n}, \"political\": {\n\"description\": \"Any political considerations surrounding an issue. Issue actions or efforts or stances that are political, such as partisan filibusters, lobbyist involvement, bipartisan efforts, deal-making and vote trading, appealing to one's base, mentions of political maneuvering. Explicit statements that a policy issue is good or bad for a particular political party.\", \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \"examples\": [\n\"Differences between right-wing and left-wing politics.\",\u21aa\u2192 \"Complexities of anarchy.\", \"Power struggle between branches of\ngovernment.\"\u21aa\u2192 ]\n}, \"external regulation and reputation\": {\n\"description\": \"The United States' external relations with another nation; the external relations of one state with another; or relations between groups. This includes trade agreements and outcomes, comparisons of policy outcomes or desired policy outcomes.\", \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \u21aa\u2192 \"examples\": [ \"Implications of us involvement in nato and\nits allies.\",\u21aa\u2192 \"Potential consequences of us intervention in ukraine.\",\u21aa\u2192 \"Conflicting opinions on us involvement in\nforeign affairs.\"\u21aa\u2192 ]\n} }\nCMV: The \"others have it worse\" argument is terrible and should never be used in an actual conversation with a depressed person Indicative Summary (LLaMA-CoT)\nCMV: The \"others have it worse\" argument is terrible and should never be used in an actual conversation with a depressed person Indicative Summary (GPT3.5)\nCMV: Today is the best time period in human history to be alive for the vast majority of people. Indicative Summary (LLaMA-CoT)\nCMV: There shouldn\u2019t be anything other than the metric system. Indicative Summary (GPT3.5)\nCMV: There shouldn\u2019t be anything other than the metric system. Indicative Summary (GPT4)\nCMV: Shoe sizes should be the same for both men and women Indicative Summary (GPT4)\nCMV: Social media is the most destructive addiction in our society Indicative Summary (LLaMA-CoT)\nCMV: Social media is the most destructive addiction in our society Indicative Summary (GPT3.5)"
        }
    ],
    "title": "Indicative Summarization of Long Discussions",
    "year": 2023
}