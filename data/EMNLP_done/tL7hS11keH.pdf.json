{
    "abstractText": "Annotated data plays a critical role in Natural Language Processing (NLP) in training models and evaluating their performance. Given recent developments in Large Language Models (LLMs), models such as ChatGPT demonstrate zero-shot capability on many text-annotation tasks, comparable with or even exceeding human annotators. Such LLMs can serve as alternatives for manual annotation, due to lower costs and higher scalability. However, limited work has leveraged LLMs as complementary annotators, nor explored how annotation work is best allocated among humans and LLMs to achieve both quality and cost objectives. We propose CoAnnotating, a novel paradigm for Human-LLM co-annotation of unstructured texts at scale. Under this framework, we utilize uncertainty to estimate LLMs\u2019 annotation capability. Our empirical study shows CoAnnotating to be an effective means to allocate work from results on different datasets, with up to 21% performance improvement over random baseline. For code implementation, see https: //github.com/SALT-NLP/CoAnnotating.",
    "authors": [
        {
            "affiliations": [],
            "name": "Minzhi Li"
        },
        {
            "affiliations": [],
            "name": "Taiwei Shi"
        },
        {
            "affiliations": [],
            "name": "Caleb Ziems"
        },
        {
            "affiliations": [],
            "name": "Min-Yen Kan"
        },
        {
            "affiliations": [],
            "name": "Nancy F. Chen"
        },
        {
            "affiliations": [],
            "name": "Zhengyuan Liu"
        },
        {
            "affiliations": [],
            "name": "Diyi Yang"
        }
    ],
    "id": "SP:8501ad065437c62242fc021cbc0284065c0545c8",
    "references": [
        {
            "authors": [
                "AmirAli Abdolrashidi",
                "Lisa Wang",
                "Shivani Agrawal",
                "Jonathan Malmaud",
                "Oleg Rybakov",
                "Chas Leichner",
                "Lukasz Lew."
            ],
            "title": "Pareto-optimal quantized resnet is mostly 4-bit",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pat-",
            "year": 2021
        },
        {
            "authors": [
                "Mostafa M Amin",
                "Erik Cambria",
                "Bj\u00f6rn W Schuller."
            ],
            "title": "Will affective computing emerge from foundation models and general ai? a first evaluation on chatgpt",
            "venue": "arXiv preprint arXiv:2303.03186.",
            "year": 2023
        },
        {
            "authors": [
                "Rie Kubota Ando",
                "Tong Zhang."
            ],
            "title": "A framework for learning predictive structures from multiple tasks and unlabeled data",
            "venue": "Journal of Machine Learning Research, 6:1817\u20131853.",
            "year": 2005
        },
        {
            "authors": [
                "Galen Andrew",
                "Jianfeng Gao."
            ],
            "title": "Scalable training of L1-regularized log-linear models",
            "venue": "Proceedings of the 24th International Conference on Machine Learning, pages 33\u201340.",
            "year": 2007
        },
        {
            "authors": [
                "Abhijeet Awasthi",
                "Sabyasachi Ghosh",
                "Rasna Goyal",
                "Sunita Sarawagi."
            ],
            "title": "Learning from rules generalizing labeled exemplars",
            "venue": "arXiv preprint arXiv:2004.06025.",
            "year": 2020
        },
        {
            "authors": [
                "Stephen H Bach",
                "Daniel Rodriguez",
                "Yintao Liu",
                "Chong Luo",
                "Haidong Shao",
                "Cassandra Xia",
                "Souvik Sen",
                "Alex Ratner",
                "Braden Hancock",
                "Houman Alborzi"
            ],
            "title": "Snorkel drybell: A case study in deploying weak supervision at industrial scale",
            "year": 2019
        },
        {
            "authors": [
                "Yejin Bang",
                "Samuel Cahyawijaya",
                "Nayeon Lee",
                "Wenliang Dai",
                "Dan Su",
                "Bryan Wilie",
                "Holy Lovenia",
                "Ziwei Ji",
                "Tiezheng Yu",
                "Willy Chung"
            ],
            "title": "A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity",
            "year": 2023
        },
        {
            "authors": [
                "Max Bartolo",
                "Tristan Thrush",
                "Sebastian Riedel",
                "Pontus Stenetorp",
                "Robin Jia",
                "Douwe Kiela."
            ],
            "title": "Models in the loop: Aiding crowdworkers with generative annotation assistants",
            "venue": "arXiv preprint arXiv:2112.09062.",
            "year": 2021
        },
        {
            "authors": [
                "Arun Tejasvi Chaganty",
                "Stephen Mussman",
                "Percy Liang."
            ],
            "title": "The price of debiasing automatic metrics in natural language evaluation",
            "venue": "arXiv preprint arXiv:1807.02202.",
            "year": 2018
        },
        {
            "authors": [
                "Shizhe Diao",
                "Pengcheng Wang",
                "Yong Lin",
                "Tong Zhang."
            ],
            "title": "Active prompting with chain-ofthought for large language models",
            "venue": "arXiv preprint arXiv:2302.12246.",
            "year": 2023
        },
        {
            "authors": [
                "Bosheng Ding",
                "Chengwei Qin",
                "Linlin Liu",
                "Lidong Bing",
                "Shafiq Joty",
                "Boyang Li"
            ],
            "title": "Is gpt-3 a good data annotator? arXiv preprint arXiv:2212.10450",
            "year": 2022
        },
        {
            "authors": [
                "Bill Dolan",
                "Chris Brockett."
            ],
            "title": "Automatically constructing a corpus of sentential paraphrases",
            "venue": "Third International Workshop on Paraphrasing (IWP2005).",
            "year": 2005
        },
        {
            "authors": [
                "Claudio Gentile",
                "Zhilei Wang",
                "Tong Zhang."
            ],
            "title": "Fast rates in pool-based batch active learning",
            "venue": "arXiv preprint arXiv:2202.05448.",
            "year": 2022
        },
        {
            "authors": [
                "Fabrizio Gilardi",
                "Meysam Alizadeh",
                "Ma\u00ebl Kubli."
            ],
            "title": "Chatgpt outperforms crowd-workers for textannotation tasks",
            "venue": "arXiv preprint arXiv:2303.15056.",
            "year": 2023
        },
        {
            "authors": [
                "Julius Gonsior",
                "Maik Thiele",
                "Wolfgang Lehner."
            ],
            "title": "Weakal: Combining active learning and weak supervision",
            "venue": "Discovery Science: 23rd International Conference, DS 2020, Thessaloniki, Greece, October 19\u201321, 2020, Proceedings 23, pages 34\u201349.",
            "year": 2020
        },
        {
            "authors": [
                "Jonatas S Grosman",
                "Pedro HT Furtado",
                "Ariane MB Rodrigues",
                "Guilherme G Schardong",
                "Simone DJ Barbosa",
                "H\u00e9lio CV Lopes."
            ],
            "title": "Eras: Improving the quality control in the annotation process for natural language processing tasks",
            "venue": "Information Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Raphael Hoffmann",
                "Congle Zhang",
                "Xiao Ling",
                "Luke Zettlemoyer",
                "Daniel S Weld."
            ],
            "title": "Knowledgebased weak supervision for information extraction of overlapping relations",
            "venue": "Proceedings of the 49th annual meeting of the association for computational",
            "year": 2011
        },
        {
            "authors": [
                "Fan Huang",
                "Haewoon Kwak",
                "Jisun An."
            ],
            "title": "Is chatgpt better than human annotators? potential and limitations of chatgpt in explaining implicit hate speech",
            "venue": "arXiv preprint arXiv:2302.07736.",
            "year": 2023
        },
        {
            "authors": [
                "Myeongjun Jang",
                "Thomas Lukasiewicz."
            ],
            "title": "Consistency analysis of chatgpt",
            "venue": "arXiv preprint arXiv:2303.06273.",
            "year": 2023
        },
        {
            "authors": [
                "Saurav Kadavath",
                "Tom Conerly",
                "Amanda Askell",
                "Tom Henighan",
                "Dawn Drain",
                "Ethan Perez",
                "Nicholas Schiefer",
                "Zac Hatfield Dodds",
                "Nova DasSarma",
                "Eli Tran-Johnson"
            ],
            "title": "Language models (mostly) know what they know",
            "year": 2022
        },
        {
            "authors": [
                "Junmo Kang",
                "Wei Xu",
                "Alan Ritter."
            ],
            "title": "Distill or annotate? cost-efficient fine-tuning of compact models",
            "venue": "arXiv preprint arXiv:2305.01645.",
            "year": 2023
        },
        {
            "authors": [
                "Aniket Kittur",
                "Ed H Chi",
                "Bongwon Suh."
            ],
            "title": "Crowdsourcing user studies with mechanical turk",
            "venue": "Proceedings of the SIGCHI conference on human factors in computing systems, pages 453\u2013456.",
            "year": 2008
        },
        {
            "authors": [
                "Tom Kocmi",
                "Christian Federmann."
            ],
            "title": "Large language models are state-of-the-art evaluators of translation quality",
            "venue": "arXiv preprint arXiv:2302.14520.",
            "year": 2023
        },
        {
            "authors": [
                "Jan Koco\u0144",
                "Igor Cichecki",
                "Oliwier Kaszyca",
                "Mateusz Kochanek",
                "Dominika Szyd\u0142o",
                "Joanna Baran",
                "Julita Bielaniewicz",
                "Marcin Gruza",
                "Arkadiusz Janz",
                "Kamil Kanclerz"
            ],
            "title": "Chatgpt: Jack of all trades, master of none",
            "venue": "arXiv preprint arXiv:2302.10724",
            "year": 2023
        },
        {
            "authors": [
                "Taja Kuzman",
                "Nikola Ljube\u0161i\u0107",
                "Igor Mozeti\u010d."
            ],
            "title": "Chatgpt: Beginning of an end of manual annotation? use case of automatic genre identification",
            "venue": "arXiv preprint arXiv:2303.03953.",
            "year": 2023
        },
        {
            "authors": [
                "Xin Li",
                "Dan Roth."
            ],
            "title": "Learning question classifiers",
            "venue": "COLING 2002: The 19th International Conference on Computational Linguistics.",
            "year": 2002
        },
        {
            "authors": [
                "Stephanie Lin",
                "Jacob Hilton",
                "Owain Evans."
            ],
            "title": "Teaching models to express their uncertainty in words",
            "venue": "arXiv preprint arXiv:2205.14334.",
            "year": 2022
        },
        {
            "authors": [
                "Todd Lingren",
                "Louise Deleger",
                "Katalin Molnar",
                "Haijun Zhai",
                "Jareen Meinzen-Derr",
                "Megan Kaiser",
                "Laura Stoutenborough",
                "Qi Li",
                "Imre Solti"
            ],
            "title": "Evaluating the impact of pre-annotation on annotation speed and potential bias: natural language processing",
            "year": 2014
        },
        {
            "authors": [
                "Pierre Lison",
                "Aliaksandr Hubin",
                "Jeremy Barnes",
                "Samia Touileb."
            ],
            "title": "Named entity recognition without labelled data: A weak supervision approach",
            "venue": "arXiv preprint arXiv:2004.14723.",
            "year": 2020
        },
        {
            "authors": [
                "Alisa Liu",
                "Swabha Swayamdipta",
                "Noah A Smith",
                "Yejin Choi."
            ],
            "title": "Wanli: Worker and ai collaboration for natural language inference dataset creation",
            "venue": "arXiv preprint arXiv:2201.05955.",
            "year": 2022
        },
        {
            "authors": [
                "Daniel Loureiro",
                "Aminette D\u2019Souza",
                "Areej Nasser Muhajab",
                "Isabella A White",
                "Gabriel Wong",
                "Luis Espinosa Anke",
                "Leonardo Neves",
                "Francesco Barbieri",
                "Jose Camacho-Collados"
            ],
            "title": "Tempowic: An evaluation benchmark for detecting meaning shift",
            "year": 2022
        },
        {
            "authors": [
                "Gideon S Mann",
                "Andrew McCallum."
            ],
            "title": "Generalized expectation criteria for semi-supervised learning with weakly labeled data",
            "venue": "Journal of machine learning research, 11(2).",
            "year": 2010
        },
        {
            "authors": [
                "Yu Meng",
                "Jiaming Shen",
                "Chao Zhang",
                "Jiawei Han."
            ],
            "title": "Weakly-supervised neural text classification",
            "venue": "proceedings of the 27th ACM International Conference on information and knowledge management, pages 983\u2013992.",
            "year": 2018
        },
        {
            "authors": [
                "Bonan Min",
                "Ralph Grishman",
                "Li Wan",
                "Chang Wang",
                "David Gondek."
            ],
            "title": "Distant supervision for relation extraction with an incomplete knowledge base",
            "venue": "Proceedings of the 2013 Conference of the North American Chapter of the Association for Computa-",
            "year": 2013
        },
        {
            "authors": [
                "Saif Mohammad",
                "Svetlana Kiritchenko",
                "Parinaz Sobhani",
                "Xiaodan Zhu",
                "Colin Cherry."
            ],
            "title": "Semeval-2016 task 6: Detecting stance in tweets",
            "venue": "Proceedings of the 10th international workshop on semantic evaluation (SemEval-2016), pages 31\u201341.",
            "year": 2016
        },
        {
            "authors": [
                "Saif Mohammad",
                "Svetlana Kiritchenko",
                "Parinaz Sobhani",
                "Xiaodan Zhu",
                "Colin Cherry."
            ],
            "title": "SemEval-2016 task 6: Detecting stance in tweets",
            "venue": "Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016), pages 31\u2013",
            "year": 2016
        },
        {
            "authors": [
                "Chengwei Qin",
                "Aston Zhang",
                "Zhuosheng Zhang",
                "Jiaao Chen",
                "Michihiro Yasunaga",
                "Diyi Yang"
            ],
            "title": "Is chatgpt a general-purpose natural language processing task solver? arXiv preprint arXiv:2302.06476",
            "year": 2023
        },
        {
            "authors": [
                "Mohammad Sadegh Rasooli",
                "Joel R. Tetreault."
            ],
            "title": "Yara parser: A fast and accurate dependency parser",
            "venue": "Computing Research Repository, arXiv:1503.06733. Version 2.",
            "year": 2015
        },
        {
            "authors": [
                "Alexander Ratner",
                "Stephen H Bach",
                "Henry Ehrenberg",
                "Jason Fries",
                "Sen Wu",
                "Christopher R\u00e9."
            ],
            "title": "Snorkel: Rapid training data creation with weak supervision",
            "venue": "Proceedings of the VLDB Endowment. International Conference on Very Large Data Bases,",
            "year": 2017
        },
        {
            "authors": [
                "Michael Reiss"
            ],
            "title": "Testing the reliability of chatgpt for text annotation and classification: A cautionary remark",
            "year": 2023
        },
        {
            "authors": [
                "Rion Snow",
                "Brendan O\u2019connor",
                "Dan Jurafsky",
                "Andrew Y Ng"
            ],
            "title": "Cheap and fast\u2013but is it good? evaluating non-expert annotations for natural language tasks",
            "venue": "In Proceedings of the 2008 conference on empirical methods in natural language processing,",
            "year": 2008
        },
        {
            "authors": [
                "Yiming Tan",
                "Dehai Min",
                "Yu Li",
                "Wenbo Li",
                "Nan Hu",
                "Yongrui Chen",
                "Guilin Qi."
            ],
            "title": "Evaluation of chatgpt as a question answering system for answering complex questions",
            "venue": "arXiv preprint arXiv:2303.07992.",
            "year": 2023
        },
        {
            "authors": [
                "Serra Sinem Tekiroglu",
                "Yi-Ling Chung",
                "Marco Guerini."
            ],
            "title": "Generating counter narratives against online hate speech: Data and strategies",
            "venue": "arXiv preprint arXiv:2004.04216.",
            "year": 2020
        },
        {
            "authors": [
                "Petter T\u00f6rnberg."
            ],
            "title": "Chatgpt-4 outperforms experts and crowd workers in annotating political twitter messages with zero-shot learning",
            "venue": "arXiv preprint arXiv:2304.06588.",
            "year": 2023
        },
        {
            "authors": [
                "Marcos Treviso",
                "Ant\u00f3nio G\u00f3is",
                "Patrick Fernandes",
                "Erick Fonseca",
                "Andre Martins."
            ],
            "title": "Predicting attention sparsity in transformers",
            "venue": "Proceedings of the Sixth Workshop on Structured Prediction for",
            "year": 2022
        },
        {
            "authors": [
                "Jiaan Wang",
                "Yunlong Liang",
                "Fandong Meng",
                "Haoxiang Shi",
                "Zhixu Li",
                "Jinan Xu",
                "Jianfeng Qu",
                "Jie Zhou."
            ],
            "title": "Is chatgpt a good nlg evaluator? a preliminary study",
            "venue": "arXiv preprint arXiv:2303.04048.",
            "year": 2023
        },
        {
            "authors": [
                "Shuohang Wang",
                "Yang Liu",
                "Yichong Xu",
                "Chenguang Zhu",
                "Michael Zeng."
            ],
            "title": "Want to reduce labeling cost? gpt-3 can help",
            "venue": "arXiv preprint arXiv:2108.13487.",
            "year": 2021
        },
        {
            "authors": [
                "Xuezhi Wang",
                "Jason Wei",
                "Dale Schuurmans",
                "Quoc Le",
                "Ed Chi",
                "Denny Zhou."
            ],
            "title": "Self-consistency improves chain of thought reasoning in language models",
            "venue": "arXiv preprint arXiv:2203.11171.",
            "year": 2022
        },
        {
            "authors": [
                "Ann Yuan",
                "Daphne Ippolito",
                "Vitaly Nikolaev",
                "Chris Callison-Burch",
                "Andy Coenen",
                "Sebastian Gehrmann."
            ],
            "title": "Synthbio: A case study in humanai collaborative curation of text datasets",
            "venue": "arXiv preprint arXiv:2111.06467.",
            "year": 2021
        },
        {
            "authors": [
                "Jieyu Zhang",
                "Cheng-Yu Hsieh",
                "Yue Yu",
                "Chao Zhang",
                "Alexander Ratner."
            ],
            "title": "A survey on programmatic weak supervision",
            "venue": "arXiv preprint arXiv:2202.05433.",
            "year": 2022
        },
        {
            "authors": [
                "Jieyu Zhang",
                "Bohan Wang",
                "Xiangchen Song",
                "Yujing Wang",
                "Yaming Yang",
                "Jing Bai",
                "Alexander Ratner."
            ],
            "title": "Creating training sets via weak indirect supervision",
            "venue": "arXiv preprint arXiv:2110.03484.",
            "year": 2021
        },
        {
            "authors": [
                "Justine Zhang",
                "Jonathan P Chang",
                "Cristian DanescuNiculescu-Mizil",
                "Lucas Dixon",
                "Yiqing Hua",
                "Nithum Thain",
                "Dario Taraborelli."
            ],
            "title": "Conversations gone awry: Detecting early signs of conversational failure",
            "venue": "arXiv preprint arXiv:1805.05345.",
            "year": 2018
        },
        {
            "authors": [
                "Xiang Zhang",
                "Junbo Zhao",
                "Yann LeCun."
            ],
            "title": "Character-level convolutional networks for text classification",
            "venue": "Advances in neural information processing systems, 28.",
            "year": 2015
        },
        {
            "authors": [
                "Qihuang Zhong",
                "Liang Ding",
                "Juhua Liu",
                "Bo Du",
                "Dacheng Tao."
            ],
            "title": "Can chatgpt understand too? a comparative study on chatgpt and fine-tuned bert",
            "venue": "arXiv preprint arXiv:2302.10198.",
            "year": 2023
        },
        {
            "authors": [
                "Caleb Ziems",
                "William Held",
                "Omar Shaikh",
                "Jiaao Chen",
                "Zhehao Zhang",
                "Diyi Yang"
            ],
            "title": "Can large language models transform computational social science? arXiv preprint arXiv:2305.03514",
            "year": 2023
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Labeled data plays a critical role in establishing benchmarks and developing models for Natural Language Processing (NLP). Although Large Language Models (LLMs) like ChatGPT have demonstrated their strong zero-shot performance in various tasks such as question answering, reasoning, natural language inference, sentiment analysis, and named entity recognition, results obtained by finetuned language models still outperform LLMs on most of these tasks (Qin et al., 2023; Zhong et al., 2023; Ziems et al., 2023). Therefore, collecting labeled data for model training and fine-tuning is still valuable. Instead of deploying LLMs directly for downstream uses, it is worthwhile to investigate how researchers can leverage LLMs\u2019 zero-shot capability in labeling text data to construct high-\nquality datasets and improve the performance of fine-tuned models.\nTypically, researchers recruit human annotators such as experts or crowd workers to perform data annotation (Kittur et al., 2008; Snow et al., 2008). Some challenges in manual annotation includes high costs of recruiting and training annotators, annotation inconsistency and human subjectivity (Lingren et al., 2014; Grosman et al., 2020). Recent work explored how LLMs perform relative to crowd workers (Ding et al., 2022) and results showed that it is possible for LLMs like ChatGPT to replace large-scale manual annotation (Huang et al., 2023; Kuzman et al., 2023). In some cases, LLMs\u2019 annotation quality even outperforms human annotators on certain tasks (Gilardi et al., 2023). Given the much lower annotation cost than crowd workers, LLMs are considered to have great poten-\ntial to increase the cost efficiency of the data annotation process. However, some studies also show that, relative to human performance, LLMs\u2019 zero-shot performance falls short on more difficult and pragmatic tasks (Wang et al., 2021; Kocon\u0301 et al., 2023). They suggest that practitioners should use caution when using LLMs to annotate data (Reiss, 2023; Huang et al., 2023). Such prior works view humans and LLMs as competitors, measuring the accuracy of LLM labels as a replacement for human annotation, rather than considering how humans and LLMs might collaborate in an efficient manner. It is Human-LLM collaboration that motivates this work. We propose the CoAnnotating framework, which aims to balance the complementary profiles of humans and LLMs in terms of their respective annotation quality and cost.\nOur work tackles the problem of Human-LLM co-annotation from a resource allocation perspective. Following Gentile et al. (2022), Diao et al. (2023) and Wang et al. (2021), we consider model confidence as a reliable signal for the model\u2019s expected performance. As we consider allocating a given datapoint for an LLM to annotate, we can use the inverse of the model\u2019s uncertainty to estimate our confidence in that allocation. Under CoAnnotating, we quantify LLMs\u2019 annotating expertise on the instance-level (estimating how well LLMs can annotate the given data point) beyond task-level (evaluating how LLMs performs on overall for each dataset). As such, a more informed allocation decision can be made with this fine-grained and contextualized instance-level perspective, rather than broad and coarse dataset-level expertise.\nWe show that our proposed method using the uncertainty of responses can achieve a more efficient and more accurate work allocation than the random allocation baseline. Our results also show that confidence scores generated by LLMs are generally well-calibrated but not always reliable. It is possible to outsource some annotation work to achieve human-level performance for more straightforward tasks like topic understanding. On the other hand, a tradeoff between annotation quality and annotation cost is inevitable for more nuanced tasks. Our framework establishes a guide to effectively allocate AI and human efforts in collaborative annotation, and in doing so, it provides key insights into the capacities of LLMs, as well as the nature of the tasks and data that remain outside these capacities."
        },
        {
            "heading": "2 Related Work",
            "text": ""
        },
        {
            "heading": "2.1 Weak Supervision",
            "text": "In a traditional supervised learning setting, every training data point is labeled by human annotators. However, acquiring manually annotated labels for training data can be prohibitively costly and time-consuming. Weak supervision helps to address the challenge using partially and imperfectly labeled data for training (Zhang et al., 2022). Weak supervision techniques obtain these noisy labels by tapping into heuristics (Ratner et al., 2017; Meng et al., 2018; Awasthi et al., 2020), feature annotation (Mann and McCallum, 2010), external knowledge bases (Hoffmann et al., 2011; Min et al., 2013), pretrained models (Bach et al., 2019; Zhang et al., 2021) and third-party tools (Lison et al., 2020). Moreover, weak supervision can be combined with the active learning framework (Gonsior et al., 2020) to select the most informative data to be annotated by humans and utilize weak supervision to decide noisy labels. Given LLMs\u2019 stunning zero-shot capabilities, our work explores the possibility of using them as a more efficient labeling source, thus freeing up resources to be reinvested in the research pipeline."
        },
        {
            "heading": "2.2 LLMs for Annotation",
            "text": "Most prior works frame the decision for human or LLM annotation as one of competition rather than collaboration between these modes. These show that LLMs like GPT-3 davinci-003 have strong zero-shot sentiment analysis performance (Ding et al., 2022). ChatGPT (gpt-3.5-turbo) performs surprisingly well on automatic genre detection in under-resourced languages like Slovenian (Kuzman et al., 2023). ChatGPT can even achieve high accuracy on some of the most nuanced tasks like implicit hate speech detection (Huang et al., 2023). Similarly, GPT-4 is able to annotate texts that require reasoning and contextual knowledge and provide explanations that could facilitate interpretive research (T\u00f6rnberg, 2023). These results show the great potential of LLMs as data annotation tools with just simple prompt design and without much manual labeling efforts (Kuzman et al., 2023).\nHowever, there is still room to close significant performance gaps between LLMs\u2019 performance and existing fine-tuned baselines on some challenging tasks. LLMs struggle with named entity recognition (Ding et al., 2022; Qin et al., 2023), relational reasoning (Bang et al., 2023), affective\ntasks (Kocon\u0301 et al., 2023; Amin et al., 2023) and semantic similarity tasks (Kocmi and Federmann, 2023; Wang et al., 2023). Moreover, it does not outperform fine-tuned baselines for generation tasks like question answering and text summarization (Tan et al., 2023; Wang et al., 2023). These works all take the perspective that LLMs and humans are competitors, making task-level comparisons between LLMs and humans/fine-tuned models for each dataset. Our work views LLMs and humans as potential collaborators, with the possibility to work with each other to annotate the same dataset."
        },
        {
            "heading": "2.3 Human-Machine Collaboration for Dataset Creation",
            "text": "The quality of the dataset and the cost of creating a dataset are two important but sometimes conflicting objectives in dataset creation. Previous work suggests a human-AI collaborative framework that utilizes language models\u2019 generation capability and human revision and evaluation skills (Tekiroglu et al., 2020; Yuan et al., 2021; Bartolo et al., 2021; Liu et al., 2022) to create valuable datasets of high quality. For cost efficiency, some have proposed averaging or majority vote over human and machine outputs (Chaganty et al., 2018; Ziems et al., 2023) and some initial empirical explorations such as analyzing the random combination of distillation of LLM and manual annotation (Kang et al., 2023) as well as active labeling assignments via the logit outputs (Wang et al., 2021). Our framework takes both quality and cost into consideration by using uncertainty metrics to make informed human-AI work-allocation decisions to ensure cost efficiency without compromising quality."
        },
        {
            "heading": "3 CoAnnotating Framework",
            "text": "Our CoAnnotating framework sets up a guide for annotating text data collaboratively (Figure 2). For a given unlabeled train dataset Dt = {t1, t2, ...tm} where ti is the i-th instance in the dataset, our framework automatically decides whether each data instance should be annotated by human or by the LLMs (Section 3.3) by computing the uncertainty level of the LLMs\u2019s annotations for each instance (Section 3.2), with the goal of achieving a higher annotation quality and a lower annotation cost for a given dataset (Section 3.4)."
        },
        {
            "heading": "3.1 Prompt Construction",
            "text": "Previous work shows that LLMs\u2019 performance can be highly sensitive to perturbations in input (Jang and Lukasiewicz, 2023). Therefore, we introduce a set of diverse types of prompts Pi = {pi1, pi2, ..., pik} for each instance ti. Besides the (1) basic instruction format, we vary the prompts by swapping its sequence of sentences (2; symmetric perturbation), paraphrasing the instruction (3; semantic perturbation), enquiring in various question formats (4; True/False, 5; Textual Short Responses 6; Multiple Choice Question) and asking with confirmation bias (7; negation perturbation)."
        },
        {
            "heading": "3.2 Uncertainty Computation",
            "text": "In a real-world setting, there is no gold data on which to gauge the model\u2019s expected accuracy and thus decide on the optimal annotation strat-\negy. However, model confidence can serve as a reliable signal for model performance (Gentile et al., 2022; Diao et al., 2023; Wang et al., 2021). Therefore we compute the LLM uncertainty ui to guide the work-allocation process. We compute ui in two ways which are easy to implement and have proven effectiveness in previous literature (Diao et al., 2023): (1) self-evaluation and (2) entropy. In each case, for ti by prompting LLMs k times with different prompts in Pi we get k annotations Ai = {ai1, ai2, ..., aik} for each instance. As an ablation study (5.4), we also prompt LLMs k times with the same prompt to get k annotations to study the effect of prompt perturbations.\nSelf-Evaluation. Previous work shows that LLMs are well calibrated and can provide information about their uncertainty themselves (Wang et al., 2021; Kadavath et al., 2022; Diao et al., 2023). We ask the model to directly output its confidence score (Lin et al., 2022) by postpending the phrase \"and please give a confidence score on a scale of 0 to 1 for your prediction\". The uncertainty for ti is calculated by:\nui = 1\u2212 1\nk k\u2211 j=1 P\u03b8(aij |pij)\nwhere P\u03b8(aij |pij) is the probability of a class label being annotated by ChatGPT given the prompt pij . We obtain its value by extracting the confidence score provided by LLMs directly.\nEntropy. Entropy is a measure of the impurity in a set of data and can be used to quantify the uncertainty associated with the class labels. The\nlarger the entropy value, the more uncertain the responses are. We can use this metric to estimate the uncertainty level:\nui = \u2212 k\u2211\nj=1\nP\u03b8(aij |pij) lnP\u03b8(aij |pij)\nwhere P\u03b8(aij |pij) is calculated as the frequency of a certain prediction among all predictions."
        },
        {
            "heading": "3.3 Work Allocation Strategies",
            "text": "Building upon the aforementioned uncertainty level estimation, we can then use the uncertainty level ui to guide the work allocation.\nRandom Allocation. Random allocation is chosen as a baseline strategy for comparison. This is the strategy that randomly samples n instances (0 \u2264 n \u2264 m) in Dt to be annotated by LLMs while the remaining m\u2212 n data is annotated by humans.\nSelf-Evaluation Guided Allocation. Wang et al. (2021) introduces an active label assignment approach that ranks outputs by their logits. Not all LLM APIs support this computation, so we modify this baseline with our self-evaluation approach, sorting instances by the self-reported confidence scores in decreasing order. We then select the top n instances (0 \u2264 n \u2264 m) in Dt with the lowest level of uncertainty as the best candidates for LLM annotation. The remaining m\u2212 n data points are allocated to human annotators.\nEntropy Guided Allocation. It is not possible to entirely ensure the reliability of black box LLMs self-reported confidence. Therefore, we also propose the use of entropy across LLMs\u2019 responses\nto gauge their certainty and reliability. We sort the instances by their respective entropy values in increasing order and select the top n instances (0 \u2264 n \u2264 m) in Dt with the lowest level of uncertainty to be annotated by LLMs. Again, the remaining m\u2212 n data points with inconsistent responses will be allocated for human annotation."
        },
        {
            "heading": "3.4 Strategy Selection",
            "text": "We frame the co-annotation process as a multiobjective optimization problem with two main objectives, maximizing annotation quality and minimizing annotation cost. We can determine annotation quality by the classification performance of a model fine-tuned using a certain co-annotation strategy. The total annotation cost is the sum of manual annotation costs and those incurred by the LLM. Inspired by Kang et al. (2023), we apply the Pareto efficiency concept in strategy selection. Here, the Pareto efficient scenario refers to the situation where it is impossible to increase the classification performance of the fine-tuned model without incurring a higher annotation cost. By adopting different allocation strategies and setting different proportions of data allocated to LLMs, we get various allocation patterns with different annotation qualities and costs. We can then plot the performances of each quality-cost combination and approximate the Pareto frontier by interpolating the discrete data points (Abdolrashidi et al., 2021; Treviso et al., 2022). Practitioners can plot annotation quality against the cost for pilot data to gain a better understanding of this tradeoff, and they can use the Pareto efficient points to decide which ratio of data they should outsource to LLMs at their desired budget level."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Datasets",
            "text": "We use six classification datasets for different types of tasks. Since LLM inference costs much less than a human salary, we know the simple allocation decision is to choose LLMs over humans whenever an LLM achieves a utility greater than or equal to that of human annotators. For a more challenging setting, we identify tasks in which LLMs are known to struggle with discriminating the underlying constructs (Pikuliak, 2023; Wang et al., 2021). In such cases, there is a tradeoff between annotation quality and annotation cost and CoAnnotating facilitates better decision-making in such contexts. If the size\nof the train data is too large, we will take a stratified random sampling for approximately 1000 samples.\nTopic Classification is a challenging task for large pretrained language models like GPT-3 (Wang et al., 2021). We choose two representative datasets: TREC (Li and Roth, 2002) and AG News (Zhang et al., 2015). AG News contains news titles and their descriptions, which were gathered by an academic news search engine, and which span four topics: world, sports, business, and science/technology. TREC contains of English questions with six manually labeled class labels: abbreviation; entity; description and abstract concept; human being; location; and numeric value.\nSemantic Similarity is known to challenge ChatGPT (Jang and Lukasiewicz, 2023). We select MRPC (Dolan and Brockett, 2005) and TempoWiC (Loureiro et al., 2022) as two representative datasets for semantic similarity understanding. MRPC is a corpus of sentence pairs extracted from online news and annotated by humans for whether the sentences are semantically equivalent. TempoWiC contains annotated tweet pairs for whether there is a meaning shift of the target word.\nNuanced Comprehension We also experiment with Tweet Stance Detection (Mohammad et al., 2016a) and Conversation Gone Awry (Zhang et al., 2018) to explore the collaboration paradigm on tasks requiring more nuanced comprehension. Tweet Stance Detection in SemEval-2016 (Mohammad et al., 2016b) is a dataset of tweets annotated with the author\u2019s stance (favorable, neutral, and negative) toward a certain topic and we select the topic of abortion."
        },
        {
            "heading": "4.2 LLM Annotation",
            "text": "We obtain responses from ChatGPT (gpt-3.5-turbo) due to its high-quality annotations and low inference cost (Kuzman et al., 2023) using different prompts carefully crafted in Table 1. If the response is an ambiguous answer such as \"I cannot determine the class of the text\", we encode it as a new class label which can result in higher uncertainty metrics. The uncertainty computation decides whether annotation will be finally allocated to ChatGPT, and if so, we decide the final label with a majority vote across ChatGPT\u2019s generations (Wang et al., 2022)."
        },
        {
            "heading": "4.3 Evaluation",
            "text": "To evaluate the quality of datasets annotated with different strategies, we fine-tune the same RoBERTa base classifier and calculate macro F1 scores on test data for a fair comparison. We report macro F1 as a more accurate representation of the performance due to the unbalanced nature of LLMs\u2019 annotations for some datasets.\nIn terms of cost, we only consider monetary cost in this work. We calculate human annotation costs based on what was reported in the dataset paper. If the information is not applicable, we assume each instance is annotated by 5 independent annotators with a wage of $15/hour. We calculate ChatGPT annotation cost using the product of the token length of the input prompt and the price of calling API for (gpt-3.5-turbo) ($0.002/1k tokens) at the time of experimentation."
        },
        {
            "heading": "5 Results",
            "text": ""
        },
        {
            "heading": "5.1 Strategy Comparison",
            "text": "We plot the histograms for distribution of uncertainty metrics (entropy with different prompts and same prompt as well as confidence score). From Figure 3, we can observe that the model tends to be confident with its predictions with a skewed distribution towards high confidence value although we ask ChatGPT to normalize its answer.\nWe hypothesize that a lower level of uncertainty in ChatGPT\u2019s response indicates a higher degree of reliability in the label. Therefore, we set differ-\nent thresholds for entropy (lower than an entropy threshold) and self-confidence score (higher than a confidence threshold) to select data that ChatGPT is more certain about. For those instances selected, we evaluate ChatGPT\u2019s annotation quality by calculating its alignment with the gold label (human annotation). Figure 4\u2019s decreasing trends for entropy-guided allocation (green and blue dots) on all datasets validate our hypothesis of an inverse relationship between uncertainty and annotation quality. It justifies the helpfulness of using the entropy of ChatGPT\u2019s annotations as an estimate for its annotating expertise. Importantly, we observe that ChatGPT\u2019s self-reported confidence scores (orange dots) are not consistently a good estimate for its annotation quality. For some datasets such as AG News (top left), most of the data (94.3% with calculation) has high self-reported confidence ranging from 0.8 to 1, which leads to a weak separation of data in terms of annotation quality. For MRPC (top middle), there is a decreasing trend where data instances with higher confidence scores in fact have a poorer alignment with gold labels. This shows that the reliability of using self-reported confidence from LLMs is not guaranteed.\nThe purpose of achieving a higher quality for train data is to ensure that it can teach the classifier accurate information through fine-tuning. In Table 2, we carry out comparisons of different allocation strategies in terms of test performance after fine-tuning with such data labeled. We see that holding the proportion of data allocated to Chat-\nGPT fixed (e.g., taking the setup of 40% for TempoWIC as an example), our proposed uncertaintyguided allocation using self-evaluation and entropy results in a better-annotated dataset, reflected by its higher test F1 (56.9) than the random allocation baseline (53.2). More often than not, entropyguided allocation is better than confidence-guided allocation. This is probably due to the skewed distribution of self-reported confidence, resulting in a\npoorer distinguishability between instances LLMs are better or worse at annotating."
        },
        {
            "heading": "5.2 Pareto Efficient Allocation",
            "text": "By plotting test performance against annotation cost (Figure 5), practitioners can visualize the tradeoff in annotation quality achievable at different budgets with collaboration between human and an LLM like ChatGPT by studying the Pareto frontier.\nPareto frontier is highlighted, illustrating the optimal choices that are Pareto efficient.\nDataset Text Groundtruth ChatGPT\nAG News Title: Sprint Set to Debut Video-Streaming Cell Phone Description: OVERLAND PARK, Kan. (AP) \u2013 Channel surfing is moving off the couch as Sprint Corp... Sci/Tech Business\nTREC What does A&W of root beer fame stand for? Abbreviation Entity\nStance Detection @user As a former fetus I oppose #ProlifeYouth #SemST Negative Neutral\nConversation\nrjoccolenty: Shouldn\u2019t her name be Zainab Yusef and not Zainab Khan? Bluebolt94: Does the credits at the end of the episode say \u201dZainab Yusef\u201d? No they say \u201dZainab Khan\u201d and Yusef called her \u201dMrs. Khan\u201d during the episode. So no, her name is \u201dZainab Khan\u201d. \u2013 AnemoneProjectors: The Khans are clearly not as traditional as the Masoods, or Afia would have been called Afia Yusef. We already know this! And what GS said. Watch the show properly P \u2013\u2013 True False\nMRPC Sentence1: At 5 p.m. EDT , Henri had maximum sustained winds near 50 mph , with some gusts reaching 60 mph. Sentence2: At 8 p.m. Friday , Henri was becoming disorganized , but still had maximum sustained winds near 50 mph , with stronger gusts. Not paraphrase Paraphrase\nPoints along the highlighted Pareto frontier mean it is theoretically impossible to achieve a higher test accuracy without increasing the budget, and it is also impossible to reduce the cost but achieve the same level of annotation quality. Furthermore, it provides information on the approximate proportion that can be outsourced to ChatGPT to achieve human-level performance. For more straightforward tasks like topic classification, part of the annotation work could be potentially outsourced to ChatGPT and lead to a cost reduction (e.g., AG News: 33%) by ensuring human-level annotation performance. For datasets requiring nuanced comprehensions like Stance Detection and Conversa-\ntion Gone Awry, any level of outsourcing to the current version of ChatGPT compromises annotation quality. Practitioners can choose among the Pareto efficient points based on their budgets."
        },
        {
            "heading": "5.3 Qualitative Analysis",
            "text": "We select some instances with entropy values higher than 0.8 from each dataset (Table 3) to understand the current challenges faced by ChatGPT in annotating data. We find that ChatGPT has high uncertainty for instances containing sarcasm and incomplete sentences that require more inference during opinion mining. For example, in deciding the stance towards abortion for the tweet \u201cas a for-\nmer fetus I oppose\u201d, the incomplete nature of this sentence causes confusion to ChatGPT. Also, it struggles with numerical reasoning as seen from its inability to compare wind speed during paraphrase detection and may be misled by some keywords (\u201cCorp\u201d) related to other incorrect classes (\u201cbusiness\u201d) in topic classification."
        },
        {
            "heading": "5.4 Ablation Study",
            "text": "We carry out inferences with the same instructionformatted prompt for the same number of times and compute the entropy for ChatGPT\u2019s responses. From Figure 4, we observe some extent of effectiveness of computing entropy using the same prompt in quantifying ChatGPT\u2019s capability, as reflected by a decreasing pattern of alignment with the increased threshold. However, it serves as a much weaker method to quantify expertise compared with our method with different prompt designs since the majority of the data has zero entropy (see Figure 3). This suggests that ChatGPT\u2019s responses are generally consistent within multiple applications of the same prompt. In Table 2, the test performance of entropy-guided allocation under different prompts is consistently higher than when based on a single prompt. The performance gap gives strong evidence of the utility of applying different prompt types in Table 1."
        },
        {
            "heading": "6 Conclusion",
            "text": "This work introduces CoAnnotating, a framework which takes a collaborative angle to view the relationship between humans and LLMs when annotating each dataset. Under this framework, we use uncertainty metrics to estimate LLMs\u2019 annotating capability and guide effective work allocation. Moreover, we apply the Pareto efficiency concept for practitioners to compare strategies and understand cost-performance tradeoffs. The empirical results demonstrate the effectiveness of our proposed framework in achieving greater cost efficiency. Overall, our framework provides important insights around the reliability of self-reported confidence score by LLMs, the sensitivity of ChatGPT\u2019s responses to prompt variations as well as the extent to which human resources can be freed by LLMs to be put on more meaningful areas."
        },
        {
            "heading": "7 Limitations",
            "text": "Since LLMs has been trained on a large number of datasets, there may be data leakage issue\nwhere LLMs has seen some datasets in our experiment, making entropy values obtained for LLMs\u2019 responses lower. As an initial exploration of the coannotating concept, this work aims for human-level performance in annotating datasets. It does not consider the scope of superhuman-level performance where we treat human annotation in each dataset as gold labels. Future work can further investigate the instances where LLMs actually annotates better than humans. We consider annotating profiles of human and LLMs as two groups but this framework can be further enriched by taking variations within each group (expert, crowd workers, different LLMs) into considerations. More exploration can also be carried out to investigate how to design prompts in a way that can increase LLMs\u2019s annotating expertise so that more annotation work can be outsourced to LLMs for greater cost efficiency. Moreover, this work only did experiments for classification tasks and English datasets. However, the idea of CoAnnotating is generalizable to generation tasks and datasets in other languages as well, which are meaningful to study in future work.\nEthical Statement\nWe are aware of the potential ethical concerns of using LLMs as potential labelers in the data annotation process in terms of the perpetuation of existing biases in LLMs. Since LLMs are trained on vast amounts of texts on the Internet, they can unavoidably incorporate the biases present in these data sources. Such biases could be under-representation of certain demographic groups, cultural stereotypes as well as linguistic biases. However, we believe that the benefit of proposing a collaborative coannotation framework outweighs the potential risks related to the framework."
        },
        {
            "heading": "Acknowledgement",
            "text": "We are thankful to the members of SALT Lab and WING Lab as well as anonymous EMNLP reviewers for their helpful feedback. Minzhi Li is supported by the A*STAR Computing and Information Science (ACIS) Scholarship. Caleb Ziems is supported by the NSF Graduate Research Fellowship under Grant No. DGE-2039655. We would like to acknowledge a grant from the Office of Naval Research to DY, and National Research Foundation, Singapore under its AI Singapore Programme (AISG Award No: AISG2-GC-2022-005)."
        },
        {
            "heading": "A Model Setting",
            "text": "ChatGPT parameters: temperature = 0.7; max_tokens = 800; top_p = 0.95; frequency_penalty = 0; presence_penalty = 0; openai_api_version = \u20182023-03-15-preview\u2019 RoBERTa base parameters: Adam optimizer, learning_rate=2e-5, correct_bias = True"
        },
        {
            "heading": "B Prompts",
            "text": "In this section, we present specific prompts used to obtain annotations from ChatGPT for each dataset during our experiments.\nB.1 AG News Instruction. Please label the topic of the following news title and description as \u201cworld\u201d, \u201csports\u201d, \u201cbusiness\u201d or \u201csci/tech\u201d. Text: \u201cTitle: Wall St. Bears Claw Back Into the Black (Reuters) Description: Reuters Short-sellers, Wall Street\u2019s dwindling band of ultra-cynics, are seeing green again.\u201d\nSequence Swapping. Text: \u201cTitle: Wall St. Bears Claw Back Into the Black (Reuters) Description: Reuters - Short-sellers, Wall Street\u2019s dwindling band of ultra-cynics, are seeing green again.\u201d Please label the topic of the following news title and description as \u201cworld\u201d, \u201csports\u201d, \u201cbusiness\u201d or \u201csci/tech\u201d.\nParaphrasing. Given the following text, please classify the topic of the following news title and description as \u201cworld\u201d, \u201csports\u201d, \u201cbusiness\u201d or \u201csci/tech\u201d. Text: \u201cTitle: Wall St. Bears Claw Back Into the Black (Reuters) Description: Reuters Short-sellers, Wall Street\u2019s dwindling band of ultra-cynics, are seeing green again.\u201d\nTrue/False 1. Based on the language used, is it true that the following news title and description belongs to the topic of \u201cworld\u201d? Text: \u201cTitle: Wall St. Bears Claw Back Into the Black (Reuters) Description: Reuters Short-sellers, Wall Street\u2019s dwindling band of ultra-cynics, are seeing green again.\u201d\nTrue/False 2. Based on the language used, is it true that the following news title and description belongs to the topic of \u201csports\u201d? Text: \u201cTitle: Wall St. Bears Claw Back Into the Black (Reuters) Description: Reuters Short-sellers,\nWall Street\u2019s dwindling band of ultra-cynics, are seeing green again.\u201d\nTrue/False 3. Based on the language used, is it true that the following news title and description belongs to the topic of \u201cbusiness\u201d? Text: \u201cTitle: Wall St. Bears Claw Back Into the Black (Reuters) Description: Reuters Short-sellers, Wall Street\u2019s dwindling band of ultra-cynics, are seeing green again.\u201d\nTrue/False 4. Based on the language used, is it true that the following news title and description belongs to the topic of \u201csci/tech\u201d? Text: \u201cTitle: Wall St. Bears Claw Back Into the Black (Reuters) Description: Reuters Short-sellers, Wall Street\u2019s dwindling band of ultra-cynics, are seeing green again.\u201d\nQuestion Answering. What topic does the following news title and description belong to? Is it \u201cworld\u201d, \u201csports\u201d, \u201cbusiness\u201d or \u201csci/tech\u201d? Text: \u201cTitle: Wall St. Bears Claw Back Into the Black (Reuters) Description: Reuters Short-sellers, Wall Street\u2019s dwindling band of ultra-cynics, are seeing green again.\u201d\nMultiple Choice Question. Please choose one option that best describes the topic of the news title and description. Text: \u201cTitle: Wall St. Bears Claw Back Into the Black (Reuters) Description: Reuters Short-sellers, Wall Street\u2019s dwindling band of ultra-cynics, are seeing green again.\u201d Options: (A)World (B)Sports (C)Business (D)Sci/tech\nConfirmation Bias 1. I think the following news title and description belongs to the \u201cworld\u201d topic. Do you agree? Please give your answer as either yes or no. Text: \u201cTitle: Wall St. Bears Claw Back Into the Black (Reuters) Description: Reuters Short-sellers, Wall Street\u2019s dwindling band of ultra-cynics, are seeing green again.\u201d\nConfirmation Bias 2. I think the following news title and description belongs to the \u201csports\u201d topic. Do you agree? Please give your answer as either yes or no. Text: \u201cTitle: Wall St. Bears Claw Back Into the\nBlack (Reuters) Description: Reuters Short-sellers, Wall Street\u2019s dwindling band of ultra-cynics, are seeing green again.\u201d\nConfirmation Bias 3. I think the following news title and description belongs to the \u201cbusiness\u201d topic. Do you agree? Please give your answer as either yes or no. Text: \u201cTitle: Wall St. Bears Claw Back Into the Black (Reuters) Description: Reuters Short-sellers, Wall Street\u2019s dwindling band of ultra-cynics, are seeing green again.\u201d\nConfirmation Bias 4. I think the following news title and description belongs to the \u201csci/tech\u201d topic. Do you agree? Please give your answer as either yes or no. Text: \u201cTitle: Wall St. Bears Claw Back Into the Black (Reuters) Description: Reuters Short-sellers, Wall Street\u2019s dwindling band of ultra-cynics, are seeing green again.\u201d\nB.2 TREC\nInstruction. Please label the type of the following question as \u201cabbreviation\u201d, \u201centity\u201d, \u201cdescription and abstract concept\u201d, \u201chuman being\u201d, \u201clocation\u201d, or \u201cnumeric value\u201d. Text: \u201cWhat makes a clitoris sensitive?\u201d\nSequence Swapping. Text: \u201cWhat makes a clitoris sensitive?\u201d Please label the type of the following question as \u201cabbreviation\u201d, \u201centity\u201d, \u201cdescription and abstract concept\u201d, \u201chuman being\u201d, \u201clocation\u201d, or \u201cnumeric value\u201d.\nParaphrasing. Given the following question, please classify the type of the following question as \u201cabbreviation\u201d, \u201centity\u201d, \u201cdescription and abstract concept\u201d, \u201chuman being\u201d, \u201clocation\u201d, or \u201cnumeric value\u201d. Text: \u201cWhat makes a clitoris sensitive?\u201d\nTrue/False 1. Based on the language used, is it true that the following question belongs to the class of abbreviation? Please give your answer as either \u201ctrue\u201d or \u201cfalse\u201d. Text: \u201cWhat makes a clitoris sensitive?\u201d\nTrue/False 2. Based on the language used, is it true that the following question belongs to the class of entity? Please give your answer as either \u201ctrue\u201d or \u201cfalse\u201d. Text: \u201cWhat makes a clitoris sensitive?\u201d\nTrue/False 3. Based on the language used, is it true that the following question belongs to the class of description and abstract concept? Please give your answer as either \u201ctrue\u201d or \u201cfalse\u201d. Text: \u201cWhat makes a clitoris sensitive?\u201d\nTrue/False 4. Based on the language used, is it true that the following question belongs to the class of human being? Please give your answer as either \u201ctrue\u201d or \u201cfalse\u201d. Text: \u201cWhat makes a clitoris sensitive?\u201d\nTrue/False 5. Based on the language used, is it true that the following question belongs to the class of location? Please give your answer as either \u201ctrue\u201d or \u201cfalse\u201d. Text: \u201cWhat makes a clitoris sensitive?\u201d\nTrue/False 6. Based on the language used, is it true that the following question belongs to the class of numeric value? Please give your answer as either \u201ctrue\u201d or \u201cfalse\u201d. Text: \u201cWhat makes a clitoris sensitive?\u201d\nQuestion Answering. Which class does the following question belong to? Is it \u201cabbreviation\u201d, \u201centity\u201d, \u201cdescription and abstract concept\u201d, \u201chuman being\u201d, \u201clocation\u201d, or \u201cnumeric value\u201d? Text: \u201cWhat makes a clitoris sensitive?\u201d\nMultiple Choice Question. Please choose one option that best describes the class of the following question. Text: \u201cWhat makes a clitoris sensitive?\u201d Options: (A)Abbreviation (B)Entity (C)Description and abstract concept (D)Human being (E)Location (F)Numeric value\nConfirmation Bias 1. I think the following question belongs to the abbreviation topic. Do you agree? Please give your answer as either \u201cyes\u201d or \u201cno\u201d. Text: \u201cWhat makes a clitoris sensitive?\u201d\nConfirmation Bias 2. I think the following question belongs to the entity topic. Do you agree? Please give your answer as either \u201cyes\u201d or \u201cno\u201d. Text: \u201cWhat makes a clitoris sensitive?\u201d\nConfirmation Bias 3. I think the following question belongs to the description and abstract concept\ntopic. Do you agree? Please give your answer as either \u201cyes\u201d or \u201cno\u201d. Text: \u201cWhat makes a clitoris sensitive?\u201d\nConfirmation Bias 4. I think the following question belongs to the human being topic. Do you agree? Please give your answer as either \u201cyes\u201d or \u201cno\u201d. Text: \u201cWhat makes a clitoris sensitive?\u201d\nConfirmation Bias 5. I think the following question belongs to the location topic. Do you agree? Please give your answer as either \u201cyes\u201d or \u201cno\u201d. Text: \u201cWhat makes a clitoris sensitive?\u201d\nConfirmation Bias 6. I think the following question belongs to the numeric value topic. Do you agree? Please give your answer as either \u201cyes\u201d or \u201cno\u201d. Text: \u201cWhat makes a clitoris sensitive?\u201d\nB.3 MRPC\nInstruction. Please label if the following two sentences are paraphrases of each other. Please give your answer as \u201cparaphrase\u201d or \u201cnot paraphrase\u201d. Text: \u201cSentence1: \u201c They are trying to turn him into a martyr , \u201d said Vicki Saporta , president of the National Abortion Federation , which tracks abortion-related violence . Sentence2: \u201c We need to take these threats seriously , \u201d said Vicki Saporta , president of the National Abortion Federation .\u201d\nSequence Swapping. Text: \u201cSentence1: \u201c They are trying to turn him into a martyr , \u201d said Vicki Saporta , president of the National Abortion Federation , which tracks abortion-related violence . Sentence2: \u201c We need to take these threats seriously , \u201d said Vicki Saporta , president of the National Abortion Federation .\u201d Please label if the following two sentences are paraphrases of each other. Please give your answer as \u201cparaphrase\u201d or \u201cnot paraphrase\u201d.\nParaphrasing. Given the following two sentences, please classify the relationship of the following two sentences as \u201cparaphrase\u201d or \u201cnot paraphrase\u201d. Text: \u201cSentence1: \u201c They are trying to turn him into a martyr , \u201d said Vicki Saporta , president of the National Abortion Federation , which tracks abortion-related violence . Sentence2: \u201c We need to take these threats seriously\n, \u201d said Vicki Saporta , president of the National Abortion Federation .\u201d\nTrue/False 1. Is it true that the following two sentences are paraphrases of each other? Give your answer as \u201ctrue\u201d or \u201cfalse\u201d. Text: \u201cSentence1: \u201c They are trying to turn him into a martyr , \u201d said Vicki Saporta , president of the National Abortion Federation , which tracks abortion-related violence . Sentence2: \u201c We need to take these threats seriously , \u201d said Vicki Saporta , president of the National Abortion Federation .\u201d\nTrue/False 2. Is it true that the following two sentences are not paraphrases of each other? Give your answer as \u201ctrue\u201d or \u201cfalse\u201d. Text: \u201cSentence1: \u201c They are trying to turn him into a martyr , \u201d said Vicki Saporta , president of the National Abortion Federation , which tracks abortion-related violence . Sentence2: \u201c We need to take these threats seriously , \u201d said Vicki Saporta , president of the National Abortion Federation .\u201d\nQuestion Answering. What relationship do the following two sentences have? Is it \u201cparaphrase\u201d or \u201cnot paraphrase\u201d? Text: \u201cSentence1: \u201c They are trying to turn him into a martyr , \u201d said Vicki Saporta , president of the National Abortion Federation , which tracks abortion-related violence . Sentence2: \u201c We need to take these threats seriously , \u201d said Vicki Saporta , president of the National Abortion Federation .\u201d\nMultiple Choice Question. Please choose one option that best describes the relationship between the following two sentences. Text: \u201cSentence1: \u201c They are trying to turn him into a martyr , \u201d said Vicki Saporta , president of the National Abortion Federation , which tracks abortion-related violence . Sentence2: \u201c We need to take these threats seriously , \u201d said Vicki Saporta , president of the National Abortion Federation .\u201d Options: (A)Paraphrase (B)Not paraphrase\nConfirmation Bias 1. I think the following two sentences are paraphrases of each other. Do you agree? Please give your answer in \u201cyes\u201d or \u201cno\u201d. Text: \u201cSentence1: \u201c They are trying to turn him\ninto a martyr , \u201d said Vicki Saporta , president of the National Abortion Federation , which tracks abortion-related violence . Sentence2: \u201c We need to take these threats seriously , \u201d said Vicki Saporta , president of the National Abortion Federation .\u201d\nConfirmation Bias 2. I think the following two sentences are not paraphrases of each other. Do you agree? Please give your answer in \u201cyes\u201d or \u201cno\u201d. Text: \u201cSentence1: \u201c They are trying to turn him into a martyr , \u201d said Vicki Saporta , president of the National Abortion Federation , which tracks abortion-related violence . Sentence2: \u201c We need to take these threats seriously , \u201d said Vicki Saporta , president of the National Abortion Federation .\u201d\nB.4 TempoWiC\nInstruction. Please label the meaning of the word frisk in the following 2 sentences as the same or different. Sentence 1: imagine seeing qoute from cave story making it into smash as a dlc character instead of frisk or sans lmao Sentence 2: Bloomberg? Are you people for real?16 cases of sexual harrassment, stop and frisk, redlining mortgages, and he is a conservative. If the dems think the only way you can beat trump is with a republican, then you deserve trump, and you show just how weak the dems are. #NotMeUs\nSequence Swapping. Sentence 1: imagine seeing qoute from cave story making it into smash as a dlc character instead of frisk or sans lmao Sentence 2: Bloomberg? Are you people for real?16 cases of sexual harrassment, stop and frisk, redlining mortgages, and he is a conservative. If the dems think the only way you can beat trump is with a republican, then you deserve trump, and you show just how weak the dems are. #NotMeUs Please label the meaning of the word frisk in the following 2 sentences as the same or different.\nParaphrasing. Given the following text, please classify if the meaning of the word frisk in the following 2 sentences is the same or different. Sentence 1: imagine seeing qoute from cave story making it into smash as a dlc character instead of frisk or sans lmao Sentence 2: Bloomberg? Are you people for real?16 cases of sexual harrassment, stop and frisk,\nredlining mortgages, and he is a conservative. If the dems think the only way you can beat trump is with a republican, then you deserve trump, and you show just how weak the dems are. #NotMeUs\nTrue/False 1. Is it true that the meaning of the word frisk in the following 2 sentences is the same? Please give your answer in yes or no. Sentence 1: imagine seeing qoute from cave story making it into smash as a dlc character instead of frisk or sans lmao Sentence 2: Bloomberg? Are you people for real?16 cases of sexual harrassment, stop and frisk, redlining mortgages, and he is a conservative. If the dems think the only way you can beat trump is with a republican, then you deserve trump, and you show just how weak the dems are. #NotMeUs\nTrue/False 2. Is it true that the meaning of the word frisk in the following 2 sentences is different? Please give your answer as yes or no. Sentence 1: imagine seeing qoute from cave story making it into smash as a dlc character instead of frisk or sans lmao Sentence 2: Bloomberg? Are you people for real?16 cases of sexual harrassment, stop and frisk, redlining mortgages, and he is a conservative. If the dems think the only way you can beat trump is with a republican, then you deserve trump, and you show just how weak the dems are. #NotMeUs\nQuestion Answering. Considering the meaning of the word frisk in the following 2 sentences, is it the same or different? Please give your answer in \u201csame\u201d or \u201cdifferent\u201d. Sentence 1: imagine seeing qoute from cave story making it into smash as a dlc character instead of frisk or sans lmao Sentence 2: Bloomberg? Are you people for real?16 cases of sexual harrassment, stop and frisk, redlining mortgages, and he is a conservative. If the dems think the only way you can beat trump is with a republican, then you deserve trump, and you show just how weak the dems are. #NotMeUs\nMultiple Choice Question. Please choose one option that best describes the meaning of the word frisk in the following 2 sentences: Sentence 1: imagine seeing qoute from cave story making it into smash as a dlc character instead of frisk or sans lmao Sentence 2: Bloomberg? Are you people for real?16 cases of sexual harrassment, stop and frisk, redlining mortgages, and he is a conservative. If\nthe dems think the only way you can beat trump is with a republican, then you deserve trump, and you show just how weak the dems are. #NotMeUs (A) Same (B) Different\nConfirmation Bias 1. I think the meaning of the word frisk in the following 2 sentences is the same, do you agree? Sentence 1: imagine seeing qoute from cave story making it into smash as a dlc character instead of frisk or sans lmao Sentence 2: Bloomberg? Are you people for real?16 cases of sexual harrassment, stop and frisk, redlining mortgages, and he is a conservative. If the dems think the only way you can beat trump is with a republican, then you deserve trump, and you show just how weak the dems are. #NotMeUs\nConfirmation Bias 2. I think the meaning of the word frisk in the following 2 sentences is different, do you agree? Sentence 1: imagine seeing qoute from cave story making it into smash as a dlc character instead of frisk or sans lmao Sentence 2: Bloomberg? Are you people for real?16 cases of sexual harrassment, stop and frisk, redlining mortgages, and he is a conservative. If the dems think the only way you can beat trump is with a republican, then you deserve trump, and you show just how weak the dems are. #NotMeUs\nB.5 Stance Detection\nInstruction. Please label the stance towards abortion of the following text as \u201cfavourable\u201d, \u201cneutral\u201d or \u201cnegative\u201d. Text: \u201cwe remind ourselves that love means to be willing to give until it hurts - Mother Teresa\u201d\nSequence Swapping. Text: \u201cwe remind ourselves that love means to be willing to give until it hurts - Mother Teresa\u201d Please label the stance towards abortion of the following text as \u201cfavourable\u201d, \u201cneutral\u201d or \u201cnegative\u201d.\nParaphrasing. Given the following text, please classify the position towards abortion demonstrated in the following text as \u201cfavourable\u201d, \u201cneutral\u201d or \u201cnegative\u201d. Text: \u201cwe remind ourselves that love means to be willing to give until it hurts - Mother Teresa\u201d\nTrue/False 1. Based on the language used, determine whether the following text holds a favourable stance towards abortion. Please give your answer as either \u201ctrue\u201d or \u201cfalse\u201d. Text: \u201cwe remind ourselves that love means to be willing to give until it hurts - Mother Teresa\u201d\nTrue/False 2. Based on the language used, determine whether the following text holds a neutral stance towards abortion. Please give your answer as either \u201ctrue\u201d or \u201cfalse\u201d. Text: \u201cwe remind ourselves that love means to be willing to give until it hurts - Mother Teresa\u201d\nTrue/False 3. Based on the language used, determine whether the following text holds a negative stance towards abortion. Please give your answer as either \u201ctrue\u201d or \u201cfalse\u201d. Text: \u201cwe remind ourselves that love means to be willing to give until it hurts - Mother Teresa\u201d\nQuestion Answering. What type of stance towards abortion is expressed in the following text? Is it favourable, neutral or negative? Text: \u201cwe remind ourselves that love means to be willing to give until it hurts - Mother Teresa\u201d\nMultiple Choice Question. Please choose one option that best describes the stance towards abortion of the text. Text: \u201cwe remind ourselves that love means to be willing to give until it hurts - Mother Teresa\u201d Options: (A) Favourable (B)Neutral (C)Negative\nConfirmation Bias 1. I think the following text has a favourable stance towards abortion. Do you agree? Please give your answer as either \u201cyes\u201d or \u201cno\u201d. Text: \u201cwe remind ourselves that love means to be willing to give until it hurts - Mother Teresa\u201d\nConfirmation Bias 2. I think the following text has a neutral stance towards abortion. Do you agree? Please give your answer as either \u201cyes\u201d or \u201cno\u201d. Text: \u201cwe remind ourselves that love means to be willing to give until it hurts - Mother Teresa\u201d\nConfirmation Bias 3. I think the following text has a negative stance towards abortion. Do you agree? Please give your answer as either \u201cyes\u201d or \u201cno\u201d.\nText: \u201cwe remind ourselves that love means to be willing to give until it hurts - Mother Teresa\u201d\nB.6 Conversation Gone Awry\nInstruction. Please label if the conversation below will eventually derail into a personal attack. Even if you are uncertain, you must pick either \u201cTrue\u201d or \u201cFalse\u201d without using any other words. Can.u.spel: im sorry to have been mistaken but whoever wrote that article made a miscalculation when determining the speed from knots to kph, 1 knot is 1.85 of a mile. therefore 10 knots is 18.5 miles per hour. am i not correct? Greswik: You don\u2019t seem to know the difference between mph and kph. 25 knots is 46 km/h, as the article read already.\nSequence Swapping. Can.u.spel: im sorry to have been mistaken but whoever wrote that article made a miscalculation when determining the speed from knots to kph, 1 knot is 1.85 of a mile. therefore 10 knots is 18.5 miles per hour. am i not correct? Greswik: You don\u2019t seem to know the difference between mph and kph. 25 knots is 46 km/h, as the article read already. Please label if the conversation above will eventually derail into a personal attack. Even if you are uncertain, you must pick either \u201cTrue\u201d or \u201cFalse\u201d without using any other words.\nParaphrasing Given the following conversation, please classify if the conversation below will eventually derail into hate speech. Even if you are uncertain, you must pick either \u201cTrue\u201d or \u201cFalse\u201d without using any other words. Can.u.spel: im sorry to have been mistaken but whoever wrote that article made a miscalculation when determining the speed from knots to kph, 1 knot is 1.85 of a mile. therefore 10 knots is 18.5 miles per hour. am i not correct? Greswik: You don\u2019t seem to know the difference between mph and kph. 25 knots is 46 km/h, as the article read already.\nTrue/False 1. Is it true that the conversation below will eventually derail into a personal attack? Even if you are uncertain, you must pick either \u201cTrue\u201d or \u201cFalse\u201d without using any other words. Can.u.spel: im sorry to have been mistaken but whoever wrote that article made a miscalculation when determining the speed from knots to kph, 1 knot is 1.85 of a mile. therefore 10 knots is 18.5\nmiles per hour. am i not correct? Greswik: You don\u2019t seem to know the difference between mph and kph. 25 knots is 46 km/h, as the article read already.\nTrue/False 2. Is it true that the conversation below will not eventually derail into a personal attack? Even if you are uncertain, you must pick either \u201cTrue\u201d or \u201cFalse\u201d without using any other words. Can.u.spel: im sorry to have been mistaken but whoever wrote that article made a miscalculation when determining the speed from knots to kph, 1 knot is 1.85 of a mile. therefore 10 knots is 18.5 miles per hour. am i not correct? Greswik: You don\u2019t seem to know the difference between mph and kph. 25 knots is 46 km/h, as the article read already.\nQuestion Answering. Considering the conversation below, will it eventually derail into a personal attack? Even if you are uncertain, you must pick either \u201cTrue\u201d or \u201cFalse\u201d without using any other words. Can.u.spel: im sorry to have been mistaken but whoever wrote that article made a miscalculation when determining the speed from knots to kph, 1 knot is 1.85 of a mile. therefore 10 knots is 18.5 miles per hour. am i not correct? Greswik: You don\u2019t seem to know the difference between mph and kph. 25 knots is 46 km/h, as the article read already.\nMultiple Choice Question. Please choose one option that best describes the possible continuation of the following conversation. Can.u.spel: im sorry to have been mistaken but whoever wrote that article made a miscalculation when determining the speed from knots to kph, 1 knot is 1.85 of a mile. therefore 10 knots is 18.5 miles per hour. am i not correct? Greswik: You don\u2019t seem to know the difference between mph and kph. 25 knots is 46 km/h, as the article read already. (A) it will eventually derail into a personal attack (B) it will not eventually derail into a personal attack\nConfirmation Bias 1. I think the conversation below will eventually derail into a personal attack, do you agree? Please give your answer in yes or no. Can.u.spel: im sorry to have been mistaken but whoever wrote that article made a miscalculation\nwhen determining the speed from knots to kph, 1 knot is 1.85 of a mile. therefore 10 knots is 18.5 miles per hour. am i not correct? Greswik: You don\u2019t seem to know the difference between mph and kph. 25 knots is 46 km/h, as the article read already.\nConfirmation Bias 2. I think the conversation below will not eventually derail into a personal attack, do you agree? Please give your answer in yes or no. Can.u.spel: im sorry to have been mistaken but whoever wrote that article made a miscalculation when determining the speed from knots to kph, 1 knot is 1.85 of a mile. therefore 10 knots is 18.5 miles per hour. am i not correct? Greswik: You don\u2019t seem to know the difference between mph and kph. 25 knots is 46 km/h, as the article read already."
        }
    ],
    "title": "CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation",
    "year": 2023
}