{
    "abstractText": "Although In-Context Learning has proven effective across a broad array of tasks, its efficiency is noticeably influenced by the selection of demonstrations. Existing methods tend to select different demonstrations for each test instance, which is time-consuming and poses limitations in practical scenarios. Therefore, this study aims to address the challenge of selecting a representative subset of in-context demonstrations that can effectively prompt different test instances in a specific task. We propose that this representative subset should be of high quality and diversity. Our empirical analyses confirm that demonstrations that meet these criteria can indeed bolster model performance. To satisfy these criteria, this paper further introduces a two-stage Determinantal Point Process (DPP) method designed to incorporate both quality and diversity in the process of demonstration selection, thereby obtaining representative in-context demonstrations. Through comprehensive experimentation, we have confirmed the efficacy of our proposed method, paving the way for more practical and effective In-Context Learning.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zhao Yang"
        },
        {
            "affiliations": [],
            "name": "Yuanzhe Zhang"
        },
        {
            "affiliations": [],
            "name": "Dianbo Sui"
        },
        {
            "affiliations": [],
            "name": "Cao Liu"
        },
        {
            "affiliations": [],
            "name": "Jun Zhao"
        },
        {
            "affiliations": [],
            "name": "Kang Liu"
        }
    ],
    "id": "SP:fe2aeb6e21bb9010ce6448c15f09a68120be29c8",
    "references": [
        {
            "authors": [
                "Samaneh Azadi",
                "Jiashi Feng",
                "Trevor Darrell."
            ],
            "title": "Learning detection with diverse proposals",
            "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7149\u20137157.",
            "year": 2017
        },
        {
            "authors": [
                "Sidney Black",
                "Stella Biderman",
                "Eric Hallahan",
                "Quentin Anthony",
                "Leo Gao",
                "Laurence Golding",
                "Horace He",
                "Connor Leahy",
                "Kyle McDonell",
                "Jason Phang"
            ],
            "title": "Gpt-neox-20b: An open-source autoregressive language model",
            "venue": "BigScience",
            "year": 2022
        },
        {
            "authors": [
                "Rishi Bommasani",
                "Drew A Hudson",
                "Ehsan Adeli",
                "Russ Altman",
                "Simran Arora",
                "Sydney von Arx",
                "Michael S Bernstein",
                "Jeannette Bohg",
                "Antoine Bosselut",
                "Emma Brunskill"
            ],
            "title": "On the opportunities and risks of foundation models",
            "year": 2021
        },
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are few-shot learners. Advances in neural information processing",
            "year": 2020
        },
        {
            "authors": [
                "He He"
            ],
            "title": "On the relation between sensitivity",
            "year": 2022
        },
        {
            "authors": [
                "Fei Liu"
            ],
            "title": "Improving the similarity measure",
            "year": 2019
        },
        {
            "authors": [
                "Zhifang Sui"
            ],
            "title": "A survey for in-context learning",
            "year": 2022
        },
        {
            "authors": [
                "John A Hartigan",
                "Manchek A Wong."
            ],
            "title": "Algorithm as 136: A k-means clustering algorithm",
            "venue": "Journal of the royal statistical society. series c (applied statistics), 28(1):100\u2013108.",
            "year": 1979
        },
        {
            "authors": [
                "Pang Wei Koh",
                "Percy Liang."
            ],
            "title": "Understanding black-box predictions via influence functions",
            "venue": "International conference on machine learning, pages 1885\u20131894. PMLR.",
            "year": 2017
        },
        {
            "authors": [
                "Alex Kulesza",
                "Ben Taskar."
            ],
            "title": "k-dpps: Fixed-size determinantal point processes",
            "venue": "Proceedings of the 28th International Conference on Machine Learning (ICML-11), pages 1193\u20131200.",
            "year": 2011
        },
        {
            "authors": [
                "Alex Kulesza",
                "Ben Taskar"
            ],
            "title": "Determinantal point processes for machine learning",
            "venue": "Foundations and Trends\u00ae in Machine Learning,",
            "year": 2012
        },
        {
            "authors": [
                "Itay Levy",
                "Ben Bogin",
                "Jonathan Berant."
            ],
            "title": "Diverse demonstrations improve in-context compositional generalization",
            "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1401\u2013",
            "year": 2023
        },
        {
            "authors": [
                "Xiaonan Li",
                "Kai Lv",
                "Hang Yan",
                "Tianyang Lin",
                "Wei Zhu",
                "Yuan Ni",
                "Guotong Xie",
                "Xiaoling Wang",
                "Xipeng Qiu."
            ],
            "title": "Unified demonstration retriever for incontext learning",
            "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Lin-",
            "year": 2023
        },
        {
            "authors": [
                "Jiachang Liu",
                "Dinghan Shen",
                "Yizhe Zhang",
                "William B Dolan",
                "Lawrence Carin",
                "Weizhu Chen"
            ],
            "title": "What makes good in-context examples for gpt-3? In Proceedings of Deep Learning Inside Out (DeeLIO 2022)",
            "venue": "The 3rd Workshop on Knowledge Extrac-",
            "year": 2022
        },
        {
            "authors": [
                "Tie-Yan Liu"
            ],
            "title": "Learning to rank for information retrieval",
            "venue": "Foundations and Trends\u00ae in Information Retrieval, 3(3):225\u2013331.",
            "year": 2009
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Yao Lu",
                "Max Bartolo",
                "Alastair Moore",
                "Sebastian Riedel",
                "Pontus Stenetorp."
            ],
            "title": "Fantastically ordered prompts and where to find them: Overcoming fewshot prompt order sensitivity",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Compu-",
            "year": 2022
        },
        {
            "authors": [
                "Katerina Margatina",
                "Giorgos Vernikos",
                "Lo\u00efc Barrault",
                "Nikolaos Aletras."
            ],
            "title": "Active learning by acquiring contrastive examples",
            "venue": "Proceedings of the",
            "year": 2021
        },
        {
            "authors": [
                "Sewon Min",
                "Xinxi Lyu",
                "Ari Holtzman",
                "Mikel Artetxe",
                "Mike Lewis",
                "Hannaneh Hajishirzi",
                "Luke Zettlemoyer"
            ],
            "title": "Rethinking the role of demonstrations: What makes in-context learning work",
            "venue": "In Proceedings of the 2022 Conference on Empirical Methods",
            "year": 2022
        },
        {
            "authors": [
                "Garima Pruthi",
                "Frederick Liu",
                "Satyen Kale",
                "Mukund Sundararajan."
            ],
            "title": "Estimating training data influence by tracing gradient descent",
            "venue": "Advances in Neural Information Processing Systems, 33:19920\u201319930.",
            "year": 2020
        },
        {
            "authors": [
                "Alec Radford",
                "Jeffrey Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "venue": "OpenAI blog,",
            "year": 2019
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych."
            ],
            "title": "Sentence-bert: Sentence embeddings using siamese bert-networks",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language",
            "year": 2019
        },
        {
            "authors": [
                "Ohad Rubin",
                "Jonathan Herzig",
                "Jonathan Berant."
            ],
            "title": "Learning to retrieve prompts for in-context learning",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
            "year": 2022
        },
        {
            "authors": [
                "Tianze Shi",
                "Adrian Benton",
                "Igor Malioutov",
                "Ozan \u0130rsoy."
            ],
            "title": "Diversity-aware batch active learning for dependency parsing",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human",
            "year": 2021
        },
        {
            "authors": [
                "Richard Socher",
                "Alex Perelygin",
                "Jean Wu",
                "Jason Chuang",
                "Christopher D Manning",
                "Andrew Y Ng",
                "Christopher Potts."
            ],
            "title": "Recursive deep models for semantic compositionality over a sentiment treebank",
            "venue": "Proceedings of the 2013 conference on empiri-",
            "year": 2013
        },
        {
            "authors": [
                "Taylor Sorensen",
                "Joshua Robinson",
                "Christopher Rytting",
                "Alexander Shaw",
                "Kyle Rogers",
                "Alexia Delorey",
                "Mahmoud Khalil",
                "Nancy Fulda",
                "David Wingate."
            ],
            "title": "An information-theoretic approach to prompt engineering without ground truth labels",
            "venue": "Proceedings",
            "year": 2022
        },
        {
            "authors": [
                "Ellen M Voorhees",
                "Dawn M Tice."
            ],
            "title": "Building a question answering test collection",
            "venue": "Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 200\u2013207.",
            "year": 2000
        },
        {
            "authors": [
                "Ben Wang."
            ],
            "title": "Mesh-Transformer-JAX: ModelParallel Implementation of Transformer Language Model with JAX",
            "venue": "https://github.com/ kingoflolz/mesh-transformer-jax.",
            "year": 2021
        },
        {
            "authors": [
                "Shuohang Wang",
                "Yichong Xu",
                "Yuwei Fang",
                "Yang Liu",
                "Siqi Sun",
                "Ruochen Xu",
                "Chenguang Zhu",
                "Michael Zeng."
            ],
            "title": "Training data is more valuable than you think: A simple and effective method by retrieving from training data",
            "venue": "Proceedings of the 60th An-",
            "year": 2022
        },
        {
            "authors": [
                "Jason Wei",
                "Xuezhi Wang",
                "Dale Schuurmans",
                "Maarten Bosma",
                "brian ichter",
                "Fei Xia",
                "Ed Chi",
                "Quoc V Le",
                "Denny Zhou"
            ],
            "title": "Chain-of-thought prompting elicits reasoning in large language models",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Chenghao Yang",
                "Fan Yin",
                "He He",
                "Kai-Wei Chang",
                "Xiaofei Ma",
                "Bing Xiang."
            ],
            "title": "Efficient shapley values estimation by amortization for text classification",
            "venue": "arXiv preprint arXiv:2305.19998.",
            "year": 2023
        },
        {
            "authors": [
                "Jiacheng Ye",
                "Zhiyong Wu",
                "Jiangtao Feng",
                "Tao Yu",
                "Lingpeng Kong."
            ],
            "title": "Compositional exemplars for in-context learning",
            "venue": "arXiv preprint arXiv:2302.05698.",
            "year": 2023
        },
        {
            "authors": [
                "Kang Min Yoo",
                "Junyeob Kim",
                "Hyuhng Joon Kim",
                "Hyunsoo Cho",
                "Hwiyeol Jo",
                "Sang-Woo Lee",
                "Sang-goo Lee",
                "Taeuk Kim."
            ],
            "title": "Ground-truth labels matter: A deeper look into input-label demonstrations",
            "venue": "Proceedings of the 2022 Conference on Empirical Meth-",
            "year": 2022
        },
        {
            "authors": [
                "Xiang Zhang",
                "Junbo Zhao",
                "Yann LeCun."
            ],
            "title": "Character-level convolutional networks for text classification",
            "venue": "Advances in neural information processing systems, 28.",
            "year": 2015
        },
        {
            "authors": [
                "Yiming Zhang",
                "Shi Feng",
                "Chenhao Tan."
            ],
            "title": "Active example selection for in-context learning",
            "venue": "arXiv preprint arXiv:2211.04486.",
            "year": 2022
        },
        {
            "authors": [
                "Zhuosheng Zhang",
                "Aston Zhang",
                "Mu Li",
                "Alex Smola."
            ],
            "title": "Automatic chain of thought prompting in large language models",
            "venue": "arXiv preprint arXiv:2210.03493.",
            "year": 2022
        },
        {
            "authors": [
                "Zihao Zhao",
                "Eric Wallace",
                "Shi Feng",
                "Dan Klein",
                "Sameer Singh."
            ],
            "title": "Calibrate before use: Improving few-shot performance of language models",
            "venue": "International Conference on Machine Learning, pages 12697\u201312706. PMLR.",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "The emergence of Large Language Models (LLMs) has swept various Natural Language Processing (NLP) tasks and brought new research paradigms (Bommasani et al., 2021; Wei et al., 2022; OpenAI, 2023). In-Context Learning (ICL) (Brown et al., 2020) is the primary paradigm for leveraging LLMs, which enables the model to generalize rapidly from a few examples without parameter update. Recent studies have shown that ICL has significantly improved over the zero/few-shot setting and even surpassed the performance of full data fine-tuning (Dong et al., 2022).\nHowever, ICL is insufficiently stable and robust in performance when compared to traditional finetuning, and exhibits sensitivity to numerous factors, including demonstration selection (Liu et al.,\n2022; Rubin et al., 2022), demonstration formats (Min et al., 2022), demonstration labels (Zhao et al., 2021; Yoo et al., 2022), and demonstration order (Lu et al., 2022). Among these factors, demonstration selection is the most significant, as they provide only information about the task (Liu et al., 2022). Therefore, selecting suitable demonstrations is necessary.\nExisting demonstration selection methods usually adopt retrieval-based solutions, which aim to select different demonstrations for each test instance (Liu et al., 2022; Sorensen et al., 2022; Rubin et al., 2022; Zhang et al., 2022a). However, these retrieval-based methods can be costly in practice. In detail, these methods can only perform inference on one sample at a time, which incurs high costs in terms of token usage, particularly when considering leveraging batch prompting (Cheng et al., 2023). Besides, performing demonstration selection for each testing example is obviously time-costing (\u00a74.3). Based on this, as shown in Figure 1, this paper aims to select a representative demonstration subset from a pool of training examples for all test instances in a specific task rather than each test instance.\nTo select a representative demonstration subset for a task, we argue that there are two criteria that should be satisfied: quality and diversity. Firstly, in ICL, the quality of an instance is defined as the\ndegree that it can help the LLM to make correct predictions. Intuitively, high-quality instances can improve the LLM\u2019s performance on as many test examples as possible. Secondly, diversity means that the elements in the selected demonstration subset should be mutually dissimilar and represent the training set as comprehensively as possible. Moreover, in this paper, we argue that diversity can be refined into semantic diversity and influence diversity. Semantic diversity means that the selected examples should be diverse enough to cover more semantics or expressions in the given training set, which is consistent with existing representative subset selection in traditional deep learning (Coleman et al., 2020; Guo et al., 2022). Influence diversity means that each selected example should help the model correctly classify a diverse set of testing samples, enabling the total demonstration set to support the correct classification of more test instances for the given LLM. Pilot experiments (\u00a72) also verify that the demonstration subsets satisfying these criteria could improve ICL performance.\nIn this paper, we make the following efforts to meet the above criteria. To achieve the quality criterion, we resort to recent instance-based explanation methods (Koh and Liang, 2017; Pruthi et al., 2020). Different from them, this paper extends existing instance-based explanation methods to ICL and defines the influence score to measure the contribution of a training example to the correct classification of another example. To achieve the diversity criterion, this paper seeks the help of the determinantal point process (DPP), which is a probabilistic model that could maintain high diversity among different instances by pairwise repulsion between instances (Kulesza et al., 2012).\nMoreover, to incorporate both high quality and diversity for demonstration selection, this paper further proposes a two-stage DPP selection method. In specific, in the first stage (\u00a73.2.1), we utilize the semantic information measure instance similarity and then leverage DPP to obtain a subset of instances with high semantic diversity. In the second stage (\u00a73.2.2), we first compute the quality score of each instance in this subset based on our defined influence scores (\u00a72.2), which could reduce a significant amount of meaningless inference time compared to computing the quality for each training example. Then we utilize the obtained influence scores to measure influence similarity between instances and construct another DPP. Besides, we also introduce\nthe quality scores (\u00a72.2) of these examples to this DPP. As a result, both quality and influence diversity could be optimally introduced in the selection process. This two-stage DPP selection method enables the selected demonstration subset could not only cover more semantics in the training set but also help the given LLM classify more examples with better performance.\nOur contributions can be summarized as follows:\n\u2022 This paper aims to select representative incontext demonstrations and propose two criteria (quality and diversity) that such demonstrations should satisfy.\n\u2022 To satisfy the proposed criteria, this paper proposes a two-stage DPP selection method. According to our method, the selected demonstrations could not only be representative of the large training set but also facilitate the model\u2019s generalization to new instances.\n\u2022 Extensive experimental results demonstrate the effectiveness of our proposed method. And we also show the significant advantage in inference time and token usage compared to retrieval-based methods."
        },
        {
            "heading": "2 Pilot Experiments",
            "text": "This section explores whether the proposed criteria could improve the performance of ICL. In specific, we measure the impact of three factors: semantic diversity, instance quality, and influence diversity. We choose SST-2 (Socher et al., 2013) as the test dataset and conduct 4-shot experiments on GPT2xl (1.5B) (Radford et al., 2019), GPT-J (6B) (Wang, 2021) and GPT-NeoX (20B) (Black et al., 2022)."
        },
        {
            "heading": "2.1 Impact of Semantic Diversity",
            "text": "To explore the impact of semantic diversity, we firstly utilize sentence-BERT (Reimers and Gurevych, 2019) to encode all train instances. Then, with these sentence representations, we use K-means (Hartigan and Wong, 1979) to partition all train instances into 4 clusters. Finally, we design three strategies with different semantic diversity: 1) single-cluster: we sample 4 examples from each cluster. 2) random: random sampling 4 examples from the whole training set. 3) multi-cluster: we sample one example from each of these 4 clusters. Obviously, multi-cluster has the best semantic diversity and single-cluster has the worst diversity.\nFigure 2(a) presents the corresponding results of the five sample strategies. From the figure, we observe that multi-cluster is always superior to the other two strategies across these three LLMs. According to these results, we could find that better semantic diversity could lead to higher accuracy across models of different scales."
        },
        {
            "heading": "2.2 Impact of Instance Quality",
            "text": "To measure the quality of an instance, we need to define the influence score of an instance at first. Existing example-based explanation methods (Koh and Liang, 2017; Pruthi et al., 2020) define the influence of an example in a training set as the prediction difference of the test set between the model trained with and without this example. Inspired by this, we define the influence of the demonstration e on another example ei = (xi, yi) in ICL as follows:\nInf(e, ei) = pLM(yi|e, xi)\u2212 pLM(yi|xi) (1)\nwhere yi is the golden label of example xi. pLM(yi|e, xi) and pLM(yi|xi) refers to the output probability of yi conditioned on (e, x) and x for a given language model LM, respectively.\nInf(e, ei) could measure the contribution of e to the correctness of the example ei. Based on this, we define the quality metric of the demonstration e as follows:\nQ(e) =\n\u2211 ei\u2208Dscore Inf(e, ei)\nT (2)\nwhere Dscore denotes the score set used for measuring quality and T refers to its size. Q(e) characterizes the contribution of e to the model performance on the score set. The higher the value of this metric, the more e can help the language model in making correct predictions on this score set.\nTo improve efficiency, we randomly choose 100 examples and measure their quality by randomly sampling an additional 200 samples as the score set. Then we design three strategies with different quality: 1) high-quality: we choose the top 4 examples with the highest quality as demonstrations. 2) low-quality: we choose the bottom 4 examples with the lowest quality as demonstrations. 3) random: we randomly choose 4 examples from these 100 examples as demonstrations.\nFigure 2(b) shows the experimental results. From these results, we find that demonstrations with higher quality could get better performance."
        },
        {
            "heading": "2.3 Impact of Influence Diversity",
            "text": "With the same setting in \u00a72.2, we have obtained the influence scores on 200 score instances, which could be seen as a 200-dimension vector. Based on this, we can get the influence vector for each instance and then we utilize the similar cluster method in \u00a72.1 to partition the 100 examples into 4 clusters. We construct the following sampling strategies with different influence diversity: 1) similar-influence: we sample 4 examples from each cluster and average their performance. 2) diverse-influence: we sample one example from each cluster as demonstrations. 3) random randomly sample 4 examples as demonstrations.\nFigure 2(c) shows the corresponding results. According to these results, we observe that demonstrations with better influence diversity could improve ICL performance for LLMs of different scales."
        },
        {
            "heading": "2.4 The Conclusion on Pilot Experiments",
            "text": "Our three experiments show that semantic diversity, instance quality, and influence diversity all can improve ICL performance, which verifies the effectiveness of the proposed criteria. Therefore, our\nmethod would try to introduce these three factors in the selection process."
        },
        {
            "heading": "3 Method",
            "text": "In \u00a73.1, we illustrate the formulation of in-context learning and the background of the determinantal point process. Then, we introduce the implementation of our method in \u00a73.2, which could introduce the three factors in the whole selection process."
        },
        {
            "heading": "3.1 Preliminary",
            "text": ""
        },
        {
            "heading": "3.1.1 In-context Learning",
            "text": "In-context learning is the core emergent ability of LLMs and only requires a few examples and corresponding labels to solve a task. Formally, a demonstration ei = (xi, yi) consists of an instance xi and its label yi. For a new test instance xtest, Kshot in-context learning generate its label ypredict as follows:\nPLM(ypredict|e1, e2, \u00b7 \u00b7 \u00b7 , eK , xtest) (3)\nwhere ei is sampled from the whole train dataset and {e1, e2, \u00b7 \u00b7 \u00b7 , eK} is usually called context."
        },
        {
            "heading": "3.1.2 Determinantal Point Process",
            "text": "Determinantal Point Process (DPP) is an elegant probabilistic model with the ability to express negative interactions (Kulesza et al., 2012). DPP could help us find a representative subset while keeping high diversity among different items (Chen et al., 2018). Formally, for an index set A = {1, 2, \u00b7 \u00b7 \u00b7 ,M} and its corresponding item set IA = {a1, a2, \u00b7 \u00b7 \u00b7 , aM}, DPP provides a probability measurement for 2N item subsets. Given the feature representation ai for the item ai, DPP computes a positive semi-definite (PSD) matrix L \u2208 RM\u00d7M , where Lij = k(ai, aj) for an kernel function k(\u00b7, \u00b7) and Lij usually measures the correlation between ai and aj . Based on this, if a subset is determined by the index set Y \u2286 A, the probability of selecting Y could be defined as follows:\nP (Y ) = det(LY )\ndet(L + I ) (4)\nwhereLY refers to a submatrix of L and consists of Lij for i, j \u2208 Y . I is an identity matrix and det(\u00b7) is the determinant of a matrix.\nUnder this distribution, we could select the representative subset Ybest of size k as follows:\nYbest = argmax Y\u2286A,|Y |=k det(LY ) (5)\nObviously, the maximum a posteriori inference in DPP has high time complexity (Kulesza and Taskar, 2011). Following Chen et al. (2018), the time complexity of selecting a subset of size k is O(k2M).\nThe core of DPP is how to obtain the corresponding PSD matrix. Existing studies usually incorporate task-relevant information into this matrix, in order to utilize DPP to achieve diversity."
        },
        {
            "heading": "3.2 Two-Stage DPP Selection Method",
            "text": "In this section, we introduce a novel two-stage DPP selection method, which could introduce semantic diversity, high quality, and influence diversity in demonstration selection."
        },
        {
            "heading": "3.2.1 First Stage: Selecting Candidate Subset with Semantic Diversity",
            "text": "According to Equation 1, computing the influence score requires inference time. Thus, computing the influence score for each instance in the training set is infeasible for its high costs. Intuitively, we need to reduce the size of the set that requires calculating influence scores.\nBased on this, this paper selects a small subset from the original training set by introducing semantic diversity. Formally, the training set D = {e1, e2, \u00b7 \u00b7 \u00b7 , eN} contains N instances where ei = (xi, yi). We firstly utilize sentence-BERT (Reimers and Gurevych, 2019) to encode these instances and obtain their semantic representations {x1,x2, \u00b7 \u00b7 \u00b7 ,xN}. Then we could easily get the dataset representation s \u2208 RN\u00d7d by stack, where d is the dimension of each sentence. Finally, we could get the PSD matrix LS in DPP as follows:\nLS = ss T (6)\nObviously,LS \u2208 RN\u00d7N is a real symmetric matrix. With LS , we could obtain a candidate subset Dsem of size Nsem according to Equation 5."
        },
        {
            "heading": "3.2.2 Second Stage: Selecting Demonstrations via High Quality and Influence Diversity",
            "text": "In previous parts, we have introduced semantic diversity into Dsem. In the following parts, we would illustrate how to select high-quality instances while maintaining influence diversity to form the final demonstration set.\nFirstly, we need to select the score set to measure the quality of an instance in Dsem according to Equation 2. Recent probing studies (Min et al., 2022; Yoo et al., 2022) show the importance of the label for ICL. Therefore, we only require the\nAlgorithm 1 Two-Stage DPP Selection Input: Training set D = {ei}Ni=1, language model LM, can-\ndidate subset size Nsem, score set size T , demonstration set size k, sentence encoder sbert.\nOutput: Demonstration Subset Ddem 1: for ei \u2208 D do 2: xi = sbert(xi) 3: end for 4: s = stack(x1,x2, \u00b7 \u00b7 \u00b7 ,xN ) 5: LS = ssT\n6: Dsem = argmaxY \u2286D,|Y |=Nsem det(LY )\ndet(LS+I)\n7: random sampling Dscore of size T from D/Dsem 8: for ei \u2208 Dsem do 9: for ej \u2208 Dscore do\n10: Inf(ei, ej) = pLM(yj |ei, xj)\u2212 pLM(yj |xj) 11: end for 12: Q(ei) = \u2211 ej\u2208Dscore Inf(ei,ej) T 13: ei = (Inf(ei, e1), Inf(ei, e2), \u00b7 \u00b7 \u00b7 , Inf(ei, eT )) 14: end for 15: I = stack(e1, e2, \u00b7 \u00b7 \u00b7 , eNsem) 16: Q = (Qe1 ,Qe2 , \u00b7 \u00b7 \u00b7 ,QeNsem ) 17: LI =Q \u00b7 IIT \u00b7Q 18: Ddem = argmaxY \u2286Dsem,|Y |=k det(LY ) det(LI+I) 19: return Ddem\nexamples in the scoring set to include all of the labels. With this premise satisfied, we obtained the score set Dscore of size T through a random sample from D/Dsem. With the score set, we could easily compute the influence score and quality of each instance in Dsem according to Equation 1 and 2.\nFor item xj \u2208 Dsem, we could obtain T - dimension influence embedding Ij where each dimension denotes its influence on each instance in the score set and its quality score Q(ej). Then, we can obtain the total influence representation matrix I \u2208 RNsem\u00d7T and the quality representation of Q \u2208 RT by stacking and contacting operation. Thus we can compute another PSD matrix LI as follows:\nLI =Q \u00b7 IIT \u00b7Q (7)\nActually, IIT could construct a basic PSD matrix to help us introduce influence diversity. Inspired by Chen et al. (2018), we further introduce Q to help us select high-quality instances. In this way, DPP which is based onLI could help us select high-quality and diverse examples. Concretely, for k-shot ICL, we can select a demonstration subset Ddem of size k according to Equation 5.\nIn summary, Algorithm 1 presents the whole process of our two-stage DPP selection method. Figure 9 shows a more direct illustration of our method. Besides, a recent study (Lu et al., 2022) shows the ordering of demonstrations also has a significant influence on the performance. But in\nthis paper, we only focus on demonstration selection and just determine the order in ascending order of their quality scores in Dscore."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Experimental Setups",
            "text": ""
        },
        {
            "heading": "4.1.1 Datasets",
            "text": "Following previous studies (Zhao et al., 2021; Liu et al., 2022), we conduct experiments on six text classification tasks: SST-2 (Socher et al., 2013), TREC (Voorhees and Tice, 2000), CB (De Marneffe et al., 2019), AGNews (Zhang et al., 2015), DBPedia (Zhang et al., 2015) and RTE (Dagan et al., 2006). And we utilize accuracy as the evaluation metric. Statistics and the prompt format for each dataset could be found in Appendix A."
        },
        {
            "heading": "4.1.2 Large Language Models",
            "text": "This paper conducts experiments on three large language models of different scales: GPT2-xl (1.5B) (Radford et al., 2019), GPT-J (6B) (Wang, 2021) and GPT-NeoX (20B) (Black et al., 2022)."
        },
        {
            "heading": "4.1.3 Baselines",
            "text": "In this paper, we compare our method with the following baseline methods: Representative Subset Selection in Deep Learning: Least Confidence (LC) (Coleman et al., 2020) selects representative examples according to the max probability on all labels. Cal (Margatina et al., 2021) selects representative examples with the biggest logits divergence from neighbors. Recent Representative Demonstration Selection Methods: Random selects demonstrations by randomly sampling. Cluster (Zhang et al., 2022b; Gao et al., 2023) selects k demonstrations by choose k cluster centers of K-means cluster by semantic. DPP (Levy et al., 2023) utilize the semantic information select k demonstrations according to k-DPP (Kulesza and Taskar, 2011; Chen et al., 2018)."
        },
        {
            "heading": "4.2 Main Results",
            "text": "Table 1 presents the corresponding results. Traditional representative subset selection methods get poor performance in ICL settings. Least Confidence even gets a worse performance than random selection and Cal just gets a comparable performance with random selection. Our designed baselines Cluster and DPP, which both introduce semantic diversity, achieve some improvements compared to random selection. And DPP could\nachieve better performance compared to Cluster, which indicates that DPP is the better choice to introduce diversity. Compared to these baselines, our methods significantly improve the performances among all datasets in different settings across these three LLMs. In specific, compared to random, our methods bring more than 10% improvements across the three shots for GPT2-xl and GPT-J and 8% improvements across the three shots for GPTNeoX. Compared to DPP (only stage 1, \u00a73.2.1), which is the strongest baseline, our method also achieves an improvement ranging from 4% to 7% under different settings, which verifies the effectiveness of the second stage (\u00a73.2.2)."
        },
        {
            "heading": "4.3 Comparison with Retrieval Methods",
            "text": "Performance Comparison We compare our method to the retrieval-based methods BM25 (Wang et al., 2022) and KATE (Liu et al., 2022), which retrieve the demonstrations according to the BM25 scores (Liu et al., 2009) and the RoBERTa embed-\ndings (Liu et al., 2019). Figure 3 shows the average 8-shot performance of the six datasets. From these results, it is not surprising that these two methods could achieve better performance. This is because they both introduce information about the test set while our method does not.\nTo make a fair comparison, we also try to incorporate test set information into our method. Specifically, we used a retriever to find the most similar examples from the training set to construct the score set Dscore for our method. We name the variants using the BM25 retriever in BM25 and the Roberta retriever in Kate as Ours+BM25 and Ours+Emb, respectively. According to the results, these two variants achieve further performance improvements and the performance gaps with retrieval methods decrease as the model size increases. Benefits of Our Method Actually, it is inevitable that the performance of representative demonstrations is inferior to that of retrieval methods, as they provide different demonstrations for each test instance. However, providing the same demonstration subset (our method) can save a significant amount of resources in real-world scenarios (Cheng et al., 2023). In specific, if the demonstration subset is kept the same, they can be pre-encoded1, thus saving a significant amount of time spent on demonstration encoding when prediction. Figure 4 shows a comparison of the time spent on inferring 5000 instances on AGNews. With the support of pre-\n1This paradigm has been widely implemented in Huggingface and these pre-encoded sentences are called past_key_values in current available LLMs.\nencode, only about 1/3 of the inference time is required. In the API calling scenario, the cost is calculated based on tokens. Cheng et al. (2023) proposes batch prompting, which could generate responses for multiple examples in one batch using the same demonstration set. We calculate the token costs when testing Trec with text-davinci-002. Table 2 presents the comparisons. With batch prompting, ICL with the same demonstration subset shows a significant advantage in token usage, requiring only 1/10 of the token costs of the retrieval-based method for 8-shot learning.\nTherefore, we believe that representative demonstration selection is the more practical paradigm, which could save a significant amount of inference time and token costs."
        },
        {
            "heading": "4.4 Effect of Factors: Semantic Diversity, Instance Quality, and Influence Diversity",
            "text": "In this part, we explore the effect of the proposed three key factors in our selection method: semantic diversity, instance quality, and influence diversity.\nTable 3 presents the corresponding results and Appendix B shows the detail of each baseline. From these results, we find that instance quality is the most important factor, which contributes significantly to performance improvement. Semantic diversity also plays a significant role, which is consistent with the results of Cluster and DPP. And\nvariant SST-2 Trec AGNews\nrandom 54.86 26.11 42.07\nsem_div 57.58 32.20 66.82 ins_qua 61.93 37.08 68.11 inf_div 54.26 29.47 65.97 sem_div + ins_qua 63.86 39.92 69.88 sem_div + inf_div 59.29 34.87 68.08 ins_qua + inf_div 62.47 37.76 68.75\nsem_div + ins_qua + inf_div (ours) 65.52 42.83 72.51\nTable 3: Effect of the three factors: semantic diversity (sem_div), instance quality (ins_qua), and influence diversity (inf_div). We list the average performance among the three shots for GPT2-xl.\nRandom DPP Ours 0.35\n0.40\n0.45\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\nAc cu\nra cy\nSST-2\nRandom DPP Ours 0.10\n0.15\n0.20\n0.25\n0.30\n0.35\nTrec\nRandom DPP Ours\n0.38\n0.40\n0.43\n0.45\n0.48\n0.50\n0.53\n0.55 CB\nRandom DPP Ours\n0.30\n0.40\n0.50\n0.60\n0.70\nAGNews\nFigure 5: Order sensitivity on GPT2-xl. We conduct 4-shot experiments on SST2, Trec, CB, and AGNews and show the results of the total 24 orders.\nthe influence diversity would have a relatively positive effect when it appears with instance quality."
        },
        {
            "heading": "5 Discussions",
            "text": ""
        },
        {
            "heading": "5.1 Order Sensitivity of Representative In-Context Demonstrations",
            "text": "Lu et al. (2022) shows that ICL performance is highly sensitive to the demonstration order. Therefore, we also test whether the carefully selected representative demonstrations suffer from the order problem. In specific, we compare our method with random selection and the strongest baseline DPP.\nFigure 5 presents the corresponding results on GPT2-xl. From these results, we could observe that DPP could reduce the order sensitivity of ICL and our method further reduce the order sensitivity. According to this, we conjecture that the selected representative in-context demonstrations could effectively characterize the corresponding task, leading to a reduction in order sensitivity of ICL, which is also consistent Chen et al. (2022)."
        },
        {
            "heading": "5.2 Transferability of Representative In-Context Demonstrations across LLMs",
            "text": "In this section, we investigate the transferability of the selected representative demonstrations.\nIn specific, we utilize the demonstrations selected based on the original model to test its performance on the new model. We choose GPT2xl, GPT-J, and GPT-NeoX which were employed in previous experiments as the original models, and GPT2-large, GPT2-xl, GPT-J, GPT-NeoX, text-davinci-002, and text-davinci-003 as the new models, whose scale varies from 762M to 175B. Figure 6 shows the corresponding results.\nFrom these results, we observe that the selected representative demonstrations all achieve better performance compared to random selection, which verifies their transferability. Besides, we also find that the transferability will be better when the size of the original model and the new model is closer."
        },
        {
            "heading": "5.3 Assessing the Quality of the Selected In-Context Demonstrations",
            "text": "In this part, we explore the quality of the selected in-context demonstrations. Considering that it is not feasible to enumerate all possible combinations in a training dataset, we conduct simulations under the following conditions.\nSpecifically, we sample 10 instances from SST2, yielding C(10,4) = 210 possible combinations for 4-shot experiments. Then we test each of these 210 combinations on the test set and obtained the corresponding test accuracy for each combination. Finally, we examine the ranking of the combinations selected by our method among all possible combinations.\nAs shown in Figure 7, we show the cumulative distribution of the 210 combinations. And our method is signed with the red line. From the results, we can find that our method outperforms 90% combinations, which reveals the effectiveness of our method.\n5.4 Effect of Subet Size Dsem In Algorithm 1, we get a subset of size Dsem after the first stage DPP and select high-quality instances from this subset. However, it is inevitable to filter out some high-quality instances in the first stage. Therefore, we explore the effect of the subset size in this section. In our main experiments, we set |Dsem| = 200, and we show the performances of more value here and show the results of SST-2 on GPT2-xl in Figure 8.\nWe could observe that our method achieves better performance with the bigger subset size across different shots. This indicates bigger subset size\ncould introduce more high-quality instances in the candidate set. Based on this, the second stage could select better demonstrations. However, we could also observe that the performance improvements diminish significantly once the size exceeds 200. Considering that the bigger size would introduce much more inference costs when computing quality scores, this paper just selects 200 to conduct experiments for efficiency."
        },
        {
            "heading": "6 Related Work",
            "text": ""
        },
        {
            "heading": "6.1 In-Context Learning",
            "text": "Existing studies have shown ICL is sensitive to demonstration selection (Liu et al., 2022), demonstration formats (Dong et al., 2022), demonstration labels (Min et al., 2022; Yoo et al., 2022), and demonstration order (Lu et al., 2022). This paper focuses on the selection of demonstrations.\nExisting methods aim to find different demonstrations for each test instance by retrieval-based methods. These methods can be divided into two categories based on whether the retriever requires training (Dong et al., 2022). The training-free methods utilize the sentence representations (Liu et al., 2022), BM25 (Wang et al., 2022), mutual information (Sorensen et al., 2022), and perplexity (Gonen et al., 2022) to select demonstrations. As for methods that require training, Zhang et al. (2022a) utilized reinforcement learning to train a retriever. Rubin et al. (2022) trained an example scorer using contrastive learning with signals from LLM. More recently, Li et al. (2023) integrated different tasks to train a universal retriever, further enhancing the performance of retrieval methods.\nHowever, these methods have certain limitations in real-world applications, especially in more inference time and high token costs (\u00a74.3). Based on this, this paper tries to solve a more challenging problem: selecting representative in-context\ndemonstrations, which could prompt each test example with the same demonstrations."
        },
        {
            "heading": "6.2 Determinantal Point Process",
            "text": "Determinantal Point Process (DPP) is an elegant probabilistic model that could select representative subsets while maintaining high diversity among each instance (Kulesza et al., 2012). Such efficient method has been applied to introduce diversity in various tasks: objection detection (Azadi et al., 2017), recommendation (Chen et al., 2018), summary (Cho et al., 2019), and parsing (Shi et al., 2021). More recently, Levy et al. (2023) using DPP in composition tasks, sampling a diverse subset of in-context examples to cover more sub-phrases, which is task-specific and dependent on the specific model. Ye et al. (2023) improve the retrieval-based methods by introducing diversity into the retrieved examples via DPP. However, this paper focuses on a totally different paradigm."
        },
        {
            "heading": "7 Conclusion",
            "text": "This paper aims to address the challenge of selecting a representative demonstration subset and proposes two criteria (quality and diversity) that such demonstrations should satisfy. And we further propose a two-stage DPP method to incorporate both high quality and diversity in the selection process. Extensive experimental results show the effectiveness of our method and the significant advantages compared to retrieval-based methods."
        },
        {
            "heading": "8 Ackonwledgements",
            "text": "This work was supported by the National Key R&D Program of China (2022ZD0160503), the National Natural Science Foundation of China (No.62276264 and No.62306087), and the Natural Science Foundation of Shandong Province (Grant No. ZR2023QF154). This research was also supported by Meituan. And we thank the reviewers for their valuable feedback.\nLimitations\nThe main limitation of this paper is the proposed method could not be transferred into the black-box scenario such as the GPT-3.5 family. Existing Openai APIs only provide the log probability of the top-5 tokens, which leads to inaccurate calculation of the influence score. With such an inaccurate influence score, the accuracy of the values of the\ntwo important factors, instance quality and influence diversity, will also be affected. Therefore, our method is difficult to be transferred to these black-box models.\nBesides, we have realized the defined influence score (Equation 1) is not the optimal choice. We also design a more accurate influence score and Equation 1 is just a special case. These more accurate scores would bring more performance improvements. However, the computational cost of this more accurate method is several tens of times higher than Equation 1 used in this paper. For large language models, this cost is unacceptable (Yang et al., 2023). Therefore, this paper made trade-offs between efficiency and performance. And we leave the challenge of how to efficiently incorporate the more accurate influence scores into our method as our future work.\nEthics Statement\nThis paper aims to select representative demonstrations for in-context learning, and the experiments are conducted on publicly available datasets with available LLMs. As a result, there is no data privacy concern. Meanwhile, this paper does not involve human annotations, and there are no related ethical concerns."
        },
        {
            "heading": "A Details of Datasets",
            "text": "Table 4 shows the data statistics of our used datasets in the experiments. Considering the test set of DBPedia is too large, we just sample 3000 examples for testing in retrieval-based comparisons (Figure 3).\nTable 5 shows the prompt formats for the six datasets. Following Zhao et al. (2021), we let the model predict the label for the given sentence for SST-2 and AGNews. For TREC and DBPedia, we add the instruction sentence to illustrate the label space. For CB and RTE, which is a sentence matching task, we take the first sentence as background and combine the second sentence with a question as a prompt."
        },
        {
            "heading": "B Details of the Ablation Baseline",
            "text": "Table 3 presents the effect of the three factors. In this part, we illustrate the details of each baseline. sem_div introduces semantic diversity via DPP and chooses k demonstrations, which is the same as the DPP baseline and similar to the first stage (\u00a73.2.1). ins_qua randomly samples the candidate subset and computes the influence score of each instance. Then we choose the top-k samples with the highest quality scores as demonstrations. ins_qua also randomly samples the candidate subset and computes the influence score of each instance. Then we introduce influence diversity via DPP and choose k demonstrations. sem_div+ins_qua obtains the candidate subset by semantic DPP and computes the influence score of each instance. Then we choose the top-k samples with the highest quality scores as demonstrations. sem_div+inf_div obtains the candidate subset by semantic DPP and computes the influence score of each instance. Then we introduce influence diversity via DPP and choose k demonstrations. ins_qua+inf_div randomly samples the candidate subset and computes the influence score of\neach instance. Following the second stage (\u00a73.2.2), we utilize DPP to incorporate both quality and influence diveristy to choose k demonstrations."
        },
        {
            "heading": "C Frame of Our Method",
            "text": "To provide a more direct illustration of our method, we present the overall workflow in Figure 9, which aids in better understanding Algorithm 1."
        }
    ],
    "title": "Representative Demonstration Selection for In-Context Learning with Two-Stage Determinantal Point Process",
    "year": 2023
}