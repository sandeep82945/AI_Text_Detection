{
    "abstractText": "Spoken texts (either manual or automatic transcriptions from automatic speech recognition (ASR)) often contain disfluencies and grammatical errors, which pose tremendous challenges to downstream tasks. Converting spoken into written language is hence desirable. Unfortunately, the availability of datasets for this is limited. To address this issue, we present CS2W, a Chinese Spoken-to-Written style conversion dataset comprising 7,237 spoken sentences extracted from transcribed conversational texts. Four types of conversion problems are covered in CS2W: disfluencies, grammatical errors, ASR transcription errors, and colloquial words. Our annotation convention, data, and code are publicly available at https://github.com/guozishan/CS2W.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zishan Guo"
        },
        {
            "affiliations": [],
            "name": "Linhao Yu"
        },
        {
            "affiliations": [],
            "name": "Minghui Xu"
        },
        {
            "affiliations": [],
            "name": "Renren Jin"
        },
        {
            "affiliations": [],
            "name": "Deyi Xiong"
        }
    ],
    "id": "SP:e6002f70d5c073d67d03f9383f9b2193fcba0013",
    "references": [
        {
            "authors": [
                "Christopher Bryant",
                "Mariano Felice",
                "\u00d8istein E. Andersen",
                "Ted Briscoe."
            ],
            "title": "The BEA-2019 shared task on grammatical error correction",
            "venue": "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications, pages 52\u201375,",
            "year": 2019
        },
        {
            "authors": [
                "Eugene Charniak",
                "Mark Johnson."
            ],
            "title": "Edit detection and parsing for transcribed speech",
            "venue": "Second Meeting of the North American Chapter of the Association for Computational Linguistics.",
            "year": 2001
        },
        {
            "authors": [
                "Mai Hoang Dao",
                "Thinh Hung Truong",
                "Dat Quoc Nguyen."
            ],
            "title": "Disfluency detection for Vietnamese",
            "venue": "Proceedings of the Eighth Workshop on Noisy User-generated Text (W-NUT 2022), pages 194\u2013200, Gyeongju, Republic of Korea. Association for Com-",
            "year": 2022
        },
        {
            "authors": [
                "Vidas Daudaravicius",
                "Rafael E. Banchs",
                "Elena Volodina",
                "Courtney Napoles."
            ],
            "title": "A report on the automatic evaluation of scientific writing shared task",
            "venue": "Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications,",
            "year": 2016
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Zhengxiao Du",
                "Yujie Qian",
                "Xiao Liu",
                "Ming Ding",
                "Jiezhong Qiu",
                "Zhilin Yang",
                "Jie Tang."
            ],
            "title": "Glm: General language model pretraining with autoregressive blank infilling",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational",
            "year": 2022
        },
        {
            "authors": [
                "James Ferguson",
                "Greg Durrett",
                "Dan Klein."
            ],
            "title": "Disfluency detection with a semi-Markov model and prosodic features",
            "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
            "year": 2015
        },
        {
            "authors": [
                "J.J. Godfrey",
                "E.C. Holliman",
                "J. McDaniel."
            ],
            "title": "Switchboard: telephone speech corpus for research and development",
            "venue": "[Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing, volume 1, pages 517\u2013",
            "year": 1992
        },
        {
            "authors": [
                "Charles Hinson",
                "Hen-Hsen Huang",
                "Hsin-Hsi Chen."
            ],
            "title": "Heterogeneous recycle generation for Chinese grammatical error correction",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 2191\u20132201, Barcelona, Spain (On-",
            "year": 2020
        },
        {
            "authors": [
                "Matthew Honnibal",
                "Mark Johnson."
            ],
            "title": "Joint incremental disfluency detection and dependency parsing",
            "venue": "Transactions of the Association for Computational Linguistics, 2:131\u2013142.",
            "year": 2014
        },
        {
            "authors": [
                "Mana Ihori",
                "Akihiko Takashima",
                "Ryo Masumura."
            ],
            "title": "Parallel corpus for Japanese spoken-to-written style conversion",
            "venue": "Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 6346\u20136353, Marseille, France. European Language",
            "year": 2020
        },
        {
            "authors": [
                "Paria Jamshid Lou",
                "Peter Anderson",
                "Mark Johnson."
            ],
            "title": "Disfluency detection using auto-correlational neural networks",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4610\u20134619, Brussels, Belgium.",
            "year": 2018
        },
        {
            "authors": [
                "Mark Johnson",
                "Eugene Charniak."
            ],
            "title": "A TAGbased noisy-channel model of speech repairs",
            "venue": "Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-04), pages 33\u201339, Barcelona, Spain.",
            "year": 2004
        },
        {
            "authors": [
                "Mark Johnson",
                "Eugene Charniak",
                "Matthew Lease."
            ],
            "title": "An improved model for recognizing disfluencies in conversational speech",
            "venue": "Proceedings of Rich Transcription Workshop.",
            "year": 2004
        },
        {
            "authors": [
                "Hugo Lauren\u00e7on",
                "Lucile Saulnier",
                "Thomas Wang",
                "Christopher Akiki",
                "Albert Villanova del Moral",
                "Teven Le Scao",
                "Leandro Von Werra",
                "Chenghao Mou",
                "Eduardo Gonz\u00e1lez Ponferrada",
                "Huu Nguyen"
            ],
            "title": "The bigscience roots corpus: A 1.6 tb composite",
            "year": 2022
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdelrahman Mohamed",
                "Omer Levy",
                "Veselin Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "BART: Denoising sequence-to-sequence pre-training for natural language",
            "year": 2020
        },
        {
            "authors": [
                "Piji Li",
                "Shuming Shi."
            ],
            "title": "Tail-to-tail nonautoregressive sequence prediction for Chinese grammatical error correction",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Confer-",
            "year": 2021
        },
        {
            "authors": [
                "Chin-Yew Lin."
            ],
            "title": "ROUGE: A package for automatic evaluation of summaries",
            "venue": "Text Summarization Branches Out, pages 74\u201381, Barcelona, Spain. Association for Computational Linguistics.",
            "year": 2004
        },
        {
            "authors": [
                "Ruixuan Luo",
                "Jingjing Xu",
                "Yi Zhang",
                "Zhiyuan Zhang",
                "Xuancheng Ren",
                "Xu Sun."
            ],
            "title": "Pkuseg: A toolkit for multi-domain chinese word segmentation",
            "venue": "arXiv preprint arXiv:1906.11455.",
            "year": 2019
        },
        {
            "authors": [
                "Evgeny Matusov",
                "Arne Mauser",
                "Hermann Ney."
            ],
            "title": "Automatic sentence segmentation and punctuation prediction for spoken language translation",
            "venue": "Proceedings of the Third International Workshop on Spoken Language Translation: Papers, Kyoto, Japan.",
            "year": 2006
        },
        {
            "authors": [
                "Courtney Napoles",
                "Keisuke Sakaguchi",
                "Joel Tetreault."
            ],
            "title": "JFLEG: A fluency corpus and benchmark for grammatical error correction",
            "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics:",
            "year": 2017
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311\u2013318, Philadelphia,",
            "year": 2002
        },
        {
            "authors": [
                "Gaoqi Rao",
                "Qi Gong",
                "Baolin Zhang",
                "Endong Xun."
            ],
            "title": "Overview of NLPTEA-2018 share task Chinese grammatical error diagnosis",
            "venue": "Proceedings of the 5th Workshop on Natural Language Processing Techniques for Educational Applications, pages",
            "year": 2018
        },
        {
            "authors": [
                "Gaoqi Rao",
                "Erhong Yang",
                "Baolin Zhang."
            ],
            "title": "Overview of NLPTEA-2020 shared task for Chinese grammatical error diagnosis",
            "venue": "Proceedings of the 6th Workshop on Natural Language Processing Techniques for Educational Applications, pages 25\u201335,",
            "year": 2020
        },
        {
            "authors": [
                "Keisuke Sakaguchi",
                "Courtney Napoles",
                "Matt Post",
                "Joel Tetreault."
            ],
            "title": "Reassessing the goals of grammatical error correction: Fluency instead of grammaticality",
            "venue": "Transactions of the Association for Computational Linguistics, 4:169\u2013182.",
            "year": 2016
        },
        {
            "authors": [
                "Teven Le Scao",
                "Angela Fan",
                "Christopher Akiki",
                "Ellie Pavlick",
                "Suzana Ili\u0107",
                "Daniel Hesslow",
                "Roman Castagn\u00e9",
                "Alexandra Sasha Luccioni",
                "Fran\u00e7ois Yvon",
                "Matthias Gall\u00e9"
            ],
            "title": "Bloom: A 176bparameter open-access multilingual language model",
            "year": 2022
        },
        {
            "authors": [
                "Abigail See",
                "Peter J. Liu",
                "Christopher D. Manning."
            ],
            "title": "Get to the point: Summarization with pointergenerator networks",
            "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1073\u2013",
            "year": 2017
        },
        {
            "authors": [
                "Yunfan Shao",
                "Zhichao Geng",
                "Yitao Liu",
                "Junqi Dai",
                "Fei Yang",
                "Li Zhe",
                "Hujun Bao",
                "Xipeng Qiu."
            ],
            "title": "Cpt: A pre-trained unbalanced transformer for both chinese language understanding and generation",
            "venue": "arXiv preprint arXiv:2109.05729.",
            "year": 2021
        },
        {
            "authors": [
                "Elizabeth Shriberg."
            ],
            "title": "Disfluencies in switchboard",
            "venue": "Proceedings of international conference on spoken language processing, volume 96, pages 11\u201314. Citeseer.",
            "year": 1996
        },
        {
            "authors": [
                "J\u00f6rg Tiedemann",
                "Santhosh Thottingal."
            ],
            "title": "Opusmt\u2013building open translation services for the world",
            "venue": "Proceedings of the 22nd Annual Conference of the European Association for Machine Translation. European Association for Machine Translation.",
            "year": 2020
        },
        {
            "authors": [
                "Pavlos Vougiouklis",
                "Hady Elsahar",
                "Lucie-Aim\u00e9e Kaffee",
                "Christophe Gravier",
                "Fr\u00e9d\u00e9rique Laforest",
                "Jonathon Hare",
                "Elena Simperl."
            ],
            "title": "Neural wikipedian: Generating textual summaries from knowledge base triples",
            "venue": "Journal of Web Semantics, 52:1\u201315.",
            "year": 2018
        },
        {
            "authors": [
                "Sander Wubben",
                "Antal van den Bosch",
                "Emiel Krahmer."
            ],
            "title": "Paraphrase generation as monolingual translation: Data and evaluation",
            "venue": "Proceedings of the 6th International Natural Language Generation Conference. Association for Computational Linguis-",
            "year": 2010
        },
        {
            "authors": [
                "Zehui Yang",
                "Yifan Chen",
                "Lei Luo",
                "Runyan Yang",
                "Lingxuan Ye",
                "Gaofeng Cheng",
                "Ji Xu",
                "Yaohui Jin",
                "Qingqing Zhang",
                "Pengyuan Zhang"
            ],
            "title": "Open source magicdata-ramc: A rich annotated mandarin conversational (ramc) speech dataset",
            "year": 2022
        },
        {
            "authors": [
                "Yan Gong Yiping Peng Qiang Niu Baochang Ma Xiangang Li Yunjie Ji",
                "Yong Deng."
            ],
            "title": "Belle: Bloomenhanced large language model engine",
            "venue": "https: //github.com/LianjiaTech/BELLE.",
            "year": 2023
        },
        {
            "authors": [
                "Vicky Zayats",
                "Mari Ostendorf."
            ],
            "title": "Giving attention to the unexpected: Using prosody innovations in disfluency detection",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human",
            "year": 2019
        },
        {
            "authors": [
                "Vicky Zayats",
                "Mari Ostendorf",
                "Hannaneh Hajishirzi."
            ],
            "title": "Disfluency detection using a bidirectional lstm",
            "venue": "Interspeech 2016.",
            "year": 2016
        },
        {
            "authors": [
                "Yuanyuan Zhao",
                "Nan Jiang",
                "Weiwei Sun",
                "Xiaojun Wan."
            ],
            "title": "Overview of the nlpcc 2018 shared task: Grammatical error correction",
            "venue": "Natural Language Processing and Chinese Computing.",
            "year": 2018
        },
        {
            "authors": [
                "E P/R/F"
            ],
            "title": "Calculation Method Firstly, the gold sentence and the models\u2019 outputs are word-segmented using the PKUNLP word segmentation (WS) tool (Luo et al., 2019), and then we calculate the number of maximal matches",
            "year": 2019
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Automatic speech recognition (ASR) plays a vital role in a wide range of NLP application scenarios, such as simultaneous interpretation, where verbal utterances are transcribed into spoken style texts. These transcriptions serve as fundamental inputs to plenty of downstream tasks. However, they often inherently contain disfluencies, grammatical errors, and colloquial words, which pose tremendous challenges on downstream tasks. Automatically correcting errors and editing spoken into written language would significantly benefit downstream tasks that are usually trained on canonical texts. Developing such spoken-to-written style conversion models usually requires labeled data that cover different phenomena in ASR-transcribed spoken style texts.\nUnfortunately, existing datasets usually focus on a single type of spoken style, such as disfluencies. Consequently, models trained on these datasets cannot address all spoken style issues.\n\u2217Corresponding author\nTo bridge this gap, we propose CS2W, a largescale fine-grained Chinese Mandarin spoken-towritten style conversion dataset, developed on the Real Spontaneous Dialogue Speech dataset MagicData-RAMC (Yang et al., 2022). CS2W consists of 7,237 annotated instances, covering four major conversion problems corresponding to the majority of spoken phenomena. For each conversion instance, we manually annotate the spans and types of the corresponding conversion problems.\nWe conduct a thorough and in-depth analysis on Chinese spoken texts and summarize four conversion problems: disfluencies, ASR transcription errors, grammatical errors, and colloquial words. The\n1In Chinese, \"rubber ball\" is pronounced the same as \"banana kick\".\n2In Chinese, the word \"\u7535\u5f71\" (movie) is pronounced as \"dian ying,\" and the individual character \"\u7535\" (electric) is pronounced as \"dian.\" The error in this sentence is that only half of the word \"\u7535\u5f71\" is mentioned.\n3In Chinese, the colloquial word \"\u5212\u6c34\" refers to the act of slacking off during work or study.\nfour conversion problems are common in Chinese spoken texts and cover the major tasks in spokento-written style conversion (i.e., grammatical and ASR error correction, and simplification).\n\u2022 Disfluency: Repetitions, restarts, or repairs in spontaneous communication.\n\u2022 ASR transcription errors: Occasional homophone mistakes in ASR transcriptions.\n\u2022 Grammatical errors: Missing words, incorrect syntax structures, etc., similar to those occurring in written style texts.\n\u2022 Colloquial words: Problems related to colloquial words that differ from written language.\nTable 1 shows examples of the four types of conversion problems and their impact on machine translation.\nIn comparison to existing datasets that focus on grammatical errors or disfluencies, our dataset contains more conversion types and closely aligns with the distribution of real-world spoken data. For example, in the commonly used SWITCHBOARD corpus (Godfrey et al., 1992), instances usually contain a few disfluent words (Charniak and Johnson, 2001), and more than half of those disfluencies consist of repetitions (Shriberg, 1996). In contrast, our dataset frequently contains various types of grammatical errors and disfluencies within a single sentence.\nOur contributions are as follows:\n1. We curate and release CS2W, the first opensource Chinese dataset for spoken-to-written style conversion. The dataset is derived from real-world spontaneous conversations. We provide fine-grained annotation along with written style manually normalized texts. Additionally, we establish a comprehensive set of criteria for spoken-to-written style conversion classification and annotation.\n2. We conduct an in-depth analysis on the distribution of spoken-to-written style conversion problems and identify new types of disfluencies.\n3. We conduct benchmark evaluation experiments on CS2W to evaluate the performance of cutting-edge large language models on"
        },
        {
            "heading": "A flight to um Boston I mean Denver Tuesday",
            "text": "spoken-to-written language conversion. Experiment results demonstrate that the conversion from spoken to written language effectively improves the performance of downstream tasks."
        },
        {
            "heading": "2 Related Work",
            "text": "Previous studies have treated disfluency detection and grammatical error correction as separate tasks. We hence review their progress separately. A comprehensive comparison of GEC, disfluency detection, and spoken-to-written style conversion datasets is presented in Table 2.\nDisfluency Detection and Related Datasets Disfluency is a common phenomenon in spoken language and is generally divided into two categories: R-types and Filler words. Filler words have no meaning and are often used to indicate pauses and hesitations of the speaker. They are enumerable and easy to detect, for example, in English, Filler words include \"uh\", \"you know\", \"well\" and so on. R-types include repeat, restart, and repair. As shown in Figure 1, a repair type disfluency includes a reparandum (\"Boston\") and an interregnum (\"I mean\"), followed by its repair (\"Denver \"). A repetition type has the same reparandum and interregnum. A restart type has only a reparandum without interregnum, meaning the speaker starts a new topic. The most prevalent approach to disfluency correction involves treating it as a sequence tagging task, aiming to produce fluent discourse by identifying and removing disfluent segments (Zayats et al., 2016). Traditional models of disfluency detection use syntactic features (Honnibal and Johnson, 2014), language models (Johnson et al., 2004), or rhyme-based learning features (Zayats and Ostendorf, 2019), while more recent disfluency detection models mainly make use of pre-trained neural representations (Jamshid Lou et al., 2018). Most of these models rely on manually annotated data.\nUnfortunately, few disfluent detection datasets\nare publicly available. The SWITCHBOARD corpus (Godfrey et al., 1992) consists of transcribed telephone conversations between two individuals discussing a specific topic, which include disfluencies. Compared to this dataset, CS2W contains a higher density of disfluent sentences.\nDue to the sparsity of disfluency data, Dao et al. (2022) construct a Vietnamese disfluency dataset PhoDisfluency by manually introducing disfluency perturbations to the fluent sentences. In contrast, CS2W is collected from natural, spontaneous conversations, and is the first open-source Chinese dataset containing disfluency issues.\nGrammatical Error Correction and Related Datasets Common errors in Chinese grammatical error correction (GEC) datasets include spelling errors, missing words, redundant words, incorrect word order, collocation errors, etc. Seq2Seq models, based on RNN/CNN or Transformer, are usually used for Chinese GEC tasks. Hinson et al. (2020) first propose a Seq2Edit model for Chinese GEC, which achieves comparable performance with the Seq2Seq counterparts. Most Seq2Editbased models use PLMs like BERT (Devlin et al., 2019) to initialize their encoders. Li and Shi (2021) apply a non-autoregressive neural machine translation model to Chinese GEC.\nNumerous datasets have been proposed for GEC. These datasets primarily use two main paradigms to label the data: error-coded and direct rewriting. In the error-coded paradigm, annotators are tasked with explicitly identifying erroneous spans in the original sentence, specifying the error type, and subsequently making corrections. For instance,\nFCE (Vougiouklis et al., 2018) is an early largescale English GEC dataset using the error-coded paradigm, comprising raw text produced by English learners who complete their First Certificate in English. Another example is AESW (Daudaravicius et al., 2016), sourced from a professional editing company, which focuses on assessing the level of technical writing and includes questions on not only writing style conversion but grammatical errors. Additionally, the NLPCC18-task (Zhao et al., 2018) dataset originates from Lang-84, a language learning website where native speakers can freely select essays by learners for revision. Conversely, the direct rewriting paradigm instructs annotators to rephrase the input sentence directly, providing a corresponding grammatically correct version without altering the original meaning. An example is JFLEG (Napoles et al., 2017), developed with reference to the TOEFL exam. It places emphasis on preserving the overall fluency of the rewritten text. Moreover, WI-LOCNESS (Bryant et al., 2019) encompasses two distinct datasets, derived from essays written by students with English as either their first or second language. Finally, CGED (Rao et al., 2018, Rao et al., 2020) is designed to diagnose grammatical errors in Chinese, based on the HSK (Hanyu Shuiping Kaoshi, Test of Chinese Level) examination.\nIn contrast to the existing GEC datasets, our CS2W dataset places a stronger emphasis on grammatical errors occurring in the spoken domain rather than the written domain. Notably, while all previously established datasets feature a single\n4https://lang-8.com/\nannotation paradigm, the CS2W dataset stands out by offering two distinct annotation paradigms.\nSpoken-to-Written Style Conversion and Related Datasets Spoken-to-written style conversion can be formulated as a monolingual translation task (Wubben et al., 2010), mapping from a spoken style text to a normalized written style text. A variety of approaches have been proposed to address these monolingual translation challenges, including noisy channel models and hidden Markov models (Johnson and Charniak, 2004; Ferguson et al., 2015; Matusov et al., 2006) used earlier. In recent years, neural sequence conversion models have demonstrated superior performance (See et al., 2017). Nevertheless, these models require a sizable parallel corpus for training since they learn the relationship between input and output sequences directly in an end-to-end manner. Therefore, it is essential to curate a large-scale parallel corpus of spoken and written language.\nPublicly available spoken-to-written style conversion data are scarce, with the majority of datasets being private. Ihori et al. (2020) curate the Parallel Corpus for Japanese Spoken-to-Written Style Conversion, which annotates not only grammatical errors but also special conversion types in Japanese. These types include restoring postpositional particle expressions, hiragana symbols, etc. CS2W is a spoken-written style conversion dataset, where the conversion problems are categorized according to Chinese linguistic characteristics."
        },
        {
            "heading": "3 Dataset Curation",
            "text": "In this section, we elaborate on the creation of the CS2W dataset."
        },
        {
            "heading": "3.1 Data Source",
            "text": "CS2W is built upon the existing MagicData-RAMC dataset (Yang et al., 2022), which consists of 351 sets of spontaneous conversations in Chinese Mandarin. Each set features natural conversations between two speakers on a single topic, and it includes audio files and transcribed texts that retain real-world disfluencies, grammatical errors, and ASR transcription errors. We manually select sentences from the ASR transcriptions, which are selfcontained in meaning but with conversion problems for annotation. In total, we collect 7,237 sentences for further annotation. A comprehensive description of the data extraction process can be found in Appendix A."
        },
        {
            "heading": "3.2 Annotation Guidelines",
            "text": "The spoken-to-written style conversion normally involves lexical and syntactical editing and style transfer. The former is similar to grammatical error correction, dealing with disfluencies, ASR transcription errors, and grammatical errors while the latter is for the translation of colloquial words into canonicalized words with the same meaning used in written style texts.\nTo annotate the selected sentences, we employ two established annotation paradigms: error-coded and direct rewriting, commonly used in grammatical error correction datasets (Zhao et al., 2018; Rao et al., 2020), which have been described in Section 2.\nInitially, for each sentence, we use the errorcoded paradigm to meticulously identify spokento-written style conversion problems and determine the types of these problems (i.e., \u2208 disfluency, ASR transcription error, grammatical error, colloquial word). We also pinpoint the specific spans within the sentences where these problems manifest. It\u2019s essential to recognize that a sentence may exhibit multiple conversion problems simultaneously.\nHowever, it is worth noting that (Sakaguchi et al., 2016) highlight certain challenges associated with the error-coded paradigm, particularly concerning consensus among annotators regarding the identification of spans and problem types. Furthermore, complex annotation paradigms sometimes lead annotators to neglect the aspect of sentence fluency, resulting in unnatural expressions. Therefore, we also incorporate the direct rewriting paradigm into our annotation. This involves rewriting the spoken style language directly into a written form, producing references that are not only grammatically correct but also fluent and in a written style. Additionally, the labeled conversion problems in the error-coded paradigm need to be consistent with those corrected in the written style reference.\nTable 3 provides a breakdown of the labeling for different conversion types. To enhance annotation consistency among different annotators, we develop comprehensive guidelines in Appendix B, which offer detailed descriptions of our annotation convention along with illustrative annotation examples."
        },
        {
            "heading": "3.3 Annotation Process",
            "text": "To ensure the consistency and quality of our annotations, we implement a two-round annotation\nprocess. In the first round of annotation, we enlist the expertise of eight Chinese native speakers as parttime annotators after pre-annotation training. We require that each conversion problem within a given spoken style text be annotated in accordance with established conventions, assuring the validity and uniformity of the annotations.\nIn the second round, we conduct a manual evaluation and re-annotation, with the authors of this paper serving as senior annotators. Each annotated instance is scrutinized according to the answers to the following three core questions:\n1. Are the type and span annotations correct? This step ensures the accuracy of annotations under the error-coded paradigm.\n2. Does the written style reference faithfully retain the meaning of the original spoken style text? This step ensures the accuracy of annotations under the direct rewriting paradigm.\n3. Is the modification in the written language reference consistent with the conversion problems being labeled? This ensures the alignment between the annotations under the errorcoded paradigm and those under the direct rewriting paradigm.\nIf the annotators in the second round encounter any inconsistencies with the first-round annotations,\nthey submit their annotations to the senior annotators. The senior annotators then perform a comparative analysis of the results from both rounds and issue the final annotation verdict. Detailed guidelines for resolving inconsistencies are provided in Appendix B."
        },
        {
            "heading": "4 Dataset Analysis",
            "text": "We provide data statistics and analyses on conversion type distribution, sentences with multiple conversion problems, and a new subtype of disfluency existing in our dataset, which is absent in previous studies."
        },
        {
            "heading": "4.1 Overall Statistics",
            "text": "Table 4 presents the overall statistics of our dataset. We randomly shuffle all the annotated texts and partition them into training, development, and test sets with a proportion of 8:1:1. The training set consists of 5,789 texts, while both the development and test sets contain 724 texts each. Not surprisingly, most erroneous texts contain only one error. After Chinese word segmentation via the PKUseg tool (Luo et al., 2019), we obtain a total of 143,738 tokens. On average, each text contains approximately 12.82 tokens. Additionally, the average length of each span is 2.02, and each sentence contains an average of 1.35 spans.\n5In Chinese, \"\u5927\u6028\u79cd\" is an Internet phrase used to describe people who are aggrieved but have no way to complain."
        },
        {
            "heading": "4.2 Conversion Type Distribution",
            "text": "To assess the distribution over different conversion types, we calculate the proportions of each conversion type present in the dataset. Results are illustrated in Figure 2. Since sentences in our dataset often contain multiple conversion types, the percentage of each conversion type is obtained by dividing the number of occurrences of the conversion type by the total number of conversions in the source sentence. As shown in Figure 2, disfluency dominates in conversion problems, and notably, the percentage of R-type conversion problems, which is often challenging to rectify, is substantially high. Grammatical errors constitute a relatively minor portion, accounting for 6.9% of the dataset. Within this category, the principal error types include word missing and word redundancy."
        },
        {
            "heading": "4.3 Analysis on Sentences with Multiple Conversion Problems",
            "text": "In contrast to previous disfluency detection and grammatical error correction datasets, where each sentence typically has only one problem, as depicted in Figure 3, our CS2W dataset presents a notable departure. Specifically, we find that 25.34% of the single sentences within CS2W exhibit multiple conversion problems, with a significant 31.86% of these sentences displaying more than two types\nof conversion problems. This observation underscores the prevalence of disfluency problems, as a substantial number of sentences with other types of conversion problems also include disfluencies. Surprisingly, over 50% of sentences featuring grammatical errors or colloquial words also include disfluency problems. This suggests a likely connection between disfluencies and the emergence of grammatical errors and colloquial words, as disfluencies often arise from pauses in thought during spontaneous language production, potentially contributing to these issues."
        },
        {
            "heading": "4.4 A New sub-type of Disfluency",
            "text": "Our analysis of the most prevalent conversion problem, disfluency, in the context of spoken-to-written style conversion, has revealed a novel disfluency pattern. In the conventional R-type disfluency, the reparandum (the incorrect portion) typically precedes the repair (the corrected portion). This pattern aligns with the common observation that speakers often correct themselves upon realizing an error. However, in this distinct disfluency pattern, the repair precedes the reparandum, as illustrated in Figure 4. In other words, an utterance fragment is originally said correctly but immediately said incorrectly when it is repeated.\nTraditional disfluency correction models commonly delete the portion preceding the disfluency to generate a grammatically correct sentence. However, when confronted with this specific pattern, such an approach could potentially compromise the accuracy of the correction process."
        },
        {
            "heading": "5 Experiment",
            "text": "We conducted experiments on the curated dataset to evaluate the performance of the advanced opensource large language models (LLMs) on Chinese spoken-to-written style conversion."
        },
        {
            "heading": "5.1 Dataset",
            "text": "We ensured randomness in our data selection process by shuffling all the annotated texts. Subsequently, we partitioned these texts into training, development, and test sets, maintaining a distribution ratio of 8:1:1. The training set encompasses 5,789 texts, while both the development and test sets consist of 724 texts each."
        },
        {
            "heading": "5.2 Baselines",
            "text": "We used the following baseline models:\n5,404 1,288\n343 124\n42 30\n2 2 2\n1 10 100 1000 10000\n1 2 3 4 5 6 7 8 9\nNumber of Sentences\nN um\nbe r\nof C\non ve\nrs io\nn Pr\nob le\nm s\n(a) Statistics on the number of conversion problems contained in a single sentence.\n5,700 467 439\n305 234\n47 20\n16 2\n1\n1 10 100 1000\nD GE\nCW D & CW D & GE\nATE D & ATE\nGE & CW CW & ATE GE & ATE Multiple Types of\nConversion Problems Single Type of Conversion Problems\nNumber of Sentences\n(b) Statistics on the types of conversion problems contained in a single sentence.\nFigure 3: Statistics on the number and type of conversion problems contained in a single sentence. The horizontal axis uses logarithmic coordinates. D: Disfluency. ATE: ASR Transcription Errors. GE: Grammatical Errors. CW: Colloquial Words.\n\u7af9\u5b50 \u4e0d\u5355 \u4e0d\u5355\u72ec \u662f\u718a\u732b\u7684\u98df\u7269\uff0c\u8fd8\u53ef\u4ee5\u5236\u4f5c\u6210\u5f88\u591a\u5bb6\u5177\u3002\n\u7af9\u5b50\u4e0d\u5355\u662f\u718a\u732b\u7684\u98df\u7269\uff0c\u8fd8\u53ef\u4ee5\u5236\u4f5c\u6210\u5f88\u591a\u5bb6\u5177\u3002\n\u7af9\u5b50\u4e0d\u5355\u72ec\u662f\u718a\u732b\u7684\u98df\u7269\uff0c\u8fd8\u53ef\u4ee5\u5236\u4f5c\u6210\u5f88\u591a\u5bb6\u5177\u3002\nRP RM\nBamboo is not only is not a food for pandas, but it can also be made into a lot of furniture.\nBamboo is not only a food for pandas, but it can also be made into a lot of furniture.\nBamboo is not a food for pandas, but it can also be made into a lot of furniture.\n\u2022 BELLE (Yunjie Ji, 2023): a model based on BLOOM and finetuned with Chinese data combined with 50,000 pieces of English data, resulting in good Chinese instruction following and response generation capabilities.\n\u2022 ChatGLM9: an open bilingual language model based on General Language Model (GLM) (Du et al., 2022) framework, trained on 1T tokens of Chinese and English corpus, supplemented by supervised fine-tuning, feedback bootstrap, and reinforcement learning with human feedback.\n\u2022 GPT3.5-turbo10: a model trained on diverse data sources, which is an advanced language model based on the GPT-3.5 architecture.\nWe fine-tuned BART and CPT with the training set of CS2W and tested BLOOM, BELLE, ChatGLM, and GPT3.5-turbo under the zero- and 5-shot settings. The demonstrations used for the 5-shot setting and the method of selecting them are described in detail in Appendix C. The numbers of parameters of the models, as well as the hyperparameters, are described in detail in Appendix D."
        },
        {
            "heading": "5.3 Metrics",
            "text": "We evaluated models with BLEU (Papineni et al., 2002) and ROUGE-L (Lin, 2004). Referring to most grammatical error correction tasks, we also used the word-based MaxMatch scorer to calculate\n9https://github.com/THUDM/ChatGLM-6B 10https://openai.com/product\nP/R/F values. The method for calculating these values is described in Appendix E."
        },
        {
            "heading": "5.4 Main Results",
            "text": "Table 5 presents the performance of benchmark models on CS2W. Notably, the fine-tuned CPTlarge delivers outstanding results across all metrics. Importantly, it significantly outperforms the advanced LLMs under both the zero-shot and fewshot (5-shot) settings. This underscores the continued significance of CS2W in the context of Chinese Spoken-to-Written Style Conversion, even in the era of LLMs.\nUnder the zero-shot setting, ChatGLM exhibits a slight advantage over GPT3.5-turbo in terms of BLEU-3 and BLEU-4 scores, while GPT3.5-turbo excels in the remaining metrics. In contrast, under the 5-shot setting, GPT3.5-turbo emerges as the frontrunner, achieving the highest scores across all metrics. It\u2019s worth noting that, except for BELLE7B-0.2M, all models demonstrate improved performance under the 5-shot setting when compared to their zero-shot setting performance."
        },
        {
            "heading": "5.5 Performance on Four Conversion Types",
            "text": "Table 6 presents the benchmark model\u2019s performance across various types of conversions. The results from human evaluation are based on the accuracy of the first round of annotation. The results show that CPT-large and GPT3.5-turbo performed similarly across different conversion types. They achieve the highest accuracy in correcting disfluencies while encountering more challenges in addressing colloquial words, which aligns with the distribution of problems observed in CS2W."
        },
        {
            "heading": "5.6 Contribution of Spoken-to-Written Language Conversion to Downstream Tasks",
            "text": "To assess the impact of spoken-to-written language conversion on downstream tasks, we employed Chinese-to-English machine translation as a representative task. We randomly selected 100 normalized text references from the test set and then manually translated them into English to serve as references for the Chinese-to-English machine translation task.\nWe utilized OPUS-MT11 (Tiedemann and Thottingal, 2020) to translate the source sentences of these 100 references, along with the corresponding outputs of CPT-base and CPT-large. This approach allowed us to quantitatively evaluate the effect of spoken-to-written style conversion on the Chineseto-English machine translation task. The results, presented in Table 7, underscore the substantial positive impact of spoken-to-written language conversion as a preprocessing step for spoken language.\n11https://huggingface.co/Helsinki-NLP/opus-mt-zh-en\nNotably, the BLEU-4 score shows an improvement of 0.126 after the conversion done by CPT-large."
        },
        {
            "heading": "5.7 Results with different numbers of demonstrations provided to LLMs",
            "text": "We conducted further experiments on the BLOOM series models to investigate the impact of the number of demonstrations in the prompts on these LLMs. Specifically, we selected BLOOM series models with parameter sizes of 1.1B12, 1.7B13, 3B14, and 7.1B15 and performed experiments across a range of demonstration numbers, from 0 to 5. The outcomes of these experiments are graphically represented in Figure 5. Most models achieve significant improvement under the 1-shot setting, but performance drops and then increases with more demonstrations. We conjecture that this is due to model sensitivity to prompts. From zero to one demonstration, the model performance improves significantly due to the relevant prompts. In experiments with two to three demonstrations, limited prompt diversity leads to a performance decrease. With more demonstrations and diversity, the model performance gradually increases again.\n12https://huggingface.co/bigscience/bloom-1b1 13https://huggingface.co/bigscience/bloom-1b7 14https://huggingface.co/bigscience/bloom-3b 15https://huggingface.co/bigscience/bloom-7b1"
        },
        {
            "heading": "6 Conclusion",
            "text": "In this paper, we have presented a dataset CS2W, which is the first open-source Chinese spoken-towritten conversion dataset. The dataset covers four types of conversion problems commonly occurring in Chinese spoken texts. We manually annotate the type and span for each conversion problem and provide high-quality written style normalized texts. The dataset is used as a benchmark testbed to evaluate the performance of advanced LLMs on spoken-to-written style conversion and would promote future research on this underexplored direction."
        },
        {
            "heading": "Limitations",
            "text": "For all zero-shot and few-shot experiments, we used the same prompt for all models. However, prompt selection is important for large language models. We plan to use more prompts and prompt engineering methods to conduct experiments on the curated dataset in the future."
        },
        {
            "heading": "Ethics Statement",
            "text": "All data used in this study are freely available to the public. The raw data are from a public dataset built in previous work. We follow the policy of using these data without infringing any copyright issues. The curated dataset in this study is for academic research purposes only. All annotators are well paid according to the number of their annotations."
        },
        {
            "heading": "Acknowledgements",
            "text": "The present research was supported by the Key Research and Development Program of Yunnan Province (No. 202203AA080004) and Zhejiang Lab (No. 2022KH0AB01). We would like to thank the anonymous reviewers for their insightful comments."
        },
        {
            "heading": "A Data Extraction",
            "text": "MagicData-RAMC is an ASR transcription dataset that comprises 351 sets of spontaneous conversations in Chinese Mandarin. Each set features natural dialogues between two speakers discussing a single topic, and it includes both audio files and transcribed texts that preserve disfluencies, grammatical errors, and ASR transcription errors. We manually select sentences from the ASR transcriptions, ensuring they are self-contained in meaning but with conversion problems for annotation.\nIn transcribed text, we do not extract the following three types of sentences: Incomplete Sentences, Sentences that require context, and Sentences that are too short.\nA.1 Incomplete sentences\nIn spontaneous conversations, a speaker often breaks off abruptly or is interrupted by another speaker, resulting in many incomplete sentences in transcriptions.\ne.g. \u6211\u548c\u4ed6\u521a\u521a\u51c6\u5907\u51fa\u53bb\u73a9\uff0c\u5c31\u3002 (He and I were just getting ready to hang out but.)\nThis indicates that the speaker stops speaking at the word \"but\" or is interrupted by someone else. Incomplete sentences cannot be easily understood by annotators and, as a result, may not be accurately annotated.\nA.2 Sentences that require context\nSpontaneous conversations have continuity and many sentences need to be understood in context.\ne.g. Speaker 1: \u4f60\u8fd9\u6b21\u6570\u5b66\u8003\u8bd5\u8003\u4e86\u591a\u5c11 \u5206\uff1f (Speaker 1: What grade did you get on this math test? )\nSpeaker 2: \u4e00\u767e\u591a\u4e00\u70b9\uff0c\u6bd4\u4e0d\u4e0a\u4f60\u3002 (Speaker 2: little over a hundred, no more than you. )\nSpeaker 2\u2019s speech is a response to Speaker 1\u2019s question, which may not be fully comprehensible without considering Speaker 1\u2019s speech. Sentences that require context can also be challenging to annotate accurately."
        },
        {
            "heading": "A.3 Sentences that are too short",
            "text": "In spoken language, phrases such as \"no problem,\" \"yes,\" and \"okay\" are frequently employed, and these are considered too general. Therefore, we refrain from selecting sentences with fewer than 5 tokens.\nIn conclusion, we select complete sentences with conversion problems whose lengths are appropriate."
        },
        {
            "heading": "B Annotation Guidelines",
            "text": ""
        },
        {
            "heading": "B.1 Task Statement",
            "text": "Automatic speech recognition (ASR) plays a vital role in a wide range of NLP application scenarios. Spoken language, which serves as a fundamental input for plenty of downstream tasks, is transcribed into written text in a spoken style. However, they often inherently contain disfluencies, grammatical errors, and colloquial words. This dataset consists of transcribed texts with conversion problems for annotation. For each sentence, the annotator needs to annotate the type and the range of conversion problems and write the corresponding written language."
        },
        {
            "heading": "B.2 Conversion Type Definitions and Examples",
            "text": "We further categorize the conversion problem with a two-level classification system shown in Figure 8. Each conversion problem is described in detail next."
        },
        {
            "heading": "B.2.1 Disfluency",
            "text": "The elements that make a sentence not fluent are referred to as \"disfluency\", which can be categorized into R-type and Filler Words based on their structures.\nFiller Words Filler Words, such as \"uh\" and \"ah,\" have no specific meaning and are often used to indicate pauses and hesitations in the speaker\u2019s discourse. Additionally, common words like \"yeah\" and \"okay\" are also sometimes classified as filler words.\ne.g. \u597d\u5427\uff0c\u8fd9\u662f\u4e2a\uff0c\u55ef\uff0c\u4e00\u4e2a\u4e0d\u9519\u7684\u4e3b\u610f\u3002 (Well, this is, you know, a good plan.)\nIn this sentence, the phrases \"well\" and \"you know\" lack specific meaning and should be annotated as \"Filler words.\"\nR-type The standard structure of R-type disfluency encompasses three elements: the reparandum, an optional interregnum, and the associated repair. The reparandum consists of words that the speaker initially intends to discard, representing an unintended inclusion in the utterance. This section typically comprises one or more words slated for repetition or correction. The interregnum, often comprising fixed phrases like \"uh\" or \"you know,\" serves as a non-lexicalized component, contributing filler words without specific meaning. Lastly, the repair phase involves correcting or repeating words from the reparandum, thereby refining the overall coherence of the utterance.\ne.g. \u8ba9\u6211\u4eec\uff0c\u6211\u7684\u610f\u601d\u662f\uff0c\u8ba9\u6211\u6765\u89e3\u51b3\u8fd9 \u4e2a\u95ee\u9898\u3002 (Let us, I mean, let me work on the problem.)\nIn the provided example, the sentence \"Let us\" functions as the reparandum, embodying the words originally unintended for inclusion. The subsequent phrase \"let me\" constitutes the repair, correcting the preceding reparandum. The interregnum in this instance is \"I mean,\" a non-essential filler phrase devoid of substantive meaning."
        },
        {
            "heading": "B.2.2 ASR Transcription Errors",
            "text": "ASR Transcription Errors are occasional homophone mistakes in ASR transcriptions. CS2W is built upon the existing MagicData-RAMC dataset (Yang et al., 2022), which comprises 351 sets of spontaneous conversation speech in Chinese Mandarin and their ASR transcriptions. Consequently, there are occasional homophone mistakes in some sentences.\ne.g. \u8fd9\u4e2a\u827a\u672f\u5bb6\u5f88\u6709\u83dc\u82b1\u3002 (The artist is very cauliflower.16)\nAccording to the intended meaning of the sentence, the correct version should be \"The artist is very talented.\" Therefore, \"cauliflower\" needs to be annotated as an \"ASR Transcription Error.\""
        },
        {
            "heading": "B.2.3 Grammatical Errors",
            "text": "The transcription text of spoken language often includes grammatical errors because speakers in\n16In Chinese, \"cauliflower\" and \"talented\" have the same pronunciation.\nconversations often lack careful thinking. Common grammatical errors in spoken language include Missing Words, Redundant Words, and Incorrect Word Order.\nMissing Words Missing Words include missing subjects, missing predicates, missing objects, missing function words, and missing modifiers.\ne.g. \u90a3\u65f6\u6211\u4eec\u6709\u673a\u4f1a\u6273\u5e73\u6bd4\u5206\uff0c\u4f46\u662f\u6211\u4eec\u6ca1 \u6709\u673a\u4f1a\u3002 (We had a chance to equalize, but we didn\u2019t it.)\nThis sentence is missing a verb. The correct sentence is \"We had a chance to equalize, but we didn\u2019t take it\".\nRedundant Words Redundant Words include redundant subjects, redundant predicates, redundant objects, redundant function words, and redundant modifiers.\ne.g. \u5b83\u4eec\u7684\u76ae\u6bdb\u5f88\u6709\u5149\u6cfd,\u53ef\u4ee5\u7528\u8089\u773c\u5f88\u96be\u770b \u51fa\u6765\u3002 (Their fur is shiny and can be hardly seen with the naked eye.)\nThe modifier in this sentence is redundant. The fur is shiny so it should be visible to the naked eye. The word \"hardly\" should be deleted.\nIncorrect Word Order Incorrect Word Order is also common in spoken transcribed texts because of the frequent inversions in spoken language.\ne.g. \u6628\u5929\u770b\u4e86\u65b0\u4e70\u7684\u4e00\u90e8\u7535\u5f71\u6211\u5728\u7535\u89c6\u4e0a\u3002 (Yesterday watched a newly purchased movie I on TV.)\nIn Chinese, the correct sentence is \"Yesterday I watched a newly purchased movie on TV.\""
        },
        {
            "heading": "B.2.4 Colloquial Words",
            "text": "Spoken language often contains informal expressions, such as some popular Internet phrases, which are called \"Colloquial Words.\"\ne.g. \u8fd9\u660e\u660e\u662f\u4f60\u7684\u529f\u52b3\uff0c\u5374\u88ab\u540c\u4e8b\u62a2\u8d70\u4e86\uff0c \u4f60\u771f\u662f\u4e00\u4e2a\u5927\u6028\u79cd\u3002 (This is obviously your credit, but your coworkers took it away. You\u2019re such an unlucky guy.)\nWe need to replace all informal expressions with formal ones. In Chinese, the Internet phrase \"\u5927\u6028 \u79cd\" is used to describe people who are aggrieved but have no way to complain. Therefore, we should replace it with the more formal expression \"You\u2019re unlucky.\""
        },
        {
            "heading": "B.2.5 Mixed Type",
            "text": "In real spontaneous conversations, a single sentence often contains multiple conversion problems.\ne.g. \u5728\u56fd\u5185\u6210\u7acb\u91ce\u725b\uff0c\u8fd9\u4e2a\uff0c\u6c34\u725b\u7814\u7a76\u4e2d \u5fc3\uff0c\u6709\u5229\u4e8e\u5e2e\u52a9\u9002\u5e94\u4eba\u5de5\u73af\u5883\u3002 (The establish-\nment of the bison, I mean, buffalo research center in the country will help to adapt to an artificial environment.)\nThis sentence contains both disfluency and grammatical errors. The corrected version should be: \"The establishment of the buffalo research center in the country will help them adapt to an artificial environment.\""
        },
        {
            "heading": "B.3 Annotation Rules",
            "text": "We built an annotation platform to accelerate our annotation progress. When using it, the annotator needs to select the conversion type and annotation range of the current sentence. Then, the annotator provides the written language corresponding to this spoken language. Next, we will present the annotation rules for different conversions. Please note that on the annotation platform, each sentence is wordsegmented into individual words, each of which can be selected to make it easier for the annotator to annotate the conversion range.\nDisfluency The annotator selects the Disfluency button on the annotation platform. For Filler Words, the annotator should annotate their range. For Rtype, both the reparandum and the interregnum should be annotated, but the repair does not need to be annotated. This is because the sentence can be corrected by simply deleting the reparandum and the interregnum.\nASR Transcription Errors The annotator selects the ASR Transcription Errors button on the annotation platform and annotates the range of the ASR Transcription Errors.\nGrammatical Errors The annotator selects the Grammatical Errors button on the annotation platform. For Missing Words, the annotator needs to annotate the two words before and after the missing part. For Redundant Words, the annotator needs to annotate the redundant part. As for Incorrect Word Order, the entire sentence has to be annotated.\nColloquial Words The annotator selects the Colloquial Words button on the annotation platform and annotates the range of the colloquial words.\nMixed Type First, the annotator selects the button for the initial conversion type and annotates the range of that conversion. Subsequently, the annotator sequentially selects the buttons for the other conversion types and annotates their respective ranges.\nB.4 Inconsistent Treatment\nTo ensure annotation consistency and quality, we implement a two-round annotation process. In the first round, we enlist eight native Chinese speakers as part-time annotators after providing preannotation training. In the second round, we conduct manual evaluation and re-annotation, with the authors of this paper serving as senior annotators. In the event of inter-annotator disagreements, the annotator in the second round reannotates the sentence and submits the results of both rounds to the senior annotator. There are two scenarios of inter-annotator disagreements.\nThe first scenario is when the annotator from either the first or second round makes an incorrect annotation.\ne.g. \u5f53\u4ed6\u56de\u5230\u8f66\u8f66\u95f4\u65f6\uff0c\u5df2\u7ecf\u6709\u4e86\u660e\u663e\u7684\u53d8 \u5316\u3002 (When he returned to the ga-, garage, had changed markedly.)\nThe sentence exhibits two conversion problems, namely Disfluency and Missing Words. The annotator in the first round accurately annotates the disfluency but overlooks the grammatical errors. In the second round, the annotator correctly annotates both conversion problems. The senior annotator will then determine the correct annotation.\nThe second case is that the sentence can be corrected in multiple ways, which is common in grammatical errors.\ne.g. Source sentence: \u5982\u679c\u4eba\u4eec\u8fde\u7eed\u770b\u4e0a\u56db\u4e94 \u4e2a\u5c0f\u65f6\u7684\u7535\u89c6\u8282\u76ee\uff0c\u5c31\u4f1a\u611f\u5230\u5341\u5206\u75b2\u52b3\u3002 (If people watch TV programs for four or five hours in a row, will feel very tired.)\nTarget sentence 1: \u4eba\u4eec\u5982\u679c\u8fde\u7eed\u770b\u4e0a\u56db\u4e94\u4e2a \u5c0f\u65f6\u7684\u7535\u89c6\u8282\u76ee\uff0c\u5c31\u4f1a\u611f\u5230\u5341\u5206\u75b2\u52b3\u3002 (People in case of watching TV programs for four or five hours in a row will feel very tired.)\nTarget sentence 2: \u5982\u679c\u4eba\u4eec\u8fde\u7eed\u770b\u4e0a\u56db\u4e94 \u4e2a\u5c0f\u65f6\u7684\u7535\u89c6\u8282\u76ee\uff0c\u4ed6\u4eec\u5c31\u4f1a\u611f\u5230\u5341\u5206\u75b2\u52b3\u3002 (If people watch TV programs for four or five hours in a row, they will feel very tired.)\nThis sentence lacks a subject and has two potential solutions. First, considering the conversion as an \"Incorrect Word Order,\" the corresponding written language is target sentence 1. Second, considering the conversion as a \"Missing Word,\" the written language is target sentence 2. In this scenario, the senior annotator selects the solution with a smaller edit distance. If the edit distances are equal, the senior annotator opts for the first-round solution."
        },
        {
            "heading": "C Prompt Templates",
            "text": "C.1 Instructions Used in Main Results\nRegarding the prompts used for zero- and fewshot settings, we tried two different prompts on BLOOM-7B under the zero-shot and 5-shot settings.\nPrompt 1: \"\u4e0b\u9762\u6709\u4e00\u4e2a\u53e3\u8bed\u5230\u4e66\u9762\u8bed\u98ce\u683c\u8f6c \u6362\u4efb\u52a1,\u8bf7\u628a\u53e3\u8bed\u4fee\u6539\u4e3a\u4e66\u9762\u8bed: \u53e3\u8bed\uff1a{\u6e90\u53e5} \u4e66\u9762\u8bed:\" (Here\u2019s a spoken-to-written style conversion task, please rewrite the spoken language into the written language: spoken: {source sentence} written:).\nPrompt 2: \"\u4e0b\u9762\u6709\u4e00\u4e2a\u8bed\u6cd5\u7ea0\u9519\u4efb\u52a1,\u8bf7\u628a \u9519\u8bef\u7684\u6587\u672c\u4fee\u6539\u4e3a\u6b63\u786e\u7684\u6587\u672c: \u9519\u8bef\u6587\u672c: {\u6e90 \u53e5}\u6b63\u786e\u6587\u672c: \" (Here\u2019s a grammatical error correction task, please correct the wrong text into the right text: wrong text: {source sentence} correct text: )\nPrompt 2 outperforms Prompt 1 on all metrics. We speculate that the model may struggle to comprehend the definition of the spoken-to-written language conversion task. However, grammatical error correction is a widely-used task, and the four conversion problems, except for colloquial words, can be considered either simple or complex grammatical errors, allowing it to perform well. Hence, we adopt Prompt 2 for the rest of our experiments."
        },
        {
            "heading": "C.2 Demonstrations Used in Main Results",
            "text": "Under the zero-shot setting, the prompt is \"\u4e0b\u9762 \u6709\u4e00\u4e2a\u8bed\u6cd5\u7ea0\u9519\u4efb\u52a1\uff0c\u8bf7\u628a\u9519\u8bef\u7684\u6587\u672c\u4fee\u6539\u4e3a \u6b63\u786e\u7684\u6587\u672c\uff1a\u9519\u8bef\u6587\u672c\uff1a{\u6e90\u53e5}\u6b63\u786e\u6587\u672c\uff1a\" (Here\u2019s a grammatical error correction task, please correct the wrong text into the right text: wrong text: {source sentence} correct text:).\nWe expect LLMs to be capable of correcting all types of conversion problems. Therefore, it is crucial to ensure the diversity of demonstrations provided to LLMs. Given that CS2W encompasses four types of conversion problems, we incrementally add demonstrations of different types as the number of demonstrations increases. The demonstrations for each conversion problem are randomly selected from the validation set. These demonstrations differ from the input sentences in the test set and contain only one conversion problem. Additionally, since CS2W is dominated by disfluency as the primary conversion problem, we specifically select two demonstrations, one for R-type and another for Filler Words, under the 5-shot setting.\nIn Section 5.4 and 5.7, the demonstrations used in 5-shot experiments are shown in Figure 11.\nC.3 Impact of Demonstrations Diversity\nWhile our initial intuition suggested that including a higher diversity of conversion types in demonstrations would enable LLMs to address more types of conversions and subsequently improve results, our findings have led us to reconsider this notion. To test this hypothesis, we randomly selected five demonstrations from the validation set and repeated the selection process three times, resulting in three distinct prompts used for the 5-shot setting. The specific demonstrations included in each prompt are detailed in Table 12. Notably, Prompt 1 incorporates demonstrations with three different conversion types, offering the highest diversity, while Prompt 2 exclusively includes demonstrations featuring disfluency problems, resulting in the lowest diversity.\nWe tested BELLE-7B-2M, ChatGLM-6B, and GPT3.5-turbo under the 5-shot settings with these three prompts. The results, in comparison to those presented in Section 5.4, are summarized in Table 13.\nIn summary, our experimental findings challenge our initial hypothesis that greater diversity in examples would consistently enhance the ability of LLMs to address a wider range of conversion types and lead to improved results. Surprisingly, it is not always the case. The prompt with the most diversity, Prompt 1, displays the weakest performance. In contrast, Prompt 2 and Prompt 3, which feature fewer types of conversions but a higher concentration of demonstrations with disfluencies, delivered more favorable results.\nWe attribute this phenomenon to the prevalence of disfluency within the CS2W dataset. When the number of demonstrations with disfluencies surpasses a certain threshold, the overall performance tends to improve. However, it\u2019s worth noting that the dataset\u2019s distribution of conversion types may play a pivotal role in these results. In a scenario where the four conversion types were more balanced, prompts with greater diversity might have exhibited improved performance."
        },
        {
            "heading": "D Model Parameter Sizes and Hyperparameters",
            "text": "The numbers of parameters of the models used in the experiments are shown in Table 9.\nThe decoding temperature of LLMs used in the experiments is shown in Table 10."
        },
        {
            "heading": "E P/R/F Calculation Method",
            "text": "Firstly, the gold sentence and the models\u2019 outputs are word-segmented using the PKUNLP word segmentation (WS) tool (Luo et al., 2019), and then we calculate the number of maximal matches according to the WS results. The P, R, F0.5 measure the different rates between the set of the model\u2019s output edits e1, ..., e2 and the set of gold sentence edits g1, ..., g2 for all sentences:\nP = \u2211n i=1|ei \u2229 gi|\u2211n\ni=1|ei|\nR = \u2211n i=1|ei \u2229 gi|\u2211n\ni=1|gi|\nF0.5 = 1.25 \u2217 P \u2217R 0.25 \u2217 P +R\nWhere we define the intersection between ei and gi as:\nei \u2229 pi = {e \u2208 ei|\u2203g \u2208 gi(match(e, g))}\nPrompt Model BLEU-1 BLEU-2 BLEU-3 BLEU-4 BELLE-7B-2M 0.4885 0.3519 0.2790 0.2167 ChatGLM-6B 0.5924 0.4872 0.4261 0.37850 GPT3.5-turbo 0.6882 0.5862 0.5087 0.4393"
        }
    ],
    "title": "CS2W: A Chinese Spoken-to-Written Style Conversion Dataset with Multiple Conversion Types",
    "year": 2023
}