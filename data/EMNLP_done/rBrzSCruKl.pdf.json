{
    "abstractText": "Multi-document Summarization (MDS) characterizes compressing information from multiple source documents to its succinct summary. An ideal summary should encompass all topics and accurately model cross-document relations expounded upon in the source documents. However, existing systems either impose constraints on the length of tokens during the encoding or falter in capturing the intricate cross-document relationships. These limitations impel the systems to produce summaries that are non-factual and unfaithful, thereby imparting an unfair comprehension of the topic to the readers. To counter these limitations and promote the information equivalence between the source document and generated summary, we propose FABRIC, a novel encoder-decoder model that uses pre-trained BART to comprehensively analyze linguistic nuances, simplicial complex layer to apprehend inherent properties that transcend pairwise associations and sheaf graph attention to effectively capture the heterophilic properties. We benchmark FABRIC with eleven baselines over four widely-used MDS datasets \u2013 Multinews, CQASumm, DUC and Opinosis, and show that FABRIC achieves consistent performance improvement across all the evaluation metrics (syntactical, semantical and faithfulness). We corroborate these improvements further through qualitative human evaluation. The source code is available at https://github.com/LCS2-IIITD/FABRIC",
    "authors": [
        {
            "affiliations": [],
            "name": "Yash Kumar Atri"
        },
        {
            "affiliations": [],
            "name": "Arun Iyer"
        },
        {
            "affiliations": [],
            "name": "Tanmoy Chakraborty"
        },
        {
            "affiliations": [],
            "name": "Vikram Goyal"
        }
    ],
    "id": "SP:a98fa73494055d850d9b0a8740ab623f614241b3",
    "references": [
        {
            "authors": [
                "Griffin Adams",
                "Han-Chin Shing",
                "Qing Sun",
                "Christopher Winestock",
                "Kathleen McKeown",
                "No\u00e9mie Elhadad"
            ],
            "title": "Learning to revise references for faithful summarization",
            "venue": "In Findings of the Association for Computational Linguistics:",
            "year": 2022
        },
        {
            "authors": [
                "Yash Kumar Atri",
                "Vikram Goyal",
                "Tanmoy Chakraborty"
            ],
            "title": "Fusing multimodal signals on hyper-complex space for extreme abstractive text summarization (tl;dr) of scientific contents",
            "venue": "In Proceedings of the 29th ACM SIGKDD Conference",
            "year": 2023
        },
        {
            "authors": [
                "Yash Kumar Atri",
                "Vikram Goyal",
                "Tanmoy Chakraborty"
            ],
            "title": "Multi-document summarization using selective attention span and reinforcement learning",
            "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing,",
            "year": 2023
        },
        {
            "authors": [
                "Yash Kumar Atri",
                "Shraman Pramanick",
                "Vikram Goyal",
                "Tanmoy Chakraborty"
            ],
            "title": "See, hear, read: Leveraging multimodality with guided attention for abstractive text summarization",
            "venue": "Knowledge-Based Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Dzmitry Bahdanau",
                "Kyunghyun Cho",
                "Yoshua Bengio"
            ],
            "title": "Neural machine translation by jointly learning to align and translate",
            "venue": "In 3rd International Conference on Learning Representations,",
            "year": 2015
        },
        {
            "authors": [
                "Vidhisha Balachandran",
                "Hannaneh Hajishirzi",
                "William Cohen",
                "Yulia Tsvetkov"
            ],
            "title": "Correcting diverse factual errors in abstractive summarization via postediting and language model infilling",
            "year": 2022
        },
        {
            "authors": [
                "Cheung"
            ],
            "title": "Learning with rejection for abstrac",
            "year": 2022
        },
        {
            "authors": [
                "Kristina Toutanova"
            ],
            "title": "2019. BERT: Pre-training",
            "year": 2019
        },
        {
            "authors": [
                "Esin Durmus",
                "He He",
                "Mona Diab"
            ],
            "title": "FEQA: A question answering evaluation framework for faithfulness assessment in abstractive summarization",
            "venue": "In ACL,",
            "year": 2020
        },
        {
            "authors": [
                "Alex Fabbri",
                "Prafulla Kumar Choubey",
                "Jesse Vig",
                "ChienSheng Wu",
                "Caiming Xiong"
            ],
            "title": "Improving factual consistency in summarization with compressionbased post-editing",
            "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language",
            "year": 2022
        },
        {
            "authors": [
                "Alexander R Fabbri",
                "Irene Li",
                "Tianwei She",
                "Suyi Li",
                "Dragomir R Radev"
            ],
            "title": "Multi-news: a large-scale multi-document summarization dataset and abstractive hierarchical model",
            "venue": "arXiv preprint arXiv:1906.01749",
            "year": 2019
        },
        {
            "authors": [
                "Kavita Ganesan",
                "ChengXiang Zhai",
                "Jiawei Han"
            ],
            "title": "Opinosis: a graph-based approach to abstractive summarization of highly redundant opinions",
            "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics,",
            "year": 2010
        },
        {
            "authors": [
                "Sebastian Gehrmann",
                "Yuntian Deng",
                "Alexander Rush"
            ],
            "title": "Bottom-up abstractive summarization",
            "venue": "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2018
        },
        {
            "authors": [
                "Asish Ghoshal",
                "Arash Einolghozati",
                "Ankit Arun",
                "Haoran Li",
                "Lili Yu",
                "Yashar Mehdad",
                "Scott Wen tau Yih",
                "Asli Celikyilmaz"
            ],
            "title": "Improving faithfulness of abstractive summarization by controlling confounding effect of irrelevant sentences",
            "year": 2022
        },
        {
            "authors": [
                "Daniel Gillick",
                "Benoit Favre",
                "Dilek Z. Hakkani-T\u00fcr"
            ],
            "title": "The icsi summarization system at tac",
            "venue": "Theory and Applications of Categories",
            "year": 2008
        },
        {
            "authors": [
                "L. Giusti",
                "C. Battiloro",
                "P. Di Lorenzo",
                "S. Sardellitti",
                "S. Barbarossa"
            ],
            "title": "Simplicial attention neural networks",
            "year": 2022
        },
        {
            "authors": [
                "Maarten Grootendorst"
            ],
            "title": "Bertopic: Neural topic modeling with a class-based tf-idf procedure. arXiv preprint arXiv:2203.05794",
            "year": 2022
        },
        {
            "authors": [
                "Mandy Guo",
                "Joshua Ainslie",
                "David Uthus",
                "Santiago Ontanon",
                "Jianmo Ni",
                "Yun-Hsuan Sung",
                "Yinfei Yang"
            ],
            "title": "Longt5: Efficient text-to-text transformer for long sequences",
            "year": 2021
        },
        {
            "authors": [
                "Yanzhu Guo",
                "Chlo\u00e9 Clavel",
                "Moussa Kamal Eddine",
                "Michalis Vazirgiannis"
            ],
            "title": "Questioning the validity of summarization datasets and improving their factual consistency",
            "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language",
            "year": 2022
        },
        {
            "authors": [
                "Jakob Hansen",
                "Thomas Gebhart"
            ],
            "title": "Sheaf neural networks",
            "year": 2020
        },
        {
            "authors": [
                "Luyang Huang",
                "Lingfei Wu",
                "Lu Wang"
            ],
            "title": "Knowledge graph-augmented abstractive summarization with semantic-driven cloze reward",
            "venue": "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
            "year": 2020
        },
        {
            "authors": [
                "Wojciech Kryscinski",
                "Bryan McCann",
                "Caiming Xiong",
                "Richard Socher"
            ],
            "title": "Evaluating the factual consistency of abstractive text summarization",
            "venue": "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
            "year": 2020
        },
        {
            "authors": [
                "Philippe Laban",
                "Tobias Schnabel",
                "Paul N. Bennett",
                "Marti A. Hearst"
            ],
            "title": "SummaC: Re-visiting NLIbased models for inconsistency detection in summarization. Transactions of the Association for Computational Linguistics, 10:163\u2013177",
            "year": 2022
        },
        {
            "authors": [
                "Gyoung Ho Lee",
                "Kong Joo Lee"
            ],
            "title": "Automatic text summarization using reinforcement learning with embedding features",
            "venue": "In Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume",
            "year": 2017
        },
        {
            "authors": [
                "Hwanhee Lee",
                "Cheoneum Park",
                "Seunghyun Yoon",
                "Trung Bui",
                "Franck Dernoncourt",
                "Juae Kim",
                "Kyomin Jung"
            ],
            "title": "Factual error correction for abstractive summaries using entity retrieval",
            "venue": "In Proceedings of the 2nd Workshop on Natural Language Genera-",
            "year": 2022
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdelrahman Mohamed",
                "Omer Levy",
                "Veselin Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "BART: Denoising sequence-to-sequence pre-training for natural language",
            "year": 2020
        },
        {
            "authors": [
                "Lei Li",
                "Wei Liu",
                "Marina Litvak",
                "Natalia Vanetik",
                "Jiacheng Pei",
                "Yinan Liu",
                "Siya Qi"
            ],
            "title": "Subjective bias in abstractive summarization",
            "year": 2021
        },
        {
            "authors": [
                "Chin-Yew Lin"
            ],
            "title": "ROUGE: A package for automatic evaluation of summaries",
            "venue": "In Text Summarization Branches Out,",
            "year": 2004
        },
        {
            "authors": [
                "Yixin Liu",
                "Pengfei Liu",
                "Dragomir Radev",
                "Graham Neubig"
            ],
            "title": "BRIO: Bringing order to abstractive summarization",
            "venue": "In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
            "year": 2022
        },
        {
            "authors": [
                "Yuanjie Lyu",
                "Chen Zhu",
                "Tong Xu",
                "Zikai Yin",
                "Enhong Chen"
            ],
            "title": "Faithful abstractive summarization via fact-aware consistency-constrained transformer",
            "venue": "In Proceedings of the 31st ACM International Conference on Information & Knowledge Management,",
            "year": 2022
        },
        {
            "authors": [
                "Qianren Mao",
                "Jianxin Li",
                "Hao Peng",
                "Shizhu He",
                "Lihong Wang",
                "Philip S. Yu",
                "Zheng Wang"
            ],
            "title": "Factdriven abstractive summarization by utilizing multigranular multi-relational knowledge",
            "venue": "IEEE/ACM Transactions on Audio,",
            "year": 2022
        },
        {
            "authors": [
                "Joshua Maynez",
                "Shashi Narayan",
                "Bernd Bohnet",
                "Ryan Thomas Mcdonald"
            ],
            "title": "On faithfulness and factuality in abstractive summarization",
            "venue": "In ACL,",
            "year": 2020
        },
        {
            "authors": [
                "Ramakanth Pasunuru",
                "Mohit Bansal"
            ],
            "title": "Multireward reinforced summarization with saliency and entailment",
            "venue": "In NAACL,",
            "year": 2018
        },
        {
            "authors": [
                "Romain Paulus",
                "Caiming Xiong",
                "Richard Socher"
            ],
            "title": "A deep reinforced model for abstractive summarization. CoRR, abs/1705.04304",
            "year": 2017
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J. Liu"
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "year": 2020
        },
        {
            "authors": [
                "Olivier Pietquin",
                "Idan Szpektor"
            ],
            "title": "Factually consistent summarization via reinforcement learning with textual entailment feedback",
            "year": 2023
        },
        {
            "authors": [
                "Franco Scarselli",
                "Marco Gori",
                "Ah Chung Tsoi",
                "Markus Hagenbuchner",
                "Gabriele Monfardini"
            ],
            "title": "The graph neural network model",
            "venue": "IEEE Transactions on Neural Networks,",
            "year": 2009
        },
        {
            "authors": [
                "Abigail See",
                "Peter J. Liu",
                "Christopher D. Manning"
            ],
            "title": "Get to the point: Summarization with pointergenerator networks. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
            "year": 2017
        },
        {
            "authors": [
                "Yunchong Song",
                "Chenghu Zhou",
                "Xinbing Wang",
                "Zhouhan Lin"
            ],
            "title": "Ordered GNN: Ordering message passing to deal with heterophily and oversmoothing",
            "venue": "In The Eleventh International Conference on Learning Representations",
            "year": 2023
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N. Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin"
            ],
            "title": "Attention is all you need",
            "venue": "In Proceedings of the 31st International Conference on Neural Information Processing Sys-",
            "year": 2017
        },
        {
            "authors": [
                "Wenhao Wu",
                "Wei Li",
                "Jiachen Liu",
                "Xinyan Xiao",
                "Ziqiang Cao",
                "Sujian Li",
                "Hua Wu"
            ],
            "title": "FRSUM: Towards faithful abstractive summarization via enhancing factual robustness. In Findings of the Association for Computational Linguistics: EMNLP 2022",
            "year": 2022
        },
        {
            "authors": [
                "Wen Xiao",
                "Iz Beltagy",
                "Giuseppe Carenini",
                "Arman Cohan"
            ],
            "title": "PRIMERA: Pyramid-based masked sentence pre-training for multi-document summarization",
            "venue": "In Proceedings of the 60th Annual Meeting of the Association",
            "year": 2022
        },
        {
            "authors": [
                "Michihiro Yasunaga",
                "Rui Zhang",
                "Kshitijh Meelu",
                "Ayush Pareek",
                "Krishnan Srinivasan",
                "Dragomir Radev"
            ],
            "title": "Graph-based neural multi-document summarization",
            "venue": "In Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL",
            "year": 2017
        },
        {
            "authors": [
                "Weizhe Yuan",
                "Graham Neubig",
                "Pengfei Liu"
            ],
            "title": "Bartscore: Evaluating generated text as text generation",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Haopeng Zhang",
                "Semih Yavuz",
                "Wojciech Kryscinski",
                "Kazuma Hashimoto",
                "Yingbo Zhou"
            ],
            "title": "Improving the faithfulness of abstractive summarization via entity coverage control",
            "venue": "In Findings of the Association for Computational Linguistics:",
            "year": 2022
        },
        {
            "authors": [
                "Jingqing Zhang",
                "Yao Zhao",
                "Mohammad Saleh",
                "Peter Liu"
            ],
            "title": "PEGASUS: Pre-training with extracted gap-sentences for abstractive summarization",
            "venue": "In ICML,",
            "year": 2020
        },
        {
            "authors": [
                "Mengli Zhang",
                "Gang Zhou",
                "Wanting Yu",
                "Wenfen Liu"
            ],
            "title": "Far-ass: Fact-aware reinforced abstractive",
            "year": 2021
        },
        {
            "authors": [
                "Jun Guo"
            ],
            "title": "Improving abstractive dialogue",
            "year": 2021
        },
        {
            "authors": [
                "C Discussions"
            ],
            "title": "Why not use traditional graphs: To benchmark with the traditional graph-based methods, we utilized (Yasunaga et al., 2017) to model the interconnections between the documents",
            "year": 2017
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Multi-document summarization (MDS) aims to formulate a summary that captures the essence and main points of multiple documents on a specific topic. In contrast to single document summarization (SDS) that focuses on generating summaries from a single source, MDS faces additional challenges such as dealing with a larger search space, redundant documents, and conflicting opinions. These challenges pose difficulties for deep learning\nmodels, often resulting in the generation of summaries that are the results of hallucination and they often lack faithfulness (Maynez et al., 2020). The development of Large Language Models (LLMs) such as BERT (Devlin et al., 2019), BART (Lewis et al., 2020), and T5 (Raffel et al., 2020) has significantly advanced the field of text summarization. However, generating factually accurate and faithful summaries remains a persistent challenge (OpenAI, 2023).\nRecent studies have focused on enhancing the faithfulness and factuality of summarization models, which is broadly categorized into three types \u2013 (i) post editing models for correcting generated summaries (Fabbri et al., 2022; Balachandran et al., 2022), (ii) using multi-task problems like questionanswering (Durmus et al., 2020; Deutsch et al., 2020), entailment (Roit et al., 2023; Pasunuru and Bansal, 2018) etc., and (iii) using external knowledge (Huang et al., 2020; Mao et al., 2022; Chen and Yang, 2021; Mao et al., 2022; Lyu et al., 2022) to support the model during summary generation. In contrast to these methods, we propose a novel approach that promotes topic coherence and interdocument connections, all without the need for additional parameters, post-editing, external knowledge, or auxiliary tasks.\nAdditionally, capturing semantic connections and multi-level representation can further aid the model in discerning the redundant and pivotal information in multiple documents. Graph neural networks (Scarselli et al., 2009) are constrained in terms of subpar performance in heterophilic settings1 and oversmoothing (Song et al., 2023) when utilized with multi-layer neural networks. To mitigate these concerns, we propose FABRIC2 in which we introduce simplicial complex (Giusti 1In a heterophilic setting, diverse node and edge types can complicate the message-passing process of GNN, therefore affecting its performance.\n2FABRIC: FAirness using BaRt, sImplicial Complex and sheaf\net al., 2022) layer and sheaf graph (Hansen and Gebhart, 2020) attention for multi-document summarization. Simplicial complexes are employed to apprehend the interconnections among diverse elements of the text, encompassing words, phrases, or sentences. By representing these associations as simplices (geometric shapes formed by combining vertices, edges, and higher-dimensional counterparts), a simplicial complex furnishes a structure to examine the connectivity and coherence within the text. On the other hand, sheaf graphs facilitate the assimilation of diverse node types and attributes within the graph structure. Each node can symbolize a specific element, such as a word or a phrase, and convey its own attributes or features. By considering these heterogeneous characteristics, sheaf graphs can apprehend and model the relationships among distinct types of nodes. This empowers FABRIC to comprehend various elements and their relationships, enabling the generation of faithful and accurate summaries.\nMoreover, when dealing with MDS, a critical challenge that neural networks often encounter is processing large documents. Many recent studies have attempted to concatenate multiple documents into a flat sequence and train SDS models on them (Fabbri et al., 2019). However, this approach fails to consider the inter-document relationship and the presence of redundant long input vectors. Even very large language models like Long-T5 (Guo et al., 2021) and BART-4096 (Lewis et al., 2020), which are capable of handling input vectors beyond 2000 tokens, face practical limitations due to the quadratic growth of input memory space. Furthermore, such extensive global attention may exhibit lower performance compared to alternative methods. To address this issue, we propose a novel approach, called topic-assisted document segmentation. It involves using a segment of the document as a context vector, compressing it into an oracle summary while covering major topics, and appending it to the next segment to generate the subsequent context vector. By employing this method, summarization models can learn the representation of the document from a compressed form, overcoming the challenges associated with processing large documents.\nIn short, our contributions are as follows.\n1. We propose a novel topic assisted document segmentation method, which allows any language model to generate contextual vectors for any\ninput length. 2. We propose FABRIC, a novel encoder-decoder\nmodel that uses pre-trained BART to comprehensively analyze linguistic nuances, Simplicial Complex layer to apprehend inherent properties that transcend pairwise associations and sheaf graph attention to more effectively apprehend the heterophilic properties. 3. We evaluate FABRIC using four standard metrics \u2013 ROUGE (Lin, 2004), BARTScore (Yuan et al., 2021), FactCC (Kryscinski et al., 2020), and SummaC (Laban et al., 2022), to assess the quantitative, and qualitative performances and faithfulness. We showcase that FABRIC fares well against eleven widely-popular abstractive baselines. FABRIC beats the best baseline, PRIMERA (Xiao et al., 2022) by +0.34 ROUGE-L on Multinews, +4.90 Rouge-L on CQASumm, +2.94 on DUC and +2.28 RougeL on the Opinosis dataset. Our qualitative analyses on semantic similarity by BARTScore and faithfulness by FactCC and SummaC also show considerable gains compared to the baselinegenerated summaries. We further perform an exhaustive human evaluations and comparison with ChatGPT3 to compare the quality of the system-generated summaries."
        },
        {
            "heading": "2 Related Works",
            "text": "Abstractive summarization. The task of text summarization has seen remarkable improvement with the introduction of attention (Bahdanau et al., 2015) and transformer (Vaswani et al., 2017) based approaches. Later, transformers coupled with content selection (Gehrmann et al., 2018; Atri et al., 2021), attention approximations (Zaheer et al., 2020), windowed and task-oriented attention (Beltagy et al., 2020) were used to improve the performance further. The introduction of LLMs has also shown incredible performance by fine-tuning them over few epochs. LMs such as BERT (Devlin et al., 2019), BART (Lewis et al., 2020), T5 (Raffel et al., 2020), and Pegasus (Zhang et al., 2020) are pre-trained over a vast corpus and later finetuned over the summarization datasets to achieve state-of-the-art results. Reinforcement learning (RL) algorithms have also been leveraged to further improve the performance of the models. In abstractive summarization, Lee and Lee (2017); Pasunuru and Bansal (2018); B\u00f6hm et al. (2019); Atri et al. (2023b) intro-\n3https://openai.com/blog/chatgpt/\nduced the notion of how RL-based models can aid in text summarization. Various reward measures like Rouge-L (Paulus et al., 2017), human feedback (B\u00f6hm et al., 2019) and combination of rewards (Pasunuru and Bansal, 2018) have been used.\nFaithfulness. Existing methods for improving faithfulness include proposing new fact-corrected datasets (Balachandran et al., 2022), ensembling language models (Guo et al., 2022), adversarial techniques (Wu et al., 2022), target correction (Fabbri et al., 2022; Adams et al., 2022; Lee et al., 2022), Natural Language Inference (NLI) models (Laban et al., 2022), rejecting noisy tokens (Cao et al., 2022), controlling irrelevant sentences (Ghoshal et al., 2022), and contrasting candidate generation (Chen et al., 2021). Others use auxiliary information from source documents like additional input (Dou et al., 2021), entity (Zhang et al., 2022), knowledge graphs (Lyu et al., 2022; Huang et al., 2020; Zhao et al., 2021) or RL-based approaches with rewards as entailment feedback (Roit et al., 2023), and structured fact extraction (Zhang et al., 2021). Nevertheless, these methodologies either raise question upon the veracity of the datasets, cull out discordant data points or employ extrinsic data sources to alleviate the factual incongruities. Formulating a new dataset entails substantial costs, and winnowing existing ones might diminish the dataset pool for training a competitive model. In contrast, our proposed approach surmounts these constraints, capitalizing on the entirety of accessible data during training and leveraging the dynamics of simplicial complexes and sheaf graphs to apprehend the inter- and intra-document relationships, thereby engendering exceedingly faithful and factual summaries."
        },
        {
            "heading": "3 Proposed Methodology",
            "text": "We present FABRIC, a novel multi-encoder-decoder model for multi-document abstractive text summarization. Our approach harnesses the power of topic assisted document segments and leverages higher order topological spaces to adeptly extract essential information. Figure 1 shows a schematic diagram of FABRIC. This section explains each component of FABRIC in detail."
        },
        {
            "heading": "3.1 Topic Assisted Document Segments",
            "text": "Transforming the entire document to a contextual vector is very expensive pertaining to the quadratic growth of memory and computations in\nTransformer-based models. LMs like Longformer (Beltagy et al., 2020) are able to process documents in a linear complexity. However, they fail to efficiently capture the context of the whole document. To address this limitation, we propose a new data modelling strategy, called Topic Assisted Document Segmentation with Oracle proxies. At first, the source document D is split into segments D1, D2, D3, . . . , Dn based on major topics identified. We use BERTopic (Grootendorst, 2022) for topical identification. Next, we formulate oracle summaries for segment D1 using an Integer Linear Programming (ILP) solver (Gillick et al., 2008) and penalize it with BERTopic (Grootendorst, 2022) to aid the module in generating oracle summaries and to cover all major topics of the document. We append the oracle summary obtained O1 to the next segment O1 + D1 and formulate the next oracle summary using only O1 + D1. Each generated segment is limited to 768 tokens for BART to process the input vector effectively. Each segment, therefore, obtains an independent encoder representation of the document, which when fused with the other modules, is fed to the BART decoder to generate the final summary."
        },
        {
            "heading": "3.2 Simplicial Complex Layer",
            "text": "Summarizing documents does not always entail information in pairwise connections. Consequently, methods based on single-dimensional graphs fall short in capturing the comprehensive context and its intricate relationships. Conversely, the utilization of a simplicial complex layer enables the incorporation of higher-order graphs, where the inclusion of simplices (vertices within a single-order graph) empowers the modeling of information that extends beyond pairwise associations.\nA simplicial complex is a mathematical structure that represents relationships between different levels of \"simplices.\" A simplex is a generalization of a triangle (2-simplex) to higher dimensions. In the context of summarization, simplicial complexes are used to capture relationships between multiple documents that might not be directly connected, by considering their shared properties or interactions. This approach formulates an exceedingly diverse and extensive feature set, facilitating the model\u2019s ability to comprehend inter-document relations in a more comprehensive and nuanced manner.\nWe use the simplicial complex (SC) layer in the self-attention setting similar to (Giusti et al., 2022).\nMathematically, we define the input to SC layer as SCi and learnable weights asWsc. The transformations are applied to the lower irrotational filter H i, and upper solenoidal filterHs. The transformations are represented by H i = [SCi]iW (i) sc \u2208 RFl+1 , and Hs = [SCi]iW (i) sc \u2208 RFl+1 . The representation H i and Hs are combined for each iteration, and self-attention is computed using the following equations,\ne (u) l,i,j =a (i) l ( h (i) l,p, h (i) l,q ) for j \u2208 N (u)i ,\ne (d) l,i,j = a (s) l ( h (s) l,p , h (s) l,q ) for j \u2208 N (d)i\nThese representations are normalized using the softmax function as \u03b1(u)l = softmaxj(e (u) i ), and \u03b1 (s) l = softmaxj(e (s) l ). The attention weights of the SC layer are computed using,\nZl+1 = \u03c3l(\nJ (d) l\u2211\np=1\n( L\n(d) l )p ZlW (d) l,p + J (u) l\u2211\np=1\n( L\n(u) l )p ZlW (u) l,p\n+ P\u0302lZlW (h,l))\nwhere the coefficients of the upper and lower attentional Laplacians, L(u)l and L (d) l , respectively are\nobtained . The filter weights { W\n(d) l,p } p , { W (u) l,p } p ,\nW (h) l and the attention mechanism parameters a (u) l and a(d)l are learnable parameters, while the order J (d) l and J (u) l of the filters, the number Fl+1 of\noutput signals, and the non-linearity \u03c3l(\u00b7) are hyperparameters to be chosen at each layer. The final representation is passed through a feed-forward layer."
        },
        {
            "heading": "3.3 Sheaf Graph Attention",
            "text": "Similar to graph neural networks (GNNs) (Scarselli et al., 2009) and graph attention networks (GATs) (Velic\u030ckovic\u0301 et al., 2018), the contextual representation of simplicial complex (SC) layer encounters limitations in performance, particularly in heterophilic settings and over-smoothing. Moreover, relying on a single module to capture the interdocument relationship may introduce biases in representing factual knowledge. To overcome this limitation, we introduce a new module, called sheaf graph attention in the MDS setting, taking inspiration from the prior sheaf attention networks (Hansen and Gebhart, 2020).\nA sheaf is a mathematical construct used to associate local data with certain topological spaces. In a sheaf, data are organized in a way that respects the local structures of the underlying space. In the context of graphs, sheaf graphs extend the idea of traditional graph structures by incorporating not only node and edge connections but also the information associated with these connections. In practical terms, sheaf graphs can represent relationships between data points while also encoding additional context or attributes associated with those\nrelationships. This makes them suitable for capturing complex interactions, semantic relationships, and context in various applications, including natural language processing tasks like summarization.\nMathematically, we define the input vector as Xs and introduce the learnable weight matrices Wa and Wb. The identity matrix is denoted by I , and the sheaf Laplacian is represented as \u03c8. We perform a Kronecker product between I and Wa. The sheaf Laplacian \u03c8 is defined as a vector in an undirected graph Gu, where vertices are defined by v and edges by e. Mathematically, it can be expressed as follows:\nSheaf(X) = relu((I \u2212 \u03c8)(I \u2297Wa)XWb (1)\nHere, X is the data transformation block, and \u2297 is Kronecker product."
        },
        {
            "heading": "3.4 Encoder Setting",
            "text": "The first module introduces a document segments via topic guidance, which enables FABRIC to generate multiple target sequence vectors with segmented source documents aided with oracle proxies. The sequence vectors are learned using the BART encoder model. These feature vectors helps the model to understand the linguistic properties and retain multiple context vectors. The second module introduces the simplician complex layer, helping the model to understand the inter-document relations and aiding the weights of the vectors to promote the factualiy and faithfulness. As the feature vector from the SC layer are not same as attention input, the output is passed through a feedforward layer and fused with the multi-head attention module of BART. Finally, the vectors from the sheaf graph attention model also undergo normalization via a feed-forward layer for feature vector normalization, followed by fusion with the heads of the multi-head attention in the BART encoder. The SC layer and sheaf graph contribute to the model\u2019s understanding of inter and intra-document relationships and the weighting of contexts, thereby promoting factual and faithful representations for the decoder generator model."
        },
        {
            "heading": "3.5 Decoder Setting",
            "text": "The amalgamated representation derived from the encoder module of FABRIC, consisting of the BART encoder, SC layer, and sheaf graph attention, is forwarded to the BART decoder module. In this configuration, the BART decoder generates summaries\nutilizing the encoder representation and the pointing mechanism. Much like a pointer generator, the pointing mechanism enables the model to directly copy text from the source document."
        },
        {
            "heading": "4 Datasets",
            "text": "We benchmark our study on four widely popular datasets. (i) Multinews (Fabbri et al., 2019) comprises news articles as source documents and human-written summaries as target summaries. (ii) CQASumm (Chowdhury and Chakraborty, 2019) dataset consists of question-answer pairs, where the accepted answer is used as the target summary and the remaining answers form the source document. (iii) DUC (DUC, 2002) includes news articles as source documents, with target summaries manually annotated by editors. (iv) Opinosis (Ganesan et al., 2010) combines user reviews from various platforms, where individual opinions serve as the source document, while the target summaries are human-annotated."
        },
        {
            "heading": "5 Abstractive Baselines",
            "text": "(i) The Pointer Generator (PG) approach (See et al., 2017) combines attention, and pointing mechanism to apprehend inter-document relationships. (ii) Himap (Fabbri et al., 2019) amalgamates MMR sentence weights in the PG network to emphasize pivotal information in the summary. (iii) Bottomup Transformers (Gehrmann et al., 2018) employ the Transformer architecture (Vaswani et al., 2017) with one random attention head functioning as the copy pointer. (iv) BERT (Devlin et al., 2019) is an encoder-only language model trained using token masking techniques. (v) BART (Lewis et al., 2020) employs an encoder-decoder model trained on the text span masking technique. (vi) T5 (Raffel et al., 2020), akin to BART, is an encoder-decoder-based model that treats all downstream tasks as text-totext problems during training. (vii) LongT5 (Guo et al., 2021) scales the T5 architecture and utilizes sentence masking during pretraining to enrich language generation. (viii) Pegasus (Zhang et al., 2020) adopts an innovative sentence masking technique in the language model to capture sentencelevel representations. (ix) Longformer (Beltagy et al., 2020) incorporates a Transformer with sparse attention to handle elongated sequences.(x) BRIO (Liu et al., 2022) employs a stochastic approach, rather than maximum likelihood, to train the network.(xi) PRIMERA (Xiao et al., 2022) extends\nSystem Multinews CQASumm DUC Opinosis\nR-1 R-2 R-L R-1 R-2 R-L R-1 R-2 R-L R-1 R-2 R-L\nPG 41.85 12.91 20.79 31.09 5.52 21.85 31.43 6.03 23.08 19.65 1.29 20.08 HiMAP 44.17 16.05 24.38 27.13 4.48 19.87 31.44 6.11 23.17 18.02 1.46 19.84 Transfor. 44.32 15.11 28.07 27.52 4.53 21.0 32.14 6.24 23.34 20.46 1.41 21.35 BERT 44.27 16.23 31.41 27.32 4.55 21.14 34.64 6.39 24.18 20.41 4.62 21.84 BART 48.47 18.41 33.21 27.84 4.65 21.74 35.41 6.48 24.67 19.8 6.82 26.87 T5 44.08 16.39 37.68 28.11 3.74 21.45 34.13 6.32 24.13 27.41 6.97 27.41 LongT5 48.17 19.43 38.94 28.74 4.84 22.12 34.58 6.37 24.32 29.46 7.04 28.64 Pegasus 41.79 16.58 39.72 28.24 4.87 22.41 34.61 6.41 24.71 31.28 7.15 29.39 Longfor. 46.89 18.50 41.83 28.01 5.05 23.86 36.31 6.76 27.11 33.32 8.63 30.49 BRIO 47.24 19.34 44.57 29.13 5.12 24.17 37.18 7.02 29.37 31.15 8.52 29.64 PRIMERA 49.90 21.11 46.23 31.54 5.58 26.57 37.84 7.21 31.18 34.64 9.12 33.20\nthe Longformer architecture (Beltagy et al., 2020) by pretraining it on the downstream task."
        },
        {
            "heading": "6 Evaluation Setup",
            "text": "We benchmark FABRIC on the quantitative metrics \u2013 Rouge-1 (R1), Rouge-2 (R2) and Rouge-L (RL) (Lin, 2004), to evaluate the lexical overlap, as well as on qualitative metrics \u2013 BARTScore (Yuan et al., 2021) to compute the semantic overlap, and FactCC (Kryscinski et al., 2020), and SummaC (Laban et al., 2022) for faithfulness assessment."
        },
        {
            "heading": "6.1 Evaluation Metrics",
            "text": "To compare the quality of the summaries, we employ the following evaluation metrics. (i) Rouge computes the lexical overlap between the target and the generated summary. (ii) BARTScore computes the semantic overlap between target and the generated summary using the pre-trained BART (Lewis et al., 2020) LM. (iii) SummaC evaluates the consistency of summary sentences w.r.t the source article, taking into account any inconsistencies that may occur throughout the source text. (iv) FactCC leverages a model trained to assess the consistency between a text/summary and its source article using synthetic data generated through various transformations."
        },
        {
            "heading": "6.2 Human Evaluation Setup",
            "text": "We conducted a human evaluation to assess the qualitative aspects of the summaries generated by FABRIC. The evaluation focused on five parameters \u2013 Informativeness (Inf), Relevance (Rel), Coherence (Coh), Fluency (Flu), and Topic coherence (Topic). To ensure a representative evaluation, we randomly selected 50 test samples from the system-generated summaries and engaged 30 annotators4 with expertise in the evaluation process. To minimize bias, each sample was annotated by at least two annotators, and annotations with a divergence of more than two degrees were excluded to maintain consistency. The assigned scores by the annotators were then averaged for each sample. For additional details, please refer to Appendix B."
        },
        {
            "heading": "7 Experimental Results",
            "text": "We perform quantitative and qualitative evaluation on the four datasets. We benchmark the datasets over eleven baselines and present quantitative and qualitative results."
        },
        {
            "heading": "7.1 Quantitative Evaluation",
            "text": "Table 1 presents the lexical overlap between the various generated summaries and the reference summaries. Our results demonstrate that FABRIC\n4The annotators were linguistics/subject experts and their age ranged between 25-35.\nattains 50.68 R1 and 46.57 RL, beating the best baseline (PRIMERA) by +0.78 R1 and +0.34 RL points. For CQASumm, FABRIC attains 35.81 R1 and 31.47 RL beating PRIMERA by +4.27 R1 and +4.90 RL points. Similarly, for DUC and Opinosis, FABRIC attains 39.64 R1 and 34.12 RL, respectively and 34.12 R1 and 35.48 RL respectively, beating PRIMERA by +1.80 R1, +4.57 R1, +2.94 RL, and +2.28 RL respectively.\nTo demonstrate the effectiveness of each module in FABRIC, we conduct an ablation study. The results of each ablation are presented in Table 1. Our base model, augmented with the simplicial complex (SC) layer, enhances the R1 and RL scores compared to the multinews baseline by +2.89 R1 and +9.14 RL points, respectively. Furthermore, the integration of sheaf graph attention contributes to additional improvements, boosting the performance by +2.66 R1 points and +2.52 RL points. These findings corroborate our hypothesis that language models alone are insufficient to capture interdocument relationships. However, when combined with context captured on higher dimension, they significantly enhance the model\u2019s ability to achieve high performance."
        },
        {
            "heading": "7.2 Qualitative Evaluation",
            "text": "We also conducted a human evaluation to assess the performance of FABRIC. Table 3 presents the results, demonstrating that our model generates high-quality summaries that are redundant, faithful, and easily comprehensible to humans. In addition to the human evaluation, we employed the BARTScore (Yuan et al., 2021), FactCC (Kryscinski et al., 2020), and SummaC (Laban et al., 2022) metrics to evaluate the semantic overlap and faithfulness between the system-generated summaries and the reference summaries.\nTable 2 provides an assessment of the semantic overlap, faithfulness, and factuality of the generated summaries. The results demonstrate a significant improvement in all three qualitative metrics. In terms of semantic overlap, FABRIC achieves a score of \u22121.71 compared to multinews, exhibiting an improvement of +0.02 over the best baseline, PRIMERA. Similarly, for the FactCC and SummaC metrics, FABRIC shows improvements of +0.8 and +1.1, respectively. For the CQASumm dataset, FABRIC achieves a semantic overlap of \u22122.60, a FactCC score of 57.6, and a SummaC score of 54.2, surpassing the best baseline, PRIMERA, by\n+0.02, +0.6, and +0.4 points, respectively. Table 2 summarizes the improvements across all baselines on four datasets. These findings confirm our hypothesis that language models alone are insufficient to comprehend the relationships between multiple entities, necessitating the incorporation of additional modules to ensure the accuracy and coherence of the generated summaries.\nThe quantitative improvements achieved by our model are further supported by human assessments. Table 3 presents the results of these assessments, revealing FABRIC\u2019s consistent performance across all datasets. With the exception of informativeness on the multinews dataset compared to the PRIMERA baseline, FABRIC achieves the highest scores in all metrics on multinews and CQAsumm. This indicates that the generated summaries are highly faithful, relevant, and coherent when compared to the other baselines. Although FABRIC exhibits some shortcomings in terms of informativeness according to the human evaluations, it still outperforms other baselines by a significant margin. A detailed examination of the generated summaries and an analysis of the findings can be found in Section 8."
        },
        {
            "heading": "8 Error Analysis",
            "text": "As indicated in Table 3, significant improvements are observed across all four metrics of human evaluation. The generated summaries successfully capture the essence of the source documents and cover the major topics discussed. For instance, in sample #1 in Table 4, the generated summary not only\ncomprehensively conveys the main incident but also provides additional relevant information. This additional information is captured by the simplicial complex layer and the sheaf graph attention, which pass it on to the decoder for inclusion in the final summary. However, in the case of sample #2, the source document presents the information about the year 1750 as a hypothesis, while another document presents it as a quotation. This discrepancy leads FABRIC to treat this information as definitive and present it as a quoted fact in the summary. This highlights the challenge of properly handling such cases and emphasizes the notion that target summaries and quantitative metrics alone may not suffice as the true performance measure (Li et al., 2021) for the task of abstractive summarization.\n9 FABRIC vs ChatGPT\nWe conducted a comparison between the summaries generated by FABRIC and ChatGPT as shown in Table 4. We randomly generated 50 summaries from the multinews test set for this analysis. When comparing the two, we found that the summaries generated by ChatGPT are often overly general, lacking relevance and informativeness in relation to the source documents. For instance, in sample #1, ChatGPT discusses a general topic that deviates from the main focus by expanding on its own knowledge graph. Although it showcases linguistic capabilities, it fails to align the generated summary with the specific factual information from the source document. Similarly, in sample #2, Chat-\nGPT provides a summary that captures the main idea of the source but neglects to mention important factual details such as the year or any correlations with specific locations. This comparison highlights that general purpose LLMs like ChatGPT have a tendency to focus on linguistic aspects but struggle to ensure fidelity to the factual information and alignment with the original source. As a result, they can be considered unfaithful as they deviate from the source and expand the generated output based on their own knowledge."
        },
        {
            "heading": "10 Conclusion",
            "text": "In this study, we presented FABRIC, a encoderdecoder model designed to enhance topic coherence and inter-document relations for multidocument abstractive summarization. The key components of FABRIC include BART for capturing linguistic aspects and implicial complex Layer and sheaf graph attention for capturing inter-document relationships. We compared FABRIC with eleven baselines on four widely popular MDS datasets. The results consistently demonstrated that FABRIC surpasses existing systems and achieves significant improvements across both quantitative and qualitative measures. These findings were further backed by human evaluation, validating the effectiveness of FABRIC in generating more accurate and faithful summaries that better represent the content of the source document."
        },
        {
            "heading": "11 Acknowledgement",
            "text": "The authors acknowledge the support of ihubAnubhuti-iiitd Foundation at IIIT-Delhi."
        },
        {
            "heading": "12 Limitations",
            "text": "While our study presents promising results for FABRIC in the context of multi-document abstractive summarization, there are certain limitations that should be acknowledged. Firstly, FABRIC demonstrated improvements in both quantitative and qualitative evaluation metrics, the subjective nature of summarization quality makes it challenging to establish a universally agreed-upon standard for evaluation. Secondly, the performance of FABRIC could be influenced by factors such as the size and quality of the training data, hyperparameter tuning, and architectural choices, which should be further investigated. Lastly, the computational complexity and resource requirements of FABRIC should be taken into consideration, as\nthey may limit its practical applicability in certain real-time or resource-constrained settings. Overall, while FABRIC shows promising advancements in multi-document abstractive summarization, further research is needed to address these limitations and extend its applicability to a broader range of scenarios."
        },
        {
            "heading": "13 Ethics Statement",
            "text": "The benchmarked datasets \u2013 Multinews, CQASumm, DUC and Opinosis are available under open-source licenses. The baselines were also covered by the open-source licenses. The human evaluation for the quality assessment of summaries were done by students from academic institute. All experiments were performed over Nvidia A100 (80GB) GPU."
        },
        {
            "heading": "A Appendix",
            "text": "A.1 System Setup/Implementation Details\nFor Multinews and CQASumm , we used the original cleaned corpus and segmented the source doucments as per the top-5 topics coverage. We trained the BERTopic over the source corpus and generated topics later. On average, we segmented the source document into three documents as per the upper limit of BART encoder and number of topics found. For DUC and Opinosis, we used the model trained on the multinews dataset for inference. For modeling, we used PyTorch 1.14 for prototyping. We initially set the learning rate to 0.002, and later warm-up is applied for the first 10000 steps. The model is trained for 8 epochs for multinews and CQASumm."
        },
        {
            "heading": "B Human Evaluation",
            "text": "We evaluate the qualitative aspects of the generated summaries on 5 metrics \u2013 Informativeness, Relevance, Coherence, Fluency, and Topical modeling. We define these metrics as follows: (1) Informativeness: The degree to which a summary provides accurate and comprehensive information about the source text, conveying the main points effectively. (2) Relevance: The extent to which a summary is directly related and applicable to the topic and content of the source text, capturing the key aspects and avoiding irrelevant details. (3) Coherence: The coherence of a summary refers to its logical flow and smooth organization of ideas, ensuring that the sentences and paragraphs are well-connected and cohesive. (4) Fluency: Fluency measures the readability and naturalness of a summary\u2019s language, including grammar, syntax, and smoothness of expression, allowing for easy comprehension and readability. (5) Topical modeling: The overarching subject or theme that the summary focuses on, capturing the main idea and central topic of the source text, while maintaining coherence and relevance in conveying the essential information.\nWe also show few more examples of our proposed FABRIC in Table 5."
        },
        {
            "heading": "C Discussions",
            "text": "Why not use traditional graphs: To benchmark with the traditional graph-based methods, we utilized (Yasunaga et al., 2017) to model the interconnections between the documents. However, when tested, the performance improvement was only seen for the DUC dataset. For Multinews, CQASumm and Opinosis, the performance was inconsistent over the syntactical and semantic metrics. We infer that traditional graph-based approaches struggle to capture nuanced dependencies and higherorder connections between the documents. In contrast, Simplicial Complex and Sheaf Graph capture the underlying semantics and meaning of the documents, not just their surface-level links. It provides a way to incorporate semantic context and relevance into the model, facilitating a more holistic understanding of how information is distributed across the documents.\nHow do Sheaf Graphs improve performance in heterophilic settings and counter oversmoothing: In a heterophilic setting, where nodes have varying degrees of relevance and connections across different subgroups or categories, traditional graph attention mechanisms might struggle to capture diverse relationships effectively. Sheaf graph attention excels in this scenario by allowing for adaptive information flow based on the local structures. Unlike standard graph attention, which computes weights based on node similarities, sheaf graph attention can tailor its attention weights for each context, considering both local and global patterns. This ability to differentiate and adapt to heterophilic relationships enables better representation of information spread across different subgroups, leading to improved performance. Over-smoothing is a common issue in graph neural networks (GNNs), where nodes\u2019 representations become overly similar after multiple graph convolutions, causing loss of discriminative information. Sheaf graph attention mitigates over-smoothing by incorporating higher-order relationships and context-specific attention. Instead of relying solely on aggregating neighbouring nodes\u2019 features, sheaf graph attention considers simplicial structures and focuses on more complex interactions, preventing overemphasis on similar nodes. This allows nodes to maintain their distinct characteristics even after multiple iterations of information propagation."
        }
    ],
    "title": "Promoting Topic Coherence and Inter-Document Consorts in Multi-Document Summarization via Simplicial Complex and Sheaf Graph",
    "year": 2023
}