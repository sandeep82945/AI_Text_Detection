{
    "abstractText": "Despite the striking advances in recent language generation performance, modelgenerated responses have suffered from the chronic problem of hallucinations that are either untrue or unfaithful to a given source. Especially in the task of knowledge grounded conversation, the models are required to generate informative responses, but hallucinated utterances lead to miscommunication. In particular, entity-level hallucination that causes critical misinformation and undesirable conversation is one of the major concerns. To address this issue, we propose a post-hoc refinement method called REM. It aims to enhance the quality and faithfulness of hallucinated utterances by refining them based on the source knowledge. If the generated utterance has a low source-faithfulness score with the given knowledge, REM mines the key entities in the knowledge and implicitly uses them for refining the utterances. We verify that our method reduces entity hallucination in the utterance. Also, we show the adaptability and efficacy of REM with extensive experiments and generative results. Our code is available at https://github.com/YOONNAJANG/REM.",
    "authors": [
        {
            "affiliations": [],
            "name": "Yoonna Jang"
        },
        {
            "affiliations": [],
            "name": "Suhyune Son"
        },
        {
            "affiliations": [],
            "name": "Jeongwoo Lee"
        },
        {
            "affiliations": [],
            "name": "Junyoung Son"
        },
        {
            "affiliations": [],
            "name": "Yuna Hur"
        },
        {
            "affiliations": [],
            "name": "Jungwoo Lim"
        },
        {
            "affiliations": [],
            "name": "Hyeonseok Moon"
        },
        {
            "affiliations": [],
            "name": "Kisu Yang"
        },
        {
            "affiliations": [],
            "name": "Heuiseok Lim"
        }
    ],
    "id": "SP:a80a68f0be3a8eec3b17e3934b3b6e1eab8b8541",
    "references": [
        {
            "authors": [
                "Leonard Adolphs",
                "Kurt Shuster",
                "Jack Urbanek",
                "Arthur Szlam",
                "Jason Weston."
            ],
            "title": "Reason first, then respond: Modular generation for knowledge-infused dialogue",
            "venue": "arXiv preprint arXiv:2111.05204.",
            "year": 2021
        },
        {
            "authors": [
                "Guangsheng Bao",
                "Yue Zhang."
            ],
            "title": "A general contextualized rewriting framework for text summarization",
            "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing.",
            "year": 2023
        },
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are few-shot learners. Advances in neural information processing",
            "year": 2020
        },
        {
            "authors": [
                "Yu Cao",
                "Wei Bi",
                "Meng Fang",
                "Shuming Shi",
                "Dacheng Tao."
            ],
            "title": "A model-agnostic data manipulation method for persona-based dialogue generation",
            "venue": "arXiv preprint arXiv:2204.09867.",
            "year": 2022
        },
        {
            "authors": [
                "Javier Gonz\u00e1lez Corbelle",
                "Alberto Bugar\u00edn Diz",
                "Jose Alonso-Moral",
                "Juan Taboada."
            ],
            "title": "Dealing with hallucination and omission in neural natural language generation: A use case on meteorology",
            "venue": "Proceedings of the 15th International Conference on",
            "year": 2022
        },
        {
            "authors": [
                "Souvik Das",
                "Sougata Saha",
                "Rohini K Srihari."
            ],
            "title": "Diving deep into modes of fact hallucinations in dialogue systems",
            "venue": "arXiv preprint arXiv:2301.04449.",
            "year": 2023
        },
        {
            "authors": [
                "Emily Dinan",
                "Stephen Roller",
                "Kurt Shuster",
                "Angela Fan",
                "Michael Auli",
                "Jason Weston."
            ],
            "title": "Wizard of wikipedia: Knowledge-powered conversational agents",
            "venue": "arXiv preprint arXiv:1811.01241.",
            "year": 2018
        },
        {
            "authors": [
                "Yao Dou",
                "Maxwell Forbes",
                "Rik Koncel-Kedziorski",
                "Noah A Smith",
                "Yejin Choi."
            ],
            "title": "Is gpt-3 text indistinguishable from human text? scarecrow: A framework for scrutinizing machine text",
            "venue": "Proceedings of the 60th Annual Meeting of the Associa-",
            "year": 2022
        },
        {
            "authors": [
                "Nouha Dziri",
                "Ehsan Kamalloo",
                "Sivan Milton",
                "Osmar Zaiane",
                "Mo Yu",
                "Edoardo M Ponti",
                "Siva Reddy"
            ],
            "title": "Faithdial: A faithful benchmark",
            "year": 2022
        },
        {
            "authors": [
                "Nouha Dziri",
                "Andrea Madotto",
                "Osmar Zaiane",
                "Avishek Joey Bose."
            ],
            "title": "Neural path hunter: Reducing hallucination in dialogue systems via path grounding",
            "venue": "arXiv preprint arXiv:2104.08455.",
            "year": 2021
        },
        {
            "authors": [
                "Nouha Dziri",
                "Sivan Milton",
                "Mo Yu",
                "Osmar Zaiane",
                "Siva Reddy"
            ],
            "title": "On the origin of hallucinations in conversational models: Is it the datasets or the models? arXiv preprint arXiv:2204.07931",
            "year": 2022
        },
        {
            "authors": [
                "Nouha Dziri",
                "Hannah Rashkin",
                "Tal Linzen",
                "David Reitter."
            ],
            "title": "Evaluating groundedness in dialogue systems: The begin benchmark",
            "venue": "arXiv preprint arXiv:2105.00071.",
            "year": 2021
        },
        {
            "authors": [
                "Jiazhan Feng",
                "Chongyang Tao",
                "Xueliang Zhao",
                "Dongyan Zhao."
            ],
            "title": "Learning multi-turn response selection in grounded dialogues with reinforced knowledge and context distillation",
            "venue": "ACM Transactions on Information Systems, 41(4):1\u201327.",
            "year": 2023
        },
        {
            "authors": [
                "Xinwei Geng",
                "Xiaocheng Feng",
                "Bing Qin."
            ],
            "title": "Learning to rewrite for non-autoregressive neural machine translation",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 3297\u20133308.",
            "year": 2021
        },
        {
            "authors": [
                "Karthik Gopalakrishnan",
                "Behnam Hedayatnia",
                "Qinlang Chen",
                "Anna Gottardi",
                "Sanjeev Kwatra",
                "Anu Venkatesh",
                "Raefer Gabriel",
                "Dilek Hakkani-T\u00fcr."
            ],
            "title": "Topical-chat: Towards knowledge-grounded open-domain conversations",
            "venue": "Proc. Interspeech 2019,",
            "year": 2019
        },
        {
            "authors": [
                "Tanya Goyal",
                "Greg Durrett."
            ],
            "title": "Evaluating factuality in generation with dependency-level entailment",
            "venue": "arXiv preprint arXiv:2010.05478.",
            "year": 2020
        },
        {
            "authors": [
                "Xingwei He."
            ],
            "title": "Parallel refinements for lexically constrained text generation with bart",
            "venue": "arXiv preprint arXiv:2109.12487.",
            "year": 2021
        },
        {
            "authors": [
                "Yoonna Jang",
                "Jungwoo Lim",
                "Yuna Hur",
                "Dongsuk Oh",
                "Suhyune Son",
                "Yeonsoo Lee",
                "Donghoon Shin",
                "Seungryong Kim",
                "Heuiseok Lim."
            ],
            "title": "Call for customized conversation: Customized conversation grounding persona and knowledge",
            "venue": "Proceedings",
            "year": 2022
        },
        {
            "authors": [
                "Ziwei Ji",
                "Nayeon Lee",
                "Rita Frieske",
                "Tiezheng Yu",
                "Dan Su",
                "Yan Xu",
                "Etsuko Ishii",
                "Ye Jin Bang",
                "Andrea Madotto",
                "Pascale Fung."
            ],
            "title": "Survey of hallucination in natural language generation",
            "venue": "ACM Computing Surveys, 55(12):1\u201338.",
            "year": 2023
        },
        {
            "authors": [
                "Tomohito Kasahara",
                "Daisuke Kawahara",
                "Nguyen Tung",
                "Shengzhe Li",
                "Kenta Shinzato",
                "Toshinori Sato."
            ],
            "title": "Building a personalized dialogue system with prompt-tuning",
            "venue": "arXiv preprint arXiv:2206.05399.",
            "year": 2022
        },
        {
            "authors": [
                "Sihyung Kim",
                "Oh-Woog Kwon",
                "Harksoo Kim."
            ],
            "title": "Knowledge-grounded chatbot based on dual wasserstein generative adversarial networks with effective attention mechanisms",
            "venue": "Applied Sciences, 10(9):3335.",
            "year": 2020
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdelrahman Mohamed",
                "Omer Levy",
                "Veselin Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "2020a. Bart: Denoising sequence-to-sequence pre-training for natural language",
            "year": 2020
        },
        {
            "authors": [
                "Patrick Lewis",
                "Ethan Perez",
                "Aleksandra Piktus",
                "Fabio Petroni",
                "Vladimir Karpukhin",
                "Naman Goyal",
                "Heinrich K\u00fcttler",
                "Mike Lewis",
                "Wen-tau Yih",
                "Tim Rockt\u00e4schel"
            ],
            "title": "2020b. Retrieval-augmented generation for knowledge-intensive nlp tasks",
            "year": 2020
        },
        {
            "authors": [
                "Jiwei Li",
                "Michel Galley",
                "Chris Brockett",
                "Jianfeng Gao",
                "Bill Dolan."
            ],
            "title": "A diversity-promoting objective function for neural conversation models",
            "venue": "arXiv preprint arXiv:1510.03055.",
            "year": 2015
        },
        {
            "authors": [
                "Wei Li",
                "Wenhao Wu",
                "Moye Chen",
                "Jiachen Liu",
                "Xinyan Xiao",
                "Hua Wu."
            ],
            "title": "Faithfulness in natural language generation: A systematic survey of analysis, evaluation and optimization methods",
            "venue": "arXiv preprint arXiv:2203.05227.",
            "year": 2022
        },
        {
            "authors": [
                "Yanyang Li",
                "Jianqiao Zhao",
                "Michael R Lyu",
                "Liwei Wang."
            ],
            "title": "Eliciting knowledge from large pre-trained models for unsupervised knowledge-grounded conversation",
            "venue": "arXiv preprint arXiv:2211.01587.",
            "year": 2022
        },
        {
            "authors": [
                "Yu Li",
                "Baolin Peng",
                "Yelong Shen",
                "Yi Mao",
                "Lars Liden",
                "Zhou Yu",
                "Jianfeng Gao."
            ],
            "title": "Knowledgegrounded dialogue generation with a unified knowledge representation",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the",
            "year": 2022
        },
        {
            "authors": [
                "Zekang Li",
                "Cheng Niu",
                "Fandong Meng",
                "Yang Feng",
                "Qian Li",
                "Jie Zhou."
            ],
            "title": "Incremental transformer with deliberation decoder for document grounded conversations",
            "venue": "arXiv preprint arXiv:1907.08854.",
            "year": 2019
        },
        {
            "authors": [
                "Jungwoo Lim",
                "Myugnhoon Kang",
                "Yuna Hur",
                "Seung Won Jeong",
                "Jinsung Kim",
                "Yoonna Jang",
                "Dongyub Lee",
                "Hyesung Ji",
                "DongHoon Shin",
                "Seungryong Kim"
            ],
            "title": "You truly understand what i need: Intellectual and friendly dialog agents",
            "year": 2022
        },
        {
            "authors": [
                "Chin-Yew Lin."
            ],
            "title": "Rouge: A package for automatic evaluation of summaries",
            "venue": "Text summarization branches out, pages 74\u201381.",
            "year": 2004
        },
        {
            "authors": [
                "Qi Liu",
                "Dani Yogatama",
                "Phil Blunsom."
            ],
            "title": "Relational memory-augmented language models",
            "venue": "Transactions of the Association for Computational Linguistics, 10:555\u2013572.",
            "year": 2022
        },
        {
            "authors": [
                "Ilya Loshchilov",
                "Frank Hutter."
            ],
            "title": "Decoupled weight decay regularization",
            "venue": "arXiv preprint arXiv:1711.05101.",
            "year": 2017
        },
        {
            "authors": [
                "Longxuan Ma",
                "Wei-Nan Zhang",
                "Mingda Li",
                "Ting Liu."
            ],
            "title": "A survey of document grounded dialogue systems (dgds)",
            "venue": "arXiv preprint arXiv:2004.13818.",
            "year": 2020
        },
        {
            "authors": [
                "Potsawee Manakul",
                "Adian Liusie",
                "Mark JF Gales."
            ],
            "title": "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models",
            "venue": "arXiv preprint arXiv:2303.08896.",
            "year": 2023
        },
        {
            "authors": [
                "Seungwhan Moon",
                "Pararth Shah",
                "Anuj Kumar",
                "Rajen Subba."
            ],
            "title": "Opendialkg: Explainable conversational reasoning with attention-based walks over knowledge graphs",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational",
            "year": 2019
        },
        {
            "authors": [
                "Feng Nan",
                "Ramesh Nallapati",
                "Zhiguo Wang",
                "Cicero dos Santos",
                "Henghui Zhu",
                "Dejiao Zhang",
                "Kathleen Mckeown",
                "Bing Xiang."
            ],
            "title": "Entity-level 2023tency of abstractive text summarization",
            "venue": "Proceedings of the 16th Conference of the European Chapter of",
            "year": 2021
        },
        {
            "authors": [
                "Chenxu Niu",
                "Yue Hu",
                "Wei Peng",
                "Yuqiang Xie."
            ],
            "title": "Learning to balance the global coherence and informativeness in knowledge-grounded dialogue generation",
            "venue": "ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing",
            "year": 2023
        },
        {
            "authors": [
                "Adam Paszke",
                "Sam Gross",
                "Francisco Massa",
                "Adam Lerer",
                "James Bradbury",
                "Gregory Chanan",
                "Trevor Killeen",
                "Zeming Lin",
                "Natalia Gimelshein",
                "Luca Antiga"
            ],
            "title": "Pytorch: An imperative style, high-performance deep learning library",
            "year": 2019
        },
        {
            "authors": [
                "Fabio Petroni",
                "Aleksandra Piktus",
                "Angela Fan",
                "Patrick Lewis",
                "Majid Yazdani",
                "Nicola De Cao",
                "James Thorne",
                "Yacine Jernite",
                "Vladimir Karpukhin",
                "Jean Maillard"
            ],
            "title": "Kilt: a benchmark for knowledge intensive language tasks",
            "year": 2021
        },
        {
            "authors": [
                "Maja Popovi\u0107."
            ],
            "title": "chrf: character n-gram f-score for automatic mt evaluation",
            "venue": "Proceedings of the tenth workshop on statistical machine translation, pages 392\u2013395.",
            "year": 2015
        },
        {
            "authors": [
                "Pavel Posokhov",
                "Kirill Apanasovich",
                "Anastasia Matveeva",
                "Olesia Makhnytkina",
                "Anton Matveev."
            ],
            "title": "Personalizing dialogue agents for russian: Retrieve and refine",
            "venue": "2022 31st Conference of Open Innovations Association (FRUCT), pages",
            "year": 2022
        },
        {
            "authors": [
                "Matt Post."
            ],
            "title": "A call for clarity in reporting bleu scores",
            "venue": "arXiv preprint arXiv:1804.08771.",
            "year": 2018
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J Liu."
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "Journal of Machine Learning Research, 21:1\u2013",
            "year": 2020
        },
        {
            "authors": [
                "Stefan Schweter",
                "Alan Akbik"
            ],
            "title": "FLERT: Document-level features for named entity recognition",
            "year": 2020
        },
        {
            "authors": [
                "Xiaoyu Shen",
                "Hui Su",
                "Shuzi Niu",
                "Vera Demberg."
            ],
            "title": "Improving variational encoder-decoders in dialogue generation",
            "venue": "Proceedings of the AAAI conference on artificial intelligence, volume 32.",
            "year": 2018
        },
        {
            "authors": [
                "Kurt Shuster",
                "Mojtaba Komeili",
                "Leonard Adolphs",
                "Stephen Roller",
                "Arthur Szlam",
                "Jason Weston."
            ],
            "title": "Language models that seek for knowledge: Modular search & generation for dialogue and prompt completion",
            "venue": "Findings of the Association for",
            "year": 2022
        },
        {
            "authors": [
                "Kurt Shuster",
                "Spencer Poff",
                "Moya Chen",
                "Douwe Kiela",
                "Jason Weston."
            ],
            "title": "Retrieval augmentation reduces hallucination in conversation",
            "venue": "arXiv preprint arXiv:2104.07567.",
            "year": 2021
        },
        {
            "authors": [
                "Kurt Shuster",
                "Jing Xu",
                "Mojtaba Komeili",
                "Da Ju",
                "Eric Michael Smith",
                "Stephen Roller",
                "Megan Ung",
                "Moya Chen",
                "Kushal Arora",
                "Joshua Lane"
            ],
            "title": "Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage",
            "year": 2022
        },
        {
            "authors": [
                "Leandro Silva",
                "Mainack Mondal",
                "Denzil Correa",
                "Fabr\u00edcio Benevenuto",
                "Ingmar Weber."
            ],
            "title": "Analyzing the targets of hate in online social media",
            "venue": "Tenth international AAAI conference on web and social media.",
            "year": 2016
        },
        {
            "authors": [
                "Haoyu Song",
                "Yan Wang",
                "Wei-Nan Zhang",
                "Xiaojiang Liu",
                "Ting Liu."
            ],
            "title": "Generate, delete and rewrite: A three-stage framework for improving persona consistency of dialogue generation",
            "venue": "arXiv preprint arXiv:2004.07672.",
            "year": 2020
        },
        {
            "authors": [
                "Qingfeng Sun",
                "Can Xu",
                "Huang Hu",
                "Yujing Wang",
                "Jian Miao",
                "Xiubo Geng",
                "Yining Chen",
                "Fei Xu",
                "Daxin Jiang."
            ],
            "title": "Stylized knowledge-grounded dialogue generation via disentangled template rewriting",
            "venue": "Proceedings of the 2022 Conference of the North",
            "year": 2022
        },
        {
            "authors": [
                "Weiwei Sun",
                "Pengjie Ren",
                "Zhaochun Ren."
            ],
            "title": "Generative knowledge selection for knowledgegrounded dialogues",
            "venue": "Findings of the Association for Computational Linguistics: EACL 2023, pages 2032\u20132043.",
            "year": 2023
        },
        {
            "authors": [
                "Romal Thoppilan",
                "Daniel De Freitas",
                "Jamie Hall",
                "Noam Shazeer",
                "Apoorv Kulshreshtha",
                "Heng-Tze Cheng",
                "Alicia Jin",
                "Taylor Bos",
                "Leslie Baker",
                "Yu Du"
            ],
            "title": "Lamda: Language models for dialog applications",
            "venue": "arXiv preprint arXiv:2201.08239",
            "year": 2022
        },
        {
            "authors": [
                "Hugo Touvron",
                "Thibaut Lavril",
                "Gautier Izacard",
                "Xavier Martinet",
                "Marie-Anne Lachaux",
                "Timoth\u00e9e Lacroix",
                "Baptiste Rozi\u00e8re",
                "Naman Goyal",
                "Eric Hambro",
                "Faisal Azhar"
            ],
            "title": "Llama: Open and efficient foundation language models",
            "year": 2023
        },
        {
            "authors": [
                "Van-Khanh Tran",
                "Le-Minh Nguyen."
            ],
            "title": "Semantic refinement gru-based neural language generation for spoken dialogue systems",
            "venue": "Computational Linguistics: 15th International Conference of the Pacific Association for Computational Linguistics, PACLING",
            "year": 2018
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems, 30.",
            "year": 2017
        },
        {
            "authors": [
                "Weichao Wang",
                "Wei Gao",
                "Shi Feng",
                "Ling Chen",
                "Daling Wang."
            ],
            "title": "Adaptive posterior knowledge selection for improving knowledge-grounded dialogue generation",
            "venue": "Proceedings of the 30th ACM International Conference on Information & Knowledge",
            "year": 2021
        },
        {
            "authors": [
                "Yihe Wang",
                "Yitong Li",
                "Yasheng Wang",
                "Fei Mi",
                "Pingyi Zhou",
                "Xin Wang",
                "Jin Liu",
                "Xin Jiang",
                "Qun Liu."
            ],
            "title": "Pan more gold from the sand: Refining opendomain dialogue training with noisy self-retrieval generation",
            "venue": "arXiv preprint arXiv:2201.11367.",
            "year": 2022
        },
        {
            "authors": [
                "Jason Weston",
                "Emily Dinan",
                "Alexander H Miller."
            ],
            "title": "Retrieve and refine: Improved sequence generation models for dialogue",
            "venue": "arXiv preprint arXiv:1808.04776.",
            "year": 2018
        },
        {
            "authors": [
                "Thomas Wolf",
                "Lysandre Debut",
                "Victor Sanh",
                "Julien Chaumond",
                "Clement Delangue",
                "Anthony Moi",
                "Pierric Cistac",
                "Tim Rault",
                "R\u00e9mi Louf",
                "Morgan Funtowicz"
            ],
            "title": "Huggingface\u2019s transformers: State-ofthe-art natural language processing",
            "year": 2019
        },
        {
            "authors": [
                "Chaojun Xiao",
                "Zhengyan Zhang",
                "Xu Han",
                "Chi-Min Chan",
                "Yankai Lin",
                "Zhiyuan Liu",
                "Xiangyang Li",
                "Zhonghua Li",
                "Zhao Cao",
                "Maosong Sun."
            ],
            "title": "Plug-and-play document modules for pre-trained models",
            "venue": "arXiv preprint arXiv:2305.17660.",
            "year": 2023
        },
        {
            "authors": [
                "Wenhao Yu",
                "Chenguang Zhu",
                "Zaitang Li",
                "Zhiting Hu",
                "Qingyun Wang",
                "Heng Ji",
                "Meng Jiang."
            ],
            "title": "A survey of knowledge-enhanced text generation",
            "venue": "ACM Computing Surveys, 54(11s):1\u201338.",
            "year": 2022
        },
        {
            "authors": [
                "Yeqin Zhang",
                "Haomin Fu",
                "Cheng Fu",
                "Haiyang Yu",
                "Yongbin Li",
                "Cam-Tu Nguyen."
            ],
            "title": "Coarse-to-fine knowledge selection for document grounded dialogs",
            "venue": "ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing",
            "year": 2023
        },
        {
            "authors": [
                "Zhihan Zhang",
                "Wenhao Yu",
                "Chenguang Zhu",
                "Meng Jiang."
            ],
            "title": "A unified encoder-decoder framework with entity memory",
            "venue": "arXiv preprint arXiv:2210.03273.",
            "year": 2022
        },
        {
            "authors": [
                "Xueliang Zhao",
                "Tingchen Fu",
                "Chongyang Tao",
                "Wei Wu",
                "Dongyan Zhao",
                "Rui Yan."
            ],
            "title": "Learning to express in knowledge-grounded conversation",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational",
            "year": 2022
        },
        {
            "authors": [
                "Hanxun Zhong",
                "Zhicheng Dou",
                "Yutao Zhu",
                "Hongjin Qian",
                "Ji-Rong Wen."
            ],
            "title": "Less is more: Learning to refine dialogue history for personalized dialogue generation",
            "venue": "arXiv preprint arXiv:2204.08128.",
            "year": 2022
        },
        {
            "authors": [
                "Kangyan Zhou",
                "Shrimai Prabhumoye",
                "Alan W Black."
            ],
            "title": "A dataset for document grounded conversations",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 708\u2013713.",
            "year": 2018
        },
        {
            "authors": [
                "CMUDoG (Zhou"
            ],
            "title": "2018) is a knowledge grounded conversation dataset with two speakers conversing based on movie Wikipedia articles. Unlike the WoW and FoCus, where only one of the two speakers",
            "year": 2018
        },
        {
            "authors": [],
            "title": "SuperHero Maleficent is a 2014 American dark fantasy film directed by Robert",
            "year": 2014
        },
        {
            "authors": [
                "Angelina Jolie",
                "Sharito Copley",
                "Elle Fanning",
                "Sam Riley",
                "Imelda Staunton"
            ],
            "title": "REMbase : movie we\u2019re talking about is Maleficent. Have you seen it? It\u2019s a fantasy",
            "year": 2014
        },
        {
            "authors": [
                "Abagnale"
            ],
            "title": "Catch me if you can Rotten Tomatoes: 96% and average: 7.9/10 Metacritic Score: 76/100",
            "venue": "CinemaScore: A-",
            "year": 2002
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "The knowledge grounded conversation (KGC; also called knowledge grounded conversation, KGD), which is a subfield of the dialogue systems, is a task of generating human-like utterances by referring to specialized knowledge such as Wikipedia1 (Zhao et al., 2022; Li et al., 2022c). The KGC task requires the ability to generate fluent and informative utterances based on source knowledge. Considering this ability, there has been numerous concurrent research on the KGC to build models that can have conversations with human-like expertise (Ma et al.,\n\u2217These authors contributed equally to this work. \u2020Corresponding author.\n1https://www.wikipedia.org/\n2020; Yu et al., 2022; Shuster et al., 2022a; Liu et al., 2022; Sun et al., 2023; Xiao et al., 2023).\nA colossal number of training corpora and parameters have brought the recent explosion of language generation performance in pre-trained language models (PLMs) (Brown et al., 2020; Raffel et al., 2020) and large language models (LLMs) (Thoppilan et al., 2022; Touvron et al., 2023; OpenAI, 2023). However, hallucination, which has been a chronic problem in natural language generation, is still cited as one of the biggest challenges remaining unsolved (Ji et al., 2023). In the KGC task, even though the ground truth knowledge is given, the models make the error of generating hallucinated utterances not faithful to the source knowledge (Li et al., 2022a; Ji et al., 2023).\nEspecially, entity-level hallucination, generating\nnames of entities that are incorrect or not present in the source document (Nan et al., 2021), causes critical misinformation and jeopardizes the flow of the conversation (Das et al., 2023). As shown in Case 1 of Figure 1, the previous KGC models generate the utterance containing information about the wrong entity, which is not given in the knowledge. Further, the generated utterance is excessively general while not considering sufficient entities that align with the context of the conversation, as shown in Case 2. These deficiencies can undermine the helpfulness of AI conversational models. Though previous research has tried to mitigate them in general domain conversation (Shuster et al., 2021), research to address the entity-level hallucination in KGC remains in dark (Zhang et al., 2022).\nTo address these entity-level hallucination problems, we propose a post-hoc utterance refining method by entity mining, called REM, for more desirable and source-faithful KGC. REM can be used to refine the unfaithful utterances generated by previous models in a plug-and-play manner. To refine utterances, we leverage the entity mining method, which extracts the named entities to implicitly utilize key information in the knowledge in a multi-tasking manner. With this simple but effective method, REM aims to mitigate entity-level hallucination and lead to a more successful conversation.\nIn order to measure the effectiveness of REM, we conduct an extensive empirical evaluation. First, to demonstrate the post-hoc refining ability of REM, we experiment with refining the utterances generated by baseline models on three KGC datasets. We investigate the flexibility and validity of REM with cross-data experiments and adversarial data refining experiments, respectively. In addition, we conduct an ablation study and human evaluation to verify the effectiveness of our method, showing the improvement of the sourcefaithfulness score and entity coverage of refined utterances. We also demonstrate the scalability of REM by applying it to large language models. From a case study comparing the refined results of REM and baseline utterance, we demonstrate that our REM model improves the source-faithfulness in the utterances.\nOur contributions are threefold: (1) We propose a post-hoc refining method by implicitly mining key entities in the knowledge for more source-faithful conversation; (2) We show that our simple but ef-\nfective method is adaptable to the existing models, including large language models, in a plug-andplay manner; (3) We substantiate that our method reduces entity-level hallucination and accomplish more desirable knowledge grounded conversation with diverse experiments."
        },
        {
            "heading": "2 Related Work",
            "text": ""
        },
        {
            "heading": "2.1 Knowledge Grounded Conversation",
            "text": "In the task of knowledge grounded conversation (KGC), the systems aim to generate an informative conversation based on specialized knowledge. To support research in this area, publicly available datasets for the KGC task have been developed (Gopalakrishnan et al., 2019; Moon et al., 2019; Shuster et al., 2022b). These datasets focus particularly on generating informative conversations on specific topics (Dinan et al., 2018; Zhou et al., 2018; Jang et al., 2022). Building upon these KGC datasets, there has been active research to generate contextually consistent utterances while utilizing the source knowledge. Kim et al. (2020); Adolphs et al. (2021); Wang et al. (2021); Zhang et al. (2023); Feng et al. (2023) incorporate knowledge and context selectors to filter out irrelevant knowledge sentences and redundant dialogue history, respectively. Additionally, (Niu et al., 2023) propose the history-adapted knowledge copy (HAKC) network, which selectively chooses context-aware knowledge to maintain dialogue coherence. Likewise, diverse research is widely conducted in KGC tasks."
        },
        {
            "heading": "2.2 Knowledge Hallucination in KGC",
            "text": "Despite the remarkable advancements, KGC systems are known to suffer from knowledge hallucination generating unfaithful utterances to source knowledge (Dziri et al., 2021b). To address hallucination, Shuster et al. (2021) propose neural-retrieval-in-the-loop architectures to improve knowledge-ability consisting of retrievers, rankers, and encoder-decoders. Additionally, Li et al. (2022b) proposes a method that utilizes entity and relation information from a knowledge graph to generate more faithful utterances. However, in KGC, there is a lack of studies on entity-level hallucination, which directly identifies and controls the generation of unfaithful utterances (Das et al., 2023). Although Dziri et al. (2021a) explore the study on entity-level hallucination, this study only considers cases where the source of knowledge is\na knowledge graph. Therefore, there is a need for research on entity-level hallucination in KGC tasks where the source knowledge is provided."
        },
        {
            "heading": "2.3 Utterance Refining Methods",
            "text": "Refining methods have been studied to improve the generation results when they are not satisfactory or not in the desired intention. (He, 2021; Geng et al., 2021; Sun et al., 2022; Bao and Zhang, 2023) Especially in dialogue systems, the researches aim to improve the quality of response by applying the refining method have been proposed (Tran and Nguyen, 2018; Posokhov et al., 2022; Wang et al., 2022). To tackle the limitation of generating uninformative or not engaging utterances (Shen et al., 2018), Weston et al. (2018) retrieves the utterance and refines it by regenerating the retrieved utterance. Moreover, for fascinating dialogue systems, the ability to generate personalized responses according to the user\u2019s dialogue history is required (Cao et al., 2022). However, as history is usually long and noisy, the problem of missing personalized information exists (Kasahara et al., 2022). To address this problem, Zhong et al. (2022) refines the user dialogue history to extract valuable information. Furthermore, they generate personalized dialogue by utilizing refined history information. Also, Song et al. (2020) adopts a rewriting method for personaconsistent dialogue generation. In this study, our goal is to reduce entity-level hallucination, which is critical in informative conversation (Corbelle et al., 2022), with the refining method."
        },
        {
            "heading": "3 Proposed Method",
            "text": "Our proposed REM aims to refine the modelgenerated utterance to be more faithful to the source knowledge, as shown in Figure 3. The utterance is filtered by the faithfulness scoring function, whether to be refined or not. We train the pretrained language model with an encoder-decoder structure in the REM method. In the REM model, the entity miner extracts the named entities from the source knowledge and learns them implicitly. The utterance generator makes more faithful utterances based on the key information extracted by the entity miner. In this section, we formulate a KGC task and our proposed utterance refining method, and describe the REM model and its training process."
        },
        {
            "heading": "3.1 Knowledge Grounded Conversation",
            "text": "As depicted in Figure 2 (a), the KGC models generate the informative utterance u\u0302 considering both the conversational context (or dialogue history) c and the corresponding source knowledge k as follows:\np\u03b8(u\u0302|k, c) = n\u220f t=1 p\u03b8(u\u0302t|u\u0302<t,k, c), (1)\nwhere n indicates the max sequence length of the utterance, and \u03b8 denotes the KGC model parameter."
        },
        {
            "heading": "3.2 Post-hoc Utterance Refining",
            "text": "While KGC models aim to generate informative utterances, model-generated utterance u\u0302 may not reflect the input source knowledge faithfully, as shown in Figure 1. In this context, we first filter out the utterance which is not faithful to the source. Then we renovate the given utterance into the refined utterance u\u0303 which represents the intended knowledge better by utilizing the model-generated utterance u\u0302 and its corresponding knowledge k from KGC models as follows:\np\u03c8(u\u0303|k, u\u0302) = n\u220f t=1 p\u03c8(u\u0303t|u\u0303<t,k, u\u0302), (2)\nwhere \u03c8 denotes the REM model parameter.\nFaithfulness Filtering To filter the modelgenerated utterance u\u0302, we quantify the sourcefaithfulness score, which indicates how u\u0302 is consistent with the source knowledge k. To this end, we adopt the DAE (Goyal and Durrett, 2020) as\na scoring function to estimate the entailment between the source knowledge and u\u0302 considering the dependency arc-level consistency of the utterance.\nFor efficiency, we only refine the utterances that have lower scores than the threshold according to the source-faithfulness score, as follows:\nu\u0303 = { REM(k, u\u0302) : if score(k, u\u0302) < \u03c4 u\u0302 : otherwise,\n(3)\nwhere score(\u00b7) denotes the scoring function (i.e., DAE) and \u03c4 is a threshold value between 0 and 1. When \u03c4 is 1, all utterances are re-generated as u\u0303; otherwise, when \u03c4 is 0, all utterances are not refined. We utilize this filtering module only in the inference step, not in the training step.\nRefining Utterance by Entity Mining (REM) Our refining method, REM, is decomposed into two sub-modules that are (i) entity miner and (ii) utterance generator, as shown in Figure 2. The refining task is formulated as follows:\np\u03c8(u\u0303|k, u\u0302) \u221d p\u03c8(e|k, u\u0302)\ufe38 \ufe37\ufe37 \ufe38 Entity miner p\u03c8(u\u0303|e,k, u\u0302)\ufe38 \ufe37\ufe37 \ufe38 Utterance generator (4)\nThese two modules are trained in a multi-tasking manner with parameter \u03c8. The former mines entities e from source knowledge and learns entitylevel knowledge implicitly. The latter learns to generate the utterance u with the implicitly mined entities, which is key information of source knowledge,\nreducing entity-level hallucinations and producing more source-faithful utterances."
        },
        {
            "heading": "3.3 Training Objectives",
            "text": "The training objective of REM mainly falls into named entity recognition (NER) by entity miner and utterance re-generation (GEN) by utterance generator.\nTo predict the named entities, the NER head is attached on top of the encoder and mines the entities inside the knowledge k. It makes the model learn the essential entity information, enhancing the interpretation of the source knowledge. To train NER, we tag named entities with one of the following entity types {\u2018LOC\u2019,\u2018PER\u2019,\u2018ORG\u2019, \u2018MISC\u2019} using the off-the-shelf entity tagging module2 for the source knowledge in the data.\nThe NER loss LNER is only defined for the NER label li tagged for each token ki in k and minimized during training as follows:\nLNER = \u2212 1\nNk Nk\u2211 i=1 li log p(ki|u\u0302), (5)\nwhere Nk denotes the token length of the source knowledge.\nThe language modeling head (GEN) learns to refine the given model-generated utterance u\u0302 along with k in an auto-regressive manner while extracting entities e. The model learns to compose the information of the inputs and extracted entities from\n2https://github.com/flairNLP/flair\nthe encoder hidden states. It is trained by minimizing the following loss function:\nLGEN = \u2212 1\nNu Nu\u2211 i=1 log p(ui|u<i,k, u\u0302; e), (6)\nwhere e is implicitly mined in the encoder during training.\nThe final training objective for a REM trained on both tasks is the following, where \u03bbn is the training hyperparameter:\nLREM = \u03bb1LNER + \u03bb2LGEN (7)"
        },
        {
            "heading": "4 Experimental Settings",
            "text": "In this section, we introduce the dataset, the automatic evaluation metric, and the baseline models used in the experiments. The implementation details are attached in Appendix C."
        },
        {
            "heading": "4.1 Datasets",
            "text": "We utilize three datasets as our testbed, but we only use instances for training and testing where ground truth knowledge is given in the data.\nFoCus (Jang et al., 2022), which considers both knowledge and persona in conversation, has been released. In FoCus, machine generates utterances with customized and knowledgeable utterances about world landmarks. Wizard of Wikipedia (WoW) (Dinan et al., 2018), which is a widely used benchmark, consists of Wizard and Apprentice talking to each other on various topics in Wikipedia. Another dataset, CMUDoG (Zhou et al., 2018) includes conversations between two speakers discussing different aspects of a specific movie, such as information, plot, etc. The data statistics are presented in Appendix A."
        },
        {
            "heading": "4.2 Automated Evaluation Metrics",
            "text": "We evaluate the refining performance of REM with automated metrics in three criteria: sourcefaithfulness, reference matching, and diversity. To evaluate source-faithfulness, we adopt DAE, entity coverage (EC), and entity type coverage (TC). DAE (Goyal and Durrett, 2020) is used to assess whether the system accurately reflects the facts from the given knowledge when generating utterances at the level of dependency arcs. Furthermore, we utilize two entity-level metrics (EC and TC), following subsequent paragraphs, to evaluate the source-faithfulness in terms of the entity. For the reference matching n-gram score, we utilize\nchrF (Popovic\u0301, 2015), ROUGE-L (Lin, 2004) and SacreBLEU (Post, 2018) to evaluate how close the generated hypothesis is to the ground-truth answer in the test set. For diversity evaluation, DistinctN3 (Li et al., 2015) is adopted.\nEntity Coverage and Entity Type Coverage We compute the entity coverage (EC) and entity type coverage (TC) to quantify the extent of correct entities and context coherence, respectively. To compute EC and TC, we extract the named entities from the generated (model-predicted) utterance up (including u\u0303 and u\u0302), source knowledge k, and ground truth utterance u, respectively, using the off-theshelf NER model (Schweter and Akbik, 2020) (The distribution of named entity types are described in Appendix B). First, we evaluate the ratio of the named entities residing in the generated utterance up by comparing it with the ground truth utterance u as follows:\nEC = N ( (Ek \u2229 Eu) \u2229 Eup ) N ( Ek \u2229 Eu\n) , (8) where N (l) is the number of values in list l and Ek is the set of named entities in source knowledge. Eu and Eup indicate the set of named entities in ground truth utterance and generated utterance, respectively.\nIn addition, we evaluate TC, as existing models produce fluent text but demonstrate low context coherence. To identify the intent of context and the information that should be included in the response, we leverage the named entity types in the ground truth utterance u. For example, if the entity type \u2018LOC\u2019 has the highest proportion among the named entities in u, it indicates that the conversation is focused on location-related information. In such cases, the model should generate responses that are relevant to the location to ensure coherence and relevance in the conversation.\nTo this end, we compute the ratio of name entity types extracted from the generated utterance up compared to the ground truth utterance u in each named entity type.\nTC = 1\n|T | T\u2211 t (N (Etup) N ( Etu ) ), (9) where T is the set of named entity types {\u2018LOC\u2019, \u2018PER\u2019, \u2018ORG\u2019, \u2018MISC\u2019}.\n3https://github.com/neural-dialogue-metrics/ Distinct-N"
        },
        {
            "heading": "4.3 KGC Baselines",
            "text": "BART BART (Lewis et al., 2020a) is Transformer-based (Vaswani et al., 2017) pre-trained model with the encoder-decoder structure. It utilizes various noising methods and in-filling schemes during pre-training. We fine-tune BART on three KGC datasets and use its predicted utterance for train, validation, and test set.\nINFO INFO (Lim et al., 2022) leverages RAG (Lewis et al., 2020b) to enhance the factuality of the generation results in FoCus dataset. It retrieves a large number of knowledge documents and generates informative conversations based on them.\nEDMem We utilize and refine the utterances generated by EDMem (Zhang et al., 2022). EDMem is pre-trained on Wikipedia documents to learn entity embeddings and incorporates entity knowledge for entity-intensive dialogue generation.\nITDD ITDD (Li et al., 2019) is the bestperforming method on the CMUDoG dataset. With a two-pass decoder inspired by the human cognitive process, it improves context coherence and knowledge correctness."
        },
        {
            "heading": "5 Results and Analysis",
            "text": "In this section, we report the experimental results and analysis. We first discuss the post-hoc refining ability of our method in \u00a75.1. Then, we evaluate the flexibility of REM through cross-data refining experiments in \u00a75.2. We also conduct experiments on refining adversarial utterances in \u00a75.3, and perform an ablation study in \u00a75.4. Furthermore, we provide the results of human evaluation in \u00a75.5, and present a case study in \u00a75.7. Finally, we analyze the application of REM to large language models in \u00a75.6."
        },
        {
            "heading": "5.1 Post-hoc Refining Ability",
            "text": "To demonstrate the post-hoc refining ability, we evaluate the refining performance of REM with vanilla PLM fine-tuned on three datasets and existing models from previous studies. The results are in Table 1 where REMbase and REMlarge refer to the models trained using the REM method on the BART-base and BART-large (Lewis et al., 2020a).\nFine-tuned Baselines The comparison results of REM with the vanilla PLM fine-tuned on three\ndatasets are presented at the top of Table 1. We fine-tune the BART-base model with each dataset and refer to it as BARTbase. To the generated outputs of BARTbase, we evaluate the refining performance with REMbase. The results demonstrate that the REM leads to improvements not only in the scores of source-faithfulness metrics but also in the reference matching metrics. We also show the ability of REM that refines the utterances of the larger model in Appendix F.\nIn contrast, REM shows a tendency to decrease the performance of diversity metrics. This indicates that in BARTbase-generated utterances, there are tokens that contribute to increased diversity but also lead to hallucination. These hallucinated tokens are subsequently refined through the REM process. In particular, the significant improvements in EC and TC metrics suggest that entities that cause entitylevel hallucination are refined during the refining process with REM.\nExisting Baselines To investigate the adaptability of REM, we compare the refining performance with previous studies, and the results are annotated with \u2020 symbol in Table 1. We re-implement EDMem, ITDD, and INFO for fair comparison with REMlarge. The results reveal that REMlarge exhibits an improvement in source-faithfulness performance. Additionally, it demonstrates enhanced generation performance in the reference matching score, excluding INFO. The reason is that INFO utilizes a large number of knowledge documents for generation, whereas REM generates utterances based on the given ground truth knowledge within the dataset. Furthermore, while the source-faithfulness score increases, the diversity score decreases. This result discusses that REM removes tokens that enhance diversity but also contribute to entity hallucination, similar to the results observed with vanilla PLM."
        },
        {
            "heading": "5.2 Cross-data Utterance Refining",
            "text": "To inspect the flexibility of REM, we conduct crossdata experiments, and the results are shown in Table 2.\nREM trained on CMUDoG consistently underperforms in source-faithfulness and reference matching scores on the other two datasets. When refining FoCus test set with REM trained on CMUDoG, the performance significantly decreases in all metrics. This tendency is similarly shown in the results of WoW test set. Likewise, the REM trained\non WoW exhibits a decrease in performance on FoCus and CMUDoG test sets.\nAccording to the previous comprehensive human study (Dziri et al., 2022b) that analyzes the portion of hallucination in KGC dataset, the reason for the performance decrease is hallucinated utterances in WoW and CMUDoG datasets. The results revealed that only 24.15% of utterances in wow and 16.2% in CMUDoG exhibited entailment. These proportions indicate that a significant portion of utterances contains knowledge hallucination. Consequently, hallucination in the dataset has an impact on model training and evaluation.\nOn the other hand, the model trained on FoCus dataset demonstrates high source-faithfulness performance across all datasets. We assume that the reason for performance differences lies in dataset construction. While WoW and CMUDoG contain\nutterances that provide responses without knowledge, FoCus ensures that all utterances are generated based on knowledge in the dataset. Therefore, the REM trained on FoCus has facilitated the training of a more faithful KGC model."
        },
        {
            "heading": "5.3 Adversarial Data Refining",
            "text": "To investigate the validity of REM, we have prompted ChatGPT (OpenAI-Blog, 2022) to generate the synthetic data by adversarially changing the ground truth utterance4. We demonstrate the performance of REM by refining the utterances that are distorted to be unfaithful to the source knowledge; all data are refined with (\u03c4 = 1.0). As presented in Table 3, compared to the adversarially synthesized\n4The prompts are shown in Appendix E.\ndata (ADV), both source-faithfulness and reference matching scores increased significantly after refining. ROUGE-L score of the ADV is slightly higher in CMUDoG, which is likely due to the characteristic that the utterances of CMUDoG have much shorter lengths than other datasets (Dziri et al., 2022a)."
        },
        {
            "heading": "5.4 Ablation Study",
            "text": "To explore the effect of entity miner, we conduct an ablation study of our proposed method. In Table 4, we present the results on the FoCus dataset, which has the most informative conversations in \u00a75.2. We compare the REM model trained with multi-task learning and only trained with utterance refining (w/o NER).\nIn case the model is trained without entity miner, the results show a performance decrease across the board except in one case. Our proposed REM method, which learns essential information with entity miner, can be demonstrated to be effective for source-faithfulness and reference matching scores. The DAE score of the large models shows better performance without entity miner. The large model shows unstable results in \u00a75.3. However, a significant improvement in the performance of the REM model is shown, with or without entity miner, compared to the baseline utterance. This suggests that refining helps increase the quality and sourcefaithfulness of fatal utterances."
        },
        {
            "heading": "5.5 Human Evaluation",
            "text": "To qualitatively evaluate the results before and after refining, we perform a human evaluation on 100 randomly sampled utterance examples, each from three datasets. One example contains an utterance produced by the baseline and the refined utterance by REM, and we evaluate them with three criteria: 1) fluency, 2) source-faithfulness, and 3) paraphrasing. The first criterion assesses naturalness by measuring the fluency of the generated results. The\nsecond criterion measures source-faithfulness by assessing whether the sentence is factually consistent with the given knowledge. In addition, the third criterion evaluates whether the given knowledge has been appropriately reorganized and incorporated into the utterance rather than just copied and pasted. We provide the questionnaire used in Appendix G\nThe results of the comparative human evaluation of baseline utterances with scores below the threshold and utterances after refining are shown in Figure 4 (\u03c4 = 0.5). Across all data and criteria, the refined utterances win in most cases. Especially in FoCus, refined utterances do not lose to the utterance before refining. REM performs the worst in CMUDoG, which is similar to the experiment in Section 5.1. The dissimilarity between the CMUDoG and the other two datasets can be attributed to its predominant resemblance to a general utterance instead of the knowledge grounded conversations. Nevertheless, we qualitatively demonstrate the effectiveness of REM with a significantly higher number of winning cases."
        },
        {
            "heading": "5.6 REM-LLM",
            "text": "To show the scalability of our method to large language models (LLMs), we apply REM method to the prompt of not-tunable LLM (i.e., ChatGPT) beyond fine-tuning the models. In this experiment, large language models with (LLMREM ) and without (LLM) the REM method refine the utterance of the KGC baseline model (BARTbase) and ChatGPT (LLMKGC). LLM is required to refine the utterance considering the given source knowledge, while LLMREM is made to modify the utterance by extracting key entities from the knowledge and utilizing them. We attach the prompts used in Ap-\npendix H. As shown in Table 5, both LLM and LLMREM show improved source-faithfulness performance, especially in CMUDoG and FoCus. LLMREM is able to achieve the most significant improvement by entity mining and refining the utterance with key entities. This demonstrates that when prompting with LLMs, more source-faithful utterances can be produced with REM by asking LLMs to find the important parts and use them for making responses."
        },
        {
            "heading": "5.7 Case Study",
            "text": "To analyze the generative results of REM, we present the examples of three datasets in Table 6. In FoCus example, the utterance of baseline answers only provides the information of year, but with the imperfect entity mention \u2018Per\u2019. However, after being refined with REM, the utterance provides more specific knowledge with correct entity mentions, even utilizing the persona knowledge. In WoW example, the baseline utterance provides knowledge that is not given in the knowledge, but REM gives source-faithful information. In CMUDoG example, REM provides more detailed factual knowledge in the utterance than in the baseline utterance. We show more examples also in Appendix I.\nFoCus\n[Knowledge] Designed by French architect Paul Andreu, the NCPA opened in 2007 and is the largest theatre complex in Asia. [Persona Knowledge] I love art. I\u2019m interested in architecture. I love lakes. I want to go on a trip. I want to visit China. [Utterance] BARTbase : National for Per Arts in opened 2007. + REMbase : National Center for the Performing Arts (NCPA) opened in 2007 and is the largest theatre complex in Asia. If you love art, you have to come see it with your own eyes!\nWoW\n[Knowledge] Among other honors, he has won nine Goyas, two European Film Awards and an Oscar. [Utterance] BARTbase : I\u2019ve seen it a few times. It was directed by Alejandro Amen\u00e1 + REMbase : of course! He has won nine Goyas, two European Film Awards, and an Oscar! That\u2019s a lot of awards for a director!\nCMUDoG"
        },
        {
            "heading": "6 Conclusion",
            "text": "In this work, we proposed REM, a post-hoc refining method for improving the source-faithfulness of the utterances in the knowledge grounded conversation (KGC). REM enabled simple but effective refining by extracting entities from the source knowledge given in the KGC task. It makes the model learn the key information implicitly and use it for refining the utterance more faithful to the source knowledge. We presented extensive experiments applying REM in a plug-in-play method to various model-generated outputs, showing increased source-faithfulness and entity coverage after refining. Also, qualitative analysis and human evaluation proved the refining efficacy of REM. We verified that our proposed method could be utilized with the prompt of the large language models.\nLimitations\nOur research proposed a method that aims to refine the non-source-faithful utterances in the knowledge grounded conversation. Though we address the problem of models not reflecting even the ground truth knowledge given, it is difficult to solve if the retriever does not give accurate knowledge from the in-the-wild setting. Therefore, the performance of the refiner may depend on the retriever\u2019s performance. As it is beyond the scope of this paper, we leave it as future work. When filtering the utterances by source-faithfulness score, we only utilized DAE, but other scores or classifiers (Dou et al., 2022; Manakul et al., 2023) can be adopted for filtering according to the data or domain. There is an area of research in detecting critical errors in generated results in neural machine translation. Similarly, in the dialogue tasks, the better the classifier performs in detecting hallucinated utterances, the better the performance of the refiner will be. In addition, we expect that existing baseline models could be further improved if trained with REM in an end-to-end manner, so we leave it as future work.\nEthics Statement\nThe datasets used in our work are from previously published papers, so we do not attach privacy or ethical issues to the dataset. At inference, we will make the model not generate tokens in a list of several stopwords utilizing Hatebase5, Silva et al. (2016), etc., to avoid generating harmful utterances that the model may have learned during pre-training. As we are aware that excessive computational energy used to train models stimulates environmental problems, we adopt the multi-task learning method for training entity miner and utterance generator instead of having a separate entity miner model to improve efficiency. Also, we distribute all codes and model checkpoints so they do not have to be trained again. We believe that our refining method can contribute to mitigating the entity-level hallucination of model-generated utterances and preventing the misuse of AI systems."
        },
        {
            "heading": "Acknowledgements",
            "text": "This research was supported by the MSIT(Ministry of Science and ICT), Korea, under the ITRC(Information Technology Research Center)\n5http://hatebase.org\nsupport program(IITP-2023-2018-0-01405) supervised by the IITP(Institute for Information & Communications Technology Planning & Evaluation). This work was supported by Institute of Information & communications Technology Planning & Evaluation(IITP) grant funded by the Korea government(MSIT) (No. 2020-0-00368, A Neural-Symbolic Model for Knowledge Acquisition and Inference Techniques). Also, this work was supported by NCSOFT NLP Center."
        },
        {
            "heading": "A Dataset Details",
            "text": "FoCus (Jang et al., 2022) is a dataset where a human and a machine take turns having a conversation about a specific landmark. This dataset consists of 14,452 conversations, with 173,424 utterances. We use the validation set, which has 1,445 conversations and 17,340 utterances, for the experiment, as the official test set does not provide ground truth knowledge and utterances.\nWizard of Wikipedia (WoW) (Dinan et al., 2018) is a conversational dataset based on Wikipedia articles on various topics. The dataset covers 1,365 topics and consists of 22,311 conversations with a total of 201,999 utterances, which are divided into 166,787 for train, 17,715 for validation, and 17,497 for test. We used a random split version of the validation and test set. Only for evaluating EDMem (Zhang et al., 2022), we follow its test setting, KILT (Petroni et al., 2021), a variant of the WoW dataset.\nCMUDoG (Zhou et al., 2018) is a knowledge grounded conversation dataset with two speakers conversing based on movie Wikipedia articles. Unlike the WoW and FoCus, where only one of the two speakers has access to the knowledge, both speakers of this dataset have access to the content of the article. It has a resemblance to a generic dialogue compared to the other two datasets. It is composed of a total of 4,112 conversations with an average of 21.43 turns."
        },
        {
            "heading": "B Distribution of Named Entity-Type",
            "text": "We show the entity type distribution of all datasets, the train, development, and test sets used for finetuning the baseline model BARTbase, in Figure 5. WoW has the evenest distribution, and FoCus has the second most even distribution. CMUDoG has the most \u201cPER\u201d entity class among the other three classes.\nC Implementation Details\nWhen implementing REM, we adopt BART (Lewis et al., 2020a), which has an encoder-decoder structure, and train the entity mining and utterance generation tasks. We experiment with BARTbase of 140M parameters and BARTlarge of 406M parameters. We train REM on the pairs of model-predicted utterances, generated by the fine-tuned BART baseline, and reference utterance. We implement the models by exploiting Pytorch (Paszke et al., 2019) and HuggingFace (Wolf et al., 2019) with a fixed seed for reimplementation. The models are trained with a learning rate of 6.25e-5 for 10 epochs with early stopping. AdamW (Loshchilov and Hutter, 2017) is used as the optimizer. We set the train batch size to 8 with a gradient accumulation of 32. The time required for training is about 2 hours per epoch on a single RTX-6000 GPU. For decoding, we used a beam size of 5, min length of 32, max length of 512, top k of 50, and no-repeat n-gram size of 2. NER loss weight \u03bb1 and GEN loss weights \u03bb2 are set as 0.5:1, 0.3:1, and 0.7:1 for WoW, CMUDoG, and FoCus, respectively, according to the preliminary study. We will open the source codes which we used for the experiments after the review process."
        },
        {
            "heading": "D Threshold",
            "text": "To utilize the off-the-shelf metric as our scoring function for filtering, we manually find the threshold both for effectiveness and efficiency. The high threshold is intended for evaluating the sourcefaithfulness of a given utterance strictly. A low threshold, on the other hand, targets only those utterances that are not faithful to the knowledge and aims to regenerate only fatal cases. As shown in Figure 6, we use a threshold of 0.5 to consider all datasets and 1.0 if we need to refine all utterances."
        },
        {
            "heading": "E Prompts for Adversarial Data Generation with ChatGPT",
            "text": "The prompt used for generating adversarial data with ChatGPT is in Table 8:\nPrompt"
        },
        {
            "heading": "F Refining Utterances of Larger Models",
            "text": ""
        },
        {
            "heading": "G Human Evaluation Questionnaire",
            "text": "Questionnaire\nH Prompts for LLM and LLMREM The prompts for refining utterances with LLM and LLMREM are in Table 11.\nLLM\nI REM Generation Examples\nFoCus\n[Knowledge] The V\u00e1clav Havel Library, located in Prague, is a charitable organization founded by Dagmar Havlov\u00e1, Karel Schwarzenberg and Miloslav Petrusek on 26 July 2004. [Persona Knowledge] I love going to libraries. I love reading. I want to visit Prague. I want to visit New York. I love books. [Utterance] BARTbase : cl Ha Library founded 26 2004. + REMbase : V\u00e1clav Havel Library was founded on 26 July 2004 by Dagmar Havlov\u00e1, Karel Schwarzenberg and Miloslav Petrusek.\n[Knowledge] The design of the house is attributed to John Verge and John Bibb and was built from 1835 to 1839 by James Hume. [Persona Knowledge] I love colonial architecture. I like Australia. I would like to visit a museum. I would love to see a grotto. I have read about the Cadigal people. [Utterance] BARTbase : was from35 18 to39 + REMbase : it was built from 1835 to 1839 by James Hume. I got this information on the internet. It was designed by John Verge and John Bibb.\nWoW\n[Knowledge] A tattoo is a form of body modification where a design is made by inserting ink, dyes and pigments, either indelible or temporary, into the dermis layer of the skin to change the pigment. [Utterance] BARTbase : I\u2019m not sure if it is really a tattoo artist, but I do know that + REMbase : of course, it is a form of body modification where a design is made by inserting ink, dyes and pigments into the dermis layer of the skin to change the pigment.\n[Knowledge] It was also applied to the pit-style cooking techniques now frequently used in the Southeastern United States. [Utterance] BARTbase : , I\u2019ll have to try it sometime! I\u2019ve heard it\u2019s used in the + REMbase : , I don\u2019t know if I\u2019d ever try it. I know that pit-style cooking techniques are now frequently used in the Southeastern United States.\nFoCus\n[Knowledge] Elizabeth Bay House is a heritage-listed Colonial Regency style house and now a museum and grotto, located at 7 Onslow Avenue in the inner eastern Sydney suburb of Elizabeth Bay in the City of Sydney local government area of New South Wales, Australia. [Persona Knowledge] I love colonial architecture. I like Australia. I would like to visit a museum. I would love to see a grotto. I have read about the Cadigal people. [Utterance] BARTbase : Elizabeth House located Australia which like. is place you like + REMlarge : This place is called Elizabeth Bay House and it is located in Australia, which you like. It is a heritage-listed Colonial Regency style house and now a museum and grotto.\n[Knowledge] The Memphis Zoo, located in Midtown, Memphis, Tennessee, United States, is home to more than 3,500 animals representing over 500 different species. [Persona Knowledge] I hope to visit Tennessee. I like to ride on a tram. I have never seen a wetland. I would like to see a Giant Panda. I wish I could see a penguin. [Utterance] BARTbase : is Memphis in. is place hope visit. + REMlarge : It\u2019s the Memphis Zoo in Tennessee, a place you hope to visit. It is home to more than 3,500 animals, 500 different species.\nWoW\n[Knowledge] Competing theories state that Hindu identity developed in the British colonial era, or that it developed post-8th century CE after the Islamic invasion and medieval Hindu-Muslim wars. [Utterance] BARTbase : , I\u2019m not fluent in English, but I understand that Hindu identity developed in the + REMlarge : No, I\u2019m not fluent in English, but I understand that Hindu identity developed in the British colonial era, or that it developed post-8th century CE.\n[Knowledge] Human occupation of Qatar dates back to 50,000 years ago, and Stone Age encampments and tools have been unearthed in the peninsula. [Utterance] BARTbase : \u2019s a pretty busy place, I\u2019ve been to Qatar a few times. It\u2019s + REMlarge : That\u2019s true. It\u2019s a pretty busy place, but it\u2019s been around for a long time. Human occupation of Qatar dates back 50,000 years ago, and Stone Age encampments and tools have been found in the peninsula.\nCMUDoG\n[Knowledge] Sally Hawkins as Elisa Esposito, a mute cleaner who works at a secret government laboratory. ... The Shape of Water Rotten Tomatoes: 92% and average: 8.4/10 Metacritic Score: 87/100 CinemaScore: A 2017 [Utterance] BARTbase : have you seen The Shape of Water? + REMlarge : Hello, Have you seen The Shape of Water? It\u2019s a really good movie. It has a 92% on Rotten Tomatoes and a Metacritic Score of 87/100.\n[Knowledge] Lindsay Lohan as Cady Heron Rachel McAdams as Regina George Lacey Chabert as Gretchen Wieners Amanda Seyfried as Karen Smith Lizzy Caplan as Janis Ian Boasts a one-two-three punch in star Lindsay Lohan, screenwriter Tina Fey and director Mark Waters, and, indeed, it delivers a knockout The screenplay was highly praised by critics with Peter Travers of Rolling Stone calling it \u2019comic gold\u2019. ... [Utterance] BARTbase : , what did you think of it? + REMlarge : I really liked it, I thought Lindsay Lohan did a great job as Cady Heron. Tina Fey did an amazing job writing the screenplay as well.\nTable 13: Examples of the fine-tuned baseline utterances refining by REMlarge on KGC datasets.\nFoCus\n[Knowledge] hesselberg ( pronounced [ ] ( about this soundlisten ) ; 689 m above sea level ) is the highest point in middle franconia and the franconian jura and is situated 60 km south west of nuremberg, germany. [Persona Knowledge] I love to enjoy nature. I live near Nuremberg. I am from Germany. I like heights. I study geology. [Utterance] INFO : The name of this place is Hesselberg. + REMlarge : The name of this place is Hesselberg, and it is located 60 km south west of nuremberg, germany, the country you are from.\n[Knowledge] st. george\u2019s united methodist church, located at the corner of 4th and new streets, in the old city neighborhood of philadelphia, is the oldest methodist church in continuous use in the united states, beginning in 1769. [Persona Knowledge] I will stay in Philadelphia. I am going to Pennsylevania. I like history. I am religious. I am interested in the American Revolution. [Utterance] INFO : This is St. George\u2019s United Methodist Church you may know of it because you are religious. + REMlarge : This is St. George\u2019s United Methodist Church, you may know of it because you are religious. It is the oldest methodist church in continuous use in the united states.\nWoW (KILT)\n[Knowledge] Red Ketchup is a cult Quebec comic book series featuring FBI\u2019s crazed rogue agent, Steve R\u0308edK\u0308etchup. The series was created by Pierre Fournier and R\u00e9al Godbout, and will soon be adapted into a live action feature film by Martin Villeneuve for GO Films in Montreal. [Utterance] EDMem : ketchup red is a sweet sauce made from tomatoes. + REMlarge : I love red ketchup, which is a cult Quebec comic book series featuring FBI\u2019s crazed rogue agent, Steve R\u0308edK\u0308etchup. The series was created by Pierre Fournier and R\u00e9al Godbout\n[Knowledge] Childhood obesity is a condition where excess body fat negatively affects a child\u2019s health or well-being. As methods to determine body fat directly are difficult, the diagnosis of obesity is often based on BMI. Due to the rising prevalence of obesity in children and its many adverse health effects it is being recognized as a serious public health concern. The term overweight rather than obese is often used when discussing childhood obesity, especially in open discussion, as it is less stigmatizing. [Utterance] EDMem : i\u2019m not sure, but i do know that in the united states, overweight people are more likely to be obese than healthy people. + REMlarge : Yea i\u2019m not sure, but the prevalence of obesity in children and its many adverse health effects it is being recognized as a serious public health concern."
        }
    ],
    "title": "Post-hoc Utterance Refining Method by Entity Mining for Faithful Knowledge Grounded Conversations",
    "year": 2023
}