{
    "abstractText": "Dialogue systems are frequently updated to accommodate new services (e.g. booking restaurants, setting alarm clocks, etc.), but naive updates with new data compromises performance on previous services due to catastrophic forgetting. To mitigate this issue, we propose a simple but powerful reformulation for dialogue state tracking (DST), a key component of dialogue systems that estimates the user\u2019s goal as a conversation proceeds. We restructure DST to eliminate service-specific structured text and unify data from all services by decomposing each DST sample to a bundle of fine-grained example-guided question answering tasks. Our reformulation encourages a model to learn the general skill of learning from an in-context example to correctly answer a natural language question that corresponds to a slot in a dialogue state. With a retriever trained to find examples that introduce similar updates to dialogue states, we find that our method can significantly boost continual learning performance, even for a model with just 60M parameters. When combined with dialogue-level memory replay, our approach attains state-of-the-art performance on continual learning metrics without relying on any complex regularization or parameter expansion methods.",
    "authors": [
        {
            "affiliations": [],
            "name": "Hyundong Cho"
        },
        {
            "affiliations": [],
            "name": "Andrea Madotto"
        },
        {
            "affiliations": [],
            "name": "Zhaojiang Lin Khyathi"
        },
        {
            "affiliations": [],
            "name": "Raghavi Chandu"
        },
        {
            "affiliations": [],
            "name": "Satwik Kottur"
        },
        {
            "affiliations": [],
            "name": "Jing Xu"
        },
        {
            "affiliations": [],
            "name": "Jonathan May"
        },
        {
            "affiliations": [],
            "name": "Chinnadhurai Sankar"
        }
    ],
    "id": "SP:4d4636dfd9d2c0b846e2da246a2b92056f8ee198",
    "references": [
        {
            "authors": [
                "Armen Aghajanyan",
                "Anchit Gupta",
                "Akshat Shrivastava",
                "Xilun Chen",
                "Luke Zettlemoyer",
                "Sonal Gupta."
            ],
            "title": "Muppet: Massive multi-task representations with pre-finetuning",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language",
            "year": 2021
        },
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are few-shot learners. Advances in neural information processing",
            "year": 2020
        },
        {
            "authors": [
                "Hyundong Cho",
                "Chinnadhurai Sankar",
                "Christopher Lin",
                "Kaushik Sadagopan",
                "Shahin Shayandeh",
                "Asli Celikyilmaz",
                "Jonathan May",
                "Ahmad Beirami."
            ],
            "title": "Know thy strengths: Comprehensive dialogue state tracking diagnostics",
            "venue": "Findings of the Association",
            "year": 2022
        },
        {
            "authors": [
                "Sanchit Agarwal",
                "Shuyang Gao",
                "Adarsh Kumar",
                "Anuj Goyal",
                "Peter Ku",
                "Dilek Hakkani-Tur"
            ],
            "title": "MultiWOZ 2.1: A consolidated multi-domain dialogue dataset with state corrections and state tracking baselines",
            "year": 2020
        },
        {
            "authors": [
                "Chrisantha Fernando",
                "Dylan Banarse",
                "Charles Blundell",
                "Yori Zwols",
                "David Ha",
                "Andrei A Rusu",
                "Alexander Pritzel",
                "Daan Wierstra."
            ],
            "title": "Pathnet: Evolution channels gradient descent in super neural networks",
            "venue": "arXiv preprint arXiv:1701.08734.",
            "year": 2017
        },
        {
            "authors": [
                "Robert M French."
            ],
            "title": "Catastrophic forgetting in connectionist networks",
            "venue": "Trends in cognitive sciences, 3(4):128\u2013135.",
            "year": 1999
        },
        {
            "authors": [
                "Shuyang Gao",
                "Abhishek Sethi",
                "Sanchit Agarwal",
                "Tagyoung Chung",
                "Dilek Hakkani-Tur."
            ],
            "title": "Dialog state tracking: A neural reading comprehension approach",
            "venue": "Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue, pages 264\u2013273,",
            "year": 2019
        },
        {
            "authors": [
                "Raghav Gupta",
                "Harrison Lee",
                "Jeffrey Zhao",
                "Yuan Cao",
                "Abhinav Rastogi",
                "Yonghui Wu."
            ],
            "title": "Show, don\u2019t tell: Demonstrations outperform descriptions for schema-guided task-oriented dialogue",
            "venue": "Proceedings of the 2022 Conference of the North Amer-",
            "year": 2022
        },
        {
            "authors": [
                "Michael Heck",
                "Carel van Niekerk",
                "Nurul Lubis",
                "Christian Geishauser",
                "Hsien-Chin Lin",
                "Marco Moresi",
                "Milica Gasic."
            ],
            "title": "TripPy: A triple copy strategy for value independent neural dialog state tracking",
            "venue": "Proceedings of the 21th Annual Meeting of the",
            "year": 2020
        },
        {
            "authors": [
                "Ehsan Hosseini-Asl",
                "Bryan McCann",
                "Chien-Sheng Wu",
                "Semih Yavuz",
                "Richard Socher."
            ],
            "title": "A simple language model for task-oriented dialogue",
            "venue": "Advances in Neural Information Processing Systems, 33:20179\u2013 20191.",
            "year": 2020
        },
        {
            "authors": [
                "Saihui Hou",
                "Xinyu Pan",
                "Chen Change Loy",
                "Zilei Wang",
                "Dahua Lin."
            ],
            "title": "Learning a unified classifier incrementally via rebalancing",
            "venue": "Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition, pages 831\u2013839.",
            "year": 2019
        },
        {
            "authors": [
                "Yushi Hu",
                "Chia-Hsuan Lee",
                "Tianbao Xie",
                "Tao Yu",
                "Noah A. Smith",
                "Mari Ostendorf."
            ],
            "title": "Incontext learning for few-shot dialogue state tracking",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022, pages 2627\u20132643, Abu",
            "year": 2022
        },
        {
            "authors": [
                "Sungdong Kim",
                "Sohee Yang",
                "Gyuwan Kim",
                "SangWoo Lee."
            ],
            "title": "Efficient dialogue state tracking by selectively overwriting memory",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 567\u2013582, Online.",
            "year": 2020
        },
        {
            "authors": [
                "James Kirkpatrick",
                "Razvan Pascanu",
                "Neil Rabinowitz",
                "Joel Veness",
                "Guillaume Desjardins",
                "Andrei A Rusu",
                "Kieran Milan",
                "John Quan",
                "Tiago Ramalho",
                "Agnieszka Grabska-Barwinska"
            ],
            "title": "Overcoming catastrophic forgetting in neural networks",
            "year": 2017
        },
        {
            "authors": [
                "Shuyang Li",
                "Jin Cao",
                "Mukund Sridhar",
                "Henghui Zhu",
                "Shang-Wen Li",
                "Wael Hamza",
                "Julian McAuley."
            ],
            "title": "Zero-shot generalization in dialog state tracking through generative question answering",
            "venue": "Proceedings of the 16th Conference of the European",
            "year": 2021
        },
        {
            "authors": [
                "Zhizhong Li",
                "Derek Hoiem."
            ],
            "title": "Learning without forgetting",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 40(12):2935\u20132947.",
            "year": 2018
        },
        {
            "authors": [
                "Zhaojiang Lin",
                "Bing Liu",
                "Andrea Madotto",
                "Seungwhan Moon",
                "Zhenpeng Zhou",
                "Paul Crook",
                "Zhiguang Wang",
                "Zhou Yu",
                "Eunjoon Cho",
                "Rajen Subba",
                "Pascale Fung."
            ],
            "title": "Zero-shot dialogue state tracking via cross-task transfer",
            "venue": "Proceedings of the 2021 Con-",
            "year": 2021
        },
        {
            "authors": [
                "Qingbin Liu",
                "Pengfei Cao",
                "Cao Liu",
                "Jiansong Chen",
                "Xunliang Cai",
                "Fan Yang",
                "Shizhu He",
                "Kang Liu",
                "Jun Zhao."
            ],
            "title": "Domain-lifelong learning for dialogue state tracking via knowledge preservation networks",
            "venue": "Proceedings of the 2021 Conference on",
            "year": 2021
        },
        {
            "authors": [
                "Andrea Madotto",
                "Zhaojiang Lin",
                "Zhenpeng Zhou",
                "Seungwhan Moon",
                "Paul Crook",
                "Bing Liu",
                "Zhou Yu",
                "Eunjoon Cho",
                "Pascale Fung",
                "Zhiguang Wang."
            ],
            "title": "Continual learning in task-oriented dialogue systems",
            "venue": "Proceedings of the 2021 Conference on Empiri-",
            "year": 2021
        },
        {
            "authors": [
                "Michael McCloskey",
                "Neal J Cohen."
            ],
            "title": "Catastrophic interference in connectionist networks: The sequential learning problem",
            "venue": "Psychology of learning and motivation, volume 24, pages 109\u2013165. Elsevier.",
            "year": 1989
        },
        {
            "authors": [
                "Sewon Min",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Hannaneh Hajishirzi"
            ],
            "title": "MetaICL: Learning to learn",
            "year": 2022
        },
        {
            "authors": [
                "Long Ouyang",
                "Jeffrey Wu",
                "Xu Jiang",
                "Diogo Almeida",
                "Carroll Wainwright",
                "Pamela Mishkin",
                "Chong Zhang",
                "Sandhini Agarwal",
                "Katarina Slama",
                "Alex Ray"
            ],
            "title": "Training language models to follow instructions with human",
            "year": 2022
        },
        {
            "authors": [
                "Baolin Peng",
                "Chunyuan Li",
                "Jinchao Li",
                "Shahin Shayandeh",
                "Lars Liden",
                "Jianfeng Gao."
            ],
            "title": "Soloist: Building task bots at scale with transfer learning and machine teaching",
            "venue": "Transactions of the Association for Computational Linguistics, 9:807\u2013824.",
            "year": 2021
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J Liu"
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "J. Mach. Learn. Res.,",
            "year": 2020
        },
        {
            "authors": [
                "Abhinav Rastogi",
                "Xiaoxue Zang",
                "Srinivas Sunkara",
                "Raghav Gupta",
                "Pranav Khaitan."
            ],
            "title": "Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, vol-",
            "year": 2020
        },
        {
            "authors": [
                "Sylvestre-Alvise Rebuffi",
                "Alexander Kolesnikov",
                "Georg Sperl",
                "Christoph H Lampert."
            ],
            "title": "icarl: Incremental classifier and representation learning",
            "venue": "Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pages 2001\u20132010.",
            "year": 2017
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych."
            ],
            "title": "SentenceBERT: Sentence embeddings using Siamese BERTnetworks",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natu-",
            "year": 2019
        },
        {
            "authors": [
                "Stephen Robertson",
                "Hugo Zaragoza"
            ],
            "title": "The probabilistic relevance framework: Bm25 and beyond",
            "venue": "Foundations and Trends\u00ae in Information Retrieval,",
            "year": 2009
        },
        {
            "authors": [
                "Victor Sanh",
                "Albert Webson",
                "Colin Raffel",
                "Stephen Bach",
                "Lintang Sutawika",
                "Zaid Alyafeai",
                "Antoine Chaffin",
                "Arnaud Stiegler",
                "Teven Le Scao",
                "Arun Raja"
            ],
            "title": "Multitask prompted training enables zeroshot task generalization",
            "venue": "In The Tenth International",
            "year": 2022
        },
        {
            "authors": [
                "Yilin Shen",
                "Xiangyu Zeng",
                "Hongxia Jin."
            ],
            "title": "A progressive model to enable continual learning for semantic slot filling",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Confer-",
            "year": 2019
        },
        {
            "authors": [
                "Yixuan Su",
                "Lei Shu",
                "Elman Mansimov",
                "Arshit Gupta",
                "Deng Cai",
                "Yi-An Lai",
                "Yi Zhang."
            ],
            "title": "Multi-task pre-training for plug-and-play task-oriented dialogue system",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics",
            "year": 2022
        },
        {
            "authors": [
                "Shailaja Keyur Sampat",
                "Siddhartha Mishra",
                "Sujan Reddy A",
                "Sumanta Patro",
                "Tanay Dixit",
                "Xudong Shen."
            ],
            "title": "Super-NaturalInstructions: Generalization via declarative instructions on 1600+ NLP tasks",
            "venue": "Proceedings of the 2022 Conference on Empiri-",
            "year": 2022
        },
        {
            "authors": [
                "Jason Wei",
                "Maarten Bosma",
                "Vincent Y Zhao",
                "Kelvin Guu",
                "Adams Wei Yu",
                "Brian Lester",
                "Nan Du",
                "Andrew M Dai",
                "Quoc V Le."
            ],
            "title": "Finetuned language models are zero-shot learners",
            "venue": "arXiv preprint arXiv:2109.01652.",
            "year": 2021
        },
        {
            "authors": [
                "Jason Williams",
                "Antoine Raux",
                "Deepak Ramachandran",
                "Alan Black."
            ],
            "title": "The dialog state tracking challenge",
            "venue": "Proceedings of the SIGDIAL 2013 Conference, pages 404\u2013413, Metz, France. Association for Computational Linguistics.",
            "year": 2013
        },
        {
            "authors": [
                "Chien-Sheng Wu",
                "Steven C.H. Hoi",
                "Richard Socher",
                "Caiming Xiong."
            ],
            "title": "TOD-BERT: Pre-trained natural language understanding for task-oriented dialogue",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
            "year": 2020
        },
        {
            "authors": [
                "Jeffrey Zhao",
                "Raghav Gupta",
                "Yuan Cao",
                "Dian Yu",
                "Mingqiu Wang",
                "Harrison Lee",
                "Abhinav Rastogi",
                "Izhak Shafran",
                "Yonghui Wu."
            ],
            "title": "Descriptiondriven task-oriented dialog modeling",
            "venue": "arXiv preprint arXiv:2201.08904.",
            "year": 2022
        },
        {
            "authors": [
                "Qi Zhu",
                "Bing Li",
                "Fei Mi",
                "Xiaoyan Zhu",
                "Minlie Huang."
            ],
            "title": "Continual prompt tuning for dialog state tracking",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1124\u20131137,",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "As conversational digital assistants are becoming increasingly popular and versatile, it is important to continuously update them to accommodate more services.1 One of their key components is a dialogue state tracking (DST) model that estimates the user\u2019s goal, i.e. the dialogue state (Williams et al., 2013). The dialogue state is used for queries sent to application programming interfaces to retrieve\n\u2217This work was done while at Meta AI. 1In this work, we use services and domains interchangeably to denote high-level services supported by digital assistants, e.g. setting an alarm or booking a restaurant. Task refers to lower-level functions, e.g. question answering, sentiment classification, and dialogue state tracking.\ninformation that grounds the dialogue model\u2019s response.\nUnfortunately, naively updating a model for a new service by training with new data causes catastrophic forgetting (McCloskey and Cohen, 1989; French, 1999): upon learning from new data, the model\u2019s performance for previous services regresses. To mitigate this issue while also avoiding the impracticality of training a model from scratch\nwith data from all services each time new data becomes available, three main approaches have been established as generally effective approaches to continual learning (CL): memory replay, regularization, and parameter expansion. Variations and combinations of the three have been applied for DST in previous work (Liu et al., 2021; Madotto et al., 2021; Zhu et al., 2022).\nHowever, most previous work has focused on improving CL performance with service-specific inputs or outputs, a paradigm that limits knowledge transfer between services (left side of Figure 1). This approach introduces a large distribution shift from one service to another since the model needs to memorize service-specific slots that it needs to predict as part of the output. However, DST can become a significantly more consistent task across services by simply reformulating it as a collection of example-guided question answering tasks. Our approach, Dialogue State Tracking as ExampleGuided Question Answering (DST-EGQA2) trains a model to learn to answer natural language questions that correspond to dialogue state slots (right side of Figure 1) with the help of in-context examples instead of predicting service-specific structured outputs all at once without any explicit guidance (left side of Figure 1). We hypothesize that DST-EGQA benefits continual learning because it transforms the DST task to become more granular, easy, and consistent across services.\nWe discover that this is indeed the case, as our approach leads to significant gains in CL performance without using any of the aforementioned CL approaches or data augmentation methods. Specifically, we transform DST into the TransferQA (Lin et al., 2021) format and add examples from a retriever that is trained to identify turns that result in similar dialogue state updates (Hu et al., 2022). In addition, our approach does not require complex partitioning of the full training set into training samples and retrieval samples. We find that we can use each sample in the training set as both target samples and examples in the retrieval database without causing any label leakage. Also, we experiment with a wide array of retrievers and find that models trained to perform DST-EGQA can be effective even with lower quality retrievers by intentionally training it with subpar examples such that it can learn when to leverage good examples and\n2Code available at https://github.com/ facebookresearch/DST-EGQA\nignore bad ones. Lastly, we simply tweak the sampling approach for memory replay to sample at the dialogue-level instead of the turn-level and achieve significant gains to CL performance even with a single dialogue sample, resulting in state-of-theart performance on the Schema Guided Dialogue (SGD) dataset (Zhu et al., 2022).\nIn summary, our main contributions are:\n1. We show that simply reformulating DST as a fine-grained example-guided question answering task (DST-EGQA) significantly improves continual learning performance by enhancing task consistency across services.\n2. We propose a simple but highly effective dialogue-level sampling strategy for choosing memory samples that leads to state-of-theart performance when combined with DSTEGQA.\n3. We share a thorough analysis on DST-EGQA to establish its effectiveness, robustness, and limitations as a method for continual learning."
        },
        {
            "heading": "2 Dialogue State Tracking as Example-Guided Question Answering (DST-EGQA)",
            "text": "The goal of continual learning for DST is to sequentially train on a stream of n services T1...Tn with the goal of minimal degradation, i.e. catastrophic forgetting, of peak performance that was achieved when the model was trained on for each service Ti. In this section, we motivate and elaborate on the methodology of DST-EGQA for attaining this goal. Figure 2 presents an illustrated overview."
        },
        {
            "heading": "2.1 DST as question answering",
            "text": "Dialogue state tracking (DST) is defined as estimating the beliefs of a user\u2019s goals at every turn in a dialogue. It was traditionally formulated as a slot-filling task (Wu et al., 2020; Heck et al., 2020), and more recently as a structured text generation task (Hosseini-Asl et al., 2020; Peng et al., 2021; Su et al., 2022), shown in (0) in Figure 2. If a user were to say \u201cFind me a 3 star hotel.\", the goal is to deduce hotel-star = 3. However, we can also indirectly achieve the same predictions by reformulating DST as a collection of per-slot questions to answer (Gao et al., 2019; Lin et al., 2021). Given the same user request, we can ask our model to answer \u201cWhat is the hotel star rating the\nuser wants?\" and have it predict 3. We hypothesize that this question answering approach is more conducive to continual learning because it leverages a general skill that is understandable through natural language. We only need to ask different questions to predict slot values we are interested in. On the other hand, directly predicting a structured dialogue state requires training the model to generate slots that is has never generated before.\nTo transform DST into question answering as shown in (1) in Figure 2, we leverage the TransferQA (Lin et al., 2021) format. Given DSt, the dialogue state of a dialogue until turn t expressed as (key, value) pairs {(st,i, vt,i) | i \u2208 I} for slot i, I = {1, ..., NT }, where NT is the number of slots of interest for domain T , each st,i is transformed into a question with a manually pre-defined template Q : si \u2192 qi. The overhead of creating these templates is minimal as it only has to be done once and is as simple as transforming the name slot in the hotel domain to a natural text question equivalent, e.g. \u201cWhat is the name of the hotel that the user wants?\u201d. Thus, with dialogue history until turn t as Ht = {u1, b1, ..., ut\u22121, bt\u22121, ut}, where ui is the user\u2019s utterance on the ith turn and bi is that of the bot\u2019s, the original single input output pair of\nHt \u2295 T \u2192 {(st,i = vt,i) | i \u2208 I} (1)\nbecomes NT granular question answer pairs:\n{Q(st,i)\u2295Ht \u2192 vt,i | i \u2208 I} (2)\nwhere \u2295 denotes simple text concatenation. A difference from the original TransferQA approach is that since we will be finetuning the model, we skip the step of training with external question answering datasets and do not take any special measures to handle none, i.e., empty slots, because our models will learn to generate none as the answer for these slots. Further detail on the TransferQA format and additional examples of the fully constructed inputs are shared in Appendix A.1."
        },
        {
            "heading": "2.2 Fine-tuning with in-context examples",
            "text": "Adapting to new services can be made even more seamless by providing in-context examples (Wang et al., 2022; Min et al., 2022; Ouyang et al., 2022). Even when faced with a question it has never seen before, the examples provide guidance on how it should be answered. This kind of task reformulation enables the development of models that achieve state-of-the-art zero-shot performance and generalizability even with small models (60M parameters) by explicitly fine-tuning with instructions and in-context examples. Since most recent work that focus on generalizabilty and zero-shot models leverages generation models because of their open\nvocabulary, we also place our focus on generation models.\nMotivated by the results from Tk-instruct (Wang et al., 2022) and MetaICL (Min et al., 2022) that showed even relatively small models can generalize well if explicitly trained to follow instructions with examples, we explore whether we can prevent a model from overfitting to domain-specific questions and instead continually develop examplebased question answering capabilities to enhance continual learning performance. Therefore, we extend Equation 2 to include in-context examples that are retrieved from the training set, as shown in (2) in Figure 2. To retrieve relevant examples, we use Ht to form a query that retrieves the top k samples {H\n\u2032j t\u2032 |j \u2264 k} to use as in-context examples.\n3 By inserting the retrieved examples and their relevant slot values for each slot question qi, the final format becomes:\n{Q(st,i)\u2295{H \u2032j t\u2032 \u2295v \u2032j t\u2032,i|j \u2264 k}\u2295Ht \u2192 vt,i | i \u2208 I} (3) Throughout this work, we use k = 1 unless otherwise specified."
        },
        {
            "heading": "2.3 Retrieving relevant in-context examples",
            "text": "The goal of the retrieval system is to find an example turn H \u2032t\u2032 that requires similar reasoning for answering the target sample Ht, such that fine-tuning with it as an in-context example will help enable the model to apply the same reasoning for answering the question for the target sample. Hu et al. (2022) found that instead of matching for dialogue state overlap, matching for similar dialogue state change \u2206DS, i.e. state change similarity (SCS), yields more relevant examples. State changes are simply a subset of DS that is different from the previous turn: \u2206DS = {(st,i, vt,i) | i \u2208 I, vt,i \u0338= vt\u22121,i}.\nWe found that computing similarity with this definition of state change results in many ties that leads to less relevant examples being lumped into the same rank as more relevant ones, so we make minor modifications by including the \u2206DS operations, e.g. INSERT, DELETE, and UPDATE, as part of the slot key: \u2206DSours = {(s1 \u2295 o1, v1), ...(sm \u2295 om, vm)}, where o is the slot operation. To resolve ties that still remain with this modification, we use the BM25 (Robertson et al., 2009) score between the target and example\u2019s last bot and user utter-\n3Note that t \u0338= t\u2032 because the retrieved example may not occur at the same tth turn.\nances (bt \u2212 1, ut).4 With our changes, we were able to observe a much better top k = 1 match, which we verified manually with 100 random samples. We denote examples retrieved with this new SCS+BM25 score as the Oracle because getting \u2206DS requires knowing the DS that we would like to predict ahead of time, and therefore cannot be used at test time. However, the Oracle score is useful for training a retriever that can retrieve examples with similar \u2206DS and for estimating the upper bound for DST-EGQA.\nUsing the Oracle score, for each sample in the training set, we calculate its similarity with other training samples and select the top 200 samples. From the selected samples, we pair the top ten and bottom ten as hard positive and hard negative samples, respectively, to train a SentenceBERTbased (Reimers and Gurevych, 2019) retriever using contrastive loss. We call the resulting retriever IC-DST-retriever v2 (IDR2). This is the same configuration for creating the dataset that was used to train the original retriever used for IC-DST, but instead of using x% of the entire training data, we use the entire training set of the first domain T1 to train separate retrievers for each of the five domain orderings. We impose this constraint such that we conduct our experiments under the practical assumption that we are only provided data for T1 at the beginning and we do not want to extend the continual learning problem for training the retriever. More details of IDR2\u2019s training procedure can be found in Section A.3."
        },
        {
            "heading": "2.4 Dialogue-level sampling for memory",
            "text": "The approaches that we outlined thus far are not orthogonal to existing continual learning methods. Therefore, they can be combined to further boost performance. One of the simplest methods is memory replay, which samples training data from previous tasks and adds them to the current training set so that the models forget less. For memory replay to be effective, it is important to select representative and nonredundant training samples.\nIn DST, a training sample is a single turn in a dialogue, since dialogue state is predicted for every turn. To reduce redundant instances, we propose a simple change to selecting training samples. Instead of combining turns from all dialogues and then randomly sampling turns, we propose sam-\n4Refer to Appendix A.2 for the details of the original definition of state change similarity and the reasoning behind our modification details.\npling at the dialogue-level first and then including all turns from the sampled dialogues to form the memory. The motivation is that there are rarely the same type of dialogue state updates within a dialogue, but there is a high chance that frequent dialogue state updates across dialogues may be sampled multiple times when using turn-level sampling.\nThe simple difference between the sampling strategies are clearer when observing their code snippets in Python 3:\nTurn-level sampling. 1 # flatten() turns a nested list into a single-level list. 2 chosen_turn_samples = random.sample(\nflatten(dialogue), memory size)\nDialogue-level sampling. 1 samples = random.sample(dialogue, memory size//10); 2 chosen_turn_samples = random.sample(\nflatten(samples), memory size)"
        },
        {
            "heading": "3 Experimental Setup",
            "text": ""
        },
        {
            "heading": "3.1 Data",
            "text": "We use the continual learning setup proposed by Zhu et al. (2022), which uses 15 single domains from the Schema Guided Dialogue dataset (Rastogi et al., 2020), and aggregate our results over the same five domain orders to make the most reliable comparisons with their results. Comparing results with the same order is crucial as we find that results can have significant variance depending on the chosen domains and their order. For multi-task training, there is only a single permutation, and therefore we aggregate results over runs with three different seed values. Our formulation described in Section 2.2 shows that we are operating under the assumption that the domain of interest will be known ahead of time."
        },
        {
            "heading": "3.2 Evaluation",
            "text": "DST performance is mainly measured by joint goal accuracy (JGA), which indicates the percentage of turns for which all slot values are correctly predicted. For CL, given JGA for domain i after training up to the tth domain at,i and the total number of domains T , we compare our approaches with three metrics from Zhu et al. (2022):\n(i) Average JGA = 1\nT T\u2211 i=1 aT,i, the average of JGA\non each domain after training on all domains in\nthe continual learning setup, (ii) Forward Trans-\nfer (FWT) = 1\nT \u2212 1 T\u2211 i=2 ai\u22121,i, how much training\non the current domain boosts JGA on future unseen domains, and (iii) Backward Transfer (BWT)\n= 1\nT \u2212 1 T\u22121\u2211 i=1 aT,i\u2212ai,i, how much the training on the current domain reduces JGA on data from previously seen domains. We place the most importance on Final JGA, while FWT and BWT provide additional signal on how different approaches provide more transferability, and hence task consistency, between domains."
        },
        {
            "heading": "3.3 Baselines",
            "text": "We replicate the baseline results from Zhu et al. (2022) using their implementation, which include approaches from Madotto et al. (2021):\n\u2022 SimpleTOD (Hosseini-Asl et al., 2020): perform DST as a structured text generation task, predicting the full state as a single sequence. As was done in Zhu et al. (2022), we modify the SimpleTOD format to append the domain name at the end of the dialogue history as described in Equation 1.\n\u2022 Memory: randomly select M turns from the training data for each previous domain and include it in the current domain\u2019s training data.\n\u2022 EWC: use the same samples selected for memory replay to regularize with the Fisher information matrix (Kirkpatrick et al., 2017)\n\u2022 AdapterCL (Madotto et al., 2021): freeze the base model and train parameter efficient adapters for each domain with number of weights that are equivalent to 2% of that of the pretrained model.\n\u2022 Continual Prompt Tuning (Zhu et al., 2022): freeze the base model and continually train soft prompts after reformulating DST as a masked-span recovery task (Raffel et al., 2020). We include their best results, which take advantage of a memory buffer for replay and for memory-guided backward transfer, a form of regularization that prevents updates if doing so would increase the current model\u2019s loss on the memory samples by computing gradients on them.\nFor DST-EGQA, we compare various configurations to better understand the strengths and weak-\nnesses of our approach. We vary the retriever used during training and combine with other memory replay strategies. We also show CPT Multi-task and DST-EGQA Multi-task to show the multi-tasking upper bound performance for average JGA."
        },
        {
            "heading": "3.4 Retrieval baselines",
            "text": "We also experiment with various retrieval techniques as baselines to IDR2:\n\u2022 Random sampling\n\u2022 BM25 (Robertson et al., 2009)\n\u2022 OpenAI\u2019s text-embedding-ada-002 model5\n\u2022 SentenceBERT (Reimers and Gurevych, 2019): the all-mpnet-base-v26\n\u2022 The original IC-DST retriever (oIDR): the retriever from Hu et al. (2022) that was trained with the original SCS formulation and pairs created from the MultiWOZ 2.1 dataset (Eric et al., 2020).\nOther than random sampling and BM25, retrieval ranking is based on the similarity between sentence embeddings, which is the dot product between the query and the key. With the exception of oIDR, which was trained to identify similarity with the last turn\u2019s dialogue state and last utterance pairs between the bot and user: {(st\u22121,i = vt\u22121,i) | i \u2208 I} \u2295 ut\u22121 \u2295 ut, the query and key of the database uses only the last utterance pairs: ut\u22121 \u2295 ut. We found this approach to be better as it diminishes the undesirably high similarity assigned to examples from the same dialogue that have the same previous dialogue state."
        },
        {
            "heading": "3.5 Technical details",
            "text": "We conduct our experiments with the T5-small model (Raffel et al., 2020). We train with a single GPU using the AdamW optimizer, a learning rate of 1e-4, and a batch size of 16. We train on each domain for ten epochs without early stopping. We select the checkpoint with the best validation set performance when moving on to the next domain. Our experiments are run on V100, A40, and A100 GPUs, based on availability.7\n5https://platform.openai.com/docs/ guides/embeddings\n6https://www.sbert.net/docs/ pretrained_models.html\n7Our preliminary experiments with different GPU types with otherwise identical configurations showed that the choice"
        },
        {
            "heading": "4 Experiments and Analysis",
            "text": ""
        },
        {
            "heading": "4.1 Main results",
            "text": "TransferQA\u2019s format is more CL-friendly. The results for only transforming the DST from prior work (Equation 1) to that of granular question answering using the TransferQA (Equation 2) format is shown in the row for DST-EGQA \u2212 In-context examples in Table 1. Without the help of any incontext examples, the transformation alone yields a dramatic improvement in CL performance, increasing average JGA from 14.4 to 43.2, and also improving on both FWT and BWT. These results supports our hypothesis that a question answering task that is understandable through natural language is more conducive to better continual learning than learning to generate service-specific structured output.\nExample-guided question answering further enhances CL performance. The subsequent rows for DST-EGQA shows that fine-tuning with incontext examples can further enhance all CL metrics by a large margin. Most notable is the boosts that are seen in the FWT, for which memory replay has almost a negligible effect. Augmenting DSTEGQA with memory replay leads to even larger boosts, even exceeding the CPT Multi-task model, with most gains coming from BWT, which is expected with memory replay methods. Using the Oracle retriever at test time leads to statistically insignificant improvements, indicating that IDR2 can retrieve examples that are on par with the Oracle examples. Lastly, we can see that the relative gains in Average JGA and BWT from memory replay becomes less pronounced with models trained with in-context examples, indicating that memory replay and example-guided question answering have overlapping gains.\nDouble-dipping the training set as a retrieval database does not lead to overfitting. It is important to note that, because our retrieval methods are commutative, a target sample that is paired with an example will serve as an example when the example becomes the target sample. Therefore, the answers for all training samples are seen as part of the context during training with our setup described in Section 2.3. This raises overfitting concerns that the model could easily memorize the\nof GPU in final performance introduces minimal variability to the final result.\nanswers for all samples and thus not learn generalizable question-answering. Interestingly, this does not seem to be the case, as training in this setup leads to improved or on-par final test set performance compared to training without any examples. This implies that our approach does not impose additional data constraints of having to split the training set into dedicated training samples and retrieval samples for it to be effective.\nHowever, not shown in Table 1 is that we find that DST-EGQA is sensitive to the training dynamics (Section 4.2) and the quality of the retrieved examples (Section 4.3)."
        },
        {
            "heading": "4.2 Training dynamics",
            "text": "In practical settings we don\u2019t have an oracle retriever, and our database may not contain the a perfect example for each case seen at test time. Thus, we may in fact retrieve irrelevant examples. It is important for the model to be able to handle these situations. Specifically, it should be able to leverage relevant examples, yet ignore irrelevant ones. To become more robust to these realistic circumstances, it may be useful to intentionally mix in irrelevant examples during training for DST-EGQA. We vary the combination of IDR2 and Oracle used for training, validation, and test time. Results in Table 2 support our hypothesis, showing that aligning the retrieval method from training time with the method used at test time leads to the best performance. Interestingly, best performance is achieved by using the Oracle retriever at validation time, shown by the large gap between IDR2 \u2192 IDR2 \u2192 IDR2 and IDR2 \u2192 Oracle \u2192 IDR2 (second and third row). This is somewhat surprising given that one may expect selecting a checkpoint that performs the best in the same setting as test time would lead to better test time performance."
        },
        {
            "heading": "4.3 Retrieval method sensitivity",
            "text": "The findings from Section 4.2 raises a question on whether training with other retrievers that may provide a different mixture of good and bad exam-\nples can lead to a further boost performance with DST-EGQA. We apply all the retrievers defined in Section 2.3 and use the same training dynamics that led to best results previously to examine each retriever\u2019s effectiveness. As shown in Table 3, our IDR2 model seems to capture this balance the most effectively, as it is significantly better than all other retrieval methods."
        },
        {
            "heading": "4.4 Memory sampling strategy and size",
            "text": "We study the effect of the memory sampling strategy and the size of the memory budget. We do not use in-context examples for all configurations to study their effects in isolation. As hinted by the results in Table 1, dialogue-level sampling seems to be a superior sampling strategy to turn-level sampling. We take a deeper dive into the relationship between the two sampling techniques and how both approaches scale with memory budgets by varying the memory budget sizes to 10, 50, and 100. Here, size refers to the number of training samples. To make sure the comparison between turn-level and dialogue-level samples is fair, we sample dialogues until the total number of turns in sampled dialogues exceed the target size, and then sample the targeted\nnumber of samples from the exceeded set. Table 4 shows that dialogue-level sampling achieves a significantly better performance for all equivalent memory budget sizes for turn-level sampling and is even on par with the next budget size used for turn-level sampling. This is likely due to dialogue-sampling leading to a more comprehensive set of samples that cover a wider diversity of dialogue state updates in these smaller sizes of the memory budget as described in subsection 2.4. As the memory budget becomes larger, however, the gap between turn-level sampling and dialogue-level sampling diminishes, since both methods converge to multi-task training when the memory budget is unlimited."
        },
        {
            "heading": "4.5 Number of in-context examples",
            "text": "We also study the effect of having more than one incontext example and share the results in Table 5. Including only one example to learn from in-context creates a single point of failure, which is especially risky for suboptimal retrieval methods. Having additional examples to learn from can help mitigate this risk. Therefore, we repeat our experiments using multiple in-context examples. However, at least with small model sizes, the DST models are not able to effectively leverage additional examples. This is not surprising for the Oracle retriever, where in most cases the top example is the best example that can be leveraged from the training set."
        },
        {
            "heading": "5 Related Work",
            "text": "Continual learning Continual learning prolongs the lifetime of a model by training it further with new incoming data without incurring the cost of\ncatastrophic forgetting (McCloskey and Cohen, 1989; French, 1999). There are three main branches of continual learning: architecture-based methods, replay-based methods, and regularization-based methods. Architecture-based methods propose dynamically adding model weights when learning new data (Fernando et al., 2017; Shen et al., 2019). Replay-based methods mitigate catastrophic forgetting by keeping a small sample of the previous data as part of a a memory budget to train with the new data (Rebuffi et al., 2017; Hou et al., 2019). These methods mainly experiment with sampling strategies and memory budget efficiency. Lastly, regularization-based methods place constraints on how the model becomes updated during training with the new data such that its performance on previous data is maintained (Kirkpatrick et al., 2017; Li and Hoiem, 2018).\nDialogue state tracking Continual learning for DST has been explored by a series of recent work that applied a combination of methods mentioned above. Liu et al. (2021) expanded on SOMDST (Kim et al., 2020) with prototypical sample selection for the memory buffer and multi-level knowledge distillation as a regularization mechanism. Madotto et al. (2021) applied various continual learning methods to end-to-end task-oriented dialogue models and found that adapters are most effective for the intent classification and DST while memory is most effective for response generation. More recently, Zhu et al. (2022) proposed Continual Prompt Tuning (CPT), which is most related to our work. CPT improves continual learning performance by finetuning soft prompts for each domain and reformulating DST to align with T5\u2019s maskedspan recovery pretraining objective (Raffel et al., 2020). Compared to CPT, we suggest a more granular reformulation to facilitate the learning from examples and do not rely on any regularization nor additional weights.\nTask reformulation and in-context learning Enhancing a model\u2019s generalizability to various tasks by reformulating input and/or outputs to become more uniform has become an increasingly popular method for massive multi-task learning (Aghajanyan et al., 2021), even for tasks that are considered distant from one another. T5 (Raffel et al., 2020) accelerated this movement by providing dataset or task-specific labels or minimal instructions to the inputs and then doing multi-task\ntraining. Building on T5, Sanh et al. (2022) and Wei et al. (2021) used more elaborate and diverse set of instruction templates and showed that this can significantly boost zero-shot performance. Cho et al. (2022) applied a similar idea to a more selective set of pre-finetuning tasks before training on the target DST dataset to improve DST robustness. Tk-instruct (Wang et al., 2022) takes a step further by scaling up the amount of tasks included in T0 and also provides positive and negative examples in the context in addition to the instructions. Similarly, Min et al. (2022) introduced MetaICL, which explicitly trains a model with the few-shot in-context learning format used for large language models (Brown et al., 2020), and showed that it showed better in-context learning performance than larger models. Task reformulation has also been recently explored to help the model better understand the task at hand and reduce domain-specific memorization and thus boost zero-shot DST performance (Li et al., 2021; Lin et al., 2021; Gupta et al., 2022; Zhao et al., 2022)."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this paper, we propose Dialogue State Tracking as Example-Guided Question Answering as a method for enhancing continual learning performance that factors dialogue state tracking into granular question answering tasks and fine-tunes the model to leverage relevant in-context examples to answer these questions. Our method is an effective alternative to existing continual learning approaches that does not rely on complex regularization, parameter expansion, or memory sampling techniques. Analysis of our approach reveals that even models as small as 60M parameters can be trained to perform in-context learning for continual learning and that complementing such a model with a randomly sampled memory achieves stateof-the-art results compared to strong baselines.\nLimitations\nUsing the TransferQA idea and retrieved examples for in-context fine-tuning adds a lot of configurations, which we have not been exhaustively explored, in lieu of prioritization of, we judged, more important experiments. For example, we did not explore sensitivity to the specific wording of questions, as was done with T0 (Sanh et al., 2022). We leave as future work the testing of the hypothesis that having more diverse questions per slot can lead\nto even more generalizability between domains and bring even further improvements to DST-EGQA.\nAnother limitation of DST-EGQA is that the retrieval database stores all previously seen samples from training and thus can be considered a memory with infinite size in our current formulation. Although the samples in the retrieval database are not used as training samples and provided as in-context examples during inference after being trained with subsequent services, the memory requirement for maintaining the database may be quite high. However, we believe that this memory requirement is still less restrictive than having the compute for fully retraining the model with all data whenever the model needs to learn a new service, especially when the training data set is large.\nLastly, an important practical consideration is the varying technical overhead in implementation and portability of different approaches. Compared to other approaches, training and inference is relatively simple, as we use an autoregressive text generation objective without special modifications. However, while our approach does not require any additional parameters, it does require a database and a retrieval model that is comparable in size to the DST model. Therefore, depending on the technical constraints, managing these two components may be less desirable."
        },
        {
            "heading": "A Additional details",
            "text": "A.1 TransferQA format The TransferQA format (Lin et al., 2021) has two different formats depending on whether the question is multiple choice or extractive. Categorical questions with fixed answer choices are given as multiple choice questions where the options are provided as part of the context, prepended by [opt]. Extractive questions do not have a special format. We remove the prefix Extractive Question: and Multi-choice QA as the presence of [opt] already allows the model to distinguish between the two. In addition, when there are in-context examples, we add [target] and [example] so that the model can distinguish between the examples and the target. The original and our modifications are shown in Figure 3.\nA.2 State change similarity Given two sets of state changes represented as \u2206DSa = {(s1, v1), ...(sm vm)} and \u2206DSb = {(s1, v1), ...(sn vn)}, where s is the slot key and v is the slot value to update the slot to, Hu et al. (2022) defines state change similarity (SCS) as the average of the similarity between slot keys s, Fslot and the similarity between key value pairs, Fslot\u2212value:\nSCS(\u2206DSa,\u2206DSb) = 1\n2 (Fslot + Fslot\u2212value)\nSimilarity F between the two sets is measured by computing the average of two F1 scores using each set as the target. We use the standard calculation: F1 = 2PR P+R , where P is precision and R is recall.\nThe resulting ties with this formula were not as critical for IC-DST (Hu et al., 2022), because top k examples, where k is a sizeable value that includes most ties, were all provided as in-context learning examples.\nA.3 IC-DST retriever v2 We use the same hyperparameter settings as oIDR (Hu et al., 2022), which uses a learning rate of 2e\u22125, 1000 warm-up steps, and the contrastive loss objective. We experimented with a binary classification and triplet evaluator at test time for discriminating between similar and dissimilar samples and selecting the best checkpoint to use. The binary classification evaluator determines accuracy based\non cosine similarity between the paired examples and an automatically calculated similarity threshold that results in the best accuracy. The triplet evaluator, on the other hand, compares whether distance(q, p) > distance(q, n), where p is the similar pair, n is the negative pair, and q is the query that serves as the anchor between the similar and dissimilar samples. We find that the two evaluators yield statistically insignificant differences in the final performance for our approach and therefore we use the triplet evaluator for all the results included in this work. We exclude the previous turn\u2019s dialogue state as the input query when fine-tuning SentBERT (Reimers and Gurevych, 2019)."
        }
    ],
    "title": "Continual Dialogue State Tracking via Example-Guided Question Answering",
    "year": 2023
}