{
    "abstractText": "The tremendous growth of social media users interacting in online conversations has led to significant growth in hate speech affecting people from various demographics. Most of the prior works focus on detecting explicit hate speech, which is overt and leverages hateful phrases, with very little work focusing on detecting hate speech that is implicit or denotes hatred through indirect or coded language. In this paper, we present CoSyn, a context synergized neural network that explicitly incorporates userand conversational-context for detecting implicit hate speech in online conversations. CoSyn introduces novel ways to encode these external contexts and employs a novel context interaction mechanism that clearly captures the interplay between them, making independent assessments of the amounts of information to be retrieved from these noisy contexts. Additionally, it carries out all these operations in the hyperbolic space to account for the scalefree dynamics of social media. We demonstrate the effectiveness of CoSyn on 6 hate speech datasets and show that CoSyn outperforms all our baselines in detecting implicit hate speech with absolute improvements in the range of 1.24% 57.8%. We make our code available1.",
    "authors": [
        {
            "affiliations": [],
            "name": "Sreyan Ghosh"
        },
        {
            "affiliations": [],
            "name": "Manan Suri"
        },
        {
            "affiliations": [],
            "name": "Purva Chiniya"
        },
        {
            "affiliations": [],
            "name": "Utkarsh Tyagi"
        },
        {
            "affiliations": [],
            "name": "Sonal Kumar"
        },
        {
            "affiliations": [],
            "name": "Dinesh Manocha"
        }
    ],
    "id": "SP:f4b1a6133860c80aabeef2e1226f51e8c0fdfcb4",
    "references": [
        {
            "authors": [
                "Vibhor Agarwal",
                "Sagar Joglekar",
                "Anthony P Young",
                "Nishanth Sastry."
            ],
            "title": "Graphnli: A graph-based natural language inference model for polarity prediction in online debates",
            "venue": "Proceedings of the WWW 2022, pages 2729\u20132737.",
            "year": 2022
        },
        {
            "authors": [
                "Chen Avin",
                "Zvi Lotker",
                "David Peleg",
                "Yvonne-Anne Pignolet",
                "Itzik Turkel."
            ],
            "title": "Elites in social networks: An axiomatic approach to power balance and price\u2019s square root law",
            "venue": "PloS one, 13(10):e0205820.",
            "year": 2018
        },
        {
            "authors": [
                "Albert-L\u00e1szl\u00f3 Barab\u00e1si",
                "Eric Bonabeau."
            ],
            "title": "Scalefree networks",
            "venue": "Scientific american, 288(5):60\u201369.",
            "year": 2003
        },
        {
            "authors": [
                "Helena Bonaldi",
                "Sara Dellantonio",
                "Serra Sinem Tekiro\u011flu",
                "Marco Guerini."
            ],
            "title": "Humanmachine collaboration approaches to build a dialogue dataset for hate speech countering",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Nat-",
            "year": 2022
        },
        {
            "authors": [
                "Tommaso Caselli",
                "Valerio Basile",
                "Jelena Mitrovi\u0107",
                "Inga Kartoziya",
                "Michael Granitzer."
            ],
            "title": "I feel offended, don\u2019t be abusive! implicit/explicit messages in offensive and abusive language",
            "venue": "Proceedings of the 12th LREC.",
            "year": 2020
        },
        {
            "authors": [
                "Ines Chami",
                "Zhitao Ying",
                "Christopher R\u00e9",
                "Jure Leskovec."
            ],
            "title": "Hyperbolic graph convolutional neural networks",
            "venue": "Advances in neural information processing systems, 32.",
            "year": 2019
        },
        {
            "authors": [
                "Krzysztof Choroma\u0144ski",
                "Micha\u0142 Matuszak",
                "Jacek Miekisz."
            ],
            "title": "Scale-free graph with preferential attachment and evolving internal vertex structure",
            "venue": "Journal of Statistical Physics, 151(6):1175\u20131183.",
            "year": 2013
        },
        {
            "authors": [
                "James W Cooley",
                "John W Tukey."
            ],
            "title": "An algorithm for the machine calculation of complex fourier series",
            "venue": "Mathematics of computation, 19(90):297\u2013 301.",
            "year": 1965
        },
        {
            "authors": [
                "Quentin D\u00e9nigot",
                "Heather Burnett."
            ],
            "title": "Dogwhistles as identity-based interpretative variation",
            "venue": "Proceedings of the Probability and Meaning Conference (PaM 2020), pages 17\u201325. ACL.",
            "year": 2020
        },
        {
            "authors": [
                "Mai ElSherief",
                "Caleb Ziems",
                "David Muchlinski",
                "Vaishnavi Anupindi",
                "Jordyn Seybolt",
                "Munmun De Choudhury",
                "Diyi Yang."
            ],
            "title": "Latent hatred: A benchmark for understanding implicit hate speech",
            "venue": "Proceedings of the 2021 Conference on Empirical Meth-",
            "year": 2021
        },
        {
            "authors": [
                "Zaki Mustafa Farooqi",
                "Sreyan Ghosh",
                "Rajiv Ratn Shah."
            ],
            "title": "Leveraging transformers for hate speech detection in conversational code-mixed tweets",
            "venue": "arXiv preprint arXiv:2112.09986.",
            "year": 2021
        },
        {
            "authors": [
                "Paula Fortuna",
                "S\u00e9rgio Nunes."
            ],
            "title": "A survey on automatic detection of hate speech in text",
            "venue": "ACM Computing Surveys (CSUR), 51(4):1\u201330.",
            "year": 2018
        },
        {
            "authors": [
                "Lei Gao",
                "Ruihong Huang."
            ],
            "title": "Detecting online hate speech using context aware models",
            "venue": "arXiv preprint arXiv:1710.07395.",
            "year": 2017
        },
        {
            "authors": [
                "Tanmay Garg",
                "Sarah Masud",
                "Tharun Suresh",
                "Tanmoy Chakraborty."
            ],
            "title": "Handling bias in toxic speech detection: A survey",
            "venue": "arXiv preprint arXiv:2202.00126.",
            "year": 2022
        },
        {
            "authors": [
                "Karish Grover",
                "SM Angara",
                "Md Akhtar",
                "Tanmoy Chakraborty"
            ],
            "title": "Public wisdom matters! discourse-aware hyperbolic fourier co-attention for social-text classification",
            "venue": "arXiv preprint arXiv:2209.13017",
            "year": 2022
        },
        {
            "authors": [
                "Joshua R Gubler",
                "Nathan P Kalmoe."
            ],
            "title": "Violent rhetoric in protracted group conflicts: Experimental evidence from israel and india",
            "venue": "Political Research Quarterly, 68(4):651\u2013664.",
            "year": 2015
        },
        {
            "authors": [
                "Liam Hebert",
                "Lukasz Golab",
                "Robin Cohen."
            ],
            "title": "Predicting hateful discussions on reddit using graph transformer networks and communal context",
            "venue": "2022 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology",
            "year": 2022
        },
        {
            "authors": [
                "Yiqiao Jin",
                "Xiting Wang",
                "Ruichao Yang",
                "Yizhou Sun",
                "Wei Wang",
                "Hao Liao",
                "Xing Xie."
            ],
            "title": "Towards fine-grained reasoning for fake news detection",
            "venue": "Proceedings of the AAAI, volume 36, pages 5746\u2013 5754.",
            "year": 2022
        },
        {
            "authors": [
                "David Jurgens",
                "Libby Hemphill",
                "Eshwar Chandrasekharan."
            ],
            "title": "A just and comprehensive strategy for using NLP to address online abuse",
            "venue": "Proceedings of the 57th Annual Meeting of the ACL, pages 3658\u20133666. ACL.",
            "year": 2019
        },
        {
            "authors": [
                "Jonathan Leader Maynard",
                "Susan Benesch."
            ],
            "title": "Dangerous speech and dangerous ideology: An integrated model for monitoring and prevention",
            "venue": "Genocide Studies and Prevention, 9(3).",
            "year": 2016
        },
        {
            "authors": [
                "Jessica Lin."
            ],
            "title": "Leveraging world knowledge in implicit hate speech detection",
            "venue": "arXiv preprint arXiv:2212.14100.",
            "year": 2022
        },
        {
            "authors": [
                "Yi-Ju Lu",
                "Cheng-Te Li."
            ],
            "title": "Gcan: Graphaware co-attention networks for explainable fake news detection on social media",
            "venue": "arXiv preprint arXiv:2004.11648.",
            "year": 2020
        },
        {
            "authors": [
                "Hiren Madhu",
                "Shrey Satapara",
                "Sandip Modha",
                "Thomas Mandl",
                "Prasenjit Majumder."
            ],
            "title": "Detecting offensive speech in conversational code-mixed dialogue on social media: A contextual dataset and benchmark experiments",
            "venue": "Expert Systems with Appli-",
            "year": 2023
        },
        {
            "authors": [
                "Rijul Magu",
                "Jiebo Luo."
            ],
            "title": "Determining code words in euphemistic hate speech using word embedding networks",
            "venue": "Proceedings of the 2nd Workshop on Abusive Language Online (ALW2), pages 93\u2013100. ACL.",
            "year": 2018
        },
        {
            "authors": [
                "Binny Mathew",
                "Ritam Dutt",
                "Pawan Goyal",
                "Animesh Mukherjee."
            ],
            "title": "Spread of hate speech in online social media",
            "venue": "Proceedings of the 10th ACM WWW, pages 173\u2013182.",
            "year": 2019
        },
        {
            "authors": [
                "Binny Mathew",
                "Punyajoy Saha",
                "Seid Muhie Yimam",
                "Chris Biemann",
                "Pawan Goyal",
                "Animesh Mukherjee."
            ],
            "title": "Hatexplain: A benchmark dataset for explainable hate speech detection",
            "venue": "Proceedings of the AAAI, volume 35, pages 14867\u201314875.",
            "year": 2021
        },
        {
            "authors": [
                "Pushkar Mishra",
                "Marco Del Tredici",
                "Helen Yannakoudakis",
                "Ekaterina Shutova."
            ],
            "title": "Author profiling for abuse detection",
            "venue": "Proceedings of the 27th ICCL, pages 1088\u20131098. ACL.",
            "year": 2018
        },
        {
            "authors": [
                "Sandip Modha",
                "Thomas Mandl",
                "Prasenjit Majumder",
                "Shrey Satapara",
                "Tithi Patel",
                "Hiren Madhu."
            ],
            "title": "Overview of the hasoc subtrack at fire 2022: Identification of conversational hate-speech in hindi-english code-mixed and german language",
            "venue": "Working Notes of",
            "year": 2022
        },
        {
            "authors": [
                "Sandip Modha",
                "Thomas Mandl",
                "Gautam Kishore Shahi",
                "Hiren Madhu",
                "Shrey Satapara",
                "Tharindu Ranasinghe",
                "Marcos Zampieri"
            ],
            "title": "Overview of the hasoc subtrack at fire",
            "year": 2021
        },
        {
            "authors": [
                "Nicolas Ocampo",
                "Ekaterina Sviridova",
                "Elena Cabrio",
                "Serena Villata."
            ],
            "title": "An in-depth analysis of implicit and subtle hate speech messages",
            "venue": "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Lin-",
            "year": 2023
        },
        {
            "authors": [
                "John Pavlopoulos",
                "Prodromos Malakasiotis",
                "Juli Bakagianni",
                "Ion Androutsopoulos."
            ],
            "title": "Improved abusive comment moderation with user embeddings",
            "venue": "Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism, pages",
            "year": 2017
        },
        {
            "authors": [
                "John Pavlopoulos",
                "Jeffrey Sorensen",
                "Lucas Dixon",
                "Nithum Thain",
                "Ion Androutsopoulos"
            ],
            "title": "Toxicity detection: Does context really matter? arXiv preprint arXiv:2006.00998",
            "year": 2020
        },
        {
            "authors": [
                "Juan Manuel P\u00e9rez",
                "Franco Luque",
                "Demian Zayat",
                "Mart\u00edn Kondratzky",
                "Agust\u00edn Moro",
                "Pablo Serrati",
                "Joaqu\u00edn Zajac",
                "Paula Miguel",
                "Natalia Debandi",
                "Agust\u00edn Gravano"
            ],
            "title": "Assessing the impact of contextual information in hate speech detection",
            "year": 2022
        },
        {
            "authors": [
                "James A Piazza."
            ],
            "title": "Politician hate speech and domestic terrorism",
            "venue": "International Interactions, 46(3):431\u2013453.",
            "year": 2020
        },
        {
            "authors": [
                "Jing Qian",
                "Anna Bethke",
                "Yinyin Liu",
                "Elizabeth M. Belding-Royer",
                "William Yang Wang."
            ],
            "title": "A benchmark dataset for learning to intervene in online hate speech",
            "venue": "Conference on Empirical Methods in Natural Language Processing.",
            "year": 2019
        },
        {
            "authors": [
                "Jing Qian",
                "Mai ElSherief",
                "Elizabeth Belding",
                "William Yang Wang."
            ],
            "title": "Leveraging intra-user and inter-user representation learning for automated hate speech detection",
            "venue": "NAACL-HLT 2018, pages 118\u2013123. ACL.",
            "year": 2018
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych."
            ],
            "title": "Sentence-bert: Sentence embeddings using siamese bert-networks",
            "venue": "arXiv preprint arXiv:1908.10084.",
            "year": 2019
        },
        {
            "authors": [
                "Natali Ruchansky",
                "Sungyong Seo",
                "Yan Liu."
            ],
            "title": "Csi: A hybrid deep model for fake news detection",
            "venue": "Proceedings of the 2017 ACM on CIKM, pages 797\u2013806.",
            "year": 2017
        },
        {
            "authors": [
                "Manuela Sanguinetti",
                "Fabio Poletto",
                "Cristina Bosco",
                "Viviana Patti",
                "Marco Stranisci."
            ],
            "title": "An italian twitter corpus of hate speech against immigrants",
            "venue": "Proceedings of the eleventh LREC.",
            "year": 2018
        },
        {
            "authors": [
                "Maarten Sap",
                "Saadia Gabriel",
                "Lianhui Qin",
                "Dan Jurafsky",
                "Noah A Smith",
                "Yejin Choi."
            ],
            "title": "Social bias frames: Reasoning about social and power implications of language",
            "venue": "arXiv preprint arXiv:1911.03891.",
            "year": 2019
        },
        {
            "authors": [
                "Ramit Sawhney",
                "Shivam Agarwal",
                "Atula T. Neerkaje",
                "Kapil Jayesh Pathak."
            ],
            "title": "Orthogonal multimanifold enriching of directed networks",
            "venue": "Proceedings of The 25th International Conference on Artificial Intelligence and Statistics, volume 151 of",
            "year": 2022
        },
        {
            "authors": [
                "Ramit Sawhney",
                "Shivam Agarwal",
                "Atula Tejaswi Neerkaje",
                "Nikolaos Aletras",
                "Preslav Nakov",
                "Lucie Flek."
            ],
            "title": "Towards suicide ideation detection through online conversational context",
            "venue": "Proceedings of the 45th International ACM SIGIR Confer-",
            "year": 2022
        },
        {
            "authors": [
                "Ramit Sawhney",
                "Shivam Agarwal",
                "Megh Thakkar",
                "Arnav Wadhwa",
                "Rajiv Ratn Shah."
            ],
            "title": "Hyperbolic online time stream modeling",
            "venue": "Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval,",
            "year": 2021
        },
        {
            "authors": [
                "Ramit Sawhney",
                "Harshit Joshi",
                "Rajiv Ratn Shah",
                "Lucie Flek."
            ],
            "title": "Suicide ideation detection via social and temporal user representations using hyperbolic learning",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for",
            "year": 2021
        },
        {
            "authors": [
                "Anna Schmidt",
                "Michael Wiegand."
            ],
            "title": "A survey on hate speech detection using natural language processing",
            "venue": "Fifth International Workshop on Natural Language Processing for Social Media, pages 1\u201310. ACL.",
            "year": 2017
        },
        {
            "authors": [
                "Anna Schmidt",
                "Michael Wiegand."
            ],
            "title": "A survey on hate speech detection using natural language processing",
            "venue": "Fifth International Workshop on Natural Language Processing for Social Media, April 3, 2017, pages 1\u201310. ACL.",
            "year": 2019
        },
        {
            "authors": [
                "Amit Sheth",
                "Valerie L Shalin",
                "Ugur Kursuncu."
            ],
            "title": "Defining and detecting toxicity on social media: context and knowledge are key",
            "venue": "Neurocomputing, 490:312\u2013318.",
            "year": 2022
        },
        {
            "authors": [
                "Leif Sigerson",
                "Cecilia Cheng."
            ],
            "title": "Scales for measuring user engagement with social network sites: A systematic review of psychometric properties",
            "venue": "Computers in Human Behavior, 83:87\u2013105.",
            "year": 2018
        },
        {
            "authors": [
                "Kai Sheng Tai",
                "Richard Socher",
                "Christopher D Manning."
            ],
            "title": "Improved semantic representations from tree-structured long short-term memory networks",
            "venue": "arXiv preprint arXiv:1503.00075.",
            "year": 2015
        },
        {
            "authors": [
                "Lin Tian",
                "Xiuzhen Jenny Zhang",
                "Jey Han Lau."
            ],
            "title": "Duck: Rumour detection on social media by modelling user and comment propagation networks",
            "venue": "NAACL-HLT 2022, pages 4939\u20134949.",
            "year": 2022
        },
        {
            "authors": [
                "Nitasha Tiku",
                "Casey Newton"
            ],
            "title": "Twitter ceo:\u201cwe suck at dealing with abuse.",
            "year": 2015
        },
        {
            "authors": [
                "Bertie Vidgen",
                "Dong Nguyen",
                "Helen Margetts",
                "Patricia Rossini",
                "Rebekah Tromble."
            ],
            "title": "Introducing cad: the contextual abuse dataset",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics:",
            "year": 2021
        },
        {
            "authors": [
                "William Warner",
                "Julia Hirschberg."
            ],
            "title": "Detecting hate speech on the world wide web",
            "venue": "Proceedings of the Second Workshop on Language in Social Media, pages 19\u201326. ACL.",
            "year": 2012
        },
        {
            "authors": [
                "Zeerak Waseem",
                "Dirk Hovy."
            ],
            "title": "Hateful symbols or hateful people? predictive features for hate speech detection on Twitter",
            "venue": "Proceedings of the NAACL Student Research Workshop, pages 88\u201393. ACL.",
            "year": 2016
        },
        {
            "authors": [
                "Michael Wiegand",
                "Josef Ruppenhofer",
                "Thomas Kleinbauer."
            ],
            "title": "Detection of Abusive Language: the Problem of Biased Datasets",
            "venue": "NAACL-HLT 2019, pages 602\u2013608. ACL.",
            "year": 2019
        },
        {
            "authors": [
                "Zhiping Xiao",
                "Weiping Song",
                "Haoyan Xu",
                "Zhicheng Ren",
                "Yizhou Sun."
            ],
            "title": "Timme: Twitter ideology-detection via multi-task multi-relational embedding",
            "venue": "Proceedings of the 26th ACM SIGKDD, pages 2258\u20132268.",
            "year": 2020
        },
        {
            "authors": [
                "Chengkun Zhang",
                "Junbin Gao."
            ],
            "title": "Hype-han: Hyperbolic hierarchical attention network for semantic embedding",
            "venue": "Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence, pages 3990\u20133996.",
            "year": 2021
        },
        {
            "authors": [
                "erief"
            ],
            "title": "2021) is a hate speech dataset of 27K",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Hate speech is defined as the act of making utterances that can potentially offend, insult, or threaten a person or a community based on their caste, religion, sexual orientation, or gender (Schmidt and Wiegand, 2019). For social media companies like Twitter, Facebook, and Reddit, appropriately dealing with hate speech has been a crucial challenge (Tiku and Newton, 2015). Hate speech can take the form of overt abuse, also known as explicit hate speech (Schmidt and Wiegand, 2017), or can be uttered in coded or indirect language, also known as\n1https://github.com/Sreyan88/CoSyn \u2217These authors contributed equally to this work.\nimplicit hate speech (Jurgens et al., 2019). Fig.1 illustrates a Twitter conversation where users convey hate implicitly through sarcasm and conversational context. Societal Problem and Impact. Though a considerable amount of research has been done on detecting explicit hate speech (Schmidt and Wiegand, 2019), detecting implicit hate speech is a greatly understudied problem in the literature, despite the social importance and relevance of the task. In the past, extremist groups have used coded language to assemble groups for acts of aggression (Gubler and Kalmoe, 2015) and domestic terrorism (Piazza, 2020) while maintaining deniability for their actions (D\u00e9nigot and Burnett, 2020). Because it lacks clear lexical signals, implicit hate utterances evade keyword-based detection systems (Wiegand et al., 2019), and even the most advanced neural architectures may not be effective in detecting such utter-\nances (Caselli et al., 2020).\nCurrent Challenges. Current state-of-the-art hate speech detection systems fail to effectively detect implicit and subtle hate (Ocampo et al., 2023). Detecting implicit hate speech is difficult for multiple reasons: (1) Linguistic nuance and diversity: Implicit hate can be conveyed through sarcasm, humor (Waseem and Hovy, 2016), euphemisms (Magu and Luo, 2018), circumlocution (Gao and Huang, 2017), and other symbolic or metaphorical languages (Qian et al., 2018). (2) Varying context: Implicit hate can be conveyed through everything from dehumanizing comparisons (Leader Maynard and Benesch, 2016), and stereotypes (Warner and Hirschberg, 2012) to threats, intimidation, and incitement to violence (Sanguinetti et al., 2018; Fortuna and Nunes, 2018). (3) Lack of sufficient linguistic signals: Unlike parent posts, which contain sufficient linguistic cues through background knowledge provided by the user, replies or comments to the parent post are mostly short and context-less reactions to the parent post. These factors make implicit hate speech difficult to detect and emphasize the need for better learning systems.\nWhy prior work is insufficient. (ElSherief et al., 2021) define implicit hate speech as \u201ccoded or indirect language that disparages a person or group.\u201d They also propose the first dataset, Latent Hatred, to benchmark model performance on implicit hate speech classification and show that existing stateof-the-art classifiers fail to perform well on the benchmark. Though Latent Hatred builds on an exhaustive 6-class taxonomy, it ignores implicit hate speech that is conversational-context-sensitive even though it accounts for a majority of implicit hate speech online (Modha et al., 2022; Hebert et al., 2022). Lin (2022) builds on Latent Hatred and propose one of the first systems to classify implicit hate speech leveraging world knowledge through knowledge graphs (KGs). However, beyond the fact that their system is restricted to only English due to the unavailability of such KGs in other languages, their system also fails to capture any kind of external context, which is vital for effective hate speech detection (Sheth et al., 2022). Thus, we first extend the definition of implicit hate speech to include utterances that convey hate only in the context of the conversational dialogue (example in Fig.1). Next, we propose a novel neural learning system to solve this problem.\nMain Contributions. In this paper, we propose CoSyn, a novel neural network architecture for detecting implicit hate speech that effectively incorporates external contexts like conversational and user. Our primary aim is to classify whether a target utterance (text only) implies hate or not, including the ones that signal hate implicitly. CoSyn jointly models the user\u2019s personal context (historical and social) and the conversational dialogue context in conversation trees. CoSyn has four main components: (1) To encode text utterances, we train a transformer sentence encoder and promote it to learn bias-invariant representations. This helps us to handle keyword bias, a long-standing problem in hate speech classification (Garg et al., 2022). (2) We start by modeling the user\u2019s personal historical context using a novel Hyperbolic Fourier Attention Network (HFAN). HFAN models diverse and scale-free user engagement of a user on social media by leveraging Discrete Fourier Transform (Cooley and Tukey, 1965) and hyperbolic attention on past user utterances. (3) We next model the user\u2019s personal social context using a Hyperbolic Graph Convolutional Network (HGCN) (Chami et al., 2019). HGCN models the scale-free dynamics of social networks using hyperbolic learning, leveraging the social connections between users, which act as edges in the graph. (4) Finally, to jointly model a user\u2019s personal context and the conversational dialogue context, we propose a novel Context Synergized Hyperbolic Tree-LSTM (CSHT). CSHT effectively models the scale-free nature of conversation trees and clearly captures the interaction between these context representations in the hyperbolic learning framework. We describe all our components in detail in Section 2.7. To summarize, our main contributions are as follows:\n\u2022 We introduce CoSyn, the first neural network architecture specifically built to detect implicit hate speech in online conversations. CoSyn leverages the strengths of existing research and introduces novel modules to explicitly take into account user and conversational context integral to detecting implicit hate speech.\n\u2022 Through extensive experimentation, we show that CoSyn outperforms all our baselines quantitatively on 6 hate speech datasets with absolute improvements of 1.24% - 57.8%.\n\u2022 We also perform extensive ablative experiments and qualitative comparisons to prove\nthe efficacy of CoSyn."
        },
        {
            "heading": "2 Methodology",
            "text": "Fig. 3 provides a clear pictorial representation of our proposed model architecture (algorithm shown in Algorithm 1). We provide an overview describing various operations in Hyperbolic Geometry in Appendix 2.2; and we request our readers to refer to that for more details. In this section, we describe the three constituent components of our proposed CoSyn, which model different aspects of context, namely, the author\u2019s personal historical context, the author\u2019s personal social context, and both the personal historical and social contexts with the conversational context."
        },
        {
            "heading": "2.1 Background, Notations, and Problem Formulation.",
            "text": "Let\u2019s suppose we have N distinct conversation trees, where each tree is denoted by Tn \u2208 T = {T0, \u00b7 \u00b7 \u00b7 , Tn, \u00b7 \u00b7 \u00b7 , TN}. Each tree Tn has JTn individual utterances denoted by Tn = {tTn0 , \u00b7 \u00b7 \u00b7 , t Tn j , \u00b7 \u00b7 \u00b7 , t Ti J }. Each individual utterance tTnj is authored by one of the L users in the dataset denoted by u \u2208 {u0, \u00b7 \u00b7 \u00b7 , ul, \u00b7 \u00b7 \u00b7 , uL}. The primary aim of CoSyn is to classify each utterance t into its label ygt \u2208 {0, 1} where 0 and 1 indicate whether the utterance is hateful or not. Additionally, each hateful utterance (ygti = 1) is labeled with yip \u2208 {0, 1} where 0 and 1 indicate whether the hateful utterance is explicitly or implicitly hateful. yip is used only for analysis. In the following subsections, \"user\" refers to the author of an utterance in a conversation tree to be assessed."
        },
        {
            "heading": "2.2 Hyperbolic Geometry: Background",
            "text": "Hyperbolic Geometry. A Riemannian manifold is a D-dimensional real and smooth manifold defined with an inner product on tangent space gx : TxM\u00d7 TxM \u2192 R at each point x \u2208 M, where the tangent space TxM is a D-dimensional vector space representing the first-order local approximation of the manifold around a given point x. A Poincar\u00e9 ball manifold is a hyperbolic space defined as a constant negative curvature Riemannian manifold, denoted by ( HD, g ) where manifold\nHD = { x \u2208 RD : \u2225x\u2225< 1 } and the Riemannian metric is given by gx = \u03bb2xg E where gE = ID denotes the identity matrix, i.e., the Euclidean metric tensor and \u03bbx = 11\u2212\u2225\u2225x\u2225\u22252 . To perform operations in the hyperbolic space, the exponential map\nexpx : TxHD \u2192 HD and the logarithmic map logx : HD \u2192 TxHD are used to project Euclidean vectors to the hyperbolic space and vice versa respectively.\nexpx(v) := x\u2295 ( tanh ( \u03bbx\u2225v\u2225\n2\n) v\n\u2225v\u2225\n) (1)\nlogx(y) := 2 \u03bbx tanh\u22121(\u2225\u2212x\u2295y\u2225) \u2212x\u2295 y \u2225\u2212x\u2295 y\u2225 (2)\nwhere x, y \u2208 HD, v \u2208 TxHD. Further, to perform operations in the Hyperbolic space, the following basic hyperbolic operations are described below:\nMob\u0308ius Addition \u2295 adds a pair of points x, y \u2208 HD as,\nx\u2295 y := ( 1 + 2\u27e8x, y\u27e9+ \u2225y\u22252 ) x+ ( 1\u2212 \u2225x\u22252 ) y\n1 + \u27e8x, y\u27e9+ \u2225x\u22252\u2225y\u22252 (3)\nM\u00f6bius Multiplication \u2297 multiplies vectors x \u2208 HD and W \u2208 RD\u2032\u00d7D given by,\nW \u2297 x := expo (W log0(x)) (4)\nM\u00f6bius Element-wise Multiplication \u2299 performs element-wise multiplication on x, y \u2208 HD,\nx\u2299 y := tanh ( \u2225xy\u2225 y tanh\u22121(\u2225y\u2225) ) \u2225xy\u2225 \u2225y\u2225 (5)\nHyperbolic Distance between points x,y \u2208 HD is given by:\ndB := 2 tanh \u22121(\u2225\u2212x\u2295 y\u2225) (6)\nFourier Transform. The Fourier transform breaks down a signal into its individual frequency components. When applied to a sequence xn with n \u2208 [0, N \u2212 1], the Discrete Fourier Transform (DFT) generates a new representation Xk for each value of k, where 0 \u2264 k \u2264 N \u2212 1. DFT accomplishes this by computing a sum of the original input tokens xn, multiplied by twiddle factors [e\u22122\u03c0ikn/N ], where n is the index of each token in the sequence. Thus, DFT is expressed as:\nXk = N\u22121\u2211 n=0 xne \u22122\u03c0ikn/N , 0 \u2264 k \u2264 N \u2212 1 (7)"
        },
        {
            "heading": "2.3 Bias-invariant Encoder Training",
            "text": "CoSyn, like other works in literature, builds on the assumption that linguistic signals from text utterances can effectively enable the detection of hate speech in online conversations. Thus, our primary aim is to learn an encoder e(. ) that can effectively generate vector representations Rd for a text utterance where d is the dimension of the vector. Specifically, we fine-tune a SentenceBERT (Reimers and Gurevych, 2019) and solve an additional loss proposed in (Mathew et al., 2021) using self-attention maps and ground-truth hate spans. Keyword bias is a long-standing problem in hate speech classification, and solving the extra objective promotes learning bias-invariant sentence representations."
        },
        {
            "heading": "2.4 Modeling Personal User Context",
            "text": "Modeling personal user context, in the form of author profiling, for hate speech classification has shown great success in the past because hateful users (users prone to making hate utterances) share common stereotypes and form communities around them. They exhibit strong degrees of homophily and have high reciprocity values (Mathew et al., 2019). We hypothesize that this will prove to be especially useful in classifying conversational implicit hate speech, which on its own lacks clear lexical signals or any form of background knowledge. Thus, our primary aim is to learn a vector representation Uu \u2208 Rd for the user u who has authored the utterance t to be assessed, where d is the dimension of the vector. For our work, we also explore the importance of the personal historical context of a user to enable better author profiling. Studies show that past social engagement and linguistic styles of their utterances on social media platforms play an important role in assessing the user\u2019s ideology and emotions (Xiao et al., 2020). Thus we propose a novel methodology for author profiling that is more intuitive, explainable, and effective for our task. Our primary aim is to model the user\u2019s (author of the utterance to be assessed) personal context and generate user representations Uu, which can then be used for hate speech classification. To achieve this, we first encode a user\u2019s historical utterances Uhistu using our Hyperbolic\nFourier Attention Network (HFAN) followed by modeling the user\u2019s social context by passing Uhistu through a Hyperbolic Graph Convolution Network (HGCN). To be precise, learning personal user context takes the form of e(HistoricalUtterances) \u2192 HFAN\u2192 Uhistu \u2192 HGCN\u2192 Uu. We next describe, in detail, HFAN and HGCN."
        },
        {
            "heading": "2.5 Hyperbolic Fourier Attention Network",
            "text": "User engagement on social media is often diverse and possesses scale-free properties (Sigerson and Cheng, 2018). Thus to account for the natural irregularities and effectively model a user\u2019s personal historical context, we propose a novel Hyperbolic Fourier Attention Network (HFAN). The first step is to encode historical utterances, Hu, using our encoder e(.), made by the user u, denoted by Hu \u2208 {hu0 , \u00b7 \u00b7 \u00b7 , hus , \u00b7 \u00b7 \u00b7 , huS}. Next, we apply 2D DFT to the embeddings (1D DFT along the temporal dimension and 1D DFT along the embedding dimension) to capture the most commonly occurring frequencies (ideologies, opinions, emotions, etc.) in the historical utterances made by the user using:\nUfourieru = expc0 (Fs (Fh (logc0 (e(Hu)))) (8)\nwhere F is the DFT operation. The 2D DFT operation helps highlight the most prominent frequencies, which signifies a holistic understanding of the user\u2019s sociological behavior. Next, we hypothesize that the frequencies most relevant to a conversation can act as the most important clues to\nassessing how a user would react to other utterances in the conversation tree (for e.g., a user\u2019s stance on the contribution of a particular political party to a recent riot in discussion). Additionally, these frequencies may change over time. Thus, to account for the latter factor first, we pass the embeddings through a Hyperbolic GRU (Zhang and Gao, 2021), which first projects these embeddings from the Euclidean to the hyperbolic space using a Poincar\u00e9 ball manifold and then effectively captures the sequential temporal context on time-aligned historic user utterances. The Hyperbolic GRU is a modified version of the conventional GRU, which performs Mobius operations on the Poincar\u00e9 model (addition, multiplication, and bias). We request our readers to refer to (Zhang and Gao, 2021) for more details. Next, to account for the former factor, we perform Hyperbolic Attention (Zhang and Gao, 2021), which first linearly projects the utterance embeddings within Poincar\u00e9 space and then constructs the final user embedding Uhistu via Einstein midpoint:\n\u03b1i = exp ( \u2212\u03b2hdL ( chL,h u sL \u2032)\u2212 ch) (9) Uhistu =\n\u2211 S\n[ \u03b1i\u03b3 (h\nu iK)\u2211 l \u03b1l\u03b3 ( huiK )]huiK, (10) where hsL and hsK are the utterance encoding of utterance hs obtained from Ufourieru projected from the Poincar\u00e9 space into the Lorentz space and Klein space for computational convenience (Zhang\nand Gao, 2021). csL is the sentence centroid, which is randomly initialized and learnable."
        },
        {
            "heading": "2.6 Hyperbolic Graph Convolutional Network",
            "text": "After obtaining the user representations Uhistu for every user u in the dataset, we model social relationships between the users as a graph G = (V , E). Each edge e = {ui, uj} \u2208 E represents one of the four types of relations: 1) User ui retweets a tweet posted by uj , 2) User ui mentions user uj in a tweet tt, 3) User ui replies to a post by user uj or 4) User ui follows user uj . Each vertex v \u2208 V represents the user representations Uu. HGCN (Chami et al., 2019) modifies the conventional GCN and performs neighbor aggregation using graph convolutions in the hyperbolic space to enrich a user\u2019s historical context representations learned through HFAN using social context. Social network connections between users on a platform often possess hierarchical and scale-free structural properties (degree distribution of nodes follows the power law as seen in Fig 2 and decreases exponentially with a few nodes having a large number of connections (Barab\u00e1si and Bonabeau, 2003)). To model such complex hierarchical representations, HGCN performs all operations in the Poincar\u00e9 space. We first project our representations U onto the hyperbolic space using a Poincar\u00e9 ball manifold (expK(.)) with a sectional curvature -1/K. Formally, the feature aggregation based at the ith HGCN layer is denoted by:\nO(i) = \u03c3\u2297 Ki\u22121,Ki ( FM ( A\u0303O(i\u22121)W(i) )) (11)\nwhere -1/Ki\u22121 and -1/Ki are the hyperbolic curvatures at layers i - 1 and i, respectively. A\u0303 = D\u22121/2AD\u22121/2 is the degree normalized adjacency matrix, W is a trainable network parameter , Oi is the output of the ith layer and FM is the Frechet Mean operation. \u03c3\u2297\nKi\u22121,Ki is the hyperbolic nonlinear activation allowing varying curvature at each layer."
        },
        {
            "heading": "2.7 Context-Synergized Hyperbolic Tree-LSTM",
            "text": "To model the conversational context in conversation trees effectively, we propose ContextSynergized Hyperbolic Tree-LSTM (CSHT). CSHT presents several modifications and improvements over Tree-LSTM (Tai et al., 2015), including (1) incorporating both the user\u2019s personal context and the conversation context while clearly capturing the interactions between them, and (2) operating in the hyperbolic space, unlike the original TreeLSTM, which operates in the Euclidean space. Conversation trees on social media possess a hierarchical structure of message propagation, where certain nodes may have many replies; e.g., nodes that include utterances from popular users. Such phenomena lead to the formation of hubs within the conversation tree, which indicates scale-free and asymmetrical properties of the conversation tree (Avin et al., 2018). The conversation tree is T represented using T = (V , E), where vertex v \u2208 V represents the encoded utterance Xj = e(tj) (t is part of the conversation tree T ) and edge e \u2208 E represents one of the three relations between the utterances: (1) parent-comment, (2) comment-reply or (3) replyreply. CSHT is modeled as a Bi-Directional TreeLSTM [\u2212\u2212\u2212\u2192 CSHT (Xj ;Uu) , \u2190\u2212\u2212\u2212 CSHT (Xj ;Uu) ] where Uu is the user representation of the user u who authored the utterance to be assessed obtained from the HGCN.\nIn order to understand the signals in CHST, we focus on a specific node tj . We gather information from all input nodes tk where {tk, tj} \u2208 E , and combine their hidden states hk using Einstein\u2019s midpoint to produce an aggregated hidden state h\u0303j for node tj . We use the hyperbolic representation of the current post, denoted as Xj , as well\nas the user embeddings of the author of the post, denoted as Uu, to define computational gates operating in the hyperbolic space for CSHT cells. As defined in Subsection2.2\u2299,\u2295,\u2297 represent M\u00f6bius Dot Product, M\u00f6bius Addition and M\u00f6bius matrix multiplication, respectively.\nConsidering multiple input nodes tk, {tk, tj} \u2208 E , we implement multiple hyperbolic forget gates incorporating the outputs hk of the input nodes with the current node\u2019s combined user and post representation rj .\nrj = W (fx) \u2297Xj \u2295W(fg) \u2297 Uu,\nfjk = expo ( \u03c3 ( logo ( rj \u2295U(f) \u2297 hk \u2295 b(f) ))) (12)\nThe input gate ij and the intermediate memory gate uj corresponding to the representation for the current utterance are given by:\nij = expo \u03c3 ( logo ( W(i) \u2297Xj \u2295U(i) \u2297\nh\u0303j \u2295 b(i) )) (13)\nuj = expo ( tanh ( logo ( W(u) \u2297Xj \u2295U(u)\u2297\nh\u0303j \u2295 b(u) )))\n(14) The input gate mj and the intermediate memory gate sj corresponding to the user representation from the social graph are given by:\nmj = expo ( \u03c3 ( logo ( W(m) \u2297 Uu\u2295\nU(m) \u2297 h\u0303j \u2295 b(m) ))) (15)\nsj = expo\n( tanh ( logo ( W(s) \u2297 Uu\u2295\nU(s) \u2297 h\u0303j \u2295 b(s) ))) (16)\nThe output gate for the tree cell is then calculated as follows:\noj = expo ( \u03c3 ( logo ( W(o) \u2297 Uu \u2295U(o) \u2297 h\u0303j \u2295 b(o) ))) (17)\nThe parameters W(w),U(w),b(w) are learnable parameters in the respective gate w. We obtain the cell state for the current cell cj by combining the representations from the multiple forget gates fjk, k\u2200tk, s.t.{tk, tj} \u2208 E , as well as gates corresponding to the tweet and user representations as follows:\ncj = ij \u2299 uj \u2295mj \u2299 sj \u2295 \u2211 k fjk \u2299 ck (18)\nThese equations are applied recursively by blending in tree representations at every level. The output of the current cell, hj is given by:\nCHST(Xj ,Uj) = hj = oj \u2299 expo (tanh (cj)) (19) Final Prediction Layer. We concatenate the node output from CSHT hj , projected to the Euclidean space, with the Euclidean utterance features for the given tweet, Xj to form a robust representation incorporating features of the tweet along with social and conversational context derived from the CSHT network of CoSyn. This concatenated representation is passed through a final classification layer to obtain the final prediction ygtj = Softmax (MLP ([logo (hj) ;Xj ])). For training, we optimize a binary cross-entropy loss."
        },
        {
            "heading": "3 Experiments and Results",
            "text": ""
        },
        {
            "heading": "3.1 Dataset",
            "text": "We evaluate CoSyn on 6 conversational hate speech datasets; namely, Reddit (Qian et al., 2019), GAB (Qian et al., 2019), DIALOCONAN (Bonaldi et al., 2022), CAD (Vidgen et al., 2021), ICHCL (Modha et al., 2021) and Latent Hatred (ElSherief et al., 2021). Appendix A provides dataset statistics. Table 1 reports the micro-F1 scores averaged across 3 runs with 3 different random seeds.\nImplicit Hate Annotations. The original datasets do not have annotations to indicate if an utterance denotes implicit or explicit hate speech. Thus, for our work, we add extra annotations for evaluating how CoSyn fares against our baselines in understanding the context for detecting implicit hate speech. Specifically, we use Amazon Mechanical Turk (MTurk) and ask three individual MTurk workers to annotate if a given utterance conveys hate implicitly or explicitly. The primary factor was the requirement of conversational context to understand the conveyed hate. At stage (1), we provide them with the definition of hate speech and examples of explicit and implicit hate speech. At stage (2), we provide complete conversations and ask them to annotate implicit or explicit in a binary fashion. Cohen\u2019s Kappa Scores for inter-annotator agreement are provided with the dataset details in Appendix A."
        },
        {
            "heading": "3.2 Baselines",
            "text": "Due to the acute lack of prior work in this space, beyond just hate speech classification, we also compare our method with systems proposed in the thriving fake news detection literature, which considers conversational and user contexts to detect fake news. Some of these systems had to be adapted\nto our task, and we describe about the working of each baseline in detail in Appendix B. Specifically, we compare CoSyn with Sentence-BERT (Reimers and Gurevych, 2019), ConceptNet, HASOC (Farooqi et al., 2021), Conc-Perspective (Pavlopoulos et al., 2020), CSI (Ruchansky et al., 2017), GCAN (Lu and Li, 2020), HYPHEN (Grover et al., 2022), FinerFact (Jin et al., 2022), GraphNLI (Agarwal et al., 2022), DUCK (Tian et al., 2022), MRIL (Sawhney et al., 2022a) and Madhu (Madhu et al., 2023)."
        },
        {
            "heading": "3.3 Hyperparameters",
            "text": "We decide on the best hyper-parameters for CoSyn based on the best validation set performance using grid search. The optimal hyperparameters are found to be, batch-size b = 32, HGCN output embedding dimension g = 512, hidden dimension of CHST h = 768, latent dimension of HFAN l = 100, learning rate lr = 1.3e\u22122, weight decay \u03b2 = 3.2e\u22124, and dropout rate \u03b4 = 0.41."
        },
        {
            "heading": "3.4 Results and Ablations",
            "text": "Table 1 compares the performance of CoSyn with all our baselines on 6 hate speech datasets. As we see, Cosyn outperforms all our baselines both on the entire dataset and on the implicit subset, thus showing its effectiveness for implicit hate speech detection. Despite the ambiguous nature of implicit hate speech, CoSyn has high precision scores for implicit hate speech, thus implying that it mitigates the problem of false positives better than other baselines. One common observation is that our bias invariant SentenceBERT approach emerges as the most competitive baseline to CoSyn, thereby reinforcing that most prior work do not effectively leverage external context.\nWhen evaluated on the entire dataset, CoSyn achieves absolute improvements in the range of 5.1% - 35.2% on Reddit, 4.0% - 45.0% on CAD, 4.8% - 22.4% on DIALOCONAN, 3.9% - 42.7% on GAB, 9.7% - 38.4% on ICHCL and 5.8% - 31.6% on Latent Hatred ober our baselines. When evaluated on the implicit subsets, CoSyn achieves absolute improvements in the range of 5.1% - 57.9% on Reddit, 8.6% - 31.3% on CAD, 18.2% - 40.7% on DIALOCONAN, 2.9% - 28.5% on GAB, 8.2% - 19.5% on ICHCL and 1.2% - 18.1% on Latent Hatred.\nTable 2 ablates the performance of CoSyn, removing one component at a time to show the significance of each. All results have been averaged\nacross all 6 datasets. Some major observations include (1) CoSyn sees a steep drop in performance when used without user context (we model only the conversation context with a vanilla Tree-LSTM in the hyperbolic space). This proves the effectiveness of the user\u2019s personal context. Additionally, modeling user context with HFAN and HGCN proves to be more effective than just feeding meanpooled historical utterance embeddings into CSHT. (2) Modeling in the Euclidean space results in an overall F1 drop of 3.8%. We reinforce the effectiveness of modeling in the hyperbolic space through our findings in Fig. 2."
        },
        {
            "heading": "3.5 Results Analysis",
            "text": "In Fig. 4, we show test set predictions from 4 different conversation trees from the ICHCL dataset with an attempt to study the effect of conversational and author context for target utterance classification. We notice that hateful users possess high degrees of homophily and are predominantly hateful over time. It also reveals a limitation of CoSyn where insufficient context from the parent leads to a false positive (comment in the 4th example)."
        },
        {
            "heading": "4 Related Work",
            "text": "Prior research on identifying hate speech on social media has proposed systems that can flag online hate speech with remarkable accuracy (Schmidt and Wiegand, 2019). However, as mentioned\nearlier, prior efforts have focused primarily on classifying overt abuse or explicit hate speech (Schmidt and Wiegand, 2019) with little or no work on classifying implicit hate speech or that conveyed in coded language. The lack of research on this topic can also be attributed to existing datasets being skewed towards explicitly abusive text (Waseem and Hovy, 2016). Recently, this area of research has seen growing interest, with several datasets and benchmarks released for evaluating the performance of existing hate speech classifiers in identifying implicit hate speech (Caselli et al., 2020; ElSherief et al., 2021; Sap et al., 2019). One common observation is that most prior systems from literature fail to identify implicit hate utterances (ElSherief et al., 2021). Lin et al. (Lin, 2022) proposes one of the first systems to classify implicit hate speech leveraging world knowledge. However, they evaluate their performance on only Latent Hatred, which lacks conversational context. Additionally, acquiring\nworld knowledge through knowledge graphs (KGs) requires language-specific KGs, and short utterances in conversation trees make the retrieval weak. In the past, to classify context-sensitive hate speech in existing open-source datasets, researchers incorporated conversational context for hate speech classification (Gao and Huang, 2017; P\u00e9rez et al., 2022). However, these systems employ naive fusion and fail to leverage structural dependencies between utterances in the conversation tree. Another line of work explores author profiling using community-based social context (connections a user has with other users) (Pavlopoulos et al., 2017; Mishra et al., 2018). However, the representations are not learned end-to-end and employ naive fusion.\nHyperbolic networks have been explored earlier for tasks that include modeling user interactions in social media, like suicide ideation detection (Sawhney et al., 2021b, 2022b), fake news detection (Grover et al., 2022), online time stream modeling (Sawhney et al., 2021a), etc. All these works show that modeling the hierarchical and scale-free nature of social networks and data generated online benefits from modeling in the hyperbolic space over Euclidean space."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this paper, we present CoSyn, a novel learning framework to detect implicit hate speech in online conversations. CoSyn jointly models the conversational context and the author\u2019s historical and social context in the hyperbolic space to classify whether a target utterance is hateful. Leveraging these contexts allows CoSyn to effectively detect implicit hate speech ubiquitous in online social media."
        },
        {
            "heading": "Acknowledgement",
            "text": "This work was supported by ARO grants W911NF2310352 and W911NF2110026.\nLimitations\nIn this section, we list down some potential limitations of CoSyn:\n1. Lacking world knowledge is one of CoSyn\u2019s potential limitations. The inclusion of world knowledge could serve as a crucial context, enhancing CoSyn\u2019s performance in this task (Sheth et al., 2022). We would like to explore this as part of future work.\n2. Table 2 clearly demonstrates that CoSyn\u2019s effectiveness relies on the cohesive integration\nof all its components. Therefore, as a direction for future research, our focus will be on enhancing the performance of individual components.\nEthics Statement\nOur institution\u2019s Institutional Review Board (IRB) has granted approval for this study. In the annotation process, we took precautions by including a cautionary note in the instructions, alerting annotators to potentially offensive or distressing content. Annotators were also allowed to discontinue the labeling process if they felt overwhelmed.\nAdditionally, in light of the rapid proliferation of offensive language on the internet, numerous A0based frameworks have emerged for hate speech detection. Nevertheless, a significant drawback of many current hate speech detection models is their narrow focus on explicit or overt hate speech, thereby overlooking the identification of implicit expressions of hate that hold equal potential for harm. CoSyn could ideally identifying implicit hate speech with remarkable accuracy, preventing targeted communities from experiencing increased harm online."
        },
        {
            "heading": "A Dataset Details",
            "text": "Reddit. The Reddit hate speech intervention dataset (Qian et al., 2019) has 5,020 conversations, including 22,324 comments. On average, each conversation consists of 4.45 comments, and the length of each comment is 58.0 tokens. 5,257 comments are labeled hate speech, and 17,067 are labeled nonhate speech. Most conversations, 3,847 (76.6%), contain hate speech. Each conversation with hate speech has 2.66 responses on average, for a total of 10,243 intervention responses. The average length of the intervention responses is 17.96 tokens. User history, the timestamp for each post, and the username for each post were fetched using the Reddit API2. Dataset statistics can be found in Table 3. The Cohen\u2019s Kappa Scores for inter-annotator agreement for 3 pairs of annotators annotating for implicit hate speech were 0.78, 0.74, and 0.71.\nGAB. The GAB (Qian et al., 2019) 11,825 conversations, consisting of 33,776 posts. On average,\n2https://www.reddit.com/dev/api/\neach conversation consists of 2.86 posts, and the average length of each post is 35.6 tokens. 14,614 posts are labeled hate speech, and 19,162 are labeled non-hate speech. Nearly all the conversations, 11,169 (94.5%), contain hate speech. 31,487 intervention responses were originally collected for conversations with hate speech, or 2.82 responses per conversation on average. The average length of the intervention responses is 17.27 tokens. User history was fetched using the GAB API3. The metadata for each fetched post provides information like the author and timestamp for a post. Dataset statistics can be found in Table 6. The Cohen\u2019s Kappa Scores for inter-annotator agreement for 3 pairs of annotators annotating for implicit hate speech were 0.85, 0.82, and 0.91.\nDIALOCONAN. The DIALOCONAN dataset (Bonaldi et al., 2022) has more than 3K dialogical interactions between two interlocutors, one acting as the hater and the other as the NGO operator, for a total of more than 16K turns. The previous tweets of a particular user were considered to be the history for that. Dataset statistics can be found in Table 7. The Cohen\u2019s Kappa Scores for inter-annotator agreement for 3 pairs of annotators annotating for implicit hate speech were 0.79, 0.78, and 0.79.\nCAD. The CAD dataset (Vidgen et al., 2021) is an annotated dataset of \u2248 25,000 Reddit entries. The dataset is labeled with 6 conceptually different categories, including Identity-directed, Person-directed, Affiliation-directed, Counter Speech, Non-hateful Slurs, and Neutral. The dataset is also annotated with salient subcategories, such as whether personal abuse is directed at a person in the conversation thread or someone outside it. This taxonomy offers greater coverage and granularity of abuse than previous work. Each entry can be assigned to multiple primary and/or secondary categories. The dataset is also annotated in context, where each entry is annotated in the context of the conversational thread it is part of. Every annotation also has a label for whether contextual information was needed to make the annotation. User history, the timestamp for each post, and the username for each post were fetched using the Reddit API4. Dataset statistics can be found in Table 5. The Cohen\u2019s Kappa Scores for inter-annotator agreement for 3 pairs of annotators annotating for implicit hate speech were\n3https://www.npmjs.com/package/gab-api 4https://www.reddit.com/dev/api/\nAlgorithm 1 CoSyn: Implicit Hatespeech Detection Given:\nN distinct conversation trees T indexed by Tn L distinct users where each user is indexed by ul historical utterances of user u, Hu each tree Tn = {tTn0 , \u00b7 \u00b7 \u00b7 , t Tn j , \u00b7 \u00b7 \u00b7 , t Ti J } \u25b7J\nTn utterances Initialize:\ne(.)\u2190 e(JTn ) \u25b7Bias-invariant Encoder Training Uhistul \u2190 e(H ul ) \u25b7Encode historical utterances using HFAN. Uul \u2190 HGCN(U hist ul\n)) \u25b7Modeling Personal User Context Process:\nConsidering tTnj belonging to user ul Xj \u2190 e(tTnj ) hj \u2190 CSHT (Xj ,Uul ) \u25b7CSHT ygtj = Softmax (MLP ([logo (hj) ;Xj ])) \u25b7Final Prediction\nreturn ygtj\n0.65, 0.73, and 0.69.\nICHCL. The ICHCL dataset (Modha et al., 2021) (Identification of Conversational HateSpeech in Code-Mixed Languages) consists of hind-english code-switched Twitter conversations. The primary task is to identify comments and replies that can be considered acceptable when considered alone but may appear hateful, profane, or offensive when the context of a parent tweet is considered. Binary classification of such contextual posts was considered in this subtask. Around 7,000 code-mixed postings in English and Hindi were downloaded from Twitter and annotated in-house by the authors. User history was fetched using the Twitter API5. Dataset statistics can be found in Table 8. The Cohen\u2019s Kappa Scores for inter-annotator agreement for 3 pairs of annotators annotating for implicit hate speech were 0.72, 0.81, and 0.74.\nLatent Hatred. The Latent Hatred dataset (ElSherief et al., 2021) is a hate speech dataset of 27K Gab messages annotated according to a 6-class taxonomy that includes White Grievance, Incitement to Violence, Inferiority Language, Irony, Stereotypes and Misinformation, and Threatening and Intimidation. Comments for every post, the user\u2019s user history, and the timestamp for each post were fetched using the Twitter API6. Dataset statistics can be found in Table 4. The Cohen\u2019s Kappa Scores for inter-annotator agreement for 3 pairs of annotators annotating for implicit hate speech were 0.91, 0.96, and 0.89."
        },
        {
            "heading": "B Baseline Descriptions",
            "text": "Sentence-BERT w/ Classification Head We use our bias-invariant Utterance Encoder trained and\n5https://developer.twitter.com/en/docs/twitter-api 6https://developer.twitter.com/en/docs/twitter-api\ninferred on utterances in isolation for this baseline.\nConceptNet Similar to Sentence-BERT but fused with world knowledge from ConceptNet inspired from (ElSherief et al., 2021; Lin, 2022). HASOC (Farooqi et al., 2021) We use the system proposed by the winning solution in the HASOC 2021 challenge. The authors propose to train a transformer encoder by concatenating parentcomment-reply chains separated by the SEP token. Conc-Perspective (Pavlopoulos et al., 2020) Similar to HASOC, but context concatenation is done only during inference and not during training. CSI (Ruchansky et al., 2017) Capture, Score, and Integrate (CSI), originally proposed for fake news classification, implements a neural network to jointly learn the temporal pattern of user activity on a given utterance, and the user characteristic based on the behavior of users. GCAN (Lu and Li, 2020) Graph-aware CoAttention Network (GCAN), originally proposed for fake news classification, implements a neural network that uses the target utterance and its\npropagation-based user\u2019s features. HYPHEN (Grover et al., 2022) HYPHEN or Discourse-Aware Hyperbolic Fourier Co-Attention, proposed for social-text classification and incorporates conversational discourse knowledge with Abstract Meaning Representation graphs and employs co-attention in the hyperbolic space. FinerFact (Jin et al., 2022) FinerFact, originally proposed for fake news detection, incorporates a fine-grained reasoning framework by introducing a mutual reinforcement-based method for incorporating human knowledge and designs a prior-aware bi-channel kernel graph network to model subtle differences between pieces of evidence. GraphNLI (Agarwal et al., 2022) Graph-based Natural Language Inference Model (GraphNLI) proposes a graph-based deep learning architecture that effectively captures both the local and the global context in online conversation trees through graph-based walks. DUCK (Tian et al., 2022) Rumour detection with user and comment networks (DUCK), similar to CoSyn, employs graph attention networks to jointly model the contents and the structure of social media conversation trees, as well as the network of users who engage in these conversations."
        },
        {
            "heading": "C Additional Details",
            "text": "Model Parameters: Sentence-BERT has \u2248 110M parameters with 12-layers of encoder, 768-hiddenstate, 2048 feed-forward hidden-state and 8-heads. CoSyn has \u2248 18M parameters. Compute Infrastructure: All our experiments are conducted on a single NVIDIA A100 GPU. An entire CoSyn training pipeline takes \u2248 40 minutes.\nImplementation Software and Packages: We implement all our models in PyTorch 7 and use the HuggingFace 8 implementations of SentenceBERT.\nPotential Risks: CoSyn relies on training data that may contain biases inherent in the data sources.\n7https://pytorch.org/ 8https://huggingface.co/\nThe detection system may inadvertently amplify or reinforce existing societal biases if these biases are not adequately addressed. For example, if the training data is biased towards specific demographics or ideologies, the model might exhibit unfair treatment or misclassification of certain groups, leading to potential discrimination or harm. Understanding the contextual nuances of language is a complex task. CoSyn might also be prone to over-generalization, potentially resulting in false positives or misclassification of non-hateful speech. The risk is that legitimate expressions of opinion or controversial yet non-hateful statements may be mistakenly flagged as hate speech. This could inadvertently lead to censorship or suppression of freedom of speech, limiting open dialogue and critical discussions on important social issues."
        }
    ],
    "title": "CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a Context Synergized Hyperbolic Network",
    "year": 2023
}