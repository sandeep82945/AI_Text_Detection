{
    "abstractText": "Label aggregation such as majority voting is commonly used to resolve annotator disagreement in dataset creation. However, this may disregard minority values and opinions. Recent studies indicate that learning from individual annotations outperforms learning from aggregated labels, though they require a considerable amount of annotation. Active learning, as an annotation cost-saving strategy, has not been fully explored in the context of learning from disagreement. We show that in the active learning setting, a multi-head model performs significantly better than a single-head model in terms of uncertainty estimation. By designing and evaluating acquisition functions with annotator-specific heads on two datasets, we show that group-level entropy works generally well on both datasets. Importantly, it achieves performance in terms of both prediction and uncertainty estimation comparable to full-scale training from disagreement, while saving 70% of the annotation budget.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xinpeng Wang"
        }
    ],
    "id": "SP:6329a7c9c6c15c0a8e11bbcf1ef3a273a57c75e1",
    "references": [
        {
            "authors": [
                "Sohail Akhtar",
                "Valerio Basile",
                "Viviana Patti."
            ],
            "title": "Whose opinions matter? perspective-aware models to identify opinions of hate speech victims in abusive language detection",
            "venue": "arXiv preprint arXiv:2106.15896.",
            "year": 2021
        },
        {
            "authors": [
                "Lora Aroyo",
                "Chris Welty."
            ],
            "title": "Truth is a lie: Crowd truth and the seven myths of human annotation",
            "venue": "AI Magazine, 36(1):15\u201324.",
            "year": 2015
        },
        {
            "authors": [
                "Connor Baumler",
                "Anna Sotnikova",
                "Hal Daum\u00e9 III."
            ],
            "title": "Which examples should be multiply annotated? active learning when annotators may disagree",
            "venue": "Findings of the Association for Computational Linguistics: ACL 2023, pages 10352\u201310371, Toronto,",
            "year": 2023
        },
        {
            "authors": [
                "Beata Beigman Klebanov",
                "Eyal Beigman",
                "Daniel Diermeier."
            ],
            "title": "Analyzing disagreements",
            "venue": "Coling 2008: Proceedings of the workshop on Human Judgements in Computational Linguistics, pages 2\u20137, Manchester, UK. Coling 2008 Organizing Commit-",
            "year": 2008
        },
        {
            "authors": [
                "Trevor Cohn",
                "Lucia Specia."
            ],
            "title": "Modelling annotator bias with multi-task Gaussian processes: An application to machine translation quality estimation",
            "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume",
            "year": 2013
        },
        {
            "authors": [
                "Ido Dagan",
                "Sean P Engelson."
            ],
            "title": "Committeebased sampling for training probabilistic classifiers",
            "venue": "Machine Learning Proceedings 1995, pages 150\u2013 157. Elsevier.",
            "year": 1995
        },
        {
            "authors": [
                "Aida Mostafazadeh Davani",
                "Mark D\u00edaz",
                "Vinodkumar Prabhakaran."
            ],
            "title": "Dealing with disagreements: Looking beyond the majority vote in subjective annotations",
            "venue": "Transactions of the Association for Computational Linguistics, 10:92\u2013110.",
            "year": 2022
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Tommaso Fornaciari",
                "Alexandra Uma",
                "Silviu Paun",
                "Barbara Plank",
                "Dirk Hovy",
                "Massimo Poesio."
            ],
            "title": "Beyond black & white: Leveraging annotator disagreement via soft-label multi-task learning",
            "venue": "Proceedings of the 2021 Conference of the North Amer-",
            "year": 2021
        },
        {
            "authors": [
                "Gavin Gaffney Gaffney."
            ],
            "title": "Pushshift gab corpus",
            "venue": "https://files.pushshift.io/gab/.",
            "year": 2018
        },
        {
            "authors": [
                "Yarin Gal",
                "Zoubin Ghahramani."
            ],
            "title": "Dropout as a bayesian approximation: Representing model uncertainty in deep learning",
            "venue": "international conference on machine learning, pages 1050\u20131059. PMLR.",
            "year": 2016
        },
        {
            "authors": [
                "Daniel Gissin",
                "Shai Shalev-Shwartz."
            ],
            "title": "Discriminative active learning",
            "venue": "arXiv preprint arXiv:1907.06347.",
            "year": 2019
        },
        {
            "authors": [
                "Mitchell L Gordon",
                "Kaitlyn Zhou",
                "Kayur Patel",
                "Tatsunori Hashimoto",
                "Michael S Bernstein."
            ],
            "title": "The disagreement deconvolution: Bringing machine learning performance metrics in line with reality",
            "venue": "Proceedings of the 2021 CHI Conference on Human",
            "year": 2021
        },
        {
            "authors": [
                "Dan Hendrycks",
                "Kevin Gimpel."
            ],
            "title": "A baseline for detecting misclassified and out-of-distribution examples in neural networks",
            "venue": "International Conference on Learning Representations.",
            "year": 2017
        },
        {
            "authors": [
                "Marek Herde",
                "Daniel Kottke",
                "Denis Huseljic",
                "Bernhard Sick."
            ],
            "title": "Multi-annotator probabilistic active learning",
            "venue": "2020 25th International Conference on Pattern Recognition (ICPR), pages 10281\u201310288. IEEE.",
            "year": 2021
        },
        {
            "authors": [
                "Neil Houlsby",
                "Ferenc Husz\u00e1r",
                "Zoubin Ghahramani",
                "M\u00e1t\u00e9 Lengyel."
            ],
            "title": "Bayesian active learning for classification and preference learning",
            "venue": "arXiv preprint arXiv:1112.5745.",
            "year": 2011
        },
        {
            "authors": [
                "Dirk Hovy",
                "Taylor Berg-Kirkpatrick",
                "Ashish Vaswani",
                "Eduard Hovy."
            ],
            "title": "Learning whom to trust with MACE",
            "venue": "Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
            "year": 2013
        },
        {
            "authors": [
                "Brendan Kennedy",
                "Mohammad Atari",
                "Aida Mostafazadeh Davani",
                "Leigh Yeh",
                "Ali Omrani",
                "Yehsong Kim",
                "Kris Coombs",
                "Shreya Havaldar",
                "Gwenyth Portillo-Wightman",
                "Elaine Gonzalez"
            ],
            "title": "Introducing the gab hate",
            "year": 2022
        },
        {
            "authors": [
                "David D Lewis."
            ],
            "title": "A sequential algorithm for training text classifiers: Corrigendum and additional data",
            "venue": "Acm Sigir Forum, volume 29, pages 13\u201319. ACM New York, NY, USA.",
            "year": 1995
        },
        {
            "authors": [
                "Cecilia Ovesdotter Alm."
            ],
            "title": "Subjective natural language problems: Motivations, applications, characterizations, and implications",
            "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,",
            "year": 2011
        },
        {
            "authors": [
                "Ellie Pavlick",
                "Tom Kwiatkowski."
            ],
            "title": "Inherent disagreements in human textual inferences",
            "venue": "Transactions of the Association for Computational Linguistics, 7:677\u2013694.",
            "year": 2019
        },
        {
            "authors": [
                "Joshua C Peterson",
                "Ruairidh M Battleday",
                "Thomas L Griffiths",
                "Olga Russakovsky."
            ],
            "title": "Human uncertainty makes classification more robust",
            "venue": "Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9617\u20139626.",
            "year": 2019
        },
        {
            "authors": [
                "Barbara Plank",
                "Dirk Hovy",
                "Anders S\u00f8gaard"
            ],
            "title": "Linguistically debatable or just plain wrong? In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume",
            "year": 2014
        },
        {
            "authors": [
                "Dennis Reidsma",
                "Jean Carletta."
            ],
            "title": "Squibs: Reliability measurement without limits",
            "venue": "Computational Linguistics, 34(3):319\u2013326.",
            "year": 2008
        },
        {
            "authors": [
                "Filipe Rodrigues",
                "Francisco Pereira."
            ],
            "title": "Deep learning from crowds",
            "venue": "Proceedings of the AAAI conference on artificial intelligence, volume 32.",
            "year": 2018
        },
        {
            "authors": [
                "Maarten Sap",
                "Swabha Swayamdipta",
                "Laura Vianna",
                "Xuhui Zhou",
                "Yejin Choi",
                "Noah A. Smith."
            ],
            "title": "Annotators with attitudes: How annotator beliefs and identities bias toxic language detection",
            "venue": "Proceedings of the 2022 Conference of the North Amer-",
            "year": 2022
        },
        {
            "authors": [
                "Ozan Sener",
                "Silvio Savarese."
            ],
            "title": "Active learning for convolutional neural networks: A core-set approach",
            "venue": "arXiv preprint arXiv:1708.00489.",
            "year": 2017
        },
        {
            "authors": [
                "Victor S. Sheng",
                "Foster Provost",
                "Panagiotis G. Ipeirotis."
            ],
            "title": "Get another label? improving data quality and data mining using multiple, noisy labelers",
            "venue": "Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and",
            "year": 2008
        },
        {
            "authors": [
                "Harini Suresh",
                "John V Guttag."
            ],
            "title": "A framework for understanding unintended consequences of machine learning",
            "venue": "arXiv preprint arXiv:1901.10002, 2(8).",
            "year": 2019
        },
        {
            "authors": [
                "Alexandra Uma",
                "Tommaso Fornaciari",
                "Dirk Hovy",
                "Silviu Paun",
                "Barbara Plank",
                "Massimo Poesio."
            ],
            "title": "A case for soft loss functions",
            "venue": "Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, volume 8, pages 173\u2013177.",
            "year": 2020
        },
        {
            "authors": [
                "Alexandra Uma",
                "Tommaso Fornaciari",
                "Dirk Hovy",
                "Silviu Paun",
                "Barbara Plank",
                "Massimo Poesio."
            ],
            "title": "Learning from disagreement: A survey",
            "venue": "Journal of Artificial Intelligence Research, 72:1385\u20131470.",
            "year": 2021
        },
        {
            "authors": [
                "Zeerak Waseem",
                "Smarika Lulz",
                "Joachim Bingel",
                "Isabelle Augenstein."
            ],
            "title": "Disembodied machine learning: On the illusion of objectivity in nlp",
            "venue": "arXiv preprint arXiv:2101.11974.",
            "year": 2021
        },
        {
            "authors": [
                "Mike Zhang",
                "Barbara Plank."
            ],
            "title": "Cartography active learning",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, pages 395\u2013 406, Punta Cana, Dominican Republic. Association for Computational Linguistics.",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "An important aspect of creating a dataset is asking for multiple annotations and aggregating them in order to derive a single ground truth label. Aggregating annotations, however, implies a single golden ground truth, which is not applicable to many subjective tasks such as hate speech detection (Ovesdotter Alm, 2011). A human\u2019s judgement on subjective tasks can be influenced by their perspective and beliefs or cultural background (Waseem et al., 2021; Sap et al., 2022). When addressing disagreement in annotation, aggregating them by majority vote could result in the viewpoints of the minority being overlooked (Suresh and Guttag, 2019).\nIn order to address this issue, many works have been proposed to directly learn from the annotation disagreements in subjective tasks. There are two major approaches to achieving that: learning from the soft label (Peterson et al., 2019; Uma et al.,\n2020; Fornaciari et al., 2021) and learning from the hard label of individual annotators (Cohn and Specia, 2013; Rodrigues and Pereira, 2018; Davani et al., 2022).\nIn a recent work, Davani et al. (2022) shows that modelling the individual annotators by adding annotator-specific classification heads in a multitask setup outperforms the traditional approach that learns from a majority vote. However, training such a model needs a huge amount of data with multiple annotations to model the opinions and beliefs of the individual annotators.\nOn another line, Active Learning (AL) is a framework that allows learning from limited labelled data by querying the data to be annotated. In this paper, we propose to take the best of both worlds: active learning and human label variation, to mitigate the high cost of the annotation budget needed for training the model. In particular, we propose a novel active learning setting, where the multi-head model actively selects the annotator and the sample to be labelled. Our results show this effectively reduces annotation costs while at the same time allowing for modelling individual perspectives.\nKey Findings We made several key observations:\n\u2022 The multi-head model works significantly better than the single-head model on uncertainty estimation.\n\u2022 The use of group-level entropy is generally recommended. Individual-level entropy methods perform differently depending on the dataset properties.\n\u2022 The multi-head model achieves a performance comparable to full-scale training with only around 30% annotation budget."
        },
        {
            "heading": "2 Related Work",
            "text": ""
        },
        {
            "heading": "2.1 Learning from Disagreement",
            "text": "There is a growing body of work that studies irreconcilable differences between annotations (Plank et al., 2014; Aroyo and Welty, 2015; Pavlick and Kwiatkowski, 2019; Uma et al., 2021). One line of research aims at resolving the variation by aggregation or filtering (Reidsma and Carletta, 2008; Beigman Klebanov et al., 2008; Hovy et al., 2013; Gordon et al., 2021). Another line of research tries to embrace the variance by directly learning from the raw annotations (Rodrigues and Pereira, 2018; Peterson et al., 2019; Fornaciari et al., 2021; Davani et al., 2022), which is the focus of our paper."
        },
        {
            "heading": "2.2 Active Learning",
            "text": "In active learning, many different methods for selecting data have been proposed to save annotation cost, such as uncertainty sampling (Lewis, 1995) based on entropy (Dagan and Engelson, 1995) or approximate Bayesian inference (Gal and Ghahramani, 2016). Other approaches focus on the diversity and informativeness of the sampled data (Sener and Savarese, 2017; Gissin and Shalev-Shwartz, 2019; Zhang and Plank, 2021). Herde et al. (2021) proposed a probabilistic active learning framework in a multi-annotator setting, where the disagreement is attributed to errors. Recent work by Baumler et al. (2023) accepted the disagreement in the active learning setting, and they showed improvement over the passive learning setting using singlehead model. Our work shows the advantage of the multi-head model and compares it with traditional single-head active learning methods."
        },
        {
            "heading": "3 Method",
            "text": "Multi-head Model We use a multi-head model where each head corresponds to one unique annota-\ntor, following Davani et al., 2022. In the fine-tuning stage, annotations are fed to the corresponding annotator heads, adding their losses to the overall loss. During testing, the F1 score is calculated by comparing the majority votes of the annotator-specific heads with the majority votes of the annotations."
        },
        {
            "heading": "3.1 Multi-head Acquisition Functions",
            "text": "We study five acquisition functions for the multihead model. Since our model learns directly from the annotation, we care about which annotator should give the label. So we query the instanceannotation pair (xi, yai ) with its annotator ID a. In this way, our data is duplicated by the number of annotations available.\nRandom Sampling (Rand.) We conduct random sampling as a baseline acquisition method where we randomly sample K (data, annotation, annotator ID) pairs from the unlabeled data pool U at each active learning iteration.\nIndividual-level Entropy (Indi.) Intuitively, the annotator-specific heads model the corresponding annotators. Therefore, we can calculate the entropy of the classification head to measure the specific annotator\u2019s uncertainty. Given the logits za = [za1 , ..., z a n] of the head a, the entropy is calculated as following: Hindi(p a|x) = \u2212 \u2211n i=1 p a i (x) log(p a i (x)), where pai (x) = softmax(z a i (x)). Then we choose the (instance, annotator) pair with the highest entropy: argmaxx\u2208U,a\u2208AHindi(p\na|x), where U denotes the unlabeled set and A denotes the annotator pool. We compute entropy only for the remaining annotators who have not provided annotations for the instance.\nGroup-level Entropy (Group) Instead of looking at the individual\u2019s uncertainty, we can also query the data by considering the group-level uncertainty. One way to represent the uncertainty of the group on a sample is to calculate the entropy based on the aggregate of each annotatorspecific head\u2019s output. Therefore, we normalize and sum the logits of each head at the group level: zgroup = [z1, ..., zn] = \u2211H h=1 z h norm, and calculate the group-level entropy as follows: Hgroup(x) = \u2212 \u2211n i=1 pi(x) log(pi(x)), where pi(x) = softmax(zi(x)). We then query the data with the highest uncertainty.\nVote Variance (Vote) Another way to measure the uncertainty among a group is by measuring\nthe variance of the votes. Given the prediction yh of classification head h, we calculate the vote variance: Var = 1H \u2211H i=1(y\nh \u2212 \u00b5)2, where \u00b5 = 1 H \u2211H h=1 y\nh. This approach can be applied to binary classification or regression problems.\nMixture of Group and Indi. Entropy (Mix.) We also consider a variant which combines the group-level and individual-level entropy by simply adding the two: Hmix = Hindi +Hgroup."
        },
        {
            "heading": "4 Experiments",
            "text": "Dataset We selected two distinct hate speech datasets for our experiments: Hate Speech on Brexit (HS-Brexit) (Akhtar et al., 2021) and Gab Hate Corpus (GHC) (Kennedy et al., 2022). We split the raw annotation dataset according to the split of the aggregated version dataset provided. The HS-Brexit dataset includes 1,120 English tweets relating to Brexit and immigration, where a total of six individuals were involved in annotating each tweet. As each tweet contains all six annotations, we refer to HS-Brexit as densely annotated. In GHC, 27,665 social-media posts were collected from the public corpus of Gab.com (Gaffney, 2018). From a set of 18 annotators, each instance gets at least three annotations. Therefore, GHC is sparsely annotated. Both datasets contain binary labels y \u2208 [0, 1] and have almost the same positive/negative raw annotation ratio (0.15).\nSingle-head Model Baselines We implement four acquisition methods for single-head model active learning for comparison: Random sampling\n(Rand.), Max-Entropy (Ent.; Dagan and Engelson, 1995), Bayesian Active Learning by Disagreement (BALD; Houlsby et al., 2011) and Discriminative Active Learning (DAL; Gissin and ShalevShwartz, 2019). We compare them with the multihead approach with random sampling which has an average performance among the five multi-head acquisition methods we investigated.\nTwo different single-head model approaches are considered: Learning from the Majority Vote (Single-Majority) and Learning from Raw annotations (Single-Annotation). In the first setting, all annotators\u2019 annotations are queried, and the majority vote is used to train the model. In the second setting, we train the model with individual annotations without aggregation, following the repeated labelling approach by Sheng et al. (2008).\nExperimental Setup We follow the setup of Davani et al. (2022) for modelling and evaluation. We initialize the layers before the heads with a BERTbase model (Devlin et al., 2019). To balance training data, we do oversampling following Kennedy et al. (2022). Moreover, we use class weights on the loss function for multi-head model training, which makes it more stable. It is not used for the single-head model as it degrades performance.\nTo evaluate the model, we first report the F1 score against the majority vote. Secondly, we also compute individual F1 scores, measuring annotatorspecific heads against annotator labels. Thirdly and importantly, we are interested to gauge how well the model can predict the data uncertainty\nby calculating the Pearson correlation between the model\u2019s uncertainty and the annotation disagreement measured by the variance of the annotations on the same instance. For the single-head model, we use Prediction Softmax Probability proposed by Hendrycks and Gimpel (2017) as the uncertainty estimation of the model. For the multi-head model, we follow Davani et al. (2022) and calculate the variance of the prediction of the heads as the model\u2019s uncertainty."
        },
        {
            "heading": "5 Result",
            "text": "Single-head vs Multi-head Model Figure 2 shows the comparison of the multi-head model and the single-head during the active learning process In the upper row, we compare the multi-head approach with single-majority approach on majority F1 score and uncertainty estimation. In terms of predicting the majority vote, the multi-head model performs on par with the best-performing singlehead method on both datasets, such as BALD. For uncertainty estimation measured against annotator disagreement, the multi-head model outperforms the single-head model by a large margin.\nWe have the same observation when comparing with single-annotation model, shown in the bottom row. Therefore, we recommend using a multi-head model in a subjective task where humans may disagree and uncertainty estimation is important.\nLabel Diversity vs. Sample Diversity When it comes to group-level uncertainty based acquisition functions (Group and Vote), we tested two approaches to determine which annotator to query\nfrom: Label Diversity First and Sample Diversity First. In Label Diversity First, we query from all the available annotators to prioritize the label diversity of a single sample. In Sample Diversity Fisrat approach, we only randomly choose one of the annotators for annotation. Given the same annotation budget for each annotation round, Label Diversity First would query fewer samples but more annotations than Sample Diversity First approach. In our preliminary result, Label Diversity First shows stronger performance in general. Therefore, we adopt this approach for the following experiments.\nComparison of Multi-head acquisition functions To compare different strategies to query for annotations, we compare the five proposed acquisition functions from Section 3.1 in Fig 3. Group performs generally well on both datasets. We also see a trend here that HS-Brexit favours acquisition function based on group-level uncertainty (Vote), while individual-level uncertainty (Indi.) works better on GHC dataset. For HS-Brexit, Group is the best-performing method based on the majority F1 score. When evaluated on raw annotation (F1 indi. score), both vote variant and group-level entropy perform well. For uncertainty estimation, random sampling is slightly better than group-level entropy approach. On the GHC dataset, both Indi. and Group perform well on uncertainty estimation and raw annotation prediction. However, we don\u2019t see an obvious difference between all the acquisition functions on the majority vote F1 score.\nAnnotation Cost In terms of saving annotation cost, we see that the F1 score slowly goes into a\nplateau after around 25 rounds on both datasets in Fig 3, which is around 30% usage of the overall dataset (both datasets are fully labelled at around 90 rounds). For example, Vote achieves the majority F1 score of 52.3, which is 94% of the performance (55.8) of the full-scale training (round 90)."
        },
        {
            "heading": "6 Conclusion",
            "text": "We presented an active learning framework that embraces human label variation by modelling the annotator with annotator-specific classification heads, which are used to estimate the uncertainty at the individual annotator level and the group level. We first showed that a multi-head model is a better choice over a single-head model in the active learning setting, especially for uncertainty estimation. We then designed and tested five acquisition functions for the annotator-heads model on two datasets. We found that group-level entropy works generally well on both datasets and is recommended. Depending on the dataset properties, the individual-level entropy method performs differently.\nLimitations\nThe multi-head approach is only viable when the annotator IDs are available during the active learning process since we need to ask the specific annotator for labelling. Furthermore, the annotators should remain available for a period of time in order to provide enough annotations to be modelled by the specific head successfully. Note that we here simulate the AL setup. The multi-head approach is good at estimating the uncertainty based on the annotators it trains on, however, whether the uncertainty can still align with yet another pool of people is still an open question.\nFurther analysis is needed to understand why GHC and HS-Brexit favour different acquisition functions. Besides the difference between dense and sparse annotation, factors such as diversity of the topics covered and annotator-specific annotation statics are also important, which we leave as future work."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank the anonymous reviewers for their feedback. This research is supported by the ERC Consolidator Grant DIALECT 101043235."
        },
        {
            "heading": "A Data Preparation",
            "text": "In contrast to the traditional active learning approach, which only selects instances from the unlabeled data pool, our approach also considers which annotator should give the annotation since the annotation should be fed to the annotator-specific heads. To address this issue, we reform the dataset by splitting one instance with N annotations into N (data, annotation) pairs with its annotator ID. When selecting the batch from the populated data pool, the (data, annotation) pair is given to the classification head corresponding to its annotator ID."
        },
        {
            "heading": "B Active Learning Setting",
            "text": "Since our work focus on raw annotation, we set the seed dataset size and the query batch size based on the annotation budget. We set the annotation budget for HS-Brexit as (60, 60) for both seed data size and query data size respectively. For GHC, we set it as (200, 200)."
        },
        {
            "heading": "C Training Setup",
            "text": "We list our training parameter in Table 1. We halve the learning rate when the F1 score decreases at evaluation."
        }
    ],
    "title": "ACTOR: Active Learning with Annotator-specific Classification Heads to Embrace Human Label Variation",
    "year": 2023
}