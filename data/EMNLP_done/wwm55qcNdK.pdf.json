{
    "abstractText": "Large language models (LLMs) have been widely applied in various fields due to their excellent capability for memorizing knowledge and chain of thought (CoT). When these language models are applied in the field of psychological counseling, they often rush to provide universal advice. However, when users seek psychological support, they need to gain empathy, trust, understanding and comfort, rather than just reasonable advice. To this end, we constructed a multi-turn empathetic conversation dataset of more than 2 million samples, in which the input is the multi-turn conversation context, and the target is empathetic responses that cover expressions such as questioning, comfort, recognition, listening, trust, emotional support, etc. Experiments have shown that the empathy ability of LLMs can be significantly enhanced when finetuning by using multi-turn dialogue history and responses that are closer to the expression of a psychological consultant.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Yirong Chen"
        },
        {
            "affiliations": [],
            "name": "Xiaofen Xing"
        },
        {
            "affiliations": [],
            "name": "Jingkai Lin"
        },
        {
            "affiliations": [],
            "name": "Huimin Zheng"
        },
        {
            "affiliations": [],
            "name": "Zhenyu Wang"
        },
        {
            "affiliations": [],
            "name": "Qi Liu"
        },
        {
            "affiliations": [],
            "name": "Xiangmin Xu"
        }
    ],
    "id": "SP:d17dea228f146761876a1c0b7c979f8b75814cb2",
    "references": [
        {
            "authors": [
                "Yi Cheng",
                "Wenge Liu",
                "Wenjie Li",
                "Jiashuo Wang",
                "Ruihui Zhao",
                "Bang Liu",
                "Xiaodan Liang",
                "Yefeng Zheng."
            ],
            "title": "Improving multi-turn emotional support dialogue generation with lookahead strategy planning",
            "venue": "Proceedings of the 2022 Conference on Empiri-",
            "year": 2022
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Zhengxiao Du",
                "Yujie Qian",
                "Xiao Liu",
                "Ming Ding",
                "Jiezhong Qiu",
                "Zhilin Yang",
                "Jie Tang."
            ],
            "title": "GLM: General language model pretraining with autoregressive blank infilling",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational",
            "year": 2022
        },
        {
            "authors": [
                "Joseph L Fleiss."
            ],
            "title": "Measuring nominal scale agreement among many raters",
            "venue": "Psychological Bulletin, 76(5):378\u2013382.",
            "year": 1971
        },
        {
            "authors": [
                "Dirk Hovy",
                "Shannon L. Spruit."
            ],
            "title": "The social impact of natural language processing",
            "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 591\u2013598, Berlin, Germany. Association",
            "year": 2016
        },
        {
            "authors": [
                "Edward J Hu",
                "Yelong Shen",
                "Phillip Wallis",
                "Zeyuan Allen-Zhu",
                "Yuanzhi Li",
                "Shean Wang",
                "Lu Wang",
                "Weizhu Chen."
            ],
            "title": "LoRA: Low-rank adaptation of large language models",
            "venue": "International Conference on Learning Representations.",
            "year": 2022
        },
        {
            "authors": [
                "Chin-Yew Lin."
            ],
            "title": "ROUGE: A package for automatic evaluation of summaries",
            "venue": "Text Summarization Branches Out, pages 74\u201381, Barcelona, Spain. Association for Computational Linguistics.",
            "year": 2004
        },
        {
            "authors": [
                "Siyang Liu",
                "Chujie Zheng",
                "Orianna Demasi",
                "Sahand Sabour",
                "Yu Li",
                "Zhou Yu",
                "Yong Jiang",
                "Minlie Huang."
            ],
            "title": "Towards emotional support dialog systems",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics",
            "year": 2021
        },
        {
            "authors": [
                "Paul F Christiano",
                "Jan Leike",
                "Ryan Lowe."
            ],
            "title": "Training language models to follow instructions with human feedback",
            "venue": "Advances in Neural Information Processing Systems, volume 35, pages 27730\u201327744. Curran Associates, Inc.",
            "year": 2022
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311\u2013318, Philadelphia,",
            "year": 2002
        },
        {
            "authors": [
                "Wei Peng",
                "Yue Hu",
                "Luxi Xing",
                "Yuqiang Xie",
                "Yajing Sun",
                "Yunpeng Li."
            ],
            "title": "Control globally, understand locally: A global-to-local hierarchical graph network for emotional support conversation",
            "venue": "Proceedings of the Thirty-First International Joint Conference on",
            "year": 2022
        },
        {
            "authors": [
                "Wei Peng",
                "Ziyuan Qin",
                "Yue Hu",
                "Yuqiang Xie",
                "Yunpeng Li."
            ],
            "title": "Fado: Feedback-aware double controlling network for emotional support conversation",
            "venue": "Knowledge-Based Systems, 264:110340.",
            "year": 2023
        },
        {
            "authors": [
                "Huachuan Qiu",
                "Hongliang He",
                "Shuai Zhang",
                "Anqi Li",
                "Zhenzhong Lan"
            ],
            "title": "Smile: Single-turn to multi-turn inclusive language expansion via chatgpt for mental health support",
            "year": 2023
        },
        {
            "authors": [
                "Alec Radford",
                "Karthik Narasimhan",
                "Tim Salimans",
                "Ilya Sutskever"
            ],
            "title": "Improving language understanding by generative pre-training",
            "year": 2018
        },
        {
            "authors": [
                "Hannah Rashkin",
                "Eric Michael Smith",
                "Margaret Li",
                "Y-Lan Boureau."
            ],
            "title": "Towards empathetic opendomain conversation models: A new benchmark and dataset",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,",
            "year": 2019
        },
        {
            "authors": [
                "Hao Sun",
                "Zhenru Lin",
                "Chujie Zheng",
                "Siyang Liu",
                "Minlie Huang."
            ],
            "title": "PsyQA: A Chinese dataset for generating long counseling text for mental health support",
            "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages",
            "year": 2021
        },
        {
            "authors": [
                "Quan Tu",
                "Yanran Li",
                "Jianwei Cui",
                "Bin Wang",
                "Ji-Rong Wen",
                "Rui Yan."
            ],
            "title": "MISC: A mixed strategyaware model integrating COMET for emotional support conversation",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Lin-",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "With the birth of BERT (Devlin et al., 2019) and GPT (Radford et al., 2018), large language models (LLMs) have made rapid progress in the past five years. In November 2022, OpenAI launched ChatGPT2 (OpenAI, 2022), a large language model fine-tuning by reinforcement learning from human feedback (RLHF) (Ouyang et al., 2022). However, when applied to mental health or emotional support conversation, there are three main issues lead to ChatGPT appear less \u201chuman-centered\u201d:\n1) ChatGPT tends to provide repetitive and standardized responses. ChatGPT often uses the following template to respond to users\u2019 questions related to mental health: \"\u6211\u5f88\n\u2217Corresponding author. Email: xfxing@scut.edu.cn 1https://github.com/scutcyr/SoulChat 2https://chat.openai.com\n\u62b1\u6b49...\u3002xxx\u662f...\u3002\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5efa\u8bae\uff1a...\u3002 (I\u2019m sorry to ...{xxx} is ...Here are some suggestions:...)\", which may cause boredom.\n2) ChatGPT is inclined to provide suggestions rather than ask questions or listen. It is eager to solve users\u2019 problems, usually providing lengthy and general suggestions, as shown in Figure 12 of Appendix F. However, professional psychologists rarely provide specific suggestions during the counseling process.\n3) ChatGPT acts a bit like a rational \"Straight man\" for those users who need listening and comfort. Users who seek emotional support usually expect empathy support such as listening, understanding and comfort.\nSimilar issues can also be found in other LLMs, e.g. ChatGLM (Zeng et al., 2023), SparkDesk3, as presented in Appendix F. It may be due to the lack of large-scale multi-turn empathy conversation datasets for fine-tuning stage, especially in the field of Chinese mental health or emotional support. EMPATHETICDIALOGUES (Rashkin et al., 2019) and ESConv (Liu et al., 2021) are two English empathy conversation datasets that is used for developing emotional support conversation (ESC) systems, e.g MISC (Tu et al., 2022), GLHG (Peng et al., 2022), MultiESC (Cheng et al., 2022), FADO (Peng et al., 2023) and etc. On the one hand, these models may rely on annotated empathy strategies and emotions of users during the training or inference stage, which means that building large-scale similar datasets for fine-tuning LLMs is difficult. On the other hand, these datasets are in English, so that they cannot be applied to fine-tune Chinese LLMs. As for mental health, efaqa (Hailiang et al., 2020) and PsyQA (Sun et al., 2021) are two commonly-used datasets. Among\n3https://xinghuo.xfyun.cn\nthem, efaqa contains 20,000 conversations and provides annotation information such as types of troubles, psychological disorders, SOS, etc. However, efaqa has a complex multi-party dialogue relationship and a high proportion of low-quality responses from netizens, while PsyQA contains 22,346 questions and 56,063 single-turn long-text psychological counseling conversations. Thus, neither of these datasets can solve the three issues of ChatGPT mentioned above.\nRecently, Qiu et al. (2023) proposed a SMILE approach to employ ChatGPT to convert singleturn dialogues into multi-turn ones. They utilized SMILE to extend the single-turn conversation dataset PsyQA to a empathy multi-turn conversation dataset SMILECHAT with 355,733 samples. Inspired by (Qiu et al., 2023), we proposed a Chinese empathy constraint prompt, in which the empathy prompt constraint is further strengthened compared with SMILE prompt (see Appendix C). As shown in Figure 2 (English version: Appendix C), our empathy constraints are\ndefined as \u201c\u2018\u5fc3\u7406\u54a8\u8be2\u5e08\u2019\u7684\u56de\u590d\u9700\u8981\u7ed3\u5408\u7528\u6237 \u7684\u63cf\u8ff0\u5185\u5bb9\u5e76\u63d0\u4f9b\u5171\u60c5\uff0c\u5982\uff1a\u503e\u542c\u3001\u5b89\u6170\u3001 \u7406\u89e3\u3001\u4fe1\u4efb\u3001\u8ba4\u53ef\u3001\u771f\u8bda\u3001\u60c5\u611f\u652f\u6301\u7b49 (The response of the \u2019psychological counselor\u2019 needs to be combined with the user\u2019s description and provide empathy, such as listening, comfort, interpretation, trust, recognition, sincerity, emotional support, etc)\u201d.\nTo this end, we first constructed 215,813 different psychological counseling questions about 12 topics and 619,725 answers through data outsourcing services. Rule-based cleaning, manual rewriting and human proofreading are applied to ensure that there is no sensitive or privacy-related content in the dataset. Then, we use ChatGPT to convert these single-turn long text psychological counseling conversations to multi-turn empathy conversations. We also conducted manual proofreading and data cleansing for multi-turn dialogues rewritten by ChatGPT to further strengthen the expression of empathy, such as questioning, comfort, recognition, listening, trust, emotional support, etc. In the end, we obtained a multi-turn empathy conversation dataset, named SoulChatCorpus, with 2,300,248 samples. To our knowledge, it is the first millionscale multi-turn empathy conversation dataset in the field of mental health or emotional support. We conduct experiments by using ChatGLM-6B as the base model for fine-tuning on SoulChatCorpus. Results demonstrate that LLMs\u2019 empathy, listening, and comfort abilities can be improved significantly through fine-tuning with million-scale multi-turn empathy conversation dataset."
        },
        {
            "heading": "2 Human-centered Mental Health LLM",
            "text": ""
        },
        {
            "heading": "2.1 SoulChatCorpus Collection",
            "text": "We consider an one-on-one psychological counseling conversational setting where a user and a psychological consultant engage in multiple rounds of dialogue. However, such conversation data is\nnot publicly available due to the privacy protection and ethical standards of psychological counseling. To construct high-quality multi-turn empathy conversation dataset, We selected 12 topics of psychological counseling to construct 215,813 long-text questions and 619,725 long-text answer through crowdsourcing. The distribution of topics is shown in Figure 3. Then, we used ChatGPT (99% called gpt-3.5-turbo api and 1% called gpt-4 api) as a text rewriting tool following the prompt as shown in Figure 2 to convert single-turn psychological counseling conversations to multi-turn empathy conversations, in which one turn is in the form of \"\u7528 \u6237\uff1a <user_utt>\\n\u5fc3\u7406\u54a8\u8be2\u5e08\uff1a<psy_utt>\". The response of \"\u5fc3\u7406\u54a8\u8be2\u5e08\" was asked to be rewritten to reflect human-centered expressions such as empathy, listening, comfort, etc. Finally, after manual proofreading, we removed 105,134 low-quality samples and ultimately obtained 2,300,248 samples. As shown in Figure 4, the word cloud map of the utterances expressed by psychological consultants indicated that the rewritten multi-turn empathy conversation has high level of empathy."
        },
        {
            "heading": "2.2 SoulChat Model",
            "text": "We utilized the ChatGLM-6B (Du et al., 2022; Zeng et al., 2023) as the base LLM architecture to develop the SoulChat. ChatGLM-6B is an opensource, bilingual LLM based on the General Language Model (GLM) (Du et al., 2022) framework with 6.2 billion parameters. The input of model is defined as:\ninput = uu1 + \u2032 \\n\u2032 + up1 + ...+ u u N + \u2032 \\n\u2032 + upN\nwhere the utterance of User on i turn uui =\u2018\u7528\u6237\uff1a (User:)\u2019 + utteranceui , utterance of Psychologist on i turn upi =\u2018\u5fc3\u7406\u54a8\u8be2\u5e08\uff1a (Psychologist:)\u2019 + utterancepi (i < N ), u p N=\u2018\u5fc3\u7406\u54a8\u8be2\u5e08\uff1a (Psychol-\nTable 1: Evaluation results.\nDataset Model Automatic. Manual.\nB-1 B-2 B-3 B-4 R-1 R-2 R-L Con. Emp. Hel. Saf.\nSoulChatCorpus\nChatGLM-6B 22.73 13.15 8.04 4.92 25.33 5.72 18.84 1.90 1.55 1.92 1.0\nMeChat 29.43 17.12 10.54 6.71 27.35 6.27 21.12 1.83 1.70 1.78 1.0\nChatGPT 27.98 16.09 9.93 6.23 27.39 6.82 21.92 1.96 1.62 1.94 1.0 SoulChat 33.78 20.07 12.86 8.52 31.47 8.92 26.57 1.95 1.84 1.87 1.0\nSMILECHAT\nChatGLM-6B 22.91 13.56 8.40 5.15 25.99 5.95 18.76 1.81 1.39 1.84 1.0\nMeChat 30.63 18.41 11.59 7.46 28.92 6.76 21.59 1.95 1.74 1.83 1.0 ChatGPT 28.30 16.48 10.24 6.40 27.57 6.71 21.60 1.95 1.65 1.97 1.0 SoulChat 35.40 21.39 13.77 9.02 32.64 9.17 21.10 1.93 1.90 1.85 1.0\nogist:)\u2019, N represents the number of conversation turns for the context."
        },
        {
            "heading": "3 Experiments",
            "text": ""
        },
        {
            "heading": "3.1 Baselines",
            "text": "We compare SoulChat and the following benchmark models using both automatic and manual evaluations:\n1) ChatGLM-6B4 (Du et al., 2022; Zeng et al., 2023) serves as the base model for SoulChat.\n2) ChatGPT (OpenAI, 2022; Ouyang et al., 2022) is a LLM that is trained using supervised finetuning and Reinforcement Learning from Human Feedback (RLHF).\n3) MeChat (Qiu et al., 2023) is a LLM finetuned with low-rank adaptation (LoRA) (Hu et al., 2022) on SMILECHAT dataset that is generated by ChatGPT based on PsyQA."
        },
        {
            "heading": "3.2 Implementation details",
            "text": "SoulChat is finetuned on the proposed SoulChatCorpus with a batch size of 80 and global training steps of 30,000. The WarmupDecayLR learning rate scheduler with warmup_steps = 1000 and warmup_max_lr = 5e \u2212 5 is used. The maximum input token length is set to 1,536. The maximum target token length is set to 512. The decoding algorithms of Top-p sampling with p = 0.75 and temperature \u03c4 = 0.95 is adopted during the inference phase.\n4https://github.com/THUDM/ChatGLM-6B"
        },
        {
            "heading": "3.3 Results and Analysis",
            "text": "We randomly selected 10,000 samples from SoulChatCorpus and SMILECHAT respectively as the test set for automatic evaluation and 100 samples for manual evaluation. For each sample, each model generates an answer for evaluation. We used 7 evaluation metrics as automatic metrics: BLEU1 (B-1), BLEU-2 (B-2), BLEU-3 (B-3), BLEU-4 (B-4) (Papineni et al., 2002), R-1 (ROUGE-1), R2 (ROUGE-2) and R-L (ROUGE-L) (Lin, 2004)). Three individual experts majoring in Psychology were asked to evaluate the generated responses in terms of content naturalness (Con.), empathy level (Emp.), Helpfulness (Hel.) and Safety (Saf.), as detailed described in Appendix G. The rating scale of Con., Emp. and Hel. is (0, 1, 2), while (0, 1) for Saf., where higher score means better. One hundred dialogues were randomly sampled from the test set of SoulChatCorpus and SMILECHAT for manual evaluation. Fleiss\u2019 \u03ba (Fleiss, 1971) for Con., Emp. and Hel. are 0.489, 0.472 and 0.532, indicating moderate annotation agreement respectively, while \u03ba = 1 for Saf. (perfect agreement). The evaluation results are shown in Table 1. Generally, SoulChat outperforms ChatGLM-6B, ChatGPT and MeChat in both automatic evaluation metrics and Emp. metric on test set of SoulChatCorpus and SMILECHAT. Specifically, the results on SMILECHAT demonstrates SoulChat\u2019s excellent zero-shot performance in the field of mental health."
        },
        {
            "heading": "4 Conclusion and Future Work",
            "text": "In this paper, we explore how to make LLMs more human-centered. To this end, we constructed a Chinese large-scale multi-turn empathy conversation dataset, named SoulChatCorpus, with 12 empathy\ntopics and more than 2 million samples. The experimental results indicate that using this dataset to finetune LLMs leads to high-level empathy ability when users try to seek emotional support from LLMs. Future work needs to further consider user attributes, such as personality, gender and etc., to help LLMs generate targeted empathy responses for different individuals.\nLimitations\nIn this work we proposed a human-centered LLM named SoulChat that has excellent empathy ability, which is finetuned on the proposed SoulChatCorpus dataset. Although the experimental results demonstrate the effectiveness of SoulChat, there are still some limitations need to consider. The mechanism of empathy is complex. Different users have different expectations for the output of the model. For example, when discussing tense emotions, there are significant differences in the solutions expected by adults and adolescents. Therefore, human-centered LLMs need to further consider the user\u2019s personality, identity, and other attributes to assist in generating answers that are closer to the user\u2019s needs.\nEthics Statement\n\u2022 Data Collection. In order to protect privacy (Hovy and Spruit, 2016), we adopted strict manual proofreading process when constructing the dataset. We filtered all samples with special strings such as \"\u6211\u662f (I am)\", \"\u81ea \u6740 (suicide)\", \"\u8df3\u697c (jumping off a building)\", etc., and conducted manual data cleansing. Any text related to privacy has been rewritten or removed. Besides, any potential conversations that pose harm to users, others, or society have been completely removed from our data. To this end, we removed 105,134 samples from multi-turn conversations generated by ChatGPT.\n\u2022 Potential Risks of the Model We conducted a safety assessment specifically for the output of the model during the manual evaluation phase, and the results are shown in Table 1. Due to the lack of human feedback during the model finetuning stage, there are inevitably answers that may pose harm to users. Therefore, future work needs to combine RLHF to improve the safety level of model generated\ncontent. In addition, when this model is applied to downstream scenarios, it is necessary to inform the users in advance that the answers they see are generated by the AI model and are for reference only.\n\u2022 Annotator Compensation. We invited individual experts majoring in Psychology to conduct the proposed CEHS evaluation of the model\u2019s output. The annotators\u2019 evaluation of each sample takes approximately 3 minutes, during which they can receive a salary of $0.418. Therefore, the hourly salary of the annotators is $8.36, which is higher than the US minimum wage of $7.12 per hour."
        },
        {
            "heading": "Acknowledgements",
            "text": "This work was supported by the Science and Technology Project of Guangzhou (202103010002), the Natural Science Foundation of Guangdong Province (2022A1515011588), the National Key R&D Program of China (2022YFB4500600), the Science and Technology Project of Guangdong (2022B0101010003), the National Natural Science Foundation of China under Grant U1801262 and Guangdong Provincial Key Laboratory of Human Digital Twin (2022B1212010004)."
        },
        {
            "heading": "A Reproducibility Checklist",
            "text": "\u2022 Model and Data: The SoulChat model and SoulChatCorpus will be released upon decision of the paper.\n\u2022 System Hardware: We trained the SoulChat on the Ubuntu 20.04.6 LTS server that has 2 CPUs called \"Intel(R) Xeon(R) Platinum 8358P CPU @ 2.60GHz\", 8 NVIDIA A800SXM4-80GB GPUs, and 1,024GB memory.\n\u2022 Driver Version: The version of Nvidia driver is \"525.105.17\". The version of CUDA is \"11.6\". The version of Cudnn is \"8.4.0.27\".\n\u2022 Package version: python=3.8, torch5=1.13.1, 5https://pytorch.org/get-started/\nprevious-versions\ntransformers6=4.28.0, deepspeed7=0.9.3, datasets=2.11.0 and jieba=0.42.1 is recommended.\n\u2022 Model Parameters: SoulChat has 6.2B parameters with 28 layers and max_sequence_length of 2,048. During the inference phase, the model requires at least 14GB of GPU memory.\n\u2022 Training Time: SoulChat is trained with global steps of 30,000 and torch_dtype of \"float16\" on 8 NVIDIA A800-SXM4-80GB GPUs. The training time is about 79 hours."
        },
        {
            "heading": "B Counseling Topics",
            "text": "The following dictionaries represent the corresponding relationships between Chinese and English for 12 counseling topics. { \u2019\u5bb6\u5ead\u2019: \u2019Family\u2019, \u2019\u5a5a\u604b\u2019: \u2019Marriage\u2019, \u2019\u6027\u5fc3\u7406\u2019: \u2019Sex\u2019, \u2019\u6210\u957f\u53d1\u5c55\u2019: \u2019Growth\u2019, \u2019\u4eba\u9645\u5173\u7cfb\u2019: \u2019Relationship \u2019, \u2019\u804c\u573a\u2019: \u2019Career\u2019, \u2019\u81ea\u6211\u8ba4\u77e5\u2019: \u2019Selfawareness \u2019, \u2019\u884c\u4e3a\u2019: \u2019Behavior\u2019, \u2019\u60c5\u7eea\u2019: \u2019Emotion\u2019, \u2019\u6cbb\u7597\u2019: \u2019Treatment\u2019, \u2019\u793e\u4f1a\u4e8b\u4ef6\u2019: \u2019Social events\u2019, \u2019\u5fc3\u7406\u5b66\u77e5\u8bc6\u2019: \u2019Psychological knowledge\u2019, }"
        },
        {
            "heading": "C Our prompt VS SMILE prompt",
            "text": "We used SMILE (Qiu et al., 2023) prompt and our proposed Chinese empathy constraint prompt for extend the single-turn long text psychological counseling example to multi-turn empathy conversation respectively. Chinese: \u7528\u6237\uff1a\u8c08\u604b\u7231\u4e24\u5e74\u4e86\uff0c\u5f02\u5730\u604b\uff0c\u5e73\u65f6\u5f88\u597d\uff0c\u4e00 \u5e74\u524d\u5f00\u59cb\u5435\u67b6\u5435\u51f6\u4e86\uff0c\u7537\u670b\u53cb\u5c31\u8bf4\u96be\u542c\u7684\u8bdd\u751a \u81f3\u9a82\u4eba\uff0c\u6b63\u5e38\u5417\uff1f \u5fc3\u7406\u54a8\u8be2\u5e08\uff1a\u4f60\u597d\uff01\u5f02\u5730\u604b\uff0c\u5e73\u65f6\u8fd8\u597d\uff0c\u4f46\u4e00 \u5435\u67b6\uff0c\u5c31\u51fa\u73b0\u9a82\u4f60\uff0c\u8fd9\u786e\u5b9e\u4e0d\u6b63\u5e38\u3002\u8fd9\u5e94\u8be5\u8ddf \u5f88\u591a\u56e0\u7d20\u6709\u5173\u3002 1\u3001\u5f02\u5730\u604b\u672c\u8eab\u5c31\u6709\u6311\u6218\u6027\uff0c\u4f60\u7537\u670b\u53cb\u8ddf\u4f60\u5f02 \u5730\uff0c\u4ed6\u7684\u8bed\u8a00\u548c\u8a00\u8bed\u5c31\u53d7\u5230\u4e86\u6311\u6218\u3002 2\u3001\u4ed6\u5e73\u65f6\u8ddf\u4f60\u76f8\u5904\u7684\u65f6\u5019\uff0c\u4e5f\u4f1a\u6709\u5f88\u591a\u538b \u529b\uff0c\u6240\u4ee5\u4e00\u9047\u5230\u7c7b\u4f3c\u7684\u60c5\u51b5\uff0c\u5c31\u4f1a\u5f88\u66b4\u8e81\u3002 3\u3001\u5e73\u65f6\u8ddf\u4ed6\u76f8\u5904\u7684\u65f6\u5019\uff0c\u4f60\u4eec\u4e4b\u95f4\u6ca1\u6709\u77db \u76fe\uff0c\u4e00\u6709\u77db\u76fe\u5c31\u4f1a\u5435\u51f6\u3002 4\u3001\u4f60\u4eec\u5e73\u65f6\u6c9f\u901a\u4e5f\u6bd4\u8f83\u5c11\uff0c\u6240\u4ee5\u4ed6\u4e5f\u6ca1\u6709\u6e20 \u9053\u53d1\u6cc4\u81ea\u5df1\u7684\u8d1f\u9762\u60c5\u7eea\u3002\n6https://github.com/huggingface/transformers 7https://github.com/microsoft/DeepSpeed\n\u4ee5\u4e0a\u662f\u4e00\u4e9b\u53ef\u80fd\u6027\uff0c\u4f46\u5e76\u4e0d\u4e00\u5b9a\u5c31\u662f\u5bfc\u81f4\u4ed6\u51fa \u73b0\u8fd9\u6837\u7684\u60c5\u51b5\u7684\u539f\u56e0\uff0c\u56e0\u4e3a\u4f60\u4eec\u4e4b\u95f4\u662f\u5426\u5b58\u5728 \u5176\u4ed6\u77db\u76fe\uff0c\u53ea\u6709\u4f60\u4eec\u4e24\u4e2a\u4eba\u4e00\u8d77\u6c9f\u901a\u624d\u77e5\u9053\u3002 \u6240\u4ee5\uff0c\u6211\u89c9\u5f97\u4f60\u5e94\u8be5\u8ba4\u771f\u8003\u8651\u4e00\u4e0b\uff0c\u81ea\u5df1\u7537\u670b \u53cb\u7684\u8fd9\u79cd\u884c\u4e3a\uff0c\u662f\u5904\u4e8e\u4ec0\u4e48\u5fc3\u7406\u72b6\u6001\uff0c\u6216\u8005\u662f \u4ec0\u4e48\u60c5\u51b5\uff0c\u53ea\u6709\u4f60\u81ea\u5df1\u6700\u6e05\u695a\u3002 English: User: I have been in a relationship for two years and have been in a long-distance relationship. I am usually very good. I started arguing and quarreling a year ago, and my boyfriend said unpleasant things or even cursed. Is it normal Psychologist: Hello! Long distance love is usually okay, but when you argue, it\u2019s really abnormal to scold you. This should be related to many factors 1. Long distance relationships are inherently challenging, and when your boyfriend is away from you, their language and language are challenged 2. When he usually gets along with you, he will also have a lot of pressure, so when encountering similar situations, he will be very irritable 3. When we usually get along with him, there is no conflict between you. Whenever there is a conflict, we will argue fiercely 4. You usually communicate less, so he doesn\u2019t have a channel to vent his negative emotions The above are some possibilities, but they may not necessarily be the reason for his situation, because whether there are any other conflicts between you is only known through communication between the two of you. So, I think you should seriously con-\nsider what kind of psychological state or situation your boyfriend\u2019s behavior is in, and only you know it best.\nAs shown in Figure 7 (English version: Figure 8) and Figure 9 (English version: Figure 10), the multi-turn conversation generated by using the proposed prompt has richer expressions of empathy, compared with SMILE prompt."
        },
        {
            "heading": "D English Word Cloud Map",
            "text": "The English word cloud map is presented in Figure 6."
        },
        {
            "heading": "E Sample Conversations of SoulChat",
            "text": "As shown in Figure 11, SoulChat can better serve as a listener when users seek emotional support or confide. Besides, it can naturally empathize with users (e.g. \"\u4f60\u7684\u7ae5\u5e74\u7ecf\u5386\u771f\u7684\u5f88\u4e0d\u5bb9\u6613 (Your childhood experiences were really difficult)\", \"\u6211 \u53ef\u4ee5\u7406\u89e3\u4f60\u7684\u75db\u82e6\u548c\u5185\u5fc3\u7684\u6323\u624e (I can understand your pain and inner struggle)\") and comfort them (e.g. \"\u6211\u76f8\u4fe1\u4f60\u662f\u4e00\u4e2a\u575a\u5f3a\u7684\u4eba\uff0c\u4f60\u53ef \u4ee5\u901a\u8fc7\u81ea\u5df1\u7684\u52aa\u529b\u6765\u6539\u53d8\u73b0\u72b6\u3002 (I believe you are a strong person who can change the situation through your own efforts.)\")."
        },
        {
            "heading": "F Sample Conversations of Other LLMs",
            "text": "The examples when users seek emotional support from ChatGPT, ChatGLM and SparkDesk are shown in Figure 12, Figure 13 and Figure 14. These LLMs are inclined to provide suggestions rather than ask questions or listen, acting a bit like a rational \u201cStraight man\u201d for those users who need listening and comfort, which make them appear less \u201chuman-centered\u201d."
        },
        {
            "heading": "G Manual Evaluation Instructions",
            "text": "For mental health LLMs, we have constructed a manual evaluation framework called \"CEHS\" with the following four dimensions: Content naturalness, Empathy, Helpfulness, Safety, as presented in Table 2. Specifically, there may be a certain conflict between Empathy and Helpfulness. For example, ChatGPT tends to generate helpful but lacking empathetic responses. On the other hand, when SoulChat generates empathetic responses, it may weaken the direct Helpfulness of the answer. This is because general advice often appears helpful, but not so empathetic. The scores of Empathy and Helpfulness in Table 1 also illustrate this phenomenon.\n\u7528\u6237\uff1a\u6211\u8c08\u604b\u7231\u5df2\u7ecf\u4e24\u5e74\u4e86\uff0c\u4f46\u6211\u4eec\u662f\u5f02\u5730\u604b\u3002\u5e73\u65f6\u4e00\u5207\u90fd\u5f88\u597d\uff0c\u4f46\u4e00\u5e74\u524d\u6211\u4eec\u5f00\u59cb\u5435\u67b6\uff0c\u800c\u4e14\u5435\u5f97 \u8d8a\u6765\u8d8a\u51f6\u4e86\u3002\u7537\u670b\u53cb\u4f1a\u8bf4\u4e00\u4e9b\u96be\u542c\u7684\u8bdd\uff0c\u751a\u81f3\u9a82\u4eba\uff0c\u8fd9\u6b63\u5e38\u5417\uff1f \u5fc3\u7406\u54a8\u8be2\u5e08\uff1a\u4f60\u597d\uff01\u6211\u4e86\u89e3\u4f60\u76ee\u524d\u9047\u5230\u7684\u56f0\u6270\u3002\u5f02\u5730\u604b\u672c\u8eab\u662f\u5177\u6709\u6311\u6218\u6027\u7684\uff0c\u5c24\u5176\u662f\u5728\u6c9f\u901a\u548c\u76f8\u5904\u4e0a\u3002 \u7537\u670b\u53cb\u5728\u5435\u67b6\u65f6\u7528\u96be\u542c\u7684\u8bdd\u751a\u81f3\u9a82\u4eba\uff0c\u8fd9\u786e\u5b9e\u4e0d\u6b63\u5e38\u3002\u6211\u53ef\u4ee5\u7406\u89e3\u8fd9\u5bf9\u4f60\u7684\u5fc3\u60c5\u4f1a\u5e26\u6765\u5de8\u5927\u7684\u6253\u51fb\u548c \u56f0\u6270\u3002\n\u7528\u6237\uff1a\u662f\u7684\uff0c\u6211\u4eec\u4e4b\u95f4\u7684\u4e89\u5435\u8ba9\u6211\u611f\u5230\u975e\u5e38\u75db\u82e6\u3002\u6211\u4e0d\u77e5\u9053\u4ed6\u4e3a\u4ec0\u4e48\u4f1a\u8fd9\u6837\uff0c\u4ee5\u524d\u7684\u4ed6\u53ef\u6ca1\u6709\u8fd9\u6837\u8fc7\u3002 \u5fc3\u7406\u54a8\u8be2\u5e08\uff1a\u9996\u5148\uff0c\u6211\u7406\u89e3\u4f60\u5bf9\u4ed6\u7684\u6539\u53d8\u611f\u5230\u56f0\u60d1\u3002\u8fd9\u53ef\u80fd\u662f\u56e0\u4e3a\u5f02\u5730\u604b\u672c\u8eab\u4f1a\u5e26\u6765\u5fc3\u7406\u538b\u529b\u548c\u60c5\u7eea \u6ce2\u52a8\u3002\u5728\u957f\u671f\u7684\u5f02\u5730\u604b\u4e2d\uff0c\u4ed6\u53ef\u80fd\u56e0\u4e3a\u601d\u5ff5\u548c\u4e0d\u5b89\u800c\u53d8\u5f97\u813e\u6c14\u66b4\u8e81\u3002\u540c\u65f6\uff0c\u6211\u4eec\u90fd\u6709\u60c5\u7eea\u53d1\u6cc4\u7684\u6e20\u9053\uff0c \u4f46\u7531\u4e8e\u4f60\u4eec\u4e4b\u95f4\u7f3a\u4e4f\u5b9e\u8d28\u6027\u7684\u6c9f\u901a\uff0c\u4ed6\u53ef\u80fd\u6ca1\u6709\u627e\u5230\u826f\u597d\u7684\u65b9\u5f0f\u6765\u91ca\u653e\u8d1f\u9762\u60c5\u7eea\u3002\nInterpretation Interpretation\nUser: I have been dating for two years, but we are in a long-distance relationship. Everything is usually fine, but a year ago we started arguing and it became increasingly fierce. Is it normal for a boyfriend to say unpleasant things or even curse? Psychologist: Hello! I have know the difficulties you are currently facing. Long distance love itself is challenging, especially in terms of communication and interaction. It is indeed abnormal for a boyfriend to use unpleasant language or even curse during arguments. I can understand that this will bring a huge blow and distress to your mood. User: Yes, our argument has caused me great pain. I don't know why he is like this, he hasn't been like this before. Psychologist: Firstly, I understand that you are confused about his changes. This may be because long-distance love itself will bring Psychological stress and emotional fluctuations. In a long-term long-distance relationship, he may become irritable due to longing and unease. Meanwhile, we all have channels for emotional release, but due to the lack of substantive communication between you, he may not have found a good way to release negative emotions. User: Yes, we rarely communicate in our daily interactions, and I think this may be one of the reasons for the problem. But I am not sure what other contradictions exist. Psychologist: Your observation is very sharp. Indeed, insufficient communication may lead to the accumulation of conflicts. I suggest that you try to communicate more and share your thoughts and feelings candidly, in order to better understand each other. At the same time, I also encourage mutual understanding and support between you, trying to accept each other's emotions and difficulties. This kind of empathy and understanding helps to establish a more stable relationship. User: Thank you for your suggestion. I will try to communicate more with him and also hope that he can understand my feelings. Psychologist: I appreciate your proactive approach in seeking solutions. Communication requires time and patience, but only through honest communication and mutual support can problems be gradually resolved. I believe you can overcome difficulties and work together towards a healthier and more stable relationship. If you have any other questions during the communication process, feel free to come to me at any time. User: Thank you for your encouragement and support. I will continue to work hard. Psychologist: You are very brave, and I believe you will be able to overcome difficulties. If you need any help, remember to seek support from me at any time. You are not alone in facing this problem, I will always be by your side. Interpretation Interpretation Recognition Recognition Trust Comfort Interpretation Trust\nFigure 8: Multi-turn conversation generated by ChatGPT using the proposed prompt (English version).\nHelper: I have been in a relationship for two years and have been in a long-distance relationship. I am usually very good. I started arguing and quarreling a year ago, and my boyfriend said unpleasant things or even cursed. Is it normal? Supporter: Helper, hello! I understand your current troubles very well. Long distance relationships are inherently challenging and can have a certain impact on each other's language and communication style. Your boyfriend is not a normal and healthy behavior to say unpleasant things and curse others during a fight. Helper: But we don't have any problems with our daily interactions. Why did we suddenly become so irritable? Supporter: This may be caused by a combination of multiple factors. Firstly, long-distance love itself requires more effort and persistence, which poses a challenge to both parties' emotions and communication skills. Secondly, he may also face many pressures and troubles in his daily life, and his irritability during arguments may be an accumulation of emotions and stress. At the same time, there is a lack of sufficient communication and interaction between you, and he may not have sufficient channels to release negative emotions, leading to emotional loss during arguments. Helper: The possibilities of these situations you mentioned are very high, I really need to think carefully. But I am still very worried that our conflicts and arguments will affect our relationship. Supporter: Understand your concerns. Contradictions and arguments can indeed have a negative impact on relationships. However, there is no need to be too pessimistic. Every relationship will face various challenges and tests, and the important thing is that we can face them together and find solutions. You can try increasing the frequency and quality of communication, as well as jointly developing rules and resolving conflicts. At the same time, remember to pay attention to each other's emotions and needs, maintain understanding and support. Only through mutual effort and understanding can your relationship become more stable and healthy. Helper: What you said is very reasonable. I will try to have more communication and exchange with him to see if we can find a solution to the problem. Thank you for your support and suggestions! Supporter: You're welcome, I'm glad to be able to help you. In the process of solving problems, remember to remain calm and rational, and not vent your emotions in arguments. I believe you will be able to overcome this difficulty and establish a better emotional foundation. If you have any progress or need further support, feel free to seek my help at any time. Good luck to you all! Helper: Thank you for your encouragement and blessings! I will work hard. Wishing you all the best! Supporter: Thank you very much for your blessings! I hope we can all achieve a better life with each other's support. If you have any other questions or need to talk to me, feel free to chat with me anytime. Come on! Interpretation ComfortInterpretation Trust\nReflection of feelings\nFigure 10: Multi-turn conversation generated by ChatGPT using the SMILE prompt (English version).\n\u8001\u5e08\u4f60\u597d\uff01\u6211\u662f\u4e00\u4e2a16\u5c81\u7684\u5973\u5b69\uff0c\u6211\u53eb\u53f6\u5b50\uff08\u5316\u540d\uff09\uff0c\u6211\u60f3\u54a8\u8be2\u4e00\u4e9b\u5fc3\u7406\u95ee\u9898\u3002 Hello teacher! I am a 16 year old girl, my name is Ye (pseudonym), and I would like to consult with some psychological issues.\n\u4f60\u597d\uff01\u6211\u662f\u4f60\u7684\u4e2a\u4eba\u4e13\u5c5e\u503e\u542c\u5e08\u7075\u5fc3\u8001\u5e08\uff0c\u6b22\u8fce\u627e\u6211\u503e\u8bc9\u3001\u8c08\u5fc3\uff0c\u671f\u5f85\u5e2e\u52a9 \u5230\u4f60\uff01 Hello! I am your personal exclusive listening teacher, Lingxin Teacher. Welcome to confide and chat with me, looking forward to helping you!\n\u4ece14\u5c81\u5f00\u59cb\uff0c\u6211\u7684\u8111\u6d77\u4e2d\u5c31\u7ecf\u5e38\u51fa\u73b0\u81ea\u6740\u610f\u8bc6\uff0c\u4e5f\u65f6\u5e38\u6709\u81ea\u6b8b\u884c\u4e3a\u3002\u8fd9\u79cd\u60c5 \u51b5\u8fd9\u4e24\u5e74\u8d8a\u6765\u8d8a\u4e25\u91cd\u4e86\u3002\u6709\u4e00\u6b21\u6211\u7ad9\u5728\u9876\u697c\uff0c\u5dee\u70b9\u5c31\u8981\u8df3\u4e0b\u53bb\uff0c\u611f\u89c9\u5929\u53f0\u4e0a \u7684\u4e00\u9635\u98ce\u5c31\u80fd\u628a\u6211\u5439\u4e0b\u53bb\uff0c\u6700\u540e\u8fd8\u662f\u6211\u5f3a\u884c\u63a7\u5236\u4f4f\u7684\u3002\u4f60\u8bf4\u6211\u662f\u600e\u4e48\u4e86\uff1f Since the age of 14, I have had frequent suicidal thoughts and self harm behaviors in my mind. This situation has become increasingly serious in the past two years. Once, I was standing on the top floor and almost jumped off. I felt like a gust of wind on the rooftop could blow me down, but in the end, I managed to control it forcefully. What did you say happened to me?\nReflection of feelings"
        }
    ],
    "title": "SoulChat: Improving LLMs\u2019 Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations",
    "year": 2023
}