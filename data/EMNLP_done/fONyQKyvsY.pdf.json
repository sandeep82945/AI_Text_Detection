{
    "abstractText": "This paper analyses two hitherto unstudied sites sharing state-backed disinformation, Reliable Recent News (rrn.world) and WarOnFakes (waronfakes.com), which publish content in Arabic, Chinese, English, French, German, and Spanish. We describe our content acquisition methodology and perform cross-site unsupervised topic clustering on the resulting multilingual dataset. We also perform linguistic and temporal analysis of the web page translations and topics over time, and investigate articles with false publication dates. We make publicly available this new dataset of 14,053 articles, annotated with each language version, and additional metadata such as links and images. The main contribution of this paper for the NLP community is in the novel dataset which enables studies of disinformation networks, and the training of NLP tools for disinformation detection.",
    "authors": [
        {
            "affiliations": [],
            "name": "Freddy Heppell"
        },
        {
            "affiliations": [],
            "name": "Kalina Bontcheva"
        }
    ],
    "id": "SP:2928e19976d370876e859f8471b9bc8147ccc802",
    "references": [
        {
            "authors": [
                "Charu C. Aggarwal",
                "Alexander Hinneburg",
                "Daniel A. Keim."
            ],
            "title": "On the surprising behavior of distance metrics in high dimensional spaces",
            "venue": "International Conference on Database Theory.",
            "year": 2001
        },
        {
            "authors": [
                "Alexandre Alaphilippe",
                "Gary Machado",
                "Raquel Miguel",
                "Francesco Poldi."
            ],
            "title": "Doppelganger - media clones serving russian propaganda",
            "venue": "Technical report, EU DisinfoLab.",
            "year": 2022
        },
        {
            "authors": [
                "Nick Backovic",
                "Kyle Walter."
            ],
            "title": "Logically investigations: Russian propaganda disguised as fact checking",
            "venue": "Technical report, Logically.",
            "year": 2023
        },
        {
            "authors": [
                "Alberto Barr\u00f3n-Cede\u00f1o",
                "Israa Jaradat",
                "Giovanni Da San Martino",
                "Preslav Nakov."
            ],
            "title": "Proppy: Organizing the news based on their propagandistic content",
            "venue": "Information Processing & Management, 56(5):1849\u2013 1864.",
            "year": 2019
        },
        {
            "authors": [
                "Gillian Bolsover",
                "Philip Howard."
            ],
            "title": "Computational propaganda and political big data: Moving toward a more critical research agenda",
            "venue": "Big Data, 5(4):273\u2013276.",
            "year": 2017
        },
        {
            "authors": [
                "Ricardo J.G.B. Campello",
                "Davoud Moulavi",
                "Joerg Sander."
            ],
            "title": "Density-based clustering based on hierarchical density estimates",
            "venue": "Advances in Knowledge Discovery and Data Mining, pages 160\u2013 172, Berlin, Heidelberg. Springer Berlin Heidelberg.",
            "year": 2013
        },
        {
            "authors": [
                "Giovanni Da San Martino",
                "Alberto Barr\u00f3n-Cede\u00f1o",
                "Preslav Nakov."
            ],
            "title": "Findings of the NLP4IF-2019 shared task on fine-grained propaganda detection",
            "venue": "Proceedings of the Second Workshop on Natural Language Processing for Internet Freedom: Censorship,",
            "year": 2019
        },
        {
            "authors": [
                "Giovanni Da San Martino",
                "Seunghak Yu",
                "Alberto Barr\u00f3n-Cede\u00f1o",
                "Rostislav Petrov",
                "Preslav Nakov."
            ],
            "title": "Fine-grained analysis of propaganda in news article",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
            "year": 2019
        },
        {
            "authors": [
                "Maarten Grootendorst."
            ],
            "title": "BERTopic: Neural topic modeling with a class-based TF-IDF procedure",
            "venue": "Computing Research Repository, arXiv:2203.05794. Version 1. 16https://www.vigilantproject.eu",
            "year": 2022
        },
        {
            "authors": [
                "Hans W.A. Hanley",
                "Deepak Kumar",
                "Zakir Durumeric."
            ],
            "title": "Happenstance: Utilizing semantic search to track russian state media narratives about the russo-ukrainian war on reddit",
            "venue": "Computing Research Repository, arXiv:2205.14484v2. Version 2.",
            "year": 2022
        },
        {
            "authors": [
                "Ruixuan Luo",
                "Jingjing Xu",
                "Yi Zhang",
                "Zhiyuan Zhang",
                "Xuancheng Ren",
                "Xu Sun."
            ],
            "title": "Pkuseg: A toolkit for multi-domain chinese word segmentation",
            "venue": "Computing Research Repository, arXiv:1906.11455. Version 3.",
            "year": 2022
        },
        {
            "authors": [
                "Eva Maitland"
            ],
            "title": "RRN.world nutrition label. Technical report, NewsGuard",
            "year": 2022
        },
        {
            "authors": [
                "Giovanni Da San Martino",
                "Stefano Cresci",
                "Alberto Barron-Cedeno",
                "Seunghak Yu",
                "Roberto Di Pietro",
                "Preslav Nakov."
            ],
            "title": "A survey on computational propaganda detection",
            "venue": "Computing Research Repository, arXiv:2007.08024.",
            "year": 2020
        },
        {
            "authors": [
                "Leland McInnes",
                "John Healy",
                "James Melville."
            ],
            "title": "UMAP: Uniform manifold approximation and projection for dimension reduction",
            "venue": "Computing Research Repository, arXiv:1802.03426.",
            "year": 2020
        },
        {
            "authors": [
                "Ben Nimmo",
                "Mike Torrey."
            ],
            "title": "Taking down coordinated inauthentic behavior from russia and china",
            "venue": "Technical report, Meta.",
            "year": 2022
        },
        {
            "authors": [
                "James W Pennebaker",
                "Ryan L Boyd",
                "Kayla Jordan",
                "Kate Blackburn"
            ],
            "title": "The development and psychometric properties of LIWC2015",
            "year": 2015
        },
        {
            "authors": [
                "Hannah Rashkin",
                "Eunsol Choi",
                "Jin Yea Jang",
                "Svitlana Volkova",
                "Yejin Choi."
            ],
            "title": "Truth of varying shades: Analyzing language in fake news and political fact-checking",
            "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Lan-",
            "year": 2017
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych."
            ],
            "title": "SentenceBERT: Sentence embeddings using Siamese BERTnetworks",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natu-",
            "year": 2019
        },
        {
            "authors": [
                "Madeline Roache"
            ],
            "title": "WarOnFakes.com nutrition label. Technical report, NewsGuard",
            "year": 2022
        },
        {
            "authors": [
                "Kaitao Song",
                "Xu Tan",
                "Tao Qin",
                "Jianfeng Lu",
                "TieYan Liu."
            ],
            "title": "MPNet: Masked and permuted pretraining for language understanding",
            "venue": "Computing Research Repository, arXiv:2004.09297. Version 2.",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Coordinated, state-backed disinformation operations have become an increasing problem in recent years, particularly surrounding the war in Ukraine (Morku\u0304nas, 2022). In September 2022, a sophisticated network of doppelganger websites (impersonating genuine news sites from across Europe) was discovered by EUDisinfoLab (Alaphilippe et al., 2022) and later expanded on in a report from Meta (Nimmo and Torrey, 2022). Among these was also a small number of conventional false news sites.\nThe focus of this study is on two related disinformation sites in particular: Reliable Recent News1 (RRN) and War On Fakes2 (WoF). Both sites are multilingual, publishing in Arabic, Chinese, English, French, German, and Spanish, and RRN additionally in Italian3. They have been promoted by Russian government sources, including being shared by Russian embassies (Maitland,\n1https://rrn.world, formerly called Reliable Russia News using rrussianews.com.\n2https://waronfakes.com 3WoF also has a separate Russian-language site\n2022; Roache, 2022), and publicised by the Ministry of Foreign Affairs of Russia\u2019s official Twitter account4. We focus on these two \u201cnews\u201d sources due to their links to the Doppelganger network, their potential to deceive unsuspecting citizens (compared to better known propaganda sources such as Russia Today), and their prior exposure as disinformation spreaders (see Appendix A).\nBackovic and Walter (2023) investigated the ownership of WarOnFakes, and stated it was operated by Russian journalist Timofey Vasiliev, a known affiliate of Russian propaganda groups, due to the presence of his name, email and phone number on the website. However, they do not state precisely how they found this information, and do not attempt to establish a link between Vasiliev and RRN or the Doppelganger operation.\nHanley et al. (2022) included selected articles from WarOnFakes and nine other disinformation websites in an analysis of narratives spread on Reddit. In contrast, our dataset includes all WarOnFakes posts and extracts the full article content.\nPropaganda is defined as content that intentionally influences opinion to advance its creators\u2019 goals (Bolsover and Howard, 2017). Numerous propaganda datasets have previously been created, with both document-level (Rashkin et al., 2017; Barr\u00f3n-Cede\u00f1o et al., 2019) and span-level (Da San Martino et al., 2019b) technique annotations, using articles collected from multiple disinformation sites. At article-level, classifiers using combinations of multiple linguistic representations based on style and readability outperform content representation (Barr\u00f3n-Cede\u00f1o et al., 2019), whereas content-based transformer models such as BERT have seen use at span-level (Da San Martino et al., 2019a). Detectors are often evaluated on single datasets, prompting concerns on generalisation (Martino et al., 2020).\nWe are not aware of any prior work including RRN, nor of any work which has released a com-\n4https://twitter.com/mfa_russia/status/150022 3302941487107\nplete dataset of a disinformation operation, including a detailed linguistic analysis.\nThus the contributions of this paper are: i) a new publicly available5 dataset of content from two state-backed disinformation websites; ii) a linguistic, topic, and temporal analysis of their articles; and iii) our open-source toolkit for processing site data and extraction of translations6."
        },
        {
            "heading": "2 Methodology",
            "text": ""
        },
        {
            "heading": "2.1 Data Collection",
            "text": "In March 2023 we used the WordPress REST API7 to obtain all posts from WoF and RRN. Each post was parsed to extract its text, removing non-article content (such as figure captions). The webpage of each post was then analysed to extract the different translations from the language picker. Our extraction tool supports the specific markup used by these two sites, but can be easily extended to support others. An example of an extracted article is shown in Appendix B.\nPublication and modification times, which are provided in GMT by the API, were also converted to Moscow local time for analysis, since it is believed that at least one of the sites is based in Russia (Backovic and Walter, 2023)."
        },
        {
            "heading": "2.2 Topic Analysis",
            "text": "The articles were clustered using BERTopic (Grootendorst, 2022). We assume that whilst each article may discuss many topics, each sentence of an article is likely to discuss a single topic. Articles were split using spaCy\u2019s dependency-parsebased sentenceizer, and sentences with less than 5 tokens were removed. The remaining sentences were embedded with Sentence Transformers MPNET8 (Reimers and Gurevych, 2019; Song et al., 2020). The dimensionality of each embedding was reduced using UMAP (McInnes et al., 2020) from 768 to 5, whilst keeping the structure of the higherdimensional space. This is necessary to avoid the \u2018curse of dimensionality\u20199.\nThe 5d embeddings were clustered with HDBSCAN (Campello et al., 2013), which notably al-\n5https://zenodo.org/records/10007383 6https://github.com/GateNLP/wordpress-site-e xtractor 7https://developer.wordpress.org/rest-api/ 8https://huggingface.co/sentence-transformers/ all-mpnet-base-v2 @ bd44305 9Clustering is difficult in higher dimensional spaces as distance is less meaningful (Aggarwal et al., 2001)\nlows for embeddings to not be included in a cluster, preventing overly broad clusters by forcing nearby but unrelated sentences in. It is expected that this produces a large number of outliers, since it is natural that many of the sentences in the articles will have meanings unrelated to any other. A minimum cluster size of 25 is set to prevent too many small clusters from being generated.\nKeyword representations are generated by creating a bag-of-words vector of the unigrams and bigrams of each topic (excluding English stopwords) which is L1-normalized to account for cluster size. An adapted class-based TF-IDF is used to calculate the most significant words in each cluster. This representation is then fine-tuned by selecting keywords with a high Maximal Marginal Relevance, in order to maximise their diversity. The diversity parameter was set to 0.5. The top 3 most significant keywords are used to name the cluster.\nEach article is then labelled with the unique set of clusters assigned to its sentences."
        },
        {
            "heading": "2.3 Article Backdating",
            "text": "In WordPress, article publication dates can be set to any given date, however this does not affect the auto-incrementing IDs which are generated in the order of article creation. Thus backdated articles can be detected based on their IDs being higher than that of their following articles, when they are ordered by supposed publication date."
        },
        {
            "heading": "2.4 n-gram Frequency",
            "text": "Frequent 2-4-grams were extracted using NLTK, after tokenisation, lowercasing, and stopword and punctuation removal. N-gram frequency was calculated monthly, and the most frequent 10 n-grams per month were selected, excluding the phrase \u201carmed forces\u201d10, and n-grams which are part of another, longer n-gram of equal frequency (e.g. removing \u201cukrainian armed\u201d in favour of \u201cukrainian armed forces\u201d). We include ties for 10th place."
        },
        {
            "heading": "3 Analysis",
            "text": ""
        },
        {
            "heading": "3.1 Dataset Size and Coverage",
            "text": "Our dataset contains 14,053 translations of 3,447 articles posted between 4 Mar 2022 and 6 Mar 2023. Table 1 shows the number of articles per\n10This term is highly frequent, but is ambiguous as includes both Russian and Ukrainian armed forces, which appear as separate highly frequent trigrams.\nsite and language, and mean token and sentence counts11."
        },
        {
            "heading": "3.2 Article Frequency",
            "text": "Figure 1 shows the proportion of each language over time for each site. The first WoF article is published on the 4th March 2022, and the first RRN article on the 11th. WarOnFakes has an unusual pattern of publication in its first few days, publishing sixty articles on the first day, and an average of 34 articles/day over the first 7 days, whereas RRN published only 7 articles on day one and an average of 21 articles/day over the first week.\nGenerally, posts are published on weekdays, with only 9.5% of posts having publication dates and 7.0% having modification dates on a Saturday or Sunday. The week beginning 2nd January 2023, much of which is public holidays in Russia12, has\n11Calculated using the spaCy tokeniser and rule-based sentenciser, with \\n added to delimiters. Chinese segmented with PKUSEG web model (Luo et al., 2022). Arabic support is limited.\n12https://www.cbr.ru/eng/other/holidays/\nthe lowest activity in the sites\u2019 history, with only 60 articles published on RRN and 19 on WoF. For comparison, the mean in other weeks is 200 (RRN) and 66 (WoF).\n25 identical articles were published on both sites predominantly in March 2022, and in all but one case they were a WoF-style debunk. They were not published simultaneously on the two sites, nor is it consistent which site published first."
        },
        {
            "heading": "3.3 Language Coverage",
            "text": "Only a small minority of posts (\u223c9.1%) are not available in English, and the majority of these do not have any translations at all, suggesting they are likely \u2018orphaned\u2019 translations. The mean number of available languages for a post is 4.1\u00b11.5 (1 std)\nAll site-language pairs continued to be published until the end of the collection period, except Arabic and Spanish on WoF and Chinese on RRN, which stopped in July and October 2022 respectively. Spanish posts resumed in December 2022."
        },
        {
            "heading": "3.4 Topics",
            "text": "Amongst the 45,991 English sentences in the English articles, 24,800 were considered outliers and 21,191 were assigned one of 144 topics. These topics ranged from broad, recurrent themes (e.g. #0, the donation of arms and aid to Ukraine) to more specific, time-limited ones (e.g. #139, the burning of the Quran by far-right activist Rasmus Paludan).\nThe mean number of topics assigned per article is 4.33 \u00b1 2.66 (1 std). In the first week of the war in Ukraine (beginning 28th Feb 2022), the vast majority of articles are categorised as #2 (russian\nmilitary, ukranian telegram, telegram channels, according [to] ukranian). These articles are all from WarOnFakes (since RRN did not start publishing until the following week) and are claiming that various evidence from the war in Ukraine is fake.\nOf the 144 topics we identified, 126 were assigned to articles from both RRN and WoF, and only 18 were assigned to posts from just one of the two sites. This demonstrates the significant topical overlap between the sites. Further details and figures are provided in Appendix C."
        },
        {
            "heading": "3.5 LIWC Analysis",
            "text": "We use LIWC2015 (Pennebaker et al., 2015) to compare the linguistic properties of English RRN and WoF posts against the metrics for genuine New York Times (NYT) articles provided by Pennebaker et al. (see Table 2 and Appendix C.1).\nEmotional tone, which is on a scale of 0-100 (negative to positive), shows that RRN and WoF are written more negatively than real news, with WoF being even more negative than RRN. This is confirmed by the values for Affective Processes, which show that both sites use more emotion-laden words than NYT. The sub-metrics show this is skewed towards negativity, particularly anger (where both sites have over double the proportion of angerindicating words than NYT).\nAll three sources focus most commonly on the present (e.g. words like \u201ctoday\u201d, \u201cis\u201d, \u201cnow\u201d), however RRN and WoF do so at a higher rate than the NYT. RRN and WoF also use more future focus terms (e.g. \u201cmay\u201d, \u201cwill\u201d, \u201csoon\u201d) compared to the NYT , and past focus terms (e.g. \u201cago\u201d, \u201cdid\u201d, \u201ctalked\u201d) less frequently. This suggests that the content of RRN and WoF comments is more speculative as compared to reputable journalism and is more focused on covering current events than past ones.\nTable 3 shows the top 5 LIWC categories with the strongest correlation for each of the two sites. The strong correlation of colons and interrogatives for WoF is unsurprising, given its repeated use of the phrase \u201cWhat\u2019s really going on:\u201d. RRN\u2019s correlation with conjunctions suggests it tends to use more complex sentences. The remaining attributes are below the 0.3 threshold of strong correlation. However RRN is weakly correlated to personal pronouns which is due to its tendency to cover individual politicians (see Table 6 in Appendix C), while WoF is weakly correlated to impersonal pro-\nnouns (i.e. one, you, they) as it tends to discuss groups, such as the Russian and Ukrainian armed forces (see Table 7 in Appendix C)."
        },
        {
            "heading": "3.6 Article Backdating",
            "text": "Both sites tend to backdate non-English posts (by as much as 136 days in two cases, see Appendix C, Table 5), in order to make translations appear published at a similar time. The two most backdated articles are Spanish and Chinese translations of an English article, which were actually published 136 days later.\nOur hypothesis for the backdating is due to limited resources articles were only translated into a given language when that became necessary for a particular disinformation campaign. In order to convey timeliness, the translations were then backdated to the date of the original."
        },
        {
            "heading": "3.7 n-gram Analysis",
            "text": "Tables 6 and 7 in Appendix C show the top occuring n-grams per month for the respective websites. The most frequent \u201creally going\u201d n-gram on WoF is part of the phrase \u201cWhat\u2019s really going on\u201d, which appears in all of its fact-check-style articles. The n-gram also appears frequently in the first month of RRN data, due to the articles copied from WoF.\nOn WoF, the most frequent n-grams typically relate directly to the war in Ukraine itself (\u201crussian troops\u201d, \u201cukranian armed forces\u201d), whereas on RRN they relate to the consequences of the conflict for the rest of the world (\u201cunited states\u201d, \u201crussian gas\u201d). Consequently, the most frequent n-grams on WoF are relatively constant across the different months, whereas RRN\u2019s n-grams change from one month to the next as they tend to be connected to current affairs. For example, the bigram \u201cantirussian sanctions\u201d enters the top 10 in June 2022, and remains the second most used bigram from July to September, and refers to the damage allegedly caused to Western economies. Other terms demonstrate that RRN also covers some genuine news, e.g. \u201celizabeth ii\u201d in September 2022 and \u201cworld cup\u201d in November and December 2022.\nEven though to a much lesser degree, WoF still responds to specific highly controversial events from the conflict. For example in August 2022, in response to Ukraine and Russia blaming each other for the shelling of the Zaporizhzhia nuclear power station13, the n-grams \u201cnuclear power\u201d and \u201cnuclear power plant\u201d both appear with high frequency in WoF articles that promote the Russian perspective on these events."
        },
        {
            "heading": "3.8 Presence of Cyrillic Characters",
            "text": "178 of the articles were found to contain characters in the Cyrillic codepoint range (Table 4), which were manually examined to determine the reason. Accidental Cyrillic: Incorrect usage of Cyrillic characters instead of the intended character in the Latin alphabet. For example, 11 times the \u201cc\u201d in Robert Habeck, a German politician, is actually the identical-looking lowercase Cyrillic Es14. Forgotten Cyrillic: Issues with translation where a Russian sentence was left in the article, with or without the target language translation. Intentional: Expected usage of Cyrillic characters\n13https://reut.rs/46KWvTS 14https://en.wikipedia.org/wiki/Es_(Cyrillic)\ne.g. the name of a Russian organisation. Unclear: We were unable to determine why the characters were used.\nGiven that both RRN and WoF had forgotten Russian text in all languages, we hypothesise that all articles were originally written in Russian. Two Arabic articles on RRN contain the phrases \u201cthe translation is too long\u201d and \u201csave translation\u201d in Russian, likely copied from a machine translation tool\u2019s UI, although we were not able to determine the specific tool used. Although this was only found in one language on one of the sites, it suggests it is more likely the articles are machine than human translated."
        },
        {
            "heading": "4 Future Work",
            "text": "There is much additional work which could be performed on this dataset. Although we identify the subject of articles via topic clustering and n-grams, we do not attempt to identify stance towards it. More complex topic analysis, such as identifying commonly co-occuring topics, would also be possible. Given the mixture of true and false posts on the sites, this dataset may be a useful resource for automated fact-checking, although this would require human annotation and ground-truth may be difficult to establish in the complex information environment of the war in Ukraine."
        },
        {
            "heading": "5 Conclusion",
            "text": "This paper presented an analysis of the Russian disinformation sites Recent Reliable News and WarOnFakes, including an analysis of the articles\u2019 topics, publication times, and linguistic properties. We show that the sites cover a diverse range of topics, and that their linguistic properties differ from those of reputable media. We analysed the presence of Cyrillic characters due to site operator errors, and their practice of backdating articles, showing that a significant proportion of translations are falsely dated. This new multilingual dataset will facilitate further research in disinformation analysis and promote repeatability.\nLimitations\nAlthough our work provides a complete collection of WoF and RRN, since these two websites seem to be highly related, it is unsurprising that they tend to publish similar types of content. Therefore this dataset cannot be considered fully representative\nof all kinds of Russian disinformation. Nevertheless, it is complementary to overtly Russian state media, such as Sputnik and Russia Today. Unfortunately, due to the ban on accessing their content from the EU, we could not supplement the dataset from those sources or compare against them.\nOur topic analysis model has not been formally validated, for example by comparing topics to those assigned by human or expert annotators. Some small scale manual validation was performed in order to find good hyperparameters, however this consisted of inspecting a small random sample of some of the categories. A particular area warranting validation in future work is examining the texts not assigned categories. These are only a very small number, however as we aggregate sentence classifications at article level, which means that an article can be assigned the correct topics even if some of its sentences may not be.\nIn our LIWC analysis, we compare to the New York Times data provided by Pennebaker et al. (2015). Although this is the closest source out of the provided LIWC baselines, the New York Times represents a more formal style of journalism than many online media. In future work we plan to compare these two disinformation sites against official state-affiliated news sources such as Russia Today.\nFinally, we did not analyse the separate Russianlanguage edition of WarOnFakes. As it is a separate site in Russian only, there is no reliable way to connect its articles to their similar English-language versions (if such are published). Analysing the Russian WoF website is planned for future work, as it requires adaptation of the analysis to be bilingual, which is out of scope for this paper.\nEthics\nThe data collection was carried out in accordance with our institutional ethics policy.\nCollection was via the Wordpress API, followed by automated processing and a limited amount of manual analysis by the authors. No external volunteers or crowd-workers were recruited. Due to the disinformation nature of these two websites, the data may contain content which is disturbing or distressing. Therefore we limited the possibility of harm during analysis by: i) minimising the number of individual articles studied by the authors as much as possible; ii) where necessary, viewing only the text of articles, to avoid the possibility of\nviewing distressing media; iii) ensuring familiarity with supporting resources for researchers working with potentially disturbing content.\nAs the websites in question are not legitimate news websites, they do not have a terms of use to allow or prohibit the acquisition of their content. We consider the collection and distribution of their articles in the public interest, due to the prominence of their disinformation and the harm that results from it. It is not feasible to contact them to obtain permission, as they have previously been unresponsive to enquiries 15. The dataset does not include images, as in many cases they appear to have been taken from stock agencies. This is a commonly used tactic by disinformation websites.\nWe have checked that the dataset does not contain personally identifiable information in the user data files, as all users have either generic (e.g. \u201cAdmin\u201d) or random (e.g. \u201cUiXnZyvH\u201d) names. No user comments were available to collect.\nIt is possible that the process of creating a disinformation dataset increases the spread and prominence of the disinformation. We would argue that is not the case with this dataset as we: i) are only focusing on content from disinformation websites, the low credibility of which has already been widely publicised (see Appendix A); iii) are not increasing the longevity of disinformation narratives by preserving them after they have being taken down, since the two independent websites that are publishing them are still publicly accessible via all common search engines.\nSome articles make reference to individuals, albeit only public figures to our knowledge, and many contain narratives which are hateful towards individuals and groups. We encourage researchers who use this dataset to do so responsibly, and in particular to avoid highlighting specific individuals and to ensure that the disinformation narratives are presented alongside authoritative evidence of their untrue nature. We would like to specifically discourage the use of this dataset for training generative models that are capable of creating new disinformation. The dataset is released under a license which prohibits commercial activity."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work is partially supported by the UK\u2019s innovation agency (InnovateUK) grant number\n15NewsGuard attempted to contact them as part of their review process (Maitland, 2022; Roache, 2022)\n10039039 (approved under the Horizon Europe Programme as VIGILANT, EU grant agreement number 101073921).16 Freddy Heppell is supported by a University of Sheffield Faculty of Engineering PGR Prize Scholarship."
        },
        {
            "heading": "A Evidence of Disinformation",
            "text": "For WarOnFakes, there is a substantial number of articles and fact-checks establishing it as a disinformation source. PolitiFact undertook a review of over 380 of their fact-checks and found a significant number of falsehoods17. In an article by AFP via France24, Roman Osadchuk, from the Atlantic Council\u2019s Digital Forensic Research Lab (DFRLab), is quoted as saying \u201cSince Russia\u2019s invasion, the \u2018War On Fakes\u2019 initiative has become a powerhouse of spreading false debunks\u201d and \u201cIt is an effective tool of state propaganda and disinformation\u201d 18. The Institute of Network Cultures describes it as \u201cKremlin-Sponsored Particpatory Propaganda\u201d19, and highlights connections between the Russian state and the website, including promotion from organisations under the Russian Ministry of Foreign Affairs, and on the Russian Ministry of\n17https://www.politifact.com/article/2022/aug/ 08/how-war-fakes-uses-fact-checking-spread-pro -russia/\n18https://www.france24.com/en/live-news/202302 16-fake-fact-checks-seek-to-obscure-russian-rol e-in-war\n19https://networkcultures.org/tactical-media-r oom/2022/07/22/weaponized-osint-the-new-kremlin -sponsored-participatory-propaganda/\nDefence\u2019s Telegram channel. BBC Monitoring, the specialist media source analysis division of BBC News, states \u201cSome of its fact-checks are genuine but most content is Russian talking points on the invasion which do not stand up to scrutiny\u201d20.\nThe site has also been covered by EUvsDisinfo21, DFRLab22, the European Digital Media Observatory23, and Media Bias/Fact Check24.\nRRN has received comparatively less attention from fact checkers, however was described as disinformation by NewsGuard (Maitland, 2022), which additionally claims that they reuse content from WarOnFakes, and EU Disinfo Lab have noted a connection in the hosting infrastructure of the two sites (Alaphilippe et al., 2022). It is therefore probable that the apparent state-backing of WarOnFakes also applies to RRN."
        },
        {
            "heading": "B Data Example",
            "text": "Figure 3 shows an example of an article published on WoF25 in English, French, Spanish, Chinese and Arabic. Full texts are omitted for languages other than English. This story was judged to be fake by fact-checkers26. Usage of guillemets (\u00ab \u00bb) as quote marks is reproduced as returned by the WordPress API, but this appears to be normalised when the page is rendered."
        },
        {
            "heading": "C Detailed Dataset Statistics",
            "text": "Figure 4 shows a weekly chart of the 10 most common topics on the site. In general, there is no clear variation between these topics, with the exception of the initial popularity of the topic #2 due to the majority of posts that week being from WarOnFakes. The significant dip in January 2023 is due to the Russian public holidays discussed in section 3.2.\nFigure 2 shows the distribution of sentence-level topic counts aggregated for each article. 78 posts were not assigned any topic, the majority of articles\n20https://monitoring.bbc.co.uk/product/c203aqg1 21https://euvsdisinfo.eu/riding-the-bomb/ 22https://medium.com/dfrlab/russian-telegram-c hannel-embraces-fact-checking-tropes-to-sprea d-disinformation-c6a54393c635\n23https://edmo.eu/2022/03/17/russian-propaga nda-disguising-as-fact-checking-a-statement-fro m-the-edmo-taskforce/\n24https://mediabiasfactcheck.com/war-on-fakes -bias/\n25https://waronfakes.com/civil/fake-russian-a viation-struck-a-maternity-hospital-with-mothers -and-children/\n26https://reut.rs/3tEvFfk\nhave 1-3 topics, however in the extreme some have as many as 21 - this is an article from WarOnFakes \u201cWhat happened in Bucha? A full analysis of the Ukrainian provocation\u201d , a long article supposedly explaining the truth about many elements of the Bucha massacre.\nTable 5 shows the proportion of backdated articles per language, and the mean and maximum backdating period for each. For English, a small number of posts are backdated after a short period of time. It is likely this is caused by posts that have been forward-dated (i.e. set to be published in the future) by one or two days, resulting in subsequent posts appearing to be backdated until the publication date catches up. However, for other languages, backdates are for a much longer period.\nC.1 Complete LIWC2015 Data The complete listing of LIWC2015 is included in Table 8, in the hope it can be used for comparison in future work.\nDifferentiation 2.34 2.26 2.32\ncontinued..."
        }
    ],
    "title": "Analysing State-Backed Propaganda Websites: a New Dataset and Linguistic Study",
    "year": 2023
}