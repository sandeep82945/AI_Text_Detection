{
    "abstractText": "Ideology detection (ID) is important for gaining insights about peoples\u2019 opinions and stances on our world and society, which can find many applications in politics, economics and social sciences. It is not uncommon that a piece of text can contain descriptions of various issues. It is also widely accepted that a person can take different ideological stances in different facets. However, existing datasets for the ID task only label a text as ideologically leftor right-leaning as a whole, regardless whether the text containing one or more different issues. Moreover, most prior work annotates texts from data resources with known ideological bias through distant supervision approaches, which may result in many false labels. With some theoretical help from social sciences, this work first designs an ideological schema containing five domains and twelve facets for a new multifaceted ideology detection (MID) task to provide a more complete and delicate description of ideology. We construct a MITweet dataset for the MID task, which contains 12,594 English Twitter posts, each annotated with a Relevance and an Ideology label for all twelve facets. We also design and test a few of strong baselines for the MID task under in-topic and cross-topic settings, which can serve as benchmarks for further research. 1",
    "authors": [
        {
            "affiliations": [],
            "name": "Songtao Liu"
        },
        {
            "affiliations": [],
            "name": "Ziling Luo"
        },
        {
            "affiliations": [],
            "name": "Minghua Xu"
        },
        {
            "affiliations": [],
            "name": "Lixiao Wei"
        },
        {
            "affiliations": [],
            "name": "Ziyao Wei"
        },
        {
            "affiliations": [],
            "name": "Han Yu"
        },
        {
            "affiliations": [],
            "name": "Wei Xiang"
        },
        {
            "affiliations": [],
            "name": "Bang Wang"
        }
    ],
    "id": "SP:f1f9a92c62858af37ffc1c708c9d2181c4e40cb8",
    "references": [
        {
            "authors": [
                "Saja Aldera",
                "Ahmad Emam",
                "Muhammad Al-Qurishi",
                "Majed Alrubaian",
                "Abdulrahman Alothaim."
            ],
            "title": "Online extremism detection in textual content: A systematic literature review",
            "venue": "IEEE Access, 9:42384\u2013 42396.",
            "year": 2021
        },
        {
            "authors": [
                "Ramy Baly",
                "Giovanni Da San Martino",
                "James Glass",
                "Preslav Nakov."
            ],
            "title": "We can detect your bias: Predicting the political ideology of news articles",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
            "year": 2020
        },
        {
            "authors": [
                "J. Edwin Boyd",
                "Douglas N. Jackson."
            ],
            "title": "The perceived structure of social attitudes and personality : A multidimensional scaling approach",
            "venue": "Multivariate Behavioral Research, 2(3):281.",
            "year": 1967
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Terry Eagleton."
            ],
            "title": "Ideology: An Introduction",
            "venue": "Verso.",
            "year": 2007
        },
        {
            "authors": [
                "Stanley Feldman",
                "Leonie Huddy."
            ],
            "title": "Not so simple: The multidimensional nature and diverse origins of political ideology",
            "venue": "BEHAVIORAL AND BRAIN SCIENCES, 37(3):312\u2013313.",
            "year": 2014
        },
        {
            "authors": [
                "L.W. Ferguson."
            ],
            "title": "Review of the book personality measurement",
            "venue": "Journal of Consulting Psychology, 16(6):475.",
            "year": 1952
        },
        {
            "authors": [
                "Jos\u00e9 Antonio Garc\u00eda-D\u00edaz",
                "Ricardo Colomo-Palacios",
                "Rafael Valencia-Garc\u00eda."
            ],
            "title": "Psychographic traits identification based on political ideology: An author analysis study on spanish politicians\u2019 tweets posted in 2020",
            "venue": "Future Generation Computer Sys-",
            "year": 2022
        },
        {
            "authors": [
                "Ted Grover",
                "Gloria Mark."
            ],
            "title": "Detecting potential warning behaviors of ideological radicalization in an alt-right subreddit",
            "venue": "Proceedings of the International AAAI Conference on Web and Social Media, 13(01):193\u2013204.",
            "year": 2019
        },
        {
            "authors": [
                "Daniela Grunow",
                "Katia Begall",
                "Sandra Buchler."
            ],
            "title": "Gender ideologies in europe: A multidimensional framework",
            "venue": "JOURNAL OF MARRIAGE AND FAMILY, 80(1):42\u201360.",
            "year": 2018
        },
        {
            "authors": [
                "Eysenck Hans."
            ],
            "title": "Sense and nonsense in psychology",
            "venue": "Sense and nonsense in psychology.",
            "year": 1957
        },
        {
            "authors": [
                "Mohit Iyyer",
                "Peter Enns",
                "Jordan Boyd-Graber",
                "Philip Resnik."
            ],
            "title": "Political ideology detection using recursive neural networks",
            "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages",
            "year": 2014
        },
        {
            "authors": [
                "Kornraphop Kawintiranon",
                "Lisa Singh."
            ],
            "title": "Knowledge enhanced masked language model for stance detection",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
            "year": 2021
        },
        {
            "authors": [
                "Johannes Kiesel",
                "Maria Mestre",
                "Rishabh Shukla",
                "Emmanuel Vincent",
                "Payam Adineh",
                "David Corney",
                "Benno Stein",
                "Martin Potthast."
            ],
            "title": "SemEval2019 task 4: Hyperpartisan news detection",
            "venue": "Proceedings of the 13th International Workshop on",
            "year": 2019
        },
        {
            "authors": [
                "Vivek Kulkarni",
                "Junting Ye",
                "Steve Skiena",
                "William Yang Wang."
            ],
            "title": "Multi-view models for political ideology detection of news articles",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3518\u2013",
            "year": 2018
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Yujian Liu",
                "Xinliang Frederick Zhang",
                "David Wegsman",
                "Nicholas Beauchamp",
                "Lu Wang."
            ],
            "title": "POLITICS: Pretraining with same-story article comparison for ideology prediction and stance detection",
            "venue": "Findings of the Association for Computational Linguis-",
            "year": 2022
        },
        {
            "authors": [
                "Burt L. Monroe",
                "Michael P. Colaresi",
                "Kevin M. Quinn."
            ],
            "title": "Fightin\u2019 words: Lexical feature selection and evaluation for identifying the content of political conflict",
            "venue": "Political Analysis, 16(4):372\u2013403.",
            "year": 2008
        },
        {
            "authors": [
                "Jennifer C. Mueller."
            ],
            "title": "Producing colorblindness: Everyday mechanisms of white ignorance",
            "venue": "SOCIAL PROBLEMS, 64(2):219\u2013238.",
            "year": 2017
        },
        {
            "authors": [
                "Dat Quoc Nguyen",
                "Thanh Vu",
                "Anh Tuan Nguyen."
            ],
            "title": "BERTweet: A pre-trained language model for English tweets",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 9\u201314, On-",
            "year": 2020
        },
        {
            "authors": [
                "David Nolan."
            ],
            "title": "Principles of pharmaceutical marketing",
            "venue": "Journal of Marketing, 40(2):123.",
            "year": 1976
        },
        {
            "authors": [
                "Samuel L. Perry",
                "Andrew L. Whitehead",
                "Joshua B. Grubbs."
            ],
            "title": "Culture wars and covid-19 conduct: Christian nationalism, religiosity, and americans\u2019 behavior during the coronavirus pandemic",
            "venue": "JOURNAL FOR THE SCIENTIFIC STUDY OF RELIGION,",
            "year": 2020
        },
        {
            "authors": [
                "Daniel Preo\u0163iuc-Pietro",
                "Ye Liu",
                "Daniel Hopkins",
                "Lyle Ungar."
            ],
            "title": "Beyond binary labels: Political ideology prediction of Twitter users",
            "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
            "year": 2017
        },
        {
            "authors": [
                "Milton Rokeach."
            ],
            "title": "The nature of human values",
            "venue": "American Journal of Sociology, 89(2).",
            "year": 1973
        },
        {
            "authors": [
                "Juliana Schwarz."
            ],
            "title": "Detecting political ideology in youtube comments using machine learning",
            "venue": "Seminar Social Media and Business Analytics.",
            "year": 2019
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141 ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc.",
            "year": 2017
        },
        {
            "authors": [
                "John Wilkerson",
                "Andreu Casas."
            ],
            "title": "Large-scale computerized text analysis in political science: Opportunities and challenges",
            "venue": "Annual Review of Political Science, 20(1):529\u2013544.",
            "year": 2017
        },
        {
            "authors": [
                "Zhiping Xiao",
                "Weiping Song",
                "Haoyan Xu",
                "Zhicheng Ren",
                "Yizhou Sun."
            ],
            "title": "Timme: Twitter ideology-detection via multi-task multi-relational embedding",
            "venue": "Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Ideologies are the collection of beliefs or philosophies attributed to a particular social group or class (Eagleton, 2007). They shape how we see the world and interact with each other. In this information age, social media has rapidly developed, allowing people to express their thoughts and opinions online, which offer strong cues about their ideologies (Preot\u0327iuc-Pietro et al., 2017; Kulkarni\n\u2217 Equal contribution: S. Liu and Z. Luo. \u2020 Corresponding author: M. Xu and B. Wang\n1Dataset and codes are available on https://github. com/LST1836/MITweet\net al., 2018; Schwarz, 2019). Ideology detection is a critical task for quantitative political and social science (Wilkerson and Casas, 2017; Liu et al., 2022), which can help policy makers to analyze public opinions for making wise decisions (Xiao et al., 2020). Tracking ideology on social media is also important for monitoring online communities and detecting signs of ideological radicalization (Grover and Mark, 2019; Aldera et al., 2021).\nIt is widely accepted that individuals or groups can take different ideological stances in different facets (Boyd and Jackson, 1967; Feldman and Huddy, 2014). Motivated by this, many efforts have been devoted to characterizing ideology from various facets (Ferguson, 1952; Rokeach, 1973; Grunow et al., 2018). From a computational linguistics viewpoint, some texts may contain descriptions of different issues and reflect the author\u2019s ideology from various aspects. As shown in Figure 1(b), the authors convey their multiple ideologies by expressing opinions on topics they care about. Therefore, it is necessary to detect the ideology of texts from multiple facets, so as to provide a more comprehensive and nuanced picture for further sociological research.\nIn order to facilitate progress on ideology detection, a number of annotated datasets have been\nreleased, as shown in Table 1. However, two drawbacks of existing datasets limit the research of this task: (1) Only one facet. Due to the absence of theoretical guidance from the multifaceted ideology, existing datasets only label a text as ideologically left- or right-leaning as a whole, regardless whether the text containing one or more different issues. For example, the upper text in Figure 1(b) can be labeled with left-leaning due to its radical attitude. However, this simple label conceals the domains discussed in the text (i.e., culture and society), and ignores that the author supports the protection of individual rights, which is conservative or rightleaning in sociology. (2) Noisy labels. Most of previous work crawl data from resources with known ideological bias and project the bias label to all texts gathered from it, which is a form of distant supervision. As discussed in Baly et al. (2020), while the distant supervision assumption generally holds, there are still many instances that defy it, which introduces noise into datasets.\nIn an effort to address these issues, in this work, we first design a multifaceted ideology schema to provide a more complete and delicate description of ideology, by considering traditional ideology division and emerging social topics. As shown in Figure 1(a), the schema covers five orthogonal domains, including politics, economy, culture, diplomacy and society, under which, there are a total\nof twelve facets. We also define the ideological attributes for the left- and right-leaning of each facet to achieve a more detailed illustration of ideology. Based on the new schema, we construct a new high-quality dataset, MITweet, for a new multifaceted ideology detection (MID) task. The dataset contains 12,594 English Twitter posts, each manually annotated with a Relevance (and an Ideology) label for all twelve facets. As the examples in Figure 1(b), MITweet makes up the absence of comprehensive annotation by annotating ideological labels for multiple facets involved in texts. In addition, MITweet covers 14 highly controversial topics in recent years (e.g., abortion, covid-19 and Russo-Ukrainian war), which can facilitate research in cross-topic MID.\nUsing MITweet as the benchmark, we develop strong baselines for the new MID task based on several widely-used pre-trained language models. We conduct thorough experiments and analysis under both in-topic and cross-topic settings. Experiment results show that: (1) BERTweet (Nguyen et al., 2020) performs the best on overall metrics for both subtasks of MID. (2) The performance of BERTweet can be further improved by using indicators as part of input, which is detected with the weighted log-odds-ratio technique with informed Dirichlet priors (Monroe et al., 2008). (3) Crosstopic setting is quite challenging and the achieved\nperformances are far from promising."
        },
        {
            "heading": "2 Multifaceted Ideology",
            "text": "To accurately measure the ideology of an individual or group, sociologists have designed a series of scales to categorize political attitudes based on one or more facets. Ferguson (1952) developed ten stance scales that encompass attitudes towards birth control, the death penalty, censorship, communism, evolution, law, patriotism, theism, criminals, and war. By carefully analyzing the results of the popular test, he was able to condense the ten scales into three distinct ideological facets: religious, humane, and ethnic. Soon after, Hans (1957) classified political ideology into \u201cRadicalism\u201d and \u201cConservatism\u201d. To demonstrate the inadequacy of the above research, Rokeach (1973) proposed a dual-axis model of ideology based on the principles of freedom and equality. This model is similar to the Nolan Chart (Nolan, 1976), a political diagram that uses two facets to divide people\u2019s ideological positions into four different quadrants. The horizontal axis represents \u201ceconomic freedom\u201d, while the vertical axis represents \u201cindividual freedom\u201d. Ideologies located in different quadrants are categorized as modern liberalism, conservatism, libertarianism, and nationalism. These prior work proposed different facets for dividing ideologies and laid the theoretical foundation for multifaceted ideology, but a core problem is that they usually study specific domains, such as politics or economics, and different facets may overlap or have ambiguous boundaries.\nWith the development of society, the study of multifaceted ideology and political spectrum has brought attention to new issues, including anti-war movements, women\u2019s rights, environmental protection, animal welfare and other related concerns. Mueller (2017) argued that color-blind racism is a form of covert and highly institutionalized discrimination, which differs from the more overt forms of racism seen during slavery and legal segregation. Therefore, colorblindness serves as the prevailing ideological support for a historically unique form of structural white supremacy known as color-blind racism. Grunow et al. (2018) argued that defining gender ideology as a one-dimensional construct that ranges from traditional to egalitarian is problematic in contemporary society. They proposed an alternative framework that considers the multidimensionality of gender ideologies and identified\nfive ideology profiles: egalitarian, essentialist egalitarian, intensive parenting, moderately traditional, and traditional. During the COVID-19 pandemic, the far-right ideology has taken on new characteristics, including a disregard for scientific expertise, distrust of news media, and allegiance to TrumpChristian nationalism (Perry et al., 2020). These new social issues call for a flexible ideological evaluation system, which can fully explain contemporary issues in various social fields and describe the existing variation in ideology from multiple facets.\nBy considering previous work and emerging social issues, we put forth a new multifaceted ideology schema (see Figure 1(a), detailed in Appendix A). Firstly, our multifaceted ideology schema divides ideology into five orthogonal domains to ensure that each domain is independent and has clear boundaries. Secondly, the multifaceted ideology schema now incorporates new contemporary issues. For instance, the facet \u201cCultural Value\u201d is linked to the anti-abortion movements, the facet \u201cJustice Orientation\u201d is associated with the Black Lives Matter movement, and the facet \"Military Force\" is connected to peace-war issues. Finally, our multifaceted ideology schema covers twelve facets, each is defined with ideological attributes for the left- and right-leaning, providing a more complete and delicate description of ideology."
        },
        {
            "heading": "3 The MITweet Dataset",
            "text": "Based on the proposed multifaceted ideology schema as described in Section 2, we annotate tweets manually to build MITweet. In this section, we describe how the data is collected, the design of annotation process, dataset statistics and the methods to ensure the quality of annotation."
        },
        {
            "heading": "3.1 Data Collection",
            "text": "We collect tweets using Twitter streaming API based on different topics. To maximize the proportion of tweets containing the author\u2019s ideology and improve annotation efficiency, we select 14 topics that meet the following two criteria: (1) highly controversial or extensively discussed in recent years; (2) related to politics, economy, culture, diplomacy or society, i.e. the five domains in the ideology schema. Then we use a set of query keywords as seeds to collect topic-related tweets. For each topic, we set the query period during which the event involved many intensive discussions on social media,\nas shown in Table 2. In total, we gather around 41.5k raw tweets for all topics.\nTo ensure the quality of MITweet, we preform several preprocessing steps for raw tweets: (1) We remove duplicates and retweets. (2) We remove @USER and URLs in tweets, as they often do not convey semantic information literally. (3) We remove tweets with less than 15, or more than 130 words. We set this length limit because tweets that are too short are usually semantically incomplete, while tweets that are too long may contain many irrelevant content, which can introduce noise into the dataset. (4) We focus on tweets that have received a lot of attention on Twitter. Tweets that express a clear or controversial point of view or represent the perspectives of many people often have higher popularity and research value.\nFor each tweet, we calculate a spread score based on the number of likes, comments and retweets, a user score based on the number of tweets, followers and followees of the author. Then a final heat score is obtained by weighting the spread score and user score. We remove tweets with heat scores below a certain threshold. After preprocessing, we have 29.0k cleaned tweets in total and randomly sample 17.0k of them for annotation."
        },
        {
            "heading": "3.2 Data Annotation",
            "text": "We invite 56 annotators to participate in our annotation, including graduate students from schools of\npublic management, social science and communications. Before starting the annotation, we conduct sufficient training for annotators and several rounds of annotation trials, which will be discussed in detail in Section 3.4.\nFor each tweet, each annotator needs to annotate a Relevance (and an Ideology) label for each of twelve facets in our ideology schema described in Section 2. This process was done in two steps. Firstly, annotators are asked to label \u201cRelated\u201d or \u201cUnrelated\u201d for each facet. For example, if an annotator believes that a tweet expresses the author\u2019s ideology regarding \u201cSocial Development\u201d, then \u201cRelated\u201d should be labeled on this facet, and vice verse. Secondly, for each facet labeled with \u201cRelated\u201d in the previous step, annotators are further required to label one ideological category: \u201cLeft\u201d, \u201cCenter\u201d or \u201cRight\u201d. Note that the \u201cCenter\u201d class means that tweets are biased towards a centrist ideology in one facet, not lacking ideological bias (e.g., purely descriptive news reports), which is labeled with \u201cUnrelated\u201d.\nEach tweet is annotated by three random annotators, and the final results are obtained through major voting. If major voting is not possible, that is, three annotators label a facet with completely different ideological categories, then the tweet will be discarded due to its possible high ambiguity. When only two annotators label \u201cRelated\u201d on a facet, they must reach an agreement on ideological\nlabels; Otherwise, the tweet will also be discarded. Finally, 74.1 percent of labeled tweets pass the inter-annotator agreement check and compose the MITweet dataset."
        },
        {
            "heading": "3.3 Dataset Statistics and Analysis",
            "text": "Overall Statistics MITweet contains a total of 12,594 tweets, 11,649 of which are related to at least one ideological facet in the schema. Each tweet is labeled with a Relevance label, and an Ideology label if the relevance label is \u201cRelated\u201d, along each facet. Meanwhile, MITweet involves 14 topics from a variety of fields, and their statistics are provided in Table 2 and Appendix C.\nRelevance Distribution As shown in Table 3, PeR, JO and EP are the most frequently related facets; MF, SD and DS are also comparatively common, while CSR and PoR are the rarest facets, with a related ratio of less than 1%. In general, most facets have a relatively low related ratio, resulting in an imbalance data distribution and posing challenges for facet relevance detection task. Nevertheless, we do not take downsampling since this is a reflection of the real-world data distribution.\nIdeology Distribution The right part of Table 3 presents the ideology statistics. It is obvious that different facets have very different data distributions. For example, most tweets are left-leaning towards SD and JO, while it is the opposite for MF and PeR. This once again indicates that it is\nnot appropriate to label texts just as either left- or right-leaning and that characterizing ideology from multiple facets can provide a more complete and nuanced view for further analysis."
        },
        {
            "heading": "3.4 Quality Control",
            "text": "As described in Section 1, most previous related work annotate datasets using distant supervision approaches, which can lead to many noisy labels in datasets. In contrast, our MITweet is annotated manually and is therefore inherently more reliable and diverse.\nIn order to further ensure the data quality, we carried out a strict annotation workflow. First of all, we explain the annotation schema in detail for annotators and provide some examples. Then several rounds of annotation trials are performed. After each trial, we collect questions from annotators and discuss frequent inconsistencies, based on which we retrain annotators and then a new round of trial will start. The above process is iterated for several times until the pass rate of agreement check reaches 0.70 and the average inter-annotator agreement reaches 0.75 (Krippendorff\u2019s alpha). During formal annotation, we annotate 14 topics one by one to avoid interference between topics and reduce the difficulty in dealing with continuously changing topics. Before starting the annotation of each topic, we introduce the background of the topic and provide some representative instances for annotators.\nWe compute the Krippendorff\u2019s alpha along each facet as the measure of agreement between annotators, as shown in Table 4. We can observe that Krippendorff\u2019s alpha of most facets are above 80, with an average of 83.1, which is a satisfactory score, indicating high consistency among annotators and that the dataset is reliable for further research."
        },
        {
            "heading": "3.5 Credibility Analysis",
            "text": "With the well-designed schema and strict annotation workflow, the data distribution of MITweet is generally consistent with the sociological characteristics of each topic involved. Take the topic of BLM as an example.\nBLM (Black Lives Matter) is a social and civil rights movement. It advocates for the rights and equality of Black communities in various aspects of society, including law enforcement, criminal justice, education, employment and healthcare. From the perspective of multifaceted ideology, BLM is mainly related to Social Development, Justice Orientation, Personal Right (Society domain) and Ethical Pursuit (Culture domain). In addition, the nature of BLM, which is the pursuit of black rights, racial equality and social reform, suggests that it stands for Revolutionism (Left) in Social Development, Result Justice (Left) in Justice Orientation, Individual Right (Right) in Personal Right and Ethical Liberalism (Left) in Ethical Pursuit.\nThe topic distribution of MITweet is shown in Appendix C, we can see that the label distribution of BLM topic is consistent with the analysis mentioned above. The facets with the largest number of related tweets are Justice Orientation, Social Development, Personal Right and Ethical Pursuit, accounting for 88.4%, 36.5%, 23.9% and 5.4% of all BLM tweets, respectively. The ideology distribution also aligns with the sociological characteristics of BLM. Most tweets related to Ethical Pursuit (81.6%), Social Development (80.6%) and Justice Orientation (89.0%) are left-leaning in their respective facets. And 87.6% of tweets related to Personal Right are right-leaning in this facet.\nFor other topics, we can observe similar consistency with sociological analysis. This indicates that\nMITweet reflects people\u2019s ideological leanings towards various facets in the real world and therefore has high credibility."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Dataset Split",
            "text": "We split the MITweet dataset in two different ways for different scenarios. (1) Random split. We randomly divide the training, development, and testing sets following a 70/15/15 split. This is for in-topic MID since all three sets share the same topics. (2) Topic split. Firstly, several topics are selected as the test topics. Then, tweets of the remaining topics are randomly divided into training set and development set according to the ratio of 4:1. This can serve as the setting of cross-topic MID, where the model is first trained and validated on source topics, and then tested on target topics."
        },
        {
            "heading": "4.2 Tasks and Models",
            "text": "We split the multifaceted ideology detection procedure into two sub-tasks in a pipeline manner: (1) Relevance Recognition aims to recognize the facets that a text is related to. We model this task as a multi-label classification problem. (2) Ideology Detection predicts which ideology a text holds regarding the related facets. This task can be modeled as a multi-class classification problem.\nWe use Transformer (Vaswani et al., 2017) encoder based pre-trained language models (PLMs) as backbone models. Three PLMs are compared in our experiments: BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), and BERTweet (Nguyen et al., 2020) pretrained on 850M English Tweets following the training procedure of RoBERTa. The base version of these models from HUGGINGFACE are used. We fine-tune the PLMs to predict the relevance or ideology by appending a linear classification layer on top of the hidden representation of the [CLS] token. For the relevance recognition task, tweet text is the input. For the ideology detection task, we concatenate the tweet with the facet name (e.g., \u201cPolitical Regime\u201d) and separate them using the [SEP] token, and then feed the sequence into PLMs.\nInspired by Kawintiranon and Singh (2021), which used the weighted log-odds-ratio technique with informed Dirichlet priors (Monroe et al., 2008) to compute stance words, we propose using the similar method to obtain the indicators for each facet. Specially, we extract tweets from training set to form a corpus Ci and a corpus Cj , where Ci contains tweets related to a facet, while Cj contains the rest, i.e., unrelated tweets. Then, by using weighted log-odds-ratio, we compute the usage difference of each word among two corpora and find the top-k significant words in Ci as indicators of the facet. Therefore, indicators are the words in training set that best represent a facet. Examples of indicators are provided in Table 5. Obviously, compared with the abstractness of facet names, indicators have more concrete meanings and different indicators describe different perspectives of a facet. We set k = 18 and concatenate tweet with indicators as an alternative input for the ideology detection task."
        },
        {
            "heading": "4.3 Evaluation Metrics",
            "text": "We adopt the Accuracy (Acc) and F1 metrics for each facet. In order to evaluate the overall performance of models, we use both micro and macro methods to integrate metrics from each facet. Macro-Acc/F1 treats each facet equally and is the average of Acc/F1 scores across all facets. MicroAcc/F1 is calculated globally by putting together predictions from all facets. Note that due to the highly unbalanced data distribution in the relevance recognition task, we only use F1-related metrics in this task for more credible evaluations."
        },
        {
            "heading": "4.4 Results and Analysis",
            "text": ""
        },
        {
            "heading": "4.4.1 In-topic Setting",
            "text": "Under in-topic setting, we train, validate and test models on the same 14 topics in MITweet. F1 scores of each facet are shown in Table 6. We also provide Acc results of the ideology detection task for each facet in Appendix D.\nFor the relevance recognition task, first, we can observe that BERTweet performs the best on most facets and achieves competitive performance on EP and SD, indicating the effectiveness of this model, which is pretrained on tweets. Second, facets with low results, such as CV, SS, CSR and PoR, are also the facets with the most unbalanced data distributions as provided in Section 3.3. This demonstrates that dealing with the low proportion of positive instances in this task is a huge challenge and needs more research efforts. One exception is the SD facet, which has a similar rated ratio as DS and MF, but much worse performance. By analyzing the prediction results, we find that many SD-related tweets use metaphors and hide the intent behind the literal sense(e.g., the lower example in Figure 1(b)), which is difficult for models to understand.\nFor the ideology detection task, we can observe that: (1) The achieved performances are low across all facets, with no facet exceeding 60%, which is far from practically usable, indicating the inherent challenge of this task. (2) Different from the relevance recognition task, in this task, each model has its own advantageous facets. For example, BERTweet leads other models by a large margin in CSR, especially after using indicators, while BERT and RoBERTa exhibit the best performances in five facets respectively. (3) The performances of eight facets are improved when using indicators as part of input. This is likely due to the fact that indicators come from the words that appear in the dataset and may contain more topic-related in-contextual meanings compared with bare facet names. That is, indicators can establish a deeper interaction with texts and help models mine the ideological bias contained in texts more accurately.\nOverall results for relevance recognition and ideology detection are presented in Table 7 and Table 8 respectively. BERTweet achieves the best overall performance on both sub-tasks, except for Macro-F1 in the ideology detection tasks, which is also competitive with the best result. This is not unexpected, because BERTweet is pre-trained on tweets and is therefore more suitable for modeling the tweet texts in this task, whereas BERT and RoBERTa have domain adaptation problems to some extent. Interestingly, after using indicators, we can see a significant improvement on BERTweet, but not for BERT and RoBERTa. We think this is likely because indicators contain some words with Twitter style (e.g., #inflation, #Black-\nPoR SS EO EE EP CSR CV DS MF SD JO PeR\nRelevance Recognition\nBERT 50.057.21 30.914.61 67.162.43 61.591.45 82.640.98 34.076.55 8.464.08 61.063.52 85.720.67 42.101.48 74.591.68 69.380.85 RoBERTa 44.554.86 31.765.47 69.211.85 61.041.56 81.551.26 39.894.55 18.395.06 62.083.25 85.100.91 44.542.77 75.131.47 69.760.87 BERTweet 46.922.59 32.711.38 71.050.69 63.290.95 82.260.46 35.042.61 19.522.43 62.731.55 85.991.84 44.072.70 75.551.24 70.710.74\nIdeology Detection\nFacet Name BERT 26.936.30 24.163.70 53.283.54 48.511.05 49.901.28 33.0514.41 44.978.70 57.590.53 46.372.32 42.321.43 37.181.12 36.313.09 RoBERTa 28.3811.46 29.618.12 51.842.27 46.968.63 53.662.69 31.658.89 47.5616.09 56.091.81 47.413.30 42.632.16 37.441.71 40.205.67 BERTweet 27.4010.54 28.974.61 54.173.21 47.988.65 51.360.99 36.429.06 46.1513.80 57.231.73 44.031.55 42.884.14 36.511.30 34.063.04\nIndicators BERT 31.799.27 29.934.20 54.424.97 46.585.27 51.442.64 19.967.22 44.749.07 54.623.45 47.112.05 44.082.97 38.831.21 40.045.22 RoBERTa 23.453.46 33.505.30 52.184.25 43.748.28 52.413.31 28.179.37 51.7711.01 56.031.91 46.883.84 45.002.37 35.311.55 39.345.33 BERTweet 24.402.69 27.595.07 52.264.34 41.258.06 52.432.79 49.936.07 43.3711.81 57.002.59 48.396.02 43.922.63 36.552.53 35.042.40\nLivesMatter), which is common during BERTweet pre-training, but may confuse BERT and RoBERTa. Moreover, the Macro- metrics are always significantly lower than the Micro- metrics, indicating that the models are good at making overall predictions across all facets, but not ideal at distinguishing between different facets."
        },
        {
            "heading": "4.4.2 Cross-topic Setting",
            "text": "New topics come up every day, but acquiring large amounts of annotated texts for new topics is timeconsuming and labor-intensive. It is hence necessary to evaluate the models\u2019 generalization ability to transfer knowledge from annotated topics. We next conduct two sets of experimentations with BERTweet under cross-topic setting: (1) Zero-shot.\nA model is first trained and validated on source topics, and then tested on target topics. (2) Few-shot. In addition to texts of source topics, a model can be further trained on a few samples from each target topic, with the parameters of PLM frozen or not. We ensure that the test sets of few-shot and zero-shot are the same, for a fair comparison.\nMost of the topics are domain-specific, and it is likely that there is little or no relevant text on some facets. For example, topic BLM has no relevant texts in EO and CSR, and only one or two relevant texts in PoR, SS, DS and MF, as shown in Appendix C. Therefore, we only use micro-Acc and micro-F1 metrics to focus on facets that are more relevant to a topic.\nZero-shot results are provided in Table 9. We can observe that the Micro-Acc of ideology detection is relatively high and even reaches 80.64% when BLM&Dm are used as target topics, while the Micro-F1 of both sub-tasks are rather low. This indicates that the model tends to predict majority categories and does not have a good understanding of the relevance and ideology features of texts. The main reason is that under cross-topic setting,\nmodels must be able to discover the association between source and target topics to gain better performance. However, without any knowledge about the target topics, models can only rely on connections on text level, so it is hard to correctly identify the relevance and ideology.\nIn Figure 2, we present the results for few-shot experiments. We can see a clear upward trend in performance as the training data increases, and almost all results under the fine-tune setting are better than those under the freeze setting. For the relevance recognition task, the model gains considerable improvements with only 5 training examples. When the number of training examples increases to 40, there is a large gap of about 10 compared with the results in zero-shot. However, for the ideology detection task, the performance improves slightly even in 40-shot, suggesting that, it is still hard for the model to transfer ideological features from source topics with few training examples and maybe there is a need to incorporate knowledge about target topics into the model in future work."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this paper, we have presented a new multifaceted ideology schema covering five domains and twelve facets to provide a more complete and delicate evaluation system for ideology. Based on the schema, we have constructed a high-quality dataset, MITweet, as a benchmark for a new MID task. Experiments show that the MID task is quite challenging, especially under cross-topic setting, which requires the knowledge transfer capability of models. We believe that this work has the potential to positively impact both the research and the applications of ideology detection.\nLimitations\n\u2022 MITweet only covers English tweets, which limits the linguistic features covered by MITweet and the scope of applications built on it. In some facets (e.g., CSR and PoR), the number of relevant texts is relatively small and may not train the model well. Therefore, we will annotate more texts with the schema by combining emerging new topics and extend MITweet to other languages in future work.\n\u2022 Only several base PLM models are chosen in our experiments, and more ideology detection methods are worth of further exploring.\n\u2022 Under cross-topic setting, we just train models with texts from source topics. As the experimental analysis shows, it is worth considering injecting prior knowledge of target topics to improve the generalization ability of models. We leave this work for the future.\nEthics Statement\nThe proposed multifaceted ideology schema is in accordance with the general ethics in social science research to understand people, society and politics. The MITweet dataset is only a peek into the huge amount of Twitter data, and the released dataset has removed all identity related information."
        },
        {
            "heading": "Acknowledgement",
            "text": "This work is supported in part by Major Project of National Social Science Foundation of China: \u201cAI and Precise International Communication\u201d (Grant No. 22&ZD317) and National Natural Science Foundation of China (Grant No. 62172167). We thank all the annotators for their hard work."
        },
        {
            "heading": "A Multifaceted Ideology Schema",
            "text": "The multifaceted ideology schema contains five domains that reflect different aspects of society. Under the five domains, there are twelve facets with ideological attributes of left- and right-leaning, as shown in Table 10. Detailed definitions are as follows.\nA.1 Domain 1: Politics\nPolitical Regime (PoR) The formal and informal structure and nature of political power in a country.\n\u2022 Socialism (Left): the ownership or control of the property should be public-owned.\n\u2022 Capitalism (Right): the ownership of the means of production should private-owned.\nState Structure (SS) The organizational form of the state, i.e., the distribution of power among agencies.\n\u2022 Centralism (Left): the power should be concentrated in the central authority.\n\u2022 Federalism (Right): the power should be distributed between a central authority and the constituents.\nA.2 Domain 2: Economy Economic Orientation (EO) Any of the ways in which humankind has arranged for its material provisioning.\n\u2022 Command Economy (Left): the government should take responsibility for making most of the important economic decisions.\n\u2022 Market Economy (Right): economic decisions should be guided by the interactions of individuals, organization, companies.\nEconomic Equality (EE) The orientation that ought to be adopted in achieving equality through economic policies.\n\u2022 Outcome Equality (Left): all groups should receive the same treatment or distribution.\n\u2022 Opportunity Equality (Right): all groups should have equal access to resources.\nA.3 Domain 3: Culture Ethical Pursuit (EP) The guiding principles and standards that govern the collective existence and conduct of individuals.\n\u2022 Ethical Liberalism (Left): the mainstream culture should support sexual liberation, samesex marriage, abortion, and other related issues.\n\u2022 Ethical Conservatism (Right): the mainstream culture should restrict individuals\u2019 behavior based on moral norms and religious doctrines.\nChurch-State Relations (CSR) The relations between religious ideology and the political consciousness of a nation.\n\u2022 Secularism (Left): the religious power and state power should be separated.\n\u2022 Caesaropapism (Right): the religious power and state power should be unified.\nCultural Value (CV) The cognitive framework shared by the members of society.\n\u2022 Collectivism (Left): an individual should be seen as subordinate to a social collective.\n\u2022 Individualism (Right): all values should be human-centred and the individual should be of supreme importance.\nA.4 Domain 4: Diplomacy Diplomatic Strategy (DS) Fundamental principles and guidelines for a nation\u2019s diplomatic endeavors.\n\u2022 Globalism (Left): foreign policy should be planned with an international perspective.\n\u2022 Isolationism (Right): political and economic entanglements with other countries should be avoided.\nMilitary Force (MF) The disposition of a nation or political faction towards the utilization of military force.\n\u2022 Militarism (Left): it is necessary to use strong armed forces to gain political or economic advantages.\n\u2022 Pacifism (Right): all types of violence between countries are incorrect.\nA.5 Domain 5: Society Social Development (SD) The collective stance of societal members towards the flux of eras.\n\u2022 Revolutionism (Left): it is necessary to take direct and noticeable action to achieve social goals.\n\u2022 Reformism (Right): the social changes should take place in a gradual way.\nJustice Orientation (JO) The orientation that ought to be adopted in achieving justice through social policies.\n\u2022 Result Justice (Left): people should be fairly distributed and treated in various social activities.\n\u2022 Procedural Justice (Right): the authorities should make fair decisions.\nPersonal Right (PeR) The standards by which individual rights are measured in the formulation of social policies.\n\u2022 Social Responsibility (Left): there should be a greater emphasis on fulfilling individual responsibilities.\n\u2022 Individual Right (Right): there should be a greater emphasis on protecting individual rights."
        },
        {
            "heading": "B Calculation Process of Tweet Heat Score",
            "text": "For each tweet, the spread score is calculated by weighting the number of likes L, comments C and retweets R. We also consider the influence\nof the tweet author and calculate the user score by weighting the number of tweets T , followers Fr and followees Fe of the author. Then the final heat score is obtained by weighting the spread score and user score.\nspread = L \u2217 \u03b11 + C \u2217 \u03b12 +R \u2217 \u03b13, user = T \u2217 \u03b21 + Fr \u2217 \u03b22 + Fe \u2217 \u03b23, heat = spread \u2217 \u00b51 + user \u2217 \u00b52.\nDuring data collection, we set \u03b11 = 0.3, \u03b12 = 0.6, \u03b13 = 0.1, \u03b21 = 0.3, \u03b22 = 0.6, \u03b23 = 0.1 and \u00b51 = 0.6, \u00b52 = 0.4. We remove tweets with heat scores below a threshold which is adjusted manually according to the topic heat on Twitter."
        },
        {
            "heading": "C Topic Distribution of MITweet",
            "text": "See Table 11."
        },
        {
            "heading": "D Additional Experimental Results",
            "text": "See Table 12.\nPoR SS EO EE EP CSR CV DS MF SD JO PeR\nFacet Name\nBERT 42.507.29 35.293.22 58.912.11 76.911.54 70.211.32 38.1810.60 59.174.86 60.341.65 65.412.35 67.574.42 88.461.34 87.071.51 RoBERTa 38.7513.35 38.247.21 58.183.15 74.852.49 70.722.40 38.186.80 70.008.08 59.231.96 70.221.29 69.145.13 88.390.87 89.050.63 BERTweet 42.508.29 40.594.33 61.452.48 77.113.48 70.493.54 47.273.64 63.338.90 58.802.22 67.261.76 70.214.77 87.730.94 87.341.19\nIndicators\nBERT 48.757.29 38.823.43 59.823.61 73.813.95 69.052.79 25.458.91 64.176.77 57.523.80 67.341.77 68.574.83 86.314.03 88.620.67 RoBERTa 43.7511.18 42.363.99 59.822.78 77.320.92 72.531.35 40.004.45 64.177.73 59.062.83 69.331.00 72.862.81 87.502.32 87.840.80 BERTweet 43.756.85 35.309.84 60.910.58 77.531.51 71.971.34 58.194.45 63.333.12 59.321.41 68.820.72 74.712.48 88.850.63 87.920.94\nTable 12: Acc scores (%) of the ideology detection sub-task for each facet under in-topic setting."
        }
    ],
    "title": "Ideology Takes Multiple Looks: A High-Quality Dataset for Multifaceted Ideology Detection",
    "year": 2023
}