{
    "abstractText": "Understanding and characterizing the discussions around key events in news streams is important for analyzing political discourse. In this work, we study the problem of identification of such key events and the news articles associated with those events from news streams. We propose a generic framework for news stream clustering that analyzes the temporal trend of news articles to automatically extract the underlying key news events that draw significant media attention. We characterize such key events by generating event summaries, based on which we form document clusters in an unsupervised fashion. We evaluate our simple yet effective framework, and show that it produces more coherent event-focused clusters. To demonstrate the utility of our approach, and facilitate future research along the line, we use our framework to construct KEYEVENTS1, a dataset of 40k articles with 611 key events from 11 topics.",
    "authors": [
        {
            "affiliations": [],
            "name": "Nishanth Nakshatri"
        },
        {
            "affiliations": [],
            "name": "Siyi Liu"
        },
        {
            "affiliations": [],
            "name": "Sihao Chen"
        },
        {
            "affiliations": [],
            "name": "Daniel J. Hopkins"
        },
        {
            "affiliations": [],
            "name": "Dan Roth"
        },
        {
            "affiliations": [],
            "name": "Dan Goldwasser"
        }
    ],
    "id": "SP:3fcd889131ba04c4a70f39e0e52fc6da39cff134",
    "references": [
        {
            "authors": [
                "Adham Beykikhoshk",
                "Ognjen Arandjelovi\u0107",
                "Dinh Phung",
                "Svetha Venkatesh."
            ],
            "title": "Discovering topic structures of a temporally evolving document corpus",
            "venue": "Knowledge and Information Systems, 55:599\u2013 632.",
            "year": 2018
        },
        {
            "authors": [
                "David M Blei",
                "Andrew Y Ng",
                "Michael I Jordan."
            ],
            "title": "Latent dirichlet allocation",
            "venue": "Journal of machine Learning research, 3(Jan):993\u20131022.",
            "year": 2003
        },
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are few-shot learners. Advances in neural information processing",
            "year": 2020
        },
        {
            "authors": [
                "Ricardo JGB Campello",
                "Davoud Moulavi",
                "J\u00f6rg Sander."
            ],
            "title": "Density-based clustering based on hierarchical density estimates",
            "venue": "Advances in Knowledge Discovery and Data Mining: 17th Pacific-Asia Conference, PAKDD 2013, Gold Coast, Australia,",
            "year": 2013
        },
        {
            "authors": [
                "Sihao Chen",
                "William Bruno",
                "Dan Roth."
            ],
            "title": "Towards corpus-scale discovery of selection biases in news coverage: Comparing what sources say about entities as a start",
            "venue": "arXiv preprint arXiv:2304.03414.",
            "year": 2023
        },
        {
            "authors": [
                "Sujan Dutta",
                "Beibei Li",
                "Daniel S Nagin",
                "Ashiqur R KhudaBukhsh."
            ],
            "title": "A murder and protests, the capitol riot, and the chauvin trial: Estimating disparate news media stance",
            "venue": "Proceedings of the Thirty-First International Joint Conference on Artifi-",
            "year": 2022
        },
        {
            "authors": [
                "Anjalie Field",
                "Doron Kliger",
                "Shuly Wintner",
                "Jennifer Pan",
                "Dan Jurafsky",
                "Yulia Tsvetkov."
            ],
            "title": "Framing and agenda-setting in russian news: a computational analysis of intricate political strategies",
            "venue": "Proceedings of the 2018 Conference on Empirical Meth-",
            "year": 2018
        },
        {
            "authors": [
                "Anjalie Field",
                "Yulia Tsvetkov."
            ],
            "title": "Entity-centric contextual affective analysis",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2550\u20132560, Florence, Italy. Association for Computational Linguistics.",
            "year": 2019
        },
        {
            "authors": [
                "Maarten Grootendorst."
            ],
            "title": "Bertopic: Neural topic modeling with a class-based tf-idf procedure",
            "venue": "arXiv preprint arXiv:2203.05794.",
            "year": 2022
        },
        {
            "authors": [
                "Matthew Hoffman",
                "Francis Bach",
                "David Blei."
            ],
            "title": "Online learning for latent dirichlet allocation",
            "venue": "advances in neural information processing systems, 23.",
            "year": 2010
        },
        {
            "authors": [
                "Resnik."
            ],
            "title": "Is automated topic model evaluation broken? the incoherence of coherence",
            "venue": "Advances in Neural Information Processing Systems, 34:2018\u2013 2033.",
            "year": 2021
        },
        {
            "authors": [
                "Yuening Hu",
                "Jordan Boyd-Graber",
                "Brianna Satinoff",
                "Alison Smith."
            ],
            "title": "Interactive topic modeling",
            "venue": "Machine learning, 95:423\u2013469.",
            "year": 2014
        },
        {
            "authors": [
                "Philippe Laban",
                "Marti A Hearst."
            ],
            "title": "newslens: building and visualizing long-ranging news stories",
            "venue": "Proceedings of the Events and Stories in the News Workshop, pages 1\u20139.",
            "year": 2017
        },
        {
            "authors": [
                "Yuanyuan Lei",
                "Ruihong Huang",
                "Lu Wang",
                "Nick Beauchamp."
            ],
            "title": "Sentence-level media bias analysis informed by discourse structures",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 10040\u201310050,",
            "year": 2022
        },
        {
            "authors": [
                "Chang Li",
                "Dan Goldwasser."
            ],
            "title": "Encoding social information with graph convolutional networks forpolitical perspective detection in news media",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2594\u2013",
            "year": 2019
        },
        {
            "authors": [
                "Siyi Liu",
                "Sihao Chen",
                "Xander Uyttendaele",
                "Dan Roth."
            ],
            "title": "MultiOpEd: A corpus of multiperspective news editorials",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Hu-",
            "year": 2021
        },
        {
            "authors": [
                "Siyi Liu",
                "Lei Guo",
                "Kate Mays",
                "Margrit Betke",
                "Derry Tanti Wijaya."
            ],
            "title": "Detecting frames in news headlines and its application to analyzing news framing trends surrounding us gun violence",
            "venue": "Proceedings of the 23rd conference on computational natural",
            "year": 2019
        },
        {
            "authors": [
                "Yiwei Luo",
                "Dallas Card",
                "Dan Jurafsky."
            ],
            "title": "Detecting stance in media on global warming",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 3296\u20133315.",
            "year": 2020
        },
        {
            "authors": [
                "Leland McInnes",
                "John Healy",
                "James Melville."
            ],
            "title": "Umap: Uniform manifold approximation and projection for dimension reduction",
            "venue": "arXiv preprint arXiv:1802.03426.",
            "year": 2018
        },
        {
            "authors": [
                "David Mimno",
                "Hanna Wallach",
                "Edmund Talley",
                "Miriam Leenders",
                "Andrew McCallum."
            ],
            "title": "Optimizing semantic coherence in topic models",
            "venue": "Proceedings of the 2011 conference on empirical methods in natural language processing, pages 262\u2013272.",
            "year": 2011
        },
        {
            "authors": [
                "Sebasti\u00e3o Miranda",
                "Arturs Znotins",
                "Shay B Cohen",
                "Guntis Barzdins."
            ],
            "title": "Multilingual clustering of streaming news",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4535\u20134544.",
            "year": 2018
        },
        {
            "authors": [
                "Davoud Moulavi",
                "Pablo A Jaskowiak",
                "Ricardo JGB Campello",
                "Arthur Zimek",
                "J\u00f6rg Sander."
            ],
            "title": "Density-based clustering validation",
            "venue": "Proceedings of the 2014 SIAM international conference on data mining, pages 839\u2013847. SIAM.",
            "year": 2014
        },
        {
            "authors": [
                "Federico Nanni",
                "Simone Paolo Ponzetto",
                "Laura Dietz."
            ],
            "title": "Building entity-centric event collections",
            "venue": "2017 ACM/IEEE Joint Conference on Digital Libraries (JCDL), pages 1\u201310. IEEE.",
            "year": 2017
        },
        {
            "authors": [
                "Jianmo Ni",
                "Chen Qu",
                "Jing Lu",
                "Zhuyun Dai",
                "Gustavo Hern\u00e1ndez \u00c1brego",
                "Ji Ma",
                "Vincent Y Zhao",
                "Yi Luan",
                "Keith B Hall",
                "Ming-Wei Chang"
            ],
            "title": "Large dual encoders are generalizable retrievers",
            "venue": "arXiv preprint arXiv:2112.07899",
            "year": 2021
        },
        {
            "authors": [
                "Maria Leonor Pacheco",
                "Tunazzina Islam",
                "Monal Mahajan",
                "Andrey Shor",
                "Ming Yin",
                "Lyle Ungar",
                "Dan Goldwasser."
            ],
            "title": "A holistic framework for analyzing the COVID-19 vaccine debate",
            "venue": "Proceedings of the 2022 Conference of the North American Chap-",
            "year": 2022
        },
        {
            "authors": [
                "Maria Leonor Pacheco",
                "Tunazzina Islam",
                "Lyle Ungar",
                "Ming Yin",
                "Dan Goldwasser."
            ],
            "title": "Interactive concept learning for uncovering latent themes in large text collections",
            "venue": "Findings of the Association for Computational Linguistics: ACL 2023, pages 5059\u2013",
            "year": 2023
        },
        {
            "authors": [
                "Girish Palshikar"
            ],
            "title": "Simple algorithms for peak detection in time-series",
            "venue": "Proc. 1st Int. Conf. Advanced Data Analysis, Business Analytics and Intelligence, volume 122.",
            "year": 2009
        },
        {
            "authors": [
                "Hannah Rashkin",
                "Sameer Singh",
                "Yejin Choi."
            ],
            "title": "Connotation frames: A data-driven investigation",
            "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 311\u2013321, Berlin, Germany. As-",
            "year": 2016
        },
        {
            "authors": [
                "Lev Ratinov",
                "Dan Roth",
                "Doug Downey",
                "Mike Anderson."
            ],
            "title": "Local and global algorithms for disambiguation to wikipedia",
            "venue": "Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies, pages",
            "year": 2011
        },
        {
            "authors": [
                "Radim Rehurek",
                "Petr Sojka."
            ],
            "title": "Gensim\u2013python framework for vector space modelling",
            "venue": "NLP Centre, Faculty of Informatics, Masaryk University, Brno, Czech Republic, 3(2):2.",
            "year": 2011
        },
        {
            "authors": [
                "Shamik Roy",
                "Dan Goldwasser."
            ],
            "title": "Weakly supervised learning of nuanced frames for analyzing polarization in news media",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 7698\u20137716.",
            "year": 2020
        },
        {
            "authors": [
                "Shamik Roy",
                "Mar\u00eda Leonor Pacheco",
                "Dan Goldwasser."
            ],
            "title": "Identifying morality frames in political tweets using relational learning",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 9939\u20139958.",
            "year": 2021
        },
        {
            "authors": [
                "Kailash Karthik Saravanakumar",
                "Miguel Ballesteros",
                "Muthu Kumar Chandrasekaran",
                "Kathleen Mckeown."
            ],
            "title": "Event-driven news stream clustering using entity-aware contextual embeddings",
            "venue": "Proceedings of the 16th Conference of the European",
            "year": 2021
        },
        {
            "authors": [
                "Andreas Spitz",
                "Michael Gertz."
            ],
            "title": "Exploring entity-centric networks in entangled news streams",
            "venue": "Companion Proceedings of the The Web Conference 2018, pages 555\u2013563.",
            "year": 2018
        },
        {
            "authors": [
                "Todor Staykovski",
                "Alberto Barr\u00f3n-Cedeno",
                "Giovanni Da San Martino",
                "Preslav Nakov."
            ],
            "title": "Dense vs",
            "venue": "sparse representations for news stream clustering.",
            "year": 2019
        },
        {
            "authors": [
                "Deyu Zhou",
                "Haiyang Xu",
                "Yulan He."
            ],
            "title": "An unsupervised bayesian modelling approach for storyline detection on news articles",
            "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1943\u20131948.",
            "year": 2015
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Analyzing the dynamics of discussions within the stream of news coverage has been an important tool for researchers to visualize and characterize media discourse around a topic (Field et al., 2018; Liu et al., 2019; Li and Goldwasser, 2019; Roy and Goldwasser, 2020; Luo et al., 2020; Liu et al., 2021; Lei et al., 2022; Dutta et al., 2022). News media discourse is typically centered around real-world events that catch media attention and gives rise to news reports streams. With the vast, ever-growing amount of news information available, we need automatic ways for identifying such key events.\nIn this paper, we study the problem of identifying and characterizing key events from a large collection of news articles. Since the number of\n1https://github.com/nnakshat/KeyEvents\nnews events is usually not known in advance, past works have typically formulated the problem as a form of non-parametric clustering of news articles, using Hierarchical Dirichlet Processes (Zhou et al., 2015; Beykikhoshk et al., 2018) or Stream Clustering (Laban and Hearst, 2017; Miranda et al., 2018; Staykovski et al., 2019; Saravanakumar et al., 2021). Rather than relying on the output of such clustering algorithms directly, we view the discovered clusters as event candidates, and leverage recent advances in Large Language Modeling (LLM) (Brown et al., 2020) to characterize these candidates and reason about their validity. From a bird\u2019s eye view, the process is related to past work on interactive clustering (Hu et al., 2014; Pacheco et al., 2022, 2023), but instead of using human feedback to shape the emergent clusters, we rely on LLM inference.\nWe propose a framework for clustering an archive of news articles into temporally motivated news events. A high-level overview of our approach is shown in Figure 1. We first retrieve relevant issue-specific articles (details about the document retrieval module are in App A) and perform temporal analysis to identify \u201cpeaks\u201d, in which the number of articles is significantly higher. We then use HDBSCAN (Campello et al., 2013) a nonparametric clustering algorithm to generate candidate event clusters. We then characterize the candidate clusters by performing few-shot multidocument summarization of the top-K articles assigned to each cluster, identify inconsistent clusters by assessing the (dis)agreement between the summary and each article individually, and redundant clusters by assessing the similarity between cluster pairs\u2019 summaries (details in Sec. 2.1). These lowquality candidates are removed, resulting in higher quality event clusters. We demonstrate this property over the NELA dataset (Horne et al., 2022) and show the improvement both in terms of event coherence and document mapping quality."
        },
        {
            "heading": "2 Event Discovery and Article Inference",
            "text": ""
        },
        {
            "heading": "2.1 Event Discovery",
            "text": "Temporal Filtering. The first step towards generating event candidates is to identify temporal landmarks or peaks, where the media coverage surges with respect to one or more real-world events. We represent the news articles as a time-series data, where T = {t1, t2, \u00b7 \u00b7 \u00b7 , tn} denote time, and C = {ct1 , ct2 , \u00b7 \u00b7 \u00b7 , ctn} denote the number of articles published at each time step. The task is to identify a set of peaks, P = {p1, p2, \u00b7 \u00b7 \u00b7 , pm} at different points in time. With this formulation, we hypothesize that the resulting clusters from our framework would be able to segregate discussions at various time steps and form coherent events compared to other approaches. We use an existing outlier detection algorithm (Palshikar et al., 2009) towards this task. More details in Appendix B.\nPeak-Specific Clustering. Within each peak, the increased media coverage can be attributed to multiple relevant events. We categorize the documents in each peak pi into a set of events, Ei = {e1, e2, \u00b7 \u00b7 \u00b7 , eq}, and form an overall event set, E = {E1, E2, \u00b7 \u00b7 \u00b7 , Em}, pertaining to the issue. We embed the title and first 4 lines of a news article instance using a dense retriever (Ni et al., 2021) model. The embedded documents are clustered using HDBSCAN to identify key news events. Prior to clustering, we reduce the dimensions of document embedding using UMAP (McInnes et al., 2018). Details are in Appendix C.\nEvent Characterization. The event set obtained at each peak (Ei), is still prone to noise and is not easily interpretable without significant effort. Characterizing the news events makes the clusters interpretable and helps remove inconsistencies. The candidate events are characterized by generating\na multi-document summary using GPT-3.5. The prompts are engineered to generate short eventspecific summaries in a two-shot setting. The two closest documents to each centroid are used in the prompt to generate event summaries.\nPost summary generation, we perform a cluster inconsistency check. A cluster is deemed to be incoherent if the top-K closest documents to the centroid do not align with the summary embedding. We embed the event summaries using the same dense retriever model, and compute the cosine similarity score between the summary embedding and the top-K documents for the cluster (k = 5). Based on a threshold value, we treat the incoherent clusters as noise and discard them. Note that we only discard clusters but not documents associated with them. They are still used for cluster membership assignment in the next stage of our framework. Tab. 1\nshows an example of the discarded cluster. We do an additional cleaning step by merging the clusters that share a similar event summary. We devise a simple greedy algorithm which utilizes GPT-3.5 for inference. In the first iteration of the algorithm, we start by constructing a set, S = {(s1, s2), \u00b7 \u00b7 \u00b7 , (sn\u22121, sn)}, that contains every pairwise combination of event summaries. For each element in S, we prompt LLM to infer if the pair of summaries are discussing about the same event. If the event summaries, say (s1, s2), are equivalent, then we merge these summaries, and update the set S by removing every element in the set that contains s1 or s2. In the second iteration, we construct a new set, S \u2032, that holds every combination of updated event summaries, and repeat the previous step. We run the algorithm for two iterations or halt if there are no merges after the first iteration. Tab. 2 shows an example where the event summaries clearly indicate that the clusters need to merged. Details about the hyperparameter selections, and prompts are in Appendix C, B."
        },
        {
            "heading": "2.2 Inference: Map Articles to Events",
            "text": "In this stage of our framework, we decide the cluster membership using a similarity module. We embed the updated event summaries using the same encoder, and compute the cosine similarity score between the summary and the document of interest. By thresholding, we determine if the article can be mapped to an event. For cluster membership, we extend the temporal window by d days before and after the peak (d = 1), and consider all the documents published in that timeframe."
        },
        {
            "heading": "3 Experiments and Results",
            "text": "We conduct experiments on the NELA-dataset, which is a large collection of news articles (see Ap-\npendix A). Using our document retrieval module, we collect a total of 335k relevant news articles on 11 contemporary issues2. The application of temporal filters reduces the article count to 90k, which is the basis for our analysis. The retrieved articles are mapped to a four-way {left, right, center, and conspiracy-pseudoscience} political rating. Details about the dataset, document retrieval module, and four-way political rating can found in Appendix A.\nEvaluation Metrics. We evaluate our framework\u2019s ability to create coherent event clusters at the desired granularity with three automatic metrics inspired by Mimno et al. (2011). Given an event ei and the top-10 relevant entities V ei = {veil }l\u2208[1..10] to ei by TF-IDF, entity purity measures the percentage of the documents that mention at least one of the top-10 entities; coverage counts the percentage of documents accounted for in the cluster assignments. In addition, entity coherence considers cooccurrences of central entity pairs in the clustered documents to measure coherency for an event.\nC(ei, V ei) = M\u2211 m=2 m\u22121\u2211 l=1 log F (veim, v ei l ) + \u03f5 F (veil )\nwhere F (veim, v ei l ) indicates the co-occurrence frequency of two entities in documents. An entity coherence value closer to zero indicates a highly coherent news event cluster. We offer a more detailed explanation of the metrics in Appendix D.\nBaselines. We compare our method\u2019s performance against various competitive topic model as baselines. We consider LDA (Blei et al., 2003; Hoffman et al., 2010) in two different settings - LDA, and LDA (Temporal). The topics are estimated individually at each temporal peak for LDA (Temporal), whereas the topics are estimated across\n2https://www.allsides.com/topics-issues\nall peaks at once for LDA. We include three additional baselines - Temporal Filtering, HDBSCAN, and BERTopic (Grootendorst, 2022). Note that BERTopic3 is an off-the-shelf neural baseline for clustering documents. For methods other than ours, we do not incorporate a cluster membership module as we directly estimate the topics for all the documents in an extended temporal window of d days before and after the peak (d = 1). Preprocessing and hyperparameter details are in Appendix C.\nResults. Tab. 3 shows the aggregated results obtained for various methods across all the issues. For LDA (baseline), the events are estimated over a union of all the documents from every peak for an issue. We study the impact of event estimation with the temporal component by comparing LDA (baseline) and Temporal Filtering methods. We observe only a slight drop in average purity (\u22123 points) for the Temporal Filtering method. Further, Tab. 8 shows that in case of Free Speech, Abortion, Immigration issues, the purity scores are higher than LDA (baseline), which validates our hypothesis that adding a temporal dimension to event identification can help form coherent events."
        },
        {
            "heading": "4 Analysis and Discussion",
            "text": ""
        },
        {
            "heading": "4.1 Coverage vs Purity Trade off",
            "text": "We evaluate the trade-off between coverage and entity purity among the methods that take event temporality into account. We observe that LDA (Temporal) has a very high coverage with the least purity, which can be attributed to noise associated with the topic distributions. BERTopic improves over this method in both coverage, and purity measures across 11 issues. It even outperforms HDBSCAN in both the metrics. However, while BERTopic has increased coverage, it still fails to outperform our\n3https://maartengr.github.io/BERTopic\nmethod in terms of purity, and this can be primarily attributed to our inference mechanism that is based on generated event summaries.\nTo address low coverage issue from our method, we propose to run our framework for the second iteration by updating event summary embedding with the mean value of top-10 most representative document embeddings in the cluster (from the first iteration). In doing so, average coverage increased by +12.5 points across all issues, with minimal decrease of < 5 points in purity. Tab. 6 shows the results for each issue after the second iteration."
        },
        {
            "heading": "4.2 Impact of Merge/Remove Operations",
            "text": "We investigate the impact of removing cluster inconsistencies over the generated candidate events. For this analysis, we compare HDBSCAN with the same hyperparameters and input data as our method. We observe that average of the inter-event cosine similarity score between event-pairs, and across all issues is lesser by 0.14 for our method. This indicates that our method achieves improved cluster separability after eliminating inconsistencies. Tab. 5 shows the report for each issue. Overall, the score is reduced, with one exception for the issue of Corruption. Manual inspection suggest that the increase can be due to removal of \"good\" clusters. An example is shown in Fig. 7."
        },
        {
            "heading": "4.3 KEYEVENTS \u21d2 More Event Coherence",
            "text": "To better understand the advantages and disadvantages of our method, the authors manually annotate a small set of data samples for Climate Change. We test for event coherence, and mapping quality over this dataset. We define an event to be coherent if the top-K most representative documents of that event are in agreement with each other (k = 3). We also annotate to verify the validity of documentto-event assignments (mapping quality), where we check for agreement between the document and its\nrespective event summary. The details about the experimental setup can be found in Appendix E.\nThe test is conducted across all events for our method, HDBSCAN, and BERTopic. To measure coherence, we first identify the top-K documents for an event based on their cosine similarity scores with the event centroid. In addition, we estimate mapping quality by judging if document pairs should be clustered together or not.\nResults. The results of the human evaluation are shown in Tab. 4. Our method failed to generate coherent events for 5 out of the 56 cases for Climate Change, while BERTopic failed in 9 out of 62 cases (ignoring 3 cases where the annotator provided a label of \u22121). HDBSCAN failed in 8 out of 53 cases. Overall, the event coherence scores from BERTopic and HDBSCAN closely trail our method by a margin of approximately \u22126 points, implying that the generated events from these methods are coherent. However, considering the event purity scores, we conclude that these two methods are more noisy. In terms of mapping quality, our method outperforms HDBSCAN by a large margin. The precision score from BERTopic is better than HDBSCAN, indicating the effectiveness of BERTopic in grouping \u2019good\u2019 item pairs together over a small sample of randomly selected datapoints for the issue - Climate Change. More details in Appendix E."
        },
        {
            "heading": "4.4 LLM Usage and Efficiency",
            "text": "As temporal filtering results in an average of 55 event clusters per issue, we observe that using LLM for event summarization and cluster-merging incurs reasonable cost, as we discuss in Limitations."
        },
        {
            "heading": "5 Broader Impact",
            "text": "Our method and the resulting KEYEVENTS dataset could be useful for analyzing political discourse across different ideologies. As a simple case study, we illustrate how the portrayal of events varies for different political ideologies. We take an entitybased approach (Rashkin et al., 2016; Field and\nTsvetkov, 2019; Roy et al., 2021) and analyze mentions of Joe Manchin, a democratic senator and the chair of Senate Energy Committee, in Climate Change articles. Fig. 2 shows that left-leaning articles mention him significantly more than the other two ideologies in some of the events (e.g. the 5th, 9th, and 14th). Analyzing these events\u2019 articles show that left leaning articles criticize his ties to the coal industry and opposition to climate change legislation, while fewer (or no) mentions in articles with other ideology leanings under the same events.\nDifferent ideologies also persist different sentiments when mentioning the same entity. In Biden\u2019s Executive Actions on Climate Change (16th event in Fig. 2), articles from different ideologies have comparable mention frequencies of Joe Manchin. We prompt GPT-3.5 to classify the sentiment expressed towards him (positive, neutral, negative). Interestingly, none of the articles from any ideology expresses a positive sentiment; 86% of the articles from the left endure a negative attitude towards him, whereas only 38% and 0% of the articles from the center and the right have negative sentiments. This distinction shows that even the same entities could be portrayed differently within each event to strengthen the beliefs along their political lines."
        },
        {
            "heading": "6 Conclusion",
            "text": "We present a framework for key events identification and showed that events generated from our approach were coherent through quantitative measures, and human evaluation. We also presented a simple qualitative study to showcase the potential of KEY EVENTS, for investigating various political perspectives under nuanced settings.\nLimitations\nAs the temporal filtering step of our framework relies on the publicaiton date of documents as input, we work with the assumption that the documents have a timestamp attached to them. However, the main idea of event characterization using LLM, and associating the documents to their closest event summary is applicable to other cases with no changes.\nOur approach relies on GPT-3.5 for generating a multi-document event summary and clustermerging. We choose to use GPT-3.5 instead of the open-source counterparts mostly due to computational resource constraints. Since all GPT calls are made on the cluster-level, we are able to maintain the total experimental cost of the paper under $5 with respect to the OpenAI API. To minimize the reliance and cost associated with LLM usage, we are using only pairs of documents with most similar vector representation to generate event summary. We opt for more an efficient approach here, and leave the exploration of efficiency vs. performance trade-off for future work."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank the anonymous reviewers of this paper for all of their vital feedback. The project was partially funded by NSF award IIS-2135573, and in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via 2022-22072200003. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.\nEthics Statement\nTo the best of our knowledge, we did not violate any ethical code while conducting the research work described in this paper. We report the technical details needed for reproducing the results and will release the code and data collected. We make it clear that the KEY EVENTS dataset is the result of an automated algorithm not human annotation (though human evaluation was used in assessing its performance over a subset of the data)."
        },
        {
            "heading": "A Document Retrieval Module",
            "text": "This module retrieves news articles relevant to an issue of interest. User is expected to provide an issue name or a set of issue names around which the documents are to be retrieved. Using this input, we generate a set of relevant keywords associated with each issue by prompting GPT-3.5. We craft the prompt in such a way that GPT-3.5 generates a list of keywords that appear in the context of the issue specified by the user. We then use BM25 algorithm on the indexed NELA data to retrieve documents associated with each keyword for the issue. We use BM25 with the default settings for b, and only vary the term frequency saturation k1 = 1.3 as we are dealing with longer news documents.\nNELA Dataset It is a collection of \u2248 1.8M news documents from 367 news outlets between January 1st 2021, and December 31st, 2021. NELA is successful in organizing the news articles based on their ideological bias. However, this structure is not well-suited to characterize the differences in discourse between the political ideologies in online news media.\nIn this work, we primarily focus on 207 news sources that are based out of USA. The political rating corresponding to these sources are mapped\nto a four-way {left, right, center, conspiracypseudoscience}. The ratings are decided based on MBFC 4. Using the scores provided by MBFC, we categorize left-center and right-center political ratings to one of the {center, left, right} ratings."
        },
        {
            "heading": "B Event Candidate Generation",
            "text": "Temporal Filtering We implement an outlier detection algorithm (Palshikar et al., 2009) which considers a temporal window of 2k points around each data point, x. These are k points before x, and k points after x. Using these 2k data points, we compute the mean and standard deviation. The data point is considered as a local peak if it is at least a standard deviation away from the mean value. Among the detected local peaks, we further apply a filter to retrieve global peaks. We do this by computing the mean and standard deviation values for the detected local peaks. If the value at the local peak is above the mean value, we mark that as a global peak. In the case of multiple peaks within a temporal window of k days, we merge them to form a single peak. We set the value of k = 3 for our experiments. Figure 3 shows the result of this algorithm for the issue - Abortion."
        },
        {
            "heading": "C Models and Hyperparameters",
            "text": "To obtain topics from LDA with Variational Bayes sampling (under both settings), we use Gensim (Rehurek and Sojka, 2011) implementation. We follow the preprocessing steps shown in (Hoyle et al., 2021), and estimate the number of topics in a datadriven manner by maximizing . We do a gridsearch over a set of {2, 3, 4, 5} for LDA (Temporal) method. The set of topics for LDA (baseline) is {10, 20, \u00b7 \u00b7 \u00b7 , 60}.\n4https://mediabiasfactcheck.com/\nIn the case of HDBSCAN, when used for our method, and as a standalone clustering model, we use a data-driven approach to estimate the best number of topics by maximizing the DBCV score (Moulavi et al., 2014). We retain the default settings for cluster_selection_method, and metric parameters, while we change the min_cluster_size to get more sensible topics. This number is selected based on a grid search whose values are sensitive to the number of input data points. Suppose |X| denote the number of data points, then the grid parameters for HDBSCAN used in our method include {0.05\u00d7|X|, 0.06\u00d7|X|, \u00b7 \u00b7 \u00b7 0.1\u00d7|X|}. This is updated to consider only the last three elements for HDBSCAN (standalone). If not, we see unusually high number of topics per peak. We set the n_neighbors parameter in UMAP embedding model to min_cluster_size.\nFor cluster incoherency check, we choose a threshold of 0.6. If the cosine similarity score between the event summary embedding and the document embedding is lower than this threshold, we discard those documents as noise.\nFor our method\u2019s similarity module, we choose a threshold of 0.69 based on evaluating the trade-off between purity, coherence and coverage values.\nPrior to computing the TF-IDF scores to retrieve the top-K entities, we use a simple yet effective method for entity linking (Ratinov et al., 2011) that is based on Wikipedia mentions."
        },
        {
            "heading": "D Evaluation Metrics",
            "text": "In this section, we describe the evaluation metrics proposed in our work.\nSeveral studies (Nanni et al., 2017; Spitz and Gertz, 2018; Chen et al., 2023) in the past have shown that entities and the context associated with them can potentially represent a topic or an event. With this as the premise, we have devised entitybased evaluation metrics that helps us quantify the quality of the resulting clusters. We further validate our results through a simple human evaluation process on partially annotated data for the issue - Climate Change.\nWe define entity purity for an event to be the proportion of the documents that are mapped to that event, where the document has at least one entity that overlaps with the top-K TF-IDF based entities for that event (k = 10). The idea is that central entities associated with a news event must be reflected in the documents clustered for that\nevent. Note that in order to remove commonly repeated entities in news such as Biden, Trump etc., we consider top-K TF-IDF based entities for an event as central entities. A purity score of 100% for an event indicates that every document in the cluster has atleast a mention of one of the top-K central entities, suggesting that each document is potentially discussing about that event.\nWe also define entity coherence metric as an additional measure to validate the cluster quality. We adapt the topic coherence metric from (Mimno et al., 2011) to define entity coherence C, for an event, ei as\nC(ei, V ei) = M\u2211 m=2 m\u22121\u2211 l=1 log F (veim, v ei l ) + \u03f5 F (veil )\nwhere, ei denotes an event, V ei = {vei1 , v ei 1 , \u00b7 \u00b7 \u00b7 , v ei 10} denotes the top-10 TFIDF based entities for ei, F (veim, v ei l ) indicates the co-document frequency (counts the joint document frequency for entity types vm, vl), F (vl) indicates document frequency for entity type vl, and \u03f5 is a smoothing factor. Informally, it considers co-occurrences of central entity pairs (as opposed to topic words) in the clustered documents to measure coherency for an event. Note that a higher value indicates a highly coherent news event. By virtue of using log in formula, a value closer to zero is more desirable than a largely negative value. We further observe that this measure is positively correlated with entity purity, indicating that purity can be a good measure to represent cluster coherence.\nIn addition to these, we have an additional metric coverage, which essentially counts the number of documents accounted for in the clustering process. Ideally, we want any clustering algorithm to reject noise and cluster every document in the corpus. We do not want to exclude any document. Post noise removal, a good clustering algorithm is expected to have a coverage of 100% in an ideal scenario."
        },
        {
            "heading": "E Human Evaluation",
            "text": "For the event coherence case, the annotators are asked to verify if the top-3 documents for the event are in agreement with each other. They are asked to provide a score of 1 if the documents are in agreement, a score 0 if they are not, or a score of \u22121 if they are not sure about the label. We show only the title and first four lines of the news article. We did not receive any \u22121 for this case.\nTo evaluate the mapping quality of our model, we randomly sample a set of peaks, and within each peak, we randomly sample 50 documents to form an overall set of 430 documents mapped to various events for the issue Climate Change. We show the title and first four lines of news article, and the event summary to the annotators. Similar to coherence case, we ask the annotators to provide a score of 1 if the document aligns with the summary, 0 for no alignment, or \u22121 if they are not sure. There is no clear definition of alignment, and we let the annotators make this judgement. We received a total of 6 not sure labels. On eliminating unsure instances, our method got 352 out of 424 instances correct, which translates to a precision value of \u2248 0.83.\nHowever, in order to compare the performance of our method with other model, we devise a strategy to derive \u2019good\u2019 and \u2019bad\u2019 example-pairs by treating human-labeled data as the gold standard. We assume that if the two documents receive a score of 1 within the same event, then they must be \u2019equivalent\u2019.\nWith this assumption, for a given temporal peak and within every event, we construct \u2019good/positive\u2019 example set by considering every possible document-pairs from valid cluster assignments. To construct \u2019bad/negative\u2019 example set, we consider a union of the following - (a) Documentpairs from valid cluster assignments between different events; (b) Document-pairs from an invalid, and a valid cluster assignment within each event.\nThe task is to evaluate how well each method performs in retaining the good example-pairs within the same cluster. We ensure to remove all the documents that are not mapped to any event by each method. Owing to the nature of data collection, we report only the precision values for all the three methods under consideration."
        },
        {
            "heading": "F Results",
            "text": ""
        },
        {
            "heading": "G Prompt Templates",
            "text": "This section shows the prompt templates used to generate multi-document summary (Fig. 9), and to verify if a pair of cluster characterization is equivalent (Fig. 10).\nIssue Model Avg. Inter-EventCosine Similarity # Events # Merge Operations # Remove Operations\nCapitol Insurrection HDBSCAN 0.864877655 64 - -\nOur Method 0.641329667 40 21 3\nCoronavirus HDBSCAN 0.860832152 122 - -\nOur Method 0.857558543 112 10 2\nClimate Change HDBSCAN 0.833522985 74 - -\nOur Method 0.772742185 56 11 7\nFree Speech HDBSCAN 0.847346069 72 - -\nOur Method 0.668949583 56 7 13\nAbortion HDBSCAN 0.877382542 48 - -\nOur Method 0.410449078 24 20 4\nImmigration HDBSCAN 0.852341823 64 - -\nOur Method 0.75051009 48 15 1\nGun Control HDBSCAN 0.829052923 60 - -\nOur Method 0.663993032 40 9 9\nCriminal Injustice & Law Enforcement HDBSCAN 0.824876478 70 - -\nSummary Document\nNews Event Title: Election Fraud Claims in the US. News Event Description: This is about the claims of election fraud in the US and the upcoming congressional meeting to certify the Electoral College votes.\nVice President Pence supports Congress members who will object to Biden\u2019s designation Jan. 6.\nVice President Mike Pence welcomed the decision by a group of senators, led by Sen. Ted Cruz ( R-Texas ), to challenge the scheduled nomination of Democratic presidential candidate Joe Biden as the winner of the election held on Nov. 3. The vice president welcomes the efforts of members of the House and Senate to use the authority they have under the law to raise objections and bring forward evidence before the Congress and the American people, Pence\u2019s chief of staff Marc Short said, according to Axios on Jan. 3.@ @ @ @ @ @ @ of millions of Americans about voter fraud and irregularities.\nTable 7: Illustrates an example where the cluster was removed due to the document being present in the top-5 list for this event. We see that the document is talking about the same issue from a different frame and merely, using a similarity module to identify cluster incoherency is not sufficient in this case."
        }
    ],
    "title": "Using LLM for Improving Key Event Discovery: Temporal-Guided News Stream Clustering with Event Summaries",
    "year": 2023
}