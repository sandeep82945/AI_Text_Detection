{
    "abstractText": "Propaganda is a form of deceptive narratives that instigate or mislead the public, usually with a political purpose. In this paper, we aim to identify propaganda in political news at two fine-grained levels: sentence-level and tokenlevel. We observe that propaganda content is more likely to be embedded in sentences that attribute causality or assert contrast to nearby sentences, as well as seen in opinionated evaluation, speculation and discussions of future expectation. Hence, we propose to incorporate both local and global discourse structures for propaganda discovery and construct two teacher models for identifying PDTB-style discourse relations between nearby sentences and common discourse roles of sentences in a news article respectively. We further devise two methods to incorporate the two types of discourse structures for propaganda identification by either using teacher predicted probabilities as additional features or soliciting guidance in a knowledge distillation framework. Experiments on the benchmark dataset demonstrate that leveraging guidance from discourse structures can significantly improve both precision and recall of propaganda content identification.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Yuanyuan Lei"
        },
        {
            "affiliations": [],
            "name": "Ruihong Huang"
        }
    ],
    "id": "SP:9e9b9b64c6003fa946c206821ea0037b5e1b5016",
    "references": [
        {
            "authors": [
                "Tariq Alhindi",
                "Tuhin Chakrabarty",
                "Elena Musi",
                "Smaranda Muresan."
            ],
            "title": "Multitask instructionbased prompting for fallacy recognition",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 8172\u20138187,",
            "year": 2022
        },
        {
            "authors": [
                "Ramy Baly",
                "Giovanni Da San Martino",
                "James Glass",
                "Preslav Nakov."
            ],
            "title": "We can detect your bias: Predicting the political ideology of news articles",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
            "year": 2020
        },
        {
            "authors": [
                "Alberto Barron-Cedeno",
                "Giovanni Da San Martino",
                "Israa Jaradat",
                "Preslav Nakov."
            ],
            "title": "Proppy: A system to unmask propaganda in online news",
            "venue": "Proceedings of the 33rd AAAI Conference on Artificial Intelligence, pages 9847\u20139848, Honolulu, HI,",
            "year": 2019
        },
        {
            "authors": [
                "Iz Beltagy",
                "Matthew E. Peters",
                "Arman Cohan"
            ],
            "title": "Longformer: The long-document transformer",
            "year": 2020
        },
        {
            "authors": [
                "Edward L Bernays."
            ],
            "title": "Propaganda",
            "venue": "Ig publishing.",
            "year": 2005
        },
        {
            "authors": [
                "Bonnie Brennen."
            ],
            "title": "Making sense of lies, deceptive propaganda, and fake news",
            "venue": "Journal of Media Ethics, 32(3):179\u2013181.",
            "year": 2017
        },
        {
            "authors": [
                "Wei-Fan Chen",
                "Khalid Al Khatib",
                "Henning Wachsmuth",
                "Benno Stein."
            ],
            "title": "Analyzing political bias and unfairness in news articles at different levels of granularity",
            "venue": "Proceedings of the Fourth Workshop on Natural Language Processing and Computational",
            "year": 2020
        },
        {
            "authors": [
                "Prafulla Kumar Choubey",
                "Ruihong Huang."
            ],
            "title": "Profiling news discourse structure using explicit subtopic structures guided critics",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, pages 1594\u20131605, Punta Cana, Dominican Re-",
            "year": 2021
        },
        {
            "authors": [
                "Prafulla Kumar Choubey",
                "Aaron Lee",
                "Ruihong Huang",
                "Lu Wang."
            ],
            "title": "Discourse as a function of event: Profiling discourse structure in news articles around the main event",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Lin-",
            "year": 2020
        },
        {
            "authors": [
                "Giovanni Da San Martino",
                "Alberto Barr\u00f3n-Cede\u00f1o",
                "Preslav Nakov."
            ],
            "title": "Findings of the NLP4IF-2019 shared task on fine-grained propaganda detection",
            "venue": "In",
            "year": 2019
        },
        {
            "authors": [
                "sity",
                "Oxford",
                "UK. Edgar H Henderson"
            ],
            "title": "Toward a definition of propa",
            "year": 1943
        },
        {
            "authors": [
                "Geoffrey Hinton",
                "Oriol Vinyals",
                "Jeff Dean"
            ],
            "title": "Distilling the knowledge in a neural network",
            "year": 2015
        },
        {
            "authors": [
                "Benjamin D. Horne",
                "William Dron",
                "Sara Khedr",
                "Sibel Adali."
            ],
            "title": "Sampling the news producers: A large news and feature data set for the study of the complex media landscape",
            "venue": "Proceedings of the International AAAI Conference on Web and Social",
            "year": 2018
        },
        {
            "authors": [
                "Zhijing Jin",
                "Abhinav Lalwani",
                "Tejas Vaidhya",
                "Xiaoyu Shen",
                "Yiwen Ding",
                "Zhiheng Lyu",
                "Mrinmaya Sachan",
                "Rada Mihalcea",
                "Bernhard Schoelkopf."
            ],
            "title": "Logical fallacy detection",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022,",
            "year": 2022
        },
        {
            "authors": [
                "Johannes Kiesel",
                "Maria Mestre",
                "Rishabh Shukla",
                "Emmanuel Vincent",
                "Payam Adineh",
                "David Corney",
                "Benno Stein",
                "Martin Potthast."
            ],
            "title": "Semeval2019 task 4: Hyperpartisan news detection",
            "venue": "Proceedings of the 13th International Workshop on Se-",
            "year": 2019
        },
        {
            "authors": [
                "Harold D Lasswell."
            ],
            "title": "The theory of political propaganda",
            "venue": "American Political Science Review, 21(3):627\u2013631.",
            "year": 1927
        },
        {
            "authors": [
                "Yuanyuan Lei",
                "Ruihong Huang."
            ],
            "title": "Few-shot (dis)agreement identification in online discussions with regularized and augmented meta-learning",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022, pages 5581\u20135593, Abu",
            "year": 2022
        },
        {
            "authors": [
                "Yuanyuan Lei",
                "Ruihong Huang",
                "Lu Wang",
                "Nick Beauchamp."
            ],
            "title": "Sentence-level media bias analysis informed by discourse structures",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 10040\u201310050,",
            "year": 2022
        },
        {
            "authors": [
                "Quanzhi Li",
                "Qiong Zhang",
                "Luo Si",
                "Yingchi Liu."
            ],
            "title": "Rumor detection on social media: Datasets, methods and opportunities",
            "venue": "Proceedings of the Second Workshop on Natural Language Processing for Internet Freedom: Censorship, Disinformation,",
            "year": 2019
        },
        {
            "authors": [
                "Andrew T Little."
            ],
            "title": "Propaganda and credulity",
            "venue": "Games and Economic Behavior, 102:224\u2013232.",
            "year": 2017
        },
        {
            "authors": [
                "Yujian Liu",
                "Xinliang Frederick Zhang",
                "David Wegsman",
                "Nicholas Beauchamp",
                "Lu Wang."
            ],
            "title": "POLITICS: Pretraining with same-story article comparison for ideology prediction and stance detection",
            "venue": "Findings of the Association for Computational Linguis-",
            "year": 2022
        },
        {
            "authors": [
                "Ilya Loshchilov",
                "Frank Hutter"
            ],
            "title": "Decoupled weight decay regularization",
            "year": 2019
        },
        {
            "authors": [
                "David Miller",
                "Piers Robinson."
            ],
            "title": "Propaganda, politics and deception",
            "venue": "The Palgrave handbook of deceptive communication, pages 969\u2013988.",
            "year": 2019
        },
        {
            "authors": [
                "Ray Oshikawa",
                "Jing Qian",
                "William Yang Wang."
            ],
            "title": "A survey on natural language processing for fake news detection",
            "venue": "Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 6086\u20136093, Marseille, France. European Lan-",
            "year": 2020
        },
        {
            "authors": [
                "Wonpyo Park",
                "Dongju Kim",
                "Yan Lu",
                "Minsu Cho"
            ],
            "title": "Relational knowledge distillation",
            "year": 2019
        },
        {
            "authors": [
                "Ver\u00f3nica P\u00e9rez-Rosas",
                "Bennett Kleinberg",
                "Alexandra Lefevre",
                "Rada Mihalcea."
            ],
            "title": "Automatic detection of fake news",
            "venue": "Proceedings of the 27th International Conference on Computational Linguistics, pages 3391\u20133401, Santa Fe, New Mexico, USA.",
            "year": 2018
        },
        {
            "authors": [
                "Matthew E. Peters",
                "Mark Neumann",
                "Mohit Iyyer",
                "Matt Gardner",
                "Christopher Clark",
                "Kenton Lee",
                "Luke Zettlemoyer."
            ],
            "title": "Deep contextualized word representations",
            "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for",
            "year": 2018
        },
        {
            "authors": [
                "Rashmi Prasad",
                "Nikhil Dinesh",
                "Alan Lee",
                "Eleni Miltsakaki",
                "Livio Robaldo",
                "Aravind Joshi",
                "Bonnie Webber"
            ],
            "title": "The Penn Discourse TreeBank 2.0",
            "venue": "In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC\u201908),",
            "year": 2008
        },
        {
            "authors": [
                "Hannah Rashkin",
                "Eunsol Choi",
                "Jin Yea Jang",
                "Svitlana Volkova",
                "Yejin Choi."
            ],
            "title": "Truth of varying shades: Analyzing language in fake news and political fact-checking",
            "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Lan-",
            "year": 2017
        },
        {
            "authors": [
                "Victoria Rubin",
                "Niall Conroy",
                "Yimin Chen",
                "Sarah Cornwell."
            ],
            "title": "Fake news or truth? using satirical cues to detect potentially misleading news",
            "venue": "Proceedings of the Second Workshop on Computational Approaches to Deception Detection, pages 7\u201317, San",
            "year": 2016
        },
        {
            "authors": [
                "Jason Stanley."
            ],
            "title": "How propaganda works",
            "venue": "How propaganda works. Princeton University Press.",
            "year": 2015
        },
        {
            "authors": [
                "Cristina Tardaguila",
                "Fabricio Benevenuto",
                "Pablo Ortellado."
            ],
            "title": "Fake news is poisoning brazilian politics",
            "venue": "whatsapp can stop it. The New York Times.",
            "year": 2018
        },
        {
            "authors": [
                "Esther van den Berg",
                "Katja Markert."
            ],
            "title": "Context in informational bias detection",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 6315\u20136326.",
            "year": 2020
        },
        {
            "authors": [
                "Prashanth Vijayaraghavan",
                "Soroush Vosoughi."
            ],
            "title": "TWEETSPIN: Fine-grained propaganda detection in social media using multi-view representations",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computa-",
            "year": 2022
        },
        {
            "authors": [
                "George-Alexandru Vlad",
                "Mircea-Adrian Tanase",
                "Cristian Onose",
                "Dumitru-Clementin Cercel."
            ],
            "title": "Sentence-level propaganda detection in news articles with transfer learning and BERT-BiLSTM-capsule model",
            "venue": "Proceedings of the Second Workshop on",
            "year": 2019
        },
        {
            "authors": [
                "Lingwei Wei",
                "Dou Hu",
                "Wei Zhou",
                "Zhaojuan Yue",
                "Songlin Hu."
            ],
            "title": "Towards propagation uncertainty: Edge-enhanced Bayesian graph convolutional networks for rumor detection",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Compu-",
            "year": 2021
        },
        {
            "authors": [
                "Ronald J Williams."
            ],
            "title": "Simple statistical gradientfollowing algorithms for connectionist reinforcement learning",
            "venue": "Machine learning, 8:229\u2013256.",
            "year": 1992
        },
        {
            "authors": [
                "Seunghak Yu",
                "Giovanni Da San Martino",
                "Mitra Mohtarami",
                "James Glass",
                "Preslav Nakov."
            ],
            "title": "Interpretable propaganda detection in news articles",
            "venue": "Proceedings of the International Conference on Recent Advances in Natural Language Processing",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Propaganda refers to a type of misleading and deceptive information used to promote or publicize a certain political point of view (Lasswell, 1927; Henderson, 1943; Stanley, 2015; Rashkin et al., 2017). This information is often manipulated in a strategic way to shape societal beliefs (Rashkin et al., 2017; Barron-Cedeno et al., 2019). Propaganda can be harmful to both individuals and society as a whole, such as disseminating false information, inciting people\u2019s perceptions, leading to conflicts, perpetuating prejudices, impeding democracy process etc. (Bernays, 2005; Stanley, 2015; Little,\n1The code and data link: https://github.com/yuanyuanleinlp/propaganda_emnlp_2023\n2017). Despite its misleading nature and harmful effects, propaganda can be pervasive in political news, and has the potential to reach very large audiences (Glowacki et al., 2018; Tardaguila et al., 2018). Hence, developing intelligent models to identify propaganda in political news is important and necessary.\nInstead of detecting propaganda at the level of articles (Horne et al., 2018; De Sarkar et al., 2018; Rashkin et al., 2017; Rubin et al., 2016), this paper focuses on identifying propaganda at fine-grained levels: sentence-level and token-level. Through extracting the sentence or fragment imbued with propaganda, our aim is to accurately locate the propagandistic content and thereby provide detailed interpretable explanations. Propaganda content not only presents unverified or even false information, but also employs a variety of argumentation strategies to convince the readers (Yu et al., 2021). Therefore, identifying propaganda at fine-grained levels still remains a difficult and challenging task, and requires profound understanding of broader context in an article (Da San Martino et al., 2019b).\nFirst, we observe that propaganda can be injected into sentences that attribute causality or assert contrast to nearby sentences. Take the article in Figure 1 as an example, the second sentence (S2) makes an illogical and misleading deduction from its preceding sentence: This suggested giving advice on how to prevent Jihadist attacks is now against community standards. Propaganda content such as S2 usually disseminate the misinformation by leveraging causal relations, either by inferring baseless reasons or deducting speculative consequences. In addition, propaganda content can also utilize contrast relation to raise doubt or challenge credibility. For example, the last sentence (S4) casts doubts towards its previous sentence: why would Facebook remove such a page and never explain why? Through the strategy of contrasting, the author aims to undermine the credibility of Facebook and\nthereby incite public protest. Accordingly, we propose that understanding the discourse relations of a sentence with its nearby sentences in the local context can enable discovery of propaganda contents.\nMoreover, we observe that propaganda content or deceptive narratives is more likely to be embedded into opinionated evaluations or expectation speculations. In contrast, sentences describing factual occurrences are less likely to carry propaganda. Take the article in Figure 2 as an example, the first three sentences, either reporting the main event or describing the current context triggered by the main event, all provide the readers with factual occurrences devoid of deceptive content. However, in the succeeding sentence (S4), the author includes a quotation to express emotional assessments: this reckless decision was based on her political agenda. Propaganda sentences such as S4 always convince the readers and influence their mindset by inserting opinionated evaluations. Furthermore, the author speculates future expectations in the next sentence (S5) that ICE officers will continue to protect public safety. Propaganda sentences such as S5 usually promise a bright yet unprovable future with the aim of gaining trust and support. Therefore, we propose that understanding the discourse role of a sentence in telling a news story can help reveal propaganda. Motivated by the above observations, we propose to incorporate both local and global discourse structures for propaganda identification. Specifically, we establish two teacher models to recognize PDTB-style discourse relations between a sentence and its nearby sentences (Prasad et al., 2008), as well as identify one of eight common news discourse roles for each sentence based upon news discourse structure (Choubey et al., 2020). We further devise two approaches to effectively incorporate the two types of discourse structures for propaganda identification. The first approach concatenates the predicted probabilities from two teacher models as additional features. The second approach develops a more sophisticated knowledge distillation framework, where we design a response-based distillation loss to mimic the prediction behavior of teacher models, as well as a feature relation-based distillation loss to seek guidance from the embeddings generated by teacher models. The responsebased and feature relation-based distillation mutually complement each other, acquiring an enhanced guidance from discourse structures. Experiments on the benchmark dataset demonstrate the effectiveness of our approaches for leveraging discourse structures, with both precision and recall improved. The ablation study validates the necessity and syn-\nergy between local and global discourse structures."
        },
        {
            "heading": "2 Discourse Structures",
            "text": "In this section, we explain the details for the two discourse structures: discourse relation based on PDTB-style relations, and discourse role that draws upon news discourse structure. We also perform a statistical analysis to verify our empirical observations, and introduce the procedure of constructing teacher models for both discourse structures."
        },
        {
            "heading": "2.1 Discourse Relations",
            "text": ""
        },
        {
            "heading": "2.1.1 PDTB Discourse Structure",
            "text": "The Penn Discourse Treebank (PDTB) discourse structure (Prasad et al., 2008) interprets the discourse relation between adjacent sentences in news articles into four types: 1). Comparison highlights prominent differences between two arguments, and represents the relation of contrasting or concession. 2). Contingency indicates two arguments causally influence each other, and represents a cause-andeffect or conditional relationship. 3). Temporal captures the temporal or chronological relationship between two arguments, such as precedence, succession, or simultaneously. 4). Expansion covers relations of elaborating additional details, providing explanations, or restating narratives."
        },
        {
            "heading": "2.1.2 Statistical Analysis",
            "text": "To validate the correlation between propaganda and discourse relations, we also conduct a statistical analysis on the validation set of propaganda dataset (Da San Martino et al., 2019b), where we run the model of classifying discourse relations. Table 1 shows the ratio of propaganda sentences that have each of the four discourse relations with nearby sentences. The numerical analysis confirms our observation: sentences that exhibit contingency and comparison relations with adjacent sentences are more prone to containing propaganda, whereas sentences that narrate events in a chronological order significantly contain less propaganda."
        },
        {
            "heading": "2.1.3 Teacher Model for Discourse Relation",
            "text": "We train the teacher model for discourse relations by using Longformer (Beltagy et al., 2020) as the\nbasic language model. The sentence pair embedding is the concatenation of hidden states at the two sentences start tokens <s>. A two-layer neural network is built on top of the pair embedding to predict discourse relations into comparison, contingency, temporal, or expansion. The model is trained on PDTB 2.0 data (Prasad et al., 2008) that annotates both explicit and implicit relations between adjacent sentences. Considering propaganda sentences can be connected with nearby sentences with or without discourse connectives explicitly shown, we utilize both explicit and implicit discourse relations data for training.\nGiven a pair of sentences from the propaganda article, the local discourse relation teacher model generates the predicted probability of four relations between i-th sentence and its nearby sentence as:\nP locali = (P local i1 , P local i2 , P local i3 , P local i4 ) (1)"
        },
        {
            "heading": "2.2 Discourse Role",
            "text": ""
        },
        {
            "heading": "2.2.1 News Discourse Structure",
            "text": "The news discourse structure (Choubey et al., 2020) categorizes the discourse role of each sentence in news article into three broad types and eight subtypes: 1). main event contents contain two subtypes, Main event (M1) and Consequence (M2), and cover sentences that describe the main event and their immediate consequences which are often found inseparable from main events. 2). contextinforming contents have two subtypes, Previous Event (C1) and Current Context (C2), and cover sentences that explain the context of the main event, including recent events and general circumstances. 3). additional supportive contents have four subtypes, describing past events that precede the main event in months and years (Historical Event (D1)) or unverifiable fictional situations (Anecdotal Event (D2)), or opinionated contents including reactions from immediate participants, experts, known personalities as well as journalists or news sources (Evaluation (D3)), except speculations and projected consequences referred as Expectation (D4)."
        },
        {
            "heading": "2.2.2 Statistical Analysis",
            "text": "To verify the correlation between propaganda and news discourse structure, we perform a statistical analysis on the validation set of propaganda dataset (Da San Martino et al., 2019b), where we run the model of profiling news discourse structure (Choubey and Huang, 2021). Table 2 presents the ratio of propaganda sentences across the eight news discourse roles. The numerics validate our observations: propaganda is more likely to be embedded into sentences expressing opinions or evaluations (D3), speculating future expectations (D4), or fabricating historical background (D1). Conversely, sentences describing factual occurrences, such as reporting main event (M1) or informing context (C1, C2) are less likely to carry propaganda."
        },
        {
            "heading": "2.2.3 Teacher Model for Discourse Role",
            "text": "We follow the same framework in the current stateof-art model of profiling news discourse structure (Choubey and Huang, 2021), where an actor-critic model is developed that selects between the standard REINFORCE (Williams, 1992) algorithm or imitation learning for training actor. Additionally, we replace the ELMo word embeddings (Peters et al., 2018) with Longformer language model (Beltagy et al., 2020), which generates contextualized embeddings for long documents based on transformer (Vaswani et al., 2017) and provides further improvements to the current state-of-the-art.\nGiven a candidate propaganda article consisting of n sentences, the global discourse role teacher model generates the predicted probability of eight discourse roles for i-th sentence as:\nP globali = (P global i1 , P global i2 , ..., P global i8 ) (2)"
        },
        {
            "heading": "3 Fine-grained Propaganda Identification",
            "text": "In order to incorporate the two types of discourse structures into propaganda identification, we further devise two methods: a feature concatenation model and a knowledge distillation model. Figure3 illustrates the framework of knowledge distillation.\nConsidering the news articles are typically long, we utilized Longformer (Beltagy et al., 2020) as the basic language model to encode the entire article. Given a candidate propaganda article consisting of n sentences, sentence embeddings (s1, s2, ..., sn) are initialized as the hidden state at sentence start tokens <s>. The i-th sentence contains m tokens, and its tokens embeddings are (wi1, wi2, ...wim)."
        },
        {
            "heading": "3.1 Feature Concatenation Model",
            "text": "The feature concatenation model directly concatenates the predicted probabilities generated by the two teacher models as additional features, since they contain the discourse structures information. The updated feature vectors for i-th sentence and its j-th token in the two fine-grained tasks are:\ns\u0302i = si \u2295 P locali \u2295 P globali w\u0302ij = wij \u2295 P locali \u2295 P globali\n(3)\nwhere \u2295 denotes feature concatenation, P locali and P globali are probabilities of discourse relations and discourse roles predicted by two teacher models.\nAdditionally, a two-layer classification head is built on top of the updated embedding to make prediction. The cross-entropy loss is used for training."
        },
        {
            "heading": "3.2 Knowledge Distillation Model",
            "text": "The knowledge distillation model constructs additional learning layers to learn local discourse relation and global discourse role respectively. By optimizing the response-based distillation loss to mimic the prediction behaviors of teacher, and the feature relation-based distillation loss to learn from the embeddings generated by the teachers, the discourse structures information can be distilled into the task of propaganda identification."
        },
        {
            "heading": "3.2.1 Learning Layers",
            "text": "Three types of learning layers are built on top of sentence si or token embedding wij : propaganda learning layer, student discourse relation learning layer, and student discourse role learning layer.\nThe propaganda learning layer is to learn the main task of propaganda identification at either\nsentence level or token level: Qpropai = softmax(W2(W1si + b1) + b2)\nQpropaij = softmax(W2(W1wij + b1) + b2) (4)\nwhere Qpropai and Q propa ij are the predicted probability of i-th sentence and its j-th token containing propaganda. W1,W2, b1, b2 are trainable parameters. The cross entropy loss is used for training:\nLosssent\u2212propa = \u2212 n\u2211\ni=1\nP propai log(Q propa i )\nLosstoken\u2212propa = \u2212 n\u2211\ni=1 m\u2211 j=1 P propaij log(Q propa ij ) (5)\nwhere P propai and P propa ij are human annotated propaganda label for i-th sentence and its j-th token. The student discourse relation learning layer is built on top of the concatenation of i-th sentence embedding si and its adjacent sentence embedding si\u22121, to learn the discourse relation between them from the teacher model: Qlocali = (Q local i1 , Q local i2 , ..., Q local i4 )\n= softmax(W6(W5(si \u2295 si\u22121) + b5) + b6) (6)\nwhere W5,W6, b5, b6 are trainable parameters in the student discourse relation layer, Qlocali is the learned outcome of predicting discourse relations.\nThe student discourse role learning layer is built on top of the sentence embedding si, to learn its discourse role information from the teacher model:\nQglobali = (Q global i1 , Q global i2 , ..., Q global i8 )\n= softmax(W4(W3si + b3) + b4) (7)\nwhere W3,W4, b3, b4 are trainable parameters in the student discourse role layer, and Qglobali is its learned outcome of predicting eight discourse roles."
        },
        {
            "heading": "3.2.2 Response-based Distillation",
            "text": "The response-based distillation loss (Hinton et al., 2015) is designed to minimize the discrepancy between the learned outcome of student layers and the predicted probability generated by the teacher models. By guiding the student layers to mimic the prediction behaviors of teachers, the knowledge of discourse relation and discourse role from the teachers can be distilled into the model.\nSpecifically, the Kullback\u2013Leibler (KL) divergence loss is employed for measuring the distance between the learned probability of student layers and referenced probability from teacher models:\nLossresponse\u2212local = n\u2211 i=1 P locali log (P locali Qlocali ) (8)\nLossresponse\u2212global = n\u2211 i=1 P globali log (P globali Qglobali ) (9)\nwhere P locali and P global i are response from the teachers, and are referenced as learning target. Qlocali and Q global i are learned outcomes of student discourse relation layers and student discourse role layers. The response-based distillation loss penalizes the performance gap between teacher models and student layers, and forces student layers to be updated with discourse structures knowledge."
        },
        {
            "heading": "3.2.3 Feature Relation-based Distillation",
            "text": "The feature relation-based distillation loss is designed to seek guidance from the teacher-generated sentence embeddings which also contain discourse\nstructures knowledge. However, sentence embedding itself has no absolute meaning and instead relies on its spatial relations with other contexts. Thus, rather than directly minimizing the euclidean distance between teacher-generated and studentlearned features, we follow (Park et al., 2019) to guide the student layers to learn the spatial relations between sentences found in the teacher models.\nSpecifically, let slocali and s global i denotes the i-th sentence embedding trained by the two teachers. The spatial matrix of the teachers are computed:\nM localik = cosine(s local i , s local k ) Mglobalik = cosine(s global i , s global k )\n(10)\nwhere M localik and M global ik are spatial relation between i-th and k-th sentence in the teachers. Also, the spatial matrix of student-learned features is:\nMik = cosine(si, sk) (11)\nThe feature relation-based distillation loss is the mean squared error (MSE) loss between spatial matrix of teacher models and student layers:\nLossrelation\u2212local = \u2211 i,k (M localik \u2212Mik)2\nLossrelation\u2212global = \u2211 i,k (Mglobalik \u2212Mik) 2\n(12)\nTo summarize, the response-based distillation and feature relation-based distillation mutually complement each other, with the former informed by teacher-predicted probabilities and the latter guided by teacher-generated embeddings."
        },
        {
            "heading": "3.2.4 Learning Objective",
            "text": "The total distillation loss for local discourse relation and global discourse role are: Losslocal = Lossresponse\u2212local + Lossrelation\u2212local\nLossglobal = Lossresponse\u2212global + Lossrelation\u2212global (13)\nThe overall learning objective for identifying propaganda at sentence and token level are:\nLosssent = Losssent\u2212propa + Lossglobal + Losslocal Losstoken = Losstoken\u2212propa + Lossglobal + Losslocal (14)"
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Dataset",
            "text": "Acquiring human-annotated labels at fine-grained levels is challenging and expensive, leading to a limited resource of available datasets. In our subsequent experiments, we utilized the propaganda dataset published by (Da San Martino et al., 2019b) that provides human-annotated labels for propaganda contents. We adhere to the same train / dev / test splitting in the released dataset. This propaganda dataset was also used in the NLP4IF-2019 challenge (Da San Martino et al., 2019a), which featured tasks involving sentence-level identification and token-level classification. In this paper, we specifically concentrate on propaganda identification at both the sentence and token levels."
        },
        {
            "heading": "4.2 Teacher Models",
            "text": "The teacher model for discourse relation is trained on PDTB 2.0 dataset (Prasad et al., 2008). Following its official suggestion, sections 2-21, sections 22 & 24 and section 23 are used for train / dev / test set respectively. Table 3 displays the classification performance for the four discourse relations. On the other hand, the teacher model for discourse role is trained on News Discourse dataset (Choubey et al., 2020). The performance of classifying the eight news discourse roles is presented in Table 4."
        },
        {
            "heading": "4.3 Baseline Models",
            "text": "We include the following baselines for comparison:\n\u2022 all-propaganda: a naive baseline that predicts all sentences / tokens into propaganda\n\u2022 chatgpt: an instruction prompt (A.1) is designed for the large language model ChatGPT to automatically generate predicted labels for sentence / tokens in the same test set\n\u2022 chatgpt + 5-shot: we add five examples of propaganda sentences and five examples of non-propaganda sentences into the prompt\n\u2022 chatgpt + discourse structures prompt: we add the local discourse relation and global discourse role of each sentence into the prompt\n\u2022 (Da San Martino et al., 2019a): we present the best performance achieved by the rank one team in the NLP4IF-2019 challenge, where the model was also trained on extensive corpora including Wikipedia and BookCorpus\n\u2022 (Da San Martino et al., 2019b): where both sentence and token level propaganda identification tasks are performed\n\u2022 (Fadel et al., 2019): pretrained ensemble learning is employed for sentence-level task\n\u2022 (Vlad et al., 2019): a capsule model architecture is designed for sentence-level task\n\u2022 longformer: we build a baseline that follows the same framework and is equivalent to our developed model without discourse structures"
        },
        {
            "heading": "4.4 Experimental Setting",
            "text": "The model takes the entire news article as input, and predicts the label for each sentence or token into propaganda or benign. The AdamW (Loshchilov and Hutter, 2019) is used as the optimizer. The maximum length of input is set to 4096. The number of training epochs is 6. The learning rate is adjusted by a linear scheduler. The weight decay is set to be 1e-2. Precision, Recall, and F1 of propaganda class is used as evaluation metric."
        },
        {
            "heading": "4.5 Experimental Results",
            "text": "Table 5 shows the performance of sentence-level and token-level propaganda identification.\nComparing feature concatenation models with the longformer baseline, we observe that integrating discourse relations or discourse roles as additional features brings consistent improvements for precision and recall, at both the sentence and token level tasks. This underscores that these two types of discourse structures can provide beneficial insights for identifying propaganda contents.\nComparing knowledge distillation models with the longformer baseline, it is evident that distilling the knowledge of discourse relations and discourse roles leads to a notable increase in recall by 9.25% and a significant enhancement in F1 score by 4.8%. Furthermore, in comparison to the previous best performance reported in (Da San Martino et al., 2019a), our knowledge distillation model exhibits superior performance in both precision and recall, ultimately achieving state-of-the-art results.\nComparing knowledge distillation models with feature concatenation models, we can see that distilling the knowledge from teacher models demonstrates stronger ability to incorporate two types of discourse structures, surpassing the approach of simply adding extra features.\nComparing our full model with the large language model ChatGPT, there still remains noticable performance gap, especially the recall. Also, the gap is even larger in terms of token-level task. Providing ChatGPT with extra examples or discourse structures information in the prompt can boost the performance a little bit, but it still remains inferior to our developed method."
        },
        {
            "heading": "4.6 Ablation Study",
            "text": "The ablation study of local discourse relation and global discourse role is also shown in Table 5. Both the two types of discourse structures play an essential role in identifying propaganda content, at both the sentence and token level tasks. Incorporating the two discourse structures together can further boost recall and achieves the best performance."
        },
        {
            "heading": "4.7 Effect of the Two Distillation Losses",
            "text": "Moreover, we examine the effect of two types of distillation losses in Table 6. Both response-based distillation and feature relation-based distillation yield substantial improvements. This demonstrates that learning from teacher-predicted probabilities and teacher-generated embeddings mutually complement each other, acquiring an enhanced guidance from discourse structures."
        },
        {
            "heading": "4.8 Effect of the Four Local Discourse Relations",
            "text": "In addition, we study the effect of the four local discourse relations in Table 7. The results indicate that removing any one of the four discourse relations leads to a performance drop compared to the full model, as expected, the influence of expansion relations is relatively less compared to the other three types of relations."
        },
        {
            "heading": "4.9 Qualitative Analysis",
            "text": "Figure 4 presents examples of solving false negative error through the integration of discourse structures. The first propaganda sentence is inaccurately predicted as benign by the longformer baseline. However, by incorporating the local causal discourse relation into the model, the prediction is corrected to propaganda. Likewise, the second propaganda sentence is initially misclassified as a false negative by the baseline model. However, by leveraging the knowledge from the teacher model that this sentence plays an evaluation role in the article, the model successfully rectifies this error."
        },
        {
            "heading": "5 Related Work",
            "text": "Propaganda attracted research interests for years. Prior work focus on detecting propaganda at articlelevel (Rashkin et al., 2017; Barron-Cedeno et al., 2019). The first work on fine-grained propaganda analysis was introduced by (Da San Martino et al., 2019b,a). A shared challenge focusing on tokenlevel tasks was launched by (Da San Martino et al., 2020). Several approaches have been developed for propaganda analysis, such as (Vlad et al., 2019) designed an unified neural network, (Fadel et al., 2019) utilized pretrained ensemble learning, (Dimitrov et al., 2021) trained a multimodal model mixing textual and visual features, and (Vijayaraghavan and Vosoughi, 2022) employed multi-view representations. In this paper, we focus on identifying propaganda in news articles at both sentence-level and token-level, leveraging discourse structures. Misinformation Detection was also studied for years, such as fake news (P\u00e9rez-Rosas et al., 2018; Oshikawa et al., 2020), rumor (Wei et al., 2021; Li et al., 2019), political bias (Baly et al., 2020; Chen et al., 2020), and logical fallacy (Jin et al., 2022; Alhindi et al., 2022). Although propaganda may intersect with fake news, political bias, and logical fallacies, however, they are all distinct phenomena and tasks. Fake news and rumor always hallucinate untruthful information. Political bias refers to selectively reporting verified facts while leaving readers to arrive at their own conclusions. Logical fallacies focus on errors in reasoning and argumentations to reach an invalid conclusion. In contrast, propaganda presents unverified speculation or projections in the same tone as facts, and employs a variety of persuasion strategies to convince the readers, with the purpose to manipulate public beliefs to a predetermined conclusion. Media Bias. In the most broad sense, propaganda news articles is a type of biased news reports. However, media bias often refers to ideological bias these days (Kiesel et al., 2019; Fan et al., 2019; Lei and Huang, 2022), and ideological bias is often expressed in a subtle way or under a neutral tone (van den Berg and Markert, 2020; Lei et al., 2022) by selectively including certain facts to subtly shift public opinions (Fan et al., 2019). In contrast, propaganda is not limited to hyper-partisan cases and can be applied to influence public beliefs in a way that aligns with the interests of the propagandist (Stanley, 2015; Rashkin et al., 2017). Propaganda often contains intensely emotional or opinionated content to incite or persuade the public (Da San Martino et al., 2019b), or presents unverified speculations, projections and deceptions (Miller and Robinson, 2019; Brennen, 2017). Indeed, in the current media landscape, ideologically biased media sources and propaganda media sources are often labeled separately, for example, Media Bias/Fact Check2 distinguishes ideologically biased sources, conspiracy theory sources, questionable sources which includes major propaganda sources, and a couple other categories. Ideology bias and propaganda are studied separately as well in the NLP community (Barron-Cedeno et al., 2019; Liu et al., 2022), and each task features their own benchmark datasets (Fan et al., 2019; Baly et al., 2020; Da San Martino et al., 2019b) with documents retrieved from different media sources."
        },
        {
            "heading": "6 Conclusion",
            "text": "This paper aims to identify propaganda at sentencelevel and token-level. We propose to incorporate two types of discourse structures into propaganda identification: local discourse relation and global discourse role. We further design a feature concatenation model and a knowledge distillation model to leverage the guidance from discourse structures. Limitations This paper specifically concentrates on the identification of propaganda as a specific form of misinformation. There still exists various other forms of misinformation, such as fake news, conspiracy theories, and more. While the designed discourse structures method has demonstrated its usefulness in identifying propaganda, its effectiveness for other types of misinformation remains unknown. Ethics Statement This paper focuses on the detection of propaganda, which falls within the broader category of misinformation and disinformation. The release of code and models should be utilized for the purpose of combating misinformation and not for spreading further misinformation."
        },
        {
            "heading": "Acknowledgments",
            "text": "We would like to thank the anonymous reviewers for their valuable feedback and input. We gratefully acknowledge support from National Science 2https://mediabiasfactcheck.com/\nFoundation via the awards IIS-1942918 and IIS2127746."
        },
        {
            "heading": "A Appendix",
            "text": "A.1 ChatGPT Prompt The designed instruction prompt for sentence-level propaganda identification task is: \"Propaganda is a form of misinformation or deceptive narratives that incite or mislead the public, usually with a political purpose. Please reply Yes if the following sentence contains propaganda content, else reply No. Sentence: \"xxx\". Answer:\"\nThe designed instruction prompt for token-level propaganda identification task is: \"Propaganda is a form of misinformation or deceptive narratives that incite or mislead the public, usually with a political purpose. Please extract the word in the following sentences that contains propaganda content. Please mimic the following output style. Example: \"Of course, no \"mistake\" had occurred, the ban has been lifted only because of the wide publicity that we engaged in.\". Words: wide, publicity. Sentence: \"xxx\". Words:\""
        }
    ],
    "title": "Discourse Structures Guided Fine-grained Propaganda Identification",
    "year": 2023
}