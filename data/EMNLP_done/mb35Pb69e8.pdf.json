{
    "abstractText": "Automated Essay Scoring (AES) aims to automatically assess the quality of essays. Automation enables large-scale assessment, improvements in consistency, reliability, and standardization. Those characteristics are of particular relevance in the context of language certification exams. However, a major bottleneck in the development of AES systems is the availability of corpora, which, unfortunately, are scarce, especially for languages other than English. In this paper, we aim to foster the development of AES for French by providing the TCFLE-8 corpus, a corpus of 6.5k essays collected in the context of the Test de Connaissance du Fran\u00e7ais (TCF French Knowledge Test) certification exam. We report the strict quality procedure that led to the scoring of each essay by at least two raters according to the levels of the Common European Framework of Reference for Languages (CEFR) and to the creation of a balanced corpus. In addition, we describe how linguistic properties of the essays relate to the learners\u2019 proficiency in TCFLE-8. We also advance the state-of-the-art performance for the AES task in French by experimenting with two strong baselines (i.e., RoBERTa and featurebased). Finally, we discuss the challenges of AES using TCFLE-8.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Rodrigo Wilkens"
        },
        {
            "affiliations": [],
            "name": "Alice Pintard"
        },
        {
            "affiliations": [],
            "name": "David Alfter"
        },
        {
            "affiliations": [],
            "name": "Vincent Folny"
        },
        {
            "affiliations": [],
            "name": "Thomas Fran\u00e7ois"
        },
        {
            "affiliations": [],
            "name": "IL&C"
        },
        {
            "affiliations": [],
            "name": "UCLouvain"
        }
    ],
    "id": "SP:4574b11582073abaa4e3eade938007bc4b7d68e0",
    "references": [
        {
            "authors": [
                "Dimitrios Alikaniotis",
                "Helen Yannakoudakis",
                "Marek Rei."
            ],
            "title": "Automatic text scoring using neural networks",
            "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 715\u2013725.",
            "year": 2016
        },
        {
            "authors": [
                "Cristina Arhiliuc",
                "Jelena Mitrovi\u0107",
                "Michael Granitzer."
            ],
            "title": "Language Proficiency Scoring",
            "venue": "Proceedings of the 12th Language Resources and Evaluation Conference, pages 5624\u20135630, Marseille, France. European Language Resources Association.",
            "year": 2020
        },
        {
            "authors": [
                "Taylor Arnold",
                "Nicolas Ballier",
                "Thomas Gaillat",
                "Paula Liss\u00f2n"
            ],
            "title": "Predicting CEFRL levels",
            "year": 2018
        },
        {
            "authors": [
                "Yigal Attali",
                "Jill C. Burstein."
            ],
            "title": "Automated essay scoring with e-rater\u00ae v",
            "venue": "2. The Journal of Technology, Learning and Assessment, 4(3).",
            "year": 2006
        },
        {
            "authors": [
                "Eric Atwell",
                "A. Alfaifi."
            ],
            "title": "Arabic learner corpus (ALC) v2: a new written and spoken corpus of Arabic learners",
            "venue": "Learner Corpus Studies in Asia and the World (LCSAW).",
            "year": 2014
        },
        {
            "authors": [
                "Lyle Bachman",
                "Adrian Palmer."
            ],
            "title": "Language assessment in practice: developing language assessments and justifying their use in the real world",
            "venue": "Oxford applied linguistics. Oxford Univ. Press, Oxford. 00000.",
            "year": 2010
        },
        {
            "authors": [
                "Lyle F Bachman."
            ],
            "title": "Fundamental considerations in language testing",
            "venue": "Oxford University Press. 00000.",
            "year": 1990
        },
        {
            "authors": [
                "Nicolas Ballier",
                "Thomas Gaillat."
            ],
            "title": "Classification d\u2019apprenants francophones de l\u2019anglais sur la base des metriques de complexite lexicale et syntaxique",
            "venue": "JEP-TALN-RECITAL 2016, volume 9 of ELTAL, pages 1\u201314, Paris, France.",
            "year": 2016
        },
        {
            "authors": [
                "Julie A. Belz."
            ],
            "title": "Learner corpus analysis and the development of foreign language proficiency",
            "venue": "System, 32(4):577\u2013591.",
            "year": 2004
        },
        {
            "authors": [
                "Aleksandrs Berdicevskis."
            ],
            "title": "Foreigner-directed speech is simpler than native-directed: Evidence from social media",
            "venue": "Proceedings of the Fourth Workshop on Natural Language Processing and Computational Social Science, pages 163\u2013172, Online.",
            "year": 2020
        },
        {
            "authors": [
                "Stig Johan Berggren",
                "Taraka Rama",
                "Lilja \u00d8vrelid."
            ],
            "title": "Regression or classification? Automated Essay Scoring for Norwegian",
            "venue": "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications, pages 92\u2013102.",
            "year": 2019
        },
        {
            "authors": [
                "Yves Bestgen."
            ],
            "title": "Reproducing Monolingual, Multilingual and Cross-Lingual CEFR Predictions",
            "venue": "Proceedings of the 12th Language Resources and Evaluation Conference, pages 5595\u20135602, Marseille, France. European Language Resources Association.",
            "year": 2020
        },
        {
            "authors": [
                "Daniel Blanchard",
                "Joel Tetreault",
                "Derrick Higgins",
                "Aoife Cahill",
                "Martin Chodorow."
            ],
            "title": "TOEFL11: A Corpus of Non-Native English",
            "venue": "ETS Research Report Series, 2013(2):i\u201315.",
            "year": 2013
        },
        {
            "authors": [
                "Jill Burstein",
                "Karen Kukich",
                "Susanne Wolff",
                "Chi Lu",
                "Martin Chodorow."
            ],
            "title": "Computer analysis of essays",
            "venue": "NCME Symposium on automated Scoring.",
            "year": 1998
        },
        {
            "authors": [
                "Andrew Caines",
                "Paula Buttery."
            ],
            "title": "REPROLANG 2020: Automatic Proficiency Scoring of Czech, English, German, Italian, and Spanish Learner Essays",
            "venue": "Proceedings of the 12th Language Resources and Evaluation Conference, pages 5614\u20135623, Marseille,",
            "year": 2020
        },
        {
            "authors": [
                "Cecilie Carlsen."
            ],
            "title": "Proficiency Level\u2013a Fuzzy Variable in Computer Learner Corpora",
            "venue": "Applied Linguistics, 33(2):161\u2013183.",
            "year": 2012
        },
        {
            "authors": [
                "Ana Mar\u00eda Cestero Mancera",
                "Inmaculada Penad\u00e9s Mart\u00ednez",
                "Ana Blanco Canales",
                "Laura Camargo Fern\u00e1ndez",
                "Jos\u00e9 Francisco Sim\u00f3n Granda."
            ],
            "title": "Corpus para el an\u00e1lisis de errores de aprendices de E/LE (CORANE)",
            "venue": "Actas del XII",
            "year": 2002
        },
        {
            "authors": [
                "Max Coltheart",
                "Eileen Davelaar",
                "Jon Torfi Jonasson",
                "Derek Besner."
            ],
            "title": "Access to the Internal Lexicon",
            "venue": "Attention and Performance VI. Routledge. Num Pages: 21.",
            "year": 1977
        },
        {
            "authors": [
                "Council of Europe."
            ],
            "title": "Common European Framework of Reference for Lan- guages: Learning, Teaching, Assessment",
            "venue": "Press Syndicate of the University of Cambridge.",
            "year": 2001
        },
        {
            "authors": [
                "Scott A. Crossley",
                "Danielle S. McNamara."
            ],
            "title": "Predicting second language writing proficiency: the roles of cohesion and linguistic sophistication",
            "venue": "Journal of Research in Reading, 35(2):115\u2013135.",
            "year": 2012
        },
        {
            "authors": [
                "Daniel Dahlmeier",
                "Hwee Tou Ng",
                "Siew Mei Wu."
            ],
            "title": "Building a Large Annotated Corpus of Learner English: The NUS Corpus of Learner English",
            "venue": "Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,",
            "year": 2013
        },
        {
            "authors": [
                "Iria del R\u00edo",
                "Sandra Antunes",
                "Am\u00e1lia Mendes",
                "Maarten Janssen."
            ],
            "title": "Towards error annotation in a learner corpus of Portuguese",
            "venue": "5th NLP4CALL and 1st NLP4LA workshop in Sixth Swedish Language Technology Conference (SLTC), volume 130,",
            "year": 2016
        },
        {
            "authors": [
                "Elisa Di Nuovo",
                "Manuela Sanguinetti",
                "Alessandro Mazzei",
                "Elisa Corino",
                "Cristina Bosco."
            ],
            "title": "VALICO-UD: Treebanking an Italian Learner Corpus in Universal Dependencies",
            "venue": "IJCoL. Italian Journal of Computational Linguistics, 8(1).",
            "year": 2022
        },
        {
            "authors": [
                "Semire Dikli."
            ],
            "title": "An overview of automated scoring of essays",
            "venue": "The Journal of Technology, Learning and Assessment, 5(1).",
            "year": 2006
        },
        {
            "authors": [
                "H. Dirdal",
                "I.K. Hasund",
                "E.-M. Drange",
                "E.T. Vold",
                "E.M. Berg."
            ],
            "title": "Design and construction of the tracking written learner language (trawl) corpus: A longitudinal and multilingual young learner corpus",
            "venue": "Nordic Journal of Language Teaching and Learning,",
            "year": 2022
        },
        {
            "authors": [
                "Fei Dong",
                "Yue Zhang",
                "Jie Yang."
            ],
            "title": "Attentionbased recurrent convolutional neural network for automatic essay scoring",
            "venue": "Proceedings of the 21st conference on computational natural language learning (CoNLL 2017), pages 153\u2013162.",
            "year": 2017
        },
        {
            "authors": [
                "T. Eckes."
            ],
            "title": "Quantitative Data Analysis for Language Assessment Volume I: Fundamental Techniques, 1 edition",
            "venue": "Routledge.",
            "year": 2009
        },
        {
            "authors": [
                "Dana R. Ferris."
            ],
            "title": "Lexical and syntactic features of esl writing by students at different levels of l2 proficiency",
            "venue": "TESOL Quarterly, 28(2):414\u2013420.",
            "year": 1994
        },
        {
            "authors": [
                "Lawrence T. Frase",
                "Joseph Faletti",
                "April Ginther",
                "Leslie Grant."
            ],
            "title": "Computer Analysis of the Toefl Test of Written English",
            "venue": "ETS Research Report Series, 1998(2):i\u201326.",
            "year": 1998
        },
        {
            "authors": [
                "Eric Friginal."
            ],
            "title": "Corpus Linguistics for English Teachers: Tools, Online Resources, and Classroom Activities, 1st edition edition",
            "venue": "Routledge, New York, NY.",
            "year": 2018
        },
        {
            "authors": [
                "D. Gablasova",
                "V. Brezina",
                "T. McEnery."
            ],
            "title": "The trinity lancaster corpus: Development, description and application",
            "venue": "International Journal of Learner Corpus Research, 5(2):126\u2013158.",
            "year": 2019
        },
        {
            "authors": [
                "Thomas. Gaillat",
                "L.C. Roa."
            ],
            "title": "The corpus interlangue project: Storing language learner data in a huma-num nakala database for automatic online retrieval",
            "venue": "The CLARIN Bazaar 2020. Book of Abstracts. CLARIN2020, Virtual Event.",
            "year": 2020
        },
        {
            "authors": [
                "Jeroen Geertzen",
                "Theodora Alexopoulou",
                "Anna Korhonen."
            ],
            "title": "Automatic Linguistic Annotation of Large Scale L2 Databases: The EF-Cambridge Open Language Database (EFCamDat)",
            "venue": "Selected Proceedings of the 2012 Second Language Research Fo-",
            "year": 2014
        },
        {
            "authors": [
                "Jeroen Geertzen",
                "Theodora Alexopoulou",
                "Anna Korhonen"
            ],
            "title": "Automatic linguistic annotation of large scale l2 databases: The ef-cambridge open language database (efcamdat)",
            "venue": "In Proceedings of the 31st Second Language Research Forum. Somerville,",
            "year": 2013
        },
        {
            "authors": [
                "Lucie Gianola",
                "\u0112riks Ajausks",
                "Victoria Arranz",
                "Ona de Gibert",
                "Maite Melero."
            ],
            "title": "Automatic removal of identifying information in official eu languages for public administrations: The mapa project",
            "venue": "33rd International Conference on Legal Knowledge",
            "year": 2020
        },
        {
            "authors": [
                "Ga\u00ebtanelle Gilquin."
            ],
            "title": "From design to collection of learner corpora",
            "venue": "The Cambridge Handbook of Learner Corpus Research, pages 9\u201334.",
            "year": 2015
        },
        {
            "authors": [
                "Anne Golden",
                "Scott Jarvis",
                "Kari Tenfjord."
            ],
            "title": "Crosslinguistic Influence and Distinctive Patterns of Language Learning: Findings and Insights from a Learner Corpus",
            "venue": "Multilingual Matters.",
            "year": 2017
        },
        {
            "authors": [
                "Jonas Granfeldt",
                "Pierre Nugues",
                "Emil Persson",
                "Jonas Thulin",
                "Malin \u00c5gren",
                "Suzanne Schlyter."
            ],
            "title": "CEFLE and Direkt Profil: A new computer learner corpus in French L2 and a system for grammatical profiling",
            "venue": "Proceedings of the Fifth International",
            "year": 2006
        },
        {
            "authors": [
                "Sylviane Granger."
            ],
            "title": "The International Corpus of Learner English",
            "venue": "The European English Messenger, page 34.",
            "year": 1993
        },
        {
            "authors": [
                "Sylviane Granger."
            ],
            "title": "Error-tagged Learner Corpora and CALL: A Promising Synergy",
            "venue": "CALICO Journal, 20(3):465\u2013480.",
            "year": 2003
        },
        {
            "authors": [
                "Sylviane Granger",
                "Ga\u00ebtanelle Gilquin",
                "Fanny Meunier"
            ],
            "title": "Twenty Years of Learner Corpus Research: Looking back, Moving ahead",
            "year": 2013
        },
        {
            "authors": [
                "Leslie Grant",
                "April Ginther."
            ],
            "title": "Using computertagged linguistic features to describe l2 writing differences",
            "venue": "Journal of Second Language Writing, 9(2):123\u2013145.",
            "year": 2000
        },
        {
            "authors": [
                "Liang Guo",
                "Scott A. Crossley",
                "Danielle S. McNamara."
            ],
            "title": "Predicting human judgments of essay quality in both integrated and independent second language writing samples: A comparison study",
            "venue": "Assessing Writing, 18(3):218\u2013238.",
            "year": 2013
        },
        {
            "authors": [
                "Ulrike Gut."
            ],
            "title": "The LeaP corpus : A multilingual corpus of spoken learner German and learner English",
            "venue": "Multilingual corpora and multilingual corpus analysis, 14:3\u201323.",
            "year": 2012
        },
        {
            "authors": [
                "Liz Hamp-Lyons."
            ],
            "title": "Rating Nonnative Writing: The Trouble with Holistic Scoring",
            "venue": "TESOL Quarterly, 29(4):759.",
            "year": 1995
        },
        {
            "authors": [
                "Reo Hirao",
                "Mio Arai",
                "Hiroki Shimanaka",
                "Satoru Katsumata",
                "Mamoru Komachi."
            ],
            "title": "Automated Essay Scoring System for Nonnative Japanese Learners",
            "venue": "Proceedings of the 12th Language Resources and Evaluation Conference, pages 1250\u20131257, Mar-",
            "year": 2020
        },
        {
            "authors": [
                "Reo Hirao",
                "Mio Arai",
                "Hiroki Shimanaka",
                "Satoru Katsumata",
                "Mamoru Komachi."
            ],
            "title": "Automated essay scoring system for nonnative japanese learners",
            "venue": "Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 1250\u20131257.",
            "year": 2020
        },
        {
            "authors": [
                "Przemyslaw Kaszubski."
            ],
            "title": "Learner corpora: The cross-roads of linguistic norm",
            "venue": "TALC98 Proceedings, pages 24\u201327.",
            "year": 1998
        },
        {
            "authors": [
                "Zixuan Ke",
                "Vincent Ng."
            ],
            "title": "Automated essay scoring: A survey of the state of the art",
            "venue": "IJCAI, volume 19, pages 6300\u20136308.",
            "year": 2019
        },
        {
            "authors": [
                "Elma Kerz",
                "Daniel Wiechmann",
                "Yu Qiao",
                "Emma Tseng",
                "Marcus Str\u00f6bel."
            ],
            "title": "Automated Classification of Written Proficiency Levels on the CEFR-Scale through Complexity Contours and RNNs",
            "venue": "Proceedings of the 16th Workshop on Innovative Use of",
            "year": 2021
        },
        {
            "authors": [
                "Beata Beigman Klebanov",
                "Nitin Madnani."
            ],
            "title": "Automated evaluation of writing\u201350 years and counting",
            "venue": "Proceedings of the 58th annual meeting of the association for computational linguistics, pages 7796\u20137810.",
            "year": 2020
        },
        {
            "authors": [
                "Beata Beigman Klebanov",
                "Nitin Madnani."
            ],
            "title": "Automated Essay Scoring",
            "venue": "Synthesis Lectures on Human Language Technologies, 14(5):1\u2013314.",
            "year": 2021
        },
        {
            "authors": [
                "Paraskevas Lagakis",
                "Stavros Demetriadis."
            ],
            "title": "Automated essay scoring: A review of the field",
            "venue": "2021 International Conference on Computer, Information and Telecommunication Systems (CITS), pages 1\u20136. IEEE.",
            "year": 2021
        },
        {
            "authors": [
                "Thomas K Landauer",
                "Darrell Laham",
                "Bob Rehder",
                "Missy E Schreiner."
            ],
            "title": "How well can passage meaning be derived without using word order? a comparison of latent semantic analysis and humans",
            "venue": "Proceedings of the 19th annual meeting of the",
            "year": 1997
        },
        {
            "authors": [
                "Batia Laufer",
                "Paul Nation."
            ],
            "title": "Vocabulary Size and Use: Lexical Richness in L2 Written Production",
            "venue": "Applied Linguistics, 16(3):307\u2013322.",
            "year": 1995
        },
        {
            "authors": [
                "Jae-Ho Lee",
                "Yoichiro Hasebe."
            ],
            "title": "Quantitative Analysis of JFL Learners\u2019 Writing Abilities and the Development of a Computational System to Estimate Writing Proficiency",
            "venue": "Learner Corpus Studies in Asia and the World, 5:105\u2013120.",
            "year": 2020
        },
        {
            "authors": [
                "Benoit Lemaire",
                "Philippe Dessus."
            ],
            "title": "A System to Assess the Semantic Content of Student Essays",
            "venue": "Journal of Educational Computing Research, 24(3):305\u2013320.",
            "year": 2001
        },
        {
            "authors": [
                "Lexical Computing Limited."
            ],
            "title": "OpenCLC (v1)",
            "venue": "https://www.sketchengine.eu/ cambridge-learner-corpus/#toggle-id-1. Distributed by Lexical Computing Limited on behalf of Cambridge University Press and Cambridge",
            "year": 2017
        },
        {
            "authors": [
                "Mathias Lilja."
            ],
            "title": "Automatic Essay Scoring of Swedish Essays using Neural Networks",
            "venue": "Ph.D. thesis, Uppsala University.",
            "year": 2018
        },
        {
            "authors": [
                "Stephanie Link",
                "Ahmet Dursun",
                "Kadir Karakaya",
                "Volker Hegelheimer."
            ],
            "title": "Towards Better ESL Practices for Implementing Automated Writing Evaluation",
            "venue": "Calico Journal, 31(3).",
            "year": 2014
        },
        {
            "authors": [
                "Longman."
            ],
            "title": "Longman Essential Activator",
            "venue": "Pearson ESL, Harlow.",
            "year": 2002
        },
        {
            "authors": [
                "Crist\u00f3bal Lozano."
            ],
            "title": "CEDEL2: Corpus escrito del espa\u00f1ol L2",
            "venue": "Carmen M. Bretones Callejas, Jos\u00e9 Francisco Fern\u00e1ndez S\u00e1nchez, Jos\u00e9 Ram\u00f3n Ib\u00e1\u00f1ez Ib\u00e1\u00f1ez, Mar\u00eda Elena Garc\u00eda S\u00e1nchez, Ma Enriqueta Cort\u00e9s de los R\u00edos, Sagrario Salaberri Ramiro,",
            "year": 2009
        },
        {
            "authors": [
                "Xiaofei Lu."
            ],
            "title": "The Relationship of Lexical Richness to the Quality of ESL Learners\u2019 Oral Narratives",
            "venue": "The Modern Language Journal, 96(2):190\u2013 208. https://onlinelibrary.wiley.com/doi/ pdf/10.1111/j.1540-4781.2011.01232_1.x.",
            "year": 2012
        },
        {
            "authors": [
                "Louis Martin",
                "Benjamin Muller",
                "Pedro Javier Ortiz Su\u00e1rez",
                "Yoann Dupont",
                "Laurent Romary",
                "\u00c9ric Villemonte de la Clergerie",
                "Djam\u00e9 Seddah",
                "Beno\u00eet Sagot."
            ],
            "title": "Camembert: a tasty french language model",
            "venue": "Proceedings of the 58th Annual Meeting",
            "year": 2020
        },
        {
            "authors": [
                "Maisa Martin",
                "Riikka Alanen",
                "Ari Huhta",
                "Paula Kalaja",
                "Katja M\u00e4ntyl\u00e4",
                "Mirja Tarnanen",
                "\u00c5sa Palviainen."
            ],
            "title": "CEFLING: Combining Second Language Acquisition and Testing Approaches to Writing",
            "venue": "Studies in Writing, 25.",
            "year": 2012
        },
        {
            "authors": [
                "Elijah Mayfield",
                "Alan W Black"
            ],
            "title": "Should you fine-tune bert for automated essay scoring",
            "venue": "In Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications,",
            "year": 2020
        },
        {
            "authors": [
                "Am\u00e1lia Mendes",
                "Sandra Antunes",
                "Maarten Janssen",
                "Anabela Gon\u00e7alves."
            ],
            "title": "The COPLE2 corpus: a learner corpus for Portuguese",
            "venue": "Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC\u201916), pages 3207\u2013",
            "year": 2016
        },
        {
            "authors": [
                "Farah Nadeem",
                "Huy Nguyen",
                "Yang Liu",
                "Mari Ostendorf."
            ],
            "title": "Automated Essay Scoring with Discourse-Aware Neural Models",
            "venue": "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications, pages 484\u2013",
            "year": 2019
        },
        {
            "authors": [
                "Diane Nicholls."
            ],
            "title": "The Cambridge Learner Corpus: Error coding and analysis for lexicography and ELT",
            "venue": "Proceedings of the Corpus Linguistics 2003 conference, volume 16, pages 572\u2013581.",
            "year": 2003
        },
        {
            "authors": [
                "John W. Oller",
                "Jr.",
                "F.B. Hinofotis"
            ],
            "title": "Two mutually exclusive hypotheses about second language ability : factor analytic studies of a variety of language subtests",
            "year": 1980
        },
        {
            "authors": [
                "Masumi Ono",
                "Hiroyuki Yamanishi",
                "Yuko Hijikata"
            ],
            "title": "Holistic and Analytic Assessments",
            "year": 2019
        },
        {
            "authors": [
                "Ellis B Page"
            ],
            "title": "The imminence of... grading essays by computer",
            "venue": "The Phi Delta Kappan,",
            "year": 1966
        },
        {
            "authors": [
                "Nicholas Parslow."
            ],
            "title": "Automated Analysis of L2 French Writing: a preliminary study",
            "venue": "Master\u2019s thesis. Publisher: Unpublished.",
            "year": 2015
        },
        {
            "authors": [
                "Nicholas Lynton Parslow."
            ],
            "title": "Automated Analysis of L2 French Writing: a preliminary study",
            "venue": "Ph.D. thesis, Master\u2019s thesis). University of Paris Diderot. doi: 10.13140/RG. 2.1. 2833.5204.",
            "year": 2015
        },
        {
            "authors": [
                "Clive Perdue."
            ],
            "title": "Comment rendre compte de la \"logique\" de l\u2019acquisition d\u2019une langue \u00e9trang\u00e8re par l\u2019adulte",
            "venue": "\u00c9tudes de Linguistique Appliqu\u00e9e, 92(1):8\u2013",
            "year": 1993
        },
        {
            "authors": [
                "Ildik\u00f3 Pil\u00e1n",
                "Elena Volodina"
            ],
            "title": "Investigating the importance of linguistic complexity features across different datasets related to language learning",
            "venue": "In Proceedings of the Workshop on Linguistic Complexity and Natural Language Processing,",
            "year": 2018
        },
        {
            "authors": [
                "Ildik\u00f3 Pil\u00e1n",
                "Elena Volodina."
            ],
            "title": "Investigating the importance of linguistic complexity features across different datasets related to language learning",
            "venue": "Proceedings of the Workshop on Linguistic Complexity and Natural Language Processing, pages 49\u201358.",
            "year": 2018
        },
        {
            "authors": [
                "Alice Pintard",
                "Thomas Fran\u00e7ois."
            ],
            "title": "Combining expert knowledge with frequency information to infer cefr levels for words",
            "venue": "Proceedings of the 1st Workshop on Tools and Resources to Empower People with REAding DIfficulties (READI), pages 85\u201392.",
            "year": 2020
        },
        {
            "authors": [
                "Nives Preradovic",
                "Monika Bera\u0107",
                "Damir Boras"
            ],
            "title": "Learner Corpus of Croatian as a Second and Foreign Language",
            "year": 2015
        },
        {
            "authors": [
                "Ekaterina V. Rakhilina",
                "Anastasia Vyrenkova",
                "Elmira Mustakimova",
                "Alina Ladygina",
                "Ivan Smirnov."
            ],
            "title": "Building a learner corpus for Russian",
            "venue": "Proceedings of the joint workshop on NLP for Computer Assisted Language Learning and NLP for Language",
            "year": 2016
        },
        {
            "authors": [
                "Dadi Ramesh",
                "Suresh Kumar Sanampudi."
            ],
            "title": "An automated essay scoring systems: a systematic literature review",
            "venue": "Artificial Intelligence Review, 55(3):2495\u20132527.",
            "year": 2022
        },
        {
            "authors": [
                "Bojana Rankovi\u0107",
                "Sarah Smirnow",
                "Martin Jaggi",
                "Martin J. Tomasik."
            ],
            "title": "Automated Essay Scoring in Foreign Language Students Based on Deep Contextualised Word Representations",
            "venue": "LAK20-10th International Conference on Learning Analytics &",
            "year": 2020
        },
        {
            "authors": [
                "Randi Reppen."
            ],
            "title": "Using Corpora in the Language Classroom",
            "venue": "Cambridge University Press.",
            "year": 2010
        },
        {
            "authors": [
                "Alexandr Rosen",
                "Jirka Hana",
                "Barbora Hladka",
                "Tomas Jelinek",
                "Svatava \u0160kodov\u00e1",
                "Barbora \u0160tindlov\u00e1"
            ],
            "title": "Compiling and annotating a learner corpus for a morphologically rich language \u2013 CzeSL, a corpus of non-native Czech",
            "year": 2020
        },
        {
            "authors": [
                "Rex Dajun Ruan."
            ],
            "title": "Neural Network Based Automatic Essay Scoring for Swedish",
            "venue": "page 61.",
            "year": 2020
        },
        {
            "authors": [
                "Lawrence M. Rudner",
                "Tahung Liang."
            ],
            "title": "Automated essay scoring using Bayes\u2019 theorem",
            "venue": "The Journal of Technology, Learning and Assessment, 1(2).",
            "year": 2002
        },
        {
            "authors": [
                "Andr\u00e9 A. Rupp",
                "Jodi M. Casabianca",
                "Maleika Kr\u00fcger",
                "Stefan Keller",
                "Olaf K\u00f6ller."
            ],
            "title": "Automated essay scoring at scale: a case study in Switzerland and Germany",
            "venue": "ETS Research Report Series, 2019(1):1\u2013",
            "year": 2019
        },
        {
            "authors": [
                "Kumiko Sakoda",
                "Yoko Hosoi."
            ],
            "title": "International Corpus of Japanese as a Second Language (I-JAS): \u65e5\u672c\u8a9e\u5b66\u7fd2\u8005\u306e\u8a00\u8a9e\u7814\u7a76\u3068\u6307\u5c0e\u306e\u305f\u3081\u306b [For Language Research and Teaching of Japanese Learners",
            "venue": "\u30b7\u30f3\u30dd\u30b8\u30a6\u30e0 \u8a71\u3057\u8a00\u8449\u30b3\u30fc\u30d1\u30b9\u306e\u69cb",
            "year": 2018
        },
        {
            "authors": [
                "Larry Selinker."
            ],
            "title": "Interlanguage",
            "venue": "Publisher: Walter de Gruyter, Berlin/New York Berlin, New York.",
            "year": 1972
        },
        {
            "authors": [
                "Mark D Shermis",
                "Jill Burstein",
                "Sharon Apel Bursky."
            ],
            "title": "Introduction to automated essay evaluation",
            "venue": "Handbook of automated essay evaluation, pages 23\u201337. Routledge.",
            "year": 2013
        },
        {
            "authors": [
                "Peter Siemen",
                "A. L\u00fcdeling",
                "F.H. M\u00fcller."
            ],
            "title": "FALKO - An error-annotated German learner corpus",
            "venue": "Proceedings of KONVENS 2006 - Konferenz zur Verarbeitung Naturlicher Sprache, pages 130\u2013136.",
            "year": 2006
        },
        {
            "authors": [
                "Christian Stab",
                "Iryna Gurevych."
            ],
            "title": "Identifying Argumentative Discourse Structures in Persuasive Essays",
            "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 46\u201356. Association for Computa-",
            "year": 2014
        },
        {
            "authors": [
                "Kaveh Taghipour",
                "Hwee Tou Ng."
            ],
            "title": "A neural approach to automated essay scoring",
            "venue": "Proceedings of the 2016 conference on empirical methods in natural language processing, pages 1882\u20131891.",
            "year": 2016
        },
        {
            "authors": [
                "Kari Tenfjord",
                "Paul Meurer",
                "Knut Hofland."
            ],
            "title": "The ASK corpus - a language learner corpus of Norwegian as a second language",
            "venue": "Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC), Genoa, Italy. Euro-",
            "year": 2006
        },
        {
            "authors": [
                "Kari Tenfjord",
                "Paul Meurer",
                "Knut Hofland."
            ],
            "title": "The ASK Corpus-a Language Learner Corpus of Norwegian as a Second Language",
            "venue": "LREC, volume 6, pages 1821\u20131824.",
            "year": 2006
        },
        {
            "authors": [
                "Ian Tenney",
                "Dipanjan Das",
                "Ellie Pavlick."
            ],
            "title": "Bert rediscovers the classical nlp pipeline",
            "venue": "arXiv preprint arXiv:1905.05950.",
            "year": 2019
        },
        {
            "authors": [
                "Joel Tetreault",
                "Daniel Blanchard",
                "Aoife Cahill."
            ],
            "title": "A report on the first native language identification shared task",
            "venue": "Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications, pages 48\u201357, Atlanta, Georgia. Associ-",
            "year": 2013
        },
        {
            "authors": [
                "Masaki Uto."
            ],
            "title": "A review of deep-neural automated essay scoring models",
            "venue": "Behaviormetrika, 48(2):459\u2013 484.",
            "year": 2021
        },
        {
            "authors": [
                "Sowmya Vajjala."
            ],
            "title": "Automated Assessment of NonNative Learner Essays: Investigating the Role of Linguistic Features",
            "venue": "International Journal of Artificial Intelligence in Education, 28(1):79\u2013105.",
            "year": 2018
        },
        {
            "authors": [
                "Sowmya Vajjala",
                "Taraka Rama."
            ],
            "title": "Experiments with Universal CEFR Classification",
            "venue": "Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, pages 147\u2013153, New Orleans, Louisiana. Association for",
            "year": 2018
        },
        {
            "authors": [
                "Freiderikos Valetopoulos",
                "Jolanta Zaj\u0105c"
            ],
            "title": "Les comp\u00e9tences en progression: un d\u00e9fi pour la didactique des langues",
            "year": 2012
        },
        {
            "authors": [
                "Gudrun Vanderbauwhede."
            ],
            "title": "The integrated contrastive model evaluated: The french and dutch demonstrative determiner in l1 and l2",
            "venue": "International Journal of Applied Linguistics, 22(3):392\u2013413.",
            "year": 2012
        },
        {
            "authors": [
                "J Helmut Vollmer",
                "John B. Caroll."
            ],
            "title": "Psychometric theory and language testing",
            "venue": "John W. Oller, editor, Issues in language testing research, pages 29\u201379. Newbury House, Rowley, Mass. 00000.",
            "year": 1983
        },
        {
            "authors": [
                "J Helmut Vollmer",
                "Fritz Sang."
            ],
            "title": "Competing hypotheses about second language ability : a plea of caution",
            "venue": "John W. Oller, editor, Issues in language testing research. Newbury House, Rowley, Mass. 00000.",
            "year": 1983
        },
        {
            "authors": [
                "Elena Volodina",
                "Lena Granstedt",
                "Arild Matsson",
                "Be\u00e1ta Megyesi",
                "Ildik\u00f3 Pil\u00e1n",
                "Julia Prentice",
                "Dan Ros\u00e9n",
                "Lisa Rudebeck",
                "Carl-Johan Schenstr\u00f6m",
                "Gunl\u00f6g Sundberg",
                "Mats Wir\u00e9n"
            ],
            "title": "The SweLL Language Learner Corpus: From Design to Annotation",
            "year": 2019
        },
        {
            "authors": [
                "Elena Volodina",
                "Ildik\u00f3 Pil\u00e1n",
                "Ingegerd Enstr\u00f6m",
                "Lorena Llozhi",
                "Peter Lundkvist",
                "Gunl\u00f6g Sundberg",
                "Monica Sandell."
            ],
            "title": "SweLL on the rise: Swedish Learner Language corpus for European Reference Level studies",
            "venue": "Proceedings of the Tenth Interna-",
            "year": 2016
        },
        {
            "authors": [
                "Maolin Wang",
                "Shervin Malmasi",
                "Mingxuan Huang."
            ],
            "title": "The Jinan Chinese Learner Corpus",
            "venue": "Proceedings of the Tenth Workshop on Innovative Use",
            "year": 2015
        },
        {
            "authors": [
                "Valentin Werner",
                "Robert Fuchs",
                "Sandra G\u00f6tz."
            ],
            "title": "L1 influence vs",
            "venue": "universal mechanisms: An SLAdriven corpus study on temporal expression. In Learner Corpus Research Meets Second Language Acquisition, pages 39\u201366. Cambridge University",
            "year": 2020
        },
        {
            "authors": [
                "Rodrigo Wilkens",
                "David Alfter",
                "Xiaoou Wang",
                "Alice Pintard",
                "Ana\u00efs Tack",
                "Kevin P Yancey",
                "Thomas Fran\u00e7ois."
            ],
            "title": "Fabra: French aggregator-based readability assessment toolkit",
            "venue": "Proceedings of the Thirteenth Language Resources and Evaluation",
            "year": 2022
        },
        {
            "authors": [
                "Katrin Wisniewski",
                "Karin Sch\u00f6ne",
                "Lionel Nicolas",
                "Chiara Vettori",
                "Adriane Boyd",
                "Detmar Meurers",
                "Andrea Abel",
                "Jirka Hana"
            ],
            "title": "MERLIN: An online trilingual learner corpus empirically grounding the European Reference Levels in authentic learner data",
            "year": 2013
        },
        {
            "authors": [
                "Edward W Wolfe",
                "Tian Song",
                "Hong Jiao."
            ],
            "title": "Features of difficult-to-score essays",
            "venue": "Assessing Writing, 27:1\u201310.",
            "year": 2016
        },
        {
            "authors": [
                "Helen Yannakoudakis",
                "Ted Briscoe",
                "Ben Medlock."
            ],
            "title": "A New Dataset and Method for Automatically Grading ESOL Texts",
            "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages",
            "year": 2011
        },
        {
            "authors": [
                "Tal Yarkoni",
                "David Balota",
                "Melvin Yap."
            ],
            "title": "Moving beyond coltheart\u2019s n: A new measure of orthographic similarity",
            "venue": "Psychonomic bulletin & review, 15:971\u2013979.",
            "year": 2008
        },
        {
            "authors": [
                "Wajdi Zaghouani."
            ],
            "title": "AUTO-\u00c9VAL : vers un mod\u00e8le d\u2019\u00e9valuation automatique des textes",
            "venue": "Actes du colloque des \u00e9tudiants en sciences du langage, page 16, Montr\u00e9al, Canada. Universit\u00e9 du Qu\u00e9bec \u00e0 Montr\u00e9al.",
            "year": 2002
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Automated Essay Scoring (AES) aims to develop algorithms that can assess the quality of essays similarly to humans. The field may be traced back to the seminal work of Page (1966). Since then, several publications have been studying AES.2 In the late 1990\u2019s, several functional AES systems were already available, either relying on Latent\n1TCFLE-8 is available at https://www. france-education-international.fr/corpus\n2For comprehensive reviews see Ramesh and Sanampudi (2022); Lagakis and Demetriadis (2021); Klebanov and Madnani (2021); Uto (2021); Klebanov and Madnani (2020); Ke and Ng (2019); Shermis et al. (2013).\nSemantic Analysis (e.g., Landauer et al. (1997)), NLP-extracted features combined with multiple regression (e.g., Burstein et al. (1998)) or Bayesian text classification (e.g., Rudner and Liang (2002)). As noted by Dikli (2006), a small amount of essays (less than 1000) could be enough for training such systems in some contexts. However, even collecting such a small corpus was difficult, as the essays need to be manually rated, and essays reliable assessment is a notoriously difficult task for humans (Wolfe et al., 2016).\nRecent advances in AES have been made possible by Deep Learning (DL) approaches and large language models (Ramesh and Sanampudi, 2022). Prominent studies used embeddings (Alikaniotis et al., 2016), recurrent neural network (Taghipour and Ng, 2016), attention (Dong et al., 2017), and BERT-based architectures (Mayfield and Black, 2020). These approaches have also led to a growing need for large corpora.\nConsequently, AES teams have turned their attention to learner corpus research, a branch of corpus linguistics providing large-scale, computerized, naturalistic learner production. Pioneering works such as the International Corpus of Learner English (ICLE) (Granger, 1993) and the European Science Foundation L2 Database (Perdue, 1993) demonstrated the potential of such learner data collections for Second Language Acquisition (SLA) research, but it is only recently that more learner corpora fitted for AES, i.e., large enough and annotated with different proficiency levels, were developed for various languages (Yannakoudakis et al., 2011; Blanchard et al., 2013; Geertzen et al., 2014; Wisniewski et al., 2013; Mendes et al., 2016; Sakoda and Hosoi, 2018).\nUnfortunately, there is no such large corpus for French, making the situation for French AES far from encouraging. The first systems thus relied on unsupervised approaches: Lemaire and Dessus (2001) used Latent Semantic Analysis to compare\nnative language (L1) of student essays with textbook passages, whereas AUTO-EVAL (Zaghouani, 2002) automatically captured several L1 essay features, which are heuristically combined. More recently, Parslow (2015a) trained a Naive Bayes classifier on a very small corpus of 200 essays written in foreign language (FL). Finally, Rankovic\u0301 et al. (2020) were the first to fine-tune BERT for FL French AES on more data, but they did not release it and only a single L1 is represented.\nTherefore, in order to support the development of AES solutions for French, the need for a large and reliable corpus of written French essays becomes apparent. In this paper, we make two main contributions. First, we provide the community with the TCFLE-8 corpus3, composed of 6,569 learner essays, with 8 different languages of habitual use, scores, from at least 2 raters, for the 6 levels of the Common European Framework of Reference for Languages (CEFR) (Council of Europe, 2001), and automatically annotated with +5k features. These essays were collected in the context of the official French Knowledge Test (TCF) exam, one of the main certification exams for French. Second, we provide solid baselines for future research in AES using TCFLE-8. This is the largest AES modeling study that has been done for French.\nThis paper is organized as follows. Section 2 presents the main characteristics and uniqueness of corpora used for AES. We then present the corpus compilation process, presenting the official certification exam which our corpus is based on and the essay selection process (Section 3). Next, in Section 4, we present the TCFLE-8 corpus, discussing its size, metadata and annotation. An exploration of TCFLE-8 for AES systems is presented in Section 5. Finally, final remarks are presented in Section 6. TCFLE-8 is freely available for research purposes."
        },
        {
            "heading": "2 Related Work",
            "text": "Developing a French corpus for AES means taking part in the field of learner corpus research, which, since its emergence in the late 1980s, gave rise to more than 200 learner corpora around the world4. Reviews on learner corpora (Gilquin,\n3 Test de connaissance du fran\u00e7ais (French knowledge test); FLE stands for fran\u00e7ais langue \u00e9trang\u00e8re (French as a foreign language) and 8 refers to the eight different languages of habitual use included in the corpus.\n4See the Learner Corpora around the World (https://uclouvain.be/en/research-institutes/ ilc/cecl/learner-corpora-around-the-world.html) for corpora that have been described in scientific publications.\n2015; Granger et al., 2013) point out the prevalence of English as target language for more than half of the corpora, the rest focusing on German (Siemen et al., 2006; Gut, 2012; Belz, 2004), Spanish (Lozano, 2009; Cestero Mancera et al., 2002), French (Granger, 2003; Granfeldt et al., 2006), Italian (Di Nuovo et al., 2022) and others (Atwell and Alfaifi, 2014; Wang et al., 2015; Martin et al., 2012). In terms of usual or native language of the learners (L1), the majority of learner corpora are mono-L1. Multi-L1 corpora are however favored today because they allow to study the influence of various L1s on the target language and they offer a wider degree of generalization.\nAmong this large body of written learner corpora, we will focus on two types relevant for this work: corpora used for AES and learner corpora targeting French as a foreign language."
        },
        {
            "heading": "2.1 Corpora for AES",
            "text": "Corpora built for AES can focus of specific dimensions, such as the organizational skill of essay writing (e.g., ICLE (Granger, 1993)) or the persuasive nature of the essay (e.g., Argument Annotated Essays (Stab and Gurevych, 2014)), but they usually address the global level of a learner production on a proficiency scale. One of the most commonly used scales for foreign languages is the Common European Framework of Reference for Languages (CEFR) (Council of Europe, 2001), describing six levels of proficiency from A1 (beginner) to C2 (advanced). As the mapping between each essay and its proficiency level is critical in AES, it is best to use essays written in the context of official L2 certifications, as they benefit from strict rating procedures, usually with at least two professional raters grading each production. We distinguish these corpora, which we call candidate corpora, from other learner corpora containing productions collected in language classes or on web forums."
        },
        {
            "heading": "2.1.1 Candidate corpora",
            "text": "In addition to having more reliable proficiency ratings, candidate corpora also contain more varied learner profiles in terms of L1, age and background. The largest candidate corpus is the Cambridge Learner Corpus (CLC) (Nicholls, 2003) with more than 50 million words from 200,000 written productions and 138 different L1s. It was compiled from English exams of Cambridge Assessment English and two subparts of this corpus are available for research. First, the OpenCLC (Lexical Com-\nputing Limited, 2017) is composed of more than 10,000 texts from candidates of 7 different L1s. The second available subpart of the CLC, First Certificate of English (CLC-FCE), contains 1,238 texts aligned with the CEFR (Yannakoudakis et al., 2011; Vajjala and Rama, 2018). Another corpus targeting English was released by Educational Testing Service, the ETS corpus of non-native written English or TOEFL11 (Blanchard et al., 2013). Initially compiled to perform L1 detection tasks, this corpus was later used in AES to explore both traditional machine learning (Rupp et al., 2019) and deep learning models (Nadeem et al., 2019). It contains 12,100 English essays written by TOEFL candidates of 11 non-English native languages. The essays are presented with their prompt and proficiency level given by ETS (low-medium-high).\nCollaborations between certified testing organisations and research groups also developed for other European languages, resulting into three recent candidate corpora. The MERLIN corpus (Wisniewski et al., 2013) contains 2,290 written productions from standardized tests targeting German, Italian (TELC institute) and Czech (UJOP Institute). Its design allowed for cross-lingual AES experiments (Vajjala, 2018; Arhiliuc et al., 2020; Bestgen, 2020; Caines and Buttery, 2020). The COPLE2 corpus (Mendes et al., 2016), containing 966 essays written in Portuguese (ICLP and CAPLE institutes), and the ASK corpus (Tenfjord et al., 2006b), with 1,936 texts written by candidates to the Norwegian Language Test, have also both been used for AES (del R\u00edo et al., 2016; Berggren et al., 2019; Carlsen, 2012). Table 6 in Appendix A provides an additional detailed description of existing candidate corpora."
        },
        {
            "heading": "2.1.2 Corpora from language classes",
            "text": "Some corpora compiled from learner productions in language classes also prove to be suitable for AES tasks. For example, EFCAMDAT (Education First-Cambridge Open Language Database) (Geertzen et al., 2014) has been used in AES to investigate features related to the CEFR scale (Arnold et al., 2018), to classify based on errors (Ballier and Gaillat, 2016) or neural AES models (Kerz et al., 2021). To the best of our knowledge, this is the largest L2 corpus used in AES that does not come from certification exams. EFCAMDAT contains 83 million words from more than 1 million essays written by learners of Education First\u2019s online English school. These essays span 16 levels\ntraceable to the CEFR scale, and the prompts are level-specific (Geertzen et al., 2013).\nAES experiments were also conducted for Spanish on CEDEL2, a learner corpus of more than 1 million words from 4,399 learners of 11 different L1s (Lozano, 2009), for Swedish on the SweLL corpus containing approximately 600 texts (Volodina et al., 2016) and for Japanese on the I-JAS corpus of texts written by 1000 learners of 12 different native languages (Sakoda and Hosoi, 2018). These experiments involve traditional machine learning work with features (del R\u00edo et al., 2016; Pil\u00e1n and Volodina, 2018; Lee and Hasebe, 2020) or deep learning (Lilja, 2018; Ruan, 2020; Hirao et al., 2020a)."
        },
        {
            "heading": "2.2 Learner corpora targeting French",
            "text": "To the best of our knowledge, there are no candidate corpora for French. Most learner corpora targeting French were compiled to study interlanguage5 (Selinker, 1972). They were collected from language courses at university, so the levels represented are mainly intermediate and advanced. The French Interlanguage Database (Granger, 2003) contains 450,000 words. Other corpora designed for interlanguage investigation include the Learner Corpus French (Vanderbauwhede, 2012), containing 500,000 words, and the Chy-FLE/HellasFLE (Valetopoulos and Zaja\u0328c, 2012), containing 150,000 words. The Corpus Interlangue (Gaillat and Roa, 2020), a written/spoken and bilingual corpus, contains texts and interviews from 115 students. The Corpus Ecrit de Fran\u00e7ais Langue Etrang\u00e8re (Granfeldt et al., 2006) approaches learners interlanguage in the language development sequences. It is the only corpus representative of all proficiency levels for French, and it contains 100,000 words. It has been used for AES to find the features most correlated with CEFR levels (Parslow, 2015a). Finally, the French part of the Word Reference Corpus (Berdicevskis, 2020) constitutes the largest learner corpus for French with 4 million words from forum posts on the Word Reference website. It has been used to study contactinduced simplification, but despite its considerable size, it was not used for AES, because it is noisy and text levels have not been evaluated. More information on learner corpora targeting French is presented in Table 6 in Appendix A.\n5Interlanguage describes the unique linguistic organisation developed by a foreign language learner, which presents some features of previously acquired language and may overgeneralize L2 patterns."
        },
        {
            "heading": "3 Corpus compilation",
            "text": ""
        },
        {
            "heading": "3.1 Data collection",
            "text": "TCFLE-8 being a candidate corpus for French, it has been collected by one of the agencies carrying out official certification in L2 French: France Education International (FEI). FEI is a French agency under the supervision of the Ministry of National Education and Youth. With a workforce of over 250 employees and a network of more than 1,000 experts, FEI acts in various fields of cooperation in education and training and contributes to the promotion of the French language and the Frenchspeaking world. FEI offers a wide range of certifications in French aligned with the six CEFR levels: initial diploma in French language (DILF), diploma in French language studies (DELF), diploma in advanced French language studies (DALF) and French knowledge test (TCF). Around 650,000 candidates take one of these examination on an annual base in more than 180 countries.\nAs its name implies, TCFLE-8 is based on the TCF, a linear test aligned with the six CEFR levels. The TCF is used mainly for academic studies, migration purposes and citizenship. Its written component, made up of three independent tasks, is taken annually by 120,000 candidates, 60% of which sit their exam on computer.\nThe correction is performed by professional raters. FEI has a pool of about 100 raters, recruited on occupational profiles (experienced teachers, previous experience for rating with French). Applicant raters take a psychometrically-calibrated rating competence test for writing and attend a twoday training. At the end of this procedure, the recruitment is confirmed or not. To ensure reliability in the long term, reliability indices of raters are assessed annually, and a decision is made regarding whether to retain them in the pool. In addition, to ensure reliability at the candidate level, FEI adopts a double rating approach.6 In case of discrepancy, a third rater is called to independently rate the 3 productions. The final level of the candidate is established based on the frequency of the CEFR levels given to the three candidate\u2019s productions.\nTo identify the CEFR level, the raters use adapted CEFR descriptors and scales. The descriptors (and the rating) are holistic, although each descriptor is aiming at linguistic (organisational), pragmatic and sociolinguistic dimensions and their\n6It has to be mentioned that the rating of the set of the 3 tasks is done by the same rater, thus not being independent.\nrelated criteria. Until now, language test providers used both analytical and holistic scales (HampLyons, 1995). There is no clear consensus on the superiority of one type of scale in terms of reliability and efficiency (Ono et al., 2019).\nLanguage competence is multidimensional (Bachman, 1990; Bachman and Palmer, 2010; Oller and Hinofotis, 1980; Vollmer and Sang, 1983) and is a measurable skill (Vollmer and Caroll, 1983). Measuring writing skill implies considering various facets: candidate proficiency, rater leniency/harshness and difficulty of the task. To this aim, \u201cMany-facet Rasch measurement (MFRM) is a psychometric approach that establishes a coherent framework for drawing reliable, valid, and fair inferences from rater-mediated assessments, thus answering the problem of fallible human ratings\u201d (Eckes, 2009). Therefore, we applied MFRM to the FEI dataset of TCF exams in order to identify and avoid the fallible human ratings in the data set."
        },
        {
            "heading": "3.2 Data cleaning",
            "text": "The original data collected by FEI had to be cleaned at various levels. First, outlier identification consisted in removing candidates\u2019 responses that did not achieve the A1 level, were copies of the prompt, too short/long, or off-topic. Next, we leverage the Rasch information in the dataset to detect texts for which human raters might have failed to provide a reliable judgment. We compared FEI raters\u2019 original scores and the scores adjusted by the Rasch method, using standardized residuals. After an empirical evaluation, we removed all essays with a standardized residual value greater than 4.7 In addition, we also dropped essays with a low confidence assessment (e.g., candidates that are on the borderline between levels). To accomplish this, we removed all cases where both raters disagree with each other and with the candidate\u2019s final score, and we also removed the cases where there is a distance of three CEFR levels between the lowest and the highest ratings. After this process, we set the essay score as the candidate\u2019s CEFR level when at least one of the raters assigned that level to the essay. Alternatively, if both raters agreed with the essay\u2019s score, we duly assigned this level to the essay. Any essay that does not fit any of these two criteria has been removed.\n7In our empirical evaluation, we explored four standardized residue values (2, 3 and 4), observing that around 5.6% of the corpus has a standardized residue of 2, 0.9% has a value of 3 and 0.4% a value of 4.\nAfter outlier removal, the next step was to get a representative sample from the set of TCF essays available. For a fair representation, the level of the text is an obvious variable to control. In addition, we controlled for the language of habitual use8, aiming for a representation of the most frequent languages. As the top five were all European ones and the 6th was Kabyle, a Afro-Asiatic language, we also included Chinese and Japanese to get a better representation of various typological families of languages. Thus, we launched a random sampling controlling for the 6 CEFR levels and the candidate\u2019s language of habitual use. To apply this algorithm, we set up an objective function that approximates the CEFR scores distribution by language. In order to reflect the distribution in the whole dataset, we divided the current language into frequency bands: very frequent (English and Arabic), frequent (Spanish, Kabyle, Portuguese and Russian) and infrequent (Chinese and Japanese) languages. For a description of the resulting corpus see Section 4."
        },
        {
            "heading": "3.3 (Pseudo-)anonymization",
            "text": "Candidates sometimes include personal information in their essays. While this does not pose a problem for the assessment, it can expose candidates when the texts become public. This exposure is generally tackled with anonymization methods (e.g., Wisniewski et al. (2013); Mendes et al. (2016); Tenfjord et al. (2006a); Gablasova et al. (2019); Rakhilina et al. (2016)) or pseudo-anonymization (e.g., (Glaznieks et al., 2020; Preradovic et al., 2015; Rosen et al., 2020; Dirdal et al., 2022)) in the literature on learner corpora. Typically, these processes capture names (e.g., Gablasova et al. (2019); Preradovic et al. (2015); Rosen et al. (2020); Rakhilina et al. (2016)), but sometimes they also capture other information, such as location and date (e.g., Glaznieks et al. (2020); Tenfjord et al. (2006a); Wisniewski et al. (2013) ), geo-data (e.g., Volodina et al. (2019)) and language-specific substitutions (e.g., Wisniewski et al. (2013)). In our work, we decided to provide anonymous and pseudo-anonymous versions of TCFLE-8. The latter is intended to provide a more natural text, but pseudo-anonymization may introduce grammatical errors (e.g., wrong contractions).\nThis work uses the MAPA tool9 (Gianola et al., 8The language of habitual use is the language the candidate\nindicates as the one they usually use. 9https://gitlab.com/MAPA-EU-Project/\n2020) for (pseudo-)anonymization. With this tool, we target 7 entities: names, address (i.e., country, city, building, territory and place), date (i.e., day of week, month, year and day), e-mail, organization, amount and phone. After the pseudoanonymization, we assessed its quality.10 During this process, we noticed some consistent flaws in the tool that were corrected in the corpus to improve its quality. The observed issues consisted of an overanonymization of words at sentence beginnings when predicated by a name, and an omission to replace email addresses."
        },
        {
            "heading": "4 The TCFLE-8 corpus",
            "text": "At the end of the compilation process, the final TCFLE-8 corpus comprises 6,569 essays (581,333 words). Some figures about the corpus size by CEFR levels are shown in Tables 1, 2, 3 and 4. It is expected that beginner-level essays tend to be shorter than the other ones (Frase et al., 1998). Moreover, the extreme levels (A1 and C2) are less represented in the corpus. This might be caused by two factors: (1) few A1-level learners seek an official language exam since this level is rarely sufficient for official purposes (e.g., employment and visa requirements), and (2) reaching the C2 level in a foreign language is extremely difficult.\nTable 2 indicates the number of essays distinguishing the gender. It is interesting to note that about 58% of the sample is composed of women and this proportion is not the same at at each level. Table 3 shows the essays by three tasks in the TCF exam, where there is no general difference between one task and the others. Finally, Table 4 picture the amount of essays in the different languages of habitual use.\n10The evaluation scores are presented in Section B.\nComparing TCFLE-8 to existing corpora (see Table 6 in Appendix A), it is the largest French learner corpus suitable for AES \u2013 both in size and L1 representation \u2013, the third largest candidate corpus to our knowledge and its annotation layers provide the richest information (see Section 4.2). It also covers all 6 CEFR levels."
        },
        {
            "heading": "4.1 Metadata",
            "text": "As a complement to the text of the essays and their CEFR scores, assigned according to the procedure described in Section 3.2, the TCFLE-8 corpus provides information about the candidate who wrote the essay and the essay prompt.\nRegarding the candidates\u2019 information, their gender and language of habitual use are provided. The candidates communicate this information when they register for the TCF exam. Overall, the corpus contains slightly more women than men (58% vs 41%), see Table 2. As for the language of habitual use, the corpus covers 8 languages, as described in Section 3.2: English, Arabic, Spanish, Russian, Portuguese, Kabyle, Chinese, and Japanese, respectively, with 917, 906, 904, 889, 872, 866, 681, and 534 essays (see Table 4.\nThe CEFR level achieved by each candidate considering the three written productions is also reported. This is the official CEFR level assigned to the candidate for the written part of the TCF exam.\nThe Quadratic Weighted Kappa (QWK) between the candidate\u2019s level and the CEFR-level of the essay is 0.98. It is expected that this value should be high, but not equal to 1, due to the cases where candidates cannot maintain a consistent level of essay quality. In addition, the scores assigned by the FEI raters in the double rating procedure are also available. They have a QWK of 0.71 (correlation of 0.93) with each other and 0.84 (correlation of 0.85) with the CEFR-level of the essay.\nFinally, the prompt and its position in the sequence of three TCF tasks are also reported. This information, which relates to the exam, contextualizes the essay\u2019s input and the grading sequence (described in Section 3.1). Regarding the prompt position, it is balanced in TFCFL-8 (32% essays for the first task, 33% for the second, and 35% for the third). Table 3 shows the distribution of the three tasks across the six CEFR levels.11"
        },
        {
            "heading": "4.2 Essay annotation",
            "text": "In addition to the above metada, TCFLE-8 also includes a linguistic annotation layer aimed to describe the learners\u2019 proficiency. This annotation was automatically performed using the FABRA toolkit (Wilkens et al., 2022). It allows computing the distribution of over 400 linguistic variables grouped by family of related variables (e.g., lexical diversity, and lexical frequency). These distributions are aggregated using 18 statistical descriptors, which results in more than 5k annotations per essay. In addition, we extended the existing FABRA features by including others related to SLA. In par-\n11We calculated the correlation \u2013 Spearman for continous variables or Point-biserial for binary variables \u2013 between the CEFR score and the metadata described above to identify possible biases in the scores; all correlations were between 0.038 and 0.09. This analysis confirms that the sampling process did not induce unexpected biases.\nticular, we included the error annotation provided by Language tool12, which includes, among others, the identification of agreement, casing, grammar, typography, punctuation, and typos. We also included pedagogical annotation based on the work of Pintard and Fran\u00e7ois (2020) for extending the CEFR level-related vocabulary. It should be noted that, as the pseudo-anonimzation process may alter text properties, we have chosen to perform this feature extraction on the original essays.\nIn order to better characterize how linguistic properties present in TCFLE-8 are associated with the learners\u2019 proficiency, we computed Spearman\u2019s correlations between each of above feature (gathered by the families in Wilkens et al. (2022)) and the essays\u2019 CEFR level. In the process, we dropped features with correlations lower than 0.4 or pvalues higher than 0.05. Next, as many features are variants of each other, we calculated the correlation matrix within each family to identify redundant features (i.e., an absolute correlation above 0.90). Finally, for each set of similar features, we considered only the one most correlated with the CEFR level. After this procedure, we kept 119 correlated features. In Figure 1, we show their distribution by family of variable.13\nOur analysis of the selected features highlighted linguistic properties of essays already reported in studies investigating foreign language writing. For example, measures of word length have been known to be good predictors of proficiency level for English (Ferris, 1994; Grant and Ginther, 2000), for\n12https://pypi.org/project/ language-tool-python/\n13Table 9 in the appendices presents the list of all correlated features and their correlation values.\nSwedish (Pil\u00e1n and Volodina, 2018), for Japanese (Hirao et al., 2020b) and for French Parslow (2015b). As regards lexicon, diversity measures (e.g. type/token ration) correlate with proficiency in English (Lu, 2012; Vajjala, 2018), whereas sophistication measures based on word frequencies have yielded similar results in a number of studies: more proficient writers use, on average, fewer frequent words (Laufer and Nation, 1995; Attali and Burstein, 2006; Crossley and McNamara, 2012; Guo et al., 2013). Finally, the most discriminating feature in TCFLE-8, namely the error-rate, is also one of the most correlated features to proficiency levels in the CLC-FCE and TOEFL11 (Yannakoudakis et al., 2011; Vajjala, 2018). In addition, while this analysis confirms existing research findings in AES, it also points out that TCFLE-8 may be helpful for new SLA studies. Indeed, we also provided several features explored in other acquisition-related fields, such as the OLD20 (measuring orthographic similarity) (Coltheart et al., 1977; Yarkoni et al., 2008), which are significant in our corpus but had not been linked to L2 writing proficiency so far, to the best of our knowledge."
        },
        {
            "heading": "5 AES for French",
            "text": "In this section, we analyze the applicability of the TCFLE-8 corpus for training AES systems. For this purpose, we explore two approaches: deep learning, since most AES systems relied on neural networks (Ramesh and Sanampudi, 2022), and feature-based machine leaning.\nWe split the anonymized corpus with 80% for training, 10% for validation, and 10% for testing, stratifying by score and language. In addition, to explore the impact of model initialization, we performed 5 repetitions of the training process; in each one, we adjusted the test set so that it does not overlap with the others. We performed a hyperparameter exploration using the accuracy on the validation set.\nFor the deep learning model, we used CamemBERT (Martin et al., 2020), a RoBERTa-based model for French. As for the hyperparameters14, we use a learning rate of 5e-5 and an early stop of 5. For machine learning, we use the XGBoost15 and\n14The hyperparameters search explored 1e-4, 5e-5, 1e-5, 5e-6 and 1e-6 as learning rate, 1, 3, 5, 7 and 10 as early stop patience, searching up to 40 epochs.\n15The hyperparameters used for XGBoost and the values explored are gbtree as booster, alternatively exploring gbtree, gblinear and dart, 0.3 as subsample, from 0.3 and 0.6, 3 as\nlogistic regression16 as a feature-based baseline. These were trained using the 119 features extracted using the method described in Section 4.2. The evaluation of these models is shown in Table 5.\nIn order to characterize human level performance on the task, we report standard AES evaluation metrics for the human raters (column \u201craters\u201d in Table 5), namely accuracy, adjacent accuracy, F1score, and QWK.17 Those metrics were calculated by a direct comparison between the ratings of one of the two evaluators and the reference CEFR levels for each essay. Those results show that the task of identifying the CEFR level of an essay is hard, even for humans. However, the adjacent accuracy of 0.99 clearly shows that the identification gap is typically up to one level. In the same direction, the QWK points out that once the ordinality existing between CEFR levels is considered, the agreement among raters is remarkably strong. As expected, none of our models achieved results competitive with human performance.18\nAmong the AES models explored, the transformer-based CamemBERT achieved the best values. Despite this performance, it can be seen that there is still room for improvement when comparing the results with the evaluation by experts (column raters). Considering that the transformers model performs in a range between raters and XGBoost, it is interesting to remark that the transformers model is closer to the raters\u2019 performance when we consider the ordinality relation between levels (i.e., QWK and AccuracyAdjacent). Focusing on the ability of models to discriminate specific levels, the fine-tuned version of CamemBERT emerged as a model of better performance. Moreover, the logistic model is clearly a weak baseline. Interestingly, at the C2 level, which was the most challenging for all\nmax depth, from 3, 6 and 9, 0 as max delta step, exploring 0, 5 and 10, 1 as min child weight, from 1, 3 and 10, 0.1 as eta, exploring 0.01, 0.1, 0.3, 0.5 and 0.7, 1 as gamma, from 0, 1, 10, lossguide as grow policy, exploring lossguide and depthwise, multi softmax as objective function and 50 estimators.\n16For the logistic regression, we explored the following hyperparameters: penalty from l2 or none, C from 1, 10, 100, max interaction from 100 or 300, and multi class process from multinomial or one-vs-rest. After this short exploration, we set the solver as lbfgs, l2 as the penalty, the C and the max interaction as 100 and 300, and the class processing as one-vs-rest.\n17For a transparent presentation of our results, Appendix C shows the confusion matrices of the transformer-based model.\n18Note that the scores in the \u201craters\u201d column are inflated, because the rating assigned by each rater contributes to the final CEFR score of each essay.\nthree models, XGBoost suffers from a catastrophic failure, achieving even lower performance than the Logistic model. This general weak performance is not entirely surprising, as texts at this level tend to explore language idiosyncrasies, to be precise, to have a very coherent and organized structure, etc. In contrast, the beginner levels (i.e., A1 and A2), for which transformers and XGBoost models had close results, is characterized by texts with simple vocabulary and grammatical structures.19\nAs TCFLE-8 is a new corpus for the French language, we cannot fairly compare our results with previous works, due to the considerable difference in corpus size. In the French AES literature, we identified only two papers focusing on L2 proficiency identification. First, Parslow (2015a), who used a corpus of 200 essays to train a Naive Bayes classifier and reported F1-scores ranging from 0.51 to 0.74 for the levels A1 to B2. Second, Rankovic\u0301 et al. (2020) used CamemBERT intermediate layers as features to predict level in a corpus of 100 essays and reported MSE ranging from 0.35 to 0.55."
        },
        {
            "heading": "6 Final Remarks",
            "text": "In this work, we presented TCFLE-8, a corpus of 6,569 candidates\u2019 essays written during the French knowledge test (TCF), with 8 different languages of habitual use. This paper described the data gathering by France Education International (FEI), data cleaning, anonymization, and annotation performed to compile this corpus, which is the largest French corpus targeting French as a foreign language for AES. This corpus, along with its metadata (i.e., essays, metadata and annotation) is available to the community. We also described the learners\u2019 proficiency in the corpus using numerous linguistic variables related to SLA. This description confirms that these linguistic features could capture developmental patterns in TCFLE-8 in a similar fashion to other learner corpora.\nExploring TCFLE-8 for AES, we applied different machine learning algorithms. CamemBERT appears to be more accurate and XGBoost, a featurebased model, achieved similar results at beginner level. This raises a question about what features should explored for better describing the intermediate and advanced levels. Interestingly, part of this answer may come from the transformer model\n19We compared the results of training the models on the anonymized corpus with the corresponding models trained on the original corpus (before anonymization) and no statistical difference was identified.\nitself (e.g. through a probing approach (Tenney et al., 2019)).\nFinally, TCFLE-8 was portrayed in this paper as a corpus for French AES but its properties allow for different applications in NLP, SLA and educational studies. It may be a valuable corpus for pedagogical material development, whether they be dictionaries (Longman, 2002), activities focusing on common learner difficulties and errors (Kaszubski, 1998; Reppen, 2010), computer-assisted language learning software (Granger, 2003) or L2 writing aids (Link et al., 2014). Activities of data-driven learning in language class (Friginal, 2018) could also take advantage of this corpus. With 8 different languages of habitual use, this corpus could also be beneficial for cross-linguistic studies such as transfer mechanisms and L1 influence on L2 production (Golden et al., 2017; Werner et al., 2020), and for automatic native language identification (Tetreault et al., 2013). Another possible application for this new corpus is the one of errors detection and correction (Dahlmeier et al., 2013), that we are currently investigating as future work on TCFLE-8."
        },
        {
            "heading": "7 Limitations",
            "text": "Several normalization steps were applied in order to develop a coherent corpus for AES, aiming to compile a high quality corpus illustrating the proficiency levels with learner productions on which professional raters would agree. As a consequence, some potentially interesting cases were removed. This concerns for example texts on the borderline between two levels. Although they are interesting cases as they could support studies on understanding of the level boundaries, we opted for a corpus that represents the texts of each level. TCFLE-8\nis a corpus designed for supporting the research in French as a foreign language, including AES. In this work, the focus is on the corpus compilation. Despite the initial tests performed here, our goal does not include an exhaustive verification of the corpus\u2019 applications nor an evaluation of various AES approaches. Finally, we do not intent nor recommend using TCFLE-8 for a fully-automated evaluation environment but to improve writing assessment in French as a foreign language."
        },
        {
            "heading": "Acknowledgements",
            "text": "This research has been funded by the Fonds de la Recherche Scientifique de Belgique (F.R.S.-FNRS) under the grant MIS/PGY F.4518.21 and by a research convention with France \u00c9ducation International. Computational resources have been provided by the Consortium des \u00c9quipements de Calcul Intensif (C\u00c9CI), funded by the Fonds de la Recherche Scientifique de Belgique (F.R.S.-FNRS) under Grant No. 2.5020.11 and by the Walloon Region"
        },
        {
            "heading": "A Description of the learner and candidate corpora",
            "text": "Table 6 in this appendix provides a summary of candidate corpora collected from L2 certification exams and learner corpora targeting French for a comparison with TCFLE-8."
        },
        {
            "heading": "B (Pseudo-)anonymization",
            "text": "For (pseudo-)anonymization, we start by applying the MAPA tool in the entire corpus. Next, we followed Volodina et al. (2019) by selecting 200 random texts and evaluating them manually to assess MAPA\u2019s output. In addition, we controlled the same amount of text from each level because different levels can affect the system differently. However, contrarily to Volodina et al. (2019), we also evaluate whether anonymization is appropriate. The reason for this stricter approach was to measuring the of distorting caused by the (pseudo-)anonymization step.\nThe MAPA\u2019s evaluation was carried out by two independent French native speaker. Each one evaluated 100 essays. Later, a third evaluator double-checked the 200 essays searching for inconsistencies, which were fixed after discussion with the other evaluators. During this assessment, we identify standard errors. These errors, described in Section 3.3, were automatically corrected after we identified their patterns of occurrence.\nThe results of this evaluation is shown in Table 7. The first observation is about the ability to fully identify an entity where MAPA presents difficulty. However, we point out that partial anonymization is already considered correct. In addition, a small number of errors are caused by the entity type, as exemplified by the close scores in the partial matching columns in the table, where the only distinction is the consideration of the entity and span or just the span. In this evaluation, we highlight two scores: accuracy and F2. The first takes into account the words that have been correctly identified as nonanonymized. The second, on the other hand, is a variation of the F-score where recall receives a greater weight. F2 represents the interest of coverage but without a significant loss in precision. Given the difference between these scores, and the recall and precision values, we notice that MAP tends to overdo, identifying more terms than needed for anonymization. Although the anonymization method generates an abundance of edits in the text, it ensures quality in the process and in the protection of the privacy of the writers."
        },
        {
            "heading": "C Confusion matrices of transformer-based AES model",
            "text": "Table 8 shows the results for each of the 5 repetitions (see Section 5) of the AES model based on transformers (column CamemBert in Table 5).\nC.1 Correlated features In this section, we list the features identified by the feature selection method presented in Section 4.2. Table 9 list as features and their correlations, while Figure 2 plots the distribution of some feature across the six CEFR levels.\n(a) Average number of syllables per word\n(b) Average ratio of affixes (c) Squared type/token ration\n(d) 1st quartile of Words in FLELex resource for A1 CEFR level (e) Average of A1 level lemmas according to (Pintard and Fran\u00e7ois, 2020) (f) Average errors automatically identified by Language Tool\n(g) Average of the mean orthographic Levenstein distance (based on Lexique3) (h) Average number of surface form words in the top 1000 words of Lexique3 (i) Word probability, based on Lexique3\nFigure 2: Violin plot of some of the top correlated features through the 6 CEFR levels"
        }
    ],
    "title": "TCFLE-8: a Corpus of Learner Written Productions for French as a Foreign Language and its Application to Automated Essay Scoring",
    "year": 2023
}