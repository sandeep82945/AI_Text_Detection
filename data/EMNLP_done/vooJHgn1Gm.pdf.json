{
    "abstractText": "In this paper, we address the hallucination problem commonly found in natural language generation tasks. Language models often generate fluent and convincing content but lack consistency with the provided source, resulting in potential inaccuracies. We propose a new decoding method called Fidelity-Enriched Contrastive Search (FECS), which augments the Contrastive Search framework with contextaware regularization terms. FECS promotes tokens that are semantically similar to the provided source while penalizing repetitiveness in the generated text. We demonstrate its effectiveness across two tasks prone to hallucination: abstractive summarization and dialogue generation. Results show that FECS consistently enhances faithfulness across various language model sizes while maintaining output diversity comparable to well-performing decoding algorithms.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Wei-Lin Chen"
        },
        {
            "affiliations": [],
            "name": "Cheng-Kuang Wu"
        },
        {
            "affiliations": [],
            "name": "Hsin-Hsi Chen"
        },
        {
            "affiliations": [],
            "name": "Chung-Chi Chen"
        }
    ],
    "id": "SP:68594456a3dab1092712e610e60bf6d8024e92e1",
    "references": [
        {
            "authors": [
                "Rahul Aralikatte",
                "Shashi Narayan",
                "Joshua Maynez",
                "Sascha Rothe",
                "Ryan McDonald."
            ],
            "title": "Focus attention: Promoting faithfulness and diversity in summarization",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Lin-",
            "year": 2021
        },
        {
            "authors": [
                "Sourya Basu",
                "Govardana Sachitanandam Ramachandran",
                "Nitish Shirish Keskar",
                "Lav R Varshney."
            ],
            "title": "Mirostat: A neural text decoding algorithm that directly controls perplexity",
            "venue": "arXiv preprint arXiv:2007.14966.",
            "year": 2020
        },
        {
            "authors": [
                "Sid Black",
                "Leo Gao",
                "Phil Wang",
                "Connor Leahy",
                "Stella Biderman."
            ],
            "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with MeshTensorflow",
            "venue": "If you use this software, please cite it using these metadata.",
            "year": 2021
        },
        {
            "authors": [
                "Meng Cao",
                "Yue Dong",
                "Jiapeng Wu",
                "Jackie Chi Kit Cheung."
            ],
            "title": "Factual error correction for abstractive summarization models",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6251\u20136258,",
            "year": 2020
        },
        {
            "authors": [
                "Shuyang Cao",
                "Lu Wang."
            ],
            "title": "CLIFF: Contrastive learning for improving faithfulness and factuality in abstractive summarization",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 6633\u20136649, Online and",
            "year": 2021
        },
        {
            "authors": [
                "Ziqiang Cao",
                "Furu Wei",
                "Wenjie Li",
                "Sujian Li."
            ],
            "title": "Faithful to the original: Fact aware neural abstractive summarization",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 32.",
            "year": 2018
        },
        {
            "authors": [
                "Sihao Chen",
                "Fan Zhang",
                "Kazoo Sone",
                "Dan Roth."
            ],
            "title": "Improving faithfulness in abstractive summarization with contrast candidate generation and selection",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for",
            "year": 2021
        },
        {
            "authors": [
                "Emily Dinan",
                "Stephen Roller",
                "Kurt Shuster",
                "Angela Fan",
                "Michael Auli",
                "Jason Weston."
            ],
            "title": "Wizard of wikipedia: Knowledge-powered conversational agents",
            "venue": "arXiv preprint arXiv:1811.01241.",
            "year": 2018
        },
        {
            "authors": [
                "Yue Dong",
                "Shuohang Wang",
                "Zhe Gan",
                "Yu Cheng",
                "Jackie Chi Kit Cheung",
                "Jingjing Liu."
            ],
            "title": "Multifact correction in abstractive text summarization",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
            "year": 2020
        },
        {
            "authors": [
                "Esin Durmus",
                "He He",
                "Mona Diab."
            ],
            "title": "FEQA: A question answering evaluation framework for faithfulness assessment in abstractive summarization",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5055\u2013",
            "year": 2020
        },
        {
            "authors": [
                "Nouha Dziri",
                "Andrea Madotto",
                "Osmar Za\u00efane",
                "Avishek Joey Bose."
            ],
            "title": "Neural path hunter: Reducing hallucination in dialogue systems via path grounding",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Process-",
            "year": 2021
        },
        {
            "authors": [
                "Angela Fan",
                "Mike Lewis",
                "Yann Dauphin."
            ],
            "title": "Hierarchical neural story generation",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 889\u2013898, Melbourne, Australia. Association",
            "year": 2018
        },
        {
            "authors": [
                "Katja Filippova."
            ],
            "title": "Controlled hallucinations: Learning to generate faithfully from noisy data",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 864\u2013870, Online. Association for Computational Linguistics.",
            "year": 2020
        },
        {
            "authors": [
                "Ari Holtzman",
                "Jan Buys",
                "Li Du",
                "Maxwell Forbes",
                "Yejin Choi."
            ],
            "title": "The curious case of neural text degeneration",
            "venue": "arXiv preprint arXiv:1904.09751.",
            "year": 2019
        },
        {
            "authors": [
                "Or Honovich",
                "Leshem Choshen",
                "Roee Aharoni",
                "Ella Neeman",
                "Idan Szpektor",
                "Omri Abend."
            ],
            "title": "q2: Evaluating factual consistency in knowledgegrounded dialogues via question generation and question answering",
            "venue": "Proceedings of the 2021 Confer-",
            "year": 2021
        },
        {
            "authors": [
                "Luyang Huang",
                "Lingfei Wu",
                "Lu Wang."
            ],
            "title": "Knowledge graph-augmented abstractive summarization with semantic-driven cloze reward",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5094\u20135107, On-",
            "year": 2020
        },
        {
            "authors": [
                "Ziwei Ji",
                "Nayeon Lee",
                "Rita Frieske",
                "Tiezheng Yu",
                "Dan Su",
                "Yan Xu",
                "Etsuko Ishii",
                "Ye Jin Bang",
                "Andrea Madotto",
                "Pascale Fung."
            ],
            "title": "Survey of hallucination in natural language generation",
            "venue": "ACM Computing Surveys, 55(12):1\u201338.",
            "year": 2023
        },
        {
            "authors": [
                "Philipp Koehn",
                "Rebecca Knowles."
            ],
            "title": "Six challenges for neural machine translation",
            "venue": "Proceedings of the First Workshop on Neural Machine Translation, pages 28\u201339, Vancouver. Association for Computational Linguistics.",
            "year": 2017
        },
        {
            "authors": [
                "Chenliang Li",
                "Bin Bi",
                "Ming Yan",
                "Wei Wang",
                "Songfang Huang."
            ],
            "title": "Addressing semantic drift in generative question answering with auxiliary extraction",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th",
            "year": 2021
        },
        {
            "authors": [
                "Jiwei Li",
                "Michel Galley",
                "Chris Brockett",
                "Jianfeng Gao",
                "Bill Dolan."
            ],
            "title": "A diversity-promoting objective function for neural conversation models",
            "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-",
            "year": 2016
        },
        {
            "authors": [
                "Chin-Yew Lin."
            ],
            "title": "ROUGE: A package for automatic evaluation of summaries",
            "venue": "Text Summarization Branches Out, pages 74\u201381, Barcelona, Spain. Association for Computational Linguistics.",
            "year": 2004
        },
        {
            "authors": [
                "Andrea Madotto",
                "Zhaojiang Lin",
                "Genta Indra Winata",
                "Pascale Fung."
            ],
            "title": "Few-shot bot: Promptbased learning for dialogue systems",
            "venue": "arXiv preprint arXiv:2110.08118.",
            "year": 2021
        },
        {
            "authors": [
                "Joshua Maynez",
                "Shashi Narayan",
                "Bernd Bohnet",
                "Ryan McDonald."
            ],
            "title": "On faithfulness and factuality in abstractive summarization",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for",
            "year": 2020
        },
        {
            "authors": [
                "Ramesh Nallapati",
                "Bowen Zhou",
                "Cicero dos Santos",
                "\u00c7a\u011flar Gul\u00e7ehre",
                "Bing Xiang."
            ],
            "title": "Abstractive text summarization using sequence-to-sequence RNNs and beyond",
            "venue": "Proceedings of the 20th SIGNLL Conference on Computational Natural Lan-",
            "year": 2016
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311\u2013318, Philadelphia,",
            "year": 2002
        },
        {
            "authors": [
                "Vikas Raunak",
                "Arul Menezes",
                "Marcin JunczysDowmunt."
            ],
            "title": "The curious case of hallucinations in neural machine translation",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics:",
            "year": 2021
        },
        {
            "authors": [
                "Anna Rohrbach",
                "Lisa Anne Hendricks",
                "Kaylee Burns",
                "Trevor Darrell",
                "Kate Saenko."
            ],
            "title": "Object hallucination in image captioning",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4035\u20134045, Brussels,",
            "year": 2018
        },
        {
            "authors": [
                "Kurt Shuster",
                "Spencer Poff",
                "Moya Chen",
                "Douwe Kiela",
                "Jason Weston."
            ],
            "title": "Retrieval augmentation reduces hallucination in conversation",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3784\u20133803, Punta Cana, Do-",
            "year": 2021
        },
        {
            "authors": [
                "Yixuan Su",
                "Nigel Collier."
            ],
            "title": "Contrastive search is what you need for neural text generation",
            "venue": "Transactions on Machine Learning Research.",
            "year": 2023
        },
        {
            "authors": [
                "Yixuan Su",
                "Tian Lan",
                "Yan Wang",
                "Dani Yogatama",
                "Lingpeng Kong",
                "Nigel Collier."
            ],
            "title": "A contrastive framework for neural text generation",
            "venue": "Advances in Neural Information Processing Systems.",
            "year": 2022
        },
        {
            "authors": [
                "Ben Wang",
                "Aran Komatsuzaki"
            ],
            "title": "Gpt-j-6b: A 6 billion parameter autoregressive language model",
            "year": 2021
        },
        {
            "authors": [
                "Hongmin Wang."
            ],
            "title": "Revisiting challenges in data-totext generation with fact grounding",
            "venue": "Proceedings of the 12th International Conference on Natural Language Generation, pages 311\u2013322, Tokyo, Japan. Association for Computational Linguistics.",
            "year": 2019
        },
        {
            "authors": [
                "Sean Welleck",
                "Ilia Kulikov",
                "Stephen Roller",
                "Emily Dinan",
                "Kyunghyun Cho",
                "Jason Weston."
            ],
            "title": "Neural text generation with unlikelihood training",
            "venue": "arXiv preprint arXiv:1908.04319.",
            "year": 2019
        },
        {
            "authors": [
                "Green Eggs",
                "Ham"
            ],
            "title": "As of 2016, the book has sold 8 million copies worldwide. System replies: It has sold 8 million copies",
            "year": 2016
        },
        {
            "authors": [
                "System: Yes",
                "I do"
            ],
            "title": "Have you heard of Neil Brooks. He is a sprint freestyle swimmer that won the 100 m medley relay at the 1980 Olympics in Moscow User: I have never heard of him but he sounds like he was a very good swimmer",
            "year": 1980
        },
        {
            "authors": [],
            "title": "born June 30, 1985) is an American retired competitive swimmer and the most successful and most decorated Olympian of all time, with a total of 28 medals. System replies: Yes, another good swimmer is Michael",
            "year": 1985
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Language models (LMs) have achieved remarkable success in generating human-like text, fostering advancements across numerous Natural Language Processing (NLP) applications. Despite the fluent and seemingly convincing outputs produced by LMs, these models can occasionally generate content that is factually inconsistent with the provided source (Koehn and Knowles, 2017; Rohrbach et al., 2018; Raunak et al., 2021), an issue known as the hallucination problem (Maynez et al., 2020; Ji et al., 2023). Methods to mitigate hallucination have been explored from various facets, including data perspectives (Wang, 2019; Filippova, 2020; Shuster et al., 2021), model architectures (Cao et al., 2018; Aralikatte et al., 2021; Xiao and Wang, 2021), and training strategies (Huang et al., 2020; Chen et al., 2021; Li et al., 2021). In this work, we\n*Work done during an internship at AIST. 1https://github.com/ntunlplab/FECS\nturn to a less investigated lens\u2014decoding\u2014to improve faithfulness,2 and introduces a novel decoding method named Fidelity-Enriched Contrastive Search (FECS).\nDecoding algorithms can be categorized into deterministic and stochastic groups. Deterministic methods such as beam search and greedy decoding aim to generate the most probable text continuations. While these methods might appear to be less unfaithful, they are often degenerated. That is, the outputs are uninformative, monotonous, or repetitive (Li et al., 2016; Holtzman et al., 2019; Welleck et al., 2019). Conversely, stochastic methods such as top-k (Fan et al., 2018) and nucleus sampling (Holtzman et al., 2019) inject randomness into the generation process, thereby promoting the diversity. Yet, these sampling-based approaches often come at the cost of coherency and semantic consistency (Basu et al., 2020; Su et al., 2022; Su and Collier, 2023), where increasing the output diversity positively correlates with hallucinating (Dziri\n2We follow (Ji et al., 2023) and refer to faithfulness as an antonym to hallucination, i.e., maximizing faithfulness equals minimizing hallucination.\net al., 2021). To reconcile this faithfulness-diversity trade-off, we proposed FECS\u2014a simple yet effective decoding strategy which extends the Contrastive Search framework (Su et al., 2022) and introduces context-aware regularization terms to enhance faithfulness and penalize degeneration. Specifically, a candidate token which exhibits (1) a great semantic similarity with tokens from the provided source and (2) a low semantic similarity with previously generated tokens is rewarded with a higher score to promote its selection. Importantly, FECS can be readily applied to existing LMs offthe-shelf, without requiring further training.\nWe evaluate FECS on two tasks particularly prone to text hallucination: abstractive summarization and dialogue generation (Ji et al., 2023). Experimental results show that FECS consistently improves faithfulness across various LM sizes while preserving a level of diversity comparable to predominant decoding algorithms."
        },
        {
            "heading": "2 Methodology",
            "text": "In this section, we present preliminary information on Contrastive Search (Su et al., 2022) before detailing our proposed FECS."
        },
        {
            "heading": "2.1 Preliminary",
            "text": "To address shortcomings in existing decoding methods, Su et al. (2022) propose Contrastive Search, a new decoding approach capable of generating diverse content without compromising coherency. At time step t, given an input x0:c+t, where x0:c signifies the prefix context and xc:c+t represents the previously generated tokens, Contrastive Search generates the next token xc+t via the following formula:\nxc+t = argmax v\u2208V (k)\n{ (1\u2212 \u03b1)\u00d7 p\u03b8(v|x0:c+t)\ufe38 \ufe37\ufe37 \ufe38\nmodel confidence\n\u2212 \u03b1\u00d7 max c\u2264j\u2264c+t\u22121\n{ sim(hv, hxj ) } \ufe38 \ufe37\ufe37 \ufe38\ndegeneration penalty\n}\nHere, V k denotes a set of k candidate tokens with the top-k probability from the model\u2019s prediction distribution p\u03b8(\u00b7|x0:c+t). The model confidence term represents the probability of the candidate token v, while the degeneration penalty term signifies the maximum value of the cosine similarity sim(\u00b7, \u00b7) between candidate token v and all previously generated tokens {xc, ..., xc+t\u22121}.\nSpecifically, sim(\u00b7, \u00b7) employs the token representation hxi and hv from the model\u2019s last hidden state, calculated by appending v to x0:c+t as model input. \u03b1 serves as a pre-determined, nonnegative hyper-parameter; when \u03b1 equals 0, Contrastive Search reduces to greedy decoding. Essentially, Contrastive Search preserves coherence by choosing outputs from the top-k probable candidates while also curbing degeneration behaviors such as repetitions, thereby promoting diversity."
        },
        {
            "heading": "2.2 Fidelity-Enriched Contrastive Search",
            "text": "Motivated by Contrastive Search, we extend this framework by integrating a faithfulness term that encourages factuality and reduces hallucination. Using the notations from Section 2.1, we define FECS as follows:\nConsider an input x0:c+t at time step t, where x0:c represents the prefix context, and xc:c+t is the previously generated tokens. We further decompose x0:c into: (1) the prompts x0:s, and (2) the provided source xs:c, which the output is expected to remain faithful to. FECS generates the next token xc+t via the following formula:\nxc+t = argmax v\u2208V (k)\n{ (1\u2212 \u03b1\u2212 \u03b2)\u00d7 p\u03b8(v|x0:c+t)\ufe38 \ufe37\ufe37 \ufe38\nmodel confidence\n\u2212 \u03b1\u00d7 max c\u2264i\u2264c+t\u22121\n{ sim(hv, hxi) } \ufe38 \ufe37\ufe37 \ufe38\ndegeneration penalty\n+ \u03b2 \u00d7 max s\u2264j\u2264c\u22121\n{ sim(hv, hxj ) } \ufe38 \ufe37\ufe37 \ufe38\nfaithfulness reward\n}\nThe newly introduced faithfulness term rewards candidate tokens exhibiting high semantic similarity to tokens in the source content. Specifically, the faithfulness term denotes the maximum value of the cosine similarity sim(\u00b7, \u00b7) between the candidate token v and all source tokens {xs, ..., xc\u22121}. Here, \u03b2 is also a pre-determined, non-negative hyperparameter."
        },
        {
            "heading": "3 Experimental Setup",
            "text": ""
        },
        {
            "heading": "3.1 Datasets, Models, and Configurations",
            "text": "We evaluate our method, FECS, on two tasks known for their susceptibility to hallucination issues: abstractive summarization and dialogue generation. For the abstractive summarization task, we adopt CNN-DailyMail (CNN-DM) dataset (Nallapati et al., 2016), a widely-used benchmark in\nseveral recent studies (Dong et al., 2020; Cao and Wang, 2021; Cao et al., 2020). The dialogue generation task employs the popular Wizard of Wikipedia (WoW) dataset (Dinan et al., 2018). The objective here is to generate responses based on given knowledge snippets, taken from Wikipedia, that are pertinent to the conversation topic.\nIn our experiments involving abstractive summarization, we adopt OPT (Zhang et al., 2022) with three scales: 1.3B, 2.7B, and 6.7B. For dialogue generation, we follow the Few-Shot Bot approach (Madotto et al., 2021), using GPT-Neo 1.3B and 2.7B (Black et al., 2021), along with GPT-J 6B (Wang and Komatsuzaki, 2021). All experiments are conducted with few-shot prompting, using two shots.3 We compare FECS with Contrastive Search, Greedy Decoding, Beam Search, and Nucleus Sampling. For Beam Search, we set the beam size to 4; for Nucleus Sampling, p = 0.95; and for Contrastive Search, (k, \u03b1) = (4, 0.6). For FECS, we retain the same \u03b1 value as Contrastive Search, setting (k, \u03b1, \u03b2) = (4, 0.3, 0.3) without hyper-parameter tuning."
        },
        {
            "heading": "3.2 Evaluation Metrics",
            "text": "Our evaluation process employs the following metrics:\nStandard Metrics. For assessing the quality of summarization, we employ ROUGE (Lin, 2004). For dialogue generation, we use ROUGE-L and\n3Detailed examples of prompts and additional configuration information can be found in Appendix A.\nBLEU-4 (Papineni et al., 2002). In addition, we also report BERTScore (Zhang et al., 2019) on both tasks for a more advanced soft metric.\nFaithfulness Metrics. To measure factuality in summarization, we use FEQA (Durmus et al., 2020) following prior studies (Aralikatte et al., 2021; Chen et al., 2021). Higher FEQA scores indicate greater faithfulness of the summary to the source article. For evaluating dialogue, we employ Q2 (Honovich et al., 2021), a question-answering (QA) based metric designed for assessing factual consistency in knowledge-grounded dialogue generation. Both FEQA and Q2 exhibit strong correlations with human judgments.\nDiversity Metric. For both summarization and dialogue tasks, we evaluate the diversity of the generated text x by calculating\ndiversity(x) = 4\u220f\nn=2\n(1.0\u2212 Rep-n(x) 100 )\nwhere Rep-n(x) measures the proportion of n-gram repetitions in x, and is calculated as\nRep-n(x) = (1\u2212 |unique-n-gram(x)| |total-n-gram(x)| )\u00d7 100\nA higher diversity score suggests the model outputs exhibit less degeneration (Welleck et al., 2019; Su et al., 2022).\nCNN-DailyMail. Text highlighted in green indicates factual information; red indicates hallucination not supported by the article."
        },
        {
            "heading": "4 Experimental Results",
            "text": ""
        },
        {
            "heading": "4.1 Faithfulness",
            "text": "Table 1 presents the results for abstractive summarization and dialogue generation. For abstractive summarization, FECS achieves substantial improvements on the factuality score across all scales, with 7.14%, 7.37%, and 9.55% increases for the 1.3B, 2.7B, and 6.7B models, respectively. Moreover, FECS records strong results in the ROUGE score and outperforms all other methods at the 6.7B scale. For dialogue generation, on the 1.3B scale, all stochastic algorithms, including FECS, fall short of Beam Search in most metrics. However, FECS surpasses other stochastic algorithms in terms of BLEU-4 and Q2. Upon scaling up to 2.7B and 6B, FECS outperforms all methods substantially in terms of BLEU-4, ROUGE-L, and Q2. Notably, the 6B model performs worse than its smaller counterparts, consistent with previous findings (Madotto et al., 2021).\nCompared to Contrastive Search, FECS exhibits a superior ability to focus on entities within the source material, emphasizing factual information more comprehensively. As evident in Figure 2, FECS provides more complete information\u2014comparing \u201cJamaican starlet DeShane Beckford\u201d versus \u201cDeShane Beckford\u201d\u2014and generates output more comprehensively, evidenced by Contrastive Search\u2019s failure to produce the time phrase \u201cearlier this month\". Furthermore, when factual en-\ntities are already present in the previous output, the degeneration penalty can inadvertently increase hallucinations. For instance, the term \u201cUpton Park\u201d produced by Contrastive Search lacks support from the source, whereas the correct output should be the previously generated \u201cWest Ham\u201d. In this case, FECS accurately reproduces \u201cWest Ham\u201d. Building on the framework of Contrastive Search, FECS not only inherits its properties of coherency and diversity (avoidance of degeneration) but also fosters the utilization of tokens that faithfully represent the provided source content."
        },
        {
            "heading": "4.2 Diversity",
            "text": "As we discussed in Section 1, model outputs must balance faithfulness and diversity. To better understand the impact of our proposed faithfulness reward on these two facets in the context of the original Contrastive Search, we calculated the improvements in faithfulness and the reductions in diversity based on the results from both the proposed FECS and the Contrastive Search.4 Table 3 presents these evaluations. With the CNNDailyMail dataset, FECS notably enhances faithfulness while marginally affecting diversity. Especially when the model size exceeds 2.7B, the decrease in diversity ranges only from 0.2% to 1.1%. These findings suggest that FECS successfully negotiates the faithfulness-diversity trade-off in abstractive summarization. Contrastingly, in the Wizard of Wikipedia dataset, FECS shows greater improvements in faithfulness and lesser reductions in diversity as the model size increases. Specifically, when the model size reaches 6.7B, FECS demonstrates a 63.62% improvement in faithfulness and experiences a mere 3.3% decrease in diversity. This implies that FECS performs more effectively when larger LMs are employed in dialogue generation tasks.\n4The raw results and full evaluation for other decoding methods are provided in Table 6."
        },
        {
            "heading": "4.3 Analysis",
            "text": "Latency. To assess the decoding latency of our proposed FECS objective, we report the average decoding time (sec) per instance in Table 4. The results are averaged across 100 randomly selected instances. As observed in both the dialogue generation and abstractive summarization tasks, FECS and Contrastive Search perform comparably and slightly slower than beam search. Greedy and nucleus are the fastest.\nThe role of \u03b1. To establish a more comprehensive baseline, we evaluate FECS against Contrastive Search with different values of \u03b1 on the 6.7B model. Intuitively, a smaller \u03b1 value (i.e., a lower degree of diversity) might contribute to a more factual performance. However, as shown in Table 5 lowering \u03b1 only improves faithfulness marginally and with essentially the same rouge scores. On the contrary, FECS retains a high level of diversity and achieves superior performance on both FEQA and standard metrics, indicating the effectiveness of our newly introduced \u03b2 term."
        },
        {
            "heading": "5 Human Evaluation",
            "text": "In addition to the automatic evaluation, we also perform human evaluation to assess the faithfulness of our proposed FECS on the abstractive summarization task. We compare FECS against Contrastive Search, and ask annotators to vote which response is considered more faithful to the provided source (i.e., the text to be summarized). Specifically, we randomly sample 20 instance for each of the three model sizes, with a total of 60 instances for the evaluation. More details including the full evaluation protocol are provided in Appendix A.2. We present the results in Figure 2. As observed, FECS shows superior results, recording more than 60% of the votes, and outperforms Contrastive Search with more than twice the votes. The results support\nthe outcome of automatic evaluation, suggesting our proposed FECS is able to generated contents which are more faithful to the provided source."
        },
        {
            "heading": "6 Conclusion",
            "text": "This paper introduces a novel decoding approach, Fidelity-Enriched Contrastive Search (FECS), designed to enhance faithfulness in text generation. Our experimental results on abstractive summarization and dialogue generation demonstrated the efficacy of FECS. It consistently improved faithfulness across various LM scales while preserving a level of diversity that is comparable to other leading decoding algorithms. Particularly when using larger LMs, it notably enhances faithfulness with only a minor impact on diversity. This indicates that FECS performs effectively when larger LMs are employed in dialogue generation tasks. In the future, we plan to explore how FECS performs with different kinds of source content, including erroneous or ambiguous inputs.\nLimitations\nFirstly, while FECS presents an improvement in faithfulness and diversity trade-off, its performance\ncould be influenced by the quality of the source content. The assumption that source content is always correct and complete may not hold true in all scenarios, particularly in cases where the input data is ambiguous, incomplete, or erroneous. Secondly, the faithfulness assessment is primarily quantitative, based on FEQA and Q2 established metrics. Although these metrics provide an essential standard for comparing models, they may not capture all nuanced aspects of faithfulness, such as the preservation of subtle implications or subjective information."
        },
        {
            "heading": "Acknowledgments",
            "text": "We thank the reviewers for their insightful comments. This research was supported by JSPS KAKENHI Grant Number 23K16956 and a project JPNP20006, commissioned by the New Energy and Industrial Technology Development Organization (NEDO). This work was also partially supported by National Science and Technology Council, Taiwan, under grants MOST 110-2221-E-002-128-MY3, 110-2634-F-002-050-, and NSTC 111-2634-F-002023-, and Ministry of Education (MOE) in Taiwan, under grants NTU-112L900901."
        }
    ],
    "title": "Fidelity-Enriched Contrastive Search: Reconciling the Faithfulness-Diversity Trade-Off in Text Generation",
    "year": 2023
}