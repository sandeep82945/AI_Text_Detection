{
    "abstractText": "The ability to identify important entities in a text, known as Named Entity Recognition (NER), is useful in a large variety of downstream tasks in the biomedical domain. This is a considerably difficult task when working with Consumer Health Questions (CHQs), which consist of informal language used in day-to-day life by patients. These difficulties are amplified in the case of Bengali, which allows for a huge amount of flexibility in sentence structures and has significant variances in regional dialects. Unfortunately, the complexity of the language is not accurately reflected in the limited amount of available data, which makes it difficult to build a reliable decision-making system. To address the scarcity of data, this paper presents \u2018Bangla-HealthNER\u2019, a comprehensive dataset designed to identify named entities in healthrelated texts in the Bengali language. It consists of 31,783 samples sourced from a popular online public health platform, which allows it to capture the diverse range of linguistic styles and dialects used by native speakers from various regions in their day-to-day lives. The insight into this diversity in language will prove useful to any medical decision-making systems that are developed for use in real-world applications. To highlight the difficulty of the dataset, it has been benchmarked on state-ofthe-art token classification models, where BanglishBERT achieved the highest performance with an F1-score of 56.13 \u00b1 0.75%. The dataset and all relevant code used in this work have been made publicly available1.",
    "authors": [
        {
            "affiliations": [],
            "name": "Alvi Aveen Khan"
        },
        {
            "affiliations": [],
            "name": "Fida Kamal"
        },
        {
            "affiliations": [],
            "name": "Nuzhat Nower"
        },
        {
            "affiliations": [],
            "name": "Tasnim Ahmed"
        },
        {
            "affiliations": [],
            "name": "Sabbir Ahmed"
        },
        {
            "affiliations": [],
            "name": "Tareque Mohmud Chowdhury"
        }
    ],
    "id": "SP:2235ff96d65ec2373fe9ab5520b4170de09d0aa7",
    "references": [
        {
            "authors": [
                "Askell"
            ],
            "title": "Language models are few-shot",
            "year": 2020
        },
        {
            "authors": [
                "Khan"
            ],
            "title": "Towards bangla named entity",
            "year": 2018
        },
        {
            "authors": [
                "IEEE. Jacob Cohen"
            ],
            "title": "A coefficient of agreement",
            "year": 1960
        },
        {
            "authors": [
                "Kristina Toutanova"
            ],
            "title": "2019. Bert: Pre-training",
            "year": 2019
        },
        {
            "authors": [
                "Md. Zahidul Haque",
                "Sakib Zaman",
                "Jillur Rahman Saurav",
                "Summit Haque",
                "Md. Saiful Islam",
                "Mohammad Ruhul Amin."
            ],
            "title": "B-ner: A novel bangla named entity recognition dataset with largest entities and its baseline evaluation",
            "venue": "IEEE Access, 11:45194\u2013",
            "year": 2023
        },
        {
            "authors": [
                "Tanvir Islam",
                "Sakila Mahbin Zinat",
                "Shamima Sukhi",
                "Zakir Hossain Zamil",
                "Aynur Nahar",
                "MF Mridha."
            ],
            "title": "An attention-based medical ner in the bengali language",
            "venue": "Proceedings of 2nd International Conference on Artificial Intelligence: Advances and Ap-",
            "year": 2022
        },
        {
            "authors": [
                "Israt Jahan",
                "Md Tahmid Rahman Laskar",
                "Chun Peng",
                "Jimmy Huang."
            ],
            "title": "Evaluation of chatgpt on biomedical tasks: A zero-shot comparison with fine-tuned generative transformers",
            "venue": "arXiv preprint arXiv:2306.04504.",
            "year": 2023
        },
        {
            "authors": [
                "Mohsinul Kabir",
                "Tasnim Ahmed",
                "Md Bakhtiar Hasan",
                "Md Tahmid Rahman Laskar",
                "Tarun Kumar Joarder",
                "Hasan Mahmud",
                "Kamrul Hasan."
            ],
            "title": "Deptweet: A typology for social media texts to detect depression severities",
            "venue": "Computers in Human Be-",
            "year": 2023
        },
        {
            "authors": [
                "Lo\u00efc Lannelongue",
                "Jason Grealey",
                "Michael Inouye."
            ],
            "title": "Green algorithms: quantifying the carbon footprint of computation",
            "venue": "Advanced science, 8(12):2100707.",
            "year": 2021
        },
        {
            "authors": [
                "Jiao Li",
                "Yueping Sun",
                "Robin J Johnson",
                "Daniela Sciaky",
                "Chih-Hsuan Wei",
                "Robert Leaman",
                "Allan Peter Davis",
                "Carolyn J Mattingly",
                "Thomas C Wiegers",
                "Zhiyong Lu"
            ],
            "title": "Biocreative v cdr task corpus: a resource for chemical disease relation extraction",
            "year": 2016
        },
        {
            "authors": [
                "Amit Mishra",
                "Sanjay Kumar Jain."
            ],
            "title": "A survey on question answering systems with classification",
            "venue": "Journal of King Saud University-Computer and Information Sciences, 28(3):345\u2013361.",
            "year": 2016
        },
        {
            "authors": [
                "Vasuki Nadapana",
                "Hima Bindu Kommanti."
            ],
            "title": "Investigating the role of named entity recognition in question answering models",
            "venue": "IEEE 3rd Global Conference for Advancement in Technology (GCAT), pages 1\u20137.",
            "year": 2022
        },
        {
            "authors": [
                "Salim Sazzed."
            ],
            "title": "Banglabiomed: A biomedical named-entity annotated corpus for bangla (bengali)",
            "venue": "Proceedings of the 21st Workshop on Biomedical Language Processing, pages 323\u2013329.",
            "year": 2022
        },
        {
            "authors": [
                "Syed Mohammad Shahed."
            ],
            "title": "Bengali folk rhymes: An introduction",
            "venue": "Asian folklore studies, pages 143\u2013 160.",
            "year": 1993
        },
        {
            "authors": [
                "H.A.Z. Sameen Shahgir",
                "Ramisa Alam",
                "Md. Zarif Ul Alam."
            ],
            "title": "Banglaconer: Towards robust bangla complex named entity recognition",
            "venue": "ArXiv, abs/2303.09306.",
            "year": 2023
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "A fundamental component of nearly all automated Question Answering (QA) systems is a Named Entity Recognition (NER) model (Nadapana and Kommanti, 2022; Aliod et al., 2006). To accu-\n1https://github.com/alvi-khan/ Bangla-HealthNER\nrately answer a question, the system must be capable of identifying important entities in the text. This is even more critical when addressing healthrelated queries from the general public, known as Consumer Health Questions (CHQs). CHQs are often difficult to answer due to the informal language used (Mishra and Jain, 2016), and most patients only provide a vague description of their issues. This presents a unique challenge to current systems, most of which were developed for use with medical documents that use formal language and concrete scientific terms to describe health issues (Carini et al., 2021). Being able to extract the correct medical knowledge required to answer the question from the vague descriptions containing unstandardized medical terms used by the general public is a challenging task.\nThe difficulties described are further exacerbated in the Bengali language, which poses greater challenges compared to English for several reasons. Bengali allows for a significantly larger number of inflections, with 220 inflections existing in total compared to just 9 for English (Bhattacharya et al., 2005). This forces the models to learn a large number of words that are nearly identical but have slightly different meanings. For example, in the sentence \u2018I have fallen ill\u2019, the verb \u2018fallen\u2019 remains unchanged even if the subject is changed to \u2018You\u2019 or \u2018She\u2019. In Bengali, however, the same sentence (\u2018\u0986\u09bf\u09ae \u0985\u09b8\u09c1 \u09b9\u09c7\u09df \u09aa\u09c7\u09dc\u09bf\u099b\u0964\u2019) will change the verb depending on the subject: \u2018\u09aa\u09c7\u09dc\u09bf\u099b\u2019 for the first person, \u2018\u09aa\u09c7\u09dc\u09c7\u099b\u09be\u2019 for the second-person, and \u2018\u09aa\u09c7\u09dc\u09c7\u099b\u2019 for the third-person. There is also greater flexibility regarding sentence structuring. Whereas the order of words is relatively rigid in English, and breaking the order makes sentences grammatically incorrect, the same is not true for Bengali. For example, \u2018I have a headache\u2019 is correct in English, but \u2018headache have I\u2019 sounds odd and is unlikely to be used. However, the Bengali versions of these sentences (\u2018\u0986\u09ae\u09be\u09b0 \u09ae\u09be\u09a5\u09be \u09ac\u09af\u09cd\u09a5\u09be\u2019 and \u2018\u09ae\u09be\u09a5\u09be \u09ac\u09af\u09cd\u09a5\u09be \u0986\u09ae\u09be\u09b0\u2019 re-\nspectively) are both correct and commonly used. Furthermore, there is a large amount of diversity in the language as there are numerous dialects that are so significantly different from each other that people from one region are often entirely unable to comprehend the language of another (Shahed, 1993). These attributes make Bengali an incredibly complex language with a huge amount of variation and intricacies.\nUnfortunately, the amount of data available for Bengali, especially in a medical context, is severely limited and fails to reflect the complex nature of the language. This makes it challenging to create a system that accurately understands the language in the context of CHQs. To address this issue, we present \u2018Bangla-HealthNER\u2019, the largest human-annotated Bengali medical NER dataset comprising 31,783 samples. The data has been collected from a public online health platform in Bangladesh, ensuring that it accurately captures the variety and complexity of the language used by native Bengali speakers in their dayto-day lives. The samples also consist of a large amount of text that combines Bengali and English, using words from both languages or transliterating words from one language using alphabets from the other, a common occurrence in informal conversations known as \u2018code-switching\u2019. The large variety in language present in the dataset should allow models to gain a thorough understanding of medical terminology in informal contexts."
        },
        {
            "heading": "2 Literature Review",
            "text": "Although there is a significant amount of data available for general Bengali NER (Haque et al., 2023; Chowdhury et al., 2018; Shahgir et al., 2023), the availability of data specifically tailored for Bengali medical NER remains limited. Currently, there are two datasets publicly available: one introduced by Islam et al. (2022), which we will be referring to in this paper as the \u2018Telemedicine Dataset\u2019, and the \u2018BanglaBioMed\u2019 dataset (Sazzed, 2022). Both of these datasets have relatively small sizes, with the Telemedicine dataset consisting of 190 samples and nine entity labels and BanglaBioMed consisting of 1100 sentences and four entity labels. This makes the datasets unsuitable for modern transformer-based architectures, which rely on large amounts of data for effective learning. Additionally, the data for both datasets were collected from sources that use\nformal language, differing greatly from the language people use in their day-to-day speech. The telemedicine dataset was compiled by manually transcribing telephone conversations with patients, while BanglaBioMed was created by extracting text from health articles published in a popular national newspaper.\nThe small dataset sizes combined with their formal nature means that systems trained on the existing datasets will be unable to perform well in real-world use cases. The introduction of BanglaHealthNER addresses both of these limitations since it is larger in size and also accommodates much more variety in language."
        },
        {
            "heading": "3 The Bangla-HealthNER Dataset",
            "text": ""
        },
        {
            "heading": "3.1 Data Collection",
            "text": "The dataset was collected from a popular Bengali online medical health platform2, which provides publicly available health-related queries from users as well as answers by medical professionals. Both the questions and answers were collected and are considered as separate samples in the dataset. Samples were collected via random sampling in order to obtain an unbiased representation of the data. An overview of various metrics for the dataset and the different entities is presented in Table 1 and Fig. 1, respectively. Compared to existing datasets, Bangla-HealthNER not only has significantly more samples but also much longer samples, which mostly consist of multiple sentences. Lengthier training data will force systems to learn to retain contextual information for longer distances to be able to accurately identify entities."
        },
        {
            "heading": "3.2 Pre-Processing",
            "text": "The dataset was first cleaned by removing duplicate entries, URLs, and spam text. Afterwards, personally identifiable information was removed.\n2https://daktarbhai.com/\nNames were removed with the help of a general Bengali NER model3, followed by manual inspection, and email addresses and phone numbers were removed using regular expressions."
        },
        {
            "heading": "3.3 Annotation",
            "text": "The dataset was annotated using an open-source annotation tool4 by a team of 20 undergraduate students with at least a higher secondary level of formal education in biology. They were provided with extensive guidelines to follow during the an-\n3https://pypi.org/project/bnlp-toolkit 4https://github.com/tecoholic/ner-annotator/\nnotation process, the details of which are provided in Appendix A.2. The annotations follow the Inside-Outside-Bagging (IOB) format with nonoverlapping entities and consist of seven types of entities as described in Table 2. Five percent of the samples given to the annotators were taken from a pre-annotated subset of the dataset and were used to calculate the Inter-Annotator Agreement (IAA). The guidelines, entity definitions, and preannotated data were all carefully prepared by the authors after extensively studying several works related to the domain (Li et al., 2016; Sazzed, 2022; Bodenreider, 2004). The quality of the fi-\nNon Entity Symptom Health Condition Age Medicine Dosage Medical Procedure\nSpecialist 0.70\n0.75\n0.80\n0.85\n0.90 0.95 F1 -S co re (% ) 0.93545\n0.748917\n0.809993\n0.895019\n0.948888\n0.836722\n0.937678 0.926978\nFigure 2: Average IAA F1-Score (non-weighted) per entity type\nnal dataset was also ensured by following the work of Kabir et al. (2023). The average weighted F1-score for IAA was found to be 88.56%, and the average Cohen\u2019s Kappa score (Cohen, 1960) was found to be 67.19% (substantial agreement). An entity-wise breakdown of the average IAA F1Score is provided in Fig. 2.\nThe annotation process revealed certain issues with the existing tagging formats used for NER tasks. For example, consider the phrase \u2018\u09b9\u09be\u09c7\u09a4 \u09a4\u09c0 \u09ac\u09af\u09cd\u09a5\u09be\u2019, which can be translated word-for-word into \u2018arm severe pain\u2019. According to our guidelines, the intensifier word \u2018\u09a4\u09c0 \u2019 should not be considered part of the symptom so that the accurate tags would be [B-Symptom, O, I-Symptom]. Unfortunately, the IOB format does not allow a single entity to be split into two parts in this manner. This issue does not occur in English datasets since adjectives nearly always come before or after nouns in the English language, which is why the word-for-word translation is not grammatically correct. The grammatically correct version of this phrase, \u2018severe arm pain\u2019, would have the tags [O, B-Symptom, I-Symptom]. As a consequence of this shortcoming of the tagging format, the annotators were frequently forced to deviate slightly from the guidelines and include the non-entity tokens that appeared in between entity tokens. The issue was particularly pronounced for the \u2018Symptom\u2019 and \u2018Health Condition\u2019 entities since the informal nature of the data meant that patients frequently described issues in a verbose manner.\nIt was also found that there were subtle variations in very similar concepts, which should create challenging situations. For example, the phrase \u2018\u09ae\u09be\u09a5\u09be \u09ac\u09af\u09cd\u09a5\u09be\u09b0 \u0993\u09b7\u09c1\u09a7\u2019 (\u2018headache medicine\u2019) should be tagged as [B-Medicine, I-Medicine, IMedicine] whereas the phrase \u2018\u09ae\u09c7 \u09df\u09be\u09b0 \u0993\u09b7\u09c1\u09a7\u2019 (\u2018Montair medicine\u2019) should be tagged as [B-Medicine,\nO]. This distinction occurs because the name of the medicine, \u2018Montair\u2019, in the second case implies that it is a medicine, thus making the word \u2018medicine\u2019 redundant, unlike in the first case. Similarly, the phrase \u2018\u09a8\u09be\u0995 \u0995\u09be\u09a8 \u0997\u09b2\u09be \u09a1\u09be \u09be\u09b0\u2019 (\u2018ENT Doctor\u2019) which should be tagged as [B-Specialist, ISpecialist, I-Specialist, I-Specialist] but the phrase \u2018\u09a8\u09be\u0995 \u0995\u09be\u09a8 \u0997\u09b2\u09be \u09bf\u09ac\u09c7\u09b6\u09b7\u099c\u09cd\u099e \u09a1\u09be \u09be\u09b0\u2019 (\u2018ENT Specialist Doctor\u2019) should be tagged as [B-Specialist, ISpecialist, I-Specialist, I-Specialist, O]. Again, the word \u2018doctor\u2019 in the second case is redundant since it is implied by the words \u2018ENT Specialist\u2019."
        },
        {
            "heading": "4 Benchmarking",
            "text": "To establish a benchmark, the dataset was fine-tuned on three token classification modelsBanglaBERT (Bhattacharjee et al., 2022), BanglishBERT (Bhattacharjee et al., 2022), and mBERT (Devlin et al., 2019). Aside from this, to analyze the performance of large language models on Bengali medical NER, we also included the inference results of zero-shot ChatGPT (gpt-3.5turbo, accessed June 2023) (Brown et al., 2020).\nFor the benchmarking process, the dataset was divided into training, validation, and test splits using the ratio 80 : 10 : 10. Further details about the experimental setup are provided in Appendix A.1, and Table 3 provides the results of our experiments. The scores for the evaluation metrics are calculated at the token level and are averaged across multiple runs except in the case of GPT 3.5.\nBoth BanglaBERT and BanglishBERT outperformed the mBERT model, which reinforces the understanding that models pre-trained on a specific language achieve better performance on downstream tasks than multilingual ones. BanglishBERT achieved the highest scores, likely due to the presence of text that combines Bangla and English in the dataset.\nThe GPT 3.5 model was not fine-tuned on our dataset but was given prompts to assign labels to each word in the test samples. Past literature studying the performance of ChatGPT on downstream tasks related to bio-medicine without fine-tuning found that domain-specific models achieve significantly better results, even if expert prompting is used (Jahan et al., 2023). Our results agree with this conclusion, as all the fine-tuned models outperform zero-shot ChatGPT by a large margin.\nA thorough error analysis of the predictions of the fine-tuned models reveals that the expected\nchallenging situations discussed in section 3.3 did indeed cause issues. The models seemed to have difficulty understanding subtle differences in similar concepts. For example, a large number of the responses to questions concluded with advice to visit a specialist, such as \u2018\u098f\u0995\u099c\u09a8 \u098f.\u098f\u09a8.\u09bf\u099f. \u09bf\u09ac\u09c7\u09b6\u09b7\u099c\u09cd\u099e \u09c7\u09a6\u0996\u09be\u09a8\u0964\u2019 (\u2018Please visit an E.N.T. specialist.\u2019). It was observed that samples that concluded slightly differently, such as \u2018\u09ac\u09be\u09b0\u09c7\u09a1\u09ae \u09b9\u09be\u09b8\u09aa\u09be\u09a4\u09be\u09c7\u09b2\u09b0 \u09bf\u09b6\u09b6\u09c1 \u09bf\u09ac\u09ad\u09be\u09c7\u0997 \u09c7\u09af\u09be\u0997\u09be\u09c7\u09af\u09be\u0997 \u0995\u09b0\u09c1\u09a8\u0964\u2019 (\u2018Please contact the children\u2019s unit of BIRDEM Hospital\u2019) resulted in the models marking incorrect phrases, \u2018children\u2019s unit\u2019 in this case, with the label \u2018Specialist\u2019. Similar issues were also seen with the \u2018Age\u2019 class, where the models marked any mention of time in years, such as \u2018\u09e9 \u09ac\u099b\u09b0\u0986\u09c7\u0997 \u09b9\u09be\u09a4 \u09c7\u09ad\u09c7\u0999 \u09bf\u0997\u09c7\u09df\u09bf\u099b\u09c7\u09b2\u09be\u0964\u2019 (\u2018My arm broke 3 years ago\u2019) with the label \u2018Age\u2019. This was most likely caused by the majority of such mentions in the dataset genuinely being the patient\u2019s age."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this paper, we introduced a manually annotated Bengali Named Entity Recognition dataset of health-related texts. The paper highlights several key features of the dataset, including its ability to capture the linguistic diversity and complexity of the Bengali language, as well as its emphasis on the informal nature of speech used by the average patient in medical contexts. We evaluated the dataset on Bengali and multilingual token classification models to establish a benchmark and further explored the performance of the large language model GPT 3.5 on the dataset. Given that the dataset introduces significant variety in language to the domain compared to existing data, architectures trained on past data struggled to perform well. This opens up a new direction for future work, which can concentrate on exploring methods to improve this performance.\nThe research and data presented in this paper have implications that extend beyond the domain of NER in CHQs. The challenges addressed, such as dealing with informal language, complex\nsentence structures, and regional dialects, are observed in various downstream tasks, meaning our findings can be generalized to broader contexts and applications. The dataset can also be leveraged to achieve cross-domain adaptability in fields such as social media, customer reviews, and online forums, where users communicate using colloquial and unstructured language. The proposed insights also have cross-linguistic transferability to other Indo-Aryan languages with similar linguistic characteristics. This could prove beneficial in developing NER models for languages with limited labelled data. The adaptability of NER as a feature can facilitate automated clinical decisionmaking systems as well.\nLimitations One limitation that caused notable difficulties during the annotation process was the shortcomings of the tagging format used, as discussed in section 3.3. Despite our extensive guidelines, the unstructured nature of the Bengali language resulted in our annotators being forced to mark words that separated a single multi-word entity as part of the entity due to the limitations of the tagging format. This inevitably had a negative effect on the finetuning process. Working towards establishing a tagging format that addresses these limitations and fixing the annotations of this dataset accordingly is likely to lead to improved performance.\nEthics Statement The privacy of the patients of the health platform was a top priority during the data collection process. As such, the data was de-identified through manual inspection to ensure the removal of all personal information. All of the annotation work was undertaken either by the authors themselves or by hired individuals. The annotators were provided with monetary compensation for their work, which is above the minimum wage. The annotation process has also been de-identified to prevent any privacy violations of the annotators."
        },
        {
            "heading": "Acknowledgements",
            "text": "The funding for this research was provided by the Islamic University of Technology (IUT) under the IUT Research Seed Grants (IUT RSG). We are grateful for their support."
        },
        {
            "heading": "A Appendix",
            "text": "A.1 Experiment Setup The experiments done to establish our benchmark results were run on an Nvidia 3090 GPU with 24 GB of VRAM using the Trainer library available through Hugging Face and Cuda Version 11.6. The dataset was split into training, validation, and test sets at the ratio 80 : 10 : 10 and trained for 25 epochs on each of the models. A batch size of 128 was used along with an AdamW optimizer, a linear learning rate scheduler, cross-entropy loss, 40% dropout, and a weight decay of 3e-2. A learning rate of 1e-4 was used with the first 20% of the training steps being used for warm-up. The use of Gradient Checkpointing additionally allowed us to use a maximum token length of 512.\nIn the course of our experiments, we also attempted to calculate an estimate of our carbon footprint. We did this by following the work of Lannelongue et al. (2021). It was found that each run of the experiments under our hardware setup generated approximately 331.17 grams, 222.68 grams, and 216.97 grams of CO2 for the mBERT, BanglaBERT, and BanglishBERT models respectively. It is interesting to see that the models that achieved comparatively better results in our experiments, BanglaBERT and BanglishBERT, also have a smaller impact on CO2 emissions.\nA.2 Annotation Guidelines In addition to the basic instruction of labelling each word in the samples with one of the seven entity labels, the annotators were provided with extensive instructions on how to address a large variety of different scenarios that were seen to arise. These instructions are provided below. The colour code used for the examples is as follows: Symptom, Health Condition, Age, Medicine, Dosage, Medical Procedure, Specialist.\n1. Entities should be annotated as specifically as possible. If an entity contains a sub-entity, the top-level entity should be annotated. Example: \u0997\u09a4 \u09ea \u09bf\u09a6\u09a8 \u09a7\u09c7\u09b0 \u09ae\u09be\u09a5\u09be\u09ac\u09af\u09cd\u09a5\u09be X \u0997\u09a4 \u09ea \u09bf\u09a6\u09a8 \u09a7\u09c7\u09b0 \u09ae\u09be\u09a5\u09be\u09ac\u09af\u09cd\u09a5\u09be\u2713 2. A single entity should not be divided into two parts, even if this requires including some unnecessary information. Example: \u0986\u09ae\u09be\u09b0 \u09ae\u09be\u09a5\u09be \u0997\u09a4 \u09e8 \u09bf\u09a6\u09a8 \u09a7\u09c7\u09b0 \u0985 \u09c7\u09ac\u09a5\u09be \u0995\u09b0\u09c7\u099b\u0964 X \u0986\u09ae\u09be\u09b0 \u09ae\u09be\u09a5\u09be \u0997\u09a4 \u09e8 \u09bf\u09a6\u09a8 \u09a7\u09c7\u09b0 \u0985 \u09c7\u09ac\u09a5\u09be \u0995\u09b0\u09c7\u099b\u0964\u2713\n3. Symptoms are indicators of a health condition. A health condition is a specific disease or medical event. Example: \u09be\u09df \u09b8\u09ae\u09df \u09ae\u09be\u09a5\u09be\u09ac\u09af\u09cd\u09a5\u09be \u09b9\u09df\n\u09b8\u09be\u0987\u09a8\u09c1\u09b8\u09be\u0987\u09bf\u099f\u09b8 \u09b9\u09c7\u09a4 \u09aa\u09be\u09c7\u09b0 \u09b9\u09be\u099f\u09b0\u09cd \u098f\u099f\u09be\u0995 \u09b9\u09c7\u09df\u09c7\u099b\n4. Injuries are considered health conditions. Example: \u0986\u09ae\u09be\u09b0 \u09aa\u09be \u09ae\u099a\u09c7\u0995 \u09c7\u0997\u09c7\u099b 5. Unnecessary information, such as the severity of a symptom, should not be annotated. Example: \u09ae\u09c1\u09c7\u0996 \u09a3 \u0989\u09c7\u09a0 \u0985\u09c7\u09a8\u0995 \u09c7\u09ac\u09bf\u09b6 X \u09ae\u09c1\u09c7\u0996 \u09a3 \u0989\u09c7\u09a0 \u0985\u09c7\u09a8\u0995 \u09c7\u09ac\u09bf\u09b6\u2713 6. Redundant information (such as the word \u2018\u09a1\u09be \u09be\u09b0\u2019 following the word \u2018\u09bf\u09ac\u09c7\u09b6\u09b7\u099c\u09cd\u099e\u2019) should not be annotated. Example: \u09ae\u09be\u09a5\u09be \u09c7\u09ac\u09a5\u09be\u09b0 \u0993\u09b7\u09c1\u09a7\u0964 \u09ae\u09c7 \u09df\u09be\u09b0 \u0993\u09b7\u09c1\u09a7\u0964 \u09a8\u09be\u0995, \u0995\u09be\u09a8, \u0997\u09b2\u09be \u09a1\u09be \u09be\u09b0\u0964 \u09a8\u09be\u0995, \u0995\u09be\u09a8, \u0997\u09b2\u09be \u09bf\u09ac\u09c7\u09b6\u09b7\u099c\u09cd\u099e \u09a1\u09be \u09be\u09b0\u0964 7. It is important to pay attention to contextual information when identifying entities. For example, the term \u2018Corona\u2019 can be used to describe both the COVID-19 disease and the COVID-19 pandemic in Bengali. Example: \u0995\u09c7\u09b0\u09be\u09a8\u09be \u099a\u09b2\u09be\u0995\u09be\u09b2\u09c0\u09a8 \u09a1\u09be \u09be\u09b0 \u09c7\u09a6\u0996\u09c7\u09a4 \u09aa\u09be\u09b0\u09bf\u099b \u09a8\u09be\u0964 X \u098f\u0997\u09c1\u09b2\u09be \u09bf\u0995 \u09c7\u0995\u09be\u09c7\u09b0\u09be\u09a8\u09be\u09b0 \u09b2\u0995\u09cd\u09b7\u09a3? \u2713 8. Multiple symptoms mentioned together should be annotated separately. Example: bad cold and fever X bad cold and fever \u2713 9. Medicine names can include the amount of chemical in each intake. Example: \u09c7\u09ae\u09be\u09a8\u09be\u09b8 \u09e7\u09e6 \u09bf\u09ae \u09be \u0996\u09be\u09a8 X \u09c7\u09ae\u09be\u09a8\u09be\u09b8 \u09e7\u09e6 \u09bf\u09ae \u09be \u0996\u09be\u09a8\u2713 10. Doctors frequently write the dosage in the format \u20180+1+1\u2019. Example: \u09c7\u09ae\u09be\u09a8\u09be\u09b8 \u09e7\u09e6 \u09bf\u09ae \u09be 0+0+1 11. Medical specialists typically have uniquely identifiable names (e.g., \u0997\u09be\u0987\u09c7\u09a8\u09c7\u0995\u09be\u09b2\u09bf\u099c ) but are sometimes referred to by more generic names (e.g., \u0997\u09be\u0987\u09bf\u09a8\u09b0 \u09a1\u09be \u09be\u09b0). Example: \u098f\u0995\u099c\u09a8 \u09c7\u09ae\u09bf\u09a1\u09bf\u09b8\u09c7\u09a8\u09b0 \u09a1\u09be \u09be\u09b0 \u09c7\u09a6\u0996\u09be\u09a8"
        }
    ],
    "title": "NERvous About My Health: Constructing a Bengali Medical Named Entity Recognition Dataset",
    "year": 2023
}