{
    "abstractText": "Joint entity and relation extraction tasks aim to recognize named entities and extract relations simultaneously. Suffering from a variety of data biases, such as data selection bias, and distribution bias (out of distribution, long-tail distribution), serious concerns can be witnessed to threaten the model\u2019s transferability, robustness, and generalization. In this work, we address the above problems from a causality perspective. We propose a novel causal framework called covariance and variance optimization framework (OVO) to optimize feature representations and conduct general debiasing. In particular, the proposed covariance optimizing (COP) minimizes characterizing features\u2019 covariance for alleviating the selection and distribution bias and enhances feature representation in the feature space. Furthermore, based on the causal backdoor adjustment, we propose variance optimizing (VOP) separates samples in terms of label information and minimizes the variance of each dimension in the feature vectors of the same class label for mitigating the distribution bias further. By applying it to three strong baselines in two widely used datasets, the results demonstrate the effectiveness and generalization of OVO for joint entity and relation extraction tasks. Furthermore, a fine-grained analysis reveals that OVO possesses the capability to mitigate the impact of long-tail distribution. The code is available at https://github.com/HomuraT/OVO.",
    "authors": [
        {
            "affiliations": [],
            "name": "Lin Ren"
        },
        {
            "affiliations": [],
            "name": "Yongbin Liu"
        },
        {
            "affiliations": [],
            "name": "Yixin Cao"
        },
        {
            "affiliations": [],
            "name": "Chunping Ouyang"
        }
    ],
    "id": "SP:8b5036a7cb65699ee5093159b41c79432acf8745",
    "references": [
        {
            "authors": [
                "Elisa Bassignana",
                "Barbara Plank."
            ],
            "title": "Crossre: A cross-domain dataset for relation extraction",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 3592\u20133604.",
            "year": 2022
        },
        {
            "authors": [
                "Iz Beltagy",
                "Kyle Lo",
                "Arman Cohan."
            ],
            "title": "Scibert: A pretrained language model for scientific text",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural",
            "year": 2019
        },
        {
            "authors": [
                "Razvan C. Bunescu",
                "Raymond J. Mooney."
            ],
            "title": "A shortest path dependency kernel for relation extraction",
            "venue": "HLT/EMNLP 2005, Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, Proceed-",
            "year": 2005
        },
        {
            "authors": [
                "Huajun Chen",
                "Ning Hu",
                "Guilin Qi",
                "Haofen Wang",
                "Zhen Bi",
                "Jie Li",
                "Fan Yang."
            ],
            "title": "Openkg chain: A blockchain infrastructure for open knowledge graphs",
            "venue": "Data Intell., 3(2):205\u2013227.",
            "year": 2021
        },
        {
            "authors": [
                "Kristina Toutanova"
            ],
            "title": "2019. BERT: pre-training",
            "year": 2019
        },
        {
            "authors": [
                "Sven Lautenbach"
            ],
            "title": "Collinearity: a review",
            "year": 2013
        },
        {
            "authors": [
                "Kaiming He",
                "Haoqi Fan",
                "Yuxin Wu",
                "Saining Xie",
                "Ross Girshick."
            ],
            "title": "Momentum contrast for unsupervised visual representation learning",
            "venue": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 9726\u20139735.",
            "year": 2020
        },
        {
            "authors": [
                "Shaoxiong Ji",
                "Shirui Pan",
                "Erik Cambria",
                "Pekka Marttinen",
                "Philip S. Yu."
            ],
            "title": "A survey on knowledge graphs: Representation, acquisition, and applications",
            "venue": "IEEE Trans. Neural Networks Learn. Syst., 33(2):494\u2013514.",
            "year": 2022
        },
        {
            "authors": [
                "Zhenzhong Lan",
                "Mingda Chen",
                "Sebastian Goodman",
                "Kevin Gimpel",
                "Piyush Sharma",
                "Radu Soricut."
            ],
            "title": "ALBERT: A lite BERT for self-supervised learning of language representations",
            "venue": "8th International Conference on Learning Representations,",
            "year": 2020
        },
        {
            "authors": [
                "Ying Lin",
                "Heng Ji",
                "Fei Huang",
                "Lingfei Wu."
            ],
            "title": "A joint neural model for information extraction with global features",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7999\u20138009, Online. Association for",
            "year": 2020
        },
        {
            "authors": [
                "Zihan Lin",
                "Changxin Tian",
                "Yupeng Hou",
                "Wayne Xin Zhao."
            ],
            "title": "Improving graph collaborative filtering with neighborhood-enriched contrastive learning",
            "venue": "WWW \u201922: The ACM Web Conference 2022, Virtual Event, Lyon, France, April 25 - 29, 2022, pages 2320\u2013",
            "year": 2022
        },
        {
            "authors": [
                "Yi Luan",
                "Luheng He",
                "Mari Ostendorf",
                "Hannaneh Hajishirzi."
            ],
            "title": "Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Lan-",
            "year": 2018
        },
        {
            "authors": [
                "Yi Luan",
                "Dave Wadden",
                "Luheng He",
                "Amy Shah",
                "Mari Ostendorf",
                "Hannaneh Hajishirzi."
            ],
            "title": "A general framework for information extraction using dynamic span graphs",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Makoto Miwa",
                "Mohit Bansal."
            ],
            "title": "End-to-end relation extraction using lstms on sequences and tree structures",
            "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Vol-",
            "year": 2016
        },
        {
            "authors": [
                "Subhabrata Mukherjee",
                "Ahmed Hassan Awadallah."
            ],
            "title": "Uncertainty-aware self-training for text classification with few labels",
            "venue": "CoRR, abs/2006.15315.",
            "year": 2020
        },
        {
            "authors": [
                "Guoshun Nan",
                "Jiaqi Zeng",
                "Rui Qiao",
                "Zhijiang Guo",
                "Wei Lu."
            ],
            "title": "Uncovering main causalities for longtailed information extraction",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event",
            "year": 2021
        },
        {
            "authors": [
                "Judea Pearl."
            ],
            "title": "Causal diagrams for empirical research",
            "venue": "Biometrika, 82(4):669\u2013688.",
            "year": 1995
        },
        {
            "authors": [
                "Judea Pearl",
                "Madelyn Glymour",
                "Nicholas P Jewell."
            ],
            "title": "Causal inference in statistics: A primer",
            "venue": "John Wiley & Sons.",
            "year": 2016
        },
        {
            "authors": [
                "Lev-Arie Ratinov",
                "Dan Roth."
            ],
            "title": "Design challenges and misconceptions in named entity recognition",
            "venue": "Proceedings of the Thirteenth Conference on Computational Natural Language Learning, CoNLL 2009, Boulder, Colorado, USA, June 4-5, 2009, pages",
            "year": 2009
        },
        {
            "authors": [
                "Farshid Rayhan",
                "Sajid Ahmed",
                "Asif Mahbub",
                "Md. Rafsan Jani",
                "Swakkhar Shatabda",
                "Dewan Md. Farid."
            ],
            "title": "Cusboost: Cluster-based under-sampling with boosting for imbalanced classification",
            "venue": "CoRR, abs/1712.04356.",
            "year": 2017
        },
        {
            "authors": [
                "Santosh Tokala Yaswanth Sri Sai",
                "Prantika Chakraborty",
                "Sudakshina Dutta",
                "Debarshi Kumar Sanyal",
                "Partha Pratim Das."
            ],
            "title": "Joint entity and relation extraction from scientific documents: Role of linguistic information and entity types",
            "venue": "Proceed-",
            "year": 2021
        },
        {
            "authors": [
                "Yuming Shang",
                "Heyan Huang",
                "Xianling Mao."
            ],
            "title": "Onerel: Joint entity and relation extraction with one module in one step",
            "venue": "Thirty-Sixth AAAI Conference on Artificial Intelligence, AAAI 2022, Thirty-Fourth Conference on Innovative Applications of Artificial",
            "year": 2022
        },
        {
            "authors": [
                "Zheyan Shen",
                "Peng Cui",
                "Kun Kuang",
                "Bo Li",
                "Peixuan Chen."
            ],
            "title": "Causally regularized learning with agnostic data selection bias",
            "venue": "2018 ACM Multimedia Conference on Multimedia Conference, MM 2018, Seoul, Republic of Korea, October 22-26, 2018,",
            "year": 2018
        },
        {
            "authors": [
                "Zheyan Shen",
                "Peng Cui",
                "Tong Zhang",
                "Kun Kuang."
            ],
            "title": "Stable learning via sample reweighting",
            "venue": "The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI",
            "year": 2020
        },
        {
            "authors": [
                "David Wadden",
                "Ulme Wennberg",
                "Yi Luan",
                "Hannaneh Hajishirzi."
            ],
            "title": "Entity, relation, and event extraction with contextualized span representations",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the",
            "year": 2019
        },
        {
            "authors": [
                "Yijun Wang",
                "Changzhi Sun",
                "Yuanbin Wu",
                "Hao Zhou",
                "Lei Li",
                "Junchi Yan."
            ],
            "title": "UniRE: A unified label space for entity relation extraction",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International",
            "year": 2021
        },
        {
            "authors": [
                "Yiwei Wang",
                "Muhao Chen",
                "Wenxuan Zhou",
                "Yujun Cai",
                "Yuxuan Liang",
                "Dayiheng Liu",
                "Baosong Yang",
                "Juncheng Liu",
                "Bryan Hooi"
            ],
            "title": "Should we rely on entity mentions for relation extraction? debiasing relation extraction with counterfactual analysis",
            "year": 2022
        },
        {
            "authors": [
                "Deming Ye",
                "Yankai Lin",
                "Peng Li",
                "Maosong Sun."
            ],
            "title": "Packed levitated marker for entity and relation extraction",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland,",
            "year": 2022
        },
        {
            "authors": [
                "Xingxuan Zhang",
                "Peng Cui",
                "Renzhe Xu",
                "Linjun Zhou",
                "Yue He",
                "Zheyan Shen."
            ],
            "title": "Deep stable learning for out-of-distribution generalization",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021, pages",
            "year": 2021
        },
        {
            "authors": [
                "Zexuan Zhong",
                "Danqi Chen."
            ],
            "title": "A frustratingly easy approach for entity and relation extraction",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Named Entity Recognition (NER, (Ratinov and Roth, 2009)) and Relation Extraction (RE, (Bunescu and Mooney, 2005)) are both the key fundamental tasks of Information Extraction and both significant predecessor tasks for building knowledge graphs that are used widely in daily life (Chen et al., 2021; Ji et al., 2022; Du et al., 2022a). There are two major methods to extract the final result.\n\u2217Corresponding Author.\nOne is to build a separate model (pipeline) to get the result in one step (Shang et al., 2022), and the other is to use multiple models (joint) to extract entities and relations in turn (Zhong and Chen, 2021; Ye et al., 2022).\nSuffering from various biases in data, such as data selection bias, out-of-distribution, and longtail distribution (Lin et al., 2022; Wang et al., 2022), models may learn spurious correlations and make erroneous predictions. Although we would like to be able to obtain a uniform (or unbiased) data set, such a dataset is almost nonexistent in real applications. Various biases are always mixed up in real scenarios, for example, selected data in a way that differs from the target population (data selection bias), training and testing data distribution shift (out-of-distribution), the labels with numerous samples may have more chances to inference (long-tail distribution lead to predicting majority bias), and some of the data biases are even unknown. Because statistical correlation is the basis of supervised learning algorithms, the learning algorithms may learn many spurious correlations due to these biases. Finally, this leads to a greatly re-\nduced predictive ability of the models. As shown in Fig. 1 (left), there are different degrees of the data bias of long-tail distribution in SciERC (Luan et al., 2018), which is common for other datasets as well, making models focus more on the labels with numerous samples and performing poorly on the others (fewer chances to the labels with few samples).\nIn recent years, debiasing has become a significant research focus. There are different ways to address the data bias by reweighting samples (Dixon et al., 2018; Rayhan et al., 2017; Wang et al., 2022). These methods focus on the reweights in the sample space and ignore spurious correlations due to data selection bias. Recently, stable learning (Shen et al., 2018, 2020; Zhang et al., 2021) proposed serial ways to de-bias the spurious correlation to find the causal effect of each input feature on the basis of the correlation. Specifically, these methods require extensive calculation resources to identify causality and focus solely on causal effects between features. Additionally, they fail to consider the causal effects for each feature dimension within the same class label.\nIn this work, we introduce a method called the covariance and variance optimization framework (OVO), to optimize the feature vectors from two aspects, decorrelating between features and each feature dimension of the same class label. Our contributions can be summarized as follows:\n\u2022 From decorrelating between features, inspired by stable learning, we use covariance as the confounder degree of features and try to minimize it in each batch of every epoch to learn the causality between features and targets. We minimize the covariance to reduce the collinearity of each feature, get the causal effects, alleviate the data selection and distribution biases, and enhance feature representation. We call this method covariance optimizing (COP).\n\u2022 From feature dimensions of the same class label, according to the variance of each dimension, using the intervention of causal inference (Pearl et al., 2016), it can eliminate the confounding bias from the backdoor path by blocking F \u2190 L\u2192 P as the causal graph shown in Fig.2, so that model can learn the causality from the causal path F \u2192 P . We explore the causal correlation between the fea-\nture dimensions of the same label and the outcome targets and mitigate the long-tail distribution bias further. We call this method variance optimizing (VOP).\n\u2022 We combine COP and VOP as OVO. To access the effectiveness of OVO, we conduct experiments on the joint entity and relation extraction task. By applying OVO to 3 strong baselines, we observe significant improvements in the performance of this task, which demonstrates the effectiveness and generalization of our proposed method. These results suggest that optimizing feature representation directly is actually an effective way to get improvement and reduce the bias from datasets without model redesigning, and OVO is a feasible framework in this way."
        },
        {
            "heading": "2 Related Work",
            "text": "Stable Learning aims to research how to reduce the agnostic data selection bias and model misspecification problem and make the feature more causal by reweighting samples. CRLR (Shen et al., 2018) proposes an equation to evaluate the degree of confounders called Causal Regularized Logistic Regression and gains the optimal weight by minimizing the confounder. SRDO (Shen et al., 2020) considers the smallest feature of the covariance matrix as the degree of confounder. StableNet (Zhang et al., 2021) adopts stable learning technology into image classification tasks using deep learning models and the results show the strong domain adaptation of the proposed models.\nSpan-level NER and RE Models are the approaches using the boundaries of spans as a total feature to recognize the entities and the relation\nbetween two entities. DyGIE++ (Wadden et al., 2019) and SpERT.PL (Sai et al., 2021) extract features of spans and share them between NER and RE tasks. PURE (Zhong and Chen, 2021) uses two separate span models to recognize entities and relations without interaction with each other and proposed levitated markers to reinforce the boundaries information of spans. PL-Marker (Ye et al., 2022) proposes neighborhood-oriented packing and subject-oriented packing methods to leverage the levitated markers.\nVariance and Covariance are two important metrics in deep learning. In confidence learning (Mukherjee and Awadallah, 2020), they are negatively correlated with the confidence of models and samples. Moreover, in active learning (Cohn et al., 1996), they are correlated with generalization error and bias which can be indirectly reduced by minimizing variance or covariance. Recently, IDEAL (Guo et al., 2022) uses variance as one of the measures for the inconsistency of unlabeled samples. In this work, we use them to estimate the feature representation and correlation between features respectively."
        },
        {
            "heading": "3 Method",
            "text": "In this section, we first briefly introduce the general inference process of the joint entity and relation\nextraction methods. Then, we will describe covariance optimizing (COP) and variance optimizing (VOP)."
        },
        {
            "heading": "3.1 Background: Inference Process of Joint Entity and Relation Extraction Methods",
            "text": "In the joint entity and relation extraction task, the goal is to extract both entities and the relations between them from a given text. The general process of this task involves several steps. Firstly, an encoder module is used to transfer pure text to a numerical representation that captures the semantic information. This can be done using techniques like word embeddings or pre-trained language models (PLMs).\nS = w1, w2, . . . , wl H = encoder(S)\n(1)\nWhere wi indicates the i-th word of the given text; l means the length of the text; H \u2208 Rl\u00d7n represents the representation of the text and n is the dimension size.\nFor NER, the encoded representations are passed through an entity extraction module to identify and classify entities in the text. The formulations of span-level methods are as follows:\nf span(i,j) = extractor(H, i, j)\nlabelspan(i,j) = classifier(f span (i,j) )\n(2)\nWhere 0 \u2264 i \u2264 j \u2264 l indicates the boundary of a span; l means the length of the given text; fspan(i,j) is the feature of a span; extractor(\u00b7) is a function to gain the feature of given spans; classifier(\u00b7) is a function to predict the label of spans according to its representation.\nFor RE, H and the spans of identified entities are used to determine the relations between the entities.\nf rel(i,j) = extractor(H, spani, spanj)\nlabelrel(i,j) = classifier(f rel (i,j))\n(3)\nWhere spani is the entity identified by NER; extractor(\u00b7) is a function to acquire the feature of given relations; classifier(\u00b7) is a function to predict the label of relations. In this work, OVO is used to optimize the fspan(i,j) and f rel (i,j) during training."
        },
        {
            "heading": "3.2 Covariance Optimizing",
            "text": "When the features exhibit linear correlations with each other, it can lead to instability in parameter estimation. Consequently, the optimal model becomes uncertain, and the presence of selection and distribution biases is amplified during inference. This phenomenon is called collinearity (Dormann et al., 2013). For example, y = x1 + x2 and y = 100x1 \u2212 98x2 have identical performance if assumption x1 = x2 holds in train datasets, but if x1 = 1.01x2 holds in test datasets, the gaps of them will be huge. Besides collinearity, the correlation between features also poses the same impact in deep learning. One straightforward way to reduce the effect of collinearity and correlation is to analyze them among features and then remove some relevant features. However, due to the inexplicability and excessive number of features in PLMs, this method is difficult to afford.\nThe methods of stable learning (Zhang et al., 2021) show that feature representations will be more causal when giving suitable weights for samples in loss calculating during training. Inspired by this, we propose covariance optimizing (COP) to alleviate the collinearity and correlation between features with low resource consumption, as well as improve the causality of features.\nIn COP, covariance is used to measure the correlation between features, and the target is to acquire suitable weights by minimizing the covariance among all features using gradient descent:\nW\u0302 = argmin W \u2211 i,j,i\u0338=j (cov(WFi,WFj))2 (4)\nWhere F and W mean the feature vectors and weights; W \u2208 Rn is a vector representing all sample weights and n is the number of samples, holding \u2211n i wi = 1 by softmax function. F\ni means the i-th dimension feature of all samples. cov(\u00b7, \u00b7) is the covariance function.\nNext, W\u0302 is used to weigh the loss of the corresponding sample.\nLossCOP = n\u2211\ni=0\nw\u0302i Lossorig(pi, ti) (5)\nWhere w\u0302i \u2208 W\u0302 is the final weight for the i-th sample; pi and ti mean the prediction distribution and real label respectively; Lossorig means the loss employed on the original method.\nHowever, there are two difficulties in performing the above process directly. Firstly, the majority of PLMs have an extensive number of parameters, ranging from hundreds of millions (Devlin et al., 2019) to billions (Du et al., 2022b) and even more, thus the computation of weights for the entire dataset requires significant computational resources, making it expensive and potentially unaffordable during training. Secondly, incorporating features from previous batches or epochs may lead to feature inconsistency due to the continuous evolution of features during training.\nTo overcome the aforementioned difficulties, inspired by MoCo (He et al., 2020), we only compute optimal weights for samples in the current batch, utilizing previous features and weights as additional fixed information. Furthermore, to ensure feature consistency, we discard the earliest features and weights:\nFi = [Fi\u22121[\u230aLFi/(n+ 1)\u230b :],Fcur] Wi = [Wi\u22121[\u230aLWi/(n+ 1)\u230b :],Wcur]\n(6)\nWhere F and W mean the feature vectors and weights; i means the index of the current batch; L\u2217 is the length of \u2217; \u2217cur means feature vectors or weights in the current batch; n is the batch number of feature vectors and weights needed to be saved; \u230a\u00b7\u230b is the floor function; [l :] means to delete first l data.\nTo further mitigate the feature inconsistency, we fuse and emphasize the current information with previous features and weights. Firstly, we randomly sample from Fcur and the corresponding Wcur until the number of samples is the same as\nFi.\nF\u2032cur = [Fcur[R1], . . . ,Fcur[RL]]\nW\u2032cur = [Wcur[R1], . . . ,Wcur[RL]] (7)\nWhere F\u2032cur and W \u2032 cur are the sets after random sampling; L is the length of Fi, Ri is a random integer from 0 to L, and [i] means getting the i-th element. And then, we fuse current information with the previous.\nF\u2032i = \u03b1Fi + (1\u2212 \u03b1)F\u2032cur W\u2032i = \u03b1Wi + (1\u2212 \u03b1)W\u2032cur\n(8)\nWhere \u03b1 is a hyperparameter between [0, 1] regarding how much previous information needs to be saved. Finally, F\u2032i and W \u2032 i will be applied to eq. 4 as W and F. Note that F\u2032i is used to gain the optimal W\u2032i, but only the part of Wcur will be updated and used to weight sample loss.\nTo enhance the applicability of COP, we use a hyperparameter called COP rate to adjust the degree of influence of COP during training. After acquiring the optimal weights, the loss function is as follows:\nw\u0302i \u2032 = (1\u2212 rCOP ) + rCOP \u2217 w\u0302i\nLossCOP = n\u2211\ni=0\nw\u0302i \u2032 Lossorig(pi, ti)\n(9)\nWhere w\u0302i \u2208 W\u0302 is the final weight of the i-th sample; rCOP \u2208 (0, 1] indicates COP rate."
        },
        {
            "heading": "3.3 Variance Optimizing",
            "text": "Inspired by causal intervention (Pearl et al., 2016), we construct a causal graph (Fig. 2) regarding the causality from feature vectors to the final targets. To clarify our objective, in our causal analysis, we focus on the mitigation of bias arising from the long-tail distribution. This bias tends to make labels with a substantial number of samples more readily predictable during the inference process.\nMoreover, the effectiveness of mitigating this bias can be easily quantified.\nAs shown in Fig. 2, F \u2190 L\u2192 P is a backdoor path, a path that connects F and P but does not start with F , from F to P in which F , L, and P are feature vectors, real labels, and model predictions respectively. Thus, the label distribution from the datasets is the confounder between the feature vectors and the final predictions, creating a spurious correlation that disturbs model inference and causes lower performance. For a better understanding of the causal graph, we introduce it as follows: The labels in datasets are the optimizing target of model training (L\u2192 P ) which also takes effect on the feature vector learning (L\u2192 F ). Appendix. A shows more detail of the causal graph.\nIn order to remove the confounder caused by backdoor path F \u2190 L\u2192 P and make the model learn direct causality between feature vectors and predictions, we introduce do-operator (Pearl et al., 2016) on feature vectors F to gain the causality of F on P called p(P |do(F )). As shown in Fig. 4 right, through do-operator, the edge causing confounder, F \u2190 L \u2192 P , is blocked, so that the spurious correlation has been removed.\nBackdoor adjustment (Pearl, 1995) is a method to reduce confounders in causal inference, and it can perform do-operator on the observational datasets. Formally, the backdoor adjustment reduces the bias as:\np(P |do(F )) = \u2211 L p(P |F,L)p(L) (10)\nWhere the detail for the equation is in Appendix B. Inspired by the eq. 10, it can reduce the spurious correlation if we process the feature vectors of the same label separately. So we propose a method to optimize the feature vectors in the same label by using the property of variance.\nWhen the fluctuation among samples is serious, the variance will be large, and vice versa. In other words, we can minimize the variance between the samples of the same label to bring them closer together and at the same time achieve intervention. Along this way, we introduce a new loss function using the variance to optimize the feature representation as follows:\nLossV OP = L\u2211 l=0 N\u2211 n=0 var(F(l,n)) (11)\nWhere L is the label amount in one batch of data, N is the dimension amount of feature vectors, and\nF(l,n) means the n-th dimensional feature of all samples of label l. var(\u00b7) is the operation of computing sample variance. Note that missing several labels is possible in one batch of data.\nThis method is called variance optimizing (VOP). Additionally, benefiting from the random mechanism of mini-batch gradient descent, one sample can combine with different samples into the same batch in each training epoch, which brings two main advantages as follows: Firstly, the diversity of sample combination is ensured automatically. Secondly, the impact of abnormal samples is mitigated due to the overall optimization."
        },
        {
            "heading": "3.4 Overall Optimization Framework",
            "text": "We combine COP and VOP into a unified framework called covariance and variance optimization framework (OVO), as shown in Fig. 3, and the algorithm. 1 (Appendix. C) illustrates the detailed training procedure of OVO. The final loss is as follows:\nLossfinal = LossCOP + \u03bbLossV OP (12)\nWhere \u03bb is a hyperparameter for the weight of LossV OP ."
        },
        {
            "heading": "4 Experiment",
            "text": ""
        },
        {
            "heading": "4.1 Dataset",
            "text": "We conduct experiments to evaluate our approach on two popular joint entity and relation extraction datasets: ACE051 and SciERC2(Luan et al., 2018). For ACE2005, we use the same split following (Luan et al., 2019) in the train, development, and test sets. ACE2005 dataset includes various domain data, such as newswire and broadcast news, while the SciERC dataset includes abstracts collected from AI conferences/workshops.\nAdditionally, to evaluate the effectiveness of OVO in out-of-distribution settings, we conduct experiments on CrossRE 3 (Bassignana and Plank, 2022) which is a dataset for the relation extraction task across 6 different domains, namely news, politics, natural science, music, literature, and artificial intelligence."
        },
        {
            "heading": "4.2 Evalution metrics",
            "text": "We follow the evaluation metrics in previous close works to evaluate the experiment results\u2019 performance using the micro F1 measure. For the NER\n1https://catalog.ldc.upenn.edu/LDC2006T06 2http://nlp.cs.washington.edu/sciIE/ 3https://github.com/mainlp/CrossRE\ntask, we use the span-level benchmark to evaluate, which one entity is considered recognized correctly if and only if both its boundary and type are precisely predicted. For the RE, we adopt two evaluation metrics as follows: (1) boundaries evaluation (Rel): a relation is considered recognized correctly if and only if the boundaries of head and tail entities are correct, and their relation label is correct; (2) strict evaluation (Rel+): in addition to the requirement of Rel, the types of two entities are also needed to be correctly predicted."
        },
        {
            "heading": "4.3 Implementation Details",
            "text": "We apply OVO to 3 of out of top-5 strong baselines4, specifically PURE (Zhong and Chen, 2021), SpERT.PL (Sai et al., 2021), and PL-Marker (Ye et al., 2022). For ACE2005, the BERT encoders are bert-base-uncased (Devlin et al., 2019) and albert-xxlarge-v1(Lan et al., 2020) which are in the common domain. For SciERC, the BERT encoder is scibert-scivocab-uncased (Beltagy et al., 2019) which is in the scientific domain. We use our proposed method, OVO, to optimize the feature vectors as the extra plugin beyond the common model training with all hyperparameters the same as the base models. To ensure robustness, we conduct experiments with 3 different seeds and report the average scores."
        },
        {
            "heading": "4.4 Baselines",
            "text": "For comparison, we choose serials of state-of-theart models as follows: (1) PURE (Zhong and Chen, 2021) uses two independent models for NER and RE respectively in a frustratingly easy way, and is the first to propose levitated markers for RE task called PURE(Approx) to accelerate the inference speed, but with a slight drop in performance; (2) SpERT.PL (Sai et al., 2021) uses part-of-speech and logits of entities to enhance the features of entities and relations which shows strong performance in the SciERC dataset. (3) PL-Marker (Ye et al., 2022) is the first to leverage levitated markers to both NER and RE tasks using a packed method with great improvement.\nAdditionally, for comparison with other causal debiasing methods, we choose two related methods as follows: (1) CFIE (Nan et al., 2021) uses causal inference to tackle the long-tailed IE issues; (2) CoRE (Wang et al., 2022) designs a counterfactual\n4https://paperswithcode.com/sota/ joint-entity-and-relation-extraction-on\nanalysis to debias RE by reducing the side-effects of entity mentions."
        },
        {
            "heading": "4.5 Results",
            "text": "Table 1 shows the results of comparative experiments between our proposed method and baselines. As is shown, with the scibert-scivocab-uncased encoder, our proposed method, OVO, outperforms PURE-F, SpERT.PL, and PL-Marker by +3.3%, +2.1%, and +2.9% with Rel+ on SciERC respectively. Furthermore, on ACE2005, with both bertbase-uncased encoder and albert-xxlarge-v1 encoder, our method also outperforms the baselines on Rel+. Such improvements over baselines indicate the effectiveness and generalization of OVO.\nAdditionally, due to CoRE (Wang et al., 2022) being only for RE, we compare OVO with CFIE (Nan et al., 2021) and CoRE only in RE using the result of OVO in NER. For the base model, we chose PURE because of SpERT.PL is a joint model that cannot handle NER and RE tasks separately and PL-Marker uses a packed method that cannot handle only one pair of entities in RE. As shown in Table 1, CFIE and CoRE can improve performance somewhat but are still lower than OVO. The results can show the effectiveness of OVO compared with other methods. Specifically, on SciERC, the REL+ of OVO was 1.6% higher than CFIE; on Ace2005, the REL+ of OVO was 0.2% higher than CoRE.\nTo evaluate the effectiveness of OVO on out-ofdistribution, we conduct experiments on an outdomain setting as follows: using the train set of one domain during training, and using the test sets of the other five domains during testing. We choose PL-Marker as the base model and then apply OVO on each domain. As shown in Table. 2, using OVO gains improvements in all cases with an average improvement of 1.5% and a best improvement of 2.4% in the ai domain."
        },
        {
            "heading": "4.6 Ablation Study",
            "text": "In this section, we conduct ablation studies to elucidate the effectiveness of different components of our proposed method on the baseline PL-Marker (Ye et al., 2022). We use the evaluation metrics the same as in Table 1 on both ACE2005 and SciERC datasets using bert-base-uncased and scibertscivocab-uncased as bert encoders respectively.\nw/o. COP: To evaluate the effectiveness of covariance optimizing, we remove COP and only use VOP in the model training process and set\nall weights of feature vectors as 1 for computing LossCOP . As shown in Table 3, the performance of Rel and Rel+ drop 0.8%-2.2% without COP, which can represent the importance to reduce the spurious correlation among features.\nw/o. VOP: To verify the effectiveness of variance optimization, we make VOP disabled and let only COP work in the training procedure. As shown in Table 3, when removing VOP, the performance of Rel and Rel+ drop 2.0%-3.4% and 1.6%-2.2% respectively, which can indicate the effect of the causal intervention and the VOP play an important role in OVO.\nw. SNet: StableNet (Zhang et al., 2021) is similar work with COP which use Random Fourier Features to enhance the non-linearity of enhanced features. To compare the effectiveness between COP and StableNet, we replace COP with StableNet keeping other settings the same, and then negotiate the final performance between them. The performance shows that using COP gains +0.7% and +0.4% improvement in Rel+ on ACE2005 and SciERC respectively. Moreover, from the results in Table 5, the consumption of COP is much smaller than that of StableNet."
        },
        {
            "heading": "5 Analysis",
            "text": ""
        },
        {
            "heading": "5.1 Fine-grained analysis",
            "text": "To analyze the debias ability of OVO, we conduct experiments to evaluate the performance of each label on PL-Marker. The detailed results for each relation label on SciERC are shown in Table 4. From the table, the number of USERD-FOR accounts for more than half, 54.7% of the total, but that of COMPARE is only 3.9% of the total.\nFrom the results, the two worst-performing labels both have a small number of samples which are only 6.9% and 6.4% of the total, respectively. For the comparison between with or without OVO, we find that the performances in all labels gain improvement, except for USED-FOR, which is one that has the most samples in the dataset and keeps comparable performance. Additionally, the improvement increases as the number of samples decreases. The most improvement is on PART-OF, which outperforms +9.1% in F1 than without VOP. Moreover, the overall results of average F1 gain +4.0% improvement."
        },
        {
            "heading": "5.2 Effect of Covariance Optimizing",
            "text": "As the results are shown in Table 5, by using StableNet, it gains +0.6% improvement on Ent, and COP improves on it +0.2%. Table 3 shows more results between COP and StableNet. So, we can conclude that stable learning technology can actually achieve improvement for our task. But the consumption of computing resources is relatively high and it costs approximately 5 and 1.7 times for training time and GPU memory respectively than the original. In comparison, COP uses fewer resources but gets better performance. Additionally, more detailed results of hyperparameters are\nreported in Appendix. D."
        },
        {
            "heading": "5.3 Effect of Variance Optimizing",
            "text": "To enhance adaptation to diverse methods, we introduce a weight for LossV OP to mitigate its impact on the normal training of the model and avoid performance degradation. The optimal weight varies depending on the specific dataset and method employed, as different weights yield the best performance. The detailed results are reported in Appendix. E."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this work, we propose the OVO, a novel model training framework for optimizing feature vectors using causal technology. There are two main parts of OVO which are called COP and VOP. From the perspective of the correlation among features, COP reduces the spurious relation by minimizing the covariance computed from all features. From the viewpoint of each feature, VOP makes the feature more causal by minimizing the variance calculated from each feature of the same label. After optimizing the features toward causal, our method achieves\nimprovements on 3 strong baselines and reduces the influence of data unbalanced bias. In the future, we will pay more attention to (1) how to further reduce resource consumption on COP and (2) how can let the weight of VOP adjusts itself automatically to adapt to the different datasets.\nLimitations\nOVO is a novel training framework for optimizing feature representations directly using causal technology. The limitations of OVO are as follows:\n\u2022 COP is an additional training process in each batch that will improve resource consumption. Larger models and more previous information used in COP will cost more additional resources.\n\u2022 To adapt OVO to more models, there are some hyperparameters to control the degree of effect of COP and VOP during training. These hyperparameters are sensitive to different models and datasets, so it takes time to experiment to find the optimal values of them."
        },
        {
            "heading": "Acknowledgements",
            "text": "The State Key Program of National Natural Science of China, Grant/Award Number:61533018; National Natural Science Foundation of China, Grant/Award Number: 61402220; The Philosophy and Social Science Foundation of Hunan Province, Grant/Award Number: 16YBA323; Natural Science Foundation of Hunan Province, Grant/Award Number: 2020JJ4525,2022JJ30495; Scientific Research Fund of Hunan Provincial Education Department, Grant/Award Number: 18B279,19A439,22A0316."
        },
        {
            "heading": "A Causal Graph",
            "text": "From Fig. 2, L \u2192 F denotes that real labels in datasets have an effect on the feature vectors learned by model training, and L\u2192 P denotes that real labels have an effect on model predictions because the loss in training is calculated by labels and predictions. So the backdoor path F \u2190 L \u2192 P makes models give relatively high scores to the labels with numerous samples."
        },
        {
            "heading": "B Derivation Process of Backdoor Adjustment",
            "text": "In this section, we will give an explanation for each step of backdoor adjustment. To make it easier to understand, we draw a new equation as follows:\np(P |do(F )) (1)= \u2211 L p(P |do(F ), L)p(L|do(F ))\n(2) = \u2211 L p(P |do(F ), L)P (L|F )\n(3) = \u2211 L p(P |F ,L)p(L|F )\n(4) = \u2211 L p(P |F,L)p(L)\n(13) Where the meaning of P , F , and L are the same as Fig. 2; do(\u00b7) means do-operator. The underline means the main differences from the previous step.\n(1) using the total probability theorem where do(F ) can be seen as a normal random variables event like P and L.\n(2) from the causal graph in Fig. 2, the path L \u2192 F is a direct causal path without backdoor paths, so p(L|do(F )) and p(L|F ) are equivalent.\n(3) because of conditioning on L, the association in the path F \u2190 L \u2192 P is blocked. So in this case, the association in the path F \u2192 P is causality which can remove the do-operator without any influence.\n(4) due to the direction of the causal path between L and F being F \u2190 L, there is no association from F to L which causes the L to be independent with F meaning p(L|F ) = p(L)."
        },
        {
            "heading": "C Overall Algorithm of OVO",
            "text": "The algorithm of OVO is shown in the algorithm. 1."
        },
        {
            "heading": "D Analysis of COP",
            "text": "D.1 Saving Batch Number When the dataset is large enough, it is hard to put all feature vectors into COP and optimize them at once. So, by using eq. 6, we can use part of the vectors to relieve the pressure on computing resources. To research the effect of COP when just using partial vectors, we conduct comparative experiments with\nAlgorithm 1 The training procedure of the OVO Input: Initial pre-trained BERT encoder BE(0) and classi-\nfier C(0), training dataset D, training epochs for model training Tmt, training epochs for COP Tcop\nOutput: Trained model (BE(Tmt),C(Tmt)) 1: for tmt = 0 to Tmt do 2: Fpre \u2190 Clear the previous feature vectors; 3: Wpre \u2190 Clear the previous weights; 4: for (Sents, Spans) in D do 5: H = BE(tmt)(Sents) 6: Fcur = GetSpanFeatures(H) 7: P = C(tmt)(Fcur) 8: Wcur \u2190 Initial 9: F = concat(Fpre,Fcur) 10: W = concat(Wpre,Wcur) 11: for tcop = 0 to Tcop do 12: LW = \u2211 i \u0338=j cov(WFi,WFj) 13: Wcur \u2190 Optim(LW) 14: end for 15: (Fpre,Wpre)\u2190 update and fuse 16: Lorig = CrossEntropy(P, Spans) 17: LCOP = WcurLorig 18: LV OP = \u2211L l=0 \u2211N n=0 var(F(l,n)) 19: L = LCOP + LV OP 20: (BEtmt+1,Ctmt+1)\u2190 Optim(L) 21: end for 22: end for\ndifferent saving batch numbers on PL-Marker (Ye et al., 2022). As shown in Fig. 5, as the saving batch number rises, the overall trend of F1 also rises and reaches the best performance at inf (around 210 in our training setting). It can be concluded that using more vectors for COP can reduce spurious correlation better and gain more improvement, but require more computing resources.\nD.2 Effect of alpha\nTo explore the effect of fusing current information, we conduct experiments for fusing hyperparameter \u03b1 of eq. 8. We fix the saving batch number to infinite and change the \u03b1 in the same training configuration. Fig. 6 shows the detailed result of the experiments.\nD.3 COP rate\nWe use rCOP = 1 in PURE (Zhong and Chen, 2021) and PL-Marker (Ye et al., 2022). For SpERT.PL, we set the COP rate equal to 0.1 and\n0.4 on ACE2005 and SciERC respectively. The detailed results for the COP rate are shown in Fig. 7 which only uses COP in experiments."
        },
        {
            "heading": "E Analysis of VOP",
            "text": "E.1 Tradeoff on Variance Optimizing For better adaptation to different tasks, it is important to give LossV OP a weight, preventing it to influence the model training and hurt the performance. We compute the final loss with weighed LossV OP as follows:\nLossfinal = LossCOP + \u03bbLossV OP (14)\nWhere \u03bb is a hyperparameter regarding the weight of LossV OP . From the results in Fig. 8, different datasets get the best performance in different weights of VOP which \u03bb = 0.2 is the optimal value for ACE2005 and \u03bb = 0.1 is that for SciERC, and the performance is particularly sensitive to the weight which changes drastically using different \u03bb."
        }
    ],
    "title": "CoVariance-based Causal Debiasing for Entity and Relation Extraction",
    "year": 2023
}