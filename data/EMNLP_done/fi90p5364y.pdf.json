{
    "abstractText": "Recent studies on counterfactual augmented data have achieved great success in the coarsegrained natural language processing tasks. However, existing methods encounter two major problems when dealing with the finegrained relation extraction tasks. One is that they struggle to accurately identify causal terms under the invariant entity constraint. The other is that they ignore the commonsense constraint. To solve these problems, we propose a novel framework to generate commonsense counterfactuals for stable relation extraction. Specifically, to identify causal terms accurately, we introduce an intervention-based strategy and leverage a constituency parser for correction. To satisfy the commonsense constraint, we introduce the concept knowledge base WordNet and design a bottom-up relation expansion algorithm on it to uncover commonsense relations between entities. We conduct a series of comprehensive evaluations, including the low-resource, out-of-domain, and adversarialattack settings. The results demonstrate that our framework significantly enhances the stability of base relation extraction models1.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xin Miao"
        },
        {
            "affiliations": [],
            "name": "Yongqi Li"
        },
        {
            "affiliations": [],
            "name": "Tieyun Qian"
        }
    ],
    "id": "SP:282fcf0a35500409331aec5667964e068cc739b0",
    "references": [
        {
            "authors": [
                "Nitay Calderon",
                "Eyal Ben-David",
                "Amir Feder",
                "Roi Reichart."
            ],
            "title": "Docogen: Domain counterfactual generation for low resource domain adaptation",
            "venue": "arXiv preprint arXiv:2202.12350.",
            "year": 2022
        },
        {
            "authors": [
                "Fredrik Carlsson",
                "Joey \u00d6hman",
                "Fangyu Liu",
                "Severine Verlinden",
                "Joakim Nivre",
                "Magnus Sahlgren."
            ],
            "title": "Fine-grained controllable text generation using nonresidual prompting",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational",
            "year": 2022
        },
        {
            "authors": [
                "Hao Chen",
                "Rui Xia",
                "Jianfei Yu."
            ],
            "title": "Reinforced counterfactual data augmentation for dual sentiment classification",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 269\u2013278.",
            "year": 2021
        },
        {
            "authors": [
                "Xiang Chen",
                "Ningyu Zhang",
                "Xin Xie",
                "Shumin Deng",
                "Yunzhi Yao",
                "Chuanqi Tan",
                "Fei Huang",
                "Luo Si",
                "Huajun Chen"
            ],
            "title": "Knowprompt: Knowledgeaware prompt-tuning with synergistic optimization",
            "year": 2022
        },
        {
            "authors": [
                "Xuanting Chen",
                "Junjie Ye",
                "Can Zu",
                "Nuo Xu",
                "Rui Zheng",
                "Minlong Peng",
                "Jie Zhou",
                "Tao Gui",
                "Qi Zhang",
                "Xuanjing Huang"
            ],
            "title": "How robust is gpt-3.5 to predecessors? a comprehensive study on language understanding tasks. arXiv preprint arXiv:2303.00293",
            "year": 2023
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "arXiv preprint arXiv:1810.04805.",
            "year": 2018
        },
        {
            "authors": [
                "Tanay Dixit",
                "Bhargavi Paranjape",
                "Hannaneh Hajishirzi",
                "Luke Zettlemoyer."
            ],
            "title": "Core: A retrieve-thenedit framework for counterfactual data generation",
            "venue": "arXiv preprint arXiv:2210.04873.",
            "year": 2022
        },
        {
            "authors": [
                "Sudhakaran Gajendran",
                "D Manjula",
                "Vijayan Sugumaran",
                "R Hema."
            ],
            "title": "Extraction of knowledge graph of covid-19 through mining of unstructured biomedical corpora",
            "venue": "Computational Biology and Chemistry, page 107808.",
            "year": 2023
        },
        {
            "authors": [
                "Siddhant Garg",
                "Goutham Ramakrishnan."
            ],
            "title": "Bae: Bert-based adversarial examples for text classification",
            "venue": "arXiv preprint arXiv:2004.01970.",
            "year": 2020
        },
        {
            "authors": [
                "Robert Geirhos",
                "J\u00f6rn-Henrik Jacobsen",
                "Claudio Michaelis",
                "Richard Zemel",
                "Wieland Brendel",
                "Matthias Bethge",
                "Felix A Wichmann."
            ],
            "title": "Shortcut learning in deep neural networks",
            "venue": "Nature Machine Intelligence, 2(11):665\u2013673.",
            "year": 2020
        },
        {
            "authors": [
                "Mor Geva",
                "Tomer Wolfson",
                "Jonathan Berant."
            ],
            "title": "Break, perturb, build: Automatic perturbation of reasoning paths through question decomposition",
            "venue": "Transactions of the Association for Computational Linguistics, 10:111\u2013126.",
            "year": 2022
        },
        {
            "authors": [
                "Ralph Grishman",
                "David Westbrook",
                "Adam Meyers."
            ],
            "title": "Nyu\u2019s english ace 2005 system description",
            "venue": "ACE, 5.",
            "year": 2005
        },
        {
            "authors": [
                "Zhijiang Guo",
                "Yan Zhang",
                "Wei Lu."
            ],
            "title": "Attention guided graph convolutional networks for relation extraction",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 241\u2013251, Florence, Italy. Association for Com-",
            "year": 2019
        },
        {
            "authors": [
                "Iris Hendrickx",
                "Su Nam Kim",
                "Zornitsa Kozareva",
                "Preslav Nakov",
                "Diarmuid O S\u00e9aghdha",
                "Sebastian Pad\u00f3",
                "Marco Pennacchiotti",
                "Lorenza Romano",
                "Stan Szpakowicz"
            ],
            "title": "Semeval-2010 task 8: Multiway classification of semantic relations between pairs",
            "year": 2019
        },
        {
            "authors": [
                "Phillip Howard",
                "Gadi Singer",
                "Vasudev Lal",
                "Yejin Choi",
                "Swabha Swayamdipta."
            ],
            "title": "Neurocounterfactuals: Beyond minimal-edit counterfactuals for richer data augmentation",
            "venue": "arXiv preprint arXiv:2210.12365.",
            "year": 2022
        },
        {
            "authors": [
                "Wenlong Huang",
                "Pieter Abbeel",
                "Deepak Pathak",
                "Igor Mordatch."
            ],
            "title": "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents",
            "venue": "International Conference on Machine Learning, pages 9118\u20139147. PMLR.",
            "year": 2022
        },
        {
            "authors": [
                "Xiaoqi Jiao",
                "Yichun Yin",
                "Lifeng Shang",
                "Xin Jiang",
                "Xiao Chen",
                "Linlin Li",
                "Fang Wang",
                "Qun Liu."
            ],
            "title": "Tinybert: Distilling bert for natural language understanding",
            "venue": "arXiv preprint arXiv:1909.10351.",
            "year": 2019
        },
        {
            "authors": [
                "Nitish Joshi",
                "He He."
            ],
            "title": "An investigation of the (in) effectiveness of counterfactually augmented data",
            "venue": "arXiv preprint arXiv:2107.00753.",
            "year": 2021
        },
        {
            "authors": [
                "Divyansh Kaushik",
                "Eduard Hovy",
                "Zachary C Lipton."
            ],
            "title": "Learning the difference that makes a difference with counterfactually-augmented data",
            "venue": "arXiv preprint arXiv:1909.12434.",
            "year": 2019
        },
        {
            "authors": [
                "Luoqiu Li",
                "Xiang Chen",
                "Hongbin Ye",
                "Zhen Bi",
                "Shumin Deng",
                "Ningyu Zhang",
                "Huajun Chen."
            ],
            "title": "On robustness and bias analysis of bert-based relation extraction",
            "venue": "China Conference on Knowledge Graph and Semantic Computing, pages 43\u201359. Springer.",
            "year": 2021
        },
        {
            "authors": [
                "Wanli Li",
                "Tieyun Qian",
                "Ming Zhong",
                "Xu Chen."
            ],
            "title": "Interactive lexical and semantic graphs for semisupervised relation extraction",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems.",
            "year": 2022
        },
        {
            "authors": [
                "Ziyan Li",
                "Kan Ni",
                "Haofen Wang",
                "Wenqiang Zhang."
            ],
            "title": "Relation extraction as text matching: A scheme for multi-hop knowledge base question answering",
            "venue": "CCKS 2022-Evaluation Track: 7th China Conference on Knowledge Graph and Seman-",
            "year": 2022
        },
        {
            "authors": [
                "Bill Yuchen Lin",
                "Wenyang Gao",
                "Jun Yan",
                "Ryan Moreno",
                "Xiang Ren."
            ],
            "title": "Rockner: A simple method to create adversarial examples for evaluating the robustness of named entity recognition models",
            "venue": "arXiv preprint arXiv:2109.05620.",
            "year": 2021
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Angrosh Mandya",
                "Danushka Bollegala",
                "Frans Coenen."
            ],
            "title": "Graph convolution over multiple dependency sub-graphs for relation extraction",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 6424\u20136435, Barcelona,",
            "year": 2020
        },
        {
            "authors": [
                "George A Miller."
            ],
            "title": "Wordnet: a lexical database for english",
            "venue": "Communications of the ACM, 38(11):39\u201341.",
            "year": 1995
        },
        {
            "authors": [
                "Guoshun Nan",
                "Jiaqi Zeng",
                "Rui Qiao",
                "Zhijiang Guo",
                "Wei Lu."
            ],
            "title": "Uncovering main causalities for long-tailed information extraction",
            "venue": "arXiv preprint arXiv:2109.05213.",
            "year": 2021
        },
        {
            "authors": [
                "Yulei Niu",
                "Kaihua Tang",
                "Hanwang Zhang",
                "Zhiwu Lu",
                "Xian-Sheng Hua",
                "Ji-Rong Wen."
            ],
            "title": "Counterfactual vqa: A cause-effect look at language bias",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages",
            "year": 2021
        },
        {
            "authors": [
                "Bhargavi Paranjape",
                "Mandar Joshi",
                "John Thickstun",
                "Hannaneh Hajishirzi",
                "Luke Zettlemoyer."
            ],
            "title": "An information bottleneck approach for controlling conciseness in rationale extraction",
            "venue": "arXiv preprint arXiv:2005.00652.",
            "year": 2020
        },
        {
            "authors": [
                "Judea Pearl"
            ],
            "title": "Causal inference in statistics: An overview",
            "year": 2009
        },
        {
            "authors": [
                "Judea Pearl",
                "Dana Mackenzie."
            ],
            "title": "The book of why: the new science of cause and effect",
            "venue": "Basic books.",
            "year": 2018
        },
        {
            "authors": [
                "Yujia Qin",
                "Yankai Lin",
                "Ryuichi Takanobu",
                "Zhiyuan Liu",
                "Peng Li",
                "Heng Ji",
                "Minlie Huang",
                "Maosong Sun",
                "Jie Zhou."
            ],
            "title": "ERICA: Improving entity and relation understanding for pre-trained language models via contrastive learning",
            "venue": "Proceedings of the 59th",
            "year": 2021
        },
        {
            "authors": [
                "Alec Radford",
                "Jeffrey Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "venue": "OpenAI blog,",
            "year": 2019
        },
        {
            "authors": [
                "Marcel Robeer",
                "Floris Bex",
                "Ad Feelders."
            ],
            "title": "Generating realistic natural language counterfactuals",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3611\u20133625.",
            "year": 2021
        },
        {
            "authors": [
                "Alexis Ross",
                "Ana Marasovi\u0107",
                "Matthew E Peters."
            ],
            "title": "Explaining nlp models via minimal contrastive editing (mice)",
            "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 3840\u20133852.",
            "year": 2021
        },
        {
            "authors": [
                "Indira Sen",
                "Mattia Samory",
                "Fabian Fl\u00f6ck",
                "Claudia Wagner",
                "Isabelle Augenstein"
            ],
            "title": "How does counterfactually augmented data impact models for social computing constructs? arXiv preprint arXiv:2109.07022",
            "year": 2021
        },
        {
            "authors": [
                "Rico Sennrich",
                "Barry Haddow",
                "Alexandra Birch."
            ],
            "title": "Improving neural machine translation models with monolingual data",
            "venue": "arXiv preprint arXiv:1511.06709.",
            "year": 2015
        },
        {
            "authors": [
                "Marcos Treviso",
                "Alexis Ross",
                "Nuno M Guerreiro",
                "Andr\u00e9 FT Martins."
            ],
            "title": "Crest: A joint framework for rationalization and counterfactual text generation",
            "venue": "arXiv preprint arXiv:2305.17075.",
            "year": 2023
        },
        {
            "authors": [
                "Zhao Wang",
                "Aron Culotta."
            ],
            "title": "Robustness to spurious correlations in text classification via automatically generated counterfactuals",
            "venue": "Proceedings",
            "year": 2021
        },
        {
            "authors": [
                "Jason Wei",
                "Xuezhi Wang",
                "Dale Schuurmans",
                "Maarten Bosma",
                "Ed Chi",
                "Quoc Le",
                "Denny Zhou."
            ],
            "title": "Chain of thought prompting elicits reasoning in large language models",
            "venue": "arXiv preprint arXiv:2201.11903.",
            "year": 2022
        },
        {
            "authors": [
                "Xiang Wei",
                "Xingyu Cui",
                "Ning Cheng",
                "Xiaobin Wang",
                "Xin Zhang",
                "Shen Huang",
                "Pengjun Xie",
                "Jinan Xu",
                "Yufeng Chen",
                "Meishan Zhang"
            ],
            "title": "Zeroshot information extraction via chatting with chatgpt",
            "venue": "arXiv preprint arXiv:2302.10205",
            "year": 2023
        },
        {
            "authors": [
                "Jiaxin Wen",
                "Yeshuang Zhu",
                "Jinchao Zhang",
                "Jie Zhou",
                "Minlie Huang."
            ],
            "title": "Autocad: Automatically generating counterfactuals for mitigating shortcut learning",
            "venue": "arXiv preprint arXiv:2211.16202.",
            "year": 2022
        },
        {
            "authors": [
                "Haoran Wu",
                "Wenxuan Wang",
                "Yuxuan Wan",
                "Wenxiang Jiao",
                "Michael Lyu."
            ],
            "title": "Chatgpt or grammarly? evaluating chatgpt on grammatical error correction benchmark",
            "venue": "arXiv preprint arXiv:2303.13648.",
            "year": 2023
        },
        {
            "authors": [
                "Shanchan Wu",
                "Yifan He."
            ],
            "title": "Enriching pretrained language model with entity information for relation classification",
            "venue": "Proceedings of the 28th ACM international conference on information and knowledge management, pages 2361\u20132364.",
            "year": 2019
        },
        {
            "authors": [
                "Tongshuang Wu",
                "Marco Tulio Ribeiro",
                "Jeffrey Heer",
                "Daniel S Weld."
            ],
            "title": "Polyjuice: Generating counterfactuals for explaining, evaluating, and improving models",
            "venue": "arXiv preprint arXiv:2101.00288.",
            "year": 2021
        },
        {
            "authors": [
                "Ikuya Yamada",
                "Akari Asai",
                "Hiroyuki Shindo",
                "Hideaki Takeda",
                "Yuji Matsumoto."
            ],
            "title": "LUKE: Deep contextualized entity representations with entityaware self-attention",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Lan-",
            "year": 2020
        },
        {
            "authors": [
                "Kexin Yang",
                "Dayiheng Liu",
                "Wenqiang Lei",
                "Baosong Yang",
                "Mingfeng Xue",
                "Boxing Chen",
                "Jun Xie."
            ],
            "title": "Tailor: A prompt-based approach to attributebased controlled text generation",
            "venue": "arXiv preprint arXiv:2204.13362.",
            "year": 2022
        },
        {
            "authors": [
                "Linyi Yang",
                "Jiazheng Li",
                "P\u00e1draig Cunningham",
                "Yue Zhang",
                "Barry Smyth",
                "Ruihai Dong."
            ],
            "title": "Exploring the efficacy of automatically generated counterfactuals for sentiment analysis",
            "venue": "arXiv preprint arXiv:2106.15231.",
            "year": 2021
        },
        {
            "authors": [
                "Mo Yu",
                "Yang Zhang",
                "Shiyu Chang",
                "Tommi Jaakkola."
            ],
            "title": "Understanding interlocking dynamics of cooperative rationalization",
            "venue": "Advances in Neural Information Processing Systems, 34:12822\u201312835.",
            "year": 2021
        },
        {
            "authors": [
                "Mi Zhang",
                "Tieyun Qian",
                "Ting Zhang",
                "Xin Miao."
            ],
            "title": "Towards model robustness: Generating contextual counterfactuals for entities in relation extraction",
            "venue": "Proceedings of the ACM Web Conference 2023, pages 1832\u20131842.",
            "year": 2023
        },
        {
            "authors": [
                "Xiang Zhang",
                "Junbo Zhao",
                "Yann LeCun."
            ],
            "title": "Character-level convolutional networks for text classification",
            "venue": "Advances in neural information processing systems, 28.",
            "year": 2015
        },
        {
            "authors": [
                "Yuhao Zhang",
                "Victor Zhong",
                "Danqi Chen",
                "Gabor Angeli",
                "Christopher D. Manning."
            ],
            "title": "Position-aware attention and supervised data improve slot filling",
            "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages",
            "year": 2017
        },
        {
            "authors": [
                "Zexuan Zhong",
                "Danqi Chen."
            ],
            "title": "A frustratingly easy approach for entity and relation extraction",
            "venue": "North American Association for Computational Linguistics (NAACL).",
            "year": 2021
        },
        {
            "authors": [
                "Peng Zhou",
                "Wei Shi",
                "Jun Tian",
                "Zhenyu Qi",
                "Bingchen Li",
                "Hongwei Hao",
                "Bo Xu."
            ],
            "title": "Attention-based bidirectional long short-term memory networks for relation classification",
            "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational",
            "year": 2016
        },
        {
            "authors": [
                "Wen"
            ],
            "title": "2022), the word-replacement ratio of Synonym Replacement (Zhang et al., 2015) and BERT-MLM (Jiao et al., 2019) is set to 30%. Specifically, we randomly select 30% of words in a sentence for replacement",
            "venue": "For Synonym Replace-",
            "year": 2019
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "The relation extraction (RE) task aims to extract the semantic relation between entities in the text. RE can facilitate a wide range of downstream applications such as knowledge graph construction (Gajendran et al., 2023) and question answering (Li et al., 2022b), having aroused much attention in recent years. Typical RE methods based on pre-trained language models like BERT (Devlin et al., 2018), or RoBERTa (Liu et al., 2019). While getting impressive performance, they exhibit a certain degree of instability in RE (Li et al., 2021; Chen et al., 2023), even the ChatGPT (Wei et al., 2023).\n\u2217Corresponding author. 1The code and data used in our experiments are available\nat: https://github.com/NLPWM-WHU/CCG\nrelation extraction (B) tasks. The words in blue denote causal terms, and those in orange denote entities.\nInstability has always been associated with neural networks. For example, Li et al. (2021) finds that BERT performs poorly in the de-biased set constructed by replacing high-frequency words with low-frequency ones. The instability is primarily caused by spurious correlations between the highfrequency words and labels. Specifically, this can be attributed to neural networks tending to learn shortcuts between instances and labels (Geirhos et al., 2020). Such property may hurt the model\u2019s stability in some challenging scenarios, e.g., lowresource or cross-domain scenarios.\nIn attempts to mitigate spurious correlations, counterfactual augmented data (CAD) is a rising trend. CAD can be defined as: flipping the label of an instance with minimal editing (Kaushik et al., 2019), which explicitly provides localized views of decision boundaries (Treviso et al., 2023). Current CAD methods consist of the following three steps: (1) identifying causal terms, that are causally related to the label; (2) editing the causal term, to flip the label to other prepended ones; and (3) filtering out inconsistent instances, where the predicted label is different from the prepended one.\nExisting methods have made great success in coarse-grained natural language processing tasks like sentiment analysis (Yang et al., 2021; Chen\net al., 2021; Howard et al., 2022) and natural language inference (Wu et al., 2021; Ross et al., 2021; Wen et al., 2022). However, the fine-grained RE task is under-explored (Zhang et al., 2023). Due to the intrinsic property of RE, i.e. invariant entity constraint and commonsense constraint, existing methods encounter the following two challenges.\nFirstly, existing methods struggle to accurately identify causal terms, due to the constraint of invariant entities (Zhang et al., 2023). That is, keeping the entities unaltered. The state-of-the-art methods primarily employ the model\u2019s gradient attributions to identify the causal term (Ross et al., 2021; Wen et al., 2022), i.e. selecting certain words with the highest gradient. However, entities convey more information (Zhang et al., 2023), which implies that the gradient of causal terms can be confounded by the related entities. Zhang et al. (2023) propose a syntactic-tailored strategy, i.e. taking the words along the shortest dependency path (SDP) between entities as causal terms. The drawback is its heavy reliance on syntactic parsing quality.\nSecondly, and more importantly, all existing methods ignore the commonsense constraint. They assume that all labels can be treated as prepended ones. This is feasible in coarse-grained tasks. For example, in sentiment analysis, simply replacing the causal terms can flip the sentiment orientation, as shown in Fig. 1 (A). However, for RE, the nature of entities imposes commonsense constraints on causal terms, as shown in Fig. 1 (B). In brief, the relation between entities should conform to the cognitive understanding of the real world. Although existing methods pre-train a RE base model on the existing dataset for consistency filtering (Ross et al., 2021; Wen et al., 2022; Zhang et al., 2023), there remains an issue of entanglement with the base model. For example, in low-resource scenarios, the base model is severely affected by spurious correlations and propagates the errors backward.\nTo address these two challenges, we present a Commonsense Counterfactual Generation (CCG) framework for stable relation extraction. Firstly, to identify the causal terms accurately, we present a novel intervention-based strategy, which can accurately identify the editable words by potential interventions. After obtaining preliminary results, we further utilize the constituency parser for correction. Secondly, to satisfy the commonsense constraint, we leverage the concept knowledge base WordNet (Miller, 1995) and utilize its hierarchical\nstructure knowledge i.e. the common hypernyms, to interconnect entities, thereby expanding their relations. We design a bottom-up relation expansion algorithm for implementation, which can uncover commonsense relations between entities.\nWe conduct comprehensive evaluations on a series of challenging scenarios, including the lowresource, out-of-domain, and adversarial-attack settings. The results demonstrate that our CCG generates more reasonable counterfactuals, which can consistently enhance RE models\u2019 stability in various scenarios. Furthermore, we also conduct a series of in-depth analysis studies. The results confirm the effectiveness of various CCG strategies and demonstrate that our generated counterfactuals are not only semantically readable but, more importantly, consistent with commonsense."
        },
        {
            "heading": "2 Related Work",
            "text": ""
        },
        {
            "heading": "2.1 Relation Extraction (RE)",
            "text": "Early deep learning RE models get promising performance by either extracting better semantic features from sentences (Zhou et al., 2016; Zhang et al., 2017) or incorporating syntactic features over dependency graph (Guo et al., 2019; Mandya et al., 2020). More recently, pre-trained language models (PLMs) (Devlin et al., 2018) based RE methods can achieve superior performance (Yamada et al., 2020; Qin et al., 2021; Chen et al., 2022).\nDespite the remarkable progress, the stability of RE methods has been largely neglected from the perspective of CAD. The only research towards this direction (Zhang et al., 2023) ignores the commonsense constraint. Moreover, its performance is entangled with the base model due to the consistency filtering. In contrast, our CCG takes commonsense into account and is independent of the base model during the counterfactual generation process. This ensures that our counterfactuals are reasonable and not constrained by the base model."
        },
        {
            "heading": "2.2 Counterfactual Data Augmentation",
            "text": "Inspired by causal inference (Pearl, 2009; Pearl and Mackenzie, 2018), studies to improve model stability by eliminating spurious correlation features have received increasing attention (Kaushik et al., 2019; Niu et al., 2021). Among them, counterfactual data augmentation methods have become one of the mainstreams, especially in natural language understanding tasks (Kaushik et al., 2019; Garg and Ramakrishnan, 2020; Wang and Culotta,\n2021; Ross et al., 2021; Robeer et al., 2021; Chen et al., 2021; Yang et al., 2021; Wen et al., 2022; Howard et al., 2022; Zhang et al., 2023). These methods generate augmented data by replacing the causal terms in original samples and flipping the corresponding labels. In this way, the impact of causal items on the output is emphasized while the importance of spurious correlation features is weakened (Kaushik et al., 2019; Joshi and He, 2021).\nHowever, most of these approaches have been performed on coarse-grained natural language understanding tasks, such as sentence-level sentiment analysis (Kaushik et al., 2019; Chen et al., 2021; Yang et al., 2021; Dixit et al., 2022; Howard et al., 2022), text classification (Garg and Ramakrishnan, 2020; Wang and Culotta, 2021), and natural language inference (Wen et al., 2022; Dixit et al., 2022). For fine-grained tasks like relation extraction, one key property is the commonsense associated with the entity pair. If the commonsense constraint is violated, the obtained counterfactuals may negatively affect the model\u2019s performance and stability. Based on this observation, this work explicitly introduces commonsense knowledge into the counterfactual generation for the first time."
        },
        {
            "heading": "3 Methodology",
            "text": ""
        },
        {
            "heading": "3.1 Task Definition",
            "text": "Let X = {(xi = (ei, ci), yi)} be the dataset, where xi \u2208 X is a sentence contains a known entity pair ei and their context ci. yi \u2208 Y is the corresponding relation of the entity pair. Given the sentence xi, RE aims to extract the relation yi.\nFor a given instance (xi = (ei, ci), yi), we define the commonsense counterfactual augmented data (CCAD) as: generating a counterfactual instance (x\u0302 = (ei, c\u0302i), y\u0302i) that meets the following requirements. (1) Minimal perturbation: only the causal term in c\u0302i is edited. (2) Commonsense constraint: y\u0302i needs to satisfy the commonsense constraint regarding ei and y\u0302i \u0338= yi. (3) Label flipping: x\u0302i needs to be consistent with y\u0302i. Note that requirements (1) and (3) are inherited from previous works (Kaushik et al., 2019; Garg and Ramakrishnan, 2020; Wang and Culotta, 2021), and requirement (2) is proposed by this work.\nOur framework CCG consists of three components: causal terms identification, relation expansion, and controllable editing. Each module satisfies one of the aforementioned requirements. The overview of CCG is shown in Figure 2."
        },
        {
            "heading": "3.2 Causal Terms Identification",
            "text": "To meet the requirement of minimal perturbations, the causal terms should be identified precisely. Otherwise, the errors will affect the later counterfactual generation. To this end, we propose an interventionbased strategy combined with a constituency parser. The details are shown in Figure 2 (1).\nMLM Intervenor We first employ a masked language model (MLM) as the intervenor. It intervenes on each contextual word separately. Specifically, it masks each word individually using <mask> symbol and then performs cloze-style filling. To ensure the rationality of each intervention, we only select the top N words predicted by the intervenor.\nTrained Indicator The indicator is a trained REbased model based on the existing dataset. It predicts each intervention instance separately. If a predicted label changes, we regard the intervened word as the preliminary causal term. It is worth noting that even in low-resource scenarios, the base model can still work because the decision space for determining the change of predictions (binary classification) is much smaller than the decision space for predicting the actual outcomes (multi-class classification, directly proportional to the number of relations), which greatly reduces the complexity of the problem. The process can be formalized as:\n\u03d5(wji )= 1, if b(xi) \u0338= b(xi\\w j i ; r(w j i )) 0, otherwise, (1)\nwhere r(wji ) denotes the intervention word, xi\\w j i represents the sentence xi without the word w j i , and b is the trained indicator.\nConstituency Parsing based Causal Item Identification After obtaining the preliminary causal term, We observed that words belonging to the same phrase as the preliminary causal term were not identified, although they should be treated as a whole. To alleviate this issue, we utilize a constituency parse tree to find the overlooked causal term. To achieve automatic operation, we design the processing workflow: (1) traverse upward from the node where the preliminary causal term are located to find the nearest verb phrase (NVP) or prepositional phrase (NPP). (2) If NVP is found, traverse its child nodes and label the verb (VP) or preposition (IN) nodes as causal items, then finish. (3) If NPP is found, traverse its child nodes and label the preposition (IN) nodes as causal items."
        },
        {
            "heading": "3.3 Commonsense Constrained Relation Expansion",
            "text": "To meet the requirement of commonsense constraint, we incorporate a concept knowledge base WordNet to expand the relations among entities. Specifically, to achieve relation transitivity, it is necessary to establish connections between entities. Hypernymy (super-name) are transitive relations between concepts (Miller, 1995), e.g., \u201cprimate\u201d is a hypernym for \u201chuman\u201d. This semantic relation organizes the meanings of nouns into a hierarchical structure. Moreover, the concepts gradually become broader in the hierarchy of hypernyms. Based on this property, entities can be connected through common hypernyms. Furthermore, we assume that for any entity pair, the lower common hypernym in the hierarchical structure, the closer their semantics are, and the more likely their relations can be expanded. We implemented this idea through Module 2, as shown in Figure 2 (2).\nRelationNet Construction Given a known instance, we first obtain the hypernyms of entities through WordNet. Then, we pairwise match the hypernyms between entities to form hypernym pairs. Finally, we respectively use the hypernym pairs as keys in RelationNet, while the current relation and\nits occurrence count are accumulatively recorded as the corresponding values. The entire process can be formalized in lines 1-9 of Algorithm 1.\nBottom-up Retrieval We also obtain the hypernyms of entities through WordNet. Then, we pairwise match the hyperyms between entities in a bottom-up strategy. That is, priority is given to the lowest-level hypernym pair, and then proceeding using the similar strategy iteratively. According to the matching order, each hypernym pair is used to retrieve records from RelationNet. If a record exists and contains a new relation, we add it to the potential relations list. Due to the lower common hypernym in the hierarchical structure, the closer their semantics, our bottom-up retrieval strategy can proactively identify semantically closer entity pairs with different relations. As a result, the relations discovered earlier come from the entity pairs with more similar semantics, hence it should be given a higher priority. We select the top K relations for experimentation. A more detailed process is described in lines 10-25 in Algorithm 1. Note that the ratio threshold H can be adjusted to control the scope of upward retrieval. A smaller H will yield more accurate relations but less data, while a larger H will have the opposite effect. We will discuss the impacts of these parameters in \u00a75.8.\nAlgorithm 1: Bottom-up Relation Expansion. Require: Train set X = {(xi = (e1i , e2i ), yi)}, WordNet\nW , Input instance (x = (e1, e2), y), Ratio threshold H, Top K = n;\nOutput: Potential relations Y\u0302 = {y\u03021, y\u03022, ...y\u0302n}, RelationNet R.\n1: for (e1i , e2i ) in X do 2: H1i = W(e1i ); 3: H2i = W(e2i ); 4: for h1i in H1i do 5: for h2i in H2i do 6: R = R \u222a {(h1i , h2i ) : {yi: 1}}; 7: end for 8: end for 9: end for\n10: H1 = W(e1); 11: H2 = W(e2); 12: for hop in range(len(H1 +H2) \u2217 H) do 13: H = {(hop1, hop2)|(hop1 + hop2 = hop) \u2227 (hop1 \u2265 0) \u2227 (hop2 \u2265 0)}; 14: for (hop1, hop2) in H do 15: h1 = H1[hop1]; 16: h2 = H2[hop2]; 17: Y\u0302hop = Y\u0302hop \u222a {R[h1-h2]}; 18: end for 19: sort Y\u0302hop; 20: for y\u0302hop in Y\u0302hop do 21: if y\u0302hop \u0338= y and y\u0302hop not in Y\u0302 then 22: Y\u0302 = Y\u0302 \u222a {y\u0302hop}; 23: end if 24: end for 25: end for"
        },
        {
            "heading": "3.4 Controlled Editing",
            "text": "To meet the requirement of label flipping, we need to edit the causal term conditioned on the uncovered new relation. The process can be regarded as controlled editing. We employ a prompt learning (Carlsson et al., 2022; Yang et al., 2022) method to accomplish this goal. Our proposed method consists of two stages, including finetuning and inference, as shown in Figure 2 (3).\nAt the fine-tuning stage, we put the available data into the pre-defined template and use them to fine-tune a generative model. Then, at the inference stage, we input the prompt that contains the new relation to the fine-tuned generative model and let it generate the content. Note the new relation is just the prompt, and the goal is to generate the masked tokens for satisfying this prompt. Finally, we treat the generated content as the counterfactual."
        },
        {
            "heading": "4 Evaluation Protocol",
            "text": ""
        },
        {
            "heading": "4.1 Low-resource Settings",
            "text": "Spurious correlations are particularly prevalent in low resource settings (Nan et al., 2021). To validate that CCG can mitigate such impact, we conduct\nexperiments on the low-resource SemEval (Hendrickx et al., 2019) under two scenarios i.e. 1%, 3%, 5%, 10% (Li et al., 2022a) and 2-shot, 4-shot, 8-shot, 16-shot, 32-shot (Chen et al., 2022)."
        },
        {
            "heading": "4.2 Out-of-domain Setting",
            "text": "Spurious correlations also exist in out-of-domain settings, due to domain-specific tokens (Calderon et al., 2022). To validate CCG\u2019s performance in this scenario, following previous work (Zhang et al., 2023), we employ the ACE 2005 dataset (Grishman et al., 2005) for evaluation. We select four sub-datasets from different domains, including weblogs (WL), conversation (BC), broadcast news (BN), and newswire (NW). Specifically, we conduct experiments with WL\u2192BC, WL\u2192BN and WL\u2192NW settings, respectively. Taking the WL\u2192BC setting as an example, we use WL as the training set, and BC as the test set."
        },
        {
            "heading": "4.3 Adversarial-attack Settings",
            "text": "Adversarial attacks are a common way for evaluating model robustness (Lin et al., 2021). We construct an adversarial-attack test dataset based on the original test set of SemEval, namely RE-Attack2. In general, we employ a semi-automatic approach to intervene on causal terms and entities separately, generating perturbed instances with flipped and invariant labels. Table 7 shows the detailed statistics of the datasets used in our experiments."
        },
        {
            "heading": "4.4 Baselines",
            "text": "The comparative methods include the following three types. The first type, conventional methods: (1) Synonym Replacement (Zhang et al., 2015) replaces words with synonyms; (2) Back Translation (Sennrich et al., 2015) translates text into another language, then translates it back; (3) BERTMLM (Jiao et al., 2019) replaces words by MLM.\nThe second type, counterfactual methods: (1) MICE (Ross et al., 2021) identifies causal terms by gradients and trains an editor to edit them; (2) AutoCAD (Wen et al., 2022) is similar with MICE, but it introduces unlikelihood strategy for the editor; (3) CoCo (Zhang et al., 2023) exploits syntactic and semantic dependency graphs to discover substitution. They all require consistency filtering.\nThe third type is LLM, we use ChatGPT, the most powerful LLM. We carefully designed a prompt to guide its generation of counterfactuals.\n2To the best of our knowledge, RE-Attack is the first dataset for adversarial-attack testing in RE."
        },
        {
            "heading": "4.5 Implementation Details",
            "text": "For our method, we use BERT-base as the intervenor and set N to 100. The constituency parser is from CoreNLP3. To ensure that at least one potential relation can be found for each instance, we set H to 0.8 in all experiments. To ensure quality, we set K to 1. For a fair comparison, all methods employ GPT-2 base (Radford et al., 2019) as editor.\nFollowing (Zhang et al., 2023), we use two representative PLMs i.e. BERT-base4 and RoBERTabase5 as the base model for RE. To better fit the task, the specific implementation details follow RBERT (Wu and He, 2019). We use the development set to select the optimal epoch for the base model.\n3https://stanfordnlp.github.io/CoreNLP/ 4https://huggingface.co/bert-base-uncased 5https://huggingface.co/roberta-base\nAll reported results are the mean and the standard deviation of micro-F1 value over 5 random seeds. For more implementation details, please check \u00a7A."
        },
        {
            "heading": "5 Results and Analysis",
            "text": ""
        },
        {
            "heading": "5.1 Results for Low-resource Settings",
            "text": "The results for low-resource settings are shown in Table 1. We make the following observations. 1) CCG achieves the best performance with relatively small standard deviations in almost all cases. The noteworthy point is that the improvement becomes more significant when the data size decreases. For example, the available data decreases from 10% to 1%, CCG gains about 1% to 9% enhancements. 2) The conventional methods exhibit unstable performance, which may lead to negative impacts. 3)\nThe counterfactual methods encounter a big challenge under extremely low-resource settings, e.g., 1% and 2-shot scenarios. This is because limited available data prevents the base model from working properly in consistency filtering. 4) Although ChatGPT possesses certain counterfactual reasoning capabilities in low-resource settings, it achieves suboptimal results. After observation, we find that it lacks proficiency in executing relation expansion."
        },
        {
            "heading": "5.2 Results for Out-of-domain Settings",
            "text": "Table 2 reports the results for out-of-domain settings. We make the following observations. 1) CCG outperforms all comparative methods in all target domains while maintaining relatively small standard deviations. 2) The conventional methods perform well when data is abundant, e.g., Back Trans. can achieve suboptimal results in WL\u2192BC and WL\u2192NW settings. 3) The enhancement brought by the counterfactual method is quite limited, the reason is that the base model is influenced by in-domain spurious correlations, making it once again unable to perform proper consistency filtering. 4) It is interesting that ChatGPT is always the worst, showing that it is unable to adapt itself in the settings for the counterfactual generation task."
        },
        {
            "heading": "5.3 Results for Adversarial-attack Settings",
            "text": "The results for the adversarial-attack settings are shown in Table 3. We make the following observations. 1) CCG achieves the best performance among all methods. The enhancement is quite significant, approximately 13-17%. 2) Generally, the counterfactual methods are superior to the conventional ones, which indicates that counterfactual augmented data provide more reliable assurance in complex and extreme scenarios, driving the base model to lean towards learning causal features."
        },
        {
            "heading": "5.4 Ablation Study",
            "text": "To validate the effectiveness of the main components in CCG, we introduce the following variant baselines for the ablation study. 1) CCG w/o MII removes the MLM Intervenor-based Indicator (MII) and replaces it with a gradient-based method (Wen et al., 2022). 2) CCG w/o Parser removes the constituency parser that is used for alleviating the problem of missing causal words. 3) CCG w/o LCA removes the Lowest Common Ancestor (LCA) strategy when discovering potential counterfactual relations. 4) CCG w/o WBR removes the WordNetbased Bottom-up Retrieval (WBR) and replaces it with a random selection strategy. 5) CCG w/o Editor removes the controlled Editor and directly fills the blank with the most frequent causal term in the dataset corresponding to the target relation. The experimental results are shown in Table 4.\nFrom Table 4, we can observe that, 1) Removing any of the modules or strategies causes performance degradation, which shows that every module in our approach plays an important role. 2) Removing MII or Parser results in up to 2.9% performance degradation, which further emphasizes the importance of identifying causal terms precisely and demonstrates the effectiveness of our approach to improve causal term identification. 3) Removing LCA or WBR results in a 2%-3% decrease, which shows the importance of the hierarchical structure of WordNet for finding target relations that conform to commonsense. 4) Removing Editor results in the most performance degradation, up to 6.3%, as using fixed causal terms introduces new biases."
        },
        {
            "heading": "5.5 Human Study",
            "text": "Since it is not possible to automatically evaluate the model\u2019s ability of causal terms identification and relation expansion, we conduct a human study.\nSpecifically, we randomly select 100 samples from SemEval and evaluate counterfactuals generated by CCG, CoCo, and AutoCAD by using manual annotation. The results are presented in Figure 3\nWe can observe that, 1) CCG substantially outperforms existing methods in finding causal terms, indicating that our proposed causal term identification module aligns best with the human experience. 2) Regarding the evaluation of whether the generated counterfactuals are consistent with commonsense, only CCG scores above 1, i.e., above the level of \u201cmarginally aligned\u201d. This shows that our proposed commonsense-constrained relation expansion module effectively improves the consistency of counterfactuals with human commonsense, resulting in more reasonable counterfactuals."
        },
        {
            "heading": "5.6 Case Study",
            "text": "To have a close look, we randomly select two instances from SemEval for the case study. Table 5 shows the original and augmented instances by CCG and other three typical methods. Clearly, the CCG counterfactuals conform to commonsense and align well with labels. In contrast, the counterfactuals of AutoCAD or CoCo violate the common-\nsense constraint. For example, in Case 1, there is a low likelihood of a Effect-Cause relation between entities \u201corca\u201d and \u201cexhibit\u201d. Furthermore, AutoCAD overlooks partial causal words in Case 1 and Case 2. CoCo is influenced by syntactic parsing errors in Case 1, which reduces the readability of the sentence. ChatGPT either generates illusory relation i.e. non-existent relation \u201cProduct-Container\u201d in Case 1, or reverses the relation in Case 2."
        },
        {
            "heading": "5.7 Readability Study",
            "text": "To thoroughly evaluate the quality of generated counterfactuals, we conduct a readability study to verify grammatical correctness and semantic readability based on Grammarly (Grammarly, 2023). Grammarly is a prevalent English typing assistant that reviews spelling, grammar, punctuation, clarity, engagement, and delivery mistakes in English texts, detects plagiarism, and suggests replacements for the identified errors (Wu et al., 2023).\nSpecifically, we randomly select 100 generated counterfactuals on SemEval from each method. We then treat these counterfactuals as a complete document and employ the Grammarly tool to check it. The results are shown in Figure 4. The results demonstrate that the grammatical correctness and semantic readability of CCG are only inferior to ChatGPT, but better than all other compared methods. After all, within an acceptable range of readability, what we focus on more is commonsense."
        },
        {
            "heading": "5.8 Parameter Study",
            "text": "The parameters H and K affect the amount of data augmentation, and we conducted a parameter study and show the results in Figure 5. Increasing the value of H indicates an expanded scope for upward retrieval in hypernyms, allowing more entity pairs to uncover potential relations. This continuously improves the model performance within a certain range. However, after reaching a certain threshold, they all start to decline, which validates that augmenting the training set with a small portion leads to more robust models (Treviso et al., 2023).\nOn the other hand, when more potential relations are taken into account, i.e. increasing the value of K, the performance of the base model shows a continuous downward trend. This phenomenon illustrates that the potential relations discovered earlier are more commonsense, CCG can correctly rank potential relations aligned with commonsense."
        },
        {
            "heading": "5.9 Conventional Setting Study",
            "text": "For common datasets, the quantity ratio of the training set to the test set is significantly larger than 1 (e.g. 2.65 in SemEval) and the distribution complies with the IID (Independent Identically Distribution) assumption. To explore the effectiveness of the main counterfactual methods under this set-\nting, we conduct a conventional setting study. The results are presented in Table 6. Consistent with the previous experimental findings (Kaushik et al., 2019; Sen et al., 2021; Wang and Culotta, 2021; Geva et al., 2022), the conventional setting cannot appropriately validate the effectiveness of counterfactuals. The benefits of counterfactuals, from either CCG or CoCo, are quite small under this setting. Other methods even have the opposite effect.\nIn this situation, the spurious correlations present in the test set are usually contained within the training set. This means that the spurious correlations can assist the model in finding shortcuts and improving accuracy (Sen et al., 2021). Therefore, when counterfactuals block spurious correlations, they may not help the model in terms of accuracy and could even have a counterproductive effect (Kaushik et al., 2019; Sen et al., 2021; Wang and Culotta, 2021; Geva et al., 2022)."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this paper, we solve the problems in existing methods of CAD, i.e., struggling to accurately identify causal terms under the invariant entity constraint and ignoring the commonsense constraint. We aim to produce the most human-like counterfactuals, i.e., not only grammatically correct and semantically readable but also consistent with commonsense. To this end, we need to satisfy the variant entity and commonsense constraints. To meet the first one, we present a novel intervention-based strategy, which can accurately identify the editable words by potential interventions. To meet the second one, we exploit WordNet to expand potential relations such that the counterfactual generation is constrained by commonsense. Extensive experimental results prove that our framework generates commonsense counterfactuals and outperforms the state-of-the-art baselines. It also consistently enhances the base models\u2019 stability across all settings.\nLimitations\nDespite the effectiveness of the relation expansion module for mining commonsense relations in CCG, the granularity of WordNet can affect the accuracy of the results, and WordNet as a static knowledge graph also faces the issue of temporal relevance, which makes it challenging for our method to handle emerging concepts. Therefore, we plan to integrate the principles of our algorithm with LLMs at a deep level, as these models encompass rich knowledge. Another limitation of our work is that CCG is still a pipeline framework. Some recent research attempts to jointly optimize a rationale extractor and a classifier in an end-to-end fashion (Paranjape et al., 2020; Yu et al., 2021). We plan to explore this direction."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was supported by a grant from the National Natural Science Foundation of China (NSFC) project (No. 62276193). It was also supported by the Joint Laboratory on Credit Science and Technology of CSCI-Wuhan University.\nEthics Statement\nOur work aims to explore the commonsense counterfactual generation, which is entirely at the methodological level and therefore does not have any negative social impact."
        },
        {
            "heading": "A Experimental Details",
            "text": "A.1 Datasets Low-resource Settings Following previous related works (Li et al., 2022a; Chen et al., 2022), we evaluate models\u2019 performance under two types of low-resource scenarios. Firstly, Li et al. (2022a) proposed a proportionally divided scenario, including 5% and 10% settings. Namely, randomly sampling 5% or 10% of data from a training set. In addition, we supplement 1% and 3% settings. Secondly, Chen et al. (2022) proposed a scenario divided by a fixed number of instances per relation, including 8-shot, 16-shot, and 32-shot settings. For example, for 8-shot, we randomly extract 8 instances from the training set for each relation. Furthermore, we include 2-shot and 4-shot settings. We introduce these more challenging settings for both scenarios in order to thoroughly assess models\u2019 effectiveness.\nOut-of-domain Settings ACE 2005 multilingual training corpus (Grishman et al., 2005) contains the complete set of English, Arabic, and Chinese training data for the 2005 Automatic Content Extraction (ACE) technology evaluation. In line with previous work (Zhang et al., 2023), we only conduct experiments on the English data. Due to copyright issues, please download the dataset from the provided link6. Refer to the processing approach of previous work (Zhong and Chen, 2021), we utilize the preprocessing code from DyGIE repository7.\nAdversarial-attack Settings To balance the tradeoff between time consumption and data quality, this adversarial-attack dataset is built in a semiautomatic way upon the test set of SemEval (Hendrickx et al., 2019). Specifically, we intervene each instance through label-flipped and label-invariant approaches. In the label-flipped case, for a given instance, we first replace its causal term with the different ones from other relations and flip its label. This allows us to obtain a large number of candidates, but only a small portion of them are readable. Then, we employ GPT-2 (Radford et al., 2019) to calculate their perplexity and select the top 10 sentences with the lowest perplexity for manual verification. Finally, we manually pick at most one sentence that meets the three aforementioned requirements in \u00a73.1 for each instance and apply it to RE-Attack. In the label-invariant situation, for a\n6https://catalog.ldc.upenn.edu/LDC2006T06 7https://github.com/luanyi/DyGIE/tree/master/\npreprocessing\ngiven instance, we first substitute its entities with different entities from instances with the same label. After obtaining various candidates, to pick up highquality sentences, we also apply the GPT-2-based strategy for automatic filtering. Finally, we manually choose at most one semantically fluent and relation-compliant sentence for each instance from the filtered candidates and apply it to RE-Attack.\nA.2 Baselines Conventional Methods Following previous work (Wen et al., 2022), the word-replacement ratio of Synonym Replacement (Zhang et al., 2015) and BERT-MLM (Jiao et al., 2019) is set to 30%. Specifically, we randomly select 30% of words in a sentence for replacement. For Synonym Replacement, the synonyms come from WordNet (Miller, 1995). For BERT-MLM, we employ BERT-base8 as the MLM for word substitution. We implement Back Translation (Sennrich et al., 2015) by using an online translation API9. Specifically, we first translate English sentences into Chinese text and then translate them back. To be consistent with previous work (Wen et al., 2022), all the methods mentioned above augment each instance once.\nCounterfactual Methods The current counterfactual methods lack a specialized design to conform with the commonsense constraint, including MICE (Ross et al., 2021), AutoCAD (Wen et al., 2022), and CoCo (Zhang et al., 2023). Therefore, during the implementation, these methods assume that all other relations can be potential ones. The ultimate data augmentation in quality control relies entirely on consistency filtering. Simultaneously, the quantity and ratio of data augmentation also depend on the filtering model. The detailed statistics of data augmentation are displayed in Table 8.\n8https://huggingface.co/bert-base-uncased 9https://api.fanyi.baidu.com/\nChatGPT In order to thoroughly unleash the counterfactual reasoning capability of ChatGPT, we design a clearly described and example-guided prompt, as described in Table 9. In this prompt, we incorporate the Chain-of-thought (COT) for step-wise decomposition, which has been proven effective in reasoning and commonsense to solve tasks (Huang et al., 2022; Wei et al., 2022). We divide the counterfactual generation of RE into three steps and provide specific descriptions for each one. Furthermore, we provide an example to help ChatGPT understand the assignment and standard format. In the implementation, we make use of the official API10 provided by OpenAI to perform all of our experiments. Specifically, taking into account both performance and resource consumption, the specific version we have chosen is gpt-3.5-turbo. Align with the conventional methods, ChatGPT also augments each instance once.\nA.3 Human Study\nTo intuitively analyze different strategies, we conduct a small-scale human study. Firstly, to evaluate the performance of various causal term identification strategies, we randomly select 100 instances from SemEval (Hendrickx et al., 2019) for manual annotation, where we manually identify the words that determine the relations between entities. Since we need to adhere to the principle of minimal edits, i.e. identifying causal words (recall) while avoiding affecting non-causal words (precision), we naturally utilize the F1-score for evaluation. It is worth noting that each instance is the smallest unit of data augmentation, hence each instance should be assigned the same weight. Treating each instance as an evaluation category, we employ the Macro-F1 score as a specific evaluation metric. Secondly, to directly evaluate the commonsense degree of generated counterfactuals, from SemEval, we randomly select 100 counterfac-\n10https://platform.openai.com/\ntual instances generated by each method for rating, respectively. Specifically, we assess an instance whether aligns with commonsense based on the relation role of entities. For instance, entity \u201cbuckets\u201d can take on the role of \u201cdestination\u201d, but not as \u201ceffect\u201d, as shown in Figure 1. Note that all annotations were completed by three individuals, who possess relevant research experiences, and the final decisions were determined through voting."
        }
    ],
    "title": "Generating Commonsense Counterfactuals for Stable Relation Extraction",
    "year": 2023
}