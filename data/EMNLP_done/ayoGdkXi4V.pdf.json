{
    "abstractText": "We explore the possibility of improving probabilistic models in structured prediction. Specifically, we combine the models with constrained decoding approaches in the context of token classification for information extraction. The decoding methods search for constraintsatisfying label-assignments while maximizing the total probability. To do this, we evaluate several existing approaches, as well as propose a novel decoding method called Lazy-k. Our findings demonstrate that constrained decoding approaches can significantly improve the models\u2019 performances, especially when using smaller models. The Lazy-k approach allows for more flexibility between decoding time and accuracy. The code for using Lazy-k decoding can be found here https://github.com/ ArthurDevNL/lazyk.",
    "authors": [
        {
            "affiliations": [],
            "name": "Arthur Hemmer"
        },
        {
            "affiliations": [],
            "name": "Micka\u00ebl Coustaty"
        },
        {
            "affiliations": [],
            "name": "Nicola Bartolo"
        },
        {
            "affiliations": [],
            "name": "J\u00e9r\u00f4me Brachat"
        },
        {
            "affiliations": [],
            "name": "Jean-Marc Ogier"
        }
    ],
    "id": "SP:de28c48675ee8d6d37a6521e8944b71ed4d18588",
    "references": [
        {
            "authors": [
                "Peter Anderson",
                "Basura Fernando",
                "Mark Johnson",
                "Stephen Gould."
            ],
            "title": "Guided open vocabulary image captioning with constrained beam search",
            "venue": "arXiv preprint arXiv:1612.00576.",
            "year": 2016
        },
        {
            "authors": [
                "R Bisiani"
            ],
            "title": "Beam search: Encyclopedia of artificial intelligence, sc shapiro (ed.): 56-58",
            "year": 1987
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "arXiv preprint arXiv:1810.04805.",
            "year": 2018
        },
        {
            "authors": [
                "Thibault Douzon",
                "Stefan Duffner",
                "Christophe Garcia",
                "J\u00e9r\u00e9my Espinas."
            ],
            "title": "Improving information extraction on business documents with specific pre-training tasks",
            "venue": "Document Analysis Systems: 15th IAPR International Workshop, DAS 2022, La",
            "year": 2022
        },
        {
            "authors": [
                "Hossein Rajaby Faghihi",
                "Aliakbar Nafar",
                "Chen Zheng",
                "Roshanak Mirzaee",
                "Yue Zhang",
                "Andrzej Uszok",
                "Alexander Wan",
                "Tanawan Premsri",
                "Dan Roth",
                "Parisa Kordjamshidi."
            ],
            "title": "Gluecons: A generic benchmark for learning under constraints",
            "venue": "arXiv",
            "year": 2023
        },
        {
            "authors": [
                "G David Forney."
            ],
            "title": "The viterbi algorithm",
            "venue": "Proceedings of the IEEE, 61(3):268\u2013278.",
            "year": 1973
        },
        {
            "authors": [
                "Chris Hokamp",
                "Qun Liu."
            ],
            "title": "Lexically constrained decoding for sequence generation using grid beam search",
            "venue": "arXiv preprint arXiv:1704.07138.",
            "year": 2017
        },
        {
            "authors": [
                "Yupan Huang",
                "Tengchao Lv",
                "Lei Cui",
                "Yutong Lu",
                "Furu Wei."
            ],
            "title": "Layoutlmv3: Pre-training for document ai with unified text and image masking",
            "venue": "Proceedings of the 30th ACM International Conference on Multimedia, pages 4083\u20134091.",
            "year": 2022
        },
        {
            "authors": [
                "A.H. Land",
                "A.G. Doig."
            ],
            "title": "An automatic method of solving discrete programming problems",
            "venue": "Econometrica, 28(3):497\u2013520.",
            "year": 1960
        },
        {
            "authors": [
                "Sofia Lemons",
                "Carlos Linares L\u00f3pez",
                "Robert C Holte",
                "Wheeler Ruml."
            ],
            "title": "Beam search: Faster and monotonic",
            "venue": "Proceedings of the International Conference on Automated Planning and Scheduling, volume 32, pages 222\u2013230.",
            "year": 2022
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Thi Tuyet Hai Nguyen",
                "Adam Jatowt",
                "Micka\u00ebl Coustaty",
                "Antoine Doucet."
            ],
            "title": "Survey of postocr processing approaches",
            "venue": "ACM Comput. Surv., 54(6):124:1\u2013124:37.",
            "year": 2022
        },
        {
            "authors": [
                "Xingyuan Pan",
                "Vivek Srikumar."
            ],
            "title": "Learning to speed up structured output prediction",
            "venue": "International Conference on Machine Learning, pages 3996\u20134005. PMLR.",
            "year": 2018
        },
        {
            "authors": [
                "Seunghyun Park",
                "Seung Shin",
                "Bado Lee",
                "Junyeop Lee",
                "Jaeheung Surh",
                "Minjoon Seo",
                "Hwalsuk Lee."
            ],
            "title": "Cord: a consolidated receipt dataset for post-ocr parsing",
            "venue": "Workshop on Document Intelligence at NeurIPS 2019.",
            "year": 2019
        },
        {
            "authors": [
                "Matt Post",
                "David Vilar."
            ],
            "title": "Fast lexically constrained decoding with dynamic beam allocation for neural machine translation",
            "venue": "arXiv preprint arXiv:1804.06609.",
            "year": 2018
        },
        {
            "authors": [
                "Lance A Ramshaw",
                "Mitchell P Marcus."
            ],
            "title": "Text chunking using transformation-based learning",
            "venue": "Natural language processing using very large corpora, pages 157\u2013176.",
            "year": 1999
        },
        {
            "authors": [
                "Dan Roth",
                "Wen-tau Yih."
            ],
            "title": "A linear programming formulation for global inference in natural language tasks",
            "venue": "Technical report, Illinois Univ at Urbana-Champaign Dept of Computer Science.",
            "year": 2004
        },
        {
            "authors": [
                "Dan Roth",
                "Wen-tau Yih."
            ],
            "title": "Global inference for entity and relation identification via a linear programming formulation",
            "venue": "Introduction to statistical relational learning, pages 553\u2013580.",
            "year": 2007
        },
        {
            "authors": [
                "Stuart Russel",
                "Peter Norvig"
            ],
            "title": "Artificial intelligence a modern approach",
            "year": 1994
        },
        {
            "authors": [
                "\u0160t\u011bp\u00e1n \u0160imsa",
                "Milan \u0160ulc",
                "Michal U\u0159i\u010d\u00e1\u0159",
                "Yash Patel",
                "Ahmed Hamdi",
                "Mat\u011bj Koci\u00e1n",
                "Maty\u00e1\u0161 Skalick\u1ef3",
                "Ji\u0159\u00ed Matas",
                "Antoine Doucet",
                "Micka\u00ebl Coustaty"
            ],
            "title": "Docile benchmark for document information localization and extraction",
            "year": 2023
        },
        {
            "authors": [
                "Hongbin Sun",
                "Zhanghui Kuang",
                "Xiaoyu Yue",
                "Chenhao Lin",
                "Wayne Zhang."
            ],
            "title": "Spatial dualmodality graph reasoning for key information extraction",
            "venue": "arXiv preprint arXiv:2103.14470.",
            "year": 2021
        },
        {
            "authors": [
                "Iulia Turc",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "Well-read students learn better: On the importance of pre-training compact models",
            "venue": "arXiv preprint arXiv:1908.08962.",
            "year": 2019
        },
        {
            "authors": [
                "Jiapeng Wang",
                "Lianwen Jin",
                "Kai Ding."
            ],
            "title": "Lilt: A simple yet effective language-independent layout transformer for structured document understanding",
            "venue": "arXiv preprint arXiv:2202.13669.",
            "year": 2022
        },
        {
            "authors": [
                "Yang Xu",
                "Yiheng Xu",
                "Tengchao Lv",
                "Lei Cui",
                "Furu Wei",
                "Guoxin Wang",
                "Yijuan Lu",
                "Dinei Florencio",
                "Cha Zhang",
                "Wanxiang Che"
            ],
            "title": "2020a. Layoutlmv2: Multi-modal pre-training for visually-rich document understanding",
            "venue": "arXiv preprint arXiv:2012.14740",
            "year": 2012
        },
        {
            "authors": [
                "Yiheng Xu",
                "Minghao Li",
                "Lei Cui",
                "Shaohan Huang",
                "Furu Wei",
                "Ming Zhou."
            ],
            "title": "Layoutlm: Pre-training of text and layout for document image understanding",
            "venue": "Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data",
            "year": 2020
        },
        {
            "authors": [
                "Takayuki Yoshizumi",
                "Teruhisa Miura",
                "Toru Ishida."
            ],
            "title": "A* with partial expansion for large branching factor problems",
            "venue": "AAAI/IAAI, pages 923\u2013929.",
            "year": 2000
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Much of today\u2019s Information Extraction (IE) is done using probability-based token-classification models such as BERT (Devlin et al., 2018), RoBERTa (Liu et al., 2019), LayoutLM (Xu et al., 2020b,a; Huang et al., 2022) or LiLT (Wang et al., 2022). These models aim for the best results by increasingly stacking large amounts of parameters, which comes at the cost of increased computational requirements and training complexity. Typically, only the top-1 prediction is used, despite the fact that models produce probabilities for all tokenlabel combinations.\nIdeally, alternative, high-likelihood predictions are explored to improve predictions from existing models. This is especially interesting in structuredprediction tasks, where the model\u2019s predictions are parsed into predefined structures. These structures\nallow for defining constraints that evaluate whether a produced prediction adheres to the expected structure, which can then be used to iterate over multiple high probability predictions until a satisfying solution is found.\nA concrete example of such a structure is in the case of invoice information extraction. In this task, the model is given the outputs of an Optical Character Recognition (OCR) system and needs to predict which parts of the text correspond to the various elements in an invoice. For example, in Fig. 1, the model is expected to predict the total, cash and change amounts.\nHowever, the occlusion of the \u201cCASH\u201d text introduces noise into the model\u2019s predictions, causing it to incorrectly label the cash amount as another total amount. Using the arithmetic semantics of invoices, we know that the total amount should equal the cash amount paid minus the change amount. As such, we know that the model\u2019s best prediction is probably incorrect. Alternative, high-probability labelassignments can be explored to find a constraintsatisfying solution instead.\nIndustrial document processing systems usually\nhave programmatic post-processing logic that detects and sometimes corrects aforementioned semantic constraints. These systems, however, rarely exploit the remaining information \u201chidden\u201d in the produced probability distributions, and the custom correction code is often complex and hard to maintain. Furthermore there is the possibility of OCRinduced errors, which go beyond the scope of the present work but remain an important source of errors in document IE (Nguyen et al., 2022).\nIn short, we exploit task-specific structures to explore alternative high-likelihood predictions. Specifically, we\n\u2022 propose an efficient algorithm for iterating over high-likelihood predictions and,\n\u2022 provide a proof for the correctness of the algorithm and,\n\u2022 perform several experiments to evaluate the relevance of exploring alternative highlikelihood predictions in structured prediction tasks."
        },
        {
            "heading": "2 Background",
            "text": "To search over high-probability predictions, we require a probabilistic model that outputs independent probabilities for a given sequence of tokens. Given an input sequence x = {x1, x2, . . . , xn}, xi \u2208 X where X is the token vocabulary, the goal is to estimate the probability of the output sequence y = {y1, y2, . . . , yn}, yi \u2208 Y where Y is the label vocabulary. As this probability quickly becomes intractable, it is usually estimated by factoring it as:\np(y|x) = n\u220f i p(yi|x). (1)\nThe decoding process refers to the way we obtain an estimate y\u0302 for y from such a model. The simplest approach consists of taking the argmax as\ny\u0302 = argmax y\u2208Yn\np(y|x), (2)\nwhich is done for each yi separately. In addition, we introduce a global, binary constraint C : x \u00d7 y \u2192 {0, 1} and formalize our problem of interest as\ny\u0302 = argmax y\u2208Yn\np(y|x) \u00b7 C(x,y). (3)\nNote that for the method proposed in Sec. 4, we make no further assumption about the constraint. This is important because many existing constrained decoding approaches require the constraints to be expressed in linear form (Faghihi et al., 2023).\nSome problems may consist of both linear and non-linear constraints. Token-classification models often use the BIO labeling scheme (Ramshaw and Marcus, 1999), where the labels are prefixed with B(eginning), I(nside) and O(utside) to be able to classify spans of multiple tokens. In this formulation, an I label must always be preceded by a B or another I label of the same class.\nThis labeling constraint can be expressed using linear constraints. However, the solution to the linear constraints is not guaranteed to also be a solution to the non-linear constraints. The semantic constraint cash = total + change cannot be expressed linearly because in order to compute it, the text corresponding to the labelization must be parsed from text to a float, which is a non-linear operation. An example where the optimal solution satisfying the linear (BIO) constraints does not satisfy the non-linear (semantic) constraints is shown in Tab. 1(b) one line 4."
        },
        {
            "heading": "3 Related Work",
            "text": "Several decoding methods for the setting from Eq. (3) have been proposed. An excellent benchmark for learning and decoding under constraints is provided in GLUECons (Faghihi et al., 2023). For decoding, the work mostly explores the usage of Integer Linear Programming (ILP) for finding a constraint-satisfying solution given the model\u2019s probabilities.\nILP problems can be solved using the branch and bound algorithm (Land and Doig, 1960), which is a type of informed search algorithm; it uses a linear formulation of the constraints to guide it more effectively through the search space. Another example of a method that uses knowledge about its constraints is Viterbi (Forney, 1973), which is a dynamic programming approach that can also take into account specific constraints, although more restrictive than ILP as it only works in a Markovian setting. The advantage of these informed search methods is that they will always find the optimal answer within a reasonable amount of time, should it exist. However, they also have a non-negligible minimum running time and impose aforementioned\nrequirements on the constraints. Informed search methods have previously been applied to the task of information extraction. Decoding under constraints using ILP was inspired by the work from Roth and Yih who explored the application to entity and relation extraction (Roth and Yih, 2004, 2007). They formulate the decoding problem as a linear program with the objective to maximize the overall probability of a sequence given a set of constraints.\nIn these programs, the decision variables are indicator variables 1ji , indicating the assignment of label j to token i. Using this, one can express the constraint \u201c1 label per token\u201d as \u2200i \u2211l j=1 1 j i = 1 where l is the number of possible labels. Using this linear formulation for several other constraints, they observe 2-5% improvements in F1-score on entity and relation classification tasks. Similarly, Viterbi has also been used for correcting structured predictions (Douzon et al., 2022).\nFor more complex constraints we can use uninformed search methods as they do not make any assumptions on the implementation of the constraints and simply iterate over the search space in a greedy manner. The most widely known method for this is Beam Search (BS) (Bisiani, 1987). While it does not impose any restriction on the type of constraints, it is not ideal to our global decoding setting as it works in a \u201cleft-to-right\u201d manner.\nTo illustrate, BS takes as input a parameter k and outputs the top-k sequences by computing the top-k beams at every token, based on the previous top-k beams. In order to evaluate global constraints, beam search first needs to compute all top-k sequences after which the constraint can be evaluated.\nUnfortunately, this means that if the constraintvalidating prediction ends up being the most likely (argmax) sequence, beam search will have computed k\u2212 1 too many sequences. In addition, if the constraint-validating prediction is not in the topk beams, a new search with an unknown, higher k\u2032 needs to be run, which also includes recomputing the initial previous k predictions. Several adaptations have been suggested in the context of natural language generation (Anderson et al., 2016; Hokamp and Liu, 2017; Post and Vilar, 2018; Lemons et al., 2022), but none of which solve aforementioned problems for global constraints. Others propose extending beam search with learnable heuristics that try to predict whether a given\nlabel-assignment might violate future structure constraints (Pan and Srikumar, 2018).\nOur method follows a similar approach to A\u00d7 with Partial Expansion (Yoshizumi et al., 2000) which has previously been applied to the multiple sequence alignment problem.\nTo our knowledge, we are the first to apply A* with partial expansion that allows for more general constraints than ILP for the global constraint decoding setting.\n4 Lazy-k Decoding\nAs the name suggests, the Lazy-k decoder allows for decoding the k most probable sequences in a lazy manner. This means that it only iterates over the necessary number of sequences and stops once a satisfying solution is found. The hypothesis that this decoder explores is that the constraintsatisfying sequence is somewhere among the other high probability sequences.\nTo do this efficiently, we exploit the fact that the k-th most probable sequence is always within \u201ceditdistance\u201d 1 from one of the k \u2212 1 more probable sequences. This follows from the independence of each label as shown in Eq. 1. We put \u201ceditdistance\u201d in quotes here because we use a slightly more strict definition of edit-distance that also takes\ninto account the order between the various label probabilities. More details about this can be found in App. A.\nAt its core, it is a variant of best-first search (Russel et al., 1994), where the model\u2019s predictions are used to determine the order in which the possible label assignments are explored. Each state represents a full label assignment y = {y1, y2, . . . , yn} for all n tokens x = {x1, x2, . . . , xn}. The cost g(y) of a state is defined as follows:\ng(y) = \u2212 n\u2211\ni=1\nlog p(yi|x). (4)\nWe use yk to denote the k-th lowest cost label assignment, and define the starting point y1 as:\ny1 = argmin y\u2208Yn g(y) (5)\nThe algorithm for Lazy-k decoding is given in Alg. 1. It works by maintaining a heap of the k best states, prioritized by the score of the next best unexplored state within 1 edit distance. The heap is initialized with the starting state y1. Upon exploring a state, it is tested against the constraint and returns directly if it is satisfied. If the constraint is not satisfied, the heap is extended with the newly explored state and the priority score of the originating state yi is updated to reflect the score of the next best unexplored state.\nDifferent from best-first search, upon exploring a state, we do not add all the children to the heap. Instead, we only add the next best state yk and update the priority key for yi to be the score of the next best state within edit distance 1. This significantly reduces the size of the heap, as a classical search implementation adds n possible children at every iteration, whereas in this case, the number of states in the heap is at most equal to the number of iterations. This heap-size reduction in turn translates in better run time complexity as all following heap operations become cheaper.\nThe NextBest function takes as input a state y and the frontier. The frontier is a dictionary that holds the explored states and next best states for all explored states. The values are integers that keep track of the i-th best change for a given state. If i == n (the number of tokens) then the function returns null as there is no next best change within 1 edit-distance for this state. As the next best state may already exist in the frontier, the NextBest function is wrapped in AddNextBest to make sure\nAlgorithm 1 Lazy-k Decoding Require: Input sequence: x Require: Cost function g from Eq. 4 Require: Binary constraint C, max iterations k\n1: function LAZY-K(x, g, C, k) 2: y1 \u2190 argminy\u2208Yn g(y) 3: if C(x,y1) = 1 then return y1 4: H \u2190MinHeap() 5: frontier\u2190 {y1 : 1} 6: AddNextBest(y1, H, frontier) 7: count\u2190 1 8: while H not empty and count < k do 9: yi \u2190 H .PopMin()\n10: yk \u2190NextBest(yi, frontier) 11: if C(x,yk) = 1 then return yk 12: AddNextBest(yk, H, frontier) 13: AddNextBest(yi, H, frontier) 14: count += 1 15: end while 16: return Failure 17: end function 18: 19: function ADDNEXTBEST(yi, H, frontier) 20: yij \u2190NextBest(yi, frontier) 21: while yij \u0338= null and yij \u2208 frontier do 22: frontier[yi] += 1 23: yij \u2190NextBest(yi, frontier) 24: end while 25: if yij \u0338= null then 26: frontier[yij ]\u2190 1 27: H .Add(yi, g(yij)) 28: end if 29: end function\nto only add next best states to the frontier that are not already in there. See App. B for the pseudocode for the NextBest function.\nGiven that the algorithm iterates over the possible sequences in decreasing order of probability, it is trivial to prove that it will always find the optimal solution should it exist. In practice however, the combinatorial growth in the number of states quickly renders exhaustive search infeasible. To prevent this, an additional stopping condition is used where the iteration stops if no satisfying solution has been found after a fixed number of k iterations. One could also set the stopping condition according to a cumulative probability mass p or some other measure; we leave this exploration for future work."
        },
        {
            "heading": "4.1 Complexity Analysis",
            "text": "Assuming n tokens, l labels and the requested topk sequences. The space complexity of Lazy-k is O(kn), since for every k-best state we add at most 1 new state of size n to the heap.\nThe time complexity is slightly less obvious. For the top-k states, the outer while loop will run for k iterations. Inside this loop, there are two sources of complexity:\n1. H .Add() which occurs at most twice in AddNextBest(),\n2. NextBest() which occurs once in the outer loop and twice in AddNextBest in another while loop.\nThe H .Add() operation adds an element to the heap which is of logarithmic complexity with respect to the size of the heap. Since the heap holds exactly our top-k states at each iteration, the complexity of this operation is equal to \u2211k i=1 log i =\nlog \u220fk\ni=1 i = log k! which, using Stirling\u2019s approximation, is equivalent to O(k log k).\nThe NextBest(y, frontier) function returns the frontier[y]-th next best state within 1 edit distance of y. When expanding a state for the first time, we compute a sorted list of next-best edits in O(n log n) time. Using this, every NextBest call for this state can be computed in constant time. For every state, NextBest() is called at most n times. As the sorting takes n log n time, the total time complexity of the algorithm becomes: O(k(log k + n log n))."
        },
        {
            "heading": "5 Experiments",
            "text": "To evaluate the relevance of the Lazy-k decoder, we perform invoice information extraction on several datasets. The aim of the task is to extract various amounts from invoices such that they satisfy their expected arithmetic structure. For each dataset, we train a token-classification model and generate predictions for the test set. The predictions are then fed into the different decoding algorithms along with the constraints, and return the highest-probability sequence satisfying the constraints.\nData We evaluate the decoders on a total of three datasets shown in Tab. 2: CORD (Park et al., 2019), WildReceipt (Sun et al., 2021) and DocILE (\u0160imsa et al., 2023). While the constraints are semantically\nvery similar, the datasets have slightly different labels and different levels of granularity which means each dataset has its own specific set of constraints.\nThe exact constraints for each dataset are detailed in App. C. The models for all datasets are trained using BIO labels, for which the initial constraint is that a label-assignment should be a valid BIO sequence.\nThe other constraints depend on the specific labels available in each dataset. However, it is possible for some labels not to be present in every sample. As such, we distinguish between mandatory fields (ie total amount) and optional fields (ie service fee, discount) which are considered 0 if not found. A mandatory fields will be considered empty if is not present in the predictions. As such, any constraint involving this field is not evaluated (or automatically considered as satisfied).\nFor each dataset, we apply the constraints to all samples and filter out any that do not satisfy the constraints (show counts in table). From these samples, we use 60% for training and validation (split 80-20), and 40% for testing. The samples not satisfying the constraints are added to the training set. We purposefully choose a large percentage for the test as the small train set provided sufficient performance and we mostly wish to evaluate the decoding. Having the larger test set allows us to reduce the variance in our measurements and make stronger conclusions.\nEvaluation Metric Our primary evaluation metric F s1 is the product of the micro-F1 score and the percentage of samples satisfying all the constraints. We chose this metric as it allows us to measure the balance between the extraction performance and constraint satisfaction. Our filtering procedure ensures that all the test samples can completely satisfy the constraints.\nModels For each dataset, we fine-tune a LayoutLM (Xu et al., 2020b) model for a total of 20 epochs with a batch-size of 32 and a learning rate 0.001. The models were trained using a NVIDIA\nA40 (48GB) and the inference was done on an Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz.\nMethods The Lazy-k performance is compared to both BS and ILP, as well as an Argmax baseline and a vanilla Best-First implementation. Since ILP does not support non-linear constraints, we propose a Lazy-ILP variant that works similar to Lazy-k. This method iteratively looks for the highest probability solution satisfying the linear constraints and checks if it also satisfies the non-linear constraints. If it does not, the previous optimal solution is explicitly excluded by adding a new constraint and a new solve is started. In our implementations we use the Python PuLP* package for solving the ILP problems. We chose various values for k for each method, such that it would approximately give the same total running time on different datasets. BS and Best-First are evaluated on less values for k because of their likeness with Lazy-k (exhaustive search) but slower already.\nResults The results for the LayoutLM model for the different datasets are shown in Tab. 3. It can be seen that constrained decoding approaches can significantly improve the F s1 with respect to the Argmax baseline. For WildReceipt, the F s1 score almost doubles from 44.5% to 82.1%. CORD sees a relatively smaller improvement in F s1 by going from 81.2% to 94.9% in the best case.\nThe Lazy-ILP decoder achieves a relatively high F s1 after only one iteration, whereas BS, Lazy-k and Best-First grow more gradually with respect to k. This can be explained by the fact that Lazy-ILP directly finds the first sequence satisfying the linear (BIO) constraints whereas the other approaches might need to iterate over multiple sequences to find the sequences satisfying the linear constraints. Lazy-k achieves the F s1 of Lazy-ILP (k = 1) at k \u2248 211 for CORD, k \u2248 26 for WildReceipt, and k \u2248 27 for DocILE.\nLazy-ILP\u2019s high minimum F s1 score also comes at a non-negligible average decoding time. For the same F s1 score as Lazy-ILP (k = 2\n0), Lazyk is around 38x faster for CORD, 144x faster for WildReceipt and 182x faster for DocILE. However, as k grows, the running time for Lazy-k becomes more significant. As expected, BS is much slower than the other methods. Because of the higher running time, we cut off the computation at k = 25. For the same k, Lazy-k is 150-500 times faster\n*PuLP https://pypi.org/project/PuLP/\ndepending on the dataset. It should be noted that the difference in running time between the different datasets can be primarily attributed to the average page lengths per dataset as shown in Tab. 2."
        },
        {
            "heading": "5.1 Smaller Models",
            "text": "A stated advantage is the possibility of using smaller models in combination with the constrained decoding methods to improve their performance. We devised a second experiment similar to the first one, but where we train several smaller models to evaluate the additional benefit of using constrained decoding approaches. The smaller pretrained BERT models were provided as part of a paper on the importance on pre-training compact models (Turc et al., 2019), and are tiny (4.4M parameters), mini (11.3M), small (29.1M) and medium (41.7M) respectively. We also fine-tune a BERT base model counting 110.1M parameters. As Lazyk gives the same results as BS and Best-First search but more efficiently, we only compare Lazy-k to ILP.\nResults The results are shown in Fig. 2. We observe the added value of constrained decoding increasing as the model gets smaller. In the extreme case of BERT tiny, the F s1 score of the Argmax approaches 0%, but is increased significantly when combined with ILP. However, this can partially be explained by our choice of measuring the F s1 as the product between the F1 and satisfaction ratio. Though not shown in the figures, most of the increase in F s1 can be attributed to the satisfaction ratio.\nAs the models get smaller, ILP gains in advantage with respect to Lazy-k when keeping the number of iterations constant. This means that in many cases the top-8 linear (BIO) constraint-satisfying solutions are outside of the 214 highest probability label-assignments. We wonder whether training the network to better predict correct BIO sequences would improve the overall performance, but we leave this for future work to explore."
        },
        {
            "heading": "5.2 Discussion",
            "text": "In the context of information extraction from invoices, Lazy-k can be viable approaches for constrained decoding. While ILP has the advantage of exactly computing optimal solutions to the linear constraints, it also comes at an important minimum run time cost. Depending on the \u201cspacing\u201d between the solutions to the linear and non-linear\nconstraints, Lazy-k might be more suited to the problem. Although not measured in our experiments, Lazy-k also has a more significant memory usage than ILP because it needs to keep all previous solutions in the heap.\nOn the smaller models we observe a larger impact from constrained decoding approaches. We find these results promising for resources constrained applications and from an ecological point of view. We are able to achieve similar performance with significantly lighter models and less computational resources.\nBesides the performance one should also take into account the ease of implementation of the different methods. The Lazy-k decoder is \u201cplug-andplay\u201d as it does not need any conversion of the constraints. While the linear constraints used in this paper were fairly trivial to implement, more complex problems will require more complex linear formulation which can be costly to implement correctly.\nFor the setting discussed in this paper, beam search is not recommended because of the limitation discussed in Sec. 3. However, it remains valid in the autoregressive decoding setting as this is not supported with the other methods."
        },
        {
            "heading": "6 Conclusion",
            "text": "In summary, we have introduced a novel and efficient decoding method called Lazy-k that allows for decoding under global, hard constraints. When applied in the context of invoice information extraction, Lazy-k is faster than existing, greedy search methods and allows for more flexibility in trading off computing time and extraction performance compared to ILP. In addition, the possibility of using programmatic constraints directly makes Lazyk an easy to use off-the-shelf solution for applying corrections to probabilistic models in the context of structured predictions.\nFuture work could explore the application to other structured-prediction problems with non-\nlinear constraints besides information extraction. Additionally, the improvements in extraction performance using the decoding methods are promising, which could also be explored in semisupervised learning settings. Another interesting direction to explore would be the combination of Lazy-k decoding with confidence calibration methods such as temperature scaling.\nLimitations\nMost methods presented in this paper only apply to the independent label-probability setting whereas much of today\u2019s work in NLP uses the autoregressive, generative setting. Furthermore, the methods only apply to tasks that can be formulated as struc-\ntured predictions tasks. It may not be possible to specify concrete constraints for some tasks. We did not explore the integration of soft constraints, which are constraints that can have a degree of satisfaction instead of the binary values considered in this paper.\nEthics Statement\nWe have not identified any direct ethical concerns with the presented methods and experiments. On the contrary, we believe that our method improves the verifiability of probabilistic predictions which allows for better control over opaque probabilistic methods. Furthermore, we have shown the potential for extracting more performance out of smaller models which reduces the overall energy consumption required for training and inference."
        },
        {
            "heading": "7 Acknowledgement",
            "text": "This work was supported by the French government in the framework of the France Relance program."
        },
        {
            "heading": "B NextBest",
            "text": "Algorithm 2 NextBest Implementation Require: Label assignment: y Require:\n1: function NEXTBEST(y, frontier) 2: if frontier[y] == y.Length then return\nnull 3: diffs\u2190 {log yj+1i \u2212 log y j i |y j i \u2208 y} \u25b7\nNotation from Eq. 7 4: i\u2190 ArgSort(diffs)[frontier[y]] \u25b7 Cached 5: yji \u2190 y j+1 i 6: y[i]\u2190 yj+1i 7: return y 8: end function"
        },
        {
            "heading": "C Constraints",
            "text": "Below are the constraints used for each dataset. All models are trained using the BIO labeling scheme and as such, the correct BIO constraint is used for all datasets. In addition, each numerical field in has the constraint that it needs to be parseable to\na float. A * next to a field indicates that the field is optional and thus considered false if no value is predicted for a given document.\nC.1 CORD\n\u2022menu.sub.price = sub_total.subtotal_price \u2022 sub_total.tax_price = 10%\n\u00d7 (sub_total.subtotal_price + sub_total.service_price\u2217)\n\u2022 total.cashprice = total.total_price + total.changeprice\n\u2022 total.total_price = sub_total.subtotal_price\n+ sub_total.tax_price + sub_total.service_price\u2217 \u2212 sub_total.discount_price\u2217\nC.2 WildReceipt\n\u2022 total_value = subtotal_value + tax_value \u2022 subtotal_value = \u2211 prod_price_value\nC.3 DocILE\n\u2022 amount_total_gross = amount_total_net + amount_total_tax\n\u2022 amount_due = amount_paid + amount_total_gross"
        }
    ],
    "title": "Lazy-k: Decoding for Constrained Information Extraction",
    "year": 2023
}