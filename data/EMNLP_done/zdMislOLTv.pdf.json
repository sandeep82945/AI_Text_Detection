{
    "abstractText": "Intent discovery is a crucial task in natural language processing, and it is increasingly relevant for various of industrial applications. Identifying novel, unseen intents from user inputs remains one of the biggest challenges in this field. Herein, we propose Zero-Shot-BERT-Adapters, a two-stage method for multilingual intent discovery relying on a Transformer architecture fine-tuned with Adapters. We train the model for Natural Language Inference (NLI) and later perform unknown intent classification in a zeroshot setting for multiple languages. In our evaluation, we first analyze the quality of the model after adaptive fine-tuning on known classes. Secondly, we evaluate its performance in casting intent classification as an NLI task. Lastly, we test the zero-shot performance of the model on unseen classes, showing how Zero-Shot-BERT-Adapters can effectively perform intent discovery by generating semantically similar intents, if not equal, to the ground-truth ones. Our experiments show how Zero-Shot-BERT-Adapters outperforms various baselines in two zero-shot settings: known intent classification and unseen intent discovery. The proposed pipeline holds the potential for broad application in customer care. It enables automated dynamic triage using a lightweight model that can be easily deployed and scaled in various business scenarios, unlike large language models. ZeroShot-BERT-Adapters represents an innovative multi-language approach for intent discovery, enabling the online generation of novel intents. A Python package implementing the pipeline and the new datasets we compiled are available at the following link: https://github. com/GT4SD/zero-shot-bert-adapters.",
    "authors": [
        {
            "affiliations": [],
            "name": "Daniele Comi"
        },
        {
            "affiliations": [],
            "name": "Dimitrios Christofidellis"
        },
        {
            "affiliations": [],
            "name": "Pier Francesco Piazza"
        },
        {
            "affiliations": [],
            "name": "Matteo Manica"
        }
    ],
    "id": "SP:a5587620f2486eb86713f76c844e350cd41b05a8",
    "references": [
        {
            "authors": [
                "Valentina Bellomaria",
                "Giuseppe Castellucci",
                "Andrea Favalli",
                "Raniero Romagnoli"
            ],
            "title": "Almawaveslu: A new dataset for slu in italian",
            "year": 2019
        },
        {
            "authors": [
                "Bowman",
                "Samuel R.",
                "Angeli",
                "Gabor",
                "Potts",
                "Christopher",
                "Manning",
                "Christopher D."
            ],
            "title": "A large annotated corpus for learning natural language inference",
            "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
            "year": 2015
        },
        {
            "authors": [
                "Tom B. Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah"
            ],
            "title": "Language models are few-shot learners. CoRR, abs/2005.14165",
            "year": 2020
        },
        {
            "authors": [
                "I\u00f1igo Casanueva",
                "Tadas Temcinas",
                "Daniela Gerz",
                "Matthew Henderson",
                "Ivan Vulic."
            ],
            "title": "Efficient intent detection with dual sentence encoders",
            "venue": "CoRR, abs/2003.04807.",
            "year": 2020
        },
        {
            "authors": [
                "Daniel Cer",
                "Yinfei Yang",
                "Sheng-yi Kong",
                "Nan Hua",
                "Nicole Limtiaco",
                "Rhomni St. John",
                "Noah Constant",
                "Mario Guajardo-Cespedes",
                "Steve Yuan",
                "Chris Tar",
                "Yun-Hsuan Sung",
                "Brian Strope",
                "Ray Kurzweil"
            ],
            "title": "Universal sentence encoder",
            "year": 2018
        },
        {
            "authors": [
                "Aakanksha Chowdhery",
                "Sharan Narang",
                "Jacob Devlin"
            ],
            "title": "2022. Palm: Scaling language modeling with pathways",
            "year": 2022
        },
        {
            "authors": [
                "Bavarian State Library dbmdz."
            ],
            "title": "Italian xxl electra",
            "venue": "https://github.com/dbmdz/berts.",
            "year": 2020
        },
        {
            "authors": [
                "Deepset."
            ],
            "title": "Bert-base-german-cased",
            "venue": "https:// huggingface.co/bert-base-german-cased.",
            "year": 2019
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "arXiv preprint arXiv:1810.04805.",
            "year": 2018
        },
        {
            "authors": [
                "ExplosionAI."
            ],
            "title": "spacy",
            "venue": "https://github.com/ explosion/spaCy.",
            "year": 2015
        },
        {
            "authors": [
                "ExplosionAI."
            ],
            "title": "spacy-transformers",
            "venue": "https:// github.com/explosion/spacy-transformers.",
            "year": 2019
        },
        {
            "authors": [
                "Matthew Honnibal",
                "Mark Johnson."
            ],
            "title": "An improved non-monotonic transition system for dependency parsing",
            "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1373\u20131378, Lisbon, Portugal. As-",
            "year": 2015
        },
        {
            "authors": [
                "Matthew Honnibal",
                "Ines Montani",
                "Sofie Van Landeghem",
                "Adriane Boyd"
            ],
            "title": "spaCy: Industrial-strength Natural Language Processing in Python",
            "year": 2020
        },
        {
            "authors": [
                "Neil Houlsby",
                "Andrei Giurgiu",
                "Stanislaw Jastrzebski",
                "Bruna Morrone",
                "Quentin De Laroussilhe",
                "Andrea Gesmundo",
                "Mona Attariyan",
                "Sylvain Gelly."
            ],
            "title": "Parameter-efficient transfer learning for nlp",
            "venue": "International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "Anjishnu Kumar",
                "Pavankumar Reddy Muddireddy",
                "Markus Dreyer",
                "Bj\u00f6rn Hoffmeister."
            ],
            "title": "Zeroshot learning across heterogeneous overlapping domains",
            "venue": "INTERSPEECH, pages 2914\u20132918.",
            "year": 2017
        },
        {
            "authors": [
                "DataBricks lab."
            ],
            "title": "Free dolly: Introducing the world\u2019s first truly open instruction-tuned llm",
            "venue": "https://ibm.biz/dolly-release-blog.",
            "year": 2023
        },
        {
            "authors": [
                "Stefan Larson",
                "Anish Mahendran",
                "Joseph J. Peper",
                "Christopher Clarke",
                "Andrew Lee",
                "Parker Hill",
                "Jonathan K. Kummerfeld",
                "Kevin Leach",
                "Michael A. Laurenzano",
                "Lingjia Tang",
                "Jason Mars"
            ],
            "title": "An evaluation dataset for intent classification",
            "year": 2019
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdelrahman Mohamed",
                "Omer Levy",
                "Ves Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "Bart: Denoising sequence-to-sequence pre-training for natural language",
            "year": 2019
        },
        {
            "authors": [
                "Bill Yuchen Lin",
                "Kangmin Tan",
                "Chris Miller",
                "Beiwen Tian",
                "Xiang Ren"
            ],
            "title": "Unsupervised crosstask generalization via retrieval augmentation",
            "year": 2022
        },
        {
            "authors": [
                "Han Liu",
                "Siyang Zhao",
                "Xiaotong Zhang",
                "Feng Zhang",
                "Junjie Sun",
                "Hong Yu",
                "Xianchao Zhang."
            ],
            "title": "A simple meta-learning paradigm for zero-shot intent classification with mixture attention mechanism",
            "venue": "arXiv preprint arXiv:2206.02179.",
            "year": 2022
        },
        {
            "authors": [
                "Pengfei Liu",
                "Youzhang Ning",
                "King Keung Wu",
                "Kun Li",
                "Helen Meng."
            ],
            "title": "Open intent discovery through unsupervised semantic clustering and dependency parsing",
            "venue": "arXiv preprint arXiv:2104.12114.",
            "year": 2021
        },
        {
            "authors": [
                "Zihan Liu",
                "Genta Indra Winata",
                "Zhaojiang Lin",
                "Peng Xu",
                "Pascale Fung"
            ],
            "title": "Attention-informed mixed-language training for zero-shot cross-lingual task-oriented dialogue systems",
            "year": 2019
        },
        {
            "authors": [
                "Edward Loper",
                "Steven Bird"
            ],
            "title": "Nltk: The natural language toolkit",
            "year": 2002
        },
        {
            "authors": [
                "Ilya Loshchilov",
                "Frank Hutter"
            ],
            "title": "Decoupled weight decay regularization",
            "year": 2017
        },
        {
            "authors": [
                "George A Miller."
            ],
            "title": "Wordnet: a lexical database for english",
            "venue": "Communications of the ACM, 38(11):39\u2013",
            "year": 1995
        },
        {
            "authors": [
                "Jinjie Ni",
                "Tom Young",
                "Vlad Pandelea",
                "Fuzhao Xue",
                "Vinay Adiga",
                "Erik Cambria"
            ],
            "title": "Recent advances in deep learning based dialogue systems: A systematic survey",
            "venue": "arXiv preprint arXiv:2105.04387",
            "year": 2021
        },
        {
            "authors": [
                "Massimo Nicosia",
                "Zhongdi Qu",
                "Yasemin Altun"
            ],
            "title": "Translate & fill: Improving zero-shot multilingual semantic parsing with synthetic data",
            "year": 2021
        },
        {
            "authors": [
                "Joakim Nivre",
                "Jens Nilsson."
            ],
            "title": "Pseudoprojective dependency parsing",
            "venue": "Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL\u201905), pages 99\u2013106, Ann Arbor, Michigan. Association for Computational",
            "year": 2005
        },
        {
            "authors": [
                "OpenAI."
            ],
            "title": "Introducing chatgpt",
            "venue": "https://openai. com/blog/chatgpt.",
            "year": 2022
        },
        {
            "authors": [
                "ter Welinder",
                "Paul Christiano",
                "Jan Leike",
                "Ryan Lowe"
            ],
            "title": "Training language models to follow instructions with human feedback",
            "year": 2022
        },
        {
            "authors": [
                "Soham Parikh",
                "Quaizar Vohra",
                "Prashil Tumbade",
                "Mitul Tiwari."
            ],
            "title": "Exploring zero and few-shot techniques for intent classification",
            "venue": "arXiv preprint arXiv:2305.07157.",
            "year": 2023
        },
        {
            "authors": [
                "Jonas Pfeiffer",
                "Andreas R\u00fcckl\u00e9",
                "Clifton Poth",
                "Aishwarya Kamath",
                "Ivan Vuli\u0107",
                "Sebastian Ruder",
                "Kyunghyun Cho",
                "Iryna Gurevych."
            ],
            "title": "Adapterhub: A framework for adapting transformers",
            "venue": "Proceedings of the 2020 Conference on Em-",
            "year": 2020
        },
        {
            "authors": [
                "Haode Qi",
                "Lin Pan",
                "Atin Sood",
                "Abhishek Shah",
                "Ladislav Kunc",
                "Mo Yu",
                "Saloni Potdar"
            ],
            "title": "Benchmarking commercial intent detection services with practice-driven evaluations",
            "year": 2020
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych."
            ],
            "title": "Sentencebert: Sentence embeddings using siamese bertnetworks",
            "venue": "arXiv preprint arXiv:1908.10084.",
            "year": 2019
        },
        {
            "authors": [
                "Victor Sanh",
                "Albert Webson",
                "Colin Raffel",
                "Stephen H Bach",
                "Lintang Sutawika",
                "Zaid Alyafeai",
                "Antoine Chaffin",
                "Arnaud Stiegler",
                "Teven Le Scao",
                "Arun Raja"
            ],
            "title": "Multitask prompted training enables zero-shot task generalization",
            "year": 2021
        },
        {
            "authors": [
                "Amazon Science."
            ],
            "title": "Intent induction from conversations for task-oriented dialogue",
            "venue": "https://github.com/amazon-research/ dstc11-track2-intent-induction.",
            "year": 2022
        },
        {
            "authors": [
                "Prafull Sharma",
                "Yingbo Li"
            ],
            "title": "Self-supervised contextual keyword and keyphrase retrieval with self-labelling",
            "year": 2019
        },
        {
            "authors": [
                "AB Siddique",
                "Fuad Jamour",
                "Luxun Xu",
                "Vagelis Hristidis."
            ],
            "title": "Generalized zero-shot intent detection via commonsense knowledge",
            "venue": "Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval,",
            "year": 2021
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems, 30.",
            "year": 2017
        },
        {
            "authors": [
                "Nikhita Vedula",
                "Nedim Lipka",
                "Pranav Maneriker",
                "Srinivasan Parthasarathy"
            ],
            "title": "Towards open intent discovery for conversational text",
            "year": 2019
        },
        {
            "authors": [
                "Ben Wang",
                "Aran Komatsuzaki."
            ],
            "title": "GPT-J6B: A 6 Billion Parameter Autoregressive Language Model",
            "venue": "https://github.com/kingoflolz/ mesh-transformer-jax.",
            "year": 2021
        },
        {
            "authors": [
                "Thomas Wolf",
                "Lysandre Debut",
                "Victor Sanh",
                "Julien Chaumond",
                "Clement Delangue",
                "Anthony Moi",
                "Pierric Cistac",
                "Tim Rault",
                "R\u00e9mi Louf",
                "Morgan Funtowicz"
            ],
            "title": "Huggingface\u2019s transformers: State-of-the-art natural language processing",
            "year": 2019
        },
        {
            "authors": [
                "Congying Xia",
                "Chenwei Zhang",
                "Xiaohui Yan",
                "Yi Chang",
                "Philip S Yu."
            ],
            "title": "Zero-shot user intent detection via capsule neural networks",
            "venue": "arXiv preprint arXiv:1809.00385.",
            "year": 2018
        },
        {
            "authors": [
                "Yongqin Xian",
                "Christoph H Lampert",
                "Bernt Schiele",
                "Zeynep Akata."
            ],
            "title": "Zero-shot learning\u2014a comprehensive evaluation of the good, the bad and the ugly",
            "venue": "IEEE transactions on pattern analysis and machine intelligence, 41(9):2251\u20132265.",
            "year": 2018
        },
        {
            "authors": [
                "Guangfeng Yan",
                "Lu Fan",
                "Qimai Li",
                "Han Liu",
                "Xiaotong Zhang",
                "Xiao-Ming Wu",
                "Albert YS Lam."
            ],
            "title": "Unknown intent detection using gaussian mixture model with an application to zero-shot intent classification",
            "venue": "Proceedings of the 58th annual meeting of",
            "year": 2020
        },
        {
            "authors": [
                "Wenpeng Yin",
                "Jamaal Hay",
                "Dan Roth."
            ],
            "title": "Benchmarking zero-shot text classification: Datasets, evaluation and entailment approach",
            "venue": "arXiv preprint arXiv:1909.00161.",
            "year": 2019
        },
        {
            "authors": [
                "Jianguo Zhang",
                "Kazuma Hashimoto",
                "Yao Wan",
                "Ye Liu",
                "Caiming Xiong",
                "Philip S. Yu."
            ],
            "title": "Are pretrained transformers robust in intent classification? A missing ingredient in evaluation of out-of-scope intent detection",
            "venue": "CoRR, abs/2106.04564.",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "Intent discovery is a crucial task in natural language processing, and it is increasingly relevant for various of industrial applications. Identifying novel, unseen intents from user inputs remains one of the biggest challenges in this field. Herein, we propose Zero-Shot-BERT-Adapters, a two-stage method for multilingual intent discovery relying on a Transformer architecture fine-tuned with Adapters. We train the model for Natural Language Inference (NLI) and later perform unknown intent classification in a zeroshot setting for multiple languages. In our evaluation, we first analyze the quality of the model after adaptive fine-tuning on known classes. Secondly, we evaluate its performance in casting intent classification as an NLI task. Lastly, we test the zero-shot performance of the model on unseen classes, showing how Zero-Shot-BERT-Adapters can effectively perform intent discovery by generating semantically similar intents, if not equal, to the ground-truth ones. Our experiments show how Zero-Shot-BERT-Adapters outperforms various baselines in two zero-shot settings: known intent classification and unseen intent discovery. The proposed pipeline holds the potential for broad application in customer care. It enables automated dynamic triage using a lightweight model that can be easily deployed and scaled in various business scenarios, unlike large language models. ZeroShot-BERT-Adapters represents an innovative multi-language approach for intent discovery, enabling the online generation of novel intents. A Python package implementing the pipeline and the new datasets we compiled are available at the following link: https://github. com/GT4SD/zero-shot-bert-adapters."
        },
        {
            "heading": "1 Introduction",
            "text": "Language Models (LM) and, in general, Natural Language Processing (NLP) methodologies have a pivotal role in modern communication systems. In dialogue systems, understanding the actual intention behind a conversation initiated by a user is fundamental, as well as identifying the user\u2019s intent underlying each dialogue utterance (Ni et al., 2021). Recently, there has been a growing interest in such applications, evidenced by the plethora of datasets and competitions established to tackle this problem. (Science, 2022; Casanueva et al., 2020; Zhang et al., 2021). Unfortunately, most of the available most of the available production systems leverage models trained on a finite set of possible intents, with limited or no possibility to generalize to novel unseen intents (Qi et al., 2020). Such limitations constitute a significant blocker for most applications that do not rely on a finite set of predetermined intents. They, instead, require a constant re-evaluation based on users\u2019 inputs and feedback. Additionally, most of the datasets for intent classification are mainly available for the English language, significantly limiting the development of dialogue systems in other languages. Expanding the set of available intents online is imperative to build better dialogue systems closely fitting users\u2019 needs. Besides better-matching user expectations, this also enables the definition of new common intents that can slowly emerge from a pool of different users. This is a key aspect of building systems that are more resilient over time and can follow trends appropriately. Current supervised techniques fall short of tackling the challenge above since they cannot usually discover novel intents. These models are trained by considering a finite set of classes and cannot generalize to realworld applications (Larson et al., 2019). Here, we propose a multi-language system that combines dependency parsing (Honnibal and Johnson, 2015; Nivre and Nilsson, 2005; ExplosionAI, 2015) to extract potential intents from a single utterance and a zero-shot classification approach. We rely on a BERT Transformer backbone (Vaswani et al., 2017; Devlin et al., 2018) fine-tuned for NLI (Nat-\nural Language Inference) (Xia et al., 2018; Yin et al., 2019) to select the intent that is best fitting the utterance in a zero-shot setting. In the NLI fine-tuning, we leverage Adapters (Houlsby et al., 2019; Pfeiffer et al., 2020) to reduce memory and time requirements significantly, keeping base model parameters frozen. We evaluated our approach, Zero-Shot-BERT-Adapters, for English, Italian, and German, demonstrating the possibility of its application in both high and low-resource language settings. The design focuses on a production setting where automatic intent discovery is fundamental, e.g., customer care chatbots, to ensure smooth user interaction. Figure 1 depicts how the Zero-Shot-BERT-Adapters pipeline fits in an intent detection system. From now on, for simplicity, we will refer to Zero-Shot-BERT-Adapters as Z-BERT-A in Tables and Figures."
        },
        {
            "heading": "2 Related Literature",
            "text": "There have been various efforts aiming at finding novel and unseen intents. The most popular approach is a two-step method where, initially, a binary classifier determines whether an utterance fits the existing set of intents, and, finally, zero-shot techniques are applied to determine the new intent (Xia et al., 2018; Siddique et al., 2021; Yan et al., 2020). (Liu et al., 2022) proposed an approach leveraging Transformers-based architectures, while most relied on RNN architectures like LSTMs (Xia et al., 2018). For our problem of interest, two notable efforts have attempted to address the issue of unseen intent detection (Vedula et al., 2019; Liu et al., 2021). (Liu et al., 2021) handled novel intent discovery as a clustering problem, proposing an adaptation of K-means. Here, the authors leverage dependency parsing to extract from\neach cluster a mean ACTION-OBJECT pair representing the common emerging intent for that particular cluster. Recently, Large Language Models (LLMs) achieved remarkable zero-shot generalization (Chowdhery et al., 2022; Sanh et al., 2021; Parikh et al., 2023) capabilities. (Parikh et al., 2023) report benchmarks on intent classification using GPT-3 (Chowdhery et al., 2022) and analyze performance both in zero and few-shot settings. While these solutions are compelling, they are only an ideal fit for some real-world use cases. Models of these sizes can be expensive to operationalize, especially in on-premise settings with strict hardware constraints. While there is no literature on the novel intent discovery and zero-shot classification in a multilingual setting, there has been a recent attempt to perform zero-shot intent detection (Liu et al., 2019). The authors study the problem of intent detection using attention-based models and cover low-resource languages such as Italian. Other approaches leveraging multilingual solutions, such as Nicosia et al., focus on a zero-shot multilingual semantic parsing task. Here, the authors present a novel method to produce training data for a multilingual semantic parser, where machine translation is applied to produce new data for a slot-filling task in zero-shot."
        },
        {
            "heading": "3 Background",
            "text": "In intent discovery, we aim at extracting from a single utterance x a set of potentially novel intents yi and automatically determine the best fitting one for the considered utterance. We can cast intent discovery as a Natural Language Inference (NLI) problem. We can rely on a language model \u03c6(x, \u03b3(x)) to predict the entailment between the utterance (x) and a set of hypotheses based on the candidate\nintents (\u03b3(x)) where \u03b3 is a function used to extract hypotheses from the set of potential intents yi. As previously shown by Xian et al., using NLI models for zero-shot classification represents a practical approach in problems where the set of candidate intents is known. In practice, the classification problem becomes an inference task where a combination of a premise and a hypothesis are associated with three possible classes: entailment, neutral and contradiction. Yin et al. have shown how this approach allows considering an input hypothesis based on an unseen class. It then generates a probability distribution describing the entailment from the input premise-hypothesis pair, hence a score correlating the input text to the novel class. While this technique is highly flexible and, in principle, can handle any association between utterance and candidate intent, determining good candidates based on the analyzed utterance remains a significant challenge."
        },
        {
            "heading": "4 Approach",
            "text": "Herein, we focus on building a pipeline to handle unseen classes at inference time. In this context, we need both to generate a set of candidate intents from the considered utterance and to classify the provided input against the new set of candidate intents. We tackle the problem by implementing a pipeline in two stages. In the first stage,\nwe leverage a dependency parser (Honnibal and Johnson, 2015; Nivre and Nilsson, 2005) to extract a set of potential intents by exploiting specific arc dependencies between the words in the utterance. In the second stage, we leverage the set of potential intents as candidate classes for the utterance intent classification problem using a zero-shot approach (Xian et al., 2018) based on NLI relying on a BERT-based model (Devlin et al., 2018), as depicted in Figure 2. The model is tuned with Adapters (Houlsby et al., 2019) for the NLI task (BERT-A) and is then prompted with premisehypothesis pairs for zero-shot classification on the candidate intents, completing the Zero-Shot-BERTAdapters pipeline. The entire pipeline\u2019s implementation follows the Hugging Face pipeline API from the transformers library (Wolf et al., 2019).\nIntent generation Defining a set of potential intents from an input utterance is crucial for effective intent discovery, especially when dealing with a multilingual context. To provide this set of potentially unseen candidates, we choose to exploit the dependency parser from spaCy (Honnibal and Johnson, 2015; Honnibal et al., 2020), considering: for English the model en_core_web_trf, for Italian the model it_core_news_lg, and, for German the model de_dep_news_trf (all implemented in spaCy-transformers (ExplosionAI, 2019)). We extract a pair of words from an input sentence through the dependency parser. We define each pair by searching for specific Arc-Relations (AR) in the dependency tree of the parsed sentence. Unfortunately, this approach is language-dependent, as different languages can require a specific patternmatching for the ARs.\nSince intents are usually composed by an actionobject pair (Vedula et al., 2019; Liu et al., 2021), we exploit this pattern for all languages when looking for candidate arc relationships. We search for DOBJ, compound, and AMOD arc relations in English. We must adjust this in Italian and search for AUX, ADVMOD, and compound arc relations. We further adapt the tags to RE, SB, and MO in German. We perform a four-level detection, which means finding the four primary relations that can generate a base intent using these relations. Once these relations, or a subset of them, are found, we add for all the languages the pairs composed by (VERB, NOUN) and, for English only, (ADJ, PRONM) with the most out/in going arcs. We refer to Appendix A for the Tables 11, 12 and 13\nfor a complete definition of the AR and Part-ofSpeech (POS) tags considered. We lemmatize the extracted potential intents using NLTK (Loper and Bird, 2002). Lemmatization is applied to verbs and nouns independently. The lemmatized intents represent the labels that our model uses for zero-shot classification. Algorithm 1 details in pseudocode the pipeline for the intent generation with \u0398(n) as time complexity, where n is the number of dependency arcs in an utterance.\nZero-shot classification The generated potential intents are the labels for the zero-shot BERT-based classifier implemented using NLI that scores the entailment between the utterance used as a premise and the hypothesis based on the intent. Given an input utterance, we select the intent related to the pair with the highest score. We use sentence embedding vectors to define the scores (Reimers and Gurevych, 2019)."
        },
        {
            "heading": "5 Datasets",
            "text": "We consider two datasets in our analysis: SNLI (Bowman et al., 2015) and Banking77OO (Casanueva et al., 2020; Zhang et al., 2021):\n\u2022 The SNLI corpus (Bowman et al., 2015) is a collection of 570k human-written English sentence pairs manually labeled as entailment, contradiction, and neutral. It is used for natural language inference (NLI), also known as recognizing textual entailment (RTE). The dataset comes with a split: 550152 samples for training, 10000 samples for validation, and 10000 samples for testing. Each sample is composed of a premise, a hypothesis, and a corresponding label indicating whether the premise and the hypothesis represent an entailment. The label can be set to one of the following: entailment, contradiction, or neutral.\n\u2022 Banking77-OOS (Casanueva et al., 2020; Zhang et al., 2021) is an intent classification dataset composed of online banking queries annotated with their corresponding intents. It provides a very fine-grained set of intents in the banking domain. It comprises 13,083 customer service queries labeled with 77 intents. It focuses on fine-grained singledomain intent detection. Of these 77 intents, Banking77-OOS includes 50 in-scope intents,\nand the ID-OOS queries are built up based on 27 held-out in-scope intents.\nWe also explore the effects of pretraining leveraging an NLI adaptation of Banking77 (Yin et al., 2019). To investigate the impact of pretraining on similar data, we extended the Banking77 dataset by casting the intent classification task as NLI. We consider the input utterance the premise and extract the most relevant word associated with it using KeyBERT (Sharma and Li, 2019). The word is then used to generate an entailed hypothesis based on the corresponding synset definition from WordNet via NLTK (Loper and Bird, 2002; Miller, 1995). Exemplar samples of synthetic Banking77 NLI data are reported in Table 1. For the hypotheses that are not considered entailed, we repeat the procedure for randomly sampled unrelated words. This process enabled us to consider the training split of Banking77-OOS for adaptive fine-tuning of the NLI model component. We call this generated dataset Banking77-OOS-NLI.\nTo analyze the validity of our approach in a multi-lingual setup with lower data availability, we compiled and made available both an Italian and a German version of the Banking77 dataset. We followed a two-step process involving translation using the Google Translation API (Google, 2023) and manual annotation and correction by human agents to maintain data quality following the protocol described in (Bellomaria et al., 2019)."
        },
        {
            "heading": "6 Training",
            "text": "We fine-tune two versions of BERT-A (BERTbased transformer with Adapters). The first version is trained for NLI on the SNLI dataset using the original split for training, validation, and testing (Bowman et al., 2015). The second version also considers the previously introduced Banking77-OOS-NLI which keeps the split of inscope and the out-of-scope ratio of 50 \u2013 27 out of 77 total intents. Depending on the language considered we use different BERT pretrained models: for English we use bert-base-uncased (Devlin et al., 2018); for Italian we use bert-base-italianxxl-uncased (dbmdz, 2020); for German we use bert-base-german-cased (Deepset, 2019). During training, we keep the BERT backbone frozen and only update the added Adapter layers to minimize training time and memory footprint. By freezing all the original layers and letting the model be trained only on the adaptive layers, we end up with\n896\u2019066 trainable parameters. The final model then has almost 111 million parameters (110 million parameters from the BERT-base-model and 896\u2019066 parameters added through the adapters, all with a default size of 32 bit floating point). All training runs relied on the AdamW (Loshchilov and Hutter, 2017) optimizer with a learning rate set to 2 \u00b7 10\u22125 and a warm-up scheduler. The models have been fine-tuned for a total of 6 epochs using early stopping. Our computing infrastructure for training the models run on Nvidia Tesla T4 GPUs using PyTorch and Python 3.7. In this configuration, each training epoch took approximately one minute to run. During the testing phase each run took around 36 seconds, including the overhead due to metrics computation."
        },
        {
            "heading": "7 Evaluation",
            "text": "First, we analyzed the performance of the BERT-A component and evaluated its results on a NLI task using accuracy, precision, and recall. Afterward, we compared its result on the zero-shot classification task with other available models on the same Banking77 split using accuracy. In this initial evaluation, the intents were known. The baselines considered in this setting were BART0 (Lin et al., 2022), a multitask model with 406 million parameters based on Bart-large (Lewis et al., 2019) based on prompt training; and two flavors of Zero-Shot DDN (ZS-DNN) (Kumar et al., 2017) with both encoders Universal Sentence Encoder (USE) (Cer et al., 2018) and SBERT (Reimers and Gurevych, 2019).\nIn the unknown intent case, we compared the pipeline against a set of zero-shot baselines based on various pre-trained transformers. As baselines, we included bart-large-mnli (Yin et al., 2019) as it achieves good performance in zero-shot sequence classification. We used this model as an alternative to our classification method, but in this case, we maintained our dependency parsing strategy for the intent generation. As a hypothesis for the NLI-based classification, we used the phrase: \u201cThis example is < label >\u201d. Recently, large LMs have demonstrated remarkable zero-shot capabilities in a plethora of tasks. Thus, we included four LLMs as baseline models, namely T0 (Sanh et al., 2021), GPT-J (Wang and Komatsuzaki, 2021), Dolly (lab, 2023) and GPT-3.5 (Brown et al., 2020) using textdavinci-003 via OpenAI API (base model behind InstructGPT and GPT-3.5 (Ouyang et al., 2022; OpenAI, 2022)). In these models, the template prompt defines the task of interest. We examined whether such LLMs can serve the end-to-end intent extraction (intent generation and classification). We investigated them both in a completely unsupervised, i.e., a zero-shot settingr and using intents generated with our dependency parsing method. In the former case, the given input is just the utterance of interest, while in the latter case, the provided input includes the utterance and the possible intents. In both cases, the generated output is considered as the extracted intent. Table 7 (in Appendix) reports all prompts in different languages used to query the LLMs. We use prompts where the models generate the intent without providing a set of possible options (prompts 1 and 2). Prompts that contain the candidate intents extracted using the first stage of our pipeline (prompts 3 and 4). Regarding GPT-3.5, we used two different prompts (prompts 5 and 6) reported in the results table. These are the two best performing prompts and they were built following the suggested examples from OpenAI. In this setting, the intents generated can\u2019t match perfectly the held-out ones. For this reason, we chose to measure the performance using a semantic similarity metric, based on the cosine-similarity between the sentence embeddings of the ground-truth intents and the generated ones (Vedula et al., 2019). To set a decision boundary, we relied on a threshold based on the distributional properties of the computed similarities. The threshold t is defined in\nEquation 1.\nt = { 0.5 if \u00b5 \u2264 0.5 \u00b5+ \u03b1 \u00b7 \u03c32 otherwise\n(1a)\n\u00b5 = 1\nn n\u2211 i=1 xi \u00b7 yi ||xi|| \u00b7 ||yi||\n(1b)\n\u03c32 = 1\nn n\u2211 i=1 ( xi \u00b7 yi ||xi|| \u00b7 ||yi|| \u2212 \u00b5 )2 (1c)\nwhere \u03b1 is an arbitrary parameter to control the variance impact, which we set to 0.5 in our study.\nThe evaluation of the pipeline was repeated five times to evaluate the stability of the results."
        },
        {
            "heading": "8 Results",
            "text": "Firstly, we report the performance of BERT-A on the NLI task, see Table 2. Here, BERT-A obtained the best results when being fine-tuned on Banking77-OOS-NLI. The accuracy, precision,\nand recall achieved confirm the quality of the pretrained model which achieves a 1.6% in accuracy and 2% in F1-score then BERT-A fine-tuned with SNLI. We also report the results on the Italian and German fine-tuned models to highlight the impact of the different languages.\nTable 3 shows how the Z-BERT-A component improves results over most baselines in terms of accuracy in the known intent scenario where we present all available classes to the model as options in a zero-shot setting. Remarkably, the BERT-A version fine-tuned on Banking77-OOS-NLI outperforms all the considered baselines. Also, when considering at the German and Italian version of BERT-A we obseve comparable performance with the English counterpart, showing again how our approach can adapt to different scenarios.\nFinally, we report Zero-Shot-BERT-Adapters on the unknown intent discovery task. Tables 4 and 5 show the performance of BERT-A fine-tuned on SNLI and Banking77-OOS-NLI in comparison with a selection of zero-shot baselines for intent discovery. For the baselines, we show the performance on zero-shot classification given potential intents from our approach (prompts 3, 4, and 6) and on new intents discovery solely using the input utterance (prompts 1, 2, and 5). Table 7 in Appendix A reports all prompts considered. Both flavors of Zero-Shot-BERT-Adapters outperform the considered baselines by a consistent margin, by 2.7%, against the best baseline of T0. In the multilingual setting, Table 5 and 6, we did not consider GPT-J and Dolly as a baselines because they partially or completely lack support for Italian and German. Our pipeline applied for the Italian language achieves remarkable results. It outperforms the best baseline, T0, by 13% in cosine similarity score. It also shows how LLMs\u2019 performance exhibit a bias towards low-resource languages. For German, we have observed again better perfomance com-\npared to the baselines, even though, in this comparison, T0 is competitive with our method. It is interesting to observe how approaches relying on smaller models like Zero-Shot-BERT-Adapters can outperform LLMs. The results show that combining smaller models with focused simpler classical NLP approaches can still bring better results in intent discovery and detection. The baselines consisting of LLMs, while achieving acceptable results, are not able to get a similarity score as high as Zero-Shot-BERT-Adapters. This indicates that lightweight approaches that can be easily deployed and scaled are a viable sollution for task-focused scenarios.\nFigure 3 reports the average cosine similarity be-\ntween the generated intents for each of the groundtruth intents in the multilingual setting. It combines the results between the three different language settings. We can see how for various corresponding intents, Zero-Shot-BERT-Adapters is achieving proportionally similar results in all the languages. As expected, for some classes the results on the English language settings are superior."
        },
        {
            "heading": "9 Conclusions and Future Work",
            "text": "We proposed a pipeline for zero-shot prediction of unseen intents from utterances. We performed a two-fold evaluation. First, we showed how our BERT-based model fine-tuned with Adapters on\nNLI can outperform a selection of baselines on the prediction of known intents in a zero-shot setting. Secondly, we evaluated the full pipeline capabilities comparing its performance with the results obtained by prompting LLMs in an unknown intent set considering multiple languages. These results prove that our solution represents an effective option to extend intent classification systems to handle unseen intents, a key aspect of modern dialogue systems for triage. Moreover, using a relatively lightweight base model and relying on adaptive fine-tuning, the proposed solution can be deployed in the context of limited resources scenarios, e.g., on-premise solutions or small cloud instances. In this way, we don\u2019t compromise on model performance, as we showed that smaller models like the ones powering our pipeline can outperform LLMs in intent discovery. An interesting avenue to explore in the future consists in relying on zero-shot learning approaches in the intent generation phase (Liu et al., 2021) without compromising on model size and inference requirements. Zero-Shot-BERT-Adapters and the Italian and German datasets are available at the following link: https://github.com/GT4SD/ zero-shot-bert-adapters."
        },
        {
            "heading": "10 Ethical considerations",
            "text": "Dialog systems are a helpful tool that companies and organizations leverage to respond to inquiries or resolve issues of their customers promptly. Unfortunately, an uncountable number of users interact with such tools on various occasions, which inherently poses bias concerns. We believe that using Zero-Shot-BERT-Adapters in intent detection\npipelines can help mitigate bias by dynamically adapting intents based on the user audience interacting with the system. Relying on the new emerging intents from Zero-Shot-BERT-Adapters, one can easily compile a dataset to fine-tune an existing intent detection model that carries an inherent bias coming from its training dataset. Moreover, our approach aims to minimize the usage of computing resources by relying on a relatively small model that requires minimal resources for training and inference. This parameter efficiency is relevant when considering the carbon footprint associated with training and serving of recent LLMs."
        },
        {
            "heading": "11 Limitations",
            "text": "The main limitation of this pipeline currently lies in the new intent generation stage where we are using classic dependency parsing to generate potential new intents. This is a limitation for two main reasons. Firstly, because we are bound by the input utterance when producing an intent, risking to lack in terms of generalization power. Secondly, when multiple languages are involved the result of the dependency parser has to be interpreted in a language-dependent way. As shown in Tables 11 and 12, different languages call for different arcrelationships. This limitation is something that can be addressed by replacing the dependency parsing with a model-based zero-shot approach that would be the natural extension of the presented method."
        },
        {
            "heading": "B Use-case for new emerging intents monitoring on real data",
            "text": "Here we show a practical use-case in which ZeroShot-BERT-Adapters is successfully applied. From a series of users\u2019 telco assistance utterances in which its intent has not been recognized, we apply Zero-Shot-BERT-Adapters and we extract over a period of time the various emerging intents. These intents are then displayed in this dashboard we developed by applying also Semantic Similarity versus existing intents\u2019 categories in order to get a better glimpse of actual new emerging intents. We also compute various useful statistical information together with a graph showing an Hierarchical clustering using the Agglogmerative Clustering algorithm of the intents based on the semantic similarity score as clustering distance. The approach used in order to get the various intents grouped together is to first cluster similar extracted intents based on the cosine similarity of their embeddings, similarly to what we presented in the described work. Then assign to each cluster an intent name based on the most common occurrences of action and intent separately, taken from each cluster of intents. This helps normalize the same intent expressed thorugh a a set of the various possibile variants from different utterances, identifying a common intent among the ones with a similar semantic meaning. This approach is also cited in (Liu et al., 2021).\nIn the following Figure 4 we show a glimpse of the EID (Emerging Intent Dashboard) and its practical usage, backed by the Zero-Shot-BERT-Adapters pipeline."
        }
    ],
    "title": "Zero-Shot-BERT-Adapters: a Zero-Shot Pipeline for Unknown Intent Detection",
    "year": 2023
}