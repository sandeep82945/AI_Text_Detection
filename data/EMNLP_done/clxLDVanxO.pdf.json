{
    "abstractText": "The task of table summarization involves generating text that both succinctly and accurately represents the table or a specific set of highlighted cells within a table. While significant progress has been made in table to text generation techniques, models still mostly generate descriptive summaries, which reiterates the information contained within the table in sentences. Through analysis of popular table to text benchmarks (ToTTo (Parikh et al., 2020) and InfoTabs (Gupta et al., 2020)) we observe that in order to generate the ideal summary, multiple types of reasoning is needed coupled with access to knowledge beyond the scope of the table. To address this gap, we propose RETAG, a table and reasoning aware model that uses vector-quantization to infuse different types of analytical reasoning into the output. RETAG achieves 2.2%, 2.9% improvement on the PARENT metric in the relevant slice of ToTTo and InfoTabs for the table to text generation task over state of the art baselines. Through human evaluation, we observe that output from RETAG is upto 12% more faithful and analytical compared to a strong table-aware model. To the best of our knowledge, RETAG is the first model that can controllably use multiple reasoning methods within a structure-aware sequence to sequence model to surpass state of the art performance in multiple table to text tasks. We extend (and open source 35.6K analytical, 55.9k descriptive instances) the ToTTo, InfoTabs datasets with the reasoning categories used in each reference sentences.",
    "authors": [
        {
            "affiliations": [],
            "name": "Deepanway Ghosal"
        },
        {
            "affiliations": [],
            "name": "Preksha Nema"
        },
        {
            "affiliations": [],
            "name": "Aravindan Raghuveer"
        }
    ],
    "id": "SP:74d64de0200fb2270d561df27231fbd106e3f489",
    "references": [
        {
            "authors": [
                "Aida Amini",
                "Saadia Gabriel",
                "Shanchuan Lin",
                "Rik Koncel-Kedziorski",
                "Yejin Choi",
                "Hannaneh Hajishirzi."
            ],
            "title": "Mathqa: Towards interpretable math word problem solving with operation-based formalisms",
            "venue": "Proceedings of the 2019 Conference of",
            "year": 2019
        },
        {
            "authors": [
                "Ewa Andrejczuk",
                "Julian Martin Eisenschlos",
                "Francesco Piccinno",
                "Syrine Krichene",
                "Yasemin Altun"
            ],
            "title": "Table-to-text generation and pre-training with tabt5",
            "year": 2022
        },
        {
            "authors": [
                "Junwei Bao",
                "Duyu Tang",
                "Nan Duan",
                "Zhao Yan",
                "Yuanhua Lv",
                "Ming Zhou",
                "Tiejun Zhao."
            ],
            "title": "Tableto-text: Describing table region with natural language",
            "venue": "Proceedings of the AAAI conference on artificial intelligence, volume 32.",
            "year": 2018
        },
        {
            "authors": [
                "Yonatan Bisk",
                "Rowan Zellers",
                "Jianfeng Gao",
                "Yejin Choi"
            ],
            "title": "Piqa: Reasoning about physical commonsense in natural language",
            "venue": "In Proceedings of the AAAI conference on artificial intelligence,",
            "year": 2020
        },
        {
            "authors": [
                "Wenhu Chen",
                "Jianshu Chen",
                "Yu Su",
                "Zhiyu Chen",
                "William Yang Wang."
            ],
            "title": "Logical natural language generation from open-domain tables",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7929\u2013",
            "year": 2020
        },
        {
            "authors": [
                "Wenhu Chen",
                "Jianshu Chen",
                "Yu Su",
                "Zhiyu Chen",
                "William Yang Wang."
            ],
            "title": "Logical natural language generation from open-domain tables",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7929\u2013",
            "year": 2020
        },
        {
            "authors": [
                "Wenhu Chen",
                "Jianshu Chen",
                "Yu Su",
                "Zhiyu Chen",
                "William Yang Wang."
            ],
            "title": "Logical natural language generation from open-domain tables",
            "venue": "CoRR, abs/2004.10404.",
            "year": 2020
        },
        {
            "authors": [
                "Wenhu Chen",
                "Xueguang Ma",
                "Xinyi Wang",
                "William W. Cohen"
            ],
            "title": "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks",
            "year": 2022
        },
        {
            "authors": [
                "Wenhu Chen",
                "Hongmin Wang",
                "Jianshu Chen",
                "Yunkai Zhang",
                "Hong Wang",
                "Shiyang Li",
                "Xiyou Zhou",
                "William Yang Wang."
            ],
            "title": "Tabfact: A large-scale dataset for table-based fact verification",
            "venue": "CoRR, abs/1909.02164.",
            "year": 2019
        },
        {
            "authors": [
                "Wenhu Chen",
                "Hanwen Zha",
                "Zhiyu Chen",
                "Wenhan Xiong",
                "Hong Wang",
                "William Yang Wang."
            ],
            "title": "HybridQA: A dataset of multi-hop question answering over tabular and textual data",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP",
            "year": 2020
        },
        {
            "authors": [
                "Zhiyu Chen",
                "Wenhu Chen",
                "Charese Smiley",
                "Sameena Shah",
                "Iana Borova",
                "Dylan Langdon",
                "Reema Moussa",
                "Matt Beane",
                "Ting-Hao Huang",
                "Bryan R. Routledge",
                "William Yang Wang."
            ],
            "title": "Finqa: A dataset of numerical reasoning over financial data",
            "venue": "CoRR,",
            "year": 2021
        },
        {
            "authors": [
                "Zhiyu Chen",
                "Wenhu Chen",
                "Hanwen Zha",
                "Xiyou Zhou",
                "Yunkai Zhang",
                "Sairam Sundaresan",
                "William Yang Wang."
            ],
            "title": "Logic2text: Highfidelity natural language generation from logical forms",
            "venue": "Findings of the Association for Computa-",
            "year": 2020
        },
        {
            "authors": [
                "Zhiyu Chen",
                "Wenhu Chen",
                "Hanwen Zha",
                "Xiyou Zhou",
                "Yunkai Zhang",
                "Sairam Sundaresan",
                "William Yang Wang."
            ],
            "title": "Logic2text: Highfidelity natural language generation from logical forms",
            "venue": "CoRR, abs/2004.14579.",
            "year": 2020
        },
        {
            "authors": [
                "Narang",
                "Gaurav Mishra",
                "Adams Yu",
                "Vincent Zhao",
                "Yanping Huang",
                "Andrew Dai",
                "Hongkun Yu",
                "Slav Petrov",
                "Ed H. Chi",
                "Jeff Dean",
                "Jacob Devlin",
                "Adam Roberts",
                "Denny Zhou",
                "Quoc V. Le",
                "Jason Wei"
            ],
            "title": "Scaling instruction-finetuned language",
            "year": 2022
        },
        {
            "authors": [
                "Bhuwan Dhingra",
                "Manaal Faruqui",
                "Ankur Parikh",
                "Ming-Wei Chang",
                "Dipanjan Das",
                "William Cohen"
            ],
            "title": "Handling divergent reference texts",
            "year": 2019
        },
        {
            "authors": [
                "Haoyu Dong",
                "Zhoujun Cheng",
                "Xinyi He",
                "Mengyu Zhou",
                "Anda Zhou",
                "Fan Zhou",
                "Ao Liu",
                "Shi Han",
                "Dongmei Zhang."
            ],
            "title": "Table pretraining: A survey on model architectures, pretraining objectives, and downstream tasks",
            "venue": "arXiv preprint",
            "year": 2022
        },
        {
            "authors": [
                "Dheeru Dua",
                "Yizhong Wang",
                "Pradeep Dasigi",
                "Gabriel Stanovsky",
                "Sameer Singh",
                "Matt Gardner."
            ],
            "title": "Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs",
            "venue": "Proceedings of the 2019 Conference of the North American",
            "year": 2019
        },
        {
            "authors": [
                "Mor Geva",
                "Ankit Gupta",
                "Jonathan Berant."
            ],
            "title": "Injecting numerical reasoning skills into language models",
            "venue": "CoRR, abs/2004.04487.",
            "year": 2020
        },
        {
            "authors": [
                "Mor Geva",
                "Ankit Gupta",
                "Jonathan Berant."
            ],
            "title": "Injecting numerical reasoning skills into language models",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 946\u2013958.",
            "year": 2020
        },
        {
            "authors": [
                "Heng Gong",
                "Yawei Sun",
                "Xiaocheng Feng",
                "Bing Qin",
                "Wei Bi",
                "Xiaojiang Liu",
                "Ting Liu."
            ],
            "title": "TableGPT: Few-shot table-to-text generation with table structure reconstruction and content matching",
            "venue": "Proceedings of the 28th International Con-",
            "year": 2020
        },
        {
            "authors": [
                "Vivek Gupta",
                "Maitrey Mehta",
                "Pegah Nokhiz",
                "Vivek Srikumar."
            ],
            "title": "INFOTABS: Inference on tables as semi-structured data",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2309\u20132324, Online. Association",
            "year": 2020
        },
        {
            "authors": [
                "Kelvin Guu",
                "Kenton Lee",
                "Zora Tung",
                "Panupong Pasupat",
                "Ming-Wei Chang."
            ],
            "title": "REALM: retrievalaugmented language model pre-training",
            "venue": "CoRR, abs/2002.08909.",
            "year": 2020
        },
        {
            "authors": [
                "Jonathan Herzig",
                "Pawel Krzysztof Nowak",
                "Thomas Mueller",
                "Francesco Piccinno",
                "Julian Eisenschlos."
            ],
            "title": "Tapas: Weakly supervised table parsing via pre-training",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Lin-",
            "year": 2020
        },
        {
            "authors": [
                "Fangyu Lei",
                "Shizhu He",
                "Xiang Li",
                "Jun Zhao",
                "Kang Liu"
            ],
            "title": "Answering numerical reasoning questions in table-text hybrid contents with graph-based encoder and tree-based decoder",
            "year": 2022
        },
        {
            "authors": [
                "Tongliang Li",
                "Lei Fang",
                "Jian-Guang Lou",
                "Zhoujun Li."
            ],
            "title": "TWT: Table with written text for controlled data-to-text generation",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, pages 1244\u20131254, Punta Cana, Dominican Re-",
            "year": 2021
        },
        {
            "authors": [
                "Chin-Yew Lin."
            ],
            "title": "Rouge: A package for automatic evaluation of summaries",
            "venue": "Text summarization branches out, pages 74\u201381.",
            "year": 2004
        },
        {
            "authors": [
                "Qian Liu",
                "Bei Chen",
                "Jiaqi Guo",
                "Morteza Ziyadi",
                "Zeqi Lin",
                "Weizhu Chen",
                "Jian-Guang Lou."
            ],
            "title": "Tapex: Table pre-training via learning a neural sql executor",
            "venue": "International Conference on Learning Representations.",
            "year": 2021
        },
        {
            "authors": [
                "Tianyu Liu",
                "Kexiang Wang",
                "Lei Sha",
                "Baobao Chang",
                "Zhifang Sui."
            ],
            "title": "Table-to-text generation by structure-aware seq2seq learning",
            "venue": "Thirty-Second AAAI Conference on Artificial Intelligence.",
            "year": 2018
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Fedor Moiseev",
                "Zhe Dong",
                "Enrique Alfonseca",
                "Martin Jaggi"
            ],
            "title": "Skill: Structured knowledge infusion for large language models",
            "year": 2022
        },
        {
            "authors": [
                "Caiming Xiong",
                "Dragomir Radev",
                "Dragomir Radev."
            ],
            "title": "FeTaQA: Free-form Table Question Answering",
            "venue": "Transactions of the Association for Computational Linguistics, 10:35\u201349.",
            "year": 2022
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311\u2013318.",
            "year": 2002
        },
        {
            "authors": [
                "Ankur Parikh",
                "Xuezhi Wang",
                "Sebastian Gehrmann",
                "Manaal Faruqui",
                "Bhuwan Dhingra",
                "Diyi Yang",
                "Dipanjan Das."
            ],
            "title": "ToTTo: A controlled table-totext generation dataset",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Lan-",
            "year": 2020
        },
        {
            "authors": [
                "Matt Post."
            ],
            "title": "A call for clarity in reporting BLEU scores",
            "venue": "Proceedings of the Third Conference on Machine Translation: Research Papers, pages 186\u2013 191, Belgium, Brussels. Association for Computational Linguistics.",
            "year": 2018
        },
        {
            "authors": [
                "Lianhui Qin",
                "Aditya Gupta",
                "Shyam Upadhyay",
                "Luheng He",
                "Yejin Choi",
                "Manaal Faruqui."
            ],
            "title": "TIMEDIAL: temporal commonsense reasoning in dialog",
            "venue": "CoRR, abs/2106.04571.",
            "year": 2021
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J Liu."
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "Journal of Machine Learning Research,",
            "year": 2020
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J. Liu."
            ],
            "title": "Exploring the limits of transfer learning with a unified text-totext transformer",
            "venue": "Journal of Machine Learning Re-",
            "year": 2020
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych."
            ],
            "title": "Sentencebert: Sentence embeddings using siamese bertnetworks",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.",
            "year": 2019
        },
        {
            "authors": [
                "Swarnadeep Saha",
                "Xinyan Velocity Yu",
                "Mohit Bansal",
                "Ramakanth Pasunuru",
                "Asli Celikyilmaz"
            ],
            "title": "Murmur: Modular multi-step reasoning for semistructured data-to-text generation",
            "year": 2022
        },
        {
            "authors": [
                "Maarten Sap",
                "Hannah Rashkin",
                "Derek Chen",
                "Ronan Le Bras",
                "Yejin Choi."
            ],
            "title": "Social iqa: Commonsense reasoning about social interactions",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the",
            "year": 2019
        },
        {
            "authors": [
                "Kaitao Song",
                "Xu Tan",
                "Tao Qin",
                "Jianfeng Lu",
                "TieYan Liu."
            ],
            "title": "Mpnet: Masked and permuted pretraining for language understanding",
            "venue": "Advances in Neural Information Processing Systems, 33:16857\u2013 16867.",
            "year": 2020
        },
        {
            "authors": [
                "Yixuan Su",
                "Zaiqiao Meng",
                "Simon Baker",
                "Nigel Collier."
            ],
            "title": "Few-shot table-to-text generation with prototype memory",
            "venue": "arXiv preprint arXiv:2108.12516.",
            "year": 2021
        },
        {
            "authors": [
                "Yixuan Su",
                "David Vandyke",
                "Sihui Wang",
                "Yimai Fang",
                "Nigel Collier."
            ],
            "title": "Plan-then-generate: Controlled data-to-text generation via planning",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, pages 895\u2013909, Punta Cana, Do-",
            "year": 2021
        },
        {
            "authors": [
                "Lya Hulliyyatus Suadaa",
                "Hidetaka Kamigaito",
                "Kotaro Funakoshi",
                "Manabu Okumura",
                "Hiroya Takamura."
            ],
            "title": "Towards table-to-text generation with numerical reasoning",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational",
            "year": 2021
        },
        {
            "authors": [
                "Alon Talmor",
                "Jonathan Herzig",
                "Nicholas Lourie",
                "Jonathan Berant."
            ],
            "title": "Commonsenseqa: A question answering challenge targeting commonsense knowledge",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association",
            "year": 2019
        },
        {
            "authors": [
                "Aaron Van Den Oord",
                "Oriol Vinyals"
            ],
            "title": "Neural discrete representation learning",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Fei Wang",
                "Zhewei Xu",
                "Pedro Szekely",
                "Muhao Chen"
            ],
            "title": "Robust (controlled) table-to-text generation with structure-aware equivariance learning",
            "year": 2022
        },
        {
            "authors": [
                "Xinyu Xing",
                "Xiaojun Wan."
            ],
            "title": "Structure-aware pre-training for table-to-text generation",
            "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 2273\u20132278, Online. Association for Computational Linguistics.",
            "year": 2021
        },
        {
            "authors": [
                "Yang Yang",
                "Juan Cao",
                "Yujun Wen",
                "Pengzhou Zhang."
            ],
            "title": "Table to text generation with accurate content copying",
            "venue": "Scientific reports, 11(1):1\u201312.",
            "year": 2021
        },
        {
            "authors": [
                "Pengcheng Yin",
                "Graham Neubig",
                "Wen-tau Yih",
                "Sebastian Riedel."
            ],
            "title": "Tabert: Pretraining for joint understanding of textual and tabular data",
            "venue": "arXiv preprint arXiv:2005.08314.",
            "year": 2020
        },
        {
            "authors": [
                "Ori Yoran",
                "Alon Talmor",
                "Jonathan Berant."
            ],
            "title": "Turning tables: Generating examples from semistructured tables for endowing language models with reasoning skills",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computa-",
            "year": 2022
        },
        {
            "authors": [
                "Yilun Zhao",
                "Yunxiang Li",
                "Chenying Li",
                "Rui Zhang."
            ],
            "title": "MultiHiertt: Numerical reasoning over multi hierarchical tabular and textual data",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
            "year": 2022
        },
        {
            "authors": [
                "Yilun Zhao",
                "Linyong Nan",
                "Zhenting Qi",
                "Rui Zhang",
                "Dragomir Radev"
            ],
            "title": "2022b. Reastap: Injecting table reasoning skills during pre-training via synthetic reasoning examples",
            "year": 2022
        },
        {
            "authors": [
                "Ben Zhou",
                "Daniel Khashabi",
                "Qiang Ning",
                "Dan Roth."
            ],
            "title": "going on a vacation\u201d takes longer than \u201cgoing for a walk\u201d: A study of temporal commonsense understanding",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natu-",
            "year": 2019
        },
        {
            "authors": [
                "Tat-Seng Chua"
            ],
            "title": "TAT-QA: A question answer",
            "year": 2021
        },
        {
            "authors": [],
            "title": "Occupation: Actress, businesswoman | Years active: 1994-present",
            "year": 2008
        },
        {
            "authors": [
                "Title: David Foster"
            ],
            "title": "Genres: Pop, pop rock, classical, gospel, R&B | Occupation(s): Music executive, record producer, musician, composer, songwriter, arranger | Years active: 1971-present",
            "year": 1971
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "In the task of Table to Text Generation (Yang et al., 2021), the output summaries usually are of two types: Descriptive and Analytical. A descriptive summary is formed with only information contained within the selected cells of the table and nothing else (Refer Table 1). On the other hand, an analytical summary is one that uses information\nbeyond the selected cells and / or employs nontrivial reasoning. Being able to generate a high quality analytical summary is a critical property to improve the performance of Table to Text Models. We show later in our analysis that in ToTTo (Parikh et al., 2020) and Infotabs (Gupta et al., 2020), two widely used table to text benchmarks, roughly 27% and 44% of the reference summaries are analytical, respectively. In literature, there are five popular categories of reasoning used in analytical summarization: 1. Tabular Reasoning where information in the table beyond the selected cells is used (Chen et al., 2020d; Saha et al., 2022; Zhao et al., 2022b; Chen et al., 2022), 2. Numerical Reasoning that uses math operations on/across cells (Geva et al., 2020a; Dua et al., 2019; Amini et al., 2019), 3. Temporal Reasoning that imparts knowledge about different units of time (Qin et al., 2021), 4. Commonsense Reasoning to apply world knowledge (Talmor et al., 2019; Chen et al., 2020a) and 5. Entity Awareness to distill knowledge about entities and their surface forms (Liu et al., 2018; Moiseev et al., 2022; Guu et al., 2020).\nMost table to text models, use structure-aware architectures or pretraining strategies to internally equip the model with one or more types of analyt-\nical reasoning capabilities. We draw attention to two practical scenarios where reasoning categories should not be statically baked into a table to text model and more inference time control is needed. 1. Dataset Diversity: Tables like financial charts that consists of pre-dominantly numbers usually need numerical and temporal reasoning. On the other hand, tables like biographic information would need entity and common-sense knowledge more often. Since the same model would be used to summarize diverse tables, it becomes essential to be able to pick the appropriate reasoning categories based on the input table.\n2. Usage and Context Diversity: Depending on the context of usage, a basketball match scorecard table can be summarized in two distinct ways. For avid sports experts, temporal and tabular reasoning can be used to summarize interesting patterns in the table. On the other hand, for a newspaper article the focus would shift to entity knowledge and crisp tabular summary of match results.\nFollowing from the examples above, we argue that explicit control is needed to dynamically pick the reasoning categories. during inference time. To the best of our knowledge, there is no prior literature on table to text summarization with explicit inference-time reasoning control.\nNext, we study some key patterns in the human generated references in ToTTo (Parikh et al., 2020) and Infotabs (Gupta et al., 2020). The ToTTo and Infotabs validation set have 7700 and 196 tables with at most 3 reference summaries per table. We observe that close to 16.4% and 62.2% of the tables have summaries that use more than 2 reasoning categories simultaneously in ToTTo and Infotabs respectively. We term this as Multi-Category Reasoning. Such an example is shown in Figure 1. The actual table in the dataset lists the monthly temperatures recorded in a town Spin Boldak - we show only a sample here for illustration. We observe that to generate the ideal reference from the highlighted cells requires the model to posses two reasoning skills. First, Tabular Summarization: to compute the maximum and min values over the daily mean field. Second, commonsense reasoning to map the notion of maximum to warmest and that of minimum to coolest. Therefore, to attain human level accuracy on benchmarks like ToTTo and Infotabs a single generative model should have i) the knowledge of multiple reasoning skills ii) the ability to combine more than one skill to summarize\nthe highlighted cells. To the best of our knowledge, there is no prior generative table to text model that is capable of controlling and composing multiple reasoning categories.\nIn this paper, we make the following contributions to address the problems described above.\n\u2022 We formulate a new summarization task called Reasoning Aware Table to Text motivated by failure situations that arise in real-world settings. To the best of our knowledge we are the first to propose this problem formulation. (Section 3)\n\u2022 We present RETAG, a vector quantized approcah in encoder-decoder table to text models to generate rich analytical summaries with controllable multi-category reasoning. The use of RETAG improves the performance of state-of-the-art table to text models on the ToTTo and InfoTabs by 2.2%, 2.9%, respectively, in the PARENT metric. (Sections 4,5)\n\u2022 We release an extended version of the ToTTo and the InfoTabs dataset that are annotated with the following popular reasoning categories: numerical, temporal, commonsense, table reasoning and entity knowledge as defined in (Gupta et al., 2020) (Section 6)."
        },
        {
            "heading": "2 Related Work",
            "text": "Among recent advances Table To Text Models, two directions have led to significant improvement in analytical reasoning performance: Table-Aware Architectures and Analytical Reasoning Pretraining 1. Table-Aware Architectures: Novel model architectures (Liu et al., 2021; Gong et al., 2020; Xing and Wan, 2021; Li et al., 2021) have been proposed to efficiently encode tabular data and hence better use the implicit semantic structure of rows and columns. A large number of works have been introduced to incorporate table structure using pretraining strategies. (Herzig et al., 2020; Andrejczuk et al., 2022; Xing and Wan, 2021; Yin et al., 2020) introduce a pretraining strategy with specialized objectives for structured data: such as Masked Column Prediction(MCP), Adjacent Cell Prediction (ACP) and so on. Some of the above works, also use special row and column embedding to encode the table structure in the input. (Liu et al., 2021) learns table structure using the task of neural SQL execution over tables in their pretraining strategy. (Dong et al., 2022) presents an elaborate survey for table based pretraining strategies. It has been\nshown that for analytical reasoning understanding table structure is a key ingredient. Therefore in our work we use TAPEX (Liu et al., 2021) as our backbone architecture. 2. Analytical Reasoning Pretraining: (Zhao et al., 2022b) introduces a new pretraining strategy with synthetic data augmentation using templates for very specific operations in numerical and temporal reasoning. (Zhu et al., 2021) also incorporates numerical and table operations in the model by appending symbolic reasoning operator selection on top of RoBerTa (Liu et al., 2019). (Zhao et al., 2022a; Chen et al., 2021) performs arithmetic reasoning through program generator module that converts the reasoning operation to an executable program to derive at the answer. Also, (Chen et al., 2022) disentangles computation with reasoning, by converting numerical reasoning aspect to an executable program. (Lei et al., 2022) models numerical question answering as expression tree generator task which helps in better alignment among question, table and paragraph.\nTo the best of our knowledge, none of existing techniques provide controllability with multicategory reasoning. This is the focus of our work. We discuss other prior literature on table to text datasets and controllability in Appendix G."
        },
        {
            "heading": "3 Problem Formulation",
            "text": "In this section, through a systematic human evaluation we first justify the choice of six reasoning categories (five analytical and the descriptive) that we introduce in Section 1. Next, we proceed to formally state the problem of Reasoning-Aware Table to Text Generation."
        },
        {
            "heading": "3.1 Analytical Reasoning Categories",
            "text": "InfoTabs (Gupta et al., 2020) was among the first to systematically present a comprehensive taxonomy for analytical reasoning with 14 categories. For the purposes of addressing data sparsity and nonoverlap of reasoning categories we simplify the 14 categories proposed in (Gupta et al., 2020) into 6 categories as we explain below.\nWe sample roughly 20% of instances from the validation set of each dataset (1750 instances in ToTTo and 180 instances in InfoTabs respectively). The annotation below was done by a team of trained human experts and the details of the process is discussed in further detail in Section 6.\nAll instances were now annotated with the 14\ncategories as described in (Gupta et al., 2020). For (ToTTo, InfoTabs) the breakdown of the 14 categories are given in Table 1.\nWe observe that three categories (Ellipsis, Negation, Subjective) are very rare in both datasets. Due to the sparsity of training data in these categories, we do not consider them for the modeling task. The categories (Coreference, Lexical reasoning, Syntactic Alternations) are well covered by linguistic pre-training datasets and hence we do not explicitly try to model them either. We focus on the remaining 8 categories. Due to similarity of the categories and to coalesce training data, we combine (Numerical Reasoning, Quantification) into one category. Similarly we combine Entity Type and Named Entities into one category leaving us with a total of six categories.\nPlease note that the above methodology of constructing the six categories is an extension to (Gupta et al., 2020) and not a core contribution of our work. It is presented as a simple heuristic to form a viable set of non-overlapping, useful categories each with enough training data. The core contribution of our work is agnostic to the choice of actual categories themselves. Choosing a comprehensive and concise taxonomy for table to text reasoning is outside the scope of our work.\nInformed by the above analysis, we annotated the entire dataset of InfoTabs with the six categories. The training dataset for ToTTo is large (120K samples), therefore we using a filtering heuristic (refer Appendix-A) to annotate a subset of the training set. The test set of ToTTo is not directly available as it is an online benchmark. Hence we annotated only the validation dataset for ToTTo.\nPlease note that no hyper-parameter tuning was done using the ToTTo validation set and was used for performance measurement alone."
        },
        {
            "heading": "3.2 Problem Statement",
            "text": "Let R be the set of six categories defined in Section 1: Descriptive, Tabular, Numerical, Temporal, Common-Sense and Entity reasoning. Given a table T , set of cells {Cij} contained within T and a reasoning category set r \u2286 R, the task of reasoning aware table to text is to generate a summary that uses all the information contained in {Cij}, applies analytical reasoning r and then produces a truthful summary S confirming to r.\nWe use several automatic metrics to measure the relative quality of the generated sentences compared to the reference: BLEU (Papineni et al., 2002), ROUGE-L (Lin, 2004), semantic similarity with sentence embeddings (Reimers and Gurevych, 2019) using the MPNet model (Song et al., 2020); (ii) Between the tables and generated sentences: PARENT (Dhingra et al., 2019).\nIn addition we use three human eval metrics defined by the following questions: 1.Reasoning: Does the generated summary use all reasoning categories required in r? 2. Faithful: Is the generated summary hallucination free (i.e., faithful to the table T ?) 3. Coverage: Are all cells in {Cij} used in the generated summary?"
        },
        {
            "heading": "4 Proposed Model",
            "text": "We propose our model RETAG for controllable multi-skill reasoning table to text generation. We embed the two key aspects required to generate analytical sentences: control on reasoning categories, and being reasoning aware. First, to better model each reasoning category with control, we use a vector quantization (VQ) strategy in RETAG (\u00a74.2 and \u00a74.4). Second, to precisely model each reasoning\ncategory, we use a pretraining strategy to better learn the reasoning categories from structured tables and free-form text data (\u00a74.3).\nFor any table-to-text model, a basic property required is the efficient understanding of table structure. To infuse this aspect, we use the pretrained TAPEX model (Liu et al., 2021) as the encoderdecoder backbone in our framework. TAPEX is a BART (Lewis et al., 2020) model fine-tuned on the task of neural SQL execution over tables. Authors show that this is an effective pretraining strategy for various table related downstream tasks.\nIt is important to note that our model architecture contributions are not limited to TAPEX , and thus we integrate the same modules in T5 (Raffel et al., 2020a) based models and benchmark their performance later in the paper."
        },
        {
            "heading": "4.1 Preliminaries",
            "text": "We denote the encoder and decoder as E and D. We use the question q to pass the reasoning tags in the input: Generate a sentence with TAG reasoning based on the following table? for analytical generation; Generate a descriptive sentence based on the following table? for the descriptive generation task. We concatenate q with the linearized table t to form the input x. The encoded vector is E(x) \u2208 RN\u00d7H , where N is the number of tokens in x, and H is the latent dimension. For our base model, the decoder D generates the corresponding output sentence y = D(E(x))."
        },
        {
            "heading": "4.2 Vector Quantized Reasoning",
            "text": "Our primary objective is to incorporate reasoning level control in our model RETAG . However, one of the main challenges of generating analytical sentences is to learn category specific aspects, which can be used to perform interaction between these categories for complex reasoning. To achieve this, we sandwich a vector quantization module between\nthe encoder and the decoder. Each reasoning category has its own codebook on which the vector quantization operation is performed.\nWe use the encoded representation E(x) to intervene reasoning specific knowledge from codebooks to create a new reasoning aware representation which is then passed to the decoder D.\nA codebook is denoted as c \u2208 RK\u00d7H , which is a latent embedding space of size K, with H being the dimension of each of the codes ci in c (Van Den Oord et al., 2017). We have a codebook cr for each of the five reasoning categories r. For completeness, we also have a separate sixth codebook for the descriptive category. We use the codebooks to extract reasoning based representation for the encoded E(x) using quantization process Q. It maps each token vector in E(x) to the nearest code crk for the given category codebook cr:\nQr(E(x)n) = c r k, \u2200 n = 1, . . . , N where, k = argminj ||E(x)n \u2212 c r j ||2\n(1)\nNow, to model multi-category reasoning for generating analytical sentences, we propose the following weighted summation technique:\nQr(x) = 1R R\u2211 i=1 wi.Qi(x) (2)\nHere, wi represents scalar weights for each reasoning category, predicted from the last layer of the encoder E, through an additional head layer. The binary labels 1R simplify the equation so that the codebooks used are restricted only to the specified reasoning labels. Furthermore, we add a residual connection between the reasoning based representation and the original encoder representation. We then pass the resultant vector to the decoder D to generate the analytical sentence ya.\nua = Qr(x) + E(x) ya = D(ua) (3)\nWe also generate the descriptive sentence yd in a similar manner using a residual connection between the encoded vector and the quantized representation from the descriptive codebook. For ease of understanding, we refer to Qr(x) as Q(x)."
        },
        {
            "heading": "4.3 Reasoning-Aware Pretraining",
            "text": "In order to generate analytical sentences with our proposed architecture, it is crucial that the codebooks are rich in representing each of the reasoning categories efficiently. The five reasoning cat-\negories we use extends beyond performing inferences on specific tables. Therefore, we explore pretraining strategies with various free-form and structured-data based datasets having the specific reasoning components. We collect the following datasets: (i) numerical and textual data (ND, TD) from Geva et al. (2020b), DROP (Dua et al., 2019), MathQA (Amini et al., 2019) for numerical reasoning, (ii) LogicNLG (Chen et al., 2020b), Logic2Text (Chen et al., 2020e) for numerical reasoning and table knowledge, (iii) WIKIBIO (Liu et al., 2018) for table reasoning and entity knowledge, (iv) CommonsenseQA (Talmor et al., 2019), PIQA (Bisk et al., 2020), Social-IQA (Sap et al., 2019) for commonsense reasoning, and (v) MCTACO (Zhou et al., 2019) for temporal reasoning.\nWe have a total of 276k instances from the above datasets spanning over the five reasoning categories. We formulate a seq-to-seq text generation task and pretrain our model (encoder, decoder, codebook) on the reasoning-aware dataset. We detail the model training strategy in Section 4.4."
        },
        {
            "heading": "4.4 Reasoning Control based Fine-tuning",
            "text": "To further improve upon reasoning based representations, we add a classifier network M on top of the residual features ua and ud, which classifies it into analytical and descriptive classes. This classification constraint helps the model to broadly learn the difference between analytical and descriptive sentence. We term this strategy as CI (Classification of Intermediate activations). We show later that this classification strategy helps in improved generation for both descriptive and analytical sentences. The overall loss function for a batch consisting of both analytical and descriptive references, is as follows:\nL = \u2212[(y\u0302d \u2217 logyd + y\u0302a \u2217 logya)](1) \u2212 [log(M(ud)\u2212) + log(M(ua)+)](2) + [||sg[E(x)]\u2212 Q\u0304(x)||22](3) + [\u03b2||E(x)\u2212 sg[Q\u0304(x)]||22](4)\nThe loss function consists of four components: Generative Loss: The first term is the crossentropy loss over the vocabulary for generating the gold descriptive and analytical sentences y\u0302d and y\u0302i. Classifier Loss: The second term is the cross-entropy loss from the classification constraint. We denote \u2212 and + as the descriptive and analytical class. Codebook Loss: stop-gradient (sg) in the third term is required for training the codebooks as the quantization process with argmin operation in Equation (1) is non-differentiable. Van\nDen Oord et al. (2017) used a straight-through estimator to approximate the gradient by copying the gradient from the decoder input to the encoder output. We use the common term Q\u0304(x) to represent the quantized vector for both analytical, descriptive instances. Commitment Loss: The fourth term scaled by hyperparameter \u03b2 helps the encoder output to commit to the closest codebook vector. For codebook pretraining in Section 4.3, we use the loss terms (3), (4) in the first stage, and then (1), (3), (4) in the second stage."
        },
        {
            "heading": "5 Experiments",
            "text": "We evaluate the performance of RETAG as follows: (i) Performance comparison against strong baselines (ii) Ablation study of design choices used in RETAG (iii) Effectiveness of Vector Quantization (iv) Reasoning category wise quantitative analysis and (v) Human evaluations for faithfulness and reasoning control. Since our primary contribution is on multi-category reasoning, we benchmark RETAG \u2019s performance for ToTTo valid and InfoTabs test datasets which have heterogeneous reasoning categories. Hence, we do not evaluate against datasets that are specific to one type of reasoning, such as LogicNLG, Numerical-NLG, etc.\nWe use the following notations for our experiments: given a question q with a linearized table t, we concatenate them to form the input x (as mentioned in Section 4.1). The table may contain some highlighted cells, which can be enclosed within special indicators such as <hl> or can be addition-\nally mentioned at the beginning or end of the table string. We assume that the highlighted cells would be indicated in either of these ways within the linearized table t. We use the strategy devised in Liu et al. (2021) for linearizing the table. Additionally we are also given the reasoning categories r and the corresponding output sentence y."
        },
        {
            "heading": "5.1 Main Results",
            "text": "We use the following models in our experiments: T5-Large (768M parameters) (Raffel et al., 2020b), FLAN T5-Large (768M parameters) (Chung et al., 2022) and TAPEX (406M parameters) (Liu et al., 2021). We use the models in three different ways:\n1. We use only x to directly generate y. No information about r is consumed by the model. This is the usual seq-to-seq baseline. We denote this strategy as NO TAGS in Table 2.\n2. We use information about r as part of the question q. Then we train the models to generate y from x. The category information is thus used as part of the input string x. We deonte this as TAGS in Table 2.\n3. We use information about r with the codebook selection strategy. This is our proposed RETAG method with pretraining as mentioned earlier in Section 4 and Section 4.3.\nToTTo: We observe that the models with the TAGS or RETAG approach generally outperform the models with NO TAGS. We observe this result\nacross most of the evaluation metrics. In particular the TAPEX RETAG model achieves around 1% improvement in BLEU-1, ROUGE-L and around 2% improvement over the NO TAGS models for the overall performance in the validation set. The performance improvement in the analytical set is slightly more prominent compared to the descriptive set in the BLEU-1 and PARENT metrics. We postulate that the tag-based distinction between analytical and descriptive control improves the performance for descriptive sentences, as the model gets a clear signal of when to describe the content versus when to reason.\nWe further study the importance of augmenting the input table with reasoning categories for finetuning the models in the Tags group of results. We observe that it leads to increment in performance across the BLEU-1 and PARENT metrics for the overall set. In the analytical set, the improvement in performance is around 1% across for BLEU-1 and PARENT for all the models.\nInfoTabs We achieve considerable improvement with the TAGS and RETAG approach for overall performance and analytical set performance in Infotabs. TAPEX model has superior performance over the T5 family model in NO TAGS as the TAPEX is trained on table corpora on table understanding tasks. However, the performance of the comparatively poorer T5 and FLAN-T5 model is significantly improved with the use of categorical information. It re-iterates the importance of adding reasoning based control in various models. Our proposed TAPEX RETAG model still outperforms the TAPEX TAG model by more than 1% for BLEU-1 and PARENT for overall set, and around 3% and 1% for BLEU and PARENT for the analytical set."
        },
        {
            "heading": "5.2 Ablation Studies",
            "text": "RETAG consists of three main components: the codebooks, the classification objective to differentiate analytical and descriptive and the pretraining technique of the codebooks. In this section, we study the effect of these three components on the\nperformance. 1. Number of Codebooks In Table 3, we present the performance of RETAG for two and six codebook setup with category specific quantization. The six codebook setup is the model we originally introduced in Section 4. We now combine the five reasoning categories into one analytical category and keep the descriptive category as the other category. This results in the two codebook setup, which we then benchmark with the TAPEX RETAG model.\nWe observe that six codebook setup consistently outperforms two codebook setup across the various metrics for both ToTTo and InfoTabs datasets (first and third rows in Table 3). We conclude that category specific codebooks provide more flexibility and capacity in the model with better control over the generations. 2. Intermediate Activation Classification In Table 3 we also study the effect of classifying the residual features ua and ud into analytical and descriptive classes with the CI classification loss (Section 4.4). We observe that the RETAG performance improves consistently with CI constraint for both the two and six codebook setups on both the ToTTo and InfoTabs dataset. 3. Codebook Pretraining Strategies In Table 4, we study the efficacy of the codebook pretraining stratey. All the RETAG models here have six codebooks and the CI constraint enabled. As the name suggests, in the no pretraining strategy, we do not perform any pretraining on the model and directly fine-tune it for table-to-text task. In the with pretraining strategy, we start with random initialization of the codebooks and pretrain the codebooks along with the encoder and decoder of the models on the ensemble of reasoning dataset mentioned earlier in Section 4.3. We found that the the pretraining strategy is considerably more effective for the final tasks in ToTTo and InfoTabs across all the evaluation metrics, as reported in Table 4."
        },
        {
            "heading": "5.3 Codebook Analysis",
            "text": "In this section, we analyze the effectiveness of the codebooks for analytical generations as follows.\n1. Category-Wise Performance We evaluate results across reasoning categories in Table 5. We pick out instances having just a single category annotated and report the results for them in the L.H.S of Table 5. It helps us in analyzing the effect on each category without the involvement of others. We note that the six codebooks in TAPEX RETAG helps improve performance across all the five reasoning categories in comparison to the baseline model. The TAPEX model with TAGS also helps in improving the performance over the TAPEX model without any tags.\n2. Multi-Category Reasoning: We also study TAPEX RETAG for complex analytical sentences that involves two or more reasoning categories. We report average results for instances having two or three categories in the R.H.S of Table 5. TAPEX RETAG consistently outperforms the baseline by 2% in BLEU1 score for ToTTo and around 4% in BLEU1 and 3% in ROUGE-L for the InfoTabs dataset.\n3. Random Reasoning Labels In Table 6, we study the performance when random reasoning categories are sent to the model during inference. We observe that, the evaluation scores drop by significant margins across sentences with single and multiple categories across both the datasets. This shows, that the codebook encodes meaningful and distinct representations for each reasoning category. We show in Appendix F that RETAG is also able to beat SOTA baselines for a Table QA task on a dataset called Turning Tables (Yoran et al., 2022) where the reasoning categories are provided.\nWe conclude that RETAG models capture reasoning-specific information in each codebook through pretraining, which it uses effectively for both single and multi-category analytical sentence generation."
        },
        {
            "heading": "5.4 Human Evaluation",
            "text": "We sample 500 instances from the ToTTo validation set and generate their corresponding analytical sentences from four different models specified in Table 7. Given an instance of table and the reasoning categories, we ask the annotators to evaluate the the sentence on three questions as described in Section 3.2: Reasoning, Faithful and Coverage.\nWe ask the annotators to provide a label between \u2013 yes (score 1), partially (score 0.5), or no (score 0). We compare TAPEX RETAG against the TAPEX model without tags for human evaluation to quantify faithfulness and reasoning control. We collect 3 ratings for each sample and compile the majority label results in percentage scale in Table 7. We observe that with explicit reasoning control, TAPEX RETAG generates 13% more faithful and 12% better coverage on the reasoning categories on analytical sentences as compared to TAPEX NO TAGS. We found very good inter rater agreement for the human evaluation task. The Fleiss\u2019 kappa score between the three annotators for human evaluation were as follows: 0.5011 on the reasoning categories, 0.5583 on the faithfulness, and 0.6722 on the coverage of highlighted cells. Some examples of RETAG output can be found in Appendix E."
        },
        {
            "heading": "6 Reasoning Category Tagged Dataset Release",
            "text": "As explained in Section 3.1, we will release 31.4K analytical instances and 50.6K for the ToTTo train and validation set. We will also release 4.2K analytical instances and 5.3K descriptive sentences over the entire InfoTabs dataset. This section explains the human labeling methodology and the corresponding performance metrics.\nWe prepared detailed annotation instructions, qualifying questions and trained a pool of 14 crowdsource annotators. The annotators are based in India and are fluent in English. The annotators were paid at rates above required by local wage laws.\nWe instructed the annotators to choose one or more of the five reasoning categories for analytical sentences. We instructed them to keep the five reasoning categories and the Descriptive category exclusive i.e. a sentence is descriptive only when it does not use any of the other five reasoning categories. Three annotators labeled every instance and we keep only those label voted by atleast two raters. The annotators reached a high consensus agreement on the task. 86.81% of ratings had all three raters agree on the binary class for categorizing between descriptive and analytical. 75.12% all three raters agreed on the exact same set of categories for choosing the analytical categories."
        },
        {
            "heading": "7 Conclusion",
            "text": "In this paper, we presented the case for Reasoningaware table-to-text models. We introduced RETAG, a vector quantized approach for encoder-decoder table-to-text models with explicit control across reasoning categories. RETAG beats SOTA models for ToTTo and InfoTabs datasets for analytical and descriptive sentence generation. We will also release close to 35.6K instances of reasoning category tagged analytical abd 55.9k instances of descriptive table to text data."
        },
        {
            "heading": "8 Limitations",
            "text": "Some of the limitations of our work are as follows. First, the dataset curation and performance evaluation was restricted to datasets in the English language, and does not extend to non-dominant languages. Second, several advanced methods have been introduced for numerical reasoning. Our current strategy to incorporate reasoning is datacentric. However, we would like to emphasize that the explicit reasoning control is complementary to the existing methods and in future works, advance methods to infuse reasoning can be used alongside our method. Third, to gain explicit reasoning control for newer domain/reasoning category, involves few examples to be annotated to bootstrap the model using our method. Fourth, although RETAG is designed for multiple skill reasoning, in future work we will also benchmark RETAG against reasoning specific datasets such as LogicNLG."
        },
        {
            "heading": "A Dataset Details and Filtering Strategy",
            "text": "ToTTo (Parikh et al., 2020) is an open domain table-to-text dataset where the task is as follows: given a table with a set of highlighted cells, generate a sentence constrained upon the highlighted cells. The tables are collected from Wikipedia and metadata information (table title, section title containing the table) are available. We observe that many reference sentences in the dataset are analytical, as they are based on different forms of reasoning, as opposed to simply stating the highlighted cells verbatim. We compute a fuzzy string match between the annotated reference and the highlighted cells + metadata of the table. We identify \u223c63k instances (out of total 120k in ToTTo training set) using various constraints: (i) reference contain non-stop words not present in the table; (ii) fuzzy match < 80%, (iii) fuzzy match < 85% and presence of superlatives, comparatives, or numerics (largest, faster, third, etc.). We annotate a small pilot set and surmised that \u223c 40% of the 63k instances are analytical and these 63k instances would contain most of the analytical instances in ToTTo training set. In addition we also use the full validation set for annotation, as mentioned previously in Seciton 6.\nInfoTabs (Gupta et al., 2020) is a dataset for table natural language inference (NLI), where the tables (collected from Wikipedia info-boxes) are considered as semi-structured premise and human written sentences are provided as hypothesis. The task is predict whether the sentence is an entailment, contradiction, or neutral w.r.t the table. We compute the fuzzy match between the linearized table and the entailment instances and identify: (i) 4.9k instances with fuzzy match < 75% as potentially analytical, and (ii) 1.7k instances with fuzzy match > 80% as potentially non-analytical. To keep the the two categories somewhat balanced, we additionally generate 2.9k potentially non-analytical instances using a keyword to sentence seq2seq model trained on the WikiTableText dataset (Bao et al., 2018). In total, we have 9.5k instances to annotate."
        },
        {
            "heading": "B Reasoning Categories",
            "text": "We show some examples of table, sentence pairs and the corresponding reasoning categories Figure 3 - 7. Some of these examples show how multiple reasoning categories could be combined to generate an analytical sentence. We also show an example of descriptive sentence in Figure 8."
        },
        {
            "heading": "C Experimental Setup and Computational Resources",
            "text": "We use beam search to generate outputs from the our generative models. We used a beam length of 10 is used. All models were trained with the AdamW optimizer with a learning rates of 1e-6,\n3e-6, 5e-6, 1e-5. We used Quadro RTX 8000 GPU for our experiments. We train all our models for 10 epochs, which takes 3 hours for ToTTo and 1.5\nhours for InfoTabs. The TAPEX and T5 family models have 406M and 768M parameters, respectively. The codebooks in RETAG contribute to the additional 3M parameters."
        },
        {
            "heading": "D Evaluation Metrics",
            "text": "We used the sacreBLEU implementation (Post, 2018) for computing BLEU scores. For ToTTo, we used the originally released code by authors for computing the PARENT metric. For InfoTabs, we used a lambda weight of 0.1 for computing the PARENT metric."
        },
        {
            "heading": "E Example of Generations",
            "text": "We show some instances of generated analytical sentences for the InfoTabs dataset in Table 8. We show generations from the TAPEX without tags model and our proposed TAPEX RETAG model in the table. In the first example, given the numerical, temporal reasoning categories, TAPEX RETAG is able to infer that \u201cshe has been acting for over 20 years\u201d and \u201cis still active\u201d through commonsense reasoning."
        },
        {
            "heading": "F Results on Turning Tables",
            "text": "Turning tables (Yoran et al., 2022) is a table based QA dataset with reasoning categories annotated. We observe that our TAPEX RETAG approach outperforms TAPEX for this task as well, when we use the reasoning categories mentioned in their work."
        },
        {
            "heading": "G Extended Related Work",
            "text": "G.1 Table-Aware Pretraining\nWith the success of pre-trained language models on unstructured text, a large number of works have been introduced to incorporate table structure using similar pre-trained strategies. (Herzig et al., 2020; Andrejczuk et al., 2022; Xing and Wan, 2021,?; Yin et al., 2020) introduce a pretraining strategy with specialized objectives for structured data: such as Masked Column Prediction(MCP), Adjacent Cell Prediction (ACP) and so on. Some of the above works, also use special row and column embedding to encode the table structure in the input. (Liu et al., 2021) learns table structure using the task of neural SQL execution over tables in their pretraining strategy. (Dong et al., 2022) presents an elaborate survey for table based pretraining strategies. For any table-specific reasoning task, understanding table structure forms the basis, therefore in this work we use TAPEX (Liu et al., 2021) as our base model. To the best of our knowledge it is the state of the art for ToTTo dataset.\nG.2 Datasets\nNewer dataset encompasses (Chen et al., 2020c): consists of diversified sentences across symbolic operations (such as max, min, etc.); (Chen et al., 2020d; Zhu et al., 2021; Chen et al., 2021; Zhao et al., 2022a) introduce table and text based QA tasks that primarily involve numerical and table reasoning along with interactions between table and given text to predict the correct answer. (Nan et al., 2022) is Table-QA dataset that involves complex reasoning. (Suadaa et al., 2021; Chen et al., 2020f, 2019) also consist of references that incorporate numerical and table reasoning.\nG.3 Controllability in Structured Data There are various works (Parikh et al., 2020; Su et al., 2021b; Wang et al., 2022) that focus on the controlling content while generating from structured data. (Li et al., 2021) uses a prefix set of tokens to better control the topic of the generated text. (Su et al., 2021a) extracts free-form prototypes from a large knowledge base to control the structural formation of the generated text. One of the recent works. To the best of our knowledge, ours is one of the first works to explicitly model for control on various reasoning aspects for structured data to text generation."
        }
    ],
    "title": "ReTAG: Reasoning Aware Table to Analytic Text Generation",
    "year": 2023
}