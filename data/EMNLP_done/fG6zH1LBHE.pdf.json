{
    "abstractText": "An attractive blog headline on social media platforms can immediately grab readers and trigger more clicks. However, a good headline shall not only contract the main content but also be eye-catchy with domain platform features, which are decided by the website\u2019s users and objectives. With effective headlines, bloggers can obtain more site traffic and profits, while readers can have easier access to topics of interest. In this paper, we propose a disentanglement-based headline generation model: MediaHG (Social Media Headline Generation), which can balance the content and contextual features. Specifically, we first devise a sample module for various document views and generate the corresponding headline candidates. Then, we incorporate contrastive learning and auxiliary multi-task to choose the best domain-suitable headline, according to the disentangled budgets. Besides, our separated processing gains more flexible adaptation for other headline generation tasks with special domain features. Our model is built from the content and headlines of 70k hot posts collected from REDBook, a Chinese social media platform for daily sharing. Experimental results with language metrics ROUGE and human evaluation show the improvement in the headline generation task for the platform1.",
    "authors": [
        {
            "affiliations": [],
            "name": "Boning Zhang"
        },
        {
            "affiliations": [],
            "name": "Yang Yang"
        }
    ],
    "id": "SP:07680cc2a23238aed35e1debb6e54afa8044d50b",
    "references": [
        {
            "authors": [
                "Georgios Balikas",
                "Simon Moura",
                "Massih-Reza Amini."
            ],
            "title": "Multitask learning for fine-grained twitter sentiment analysis",
            "venue": "Proceedings of the 40th international ACM SIGIR conference on research and development in information retrieval, pages 1005\u2013",
            "year": 2017
        },
        {
            "authors": [
                "Zhangming Chan",
                "Xiuying Chen",
                "Yongliang Wang",
                "Juntao Li",
                "Zhiqiang Zhang",
                "Kun Gai",
                "Dongyan Zhao",
                "Rui Yan."
            ],
            "title": "Stick to the facts: Learning towards a fidelity-oriented e-commerce product description generation",
            "venue": "Proceedings of the 2019 Conference",
            "year": 2019
        },
        {
            "authors": [
                "Zhangming Chan",
                "Yuchi Zhang",
                "Xiuying Chen",
                "Shen Gao",
                "Zhiqiang Zhang",
                "Dongyan Zhao",
                "Rui Yan."
            ],
            "title": "Selection and generation: Learning towards multi-product advertisement post generation",
            "venue": "Proceedings of the 2020 Conference on Empirical",
            "year": 2020
        },
        {
            "authors": [
                "Mingda Chen",
                "Qingming Tang",
                "Sam Wiseman",
                "Kevin Gimpel."
            ],
            "title": "A multi-task approach for disentangling syntax and semantics in sentence representations",
            "venue": "arXiv preprint arXiv:1904.01173.",
            "year": 2019
        },
        {
            "authors": [
                "Xi Chen",
                "Yan Duan",
                "Rein Houthooft",
                "John Schulman",
                "Ilya Sutskever",
                "Pieter Abbeel."
            ],
            "title": "Infogan: Interpretable representation learning by information maximizing generative adversarial nets",
            "venue": "Advances in neural information processing systems, 29.",
            "year": 2016
        },
        {
            "authors": [
                "Xiuying Chen",
                "Zhangming Chan",
                "Shen Gao",
                "MengHsuan Yu",
                "Dongyan Zhao",
                "Rui Yan."
            ],
            "title": "Learning towards abstractive timeline summarization",
            "venue": "IJCAI, pages 4939\u20134945.",
            "year": 2019
        },
        {
            "authors": [
                "Zi-Yi Dou",
                "Pengfei Liu",
                "Hiroaki Hayashi",
                "Zhengbao Jiang",
                "Graham Neubig."
            ],
            "title": "Gsum: A general framework for guided neural abstractive summarization",
            "venue": "arXiv preprint arXiv:2010.08014.",
            "year": 2020
        },
        {
            "authors": [
                "Sergey Edunov",
                "Myle Ott",
                "Michael Auli",
                "David Grangier",
                "Marc\u2019Aurelio Ranzato"
            ],
            "title": "Classical structured prediction losses for sequence to sequence learning",
            "venue": "arXiv preprint arXiv:1711.04956",
            "year": 2017
        },
        {
            "authors": [
                "Marcio Fonseca",
                "Yftah Ziser",
                "Shay B Cohen."
            ],
            "title": "Factorizing content and budget decisions in abstractive summarization of long documents by sampling summary views",
            "venue": "arXiv preprint arXiv:2205.12486.",
            "year": 2022
        },
        {
            "authors": [
                "Zhenxin Fu",
                "Xiaoye Tan",
                "Nanyun Peng",
                "Dongyan Zhao",
                "Rui Yan."
            ],
            "title": "Style transfer in text: Exploration and evaluation",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 32.",
            "year": 2018
        },
        {
            "authors": [
                "Shen Gao",
                "Xiuying Chen",
                "Piji Li",
                "Zhaochun Ren",
                "Lidong Bing",
                "Dongyan Zhao",
                "Rui Yan"
            ],
            "title": "Abstractive text summarization by incorporating reader",
            "year": 2019
        },
        {
            "authors": [
                "Irina Higgins",
                "Loic Matthey",
                "Arka Pal",
                "Christopher Burgess",
                "Xavier Glorot",
                "Matthew Botvinick",
                "Shakir Mohamed",
                "Alexander Lerchner."
            ],
            "title": "beta-vae: Learning basic visual concepts with a constrained variational framework",
            "venue": "International conference",
            "year": 2017
        },
        {
            "authors": [
                "Mark Hopkins",
                "Jonathan May."
            ],
            "title": "Tuning as ranking",
            "venue": "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1352\u20131362, Edinburgh, Scotland, UK. ACL.",
            "year": 2011
        },
        {
            "authors": [
                "Zhiting Hu",
                "Zichao Yang",
                "Xiaodan Liang",
                "Ruslan Salakhutdinov",
                "Eric P Xing."
            ],
            "title": "Toward controlled generation of text",
            "venue": "International conference on machine learning, pages 1587\u20131596. PMLR.",
            "year": 2017
        },
        {
            "authors": [
                "Di Jin",
                "Zhijing Jin",
                "Joey Tianyi Zhou",
                "Lisa Orii",
                "Peter Szolovits."
            ],
            "title": "Hooks in the headline: Learning to generate headlines with controlled styles",
            "venue": "arXiv preprint arXiv:2004.01980.",
            "year": 2020
        },
        {
            "authors": [
                "Vineet John",
                "Lili Mou",
                "Hareesh Bahuleyan",
                "Olga Vechtomova."
            ],
            "title": "Disentangled representation learning for non-parallel text style transfer",
            "venue": "arXiv preprint arXiv:1808.04339.",
            "year": 2018
        },
        {
            "authors": [
                "Huda Khayrallah",
                "Brian Thompson",
                "Matt Post",
                "Philipp Koehn."
            ],
            "title": "Simulated multiple reference training improves low-resource machine translation",
            "venue": "arXiv preprint arXiv:2004.14524.",
            "year": 2020
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdelrahman Mohamed",
                "Omer Levy",
                "Ves Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
            "year": 2019
        },
        {
            "authors": [
                "Juntao Li",
                "Lidong Bing",
                "Lisong Qiu",
                "Dongmin Chen",
                "Dongyan Zhao",
                "Rui Yan."
            ],
            "title": "Learning to write stories with thematic consistency and wording novelty",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 1715\u20131722.",
            "year": 2019
        },
        {
            "authors": [
                "Mingzhe Li",
                "Xiuying Chen",
                "Min Yang",
                "Shen Gao",
                "Dongyan Zhao",
                "Rui Yan."
            ],
            "title": "The stylecontent duality of attractiveness: Learning to write eye-catching headlines via disentanglement",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelli-",
            "year": 2021
        },
        {
            "authors": [
                "Chin-Yew Lin."
            ],
            "title": "Rouge: A package for automatic evaluation of summaries",
            "venue": "Text summarization branches out, pages 74\u201381.",
            "year": 2004
        },
        {
            "authors": [
                "Danyang Liu",
                "Juntao Li",
                "Meng-Hsuan Yu",
                "Ziming Huang",
                "Gongshen Liu",
                "Dongyan Zhao",
                "Rui Yan."
            ],
            "title": "A character-centric neural model for automated story generation",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34,",
            "year": 2020
        },
        {
            "authors": [
                "Yixin Liu",
                "Zi-Yi Dou",
                "Pengfei Liu."
            ],
            "title": "Refsum: Refactoring neural summarization",
            "venue": "arXiv preprint arXiv:2104.07210.",
            "year": 2021
        },
        {
            "authors": [
                "Yixin Liu",
                "Pengfei Liu."
            ],
            "title": "Simcls: A simple framework for contrastive learning of abstractive summarization",
            "venue": "arXiv preprint arXiv:2106.01890.",
            "year": 2021
        },
        {
            "authors": [
                "Yizhu Liu",
                "Qi Jia",
                "Kenny Zhu."
            ],
            "title": "Length control in abstractive summarization by pretraining information selection",
            "venue": "ACL, pages 6885\u20136895.",
            "year": 2022
        },
        {
            "authors": [
                "Fujun Luan",
                "Sylvain Paris",
                "Eli Shechtman",
                "Kavita Bala."
            ],
            "title": "Deep photo style transfer",
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4990\u20134998.",
            "year": 2017
        },
        {
            "authors": [
                "Minh-Thang Luong",
                "Quoc V Le",
                "Ilya Sutskever",
                "Oriol Vinyals",
                "Lukasz Kaiser."
            ],
            "title": "Multi-task sequence to sequence learning",
            "venue": "arXiv preprint arXiv:1511.06114.",
            "year": 2015
        },
        {
            "authors": [
                "Takuya Makino",
                "Tomoya Iwakura",
                "Hiroya Takamura",
                "Manabu Okumura."
            ],
            "title": "Global optimization under length constraint for neural text summarization",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume",
            "year": 2019
        },
        {
            "authors": [
                "Tomoya Mizumoto",
                "Yuji Matsumoto."
            ],
            "title": "Discriminative reranking for grammatical error correction with statistical machine translation",
            "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics:",
            "year": 2016
        },
        {
            "authors": [
                "Ramesh Nallapati",
                "Feifei Zhai",
                "Bowen Zhou."
            ],
            "title": "Summarunner: A recurrent neural network based sequence model for extractive summarization of documents",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 31.",
            "year": 2017
        },
        {
            "authors": [
                "Nadav Oved",
                "Ran Levy."
            ],
            "title": "Pass: Perturb-andselect summarizer for product reviews",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
            "year": 2021
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311\u2013318.",
            "year": 2002
        },
        {
            "authors": [
                "Natalie Schluter."
            ],
            "title": "The limits of automatic summarisation according to rouge",
            "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, pages 41\u201345. Association for Computational Linguistics.",
            "year": 2017
        },
        {
            "authors": [
                "Tianxiao Shen",
                "Tao Lei",
                "Regina Barzilay",
                "Tommi Jaakkola."
            ],
            "title": "Style transfer from non-parallel text by cross-alignment",
            "venue": "Advances in neural information processing systems, 30.",
            "year": 2017
        },
        {
            "authors": [
                "Kai Shu",
                "Suhang Wang",
                "Thai Le",
                "Dongwon Lee",
                "Huan Liu."
            ],
            "title": "Deep headline generation for clickbait detection",
            "venue": "2018 IEEE International Conference on Data Mining (ICDM), pages 467\u2013476. IEEE.",
            "year": 2018
        },
        {
            "authors": [
                "Ilya Sutskever",
                "Oriol Vinyals",
                "Quoc V Le."
            ],
            "title": "Sequence to sequence learning with neural networks",
            "venue": "Advances in neural information processing systems,",
            "year": 2014
        },
        {
            "authors": [
                "Christian Szegedy",
                "Vincent Vanhoucke",
                "Sergey Ioffe",
                "Jon Shlens",
                "Zbigniew Wojna"
            ],
            "title": "Rethinking the inception architecture for computer vision",
            "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
            "year": 2016
        },
        {
            "authors": [
                "Sho Takase",
                "Naoaki Okazaki."
            ],
            "title": "Positional encoding to control output sequence length",
            "venue": "arXiv preprint arXiv:1904.07418.",
            "year": 2019
        },
        {
            "authors": [
                "Ashwin K Vijayakumar",
                "Michael Cogswell",
                "Ramprasath R Selvaraju",
                "Qing Sun",
                "Stefan Lee",
                "David Crandall",
                "Dhruv Batra."
            ],
            "title": "Diverse beam search: Decoding diverse solutions from neural sequence models",
            "venue": "arXiv preprint arXiv:1610.02424.",
            "year": 2016
        },
        {
            "authors": [
                "Xiaojun Wan",
                "Ziqiang Cao",
                "Furu Wei",
                "Sujian Li",
                "Ming Zhou."
            ],
            "title": "Multi-document summarization via discriminative summary reranking",
            "venue": "arXiv preprint arXiv:1507.02062.",
            "year": 2015
        },
        {
            "authors": [
                "Pan Xie",
                "Zhi Cui",
                "Xiuyin Chen",
                "Xiaohui Hu",
                "Jianwei Cui",
                "Bin Wang."
            ],
            "title": "Infusing sequential information into conditional masked translation model with self-review mechanism",
            "venue": "arXiv preprint arXiv:2010.09194.",
            "year": 2020
        },
        {
            "authors": [
                "Peng Xu",
                "Chien-Sheng Wu",
                "Andrea Madotto",
                "Pascale Fung."
            ],
            "title": "Clickbait? sensational headline generation with auto-tuned reinforcement learning",
            "venue": "arXiv preprint arXiv:1909.03582.",
            "year": 2019
        },
        {
            "authors": [
                "Jingqing Zhang",
                "Yao Zhao",
                "Mohammad Saleh",
                "Peter Liu."
            ],
            "title": "Pegasus: Pre-training with extracted gap-sentences for abstractive summarization",
            "venue": "International Conference on Machine Learning, pages 11328\u201311339. PMLR.",
            "year": 2020
        },
        {
            "authors": [
                "Xingxing Zhang",
                "Mirella Lapata",
                "Furu Wei",
                "Ming Zhou."
            ],
            "title": "Neural latent extractive document summarization",
            "venue": "arXiv preprint arXiv:1808.07187.",
            "year": 2018
        },
        {
            "authors": [
                "Junbo Zhao",
                "Yoon Kim",
                "Kelly Zhang",
                "Alexander Rush",
                "Yann LeCun."
            ],
            "title": "Adversarially regularized autoencoders",
            "venue": "International conference on machine learning, pages 5902\u20135911. PMLR.",
            "year": 2018
        },
        {
            "authors": [
                "Ming Zhong",
                "Pengfei Liu",
                "Yiran Chen",
                "Danqing Wang",
                "Xipeng Qiu",
                "Xuanjing Huang."
            ],
            "title": "Extractive summarization as text matching",
            "venue": "arXiv preprint arXiv:2004.08795.",
            "year": 2020
        },
        {
            "authors": [
                "Qingyu Zhou",
                "Nan Yang",
                "Furu Wei",
                "Shaohan Huang",
                "Ming Zhou",
                "Tiejun Zhao."
            ],
            "title": "Neural document summarization by jointly learning to score and select sentences",
            "venue": "arXiv preprint arXiv:1807.02305.",
            "year": 2018
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Nowadays, in the midst of massive flow of information on large-scale social network sites (such as Facebook and Instagram), users always feel more difficult to quickly obtain the information they want. As a result, people tend to focus on more niche platforms, which are often made up of groups of users with common personal interests. The vertical platforms are not only used for\n\u2217Corresponding author 1The code is available at https://github.com/\nRosenn2000/MediaHG\neasier information search but also strengthen the community of users with the same interests. Users\u2019 attention is always limited to attractive headlines that can catch their eyes at first glimpse. As the headline condenses the main topic into a concise and appealing description, a good headline can trigger a high click rate. So generating better headlines is significant for media platforms to compete for attracting users\u2019 limited attention and deliver users better experiences.\nWe conduct the research based on a vertical Chinese social media platform REDBook (Figure 2) because it is widely praised by hundreds of millions of users and targeted by the same interest group. As more than 70% of users are female (an official reported data), the topics and tone of posts are feminine such as some typical words \"Babycare\", \"Makeup\" etc. The platform breaks down identity restrictions and allows people to share their colorful lives and experience, which are of reference value for users. We define the eye-catchy features of posts as the ability to attract users, which can be intuitively measured by the number of \"likes\",\nthat is, the heat of posts on the platform. Producers can obtain more traffic and profits while getting more likes from the platform, then they may be subscribed by more fans. The advertising revenue of bloggers is usually closely related to both the number and profile of their followers. So only with the help of good headlines, can the bloggers attract their target user group.\nBy analyzing eye-catchy REDBook headlines with more likes (more than 2k) on the platform, we find that both contents and style influence attractiveness. Since the majority of users are women, topics of interest to women occupy a large part of the topics on the platform. Accordingly, headlines with domain special topics such as \"Lipstick swatches\" or \"ootd\" (\"Outfit of the Day\") are more appealing with more likes. Combined with hot topics, the style of the headline also has a great impact on eye-catchy features. For example, when reporting the hot issue \"lipsticks sharing\", the headline \"New Lipsticks for Winter So Tender like a Creamy Almond Peach!!\" (as shown on the platform \u201c\u51ac\u5b63\u53e3\u7ea2\u65b0\u54c1\uff5e\u5976\u8338\u8338\u7684\u674f\u4ec1\u6843\u5b50\u597d \u6e29\u67d4\u201d in Chinese) wins over 13,000 likes, while another headline with the same topic but a plain description \"Lipstick Share, a New Style for Winter\" only has 300 likes. We also find the eye-catchy style of the headlines on the platform is not that similar to the style of news media headlines, as it more closely resembles the tone of women talking and sharing with their friends.\nFocusing on relevant works, we found that recent researches simply regard the headline generation task as a typical summarization task (Shu et al., 2018). They only focus on the content parallel to the given reference summary, ignoring the domain eye-catchy features. However, attractive headlinegeneration tasks have received less attention. A recent clickbait research (Xu et al., 2019) leverages adversarial training and attractiveness scores module to guide the summarization process. Another (Jin et al., 2020) introduces a novel parametersharing scheme to disentangle the attractive style from the text. However, these previous works only concentrate on style and neglect the content importance, which also weighs in eye-catchy headline generation. Disentanglement module is devised to divide the style and content into latent spaces, but a style encoder in generator training is not flexible enough(Li et al., 2021).\nTo address the headline generation issue, we pro-\npose the MediaHG model which disentangles the eye-catchy features as additional requirements in sequence-to-sequence training. The model is composed of a headline candidates generator and an eye-catchy headline selector. In our setting, the neural abstractive model is responsible for headline generation, capturing the main topic of the input document, while the selection module with constraint will encourage the adherence of generated headlines to domain eye-catchy features. Instead of confounding eye-catchy features, we treat the content feature and style feature extraction respectively. In the generation period, we devise a random sample module with different parts of the text and generate candidate headlines responding to the content. During selection period, we leverage ranking-based contrastive learning(Hopkins and May, 2011)(Zhong et al., 2020)(Liu et al., 2021) and multi-task(Luong et al., 2015) to select the best headlines among candidates. The selection is decided by the coordinating quality scores of stylecontent attractiveness. We will describe the specific quality metrics model in detail in the following part. Therefore, candidates are assigned with probabilities according to their quality, which will further influence the generation model. In other words, the headline generation model not only generates output headlines autoregressively but also estimates the probability distribution over candidate headlines.\nOur main contributions are listed below:\n\u2022 We propose a new Headline Generation model namely MediaHG to generate topic-catchy and contextual harmonized headlines for vertical niche platforms to enhance the click ratio and draw users\u2019 attention. While we base our experiments on a typical vertical platform REDBook, our methods can be adapted to other platforms through the same platformsuitable features extraction methods.\n\u2022 Our model is proved to be effective by both automatic and human evaluation scores of fluency, consistency, and attractiveness, which means it achieves a style-content dual balance.\n\u2022 To the best of our knowledge, it is the first research to focus on vertical interest platforms. We also give a new definition of domain eyecatchy headlines that is, those attractive combinations with topic and style suitable to the platform users."
        },
        {
            "heading": "2 Related work",
            "text": "Headline Generation Text generation has undergone impressive progress in recent years (Li et al., 2019)(Chan et al., 2019)(Liu et al., 2020)(Xie et al., 2020)(Chan et al., 2020), and headline generation occupies the dominance. Most existing works merely focus on document summarization with extractive (Nallapati et al., 2017)(Zhou et al., 2018)(Zhang et al., 2018) or abstractive (Gao et al., 2019)(Chen et al., 2019b)models. Several methods regard headline generation as a task based on length-controlled text summarization. Controlling length in summaries has been addressed by encoding positional information (Takase and Okazaki, 2019), a length-aware attention mechanism (Liu et al., 2022), and a length constraint optimization(Makino et al., 2019). Content guidance in GSum(Dou et al., 2020) is used as the input for its sequence-to-sequence model, and shifts in guidance distribution would require further training. Attractive headline generation is paid less attention by researchers. A sensation scorer(Xu et al., 2019) is designed to judge whether a headline is attractive and guide the headline generation by reinforcement learning. Also, a parameter-sharing scheme(Jin et al., 2020) is introduced to further extract style from the text. The style-content duality is considered with VAE (Variational AutoEncoder) as a feature extractor (Li et al., 2021) and two disentangled space constraints in parallel tasks. Differently, MediaHG allows flexible shifts in various guidance without expensive retraining. Disentanglement Disentangling neural networks\u2019 latent space has been explored in the computer vision domain to factorize the features (such as ro-\ntation and color) of images (Chen et al., 2016)(Higgins et al., 2017)(Luan et al., 2017). Compared to the computer vision field, NLP tasks mainly treat sentiment as a salient style and focus on invariant representation learning. It is used to control sentiment through training a discriminator (Hu et al., 2017). Then, disentangled representation learning is further widely adopted in nonparallel text style transfer. For example, separate training with style-specific embeddings and style-specific embeddings are proposed(Fu et al., 2018). Some work also focuses on disentangling syntax and semantic representations in text. VGVAE(Chen et al., 2019a) trains the generative model with multiple losses that exploit aligned paraphrastic sentences and word-order information to get better syntax and semantics representations. We utilize the core principle of disentangling to separate different feature budgets. Reranking Candidates Recent conditional generation work explores the idea of reranking candidates from different dimensions(Wan et al., 2015)(Mizumoto and Matsumoto, 2016). Different search methods have been used in neural language summarization models, such as greedy search in FactorSum (Fonseca et al., 2022) and beam search (Vijayakumar et al., 2016) in SimCLS (Liu and Liu, 2021)according to a learned evaluation function. The Perturb-and-Select summarizer (Oved and Levy, 2021) performs random perturbations and uses similar ideas to generate candidates ranked according to a coherence model. Unlike only intrinsic importance compared with the original document in SimCLS, content and contextual eye-catchy budgets are both considered in our work."
        },
        {
            "heading": "3 Approach",
            "text": "In this section, we describe our approach in detail, as shown in Figure 3. Inspired by FACTORSUM (Fonseca et al., 2022), we treat the content importance model as sampling document views(intrinsic importance), and contextual features as additional budgets(extrinsic importance). We pre-train the headline generation model with our dataset REDBook (Table 1) to generate candidates with intrinsic content and latent features in Sec3.1. Then, a specific metricM is employed to evaluate the effectiveness of different criteria, composed of scores from both content and domain style factors in Sec3.2. To assign higher probabilities to a more suitable candidate, we use contrastive learning for better re-ranking. The metricM construction is demonstrated in Sec3.3 which is optimized with multi-task loss."
        },
        {
            "heading": "3.1 Generate Candidates",
            "text": "The headline candidates are generated from two tasks: document parts sampling and corresponding headline generation. The candidate document views are generated from different random samples of article parts. We hypothesize that the main topic of short posts (limited to 1000 Chinese characters) shall be contracted from various sampled incomplete parts. Using samples allows the sequence-tosequence model to focus on concise and appealing topics, as we further considered.\nTo generate multiple views for the same document, we implement the following steps:\n\u2022 From a document D, we first split the sentences and generate a random sample collection of sentences, called document views Sv. The number of sentences of each document view in Sv is controlled by the sampling parameter sf \u2208 [0, 1], so that sents(Sv) \u2248 sf \u00b7 sents(D). The number of samples |Sv| is controlled with hyperparameter k.\n\u2022 We generate the headline corresponding to each document view in Sv with a pre-trained sequence-to-sequence model. The model defaults to generate headlines with content and eye-catchy features. The headlines collections { h1, h2...hnd} cover nd candidates inside.\nFor each document in the RED-IN (Table 1), we repeat the sampling method and headline generation work. While dealing with different datasets\ncontaining various lengths of documents and titles, the hyperparameters may be tuned. According to the basic REDBook platform format restrictions, the length of the document and title is limited to 1000 characters and 20 characters respectively. So we choose k candidate document views, each with sf = 2/3 sentences of the document. Different choices with appropriate values k are discussed in the ablation study.\nPowerful sequence-to-sequence PLMs models such as PEGASUS(Zhang et al., 2020) and BART (Lewis et al., 2019) are trained to estimate the probability of a sequence of tokens by minimizing crossentropy with respect to the data distribution. We hypothesize that these models generate good candidates to fulfill the content importance and latent style features objectives, which are described below. Learning Maximum likelihood estimation (MLE) is the standard training algorithm. Given the training dataset X \u2032 consists of hot post document D(i) and reference headline H(i), the loss is defined as a negative log-likelihood function:\nL ( Eint,X \u2032 ) = 1\n|X \u2032| |X \u2032|\u2211 i=1 L ( H(i), Eint ( \u03b8,D(i),H ))\ufe38 \ufe37\ufe37 \ufe38 \u2212 log p\u03b8(H(i)|D(i))\n(1) where p\u03b8 ( H(i) | D(i) ) is a distribution over the possible headline H (Lewis et al., 2019). For a specific sample { D(i), H\u2217(i) } , Eq.2 is equivalent to minimizing the sum of negative loglikelihood of the tokens in the reference headline H\u2217 whose length is l, through the cross-entropy loss:\nLsent= (2)\n\u2212 l\u2211\nj=1 \u2211 h ptrue ( h | D,H\u2217<j ) log pg\u03b8 ( h | D,H\u2217<j ; \u03b8 ) where H\u2217<j denotes the partial reference head-\nline { h\u22170, \u00b7 \u00b7 \u00b7 , h\u2217j\u22121 } . ptrue is defined as a one-hot distribution under the standard MLE framework:\nptrue ( h | D,H\u2217<j ) = { 1 h = h\u2217j 0 h \u0338= h\u2217j\n(3)\nDuring learning stage, we find the parameters \u03b8\u2217 minimize the loss above. Since the model is trained with a confounded feature dataset, we notice the\nresults are generated with both content and latent features. Inference During inference stage, the abstractive model g is used to generate the candidate headline in an autoregressive manner. It is intractable to enumerate all the possible candidate outputs, so methods such as beam search decoding(Sutskever et al., 2014) are used to reduce the search space. Estimating the probability of the next word ht is the significant step during the search:\npg\u03b8 (ht | D,H<t; \u03b8) (4)\nwhich is different from Eq.3 with its own previous predictions resource H<t instead of reference headline H\u2217<t."
        },
        {
            "heading": "3.2 Coordinating Headline Selection",
            "text": "Eq.4 implies that the headline generation model g should be able to assign a higher estimated probability to the better candidate summary during inference. However, this intuition is not directly captured in the standard MLE objective used in training. No option is adopted for the ordering of imperfect references, which will lead to the existence of multiple generations(Khayrallah et al., 2020). Therefore, we propose the probability that one candidate should be well-correlated with its quality as evaluated by an automatic feature metric M. It is intractable to enumerate all the possible candidate outputs, so we only require an accurate prediction of the most probable candidate headlines ranking order via beam search (See Appendix A).\nWe use label-smoothing (Szegedy et al., 2016) and maintain the general functional form Eq.3, but specify the marginal probability of the nonreference candidates H to be \u03b2. Additionally, we encourage the coordination of probabilities and qualities among headline candidates by contrastive learning as follows:  p(H | D) = 1\u2212 \u03b2 H = H\u2217\u2211 H\u2208H p(H | D) = \u03b2 H \u0338= H\u2217 p\u2020 (Hi | D) > p\u2020 (Hj | D) \u2200Hi, Hj \u2208 H,\nM (Hi) > M (Hj) (5)\nThe candidate quality measure M in our work is defined with two scores: content score and style score which are responsible for the topic extraction and contextual media style features, separately.\nM(Hi) = \u03b1mc(Hi) + (1\u2212 \u03b1)ms(Hi) (6)\nwhere mc score measures the topic components of a candidate headline Hi extracted from the document and style score ms measures the contextual latent features. We fine-tune the model with contrastive loss (Hopkins and May, 2011)(Zhong et al., 2020) which encourages the model to assign higher probabilities to a more suitable candidate as follows:\nLctr = \u2211 i \u2211 j>i max (0, f (Hj)\u2212 f (Hi) + \u03bbij)\n(7) where Hi and Hj are two different candidate headlines andM (Hi, H\u2217) > M (Hj , H\u2217), \u2200i, j, i < j by metrics M . \u03bbij is the margin multiplied by the difference in rank between the candidates, i.e.\u03bbij = (j \u2212 i) \u2217 \u03bb.\nFollowing multi-task fine-tuning (Edunov et al., 2017), we combine the contrastive (Eq.7) and crossentropy (Eq.2) losses to preserve the generation ability of the pre-trained abstractive model:\nLmul = Lsent + \u03b3Lctr (8)\nwhere \u03b3 is the weight of the contrastive loss. We note that the contrastive and the cross-entropy loss can effectively complement each other. Since the contrastive loss is defined on the eye-catchy features, the token-level cross-entropy loss serves as a normalization to ensure content-style balanced probability assignment. This optimization loss of the result can be used in the two-stage summarization pipeline."
        },
        {
            "heading": "3.3 Disentangled Space Constraint",
            "text": "The disentanglement scores framework shown in Figure 3 consists of content (intrinsic) constraints and appealing style (extrinsic) constraints.\nContent Space Constraint As the above styleoriented loss has already imposed constraints on the style information, the content space constraints methods will be discussed in this part. Different from the style constraint design, it is hard to find parallel sentences with the same content but different styles. Previous work DAHG(Li et al., 2021) used the prototype document and its most similar document to improve the classifier. However, the similarity precision is not clearly defined. The bag-of-words (BOW) method is proposed to approximate content information(John et al., 2018) disentanglement in document style transfer tasks, but our generation objectives are concise headlines.\nInspired by the original (BOW) method, we use ROUGE(Lin, 2004)scores to measure the main content overlapping.\nStyle Space Constraint We design a multi-task loss that ensures the style information is contained in the space S. Although our dataset for style extraction is non-parallel, we assume that each sentence is labeled with its style (with domain eyecatchy features or not). We select the eye-catchy headlines from the platform and other plain corpora sentences to train the style classifier. Following the previous work (Hu et al., 2017)(Shen et al., 2017)(Fu et al., 2018)(Zhao et al., 2018) we treat each sentence with a binary style tag (positive or negative).\nTo disentangle the style information, two headlines Hp and Hn with different labels are selected as two candidates for the classifier. Then the headlines are embedded with the same matrix to obtain the representation hp and hn of Hp and Hn, respectively. A two-way softmax layer (equivalent to logistic regression) is applied to the style vector \u222b :\nys (H \u2217) = softmax (Wss [s;h \u2217] + bss) . (9)\nwhere \u03b8mul(s) = [Wss; bss] are parameters for multi-task learning of style, and ys is the output of softmax layer. The classifier is trained with a crossentropy loss against the ground truth distribution cs (\u00b7), shown as\nLmul (\u03b8E;\u03b8mul) = \u2212 \u2211\nH\u2208 labels cs(l) log ys(H)\n(10) The optimization can be viewed as multi-task learning loss at the same time. It not only autodecodes the sentence but also predicts the possible style(Luong et al., 2015)(John et al., 2018)(Balikas et al., 2017)."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Dataset",
            "text": "We collect the dataset from a social media platform REDBook with plenty of life-sharing \"hot post\" records. As long as the content/headline is compelling enough, the blog will get more exposure and attract more followers. \"Likes\" is a measure of a post\u2019s popularity, which is also proof of eye-catchy quality. So we filter 70k different posts with more than 2k \"likes\", shown in Table 1 for the headline generator training period. To extract the global contextual features, we select the content and corresponding headline of hot post, from\ndifferent bloggers with the consideration of avoiding personal-style influence. We randomly divide the REDBook dataset into train set, validation set, and test set. For the inference and selection of the best candidate task, we randomly choose 20k posts (RED-IN). Our dataset contains the hot post published during 2021, and time is not an influencing factor as the like counts have already accumulated."
        },
        {
            "heading": "4.2 Baselines",
            "text": "We select the related Seq2seq summarization methods:BART(Lewis et al., 2019) and PEGASUS(Zhang et al., 2020) as basic large pre-trained standard in the literature. The tokenizers of BART and PEGASUS are also well-established with Chinese datasets.\nImplementation Details In the following experiments, we use either BART or PEGASUS as a backbone. We label our proposed methods MediaHG with several variants: (1) MediaHG-BA is fine-tuned with eye-catchy features based on BART. (2)MediaHG(-PG) is fine-tuned with eye-catchy features based on PEGASUS. We also change the eye-catchy features influence as (3) MediaHG-c using content constraint only and MediaHG-s using style constraint only. The choice of sample times k also has a great influence on the results. So we set (4) MediaHG-m with k = 10."
        },
        {
            "heading": "4.3 Experiment Settings",
            "text": "Consistent with the platform requirements, we set the maximum target title length as 20 characters for all models. According to the average length of the documents and titles, we set the max length of the tokenizer as 512. The encoder and the decoder of all Seq2Seq models are set as the same parameters as BART(Lewis et al., 2019) and PEGASUS(Zhang et al., 2020). As we have discussed in Sec 3.1, the number of sentences in document views Sv is controlled by the sampling factor parameter sf = 23 . Another hyperparameter k to control the number of samples |Sv| is set as 5 and 10. During the inference period with content and style\nbudgets to select the best headline, the eye-catchy feature budgets are respectively set with \u03b1 = 0.5 and \u03b3 = 0.1."
        },
        {
            "heading": "4.4 Evaluation Metrics",
            "text": "ROUGE: We evaluate models using standard full-length ROUGE F1 (Lin, 2004) following previous works(Li et al., 2021)(Gao et al., 2019)(Xu et al., 2019). ROUGE-1, ROUGE-2 and ROUGE-L refer to the matches of unigrams, bigrams, and the longest common subsequence, respectively.\nBLEU: To evaluate our model more comprehensively, we also use the metric BLEU proposed by (Papineni et al., 2002) which measures word overlap between the generated text and the groundtruth.\nHuman Evaluation: As single autometric evaluation can be misleading (Schluter, 2017), we add human evaluation metrics to our work. We randomly sample 500 cases from the test set and ask three familiar and loyal REDBook users as annotators to score the headlines generated by BART, PEAGUSUS, and MediaHG. Referring to the gender and age distribution of REDBook users, reviewers consist of a man and two women about 30 years old."
        },
        {
            "heading": "4.5 Results",
            "text": "Overall Performance We compare our model with baselines in Table 2. Firstly, PEGASUS still outperforms BART, which means our task needs a bit more abstractive summarization. Secondly, our model achieves 21.46, 7.79, 19.05, and 11.26 in terms of ROUGE-1, ROUGE-2, and ROUGE-L respectively outperforming both PEAGASUS and BART and thus proves the superiority of our model. Besides, MediaHG outperforms MediaHG-BA in terms of all the metrics scores. An example of headlines generated by BART, PEAGASUS, and our model MediaHG can be found in Appendix B. We refer readers to Appendix B for more details.\nWe also add MediaHG-c and MediaHG-s to see the eye-catchy features set influence. MediaHG-c achieves better automatic scores than MediaHG-s, which means content budget impact on the main topic extraction of the headline. The disparity between MediaHG and Media-c illustrates the stylecontent duality of a good eye-catchy headline.\nThe MediaHG-m model shares the same parameters with MediaHG except the number of sample times k. The outperformance of MediaHG-m also certificates the importance of sampling. However,\nas the number of sampling increases, experiment time increases correspondingly.\nThe human evaluation is based on 3 aspects: sentence fluency, content faithfulness, and contextual eye-catchy requirements. The rating score of each model ranges from 1 to 3, with 3 being the best. Additionally, headlines with domain features like female tongue will get better scores in attractiveness. Table 3 lists the average scores of each model, demonstrating that MediaHG outperforms other baseline models."
        },
        {
            "heading": "4.6 Analysis",
            "text": "We further analyze the contribution of different module parts from diverse perspectives to gain more insights into our method.\nCoefficients of Contrastive Loss The global training loss contains two parts: the cross-entropy\nloss and the contrastive loss. In order to study the influence of the contrastive learning module, we train our model with different contrastive learning coefficients \u03b3. As the cross-entropy loss is necessary to predict sequential tokens and preserve the generation model ability, we only change the values of \u03b3 (shown in Figure 4). When \u03b3 is smaller than 0.1, the larger \u03b3, the better of performance. But when \u03b3 is bigger than 0.1, the smaller \u03b3 leads to better performance. When \u03b3 is small, the contrastive learning module has a little positive impact on the whole model, so the results are getting better. While the \u03b3 increases, contrastive impact too much on the whole model, which disturbs the training of headline generation.\nGeneration-Fintune as a Loop As our inference selection results are style-content dual, a new set of candidates can be generated in the same way as the pre-trained model dynamically and continuously. Table 4 illustrates the effectiveness of this loop operation. It also demonstrates our method\u2019s potential improvement in headline generation."
        },
        {
            "heading": "4.7 Ablation Study",
            "text": "In order to verify the effect of each module in MediaHG, we conduct ablation tests in Table 5 and Table 6. As we have discussed, the number of sentences in document views Sv is controlled by the sampling factor parameter sf \u2208 [0, 1], so we choose 12 , 2 3 , 3 4 to perform experiments respectively shown in Table 6. Different sampling size brings different best scores, but all outperform scores with"
        },
        {
            "heading": "4 20.58 7.46 18.41 10.83",
            "text": ""
        },
        {
            "heading": "5 21.46 7.79 19.05 11.26",
            "text": ""
        },
        {
            "heading": "6 21.89 7.96 19.38 11.47",
            "text": ""
        },
        {
            "heading": "7 22.56 8.25 19.85 11.75",
            "text": ""
        },
        {
            "heading": "8 23.07 8.46 20.37 12.00",
            "text": ""
        },
        {
            "heading": "9 23.23 8.44 20.40 12.10",
            "text": "sf = 1. The results indicate the necessity of sampling in extracting the main topic.\nAnother hyperparameter k to control the number of samples |Sv| is set from 4 to 10 due to the actual needs. We see a rapid increase from 4 to 5 and then a slower increase. As the k rises, more selections are given to the selector, so the scores will increase accordingly. With the dataset length features (Table 1), we set the max k as 10 to create various but nonredundant results. At the same time, for the level of higher complexity, the experimental time increases much."
        },
        {
            "heading": "5 Conclusion and Future",
            "text": "In this paper, we propose an eye-catchy headline generation model MediaHG for vertical interest social media platforms. Our research is the first one focusing on vertical interest websites. As people\u2019s interests flourish with the information gap broken down, more websites will be designed to appeal to the same interest groups. Our design allows the features extractor approach to be used more flexibly with other websites\u2019 data. Both automatic and human evaluation show our improvement in headline generation.\nLimitations\nWhen dealing with texts of different lengths, selecting parts and generating headlines may result in redundant similar candidates or insufficient information. It is necessary to select appropriate model parameters according to the characteristics of posts."
        },
        {
            "heading": "Acknowledgements",
            "text": "This work was supported by NSFC (62322606, 62176233) and the National Key Research and Development Project of China (2018AAA0101900)."
        },
        {
            "heading": "A Appendix",
            "text": "A.1 Algorithm 1 An accurate prediction of the best headline ranking procedure is required before output. To avoid big waste in enumerating all possible candidates, we offer a beam search algorithm, especially suitable for plenty of candidates\u2019 tasks.\nA.2 Case Study We display an example of headlines generated by BART, PEAGASUS, and our model MediaHG in Table 7. The headline generated by MediaHG is more informative and attractive compared with the BART model and PEGASUS model. We also show the document of the hot post to certify the content consistency of the generated headlines. The baselines can generate fluent headlines in this case, but they miss the attractive style and will include unattractive content. The headline generated by BART is a plain statement, neglecting the main attractive topic \"green eyeliner painting\". It only catches the word \"hottie\", which does not fully encapsulate the character of the article. We also consider the faithfulness of different models. The headline generated by PEGASUS is significantly better than BART, as it catches the main word \"green eyeliner painting\"(in blue). But headlines generated with inappropriate elements still exist as we highlight in red. For our model in the case, MediaHG captures the keywords \"green eyeliner\" and \"hot girl\", which not only cover the topic but also draw more attention. This case also demonstrates our sampling module effects in main topic extraction."
        }
    ],
    "title": "MediaHG: Rethinking Eye-catchy Features in Social Media Headline Generation",
    "year": 2023
}