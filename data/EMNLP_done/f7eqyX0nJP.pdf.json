{
    "abstractText": "We explore the use of large language models (LLMs) for zero-shot semantic parsing. Semantic parsing involves mapping natural language utterances to task-specific meaning representations. LLMs are generally trained on publicly available text and code and cannot be expected to directly generalize to domain-specific parsing tasks in a zero-shot setting. In this work, we propose ZEROTOP, a zero-shot task-oriented parsing method that decomposes semantic parsing problem into a set of abstractive and extractive question-answering (QA) problems. For each utterance, we prompt the LLM with questions corresponding to its top-level intent and a set of slots and use the LLM generations to construct the target meaning representation. We observe that current LLMs fail to detect unanswerable questions; and as a result, cannot handle questions corresponding to missing slots. We address this by fine-tuning a language model on public QA datasets using synthetic negative samples. Experimental results show that our QA-based decomposition paired with the fine-tuned LLM can zero-shot parse \u2248 16% of utterances in the MTOP dataset.",
    "authors": [
        {
            "affiliations": [],
            "name": "Dheeraj Mekala"
        },
        {
            "affiliations": [],
            "name": "Jason Wolfe"
        },
        {
            "affiliations": [],
            "name": "Subhro Roy"
        }
    ],
    "id": "SP:d8df54b33431914e1edb8332a0f1216a218caa36",
    "references": [
        {
            "authors": [
                "Max Bartolo",
                "Alastair Roberts",
                "Johannes Welbl",
                "Sebastian Riedel",
                "Pontus Stenetorp."
            ],
            "title": "Beat the ai: Investigating adversarial human annotation for reading comprehension",
            "venue": "Transactions of the Association for Computational Linguistics, 8:662\u2013678.",
            "year": 2020
        },
        {
            "authors": [
                "Mark Chen",
                "Jerry Tworek",
                "Heewoo Jun",
                "Qiming Yuan",
                "Henrique Ponde de Oliveira Pinto",
                "Jared Kaplan",
                "Harri Edwards",
                "Yuri Burda",
                "Nicholas Joseph",
                "Greg Brockman"
            ],
            "title": "Evaluating large language models trained on code",
            "year": 2021
        },
        {
            "authors": [
                "Pradeep Dasigi",
                "Nelson F. Liu",
                "Ana Marasovi\u0107",
                "Noah A. Smith",
                "Matt Gardner."
            ],
            "title": "Quoref: A reading comprehension dataset with questions requiring coreferential reasoning",
            "venue": "EMNLP.",
            "year": 2019
        },
        {
            "authors": [
                "Andrew Drozdov",
                "Nathanael Sch\u00e4rli",
                "Ekin Aky\u00fcrek",
                "Nathan Scales",
                "Xinying Song",
                "Xinyun Chen",
                "Olivier Bousquet",
                "Denny Zhou."
            ],
            "title": "Compositional semantic parsing with large language models",
            "venue": "arXiv preprint arXiv:2209.15003.",
            "year": 2022
        },
        {
            "authors": [
                "Shuyang Gao",
                "Sanchit Agarwal",
                "Tagyoung Chung",
                "Di Jin",
                "Dilek Hakkani-Tur."
            ],
            "title": "From machine reading comprehension to dialogue state tracking: bridging the gap",
            "venue": "ACL 2020 Workshop on NLP for Conversational AI.",
            "year": 2020
        },
        {
            "authors": [
                "Luheng He",
                "Mike Lewis",
                "Luke Zettlemoyer"
            ],
            "title": "Question-answer driven semantic role labeling: Using natural language to annotate natural language",
            "year": 2015
        },
        {
            "authors": [
                "Haoran Li",
                "Abhinav Arora",
                "Shuohui Chen",
                "Anchit Gupta",
                "Sonal Gupta",
                "Yashar Mehdad."
            ],
            "title": "MTOP: A comprehensive multilingual task-oriented semantic parsing benchmark",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Asso-",
            "year": 2021
        },
        {
            "authors": [
                "Kevin Lin",
                "Oyvind Tafjord",
                "Peter Clark",
                "Matt Gardner."
            ],
            "title": "Reasoning over paragraph effects in situations",
            "venue": "ArXiv, abs/1908.05852.",
            "year": 2019
        },
        {
            "authors": [
                "Zhaojiang Lin",
                "Bing Liu",
                "Andrea Madotto",
                "Seungwhan Moon",
                "Zhenpeng Zhou",
                "Paul A Crook",
                "Zhiguang Wang",
                "Zhou Yu",
                "Eunjoon Cho",
                "Rajen Subba"
            ],
            "title": "Zero-shot dialogue state tracking via crosstask transfer",
            "venue": "In Proceedings of the 2021 Conference",
            "year": 2021
        },
        {
            "authors": [
                "Zhaojiang Lin",
                "Bing Liu",
                "Seungwhan Moon",
                "Paul A Crook",
                "Zhenpeng Zhou",
                "Zhiguang Wang",
                "Zhou Yu",
                "Andrea Madotto",
                "Eunjoon Cho",
                "Rajen Subba."
            ],
            "title": "Leveraging slot descriptions for zero-shot cross-domain dialogue statetracking",
            "venue": "Proceedings",
            "year": 2021
        },
        {
            "authors": [
                "Dheeraj Mekala",
                "Chengyu Dong",
                "Jingbo Shang."
            ],
            "title": "LOPS: Learning order inspired pseudo-label selection for weakly supervised text classification",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022, pages 4894\u20134908, Abu",
            "year": 2022
        },
        {
            "authors": [
                "Dheeraj Mekala",
                "Varun Gangal",
                "Jingbo Shang."
            ],
            "title": "Coarse2Fine: Fine-grained text classification on coarsely-grained annotated data",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 583\u2013594, Online",
            "year": 2021
        },
        {
            "authors": [
                "Dheeraj Mekala",
                "Jingbo Shang."
            ],
            "title": "Contextualized weak supervision for text classification",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 323\u2013 333.",
            "year": 2020
        },
        {
            "authors": [
                "Dheeraj Mekala",
                "Tu Vu",
                "Timo Schick",
                "Jingbo Shang."
            ],
            "title": "Leveraging qa datasets to improve generative data augmentation",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing.",
            "year": 2022
        },
        {
            "authors": [
                "Dheeraj Mekala",
                "Xinyang Zhang",
                "Jingbo Shang."
            ],
            "title": "Meta: Metadata-empowered weak supervision for text classification",
            "venue": "Proceedings of the",
            "year": 2020
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J Liu"
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "J. Mach. Learn. Res.,",
            "year": 2020
        },
        {
            "authors": [
                "Pranav Rajpurkar",
                "Robin Jia",
                "Percy Liang."
            ],
            "title": "Know what you don\u2019t know: Unanswerable questions for SQuAD",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 784\u2013789,",
            "year": 2018
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych."
            ],
            "title": "Sentence-bert: Sentence embeddings using siamese bert-networks",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.",
            "year": 2019
        },
        {
            "authors": [
                "Joshua Robinson",
                "David Wingate."
            ],
            "title": "Leveraging large language models for multiple choice question answering",
            "venue": "The Eleventh International Conference on Learning Representations.",
            "year": 2023
        },
        {
            "authors": [
                "Amrita Saha",
                "Rahul Aralikatte",
                "Mitesh M. Khapra",
                "Karthik Sankaranarayanan."
            ],
            "title": "DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension",
            "venue": "Meeting of the Association for Computational Linguistics (ACL).",
            "year": 2018
        },
        {
            "authors": [
                "Victor Sanh",
                "Albert Webson",
                "Colin Raffel",
                "Stephen H Bach",
                "Lintang Sutawika",
                "Zaid Alyafeai",
                "Antoine Chaffin",
                "Arnaud Stiegler",
                "Teven Le Scao",
                "Arun Raja"
            ],
            "title": "Multitask prompted training enables zero-shot task generalization",
            "year": 2021
        },
        {
            "authors": [
                "Nathan Schucher",
                "Siva Reddy",
                "Harm de Vries."
            ],
            "title": "The power of prompt tuning for low-resource semantic parsing",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 148\u2013156, Dublin,",
            "year": 2022
        },
        {
            "authors": [
                "Richard Shin",
                "Christopher Lin",
                "Sam Thomson",
                "Charles Chen",
                "Subhro Roy",
                "Emmanouil Antonios Platanios",
                "Adam Pauls",
                "Dan Klein",
                "Jason Eisner",
                "Benjamin Van Durme."
            ],
            "title": "Constrained language models yield few-shot semantic parsers",
            "venue": "Proceedings of",
            "year": 2021
        },
        {
            "authors": [
                "Kai Sun",
                "Dian Yu",
                "Jianshu Chen",
                "Dong Yu",
                "Yejin Choi",
                "Claire Cardie."
            ],
            "title": "Dream: A challenge data set and models for dialogue-based reading comprehension",
            "venue": "Transactions of the Association for Computational Linguistics, 7:217\u2013231.",
            "year": 2019
        },
        {
            "authors": [
                "Oyvind Tafjord",
                "Matt Gardner",
                "Kevin Lin",
                "Peter Clark."
            ],
            "title": "Quartz: An open-domain dataset of qualitative relationship questions",
            "venue": "arXiv preprint arXiv:1909.03553.",
            "year": 2019
        },
        {
            "authors": [
                "Alex Wang",
                "Yada Pruksachatkun",
                "Nikita Nangia",
                "Amanpreet Singh",
                "Julian Michael",
                "Felix Hill",
                "Omer Levy",
                "Samuel Bowman."
            ],
            "title": "Superglue: A stickier benchmark for general-purpose language understanding systems",
            "venue": "Advances in neural information",
            "year": 2019
        },
        {
            "authors": [
                "Wenhan Xiong",
                "Jiawei Wu",
                "Hong Wang",
                "Vivek Kulkarni",
                "Mo Yu",
                "Shiyu Chang",
                "Xiaoxiao Guo",
                "William Yang Wang."
            ],
            "title": "TWEETQA: A social media focused question answering dataset",
            "venue": "Proceedings of the 57th Annual Meeting of the Asso-",
            "year": 2019
        },
        {
            "authors": [
                "Jingfeng Yang",
                "Haoming Jiang",
                "Qingyu Yin",
                "Danqing Zhang",
                "Bing Yin",
                "Diyi Yang."
            ],
            "title": "SEQZERO: Few-shot compositional semantic parsing with sequential prompts and zero-shot models",
            "venue": "Findings of the Association for Computational Linguistics:",
            "year": 2022
        },
        {
            "authors": [
                "Wenting Zhao",
                "Konstantine Arkoudas",
                "Weiqi Sun",
                "Claire Cardie."
            ],
            "title": "Compositional task-oriented parsing as abstractive question answering",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational",
            "year": 2022
        },
        {
            "authors": [
                "Zihao Zhao",
                "Eric Wallace",
                "Shi Feng",
                "Dan Klein",
                "Sameer Singh."
            ],
            "title": "Calibrate before use: Improving few-shot performance of language models",
            "venue": "International Conference on Machine Learning, pages 12697\u201312706. PMLR.",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Large language models (LLMs) are trained on publicly available text (Raffel et al., 2020; Sanh et al., 2021; Brown et al., 2020) and code (Chen et al., 2021) and have been shown to attain reasonable zero-shot generalization on a diverse set of NLP tasks (Wang et al., 2019). However, they are not expected to generalize to domain-specific semantic parsing tasks in a similar way, where the inductive bias from pre-training is less helpful. In this work, we propose ZEROTOP that decomposes the semantic parsing task into one of answering a series of extractive and abstractive questions, corresponding\n* Work done during an internship at Microsoft Semantic Machines.\n\u2660 Work done while at Microsoft Semantic Machines.\nto its top-level intent and a set of relevant slots, and leverage the LLM\u2019s ability to zero-shot answer reading comprehension questions.\nAs illustrated in Figure 1, we cast top-level intent classification as an abstractive QA task. To address LLMs\u2019 bias towards predicting labels common in the pretraining data (Zhao et al., 2021), we propose to generate an intent description in an unconstrained manner and infer the intent label most similar to the generated description. We view slot value prediction as an extractive QA problem. Most utterances do not mention all the slots. It is therefore essential for the model to abstain from prediction when corresponding slots are not mentioned. Through our analyses, we observe that most LLMs frequently hallucinate text for missing slots with high confidence, resulting in poor performance. To address this, we fine-tune an LM on a collection of public QA datasets augmented with synthetic unanswerable samples. We call our trained model Abstainer, as it is capable of identifying unanswerable questions and abstaining from prediction. We hierarchically prompt for nested slots using the Abstainer, and infer nested intents if their corresponding slots are detected. We empirically show that this QA based decomposition of ZEROTOP is an effective way to leverage LLMs for domain specific semantic parsing, outperforming several strong baselines in the zero shot setting."
        },
        {
            "heading": "2 Related Work",
            "text": "LLMs are increasingly used for semantic parsing in low-data scenarios utilizing canonical representations (Shin et al., 2021; Yang et al., 2022), and prompt-tuning (Schucher et al., 2022; Drozdov et al., 2022). The closest work to ours is Zhao et al. (2022) where they decompose parsing into QA tasks. However, they assume access to some annotated data whereas we focus on a strict zero-shot setting where only the schema information is available along with some natural language prompts for"
        },
        {
            "heading": "What is the relation?",
            "text": "schema entities. Our work is also related to approaches towards zero-shot dialog state tracking using LLMs (Gao et al., 2020; Lin et al., 2021a,b). Specifically, Lin et al. (2021a) uses an Abstainer to handle missing slots. Our method differs in that, we focus on semantic parsing where the Abstainer needs to be applied multiple times along with intent detection to create nested meaning representations."
        },
        {
            "heading": "3 ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing",
            "text": "Problem Formulation We focus on taskoriented parsing with hierarchical intent-slot schema. Let I = {I1, I2, . . . , In} and S = {S1,S2, . . . ,Sm} be the set of all possible toplevel intents and slots respectively. Each intent Ij has a set of slots Sj = {Sj1 ,S j 2 , . . . ,S j n} that can be filled. Possible slots in an intent are represented by the intent-to-slot mapping I2S: I \u2192 P(S), where P(\u00b7) is the powerset operator. Similarly, the inverse slot-to-intent mapping is represented by S2I: S \u2192 I. The input in our setting consists of I2S and S2I, but no annotated data. ZEROTOP requires users to provide a question per slot Q = {QS1 ,QS2 , . . . ,QSk}, that represents their purpose. In a real-life setting, this can be obtained from a domain developer.\nUnconstrained Generation for Zero-Shot Intent Classification We view zero-shot intent classification as an abstractive QA problem. One intuitive way is to prime the LLM with a QA prompt and then constrain the generation to search over only valid intent labels (Shin et al., 2021). However, LLMs are known to be biased towards text sequences (Zhao et al., 2021) more common in pretraining data. For example, in the MTOP dataset, the T0-3B model predicts CREATE_CALL (make\nAlgorithm 1: ZEROTOP: Our proposed Zero-shot semantic parsing method.\nInput: Set of intents I, Set of slots S, Slot questions Q, intent-to-slot mapping I2S, slot-to-intent mapping S2I, slot-to-candidate-nested-intent mapping S2NI, Intent-model MI , Abstainer Mabs, and Utterance u Output: Predicted meaning representations MR intent = MI(u) slotValues = {} for slot Si \u2208 I2S(intent) do\nslotValues[Si] = Mabs(u,QSi) for candidate N.intent Ij \u2208 S2NI(Si) do\nfor slot Sj \u2208 I2S(Ij) do if Mabs(slotValues[Si],QSj ) is not\nNONE then Update slotValues[Si] with\nnested intent Ij , Mabs(slotValues[Si],QSj )\nMR = Construct representation with intent, slotValues Return MR\ncall) as intent for 92% of the data in the call domain. Therefore, we propose to first generate an intent description in an unconstrained fashion by priming the LM with the following prompt. Answer the following question depending on the context. context: A user said, {utterance}. question: What did the user intend to do? answer:\nThen, we choose the intent label that is most similar to generated answer using RoBERTa sentence similarity (Reimers and Gurevych, 2019). Unlike Zhao et al. (2022), our approach does not require enumerating choices in the prompt allowing us to handle a large number of intents and slots as found in datasets like MTOP.\nLeveraging QA datasets for Slot Value Prediction Slot value prediction involves extracting phrases for a slot from the user utterance. We cast this as an extractive QA problem. All slots might\nnot be mentioned in an input utterance. For example, in the MTOP dataset, on average, only onethird of possible slots are mentioned per utterance. The QA model needs to abstain from prediction for such missing slots. To analyze the abstaining capability of pre-trained QA models, we consider a few top-performing zero-shot LLMs T0-3B, GPT3, and Codex with their corresponding prompts and experiment on a 500 sample subset of unanswerable questions from the SQuAD dataset (Rajpurkar et al., 2018). We observe the accuracy of all models to be < 5% and notice that they frequently hallucinate and generate answers for unanswerable questions. In section 4, we also consider a loglikelihood-based threshold for abstaining and show that this threshold is difficult to tune using public QA datasets.\nTo address this challenge, we leverage multiple publicly available QA datasets1 to train Abstainer, a QA model capable of abstaining from prediction. Specifically, we generate synthetic unanswerable training samples by modifying existing QA data, and train a QA model jointly on existing datasets and synthetic unanswerable questions. For every (question, answer, context) triplet, we generate synthetic unanswerable questions by either (1) removing the sentence containing the answer span from the context, or (2) randomly sampling a context that doesn\u2019t have the same question. After training the Abstainer, we prompt it for each slot with its corresponding question for slot value prediction, in the following format:\nAnswer the following question depending on the context. context: A user said, {utterance}. question: {slot question} answer:\nNested Intents To identify nested intents, we assume knowledge of candidate nested intents that can be accommodated by each slot, represented by the slot-to-candidate-nested-intent mapping S2NI: S \u2192 P(I). Our method assumes that depth of output representations is at most 4 i.e. nested intents cannot further have more nested intents. One intuitive way is to prompt the LLM for nested intent with the intent prediction prompt. However, our unconstrained generation-based intent model would predict many false positive nested intents. We instead use Abstainer to prompt for their respective slots. If any slot value is identified, we consider its corresponding intent via S2I to be present as well.\n1The QA datasets details are mentioned in Appendix A.1\nZEROTOP: Putting it all together The pseudocode of ZEROTOP is mentioned in Algorithm-1. ZEROTOP employs a top-down, greedy prompting strategy, where we first prompt for intent and then, its respective slots. First, we obtain the top-level intent using the intent model. Based on the predicted intent, we prime the Abstainer for corresponding slots using their respective questions as prompts. For each identified slot value, we prompt the Abstainer for slots of candidate nested intents. We use the same prompt format for this step with the identified slot value now considered as the input utterance. Finally, we combine predicted intent, identified slot values, and nested intents to create the meaning representation."
        },
        {
            "heading": "4 Experiments",
            "text": "We experiment on the English language subset of MTOP (Li et al., 2021) dataset. MTOP is a multilingual task-oriented semantic parsing dataset comprising data from 6 languages and 11 domains. The test set has 4386 samples with 113 distinct intents and 74 slots. On average, each intent has 3.6 slots and 33% of possible slots are filled per utterance. Experiment Settings. We evaluate on the zeroshot setting, therefore we have no training data. We manually create questions for slots Q using one example per slot. For training Abstainer, we finetune T0-3B on the extractive and abstractive QA datasets for 1 epoch with a constant learning rate of 10\u22124. We use complete meaning representation match accuracy as the performance metric. More details in Appendix A.2. Baselines. We compare ZEROTOP with constrained T0-3B, GPT-3 and Codex as intent models where they are primed with intent generation prompt and are constrained to search over valid intent labels. We also compare with calibrated constrained T0-3B (Zhao et al., 2021) whose logits are adjusted to counter LM biases. We consider an ablation of ZEROTOP where we assign intent labels based only on their similarity with user utterance using RoBERTa sentence transformer. ZEROTOP-Intent represents our proposed intent prediction method.\nWe compare with constrained T0-3B, GPT-3, and Codex as slot models as well, however, when primed with a question corresponding to a slot, the output is constrained to be either from the utterance or from their corresponding phrases indicating that question cannot be answered. We com-"
        },
        {
            "heading": "Intent Model Slot Model Acc(%)",
            "text": "pare with two kinds of prompting for slot values. MTQA (Zhao et al., 2022) propose prompting an LLM to identify filled slots and then prime for their respective values. SEQZERO (Yang et al., 2022) introduce prompting each slot sequentially and using the previously identified slot value for prompting the next one. Abstainer is our finetuned T0-3B that abstains from prediction. We prompt for each slot independently.\nResults and Discussion From zero-shot intent classification results in Table 1, we observe that ZEROTOP-Intent performs significantly better than constrained T0-3B, GPT-3, and Codex. We found that constrained T0-3B is biased towards certain labels. For example, it predicts CREATE_CALL (make call), SEND_MESSAGE (send message), CREATE_REMINDER (create reminder), as intent for more than 90% of the data in call, message, reminder domains respectively. Our proposed unconstrained formulation lets the model freely express the intent and, computing similarity later with the intent labels addresses this bias.\nAs shown in Table 2, the combination of ZEROTOP-Intent and Abstainer demonstrates su-\nperior performance than alternative combinations. We observe that T0-3B, GPT-3, and Codex fail to abstain frequently. The T0-3B model abstains only for 38% of unanswerable slot questions whereas Abstainer does for 89%. As a result, we observe a notable performance gain by plugging in Abstainer as the slot model for each intent model baseline. Moreover, we observe MTQA and SEQZERO prompting methods, which are originally proposed for custom-finetuned & few-shot models, offer little assistance in zero-shot settings. For instance, when applying MTQA prompting to the T0-3B model, we observe marginal improvements. This indicates that the pre-trained T0-3B is unable to accurately identify fillable slots, demonstrating the necessity of Abstainer. Similarly, while SEQZERO prompting improves the performance of T0-3B, its effectiveness remains significantly inferior to Abstainer. Finally, we see similar performance of MTQA and SEQZERO prompting with Abstainer. However, our approach of independently prompting for each slot outperforms them.\nAnnotation Effort Analysis We use 74 samples i.e. one per slot to design questions for slots. To analyze annotation effort, we train an utterance-tomeaning representation T5-3B (Raffel et al., 2020) parser using these 74 samples and compare it with our method. The match accuracy of T5-3B parser on the MTOP dataset is 8.19% and of ZEROTOP is 15.89%, justifying our annotation effort.\nGreedy vs Beam search ZEROTOP follows a greedy strategy where we hierarchically prompt for top-level intent and for its corresponding slots. We compare it with the beam search strategy with beam size 3. Specifically, we consider 3 top-level intents and prompt for their corresponding slots, consider top-3 slot values for every slot and finally compute the best meaning representation based on their aggregated NLL scores. The NLL score of intent Im, its slots Sj \u2208 I2S(Im), and their corresponding slot values slotValues[Sj ] is computed:\n\u03b1 log p(Im) + (1\u2212 \u03b1) \u2211 Sj log p(slotValues[Sj ]|Im)\nwhere \u03b1 is tuned on a held-out validation set. Note that p(slotValues|Im) is computed recursively for its nested intents. The complete match accuracy of the greedy prompting strategy on MTOP dataset is 15.89% and of beam search strategy is 16.86%. This demonstrates that beam search can improve performance with validation data. Without validation data and setting \u03b1 to 0.5, performance drops\nto 12.36% i.e. 3% less than greedy. Therefore, we believe greedy prompting is a better choice.\nConfidence score-based Abstainer study We can alternatively have LLMs abstain from prediction based on a confidence score based threshold. We consider negative log likelihood (NLL) of the predicted slot value as the confidence score and abstain from prediction if it is greater than the threshold. We experiment on slot value prediction task with T0-3B, Codex, and GPT3 as LLMs and plot macro F1 scores for multiple NLL thresholds on a randomly sampled subset of 500 samples from MTOP dataset in Figure 2(a). Specifically, we consider the gold intent of each sample and prime LLM for extracting slot values for each slot of the gold intent. We consider F1 score as the metric due to the label imbalance across possible slot values. We present the F1-score of the Abstainer for reference. First, we observe that Abstainer is significantly better than T0-3B and GPT3 for all confidence thresholds. Second, we notice that there\nis no threshold that consistently results in good performance for all LLMs, which implies that this has to be individually tuned for each LLM. Finally, we observe Codex performs better than Abstainer for some thresholds. As our problem setting includes no annotated data, we investigate whether we can infer the optimal threshold for Codex using public QA datasets. Specifically, we consider 500 answerable and 500 unanswerable QA pairs from SQuAD dataset and plot F1 scores with a range of confidence thresholds in Figure 2(b). We can observe that the performance on answerable and unanswerable subsets is mutually exclusive i.e. there is no threshold where the performance on both answerable and unanswerable subsets is high. The range of thresholds that result in the best performance on the whole set (highlighted in green) does not transfer to MTOP and is achieved at the cost of unanswerable set where the F1 score is less than 5%. Given the difficulty in tuning threshold and the API costs of Codex, we believe using Abstainer as the slot model to be a better choice."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this paper, we propose ZEROTOP that decomposes semantic parsing into abstractive and extractive QA tasks. ZEROTOP identifies top-level intent by generating in an unconstrained fashion and inferring the intent label most similar to the generated description. We train Abstainer using public QA datasets, that is capable of identifying unanswerable questions and abstaining from prediction."
        },
        {
            "heading": "6 Limitations",
            "text": "ZEROTOP assumes that the meaning representations are of a limited depth i.e. nested intents cannot further have more nested intents and this is one of the limitations. Moreover, we also assume that it is possible to write natural questions corresponding to slots. A slot for which a natural question cannot be expressed, the LLM can\u2019t handle it without additional supervision. Finally, we believe there is a huge scope for improvement in the performance of LLMs and ZEROTOP in domain-specific tasks such as zero-shot semantic parsing and on the MTOP dataset."
        },
        {
            "heading": "7 Ethics Statement",
            "text": "This paper proposes a zero-shot semantic parsing method using large language models. The aim of the paper is to minimize the human effort in\nannotation by leveraging language models. The output of our method is a meaning representation that doesn\u2019t contain any harmful content. Hence, we do not anticipate any major ethical concerns."
        },
        {
            "heading": "8 Acknowledgments",
            "text": "We thank the anonymous reviewers and our colleagues from Microsoft Semantic Machines, especially Hao Fang, Richard Shin, Adam Pauls, Matt Gardner, and Jason Eisner for their helpful feedback."
        },
        {
            "heading": "2020 Conference on Empirical Methods in Natural",
            "text": "Language Processing (EMNLP).\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21(140):1\u201367.\nPranav Rajpurkar, Robin Jia, and Percy Liang. 2018. Know what you don\u2019t know: Unanswerable questions for SQuAD. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 784\u2013789, Melbourne, Australia. Association for Computational Linguistics.\nNils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.\nJoshua Robinson and David Wingate. 2023. Leveraging large language models for multiple choice question answering. In The Eleventh International Conference on Learning Representations.\nAmrita Saha, Rahul Aralikatte, Mitesh M. Khapra, and Karthik Sankaranarayanan. 2018. DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension. In Meeting of the Association for Computational Linguistics (ACL).\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2021. Multitask prompted training enables zero-shot task generalization. arXiv preprint arXiv:2110.08207.\nNathan Schucher, Siva Reddy, and Harm de Vries. 2022. The power of prompt tuning for low-resource semantic parsing. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 148\u2013156, Dublin, Ireland. Association for Computational Linguistics.\nRichard Shin, Christopher Lin, Sam Thomson, Charles Chen, Subhro Roy, Emmanouil Antonios Platanios, Adam Pauls, Dan Klein, Jason Eisner, and Benjamin Van Durme. 2021. Constrained language models yield few-shot semantic parsers. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7699\u20137715, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.\nKai Sun, Dian Yu, Jianshu Chen, Dong Yu, Yejin Choi, and Claire Cardie. 2019. Dream: A challenge data set and models for dialogue-based reading comprehension. Transactions of the Association for Computational Linguistics, 7:217\u2013231.\nOyvind Tafjord, Matt Gardner, Kevin Lin, and Peter Clark. 2019. Quartz: An open-domain dataset of qualitative relationship questions. arXiv preprint arXiv:1909.03553.\nAlex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. 2019. Superglue: A stickier benchmark for general-purpose language understanding systems. Advances in neural information processing systems, 32.\nWenhan Xiong, Jiawei Wu, Hong Wang, Vivek Kulkarni, Mo Yu, Shiyu Chang, Xiaoxiao Guo, and William Yang Wang. 2019. TWEETQA: A social media focused question answering dataset. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5020\u2013 5031, Florence, Italy. Association for Computational Linguistics.\nJingfeng Yang, Haoming Jiang, Qingyu Yin, Danqing Zhang, Bing Yin, and Diyi Yang. 2022. SEQZERO: Few-shot compositional semantic parsing with sequential prompts and zero-shot models. In Findings of the Association for Computational Linguistics: NAACL 2022, pages 49\u201360, Seattle, United States. Association for Computational Linguistics.\nWenting Zhao, Konstantine Arkoudas, Weiqi Sun, and Claire Cardie. 2022. Compositional task-oriented parsing as abstractive question answering. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 4418\u20134427, Seattle, United States. Association for Computational Linguistics.\nZihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improving few-shot performance of language models. In International Conference on Machine Learning, pages 12697\u201312706. PMLR."
        },
        {
            "heading": "Type Dataset # Samples",
            "text": ""
        },
        {
            "heading": "A Appendix",
            "text": ""
        },
        {
            "heading": "A.1 QA Datasets for Training Abstainer",
            "text": "Publicly available QA datasets have been previously leveraged for generating synthetic data (Mekala et al., 2022b) in weakly (Mekala and Shang, 2020; Mekala et al., 2020) and minimally supervised settings (Mekala et al., 2021, 2022a). In this paper, we use multiple extractive and abstractive QA datasets to generate synthetic unanswerable samples and train Abstainer. The details about datasets are mentioned in Table 3."
        },
        {
            "heading": "A.2 Experimental Settings",
            "text": "We use the OpenAI API text-davinci-001 for GPT-3 and code-davinci-002 for Codex. The Abstainer is fine-tuned on 411732 answerable and 435898 unanswerable samples. The batch size is 32 and each batch contains an equal number of answerable and unanswerable samples. We used 8 \u00d7 NVIDIA Tesla V100 for our experiments."
        },
        {
            "heading": "A.3 Frequently Asked Questions",
            "text": "What is the scope of the presented ideas? We believe our idea can be easily extended to any semantic parsing tasks involving natural language interfaces; we considered Task-oriented parsing as a first step because of its simpler representation. Through this work, we wanted to highlight an important real-life task that LLMs such as GPT3, Codex, and T0 underperform. Therefore, we believe this is useful and hope our work motivates more researchers to focus on this shortcoming.\nWhy didn\u2019t you extract all syntactic phrases of a certain type in the tree for slot-value detection? Syntactic phrase-based extraction of slot values requires users to manually enter rules (a.k.a. labeling functions) for each slot. When the number of slots\nincreases (e.g. 74 in MTOP), it demands significant manual effort from users, which our paper aims to reduce. Moreover, such rules would generally predict many false positives/negatives, and classifying or identifying the appropriate ones accurately requires training data, which is not available in our zero-shot setting. Therefore, we compare against strong LLMs that are known for their impressive zero-shot performance such as GPT3, Codex, T0.\nThe baseline LLMs such as GPT3 and Codex are not trained for semantic parsing. Wouldn\u2019t this make the performance improvement using ZEROTOP less significant? We compare against the T0 model which is fine-tuned on several QA datasets like our Abstainer model. We cannot fine-tune the GPT3 and Codex models on these datasets separately. However, these instructiontuned GPT3 and Codex are known to perform well on several question-answering & reading comprehension benchmarks (Robinson and Wingate, 2023). Therefore, we consider them as competitive baselines. In this paper, we show that these perform worse on zero-shot task-oriented parsing even when it is converted into a QA task, for which they are known to perform well. The reason behind their poor performance is because (1.) they are biased toward predicting labels common in the pre-training data, and (2.) they frequently hallucinate text for unanswerable questions. Through our work, we present this shortcoming, analyze the cause, and propose a method to fix it.\nWhy did you choose one prompt per slot and not multiple? We can possibly consider multiple prompts per slot and ensemble the predictions, which would intuitively boost the performance. However, multiple prompts per slot imply more annotations. Our motivation behind this work is to minimize the human annotations, thus we chose a single prompt per slot."
        }
    ],
    "title": "ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language Models",
    "year": 2023
}