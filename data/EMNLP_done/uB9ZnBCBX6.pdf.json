{
    "abstractText": "As language technologies gain prominence in real-world settings, it is important to understand how changes to language affect reader perceptions. This can be formalized as the causal effect of varying a linguistic attribute (e.g., sentiment) on a reader\u2019s response to the text. In this paper, we introduce TEXTTRANSPORT, a method for estimation of causal effects from natural language under any text distribution. Current approaches for valid causal effect estimation require strong assumptions about the data, meaning the data from which one can estimate valid causal effects often is not representative of the actual target domain of interest. To address this issue, we leverage the notion of distribution shift to describe an estimator that transports causal effects between domains, bypassing the need for strong assumptions in the target domain. We derive statistical guarantees on the uncertainty of this estimator, and we report empirical results and analyses that support the validity of TEXT-TRANSPORT across data settings. Finally, we use TEXTTRANSPORT to study a realistic setting\u2014hate speech on social media\u2014in which causal effects do shift significantly between text domains, demonstrating the necessity of transport when conducting causal inference on natural language.",
    "authors": [
        {
            "affiliations": [],
            "name": "Victoria Lin"
        },
        {
            "affiliations": [],
            "name": "Louis-Philippe Morency"
        },
        {
            "affiliations": [],
            "name": "Eli Ben-Michael"
        }
    ],
    "id": "SP:7b45c2a6b53cca6d7d895f244732965a4c65a5c6",
    "references": [
        {
            "authors": [
                "Kamyar Azizzadenesheli",
                "Anqi Liu",
                "Fanny Yang",
                "Animashree Anandkumar."
            ],
            "title": "Regularized learning for domain adaptation under label shifts",
            "venue": "International Conference on Learning Representations.",
            "year": 2019
        },
        {
            "authors": [
                "Elias Bareinboim",
                "Judea Pearl."
            ],
            "title": "Transportability of causal effects: Completeness results",
            "venue": "Proceed-",
            "year": 2021
        },
        {
            "authors": [
                "Alejandro Barredo Arrieta",
                "Natalia D\u00edaz-Rodr\u00edguez",
                "Javier Del Ser",
                "Adrien Bennetot",
                "Siham Tabik",
                "Alberto Barbado",
                "Salvador Garcia",
                "Sergio Gil-Lopez",
                "Daniel Molina",
                "Richard Benjamins",
                "Raja Chatila",
                "Francisco Herrera"
            ],
            "title": "Explainable artificial intel",
            "year": 2020
        },
        {
            "authors": [
                "Sven Buechel",
                "Udo Hahn."
            ],
            "title": "EmoBank: Studying the impact of annotation perspective and representation format on dimensional emotion analysis",
            "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational",
            "year": 2017
        },
        {
            "authors": [
                "Jonathon Byrd",
                "Zachary Lipton."
            ],
            "title": "What is the effect of importance weighting in deep learning? In Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 872\u2013881",
            "venue": "PMLR.",
            "year": 2019
        },
        {
            "authors": [
                "Cindy Chung",
                "James W Pennebaker."
            ],
            "title": "The psychological functions of function words",
            "venue": "Social communication, 1:343\u2013359.",
            "year": 2007
        },
        {
            "authors": [
                "Brandon de la Cuesta",
                "Naoki Egami",
                "Kosuke Imai."
            ],
            "title": "Improving the external validity of conjoint analysis: The essential role of profile distribution",
            "venue": "Political Analysis, 30(1):19\u201345.",
            "year": 2022
        },
        {
            "authors": [
                "Naoki Egami",
                "Christian J. Fong",
                "Justin Grimmer",
                "Margaret E. Roberts",
                "Brandon M. Stewart"
            ],
            "title": "How to make causal inferences using texts",
            "year": 2018
        },
        {
            "authors": [
                "Naoki Egami",
                "Erin Hartman."
            ],
            "title": "Elements of external validity: Framework, design, and analysis",
            "venue": "American Political Science Review, page 1\u201319.",
            "year": 2022
        },
        {
            "authors": [
                "Christian Fong",
                "Justin Grimmer."
            ],
            "title": "Causal inference with latent treatments",
            "venue": "American Journal of Political Science.",
            "year": 2021
        },
        {
            "authors": [
                "Robert Gorwa",
                "Reuben Binns",
                "Christian Katzenbach."
            ],
            "title": "Algorithmic content moderation: Technical and political challenges in the automation of platform governance",
            "venue": "Big Data & Society, 7(1):2053951719897945.",
            "year": 2020
        },
        {
            "authors": [
                "Carla J Groom",
                "James W Pennebaker."
            ],
            "title": "Words",
            "venue": "Journal of Research in Personality, 36(6):615\u2013621.",
            "year": 2002
        },
        {
            "authors": [
                "Ella Guest",
                "Bertie Vidgen",
                "Alexandros Mittos",
                "Nishanth Sastry",
                "Gareth Tyson",
                "Helen Margetts."
            ],
            "title": "An expert annotated dataset for the detection of online misogyny",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Compu-",
            "year": 2021
        },
        {
            "authors": [
                "Jaroslav H\u00e1jek."
            ],
            "title": "Comment on \"An essay on the logical foundations of survey sampling, part one",
            "venue": "V.P. Godambe and D.A. Sprott, editors, Foundations of Statistical Inference. Holt, Rinehart and Winston, Toronto.",
            "year": 1971
        },
        {
            "authors": [
                "Paul W Holland."
            ],
            "title": "Statistics and causal inference",
            "venue": "Journal of the American Statistical Association, 81(396):945\u2013960.",
            "year": 1986
        },
        {
            "authors": [
                "Thorsten Joachims",
                "Adith Swaminathan",
                "Tobias Schnabel."
            ],
            "title": "Unbiased learning-to-rank with biased feedback",
            "venue": "Proceedings of the Tenth ACM International Conference on Web Search and Data Mining, WSDM \u201917, page 781\u2013789, New York, NY,",
            "year": 2017
        },
        {
            "authors": [
                "Yue Kang",
                "Zhao Cai",
                "Chee-Wee Tan",
                "Qian Huang",
                "Hefu Liu."
            ],
            "title": "Natural language processing (nlp) in management research: A literature review",
            "venue": "Journal of Management Analytics, 7(2):139\u2013172.",
            "year": 2020
        },
        {
            "authors": [
                "Zachary Lipton",
                "Yu-Xiang Wang",
                "Alexander Smola."
            ],
            "title": "Detecting and correcting for label shift with black box predictors",
            "venue": "Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Re-",
            "year": 2018
        },
        {
            "authors": [
                "A. Rupam Mahmood",
                "Hado P van Hasselt",
                "Richard S Sutton."
            ],
            "title": "Weighted importance sampling for off-policy learning with linear function approximation",
            "venue": "Advances in Neural Information Processing Systems, volume 27. Curran Associates,",
            "year": 2014
        },
        {
            "authors": [
                "Binny Mathew",
                "Punyajoy Saha",
                "Seid Muhie Yimam",
                "Chris Biemann",
                "Pawan Goyal",
                "Animesh Mukherjee."
            ],
            "title": "Hatexplain: A benchmark dataset for explainable hate speech detection",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence,",
            "year": 2021
        },
        {
            "authors": [
                "Julian McAuley",
                "Jure Leskovec."
            ],
            "title": "Hidden factors and hidden topics: Understanding rating dimensions with review text",
            "venue": "Proceedings of the 7th ACM Conference on Recommender Systems, RecSys \u201913, page 165\u2013172, New York, NY, USA. Association",
            "year": 2013
        },
        {
            "authors": [
                "Susan M. Mudambi",
                "David Schuff"
            ],
            "title": "Research note: What makes a helpful online review? a study of customer reviews on amazon.com",
            "venue": "MIS Quarterly,",
            "year": 2010
        },
        {
            "authors": [
                "Jerzy Neyman"
            ],
            "title": "On the application of probability theory to agricultural experiments",
            "venue": "essay on principles",
            "year": 1990
        },
        {
            "authors": [
                "Yue Pan",
                "Jason Q. Zhang."
            ],
            "title": "Born unequal: A study of the helpfulness of user-generated product reviews",
            "venue": "Journal of Retailing, 87(4):598\u2013612.",
            "year": 2011
        },
        {
            "authors": [
                "Georgia Papadogeorgou",
                "Kosuke Imai",
                "Jason Lyall",
                "Fan Li."
            ],
            "title": "Causal inference with spatio-temporal data: Estimating the effects of airstrikes on insurgent violence in Iraq",
            "venue": "Journal of the Royal Statistical Society. Series B: Statistical Methodology, 84(5):1969\u2013",
            "year": 2022
        },
        {
            "authors": [
                "John Pavlopoulos",
                "Prodromos Malakasiotis",
                "Ion Androutsopoulos."
            ],
            "title": "Deeper attention to abusive user content moderation",
            "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1125\u20131135, Copenhagen,",
            "year": 2017
        },
        {
            "authors": [
                "Judea Pearl",
                "Elias Bareinboim."
            ],
            "title": "External Validity: From Do-Calculus to Transportability Across Populations, 1 edition, page 451\u2013482",
            "venue": "Association for Computing Machinery, New York, NY, USA.",
            "year": 2022
        },
        {
            "authors": [
                "James W. Pennebaker."
            ],
            "title": "The secret life of pronouns",
            "venue": "New Scientist, 211(2828):42\u201345.",
            "year": 2011
        },
        {
            "authors": [
                "James W Pennebaker",
                "Ryan L Boyd",
                "Kayla Jordan",
                "Kate Blackburn."
            ],
            "title": "The development and psychometric properties of liwc2015",
            "venue": "Technical report.",
            "year": 2015
        },
        {
            "authors": [
                "Reid Pryzant",
                "Dallas Card",
                "Dan Jurafsky",
                "Victor Veitch",
                "Dhanya Sridhar."
            ],
            "title": "Causal effects of linguistic properties",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-",
            "year": 2021
        },
        {
            "authors": [
                "Reid Pryzant",
                "Kelly Shen",
                "Dan Jurafsky",
                "Stefan Wagner."
            ],
            "title": "Deconfounded lexicon induction for interpretable social science",
            "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Hu-",
            "year": 2018
        },
        {
            "authors": [
                "Jing Qian",
                "Anna Bethke",
                "Yinyin Liu",
                "Elizabeth Belding",
                "William Yang Wang."
            ],
            "title": "A benchmark dataset for learning to intervene in online hate speech",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the",
            "year": 2019
        },
        {
            "authors": [
                "Paul R Rosenbaum",
                "Donald B Rubin."
            ],
            "title": "The Central Role of the Propensity Score in Observational Studies for Causal Effects",
            "venue": "Biometrika, 70(1):41\u201355.",
            "year": 1983
        },
        {
            "authors": [
                "Donald B Rubin."
            ],
            "title": "Estimating causal effects of treatments in randomized and nonrandomized studies",
            "venue": "Journal of educational Psychology, 66(5):688.",
            "year": 1974
        },
        {
            "authors": [
                "Cynthia Rudin."
            ],
            "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead",
            "venue": "Nature Machine Intelligence, 1(5):206\u2013215.",
            "year": 2019
        },
        {
            "authors": [
                "Tobias Schnabel",
                "Adith Swaminathan",
                "Ashudeep Singh",
                "Navin Chandak",
                "Thorsten Joachims."
            ],
            "title": "Recommendations as treatments: Debiasing learning and evaluation",
            "venue": "Proceedings of The 33rd International Conference on Machine Learning, volume 48 of Pro-",
            "year": 2016
        },
        {
            "authors": [
                "Hidetoshi Shimodaira."
            ],
            "title": "Improving predictive inference under covariate shift by weighting the loglikelihood function",
            "venue": "Journal of Statistical Planning and Inference, 90(2):227\u2013244.",
            "year": 2000
        },
        {
            "authors": [
                "Kaitao Song",
                "Xu Tan",
                "Tao Qin",
                "Jianfeng Lu",
                "TieYan Liu."
            ],
            "title": "Mpnet: Masked and permuted pretraining for language understanding",
            "venue": "Advances in Neural Information Processing Systems, volume 33, pages 16857\u201316867. Curran Associates, Inc.",
            "year": 2020
        },
        {
            "authors": [
                "Adith Swaminathan",
                "Thorsten Joachims."
            ],
            "title": "Counterfactual risk minimization: Learning from logged bandit feedback",
            "venue": "Proceedings of the 32nd International Conference on Machine Learning, volume 37 of Proceedings of Machine Learning Re-",
            "year": 2015
        },
        {
            "authors": [
                "Elizabeth Tipton."
            ],
            "title": "How generalizable is your experiment? an index for comparing experimental samples and populations",
            "venue": "Journal of Educational and Behavioral Statistics, 39(6):478\u2013501.",
            "year": 2014
        },
        {
            "authors": [
                "Xuanhui Wang",
                "Michael Bendersky",
                "Donald Metzler",
                "Marc Najork."
            ],
            "title": "Learning to rank with selection bias in personal search",
            "venue": "Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval,",
            "year": 2016
        },
        {
            "authors": [
                "Andrew Wen",
                "Sunyang Fu",
                "Sungrim Moon",
                "Mohamed El Wazir",
                "Andrew Rosenbaum",
                "Vinod C Kaggal",
                "Sijia Liu",
                "Sunghwan Sohn",
                "Hongfang Liu",
                "Jungwei Fan"
            ],
            "title": "Desiderata for delivering nlp to accelerate healthcare ai advancement and a mayo clinic nlp",
            "year": 2019
        },
        {
            "authors": [
                "Binggui Zhou",
                "Guanghua Yang",
                "Zheng Shi",
                "Shaodan Ma."
            ],
            "title": "Natural language processing for smart healthcare",
            "venue": "IEEE Reviews in Biomedical Engineering, pages 1\u201317.",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "What makes a comment on a social media site seem toxic or hateful (Mathew et al., 2021; Guest et al., 2021)? Could it be the use of profanity, or a lack of insight? What makes a product review more or less helpful to readers (Mudambi and Schuff, 2010; Pan and Zhang, 2011)? Is it the certainty of the review, or perhaps the presence of justifications? As language technologies are increasingly deployed in real-world settings, interpretability and explainability in natural language processing have become paramount (Rudin, 2019; Barredo Arrieta et al., 2020). Particularly desirable is the ability to\nunderstand how changes to language affect reader perceptions\u2014formalized in statistical terms as the causal effect of varying a linguistic attribute on a reader\u2019s response to the text (Figure 1).\nA core technical challenge for causal inference is that valid causal effects can only be estimated on data in which certain assumptions are upheld: namely, data where confounding is either fully measured or absent entirely (Rosenbaum and Rubin, 1983). Since confounding\u2014the presence of factors that affect both the reader\u2019s choice of texts to read and the reader\u2019s response (e.g., political affiliation, age, mood)\u2014is extremely difficult to measure fully in text settings, estimation of causal effects from natural language remains an open problem. One resource-intensive approach is to run a randomized experiment, which eliminates confounding by ensuring that respondents are randomly assigned texts to read (Holland, 1986; Fong and Grimmer, 2021). However, effects estimated from randomized experiments may not generalize outside of the specific data on which they were conducted (Tipton, 2014;\nBareinboim and Pearl, 2021). Therefore, learning causal effects for a new target domain can require a new randomized experiment each time.\nIn this paper, we propose to bypass the need for strong data assumptions in the target domain by framing causal effect estimation as a distribution shift problem. We introduce TEXT-TRANSPORT, a method for learning text causal effects in any target domain, including those that do not necessarily fulfill the assumptions required for valid causal inference. Leveraging the notion of distribution shift, we define a causal estimator that transports a causal effect from a causally valid source domain (e.g., a randomized experiment) to the target domain, and we derive statistical guarantees for our proposed estimator that show that it has desirable properties that can be used to quantify its uncertainty.\nWe evaluate TEXT-TRANSPORT empirically using a benchmarking strategy that includes knowledge about causal effects in both the source domain and the target domain. We find that across three data settings of increasing complexity, TEXTTRANSPORT estimates are consistent with effects directly estimated on the target domain, suggesting successful transport of effects. We further study a realistic setting\u2014user responses to hateful content on social media sites\u2014in which causal effects do change significantly between text domains, demonstrating the utility of transport when estimating causal effects from natural language. Finally, we conduct analyses that examine the intuition behind why TEXT-TRANSPORT is an effective estimator of text causal effects."
        },
        {
            "heading": "2 Problem Setting",
            "text": "Consider a collection of texts (e.g., documents, sentences, utterances) X , where person i (i = 1, . . . , N ) is shown a text Xi from X . Using the potential outcomes framework (Neyman, 1923 [1990]; Rubin, 1974), let Yi(x) denote the potential response of respondent i if they were to read text x, where Yi : X \u2192 R. Without loss of generality, assume that each respondent in reality reads only one text Xi, so their observed response is Yi(Xi).\nThen the average response \u00b5(P ) across the N respondents when texts X are drawn from a distri-\nbution P is given by:\n\u00b5(P ) = 1\nN N\u2211 i=1 EX\u223cP [Yi(X)]\n= 1\nN N\u2211 i=1 \u2211 x\u2208X Yi(x)P (x)\n(1)\nNow let X be parameterized as X = {a(X), ac(X)}, where a(X) is the text attribute of interest and ac(X) denotes all other attributes of the text X . Note that for a text causal effect to be meaningful, a(X) must be interpretable. This may be achieved by having a human code a(X) or using a lexicon or other automatic coding method. Again for simplicity, we assume a(X) \u2208 {0, 1}. Definition 1 (Natural causal effect of an attribute). Let P1(X) be a distribution such that a(X) = 1 and ac(X) \u223c P (ac(X)|a(X) = 1), and let P0(X) be a distribution such that a(X) = 0 and ac(X) \u223c P (ac(X)|a(X) = 0).\nThen the causal effect of a(X) on Y is given by:\n\u03c4\u2217 = \u00b5(P1)\u2212 \u00b5(P0) (2)\nHere, \u03c4\u2217 is the natural effect of a(X). Linguistic attributes are subject to aliasing (Fong and Grimmer, 2021), in which some other linguistic attributes (e.g., the k-th linguistic attribute ac(X)k) may be correlated with both the linguistic attribute of interest a(X) and the response Y , such that P (ac(X)k|a(X) = 1) \u0338= P (ac(X)k|a(X) = 0). For example, optimism may naturally co-occur with positive emotion, meaning that the natural effect of optimism also contains in part the effect of positive emotion. In contrast, the isolated effect would contain only the effect of optimism. In this paper, we choose to focus on natural effects due to the way linguistic attributes manifest in real-world language. That is, since optimism nearly always co-occurs with positive emotion, it may be difficult to interpret the effect of optimism when positive emotion is removed (the isolated effect), so we instead focus on their collective natural effect.\nOur goal is then to learn \u03c4T , the natural causal effect of the attribute a(X) on response Y in the text domain of interest P T . We consider use cases where it is not possible to directly estimate the effect from target data X \u223c P T , either because P T does not fulfill the assumptions required for valid causal inference or simply because the response Y is not measured in the domain of interest."
        },
        {
            "heading": "3 TEXT-TRANSPORT",
            "text": "To estimate causal effects under a target text distribution P T\u2014without computing effects on P T directly\u2014we propose TEXT-TRANSPORT, a method for transporting a causal effect from a source text distribution PR that does fulfill the assumptions required for valid causal inference and with respect to which P T is absolutely continuous. Our approach can help to generalize the causal findings of PR, which are specific to the data domain of PR, to any text distribution of interest P T . For mathematical convenience, we consider the source distribution PR to be a randomized experiment. We note that any crowdsourced dataset in which samples are randomly assigned to crowdworkers can be considered a randomized experiment."
        },
        {
            "heading": "3.1 Transporting effects",
            "text": "We characterize this problem as an instance of distribution shift, allowing us to define a causal effect estimator \u03c4\u0302T that uses the density ratio between two distributions as an importance weight to transport the effect from PR to P T . Given Xi \u223c PR, and letting dP T\ndPR (x) \u2261 PT (x) PR(x) be the density ratio1\nbetween P T and PR,\n\u00b5\u0302(P T ) = 1\nn n\u2211 i=1 dPT dPR (Xi)Yi(Xi) (3)\nwhich gives us the effect estimate under P T :\n\u03c4\u0302T = \u00b5\u0302(P T1 )\u2212 \u00b5\u0302(P T0 ) (4)\nIntuitively, as all observed texts are drawn from PR, the role of the importance weight is to increase the contribution of texts that are similar to texts from P T , while reducing the contribution of texts that are representative of PR. That is, if P T (Xi) is high and PR(Xi) is low, then Xi will have a greater contribution to \u00b5\u0302(P T ). To highlight this transport of PR to P T , in the remainder of this paper we will refer to \u00b5\u0302(P T ) as \u00b5\u0302R\u2192T .\nA strength of this estimator is that we are able to quantify statistical uncertainty around the causal effect. We demonstrate (with derivations and proofs in Appendix B) that \u00b5\u0302R\u2192T has a number of desirable properties that allow us to compute statistically valid confidence intervals: (1) it is an unbiased estimator of \u00b5(P T ), (2) it is asymptotically normal, and (3) it has a closed-form variance and an unbiased, easy-to-compute variance estimator.\n1More generally, this is the Radon-Nikodym derivative, formally defined in Appendix A."
        },
        {
            "heading": "3.2 Importance weight estimation",
            "text": "Estimating the transported response \u00b5\u0302(P T ) first requires computing either the derivative dP T\ndPR (X)\nor the individual probabilities PR(X), P T (X). While there are many potential ways to estimate this quantity, we propose the classification approach TEXT-TRANSPORTclf and the language model approach TEXT-TRANSPORTLM (Figure 2).\nTEXT-TRANSPORTclf. The classification approach for estimating dP T\ndPR (X) relies on the notion that the density ratio can be rewritten in a way that makes estimation more tractable. Let C denote the distribution (or corpus) from which a text is drawn, where C = T denotes that it is drawn from P T and C = R denotes that it is drawn from PR. Then dPT dPR (X) can be rewritten as follows:\ndPT dPR (X) = P (C = T |X) P (C = T ) P (C = R) P (C = R|X) (5)\nP (C = T |X) and P (C = R|X) can be estimated by training a binary classifier M\u03b8 : X \u2192 {0, 1} to predict if a text X came from T or R. P (C = R) and P (C = T ) are defined by their sample proportions (i.e., by their proportion of the total text after combining the two corpora).2\nTEXT-TRANSPORTLM. Because language models are capable of learning text distributions, we are able to take an alternative estimation approach that does not require learning dP T\ndPR (X). A language model trained on samples from PR or P T , for instance, can compute the probability of texts under the learned distributions.\nPre-trained large language models (LLMs) are particularly useful for estimating P\u0302R and P\u0302 T , since their training corpora are large enough to approximate the distribution of the English language, and their training data is likely to have included many PR or P T of interest. Following recent advances in LLMs, one way of obtaining P\u0302R(X) and P\u0302 T (X) from an LLM is to prompt the LLM in a way that induces it to focus on PR or P T . Once the LLM has been prompted toward either PR or P T , sentence probabilities from the LLM can be treated as reflections of PR(X) or P T (X), respectively. We provide examples of such prompts in Figure 2, and we explore this approach in our experiments.\n2In practice, rather than use the ratios dP T dPR (X) or PT (Xi)\nPR(Xi)\ndirectly, we use stabilized (i.e., normalized) versions that cancel out the sample proportions. See Appendix C."
        },
        {
            "heading": "4 Experimental Setup",
            "text": "We conduct empirical evaluations to assess the validity of causal effects obtained through TEXTTRANSPORT in three different data settings of increasing complexity (Table 1)."
        },
        {
            "heading": "4.1 Evaluation methodology",
            "text": "To assess the validity of TEXT-TRANSPORT, we conduct experiments comparing the transported average response \u00b5\u0302R\u2192T with \u00b5\u0302R, the average response under PR, and \u00b5\u0302T , the average response under P T . A valid transported response \u00b5\u0302R\u2192T will be similar to \u00b5\u0302T and significantly different from \u00b5\u0302R. To quantify these differences, we compare estimated averages and 95% confidence intervals, as well as normalized RMSE (RMSE divided by the standard deviation of the target response) between \u00b5\u0302R\u2192T and \u00b5\u0302T .\nAs we mention previously, validating transported causal effects requires an evaluation strategy in which causal effects under PR and P T are both known. Therefore, each of our evaluation datasets consists of a single crowdsourced dataset that can be divided into two parts (e.g., a corpus of movie reviews can be split by genre), such that they possess the following properties. First, to allow \u00b5\u0302R and \u00b5\u0302T to be computed directly, both PR and P T are randomized experiments (we reiterate that P T is a randomized experiment only for the purposes of validation; we would not expect actual P T s to be randomized). Second, the response Y is measured for both PR and P T . Third, PR and P T are distinct in a way where we would expect the average response to differ between the two. This allows us to evaluate whether transport has successfully occurred (if the average response is the same between PR and P T , transport will not do anything).\nWe choose three crowdsourced datasets, partition each into PR and P T , and compute \u00b5\u0302R, \u00b5\u0302T , and \u00b5\u0302R\u2192T . We estimate confidence intervals for each average response through bootstrap resampling with 100 iterations.\nBaselines. While a small number of prior studies have proposed estimators of some type of text causal effect from observational (i.e., nonrandomized) data, effects obtained from these methods are not directly comparable to those obtained using TEXT-TRANSPORT (further discussion of these methods can be found in Section 6). However, rather than using the density ratio to transport effects, other transformations of the source distribution to the target distribution are possible. One intuitive baseline is to train a predictive model on the source distribution, which is then used to generate pseudo-labels on the target distribution. These pseudo-labels can be averaged to produce a naive estimate (the naive baseline)."
        },
        {
            "heading": "4.2 Datasets",
            "text": "Amazon (controlled setting). The Amazon dataset (McAuley and Leskovec, 2013) consists of text reviews from the Amazon e-commerce website, where the reader response is the number of \u201chelpful\u201d votes the review has received. We choose reviews of musical instruments as PR and reviews of office supplies as P T .\nTo construct a best-case scenario in which there are no unmeasured factors in the data, we generate a new semi-synthetic response Y by predicting the number of helpful votes as a function of a(X), ac(X). We use a noisy version of this prediction as our new Y . This ensures that all predictable variability in the response Y is captured in the text. Furthermore, we sample reviews into PR and P T according to their predicted likelihood of being in PR or P T when accounting only for a(X), ac(X). This provides a controlled data setting in which we know that a model is capable of distinguishing between PR and P T , such that we can evaluate TEXT-TRANSPORT under best-case conditions.\nEmoBank (partially controlled setting). The EmoBank dataset (Buechel and Hahn, 2017) consists of sentences that have been rated by crowdworkers for their perceived valence Y (i.e., the positivity or negativity of the text). To construct PR, we sample sentences such that texts with high writer-intended valence occur with high probability, and to construct P T , we sample sentences such that texts with low writer-intended valence occur with high probability. This partially controls the data setting by guaranteeing that the source and target domains differ on a single attribute\u2014writerintended valence\u2014that is known to us (but hidden from the models).\nHate Speech (natural setting). The Hate Speech dataset (Qian et al., 2019) consists of comments from the social media sites Reddit and Gab. These comments have been annotated by crowdworkers as hate speech or not hate speech. The Reddit comments are chosen from subreddits where hate speech is more common, and Gab is a platform where users sometimes migrate after being blocked from other social media sites. To represent a realistic data setting in which we have no control over the construction of the source and target distributions, we treat the corpus of Reddit comments as PR and the corpus of Gab comments as P T ."
        },
        {
            "heading": "4.3 Implementation",
            "text": "Linguistic attributes. To automatically obtain linguistic attributes a(X), ac(X) from the text, we use the 2015 version of the lexicon Linguistic Inquiry and Word Count (LIWC) to encode the text as lexical categories (Pennebaker et al., 2015). LIWC is a human expert-constructed lexicon\u2014 generally viewed as a gold standard for lexicons\u2014 with a vocabulary of 6,548 words that belong to one or more of its 85 categories, most of which are related to psychology and social interaction. We binarize the category encodings to take the value 1 if the category is present in the text and 0 otherwise.\nTEXT-TRANSPORTclf. We use the following procedure to implement TEXT-TRANSPORTclf. First, we consider data DR from PR and data DT from P T . We take 10% of DR and 10% of DT as our classifier training set Dtrain. Next, we train a classifier M\u03b8 on Dtrain to distinguish between PR and P T . For our classifier, we use embeddings from pre-trained MPNet (Song et al., 2020), a wellperforming sentence transformer architecture, as inputs to a logistic regression.\nFrom M\u03b8, we can obtain P\u0302 (C = T |X) and P\u0302 (C = R|X) for all texts X in the remaining 90% of DR. We compute P (C = R) and P (C = T ) as 1 |DR| and 1 |DT | , respectively. Then we have\ndPR(X) dPT (X) = P\u0302 (C = T |X) P\u0302 (C = R|X) |DT | |DR|\n(6)\nIn the case of the Amazon dataset, we note that although we can estimate the classification probabilities as P\u0302 (C = T |X), P\u0302 (C = R|X), the true probabilities are already known, as we use them to separate texts into PR and P T . Therefore\u2014to evaluate the effectiveness of TEXT-TRANSPORT under conditions where we know the classifier to be correct\u2014we use the known probabilities P (C = T |X), P (C = R|X) in our evaluations on the Amazon dataset only.\nTEXT-TRANSPORTLM. This approach can be implemented without any training data, leaving the full body of text available for estimation. In our experiments, we estimate PR(X) and P T (X) through prompting. For each dataset, we provide pre-trained GPT-3 with a prompt that describes PR or P T , then follow the prompt with the full text from each sample X \u223c PR. On the EmoBank dataset, for instance, we provide GPT-3 with the prompts \u201cYou are writing a positive statement\u201d (for PR, the high-valence distribution) and \u201cYou are\nwriting a negative statement\u201d (for P T , the lowvalence distribution). A full list of prompts can be found in Appendix D.3.\nAfter prompting the model with either PR or P T , we compute the token probabilities over each X , then compute sentence probabilities as the product of the token probabilities. If a text has multiple sentences, we treat the average of the sentence probabilities as the overall text probability. Finally, we compute the ratio P\u0302 T (X)\nP\u0302R(X) as our importance weight."
        },
        {
            "heading": "5 Results and Discussion",
            "text": ""
        },
        {
            "heading": "5.1 Validity of TEXT-TRANSPORT",
            "text": "We evaluate the validity of our TEXT-TRANSPORT responses on the Amazon, EmoBank, and Hate Speech data settings (Figure 3, Table 2).\nWe observe that on the Amazon dataset, both TEXT-TRANSPORTclf and TEXT-TRANSPORTLM are well-validated. For both sets of Amazon re-\nsults, our transported response \u00b5\u0302R\u2192T is statistically significantly different from \u00b5\u0302R, while being statistically indistinguishable from \u00b5\u0302T . In contrast, the naive baseline produces an estimate with confidence intervals that overlap both \u00b5\u0302R and \u00b5\u0302T , and its RMSE is higher than both TEXT-TRANSPORT estimates. The success of TEXT-TRANSPORTclf in this setting suggests that if the classifier is known to be a good estimator of the probabilities P (C = T |X) and P (C = R|X), the transported estimates will be correct. The success of TEXT-TRANSPORTLM in this setting, on the other hand, suggests that prompting GPT-3 can in fact be an effective way of estimating PR(X) and P T (X) and that the ratio between the two can also be used to produce valid transported estimates.\nWe further find that as the data setting becomes less controlled (i.e., EmoBank and Hate Speech), our transported responses continue to show encouraging trends\u2014that is, the transported effect\nindeed moves the responses away from \u00b5\u0302R and toward \u00b5\u0302T , while transported responses from the naive baseline exhibit little to no movement toward the target. When evaluating TEXT-TRANSPORTLM on EmoBank, \u00b5\u0302R\u2192T and \u00b5\u0302T have no statistically significant difference. However, in evaluations of TEXT-TRANSPORTclf, we find that \u00b5\u0302R\u2192T\u2014 though transported in the right direction\u2014retains a statistically significant difference from \u00b5\u0302T ; and when evaluating TEXT-TRANSPORTLM on Hate Speech, we observe wide confidence intervals for \u00b5\u0302R\u2192T that cover both \u00b5\u0302T and \u00b5\u0302R, though the point estimates of \u00b5\u0302R\u2192T and \u00b5\u0302T are very close.\nFinally, we note that TEXT-TRANSPORTLM is less stable than TEXT-TRANSPORTclf with respect to the width of its confidence intervals, although the transported point estimates are better. This is particularly highlighted by the higher RMSE of TEXT-TRANSPORTLM compared to the naive baseline on the Hate Speech dataset, in spite of TEXT-TRANSPORTLM\u2019s much better point estimate. 3\nWe posit that the instability of TEXT-TRANSPORTLM is due to the very small probability of any particular text occurring under a given probability distribution, as well as a potential lack of precision introduced when using prompting to target an LLM to a specific distribution. We observe that both P\u0302R(X) and P\u0302 T (X) are typically both very small, and any difference between them\u2014while minute in absolute terms\u2014is amplified when taking their ratio. As a result, the range of importance weights P\u0302 T (X)\nP\u0302R(X) under\nTEXT-TRANSPORTLM is much larger than the range of\n\u02c6dPT dPR (X) under TEXT-TRANSPORTclf,\nintroducing a large amount of variability when estimating \u00b5\u0302R\u2192T .\nOften, however, TEXT-TRANSPORTLM can still produce reasonable confidence intervals (as is the case for the Amazon and EmoBank datasets), and it illustrates the efficacy of the TEXT-TRANSPORT method under one of the simplest implementations (since no additional model training or even access to target data is required).\n3In this sense, metrics like RMSE can be somewhat reductive, as they penalize the larger confidence interval but fail to capture the fact that the \u201ctransported\u201d effect under the naive estimator has moved very little toward the target distribution, while the transported effect under the LM approach has correctly made a much larger shift toward the target distribution."
        },
        {
            "heading": "5.2 A realistic use case: What makes a comment hateful?",
            "text": "In this section, we highlight a realistic use case of TEXT-TRANSPORT. Taking our Hate Speech dataset, we examine the source, transported, and target effects of five linguistic attributes, where Reddit is again the source distribution and Gab is the target distribution (Figure 4). Transported effects are estimated using TEXT-TRANSPORTclf.\nWe find that the causal effects of these five linguistic attributes estimated directly on Reddit differ significantly from their counterparts that have been transported to Gab. Though we would not have access to effects estimated directly on the target distribution in a real-world setting, we are able to validate here that the effect shifts are consistent with causal effects directly estimated from Gab.\nNegative causal effects. After transport to Gab, the linguistic attributes netspeak, insight, and family are all shown to have significant negative effects on whether a comment is perceived as hate speech, while they are found to have no significant effect in the original Reddit data. In other words, when Gab users use netspeak, make insights, or talk about family, these conversational choices cause readers to perceive the overall comment as less hateful, while the same does not hold true for Reddit users.\nPositive causal effects. In contrast, after transport to Gab, the linguistic attribute function is shown to have a significant positive effect on whether a comment is perceived as hate speech, while it was found to have no significant effect in the original Reddit data. Function words comprise articles, pronouns, conjunctions, negations,\nand other words that serve primarily grammatical purposes, and prior work has found that they can be highly suggestive of a person\u2019s psychological state (Groom and Pennebaker, 2002; Chung and Pennebaker, 2007; Pennebaker, 2011).\nThough the difference between the original and transported effect is not statistically significant, profanity is also found to have a more positive effect on whether a comment is perceived as hate speech after transport to Gab compared to Reddit. This indicates that Gab users\u2019 use of profanity in their comments causes readers to perceive the overall comment as more hateful than if a Reddit user were to make profane remarks. This effect shift may be explained by the specific nature of the profanity used on Gab, which is qualitatively harsher and more offensive than the profanity used on Reddit.\nThe differences in these transported and original causal effects emphasize the importance of our method. An automatic content moderation algorithm, for instance, would likely need to consider different linguistic factors when deciding which comments to flag on each site."
        },
        {
            "heading": "5.3 An intuition for effect transport",
            "text": "Previously in Section 3.1, we stated that the intuition behind the change of measure dP T\ndPR (X) as an importance weight in the estimator \u00b5\u0302R\u2192T was to increase the contribution of texts that are similar to P T , while reducing the weight of texts that are most representative of PR. To explore whether this is indeed the case, we identify the texts from EmoBank with the highest importance weights for each of our estimation approaches (Table 3). Texts with large importance weights have high P T (X)\nand low PR(X), meaning they should be similar to texts from P T despite actually coming from PR.\nWe observe that texts from PR (i.e., texts with greater probability of high writer-intended valence) with high weights are in fact qualitatively similar to texts from P T (i.e., texts with greater probability of low writer-intended valence). That is, although texts from PR should be generally positive, the texts with the highest weights are markedly negative in tone, making them much more similar to texts from P T . These observations support the intuition that the change of measure transports causal effects to the target domain by looking primarily at the responses to texts in the source domain that are most similar to texts in the target domain."
        },
        {
            "heading": "6 Related Work",
            "text": "TEXT-TRANSPORT draws on a diverse body of prior work from machine learning and causal inference, including the literature on domain adaptation, distribution shift, and generalizability and transportability. We build on methods from these fields to define a novel, flexible estimator of causal effects in natural language.\nText causal effects. A number of approaches have been proposed for estimating causal effects from natural language. Egami et al. (2018) construct a conceptual framework for causal inference with text that relies on specific data splitting strategies, while Pryzant et al. (2018) describe a procedure for learning words that are most predictive of a desired response. However, the interpretability of the learned effects from these works is limited. In a subsequent paper, Pryzant et al. (2021) introduce a method for estimating effects of linguistic proper-\nties from observational data. While this approach targets isolated effects of linguistic properties, it requires responses to be measured on the target domain, and it accounts only for the portion of confounding that is contained with the text.\nFinally, in a recent paper, Fong and Grimmer (2021) conduct randomized experiments over text attributes to determine their effects. While allowing for valid causal inference, the resulting constructed texts are artificial in nature and constitute a clear use case for TEXT-TRANSPORT, which can transport effects from the less-realistic experimental text domain to more naturalistic target domains.\nDomain adaptation, distribution shift, and transportability. Importance weighting has been widely used in the domain adaptation literature to help models learn under distribution shift (Byrd and Lipton, 2019). Models are trained with importanceweighted loss functions to account for covariate and label shift (Shimodaira, 2000; Lipton et al., 2018; Azizzadenesheli et al., 2019), correct for selection bias (Wang et al., 2016; Schnabel et al., 2016; Joachims et al., 2017), and facilitate offpolicy reinforcement learning (Mahmood et al., 2014; Swaminathan and Joachims, 2015).\nIn parallel, a line of work studying the external validity of estimated causal effects has emerged within statistical causal inference (Egami and Hartman, 2022; Pearl and Bareinboim, 2022). These works aim to understand the conditions under which causal effects estimated on specific data can generalize or be transported to broader settings (Tipton, 2014; Bareinboim and Pearl, 2021). Prior work has also used density ratio-style importance weights to estimate average causal effects with high-dimensional interventions (de la Cuesta et al., 2022; Papadogeorgou et al., 2022).\nWe emphasize that TEXT-TRANSPORT is conceptually novel and methodologically distinct from these prior works. In our work, we explore an open problem\u2014causal effect estimation from text\u2014and define a new framework for learning causal effects from natural language. We propose a novel solution that uses tools from the domain adaptation and transportability literature, and we introduce novel methods for estimating natural effects in practice in language settings."
        },
        {
            "heading": "7 Conclusion",
            "text": "In this paper, we study the problem of causal effect estimation from text, which is challenging\ndue to the highly confounded nature of natural language. To address this challenge, we propose TEXT-TRANSPORT, a novel method for estimating text causal effects from distributions that may not fulfill the assumptions required for valid causal inference. We conduct empirical evaluations that support the validity of causal effects estimated with TEXT-TRANSPORT, and we examine a realistic data setting\u2014hate speech and toxicity on social media sites\u2014in which TEXT-TRANSPORT identifies significant shifts in causal effects between text domains. Our results reinforce the need to account for distribution shift when estimating text-based causal effects and suggest that TEXT-TRANSPORT is a compelling approach for doing so. These promising initial findings open the door to future exploration of causal effects from complex unstructured data like language, images, and multimodal data."
        },
        {
            "heading": "8 Acknowledgements",
            "text": "This material is based upon work partially supported by the National Science Foundation (awards 1722822 and 1750439) and the National Institutes of Health (awards R01MH125740, R01MH132225, R01MH096951, and R21MH130767). Victoria Lin is partially supported by a Meta Research PhD Fellowship. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsors, and no official endorsement should be inferred."
        },
        {
            "heading": "9 Limitations",
            "text": "Although TEXT-TRANSPORT is effective in accounting for distribution shift to estimate effects of linguistic attributes in target domains without data assumptions, the method relies on the existence of a source domain that satisfies the data assumptions required for valid causal inference. Such a source domain\u2014even a small or limited one\u2014may not always be available. We plan to address this limitation in future work, where transport from any source domain is possible.\nAdditionally, TEXT-TRANSPORT proposes a framework for estimating natural causal effects from text. However, as we discuss above, in some cases it may also be of interest to estimate isolated causal effects from text. In future work, we will extend TEXT-TRANSPORT to include an estimator for isolated causal effects.\nFinally, a requirement of the target distribution\nP T is that it is absolutely continuous with respect to the source distribution PR. The absolute continuity assumption is violated if a text that would never occur in PR could possibly occur in P T . Therefore, this assumption may not be satisfied if the source and target distributions are completely unrelated and non-overlapping, even in latent space. Practically speaking, this means that it may not be possible to transport effects between distributions that are extremely different: for instance, from a corpus of technical manuals to a corpus of Shakespearean poetry."
        },
        {
            "heading": "10 Ethics Statement",
            "text": "Broader impact. Language technologies are assuming an increasingly prominent role in realworld settings, seeing use in applications like healthcare (Wen et al., 2019; Zhou et al., 2022; Reeves et al., 2021), content moderation (Pavlopoulos et al., 2017; Gorwa et al., 2020), and marketing (Kang et al., 2020). As these black-box systems become more widespread, interpretability and explainability in NLP are of ever greater importance.\nTEXT-TRANSPORT builds toward this goal by providing a framework for estimating the causal effects of linguistic attributes on readers\u2019 responses to the text. These causal effects provide clear insight into how changes to language affect the perceptions of readers\u2014an important factor when considering the texts that NLP systems consume or produce.\nEthical considerations. TEXT-TRANSPORT relies on pre-trained large language models to compute text probabilities. Consequently, it is possible that these text probabilities\u2014which are used to transport causal effect estimates\u2014may encode some of the biases contained in large pre-trained models and their training data. Interpretations of causal effects produced by TEXT-TRANSPORT should take these biases into consideration.\nAdditionally, we acknowledge the environmental impact of large language models, which are used in this work."
        },
        {
            "heading": "A Change of measure with Radon-Nikodym derivatives",
            "text": "The Radon-Nikodym derivative can be used to express one probability density function in terms of another probability density function, when the two densities are related by a change of measure. Specifically, if we have two probability measures defined on the same sample space, with one measure P absolutely continuous with respect to another measure Q, then there exists a Radon-Nikodym derivative Z such that:\nP(A) = \u222b A ZdQ\nfor any event A in the sample space. Intuitively, this means that we can define the probability of any event under the measure P in terms of the probability of the same event under the measure Q, by weighting the probabilities by a factor given by the Radon-Nikodym derivative.\nNow, suppose we have two probability density functions p(x) and q(x) defined on some real-valued random variable X , with q(x) > 0 for all x. We want to express p(x) in terms of q(x) by a change of measure. To do this, we can define a new probability measure P as:\nP(A) = \u222b A p(x) q(x) q(x)dx = \u222b A p(x)dx\nfor any event A in the sample space. If P is absolutely continuous with respect to the measure defined by q(x), then there exists a Radon-Nikodym derivative Z(x) such that:\ndP dQ (x) = Z(x) = p(x) q(x)\nThis means that we can express p(x) in terms of q(x) and the Radon-Nikodym derivative Z(x) as:\np(x) = Z(x)q(x)"
        },
        {
            "heading": "B Statistical properties of \u00b5\u0302R\u2192T",
            "text": "As we mention in the main paper, the transport estimator \u00b5\u0302R\u2192T has a number of desirable statistical properties that allow us to quantify its uncertainty, included unbiasedness, asymptotic normality, and closed-form variance. In this section, we provide proofs and derivations for these properties.\nB.1 Unbiasedness\nWe can show that \u00b5\u0302R\u2192T is an unbiased estimator for \u00b5(P T ):\nE[\u00b5\u0302R\u2192T ] = EXi\u223cPR [\u00b5\u0302 R\u2192T ]\n= EXi\u223cPR\n[ 1\nn n\u2211 i=1 dPT dPR (Xi)Yi(Xi)\n]\n= 1\nn n\u2211 i=1 EXi\u223cPR [ dPT dPR (Xi)Yi(Xi) ]\n= 1\nn n\u2211 i=1 EXi\u223cPT [Yi(Xi)]\n= \u00b5(P T )\n(7)\nB.2 Closed-form variance and confidence intervals\nLet X be the space of all texts, and consider the finite-sample setting where Yi is fixed (i.e., non-random) for all i \u2208 [n]. Then the variance of the estimator is given by:\nVar[\u00b5\u0302R\u2192T |Yi] =Var\n[ 1\nn n\u2211 i=1 dPT dPR (Xi)Yi(Xi)\n]\n= 1\nn2 n\u2211 i=1 Var [ dPT dPR (Xi)Yi(Xi) ]\n= 1\nn2 n\u2211 i=1 Cov [ dPT dPR (Xi)Yi(Xi), dPT dPR (Xi)Yi(Xi) ]\n= 1\nn2 n\u2211 i=1 Cov [\u2211 x\u2208X dPT dPR (x)Yi(x)1{Xi = x}, \u2211 x\u2032\u2208X dPT dPR (x\u2032)Yi(x \u2032)1{Xi = x\u2032} ]\n= 1\nn2 n\u2211 i=1 \u2211 x\u2208X \u2211 x\u2032\u2208X dPT dPR (x) dPT dPR (x\u2032)Yi(x)Yi(x \u2032)Cov[1{Xi = x},1{Xi = x\u2032}]\n= 1\nn2 n\u2211 i=1 \u2211 x\u2208X \u2211 x\u2032\u2208X dPT dPR (x) dPT dPR (x\u2032)Yi(x)Yi(x \u2032)(E[1{Xi = x}1{Xi = x\u2032}] \u2212 E[1{Xi = x}]E[1{Xi = x\u2032}])\n= 1\nn2 n\u2211 i=1 \u2211 x\u2208X \u2211 x\u2032\u2208X dPT dPR (x) dPT dPR (x\u2032)Yi(x)Yi(x \u2032)(PR(x, x\u2032)\u2212 PR(x)PR(x\u2032))\nIf x = x\u2032,\nVar[\u00b5\u0302R\u2192T |Yi] = 1\nn2 n\u2211 i=1 \u2211 x\u2208X dPT 2 dPR (x)Y 2i (x)(P R(x)\u2212 PR(x)PR(x))\n= 1\nn2 n\u2211 i=1 \u2211 x\u2208X dPT 2 dPR (x)Y 2i (x)P R(x)(1\u2212 PR(x))\nIf x \u0338= x\u2032,\nVar[\u00b5\u0302R\u2192T |Yi] = 1\nn2 n\u2211 i=1 \u2211 x\u2208X \u2211 x\u2032\u2208X x\u2032 \u0338=x dPT dPR (x) dPT dPR (x\u2032)Yi(x)Yi(x \u2032)(PR(x, x\u2032)\ufe38 \ufe37\ufe37 \ufe38 0 \u2212PR(x)PR(x\u2032))\n= \u2212 1 n2 n\u2211 i=1 \u2211 x\u2208X \u2211 x\u2032\u2208X x\u2032 \u0338=x dPT dPR (x) dPT dPR (x\u2032)Yi(x)Yi(x \u2032)PR(x)PR(x\u2032))\nPutting the two cases together,\nVar[\u00b5\u0302R\u2192T |Yi] = 1\nn2 n\u2211 i=1 (\u2211 x\u2208X dPT 2 dPR (x)Y 2i (x)P R(x)(1\u2212 PR(x)\n\u2212 \u2211 x\u2208X \u2211 x\u2032\u2208X x\u2032 \u0338=x dPT dPR (x) dPT dPR (x\u2032)Yi(x)Yi(x \u2032)PR(x)PR(x\u2032)\n)\n= 1\nn2 n\u2211 i=1 (\u2211 x\u2208X dPT 2 dPR (x)Y 2i (x)P R(x)\u2212 \u2211 x\u2208X dPT 2 dPR (x)Y 2i (x)P R(x)2\n\u2212 \u2211 x\u2208X \u2211 x\u2032\u2208X x\u2032 \u0338=x dPT dPR (x) dPT dPR (x\u2032)Yi(x)Yi(x \u2032)PR(x)PR(x\u2032)\n)\n= 1\nn2 n\u2211 i=1 (\u2211 x\u2208X dPT 2 dPR (x)Y 2i (x)P R(x)\u2212 ( \u2211 x\u2208X dPT 2 dPR (x)Y 2i (x)P\nR(x)\ufe38 \ufe37\ufe37 \ufe38 \u00b5\u0302i=E\u0302x\u223cPT [Yi(x)]=E\u0302x\u223cPR [ dPT dPR (x)Yi(x)]\n)2)\n= 1\nn2 n\u2211 i=1 (\u2211 x\u2208X ( dPT dPR (x)Yi(x) )2 PR(x)\u2212 \u00b5\u03022i )\n= 1\nn2 n\u2211 i=1 (\u2211 x\u2208X ( dPT dPR (x)Yi(x)\u2212 \u00b5\u0302i )2 PR(x) + 2 \u2211 x\u2208X dPT dPR (x)\u00b5\u0302iYi(x)P R(x)\n\u2212 \u2211 x\u2208X \u00b5\u03022iP R(x)\u2212 \u00b5\u03022i\n)\n= 1\nn2 n\u2211 i=1 (\u2211 x\u2208X ( dPT dPR (x)Yi(x)\u2212 \u00b5\u0302i )2 PR(x) + \u00b5\u0302i ( 2 \u2211 x\u2208X dPT dPR (x)Yi(x)P\nR(x)\ufe38 \ufe37\ufe37 \ufe38 \u00b5\u0302i\n\u2212 \u00b5\u0302i \u2211 x\u2208X\nPR(x)\ufe38 \ufe37\ufe37 \ufe38 1 \u2212\u00b5\u0302i\n))\n= 1\nn2 n\u2211 i=1 (\u2211 x\u2208X ( dPT dPR (x)Yi(x)\u2212 \u00b5\u0302i )2 PR(x) + \u00b5\u0302i(2\u00b5\u0302i \u2212 \u00b5\u0302i \u2212 \u00b5\u0302i\ufe38 \ufe37\ufe37 \ufe38\n0\n)\n)\n= 1\nn2 n\u2211 i=1 \u2211 x\u2208X\n( dPT\ndPR (x)Yi(x)\u2212 \u00b5\u0302i\n)2 PR(x)\nThen finally, letting \u00b5\u0302 = E\u0302x\u223cPT [ 1 n \u2211n i=1 Yi(x) ] = E\u0302x\u223cPR [ 1 n \u2211n i=1 dPT dPR (x)Yi(x) ] , we have\nVar[\u00b5\u0302R\u2192T ] = EY [Var[\u00b5\u0302(P )|Yi]]\n= EY  1 n2 n\u2211 i=1 \u2211 x\u2208X ( dPT dPR (x)Yi(x)\u2212 \u00b5\u0302i )2 PR(x)  = 1\nn2 n\u2211 i=1 \u2211 x\u2208X EY (dPT dPR (x)Yi(x)\u2212 \u00b5\u0302 )2PR(x) (8)\nWith the central limit theorem (CLT), we establish asymptotic normality:\n\u00b5\u0302R\u2192T \u2212 \u00b5(P T )\u221a Var[\u00b5\u0302R\u2192T ] \u2192 N(0, 1) (9)\nwhich we can use to estimate confidence intervals using the following unbiased variance estimate:\nV\u0302ar[\u00b5\u0302R\u2192T ] = 1\nn2 \u2211 i\u2208[n]\n( \u02c6dPT\ndPR (Xi)Yi(Xi)\u2212 \u00b5\u0302i\n)2 (10)"
        },
        {
            "heading": "C Hajek estimators",
            "text": "In practice, to maintain the stability of the importance weights (which can be very small), the H\u00e1jek (1971) estimator is often used in place of the instead of the standard Horvitz-Thompson estimator. With the Hajek estimator, the importance weights are normalized by the average importance weight. Then letting the importance weight be denoted by \u03b3, we have the estimator\n\u00b5\u0302R\u2192T = 1\nn n\u2211 i=1 \u03b3i(Xi)Yi(Xi)\nFor TEXT-TRANSPORTclf,\n\u03b3\u0302i = \u02c6dPT\ndPR (Xi) / 1 n n\u2211 j=1 \u02c6dPT dPR (Xj)  and for TEXT-TRANSPORTLM,\n\u03b3\u0302i = P\u0302 T (Xi)\nP\u0302R(Xi)\n/ 1 n n\u2211 j=1 P\u0302 T (Xj) P\u0302R(Xj) "
        },
        {
            "heading": "D Experimental Details",
            "text": "D.1 Data\nDetails of our datasets are provided in Table 4, including dataset composition and licensing information. All three datasets are publicly available, and all are in English.\nD.2 Model details TEXT-TRANSPORTclf. We used HuggingFace\u2019s implementation of MPNet in its sentence-transformers library (version 2.2.2), using the pre-trained model all-mpnet-base-v2. Embeddings from MPNet are 768 dimensions. Our logistic regression classifier was implemented in scikit-learn (version 1.0.2). All hyperparameters were set to their default values.\nTEXT-TRANSPORTLM. We used text-davinci-003 from the OpenAI API (version 0.27.4) as our pre-trained GPT-3. We prompted GPT-3 and computed sentence probabilities through the API. We set temperature to 0 and the maximum number of generated tokens to 0, since we wanted the model to echo our text input rather than generate new texts.\nD.3 Prompts\nThe prompts we used to induce GPT-3 toward the source distribution PR and the target distribution P T\nare provided in Table 5. To confirm that these prompts indeed induce GPT-3 to move toward PR or P T , we conducted the following empirical validation. Given text XR \u223c PR, we computed the ratio between P (XR) for GPT-3 that had been given a PR prompt and P (XR) for GPT-3 that had been given a P T prompt\u2014in other words, the probability ratio PGPT-3 PR (XR)\nPGPT-3 PT\n(XR) .\nSince the texts XR are drawn from PR, then if the prompts indeed direct GPT-3 toward the intended distribution, we would expect this ratio to have a median value greater than 1, as PR(XR) should be larger than P T (XR). We report medians and quantiles across the three evaluation datasets in Table 6.\nWe observe that across all three datasets, the median ratio is in fact greater than 1, indicating that our prompting strategy is successfully targeting GPT-3 to PR or P T . The median ratio for the Hate Speech dataset\u2014while still greater than 1\u2014is much closer to 1 than the Amazon or EmoBank datasets, which is consistent with the intuition that targeting very specific distributions like Reddit and Gab with prompting can be more challenging.\nD.4 Computing resources All experiments were conducted on machines with consumer-level NVIDIA graphics cards. We estimate the number of GPU hours used in our experiments to be fewer than 10."
        }
    ],
    "title": "TEXT-TRANSPORT: Toward Learning Causal Effects of Natural Language",
    "year": 2023
}