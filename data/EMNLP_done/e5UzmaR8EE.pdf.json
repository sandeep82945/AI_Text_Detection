{
    "abstractText": "The latest large language models (LLMs) such as ChatGPT, exhibit strong capabilities in automated mental health analysis. However, existing relevant studies bear several limitations, including inadequate evaluations, lack of prompting strategies, and ignorance of exploring LLMs for explainability. To bridge these gaps, we comprehensively evaluate the mental health analysis and emotional reasoning ability of LLMs on 11 datasets across 5 tasks. We explore the effects of different prompting strategies with unsupervised and distantly supervised emotional information. Based on these prompts, we explore LLMs for interpretable mental health analysis by instructing them to generate explanations for each of their decisions. We convey strict human evaluations to assess the quality of the generated explanations, leading to a novel dataset with 163 humanassessed explanations1. We benchmark existing automatic evaluation metrics on this dataset to guide future related works. According to the results, ChatGPT shows strong in-context learning ability but still has a significant gap with advanced task-specific methods. Careful prompt engineering with emotional cues and expertwritten few-shot examples can also effectively improve performance on mental health analysis. In addition, ChatGPT generates explanations that approach human performance, showing its great potential in explainable mental health analysis.",
    "authors": [
        {
            "affiliations": [],
            "name": "Kailai Yang"
        },
        {
            "affiliations": [],
            "name": "Shaoxiong Ji"
        },
        {
            "affiliations": [],
            "name": "Tianlin Zhang"
        },
        {
            "affiliations": [],
            "name": "Qianqian Xie"
        },
        {
            "affiliations": [],
            "name": "Ziyan Kuang"
        },
        {
            "affiliations": [],
            "name": "Sophia Ananiadou"
        }
    ],
    "id": "SP:75437c875dbf6854ed20cfc908aaa8ba92f3ca5e",
    "references": [
        {
            "authors": [
                "Pegah Abed-Esfahani",
                "Derek Howard",
                "Marta Maslej",
                "Sejal Patel",
                "Vamika Mann",
                "Sarah Goegan",
                "Leon French."
            ],
            "title": "Transfer learning for depression: Early detection and severity prediction from social media postings",
            "venue": "CLEF (Working Notes).",
            "year": 2019
        },
        {
            "authors": [
                "Mostafa M Amin",
                "Erik Cambria",
                "Bj\u00f6rn W Schuller."
            ],
            "title": "Will affective computing emerge from foundation models and general ai? a first evaluation on chatgpt",
            "venue": "arXiv preprint arXiv:2303.03186.",
            "year": 2023
        },
        {
            "authors": [
                "Yejin Bang",
                "Samuel Cahyawijaya",
                "Nayeon Lee",
                "Wenliang Dai",
                "Dan Su",
                "Bryan Wilie",
                "Holy Lovenia",
                "Ziwei Ji",
                "Tiezheng Yu",
                "Willy Chung"
            ],
            "title": "A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity",
            "year": 2023
        },
        {
            "authors": [
                "James RA Benoit."
            ],
            "title": "Chatgpt for clinical vignette generation, revision, and evaluation",
            "venue": "medRxiv, pages 2023\u201302.",
            "year": 2023
        },
        {
            "authors": [
                "Adrian Benton",
                "Glen Coppersmith",
                "Mark Dredze."
            ],
            "title": "Ethical research protocols for social media health research",
            "venue": "Proceedings of the first ACL workshop on ethics in natural language processing, pages 94\u2013102.",
            "year": 2017
        },
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are few-shot learners. Advances in neural information processing",
            "year": 2020
        },
        {
            "authors": [
                "Amy Bruckman."
            ],
            "title": "Studying the amateur artist: A perspective on disguising data collected in human subjects research on the internet",
            "venue": "Ethics and Information Technology, 4:217\u2013231.",
            "year": 2002
        },
        {
            "authors": [
                "Carlos Busso",
                "Murtaza Bulut",
                "Chi-Chun Lee",
                "Abe Kazemzadeh",
                "Emily Mower",
                "Samuel Kim",
                "Jeannette N. Chang",
                "Sungbok Lee",
                "Shrikanth S. Narayanan."
            ],
            "title": "IEMOCAP: interactive emotional dyadic motion capture database",
            "venue": "Lang. Resour. Eval-",
            "year": 2008
        },
        {
            "authors": [
                "Xuanting Chen",
                "Junjie Ye",
                "Can Zu",
                "Nuo Xu",
                "Rui Zheng",
                "Minlong Peng",
                "Jie Zhou",
                "Tao Gui",
                "Qi Zhang",
                "Xuanjing Huang"
            ],
            "title": "How robust is gpt-3.5 to predecessors? a comprehensive study on language understanding tasks. arXiv preprint arXiv:2303.00293",
            "year": 2023
        },
        {
            "authors": [
                "Kyunghyun Cho",
                "Bart Merrienboer",
                "Caglar Gulcehre",
                "Fethi Bougares",
                "Holger Schwenk",
                "Yoshua Bengio."
            ],
            "title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation",
            "venue": "EMNLP.",
            "year": 2014
        },
        {
            "authors": [
                "Glen Coppersmith",
                "Mark Dredze",
                "Craig Harman",
                "Kristy Hollingshead",
                "Margaret Mitchell."
            ],
            "title": "Clpsych 2015 shared task: Depression and ptsd on twitter",
            "venue": "Proceedings of the 2nd Workshop on CLPsych, pages 31\u201339.",
            "year": 2015
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Jay DeYoung",
                "Iz Beltagy",
                "Madeleine van Zuylen",
                "Bailey Kuehl",
                "Lucy Wang."
            ],
            "title": "Ms^2: Multidocument summarization of medical studies",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7494\u2013",
            "year": 2021
        },
        {
            "authors": [
                "Joseph L Fleiss",
                "Bruce Levin",
                "Myunghee Cho Paik."
            ],
            "title": "Statistical methods for rates and proportions",
            "venue": "john wiley & sons.",
            "year": 2013
        },
        {
            "authors": [
                "Jinlan Fu",
                "See-Kiong Ng",
                "Zhengbao Jiang",
                "Pengfei Liu."
            ],
            "title": "Gptscore: Evaluate as you desire",
            "venue": "arXiv preprint arXiv:2302.04166.",
            "year": 2023
        },
        {
            "authors": [
                "Tianyu Gao",
                "Xingcheng Yao",
                "Danqi Chen."
            ],
            "title": "SimCSE: Simple contrastive learning of sentence embeddings",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 6894\u20136910, Online and Punta Cana, Do-",
            "year": 2021
        },
        {
            "authors": [
                "Muskan Garg",
                "Chandni Saxena",
                "Sriparna Saha",
                "Veena Krishnan",
                "Ruchi Joshi",
                "Vijay Mago."
            ],
            "title": "CAMS: An Annotated Corpus for Causal Analysis of Mental Health Issues in Social Media Posts",
            "venue": "Proceedings of the Thirteenth Language Resources",
            "year": 2022
        },
        {
            "authors": [
                "Sooji Han",
                "Rui Mao",
                "Erik Cambria."
            ],
            "title": "Hierarchical attention network for explainable depression detection on Twitter aided by metaphor concept mappings",
            "venue": "Proceedings of the 29th International Conference on Computational Linguistics, pages 94\u2013104,",
            "year": 2022
        },
        {
            "authors": [
                "Clayton Hutto",
                "Eric Gilbert."
            ],
            "title": "Vader: A parsimonious rule-based model for sentiment analysis of social media text",
            "venue": "Proceedings of the international AAAI conference on web and social media, volume 8, pages 216\u2013225.",
            "year": 2014
        },
        {
            "authors": [
                "Shaoxiong Ji."
            ],
            "title": "Towards intention understanding in suicidal risk assessment with natural language processing",
            "venue": "Findings of EMNLP, pages 4028\u20134038.",
            "year": 2022
        },
        {
            "authors": [
                "Shaoxiong Ji",
                "Xue Li",
                "Zi Huang",
                "Erik Cambria."
            ],
            "title": "Suicidal ideation and mental disorder detection with attentive relation networks",
            "venue": "Neural Computing and Applications, 34:10309\u201310319.",
            "year": 2022
        },
        {
            "authors": [
                "Shaoxiong Ji",
                "Tianlin Zhang",
                "Luna Ansari",
                "Jie Fu",
                "Prayag Tiwari",
                "Erik Cambria."
            ],
            "title": "Mentalbert: Publicly available pretrained language models for mental healthcare",
            "venue": "Proceedings of the Thirteenth Language Resources and Evaluation Con-",
            "year": 2022
        },
        {
            "authors": [
                "Zhengping Jiang",
                "Sarah Ita Levitan",
                "Jonathan Zomick",
                "Julia Hirschberg."
            ],
            "title": "Detection of mental health from Reddit via deep contextualized representations",
            "venue": "Proceedings of the 11th International Workshop on Health Text Mining and Information",
            "year": 2020
        },
        {
            "authors": [
                "Wenxiang Jiao",
                "Wenxuan Wang",
                "Jen-tse Huang",
                "Xing Wang",
                "Zhaopeng Tu."
            ],
            "title": "Is chatgpt a good translator? a preliminary study",
            "venue": "arXiv preprint arXiv:2301.08745.",
            "year": 2023
        },
        {
            "authors": [
                "Armand Joulin",
                "\u00c9douard Grave",
                "Piotr Bojanowski",
                "Tom\u00e1\u0161 Mikolov."
            ],
            "title": "Bag of tricks for efficient text classification",
            "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers,",
            "year": 2017
        },
        {
            "authors": [
                "John G Keilp",
                "Michael F Grunebaum",
                "Marianne Gorlyn",
                "Simone LeBlanc",
                "Ainsley K Burke",
                "Hanga Galfalvy",
                "Maria A Oquendo",
                "J John Mann."
            ],
            "title": "Suicidal ideation and the subjective aspects of depression",
            "venue": "Journal of affective disorders, 140(1):75\u201381.",
            "year": 2012
        },
        {
            "authors": [
                "Yoon Kim."
            ],
            "title": "Convolutional neural networks for sentence classification",
            "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1746\u20131751, Doha, Qatar. Association for Computational Linguis-",
            "year": 2014
        },
        {
            "authors": [
                "Jan Koco\u0144",
                "Igor Cichecki",
                "Oliwier Kaszyca",
                "Mateusz Kochanek",
                "Dominika Szyd\u0142o",
                "Joanna Baran",
                "Julita Bielaniewicz",
                "Marcin Gruza",
                "Arkadiusz Janz",
                "Kamil Kanclerz"
            ],
            "title": "Chatgpt: Jack of all trades, master of none",
            "venue": "arXiv preprint arXiv:2302.10724",
            "year": 2023
        },
        {
            "authors": [
                "Takeshi Kojima",
                "Shixiang Shane Gu",
                "Machel Reid",
                "Yutaka Matsuo",
                "Yusuke Iwasawa."
            ],
            "title": "Large language models are zero-shot reasoners",
            "venue": "Advances in Neural Information Processing Systems.",
            "year": 2022
        },
        {
            "authors": [
                "Bishal Lamichhane."
            ],
            "title": "Evaluation of chatgpt for nlp-based mental health applications",
            "venue": "arXiv preprint arXiv:2303.15727.",
            "year": 2023
        },
        {
            "authors": [
                "Jiangnan Li",
                "Fandong Meng",
                "Zheng Lin",
                "Rui Liu",
                "Peng Fu",
                "Yanan Cao",
                "Weiping Wang",
                "Jie Zhou."
            ],
            "title": "Neutral utterances are also causes: Enhancing conversational causal emotion entailment with social commonsense knowledge",
            "venue": "Proceedings of the",
            "year": 2022
        },
        {
            "authors": [
                "Yanran Li",
                "Hui Su",
                "Xiaoyu Shen",
                "Wenjie Li",
                "Ziqiang Cao",
                "Shuzi Niu."
            ],
            "title": "DailyDialog: A manually labelled multi-turn dialogue dataset",
            "venue": "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),",
            "year": 2017
        },
        {
            "authors": [
                "Chenhao Lin",
                "Pengwei Hu",
                "Hui Su",
                "Shaochun Li",
                "Jing Mei",
                "Jie Zhou",
                "Henry Leung."
            ],
            "title": "Sensemood: depression detection on social media",
            "venue": "Proceedings of the 2020 international conference on multimedia retrieval, pages 407\u2013411.",
            "year": 2020
        },
        {
            "authors": [
                "Chin-Yew Lin."
            ],
            "title": "Rouge: A package for automatic evaluation of summaries",
            "venue": "Text summarization branches out, pages 74\u201381.",
            "year": 2004
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Zheheng Luo",
                "Qianqian Xie",
                "Sophia Ananiadou."
            ],
            "title": "Chatgpt as a factual inconsistency evaluator for abstractive text summarization",
            "venue": "arXiv preprint arXiv:2303.15621.",
            "year": 2023
        },
        {
            "authors": [
                "Navonil Majumder",
                "Soujanya Poria",
                "Devamanyu Hazarika",
                "Rada Mihalcea",
                "Alexander F. Gelbukh",
                "Erik Cambria."
            ],
            "title": "Dialoguernn: An attentive RNN for emotion detection in conversations",
            "venue": "The Thirty-Third AAAI Conference on Artificial Intelli-",
            "year": 2019
        },
        {
            "authors": [
                "Matthew Louis Mauriello",
                "Thierry Lincoln",
                "Grace Hon",
                "Dorien Simon",
                "Dan Jurafsky",
                "Pablo Paredes."
            ],
            "title": "Sad: A stress annotated dataset for recognizing everyday stressors in sms-like conversational systems",
            "venue": "Extended abstracts of the 2021 CHI",
            "year": 2021
        },
        {
            "authors": [
                "Saif Mohammad",
                "Peter Turney."
            ],
            "title": "Emotions evoked by common words and phrases: Using Mechanical Turk to create an emotion lexicon",
            "venue": "Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation",
            "year": 2010
        },
        {
            "authors": [
                "Saif M. Mohammad",
                "Peter D. Turney."
            ],
            "title": "Crowdsourcing a word-emotion association lexicon",
            "venue": "Computational Intelligence, 29(3):436\u2013465.",
            "year": 2013
        },
        {
            "authors": [
                "Thong Nguyen",
                "Andrew Yates",
                "Ayah Zirikly",
                "Bart Desmet",
                "Arman Cohan."
            ],
            "title": "Improving the generalizability of depression detection by leveraging clinical questionnaires",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Compu-",
            "year": 2022
        },
        {
            "authors": [
                "Jennifer Nicholas",
                "Sandersan Onie",
                "Mark E Larsen."
            ],
            "title": "Ethics and privacy in social media research for mental health",
            "venue": "Current psychiatry reports, 22:1\u20137.",
            "year": 2020
        },
        {
            "authors": [
                "Long Ouyang",
                "Jeffrey Wu",
                "Xu Jiang",
                "Diogo Almeida",
                "Carroll Wainwright",
                "Pamela Mishkin",
                "Chong Zhang",
                "Sandhini Agarwal",
                "Katarina Slama",
                "Alex Ray"
            ],
            "title": "Training language models to follow instructions with human",
            "year": 2022
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311\u2013318.",
            "year": 2002
        },
        {
            "authors": [
                "Inna Pirina",
                "\u00c7a\u011fr\u0131 \u00c7\u00f6ltekin."
            ],
            "title": "Identifying depression on Reddit: The effect of training data",
            "venue": "Proceedings of the 2018 EMNLP Workshop SMM4H: The 3rd Social Media Mining for Health Applications Workshop & Shared Task, pages 9\u201312.",
            "year": 2018
        },
        {
            "authors": [
                "Soujanya Poria",
                "Erik Cambria",
                "Devamanyu Hazarika",
                "Navonil Majumder",
                "Amir Zadeh",
                "Louis-Philippe Morency."
            ],
            "title": "Context-dependent sentiment analysis in user-generated videos",
            "venue": "Proceedings of the 55th Annual Meeting of the Association for Compu-",
            "year": 2017
        },
        {
            "authors": [
                "Soujanya Poria",
                "Devamanyu Hazarika",
                "Navonil Majumder",
                "Gautam Naik",
                "Erik Cambria",
                "Rada Mihalcea"
            ],
            "title": "MELD: A multimodal multi-party",
            "year": 2019
        },
        {
            "authors": [
                "Soujanya Poria",
                "Navonil Majumder",
                "Devamanyu Hazarika",
                "Deepanway Ghosal",
                "Rishabh Bhardwaj",
                "Samson Yu Bai Jian",
                "Pengfei Hong",
                "Romila Ghosh",
                "Abhinaba Roy",
                "Niyati Chhaya",
                "Alexander F. Gelbukh",
                "Rada Mihalcea"
            ],
            "title": "Recognizing emotion",
            "year": 2021
        },
        {
            "authors": [
                "Soujanya Poria",
                "Navonil Majumder",
                "Rada Mihalcea",
                "Eduard H. Hovy."
            ],
            "title": "Emotion recognition in conversation: Research challenges, datasets, and recent advances",
            "venue": "IEEE Access, 7:100943\u2013100953.",
            "year": 2019
        },
        {
            "authors": [
                "Cornelius Puschman"
            ],
            "title": "Bad judgment, bad ethics? Internet Research Ethics for the Social Age",
            "year": 2017
        },
        {
            "authors": [
                "Chengwei Qin",
                "Aston Zhang",
                "Zhuosheng Zhang",
                "Jiaao Chen",
                "Michihiro Yasunaga",
                "Diyi Yang"
            ],
            "title": "Is chatgpt a general-purpose natural language processing task solver? arXiv preprint arXiv:2302.06476",
            "year": 2023
        },
        {
            "authors": [
                "Mariana Rodrigues Makiuchi",
                "Tifani Warnita",
                "Kuniaki Uto",
                "Koichi Shinoda."
            ],
            "title": "Multimodal fusion of bert-cnn and gated cnn representations for depression detection",
            "venue": "Proceedings of the 9th International on Audio/Visual Emotion Challenge and",
            "year": 2019
        },
        {
            "authors": [
                "Weizhou Shen",
                "Junqing Chen",
                "Xiaojun Quan",
                "Zhixian Xie."
            ],
            "title": "Dialogxl: All-in-one xlnet for multiparty conversation emotion recognition",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 13789\u201313797.",
            "year": 2021
        },
        {
            "authors": [
                "Weizhou Shen",
                "Siyue Wu",
                "Yunyi Yang",
                "Xiaojun Quan."
            ],
            "title": "Directed acyclic graph network for conversational emotion recognition",
            "venue": "ACL, pages 1551\u20131560. Association for Computational Linguistics.",
            "year": 2021
        },
        {
            "authors": [
                "Xiaohui Song",
                "Longtao Huang",
                "Hui Xue",
                "Songlin Hu."
            ],
            "title": "Supervised prototypical contrastive learning for emotion recognition in conversation",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 5197\u2013",
            "year": 2022
        },
        {
            "authors": [
                "Nisan Stiennon",
                "Long Ouyang",
                "Jeffrey Wu",
                "Daniel Ziegler",
                "Ryan Lowe",
                "Chelsea Voss",
                "Alec Radford",
                "Dario Amodei",
                "Paul F Christiano."
            ],
            "title": "Learning to summarize with human feedback",
            "venue": "Advances in Neural Information Processing Systems, 33:3008\u2013",
            "year": 2020
        },
        {
            "authors": [
                "Ermal Toto",
                "ML Tlachac",
                "Elke A Rundensteiner."
            ],
            "title": "Audibert: A deep transfer learning multimodal classification framework for depression screening",
            "venue": "Proceedings of the 30th ACM international conference on information & knowledge management,",
            "year": 2021
        },
        {
            "authors": [
                "Hugo Touvron",
                "Thibaut Lavril",
                "Gautier Izacard",
                "Xavier Martinet",
                "Marie-Anne Lachaux",
                "Timoth\u00e9e Lacroix",
                "Baptiste Rozi\u00e8re",
                "Naman Goyal",
                "Eric Hambro",
                "Faisal Azhar"
            ],
            "title": "Llama: Open and efficient foundation language models",
            "year": 2023
        },
        {
            "authors": [
                "Elsbeth Turcan",
                "Kathleen McKeown."
            ],
            "title": "Dreaddit: A Reddit Dataset for Stress Analysis in Social Media",
            "venue": "Proceedings of the Tenth International Workshop on Health Text Mining and Information Analysis (LOUHI 2019), pages 97\u2013107.",
            "year": 2019
        },
        {
            "authors": [
                "Byron C Wallace",
                "Sayantan Saha",
                "Frank Soboczenski",
                "Iain J Marshall."
            ],
            "title": "Generating (factual?) narrative summaries of rcts: Experiments with neural multi-document summarization",
            "venue": "AMIA Summits on Translational Science Proceedings, 2021:605.",
            "year": 2021
        },
        {
            "authors": [
                "Jason Wei",
                "Xuezhi Wang",
                "Dale Schuurmans",
                "Maarten Bosma",
                "Ed Chi",
                "Quoc Le",
                "Denny Zhou."
            ],
            "title": "Chain of thought prompting elicits reasoning in large language models",
            "venue": "arXiv preprint arXiv:2201.11903.",
            "year": 2022
        },
        {
            "authors": [
                "Penghui Wei",
                "Jiahao Zhao",
                "Wenji Mao."
            ],
            "title": "Effective inter-clause modeling for end-to-end emotioncause pair extraction",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3171\u20133181, Online. Association",
            "year": 2020
        },
        {
            "authors": [
                "Yunhe Xie",
                "Kailai Yang",
                "Chengjie Sun",
                "Bingquan Liu",
                "Zhenzhou Ji."
            ],
            "title": "Knowledge-interactive network with sentiment polarity intensity-aware multitask learning for emotion recognition in conversations",
            "venue": "Findings of the Association for Computa-",
            "year": 2021
        },
        {
            "authors": [
                "Kailai Yang",
                "Tianlin Zhang",
                "Hassan Alhuzali",
                "Sophia Ananiadou."
            ],
            "title": "Cluster-level contrastive learning for emotion recognition in conversations",
            "venue": "IEEE Transactions on Affective Computing, pages 1\u201312.",
            "year": 2023
        },
        {
            "authors": [
                "Kailai Yang",
                "Tianlin Zhang",
                "Sophia Ananiadou."
            ],
            "title": "A mental state knowledge\u2013aware and contrastive network for early stress and depression detection on social media",
            "venue": "Information Processing & Management, 59(4):102961.",
            "year": 2022
        },
        {
            "authors": [
                "Zhilin Yang",
                "Zihang Dai",
                "Yiming Yang",
                "Jaime Carbonell",
                "Russ R Salakhutdinov",
                "Quoc V Le."
            ],
            "title": "Xlnet: Generalized autoregressive pretraining for language understanding",
            "venue": "Advances in neural information processing systems, 32.",
            "year": 2019
        },
        {
            "authors": [
                "Junjie Ye",
                "Xuanting Chen",
                "Nuo Xu",
                "Can Zu",
                "Zekai Shao",
                "Shichun Liu",
                "Yuhan Cui",
                "Zeyang Zhou",
                "Chao Gong",
                "Yang Shen"
            ],
            "title": "A comprehensive capability analysis of gpt-3 and gpt-3.5 series models. arXiv preprint arXiv:2303.10420",
            "year": 2023
        },
        {
            "authors": [
                "Chenhan Yuan",
                "Qianqian Xie",
                "Sophia Ananiadou."
            ],
            "title": "Zero-shot temporal relation extraction with chatgpt",
            "venue": "arXiv preprint arXiv:2304.05454.",
            "year": 2023
        },
        {
            "authors": [
                "Weizhe Yuan",
                "Graham Neubig",
                "Pengfei Liu."
            ],
            "title": "Bartscore: Evaluating generated text as text generation",
            "venue": "Advances in Neural Information Processing Systems, 34:27263\u201327277.",
            "year": 2021
        },
        {
            "authors": [
                "Sayyed M Zahiri",
                "Jinho D Choi."
            ],
            "title": "Emotion detection on tv show transcripts with sequencebased convolutional neural networks",
            "venue": "arXiv preprint arXiv:1708.04299.",
            "year": 2017
        },
        {
            "authors": [
                "Tianlin Zhang",
                "Annika M Schoene",
                "Shaoxiong Ji",
                "Sophia Ananiadou."
            ],
            "title": "Natural language processing applied to mental illness detection: a narrative review",
            "venue": "NPJ digital medicine, 5(1):46.",
            "year": 2022
        },
        {
            "authors": [
                "Tianlin Zhang",
                "Kailai Yang",
                "Shaoxiong Ji",
                "Sophia Ananiadou."
            ],
            "title": "Emotion fusion for mental illness detection from social media: A survey",
            "venue": "Information Fusion, 92:231\u2013246.",
            "year": 2023
        },
        {
            "authors": [
                "Tianyi Zhang",
                "Varsha Kishore",
                "Felix Wu",
                "Kilian Q. Weinberger",
                "Yoav Artzi."
            ],
            "title": "Bertscore: Evaluating text generation with BERT",
            "venue": "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenRe-",
            "year": 2020
        },
        {
            "authors": [
                "Zhiling Zhang",
                "Siyuan Chen",
                "Mengyue Wu",
                "Kenny Q. Zhu."
            ],
            "title": "Psychiatric scale guided risky post screening for early detection of depression",
            "venue": "Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI 2022,",
            "year": 2022
        },
        {
            "authors": [
                "Weixiang Zhao",
                "Yanyan Zhao",
                "Zhuojun Li",
                "Bing Qin."
            ],
            "title": "Knowledge-bridged causal interaction network for causal emotion entailment",
            "venue": "arXiv preprint arXiv:2212.02995.",
            "year": 2022
        },
        {
            "authors": [
                "Peixiang Zhong",
                "Di Wang",
                "Chunyan Miao."
            ],
            "title": "Knowledge-enriched transformer for emotion detection in textual conversations",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th Interna-",
            "year": 2019
        },
        {
            "authors": [
                "Qihuang Zhong",
                "Liang Ding",
                "Juhua Liu",
                "Bo Du",
                "Dacheng Tao."
            ],
            "title": "Can chatgpt understand too? a comparative study on chatgpt and fine-tuned bert",
            "venue": "arXiv preprint arXiv:2302.10198.",
            "year": 2023
        },
        {
            "authors": [
                "Chunting Zhou",
                "Chonglin Sun",
                "Zhiyuan Liu",
                "Francis Lau."
            ],
            "title": "A c-lstm neural network for text classification",
            "venue": "arXiv preprint arXiv:1511.08630.",
            "year": 2015
        },
        {
            "authors": [
                "Peng Zhou",
                "Wei Shi",
                "Jun Tian",
                "Zhenyu Qi",
                "Bingchen Li",
                "Hongwei Hao",
                "Bo Xu."
            ],
            "title": "Attention-based bidirectional long short-term memory networks for relation classification",
            "venue": "Proceedings of the 54th annual meeting of the association for computational",
            "year": 2016
        },
        {
            "authors": [
                "tection. Ji"
            ],
            "title": "2022b) released two PLMs",
            "year": 2022
        },
        {
            "authors": [
                "Toto"
            ],
            "title": "2021) proposed the multi-modal method",
            "year": 2021
        },
        {
            "authors": [
                "sis. Lamichhane"
            ],
            "title": "2023) evaluated the performance of ChatGPT on three mental health classification tasks, including stress, depression, and suicidality detection, and proved the good potential of ChatGPT for applications of mental health",
            "year": 2023
        },
        {
            "authors": [
                "2023 Zhong et al",
                "2023 Koco\u0144 et al",
                "Chen"
            ],
            "title": "2023) on the sentiment classification task, where ChatGPT achieves comparable or worse performance compared with fine-tuning based methods based on PLMs",
            "year": 2023
        },
        {
            "authors": [
                "hiri",
                "Choi"
            ],
            "title": "DailyDialog (Li et al., 2017). For CEE, we select the dataset RECCON (Poria et al., 2021). More information about these datasets is listed in Table 7 in the appendix. Baseline Models We compare the performance",
            "year": 2017
        },
        {
            "authors": [
                "Song"
            ],
            "title": "2022). generalizability can make up for the lack of taskspecific model architectures to some extent. On the MELD dataset, ChatGPTZS achieves 61.18",
            "year": 2022
        },
        {
            "authors": [
                "\u2022 DialogueRNN (Majumder"
            ],
            "title": "2019) used a text-CNN to extract utterance-level features, then use a separate GRU to model each participant\u2019s mental states. A global-state GRU is used to model the context",
            "year": 2019
        },
        {
            "authors": [
                "\u2022 BERT/RoBERTa (Devlin et al",
                "Liu"
            ],
            "title": "2019) utilized the PLMs BERT and RoBERTa to model the post and fine-tuned them for classification",
            "year": 2019
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "WARNING: This paper contains examples and descriptions that are depressive in nature.\nMental health conditions such as depression and suicidal ideation seriously challenge global\n\u2217 Equal contribution, listed alphabetically. \u2020 Corresponding author. Qianqian is now affiliated with Yale University. The work was done when she was at The University of Manchester.\n1The data is released at https://github.com/ SteveKGYang/MentalLLaMA\nhealth care (Zhang et al., 2022a). NLP researchers have devoted much effort to automatic mental health analysis, with current mainstream methods leveraging the Pre-trained Language Models (PLMs) (Yang et al., 2022; Abed-Esfahani et al., 2019). Most recently Large Language Models (LLMs) (Brown et al., 2020; Ouyang et al., 2022), especially ChatGPT 2 and GPT-4 (OpenAI, 2023), have exhibited strong general language processing ability (Wei et al., 2022; Luo et al., 2023; Yuan et al., 2023). In mental health analysis, Lamichhane (2023) evaluated ChatGPT on stress, depression, and suicide detection and glimpsed its strong language understanding ability to mental healthrelated texts. Amin et al. (2023) compared the zeroshot performance of ChatGPT on suicide and depression detection with previous fine-tuning-based methods.\nThough previous works depict a promising future for a new LLM-based paradigm in mental health analysis, several issues remain unresolved. Firstly, mental health condition detection is a safecritical task requiring careful evaluation and high transparency for any predictions (Zhang et al., 2022a), while these works simply tested on a few binary mental health condition detection tasks and lack the explainability on detection results. Moreover, other important mental health analysis tasks, such as the cause/factor detection of mental health conditions (Mauriello et al., 2021; Garg et al., 2022), were ignored. Secondly, previous works mostly use simple prompts to detect mental health conditions directly. These vanilla methods ignore useful information, especially emotional cues, which are widely utilized for mental health analysis in previous works (Zhang et al., 2023). We believe it requires a comprehensive exploration and evaluation of the ability and explainability of LLMs on mental health analysis, including mental health detection, emotional reasoning, and cause detection\n2https://openai.com/blog/chatgpt\nof mental health conditions. Therefore, we raise the following three research questions (RQ):\n\u2022 RQ 1: How well can LLMs perform in generalized mental health analysis and emotional reasoning with zero-shot/few-shot settings?\n\u2022 RQ 2: How do different prompting strategies and emotional cues impact the mental health analysis ability of ChatGPT?\n\u2022 RQ 3: How well can ChatGPT generate explanations for its decisions on mental health analysis?\nTo respond to these research questions, we first conduct a preliminary study of how LLMs perform on mental health analysis and emotional reasoning. We evaluate four LLMs with varying model sizes including ChatGPT, InstructGPT-3 (Ouyang et al., 2022), LLaMA-13B, and LLaMA-7B (Touvron et al., 2023), on 11 datasets across 5 tasks including binary/multi-class mental health condition detection, cause/factor detection of mental health conditions, emotion recognition in conversations, and causal emotion entailment. We then delve into the effectiveness of different prompting strategies on mental health analysis, including zero-shot prompting, Chain-of-Thought (CoT) prompting (Kojima et al., 2022), emotion-enhanced prompting, and few-shot emotion-enhanced prompting. Finally, we explore how LLMs perform for interpretable mental health analysis, where we instruct two representative LLMs: ChatGPT and InstructGPT-3,\nto generate natural language explanations for each of its results on mental health analysis. To assess the quality of LLMs-generated explanations, we perform human evaluations by following a strict annotation protocol designed by domain experts, and thus create the novel dataset with 163 humanassessed explanations of posts from LLMs, aimed at facilitating the investigating of explainable mental health analysis methods and automatic evaluation metrics. We benchmark numerous existing automatic evaluation metrics on the corpus to guide future research on automatically evaluating explainable mental health analysis. We conclude our findings as follows:\n1) Overall Performance. ChatGPT achieves the best performance among all examined LLMs, although it still significantly underperforms advanced supervised methods, highlighting the challenges of emotion-related subjective tasks.\n2) Prompting Strategies. While a simple CoT trigger sentence is ineffective for mental health analysis, ChatGPT with unsupervised emotionenhanced CoT prompts achieves the best performance, showing the importance of prompt engineering in leveraging emotional cues for mental health analysis. Few-shot learning from expertwritten examples also significantly improves model performance.\n3) Explainability. ChatGPT can generate approaching-human explanations for its classifications, indicating its potential to enhance the trans-\nparency of mental health analysis. Current best automatic evaluation metrics can moderately correlate with human evaluations, indicating the need for developing customized automatic evaluation methods in explainable mental health analysis.\n4) Limitations. Although its great potential, ChatGPT bears limitations on inaccurate reasoning and unstable predictions caused by its excessive sensitivity to minor alterations in prompts, inspiring future directions on improving ChatGPT and prompts. Unstable prediction problems can be mitigated by few-shot learning.\nOur contributions can be summarized as follows: 1) We evaluate four representative LLMs on mental health analysis, 2) We investigate the effectiveness of prompting strategies including CoT, emotionenhanced prompts, and few-shot learning for mental health analysis, 3) We explore LLMs for explainable mental health analysis, and conduct human and automatic evaluations on LLMs-generated explanations, 4) We create the first evaluation dataset with LLMs-generated explanations rigorously assessed by domain experts, for examining and developing of automatic evaluation metrics, 5) We analyze the potential and limitations of LLMs and different prompting strategies for mental health analysis."
        },
        {
            "heading": "2 Methodology",
            "text": "This section introduces the details of evaluated LLMs and different prompting strategies for improving LLMs\u2019 efficiency and explainability in mental health analysis. Due to the page limits, all evaluations, experiments, and analyses on emotional reasoning are presented in Appendix B. We also perform human evaluations on the quality of LLM-generated explanations and benchmark existing automatic evaluation metrics on the human evaluation results, where an example is shown in Figure 1."
        },
        {
            "heading": "2.1 Large Language Models",
            "text": "We benchmark the following powerful LLMs for the zero-shot mental health analysis:\n1) LLaMA-7B/13B. LLaMA (Touvron et al., 2023) is a set of open-source LLMs developed by Meta AI, which are generatively pre-trained on entirely publicly available datasets. We test the zero-shot mental health analysis tasks on LLaMA models with 7 billion (LLaMA-7B) and 13 billion (LLaMA-13B) parameters.\n2) InstructGPT-3. InstructGPT-3 continually trains GPT-3 (Brown et al., 2020) with instruction tuning (Ouyang et al., 2022), which enables the model to solve tasks in a question-answering format. We utilize curie-instruct-beta version (13 billion parameters) in our experiments.\n3) ChatGPT. ChatGPT (gpt-3.5-turbo) is trained based on the 175 billion parameters version of InstructGPT (Ouyang et al., 2022) and continually optimized through reinforcement learning from human feedback (RLHF) (Stiennon et al., 2020)."
        },
        {
            "heading": "2.2 In-context Learning as Explainable Mental Health Analyzer",
            "text": "In-context learning (Brown et al., 2020) elicits the powerful ability of LLMs given the information provided in the context without explicit updates of model parameters. We instruct LLMs with taskspecific instructions to trigger their ability as the zero-shot analyzer for different mental health analysis tasks. We systematically explore three different prompting strategies for mental health analysis, i.e., straightforward zero-shot prompting with natural language query, emotion-enhanced Chainof-Thought (CoT) (Wei et al., 2022), and distantly supervised emotion-enhanced instructions. The straightforward zero-shot prompting guides four LLMs by asking for a classification result from their responses. For example, for binary mental health condition detection, we design the following prompt:\nPost: \"[Post]\". Consider this post to answer the question: Is the poster likely to suffer from very severe [Condition]? Only return Yes or No.\nEmotion-enhanced Prompts Moreover, we design three emotion-enhanced prompting strategies to better instruct ChatGPT to conduct explainable mental health analysis: 1) Emotion-enhanced CoT prompting. We perform emotion infusion by designing unsupervised emotion-enhanced zeroshot CoT prompts, where the emotion-related part inspires the LLM to concentrate on the emotional clues from the post, and the CoT part guides the LLM to generate step-by-step explanations for its decision. This improves the explainability of LLMs\u2019 performance. For example, for the binary detection task, we modify the zero-shot prompt as follows:\nPost: \"[Post]\". Consider the emotions expressed from this post to answer the question:\nIs the poster likely to suffer from very severe [Condition]? Only return Yes or No, then explain your reasoning step by step.\n2) Supervised emotion-enhanced prompting. In addition, we propose a distantly supervised emotion fusion method by using sentiment and emotion lexicons. We utilize the VADER (Hutto and Gilbert, 2014) and NRC EmoLex (Mohammad and Turney, 2010, 2013) lexicons to assign a sentiment/emotion score to each post and convert the score to sentiment/emotion labels. Then we design emotion-enhanced prompts by adding the sentiment/emotion labels to the proper positions of the zero-shot prompt. 3) Few-shot Emotionenhanced Prompts. We further evaluate the impact of few-shot examples on emotion-enhanced prompts. We invite domain experts (Ph.D. students majoring in quantitative psychology) to write one response example for each label class within a test set, where all responses consist of a prediction and an explanation describing the rationale behind the decision. We then include these examples in the emotion-enhanced prompts to enable in-context learning of the models. For example, for the binary detection task, we modify the original emotionenhanced prompt to combine N expert-written explanations in a unified manner:\nYou will be presented with a post. Consider the emotions expressed in this post to identify whether the poster suffers from [condition]. Only return Yes or No, then explain your reasoning step by step. Here are N examples: Post: [example 1] Response: [response 1] ... Post: [example N] Response: [response N]\nPost: [Post] Response:\nTask-specific Instructions We conduct broad tests of LLMs\u2019 mental health analysis ability on the following three tasks: binary mental health condition detection, multi-class mental health condition detection, and cause/factor detection of mental health conditions. Binary mental health condition detection is modeled as a yes/no classification of the mental health condition, such as depression and stress from a post. In contrast, multi-class detection identifies one label from multiple mental health conditions. Cause/factor detection aims at\nrecognizing one potential cause of a mental health condition from multiple causes. More details about the prompt design and examples of the prompts are presented in Appendix C.2."
        },
        {
            "heading": "2.3 Evaluation for Explainability",
            "text": "Human Evaluation We examine the quality of the generated explanations by two representative LLMs: ChatGPT and InstructGPT-3, with human evaluations on the binary mental health conditions detection task. We utilize ChatGPT and InstructGPT-3 to simultaneously generate explanations for the same posts with the same emotionenhanced CoT prompts. The annotation protocol is developed through collaborative efforts with 2 domain experts (Ph.D. students majoring in quantitative psychology) and considerations of human evaluation criteria for other text generation tasks (Wallace et al., 2021; DeYoung et al., 2021). Specifically, four key aspects are assessed: 1) Fluency: the coherence and readability of the explanation. 2) Reliability: the trustworthiness of the generated explanations to support the prediction results. 3) Completeness: how well the generated explanations cover all relevant aspects of the original post. 4) Overall: the general effectiveness of the generated explanation.\nEach aspect is divided into four standards rating from 0 to 3. Higher ratings reflect more satisfactory performance and 3 denotes approaching human performance. Each LLM-generated explanation is assigned a score by 3 annotators for each corresponding aspect, followed by the examination of 1 domain expert. All annotators are PhD students with high fluency in English. We evaluate 121 posts that are correctly classified by both ChatGPT (ChatGPTtrue) and InstructGPT-3 to enable fair comparisons. 42 posts that are incorrectly classified by ChatGPT (ChatGPTfalse) are also collected for error analysis and examination of the automatic evaluation metrics. We will release the annotated corpus for facilitating future research. Details of the criteria are described in Appendix E.\nAutomatic Evaluation Though human evaluations provide an accurate and comprehensive view of the generated explanations\u2019 quality, they require huge human efforts, making it hard to be extended to large-scale datasets. Therefore, we explore utilizing automatic evaluation metrics, originally developed for generation tasks such as text summarization, to benchmark the evaluation on\nour annotated corpus. We rely on the ability of the evaluation models to score the fluency, reliability, and completeness of the explanations. We select the following widely utilized metrics to automatically evaluate LLM-generated explanations: BLEU (Papineni et al., 2002), ROUGE-1, ROUGE2, ROUGE-L (Lin, 2004), GPT3-Score (Fu et al., 2023) (davinci-003), and BART-Score (Yuan et al., 2021). We also use the BERT-score-based (Zhang et al., 2020) methods with different PLMs, including the domain-specific PLMs MentalBERT and MentalRoBERTa (Ji et al., 2022b), except for BERT and RoBERTa."
        },
        {
            "heading": "3 Experimental Settings",
            "text": "Mental Health Analysis Firstly, we introduce the benchmark datasets, baseline models, and automatic evaluation metrics for the classification results of mental health analysis.\nDatasets. For binary mental health condition detection, we select two depression detection datasets Depression_Reddit (DR) (Pirina and \u00c7\u00f6ltekin, 2018), CLPsych15 (Coppersmith et al., 2015), and another stress detection dataset Dreaddit (Turcan and McKeown, 2019). For multi-class mental health condition detection, we utilize the dataset T-SID (Ji et al., 2022a). For cause/factor detection of mental health conditions, we use a stress cause detection dataset called SAD (Mauriello et al., 2021) and a depression/suicide cause detection dataset CAMS (Garg et al., 2022). More details of these datasets are presented in Table 8 in the appendix.\nBaseline Models. We select the following baseline models: CNN (Kim, 2014), GRU (Cho et al., 2014), BiLSTM_Att (Zhou et al., 2016), fastText (Joulin et al., 2017), BERT/RoBERTa (Devlin et al., 2019; Liu et al., 2019), and MentalBERT/MentalRoBERTa (Ji et al., 2022b). Details about these baseline models are in Appendix D.2.\nMetrics. We evaluate the model performance using the recall and weighted-F1 scores as the evaluation metric for all mental health datasets. Due to imbalanced classes in some datasets such as DR, CLPsych15, and T-SID, we use weighted-F1 scores following previous methods. In addition, it is crucial to minimize false negatives, which refers to cases where the model fails to identify individuals with mental disorders. Therefore, we also report the recall scores.\nEvaluation for Explainability For the human evaluation results, we evaluate the quality of the annotations by calculating the inter-evaluator agreement: Fleiss\u2019 Kappa statistics (Fleiss et al., 2013) for each aspect. Any annotations with a majority vote are considered as reaching an agreement. To compare the automatic evaluation methods, we also compute Pearson\u2019s correlation coefficients between the automatic evaluation results and the human evaluation results, where higher values reflect more linear correlations between the two sets of data."
        },
        {
            "heading": "4 Results and Analysis",
            "text": "We conduct all LLaMA experiments on a single Nvidia Tesla A100 GPU with 80GB of memory. InstructGPT-3 and ChatGPT results are obtained via the OpenAI API. Each prompt is fed independently to avoid the effects of dialogue history."
        },
        {
            "heading": "4.1 Mental Health Analysis",
            "text": "The experimental results of mental health analysis are presented in Table 1. We first compare the zero-shot results of LLMs to gain a straight view of their potential in mental health analysis, then analyze ChatGPT\u2019s performance with other prompts enhanced by emotional information.\nZero-shot Prompting. In the comparison of LLMs, ChatGPT significantly outperforms LLaMA-7B/13B and InstructGPT-3 on all datasets. LLaMA-7BZS displays random-guessing performance on multi-class detection (T-SID) and cause detection (SAD, CAMS), showing its inability to perform these more complex tasks. With an expanded model size, LLaMA-13BZS achieves no better performance than LLaMA-7B. Though trained with instruction tuning, InstructGPT-3ZS still does not improve performance, possibly because the model size limits the LLM\u2019s learning ability. Compared with supervised methods, ChatGPTZS significantly outperforms traditional light-weighted neural network-based methods such as CNN and GRU on binary detection and cause/factor detection, showing its potential in cause analysis for mental health-related texts. However, ChatGPTZS struggles to achieve comparable performance to fine-tuning methods such as MentalBERT and MentalRoBERTa. Particularly, ChatGPTZS achieves much worse performance than all baselines on T-SID. We notice that T-SID collects mostly short posts from Twitter with many\nusernames, hashtags, and slang words. The huge gap between the posts and ChatGPT\u2019s training data can make zero-shot detection difficult (Kocon\u0301 et al., 2023). Moreover, although the zero-shot CoT prompting is proven to be effective on most NLP tasks (Zhong et al., 2023; Wei et al., 2022; Kojima et al., 2022), we surprisingly find that ChatGPTCoT has a comparable or even worse performance with ChatGPTZS . This illustrates that the simple CoT trigger sentence is not effective in mental health analysis. Overall, ChatGPT significantly outperforms other LLMs, and exhibited some generalized ability for mental health analysis. However, it still underperforms fine-tuning-based methods, leaving a huge gap in further exploring LLMs\u2019 mental health analysis ability.\nEmotion-enhanced Prompting. We further test ChatGPT with emotion-enhanced prompts on all datasets. Firstly, with the sentiment information from the lexicon VADER and NRC EmoLex, we notice that ChatGPTV and ChatGPTN_sen perform worse than ChatGPTZS on most datasets, showing that these prompts are not effective in enhancing model performance. A possible reason is that the coarse-grained sentiment classifications based on the two lexicons cannot describe complex emotions\nexpressed in the posts. Therefore, we incorporate fine-grained emotion labels from NRC EmoLex into the zero-shot prompt. The results show that ChatGPTN_emo outperforms ChatGPTN_sen on most datasets, especially on CAMS (a 7.89% improvement). However, ChatGPTN_emo still underperforms ChatGPTZS on most datasets, possibly because lexicon-based emotion labels are still not accurate in representing multiple emotions that co-exist in a post, especially in datasets with rich content, such as CLPsych15 and DR. Therefore, we explore the more flexible unsupervised emotion-enhanced prompts with CoT. As a result, ChatGPTCoT_emo outperforms all other zero-shot methods on most datasets, which proves that emotion-enhanced CoT prompting is effective for mental health analysis. Finally, with few-shot expert-written examples, ChatGPTCoT_emo_FS significantly outperforms all zero-shot methods on all datasets, especially in complex-task datasets: t-sid 16.24% improvement, SAD 6.88% improvement, and CAMS 3.7% improvement (very approaching state-of-the-art supervised method). These encouraging results show that in-context learning is effective in calibrating LLM\u2019s decision boundaries for complex and subjective tasks in mental health analysis. We provide case studies in Appendix F.1."
        },
        {
            "heading": "4.2 Evaluation Results for Explainability",
            "text": "Human Evaluation In the above subsection, we have shown that emotion-enhanced CoT prompts can enhance ChatGPT\u2019s zero-shot performance in mental health analysis. Moreover, it can prompt LLMs to provide an explanation of their step-bystep reasoning for each response. This can significantly improve the explainability of the predictions, which is a key advantage compared with most previous black-box methods. In this subsection, we provide carefully designed human evaluations to gain a clear view of LLMs\u2019 (ChatGPT and InstructGPT-3) explainability on their detection results.\nThe Fleiss\u2019 Kappa results and agreement percentages are presented in Table 2. We aggregate each score by averaging assignments from three annotators, and the distributions are presented in Figure 2. Firstly, the three annotators reach high agreements on evaluation. Over 95% of ChatGPT evaluations and 89.9% of InstructGPT-3 results reach agreement. According to the widely utilized interpretation criterion 3, all Fleiss\u2019 Kappa statistics achieve at least fair agreement (\u22650.21) and 10 out of 16 results reach at least moderate agreement (\u22650.41). These outcomes prove the quality of the human annotations.\nAs shown in Figure 2, ChatGPTtrue almost achieves an average score of 3.0 in fluency and stably maintains outstanding performance, while\n3https://en.wikipedia.org/wiki/Fleiss%27_kappa\nInstructGPT-3 achieves much worse performance in fluency with a 0 median score and an average score of less than 1.0. These results prove ChatGPT is a fluent explanation generator for mental health analysis. In reliability, ChatGPTtrue achieves a median score of 3 and over 2.7 in average score, showing ChatGPT as a trustworthy reasoner in supporting its classifications. Only a few of InstructGPT3\u2019s explanations generate moderately reliable information while most of them are unreliable. For completeness, ChatGPTtrue obtains over 2.5 scores on average, indicating that ChatGPT can cover most of the relevant content in the posts to explain its classifications, while InstructGPT-3 ignores key aspects by obtaining less than 0.5 on average. Overall, ChatGPTtrue has an average score of over 2.5, proving that ChatGPT can generate human-level explanations for correct classifications regarding fluency, reliability, and completeness and significantly outperforms previous LLMs such as InstructGPT-3. More cases are in Appendix F.2.\nAutomatic Evaluation The automatic evaluation results on the ChatGPT explanations are presented in Table 3. In ChatGPTtrue, BART-Score achieves the highest correlation scores on all aspects, showing its potential in performing human-like evaluations for explainable mental health analysis. Specifically, BART-Score outperforms all BERT-Scorebased methods, which shows that generative models can be more beneficial in evaluating natural\nlanguage texts. Unexpectedly, BART-Score also significantly outperforms GPT3-Score, a zero-shot evaluation method based on the powerful LLM GPT-3, in all aspects. These results show that task-specific pre-training is important to trigger the language model\u2019s ability for the evaluation tasks. BART-score is also fine-tuned on text summarization and paraphrasing tasks, which are crucial to assess relevance and coherence, the two important factors for providing satisfactory evaluations. However, in ChatGPTfalse, BART-Score becomes less competitive. BERT-Score achieves the best performances on fluency and reliability, and ROUGE methods outperform others on completeness and overall. A possible reason is that BERT-based methods can better distinguish false semantics in the explanations than BART. With longer posts in ChatGPTfalse (Table 2), the matching-based method ROUGE can more accurately detect the uncovered aspects in the posts, and completeness can play a more important role in determining overall performance in falsely classified samples. In BERT-Score-based methods, MentalBERT and MentalRoBERTa significantly outperform BERT and RoBERTa in most aspects, showing that pretraining on large-scale mental health texts can also benefit automatic evaluation performances of language models. More experiments on InstructGPT-3 results are presented in Appendix G."
        },
        {
            "heading": "4.3 Error Analysis",
            "text": "We further analyze some typical errors during our experiments to inspire future efforts of improving ChatGPT and emotion-enhanced prompts for mental health analysis.\nUnstable Predictions. We notice that ChatGPT\u2019s performance on mental health analysis can vary drastically with the change of a few keywords in"
        },
        {
            "heading": "Zero-shot prompts",
            "text": ""
        },
        {
            "heading": "Few-shot prompts",
            "text": "the prompt, especially on binary mental health condition detection. While keywords describing the tasks are easy to control, some other words such as adjectives, are hard to optimize. For example, we replace the adjective describing the mental health condition with different degrees in the zero-shot prompt for binary mental health detection:\n...Is the poster likely to suffer from [Adjective of Degree] [Condition]?...\nwhere the adjective (marked red) is replaced with one keyword from {any, some, very severe}, and the results on three binary detection datasets are shown in Table 4. As shown, ChatGPTZS shows very unstable performance on all three datasets, with a high variance of 10.6 on DR, 17.62 on CLPsysch15, and 89.29 on Dreaddit. There are also no global optimal adjectives as the best adjective changes with the datasets. This sensitivity makes ChatGPT\u2019s performance very unstable even with slightly different prompts. We believe this problem is due to the subjective nature of mental health conditions. The human annotations only answer\nYes/No for each post, which makes the human criteria of predictions hard to learn for ChatGPT in a zero-shot setting. To alleviate this problem, we further explore the effectiveness of few-shot prompts in these settings, where the same expert-written few-shot examples in Sec. 2.2 are included in the zero-shot prompts. As the results in Table 4 show, with few-shot prompts, ChatGPT achieves a variance of 1.34 on DR, 7.21 on CLPsych15, and 31.93 on Dreaddit, which are all significantly lower than those of zero-shot prompts. These results prove that expert-written examples can stabilize ChatGPT\u2019s predictions, because they can provide accurate references for the subjective mental health detection and cause detection tasks. The few-shot solution is also efficient as it instructs the model in an in-context learning manner, which doesn\u2019t require high-cost model fine-tuning.\nInaccurate Reasoning. Though ChatGPT is proven capable of generating explanations for its classifications, there are still many cases showing its inaccurate reasoning leading to incorrect results. To investigate the contributing factors behind these mistakes, we further compare the human evaluation results between the correctly and incorrectly classified results ChatGPTtrue and ChatGPTfalse. The results are presented in Figure 2. As shown, ChatGPTfalse still achieves comparable fluency scores to ChatGPTtrue but performs worse on both completeness and reliability. For completeness, the average score of ChatGPTfalse drops below 2.0. We also notice that the average token number of ChatGPTfalse reaches 335 (Table 2), which exceeds ChatGPTtrue by over 130 tokens. These results indicate that ChatGPT struggles to cover all relevant aspects of long-context posts. For reliability, more than half of ChatGPTfalse results give unreliable or inconsistent explanations (below 1.0), possibly due to the lack of mental health-related knowledge. A few ChatGPTfalse samples provide mostly reliable reasoning (above 2.0) but miss key information due to the lack of completeness. Overall, the mistakes of ChatGPT are mainly caused by ignorance of relevant information in long posts and unreliable reasoning process. Therefore, future works should improve ChatGPT\u2019s long-context modeling ability and introduce more mental healthrelated knowledge to benefit its performance. Inaccurate reasoning also reflects a lack of alignment between LLMs and mental health analysis tasks. A possible solution is to fine-tune the LLMs with\nmental health-related instruction-tuning datasets. We leave LLM-finetuning as future work. More cases are provided in Appendix F.3."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this work, we comprehensively studied LLMs on zero-shot/few-shot mental health analysis and the impact of different emotion-enhanced prompts. We explored the potential of LLMs in explainable mental health analysis, by explaining their predictions via CoT prompting. We developed a reliable annotation protocol for human evaluations of LLM-generated explanations and benchmarked existing automatic evaluation metrics on the human annotations. Experiments demonstrated that mental health analysis is still challenging for LLMs, but emotional information with proper prompt engineering can better trigger their ability. Human evaluation results showed that ChatGPT can generate human-level explanations for its decisions, and current automatic evaluation metrics need further improvement to properly evaluate explainable mental health analysis. ChatGPT also bears limitations, including unstable predictions and inaccurate reasoning.\nIn future work, we will explore domain-specific fine-tuning for LLMs to alleviate inaccurate reasoning problems. We will also extend the interpretable settings with LLMs to other research domains."
        },
        {
            "heading": "Acknowledgements",
            "text": "This work is supported by the computational shared facility at the University of Manchester and the University of Manchester President\u2019s Doctoral Scholar award. This work is supported by the project JPNP20006 from New Energy and Industrial Technology Development Organization (NEDO). Shaoxiong Ji is supported by the European Union\u2019s Horizon 2020 research and innovation program (agreement No 771113) and the EU\u2019s Horizon Europe research and innovation program under grant agreement No 101070350 and UK Research and Innovation (UKRI) under the UK government\u2019s Horizon Europe funding guarantee [grant number 10052546], also thanks the CSC - IT Center for Science, Finland for computational resources."
        },
        {
            "heading": "Limitations",
            "text": "Unexpected Responses. Though ChatGPT makes predictions in most of its responses as\nrequested by the prompts, there are a few cases where it refuses to make a classification. There are two main reasons: 1) the lack of evidence from the post to make a prediction; 2) the post contains content that violates the content policy of OpenAI4. For example, ChatGPT can respond: \u201cAs an AI language model, I cannot accurately diagnose mental illnesses or predict what may have caused them in this post.\u201d In our experiments, we directly exclude these responses because they are very rare, but future efforts are needed to alleviate these problems.\nLimitations of Lexicons. The motivation for using sentiment and emotion lexicons is to provide additional context with distant supervision for the prompts, which, however, have several limitations. The two lexicons, VADER (Hutto and Gilbert, 2014) and NRC EmoLex (Mohammad and Turney, 2010, 2013) we used were developed a decade ago with human annotation using social media data. It is inevitable that they suffer from annotation bias in the sentiment/emotion scores and only reflect the language used when they were developed. The Internet language evolves rapidly, and our experiments also use some recent datasets such as TSID (Ji et al., 2022a) and CAMS (Garg et al., 2022). Besides, these lexicons have limited vocabularies. Manual rules to aggregate sentence-level sentiment and emotions could be underspecified. Prompt engineering with other advanced resources with extra emotional information can be explored in future work. We also see the limitation of the dataset. Ji (2022) showed that the sentiment distribution has no significant difference in the binary case of T-SID dataset. Although the sentiment-enhanced prompt with VADER gains slightly better performance than other prompts on T-SID dataset, we cannot clearly explain if the choice of lexicon contributes to the improvement due to the black-box nature of ChatGPT."
        },
        {
            "heading": "Ethical Considerations",
            "text": "Although the datasets used are anonymously posted, our study adheres to strict privacy protocols (Benton et al., 2017; Nicholas et al., 2020) and minimizes privacy impact as much as possible, as social media datasets can reveal poster thoughts and may contain sensitive personal information. We use social posts that are manifestly\n4https://openai.com/policies/usage-policies\npublic from Reddit and Twitter. The SMS-like SAD dataset (Mauriello et al., 2021) has been released publicly on GitHub by the authors. All examples presented in our paper have been paraphrased and obfuscated using the moderate disguising scheme (Bruckman, 2002) to avoid misuse. We also do not use the user profile on social media, identify the users or interact with them. Our study aims to use social media as an early source of information to assist researchers or clinical practitioners in detecting mental health conditions for nonclinical use. The model predictions cannot replace psychiatric diagnoses. In addition, we recognize that some mental disorders are subjective (Keilp et al., 2012), and the interpretation of our analysis may differ (Puschman, 2017) because we do not understand the actual intentions of the posts."
        },
        {
            "heading": "A Related Work",
            "text": ""
        },
        {
            "heading": "A.1 Mental Health Condition Detection",
            "text": "Most recently, pre-trained language models (PLMs) have been the dominant method for various NLP tasks including mental health detection. Jiang et al. (2020) proposed the attention-based user-level and post-level classification model for mental health detection with the contextual representations from BERT as input features. Zhang et al. (2022b) proposed the hierarchical attention network with BERT as the post-encoder for early depression detection. Ji et al. (2022b) released two PLMs, MentalBERT and MentalRoBERTa, for mental healthcare, which are trained with corpus from social media. Ji (2022) showcased the intention understanding capacity of PLMs via the mask prediction task and emphasized the importance of intention understanding in suicidal ideation detection. Different from the above black-box models, Han et al. (2022) proposed the explainable depression detection model hierarchical attention network (HAN), which uses the contextual embedding of BERT as input features and incorporates the metaphor concept mappings (MCMs) as the extra features to improve the interpretability of the model. Nguyen et al. (2022) proposed to improve the generalizability of BERT based depression model by grounding the detection behavior of the depression detection model to symptoms in PHQ9.\nMoreover, there are also efforts incorporating multi-modal information, such as voice, video, visual, and text, to improve the performance of depression detection. Rodrigues Makiuchi et al. (2019) proposed a multi-modal method for depression detection, which incorporates speech and textual information with a gated convolutional neural network (gated CNN) and contextual feature from BERT. Lin et al. (2020) proposed the visual-textual multi-modal learning method based on CNN and BERT, for depression detection on social media. Toto et al. (2021) proposed the multi-modal method Audio-Assisted BERT (AudiBERT) for depression classification, which integrates the pre-trained audio embedding with text embedding from the bert encoder."
        },
        {
            "heading": "A.2 Large Language Models for Mental Health Analysis",
            "text": "Most recently, many efforts have evaluated the performance of LLMs such as ChatGPT and GPT4 on various NLP tasks (Bang et al., 2023; Qin\net al., 2023), such as machine translation (Jiao et al., 2023), text generation and evaluation (Benoit, 2023; Luo et al., 2023), language inference (Zhong et al., 2023). They have inspired efforts exploring the ability of LLMs for mental health analysis. Lamichhane (2023) evaluated the performance of ChatGPT on three mental health classification tasks, including stress, depression, and suicidality detection, and proved the good potential of ChatGPT for applications of mental health. Amin et al. (2023) further evaluated the capabilities of ChatGPT on big-five personality detection, sentiment analysis, and suicide detection. They show ChatGPT has better performance in sentiment analysis, comparable performance in suicide detection, and worse performance in personality detection when compared with RoBERTa-based and word embedding-based supervised methods. There are also works on analyzing the emotional reasoning ability of ChatGPT including (Qin et al., 2023; Zhong et al., 2023; Kocon\u0301 et al., 2023; Chen et al., 2023) on the sentiment classification task, where ChatGPT achieves comparable or worse performance compared with fine-tuning based methods based on PLMs. Ye et al. (2023) compared the performance of different LLMs including GPT-3 series (davinci and text-davinci-001) and GPT-3.5 series (code-davinci-002, text-davinci-002, text-davinci003, and gpt-3.5-turbo) on the aspect-based sentiment analysis, where code-davinci-002 has the best performance in the zero-shot setting. However, most of them only cover simple binary sentiment classification tasks or a few binary mental health detection tasks, leaving a huge gap for comprehensively exploring the ability of LLMs on emotionaware mental health analysis."
        },
        {
            "heading": "B ChatGPT for Emotional Reasoning",
            "text": "Tasks We evaluate the emotional reasoning ability of ChatGPT in complex scenarios on the following two widely studied tasks: emotion recognition in conversations (ERC) and causal emotion entailment (CEE). ERC aims at recognizing the emotion of each utterance within a conversation from a fixed emotion category set, which is often modeled as a multi-class text classification task (Poria et al., 2019b). Given an utterance with a non-neutral emotion, CEE aims to identify the casual utterances for this emotion in the previous conversation history. CEE is usually modeled as a binary classification between the candidate utterance and the target ut-\nterance.\nPrompts We perform direct guidance on exploring the ability of ChatGPT in both tasks, which designs zero-shot prompts to directly ask for a classification result from the response of ChatGPT. Details about the designed prompts are presented in Appendix C.1.\nDatasets For ERC, we select four widely utilized benchmark datasets: IEMOCAP (Busso et al., 2008), MELD (Poria et al., 2019a), EmoryNLP (Zahiri and Choi, 2017), DailyDialog (Li et al., 2017). For CEE, we select the dataset RECCON (Poria et al., 2021). More information about these datasets is listed in Table 7 in the appendix.\nBaseline Models We compare the performance of ChatGPT with supervised baseline models. For ERC, we select CNN (Kim, 2014), cLSTM (Zhou et al., 2015), CNN+LSTM (Poria et al., 2017), DialogueRNN (Majumder et al., 2019), KET (Zhong et al., 2019), BERT-Base (Devlin et al., 2019), RoBERTa-Base (Liu et al., 2019), XLNet (Yang et al., 2019), DialogXL (Shen et al., 2021a), KINet (Xie et al., 2021), SCCL (Yang et al., 2023), and SPCL (Song et al., 2022). For CEE, we select RankCP (Wei et al., 2020), RoBERTa-Base/Large, KEC (Li et al., 2022), and KBCIN (Zhao et al., 2022). Details about these baseline models are in Appendix D.1.\nMetrics We use the weighted-F1 measure as the evaluation metric for IEMOCAP, MELD, and EmoryNLP datasets. Since neutral occupies most of DailyDialog, we use micro-F1 for this dataset, and ignore the label neutral when calculating the results as in the previous works (Shen et al., 2021b; Xie et al., 2021; Yang et al., 2023). For RECCON, we report the F1 scores of both negative and positive causal pairs and the macro F1 scores as a whole.\nERC Results The experimental results on ERC task are presented in Table 5. We can see that ChatGPTZS using the zero-shot prompting outperforms traditional supervised methods including CNN and cLSTM on IEMOCAP, MELD, and EmoryNLP datasets, showing its advantage over light-weighted supervised methods. In addition, ChatGPTZS achieves comparable performance with CNN+LSTM and DialogueRNN on MELD, and EmoryNLP datasets, indicating that its\ngeneralizability can make up for the lack of taskspecific model architectures to some extent. On the MELD dataset, ChatGPTZS achieves 61.18% of weighted-F1 score, which outperforms some strong supervised methods including the fine-tuned BERTBase model (by 4.97%), and the knowledge infusion method KET (by 3.0%). However, the zero-shot performance of ChatGPT is still worse than advanced supervised methods on all datasets, and struggles to achieve dominating performance on the emotion-related tasks. This is because these tasks are very subjective even to humans, showing the promising future direction of exploring the fewshot prompting and knowledge infusion to improve the performance of ChatGPT in these subjective tasks."
        },
        {
            "heading": "Model Neg. F1 Pos. F1 Macro F1",
            "text": "CEE Results The experimental results on CEE task are presented in Table 6. We can observe that RankCP achieves the highest negative F1 score but has poor performance on the positive F1 score, which is more indicative in evaluating the emotion causal detection ability. ChatGPTZS significantly outperforms RankCP on positive F1 score, showing that it possesses some level of ability to understand\nthe emotional causes. However, its performance is still much lower than the advanced supervised methods such as KEC and KBCIN on all metrics, which incorporate effective information such as social commonsense knowledge. Quantitatively, ChatGPTZS still holds a 19.86% gap to the SOTA method KBCIN on macro F1 score.\nIn conclusion, the experiments on the ERC and CEE tasks show that ChatGPT holds comparable emotional reasoning ability in complex contexts with some traditional methods such as CNN and cLSTM, but still strongly underperforms competitive task-specific information infusion and finetuning methods. This indicates the necessity of future efforts to enhance prompting strategies and leverage external knowledge to better trigger the emotional reasoning ability of ChatGPT. These results also motivate us to design emotion-enhanced prompts to aid mental health analysis."
        },
        {
            "heading": "C Prompt Engineering",
            "text": ""
        },
        {
            "heading": "C.1 Emotional Reasoning",
            "text": "The prompt for ERC is designed as follows: Context: \"[Previous Dialogue]\". Consider this context to assign one emotion label to this utterance \"[Target]\". Only from this emotion list: [Emotion List]. Only return the assigned word. where the slots marked blue are the required inputs. [Previous Dialogue] denotes the previous dialogue history of the target utterance, where each utterance is pre-pended with its speaker, then concatenated in the sequence order. [Target] denotes the target utterance, and [Emotion List] denotes the predefined emotion category set of the corresponding dataset, which are listed in Table 7. Similarly, the prompt for CEE task is designed as follows:\nContext with emotion labels: \"[Previous Dialogue]\". Consider this context to answer the question: Did this utterance \"[Query]\" caused the [Target Emotion] emotion of the target utterance \"[Target]\"? Only return Yes or No.\nwhere [Previous Dialogue] still denotes the dialogue history with speakers, but each utterance is also post-pended with its emotion label. [Query] is the candidate utterance. [Target] and [Target Emotion] are the target utterance and its emotion label."
        },
        {
            "heading": "C.2 Mental Health Analysis",
            "text": "Zero-shot Prompting We probe LLaMA, InstructionGPT-3, and ChatGPT on zero-shot\nprompts. We design completion-based prompts on LLaMA, as it is not trained on instruction tuning. For example, for binary mental health condition detection, we design the following prompt:\nPost: \"[Post]\". The percentage that the poster is like to suffer from very severe [Condition] is\nwhere a predicted percentage of more than 50% is considered as positive, [Post] denotes the target post, [Condition] denotes the target mental health condition such as depression or stress, and [List] are the predefined labels presented in Table 8.\nFor InstructionGPT-3 and ChatGPT, we design instruction-based prompts since they are more natural for classification tasks. Specifically, for binary mental health condition detection, we design the following prompt:\nPost: \"[Post]\". Consider this post to answer the question: Is the poster likely to suffer from very severe [Condition]? Only return Yes or No.\nFor multi-class mental health detection, we use the following prompt:\nPost: \"[Post]\". Consider this post to assign only one mental disorder label to this post from this list: [List]. Only return the assigned label.\nFor cause/factor detection, the prompt is: Post: \"[Post]\". Consider this post and assign a label that causes its [Condition]. Only return answers from one of the labels: [List].\nEmotion-enhanced CoT prompting We design instruction-based prompts as we only test emotionenhanced CoT prompting strategies on ChatGPT. Specifically, for the binary mental health condition detection task, we modify the zero-shot prompt as follows:\nPost: \"[Post]\". Consider the emotions expressed from this post to answer the question: Is the poster likely to suffer from very severe [Condition]? Only return Yes or No, then explain your reasoning step by step.\nwhere the green parts are the zero-shot CoT enhancements that instructs LLM to generate explanations, and the red parts are further added on zeroshot CoT prompts to obtain the emotion-enhanced prompts. Similar modifications are performed on the prompt of multi-class detection and cause/factor detection."
        },
        {
            "heading": "Supervised emotion-enhanced prompting",
            "text": "Based on the sentiment lexicons, we assign a sentiment score to each post and convert the\nscore to one of the labels: {positive, negative, neutral}. NRC EmoLex also contains emotion annotations that were assigned from the following emotion list: anger, anticipation, disgust, fear, joy, sadness, surprise, trust. We regard the emotion category with the maximum emotion score as the emotion label of the input text. Specifically, VADER contains sentiment annotations with a sentiment score between -4 to 4. We utilize the NLTK package5 to preprocess the input text (e.g., removing punctuations and singletons), apply the predefined manual rules to obtain word sentiment and aggregate the sentence-level sentiment, and return the normalized sentiment score between -1 to 1 as the overall sentiment in the post. We set the polarity threshold to 0. For NRC EmoLex, we obtain the word\u2019s stem and match the stem with the word in the lexicon when obtaining sentiment and emotion scores. Each word\u2019s emotion and sentiment scores are summed up to obtain the sentence-level sentiment and emotion. We assume there is only one sentiment or emotion in a given post and assign the post\u2019s emotion or sentiment to the categories with the maximum emotion or sentiment scores.\nWe design the supervised emotion-enhanced zero-shot Chain-of-Thought (CoT) prompts by adding the sentiment/emotion labels to the zeroshot prompt. For example, we modify the prompt for multi-class mental health condition detection as follows:\nPost: \"[Post]\". Alice thinks it is [Sentiment/Emotion]. Consider this post to assign only one mental disorder label to this post from this list: [List]. Only return the assigned label.\nwhere the green parts are the modifications for distantly supervised emotion infusion, and [Sentiment/Emotion] denotes the corresponding sentiment/emotion label. Modifications for other tasks are similar.\nFew-shot emotion-enhanced prompting . In this section, we provide some examples of the fewshot emotion-enhanced prompts. The first example comes from DR:\nYou will be presented with a post. Consider the emotions expressed in this post to answer the question: Is the poster likely to suffer from very severe depression? Only return Yes or No, then explain your reasoning step by step. Here are two examples:\n5https://www.nltk.org\nPost: Does everyone else just hurt all the time It\u2019s not like physical pain or soreness, it\u2019s just this overwhelming feeling of exhaustion and numbness... Response: Yes. Reasoning: The post conveys a deep sense of emotional pain, exhaustion, and numbness. The poster describes feeling overwhelmed by even simple tasks and expresses a lack of enjoyment or fulfillment from activities that are typically pleasurable... Post: Hello!: ) I\u2019m a new user so if this post ends up in a weird place/thread, pls bear w me. Has anyone used Ancestry.com lately? They offer a two week trial... Response: No. Reasoning: The post does not exhibit strong emotional indicators of very severe depression. It primarily focuses on a specific concern regarding the safety of...\nPost: Its like that, if you want or not. ME: I have no problem, if it takes longer. But you asked my friend for help and let him wait for one hour and then you haven\u2019t prepared anything. Thats not what you asked for... Response:\nHere is another example for the mental health cause detection dataset SAD:\nYou will be presented post that shows the stress of the poster. Assign one label to this post only from the following stress causes list: School, Financial problem, Family issues, Social relationships, Work, Health issues, Emotional turmoil, Everyday decision making, Others. You must return the assigned labels, then explain your reasoning step by step. Here are 7 examples: Post: i have been wanting to find another job for some time now Response: Work. Reasoning: The post explicitly mentions that the poster has been wanting to find another job for some time now. This indicates that they are not satisfied with their current job and are experiencing stress in relation to their work situation. ... Post: raising a teenage girl can be stressful Response: Family issues. Reasoning: The post specifically mentions the task of raising a teenage girl, which falls under the category of family issues. The stress of parenting can be overwhelming, especially when dealing with a\nsensitive age group...\nPost: I got really scared because this happened on the way home. Response:"
        },
        {
            "heading": "D Baseline Models",
            "text": ""
        },
        {
            "heading": "D.1 Emotion Reasoning",
            "text": "We select the following competitive methods for ERC:\n\u2022 CNN (Kim, 2014) used a single-layer textCNN to model each utterance. The classification is performed on utterance-level without contexts.\n\u2022 cLSTM (Zhou et al., 2015) utilized a bidirectional LSTM to encode each utterance and another uni-directional LSTM to model the context.\n\u2022 CNN+LSTM (Poria et al., 2017) used a textCNN to model each utterance, then utilized a uni-directional LSTM to model the context based on the utterance representations.\n\u2022 DialogueRNN (Majumder et al., 2019) used a text-CNN to extract utterance-level features, then use a separate GRU to model each participant\u2019s mental states. A global-state GRU is used to model the context.\n\u2022 KET (Zhong et al., 2019) utilized a hierarchical Transformer to model utterances and context, and infuse word-level commonsense knowledge to enrich the semantics of the context.\n\u2022 BERT-Base (Devlin et al., 2019) used the PLM BERT-Base to directly model the conversation. The utterance representations are used to fine-tune the weights.\n\u2022 RoBERTa-Base (Liu et al., 2019) used a similar training paradigm to BERT-Base but with the PLM RoBERTa.\n\u2022 XLNet (Yang et al., 2019) utilized the PLM XLNet to directly model the conversation. The segment recurrence was expected to model long contexts well.\n\u2022 DialogXL (Shen et al., 2021a) improved the XLNet with the enhanced memory and dialogaware self-attention mechanism to capture\nlong historical context and dependencies between multiple parties.\n\u2022 KI-Net (Xie et al., 2021) infused both commonsense and sentiment lexicon knowledge to enhance XLNet. A self-matching module was proposed to allow interactions between utterance and knowledge representations.\n\u2022 SCCL (Yang et al., 2023) proposed a supervised cluster-level contrastive learning (SCCL) to infuse Valance-ArousalDominance information. Pre-trained knowledge adapters are leveraged to incorporate linguistic and factual knowledge.\n\u2022 SPCL (Song et al., 2022) used the PLM SimCSE (Gao et al., 2021) as the backbone model with the supervised prototypical contrastive learning (SPCL) loss.\nFor CEE task, we use the following baseline models:\n\u2022 RankCP (Wei et al., 2020) ranked the clausepair candidates in the context and utilized a neural network to perform entailment classification with the context-aware utterance representations.\n\u2022 RoBERTa-Base/Large (Liu et al., 2019) concatenated the conversation with the emotion label of each utterance as input to the PLM RoBERTa (both RoBERTa-Base and\nRoBERTa-Large are used). Then CEE was modeled as a binary classification problem for each utterance pair.\n\u2022 KEC (Li et al., 2022) utilized the directed acyclic graph networks (DAGs) incorporating social commonsense knowledge (SCK) to improve the causal reasoning ability.\n\u2022 KBCIN (Zhao et al., 2022) proposed the knowledge-bridged causal interaction network (KBCIN) with conversational graph, emotional and actional interaction module to capture context dependencies of conversations and make emotional cause reasoning."
        },
        {
            "heading": "D.2 Mental Health Analysis",
            "text": "We compare the performance of ChatGPT with that of the following baselines for mental health analysis:\n\u2022 CNN (Kim, 2014) used three channel CNN with filters of 2,3,4 to classify the post.\n\u2022 GRU (Cho et al., 2014) used a two-layer GRU to encode the post.\n\u2022 BiLSTM_Att (Zhou et al., 2016) utilized a bidirectional LSTM with attention mechanism as context encoding layer to capture the contextual information of posts.\n\u2022 fastText (Joulin et al., 2017) used an opensource and efficient text classifier based on bag of n-grams features.\n\u2022 BERT/RoBERTa (Devlin et al., 2019; Liu et al., 2019) utilized the PLMs BERT and RoBERTa to model the post and fine-tuned them for classification.\n\u2022 MentalBERT/MentalRoBERTa (Ji et al., 2022b) used mental healthcare-related PLMs MentalBERT and MentalRobBERTa to encode the post, which are fine-tuned for classification."
        },
        {
            "heading": "E Human Evaluation Criteria",
            "text": "Annotators will be given generated explanations from ChatGPT and InstructGPT-3, and the original post as the correct reference. Annotators will need to score and annotate the generated explanations from the following aspects:\nFluency Fluency evaluates the coherence and readability of the explanation. Annotators should assess if generated explanation well-structured, easy to read, and free of grammatical or syntax errors.\n\u2022 0: Incoherent, difficult to read, and contains numerous errors\n\u2022 1: Somewhat coherent, but with poor readability and several errors\n\u2022 2: Mostly fluent, easy to read, with few minor errors\n\u2022 3: Completely fluent, coherent, and error-free\nReliability Reliability measures how trustworthiness of the generated explanations to support the detection results. Annotators should assess whether the explanation is based on facts, has misinformation and wrong reasoning according to the given post. Main symptoms to check (sorted by criticality):\n\u2022 Suicide ideation expressions (golden standard).\n\u2022 Self-harm and self-guilt.\n\u2022 Long-term low passion (e.g. loss of interest to previous hobbies).\n\u2022 Loss of appetite and sleep disorders.\n\u2022 Accompanied by hypersexuality or frigidity.\n\u2022 Other symptoms.\nThe domain experts also consult other scales describing depressive symptoms, such as the Patient Health Questionnaire (PHQ-9)6. The annotation scheme is as follows:\n\u2022 0: Unreliable information or inconsistent information\n\u2022 1: Somewhat reliable information with some inconsistencies\n\u2022 2: Mostly reliable information with few inconsistencies\n\u2022 3: Completely reliable information\nCompleteness Completeness measures how well the generated explanations cover all relevant aspects of the original post. Annotators should assess whether the explanation provides sufficient context and detail, without omitting important information such as emotional cues from the original post.\n\u2022 0: Omits significant information from the original post\n\u2022 1: Partially complete with some omissions\n\u2022 2: Mostly complete with minor omissions\n\u2022 3: Complete coverage of the original post\nOverall Score Overall performance measures the general effectiveness of the generated explanation, taking into account the combined scores for fluency, factuality, reliability, and completeness.\n\u2022 0: Poor overall performance, fluency, reliability, and completeness are all poor (=0)\n\u2022 1: Fair overall performance, fluency is good (>= 2), one or two aspects among reliability, and completeness is fair (<= 1)\n\u2022 2: Good overall performance, fluency is excellent (3), one or two aspects among reliability, and completeness is not excellent (<= 2)\n\u2022 3: Excellent overall performance, fluency, reliability, and completeness is all excellent (=3)\n6https://www.apa.org/depression-guideline/ patient-health-questionnaire.pdf"
        },
        {
            "heading": "F Case studies",
            "text": ""
        },
        {
            "heading": "F.1 Emotion-enhanced Prompts",
            "text": "To provide a more intuitive view, we present an example of ChatGPTCoT_emo on the mental health condition detection for a post from the Dreaddit dataset:\nPrompt: Post: \"I am scared as fuck off what the comedown is going to be like from being jacked up on adrenaline for 5 days straight. I have not felt tired whatsoever during this time...\" Consider the emotion expressed from the post, then answer this question: Is the poster likely to suffer from very severe stress? You must return a Yes or No, then explain your reasoning step by step. Response: Yes, the poster is likely to suffer from very severe stress. The emotional language used in the post indicates a high level of fear and anxiety, with the phrase \"scared as fuck\" conveying extreme distress. The fact that they have been jacked up on adrenaline for five days straight suggests that they have been in a highly stressful situation for an extended period of time... Overall, the combination of emotional and physical symptoms suggests that the poster is experiencing severe stress.\nwhere the emotional clues and analysis are marked in red, and factual clues and analysis are marked in blue. As shown, ChatGPT with the prompt \"Consider the emotion expressed from the post...\" can effectively detect multiple emotions of fear, anxiety, and distress from the post and consider both clues from emotions and physical symptoms to make a final prediction. The emotion-enhanced zero-shot CoT prompt triggers ChatGPT to conduct the complex reasoning process with emotional cues, and thus improves the overall performance of mental health analysis."
        },
        {
            "heading": "F.2 Explainability",
            "text": "Firstly, we provide a case for each of the binary/multi-class detection tasks. For binary detection, an example is shown in Appendix. F.1, where ChatGPT explains its reasoning process from the perspectives of emotions and physical symptoms. As shown in ChatGPT\u2019s explanation, the emotional language with the phrase \"scared as fuck\" and the fact \"jacked up on adrenaline for 5 days straight\" in the post, indicate emotional and physical symptoms of a high level of fear, anxiety, and distress.\nChatGPT thus makes the prediction of experiencing severe stress based on these symptoms.\nFor multi-class detection, we select a case from the T-SID dataset:\nPrompt: Post: \"Going to end my life lol see ya later haha\" Consider the emotions expressed from this post, then assign only one label to this post from this mental disorders list: Depression, Suicide, PTSD, None. You must return the assigned label, then explain your reasoning step by step. Response: Assigned label: Suicide. Reasoning: The post explicitly mentions the idea of ending one\u2019s life, which strongly suggests suicidal ideation. The use of humor with \"lol\" and \"haha\" may indicate a defense mechanism, such as denial or avoidance. However, given the severity of the content, it is important not to dismiss the potential for suicidal behavior. While depression and PTSD can be risk factors for suicide, they are not necessarily present in this specific post.\nIn this case, ChatGPT provides evidence for making a suicide ideation prediction (marked red), such as the \"severity of the content\" and \"explicitly mentions the idea of ending one\u2019s life\". It also states reasons for excluding other mental health conditions such as depression and PTSD (marked blue), such as \"not necessarily present\". These two-sided reasoning steps significantly improve the transparency of ChatGPT\u2019s predictions.\nWe provide a case from the CAMS dataset to demonstrate how ChatGPT detects the cause/factor for mental health conditions.\nPrompt: Post: \"Really have been struggling with everything lately, and I come into work today and my boss tells my I am no longer meeting expectations and fires me. I think the worst part is still being scheduled for three more days...\" This post shows the depression of the poster. Consider the emotions expressed from this post and assign one label to this post only from the following depression causes list: Bias or abuse, Jobs and career, Medication, Relationship, Alienation, None. You must return the assigned label, then explain your reasoning step by step. Response: Jobs and career. The post directly mentions the poster\u2019s job and their recent firing, which indicates that their job and career are a significant source of stress in their life at\nthe moment. The poster also mentions struggling with everything lately, which could potentially be related to their job and the anxiety it has been causing them. Therefore, the label of \"Jobs and career\" is the most fitting for this post.\nIn this case, ChatGPT extracts the direct evidence of \"poster\u2019s job and their recent firing\" from the post (marked blue), to support its cause detection of \"Jobs and career\". In addition, ChatGPT can make inferences about the poster\u2019s complaint to potentially be related to their job (marked green), and states their relations to the poster\u2019s anxiety emotion (marked red). These multi-aspect arguments convincingly support the final decision.\nF.3 Inaccurate Reasoning\nHere is an example of the prediction from ChatGPTCoT_emo for a post in the Dreaddit dataset:\nPrompt: Post: \"Like she said \u2018shes too much attached to her boyfriend, she knows that he fucks other girls but she cant break with him cause he will block her on fb and delete her phone number forever, he is her the best friend, soulmate.\u2019 Wtf? Run away and try to fall out of love or what?\" Consider the emotion expressed from the post, then answer this question: Is the poster likely to suffer from very severe stress? You must return a Yes or No, then explain your reasoning step by step. Response: Yes. The fact that they are considering running away and falling out of love suggests that they may be experiencing a high level of emotional distress. The feeling of being attached to someone who is not treating them well and the fear of being blocked and deleted by that person on social media could exacerbate that distress. Therefore, it is reasonable to conclude that the poster is likely to suffer from very severe stress.\nwhere a poster is wrongly predicted as stressed. In this case, ChatGPT ignores the key fact that the poster was quoting the problem of another girl and felt unfair for her (marked blue). ChatGPT mistakenly analyzed the cause of stress for the mentioned girl (marked red) and put it on the poster."
        },
        {
            "heading": "G Automatic Evaluation on InstructGPT-3",
            "text": "The automatic evaluation results on InstructGPT3 explanations are presented in Table 9. The"
        },
        {
            "heading": "BERT Score-based Methods",
            "text": "results show that BERT-Score method based on BERT achieves the best performance in all aspects, outperforming statistics-based and generative language model-based methods. We notice that many InstructGPT-3 outputs only give diagnoses with no explanations at all, and BERT-based methods are expected to better capture the huge gap between the semantics of the original post and explanations than other methods. On the other hand, MentalBERT and MentalRoBERTa do not outperform BERT as in ChatGPT examples, because the quality of InstructGPT-3 explanations is very low, which does not need much domain-specific knowledge to score."
        }
    ],
    "title": "Towards Interpretable Mental Health Analysis with Large Language Models",
    "year": 2023
}