{
    "abstractText": "Automatic response forecasting for news media plays a crucial role in enabling content producers to efficiently predict the impact of news releases and prevent unexpected negative outcomes such as social conflict and moral injury. To effectively forecast responses, it is essential to develop measures that leverage the social dynamics and contextual information surrounding individuals, especially in cases where explicit profiles or historical actions of the users are limited (referred to as lurkers). As shown in a previous study, 97% of all tweets are produced by only the most active 25% of users. However, existing approaches have limited exploration of how to best process and utilize these important features. To address this gap, we propose a novel framework, named SOCIALSENSE, that leverages a large language model to induce a belief-centered graph on top of an existent social network, along with graph-based propagation to capture social dynamics. We hypothesize that the induced graph that bridges the gap between distant users who share similar beliefs allows the model to effectively capture the response patterns. Our method surpasses existing state-of-the-art in experimental evaluations for both zero-shot and supervised settings, demonstrating its effectiveness in response forecasting. Moreover, the analysis reveals the framework\u2019s capability to effectively handle unseen user and lurker scenarios, further highlighting its robustness and practical applicability.",
    "authors": [
        {
            "affiliations": [],
            "name": "Chenkai Sun"
        },
        {
            "affiliations": [],
            "name": "Jinning Li"
        },
        {
            "affiliations": [],
            "name": "Yi R. Fung"
        },
        {
            "affiliations": [],
            "name": "Hou Pong Chan"
        },
        {
            "affiliations": [],
            "name": "Tarek Abdelzaher"
        },
        {
            "affiliations": [],
            "name": "ChengXiang Zhai"
        },
        {
            "affiliations": [],
            "name": "Heng Ji"
        }
    ],
    "id": "SP:b27265592dcc172f8af2ec5fc32417fdff4eeefb",
    "references": [
        {
            "authors": [
                "Dogu Araci."
            ],
            "title": "Finbert: Financial sentiment analysis with pre-trained language models",
            "venue": "arXiv preprint arXiv:1908.10063.",
            "year": 2019
        },
        {
            "authors": [
                "Yoav Artzi",
                "Patrick Pantel",
                "Michael Gamon."
            ],
            "title": "Predicting responses to microblog posts",
            "venue": "proceedings of the 2012 conference of the north American chapter of the Association for Computational Linguistics: human language technologies, pages 602\u2013606.",
            "year": 2012
        },
        {
            "authors": [
                "Noureddine Azzouza",
                "Karima Akli-Astouati",
                "Roliana Ibrahim."
            ],
            "title": "Twitterbert: Framework for twitter sentiment analysis based on pre-trained language model representations",
            "venue": "Emerging Trends in Intelligent Computing and Informatics: Data Science,",
            "year": 2020
        },
        {
            "authors": [
                "Annye Braca",
                "Pierpaolo Dondio."
            ],
            "title": "Persuasive communication systems: a machine learning approach to predict the effect of linguistic styles and persuasion techniques",
            "venue": "Journal of Systems and Information Technology, (ahead-of-print).",
            "year": 2023
        },
        {
            "authors": [
                "Hou Pong Chan",
                "Irwin King."
            ],
            "title": "Thread popularity prediction and tracking with a permutationinvariant model",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - Novem-",
            "year": 2018
        },
        {
            "authors": [
                "Chi Seng Cheang",
                "Hou Pong Chan",
                "Derek F. Wong",
                "Xuebo Liu",
                "Zhaocong Li",
                "Yanming Sun",
                "Shudong Liu",
                "Lidia S. Chao."
            ],
            "title": "Can LMs Generalize to Future Data? An Empirical Analysis on Text Summarization",
            "venue": "Proceedings of the Conference on",
            "year": 2023
        },
        {
            "authors": [
                "Claudio Daniel Tenorio de Barros",
                "Matheus R.F. Mendon\u00e7a",
                "Alex Borges Vieira",
                "Artur Ziviani."
            ],
            "title": "A survey on embedding dynamic graphs",
            "venue": "ACM Comput. Surv., 55(2):10:1\u201310:37.",
            "year": 2023
        },
        {
            "authors": [
                "Shizhe Diao",
                "Pengcheng Wang",
                "Yong Lin",
                "Tong Zhang"
            ],
            "title": "Active prompting with chain-ofthought for large language models",
            "year": 2023
        },
        {
            "authors": [
                "Yi Fung",
                "Christopher Thomas",
                "Revanth Gangi Reddy",
                "Sandeep Polisetty",
                "Heng Ji",
                "Shih-Fu Chang",
                "Kathleen McKeown",
                "Mohit Bansal",
                "Avirup Sil."
            ],
            "title": "Infosurgeon: Cross-media fine-grained information consistency checking for fake news detection",
            "venue": "In",
            "year": 2021
        },
        {
            "authors": [
                "Yi R. Fung",
                "Tuhin Chakraborty",
                "Hao Guo",
                "Owen Rambow",
                "Smaranda Muresan",
                "Heng Ji."
            ],
            "title": "Normsage: Multi-lingual multi-cultural norm discovery from conversations on-the-fly",
            "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural",
            "year": 2023
        },
        {
            "authors": [
                "Revanth Gangi Reddy",
                "Sai Chetan Chinthakindi",
                "Zhenhailong Wang",
                "Yi Fung",
                "Kathryn Conger",
                "Ahmed ELsayed",
                "Martha Palmer",
                "Preslav Nakov",
                "Eduard Hovy",
                "Kevin Small",
                "Heng Ji"
            ],
            "title": "NewsClaims: A new benchmark for claim detection from news",
            "year": 2022
        },
        {
            "authors": [
                "Anastasia Giachanou",
                "Paolo Rosso",
                "Ida Mele",
                "Fabio Crestani."
            ],
            "title": "Emotional influence prediction of news posts",
            "venue": "Twelfth International AAAI Conference on Web and Social Media.",
            "year": 2018
        },
        {
            "authors": [
                "Fabrizio Gilardi",
                "Meysam Alizadeh",
                "Ma\u00ebl Kubli."
            ],
            "title": "Chatgpt outperforms crowd-workers for textannotation tasks",
            "venue": "arXiv preprint arXiv:2303.15056.",
            "year": 2023
        },
        {
            "authors": [
                "Jesse Graham",
                "Jonathan Haidt",
                "Matt Motyl",
                "Peter Meindl",
                "Carol Iskiwitch",
                "Marlon Mooijman."
            ],
            "title": "Moral foundations theory",
            "venue": "Atlas of moral psychology, 211.",
            "year": 2018
        },
        {
            "authors": [
                "Chi Han",
                "Jialiang Xu",
                "Manling Li",
                "Yi Fung",
                "Chenkai Sun",
                "Nan Jiang",
                "Tarek Abdelzaher",
                "Heng Ji."
            ],
            "title": "Lm-switch: Lightweight language model conditioning in word embedding space",
            "venue": "arXiv preprint arXiv:2305.12798.",
            "year": 2023
        },
        {
            "authors": [
                "Ji He",
                "Mari Ostendorf",
                "Xiaodong He",
                "Jianshu Chen",
                "Jianfeng Gao",
                "Lihong Li",
                "Li Deng."
            ],
            "title": "Deep reinforcement learning with a combinatorial action space for predicting popular reddit threads",
            "venue": "Proceedings of the 2016 Conference on Empirical Meth-",
            "year": 2016
        },
        {
            "authors": [
                "Pengcheng He",
                "Xiaodong Liu",
                "Jianfeng Gao",
                "Weizhu Chen."
            ],
            "title": "Deberta: Decoding-enhanced bert with disentangled attention",
            "venue": "arXiv preprint arXiv:2006.03654.",
            "year": 2020
        },
        {
            "authors": [
                "Tiffany Hsu",
                "Stuart A. Thompson"
            ],
            "title": "Disinformation researchers raise alarms about a.i. chatbots",
            "year": 2023
        },
        {
            "authors": [
                "Ziniu Hu",
                "Yuxiao Dong",
                "Kuansan Wang",
                "Yizhou Sun."
            ],
            "title": "Heterogeneous graph transformer",
            "venue": "Proceedings of the web conference 2020, pages 2704\u2013 2710.",
            "year": 2020
        },
        {
            "authors": [
                "Kung-Hsiang Huang",
                "Hou Pong Chan",
                "Heng Ji."
            ],
            "title": "Zero-shot faithful factual error correction",
            "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14,",
            "year": 2023
        },
        {
            "authors": [
                "Kung-Hsiang Huang",
                "Hou Pong Chan",
                "Kathleen R. McKeown",
                "Heng Ji."
            ],
            "title": "Manitweet: A new benchmark for identifying manipulation of news on social media",
            "venue": "CoRR, abs/2305.14225.",
            "year": 2023
        },
        {
            "authors": [
                "Sandeepa Kannangara."
            ],
            "title": "Mining twitter for finegrained political opinion polarity classification, ideology detection and sarcasm detection",
            "venue": "Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining, pages 751\u2013752.",
            "year": 2018
        },
        {
            "authors": [
                "Takeshi Kojima",
                "Shixiang Shane Gu",
                "Machel Reid",
                "Yutaka Matsuo",
                "Yusuke Iwasawa."
            ],
            "title": "Large language models are zero-shot reasoners",
            "venue": "arXiv preprint arXiv:2205.11916.",
            "year": 2022
        },
        {
            "authors": [
                "Vivek Kulkarni",
                "Junting Ye",
                "Steven Skiena",
                "William Yang Wang."
            ],
            "title": "Multi-view models for political ideology detection of news articles",
            "venue": "arXiv preprint arXiv:1809.03485.",
            "year": 2018
        },
        {
            "authors": [
                "Jinning Li",
                "Yirui Gao",
                "Xiaofeng Gao",
                "Yan Shi",
                "Guihai Chen."
            ],
            "title": "Senti2pop: sentiment-aware topic popularity prediction on social media",
            "venue": "2019 IEEE International conference on data mining (ICDM), pages 1174\u20131179. IEEE.",
            "year": 2019
        },
        {
            "authors": [
                "Jinning Li",
                "Huajie Shao",
                "Dachun Sun",
                "Ruijie Wang",
                "Yuchen Yan",
                "Jinyang Li",
                "Shengzhong Liu",
                "Hanghang Tong",
                "Tarek Abdelzaher."
            ],
            "title": "Unsupervised belief representation learning with informationtheoretic variational graph auto-encoders",
            "venue": "Pro-",
            "year": 2022
        },
        {
            "authors": [
                "Sha Li, Chi Han, Pengfei Yu, Carl Edwards, Manling Li, Xingyao Wang, Yi R. Fung, Charles Yu, Joel R. Tetreault,",
                "Eduard H Heng Hovy",
                "Ji."
            ],
            "title": "Defining a new nlp playground",
            "venue": "ACL Findings.",
            "year": 2023
        },
        {
            "authors": [
                "Kevin Hsin-Yih Lin",
                "Hsin-Hsi Chen."
            ],
            "title": "Ranking reader emotions using pairwise loss minimization and emotional distribution regression",
            "venue": "Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 136\u2013144, Honolulu,",
            "year": 2008
        },
        {
            "authors": [
                "Kun-Lin Liu",
                "Wu-Jun Li",
                "Minyi Guo."
            ],
            "title": "Emoticon smoothed language models for twitter sentiment analysis",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 26, pages 1678\u20131684.",
            "year": 2012
        },
        {
            "authors": [
                "Liyuan Liu",
                "Haoming Jiang",
                "Pengcheng He",
                "Weizhu Chen",
                "Xiaodong Liu",
                "Jianfeng Gao",
                "Jiawei Han."
            ],
            "title": "On the variance of the adaptive learning rate and beyond",
            "venue": "arXiv preprint arXiv:1908.03265.",
            "year": 2019
        },
        {
            "authors": [
                "Yiheng Liu",
                "Tianle Han",
                "Siyuan Ma",
                "Jiayue Zhang",
                "Yuanyuan Yang",
                "Jiaming Tian",
                "Hao He",
                "Antong Li",
                "Mengshen He",
                "Zhengliang Liu"
            ],
            "title": "Summary of chatgpt/gpt-4 research and perspective towards the future of large language models",
            "year": 2023
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Hongyuan Lu",
                "Wai Lam",
                "Hong Cheng",
                "Helen Meng."
            ],
            "title": "Partner personas generation for dialogue response generation",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
            "year": 2022
        },
        {
            "authors": [
                "Giovanni Da San Martino",
                "Stefano Cresci",
                "Alberto Barr\u00f3n-Cede\u00f1o",
                "Seunghak Yu",
                "Roberto Di Pietro",
                "Preslav Nakov."
            ],
            "title": "A survey on computational propaganda detection",
            "venue": "arXiv preprint arXiv:2007.08024.",
            "year": 2020
        },
        {
            "authors": [
                "Colleen McClain",
                "Regina Widjaya",
                "Gonzalo Rivero",
                "Aaron Smith"
            ],
            "title": "The behaviors and attitudes of us adults on twitter",
            "year": 2021
        },
        {
            "authors": [
                "Saif Mohammad",
                "Felipe Bravo-Marquez",
                "Mohammad Salameh",
                "Svetlana Kiritchenko."
            ],
            "title": "Semeval2018 task 1: Affect in tweets",
            "venue": "Proceedings of the 12th international workshop on semantic evaluation, pages 1\u201317.",
            "year": 2018
        },
        {
            "authors": [
                "Vitaliia-Anna Oliinyk",
                "Victoria Vysotska",
                "Yevhen Burov",
                "Khrystyna Mykich",
                "V\u00edtor Basto Fernandes."
            ],
            "title": "Propaganda detection in text data based on nlp and machine learning",
            "venue": "MoMLeT+ DS, pages 132\u2013144.",
            "year": 2020
        },
        {
            "authors": [
                "Quinn Owen",
                "Max Zahn"
            ],
            "title": "Avoiding potential \u2019extinction event",
            "year": 2023
        },
        {
            "authors": [
                "Adam Paszke",
                "Sam Gross",
                "Francisco Massa",
                "Adam Lerer",
                "James Bradbury",
                "Gregory Chanan",
                "Trevor Killeen",
                "Zeming Lin",
                "Natalia Gimelshein",
                "Luca Antiga"
            ],
            "title": "Pytorch: An imperative style, high-performance deep learning",
            "year": 2019
        },
        {
            "authors": [
                "Revanth Gangi Reddy",
                "Yi R Fung",
                "Qi Zeng",
                "Manling Li",
                "Ziqi Wang",
                "Paul Sullivan"
            ],
            "title": "Smartbook: Aiassisted situation report",
            "year": 2023
        },
        {
            "authors": [
                "Shalom H Schwartz."
            ],
            "title": "Universals in the content and structure of values: Theoretical advances and empirical tests in 20 countries",
            "venue": "Advances in experimental social psychology, volume 25, pages 1\u201365. Elsevier.",
            "year": 1992
        },
        {
            "authors": [
                "Chenkai Sun",
                "Jinning Li",
                "Hou Pong Chan",
                "ChengXiang Zhai",
                "Heng Ji."
            ],
            "title": "Measuring the effect of influential messages on varying personas",
            "venue": "arXiv preprint arXiv:2305.16470.",
            "year": 2023
        },
        {
            "authors": [
                "Chenkai Sun",
                "Tie Xu",
                "ChengXiang Zhai",
                "Heng Ji."
            ],
            "title": "Incorporating task-specific concept knowledge into script learning",
            "venue": "arXiv preprint arXiv:2209.00068.",
            "year": 2022
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems, pages 5998\u20136008.",
            "year": 2017
        },
        {
            "authors": [
                "Wei Wang",
                "Piji Li",
                "Hai-Tao Zheng."
            ],
            "title": "Generating diversified comments via reader-aware topic modeling and saliency detection",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 13988\u201313996.",
            "year": 2021
        },
        {
            "authors": [
                "Zhongqing Wang",
                "Xiujun Zhu",
                "Yue Zhang",
                "Shoushan Li",
                "Guodong Zhou."
            ],
            "title": "Sentiment forecasting in dialog",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 2448\u2013 2458.",
            "year": 2020
        },
        {
            "authors": [
                "Teven Le Scao",
                "Sylvain Gugger",
                "Mariama Drame",
                "Quentin Lhoest",
                "Alexander Rush."
            ],
            "title": "Transformers: State-of-the-art natural language processing",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System",
            "year": 2020
        },
        {
            "authors": [
                "Xueqing Wu",
                "Kung-Hsiang Huang",
                "Yi Fung",
                "Heng Ji."
            ],
            "title": "Cross-document misinformation detection based on event graph reasoning",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Hu-",
            "year": 2022
        },
        {
            "authors": [
                "Yuwei Wu",
                "Xuezhe Ma",
                "Diyi Yang."
            ],
            "title": "Personalized response generation via generative split memory network",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-",
            "year": 2021
        },
        {
            "authors": [
                "Jingfeng Yang",
                "Hongye Jin",
                "Ruixiang Tang",
                "Xiaotian Han",
                "Qizhang Feng",
                "Haoming Jiang",
                "Bing Yin",
                "Xia Hu."
            ],
            "title": "Harnessing the power of llms in practice: A survey on chatgpt and beyond",
            "venue": "arXiv preprint arXiv:2304.13712.",
            "year": 2023
        },
        {
            "authors": [
                "Ze Yang",
                "Can Xu",
                "Wei Wu",
                "Zhoujun Li"
            ],
            "title": "2019. Read, attend and comment: A deep architecture for automatic news comment generation",
            "year": 2019
        },
        {
            "authors": [
                "Shehel Yoosuf",
                "Yin Yang."
            ],
            "title": "Fine-grained propaganda detection with fine-tuned bert",
            "venue": "Proceedings of the second workshop on natural language processing for internet freedom: censorship, disinformation, and propaganda, pages 87\u201391.",
            "year": 2019
        },
        {
            "authors": [
                "Yuji Zhang",
                "Jing Li",
                "Wenjie Li."
            ],
            "title": "Vibe: Topicdriven temporal adaptation for twitter classification",
            "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP), Singapore. Association for Computational Linguis-",
            "year": 2023
        },
        {
            "authors": [
                "Zihao Zhao",
                "Eric Wallace",
                "Shi Feng",
                "Dan Klein",
                "Sameer Singh."
            ],
            "title": "Calibrate before use: Improving few-shot performance of language models",
            "venue": "International Conference on Machine Learning, pages 12697\u201312706. PMLR.",
            "year": 2021
        },
        {
            "authors": [
                "Denny Zhou",
                "Nathanael Sch\u00e4rli",
                "Le Hou",
                "Jason Wei",
                "Nathan Scales",
                "Xuezhi Wang",
                "Dale Schuurmans",
                "Olivier Bousquet",
                "Quoc Le",
                "Ed Chi."
            ],
            "title": "Least-to-most prompting enables complex reasoning in large language models",
            "venue": "arXiv preprint",
            "year": 2022
        },
        {
            "authors": [
                "Jie Zhou",
                "Ganqu Cui",
                "Shengding Hu",
                "Zhengyan Zhang",
                "Cheng Yang",
                "Zhiyuan Liu",
                "Lifeng Wang",
                "Changcheng Li",
                "Maosong Sun."
            ],
            "title": "Graph neural networks: A review of methods and applications",
            "venue": "AI open, 1:57\u201381.",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "\u201cYour beliefs become your thoughts. Your thoughts become your words. Your words become your actions.\"\n\u2014 Mahatma Gandhi\nAutomatic response forecasting (Figure 1) on receivers for news media is a burgeoning field of\nThe code is available at https://github.com/ chenkaisun/SocialSense\nresearch that enables numerous influential applications, such as offering content producers a way to efficiently estimate the potential impact of their messages (aiding the prevention of unexpected negative outcomes) and supporting human writers in attaining their communication goals (Sun et al., 2023) for risk management. This direction is especially important nowadays as the proliferation of AI-generated misinformation, propaganda, and hate speech are becoming increasingly elusive to detection (Hsu and Thompson, 2023; Owen and Zahn, 2023). In this context, accurately forecasting the responses from different audiences or communities to news media messages becomes critical.\nOne of the primary challenges in personalized response forecasting lies in developing effective user representations. A crucial aspect to consider when representing a user is the integration of social dynamics (e.g., social interactions around a user) as well as their individual beliefs and interests. This becomes particularly relevant for users who lack\nexplicit profiles or historical activities (commonly referred to as lurkers). Previous efforts, however, have yet to explore the types of structural information that are helpful and how to best utilize such information (Lin and Chen, 2008; Giachanou et al., 2018; Yang et al., 2019; Wu et al., 2021).\nDuring our preliminary analysis, we observed that users who share similar beliefs, specifically social values, are often situated in distant communities within the explicit social network. To provide further context, our findings reveal that a significant portion (over 44.6%) of users in the network data we collected for our experiment share beliefs with other users who are at least two hops away in the network. This emphasizes the importance of considering the connections between users with similar beliefs, even if they are not directly linked in the social network. Furthermore, previous research has indicated that user history plays a significant role in the model\u2019s performance. However, it is often directly utilized without processing in existing approaches, leading to the introduction of noise in the modeling process.\nMotivated by these findings, we introduce SOCIALSENSE (where Sense refers to the understanding and perception of social dynamics and behaviors within the online realm), a novel framework for modeling user beliefs and the social dynamics surrounding users in a social network. In this work, we conduct experiments using the SOCIALSENSE framework in the context of response forecasting. Our approach aims to capture the pattern of how \u201csimilar neighbors respond to similar news similarly\u201d. To harness the potential of network features, we curated a new user-user graph comprising 18k users from Twitter (the data will be anonymized when released), augmenting the original dataset (Sun et al., 2023). The SOCIALSENSE framework consists of three key stages: (1) inducing latent user personas using the Large Language Model (e.g., ChatGPT (Liu et al., 2023)), (2) building a belief-centered network on top of the existing social network, and (3) propagating information across multiple levels.\nWe demonstrate the effectiveness of our method through experiments on the dataset from Sun et al. (2023). Our results show that our framework outperforms existing baselines consistently across metrics in both zero-shot and fully-supervised settings. We further conduct a detailed analysis to address research questions concerning the model\u2019s general-\nizability to unseen users and its predictive capabilities for lurkers. Our findings reveal two additional key insights: (1) the model performs exceptionally well in scenarios involving lurkers, outperforming the baseline by over 10% accuracy score in sentiment polarity forecasting, and, (2) compared to baseline approaches, the model exhibits consistently better generalization capabilities when applied to unseen users. Additionally, our analysis underscores the significance of various components within the belief-augmented social network, revealing that both the belief-centered graph and the user-news interaction network play vital roles in determining the network\u2019s overall performance."
        },
        {
            "heading": "2 Task Formulation",
            "text": "In the task of Response Forecasting on Personas for News Media, our objective is to predict how users will respond to news media messages. Specifically, we focus on analyzing the sentiment intensity and polarity of these responses. Formally, given a persona P (representing the user) and a news media message M, our goal is to predict the persona\u2019s sentiment polarity \u03d5p (categorized as either Positive, Negative, or Neutral) and intensity \u03d5int (measured on a scale of 0 to 3) of the persona\u2019s response. We frame this task as a multi-class prediction problem."
        },
        {
            "heading": "3 SOCIALSENSE",
            "text": "To accurately predict individuals\u2019 responses, it is crucial to develop an effective user representation that captures their personas. While previous studies have utilized user profiles and historical data to model individuals\u2019 interests with reasonable accuracy, there is a significant oversight regarding the behavior of a large number of internet users who are passive participants, commonly referred to as lurkers. This phenomenon is exemplified by statistics showing that only 25% of highly active users generate 97% of the content on Twitter (McClain et al., 2021). Consequently, the sparse historical data available for lurkers makes it challenging to infer their responses reliably. To address this issue, a social network-based approach can be employed to leverage users\u2019 social connections, gathering information from their neighbors. However, it is important to question whether relying solely on social networks is sufficient.\nIn this work, we introduce a novel perspective by borrowing the concept of belief and defining it in terms of social values. By considering so-\ncial values, which encompass human values and moral values, we capture individuals\u2019 deeply held convictions, principles, and ethical standards that significantly shape their perspectives, behaviors, and responses within a social context. Our preliminary analysis reveals that individuals who share beliefs are often distantly connected, beyond residing in the same community. Specifically, we found that over 44.6% of users in our collected network data share beliefs with others who are at least two hops away in the network. This finding highlights the potential value of bridging these distant users and incorporating their beliefs as valuable features in response forecasting.\nIn this study, we present SOCIALSENSE (Figure 2), an innovative framework for modeling user beliefs and the social dynamics within a social network by automatically curating a belief-centered social network using a Large Language Model (e.g., ChatGPT). Our approach consists of three stages: (1) extracting latent personas using a Large Language Model, (2) constructing a belief-centered network on top of the existing social network, and (3) information propagation. In addition to the supervised method, we further explore how to achieve zero-shot prediction with social networks by simu-\nlating graph propagation with SOCIAL PROMPT."
        },
        {
            "heading": "3.1 Unmasking Latent Persona with Large Language Model",
            "text": "Although the user\u2019s past posts can provide insights into their interests, they often contain noise that makes them challenging for models to consume. For instance, they may describe life events without providing context, such as \u201c@user Waited all day next to phone. Just got a msg...\u201d. Furthermore, relying solely on raw historical data discourages explainability in response forecasting since past utterances are influenced by a person\u2019s internal beliefs rather than being the sole determinant of their future response.\nIn recent months, the Large Language Models (LLMs), particularly ChatGPT, have been shown to surpass human annotators in various tasks given their effective training techniques and access to vast amounts of pretraining data (Gilardi et al., 2023). This breakthrough presents unprecedented opportunities in analyzing users comprehensively without being scoped by previously established research. For the first time, we leverage a large language model (specifically, ChatGPT in our experiment) to extract users\u2019 internal beliefs and construct beliefs suitable for downstream consumption.\nIn this initial stage of our framework, we design a prompt Pl that enables us to extract latent information not available anywhere online. This includes dimensions such as human values, moral values, views on entities and issues, professions, and more. The prompt we have developed is shown in the Appendix. We refer to the latent persona extracted from the LLM for a user as UserL. In other words,\nUserL = LLM(profile, history,Pl) (1)"
        },
        {
            "heading": "3.2 Belief-Augmented Social Network",
            "text": "To capture social interactions and bridge distant communities, our approach incorporates both existing and induced social information to construct a network that focuses on modeling users\u2019 beliefs.\nOur graph can be formally defined as follows: it comprises three sets of nodes, namely VM representing the news media messages, VU representing the users, and VB representing a fixed set of belief nodes. The graph consists of three types of edges: EI , EF , and EB . For each edge (u,m) \u2208 EI , where u \u2208 VU and m \u2208 VM , it indicates that user u has interacted with the news media message m. For\neach edge (u1, u2) \u2208 EF , where u1, u2 \u2208 VU , it signifies that user u1 follows user u2. Lastly, for each edge (u, b) \u2208 EB , where u \u2208 VU and b \u2208 VB , it denotes that user u believes in the value represented by node b. An illustrative example sub-graph of the network is shown in Figure 3. Social Relation Network The first layer of our network consists of the user-user social network, where edges from User a to b indicate that User a follows User b. This network captures the interests of users and the relationships between users. User-Media Interactions The second component of our network comprises news nodes and response edges indicating the users in the network have responded to these news nodes in the dataset. This feature offers two advantages. Firstly, it serves as a representation of users\u2019 interests. Secondly, it facilitates the connection of users who are geographically distant in the network but might share interests in news topics, thus enabling the expansion of the set of potentially reliable neighbors for any user we would like to predict. Belief-Centered Graph Lastly, we introduce belief nodes, composed of moral and human values (principles that guide behaviors) from the Latent Personas. MORAL VALUES: Moral values are derived from a set of principles that guide individuals or societies in determining what is right or wrong, good or bad, and desirable or undesirable. We define the set of Moral Values based on the Moral Foundations Theory (Graham et al., 2018), which includes Care/Harm, Fairness/Cheating, Loyalty/Betrayal, Authority/Subversion, and Purity/Degradation. HUMAN VALUES: Human values are defined based on the Schwartz Theory of Basic Values (Schwartz, 1992), encompassing Conformity, Tradition, Security, Power, Achievement, Hedonism, Stimulation, Self-Direction, Universalism, and Benevolence. These values represent desirable goals in human life that guide the selection or evaluation of actions and policies.\nBuilding upon the network from the previous stage, we establish connections between users and their associated values in an undirected manner. This connection type offers two key benefits. Firstly, it introduces shortcuts between users who share similar beliefs or mindsets, facilitating the propagation of information across distant nodes. Secondly, it allows the prediction results of user responses to potentially be attributed to the belief\nnodes (instead of past utterances), thereby enhancing the explainability of the process."
        },
        {
            "heading": "3.3 Information Propagation",
            "text": "Given the constructed belief graph, we utilize a Graph Neural Network (GNN) (Zhou et al., 2020) to propagate information and learn an updated user representation, enabling us to infer user responses. Node Initialization To train the GNN, we first need to initialize the node representations. For user nodes VU , we leverage a Pretrained Language Model (PLM) such as DeBERTa (He et al., 2020) to encode the user\u2019s profile and history, yielding a d-dimensional dense vector u. Similarly, we initialize media nodes VM by encoding the news headline message by the PLM, obtaining vector m. The embeddings for the fixed set of belief nodes VB , b, are initialized by random vectors. Graph Propagation We consider response forecasting as a reasoning process over the connections among news media, user, and belief nodes in the social graph. Leveraging the social homophily phenomenon, we posit that the constructed social ties lead to the formation of communities reflecting similarities and differences in beliefs, both within and across communities. To capture the interactions across different types of graph components, we employ a Heterogeneous Graph Transformer (HGT) (Hu et al., 2020), which was inspired by the architecture of the classic Transformer (Vaswani et al., 2017). Unlike homogeneous GNNs, HGT\neffectively handles different edge and node types as separate meta paths, facilitating the learning of user representations from various types of contextual nodes.\nUpon obtaining the updated user representations from HGT, we concatenate them with the news embeddings. The resulting vector is passed through an MLP layer followed by a softmax activation function for classification. The model is trained using cross-entropy loss, where the labels are sentiment intensity/polarity."
        },
        {
            "heading": "3.4 Zero-Shot Prediction by Simulating Propagation with Social Prompts",
            "text": "To forecast responses in a zero-shot fashion, one approach involves directly feeding user profiles, historical data, and news headlines into large language models like ChatGPT. However, this approach lacks the inclusion of the user\u2019s social network and encounters challenges when dealing with lurkers who have limited background information. As demonstrated in the experiment section, including social context provides a clear advantage in response forecasting. In this section, we introduce the concept of SOCIAL PROMPT to simulate information propagation in the supervised setting. Neighborhood Filtering To aggregate information, one needs to select information from neighbors. Since language models have a limited context window and a user typically has hundreds of followers/followings, we filter the set of neighbors by ranking the neighbors based on their influence on the user\u2019s opinion. In our design, we utilize the concept of authority from the persuasion techniques (Braca and Dondio, 2023), using the number of followers a neighbor has to determine their level of influence. We select the top-K neighbors NK as the filtered set to represent the social context of the central user. Aggregation and Prediction Given the latent user personas attributes, UsernL extracted for each neighbor n \u2208 NK of central node c, extracted from Section 3.1 for each neighbor, and the filtered neighborhood from the previous step, we construct a prompt Ps (shown in the Appendix) that allows the LLM to produce a socially aware persona UserS . Finally, we design a prediction prompt Pp, which utilizes both UserL and UserS of the central node to make predictions. Formally,\nR = LLM(Pp,UcL,LLM(Ps, {UnL}n\u2208N K ))\n(2)\nwhere U abbreviates User, Uc indicates the current central user, and R indicates the prediction results."
        },
        {
            "heading": "4 Experiment",
            "text": ""
        },
        {
            "heading": "4.1 Data Construction",
            "text": "We use the dataset from (Sun et al., 2023) (denoted as RFPN) as the base for evaluation. The dataset consists of 13.3k responses from 8.4k users to 3.8k news headlines collected from Twitter. More details are shown in the Appendix. Network Data To test SOCIALSENSE, we curate a social network using the official Twitter API1. We initialize the network with the users in RFPN Xs. We collect all the users that each user u \u2208 Xs follows and denote them as Xt. We then select the top 10000 followed accounts from Xt \u222aXs as the most influential nodes, and denote them Xf . Lastly, we merge the top influencers with the original user set Xs into the final set VU = Xf \u222a Xs. Our final graph consists of 18, 634 users and 1, 744, 664 edges."
        },
        {
            "heading": "4.2 Experimental Setup",
            "text": "Evaluation Metrics We evaluate the prediction of sentiment intensity using the Spearman and Pearson correlation, which are denoted as rs and r, respectively. For the classification of sentiment polarity, we evaluate with the Micro-F1 score (or equivalently accuracy in the multi-class case) and Macro-F1 score, denoted as MiF1 and MaF1. Baselines We conduct a comparative analysis of SOCIALSENSE with several baseline models, including DeBERTa (He et al., 2020) (upon which our node initialization is based) and RoBERTa (Liu et al., 2019b), which are state-of-the-art pretrained language models known for their performance across various downstream tasks like sentiment analysis and information extraction. Additionally, we compare our approach with the InfoVGAE model (Li et al., 2022), a state-of-the-art graph representation learning model specifically designed for social polarity detection. InfoVGAE constructs a graph that captures the edges between users and news articles to learn informative node embeddings. We extend this model by incorporating user-user edges and also an additional two-layer MLP classifier head to adapt it for our supervised tasks. Furthermore, we include two naive baselines, namely Random and Majority. The Ran-\n1https://developer.twitter.com/en/docs/ twitter-api\ndom baseline makes predictions randomly, while the Majority baseline follows the majority label. These baselines serve as simple reference points for comparison. Lastly, we compare our response forecasting results with ChatGPT, a state-of-theart zero-shot instruction-following large language model (LLM) (Yang et al., 2023). To predict the sentiment intensity and polarity using ChatGPT, we use the prompt Pp from Section 3.4 that incorporates the user profile, user history, and the news media message as the input. We leverage the official OpenAPI with the gpt-3.5-turbo model2 for sentiment prediction.\nTo illustrate the effectiveness of SOCIAL PROMPTS (Section 3.4), we compare three models: baseline ChatGPT, ChatGPTL, and SocialSenseZero. In ChatGPTL, we incorporate the latent persona UserL from Section 3.1, while in SocialSenseZero, we leverage the aggregated social context UserS generated by SOCIAL PROMPT in addition to UserL (Section 3.4). We use K = 25 for SOCIAL PROMPT. Similarly, we utilize the prompt Pp for response prediction. The detailed prompts can be found in the Appendix. Implementation and Environments Our neural models are implemented using Pytorch (Paszke et al., 2019) and Huggingface Transformers (Wolf et al., 2020). The intensity label in the dataset follows the definition in the SemEval-2018 Task 13 (Mohammad et al., 2018), where the sign is also considered during evaluation. More implementation details and discussions of reproducibility and hyperparameters can be found in the Appendix."
        },
        {
            "heading": "4.3 Results Discussion",
            "text": "We conduct an evaluation of the proposed SOCIALSENSE model and the baseline models introduced in Section 4.2 for the supervised response forecasting task. The evaluation results are presented in Table 1. While the state-of-the-art models demonstrate competitive performance, SOCIALSENSE outperforms all other models across all evaluation metrics consistently. Although ChatGPT is designed and proven effective for zero-shot instruction-following text generation, we observe that its performance in sentiment forecasting of responses is comparatively limited, yielding lower scores compared to the other supervised models.\n2https://platform.openai.com/docs/ api-reference/models\n3https://competitions.codalab.org/ competitions/17751\nThis highlights that the task can not be fully addressed by a zero-shot model alone.\nOn the other hand, the RoBERTa and DeBERTa models, despite being smaller pre-trained models, exhibit relatively better correlation and F1 scores after fine-tuning for our response prediction task on news articles. However, these models only utilize textual information from news articles and user profiles, disregarding potential interaction patterns and shared beliefs among users. This explains why their correlations and F1 scores are, on average, 10.28% and 5.99% lower than those achieved by the proposed SOCIALSENSE framework. Additionally, the graph-based InfoVGAE model achieves higher scores compared to the text-based DeBERTa and RoBERTa baselines, highlighting the significance of graph-structured data in enhancing response forecasting performance. However, the evaluation metrics of the InfoVGAE model remain lower than those of SOCIALSENSE. While the InfoVGAE model constructs a graph primarily based on user-user and user-news interaction edges, SOCIALSENSE goes a step further by inducing and integrating additional belief nodes and edges. This novel approach results in a heterogeneous graph that forges connections among users who share similar perspectives and ideologies, thereby facilitating the learning of intricate social dynamics and bolstering the model\u2019s predictive capabilities."
        },
        {
            "heading": "4.4 Ablation Study",
            "text": "We conduct an ablation study on different components of SOCIALSENSE to evaluate their impact on\nperformance. The results are presented in Table 1. Belief-Centered Graph To assess the effectiveness of the Belief-Centered Graph in Section 3.2, we conduct an experiment where we removed the belief nodes from the graph, including the nodes representing moral values and human values. This leads to a decrease of 1.91% in correlations and 4.83% in F1 scores. These findings support our hypothesis that incorporating belief nodes is effective in modeling the shared beliefs and values among users. By including belief nodes, we enable the graph learning framework to capture the association between the underlying principles and moral frameworks that guide users\u2019 behaviors and response patterns. User-News Edges In this experiment, we exclude the user-news edges while constructing the beliefaugmented heterogeneous graph. The results show that modeling the user-news interaction as edges results in an improvement of up to 6.63% in correlation metrics for sentiment intensity prediction. This indicates that modeling users\u2019 interests and historical interactions with media is crucial for accurately predicting sentiment intensity. User Profile and Historical Posts The ablation study reveals the important roles of user profile data and historical post data in response forecasting. Excluding user profile data leads to a drop of 1.93% and 6.32% on average in the respective tasks, emphasizing its significance in predicting sentiment polarity. Removing historical post data results in a decrease of approximately 4.45% in correlations and 2.66% in F1 scores for sentiment polarity prediction. These findings highlight the importance of both data types, with profile data influencing intensity prediction more and historical data affecting polarity prediction more. Node Initialization Instead of using the text representations of users\u2019 profiles and historical posts, we randomly initialize the node features. This results in a decrease of 3.57% in correlations and a significant decrease of 8.97% in F1 scores for polarity classification, emphasizing the significance of text features in predicting sentiment polarity."
        },
        {
            "heading": "4.5 Zero-Shot Evaluation",
            "text": "In addition to supervised response forecasting, we also evaluate our framework under the zeroshot setting (Section 3.4). The results are presented in Table 2. Based on the higher scores attained by ChatGPTL, it is evident that the in-\nclusion of latent structured persona information indeed aids the model in comprehending the user more effectively. Furthermore, our model, SOCIALSENSEZero, achieves the highest scores consistently across all metrics. This demonstrates the efficacy of our method for zero-shot social context learning and provides compelling evidence that even in the zero-shot setting, social context plays a crucial role in response forecasting."
        },
        {
            "heading": "4.6 Evaluation on Lurker and Unseen User Scenarios",
            "text": "We evaluate the performance of proposed models and baselines on the task of response forecasting for lurker users, who are characterized as users with only a small amount of historical posts. In the experiment, we define the lurkers as the users with less than 50 historical responses (less than 85% of the users in the dataset), and the scenario consequently contains 745 test samples. The scores are shown in Table 3. Compared to the previous evaluation results in Table 1, we observe that the overall evaluation scores for all the models are significantly lower. This can be attributed to the fact that lurkers have a much smaller background context, making response prediction more challeng-\ning. The lurker case is especially difficult for those baselines relying heavily on historical responses. In this challenging scenario, SOCIALSENSE not only achieves significantly higher scores than others in all of the metrics but also maintains its performance on the polarity measures. Specifically, the advantage of our proposed model over DeBERTa and RoBERTa expands from 5.99% to 11.26% in terms of F1 scores for sentiment polarity prediction. These results demonstrate that even in cases where user textual information is extremely limited, our framework can still accurately infer responses, showcasing the robustness of our method. Furthermore, it is worth noting that the intensity score was noticeably lower compared to the regular setting, indicating that predicting the intensity of responses becomes more challenging when historical information is limited. We conduct further evaluation of the proposed model and baselines on unseen users, which refers to the responders who only appear in the evaluation dataset. This case study on unseen users provides insights into the generalization of the models. The evaluation results are presented in Table 3. The results indicate that the unseen user scenario presents a more challenging task compared to previous settings. Moreover, SOCIALSENSE demonstrates significantly higher performance across all metrics compared to other baselines. This outcome underscores the framework\u2019s ability to effectively generalize to unseen users, likely attributed to its robust modeling of the social network and encoding of relationships between users."
        },
        {
            "heading": "5 Related Work",
            "text": "Existing research has focused on predicting the individual-level response using additional textual features as well as deep neural networks (DNN) (Lin and Chen, 2008; Artzi et al., 2012; Li et al., 2019; Wang et al., 2020). However, these existing methods neglected the important information about users\u2019 personas as well as the modeling of graph-structured interactions among users with the social items. Another line of related works formulates the response forecasting as text-level generation task (Yang et al., 2019; Wu et al., 2021; Lu et al., 2022; Wang et al., 2021). However, these lack a quantitative measure for analyzing the response (such as in the sentiment dimensions), limiting their applicability in downstream tasks like sentiment prediction on impact evaluation of\nnews (Sun et al., 2023). In contrast, we propose a novel framework that leverages large language models to induce the graph structure and integrates disentangled social values to forecast responses, whether in a supervised or zero-shot manner. Our work demonstrates that effectively modeling the social context and beliefs of users provides a clear advantage in the social media response forecast task. This can ultimately benefit various downstream applications such as assisting fine-grained claim frame extraction (Gangi Reddy et al., 2022) and situation understanding (Reddy et al., 2023).\nIn the field of Social-NLP, related research has focused on applying NLP techniques, large language models (LLM), and prompting strategies to model, analyze, and understand text data generated in social contexts. For instance, progress has been made in misinformation detection (Fung et al., 2021; Wu et al., 2022; Huang et al., 2023b) and correction (Huang et al., 2023a), propaganda identification (Martino et al., 2020; Oliinyk et al., 2020; Yoosuf and Yang, 2019), stance detection (Zhang et al., 2023), ideology classification (Kulkarni et al., 2018; Kannangara, 2018), LM detoxification (Han et al., 2023), norms grounding (Fung et al., 2023), popularity tracking (He et al., 2016; Chan and King, 2018), and sentiment analysis (Araci, 2019; Liu et al., 2012; Azzouza et al., 2020). The emergence of advanced decoder language models like ChatGPT has led to extensive research on prompting techniques and their application across various NLP tasks (Zhou et al., 2022; Kojima et al., 2022; Zhao et al., 2021; Diao et al., 2023; Sun et al., 2022). Indeed, experiments have shown that ChatGPT even outperforms crowd workers in certain annotation tasks (Gilardi et al., 2023). However, when it comes to social tasks like response forecasting, relying solely on large-scale models without taking into account the social context and users\u2019 personas may not yield optimal performance (Li et al., 2023). Our experiments demonstrate that incorporating social context in the prompt consistently enhances the LLM\u2019s performance, as showcased in our simulation of information propagation using large language models."
        },
        {
            "heading": "6 Conclusions and Future Work",
            "text": "In conclusion, we present SOCIALSENSE, a framework that utilizes a belief-centered graph, induced by a large language model, to enable automatic response forecasting for news media. Our framework\noperates on the premise that connecting distant users in social networks facilitates the modeling of implicit communities based on shared beliefs. Through comprehensive evaluations, we demonstrate the superior performance of our framework compared to existing methods, particularly in handling lurker and unseen user scenarios. We also highlight the importance of the different components within the framework. In future research, it would be valuable to explore the application of belief-augmented social networks in other domains and to develop an effective social prompting strategy for general-purpose applications. Furthermore, it is worth investigating how response forecasting models can adapt efficiently to dynamically evolving data, especially given the swift changes observed in real-world social media platforms (de Barros et al., 2023; Cheang et al., 2023).\nLimitations\nWhile the proposed SOCIALSENSE framework demonstrates promising results in response forecasting, there are limitations to consider. Firstly, the performance of the model heavily relies on the quality and availability of social network data. In scenarios where these sources are extremely limited or noisy, the model\u2019s predictive capabilities may be compromised. Additionally, the generalizability of the framework to different domains and cultural contexts needs to be further explored and evaluated.\nEthics Statements\nThe primary objective of this study is to enable content producers to predict the impact of news releases, thereby mitigating the risk of unforeseen negative consequences such as social conflict and moral injury. By providing a stronger and more robust framework for forecasting responses, we aim to contribute to the creation of a safer online environment. In our process of collecting the network data using Twitter API, we strictly adhere to the Twitter API\u2019s Terms of Use4. As part of our commitment to responsible data handling, we will release only an anonymized version of the network data when making the code repository publicly available.\n4https://developer.twitter.com/en/ developer-terms/agreement-and-policy"
        },
        {
            "heading": "Acknowledgement",
            "text": "This research is based upon work supported in part by U.S. DARPA INCAS Program No. HR001121C0165. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of DARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein."
        },
        {
            "heading": "A Appendix",
            "text": "A.1 Implementation Details We implement the training framework using the 4.8.2 version of Huggingface Transformer library5(Wolf et al., 2020). For the graph model implementation in Section 3.3, we use the 2.0.3 version of PyG6. The hyperparameters for the experiment are shown in Table 4 and the ones not listed in the table are set to be default values from the transformer library. We use RAdam (Liu et al., 2019a) as the optimizer. We perform greedy hyperparameter search on the gnn_layer from {1,2,3}, learning rate from {5e-5, 1e-4, 5e-4, 1e-3}, # attention heads from {2, 4, 6, 8}, activation from {tanh, relu}, # epochs from {350, 1000}, and node\n5https://github.com/huggingface/transformers 6https://pytorch-geometric.readthedocs.io/en/\nlatest/index.html\ndimensions from {128, 256}. We perform our experiments on a single NVIDIA RTX A6000 48 GB. Our model consists of 10, 484, 424 tuning parameters and it takes less than 30 minutes to fine-tune.\nA.2 Analysis of Belief Data We perform additional analysis on the belief data. Specifically, we show the distribution of the belief data (Figure 4), for which the moral value of care is dominant among the users. We have also segregated the model\u2019s performance in sentiment prediction based on the users\u2019 belief values and show it in Table 6. Empirical results indicate that the model is more accurate when predicting sentiments for users characterized by universalism and degradation. Conversely, the model finds it challenging to predict sentiments for users in the categories of security and stimulation. We further sampled 50 ChatGPT extraction results from user histories and distributed them among three human raters to assess the accuracy of the extracted profiles. These raters are graduate students who qualified through an initial quiz comprising eight samples. On evaluation, the raters assigned an average score of 3.9 out of 5 for accuracy. While not flawless, these extracted beliefs play a significant role in boosting the model\u2019s performance. Such finding indicates that refining the ChatGPT extraction process could potentially lead to enhanced performance outcomes.\nA.3 Prompts Templates We show all prompts used in the work in Figure 5, Figure 6, Figure 7, Figure 8, and Figure 9. They represent Pl, Ps, Pp for the baseline ChatGPT, Pp for ChatGPTL, and Pp for SocialSenseZero respectively."
        }
    ],
    "title": "Decoding the Silent Majority: Inducing Belief Augmented Social Graph with Large Language Model for Response Forecasting",
    "year": 2023
}