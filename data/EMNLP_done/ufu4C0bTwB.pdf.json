{
    "abstractText": "Target-oriented dialogue systems, designed to proactively steer conversations toward predefined targets or accomplish specific system-side goals, are an exciting area in conversational AI. In this work, by formulating a <dialogue act, topic> pair as the conversation target, we explore a novel problem of personalized targetoriented dialogue by considering personalization during the target accomplishment process. However, there remains an emergent need for high-quality datasets, and building one from scratch requires tremendous human effort. To address this, we propose an automatic dataset curation framework using a role-playing approach. Based on this framework, we construct a large-scale personalized target-oriented dialogue dataset, TOPDIAL1, which comprises about 18K multi-turn dialogues. The experimental results show that this dataset is of high quality and could contribute to exploring personalized target-oriented dialogue.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jian Wang"
        },
        {
            "affiliations": [],
            "name": "Yi Cheng"
        },
        {
            "affiliations": [],
            "name": "Dongding Lin"
        },
        {
            "affiliations": [],
            "name": "Chak Tou Leong"
        },
        {
            "affiliations": [],
            "name": "Wenjie Li"
        }
    ],
    "id": "SP:b824de81ea7c9d6e6066b18b1b92c1c1e2aa7e42",
    "references": [
        {
            "authors": [
                "Yejin Bang",
                "Samuel Cahyawijaya",
                "Nayeon Lee",
                "Wenliang Dai",
                "Dan Su",
                "Bryan Wilie",
                "Holy Lovenia",
                "Ziwei Ji",
                "Tiezheng Yu",
                "Willy Chung"
            ],
            "title": "A multitask, multilingual, multimodal evaluation of chatgpt",
            "year": 2023
        },
        {
            "authors": [
                "Yang Deng",
                "Wenqiang Lei",
                "Wai Lam",
                "Tat-Seng Chua."
            ],
            "title": "A survey on proactive dialogue systems: Problems, methods, and prospects",
            "venue": "Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, IJCAI-23, pages 6583\u20136591.",
            "year": 2023
        },
        {
            "authors": [
                "Emily Dinan",
                "Angela Fan",
                "Adina Williams",
                "Jack Urbanek",
                "Douwe Kiela",
                "Jason Weston."
            ],
            "title": "Queens are powerful too: Mitigating gender bias in dialogue generation",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language",
            "year": 2020
        },
        {
            "authors": [
                "Joseph L Fleiss."
            ],
            "title": "Measuring nominal scale agreement among many raters",
            "venue": "Psychological bulletin, 76(5):378.",
            "year": 1971
        },
        {
            "authors": [
                "Lewis R Goldberg."
            ],
            "title": "The structure of phenotypic personality traits",
            "venue": "American psychologist, 48(1):26.",
            "year": 1993
        },
        {
            "authors": [
                "Biyang Guo",
                "Xin Zhang",
                "Ziyuan Wang",
                "Minqi Jiang",
                "Jinran Nie",
                "Yuxuan Ding",
                "Jianwei Yue",
                "Yupeng Wu."
            ],
            "title": "How close is chatgpt to human experts? comparison corpus, evaluation, and detection",
            "venue": "arXiv preprint arXiv:2301.07597.",
            "year": 2023
        },
        {
            "authors": [
                "Prakhar Gupta",
                "Harsh Jhamtani",
                "Jeffrey Bigham."
            ],
            "title": "Target-guided dialogue response generation using commonsense and data augmentation",
            "venue": "Findings of the Association for Computational Linguistics: NAACL 2022, pages 1301\u20131317, Seattle, United",
            "year": 2022
        },
        {
            "authors": [
                "Edward J Hu",
                "Phillip Wallis",
                "Zeyuan Allen-Zhu",
                "Yuanzhi Li",
                "Shean Wang",
                "Lu Wang",
                "Weizhu Chen"
            ],
            "title": "Lora: Low-rank adaptation of large language models",
            "venue": "In International Conference on Learning Representations",
            "year": 2022
        },
        {
            "authors": [
                "Minju Kim",
                "Chaehyeong Kim",
                "Yong Ho Song",
                "Seungwon Hwang",
                "Jinyoung Yeo."
            ],
            "title": "BotsTalk: Machine-sourced framework for automatic curation of large-scale multi-skill dialogue datasets",
            "venue": "Proceedings of the 2022 Conference on Empirical Meth-",
            "year": 2022
        },
        {
            "authors": [
                "Guohao Li",
                "Hasan Abed Al Kader Hammoud",
                "Hani Itani",
                "Dmitrii Khizbullin",
                "Bernard Ghanem."
            ],
            "title": "Camel: Communicative agents for \"mind\" exploration of large scale language model society",
            "venue": "arXiv preprint arXiv:2303.17760.",
            "year": 2023
        },
        {
            "authors": [
                "Margaret Li",
                "Jason Weston",
                "Stephen Roller."
            ],
            "title": "Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons",
            "venue": "Advances in Neural Information Processing Systems, Conversational AI Workshop.",
            "year": 2019
        },
        {
            "authors": [
                "Jungwoo Lim",
                "Myunghoon Kang",
                "Yuna Hur",
                "Seung Won Jeong",
                "Jinsung Kim",
                "Yoonna Jang",
                "Dongyub Lee",
                "Hyesung Ji",
                "DongHoon Shin",
                "Seungryong Kim",
                "Heuiseok Lim"
            ],
            "title": "You truly understand what I need : Intellectual and friendly dialog",
            "year": 2022
        },
        {
            "authors": [
                "Zeming Liu",
                "Haifeng Wang",
                "Zheng-Yu Niu",
                "Hua Wu",
                "Wanxiang Che"
            ],
            "title": "DuRecDial 2.0: A bilingual parallel corpus for conversational recommendation",
            "venue": "In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2021
        },
        {
            "authors": [
                "OpenAI."
            ],
            "title": "Introducing ChatGPT",
            "venue": "https:// openai.com/blog/chatgpt.",
            "year": 2022
        },
        {
            "authors": [
                "Shereen Oraby",
                "Lena Reed",
                "Shubhangi Tandon",
                "Sharath T.S.",
                "Stephanie Lukin",
                "Marilyn Walker."
            ],
            "title": "Controlling personality-based stylistic variation with neural natural language generators",
            "venue": "Proceedings of the 19th Annual SIGdial Meeting on Discourse",
            "year": 2018
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311\u2013318, Philadelphia,",
            "year": 2002
        },
        {
            "authors": [
                "Jinghui Qin",
                "Zheng Ye",
                "Jianheng Tang",
                "Xiaodan Liang."
            ],
            "title": "Dynamic knowledge routing network for target-guided open-domain conversation",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, 05, pages 8657\u20138664.",
            "year": 2020
        },
        {
            "authors": [
                "Arpit Rana",
                "Scott Sanner",
                "Mohamed Reda Bouadjenek",
                "Ron Dicarlantonio",
                "Gary Farmaner."
            ],
            "title": "User experience and the role of personalization in critiquing-based conversational recommendation",
            "venue": "ACM Transactions on the Web.",
            "year": 2023
        },
        {
            "authors": [
                "Karin Sevegnani",
                "David M. Howcroft",
                "Ioannis Konstas",
                "Verena Rieser."
            ],
            "title": "OTTers: One-turn topic transitions for open-domain dialogue",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International",
            "year": 2021
        },
        {
            "authors": [
                "Jianheng Tang",
                "Tiancheng Zhao",
                "Chenyan Xiong",
                "Xiaodan Liang",
                "Eric Xing",
                "Zhiting Hu."
            ],
            "title": "Targetguided open-domain conversation",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5624\u20135634, Florence,",
            "year": 2019
        },
        {
            "authors": [
                "Rohan Taori",
                "Ishaan Gulrajani",
                "Tianyi Zhang",
                "Yann Dubois",
                "Xuechen Li",
                "Carlos Guestrin",
                "Percy Liang",
                "Tatsunori B. Hashimoto."
            ],
            "title": "Stanford alpaca: An instruction-following llama model",
            "venue": "https:// github.com/tatsu-lab/stanford_alpaca.",
            "year": 2023
        },
        {
            "authors": [
                "Hugo Touvron",
                "Thibaut Lavril",
                "Gautier Izacard",
                "Xavier Martinet",
                "Marie-Anne Lachaux",
                "Timoth\u00e9e Lacroix",
                "Baptiste Rozi\u00e8re",
                "Naman Goyal",
                "Eric Hambro",
                "Faisal Azhar"
            ],
            "title": "Llama: Open and efficient foundation language models",
            "year": 2023
        },
        {
            "authors": [
                "Jian Wang",
                "Dongding Lin",
                "Wenjie Li."
            ],
            "title": "Dialogue planning via brownian bridge stochastic process for goal-directed proactive dialogue",
            "venue": "Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada. Association for",
            "year": 2023
        },
        {
            "authors": [
                "Jian Wang",
                "Dongding Lin",
                "Wenjie Li."
            ],
            "title": "A target-driven planning approach for goal-directed dialog systems",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems.",
            "year": 2023
        },
        {
            "authors": [
                "Wenquan Wu",
                "Zhen Guo",
                "Xiangyang Zhou",
                "Hua Wu",
                "Xiyuan Zhang",
                "Rongzhong Lian",
                "Haifeng Wang."
            ],
            "title": "Proactive human-machine conversation with explicit conversation goal",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computa-",
            "year": 2019
        },
        {
            "authors": [
                "Yuwei Wu",
                "Xuezhe Ma",
                "Diyi Yang."
            ],
            "title": "Personalized response generation via generative split memory network",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-",
            "year": 2021
        },
        {
            "authors": [
                "Zhitong Yang",
                "Bo Wang",
                "Jinfeng Zhou",
                "Yue Tan",
                "Dongming Zhao",
                "Kun Huang",
                "Ruifang He",
                "Yuexian Hou."
            ],
            "title": "TopKG: Target-oriented dialog via global planning on knowledge graph",
            "venue": "Proceedings of the 29th International Conference on Com-",
            "year": 2022
        },
        {
            "authors": [
                "Mingzhi Yu",
                "Emer Gilmartin",
                "Diane Litman."
            ],
            "title": "Identifying personality traits using overlap dynamics in multiparty dialogue",
            "venue": "Proceedings of Interspeech 2019, pages 1921\u20131925.",
            "year": 2019
        },
        {
            "authors": [
                "Jun Zhang",
                "Yan Yang",
                "Chencai Chen",
                "Liang He",
                "Zhou Yu."
            ],
            "title": "KERS: A knowledge-enhanced framework for recommendation dialog systems with multiple subgoals",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, pages",
            "year": 2021
        },
        {
            "authors": [
                "Wang",
                "Ji-Rong Wen"
            ],
            "title": "Towards topic-guided",
            "year": 2020
        },
        {
            "authors": [
                "Sevegnani"
            ],
            "title": "The test-unseen split ensures that none of the target topics in the test set are present in the training",
            "year": 2023
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Compared with traditional dialogue systems that focus merely on passively responding to user requirements, a recently investigated research topic of target-oriented dialogue systems (Sevegnani et al., 2021; Deng et al., 2023) specifies a conversation target from the system side, enabling the system to take the initiative and lead the conversation. Early work in this area mainly formulates the targets as mentioning certain keywords (Tang et al., 2019; Qin et al., 2020; Zhong et al., 2021; Yang et al., 2022) or specific topics (Wu et al., 2019; Sevegnani et al., 2021). To allow the formed targets to be applicable in broad scenarios, a few recent studies (Zhang et al., 2021; Wang et al., 2023b) define <dialogue act, topic> pairs as targets. For example, given the target of <movie recommendation, \"King\n1Our code and data are available at https://github. com/iwangjian/TopDial.\nof Comedy\">, the system needs to take appropriate dialogue acts and smoothly steer the discussed topic towards the designated one. Its ultimate objective is to achieve recommendations on the target topic \u201cKing of Comedy\u201d. Our work also follows the form of <dialogue act, topic> pairs as targets to study target-oriented dialogue systems due to their higher applicability in real-world scenarios.\nDespite many existing efforts, we find that two critical issues remain to be solved. One urgent problem is the need for well-organized benchmarks or datasets. Current studies for target-oriented dialogue (Gupta et al., 2022; Wang et al., 2023a) mainly re-purpose existing non-target-oriented dialogue datasets, which are not exactly suitable as they are crowd-sourced without consideration of target accomplishment. Nevertheless, building a new high-quality dataset from scratch requires expensive human effort. The other essential issue is that, target-oriented dialogue systems need to consider personalized aspects (Wu et al., 2021; Rana et al., 2023), such as user profiles and personalities, which were largely ignored by previous work. User profiles involve user preferences about potential topics relevant to the target, while personalities imply possible reactions and feedback during the dialogue process. With personalized information incorporated, the system could be tailored to a user and lead the conversation towards the target with higher engagement instead of obtrusively driving to the target, thereby improving user experience. Thus, we raise the question: How can we build high-quality datasets with little human effort for personalized target-oriented dialogue?\nIn this work, we first give a comprehensive definition (\u00a72) of personalized target-oriented dialogue, then lay out the desirable characteristics (\u00a72) that a qualified dialogue dataset should meet. Drawing inspiration from some recent work that has demonstrated unprecedented capabilities of large language models (LLM) in simulating human so-\ncial behaviors (Guo et al., 2023; Li et al., 2023), we propose a role-playing approach for automatic dataset curation (\u00a73) using multiple LLM agents. They are designed to follow specific instructions to fulfill the requirements. Based on that, we synthesize a large-scale dialogue dataset named TOPDIAL and show its quality and effectiveness (\u00a74).\nOur main contributions are: (1) We formulate the problem of personalized target-oriented dialogue, which is promising yet underexplored. (2) We propose a novel role-playing framework for automatic dialogue dataset curation. It provides insights into building large-scale datasets for many other dialogue tasks. (3) Our constructed TOPDIAL dataset is of high quality and contributes to the related research community."
        },
        {
            "heading": "2 Problem Formulation",
            "text": "Task Definition We consider a dialogue corpus D = {(Ui,Ki, Ti, Ci)}Ni=1, where N is the total number of dialogues. In the i-th dialogue, Ui represents the personalized information, such as the user\u2019s profiles and/or personalities. Ki represents the domain knowledge facts relevant to the i-th dialogue. Ti denotes the predefined target consisting of an <dialogue act, topic> pair. Ci = {Ci,t}NTt=1 is the dialogue content, with a total of NT turns. The task of personalized target-oriented dialogue is formalized as follows: given a target T , a set of user\u2019s personalized information U , a set of relevant domain knowledge K, and a dialogue context C, the objective is to proactively lead the conversation and generate proper utterances to achieve the target T at an appropriate time.\nDesirable Characteristics of Datasets Based on the above definition, we lay out two desirable characteristics that a qualified dataset should meet, namely target-oriented proactivity and personalization. Target-oriented proactivity emphasizes that a dialogue dataset should allow the system to (i) take the initiative throughout a conversation, (ii) proactively lead the discussed topic towards the target topic based on domain knowledge, and (iii) accomplish the target act. On the other hand, personalization indicates that dialogues in a qualified dataset should embody (i) user profiles, which may involve users\u2019 past preferences about potential topics relevant to the target, and (ii) user personalities, which may imply users\u2019 possible reactions and feedback during the system-initiative process."
        },
        {
            "heading": "3 Dataset Curation Framework",
            "text": "In this section, we describe a role-playing approach for automatic dataset curation using multiple LLM agents. Figure 1 depicts the whole framework, which involves one user agent, one system agent, and one moderator agent. All these agents are designed to follow specific instructions and communicate in our role-playing environment.\nRole-Playing Environment This environment is designed to provide a global description for prompting all LLM agents. To achieve desirable targetoriented role playing, we instantiate the environment description based on the domains of the predefined targets. For example, one can describe the environment as \u201cYou are participating in a conversation about music or movies.\u201d for a given target T = <movie recommendation, \u201cKing of Comedy\u201d>. Then, the description will be prepended to each agent\u2019s instructions.\nUser Agent The user agent aims to simulate human users who generate utterances conditioned on their specific profiles and personalities. Since there are many off-the-shelf dialogue datasets grounded with user profiles, we collect all user profiles from one chosen dataset and parse them into a profile slot pool. Each slot contains a particular slot key (e.g., name, age range, liked or disliked movies) and a list of candidate values. We randomly sample a slot value for each key, and then form all key-value pairs as the simulated user profile.\nInspired by Big-5 personality traits (Goldberg, 1993) that have been widely adopted in personalityaware tasks (Oraby et al., 2018; Yu et al., 2019), we randomly sample a positive or negative description\nfor each of the following traits: openness (O), conscientiousness (C), extraversion (E), agreeableness (A), neuroticism (N). The sampled descriptions are then combined as the simulated user personality. We verbalize the simulated user profile and personality in natural languages, prompting the user agent to act as a human user. We present our detailed instruction template in Appendix A.1.\nSystem Agent The system agent aims to serve as a human-like domain-specific enthusiast, such as a movie enthusiast who enjoys a variety of films, or a foodie who enjoys delicious food. Its longterm goal is to proactively lead the conversation towards the target, as discussed in \u00a72. To achieve target-oriented proactivity, we take a given target T and a set of relevant domain knowledge K (and a few comments related to the target topic, if applicable) from a chosen seed dataset as the fundamental prompting source. Besides, in human-to-human conversations, one can easily know the other\u2019s explicit profile information, while it is hard to be aware of implicit personality before their first conversation. Thus, we pass the simulated user profile yielded by the user agent to the system agent as a personalized prompting source (see Figure 1).\nWe assign required instructions to the system agent based on the above prompting sources and task definition. We provide the instruction template in Appendix A.2. In practice, we further enhance the system agent in a self-augmented instruction manner, where the agent\u2019s task prompt will be repeated at each dialogue round to avoid forgetting its long-term goal.\nModerator Agent The moderator agent is designed to automatically manage the termination of the conversation between the system and the user agents. To ensure that the synthetic data adhere to desirable characteristics, we set certain conditions to terminate the conversation. These condi-\ntions are outlined as follows: (1) The system agent completes the target act (e.g., recommendation) on the target topic, the user agent accepts it, and the system no longer takes the initiative for two rounds. (2) The user agent explicitly rejects the system agent\u2019s act on the target topic for the second time. (3) The conversation between the system and the user agents reaches a maximum number of rounds. For the first two conditions, we take a few dialogues from the seed dataset as in-context examples to demonstrate whether or not an ongoing conversation should be terminated. We present the detailed instruction template in Appendix A.3.\nDataset Curation We employ three ChatGPT (gpt-3.5-turbo version) agents as LLM agents for the above roles. We ask the system agent to initiate a greeting with the user agent, and they will chat turn by turn, resulting in multi-turn conversations. Their conversations are terminated by the moderator agent or the maximum limit of rounds.\nThe three agents can generate large-scale dialogues through their collaboration, with very little human effort involved in the whole process."
        },
        {
            "heading": "4 TOPDIAL Dataset",
            "text": "Based on our dataset curation framework, we synthesized the dataset TOPDIAL by utilizing the repurposed version (Wang et al., 2023a) of DuRecDial 2.0 (Liu et al., 2021) as the seed dataset after carefully considering the problem formulation and necessary prompting sources. We report more implementation details in Appendix B.1.\nDataset Statistics Table 1 compares TOPDIAL with related datasets. To the best of our knowledge, TOPDIAL is the first dataset equipped with the desirable characteristics discussed in \u00a72. It should be noted that the DuRecDial 2.0 dataset is crowdsourced without considering targets and is not exactly suitable for the end task of target-oriented proactive dialogue, while the re-purposed version of DuRecDial 2.0 largely relies on human effort to form targets and preprocess dialogues. In comparison, our TOPDIAL dataset is curated based on target-oriented proactivity. In addition, by grounding the personality information during the dataset curation process, TOPDIAL is more natural and effective in reflecting personalization.\nTable 2 shows detailed statistics of the TOPDIAL dataset (see domain distributions in Figure 2). We also visualize the transitions of dialogue acts of the system through the first six dialogue rounds in Figure 3. We observe that the system often asks preferences or other questions at the very beginning. As the dialogue continues, the system introduces topic-related attributes and elicits the user\u2019s interest. It shows that the system proactively leads the dialogue and gradually achieves target dialogue acts, i.e., recommendations on target topics.\nAutomatic and Human Evaluations To assess the quality of TOPDIAL, we conduct LLM-based automatic evaluation and human evaluation. We randomly choose 100 targets and then sample one dialogue per target from the seed and TOPDIAL datasets, respectively. We ask ChatGPT (OpenAI, 2022) and human evaluators to compare each pair of dialogues over four metrics: proactivity (Proact.), coherence (Coh.), personalization (Pers.), and target success rate (Succ.). We provide details for these metrics and our evaluation settings in Appendix B.2.\nFigure 4 shows the evaluation results, where Fleiss\u2019s kappa (Fleiss, 1971) scores are distributed between [0.41, 0.60], indicating moderate interevaluator agreement. We observe that for all metrics, the TOPDIAL dataset achieves comparable and slightly higher win percentages over the seed dataset. It verifies the high quality of TOPDIAL.\nDataset Evaluation by Baseline Models We quantitatively evaluate TOPDIAL using representative dialogue models, including DialoGPT (Zhang et al., 2020) and Alpaca-7B (Taori et al., 2023). We fine-tune these models on the seed and TOPDIAL datasets, respectively, with an identical training data size. For a fair comparison, we build the test set for evaluation with 50% from the seed test data\nand 50% from the TOPDIAL test data. Our evaluation metrics include the average score of BLEU1/2 (Papineni et al., 2002), persona F1 (Lim et al., 2022), knowledge F1 and target success rate (Succ.) (Wang et al., 2023a). We describe details of these metrics and model training in Appendix C.\nThe comparison results reported in Table 3 show a similar trend: the two baseline models trained on our TOPDIAL dataset significantly outperform those trained on the seed dataset. In particular, our TOPDIAL dataset is more effective in training personalized target-oriented dialogue models (e.g., much higher persona F1 and Succ. socres) by grounding the profile and personality information during the dataset curation process. It shows that TOPDIAL is an effective training resource for the personalized target-oriented dialogue task.\nCase Study Due to space limitation, we present some cases in Appendix D (see Figure 9 and Figure 10) for a better understanding. These cases intuitively show that our TOPDIAL dataset fulfills target-oriented proactivity and personalization. It also shows that our dataset curation framework can be a viable alternative for building personalized target-oriented dialogue datasets."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this work, we explore a new task: personalized target-oriented dialogue. We first define this challenging task, and then lay out the desirable characteristics that a qualified dialogue dataset should meet. We propose a novel role-playing framework for automatic dataset curation, based on which we construct a large-scale dialogue dataset TOPDIAL. Our statistics and evaluations validate its effectiveness and high quality."
        },
        {
            "heading": "Limitations",
            "text": "Since we adopt ChatGPT agents to simulate the designed roles, ensuring the factual correctness of the synthetic dialogues during the role-playing\nprocess is challenging, as ChatGPT may produce output content with hallucinations (Bang et al., 2023). We intend to improve the dataset curation process with some post-processing steps, such as fact-checking and correction based on the grounded domain knowledge. In addition, we observe that sometimes the moderator agent cannot appropriately terminate a conversation due to its difficulty in understanding the achievement of the target, even though it has been assigned with detailed instructions and in-context examples. We will leave this for future research."
        },
        {
            "heading": "Ethical Considerations",
            "text": "Developing target-oriented dialogue systems requires careful ethical considerations due to the potential impact on specific scenarios. As an application scenario explored in this work, providing recommendations is one of the highly-applicable target dialogue acts. Target-oriented dialogue systems can create non-obtrusive recommendations for specific products and services. Our work does not force the system to achieve the designated target nor force users to accept recommendations.\nWe emphasize that regulation of the target designation is crucial when deploying target-oriented dialogue systems in particular domains. For instance, specifying a target should not violate factual correctness, user privacy rules, or laws of human society. We want to raise awareness about the potential misuse of such systems with toxic intentions. For example, such systems may be used to pose as humans and mislead users through conversations. To avoid such risks, we highlight that it is necessary to improve transparency, such as informing users that they are chatting with a bot, not a human."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was supported by the Research Grants Council of Hong Kong (15207122, 15207920, 15207821, 15204018, 15213323) and National Natural Science Foundation of China (62076212). It was also supported in part by PolyU internal grants (ZVQ0, ZVVX)."
        },
        {
            "heading": "A.1 User Agent",
            "text": "We provide the assigned instruction template for the user agent in Figure 5."
        },
        {
            "heading": "A.2 System Agent",
            "text": "We provide the assigned instruction template for the system agent in Figure 6."
        },
        {
            "heading": "A.3 Moderator Agent",
            "text": "We provide the assigned instruction template for the moderator agent in Figure 7."
        },
        {
            "heading": "B TOPDIAL Dataset",
            "text": "B.1 Implementation Details of Dataset Curation\nIn this work, we implemented our role-playing framework based on an open-source library named ChatArena2. We called the gpt-3.5-turbo version of ChatGPT API3 to build each LLM agent. We adopted a temperature of 0.75 to generate responses for all agents. We set the maximum number of tokens to generate to 100, 80, and 20 for\n2https://github.com/chatarena/chatarena 3https://platform.openai.com/docs/\napi-reference/chat"
        },
        {
            "heading": "Task Prompt:",
            "text": ""
        },
        {
            "heading": "User Profile-specific Prompt:",
            "text": ""
        },
        {
            "heading": "System Role Prompt:",
            "text": ""
        },
        {
            "heading": "Task Prompt:",
            "text": ""
        },
        {
            "heading": "User Personality-specific Prompt:",
            "text": ""
        },
        {
            "heading": "User Profile-specific Prompt:",
            "text": "the system, user, and moderator agents, respectively. We set a maximum limit of 8 rounds based on our observation of target accomplishment while ensuring that the dataset curation is not too costly. We synthesized three different dialogue instances for each seed example in the chosen seed dataset, i.e., the repurposed version (Wang et al., 2023a) of DuRecDial 2.0 (Liu et al., 2021). On average, the cost of API calls is approximately 0.032 $ for one dialogue. We obtain two types of splits for the test set: seen and unseen, similar to Sevegnani et al. (2021); Wang et al. (2023a). The test-unseen split ensures that none of the target topics in the test set are present in the training set, whereas the test-seen split allows them to appear."
        },
        {
            "heading": "B.2 Settings of Automatic and Human Evaluations",
            "text": "We describe the settings for LLM-based automatic evaluation and human evaluation that we conduct to validate the quality of the constructed TOPDIAL dataset. We randomly choose 100 targets and then sample one dialogue per target from the seed and TOPDIAL datasets, respectively. We only include the targets and dialogue contexts while excluding grounded contexts (e.g., domain knowledge and personalized user information) for anonymity, since the grounded contexts of the seed and TOPDIAL datasets are distinguishable. For LLM-based automatic evaluation, we employ the gpt-3.5-turbo version of ChatGPT to compare each pair of dialogues. For human evaluation, we recruit three well-educated graduate students as\nevaluators and ask them to perform a blind pairwise comparison. Specifically, we employ ACUTEEVAL (Li et al., 2019), a widely used dialogue evaluation platform for multi-turn dialogue evaluation (Dinan et al., 2020; Kim et al., 2022). We adopt Fleiss\u2019s kappa (Fleiss, 1971) to measure the agreement among the human evaluators. Figure 8 shows the interface used for human evaluation.\nWe ask ChatGPT and human evaluators to compare each pair of dialogues in terms of the following metrics: proactivity (Proact.), coherence (Coh.), personalization (Pers.), and target success rate (Succ.), similar to related studies (Wang et al., 2023a; Kim et al., 2022). We use a question form to describe these metrics, with the wording of questions presented as follows:\n\u2022 Proactivity (Proact.): Which dialogue shows that the system takes the initiative during the conversation and proactively leads the topic threads toward the target topic?\n\u2022 Coherence (Coh.): Which dialogue is more natural and coherent, like humans? Whose dialogue context flows more smoothly?\n\u2022 Personalization (Pers.): Which dialogue reflects the user\u2019s preferences or personalities more? Which dialogue is more likely to arouse the user\u2019s interest?\n\u2022 Target Success Rate (Succ.): Which dialogue successfully achieves the target dialogue act on the target topic?"
        },
        {
            "heading": "C Experimental Setup",
            "text": "C.1 Implementation Details We consider the following representative dialogue models as baseline models to evaluate the TOPDIAL dataset:\n\u2022 DialoGPT (Zhang et al., 2020): It is a state-ofthe-art pre-trained dialogue response generation model for multi-turn conversations. We adopt the pre-trained small4 model (approximately 117M parameters) for fine-tuning.\n\u2022 Alpaca-7B (Taori et al., 2023): It is an open-source instruction-following large language model (LLM), which is fine-tuned from a 7B LLaMA (Touvron et al., 2023) model. It supports diverse conversational tasks and is one of the most advanced LLMs for dialogue. To make it affordable, we fine-tune Alpaca-7B5 on 2 NVIDIA 3090 GPUs with LoRA (Hu et al., 2022), a parameter-efficient fine-tuning approach.\nDue to the much larger size of the constructed TOPDIAL dataset compared to the seed dataset, we randomly sample 5K dialogues (close to the size of training dialogues in the seed dataset) from the\n4https://huggingface.co/microsoft/ DialoGPT-small\n5https://github.com/tloen/alpaca-lora\ntraining sets of the seed and TOPDIAL datasets, respectively. This ensures an identical data size for model training. Then, we fine-tune the above two baseline models for 5 epochs on the seed and TOPDIAL training datasets, respectively. We adopt default hyper-parameter settings for the two models based on their open-source code.\nFor a fair comparison, we build the test set containing 2000 samples, with 50% randomly sampled from the seed test data and 50% randomly sampled from the TOPDIAL test data. We adopt greedy search decoding for all baseline models during inference, with a maximum decoding length of 80."
        },
        {
            "heading": "C.2 Evaluation Metrics",
            "text": "To evaluate the system utterance generation performance of the baseline models trained on different datasets, we adopt commonly used evaluation metrics, including the average score of BLEU-1/2 (Papineni et al., 2002), knowledge F1 (Liu et al., 2021; Wang et al., 2023a), persona F1 (Lim et al., 2022; Zhong et al., 2022), and target success rate (Succ.) (Wang et al., 2023a), following many existing studies. Concretely, the average score of BLEU1/2 measures word overlaps of the generated utterances and the system\u2019s ground truth utterances. The knowledge F1 evaluates the performance of generating correct knowledge (e.g., topics, attributes)\nfrom the domain knowledge triples. The persona F1 calculates the F1 value of the uni-grams cooccurring in the generated utterance and grounded user profile, following existing work for personalized dialogue (Lim et al., 2022; Zhong et al., 2022). The target success rate measures the proportion of correct target topic generation within the groundtruth turn and the two adjacent turns in the test set, because multiple temporary strategies can be reasonable before reaching the target due to the nature of dialogue."
        },
        {
            "heading": "D Case Study",
            "text": "We provide two randomly picked cases in Figure 9 and Figure 10."
        }
    ],
    "title": "Target-oriented Proactive Dialogue Systems with Personalization: Problem Formulation and Dataset Curation",
    "year": 2023
}