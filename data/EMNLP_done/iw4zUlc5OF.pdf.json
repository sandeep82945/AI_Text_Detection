{
    "abstractText": "The rampant proliferation of large language models, fluent enough to generate text indistinguishable from human-written language, gives unprecedented importance to the detection of machine-generated text. This work is motivated by an important research question: How will the detectors of machine-generated text perform on outputs of a new generator, that the detectors were not trained on? We begin by collecting generation data from a wide range of LLMs, and train neural detectors on data from each generator and test its performance on heldout generators. While none of the detectors can generalize to all generators, we observe a consistent and interesting pattern that the detectors trained on data from a medium-size LLM can zero-shot generalize to the larger version. As a concrete application, we demonstrate that robust detectors can be built on an ensemble of training data from medium-sized models.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xiao Pu"
        },
        {
            "affiliations": [],
            "name": "Jingyu Zhang"
        },
        {
            "affiliations": [],
            "name": "Xiaochuang Han"
        },
        {
            "affiliations": [],
            "name": "Yulia Tsvetkov"
        },
        {
            "affiliations": [],
            "name": "Tianxing He"
        }
    ],
    "id": "SP:928b9653d87e235378efbb6337a7dfe84b1a6ce3",
    "references": [
        {
            "authors": [
                "Sahar Abdelnabi",
                "Mario Fritz."
            ],
            "title": "Adversarial watermarking transformer: Towards tracing text provenance with data hiding",
            "venue": "2021 IEEE Symposium on Security and Privacy (SP), pages 121\u2013140. IEEE.",
            "year": 2021
        },
        {
            "authors": [
                "Anton Bakhtin",
                "Sam Gross",
                "Myle Ott",
                "Yuntian Deng",
                "Marc\u2019Aurelio Ranzato",
                "Arthur Szlam"
            ],
            "title": "Real or fake? learning to discriminate machine from human generated text",
            "year": 2019
        },
        {
            "authors": [
                "Sid Black",
                "Gao Leo",
                "Phil Wang",
                "Connor Leahy",
                "Stella Biderman."
            ],
            "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with MeshTensorflow",
            "venue": "If you use this software, please cite it using these metadata.",
            "year": 2021
        },
        {
            "authors": [
                "Jason Wei"
            ],
            "title": "Scaling instruction-finetuned language models",
            "year": 2022
        },
        {
            "authors": [
                "Kevin Clark",
                "Minh-Thang Luong",
                "Quoc V Le",
                "Christopher D Manning."
            ],
            "title": "Electra: Pre-training text encoders as discriminators rather than generators",
            "venue": "arXiv preprint arXiv:2003.10555.",
            "year": 2020
        },
        {
            "authors": [
                "Liam Dugan",
                "Daphne Ippolito",
                "Arun Kirubarajan",
                "Sherry Shi",
                "Chris Callison-Burch."
            ],
            "title": "Real or fake text?: Investigating human ability to detect boundaries between human-written and machinegenerated text",
            "venue": "arXiv.",
            "year": 2022
        },
        {
            "authors": [
                "Leo Gao",
                "Stella Biderman",
                "Sid Black",
                "Laurence Golding",
                "Travis Hoppe",
                "Charles Foster",
                "Jason Phang",
                "Horace He",
                "Anish Thite",
                "Noa Nabeshima"
            ],
            "title": "The pile: An 800gb dataset of diverse text for language modeling",
            "venue": "arXiv preprint arXiv:2101.00027",
            "year": 2020
        },
        {
            "authors": [
                "Sebastian Gehrmann",
                "Hendrik Strobelt",
                "Alexander Rush."
            ],
            "title": "GLTR: Statistical detection and visualization of generated text",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 111\u2013116,",
            "year": 2019
        },
        {
            "authors": [
                "Ari Holtzman",
                "Jan Buys",
                "Li Du",
                "Maxwell Forbes",
                "Yejin Choi."
            ],
            "title": "The curious case of neural text degeneration",
            "venue": "International Conference on Learning Representations.",
            "year": 2020
        },
        {
            "authors": [
                "Daphne Ippolito",
                "Daniel Duckworth",
                "Chris CallisonBurch",
                "Douglas Eck"
            ],
            "title": "Automatic detection of generated text is easiest when humans are fooled",
            "year": 2020
        },
        {
            "authors": [
                "Ganesh Jawahar",
                "Muhammad Abdul-Mageed",
                "V.S. Laks Lakshmanan"
            ],
            "title": "Automatic detection of machine generated text: A critical survey",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 2296\u20132309, Barcelona,",
            "year": 2020
        },
        {
            "authors": [
                "Diederik P Kingma",
                "Jimmy Ba."
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "arXiv preprint arXiv:1412.6980.",
            "year": 2014
        },
        {
            "authors": [
                "John Kirchenbauer",
                "Jonas Geiping",
                "Yuxin Wen",
                "Jonathan Katz",
                "Ian Miers",
                "Tom Goldstein"
            ],
            "title": "A watermark for large language models",
            "year": 2023
        },
        {
            "authors": [
                "Philipp Koehn."
            ],
            "title": "Statistical significance tests for machine translation evaluation",
            "venue": "Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 388\u2013395, Barcelona, Spain. Association for Computational Linguistics.",
            "year": 2004
        },
        {
            "authors": [
                "Zhenzhong Lan",
                "Mingda Chen",
                "Sebastian Goodman",
                "Kevin Gimpel",
                "Piyush Sharma",
                "Radu Soricut."
            ],
            "title": "Albert: A lite bert for self-supervised learning of language representations",
            "venue": "arXiv preprint arXiv:1909.11942.",
            "year": 2019
        },
        {
            "authors": [
                "Weixin Liang",
                "Mert Yuksekgonul",
                "Yining Mao",
                "Eric Wu",
                "James Zou"
            ],
            "title": "Gpt detectors are biased against non-native english writers",
            "year": 2023
        },
        {
            "authors": [
                "Andrew L. Maas",
                "Raymond E. Daly",
                "Peter T. Pham",
                "Dan Huang",
                "Andrew Y. Ng",
                "Christopher Potts."
            ],
            "title": "Learning word vectors for sentiment analysis",
            "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human",
            "year": 2011
        },
        {
            "authors": [
                "Fatemehsadat Mireshghallah",
                "Justus Mattern",
                "Sicun Gao",
                "Reza Shokri",
                "Taylor Berg-Kirkpatrick"
            ],
            "title": "Smaller language models are better black-box machine-generated text detectors",
            "year": 2023
        },
        {
            "authors": [
                "Eric Mitchell",
                "Yoonho Lee",
                "Alexander Khazatsky",
                "Christopher D Manning",
                "Chelsea Finn."
            ],
            "title": "Detectgpt: Zero-shot machine-generated text detection using probability curvature",
            "venue": "arXiv preprint arXiv:2301.11305.",
            "year": 2023
        },
        {
            "authors": [
                "Long Ouyang",
                "Jeffrey Wu",
                "Xu Jiang",
                "Diogo Almeida",
                "Carroll Wainwright",
                "Pamela Mishkin",
                "Chong Zhang",
                "Sandhini Agarwal",
                "Katarina Slama",
                "Alex Ray"
            ],
            "title": "Training language models to follow instructions with human",
            "year": 2022
        },
        {
            "authors": [
                "Artidoro Pagnoni",
                "Martin Graciarena",
                "Yulia Tsvetkov."
            ],
            "title": "Threat scenarios and best practices to detect neural fake news",
            "venue": "Proceedings of the 29th International Conference on Computational Linguistics, pages 1233\u20131249, Gyeongju, Republic",
            "year": 2022
        },
        {
            "authors": [
                "Artidoro Pagnoni",
                "Martin Graciarena",
                "Yulia Tsvetkov."
            ],
            "title": "Threat scenarios and best practices to detect neural fake news",
            "venue": "Proceedings of the 29th International Conference on Computational Linguistics, pages 1233\u20131249.",
            "year": 2022
        },
        {
            "authors": [
                "Alec Radford",
                "Karthik Narasimhan",
                "Tim Salimans",
                "Ilya Sutskever"
            ],
            "title": "Improving language understanding by generative pre-training",
            "year": 2018
        },
        {
            "authors": [
                "Alec Radford",
                "Jeffrey Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "venue": "OpenAI blog,",
            "year": 2019
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J. Liu."
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "arXiv e-prints.",
            "year": 2019
        },
        {
            "authors": [
                "McGuffie",
                "Jasmine Wang"
            ],
            "title": "Release strategies and the social impacts of language models",
            "year": 2019
        },
        {
            "authors": [
                "Jinyan Su",
                "Terry Yue Zhuo",
                "Di Wang",
                "Preslav Nakov"
            ],
            "title": "Detectllm: Leveraging log rank information for zero-shot detection of machine-generated text",
            "year": 2023
        },
        {
            "authors": [
                "Hugo Touvron",
                "Thibaut Lavril",
                "Gautier Izacard",
                "Xavier Martinet",
                "Marie-Anne Lachaux",
                "Timoth\u00e9e Lacroix",
                "Baptiste Rozi\u00e8re",
                "Naman Goyal",
                "Eric Hambro",
                "Faisal Azhar"
            ],
            "title": "Llama: Open and efficient foundation language models",
            "year": 2023
        },
        {
            "authors": [
                "Ben Wang."
            ],
            "title": "Mesh-Transformer-JAX: ModelParallel Implementation of Transformer Language Model with JAX",
            "venue": "https://github.com/ kingoflolz/mesh-transformer-jax.",
            "year": 2021
        },
        {
            "authors": [
                "Matthew D. Zeiler",
                "Rob Fergus."
            ],
            "title": "Visualizing and understanding convolutional networks",
            "venue": "Computer Vision \u2013 ECCV 2014, pages 818\u2013833, Cham. Springer International Publishing.",
            "year": 2014
        },
        {
            "authors": [
                "Rowan Zellers",
                "Ari Holtzman",
                "Hannah Rashkin",
                "Yonatan Bisk",
                "Ali Farhadi",
                "Franziska Roesner",
                "Yejin Choi."
            ],
            "title": "Defending against neural fake news",
            "venue": "H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\u00e9-Buc, E. Fox, and R. Garnett, editors, Ad-",
            "year": 2019
        },
        {
            "authors": [
                "Rowan Zellers",
                "Ari Holtzman",
                "Hannah Rashkin",
                "Yonatan Bisk",
                "Ali Farhadi",
                "Franziska Roesner",
                "Yejin Choi"
            ],
            "title": "Defending against neural fake news",
            "year": 2020
        },
        {
            "authors": [
                "Wang",
                "Luke Zettlemoyer"
            ],
            "title": "Opt: Open pretrained transformer language models",
            "year": 2022
        },
        {
            "authors": [
                "Bakhtin"
            ],
            "title": "2019) train an energy-based model to identify machine-generated text. Zellers et al. (2020) trainn a GROVER detector and finds that models exhibiting superior performance",
            "year": 2020
        },
        {
            "authors": [
                "Both Solaiman"
            ],
            "title": "2020) propose zero-shot approaches to detect machine-generated text and evaluate the capability of pretrained models",
            "year": 2020
        },
        {
            "authors": [
                "Mitchell"
            ],
            "title": "DetectGPT, a zeroshot method that utilizes a novel curvature-based criterion to determine whether a text is generated by a specific model",
            "year": 2023
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Thanks to large-scale pretraining and tuning with human feedback (Ouyang et al., 2022), large language models (LLMs) (Chung et al., 2022; Zhang et al., 2022; Touvron et al., 2023) are now able to follow instructions and generate realistic and consistent texts. A prominent example is the recently developed ChatGPT or GPT4 model (OpenAI, 2023), which when instructed, can write documents, create executable code, or answer questions that require world knowledge. In a lot of scenarios, the machine-generated texts have high quality and cannot easily be distinguished from genuine human texts (Dugan et al., 2022; Gehrmann et al., 2019).\nThese trends give an unprecedented importance to the detection of machine-generated text (Su et al., 2023; Jawahar et al., 2020; Pagnoni et al., 2022a). A lot of work has been devoted to proposing efficient detection models or algorithms (Mitchell\nCode and datasets will be available at https://github. com/SophiaPx/detectors-generalization.\net al., 2023; Kirchenbauer et al., 2023; Zellers et al., 2019). However, in most studies, the detector is tested on the same generator model that it is trained/tuned on.\nThis study is motivated by an underexplored research question: How will the detector perform on a different generator that it is not trained on? This question is important due to multiple reasons: (1) LLMs are becoming increasingly large and expensive. Some of the most recent models are either too large to fit into a common GPU (e.g., LLaMA65B) or require payment from the user (OpenAI, 2023), making the collection of training samples difficult. (2) The number of released LLMs is growing rapidly. In a real application scenario, the detector needs to cover a wide range of LLMs (including the ones the detector is not trained on), instead of only one generator.\nIn this work, we collect generation data from a wide range of LLMs. We then train neural detectors on data from each generator and test its performance on other generators. Our primary findings include: (1) In many cases, detectors can zero-shot generalize to a held-out generator (Figure 1). In particular, we observe an interesting pattern that the detector for the medium version of an LLM can generalize to the larger version. (2) None of the detectors generalizes to all generators, implying that an ensemble of detectors/data is necessary for a wider coverage. (3) As a concrete application, we demonstrate that robust detectors can be built on an ensemble of training data from medium-sized models; Excluding large-versions only leads to a minor drop in performance."
        },
        {
            "heading": "2 Methodology",
            "text": "We begin by giving an overview of our experiment structure and establish some notations. This study includes detection of a range of popular LLMs (detailed in \u00a73), and we construct train/dev/test sets for each generator. In \u00a74.1, we train neural detectors on\ndata from each generator and test its performance on other generators. In \u00a74.2, we further consider an ensemble setting, where the detector is trained on data composed of multiple generators, and test its generalization ability on held-out generators.\nWe denote the detector model trained on data from generator model M as DM . Since we will test the accuracy of DM on data from different generators, we use AccN (DM ) to denote the accuracy of DM on the test set of generator N . Finally, we define Acc-GapDMN to measure the drop of performance when the detector is trained on generator M instead of N itself:\nAcc-GapDMN = AccN (DN )\u2212 AccN (DM ). (1)\nWe expect Acc-Gap to be larger than zero in general, and a large Acc-Gap means DM has poor generalization on generator N ."
        },
        {
            "heading": "3 Experiment Setup",
            "text": "Generators We include the detection of a total of 13 popular LMs in our study, including GPT1 (Radford et al., 2018), GPT-2 models (small, medium, large, and xl) (Radford et al., 2019), GPT3 (text-davinci-003) (Ouyang et al., 2022), GPT-4 (OpenAI, 2023), three GPT-Neo models (125M, 1.3B and 2.7B) (Black et al., 2021; Gao et al., 2020), GPT-J (Wang, 2021), and LLaMA (7B and 13B) (Touvron et al., 2023).1\nDatasets We consider data from three domains: news, reviews and knowledge. For the news domain, we utilize the RealNews dataset, which\n1There are larger versions of LLaMA, but we find it difficult to fit it into our GPU.\nis a subset of the c4 dataset (Raffel et al., 2019) named \"realnewslike\". For the reviews domain, we utilize the IMDBreview dataset (Maas et al., 2011). As for the knowledge domain, we utilize the Wikipedia dataset (Foundation) 2.\nFor each dataset, we first randomly sample 5000 real-world human-written samples, with a train/dev/test split ratio of 8:1:1. For all samples, we truncate the first 20 tokens to serve as prompts and feed them into different generators for text continuation, yielding 5000 machine-generated samples. For generation we apply nucleus sampling (Holtzman et al., 2020) with p = 0.96, following the setting in Pagnoni et al. (2022b). We truncate each sample so that its length is around 120 tokens. For all training or test sets in this work, we keep the ratio of human and machine text to be 1:1.\nDetectors For data from each generator, we train a ELECTRA-large model (Clark et al., 2020) as a binary classifier. The detectors were trained for 1 epoch with a learning rate of 5e-6 (training\n2The Wikipedia dataset we used is directly obtained from Hugging Face, data subset \"20220301.en\" (Page link: https: //huggingface.co/datasets/wikipedia).\nfor more epochs only gives minimal improvement on the dev set). For the data-mix baseline and pruned models in \u00a74.2, 3 epochs of training is used. We use Adam optimizer (Kingma and Ba, 2014) with \u03b21 = 0.9, \u03b22 = 0.999. The average accuracy (when tested on the same generator it is trained on) of all detectors in news, review and knowledge domains are 94.1%, 96.2% and 94.9%, separately."
        },
        {
            "heading": "4 Experiment Results",
            "text": ""
        },
        {
            "heading": "4.1 On Generalization Ability of Detectors",
            "text": "As explained in \u00a72, we compute Acc-Gap to reflect the generalization ability of detectors trained on each generator. Figure 1 depicts the Acc-Gap of each detector/generator pair. We link from node M to node N if Acc-GapDMN < T (good generalization), where the threshold T is set to a small number from {1%, 2%, 4%}. On the other hand, in Figure 3 (Appendix B), node M is linked to node N when Acc-GapDMN > 20% (poor generalization). For statistical significance, we utilize bootstrapping (Koehn, 2004) and generate 100 virtual test sets by sampling with replacement from the original test set. We then conduct one-sided t-test and use a p-value of 0.05.\nWe observe two interesting patterns shared across the three datasets. First, the detectors for the medium-version LLMs can generalize to the large-version models. For example, DLLaMA7B generalizes to LLaMA13B, and DGPT3 general-\nizes to GPT4.3 This is somewhat surprising because generations from the large-version generator is commonly considered to have higher quality.\nInterestingly, the generalization of the reverse direction is weaker on RealNews and IMDBReview. As shown in Table 1, when attempting to generalize from the large-version models to medium ones using ELECTRA detectors, the generalization performance is slightly worse, reflected by a larger Acc-Gap. For the reason behind, we conjecture that comparing to the larger model, the medium generator is making a similar but wider range of artifacts in its generations, leading to a smooth generalization to the detection of the larger model. We also experiment with additional base detectors, e.g. ALBERT Large v2 (Lan et al., 2019) and find that the key observation\u2014that the detectors trained for the medium-size models can generalize to largersize models\u2014still holds. These results are omitted for brevity.\nSecond, Figure 3 (Appendix B) shows that none of the detectors, on its own, can generalize to all generators. In particular, GPT3 and GPT4 seem \u201cisolated\u201d from other families of generators. This result indicates that if we want an \u201cuniversal\u201d detector which can cover all generators, an ensemble of detectors/data is necessary. We explore this direction in the next section.\n3Strictly speaking, GPT3 is not a \u201csmall version\u201d of GPT4. But they are from the same company, and our experiments consistently show they are strongly related."
        },
        {
            "heading": "4.2 Pruning Out Large-Version LLMs in a Mixed Training Dataset",
            "text": "We now demonstrate a concrete application of our findings, and the following realistic threat scenario is considered: The task is still binary classification but the machine text is composed of generations from a range of models (listed in \u00a73). For simplicity, we use a uniform data ratio for the generators.\nFollowing results of the last section, an ensemble of detectors/data is necessary. We begin by comparing two baselines: (1) Model ensemble, where we aggregate predictions from all detectors by majority voting or confidence (probability) average; (2) Data mixing, where we train a new ELECTRAlarge detector by mixing up the training data from all generators.4\nFor each baseline detector D, we report the average accuracy on all generators, and the worst-case accuracy which is min\nN AccN (D). Accuracy on the\nfour largest generators is also reported. We conduct experiments on RealNews and IMDBReview datasets, and the results for baselines on are shown in the left part of Table 2. It is shown that the datamix model outperforms the ensemble approach by a large margin. Therefore, we base our pruning experiments on the data-mix model.\nFollowing insights from the last section, we then prune out data from the large-version language models (i.e., GPT4, GPT-Neo2.7B, LLaMA13B and GPT-2xl) and train a detector by mixing up training data from the remaining generators. 5 The degree of drop on the worst-case accuracy reflects the zero-shot generalization ability of the proposed detector.\nAlso shown in Table 2, the accuracy of the proposed detectors (both average and worst-case) remains similar to or only slightly decreases compared to the data-mix baseline. Figure 2 provides detailed information on the changes in accuracy after pruning out four large-version models. The accuracy of the proposed detector only experiences a slight decrease (<3%) for GPT4 and LLaMA13B. Our results show that in the case of limited budget or computing, data from the mediumversion LM can decently approximate the largeversion in an ensembled data collection.\nOn the right part of Table 2, we conduct com4We have also tried another baseline where we average parameters from all detectors. However, the performance is worse than the majority-voting baseline, and we omit this result.\n5Our data collection for GPT4 costs around $450.\nparison experiments where both medium and large versions are pruned out. As expected, this results in a worse performance on detection of the pruned generators, reflected by the worst-case accuracy. Especially, the comparison experiment of pruning out both GPT3 and GPT4 is quite alarming: The detector trained from combined data of all other generators only has accuracy around 42% (RealNews) or 62% (IMDBReview). This implies that if OpenAI did not give public access to generations of the two models, existing detectors would fail."
        },
        {
            "heading": "5 Related Work",
            "text": "We now discuss the literature most related to our work, and defer a more complete review to Appendix A. Pagnoni et al. (2022a) demonstrate the degraded performance of trained detectors under different threat scenarios, while the range of generator models is not as wide or up-to-date as our work. Liang et al. (2023) study the bias of detectors for LLMs in the case of non-native English writers. In a very recent and concurrent work, Mireshghallah et al. (2023) study the generalization of detectors under the DetectGPT (Mitchell et al., 2023) algorithm, which is also shown to be far from perfect. Comparing to a trained detector, DetectGPT relies on access to the generator LLM, which might be expensive."
        },
        {
            "heading": "6 Conclusion and Discussion",
            "text": "In this work, we observe a generalization relationship among detectors trained on different generators in three domains, where detectors for mediumversion models demonstrate the ability to effectively generalize to the larger-version. Building upon this finding, we prune out data from largeversion generators in an ensembed training dataset and demonstrate that the performance loss is min-\nimal. Our results indicate that practitioners with limited budget or computing resources can use data from medium-size LLMs as a good approximation for the large version.\nWith the rapid release of various LLMs and generation APIs, a detector needs to cover a wide range of generators. While our work makes some initial progress, our experiments show that the detection of an unseen (or non-public) generator is still a difficult and open question. We hope our work could motivate more research devoted to this important direction.\nLimitations\nOur work focuses on supervised detector models and there are other approaches for machinegenerated text detection (Appendix A). In a very recent and concurrent work, Mireshghallah et al. (2023) studies the generalization of detectors under the DetectGPT (Mitchell et al., 2023) algorithm, which is also shown to be far from perfect. Comparing to a trained detector, DetectGPT relies on access to the generator LLM, which might be expensive. It is also interesting to base the detector on a larger LM than ELECTRA-large, but we surmise the observations should be similar.\nThe zero-shot generalization ability of detectors shown in this work implies that different generators are making similar artifacts based on which the detectors make decisions. As future work, it would be interesting to examine the salient features (Zeiler and Fergus, 2014) and compare between machine/human-generated text.\nFinally, our experiments show that the detection of an unseen or non-public generator is still a difficult and open question. For example, the combination of data from all other generators can not generalize to GPT3 and GPT4. This important research direction deserves more research efforts.\nEthics Statement\nThe detection of machine-generated text has important applications such as detecting fake news and fake reviews on the internet. However, it could also introduce new risks: Malicious parties can use released detectors to develop text generation systems that evade existing detectors in an adversarial manner. Our experiments show that the detection of an unseen (or non-public) generator is still a difficult and open question, and we hope our work could motivate more research devoted to this important\ndirection."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank the reviewers, the area chair, Prof. Xiaojun Wan, Hao Wang, Shangbin Feng, and Yichen Wang. We gratefully acknowledge support from NSF CAREER Grant No. IIS2142739. This material is funded in part by the DARPA Grant under Contract No. HR001120C0124. This research is supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via the HIATUS Program contract #2022-22072200004. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein."
        },
        {
            "heading": "A Related Work",
            "text": "Research on detecting machine-generated text can be roughly divided into two categories: supervised training and zero-shot detection (To clarify, in the literature \u201czero-shot\u201d usually means that the approach does not require training data, while our work focus on zero-shot generalization to the detection of a held-out generator).\nIn the case of supervised methods, Bakhtin et al. (2019) train an energy-based model to identify machine-generated text. Zellers et al. (2020) trainn a GROVER detector and finds that models exhibiting superior performance in generating neural disinformation are also highly effective in detecting their own generated content. Both Solaiman et al. (2019) and Ippolito et al. (2020) propose zero-shot approaches to detect machine-generated text and evaluate the capability of pretrained models. Liu et al. (2022) present a coherence-based contrastive learning model to detect the machine-generated text under low-resource scenario. Kirchenbauer et al. (2023) propose a watermarking method (Abdelnabi and Fritz, 2021) which introduces designed noise which is imperceptible to human readers. Mitchell et al. (2023) propose DetectGPT, a zeroshot method that utilizes a novel curvature-based criterion to determine whether a text is generated by a specific model. This approach has demonstrated superior detection capabilities compared to other existing zero-shot methods. While DetectGPT does not require training a separate detector, it relies on access to the generator LLM, which can be costly. Recently, Su et al. (2023) follow up the work of DetectGPT and introduce two new zero-shot methods: DetectLLM-LRR and DetectLLM-NPR."
        },
        {
            "heading": "B Auxiliary Results",
            "text": "In Figure 3, we plot detector-generator pairs with large (>20%) Acc-Gap on the three datasets. It shows that none of detectors is able to generalize to all generators. For example, all detectors except DGPT4 has large accuracy gap for GPT3.\nIn Figure 4, 5 and 6, we give detailed heatmaps of Acc-Gap for every detector/generator pair on the three datasets. The reported numbers are calculated as the averages of Acc-Gap obtained by bootstrapping 100 times."
        }
    ],
    "title": "On the Zero-Shot Generalization of Machine-Generated Text Detectors",
    "year": 2023
}