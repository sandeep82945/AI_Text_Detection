{
    "abstractText": "Existing lexical substitution (LS) benchmarks were collected by asking human annotators to think of substitutes from memory, resulting in benchmarks with limited coverage and relatively small scales. To overcome this problem, we propose a novel annotation method to construct an LS dataset based on human and machine collaboration. Based on our annotation method, we construct the first Chinese LS dataset CHNLS which consists of 33,695 instances and 144,708 substitutes, covering three text genres (News, Novel, and Wikipedia). Specifically, we first combine four unsupervised LS methods as an ensemble method to generate the candidate substitutes, and then let human annotators judge these candidates or add new ones. This collaborative process combines the diversity of machine-generated substitutes with the expertise of human annotators. Experimental results that the ensemble method outperforms other LS methods. To our best knowledge, this is the first study for the Chinese LS task.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jipeng Qiang"
        },
        {
            "affiliations": [],
            "name": "Kang Liu"
        },
        {
            "affiliations": [],
            "name": "Ying Li"
        },
        {
            "affiliations": [],
            "name": "Yun Li"
        },
        {
            "affiliations": [],
            "name": "Yi Zhu"
        },
        {
            "affiliations": [],
            "name": "Yunhao Yuan"
        },
        {
            "affiliations": [],
            "name": "Xiaocheng Hu"
        },
        {
            "affiliations": [],
            "name": "Xiaoye Ouyang"
        }
    ],
    "id": "SP:c962b5e69b462cf7124f1b855aa5aae4a54f3738",
    "references": [
        {
            "authors": [
                "Domagoj Alagi\u0107",
                "Jan \u0160najder."
            ],
            "title": "A preliminary study of croatian lexical substitution",
            "venue": "Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing, pages 14\u201319.",
            "year": 2017
        },
        {
            "authors": [
                "Nikolay Arefyev",
                "Boris Sheludko",
                "Alexander Podolskiy",
                "Alexander Panchenko."
            ],
            "title": "A comparative study of lexical substitution approaches based on neural language models",
            "venue": "arXiv preprint arXiv:2006.00031.",
            "year": 2020
        },
        {
            "authors": [
                "Chris Biemann"
            ],
            "title": "Turk bootstrap word sense inventory 2.0: A large-scale resource for lexical substitution",
            "venue": "In Proceedings of the Eighth International Conference on Language Resources and Evaluation",
            "year": 2012
        },
        {
            "authors": [
                "Jacob Cohen."
            ],
            "title": "A coefficient of agreement for nominal scales",
            "venue": "Educational and psychological measurement, 20(1):37\u201346.",
            "year": 1960
        },
        {
            "authors": [
                "Joseph L Fleiss."
            ],
            "title": "Measuring nominal scale agreement among many raters",
            "venue": "Psychological bulletin, 76(5):378.",
            "year": 1971
        },
        {
            "authors": [
                "Samer Hassan",
                "Andras Csomai",
                "Carmen Banea",
                "Ravi Sinha",
                "Rada Mihalcea."
            ],
            "title": "Unt: Subfinder: Combining knowledge sources for automatic lexical substitution",
            "venue": "Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-",
            "year": 2007
        },
        {
            "authors": [
                "Gerold Hintz",
                "Chris Biemann."
            ],
            "title": "Delexicalized supervised german lexical substitution",
            "venue": "Proceedings of GermEval, pages 11\u201316.",
            "year": 2015
        },
        {
            "authors": [
                "Gerold Hintz",
                "Chris Biemann."
            ],
            "title": "Language transfer learning for supervised lexical substitution",
            "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 118\u2013129.",
            "year": 2016
        },
        {
            "authors": [
                "Gerhard Kremer",
                "Katrin Erk",
                "Sebastian Pad\u00f3",
                "Stefan Thater."
            ],
            "title": "What substitutes tell us-analysis of an \u201call-words\u201d lexical substitution corpus",
            "venue": "Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,",
            "year": 2014
        },
        {
            "authors": [
                "Caterina Lacerra",
                "Tommaso Pasini",
                "Rocco Tripodi",
                "Roberto Navigli."
            ],
            "title": "Alasca: an automated approach for large-scale lexical substitution",
            "venue": "Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21, pages",
            "year": 2021
        },
        {
            "authors": [
                "Caterina Lacerra",
                "Rocco Tripodi",
                "Roberto Navigli."
            ],
            "title": "Genesis: A generative approach to substitutes in context",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 10810\u201310823.",
            "year": 2021
        },
        {
            "authors": [
                "Mina Lee",
                "Chris Donahue",
                "Robin Jia",
                "Alexander Iyabor",
                "Percy Liang."
            ],
            "title": "Swords: A benchmark for lexical substitution with improved data coverage and quality",
            "venue": "NAACL, pages 4362\u20134379, Online. Association for Computational Linguistics.",
            "year": 2021
        },
        {
            "authors": [
                "Shen Li",
                "Zhe Zhao",
                "Renfen Hu",
                "Wensi Li",
                "Tao Liu",
                "Xiaoyong Du."
            ],
            "title": "Analogical reasoning on chinese morphological and semantic relations",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2:",
            "year": 2018
        },
        {
            "authors": [
                "Alisa Liu",
                "Swabha Swayamdipta",
                "Noah A Smith",
                "Yejin Choi."
            ],
            "title": "Wanli: Worker and ai collaboration for natural language inference dataset creation",
            "venue": "arXiv preprint arXiv:2201.05955.",
            "year": 2022
        },
        {
            "authors": [
                "Diana McCarthy."
            ],
            "title": "Lexical substitution as a task for wsd evaluation",
            "venue": "Proceedings of the ACL-02 workshop on Word sense disambiguation: recent successes and future directions, pages 89\u2013115.",
            "year": 2002
        },
        {
            "authors": [
                "Diana McCarthy",
                "Roberto Navigli."
            ],
            "title": "Semeval2007 task 10: English lexical substitution task",
            "venue": "In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 48\u2014-53.",
            "year": 2007
        },
        {
            "authors": [
                "J Mei",
                "Y Zhu",
                "Y Gao"
            ],
            "title": "Tongyici cilin (extended)",
            "venue": "HIT IR-Lab",
            "year": 1996
        },
        {
            "authors": [
                "Oren Melamud",
                "Ido Dagan",
                "Jacob Goldberger."
            ],
            "title": "Modeling word meaning in context with substitute vectors",
            "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
            "year": 2015
        },
        {
            "authors": [
                "Oren Melamud",
                "Omer Levy",
                "Ido Dagan."
            ],
            "title": "A simple word embedding model for lexical substitution",
            "venue": "Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing, pages 1\u20137.",
            "year": 2015
        },
        {
            "authors": [
                "George Michalopoulos",
                "Ian McKillop",
                "Alexander Wong",
                "Helen Chen"
            ],
            "title": "Lexsubcon: Integrating knowledge from lexical resources into contextual embeddings for lexical substitution",
            "year": 2022
        },
        {
            "authors": [
                "Gustavo H Paetzold",
                "Lucia Specia."
            ],
            "title": "Unsupervised lexical simplification for non-native speakers",
            "venue": "AAAI, pages 3761\u20133767.",
            "year": 2016
        },
        {
            "authors": [
                "Jipeng Qiang",
                "Yang Li",
                "Chaowei Zhang",
                "Yun Li",
                "Yi Zhu",
                "Yunhao Yuan",
                "Xindong Wu."
            ],
            "title": "Chinese idiom paraphrasing",
            "venue": "Transactions of the Association for Computational Linguistics, 11:740\u2013754.",
            "year": 2023
        },
        {
            "authors": [
                "Jipeng Qiang",
                "Yun Li",
                "Yi Zhu",
                "Yunhao Yuan",
                "Yang Shi",
                "Xindong Wu."
            ],
            "title": "Lsbert: Lexical simplification based on bert",
            "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing, 29:3064\u2013 3076.",
            "year": 2021
        },
        {
            "authors": [
                "Jipeng Qiang",
                "Kang Liu",
                "Yun Li",
                "Yunhao Yuan",
                "Yi Zhu."
            ],
            "title": "Parals: Lexical substitution via pretrained paraphraser",
            "venue": "ACL.",
            "year": 2023
        },
        {
            "authors": [
                "Jipeng Qiang",
                "Xinyu Lv",
                "Yun Li",
                "Yunhao Yuan",
                "Xindong Wu."
            ],
            "title": "Chinese lexical simplification",
            "venue": "IEEE Transactions on Audio, Speech and Language Processing., 29:1819\u20131828.",
            "year": 2021
        },
        {
            "authors": [
                "Jipeng Qiang",
                "Shiyu Zhu",
                "Yun Li",
                "Yi Zhu",
                "Yunhao Yuan",
                "Xindong Wu."
            ],
            "title": "Natural language watermarking via paraphraser-based lexical substitution",
            "venue": "Artificial Intelligence, 317:103859.",
            "year": 2023
        },
        {
            "authors": [
                "Antonio Toral."
            ],
            "title": "The lexical substitution task at evalita 2009",
            "venue": "Proceedings of EVALITA Workshop, 11th Congress of Italian Association for Artificial Intelligence, Reggio Emilia, Italy.",
            "year": 2009
        },
        {
            "authors": [
                "Weizhe Yuan",
                "Graham Neubig",
                "Pengfei Liu."
            ],
            "title": "Bartscore: Evaluating generated text as text generation",
            "venue": "Advances in Neural Information Processing Systems, volume 34, pages 27263\u201327277. Curran Associates, Inc.",
            "year": 2021
        },
        {
            "authors": [
                "Deniz Yuret."
            ],
            "title": "Ku: Word sense disambiguation by substitution",
            "venue": "Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval2007), pages 207\u2013214.",
            "year": 2007
        },
        {
            "authors": [
                "Tianyi Zhang",
                "Varsha Kishore",
                "Felix Wu",
                "Kilian Q Weinberger",
                "Yoav Artzi."
            ],
            "title": "Bertscore: Evaluating text generation with bert",
            "venue": "arXiv preprint arXiv:1904.09675.",
            "year": 2019
        },
        {
            "authors": [
                "Wangchunshu Zhou",
                "Tao Ge",
                "Ke Xu",
                "Furu Wei",
                "Ming Zhou."
            ],
            "title": "Bert-based lexical substitution",
            "venue": "ACL, pages 3368\u20133373.",
            "year": 2019
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Lexical substitution (LS) aims at finding appropriate substitutes for a target word in a sentence, which can be used as a backbone of various NLP applications such as writing assistance (Lee et al., 2021; Qiang et al., 2023a), word sense disambiguation (McCarthy, 2002), and lexical simplification (Paetzold and Specia, 2016; Qiang et al., 2021a,b). For instance, when presented with the sentence \"I read an amazing paper today\", we aim to select a more descriptive adjective to substitute the word \"amazing\". While options such as \"awesome\" and \"great\" may readily come to mind, it proves arduous for us to conceive of equally fitting alternatives such as \"incredible\" and \"fascinating\". Despite extensive research conducted on Lexical Substitution (LS) in various languages, including\n\u2217Corresponding author.\nEnglish (Hassan et al., 2007; Yuret, 2007; Melamud et al., 2015b; Lee et al., 2021; Qiang et al., 2023b), German (Hintz and Biemann, 2015, 2016), Italian (Toral, 2009), and Croatian (Alagic\u0301 and \u0160najder, 2017), Chinese LS has received limited attention. In this paper, we address this gap by focusing on the Chinese LS task.\nTo enable the development and evaluation of effective Chinese LS methods, a large-scale dataset is intuitively important. Existing widely used English LS benchmarks, LS07 (McCarthy and Navigli, 2007), CoInCo (Kremer et al., 2014), and SwordS (Lee et al., 2021), were collected by asking human annotators to think of substitutes from memory. The annotation method has the following two problems.\n(1) Limited Coverage: Human annotators may have limitations in recalling a comprehensive range of potential substitutes for a given target word, potentially overlooking less common or domainspecific substitutes (Liu et al., 2022). Much work (Lee et al., 2021; Qiang et al., 2023b) have also pointed out the lack of coverage of existing LS datasets. For example, the data collection strategy used in the existing benchmarks might contain words like \"awesome\" and \"great\", but miss words like \"incredible\" and \"fascinating\".\n(2) High cost: Annotating lexical substitutes for target words in sentences is a time-consuming and labor-intensive task. It requires human annotators to carefully consider suitable substitutes, taking into account various linguistic and contextual factors. Due to the complexity of the task, annotating a large number of instances becomes challenging within a reasonable timeframe and budget. Consequently, widely used English LS datasets such as LS07, CoInCo, and SwordS comprise a mere 2,010, 2,474, and 1,250 instances, respectively.\nTo address these challenges, we propose a novel annotation method to construct an LS dataset based on human and machine collaboration. Firstly, we\npropose an ensemble method that leverages four different unsupervised LS methods to automatically generate substitutes. Automated methods can quickly generate a vast pool of potential substitutes, reducing the burden on human annotators. Secondly, we let human annotators assess the suitability of these alternatives as substitutes. Additionally, we request annotators to suggest new alternatives that are not present in the machine-generated options. This collaborative process harnesses the expertise of human annotators while leveraging the efficiency and scalability of machine-generated candidates. This efficiency allows for the creation of a larger dataset within a reasonable budget.\nThe annotation method is motivated by the following two findings:\n(1) Machine-generated LS methods can introduce a greater diversity of substitutes. By leveraging computational techniques like word embeddings, language models, or paraphrasing models, a wide range of plausible substitutes can be generated. This diversity enriches the dataset by providing a variety of substitution options, capturing different semantic relationships and syntactic patterns.\n(2) Assessing the suitability of these substitutes is much simpler for the annotator compared to generating a substitute from memory. Human annotators can focus on selecting the most appropriate substitutes from the machine-generated pool, ensuring high-quality and contextually relevant annotations.\nIn summary, our contributions are listed below:\n(1) We provide a novel approach to construct an LS dataset based on human and machine collaboration. Our approach provides a good idea for constructing large-scale, high-coverage LS datasets. Based on our designing method, we construct the first large-scale Chinese LS dataset CHNLS that consists of 33,695 instances, which cover different text genres, namely News, Novel, and Wikipedia articles. Correspondingly, the latest English LS dataset only contains 1,250 instances.\n(2) We present four Chinese LS methods (dictionary-based, embedding-based, BERT-based, and paraphraser-based) by adjusting current English LS methods, and give an ensemble method that combines the four methods. Experimental results on CHNLS show that the ensemble method can be served as a strong baseline for future studies.\nThe dataset and code is available at github 1."
        },
        {
            "heading": "2 Related Work",
            "text": "Lexical Substitution Resources. Existing lexical substitution (LS) datasets are available for various languages, including English and other languages. Each instance in LS dataset is composed of a sentence, a target word, and corresponding substitutes.\nIn English, the first LS dataset from SemEval 2007 (LS07) (McCarthy and Navigli, 2007), consists of 300 development and 1,710 test instances for 201 polysemous words. For each target word, 10 sentences are provided. The annotators\u2019 task deployed by Amazon Mechanical Turk was to give up to 3 possible substitutes. Afterward, Biemnann (Biemann, 2012) created a large-scale dataset (TWSI) that annotates 25K sentences from Wikipedia, which, however, only covers noun targets. To alleviate this limitation, Kremer et al. (Kremer et al., 2014) proposed Concept In Context (ConInCo), a dataset of 2,474 sentences covering 3,874 distinct targets with different part-of-speech tags, which is the current largest LS benchmark. It consists of 15K target instances with a given 35% development and 65% test. Recently, Stanford Word Substitution Benchmark (SwordS) (Lee et al., 2021) is built on CoInCo by asking human annotators for higher coverage and higher quality. SwordS consists of 1250 instances with a given 417 development and 833 test. Considering the size of vocabulary in English, the size of the vocabulary covered by LS datasets is too small. Additionally, we found that many appropriate substitutes for many instances in SwordS are missing, since human annotators frequently utilize repetitive patterns to fabricate instances, leading to a lack of linguistic diversity (Liu et al., 2022).\nThe German LS dataset from GermEval 2015 consists of 2,040 instances from the German Wikipedia, which contains 153 unique target words. Italian LS dataset from EVALITA 2009 consists of 2,310 instances, which contains 231 unique target words. All the above LS datasets in all languages are constructed by human annotators. Due to their relatively small size, all of these datasets can only be used for evaluation and not for training. Unfortunately, research on Chinese LS is still scarce: to the best of our knowledge, there is currently no publicly available LS corpora for training, even lacking a dataset to evaluate the ability of LS models.\n1https://github.com/KpKqwq/CHLS\nLexical Substitution. LS methods can be divided into four types: (1) dictionary-based method (Hassan et al., 2007; Yuret, 2007), (2) Embeddingbased method (Melamud et al., 2015a,b), (3) BERT-based method (Zhou et al., 2019; Lacerra et al., 2021a; Michalopoulos et al., 2022), and (4) Paraphraser-based method (Qiang et al., 2023c,b).\nThe early lexical substitution studies obtain synonyms by searching linguistic resources, such as WordNet. Embedding-based methods utilize word embedding modelings to obtain highly similar words as the substitutions. Since 2019, LS methods based on pretrained language models have attracted much attention (Zhou et al., 2019; Lacerra et al., 2021a; Michalopoulos et al., 2022), in which pretrained BERT is most used. Zhou et al. (Zhou et al., 2019) apply dropout to the embeddings of target words for partially obscuring the word, and obtain a probability distribution over the BERT output vocabulary. Arefyev et al. (Arefyev et al., 2020) present a comparative study of popular pretrained language models, such as ELMo, BERT, and XLNet. Lacerra et al. (Lacerra et al., 2021b) first merge the development set of two LS datasets (CoInCo and TWSI), and split it into training and development sets for fine-tuning the encoder-decoder\nframework. Michalopoulos et al. (Michalopoulos et al., 2022) propose a new mix-up embedding strategy by incorporating the knowledge of WordNet into the prediction process of BERT. Recently, Qiang et al (Qiang et al., 2023b) propose a method ParaLS that utilizes a pretrained paraphraser to generate the substitutes. Compared to language modeling, paraphraser produces fluent, meaningpreserving paraphrases but contain variations in word choice. ParaLS achieves good results and is considered the state-out-of-art LS method."
        },
        {
            "heading": "3 Creating CHNLS",
            "text": "In this section, we describe our method to build an LS dataset, and the overall architecture for constructing the Chinese LS corpus is illustrated in Figure 1."
        },
        {
            "heading": "3.1 Data Preparation",
            "text": "In this step, we extract the sentences and the corresponding target words. To ensure diversity and complexity in our dataset, we utilize three distinct text genres: News, Novel, and Wiki. The News category is sourced from the contents of People\u2019s Daily, Wiki consists of articles from Wikipedia (encyclopedia), and the Novel category comprises\nselected Chinese-published novels. By incorporating multiple sources, we aim to capture the richness and intricacy of the Chinese language.\nTo refine the dataset, we apply a filtering process to eliminate excessively short or long sentences based on their word count. For each sentence, we further segment it into words, considering nouns, verbs, adjectives, and adverbs as the target words for our analysis."
        },
        {
            "heading": "3.2 Machine-generated Substitution",
            "text": "Considering the sentence w1, w2, ..., tw, ..., wn containing the target word tw, we employ LS methods to generate a set of 15 pseudo substitutes for each target word. To foster a broader range of substitutes, we adopt an ensemble approach that combines four distinct LS methods: Dictionary-based, Embedding-based, BERT-based, and Paraphraserbased. By leveraging these diverse methods, each of which taps into different semantic knowledge, we aim to enhance the overall diversity of substitutes available for consideration.\nTypically, LS methods encompass two essential steps: substitute generation and substitute ranking. The initial objective of substitute generation is to identify and produce potential alternatives that can effectively replace a target word within a given sentence. Once a set of substitute candidates is generated, the subsequent task of substitute ranking comes into play, aiming to ascertain the most appropriate substitute for the target word within the specific sentence.\nSubstitute Generation. We present four baseline approaches by adapting existing English LS methods:\n(1) Dict-based: The dictionary-based method relies on a synonym thesaurus (HIT-Cilin (Mei et al., 1996)) to generate the candidate substitutes.\n(2) Embedding-based: The embedding-based method selects substitutes with the highest similarities from word embedding models (Li et al., 2018). Substitutes are chosen based on their proximity, as determined by cosine similarity, to the target word.\n(3) BERT-based: The BERT-based method (Qiang et al., 2021b) utilizes Chinese BERT modeling2 and masks the target word for prediction.\n(4) Paraphraser-based: The Paraphraser-based method (Qiang et al., 2023b) leverages a pretrained paraphrase model to generate substitutes. By inputting the sentence into the encoder of the para-\n2https://huggingface.co/bert-base-chinese\nphrase model, substitutes are generated using a special decoding strategy that focuses exclusively on the lexical variations of the target word.\nGiven the absence of a suitable Chinese paraphraser and a sufficiently large-scale paraphrase corpus, we take the initiative to construct a comprehensive Chinese paraphrase corpus. This corpus is then utilized to fine-tune a pretrained Chinese BART model3, enhancing its effectiveness for paraphrase generation.\nTo construct a paraphrase corpus, we leverage a large-scale bilingual English-Chinese translation corpus. The construction process entails the following steps:\n(1) Gathering the machine translation corpus: We select a Chinese-English corpus consisting of 5.2 million sentence pairs4 as our primary source.\n(2) Aligning sentence pairs: We utilize a Chinese translator5 to translate the English sentences into Chinese, thus creating aligned sentence pairs representing paraphrases.\n(3) Identifying potential paraphrases: By comparing the aligned sentence pairs, we identify pairs that convey similar or identical meanings while being expressed differently. These pairs serve as potential paraphrases.\n(4) Filtering and cleaning paraphrase pairs: We apply filters to remove unsuitable sentence pairs for paraphrase generation. For instance, we exclude pairs with significant length differences, pairs containing mistranslations, or pairs exhibiting inconsistencies.\nThrough these steps, we construct a high-quality paraphrase corpus that can be used for various natural language processing tasks, including paraphrase generation and LS.\nSubstitute Ranking. The effectiveness of text generation metrics for substitute ranking has been demonstrated in previous work (Qiang et al., 2023b). Therefore, we employ the BARTScore (Yuan et al., 2021) and BERTScore (Zhang et al., 2019) metrics for substitute ranking. To perform this ranking, we replace the target word in the original sentence with each substitute candidate, thereby creating an updated version of the sentence.\nBARTScore leverages pre-trained BART models to calculate the similarity between the original sentence and the updated sentence. BARTScore\n3https://huggingface.co/fnlp/bart-base-chinese 4https://github.com/brightmart/nlpchinesecorpus 5https://huggingface.co/Helsinki-NLP/opus-mt-en-zh\nconsiders various aspects of text quality, including fluency, grammaticality, and semantic similarity.\nBERTScore utilizes pre-trained BERT models to measure the similarity between the original sentence and the updated sentence. BERTScore has shown a strong correlation with human judgments and has been widely used for evaluating text generation tasks.\nFinally, our ranking method employs a linear combination of the scores of BARTScore and BERTScore to compute the final score for each candidate substitute. They consider different aspects of text quality and provide comprehensive measures to rank the substitutes based on their similarity to the reference word. By incorporating these metrics, the ranking process can be more robust and accurate, leading to an improved selection of suitable substitutes in lexical substitution tasks.\nA ensemble Method. The aforementioned four LS methods utilize substitute generate and substitute ranking to generate 15 substitutes separately for each method. Specifically, the substitutes generated by Dictionary-based, Embeddingbased, BERT-based, and paraphraser-based methods are denoted as {c1D, ..., c15D }, {c1E , ..., c15E }, {c1B, ..., c15B }, and {c1P , ..., c15P }, as shown in Figure 1.\nTaking into consideration that each LS method generates 15 substitutes, the utilization of four LS methods results in a total of 60 candidate substitutes. To avoid overwhelming the annotators and incurring additional costs, as well as to prevent annotator fatigue, we need to limit the number of substitutes for annotation.\nTo achieve this, we propose a simple ensemble method that combines the above four methods. We assigned voting weights of 1 to Dict-based, Embedding-based, BERT-based, and paraphraserbased methods individually. We select the top 15 candidate substitutes with the highest votes, denoted as {c1, c2, ..., c15}, as pseudo substitutes. This selection process ensures that the substitutes generated by multiple methods are more likely to be chosen as potential substitutes."
        },
        {
            "heading": "3.3 Manual Annotation",
            "text": "Given the sentence and target word pairs, as well as the corresponding 15 pseudo substitutes {c1, c2, ..., c15}, we engage multiple annotators for annotation. It is noteworthy that all the annotators involved in this process are native Chinese under-\ngraduates. We have created a specialized website for annotating data. On each page of the website, a sentence is presented with a highlighted target word, along with 15 pseudo substitutes for that target word. Additionally, there is an option to add new substitutes that are not included among the pseudo-substitutes. For each pseudo substitute, there are two radio buttons labeled \"positive\" and \"negative.\" The annotators\u2019 task was to select \"positive\" if they considered the substitute to be a suitable replacement for the target word within the given sentence. Conversely, they were to choose \"negative\" if they determined that the substitute would not be appropriate.\nTo encourage annotators to contribute new substitutes, we offer higher compensation for providing new substitutes that are not included among the pseudo-substitutes. During the annotation process, each sentence and target word pair in the dataset is annotated three times. The final substitutes are selected from the newly added substitutes and the pseudo-substitutes that have been marked at least once.\nWe conducted a pilot test with one annotator, and they were able to annotate approximately 150 instances in one hour. The average time required per assignment was approximately 25 seconds, which may seem surprising. However, two factors contribute to this efficiency: (1) Native speakers can quickly make binary judgments regarding substitute words. (2) Annotators only need to read the target sentence once to provide judgments for all substitutes in an assignment. For more information on the interface, instructions, and filtering criteria, please refer to Appendix A."
        },
        {
            "heading": "4 Data analysis",
            "text": "The statistical information of the constructed Chinese LS dataset, CHNLS, is presented in Table 1.\nThe dataset consists of a total of 33,695 sentences and target word pairs, with a corresponding 144,708 labeled substitutes. On average, close to 10 words per sentence are selected as target words. We calucate named as\nHigh quality. The objective is to evaluate the accuracy of the substitutions made in the given sentence and target word pairs. A total of 300 instances were randomly selected, with 100 instances chosen from one of three text genres. A new annotator, proficient in the Chinese language, was assigned the task of assessing the precision of the substitutions within the selected instances.\nThis annotator compared each substitute against the original target word to determine if it accurately captured the intended meaning and maintained syntactic and semantic coherence within the sentence. He classified the substitutions as correct or incorrect. The precision of the substitutions was computed by dividing the number of correct substitutes by the total number of substitutes evaluated. The precision would be calculated as 1136/1254, which is equivalent to 90.5%. The high precision rate of above 90% indicates the high quality of the substitutions within the dataset.\nHigh coverage. We show that CHNLS achieves high coverage. The same 300 instances in high quality are selected. Three new human evaluators, proficient in the Chinese language, were asked to independently think of substitutes for each sentence and target word pair in the selected instances.\nThe substitutes provided by the evaluators are compared against the set of substitutions present in the constructed dataset. Each substitute is evaluated to determine whether it matched any of the substitutions in the dataset. The coverage of the dataset is calculated by dividing the number of substitutions provided by the human annotators that belonged to the dataset\u2019s set of substitutions by the total number of substitutions provided.\nThe human annotators provide 742 substitutions and 723 substitutions belonged to the substitutions provided in the CHNLS. The coverage is calculated as 723/742, which is equivalent to 97%. This verification process demonstrates the extensive coverage of the dataset and its suitability for training and evaluating Chinese LS models. Additionally, it is worth noting that the three annotations only yielded a total of 742 substitutes, which is significantly smaller than the 1254 substitutes present in the dataset. This observation highlights the imprac-\nticality of relying solely on manual annotation for generating language substitution word data, as it results in a substantial lack of coverage.\nHigh agreement. We used common agreement metrics such as Cohen\u2019s Kappa(Cohen, 1960) and Fleiss\u2019 Kappa(Fleiss, 1971) to quantify the level of agreement among annotators. Cohen\u2019s Kappa measures agreement between two raters, and Fleiss\u2019 Kappa can be used for measuring agreement between multiple raters. The Kappa result be interpreted as follows: values \u2264 0 as indicating no agreement and 0.01\u20130.20 as none to slight, 0.21\u20130.40 as fair, 0.41\u20130.60 as moderate, 0.61\u20130.80 as substantial, and 0.81\u20131.00 as almost perfect agreement.\nTable 2 lists the agreement scores for three annotators. Specifically, we calculated Fleiss\u2019 Kappa for our dataset, yielding a value of 0.594. This statistic underscores a substantial level of agreement among our human annotators, reaffirming the consistency and reliability of the annotations."
        },
        {
            "heading": "5 Experiments",
            "text": ""
        },
        {
            "heading": "5.1 Experimental Setup",
            "text": "Dataset. We split the whole dataset CHNLS into train (80%), valid (10%), test (10%) set. The train/valid/test sets in Wiki, News, and Novel have 8,425/1,065/888, 9,472/1,169/1,110, and 9,379/1,080/11,07 instances, respectively. The experimental results are computed on test sets.\nMetrics. We employ the designated official metrics, namely \"best,\" \"best-m,\" \"oot,\" and \"oot-m,\" as outlined in the SemEval 2007 task. In addition, we incorporate Precision@1 (P@1) as an evaluation metric, adhering to the conventions established by previous LS methodologies (Zhang et al., 2019; Qiang et al., 2023b). Notably, \"best,\" \"best-m,\" and \"P@1\" gauge the quality of the most accurate predictions, while both \"oot\" (out-of-ten) and \"oot-m\" assess the extent to which the gold substitutes is encompassed within the top 10 predictions.\nImplementation Details. Dict-based(Dict), Embedding-based (Embedding), and BERT-based (BERT): we use the default settings of the pretrained modeling during constructing our LS datasets. For Paraphraser-based(ParaLS), we first\nconstruct a large Chinese paraphrase dataset, containing 5,174,152 sentence pairs. Then we finetune Chinese BART on it to train a paraphraser. The initial learning rate is set to lr = 1\u00d7 10\u22125 and dropout is set to 0.1. We adopt the Adam optimizer with \u03b21 = 0.9, \u03b22 = 0.999, \u03f5 = 10\u22128. For the above methods, we set the max number of the generated candidates as 50. We use BARTscore and BERTscore to rank the candidates and select the top 10 words to calculate metrics. The weights are set as 1, 0.1 for BARTscore and BERTscore for all the above methods. To validate vLLM\u2019s ability on this dataset, we also tested two LLMs: ChatGLM6 and ChatGPT7,using their official API interfaces."
        },
        {
            "heading": "5.2 Evaluation Results",
            "text": "Table 3 displays the performance of all methods on the various metrics. To eliminate the impact of substitute ranking, we also provide the results without substitute ranking in parentheses.\nAmong the individual methods, we observed that BERT and ParaLS outperform the baselines\n6https://open.bigmodel.cn/ 7https://platform.openai.com/\nDict and Embedding. This is because both BERT and ParaLS utilize pretrained models that incorporate contextual information for better predictions. Without substitute ranking, ParaLS achieves better performance than BERT. It also means that ParaLS based on our constructed paraphrase corpus is the best individual LS method. When compared with vLLMs, we found BERT and ParaLS also outperform ChatGPT and ChatGLM.\nExperimental results demonstrate that our proposed method Ensemble surpasses the individual LS methods on all metrics with statistical significance. Ensemble expands the coverage of possible substitutes by utilizing multiple LS methods. Each method has its own coverage limitations and biases. By combining them, Ensemble overcomes individual limitations and biases, leading to broader coverage of substitute candidates. This broader coverage increases the likelihood of finding suitable substitutes for a wide range of target words. Additionally, different LS methods may exhibit varying levels of sensitivity to different linguistic contexts, word senses, or syntactic structures. By combining multiple methods, the ensemble approach becomes\nmore robust to such variations, as it can draw on the strengths of different methods to handle different linguistic scenarios effectively. This robustness contributes to the overall improved performance.\nThese reasons indicate that Ensemble benefits from the diversity, enhanced coverage, and robustness of individual LS methods. The combination of these factors contributes to the significant outperformance of the ensemble approach over the individual LS methods on all evaluation metrics, demonstrating its effectiveness in generating highquality substitutes for the Chinese LS task."
        },
        {
            "heading": "5.3 Qualitative evaluation",
            "text": "To qualitatively evaluate the effectiveness of the substitutes generated by LS methods, we present four instances of the Wiki subset of CHNLS for analysis. Table 4 displays the top 10 generated substitutes. More instances are shown in Appendix B.\nIt is evident that the substitutes we have annotated exhibit a considerable level of comprehensiveness, without any significant absence of suitable substitutes. This observation indicates the high cov-\nerage achieved by our constructed dataset. In comparison, even the latest English lexical substitution datasets, such as SwordS which is the improved version of CoInCo, still exhibit deficiencies in capturing a sufficient number of appropriate substitutes (Qiang et al., 2023b).\nConsistent with the findings from the quantitative evaluation, the performance of the Dict-based and Embedding-based methods, which do not take contextual information into account during the substitution generation process, is relatively low compared to other methods.\nBERT and ParaLS approaches demonstrate promising results in terms of capturing contextual information and generating semantically similar substitutes. By leveraging the strengths of different approaches, Ensemble has two advantages. Firstly, Ensemble yields a greater number of appropriate alternatives when compared to BERT and ParaLS. Across the five instances, BERT, ParaLS, and Ensemble produce 20, 19, and 24 correct substitutes, respectively. Secondly, certain well-suited alternatives that were initially ranked lower in the individual methods ascend to higher positions. For in-\nstance, the substitute \"\u8d70\u7ea2\" (meaning \"to become famous\") in instance 2 exhibits a notable elevation, securing the second rank."
        },
        {
            "heading": "6 Conclusions",
            "text": "This study presents the first comprehensive exploration of the Chinese Lexical Substitution (LS) task. We propose a novel annotation method to construct a large-scale Chinese LS dataset through a collaborative human-machine approach. The constructed dataset consists of 33,695 instances and 165,105 substitutes with high quality and high coverage. Our proposed ensemble method by leveraging the strengths of each method while mitigating their weaknesses, our ensemble approach significantly outperforms the individual LS methods across all evaluation metrics.\nIn conclusion, our study fills the research gap on how to construct a large-scale LS dataset with high coverage and low cost, providing a solid foundation for further research and development. The construction of a high-quality dataset and the development of an effective ensemble method showcase the potential for improved lexical substitution in the Chinese language.\nLimitations\nWhile our proposed collaborative approach successfully constructs a large-scale Chinese Lexical Substitution (LS) dataset, it is important to acknowledge some limitations to provide a balanced perspective.\nDespite the large-scale nature of the dataset, it may not cover all possible lexical substitution scenarios in the Chinese language. The dataset\u2019s coverage might be limited to three genres (Wiki, News, Novel), which could affect its applicability in certain contexts. Researchers should be cautious when generalizing findings beyond the dataset\u2019s scope.\nWhile efforts were made to ensure annotator agreement through guidelines and quality control measures, some level of inconsistency in judgments among human annotators is inevitable. The interannotator agreement might vary for different instances, which could introduce some noise or ambiguity in the dataset.\nEthics Statement\nThe dataset used in our research is constructed using publicly available data sources, ensuring that there are no privacy concerns or violations. We\ndo not collect any personally identifiable information, and all data used in our research is obtained following legal and ethical standards.\nAn additional ethical concern revolves around the possibility of the Chinese LS method being exploited for malicious intents, including the generation of fabricated or deceptive content. It is imperative to contemplate the potential repercussions arising from the outputs of the LS method and to implement protective measures to deter its exploitation for nefarious objectives."
        },
        {
            "heading": "Acknowledgement",
            "text": "This research is partially supported by the National Natural Science Foundation of China under grants 62076217, U22B2037 and 61906060, and the Blue Project of Yangzhou University."
        },
        {
            "heading": "A The construction process of CHNLS",
            "text": "We selected three types of corpus (novel, news, and Wikipedia) as the source of the original text. Each document is divided into sentences, and each verb, noun, adjective, and adverb in each sentence\nis selected as a potential target word. A total of 12,000 target words were selected from each of the three corpora. Subsequently, we employed four distinct lexical substitution methods to generate a set of 15 candidate words for each target word.\nConsequently, every sentence, target word, and corresponding collection of 15 candidate words formed a single sample. Ultimately, we accumulated a comprehensive dataset comprising 36,000 samples. To ensure reliable annotations, each sample was presented to three annotators who were instructed to select appropriate alternatives from the provided word list for tagging. The final annotation results constituted the lexical substitution dataset.\nA.1 Selection of target words We first divided each type of raw corpus into natural sentences. A natural sentence is a complete sentence that ends with a period, exclamation mark, question mark, or ellipsis and can express a complete meaning. Using a word segmenter, we segment and part-of-speech tag the natural sentences. For each verb, noun, adjective, and adverb in each natural sentence, we select them as potential target words. After removing proper nouns, fixed collocations, and other words that cannot be appropriately substituted, the remaining words are considered target words.\nA.2 Annotation Website We have built a website based on JavaWeb+MySQL for annotators\u2019 labeling work. We provide a portion of the target words and a list of 15 substitute words to three annotators to collect suitable sets of substitute words from them.\nTo improve the quality of annotation, we have implemented the following three design strategies.\n(1) To reduce costs and ensure annotation quality, we adopted a rotating approach to presenting the substitute word lists to annotators. In the annotation of each target word, not all 15 substitute words in the list were provided to a single annotator. Instead, a selective subset of 11 or 12 substitute words was presented. This approach aimed to maintain the quality of annotations by avoiding overwhelming annotators with too many words to annotate at once, while significantly reducing the time required for annotation.\nFor these 15 words, they were systematically rotated among the four annotators, ensuring equal opportunities for each word to be assigned to an\nannotator. This rotation strategy does not compromise the reliability of the annotation results, as each word has an equal chance of being assigned to any annotator. Thus, this approach ensures fairness and avoids potential bias in the annotation process.\n(2) We modified the substitute word lists for a selected subset of target words and provided them as confusion sets to the annotators to ensure annotation quality. From the original set of 36,000 target words in three corpora, we randomly selected one-third of the target words. For each selected target word, we made modifications to two substitute words out of the 15-word list. One substitute word was changed to the original target word, which served as a required option for the annotators. The other substitute word was replaced with any Chinese word of the same length as the original target word, sourced from a dictionary, and served as a forbidden option for the annotators.\nDuring the annotation process, we evaluated the quality of annotations by checking whether the annotators correctly labeled the confusion set options. This allowed us to assess the annotation quality based on the annotators\u2019 handling of the confusion sets.\n(3) We have designed three annotation starting positions to ensure consistency in the annotation progress for the three corpora. Each target word has been assigned a unique identifier. Each annotator begins annotating from a designated starting position, which corresponds to the identifier of the target word. To maintain consistency in the an-\nnotation progress across all corpora, we have established a starting position for annotation at the beginning of each corpus, evenly distributed among multiple annotators.\nOnce an annotator successfully annotates a target word, the current annotation identifier increments and the next annotatable content is automatically displayed. Only when an annotator reaches the maximum target word identifier, the annotation cycle restarts from the beginning. This approach offers the advantage of enabling consecutive annotations for target words within the same sentence in most cases, effectively reducing the workload of reading sentences, which is the most time-consuming task.\nFinally, we eliminated instances that did not contain any meaningful substitute. The number of instances is 33,695.\nA.3 Annotation Manual\nThis manual is designed to facilitate the use of the Chinese lexical substitution dataset annotation system. It provides instructions on how to use the system effectively and serves as a reference for users, clarifying the purpose and functionality of the system. The manual includes an overview of the task, an explanation of the system\u2019s features, specific annotation examples, and a section addressing potential issues that may arise.\nA.4 The Work of Annotators\nAnnotators are initially instructed to carefully peruse the annotation manual in its entirety. The administrator provides each annotator with a username and password. The administrator also instructs the annotators to annotate the data carefully and explains the website\u2019s special features. The system\u2019s backend assigns corresponding data to annotators for annotation.\nOn the annotation website, for each instance, annotators need to determine whether suitable substitute words can be found for the target word in the instance. If an annotator believes that the target word in an instance is not suitable for replacement with any word other than the original word, they can select \"Not Replaceable\" for that sample and mark all substitute words as \"Not Suitable.\" If an annotator believes that suitable substitute words can be found for the target word in an instance, they need to evaluate and select the appropriate substitute words from the given list. Additionally,\nannotators can provide alternative suitable substitute words for each instance, different from the ones provided in the given substitute word list. The final collection consists of pairs of target words and the selected substitute word sets as annotated by the annotators.\nRegarding the wage for each annotator, our principle is 15\u00a5 per hour. We conducted a pilot test with one annotator, and they were able to annotate approximately 150 instances in one hour. Based on this calculation, the average price for annotating one instance is 0.1\u00a5. To incentivize annotators to provide new words, an additional price of 0.1\u00a5 is offered for each new substitute word."
        },
        {
            "heading": "B More Examples",
            "text": "Here, we randomly choose 5 instances from News and 5 instances from Novel for analysis in Table 5 and 6.\nBERT, ParaLS, and Ensemble provide high coverage and high-quality substitutes compared to Dict and Embedding. These results indicate that Ensemble achieves a little better results."
        }
    ],
    "title": "Chinese Lexical Substitution: Dataset and Method",
    "year": 2023
}