{
    "abstractText": "Current research on automatic readability assessment (ARA) has focused on improving the performance of models in high-resource languages such as English. In this work, we introduce and release BASAHACORPUS as part of an initiative aimed at expanding available corpora and baseline models for readability assessment in lower resource languages in the Philippines. We compiled a corpus of short fictional narratives written in Hiligaynon, Minasbate, Karaya, and Rinconada\u2014languages belonging to the Central Philippine family tree subgroup\u2014to train ARA models using surface-level, syllablepattern, and n-gram overlap features. We also propose a new hierarchical cross-lingual modeling approach that takes advantage of a language\u2019s placement in the family tree to increase the amount of available training data. Our study yields encouraging results that support previous work showcasing the efficacy of cross-lingual models in low-resource settings, as well as similarities in highly informative linguistic features for mutually intelligible languages.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Joseph Marvin Imperial"
        },
        {
            "affiliations": [],
            "name": "Ekaterina Kochmar"
        }
    ],
    "id": "SP:f2d56fc39276ab151a775c67a892f99251ada11a",
    "references": [
        {
            "authors": [
                "Muhamed Al Khalil",
                "Nizar Habash",
                "Zhengyang Jiang."
            ],
            "title": "A large-scale leveled readability lexicon for Standard Arabic",
            "venue": "Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 3053\u20133062, Marseille, France. European",
            "year": 2020
        },
        {
            "authors": [
                "Patricia L Carrell."
            ],
            "title": "Readability in ESL",
            "venue": "University of Hawaii National Foreign Language Resource Center.",
            "year": 1987
        },
        {
            "authors": [
                "Susmoy Chakraborty",
                "Mir Tafseer Nayeem",
                "Wasi Uddin Ahmad."
            ],
            "title": "Simple or Complex? Learning to Predict Readability of Bengali Texts",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 12621\u201312629.",
            "year": 2021
        },
        {
            "authors": [
                "David J Chard",
                "Jean Osborn."
            ],
            "title": "Phonics and word recognition instruction in early reading programs: Guidelines for accessibility",
            "venue": "Learning Disabilities Research & Practice, 14(2):107\u2013117.",
            "year": 1999
        },
        {
            "authors": [
                "Nam-Thuan Doan",
                "Thi-Anh-Thi Le",
                "An-Vinh Luong",
                "Dien Dinh"
            ],
            "title": "Combining Latent Semantic Analysis and Pre-trained Model for Vietnamese Text Readability Assessment: Combining Statistical Semantic Embeddings and Pre-trained Model for",
            "year": 2022
        },
        {
            "authors": [
                "Arthur C Graesser",
                "Danielle S McNamara",
                "Max M Louwerse",
                "Zhiqiang Cai."
            ],
            "title": "Coh-Metrix: Analysis of Text on Cohesion and Language",
            "venue": "Behavior Research Methods, Instruments, & Computers, 36(2):193\u2013202.",
            "year": 2004
        },
        {
            "authors": [
                "Merry Ruth M Gutierrez."
            ],
            "title": "The Suitability of the Fry and SMOG Readability Formulae in Determining the Readability of Filipino Texts",
            "venue": "The Normal Lights, 8(1).",
            "year": 2015
        },
        {
            "authors": [
                "Joseph Marvin Imperial",
                "Ekaterina Kochmar."
            ],
            "title": "Automatic Readability Assessment for Closely Related Languages",
            "venue": "Findings of the Association for Computational Linguistics: ACL 2023, pages 5371\u2013 5386, Toronto, Canada. Association for Computa-",
            "year": 2023
        },
        {
            "authors": [
                "Joseph Marvin Imperial",
                "Ethel Ong."
            ],
            "title": "Exploring Hybrid Linguistic Feature Sets to Measure Filipino Text Readability",
            "venue": "2020 International Conference on Asian Language Processing (IALP), pages 175\u2013180. IEEE.",
            "year": 2020
        },
        {
            "authors": [
                "Joseph Marvin Imperial",
                "Ethel Ong"
            ],
            "title": "Diverse Linguistic Features for Assessing Reading Difficulty",
            "year": 2021
        },
        {
            "authors": [
                "Joseph Marvin Imperial",
                "Ethel Ong."
            ],
            "title": "Under the microscope: Interpreting readability assessment models for Filipino",
            "venue": "Proceedings of the 35th Pacific Asia Conference on Language, Information and Computation, pages 1\u201310, Shanghai, China. Associa-",
            "year": 2021
        },
        {
            "authors": [
                "Joseph Marvin Imperial",
                "Lloyd Lois Antonie Reyes",
                "Michael Antonio Ibanez",
                "Ranz Sapinit",
                "Mohammed Hussien."
            ],
            "title": "A baseline readability model for Cebuano",
            "venue": "Proceedings of the 17th Workshop on Innovative Use of NLP for Building",
            "year": 2022
        },
        {
            "authors": [
                "Joseph Marvin Imperial",
                "Rachel Edita Roxas",
                "Erica Mae Campos",
                "Jemelee Oandasan",
                "Reyniel Caraballo",
                "Ferry Winsley Sabdani",
                "Ani Rosa Almario."
            ],
            "title": "Developing a machine learning-based grade level classifier for Filipino children\u2019s literature",
            "venue": "In",
            "year": 2019
        },
        {
            "authors": [
                "Zahrul Islam",
                "Rashedur Rahman."
            ],
            "title": "Readability of Bangla news articles for children",
            "venue": "Proceedings of the 28th Pacific Asia Conference on Language, Information and Computing, pages 309\u2013317, Phuket,Thailand. Department of Linguistics, Chula-",
            "year": 2014
        },
        {
            "authors": [
                "Zahurul Islam",
                "Alexander Mehler",
                "Rashedur Rahman."
            ],
            "title": "Text readability classification of textbooks of a low-resource language",
            "venue": "Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation, pages 545\u2013553, Bali,",
            "year": 2012
        },
        {
            "authors": [
                "J Peter Kincaid",
                "Robert P Fishburne Jr",
                "Richard L Rogers",
                "Brad S Chissom."
            ],
            "title": "Derivation Of New Readability Formulas (Automated Readability Index, Fog Count And Flesch Reading Ease Formula) For Navy Enlisted Personnel",
            "venue": "Naval Technical Train-",
            "year": 1975
        },
        {
            "authors": [
                "Bruce W. Lee",
                "Yoo Sung Jang",
                "Jason Lee."
            ],
            "title": "Pushing on text readability assessment: A transformer meets handcrafted linguistic features",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 10669\u2013",
            "year": 2021
        },
        {
            "authors": [
                "Justin Lee",
                "Sowmya Vajjala."
            ],
            "title": "A neural pairwise ranking model for readability assessment",
            "venue": "Findings of the Association for Computational Linguistics: ACL 2022, pages 3802\u20133813, Dublin, Ireland. Association for Computational Linguistics.",
            "year": 2022
        },
        {
            "authors": [
                "Heidi B Macahilig."
            ],
            "title": "A content-based readability formula for Filipino texts",
            "venue": "The Normal Lights, 8(1).",
            "year": 2014
        },
        {
            "authors": [
                "Ion Madrazo Azpiazu",
                "Maria Soledad Pera"
            ],
            "title": "Is Cross-Lingual Readability Assessment Possible",
            "venue": "Journal of the Association for Information Science and Technology,",
            "year": 2020
        },
        {
            "authors": [
                "Curtis D McFarland."
            ],
            "title": "The Philippine language situation",
            "venue": "World Englishes, 23(1):59\u201375.",
            "year": 2004
        },
        {
            "authors": [
                "Sepideh Mollanorozy",
                "Marc Tanti",
                "Malvina Nissim."
            ],
            "title": "Cross-lingual transfer learning with Persian",
            "venue": "Proceedings of the 5th Workshop on Research in Computational Linguistic Typology and Multilingual NLP, pages 89\u201395, Dubrovnik, Croatia. Association",
            "year": 2023
        },
        {
            "authors": [
                "Fabian Pedregosa",
                "Ga\u00ebl Varoquaux",
                "Alexandre Gramfort",
                "Vincent Michel",
                "Bertrand Thirion",
                "Olivier Grisel",
                "Mathieu Blondel",
                "Peter Prettenhofer",
                "Ron Weiss",
                "Vincent Dubourg."
            ],
            "title": "Scikit-learn: Machine learning in Python",
            "venue": "the Journal of machine Learning",
            "year": 2011
        },
        {
            "authors": [
                "Emily Pitler",
                "Ani Nenkova."
            ],
            "title": "Revisiting readability: A unified framework for predicting text quality",
            "venue": "Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 186\u2013195, Honolulu, Hawaii. Association for Compu-",
            "year": 2008
        },
        {
            "authors": [
                "Hind Saddiki",
                "Nizar Habash",
                "Violetta Cavalli-Sforza",
                "Muhamed Al Khalil."
            ],
            "title": "Feature optimization for predicting readability of Arabic L1 and L2",
            "venue": "Proceedings of the 5th Workshop on Natural Language Processing Techniques for Educational Appli-",
            "year": 2018
        },
        {
            "authors": [
                "Sowmya Vajjala."
            ],
            "title": "Trends, limitations and open challenges in automatic readability assessment research",
            "venue": "Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 5366\u2013 5377, Marseille, France. European Language Re-",
            "year": 2022
        },
        {
            "authors": [
                "Sowmya Vajjala",
                "Detmar Meurers."
            ],
            "title": "On improving the accuracy of readability classification using insights from second language acquisition",
            "venue": "Proceedings of the Seventh Workshop on Building Educational Applications Using NLP, pages 163\u2013173,",
            "year": 2012
        },
        {
            "authors": [
                "Sowmya Vajjala",
                "Taraka Rama."
            ],
            "title": "Experiments with universal CEFR classification",
            "venue": "Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, pages 147\u2013153, New Orleans, Louisiana. Association for",
            "year": 2018
        },
        {
            "authors": [
                "Zhijuan Wang",
                "Xiaobin Zhao",
                "Wei Song",
                "Antai Wang."
            ],
            "title": "Readability Assessment of Textbooks in Low Resource Languages",
            "venue": "Computers, Materials & Continua, 61(1).",
            "year": 2019
        },
        {
            "authors": [
                "Zarah Weiss",
                "Xiaobin Chen",
                "Detmar Meurers."
            ],
            "title": "Using Broad Linguistic Complexity Modeling for Cross-Lingual Readability Assessment",
            "venue": "Proceedings of the 10th Workshop on NLP for Computer Assisted Language Learning, pages 38\u201354, Online.",
            "year": 2021
        },
        {
            "authors": [
                "Bryan Wilie",
                "Karissa Vincentio",
                "Genta Indra Winata",
                "Samuel Cahyawijaya",
                "Xiaohong Li",
                "Zhi Yuan Lim",
                "Sidik Soleman",
                "Rahmad Mahendra",
                "Pascale Fung",
                "Syafri Bahar",
                "Ayu Purwarianti"
            ],
            "title": "IndoNLU: Benchmark and resources for evaluating Indonesian",
            "year": 2020
        },
        {
            "authors": [
                "Menglin Xia",
                "Ekaterina Kochmar",
                "Ted Briscoe."
            ],
            "title": "Text readability assessment for second language learners",
            "venue": "Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications, pages 12\u201322, San Diego, CA. Associa-",
            "year": 2016
        },
        {
            "authors": [
                "R. David Zorc."
            ],
            "title": "The Bisayan dialects of the Philippines: Subgrouping and reconstruction",
            "venue": "Pacific Linguistics, Research School of Pacific and Asian Studies.",
            "year": 1976
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "To ensure optimal reading comprehension, literary resources such as books need to be assigned to readers based on their reading level assessment (Carrell, 1987). Readability assessment can be tackled with a variety of methods ranging from the application of rule-based approaches using such widely accepted formulas as Flesch-Kincaid (Kincaid et al., 1975), to the use of software for linguistic feature extraction such as Coh-Metrix (Graesser et al., 2004) or LFTK (Lee et al., 2021), to the application of extensive machine learning models (Vajjala and Meurers, 2012; Xia et al., 2016). Recently, the latter have been the focus of research on ARA due to the availability of increasingly complex models, including deep learning architectures, that yield\n1https://github.com/imperialite/BasahaCorpu s-HierarchicalCrosslingualARA\nbetter text representations and outperform simpler (e.g., formula-based) approaches (Vajjala, 2022). These are, however, mostly practical if trained on high-resource data like English.\nBeyond the limelight on high-resource languages like English, languages that do require extensive research efforts and initiatives are commonly considered low-resource. One such group of languages comprises over 170 living languages spoken in the Philippines, and one of the three concluding recommendations in the final report of the five-year (2013\u20132018) USAID Basa Pilipinas (\u201cRead Philippines\") Program2 targeting the im-\n2https://www.edc.org/usaidphilippines-basa-p ilipinas-program-final-project-report\nprovement of literacy in the Philippines was the \"provision of curriculum-based teaching and learning materials (TLMs) and quality supplementary reading materials\". This entails the need for a variety of age-appropriate texts for young learners in the Philippines to be accessible at home and in school. Following this, the Department of Education further encouraged the development of reading materials for the Mother Tongue-Based Multilingual Education (MTB-MLE) scheme implemented at primary levels of school education in the Philippines.3 Thus, the Philippine education sector needs access not only to sufficient age-appropriate learning and reading materials but also to automated tools for assessing text difficulty that can work effectively for the variety of languages covered by MTB-MLE.\nThis work contributes a number of resources to the Philippine language research landscape, catering to the challenges identified above, and aligns with other recent research efforts aimed at lowresource languages such as the IndoNLP (Wilie et al., 2020; Winata et al., 2023). First, to increase accessibility and encourage more research endeavors in low-resource Philippine languages, we collect and release BASAHACORPUS,4 a compilation of children\u2019s narratives and short stories from Let\u2019s Read Asia online library in four Philippine languages (Hiligaynon, Minasbate, Karay-a, and Rinconda). Second, we train a number of baseline readability assessment models using various cross-lingual setups leveraging the hierarchy in the language family tree. Lastly, we apply a simple model interpretation technique to identify how different linguistic features act as predictors of text complexity for each language."
        },
        {
            "heading": "2 A Closer Look into Central Philippine Languages",
            "text": "The Philippines is an archipelago with a rich linguistic background, as evidenced by over 170 languages at the backbone of its culture.5 In particular, the central Philippine language subtree is considered the largest among other subtrees as it is composed of a number of branches, including the national language Tagalog (also known as Filipino),\n3https://www.deped.gov.ph/2016/10/24/mother-t ongue-based-learning-makes-lessonsmore-interacti ve-and-easier-for-students/\n4Basaha generally denotes verbal form of \"read\" in Bisayan languages.\n5https://www.ethnologue.com/country/PH/\nthe Bikol languages, the Bisayan languages, and the East Mindanao languages (McFarland, 2004). Focusing on the languages of interest for this study, we show where Hiligaynon, Minasbate, Karay-a, and Rinconada are situated in this tree (see Figure 1) and how they are classified within specific subgroups (Zorc, 1976). In the following sections, we integrate the hierarchical relationships of these four languages with other languages in the family tree into our experiments."
        },
        {
            "heading": "2.1 Data from Let\u2019s Read Asia",
            "text": "Let\u2019s Read Asia6 is an online library of communitytranslated literary materials sponsored by The Asia Foundation. Using the data collected from the website, we built BASAHACORPUS by compiling short stories written in Philippine languages, which were only available in Hiligaynon, Minasbate, Karay-a, and Rinconada, thus defining our choice to work on these languages. The compiled data are distributed across the first three years of elementary education (L1, L2, and L3). We provide information on the language family, origin subgroup, linguistic vitality, availability of language resources, and whether these languages are used as a medium of instruction in classes in Table 1.\nWe also compute basic statistical information about the data per language and per level, including mean word and sentence count and vocabulary size, and report it in Table 2. All languages in BASAHACORPUS exclusively use Latin script as is the case for the majority of languages in the Philippines. In terms of the distribution of resources, we obtained explicit permission from Let\u2019s Read Asia to use this data in this research with the further goal of publicly sharing the resources, which are licensed under Creative Commons BY 4.0."
        },
        {
            "heading": "3 Linguistic Features for Low-Resource Languages",
            "text": "Due to the lack of available NLP tools to extract advanced linguistic information from texts that would work for all four target languages as well as enough data to use deep learning approaches, we derive the same linguistic features as used by the previous work on ARA in other low-resource Philippine languages such as Tagalog (Imperial et al., 2019; Imperial and Ong, 2020, 2021a) and Cebuano (Imperial et al., 2022). However, we note that this study is the first to explore baseline\n6https://www.letsreadasia.org/"
        },
        {
            "heading": "Mean Word",
            "text": "modeling of text complexity in the four selected languages \u2013 Hiligaynon, Minasbate, Karay-a, and Rinconada. We list all extracted features below.\nTraditional Features. We extract 7 frequencybased features using count-based text characteristics. Despite being often considered simplistic, these predictors have consistently proven to be effective in text readability detection (Pitler and Nenkova, 2008; Imperial and Ong, 2021b). As in the previous work on a Cebuano dataset Imperial et al. (2022), our extracted text-level features include the total number of unique words, total number of words per document, average word length per document, average number of syllables (per word), total sentence count per document, average sentence length per document, and the total number of polysyllable words.\nSyllable-pattern Orthographic Features. We also extract 11 orthographic predictors taking into account all possible syllable patterns in the Philippine language space. These consonant\n(c) and vowel (v) patterns include v, cv, vc, cvc, vcc, ccv, cvcc, ccvcc, ccvccc. We also extract consonant clusters and measure the average length of consonant groups in a word without an intervening vowel which have been proven to influence reading difficulty (Chard and Osborn, 1999).\nCross-lingual N-gram Overlap. A new CROSSNGO feature has recently been introduced by Imperial and Kochmar (2023), which exploits mutual intelligibility or the degree of language relatedness via n-gram overlap between languages from the same family tree. Since the study reported a significant boost in performance for readability assessment in low-resource languages using this feature, we see a clear practical application for it in this work. We estimate the bigram and trigram overlap between the four target central Philippine languages (Hiligaynon, Minasbate, Karay-a, and Rinconada), as well as the three parent languages (Tagalog, Bikol, and Cebuano) for a total of 14 new features. As an additional reference, we add two\ntables quantifying the similarities via cross-lingual n-gram overlap of the 7 Philippine languages used in this study in Tables 7 and 6 of Appendix A."
        },
        {
            "heading": "4 Hierarchical Cross-lingual Modeling",
            "text": "Cross-lingual modeling for automatic readability assessment typically involves extracting languageindependent features or experimenting with a classifier trained on the data in one language and applied to comparable data in another language (Madrazo Azpiazu and Pera, 2020; Weiss et al., 2021; Lee and Vajjala, 2022; Imperial and Kochmar, 2023). In this study, we introduce a new approach to training readability assessment models using close relationships between languages in the family tree, which we refer to as hierarchy-based cross-lingual modeling. For this setup, our cross-lingual training process is divided into iterations involving different combinations of language data in the training split with respect to the hierarchy the languages occupy in the Central Philippine language subtree, as illustrated in Figure 1. We list all such feature combinations below:\nMonolingual (L). This setup uses the standard train-test split involving one language only.\nLang + Parent Lang (L+P). This setup combines the parent language or lingua franca with respect to their subgroup. For Hiligaynon, Minasbate, and Karay-a, belonging to the Bisayan languages in the Visayas region, we add the Cebuano language, while for Rinconada, classified as a member of the Bikol languages belonging to the Luzon region, we add the Central Bikol language both from Imperial and Kochmar (2023).\nLang + National Lang (L+N). This setup combines the four target languages with Tagalog in the training data extracted from Imperial and Kochmar (2023), Imperial and Ong (2020) and Imperial et al. (2019). Tagalog is the recognized national language taught as a subject in all elementary and secondary schools in the Philippines."
        },
        {
            "heading": "Lang + Parent Lang + National Lang (L+P+N).",
            "text": "This setup combines each target language with its corresponding parent language and Tagalog in the training data.\nAll Langs (*L). This setup combines all seven languages used in the previous iterations (Hiligaynon, Minasbate, Karay-a, Rinconada, Bikol, Cebuano, and Tagalog) in the training data.\nWe note that the Tagalog, Bikol, and Cebuano data from Imperial and Kochmar (2023) that we use for this study also follows the same category distribution (L1, L2, and L3) as our four languages from Table 2. For all model training in this study, we use Random Forest with default hyperparameters from Scikit-Learn (Pedregosa et al., 2011), as the efficacy of this algorithm was reported in the previous studies on ARA in the Philippine languages (Imperial et al., 2022; Imperial and Ong, 2021a). We perform stratified 5-fold sampling for all three classes to be properly represented. Hyperparameter values of the Random Forest model can also be found in Table 5 of Appendix A."
        },
        {
            "heading": "5 Results and Discussion",
            "text": "Below, we summarize and discuss the most notable insights obtained from the conducted experiments."
        },
        {
            "heading": "5.1 Using extensive multilingual training data results in generally better performance.",
            "text": "Table 3 shows the results of the ablation experiments using the hierarchical cross-lingual modeling setup as described in Section 4. We observe that using the all languages setup (*L) for the training data helps obtain the best accuracy performance for the three Bisayan languages (HIL, MSB and KRJ) but not for Rinconada (BTO) from the Bikol subgroup. However, the score for Rinconda with the *L setup is still higher than for the monolingual model and even the L+P+N setup. A t-test confirms that the scores obtained with the *L setup are significantly higher than those obtained with the monolingual setup L for all languages at \u03b1 = 0.05 level (p = 0.048). These results support the findings of Imperial and Kochmar (2023), who showed the importance of combining data from closely related\nlanguages (or languages within the same family tree) for performance improvements in ARA models."
        },
        {
            "heading": "5.2 Stronger mutual intelligibility improves model performance.",
            "text": "Following Imperial and Kochmar (2023), we compute the overlap of the top 25% of the trigrams and bigrams in order to estimate mutual intelligibility between languages from the Bisayan and Bikol subgroups and their respective parent languages, Cebuano and Bikol. We find that Rinconada (BTO) has the highest overlap (0.696 for trigrams and 0.887 for bigrams) with its parent language (Bikol) \u2013 a fact that explains why the best results for this language are obtained with the L+P combination. For comparison, the other three languages (Hiligaynon, Minasbate, and Karay-a) show n-gram overlaps of 0.609, 0.579, and 0.540 for trigrams, and 0.863, 0.789, and 0.809 for bigrams with their parent language, respectively. See the trigram and bigram overlap results in Tables 6 and 7 in Appendix A."
        },
        {
            "heading": "5.3 Support for traditional features in approximating text complexity for Philippine languages.",
            "text": "Finally, we identify the most informative linguistic features by calculating the mean decrease in impurities when splitting by the Random Forest models trained with all languages (*L) and applied to the test splits for each of the four languages. Table 4 shows that all models for all languages demonstrate the same order in top features which are all considered count-based predictors. We believe that this finding corroborates results from previous work showing that frequency-based features such as word and sentence counts are still viable measures of text complexity for Philippine languages (Macahilig, 2014; Gutierrez, 2015)."
        },
        {
            "heading": "6 Related Work",
            "text": "In the past, cross-lingual modeling was applied to classification-based ARA both for non-related (Vajjala and Rama, 2018; Madrazo Azpiazu and Pera, 2020; Weiss et al., 2021; Lee and Vajjala, 2022; Mollanorozy et al., 2023) and highly-related languages (Imperial and Kochmar, 2023), with the latter reporting favorable results under predefined language similarity constraints such as high n-gram overlap.7 Research efforts that greatly contribute to\n7Here, we interpret language relatedness as a measure of similarity of linguistic characteristics such as n-gram overlap"
        },
        {
            "heading": "HIL MSB",
            "text": ""
        },
        {
            "heading": "KRJ BTO",
            "text": "the development of low-resource and cross-lingual readability assessment systems often focus on corpus building and the development of baseline models. Previous efforts of this kind have covered a wide array of languages, including Bangla (Islam et al., 2012; Islam and Rahman, 2014), Tibetan (Wang et al., 2019), Arabic (Saddiki et al., 2018; Al Khalil et al., 2020), Vietnamese (Doan et al., 2022), Bengali (Chakraborty et al., 2021), and Bikol (Imperial and Kochmar, 2023). As compared to the previous works, ours is the first study in readability assessment that investigates the effects of different language hierarchies in modeling text complexity for languages belonging to different subgroups of a greater family tree, with the focus on central Philippine languages."
        },
        {
            "heading": "7 Summary",
            "text": "We introduce BASAHACORPUS, a compilation of language resources that includes a collected corpus of short stories and baseline readability assessment models for four central Philippine languages. We show that, through a hierarchical crosslingual modeling approach, a readability model trained with all the available Philippine language data generally performs better compared to using single-language datasets. Through model interpretation, we also provide further support for the use of frequency-based features such as word and sentence counts as effective predictors of complexity in Philippine languages. This study serves as a response to the call for more research efforts, theoretically grounded baselines, and accessible data for low-resource languages.\n(Imperial and Kochmar, 2023)."
        },
        {
            "heading": "Limitations",
            "text": "Limited feature sets for low-resource languages. Due to severely limited existing NLP research efforts for the Philippine languages that this work addresses, we have to resort to a small number of feature extraction methods covering surface-level characteristics, syllable patterns, and n-gram overlap that have been previously applied to the related Philippine languages such as Tagalog and Cebuano (Imperial and Ong, 2020, 2021a; Imperial et al., 2022; Imperial and Kochmar, 2023). Nevertheless, we believe that our findings are valuable as this work provides the baseline for readability assessment in Hiligaynon, Minasbate, Karay-a, and Rinconada in addition to being the first one to address these languages. We hope that future research efforts will lead to a substantial expansion in the data available for these languages, which in turn will help researchers develop and apply more advanced ARA models to these languages and benchmark them against the results reported in our paper. We consider our work the first step in the direction of addressing such challenging tasks as ARA in low-resource Philippine languages.\nLow variety of the data. This work uses only fictional short stories in specific grade levels (L1, L2, and L3) as training data for the readability assessment models, which may be considered a limitation in the application domain. While the same features can be extracted and applied to other text forms in various domains such as news articles or poems, we do not claim that the results will generalize or apply to such other datasets."
        },
        {
            "heading": "Ethics Statement",
            "text": "We foresee no serious ethical implications from this study."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank the anonymous reviewers for their constructive feedback and the ACs, SACs, and PCs for their appreciation of this work. We also thank the community translators and maintainers of the online library of Let\u2019s Read Asia for keeping the digital resources in the Philippine languages freely available for everyone. JMI is supported by the UKRI Centre for Doctoral Training in Accountable, Responsible, and Transparent AI (ART-AI)\n[EP/S023437/1] of the University of Bath and by the Study Grant Program of National University Philippines."
        },
        {
            "heading": "A Appendix",
            "text": ""
        }
    ],
    "title": "BASAHACORPUS: An Expanded Linguistic Resource for Readability Assessment in Central Philippine Languages",
    "year": 2023
}