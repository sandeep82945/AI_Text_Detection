{
    "abstractText": "Transformer models have demonstrated remarkable performance in neural machine translation (NMT). However, their vulnerability to noisy input poses a significant challenge in practical implementation, where generating clean output from noisy input is crucial. The MTNT dataset (Michel and Neubig, 2018) is widely used as a benchmark for evaluating the robustness of NMT models against noisy input. Nevertheless, its utility is limited due to the presence of noise in both the source and target sentences. To address this limitation, we focus on cleaning the noise from the target sentences in MTNT, making it more suitable as a benchmark for noise evaluation. Leveraging the capabilities of large language models (LLMs), we observe their impressive abilities in noise removal. For example, they can remove emojis while considering their semantic meaning. Additionally, we show that LLM can effectively rephrase slang, jargon, and profanities. The resulting datasets, called C-MTNT, exhibit significantly less noise in the target sentences while preserving the semantic integrity of the original sentences. Our human and GPT-4 evaluations also lead to a consistent conclusion that LLM performs well on this task. Lastly, experiments on C-MTNT showcased its effectiveness in evaluating the robustness of NMT models, highlighting the potential of advanced language models for data cleaning and emphasizing C-MTNT as a valuable resource.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Quinten Bolding"
        },
        {
            "affiliations": [],
            "name": "Baohao Liao"
        },
        {
            "affiliations": [],
            "name": "Brandon James Denis"
        },
        {
            "affiliations": [],
            "name": "Jun Luo"
        },
        {
            "affiliations": [],
            "name": "Christof Monz"
        }
    ],
    "id": "SP:afa98467c4f6dcf1074fb2e60ffd5ca130965347",
    "references": [
        {
            "authors": [
                "Mikel Artetxe",
                "Holger Schwenk."
            ],
            "title": "Massively multilingual sentence embeddings for zeroshot cross-lingual transfer and beyond",
            "venue": "Trans. Assoc. Comput. Linguistics, 7:597\u2013610.",
            "year": 2019
        },
        {
            "authors": [
                "Ankur Bapna",
                "Mia Xu Chen",
                "Orhan Firat",
                "Yuan Cao",
                "Yonghui Wu."
            ],
            "title": "Training deeper neural machine translation models with transparent attention",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brus-",
            "year": 2018
        },
        {
            "authors": [
                "Steven Bird",
                "Ewan Klein",
                "Edward Loper."
            ],
            "title": "Natural Language Processing with Python",
            "venue": "O\u2019Reilly.",
            "year": 2009
        },
        {
            "authors": [
                "Mauro Cettolo",
                "Christian Girardi",
                "Marcello Federico."
            ],
            "title": "WIT3: web inventory of transcribed and translated talks",
            "venue": "Proceedings of the 16th Annual conference of the European Association for Machine Translation, EAMT 2012, Trento, Italy, May 28-30,",
            "year": 2012
        },
        {
            "authors": [
                "Ting Chen",
                "Simon Kornblith",
                "Mohammad Norouzi",
                "Geoffrey E. Hinton."
            ],
            "title": "A simple framework for contrastive learning of visual representations",
            "venue": "CoRR, abs/2002.05709.",
            "year": 2020
        },
        {
            "authors": [
                "Zekai Chen",
                "Mariann Micsinai Balan",
                "Kevin Brown."
            ],
            "title": "Language models are few-shot learners for prognostic prediction",
            "venue": "CoRR, abs/2302.12692.",
            "year": 2023
        },
        {
            "authors": [
                "John Joon Young Chung",
                "Ece Kamar",
                "Saleema Amershi"
            ],
            "title": "Increasing diversity while maintaining accuracy: Text data generation with large language models and human interventions",
            "year": 2023
        },
        {
            "authors": [
                "Steven Coyne",
                "Keisuke Sakaguchi."
            ],
            "title": "An analysis of gpt-3\u2019s performance in grammatical error correction",
            "venue": "CoRR, abs/2303.14342.",
            "year": 2023
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Yingbo Gao",
                "Baohao Liao",
                "Hermann Ney."
            ],
            "title": "Unifying input and output smoothing in neural machine translation",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, COLING 2020, Barcelona, Spain (Online), Decem-",
            "year": 2020
        },
        {
            "authors": [
                "Lieve Hamers",
                "Yves Hemeryck",
                "Guido Herweyers",
                "Marc Janssen",
                "Hans Keters",
                "Ronald Rousseau",
                "Andr\u00e9 Vanhoutte."
            ],
            "title": "Similarity measures in scientometric research: The jaccard index versus salton\u2019s cosine formula",
            "venue": "Inf. Process. Manag., 25(3):315\u2013",
            "year": 1989
        },
        {
            "authors": [
                "Felix Hieber",
                "Tobias Domhan",
                "Michael J. Denkowski",
                "David Vilar."
            ],
            "title": "Sockeye 2: A toolkit for neural machine translation",
            "venue": "pages 457\u2013458.",
            "year": 2020
        },
        {
            "authors": [
                "Dongyang Hu",
                "Junhui Li."
            ],
            "title": "Contrastive learning for robust neural machine translation with ASR errors",
            "venue": "Natural Language Processing and Chinese Computing - 11th CCF International Conference, NLPCC 2022, Guilin, China, September 24-25,",
            "year": 2022
        },
        {
            "authors": [
                "Xiao Shi Huang",
                "Felipe P\u00e9rez",
                "Jimmy Ba",
                "Maksims Volkovs."
            ],
            "title": "Improving transformer optimization through better initialization",
            "venue": "Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume",
            "year": 2020
        },
        {
            "authors": [
                "Yongkeun Hwang",
                "Hyungu Yun",
                "Kyomin Jung."
            ],
            "title": "Contrastive learning for context-aware neural machine translationusing coreference information",
            "venue": "arXiv preprint arXiv:2109.05712.",
            "year": 2021
        },
        {
            "authors": [
                "Matthew A Jaro."
            ],
            "title": "Advances in record-linkage methodology as applied to matching the 1985 census of tampa, florida",
            "venue": "Journal of the American Statistical Association, 84(406):414\u2013420.",
            "year": 1989
        },
        {
            "authors": [
                "Wenxiang Jiao",
                "Wenxuan Wang",
                "Jen-tse Huang",
                "Xing Wang",
                "Zhaopeng Tu."
            ],
            "title": "Is chatgpt A good translator? A preliminary study",
            "venue": "CoRR, abs/2301.08745.",
            "year": 2023
        },
        {
            "authors": [
                "Vladimir Karpukhin",
                "Omer Levy",
                "Jacob Eisenstein",
                "Marjan Ghazvininejad."
            ],
            "title": "Training on synthetic noise improves robustness to natural noise in machine translation",
            "venue": "CoRR, abs/1902.01509.",
            "year": 2019
        },
        {
            "authors": [
                "Huda Khayrallah",
                "Hainan Xu",
                "Philipp Koehn."
            ],
            "title": "The JHU parallel corpus filtering systems for WMT 2018",
            "venue": "Proceedings of the Third Conference on Machine Translation: Shared Task Papers, WMT 2018, Belgium, Brussels, October 31 - November 1, 2018,",
            "year": 2018
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Jimmy Ba."
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.",
            "year": 2015
        },
        {
            "authors": [
                "Sosuke Kobayashi."
            ],
            "title": "Contextual augmentation: Data augmentation by words with paradigmatic relations",
            "venue": "CoRR, abs/1805.06201.",
            "year": 2018
        },
        {
            "authors": [
                "Philipp Koehn",
                "Vishrav Chaudhary",
                "Ahmed El-Kishky",
                "Naman Goyal",
                "Peng-Jen Chen",
                "Francisco Guzm\u00e1n."
            ],
            "title": "Findings of the WMT 2020 shared task on parallel corpus filtering and alignment",
            "venue": "Proceedings of the Fifth Conference on Machine",
            "year": 2020
        },
        {
            "authors": [
                "Anis Koubaa."
            ],
            "title": "Gpt-4 vs",
            "venue": "gpt-3.5: A concise showdown.",
            "year": 2023
        },
        {
            "authors": [
                "Taku Kudo",
                "John Richardson."
            ],
            "title": "Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP",
            "year": 2018
        },
        {
            "authors": [
                "Takumitsu Kudo"
            ],
            "title": "Mecab : Yet another part-ofspeech and morphological analyzer",
            "year": 2005
        },
        {
            "authors": [
                "Baohao Liao",
                "Yingbo Gao",
                "Hermann Ney."
            ],
            "title": "Multi-agent mutual learning at sentence-level and token-level for neural machine translation",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020,",
            "year": 2020
        },
        {
            "authors": [
                "Baohao Liao",
                "Shahram Khadivi",
                "Sanjika Hewavitharana."
            ],
            "title": "Back-translation for large-scale multilingual machine translation",
            "venue": "Proceedings of the Sixth Conference on Machine Translation, WMT@EMNLP 2021, Online Event, November 10-11, 2021, pages",
            "year": 2021
        },
        {
            "authors": [
                "Chin-Yew Lin."
            ],
            "title": "Rouge: A package for automatic evaluation of summaries",
            "venue": "Text summarization branches out, pages 74\u201381.",
            "year": 2004
        },
        {
            "authors": [
                "Konstantinos Mavrogiorgos",
                "Argyro Mavrogiorgou",
                "Athanasios Kiourtis",
                "Nikolaos Zafeiropoulos",
                "Spyridon Kleftakis",
                "Dimosthenis Kyriazis."
            ],
            "title": "Automated rule-based data cleaning using NLP",
            "venue": "32nd Conference of Open Innovations Association, FRUCT",
            "year": 2022
        },
        {
            "authors": [
                "Yu Meng",
                "Jiaxin Huang",
                "Yu Zhang",
                "Jiawei Han."
            ],
            "title": "Generating training data with language models: Towards zero-shot language understanding",
            "venue": "NeurIPS.",
            "year": 2022
        },
        {
            "authors": [
                "Zhengjie Miao",
                "Yuliang Li",
                "Xiaolan Wang."
            ],
            "title": "Rotom: A meta-learned data augmentation framework for entity matching, data cleaning, text classification, and beyond",
            "venue": "SIGMOD \u201921: International Conference on Management of Data, Virtual Event,",
            "year": 2021
        },
        {
            "authors": [
                "Paul Michel",
                "Graham Neubig."
            ],
            "title": "MTNT: A testbed for machine translation of noisy text",
            "venue": "CoRR, abs/1809.00388.",
            "year": 2018
        },
        {
            "authors": [
                "George A. Miller."
            ],
            "title": "Wordnet: A lexical database for english",
            "venue": "Commun. ACM, 38(11):39\u201341.",
            "year": 1995
        },
        {
            "authors": [
                "Niels M\u00fcndler",
                "Jingxuan He",
                "Slobodan Jenko",
                "Martin T. Vechev."
            ],
            "title": "Self-contradictory hallucinations of large language models: Evaluation, detection and mitigation",
            "venue": "CoRR, abs/2305.15852.",
            "year": 2023
        },
        {
            "authors": [
                "Graham Neubig."
            ],
            "title": "The Kyoto free translation task",
            "venue": "http://www.phontron.com/kftt.",
            "year": 2011
        },
        {
            "authors": [
                "Naoaki Okazaki",
                "Jun\u2019ichi Tsujii"
            ],
            "title": "Simple and efficient algorithm for approximate dictionary matching",
            "venue": "In COLING 2010, 23rd International Conference on Computational Linguistics, Proceedings of the Conference,",
            "year": 2010
        },
        {
            "authors": [
                "OpenAI."
            ],
            "title": "GPT-3 API Documentation",
            "venue": "https://beta.openai.com/docs/ api-reference/introduction. Accessed on: February 23, 2023.",
            "year": 2021
        },
        {
            "authors": [
                "OpenAI."
            ],
            "title": "GPT-4 technical report",
            "venue": "CoRR, abs/2303.08774.",
            "year": 2023
        },
        {
            "authors": [
                "Myle Ott",
                "Sergey Edunov",
                "Alexei Baevski",
                "Angela Fan",
                "Sam Gross",
                "Nathan Ng",
                "David Grangier",
                "Michael Auli."
            ],
            "title": "fairseq: A fast, extensible toolkit for sequence modeling",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Asso-",
            "year": 2019
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, July 6-12, 2002, Philadelphia,",
            "year": 2002
        },
        {
            "authors": [
                "Jonathan Pilault",
                "Raymond Li",
                "Sandeep Subramanian",
                "Chris Pal."
            ],
            "title": "On extractive and abstractive neural document summarization with transformer language models",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language",
            "year": 2020
        },
        {
            "authors": [
                "Reid Pryzant",
                "Youngjoo Chung",
                "Dan Jurafsky",
                "Denny Britz."
            ],
            "title": "JESC: Japanese-English subtitle corpus",
            "venue": "Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan. European Language",
            "year": 2018
        },
        {
            "authors": [
                "Joshua Robinson",
                "Christopher Michael Rytting",
                "David Wingate."
            ],
            "title": "Leveraging large language models for multiple choice question answering",
            "venue": "CoRR, abs/2210.12353.",
            "year": 2022
        },
        {
            "authors": [
                "Timo Schick",
                "Jane Dwivedi-Yu",
                "Roberto Dess\u00ec",
                "Roberta Raileanu",
                "Maria Lomeli",
                "Luke Zettlemoyer",
                "Nicola Cancedda",
                "Thomas Scialom."
            ],
            "title": "Toolformer: Language models can teach themselves to use tools",
            "venue": "CoRR, abs/2302.04761.",
            "year": 2023
        },
        {
            "authors": [
                "Connor Shorten",
                "Taghi M. Khoshgoftaar",
                "Borko Furht."
            ],
            "title": "Text data augmentation for deep learning",
            "venue": "J. Big Data, 8(1):101.",
            "year": 2021
        },
        {
            "authors": [
                "Ruixiang Tang",
                "Xiaotian Han",
                "Xiaoqian Jiang",
                "Xia Hu"
            ],
            "title": "Does synthetic data generation of llms help clinical text mining? CoRR, abs/2303.04360",
            "year": 2023
        },
        {
            "authors": [
                "driguez",
                "Robert Stojnic",
                "Sergey Edunov",
                "Thomas Scialom"
            ],
            "title": "2023b. Llama 2: Open foundation and fine-tuned chat models. CoRR, abs/2307.09288",
            "year": 2023
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141 ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc.",
            "year": 2017
        },
        {
            "authors": [
                "Yizhong Wang",
                "Yeganeh Kordi",
                "Swaroop Mishra",
                "Alisa Liu",
                "Noah A. Smith",
                "Daniel Khashabi",
                "Hannaneh Hajishirzi."
            ],
            "title": "Self-instruct: Aligning language model with self generated instructions",
            "venue": "CoRR, abs/2212.10560.",
            "year": 2022
        },
        {
            "authors": [
                "Jason Wei",
                "Xuezhi Wang",
                "Dale Schuurmans",
                "Maarten Bosma",
                "Ed H. Chi",
                "Quoc Le",
                "Denny Zhou."
            ],
            "title": "Chain of thought prompting elicits reasoning in large language models",
            "venue": "CoRR, abs/2201.11903.",
            "year": 2022
        },
        {
            "authors": [
                "Jason W. Wei",
                "Kai Zou."
            ],
            "title": "EDA: easy data augmentation techniques for boosting performance on text classification tasks",
            "venue": "CoRR, abs/1901.11196.",
            "year": 2019
        },
        {
            "authors": [
                "Peipei Xia",
                "Li Zhang",
                "Fanzhang Li."
            ],
            "title": "Learning similarity with cosine similarity ensemble",
            "venue": "Inf. Sci., 307:39\u201352.",
            "year": 2015
        },
        {
            "authors": [
                "Hainan Xu",
                "Philipp Koehn."
            ],
            "title": "Zipporah: a fast and scalable data cleaning system for noisy webcrawled parallel corpora",
            "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Den-",
            "year": 2017
        },
        {
            "authors": [
                "Kang Min Yoo",
                "Dongju Park",
                "Jaewook Kang",
                "SangWoo Lee",
                "Woo-Myoung Park."
            ],
            "title": "Gpt3mix: Leveraging large-scale language models for text augmentation",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event /",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Neural machine translation (NMT) has witnessed significant progress (Bapna et al., 2018; Hieber et al., 2020; Liao et al., 2021) in recent years, particularly with the introduction of Transformer (Vaswani et al., 2017). Despite their impressive performance on clean benchmarks (Barrault et al., 2019; Huang et al., 2020; Liao et al., 2020), these\n\u2217 Work done while doing this master thesis in Huawei. 1Up-to-date version at https://arxiv.org/abs/2310.13469.\nmodels exhibit a noticeable decline in translation quality when exposed to noisy input. This hampers their performance in real-world scenarios, where human users unintentionally introduce misspellings and grammatical errors during text input (Karpukhin et al., 2019). Therefore, evaluating the robustness of NMT models against noisy inputs becomes crucial before their deployment.\nDespite the importance of assessing the resilience of NMT models against noise, the available evaluation datasets remain limited. To the best of our knowledge, MTNT (Michel and Neubig, 2018) stands as one of the few well-established resources for evaluating NMT models\u2019 performance in the presence of noise. The noise distribution in MTNT closely resembles real-world use cases, but its applicability is constrained by the presence of noise in the target sentences. For instance, a FrenchEnglish pair may appear as: \u201cREEEEEEEEEEEE les normies sur mon eiffel y\u2019en a marre\u201d \u2194 \u201cREEEEEEE bored of the normies on my eiffel\u201d, which is not desirable. Our expectation is that an effective NMT model is capable of translating a noisy source sentence into a clean target sentence.\nIn order to enhance the applicability of MTNT for evaluating NMT models, we propose cleaning the target side of this dataset. In contrast to conventional cleaning approaches (Xu and Koehn, 2017; Khayrallah et al., 2018; Koehn et al., 2020) that typically involve filtering out undesirable sentences and retaining only high-quality ones, we aim to remove noise from sentences without reducing the overall sample number. Language-aware rulebased approaches, which rely on predefined rules to eliminate noise, have been widely employed as a common method for such cleaning (Miao et al., 2021; Mavrogiorgos et al., 2022). While these methods can effectively remove certain types of noise, it becomes impractical to define rules for every possible noise source. Moreover, some natural noise introduced by human input is not easily\nidentified by rule-based approaches alone. Another highly promising approach involves leveraging large language models (LLMs) (Touvron et al., 2023a; Chen et al., 2023). Previous works have already demonstrated the effectiveness of LLMs in various tasks, including Q&A(Robinson et al., 2022), text summarization (Pilault et al., 2020), and data generation (Meng et al., 2022; Chung et al., 2023; Tang et al., 2023). However, applying an LLM to clean the target sentences poses several challenges that need to be addressed diligently:\n\u2022 Comprehensive noise removal: LLMs should be capable of thoroughly cleaning the target sentence by eliminating all forms of noise, including removing semantically meaningless emojis, translating emojis with semantic content into words, correcting misspellings, etc.\n\u2022 Semantic preservation: A cleaned target sentence should retain similar semantic information as the original noisy target sentence.\n\u2022 Alignment with the source sentence: The cleaned target sentence should convey the same intended meaning as the noisy source sentence, ensuring accurate translation and faithful representation of the original content.\nIn this paper, we propose to apply GPT-3.5 (OpenAI, 2021) to clean the noisy target sentences in the MTNT dataset. Our approach addresses the challenges of noise removal, semantic preservation, and alignment with the source sentence. Inspired by the success of prompting methods (Brown et al., 2020; Wei et al., 2022; Schick et al., 2023), we design few-shot prompts to guide GPT-3.5 to clean the noisy target sentences in three ways: (1) Utilizing information from both the source and target side for cleaning, (2) Cleaning the target sentence independently, and (3) Generating a clean target sentence by translating the noisy source sentence. Through a comprehensive analysis, we demonstrate the effectiveness of our cleaning methods, particularly with methods (1) and (3). These methods successfully remove emojis, while considering their semantic meaning, and also rephrase slang, jargon, and profanities appropriately. The resulting datasets, named C-MTNT, exhibit significantly reduced levels of noise compared to the original sentences, while still preserving their semantic integrity.\nFurthermore, our research highlights another remarkable potential of LLMs in generating highquality parallel data with limited monolingual resources. This finding has significant implications for low-resource domains and languages, where acquiring parallel corpora is often challenging.\nAfter the cleaning, we conduct human and GPT4 (OpenAI, 2023) evaluations. Both evaluations draw the same conclusion that LLM has a great capability for such a cleaning task, especially with method (1).\nIn the end, we conduct comprehensive experiments to train NMT models on some noisy training datasets, and evaluate them on different evaluation sets, including clean benchmarks and the benchmark constructed with a rule-based noise removal method. C-MTNT consistently demonstrates better noise evaluation manner on the NMT models.\nTo the best of our knowledge, this is the first study to apply LLMs in the context of cleaning data, specifically addressing the challenges outlined above. Our findings highlight the potential of leveraging advanced language models for datacleaning tasks and emphasize C-MTNT as a valuable resource for evaluating the NMT model in real-world scenarios."
        },
        {
            "heading": "2 Data Generation and Cleaning",
            "text": "The primary objective of this study is to harness the capabilities of LLMs in effectively removing noise and generating parallel language datasets to evaluate the robustness of NMT models against noisy input. In this section, we will give an overview of our data source MTNT and delineate our approach to LLM interaction."
        },
        {
            "heading": "2.1 MTNT Dataset",
            "text": "MTNT (Michel and Neubig, 2018), which incorporates noisy comments gathered from Reddit alongside professionally sourced translations, has emerged as a benchmark for assessing the performance of NMT models when exposed to noisy\ninput. This dataset was developed in response to the scarcity of publicly available parallel corpora containing naturally occurring noise. It encompasses three distinct languages, namely English, French, and Japanese, and offers parallel data for two language pairs: English-French and EnglishJapanese. As shown in Table 1, we present a comprehensive analysis of noisy types within MTNT. Notably, these noise types manifest in both source and target sentences, which is not expected since we want to evaluate the ability of an NMT model to translate a noisy source sentence into a clean target sentence. Consequently, here we devised an approach aimed at cleaning the target sentences in MTNT to enhance its assessment capability."
        },
        {
            "heading": "2.2 Approach",
            "text": "Our approach to cleaning MTNT entails meticulous consideration of various available settings and resources. It includes the assessment of its effectiveness in scenarios where bilingual resources are accessible, as well as the investigation of its feasibility in cases where only source or target data is available. To explore the capabilities of LLM, we incorporate three methods specifically tailored to different data scenarios, accounting for the varying availability of language resources.\n\u2022 Bilingual cleaning: This approach involves providing both noisy source and target samples as input, with the focus on cleaning the target sample while preserving alignment with the source sample.\n\u2022 Monolingual cleaning: In this approach, a noisy target sample is given as input, and a clean target sample is generated as output. It demonstrates the ability of LLM to clean sentences without relying on the original source sample that may contain excessive noise.\n\u2022 Translation: This method generates new parallel data by taking a noisy source sample as input and producing a clean target sample as output. It showcases LLM\u2019s capability of noise ignorance.\nChain-of-thought prompting. Inspired by the recent achievements of prompting methods (Brown et al., 2020; Schick et al., 2023), we craft a set of few-shot examples that incorporate a coherent chain of thought (Wei et al., 2022). These examples serve to facilitate the model\u2019s comprehension\nof diverse inputs and their corresponding handling strategies. Based on the optimal performance of four-shot examples (Brown et al., 2020), we manually curate a collection of four-shot examples for each method. The full list of examples used in our approach can be found in Appendix A.\nPrompt design. As shown in Figure 1, each prompt consists of multiple components. The call follows a specific layout, starting with a brief description of the context, and providing essential information about the samples, domain, and language. This is followed by a concise formulation of the method: (1) Bilingual cleaning of target samples; (2) Monolingual cleaning of language samples; (3) Data generation through translation. Next,\nwe present a framework for the desired output, followed by the few-shot examples for each method, which include the input example, chain-of-thought reasoning for the output, and the example output itself. Finally, we insert the input sample(s) and request the desired output.\nLanguage model. The prompts are utilized to interact with OpenAI\u2019s GPT through API calls. Specifically, we use the original GPT-3.5 (textdavinci-003) variant (OpenAI, 2021). In this way, we want to show that some publicly released pretrained LLMs, like Llama 2 (Touvron et al., 2023b), might also have this ability.\nSemantic similarity. To ensure that the text generated by our approach maintains the original meaning without unintentional hallucinations (M\u00fcndler et al., 2023), we set a threshold based on LASER (Artetxe and Schwenk, 2019). LASER is language agnostic, allowing us to compare samples not only within the same language but also across different languages. We measure the cosine similarity between the representations of original and cleaned sentences, as shown in Equation 1. (For bilingual and monolingual cleaning, the original sentence is the noisy target sentence. For translation, the original sentence is the noisy source sentence.)\nsim(e1, e2) = e1 \u00b7 e2\n\u2225e1\u22252 \u2225e2\u22252 (1)\nwhere e1 and e2 are representations of original and newly generated sentences, respectively. Based on previous work on sentence embedding similarity (Okazaki and Tsujii, 2010; Xia et al., 2015), we set a threshold for the LASER score as 0.7. This threshold is selected to strike a balance between preserving the meaning of sentences and allowing sufficient variations. If sim(e1, e2) < 0.7, we repeat the API call but include a notice in the request: \u201cPlease ensure that your response accurately reflects the meaning of the original input sentence.\u201d, to ensure that the meaning of the new sentence aligns closely with the original one. This process continues until sim(e1, e2) \u2265 0.7 or reaching the maximum number of iterations of 10."
        },
        {
            "heading": "3 Analysis on C-MTNT",
            "text": "In this section, we analyze the generated data to evaluate its quality and suitability as a noise evaluation benchmark. We compare our method to a rule-based baseline and quantitatively assess the level of noise present in the target sentences. In\naddition, we also compare the new target samples from C-MTNT to the original ones by evaluating their semantic similarity."
        },
        {
            "heading": "3.1 Baseline",
            "text": "In addition to our LLM approach, we utilize the language_tool_python module2, which is an opensource grammar tool used for spelling, grammar, and overall language correction. With this rulebased baseline, we want to determine the performance gap between the rule-based method and our LLM-based approaches."
        },
        {
            "heading": "3.2 Quantitative Noise Measurement",
            "text": "We focus on several quantifiable noise types to measure the amount of noise in a set of samples and obtain an objective overview. These types are present in both the source and target sentences of MTNT, including spelling and grammatical errors, emojis, internet slang, and profanities.\nWe apply the language_tool_python toolkit2 to measure the misspellings and grammatical errors. To count the occurrences of emojis in the sentences, we use the emoji library3. For detecting profanities within the text, we employ better_profanity4 for English profanities, and profanity_check5 for French and Japanese profanities. As there are no available libraries for detecting internet slang, we compile lists of popular internet slang for each language from the past ten years.\nAs shown in Table 2, we contend that the LLM methods possess the capability to simulate natural language as it appears in clean benchmarks such as Newstest20146, TED (Pryzant et al., 2018), KFTT (Neubig, 2011), and JESC (Cettolo et al., 2012), thereby generating clean target sentences. While conventional language correction tools excel in rectifying spelling and grammatical errors, they are inadequate in effectively eliminating or paraphrasing slang, profanities, or emojis. Conversely, the LLM methods demonstrate proficiency in addressing such language phenomena, as also evidenced by some samples in Appendix D. As a result, the target sentences in C-MTNT exhibit significantly less noise compared to MTNT, leveling the cleanliness of the reference benchmarks.\n2https://github.com/jxmorris12/language_tool_python 3https://github.com/carpedm20/emoji 4https://github.com/snguyenthanh/better_profanity 5https://github.com/vzhou842/profanity-check 6http://www.statmt.org/wmt15/test.tgz\nLang. Eval. Set Spell./Gram. Emojis Slang Profanities\nNotable is the lower performance in the generated Japanese target sentences. We attribute this to two factors: insufficient capture of slang and profanities, and the known variations in performance of GPT-4 (OpenAI, 2023) across different languages (Koubaa, 2023). GPT-4 performs much worse on Japanese tasks compared to English tasks. A similar performance discrepancy is expected with GPT-3.5 (OpenAI, 2021)."
        },
        {
            "heading": "3.3 Meaning Preservation",
            "text": "Our second objective is to preserve the original meaning during cleaning. We apply multiple metrics to measure the sentence similarity, including LASER (Artetxe and Schwenk, 2019), BLEU score (Papineni et al., 2002), Rouge-1 score (Lin, 2004), Jaro Winkler distance (Jaro, 1989), and Jaccard score (Hamers et al., 1989).\nFigure 2 illustrates similarity scores across dif-\nferent language pairs, revealing distinct deviations among different methods. These deviations stem from different input data: bilingual, monolingual target, and monolingual source. The translation method exhibits the lowest similarity score between original and clean sentences. In contrast, the monolingual method shows the minimal deviation between original and clean sentences, while the bilingual method falls in between. We argue that the larger deviation from the bilingual and translation is mainly from rephrasing and word reordering (see Appendix D for detailed samples). Despite these variations, all methods retain a substantial portion of the original semantic structure.\nNotably, similarity scores from the correction tool are the highest for all metrics among all methods, since this rule-based method can only clean or remove noise but lacks the ability to rephrase challenging noise types like slang, emojis, and profanities (see Table 2 for its results on slang, profanities, and emojis). Most cleaned sentences stay very similar to the original noisy ones. Complemented by the findings in Section 3.2, our cleaning methods show their impressive ability in reducing noise while preserving semantic similarity."
        },
        {
            "heading": "3.4 Human and GPT-4 Evaluations",
            "text": "Apart from evaluating C-MTNT by measuring its noise amount and its semantic preservation, here we conduct human and GPT-4 (OpenAI, 2023) evaluations.\nDue to the limited research budget, we only conducted the human evaluation with the help of the first four authors of this paper on some sampled sentences instead of all sentences. 100 sentences from C-MTNT Fr\u2192En are sampled to generate three files. These three files are about binary comparisons of bilingual vs. monolingual, bilingual vs. translation, and monolingual vs. translation. The order of sentences, including their indexes\nand which cleaning method comes first, is randomly shuffled. There is no chance for the annotator to guess which sentence corresponds to which method, and which file corresponds to the comparison between which two methods. Notably, we prefer binary comparison to ranking over three methods, since it\u2019s easier for human annotators. In addition, the cleaned sentences from the correction tool are excluded, since they are too easy to be beaten. Four annotators are asked to give their preferences for each comparison, based on our three criteria of comprehensive noise removal, semantic preservation, and alignment with the source sentence. If both sentences show a similar level of noise, they are asked to give a \u201cTie\u201d.\nWe also prompt GPT-4 (See Appendix G for the prompt) on the same sampled sentences to check whether GPT-4 draws a similar conclusion. As shown in Figure 3a, human and GPT-4 evaluations share a similar preference: bilingual > translation > monolingual. Compared to GPT-4, human annotators prefer to vote for \"Tie\". We argue the main reason is that most cleaned sentences are very similar with a low level of noise, which further justifies the effectiveness of our proposed methods. Since human annotators and GPT-4 share a similar preference, we further evaluate all C-MTNT sentences with GPT-4 in Figure 3b. The conclusion is similar to the above discussion, i.e. bilingual > translation > monolingual."
        },
        {
            "heading": "4 Machine Translation Experiments",
            "text": "In this section, we further investigate the suitability of C-MTNT as a benchmark to evaluate NMT\nmodel\u2019s robustness against noisy input. Let\u2019s reemphasize our expected NMT model: Irrespective of whether the source sentence is clean or noisy, the model has the ability to generate a coherent target sentence that is free of errors or distortions.\nWe first mimic the real-world scenario to train a set of NMT models on datasets that contain both noisy and clean source sentences but with only clean target sentences, then evaluate these models on C-MTNT and other benchmarks."
        },
        {
            "heading": "4.1 Model and Training Details",
            "text": "All models are trained with the fairseq toolkit (Ott et al., 2019). The architecture is based on the vanilla transformer, with 6 encoder and 6 decoder layers. The hidden dimension is set to 512, with 1024 for the feed-froward intermediate output. We use Adam optimizer (Kingma and Ba, 2015) with its default hyperparameters. Dropout with a probability of 0.3 and a label smoothing factor of 0.1 (Gao et al., 2020) is applied. We train all models for 20 epochs with a learning rate of 5e\u2212 4 that is scheduled by inverse square root with 4K warmup steps, and set a batch size as 128. Subword tokenization is performed using SentencePiece (Kudo and Richardson, 2018) with BPE subwords. For all languages, we use a vocabulary size of 16K without sharing embeddings."
        },
        {
            "heading": "4.2 Training Data",
            "text": "For the English \u2194 French translation directions, we utilize the same training data as Michel and Neubig (2018), which comprises the europarl-v77\n7http://www.statmt.org/europarl/\nand news-commentaryv108 corpora. The training set consisted of 2.2M samples, with 55M French tokens and 52M English tokens (non-tokenized). The WMT15 newsdiscussdev20159 serves as the validation set, used to select the best checkpoint. The trained models are evaluated on the C-MTNT, MTNT, and newstest20146 test (eval.) sets.\nRegarding the English-to-Japanese translation direction, we follow the data construction approach of Michel and Neubig (2018), combining the training and validation data from the KFTT (Neubig, 2011), JESC (Pryzant et al., 2018), and TED talks (Cettolo et al., 2012) corpora. The Japanese segments in each dataset are tokenized using the MeCab library (Kudo, 2005). This results in a training set of 3.9M samples, consisting of 35M English tokens without tokenization. We use the training and dev sets associated with each corpus as the training and validation sets, respectively, and evaluate the models on MTNT, C-MTNT, and the respective test set from each corpus."
        },
        {
            "heading": "4.3 Data Augmentation",
            "text": "The above-mentioned training data are clean, contain negligible noise, and can\u2019t resemble the realworld use case. Therefore, we introduce noise with different augmentation methods to the source sentences, including character augmentation (spelling/typographical errors, capitalization), contextual word embedding augmentation (word omission/insertion/repetition), MTNT-based error replacement (spoken language, jargon, internet slang, grammati-\n8http://www.statmt.org/wmt15/training-parallel-ncv10.tgz\n9http://www.statmt.org/wmt15/dev-v2.tgz\ncal errors), and synonym substitution (grammatical errors).\nCharacter augmentation (Char.) involves character-level augmentation methods, including random or controlled techniques with a probability of 0.5 for each choice (Karpukhin et al., 2019).\nContextual word embedding augmentation (Con.) utilizes language models, specifically BERT (bert-base-uncased) (Devlin et al., 2019), to substitute some word embeddings with their contextual word embeddings (Kobayashi, 2018). We employ the French BERT 10 for French source sentences.\nMTNT-based error replacement (Err.) is inspired by the symbolic strategies (Shorten et al., 2021). Errors are identified with language_tool_python, and only the most valuable ones occurring more than once are retained in a dictionary for augmentation. By replacing the correct forms with the mapped common errors, we intentionally introduce these errors into the sentence.\nFor synonym substitution (Syn.), we employ WordNet (Miller, 1995) and NLTK (Bird et al., 2009), to randomly select and replace words with their synonyms.\nThese techniques are only tailored for English and French, which is also the main reason for our exclusion of Japanese-to-English direction. The source sentences x are augmented with a probability of \u03b1 = 0.1, augmenting approximately 10% of the tokens in each sample. This process generates four augmented versions: zch, zc, ze, and zs, representing sentence augmentation with character, contextual word embedding, error, and synonym augmentation, respectively. The selection of \u03b1 = 0.1 is based on previous works (Karpukhin et al., 2019; Wei and Zou, 2019) and our similar finding (see Figure 4). These augmented sentences are combined with the original clean sentences, resulting in four new training sets, {x, zch}, {x, zc}, {x, ze}, and {x, zs}. Each is used to train a model, capable of handling some specific types of noise.\nNotably, the distribution of introduced noise is not possible to totally resemble the noise distribution in the MTNT (or C-MTNT) source sentences, since we only introduce some types of noise to each new set with a pre-defined rule, i.e. the augmentation method. This setting is desired and makes the evaluation more general and practical.\n10https://github.com/stefan-it/europeana-bert"
        },
        {
            "heading": "4.4 Contrastive Learning",
            "text": "In addition to the straightforward training on newly constructed sets, we also train models with contrastive learning, which is inspired by previous works (Chen et al., 2020; Hwang et al., 2021; Hu and Li, 2022) that recognize the effectiveness of contrastive learning in improving the robustness of NLP and NMT models. By employing this method, we can analyze the performance of C-MTNT on a wider range of models trained with different approaches and settings.\nFor contrastive learning, the Transformer encoder takes both original x and augmented z source sentences as inputs and calculates the contrastive loss based on their output representations. Similar to straightforward training, we train a separate model on each set with contrastive learning. More details and experiments on contrastive training are in Appendix F."
        },
        {
            "heading": "4.5 Results and Analysis",
            "text": "Before introducing our results in Table 3 for clean benchmarks, MTNT and C-MTNT, we first want to emphasize that the BLEU scores across different benchmarks are incomparable because these benchmarks contain different evaluation sentences. Though MTNT and C-MTNT contain the same source sentences, their target sentences are different since we apply LLM to clean the target side of\nMTNT. Therefore, we focus on the relative performance gain:\nG = (sr \u2212 sb)/sb (2)\nwhere sb is the BLEU score from the model trained only on the data without any augmentation, i.e. the training dataset in Section 4.2, and sr is the BLEU score from the model trained on the augmented dataset. If a model trained with the augmented dataset obtains higher G on an evaluation set, we can say the evaluation set is an ideal noise evaluation set. The reason is: The augmented dataset mimics our expected data distribution. I.e. noise only exists in the source side. A model trained on this dataset is supposed to have the ability to translate noisy source sentences into clean target sentences. If this model obtains a high G on an evaluation set, it shows that this evaluation set also fulfills the expected data distribution.\nAs shown in Table 3, all trained models tend to have significantly higher G for bilingual and translation C-MTNT. We also show the average G over four models trained with different augmented datasets in Figure 5. It is even more evident that bilingual and translation C-MTNT offers higher G across all cleaning methods.\nSome may argue that C-MTNT achieves a higher G score because the augmented training dataset has a similar distribution to C-MTNT, making it\neasier to evaluate the trained models on C-MTNT. However, this argument is not valid for two reasons: (1) Bilingual and translation C-MTNT consistently offer higher G across all models trained with different augmented datasets (see Table 3). It\u2019s almost impossible to intentionally make every augmented dataset has a similar distribution as CMTNT where the source sentence contains natural noise; (2) Monolingual C-MTNT offers lower G, sometimes even lower than MTNT and the benchmark constructed from the correction tool. This shows that cleaning with a LLM doesn\u2019t always work. It\u2019s better to have guidance, like guidance from a source sentence for the bilingual and translation methods. According to our observation, if we clean the noisy target sentence in a monolingual way without any guidance, LLM tends to introduce extra information or delete important information, which hurts translation because the cleaned target sentence doesn\u2019t align well with the source sentence. In sum, C-MTNT generated by bilingual and translation methods shows its superiority as a noise evaluation benchmark, encouraging a NMT model to translate a noisy source sentence to a clean target sentence."
        },
        {
            "heading": "5 Related Work",
            "text": "The application of LLMs, such as GPT-3.5 (textdavinci-003) (OpenAI, 2021), in downstream tasks has garnered significant attention and led to extensive research in this field (Wang et al., 2022; Schick et al., 2023). Researchers have conducted comprehensive investigations to explore the capabilities of LLMs, and built upon their various applications (Coyne and Sakaguchi, 2023; M\u00fcndler et al., 2023; Jiao et al., 2023).\nResearchers have also observed the potential of LLMs to generate high-quality data, leading to a focus on expanding existing datasets, augmenting data, or generating entirely new data (Meng\net al., 2022; Yoo et al., 2021; Chung et al., 2023). These efforts have helped address the issue of data scarcity in various domains.\nHowever, it is crucial to note that the aforementioned research works lack at least one of the two novel aspects addressed in this paper. Firstly, our research focuses on evaluating the robustness of NMT models to real-world noise introduced by human users. Secondly, we explore the generation or cleaning of parallel data specifically for NMT purposes. These unique aspects of robustness evaluation and parallel data generation/cleaning contribute to the existing literature in a novel way."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this work, we propose three methods to apply LLM to clean a noisy MT benchmark, MTNT, where natural noise exists in both source and target sentences. We aim to clean the target side of MTNT to make it more suitable as a benchmark in evaluating NMT models\u2019 robustness against noisy input. With a meticulous design of some few-shot prompts, we guide GPT to clean the noisy target sentence with only the noisy source sentence, only the noisy target sentence, or both noisy source and target sentences. By measuring the noise frequency in the cleaned target sentences, measuring the semantic similarity between noisy and cleaned target sentences, and evaluating with human annotators and GPT-4, we show that our proposed methods can effectively remove natural noise with LLM, while preserving the semantic structure. Our further investigation of the newly created benchmark, C-MTNT, on some trained models also shows its effectiveness as a noise evaluation benchmark for NMT models."
        },
        {
            "heading": "7 Limitations",
            "text": "Despite the contributions and potential benefits of our research, there are several limitations that\nshould be acknowledged. Firstly, our approach relies on the use of pre-trained LLMs for data cleaning and generation. While LLMs have shown promising capabilities, they are not immune to biases and limitations present in the training data. As a result, our proposed dataset may still contain biases similar to those found in the original MTNT dataset, even after our efforts to mitigate them.\nFurthermore, our assessment of the robustness of NMT models against noisy input relies on the utilization of C-MTNT, which is created using our proposed methodology, and MTNT. While C-MTNT offers valuable insights into the performance of NMT models, it is crucial to acknowledge that it may not comprehensively represent all potential sources of noise encountered in real-world settings. Human-generated noise exhibits variability and contextual dependencies, and our dataset may not encompass the entire spectrum of noise that NMT models may face during actual deployment. The same can be said for MTNT.\nAdditionally, our research focuses on evaluating the robustness of NMT models in specific language directions, namely English \u2194 French and English \u2192 Japanese. While these directions provide valuable insights, generalizing the findings to other language pairs should be done with caution. Different languages may exhibit unique linguistic characteristics, which can influence the performance and robustness of NMT models. Therefore, further research is needed to investigate the generalizability of our findings across a broader range of languages and translation directions.\nIn summary, while our research contributes to the assessment of NMT model robustness and the generation of high-quality evaluation datasets, it is important to recognize the limitations associated with biases in LLMs, the potential incompleteness of our dataset, and the need for further investigation into different language pairs."
        },
        {
            "heading": "8 Ethical Considerations",
            "text": "The utilization of pre-trained LLMs in natural language processing tasks, including data generation and machine translation, presents several ethical considerations that must be carefully examined. In this section, we discuss the ethical implications associated with the use of LLMs and highlight the potential biases that may arise in C-MTNT."
        },
        {
            "heading": "8.1 Biases in Pre-trained Large Language Models",
            "text": "Pre-trained LLMs, such as GPT-3.5, are trained on vast amounts of internet text, which inevitably introduces biases present in the training data. These biases can manifest in different forms, including but not limited to cultural, gender, racial, and political biases. The models can inadvertently reproduce and amplify these biases when generating new content or translating text.\nIt is crucial to acknowledge that biases present in LLMs can influence the quality and fairness of the generated data, potentially perpetuating societal inequalities and reinforcing existing stereotypes. The responsible use of LLMs requires diligent examination and mitigation of these biases to ensure equitable outcomes and avoid further marginalization or harm to underrepresented groups."
        },
        {
            "heading": "8.2 Mitigating Biases in Data Generation",
            "text": "While we employ LLMs for data cleaning and generation in our proposed dataset, it is essential to note that biases similar to those in MTNT may be present in the generated data. Despite efforts to mitigate biases, the LLMs may not fully capture the complexities and nuances of language, leading to potential biases in the generated sentences.\nWe carefully evaluated the generated data for any biased content and took steps to minimize biased outputs. Additionally, we encourage the involvement of diverse annotators and domain experts during the evaluation and curation of the dataset to ensure a broader perspective and mitigate the influence of individual biases. We also encourage translators and reviewers who are well-versed in the target languages and cultural nuances to ensure the translations accurately reflect the intended meaning while avoiding biased or offensive content. Moreover, we actively seek feedback from the affected communities and stakeholders to address any concerns and rectify biases that might arise."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank all EMNLP reviewers for their great feedback. The first author, Quinten Bolding, finished this work while doing his thesis at Huwai Amsterdam Research Center. This work was supported by Huawei\u2019s infrastructure. The thesis supervisor, Baohao Liao, is funded in part by the Netherlands Organization for Scientific Research (NWO) under project number VI.C.192.080."
        },
        {
            "heading": "A Few-Shot Examples",
            "text": "Bilingual cleaning for FR-EN. For the bilingual cleaning in the French-to-English translation direction, we use the following examples: Input: \"Jss tro contenteee!\", \"Im soooo happyyyy! \" Desired output: \"I\u2019m so happy!\n\" Reasoning: The noisy French sentence uses abbreviations (\"Jss\" for \"Je suis\") and excessive letters in the word \"contenteee.\" The clean English sentence replaces the abbreviations and removes the extra letters to convey the same meaning clearly.\nInput: \"Tkt, c trooo bi1! \", \"Don\u2019t worry, it\u2019s awesooome!\n\" Desired output: \"Don\u2019t worry, it\u2019s great!\" Reasoning: The noisy French sentence uses internet slang (\"Tkt\" for \"T\u2019inqui\u00e8te\") and excessive letters in the word \"trooo.\" The clean English sentence replaces the slang with a more standard expression and removes the extra letters for better comprehension.\nInput: \"Jvoudr\u00e9 vnir avc vs! \", \"I wud luv 2 cum wth u guys! \" Desired output: \"I would\nlove to come with you!\" Reasoning: The noisy French sentence uses abbreviations (\"Jvoudr\u00e9\" for \"Je voudrais\") and non-standard spelling (\"vnir\" for \"venir\"). The clean English sentence replaces the abbreviations and corrects the spelling for clearer communication.\nInput: \"Ct troo bi1, jkiff trp! \", \"It\u2019s sooo gre8, I luv it! \" Desired output: \"It\u2019s amazing, I\nlove it!\" Reasoning: The noisy French sentence uses non-standard spelling (\"troo\" for \"tr\u00e8s\") and excessive letters in the words \"bi1\" and \"jkiff.\" The clean English sentence corrects the spelling and removes the extra letters for a more natural and concise expression.\nBilingual cleaning for EN-FR. For the bilingual cleaning in the English-to-French translation direction, we use the following examples: Input: \"I\u2019m sooooo happyyyy! \", \"Je suis tellement heureuxxxx ! \" Desired output: \"Je suis tellement heureux!\" Reasoning: The noisy French sentence contains excessive letters in the word \"heureux\" and an unnecessary exclamation mark. The clean French sentence removes the extra letters and the exclamation mark to convey the same message accurately.\nInput: \"Can\u2019t wait to see youuuu! \", \"J\u2019ai trooooop h\u00e2te de te voiiiiir ! \" Desired output: \"J\u2019ai tellement h\u00e2te de te voir!\" Reasoning: The noisy French sentence includes excessive letters in the words \"trooop\" and \"voiiiiir.\" The clean French sentence removes the extra letters to maintain the same meaning more concisely.\nInput: \"Let\u2019s grab a bite laterrrr! \", \"Allons manger un morceau plu tarrrrd!\n\" Desired output: \"Allons manger un morceau plus tard!\" Reasoning: The noisy French sentence has excessive letters in the words \"plu\" and \"tarrrrd\" and unnecessary fast food emojis.\nThe clean French sentence removes the extra letters and the emojis while maintaining the same meaning.\nInput: \"This movie is amaziiing! \", \"Ce film est troooop\ng\u00e9niaaaaal! \" Desired output: \"Ce film est tellement g\u00e9nial!\" Reasoning: The noisy French sentence contains excessive letters in the words \"troooop\" and \"g\u00e9niaaaaal\" and unnecessary fire and heart emojis. The clean French sentence removes the extra letters and the emojis to convey the same message accurately.\nBilingual cleaning for EN-JA. For the bilingual cleaning in the English-to-Japanese translation direction, we use the following examples: Input: \"I\u2019m soooo happyyyy! \", \"\u3059\u3063\u3054\u30fc\u304f\u5b09\u3057\u3044\uff01 \" Desired output: \"\u3059 \u3054 \u304f \u5b09 \u3057 \u3044 \u3067 \u3059\uff01\" Reasoning: The noisy Japanese sentence uses excessive elongation in the word \"\u3059 \u3063 \u3054 \u30fc \u304f\" and includes an unnecessary exclamation mark. The clean Japanese sentence removes the excessive elongation and uses a more polite form to convey the same meaning accurately.\nInput: \"Can\u2019t wait to see youuuu! \" Desired output: \"\u4f1a \u3048\u308b\u306e\u304c\u697d\u3057\u307f\u3067\u3059\uff01 \" Reasoning: The noisy Japanese sentence includes excessive elongation in the word \"\u3088 \u3049 \u3049 \u3049\" and an unnecessary exclamation mark. The clean Japanese sentence removes the excessive elongation and uses a more polite form for a clearer and more appropriate expression.\nInput: \"Let\u2019s grab a bite laterrrr! \", \"\u5f8c \u3067 \u8efd \u304f \u98df \u3079\u3088\u3063\u304b\u3041\u3041\u3041! \" Desired output: \"\u5f8c\u3067\u3061\u3087\u3063\u3068\u98df\u3079\u307e \u3057\u3087\u3046\uff01\" Reasoning: The noisy Japanese sentence includes excessive elongation in the word \"\u3088 \u3063 \u304b \u3041 \u3041 \u3041\" and unnecessary fast food emojis. The clean Japanese sentence removes the excessive elongation and provides a more polite and appropriate phrase to convey the same meaning.\nInput: \"This movie is amaziiing! \", \"\u3053\u306e\u6620\u753b\u306f\u3059\u3063\u3054\u3044\u3043\u3043\u3043\n\" Desired output: \"\u3053\u306e\u6620\u753b\u306f\u7d20\u6674\u3089\u3057 \u3044\u3067\u3059\uff01\" Reasoning: The noisy Japanese sentence uses excessive elongation in the word \"\u3059 \u3063 \u3054 \u3044\u3043\u3043\u3043\" and includes unnecessary fire and heart emojis. The clean Japanese sentence removes the excessive elongation and provides a more appropriate and accurate expression for the same meaning.\nTranslation for FR-EN. For the generative translation method in the French-to-English translation direction, we use the following examples: Input: \"Heyyy, \u00e7a va trop biennn! Jsuis trop hype\u00e9\u00e9\u00e9 pour ce soir! \" Desired output: \"Hey, I\u2019m doing great! I\u2019m so excited for tonight!\" Reasoning: The noisy sentence contains excessive letters in words and emojis. The clean sentence removes the extra letters and emojis to convey the same message more clearly.\nInput: \"OMG jpeux pas croire, c\u2019est trooop ouf! \" Desired output: \"Oh my God, I can\u2019t believe it, it\u2019s so amazing!\"\nReasoning: The noisy sentence uses internet slang (\"OMG,\" \"trooop,\" \"ouf\") and excessive punctuation (\"!!\"). The clean sentence replaces the slang with more standard expressions and removes the excessive punctuation for better comprehension.\nInput: \"Mdr t\u2019es trop marrant, tu me fais tp rire \" Desired output: \"Haha, you\u2019re so funny, you make me laugh a lot.\" Reasoning: The noisy sentence contains internet slang (\"Mdr,\" \"trop,\" \"tp\") and a laughing emoji. The clean sentence replaces the slang with more common expressions and removes the emoji for a more formal and clear communication.\nInput: \"H\u00e9\u00e9, on se voit au restau tout de suite?\" Desired output: \"Hey, can we meet at the restaurant right away? \" Reasoning: The noisy sentence has intentional misspellings (\"H\u00e9\u00e9,\" \"restau\") and fast food emojis. The clean sentence corrects the spellings and removes the emojis to convey the same message accurately.\nTranslation for EN-FR. For the generative translation method in the English-to-French translation direction, we use the following examples: Input: \"Heyy, what\u2019s up? I\u2019m sooo exicteddd to go out tonight!\n\" Desired output: \"Salut, quoi de neuf ? Je suis tellement excit\u00e9(e) de sortir ce soir !\" Reasoning: The noisy sentence contains excessive letters in words and emojis. The clean sentence removes the extra letters and emojis to convey the same message more clearly in French.\nInput: \"OMG I can\u2019t even rn, this party is gonna be LIT AF!\n\" Desired output: \"Mon Dieu, je ne peux pas le croire, cette f\u00eate va \u00eatre incroyable !\" Reasoning: The noisy sentence uses internet slang (\"OMG,\" \"rn,\" \"LIT AF\") and abbreviations. The clean sentence replaces the slang with more standard expressions and removes the abbreviations for better comprehension in French.\nInput: \"lol ur so funny, u always make me laugh \" Desired output: \"lol tu es tellement dr\u00f4le, tu me fais toujours rire.\" Reasoning: The noisy sentence contains internet slang (\"lol,\" \"ur\") and a laughing emoji. The clean sentence replaces the slang with more common expressions and removes the emoji for a more formal and clear communication in French.\nInput: \"Heyy, wanna grab some fud later? \" Desired output: \"Hey, tu veux qu\u2019on aille manger plus tard ?\" Reasoning: The noisy sentence has intentional misspellings (\"Heyy,\" \"fud\") and fast food emojis. The clean sentence corrects the spellings and removes the emojis to convey the same message accurately in French.\nTranslation for EN-JA. For the generative translation method in the English-to-Japanese translation direction, we use the following examples: Input: \"Heyyy, what\u2019s up? I\u2019m sooo excited to go out tonight!\n\" Desired output: \"\u3084\u3041\u3084\u3041\u3001\u5143\u6c17\uff1f\u4eca \u591c\u51fa\u304b\u3051\u308b\u306e\u304c\u3059\u3063\u3054\u304f\u697d\u3057\u307f\uff01\" Reasoning: The noisy sentence\ncontains excessive letters in words and emojis. The clean sentence removes the extra letters and emojis to convey the same message more clearly in Japanese.\nInput: \"OMG I can\u2019t even rn, this party is gonna be LIT AF!\n\" Desired output: \"\u3048\u3048\u3063\u3001\u30de\u30b8 \u3067\uff1f\uff01\u3053\u306e\u30d1\u30fc\u30c6\u30a3\u306f\u6700\u9ad8\u306b\u76db\u308a\u4e0a\u304c\u308b\u305e\" Reasoning: The noisy sentence uses internet slang (\"OMG,\" \"rn,\" \"LIT AF\") and abbreviations. The clean sentence replaces the slang with more standard expressions and removes the abbreviations and emojis for better comprehension in Japanese.\nInput: \"lol you\u2019re so funny, you always make me laugh \" Desired output: \"\u7b11 \u304a\u524d\u3001\u30db\u30f3\u30c8\u9762 \u767d\u3044\u306a\u3002\u3044\u3064\u3082\u7b11\u308f\u305b\u3066\u304f\u308c\u308b\u3093\u3060\u3088\" Reasoning: The noisy sentence contains internet slang (\"lol\") and a laughing emoji. The clean sentence replaces the slang with more common expressions and removes the emoji for a more natural and clear communication in Japanese.\nInput: \"Heyyy, wanna grab some food later? \" Desired output: \"\u3084\u3041\u3084\u3041\u3001\u5f8c\u3067\u98df\u3079 \u7269\u3067\u3082\u8cb7\u3063\u3066\u3044\u304b\u306a\u3044\uff1f\" Reasoning: The noisy sentence has intentional misspellings (\"Heyyy\") and fast food emojis. The clean sentence corrects the spellings and removes the emojis for a more natural and clear communication in Japanese.\nMonolingual cleaning for FR-EN. For the monolingual cleaning in the French-to-English translation direction, we use the following examples: Input: \"Heyy, what\u2019s up? I\u2019m sooo exicteddd to go out tonight!\n\" Desired output: \"Hey, what\u2019s up? I\u2019m so excited to go out tonight!\" Reasoning: \"The noisy sentence contains excessive letters in words and emojis. The clean sentence removes the extra letters and emojis to convey the same message more clearly.\"\nInput: \"OMG I can\u2019t even rn, this party is gonna be LIT AF!\n\" Desired output: \"Oh my God, I can\u2019t even right now, this party is going to be awesome!\" Reasoning: \"The noisy sentence uses internet slang (\u2019OMG\u2019, \u2019rn\u2019, \u2019LIT AF\u2019) and abbreviations. The clean sentence expands the slang and abbreviations for better comprehension.\"\nInput: \"lol ur so funny, u always make me laugh \" Desired output: \"Laugh out loud, you\u2019re so funny. You always make me laugh.\" Reasoning \"The noisy sentence contains internet slang (\u2019lol\u2019, \u2019ur\u2019) and a laughing emoji. The clean sentence replaces the slang with its full form and removes the emoji for a more formal expression.\"\nInput: \"Heyy, wanna grab some fud later? \" Desired Output \"Hey, do you want to grab some food later?\" Reasoning: \"The noisy sentence has intentional misspellings (\u2019Heyy\u2019, \u2019fud\u2019) and food emojis. The clean sentence corrects the spellings and removes the emojis to convey the same message accurately.\"\nMonolingual cleaning for EN-FR. For the monolingual cleaning in the English-to-French\ntranslation direction, we use the following examples: Input: \"Saluttt, \u00e7a va? Je suiis trp excit\u00e9\u00e9\u00e9\u00e9 pr sortir ce soiiiir! \" Desired output: \"Salut, \u00e7a va? Je suis trop excit\u00e9 pour sortir ce soir!\" Reasoning: The noisy sentence contains excessive letters in words and emojis. The clean sentence removes the extra letters and emojis to convey the same message more clearly.\nInput: \"Tkt, j\u2019te dm dans 2min, ok? \" Desired output: \"T\u2019inqui\u00e8te, je te donne des nouvelles dans 2 minutes, d\u2019accord?\" Reasoning: The noisy sentence uses internet slang (\u2019Tkt\u2019, \u2019j\u2019te\u2019, \u2019dm\u2019) and abbreviations. The clean sentence expands the slang and abbreviations for better comprehension.\nInput: \"Mdrr t\u2019es tro drol, tu m\u2019fais tp rire \" Desired output: \"Mort de rire, tu es vraiment dr\u00f4le, tu me fais trop rire.\" Reasoning: The noisy sentence contains internet slang (\u2019Mdrr\u2019, \u2019tro\u2019, \u2019tp\u2019) and a laughing emoji. The clean sentence replaces the slang with its full form and removes the emoji for a more formal expression.\nInput: \"H\u00e9\u00e9, on se retrouve au mcdo plutar? \" Desired output: \"H\u00e9, est-ce qu\u2019on peut se retrouver au McDonald\u2019s plus tard?\" Reasoning: The noisy sentence has intentional misspellings (\u2019H\u00e9\u00e9\u2019, \u2019plutar\u2019) and fast food emojis. The clean sentence corrects the spellings and removes the emojis to convey the\nsame message accurately.\nMonolingual cleaning for EN-JA. For the monolingual cleaning in the English-to-Japanese translation direction, we use the following examples: Input: \"\u5143\u6c17\u3063\u3059\u304b\uff1f \u3081\u3063 \u3061\u3083\u697d\u3057\u307f\u3060\u305c\u301c \" Desired output: \"\u5143\u6c17\u3067\u3059\u304b\uff1f\u3068\u3063\u3066 \u3082\u697d\u3057\u307f\u3067\u3059\u306d\uff01\" Reasoning: The noisy sentence contains informal language (\"\u3063 \u3059 \u304b\" instead of \"\u3067 \u3059 \u304b\") and excessive use of \" \" at the end. The clean sentence removes the informal elements and expresses the same meaning more formally.\nInput: \"\u3081\u3063\u3061\u3083\u304a\u3044\u3057\u30fc\u3044\uff01LOL \" Desired output: \"\u3068\u3063\u3066\u3082\u304a\u3044\u3057\u3044\uff01 \u7b11\" Reasoning: The noisy sentence includes the use of \"\u3081 \u3063 \u3061 \u3083\" (a casual intensifier) and the English acronym \"LOL.\" The clean sentence removes the casual intensifier and replaces \"LOL\" with the Japanese equivalent \"\u7b11\" (meaning \"laugh\").\nInput: \"\u30a2\u30cf\u30cf\u3001\u8d85\u304a\u3082\u308d\u3044\uff01 \" Desired output: \"\u7b11 \u3001 \u3068 \u3066 \u3082 \u9762 \u767d \u3044\uff01\" Reasoning: The noisy sentence uses \"\u30a2 \u30cf \u30cf\" (a casual laughter expression) and an emoji. The clean sentence replaces \"\u30a2 \u30cf \u30cf\" with the more standard \"\u7b11\" and removes the emoji.\nInput: \"\u3088\u3063\u3057\u3083\u3001\u5f85\u3061\u5408\u308f\u305b\u307e\u3064 \u304b\uff1f \" Desired output: \"\u3088\u3057\u3001\u5f85\u3061\u5408\u308f\u305b\u3057 \u307e\u3057\u3087\u3046\u304b\uff1f\" Reasoning: The noisy sentence contains a misspelling (\"\u307e \u3064 \u304b\" instead of \"\u307e \u3057 \u3087 \u3046 \u304b\") and fast food emojis. The clean sentence corrects the spelling and removes the emojis while maintaining the same meaning."
        },
        {
            "heading": "B Task Descriptions",
            "text": "The task description for the bilingual cleaning method is as follows: Your task is to clean the given {tgt} sentence. You will receive two sentences as input: the {src} sentence containing noise, and the translated tgt version of that sentence, also containing noise. Your task is to clean only the {tgt} sentence and return it as output. The task description for the generative translation method is as follows: Your task is to translate the given noisy {src} sentence to the correct {tgt} version, thereby removing all noise. You will only return the clean {tgt} sentence as output. The task description for the monolingual cleaning method is as follows: Your task is to clean the {tgt} sentence that you will receive as input: You will then return the clean version of the {tgt} sentence as output. For each task {src} refers to the source language (English or French) and {tgt} refers to the target language (English, French, or Japanese)."
        },
        {
            "heading": "C Requests",
            "text": "This section shows the requests we used in the prompts. The request for the monolingual cleaning method and generative translation methods are the same and are as follows: This is the input {input_sent}, . Please return the desired output in the correct format. The only difference is that the {input_sent} refers to the target sentence in the case of the monolingual cleaning method, whereas the {input_sent} refers to the source sentence for the generative translation method. The request for the bilingual cleaning task is different because of the multiple inputs. The request for this method is as follows: These are the inputs {src_sent}, {tgt_sent}. Please return the desired output in the correct format."
        },
        {
            "heading": "D Samples",
            "text": "In Table 4, we show several samples from MTNT, and show how each distinct method tends to clean these samples in different ways. In some samples abbreviations are corrected, in others emojis are removed and some are changed based on language or word choice."
        },
        {
            "heading": "E Detailed Similarity Scores",
            "text": "For the convenience of the latter works that plan to use our method as a baseline, we list the detailed similarity scores from Figure 2 in Table 5, 6 and 7."
        },
        {
            "heading": "F Contrastive Learning",
            "text": "F.1 Training Loss\nThe contrastive loss (Chen et al., 2020) is computed based on two source sentences: the original source sentences x and the augmented source sentences z.\nLctr = \u2212 N\u2211 i log exp(sim(exi , ezi)/\u03c4)\u2211N j exp(sim(exi , ezj )/\u03c4)\nwhere xi is the original sentence, zi is the augmented version of xi, and \u03c4 is the temperature factor. Therefore, the positive sample is the corresponding augmented sentence, while the negative samples are the augmented versions of other original source sentences from the same mini-batch.\nexi and ezi are the average representations along the sequence dimension from the encoder outputs.\nApart from the contrastive loss, the standard cross-entropy loss is calculated as:\nLce = \u2212 N\u2211 i=1 (logP\u03b8(y i|xi) + logP\u03b8(yi|zi))\nWe combine both losses as the final loss:\nL = Lce + \u03bbLctr\nwhere \u03bb is an interpolation factor. We incorporate the augmented source inputs z to ensure that the model can still generate correct translations with noisy input.\nF.2 Optimal Hyperparameters We conduct thorough experiments to choose the optimal hyperparameters for contrastive learning.\nTemperature \u03c4 . This hyperparameter plays a crucial role in adjusting the softmax function used in the contrastive learning framework, thereby affecting the distribution of the similarity scores between augmented and original sentences. By varying the value of \u03c4 , we can control the concentration or diffusion of the score distribution. Figure 6 shows the results from the models trained with different augmentation strategies. It is evident that \u03c4 = 0.1 uniformly performs the best. So we set \u03c4 = 0.1 by default.\nLoss balance \u03bb. Our final loss consists of the standard cross-entropy loss and the contrastive loss. Here we conduct experiments to choose the optimal loss balance factor \u03bb. As shown in Figure\n7, the optimal \u03bb varies for different augmentation methods. We set \u03bb = 0.01 by default since this value works better for most methods."
        },
        {
            "heading": "G Prompt for GPT-4 Evaluation",
            "text": "\"\"\"In the following, I\u2019m going to show you one noisy source sentence in French and one noisy target sentence in English. In addition, I also offer you two clean versions of the noisy target sentence. Can you rank these two clean\ntarget sentences based on these three criteria: 1. Comprehensive noise removal:\nAll forms of noise should be eliminated from the noisy target sentence, including removing semantically meaningless emojis, translating emojis with semantic content into words, correcting misspellings, etc. 2. Semantic preservation:\nThe clean target sentence should retain similar semantic information as the original noisy target sentence. 3. Alignment with the source\nsentence: The clean target sentence should convey the same intended meaning as the noisy source sentence, ensuring accurate translation and faithful\nrepresentation of the original content. Noisy source sentence in French:\n{0} Noisy target sentence in\nEnglish: {1} The first clean target sentence:\n{2} The second clean target\nsentence: {3} For your output, you don\u2019t need\nto give any explanation. If the first version is better, you output 1. If the second version is better, you output 2. If they are equally clean, you output 3.\"\"\".format(source, target, target_from_clean_method_v1, target_from_clean_method_v2)"
        }
    ],
    "title": "Ask Language Model to Clean Your Noisy Translation Data",
    "year": 2023
}