{
    "abstractText": "Answering time-sensitive questions from long documents requires temporal reasoning over the times in questions and documents. An important open question is whether large language models can perform such reasoning solely using a provided text document, or whether they can benefit from additional temporal information extracted using other systems. We address this research question by applying existing temporal information extraction systems to construct temporal graphs of events, times, and temporal relations in questions and documents. We then investigate different approaches for fusing these graphs into Transformer models. Experimental results show that our proposed approach for fusing temporal graphs into input text substantially enhances the temporal reasoning capabilities of Transformer models with or without fine-tuning. Additionally, our proposed method outperforms various graph convolution-based approaches and establishes a new state-of-the-art performance on SituatedQA and three splits of TimeQA.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xin Su"
        },
        {
            "affiliations": [],
            "name": "Phillip Howard"
        },
        {
            "affiliations": [],
            "name": "Nagib Hakim"
        },
        {
            "affiliations": [],
            "name": "Steven Bethard"
        }
    ],
    "id": "SP:30cdc04c7d6288d35047e7495d6326b1e05f4904",
    "references": [
        {
            "authors": [
                "Jiangang Bai",
                "Yujing Wang",
                "Yiren Chen",
                "Yaming Yang",
                "Jing Bai",
                "Jing Yu",
                "Yunhai Tong."
            ],
            "title": "SyntaxBERT: Improving pre-trained transformers with syntax trees",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Compu-",
            "year": 2021
        },
        {
            "authors": [
                "Miguel Ballesteros",
                "Rishita Anubhai",
                "Shuai Wang",
                "Nima Pourdamghani",
                "Yogarshi Vyas",
                "Jie Ma",
                "Parminder Bhatia",
                "Kathleen McKeown",
                "Yaser AlOnaizan"
            ],
            "title": "Severing the edge between before and after: Neural architectures for temporal ordering",
            "year": 2020
        },
        {
            "authors": [
                "Nathanael Chambers",
                "Taylor Cassidy",
                "Bill McDowell",
                "Steven Bethard."
            ],
            "title": "Dense event ordering with a multi-pass architecture",
            "venue": "Transactions of the Association for Computational Linguistics, 2:273\u2013 284.",
            "year": 2014
        },
        {
            "authors": [
                "Angel X. Chang",
                "Christopher Manning."
            ],
            "title": "SUTime: A library for recognizing and normalizing time expressions",
            "venue": "Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC\u201912), pages 3735\u20133740, Istanbul,",
            "year": 2012
        },
        {
            "authors": [
                "Wenhu Chen",
                "Xinyi Wang",
                "William Yang Wang."
            ],
            "title": "A dataset for answering time-sensitive questions",
            "venue": "Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2).",
            "year": 2021
        },
        {
            "authors": [
                "Ziqiang Chen",
                "Shaojuan Wu",
                "Xiaowang Zhang",
                "Zhiyong Feng."
            ],
            "title": "Tml: A temporal-aware multitask learning framework for time-sensitive question answering",
            "venue": "Companion Proceedings of the ACM",
            "year": 2023
        },
        {
            "authors": [
                "Ziqiang Chen",
                "Shaojuan Wu",
                "Xiaowang Zhang",
                "Zhiyong Feng."
            ],
            "title": "Tml: A temporal-aware multitask learning framework for time-sensitive question answering",
            "venue": "Companion Proceedings of the ACM Web Conference 2023, WWW \u201923 Companion, page",
            "year": 2023
        },
        {
            "authors": [
                "Prafulla Kumar Choubey",
                "Ruihong Huang."
            ],
            "title": "Modeling document-level temporal structures for building temporal dependency graphs",
            "venue": "Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics",
            "year": 2022
        },
        {
            "authors": [
                "Jeremy R. Cole",
                "Aditi Chaudhary",
                "Bhuwan Dhingra",
                "Partha Talukdar."
            ],
            "title": "Salient span masking for temporal understanding",
            "venue": "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 3052\u2013",
            "year": 2023
        },
        {
            "authors": [
                "Agnieszka Falenska",
                "\u00d6zlem \u00c7etino\u011flu."
            ],
            "title": "Assessing gender bias in Wikipedia: Inequalities in article titles",
            "venue": "Proceedings of the 3rd Workshop on Gender Bias in Natural Language Processing, pages 75\u201385, Online. Association for Computational",
            "year": 2021
        },
        {
            "authors": [
                "Yanlin Feng",
                "Xinyue Chen",
                "Bill Yuchen Lin",
                "Peifeng Wang",
                "Jun Yan",
                "Xiang Ren."
            ],
            "title": "Scalable multihop relational reasoning for knowledge-aware question answering",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language",
            "year": 2020
        },
        {
            "authors": [
                "Mandy Guo",
                "Joshua Ainslie",
                "David Uthus",
                "Santiago Ontanon",
                "Jianmo Ni",
                "Yun-Hsuan Sung",
                "Yinfei Yang."
            ],
            "title": "LongT5: Efficient text-to-text transformer for long sequences",
            "venue": "Findings of the Association for Computational Linguistics: NAACL 2022, pages 724\u2013",
            "year": 2022
        },
        {
            "authors": [
                "Rujun Han",
                "Qiang Ning",
                "Nanyun Peng."
            ],
            "title": "Joint event and temporal relation extraction with shared representations and structured prediction",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th In-",
            "year": 2019
        },
        {
            "authors": [
                "Gautier Izacard",
                "Edouard Grave"
            ],
            "title": "Leveraging passage retrieval with generative models for open domain question answering",
            "year": 2020
        },
        {
            "authors": [
                "Gautier Izacard",
                "Edouard Grave."
            ],
            "title": "Leveraging passage retrieval with generative models for open domain question answering",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,",
            "year": 2021
        },
        {
            "authors": [
                "Zhen Jia",
                "Abdalghani Abujabal",
                "Rishiraj Saha Roy",
                "Jannik Str\u00f6tgen",
                "Gerhard Weikum."
            ],
            "title": "Tequila: Temporal question answering over knowledge bases",
            "venue": "Proceedings of the 27th ACM International Conference on Information and Knowledge Management,",
            "year": 2018
        },
        {
            "authors": [
                "Zhen Jia",
                "Soumajit Pramanik",
                "Rishiraj Saha Roy",
                "Gerhard Weikum."
            ],
            "title": "Complex temporal question answering on knowledge graphs",
            "venue": "Proceedings of the 30th ACM International Conference on Information & Knowledge Management, CIKM \u201921, page",
            "year": 2021
        },
        {
            "authors": [
                "Mandar Joshi",
                "Eunsol Choi",
                "Daniel Weld",
                "Luke Zettlemoyer."
            ],
            "title": "TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension",
            "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Vol-",
            "year": 2017
        },
        {
            "authors": [
                "Vladimir Karpukhin",
                "Barlas Oguz",
                "Sewon Min",
                "Patrick Lewis",
                "Ledell Wu",
                "Sergey Edunov",
                "Danqi Chen",
                "Wen-tau Yih."
            ],
            "title": "Dense passage retrieval for opendomain question answering",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural",
            "year": 2020
        },
        {
            "authors": [
                "Omar Khattab",
                "Keshav Santhanam",
                "Xiang Lisa Li",
                "David Hall",
                "Percy Liang",
                "Christopher Potts",
                "Matei Zaharia."
            ],
            "title": "Demonstrate-searchpredict: Composing retrieval and language models for knowledge-intensive nlp",
            "venue": "arXiv preprint",
            "year": 2022
        },
        {
            "authors": [
                "Thomas N. Kipf",
                "Max Welling."
            ],
            "title": "Semisupervised classification with graph convolutional networks",
            "venue": "International Conference on Learning Representations.",
            "year": 2017
        },
        {
            "authors": [
                "Danielle Epstein",
                "Illia Polosukhin",
                "Jacob Devlin",
                "Kenton Lee",
                "Kristina Toutanova",
                "Llion Jones",
                "Matthew Kelcey",
                "Ming-Wei Chang",
                "Andrew M. Dai",
                "Jakob Uszkoreit",
                "Quoc Le",
                "Slav Petrov"
            ],
            "title": "Natural questions: A benchmark for question answering",
            "year": 2019
        },
        {
            "authors": [
                "Uszkoreit",
                "Quoc Le",
                "Slav Petrov."
            ],
            "title": "Natural Questions: A Benchmark for Question Answering Research",
            "venue": "Transactions of the Association for Computational Linguistics, 7:453\u2013466.",
            "year": 2019
        },
        {
            "authors": [
                "Kenton Lee",
                "Ming-Wei Chang",
                "Kristina Toutanova."
            ],
            "title": "Latent retrieval for weakly supervised open domain question answering",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 6086\u20136096, Florence, Italy.",
            "year": 2019
        },
        {
            "authors": [
                "Xingxuan Li",
                "Liying Cheng",
                "Qingyu Tan",
                "Hwee Tou Ng",
                "Shafiq Joty",
                "Lidong Bing"
            ],
            "title": "Unlocking temporal question answering for large language models using code execution",
            "year": 2023
        },
        {
            "authors": [
                "Aman Madaan",
                "Yiming Yang."
            ],
            "title": "Neural language modeling for contextualized temporal graph generation",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
            "year": 2021
        },
        {
            "authors": [
                "Christopher Manning",
                "Mihai Surdeanu",
                "John Bauer",
                "Jenny Finkel",
                "Steven Bethard",
                "David McClosky."
            ],
            "title": "The Stanford CoreNLP natural language processing toolkit",
            "venue": "Proceedings of 52nd Annual Meeting of the Association for Computational Linguis-",
            "year": 2014
        },
        {
            "authors": [
                "Puneet Mathur",
                "Vlad Morariu",
                "Verena Kaynig-Fittkau",
                "Jiuxiang Gu",
                "Franck Dernoncourt",
                "Quan Tran",
                "Ani Nenkova",
                "Dinesh Manocha",
                "Rajiv Jain."
            ],
            "title": "DocTime: A document-level temporal dependency graph parser",
            "venue": "Proceedings of the 2022 Conference",
            "year": 2022
        },
        {
            "authors": [
                "Costas Mavromatis",
                "Prasanna Lakkur Subramanyam",
                "Vassilis N. Ioannidis",
                "Soji Adeshina",
                "Phillip Howard",
                "Tetiana Grinberg",
                "Nagib Hakim",
                "George Karypis."
            ],
            "title": "Tempoqr: Temporal question reasoning over knowledge graphs",
            "venue": "AAAI Conference on Artificial",
            "year": 2021
        },
        {
            "authors": [
                "Qiang Ning",
                "Sanjay Subramanian",
                "Dan Roth"
            ],
            "title": "An improved neural baseline for temporal relation",
            "year": 2019
        },
        {
            "authors": [
                "Qiang Ning",
                "Hao Wu",
                "Dan Roth."
            ],
            "title": "A multiaxis annotation scheme for event temporal relations",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1318\u20131328, Melbourne, Aus-",
            "year": 2018
        },
        {
            "authors": [
                "Qiang Ning",
                "Ben Zhou",
                "Zhili Feng",
                "Haoruo Peng",
                "Dan Roth."
            ],
            "title": "CogCompTime: A tool for understanding time in natural language",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstra-",
            "year": 2018
        },
        {
            "authors": [
                "OpenAI."
            ],
            "title": "ChatGPT: Optimizing language models for dialogue",
            "venue": "OpenAI.",
            "year": 2022
        },
        {
            "authors": [
                "James Pustejovsky",
                "Patrick Hanks",
                "Roser Sauri",
                "Andrew See",
                "Robert Gaizauskas",
                "Andrea Setzer",
                "Dragomir Radev",
                "Beth Sundheim",
                "David Day",
                "Lisa Ferro"
            ],
            "title": "The timebank corpus",
            "venue": "In Corpus linguistics,",
            "year": 2003
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J Liu."
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2020
        },
        {
            "authors": [
                "Hayley Ross",
                "Jonathon Cai",
                "Bonan Min."
            ],
            "title": "Exploring Contextualized Neural Language Models for Temporal Dependency Parsing",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8548\u20138553,",
            "year": 2020
        },
        {
            "authors": [
                "Apoorv Saxena",
                "Soumen Chakrabarti",
                "Partha Talukdar."
            ],
            "title": "Question answering over temporal knowledge graphs",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference",
            "year": 2021
        },
        {
            "authors": [
                "Michael Schlichtkrull",
                "Thomas N. Kipf",
                "Peter Bloem",
                "Rianne van den Berg",
                "Ivan Titov",
                "Max Welling."
            ],
            "title": "Modeling relational data with graph convolutional networks",
            "venue": "The Semantic Web, pages 593\u2013 607, Cham. Springer International Publishing.",
            "year": 2018
        },
        {
            "authors": [
                "Chao Shang",
                "Peng Qi",
                "Guangtao Wang",
                "Jing Huang",
                "Youzheng Wu",
                "Bowen Zhou."
            ],
            "title": "Open temporal relation extraction for question answering",
            "venue": "3rd Conference on Automated Knowledge Base Construction.",
            "year": 2021
        },
        {
            "authors": [
                "Aditya Sharma",
                "Apoorv Saxena",
                "Chitrank Gupta",
                "Mehran Kazemi",
                "Partha Talukdar",
                "Soumen Chakrabarti."
            ],
            "title": "TwiRGCN: Temporally weighted graph convolution for question answering over temporal knowledge graphs",
            "venue": "Proceedings of the 17th",
            "year": 2023
        },
        {
            "authors": [
                "Peter Shaw",
                "Jakob Uszkoreit",
                "Ashish Vaswani."
            ],
            "title": "Self-attention with relative position representations",
            "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,",
            "year": 2018
        },
        {
            "authors": [
                "Hugo Touvron",
                "Thibaut Lavril",
                "Gautier Izacard",
                "Xavier Martinet",
                "Marie-Anne Lachaux",
                "Timoth\u00e9e Lacroix",
                "Baptiste Rozi\u00e8re",
                "Naman Goyal",
                "Eric Hambro",
                "Faisal Azhar"
            ],
            "title": "Llama: Open and efficient foundation language models",
            "year": 2023
        },
        {
            "authors": [
                "Harsh Trivedi",
                "Niranjan Balasubramanian",
                "Tushar Khot",
                "Ashish Sabharwal."
            ],
            "title": "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions",
            "venue": "arXiv preprint arXiv:2212.10509.",
            "year": 2022
        },
        {
            "authors": [
                "Naushad UzZaman",
                "Hector Llorens",
                "Leon Derczynski",
                "James Allen",
                "Marc Verhagen",
                "James Pustejovsky."
            ],
            "title": "SemEval-2013 task 1: TempEval-3: Evaluating time expressions, events, and temporal relations",
            "venue": "Second Joint Conference on Lexical and Compu-",
            "year": 2013
        },
        {
            "authors": [
                "Siddharth Vashishtha",
                "Benjamin Van Durme",
                "Aaron Steven White."
            ],
            "title": "Fine-grained temporal relation extraction",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2906\u20132919, Florence, Italy. Asso-",
            "year": 2019
        },
        {
            "authors": [
                "Marc Verhagen",
                "Robert Gaizauskas",
                "Frank Schilder",
                "Mark Hepple",
                "Jessica Moszkowicz",
                "James Pustejovsky."
            ],
            "title": "The tempeval challenge: identifying temporal relations in text",
            "venue": "Language Resources and Evaluation, 43:161\u2013179.",
            "year": 2009
        },
        {
            "authors": [
                "Marc Verhagen",
                "Roser Sauri",
                "Tommaso Caselli",
                "James Pustejovsky."
            ],
            "title": "Semeval-2010 task 13: Tempeval-2",
            "venue": "Proceedings of the 5th international workshop on semantic evaluation, pages 57\u201362.",
            "year": 2010
        },
        {
            "authors": [
                "Bailin Wang",
                "Richard Shin",
                "Xiaodong Liu",
                "Oleksandr Polozov",
                "Matthew Richardson."
            ],
            "title": "RAT-SQL: Relation-aware schema encoding and linking for textto-SQL parsers",
            "venue": "Proceedings of the 58th Annual",
            "year": 2020
        },
        {
            "authors": [
                "Teven Le Scao",
                "Sylvain Gugger",
                "Mariama Drame",
                "Quentin Lhoest",
                "Alexander Rush."
            ],
            "title": "Transformers: State-of-the-art natural language processing",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System",
            "year": 2020
        },
        {
            "authors": [
                "An Yang",
                "Quan Wang",
                "Jing Liu",
                "Kai Liu",
                "Yajuan Lyu",
                "Hua Wu",
                "Qiaoqiao She",
                "Sujian Li."
            ],
            "title": "Enhancing pre-trained language representations with rich knowledge for machine reading comprehension",
            "venue": "Proceedings of the 57th Annual Meeting of the Asso-",
            "year": 2019
        },
        {
            "authors": [
                "Jiarui Yao",
                "Haoling Qiu",
                "Bonan Min",
                "Nianwen Xue."
            ],
            "title": "Annotating Temporal Dependency Graphs via Crowdsourcing",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5368\u20135380, Online. As-",
            "year": 2020
        },
        {
            "authors": [
                "Michihiro Yasunaga",
                "Hongyu Ren",
                "Antoine Bosselut",
                "Percy Liang",
                "Jure Leskovec."
            ],
            "title": "QA-GNN: Reasoning with language models and knowledge graphs for question answering",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter",
            "year": 2021
        },
        {
            "authors": [
                "Ori Yoran",
                "Tomer Wolfson",
                "Ben Bogin",
                "Uri Katz",
                "Daniel Deutch",
                "Jonathan Berant."
            ],
            "title": "Answering questions by meta-reasoning over multiple chains of thought",
            "venue": "arXiv preprint arXiv:2304.13007.",
            "year": 2023
        },
        {
            "authors": [
                "Michael Zhang",
                "Eunsol Choi."
            ],
            "title": "SituatedQA: Incorporating extra-linguistic contexts into QA",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7371\u2013 7387, Online and Punta Cana, Dominican Republic.",
            "year": 2021
        },
        {
            "authors": [
                "Shuaicheng Zhang",
                "Qiang Ning",
                "Lifu Huang."
            ],
            "title": "Extracting temporal event relation with syntax-guided graph transformer",
            "venue": "Findings of the Association for Computational Linguistics: NAACL",
            "year": 2022
        },
        {
            "authors": [
                "Xikun Zhang",
                "Antoine Bosselut",
                "Michihiro Yasunaga",
                "Hongyu Ren",
                "Percy Liang",
                "Christopher D Manning",
                "Jure Leskovec."
            ],
            "title": "GreaseLM: Graph REASoning enhanced language models",
            "venue": "International Conference on Learning Representations.",
            "year": 2022
        },
        {
            "authors": [
                "Yuchen Zhang",
                "Nianwen Xue."
            ],
            "title": "Neural ranking models for temporal dependency structure parsing",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3339\u20133349, Brussels, Belgium. Association for Com-",
            "year": 2018
        },
        {
            "authors": [
                "Yuchen Zhang",
                "Nianwen Xue."
            ],
            "title": "Acquiring structured temporal representation via crowdsourcing: A feasibility study",
            "venue": "Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019), pages 178\u2013185, Minneapolis,",
            "year": 2019
        },
        {
            "authors": [
                "L. George"
            ],
            "title": "Europe and Western European Union Parliamentary Assembly",
            "venue": "Bryn Mawr College",
            "year": 1956
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Long-document time-sensitive question answering (Chen et al., 2021) requires temporal reasoning over the events and times in a question and an accompanying long context document. Answering such questions is a challenging task in natural language processing (NLP) as models must comprehend and interpret the temporal scope of the question as well as the associated temporal information dispersed throughout the long document. For example, consider the time-sensitive questions about George Washington\u2019s position provided in Figure 1. The relevant events and temporal information regarding George Washington\u2019s position are scattered across many different sentences in the context document. Since there is no one single text segment containing the answer, the model must integrate and reason over events and times\nthroughout the context document. Additionally, this example illustrates how changing the time expression in the question may also result in a change in the answer: in this case, replacing between 1776 - 1780 with from 1790 to 1797 changes the answer from Commander-in-Chief to Presidency and Chancellor.\nThough not designed directly for question answering, there is a substantial amount of research on temporal information extraction (Chambers et al., 2014; Ning et al., 2018a; Zhang and Xue, 2018, 2019; Han et al., 2019; Ning et al., 2019; Vashishtha et al., 2019; Ballesteros et al., 2020; Yao et al., 2020; Zhang et al., 2022a). Such models can help reveal the structure of the timeline underlying a document. However, there is little existing research on combining such information extraction systems with question answering Transformer models (Izacard and Grave, 2021) to effectively reason over temporal information in long documents.\nIn this work, we utilize existing temporal information extraction systems to construct temporal\ngraphs and investigate different fusion methods to inject them into Transformer models.\nWe evaluate the effectiveness of each temporal graph fusion approach on long-document timesensitive question answering datasets. Our contributions are as follows:\n1. We introduce a simple but novel approach to fuse temporal graphs into the input text of question answering Transformer models. 2. We compare our method with prior approaches such as fusion via graph convolutions, and show that our input fusion method outperforms these alternative approaches. 3. We demonstrate that our input fusion approach can be used seamlessly with large language models in an in-context learning setting. 4. We perform a detailed error analysis, revealing the efficacy of our method in fixing temporal reasoning errors in Transformer models."
        },
        {
            "heading": "2 Related Work",
            "text": ""
        },
        {
            "heading": "2.1 Extracting Temporal Graphs",
            "text": "Research on extracting temporal graphs from text can be grouped into the extraction of event and time graphs (Chambers et al., 2014; Ning et al., 2018b), contextualized event graphs (Madaan and Yang, 2021), and temporal dependency trees and graphs (Zhang and Xue, 2018, 2019; Yao et al., 2020; Ross et al., 2020; Choubey and Huang, 2022; Mathur et al., 2022). Additionally, some prior work has focused on the problem of extracting temporal relations between times and events (Ning et al., 2018a, 2019; Vashishtha et al., 2019; Han et al., 2019; Ballesteros et al., 2020; Zhang et al., 2022a). The outputs of these temporal relation extraction systems are often used to construct temporal graphs. In this work, we use CAEVO (Chambers et al., 2014) and SUTime (Chang and Manning, 2012) to construct our temporal graphs because they are publicly available (unlike more recent models such as the temporal dependency graph parser proposed by Mathur et al. (2022)) and can easily scale to large amounts of long documents without requiring additional training."
        },
        {
            "heading": "2.2 Temporal Question Answering",
            "text": "Jia et al. (2018) decomposes questions and applies temporal constraints to allow general questionanswering systems to answer knowledge-basetemporal questions. Saxena et al. (2021), Jia et al. (2021), Mavromatis et al. (2021), and Sharma et al.\n(2023) use time-aware embeddings to reason over temporal knowledge graphs. Similar to our work, Huang et al. (2022) and Shang et al. (2021) answer temporal questions on text, but they focus on temporal event ordering questions over short texts rather than time-sensitive questions over long documents. Li et al. (2023) focus on exploring large language models for information extraction in structured temporal contexts. They represent the extracted time-sensitive information in code and then execute Python scripts to derive the answers. In contrast, we concentrate on temporal reasoning in the reading comprehension setting, using unstructured long documents to deduce answers. This poses more challenges in information extraction and involves more complex reasoning, which motivates our integration of existing temporal information extraction systems with transformer-based language models. The most similar work to ours is Mathur et al. (2022), which extracts temporal dependency graphs and merges them with Transformer models using learnable attention mask weights. We compare directly to this approach, and also explore both graph convolutions and input modifications as alternatives to fusing temporal graphs into Transformer models."
        },
        {
            "heading": "2.3 Fusing Graphs into Transformer Models",
            "text": "The most common approaches for fusing graphs into Transformer models are graph neural networks (GNN) and self-attention. In the GNN-based approach, a GNN is used to encode and learn graph representations which are then fused into the Transformer model (Yang et al., 2019; Feng et al., 2020; Yasunaga et al., 2021; Zhang et al., 2022b). In the self-attention approach, the relations in the graphs are converted into token-to-token relations and are then fused into the self-attention mechanism. For example, Wang et al. (2020) uses relative position encoding (Shaw et al., 2018) to encode a database schema graph into the BERT representation. Similarly, Bai et al. (2021) utilize attention masks to fuse syntax trees into Transformer models. We explore GNN-based fusion of temporal graphs into question answering models, comparing this approach to the attention-based approach of Mathur et al. (2022), as well as our simpler approach which fuses the temporal graph directly into the Transformer model\u2019s input.\nContext Document Question\nTemporal GraphTransformer\nEncoding Graph Construction"
        },
        {
            "heading": "Graph Fusion",
            "text": "ERR GNN\n/\nAnswer Tuned Frozen\nFigure 2: Overview of our approach. The ERR method allows for optional fine-tuning of the Transformer model, whereas for the GNN method requires finetuning."
        },
        {
            "heading": "3 Method",
            "text": "Our approach applies temporal information extraction systems to construct temporal graphs and then fuses the graphs into pre-trained Transformer models. We consider two fusion methods:\n1. Explicit edge representation fusion (ERR): a simple but novel approach to fuse the graphs into the input text. 2. Graph neural network fusion: a GNN is used to fuse the graphs into the token embeddings or the last hidden layer representations (i.e., contextualized embeddings) of the Transformer model.\nThe overall approach is illustrated in Figure 2."
        },
        {
            "heading": "3.1 Graph Construction",
            "text": "Given a time-sensitive question and a corresponding context document, we construct a directed temporal graph where events and time expressions are nodes and temporal relations are edges of the type BEFORE, AFTER, INCLUDES, INCLUDED BY, SIMULTANEOUS, or OVERLAP.\nWe extract the single timestamp included in each question, which is either explicitly provided by the dataset (as in SituatedQA (Zhang and Choi, 2021)) or alternatively is extracted via simple regular expressions (the regular expressions we use achieve 100% extraction accuracy on TimeQA (Chen et al., 2021)). We add a single question-time node to the graph for this time.\nFor the document, we apply CAEVO1 to iden-\n1https://github.com/nchambers/caevo\nQuestion Time: between\n1776 - 1780 December 1783June 14, 1775\ncreated\nnominated\nbade farewell\nresigned\nincluded by\ndays later\nbecome\nbefore\nafte r\nafter\nbef ore\nbefore\nbefore\nbefore\nafter incl\nude d b\ny\nincl ude\nd b y\nbefore\nafter\nbefore\nbefore\nafter\nafter\nevent time"
        },
        {
            "heading": "Question Time:",
            "text": "1776 - 1780 Dec 1783 before after June 14, 1775\ncreated\nbecome resigned\nbade farewell\nafter\nbefore incl ude d by\nbefore\nafte r\nafter included by\nafter after\nFigure 3: Temporal graph example.\ntify the events, time expressions, and the temporal relations between them. CAEVO follows the standard convention in temporal information extraction that events are only simple actions (typically verbs) with linking of these actions to subjects, objects, and other arguments left to dependency parsers (Pustejovsky et al., 2003; Verhagen et al., 2009, 2010; UzZaman et al., 2013). We add documentevent and document-time nodes for each identified event and time, respectively, and add edges between nodes for each identified temporal relation.\nTo link the question-time node to the documenttime nodes, we use SUTime2 to normalize time expressions to time intervals, and deterministically compute temporal relations between question time and document times as edges. For example, given a document-time node \u201cthe year 2022\u201d and a question-time node \u201cfrom 1789 to 1797\u201d from the question \u201cWhat was George Washington\u2019s position from 1789 to 1797?\u201d, the times will be normalized to [2022-01-01, 2022-12-31] and [1789-01-01, 1797-12-31] respectively, and the temporal relation between them can then be computed as AFTER.\nTo link the question-time node to document events, for each document-event node, we calculate the shortest path in the temporal graph between it and the question-time node and recursively apply standard transitivity rules (see Appendix A.1) along the path to infer the temporal relation. For example, given a path A is BEFORE B and B INCLUDES C, we can infer the relation between A and C is BEFORE. An example of a constructed temporal graph for Q1 in Figure 1 is illustrated in Figure 3."
        },
        {
            "heading": "3.2 Graph Fusion",
            "text": "For both fusion methods, we concatenate the question and corresponding context document as an input sequence to the Transformer model. For example, given the question and document from Figure 1 Q1, the input is:\n2https://nlp.stanford.edu/software/sutime.html\nquestion: What was George Washington\u2019s position between 1776 - 1780? context: . . . Congress created the Continental Army on June 14, 1775 . . ."
        },
        {
            "heading": "3.2.1 Explicit Edge Representation",
            "text": "In the ERR method, we mark a temporal graph\u2019s nodes and edges in the input sequence, using <question time> and </question time> to mark the question-time node and relation markers such as <before> and </before> to mark the nodes in the context document and their relations to the question time. Thus, the ERR input for the above example is:\nquestion: What was George Washington\u2019s position <question time>between 1776- 1780</question time>? context: . . . Congress <before>created</before> the Continental Army on <before>June 14, 1775</before>. . . This approach aims to make the model learn to attend to parts of the input sequence that may contain answer information. For instance, the model may learn that information related to the answer may be found near markers such as <overlap>, <includes>, <included by>, and <simultaneous>. Additionally, the model may learn that answer-related information may exist between <before> and <after>, even if the answer does not have any nearby temporal information."
        },
        {
            "heading": "3.2.2 GNN-based Fusion",
            "text": "In GNN-based fusion, we add <e> and </e> markers around each node, and apply a relational graph convolution (RelGraphConv; Schlichtkrull et al., 2018) over the marked nodes. RelGraphConv is a variant of graph convolution (GCN; Kipf and Welling, 2017) that can learn different transformations for different relation types. We employ the RelGraphConv to encode a temporal graph and update the Transformer encoder\u2019s token embedding layer or last hidden layer representations (i.e., contextualized embeddings). We utilize the RelGraphConv in its original form without any modifications.\nFormally, given a temporal graph G = (V,E), we use representations of the <e> markers from the Transformer model\u2019s token embedding layer or the last hidden layer as initial node embeddings. The output of layer l + 1 for node i \u2208 V is:\nhl+1i = \u03c3( \u2211 r\u2208R \u2211 j\u2208N r(i) 1 ci,r W (l)r h (l) j +W (l) 0 h (l) i )\nwhere N r(i) denotes all neighbor nodes that have relation r with node i, 1ci,r is a normalization constant that can be learned or manually specified, \u03c3 is the activation function, W0 is the self-loop weight, and Wr is the learnable weights. We refer readers to Schlichtkrull et al. (2018) for more details."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Datasets",
            "text": "We evaluate on two time-sensitive question answering datasets: Time-Sensitive Question Answering (TimeQA; Chen et al., 2021) and SituatedQA (Zhang and Choi, 2021). We briefly describe these two datasets below and provide statistics on each dataset in Table 9 of Appendix A.6.\nTimeQA The TimeQA dataset is comprised of time-sensitive questions about time-evolving facts paired with long Wikipedia pages as context. The dataset has two non-overlapping splits generated by diverse templates which are referred to as TimeQA Easy and TimeQA Hard, with each split containing 20k question-answer pairs regarding 5.5K timeevolving facts and 70 relations. TimeQA Easy contains questions which typically include time expressions that are explicitly mentioned in the context document. In contrast, TimeQA Hard has time expressions that are not explicitly specified and therefore require more advanced temporal reasoning. For example, both questions in Figure 1 are hard questions, but if we replace the time expressions in the questions with In 1788, they will become easy questions. In addition, smaller Human-paraphrased Easy and Hard splits are also provided.\nSituatedQA SituatedQA is an open-domain question answering dataset comprising two subsets: Temporal SituatedQA and Geographical SituatedQA. We focus on Temporal SituatedQA, which we will hereafter refer to as SituatedQA. Each question in SituatedQA is accompanied by a temporal annotation that could change the answer to the question if it is modified. For instance, the question \"Which COVID-19 vaccines have been authorized for adults in the US as of Jan 2021?\" has a corresponding answer of \"Moderna, Pfizer.\" However, if we change the time to \"Apr 10, 2021,\" the answer becomes \"Moderna, Pfizer, J&J.\" As SituatedQA is a re-annotation of a subset of NQ-Open (Kwiatkowski et al., 2019a; Lee et al., 2019), we use the top 100 passages retrieved from Wikipedia\nby FiD (Izacard and Grave, 2021)3 for each question as context documents.\nEvaluation Metrics We use the official evaluation methods and metrics provided in the code release of the datasets. For TimeQA, we report the exact match and F1 scores. For SituatedQA, we report the exact match score."
        },
        {
            "heading": "4.2 Baselines",
            "text": "We compare our models with the previous state-ofthe-art on the TimeQA and SituatedQA, which we describe in this section and summarize in Table 1.\nFor TimeQA, we compare against: FiD & BigBird Chen et al. (2021) adapt two long-\ndocument question answering models, BigBird (Zaheer et al., 2020) and FiD (Izacard and Grave, 2021), to the TimeQA dataset. Before finetuning the models on TimeQA, they also finetune on Natural Questions (Kwiatkowski et al., 2019b) and TriviaQA (Joshi et al., 2017), finding that training on Natural Questions results in the best performance. The best model from Chen et al. (2021) on TimeQA Easy and Hard is FiD, while BigBird performs best on the Humanparaphrased TimeQA Easy and Hard splits. Replicated FiD We also report our replication of Chen et al. (2021)\u2019s FiD model using the code provided by their GitHub repository4, but even with extensive hyperparameter tuning, we were unable to reproduce their reported performance of the FiD model on TimeQA Easy5. DocTime DocTime (Mathur et al., 2022) first uses CAEVO to identify events and time expressions in context documents. Then, a custom-trained temporal dependency parser is applied to parse temporal dependency graphs. Finally, the parsed 3https://github.com/facebookresearch/FiD 4wenhuchen/Time-Sensitive-QA 5Other researchers have reported the same issue on GitHub\ntemporal dependency graphs are fused into the attention mechanism of the FiD model, which is fine-tuned on Natural Questions. BigBird + MTL & Longformer + MTL Chen et al. (2023a) inject temporal information into long text question answering systems using a multi-task learning (MTL) approach. They train BigBird and Longformer models on time-sensitive question answering tasks, along with three auxiliary temporal-awareness tasks. They explore first fine-tuning on Natural Questions and TriviaQA datasets, finding that TriviaQA results in the best performance. BigBird + MTL is their best model on TimeQA Easy, while Longformer + MTL performs best on TimeQA Hard.\nFor SituatedQA, we compare against: DPR + Query Modified Zhang and Choi (2021)\nadapt a retrieval-based model, DPR (Karpukhin et al., 2020), for SituatedQA. They first fine-tune the retriever and reader of DPR on Natural Questions and then further fine-tune on SituatedQA. TSM (Cole et al., 2023) uses SuTime to identify and mask time expressions throughout all Wikipedia documents. They then fine-tune T51.1-XXL (Raffel et al., 2020) to predict the masked time expressions. Finally, they fine-tune the resulting T5-1.1-XXL model on SituatedQA."
        },
        {
            "heading": "4.3 Implementation Details",
            "text": "We use LongT5-base (Guo et al., 2022), a transformer sequence-to-sequence model, as our base model. Our experiments demonstrate that LongT5 outperforms the FiD model (Izacard and Grave, 2020) commonly used on long-document question answering tasks. To fairly compare with previous work (Chen et al., 2021; Mathur et al., 2022), we pre-train the LongT5 model on Natural Questions (Kwiatkowski et al., 2019a) and then fine-tune it\non TimeQA and SituatedQA, respectively. Appendix A.5 provides other implementation details such as hyperparameters, graph statistics, software versions, and external tool performance.\nWe perform model selection before evaluating on the test sets, exploring different graph subsets with both the ERR and GNN based fusion approaches introduced in Section 3.2. Table 6 in appendix A.2 shows that the best ERR method uses a document-time-to-question-time (DT2QT) subgraph and the best GNN method uses the full temporal graph by fusing it into the token embedding layer representations of the Transformer model. We hereafter refer to the LongT5 model fused with a DT2QT graph using the ERR method as LongT5ERR, and the LongT5 model fused with a full temporal graph using the GNN method as LongT5GNN."
        },
        {
            "heading": "4.4 Main Results",
            "text": "We summarize the performance of baseline models and those trained with our graph fusion methods in Table 2.\nWhich baseline models perform best? On TimeQA, our LongT5 model without temporal graph fusion performs better than or equivalent to all other baseline models across every split and metric except for the Easy split. The best-performing model reported on TimeQA Easy is DocTime. On SituatedQA, LongT5 with no fusion performs as well as the best-reported results on this dataset.\nWhich graph fusion methods perform best? Using LongT5, we consider both of our ERR and GNN fusion methods described in Section 3.2. On\nTimeQA, the LongT5GNN model fails to outperform LongT5 without fusion, while the LongT5ERR model improves over LongT5 on every split and dataset, exhibiting particularly large gains on the Hard splits. On Situated QA, both LongT5ERR and LongT5GNN models improve over the no-fusion LongT5 baseline, with ERR again providing the best performance. The somewhat inconsistent performance of the GNN fusion method across datasets (beneficial on SituatedQA while detrimental on TimeQA) suggests the need for a different GNN design for TimeQA, which we leave to future work.\nTo explore the differences between LongT5ERR and LongT5GNN models, we analyze 20 randomly sampled examples from TimeQA Hard where LongT5ERR is correct but LongT5GNN is incorrect. From our manual analysis of these 20 examples, all 20 examples share the same pattern: LongT5GNN fails to capture explicit temporal expressions in the context and relate them to the question\u2019s timeline, which is crucial for deducing the right answer. This suggests that directly embedding precomputed temporal relations between time nodes into the input is more efficient than implicitly doing so through the GNN, allowing the model to utilize them more easily. Table 14 of appendix A.11 shows three of the analyzed examples.\nDoes our approach outperform prior work? On TimeQA, the LongT5ERR model achieves a new state-of-the-art on three of the four splits, with TimeQA Easy being the exception. On SituatedQA, the LongT5ERR model achieves a new state-of-theart, outperforming the best reported results on this dataset. Our model excels on datasets that require\nmore temporal reasoning skills, like TimeQA Hard (where our model achieves a 5.8-point higher exact match score than DocTime) and SituatedQA (where our model achieves a 4.3-point higher exact match score than TSM).\nOur approach offers further advantages over alternative models due to its simplicity, as summarized in Table 1. The best prior work on TimeQA Easy, DocTime, requires training a temporal dependency parser on additional data, using CAEVO, and modifying the Transformer model\u2019s attention mechanism. The best prior work on SituatedQA, TSM, requires an 11-billion parameter T5 model which is pre-trained on the entirety of Wikipedia. In contrast, our approach only uses SUTime to construct a graph, requires only minor adjustments to the Transformer model\u2019s input, and outperforms prior work using a model with only 250 million parameters.\nWhy does our model not achieve state-of-art performance on TimeQA Easy as it does on other splits and datasets? On TimeQA Easy, there is a performance gap between our LongT5ERR model and DocTime. Because the DocTime model has not been released we cannot directly compare with its predicted results. Instead, we randomly select 50 errors from our LongT5ERR\u2019s output on the TimeQA Easy development set for error analysis. Table 3 shows that most of the errors are false negatives, where the model\u2019s predicted answers are typically co-references to the correct answers (as in Table 3 example 1) or additional correct answers that are\napplicable in the given context but are not included in the gold annotations (as in Table 3 example 2). The remaining errors are primarily related to semantic understanding, including the inability to accurately identify answer entities (e.g. identifying Greek Prime Minister George Papandreou as an employer in Table 3 example 3), the inability to interpret negation (e.g. in Table 3 example 4, where \u201crejected\u201d implies that Veloso did not join Benfica), and the inability to reason about time with numerical calculations (e.g. \u201ca year later\u201d in Table 3 example 5 implies 1846). Addressing the semantic understanding errors may require incorporating additional entities and their types into the graphs, as well as better processing of negation information and relative times.\nTo better understand the extent of false negatives in TimeQA Easy, we re-annotated the 392 test examples where the predictions of the replicated FiD model and our LongT5ERR model are partially correct (i.e., EM = 0 and F1 > 0). We then incorporated additional coreferent mentions into the gold label set for these examples. For instance, if the original gold answer was \u201cUniversity of California,\u201d we added its coreferent mention \u201cUniversity of California, Los Angeles\u201d to the gold answers. We then evaluate both the replicated FiD (the best-performing model we can reproduce) and our LongT5ERR model on the re-annotated TimeQA Easy split. The last two rows of Table 2 show that while the exact match score for FiD increases by 8.7, the exact match score for our LongT5ERR\nmodel increases by 11.9. This suggests that our model may be incurring greater penalties for finding valid coreferent answers than baseline methods.\nDoes our ERR method benefit large language models using in-context learning? We have focused so far on temporal graph fusion when finetuning models, but large language models such as ChatGPT (OpenAI, 2022) and LLaMA (Touvron et al., 2023) can achieve impressive performance without additional fine-tuning via in-context learning. Therefore, we tested the performance of ChatGPT (gpt-3.5-turbo) both with and without ERR for fusing the question-time-to-document-time graph. Following previous work (Khattab et al., 2022; Trivedi et al., 2022; Yoran et al., 2023) and considering the cost of ChatGPT\u2019s commercial API, we randomly sample 500 examples from TimeQA Easy and TimeQA Hard for evaluation. The prompt format for ChatGPT remains the same as the input format described in Section 3.2.1, except that we concatenate in-context learning few-shot exemplars and task instructions before the input. We evaluate ChatGPT with and without graph fusion using an 8-shot setting. Examples of prompts are provided in Table 11 of Appendix A.8. Table 4 shows that our ERR graph fusion method improves the performance of ChatGPT on TimeQA Easy and particularly on TimeQA Hard. We note that this improvement is possible because our method can easily integrate with state-of-the-art large language models, as our approach to temporal graph fusion modifies only the input sequence. Prior work which relies on modifying attention mechanisms or adding graph neural network layers is incompatible with this in-context learning setting."
        },
        {
            "heading": "5 Analysis",
            "text": "In this section, we analyze our LongT5ERR model on the TimeQA development set.\nHow do predictions differ compared to FiD? We compare the predictions of LongT5ERR to the replicated FiD model in Table 5. While LongT5ERR and FiD both correct about the same number of\neach other\u2019s errors on TimeQA Easy (269 vs. 243), LongT5ERR corrects many more of FiD\u2019s errors than the reverse on TimeQA Hard (494 vs. 260). To further analyze these cases, we sampled 10 errors from the set where LongT5ERR was correct while FiD was incorrect as well as the set where the FiD was correct while LongT5ERR was incorrect. We did this across both TimeQA Easy and TimeQA Hard, totaling 40 examples. Among the 20 examples in which LongT5ERR was correct and FiD was incorrect, 17 have node markers near the answers in the ERR input sequence, and the most frequent ones are <included by> and <overlap>. The remaining 3 examples have unanswerable questions. In the examples in which FiD was correct while LongT5ERR was incorrect, we observe that 13 examples are additional correct answers (i.e., false negatives), while the other 7 examples are semantic understanding errors similar to those discussed previously. These results suggest that our ERR graph fusion approach is providing the model with useful targets for attention which allow it to produce more correct answers.\nHow does the length of the document affect performance? We compare the performance of LongT5ERR to the replicated FiD model on various document lengths, as depicted in Figure 4.\nLongT5ERR performs less competitively than FiD on the Easy split for longer documents. This could be attributed to a high frequency of false negatives in LongT5ERR, as discussed previously. Additionally, it could be that LongT5ERR is less efficient at string matching on longer documents than FiD. Most of the question times in the Easy split are explicitly mentioned in the context document, which can be solved via string matching rather than temporal reasoning. However, our LongT5ERR model shows a substantial improvement on TimeQA Hard, outperforming the FiD model across most lengths."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this paper, we compared different methods for fusing temporal graphs into Transformer models for time-sensitive question answering. We found that our ERR method, which fuses the temporal graph into the Transformer model\u2019s input, outperforms GNN-based fusion as well as attention-based fusion models. We also showed that, unlike prior work on temporal graph fusion, our approach is compatible with in-context learning and yields improvements when applied to large language models such as ChatGPT. Our work establishes a promising research direction on fusing structured graphs with the inputs of Transformer models. In future work, we intend to use better-performing information extraction systems to construct our temporal graphs, enhance our approach by adding entities and entity type information to the graphs, and extend our method to spatial reasoning."
        },
        {
            "heading": "Limitations",
            "text": "We use CAEVO and SUTime to construct temporal graphs because of their scalability and availability. Using more accurate neural network-based temporal information extraction tools may provide better temporal graphs but may require domain adaptation and retraining.\nWhile we did not find graph convolutions to yield successful fusion on TimeQA, we mainly explored variations of such methods proposed by prior work. We also did not explore self-attention based fusion methods, as preliminary experiments with those methods yielded no gains, and DocTime provided an instance of such methods for comparison. But there may exist other variations of graph convolution and self-attention based fusion methods beyond those used in prior work that would make such methods more competitive with our\ninput-based approach to fusion. We also did not deeply explore the places where graph neural networks failed. For example, the graph convolution over the final layer contextualized embeddings using the full temporal graph yielded performance much lower than all other graph convolution variants we explored. We limited our exploration of failures to the more successful explicit edge representation models."
        },
        {
            "heading": "Ethics Statement",
            "text": "Wikipedia contains certain biases (Falenska and \u00c7etinog\u0306lu, 2021), and we use data from Wikipedia to train our model, thus we are potentially introducing similar biases into our models."
        },
        {
            "heading": "A Appendix",
            "text": ""
        },
        {
            "heading": "A.1 Transitivity rules",
            "text": "Figure 5 shows the standard temporal transitivity rules we apply to infer relations from paths through the temporal graph."
        },
        {
            "heading": "A.2 Model Selection",
            "text": "For the ERR method introduced in Section 3.2.1, we consider a document-time-to-question-time (DT2QT) subgraph that contains all the edges connecting document-time nodes to the question-time node, and a document-time-event-to-question-time (DTE2QT) subgraph that builds on the documenttime-to-question-time subgraph by adding all the edges from the document-event nodes to the question-time node. We do not fuse the entire temporal graph with ERR because doing so would significantly increase the length of the input. On average, this fusion will add a number of tokens equal to twice the number of edges because each edge needs to be represented by two special markers, e.g., <before> 2009 </before>.\nFor the GNN method, we consider both the entire temporal graph, and an \u201call time graph\u201d derived from the DT2QT subgraph, with additional edges for the temporal relations between each time expression node and all other nodes.\nWe also consider whether to use all six relations or only three relations, merging (BEFORE, AFTER, SIMULTANEOUS, INCLUDES, INCLUDED BY, OVERLAP) into (BEFORE, AFTER, and OVERLAP).\nWe used the TimeQA Easy and Hard development sets for model selections. Table 6 shows the results of model selection. For ERR, merging the relations down to 3 slightly decreases performance on TimeQA Hard, the DT2QT graph is slightly better for TimeQA Hard, and the DTE2QT graph is slightly better for TimeQA Easy. Since the DT2QT is simpler, we select this model as our ERR model.\nFor GNN, no models outperform LongT5 alone, regardless of whether the GNN was applied to the token embeddings or the final contextualized embeddings, and whether applied to simpler or more complex temporal graphs."
        },
        {
            "heading": "A.3 Confidence Intervals",
            "text": "We use the bootstrap resampling method to construct 95% confidence intervals on the test sets. The results are shown in Table 7."
        },
        {
            "heading": "A.4 Software Licenses",
            "text": "We train question answering systems to answer English Wikipedia time-sensitive questions. Upon publication, we will release our code under the\nMIT license. We list below the licenses of the data, software, and models we used. Our use is consistent with their intended uses.\n\u2022 Stanford CoreNLP: GNU General Public License Version 3 6. \u2022 CAEVO, Long-t5-tglobal-base model, HuggingFace Transformers: Apache License, Version 2.0 7. \u2022 TimeQA dataset: BSD 3-Clause License 8. \u2022 Pytorch: BSD-style license 9.\nA.5 Implementation Details\nWe use SUTime from Stanford CoreNLP V4.5.0 (Manning et al., 2014) to identify and normalize time expressions. We use the LongT5 implementation from Huggingface Transformers V4.20.1 (Wolf et al., 2020) and the LongT5 base model (250 million parameters) with transient-global attention checkpoint (long-t5-tglobal-base) from Google as the starting point for training. We follow the code provided in the FiD Github repository10 to preprocess the Natural Questions dataset. We create new tokens in the tokenizer and model vocabulary for special marker tokens such as <e>. We tune the learning rate r \u2208 {1\u00d710\u22125, 2\u00d710\u22125, 3\u00d710\u22125, 4\u00d7 10\u22125, 5\u00d710\u22125}, batch size b \u2208 {4, 8, 16, 32}, and number of RelGraphConv layers l \u2208 {1, 3, 6} on the development set of TimeQA and use early stopping to monitor the exact match metrics. We use ReLU as activation functions in RelGraphConv layers. We set the hidden state size of RelGraphConv layers to the same as LongT5-Base. All experiments are conducted on 4 Nvidia A6000 GPUs.\n6www.gnu.org/licenses/gpl-3.0.html 7www.apache.org/licenses/LICENSE-2.0 8/opensource.org/licenses/BSD-3-Clause 9github.com/pytorch/pytorch/blob/master/ LICENSE 10https://github.com/facebookresearch/FiD\nThe total GPU hours of experiments are around 160. We will make our code publicly available upon publication of the paper11.\nGraph Statistics The constructed graphs statistics are presented in Table 8.\nPerformance of the External Tools We use two tools: SUTime from Stanford CoreNLP and CAEVO. CAEVO\u2019s reported precision is 0.92 for event-time relations and 0.88 for time-time relations. The accuracy of SUTime in recognizing time expression types and values is 0.96 and 0.82, respectively."
        },
        {
            "heading": "A.6 Datasets",
            "text": "Table 9 presents the statistics of the datasets used for the experiments. Table 10 shows the input length of the LongT5 model before and after fusing the DT2QT sub-graph using the ERR method."
        },
        {
            "heading": "A.7 Temporal Relations",
            "text": "We visualize the temporal relations between the time intervals in Figure 6."
        },
        {
            "heading": "A.8 ChatGPT Prompts",
            "text": "We present the ChatGPT prompts we used in Table Table 11. Considering the overall input length constraint, for context documents in in-context learning examples, we use sentences containing answers as context for questions that have answers. For questions without answers, we randomly sample a sentence from the original context document as the context."
        },
        {
            "heading": "A.9 GPT-4 Results",
            "text": "Following the in-context learning setup described in Section 4.4, we replicate the experiment using\n11https://github.com/IntelLabs/multimodal_ cognitive_ai/tree/main/Fusing_Temporal_Graphs\nthe GPT-4 model. However, due to the costs of calling the commercial GPT-4 API, we only randomly sampled 100 examples each from TimeQA Easy and TimeQA Hard, resulting in a total of 200 samples for the experiment. The results are shown in Table 12. ERR method achieves similar performance improvements with GPT-4 as it does with ChatGPT (gpt-3.5-turbo)."
        },
        {
            "heading": "A.10 Additional Error Analysis",
            "text": "Table 13 presents error examples, in addition to the examples shown in Table 3."
        },
        {
            "heading": "A.11 Analysis of the GNN Fusion Method",
            "text": "Table 14 shows examples from TimeQA Hard where LongT5ERR is correct but LongT5GNN is incorrect."
        },
        {
            "heading": "A.12 Other Experimented Methods",
            "text": "The following are some of the methods we have tried but yielded lower performance than our main methods reported in Table 6.\n1. We tried to use the coreference resolution tools to process the context documents and then construct and fuse temporal graphs based on the processed text, but we found that the coreference resolution preprocessing hurt the performance of the models. 2. We tried to fuse constructed temporal graphs into FiD models using relation-aware attention (Wang et al., 2020), but we found that the fused FiD models performed almost the same as the non-fused FiD models. 3. Our preliminary study found that the performance of the models can be significantly improved if only the most relevant paragraph in the context document is used as the context.\nThus, we tried to train a cross-encoder-based ranker to rank the paragraphs in the context documents, but we found that the pipeline approach using a cross-encoder as a paragraphs ranker and a LongT5 as a reader was not as good as using LongT5 directly to generate answers end-to-end."
        }
    ],
    "title": "Fusing Temporal Graphs into Transformers for Time-Sensitive Question Answering",
    "year": 2023
}