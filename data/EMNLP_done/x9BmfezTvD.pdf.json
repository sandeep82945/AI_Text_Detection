{
    "abstractText": "Recent advances in weakly supervised text classification mostly focus on designing sophisticated methods to turn high-level human heuristics into quality pseudo-labels. In this paper, we revisit the seed matching-based method, which is arguably the simplest way to generate pseudo-labels, and show that its power was greatly underestimated. We show that the limited performance of seed matching is largely due to the label bias injected by the simple seed-match rule, which prevents the classifier from learning reliable confidence for selecting high-quality pseudo-labels. Interestingly, simply deleting the seed words present in the matched input texts can mitigate the label bias and help learn better confidence. Subsequently, the performance achieved by seed matching can be improved significantly, making it on par with or even better than the state-of-theart. Furthermore, to handle the case when the seed words are not made known, we propose to simply delete the word tokens in the input text randomly with a high deletion ratio. Remarkably, seed matching equipped with this random deletion method can often achieve even better performance than that with seed deletion. We refer to our method as SimSeed, which is publicly available .",
    "authors": [
        {
            "affiliations": [],
            "name": "Chengyu Dong"
        },
        {
            "affiliations": [],
            "name": "Zihan Wang"
        },
        {
            "affiliations": [],
            "name": "Jingbo Shang"
        }
    ],
    "id": "SP:51aafe1b67c706918d2ceb1adf756ea5a27600e7",
    "references": [
        {
            "authors": [
                "Devansh Arpit",
                "Stanislaw Jastrzebski",
                "Nicolas Ballas",
                "David Krueger",
                "Emmanuel Bengio",
                "Maxinder S. Kanwal",
                "Tegan Maharaj",
                "Asja Fischer",
                "Aaron C. Courville",
                "Yoshua Bengio",
                "Simon Lacoste-Julien"
            ],
            "title": "A closer look at memorization in deep",
            "year": 2017
        },
        {
            "authors": [
                "Xiaoyi Chen",
                "Ahmed Salem",
                "Michael Backes",
                "Shiqing Ma",
                "Yang Zhang."
            ],
            "title": "Badnl: Backdoor attacks against nlp models",
            "venue": "ICML 2021 Workshop on Adversarial Machine Learning.",
            "year": 2021
        },
        {
            "authors": [
                "Kevin Clark",
                "Minh-Thang Luong",
                "Quoc V. Le",
                "Christopher D. Manning."
            ],
            "title": "Electra: Pre-training text encoders as discriminators rather than generators",
            "venue": "ArXiv, abs/2003.10555.",
            "year": 2020
        },
        {
            "authors": [
                "Jiazhu Dai",
                "Chuanshuai Chen",
                "Yufeng Li."
            ],
            "title": "A backdoor attack against lstm-based text classification systems",
            "venue": "IEEE Access, 7:138872\u2013138878.",
            "year": 2019
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Sebastian Duerr"
            ],
            "title": "Seduerr/t5-pawraphrase \u00b7 hugging face",
            "year": 2021
        },
        {
            "authors": [
                "Yarin Gal",
                "Zoubin Ghahramani."
            ],
            "title": "Dropout as a bayesian approximation: Representing model uncertainty in deep learning",
            "venue": "ArXiv, abs/1506.02142.",
            "year": 2015
        },
        {
            "authors": [
                "Tianyu Gao",
                "Xingcheng Yao",
                "Danqi Chen."
            ],
            "title": "Simcse: Simple contrastive learning of sentence embeddings",
            "venue": "ArXiv, abs/2104.08821.",
            "year": 2021
        },
        {
            "authors": [
                "Chuan Guo",
                "Geoff Pleiss",
                "Yu Sun",
                "Kilian Q Weinberger."
            ],
            "title": "On calibration of modern neural networks",
            "venue": "International Conference on Machine Learning, pages 1321\u20131330. PMLR.",
            "year": 2017
        },
        {
            "authors": [
                "Geoffrey E. Hinton",
                "Nitish Srivastava",
                "Alex Krizhevsky",
                "Ilya Sutskever",
                "Ruslan Salakhutdinov."
            ],
            "title": "Improving neural networks by preventing co-adaptation of feature detectors",
            "venue": "ArXiv, abs/1207.0580.",
            "year": 2012
        },
        {
            "authors": [
                "Jinchi Huang",
                "Lie Qu",
                "Rongfei Jia",
                "Binqiang Zhao."
            ],
            "title": "O2u-net: A simple noisy label detection approach for deep neural networks",
            "venue": "Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 3326\u20133334.",
            "year": 2019
        },
        {
            "authors": [
                "Keita Kurita",
                "Paul Michel",
                "Graham Neubig."
            ],
            "title": "Weight poisoning attacks on pre-trained models",
            "venue": "arXiv preprint arXiv:2004.06660.",
            "year": 2020
        },
        {
            "authors": [
                "Dheeraj Mekala",
                "Chengyu Dong",
                "Jingbo Shang."
            ],
            "title": "Lops: Learning order inspired pseudo-label selection for weakly supervised text classification",
            "venue": "ArXiv, abs/2205.12528.",
            "year": 2022
        },
        {
            "authors": [
                "Dheeraj Mekala",
                "Jingbo Shang."
            ],
            "title": "Contextualized weak supervision for text classification",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 323\u2013 333.",
            "year": 2020
        },
        {
            "authors": [
                "Dheeraj Mekala",
                "Xinyang Zhang",
                "Jingbo Shang."
            ],
            "title": "Meta: Metadata-empowered weak supervision for text classification",
            "venue": "Conference on Empirical Methods in Natural Language Processing.",
            "year": 2020
        },
        {
            "authors": [
                "Yu Meng",
                "Jiaming Shen",
                "Chao Zhang",
                "Jiawei Han."
            ],
            "title": "Weakly-supervised neural text classification",
            "venue": "Proceedings of the 27th ACM International Conference on Information and Knowledge Management, pages 983\u2013992. ACM.",
            "year": 2018
        },
        {
            "authors": [
                "Yu Meng",
                "Yunyi Zhang",
                "Jiaxin Huang",
                "Chenyan Xiong",
                "Heng Ji",
                "Chao Zhang",
                "Jiawei Han."
            ],
            "title": "Text classification using label names only: A language model self-training approach",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural",
            "year": 2020
        },
        {
            "authors": [
                "Bo Pang",
                "Lillian Lee."
            ],
            "title": "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales",
            "venue": "Proceedings of the ACL.",
            "year": 2005
        },
        {
            "authors": [
                "Seongmin Park",
                "Jihwa Lee."
            ],
            "title": "Lime: Weaklysupervised text classification without seeds",
            "venue": "ArXiv, abs/2210.06720.",
            "year": 2022
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam M. Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J. Liu."
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "ArXiv, abs/1910.10683.",
            "year": 2019
        },
        {
            "authors": [
                "Mamshad Nayeem Rizve",
                "Kevin Duarte",
                "Yogesh Singh Rawat",
                "Mubarak Shah."
            ],
            "title": "In defense of pseudo-labeling: An uncertainty-aware pseudo-label selection framework for semi-supervised learning",
            "venue": "ArXiv, abs/2101.06329.",
            "year": 2021
        },
        {
            "authors": [
                "Fangbo Tao",
                "Chao Zhang",
                "Xiusi Chen",
                "Meng Jiang",
                "Tim Hanratty",
                "Lance Kaplan",
                "Jiawei Han."
            ],
            "title": "Doc2cube: Automated document allocation to text cube via dimension-aware joint embedding",
            "venue": "Dimension, 2016:2017.",
            "year": 2015
        },
        {
            "authors": [
                "Jonathan Tompson",
                "Ross Goroshin",
                "Arjun Jain",
                "Yann LeCun",
                "Christoph Bregler."
            ],
            "title": "Efficient object localization using convolutional networks",
            "venue": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 648\u2013656.",
            "year": 2014
        },
        {
            "authors": [
                "Zihan Wang",
                "Dheeraj Mekala",
                "Jingbo Shang."
            ],
            "title": "X-class: Text classification with extremely weak supervision",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-",
            "year": 2021
        },
        {
            "authors": [
                "Lu Zhang",
                "Jiandong Ding",
                "Yi Xu",
                "Yingyao Liu",
                "Shuigeng Zhou."
            ],
            "title": "Weakly-supervised text classification based on keyword graph",
            "venue": "Conference on Empirical Methods in Natural Language Processing.",
            "year": 2021
        },
        {
            "authors": [
                "Xiang Zhang",
                "Junbo Zhao",
                "Yann LeCun."
            ],
            "title": "Character-level convolutional networks for text classification",
            "venue": "Advances in neural information processing systems, 28:649\u2013657.",
            "year": 2015
        },
        {
            "authors": [
                "Yuan Zhang",
                "Jason Baldridge",
                "Luheng He."
            ],
            "title": "Paws: Paraphrase adversaries from word scrambling",
            "venue": "ArXiv, abs/1904.01130.",
            "year": 2019
        },
        {
            "authors": [
                "Xuandong Zhao",
                "Siqi Ouyang",
                "Zhiguo Yu",
                "Ming Wu",
                "Lei Li."
            ],
            "title": "Pre-trained language models can be fully zero-shot learners",
            "venue": "arXiv preprint arXiv:2212.06950.",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Recently, weakly supervised text classification, because of its light requirement of human effort, has been extensively studied (Mekala and Shang, 2020; Wang et al., 2021; Zhao et al., 2022; Meng et al., 2020; Zhang et al., 2021; Meng et al., 2018; Tao et al., 2015; Park and Lee, 2022). Specifically, it requires only high-level human guidance to label the text, such as a few rules provided by human experts that match the text with the labels. These labels, which are not necessarily correct and are\n\u2217 Corresponding author. 1https://github.com/shwinshaker/\nSimSeed\nthus often dubbed as pseudo-labels, are then employed to train the text classifier following a standard fully supervised or semi-supervised training framework. State-of-the-art methods mostly focus on designing sophisticated human guidance to obtain high-quality labels, through contextualized weak supervision (Mekala and Shang, 2020), prompting language models (Meng et al., 2020; Zhao et al., 2022), clustering for soft matching (Wang et al., 2021), and complicated interactions between seeds (Zhang et al., 2021).\nIn this paper, we revisit the seed matching-based weak supervision (denoted as Vanilla) (Mekala and Shang, 2020; Meng et al., 2018; Tao et al., 2015), which is arguably the simplest way to generate pseudo-labels, and show that its power was greatly underestimated. Specifically, this simple method matches input text with a label if the user-provided seed words of this label are contained in the input text. For example, in sentiment analysis, a document will be labeled as \u201cpositive\u201d if it contains the word \u201chappy\u201d. A text classifier is then trained based on all these pseudo-labels.\nOne can expect a non-trivial number of errors in the seed matching-based pseudo-labels. In an ideal case, if we can select only those correct pseudolabels for training, the accuracy of the text classifier can be significantly boosted. For example, on the 20 Newsgroups dataset, ideally with only those correct pseudo-labels one can get an accuracy of 90.6%, compared to 80.1% obtained on all pseudolabels (see more in Section 4). In practice, to select those correct labels, a common way is to use the confidence score of a classifier trained on pseudolabels (Rizve et al., 2021). However, those highconfidence pseudo-labels may not be correct in the weakly-supervised setting, likely because the classifier may fail to learn reliable confidence on these noisy pseudo-labels (Mekala et al., 2022).\nIn this paper, we take a deep dive into this problem and find that, surprisingly, the high noise rate\namong the pseudo-labels is often not an obstacle to learning reliable confidence at all. In fact, on a set of synthesized pseudo-labels where the noise rate is exactly the same as those given by seed matching, but the noisy labels are generated by randomly flipping true labels into other classes, the confidence learned by a classifier can genuinely reflect the correct labels, as shown in Figure 1.\nTherefore, we argue that the poor confidence learned on realistic pseudo-labels is largely attributed to the strong but likely erroneous correlation between the text and pseudo-label injected by the seed-matching rule, which we refer to as label bias. Such a bias can be easily learned by the text classifier upon training, thus yielding spuriously high confidence on any text matching the seed word and ruining the pseudo-label selection.\nTo defend against such a label bias, we propose to simply delete the seed words present in the text upon training a classifier on the pseudolabeled data, which effectively prevents the classifier from learning the biased correlation between seeds and the corresponding pseudo-labels. As shown in Figure 1, such a simple seed deletion method can significantly improve the confidence score of the trained classifier and thus help select pseudo-labels with fewer label errors at every selection ratio. Empirical results verify that these\nless noisy pseudo-labels can indeed improve the classification accuracy significantly, making seed matching-based weak supervision on par with or sometimes even better than the state-of-the-art.\nWe further investigate the scenario where the seed words are not made known. We propose to delete every word token in the input text randomly and independently. This simple random deletion method can improve confidence learning even more as shown in Figure 1. Our theoretical analysis also shows that this random deletion method can mitigate the label bias with a high probability and therefore recover the seed deletion in effect. It is worth noting that both of these methods introduce no additional hyperparameters.\nIn summary, our contributions are as follows. \u2022 We revisit the seed matching-based weak super-\nvision and find that its effectiveness is mainly limited by the label bias injected by the seedmatching rule. \u2022 We show that simply deleting seed words from the pseudo-labeled texts can significantly alleviate the label bias and improve the confidence estimation for pseudo-label selection, as well as end-to-end classification accuracy achieved by seed matching, on par with or even better than the state-of-the-art. \u2022 We further propose the random deletion method to handle the case when the seed words are unknown and demonstrate its effectiveness both empirically and theoretically."
        },
        {
            "heading": "2 Preliminaries and Related Work",
            "text": "Seed matching as simple weak supervision. Seed matching (Meng et al., 2018) is probably one of the simplest weak supervision. Specifically, for each label class, a user provides a set of seed words that are indicative of it. A given document is annotated as the label class whose seed words appear in the document, or annotated as the label class whose seed words appear most frequently if multiple such label classes exist. Sophisticated weak supervisions have also been proposed to generate pseudo-labels with better quality, such as meta data (Mekala et al., 2020), context (Mekala and Shang, 2020), sentence representation (Wang et al., 2021), predictions of masked language models (Meng et al., 2020) and keyword-graph predictions (Zhang et al., 2021). Confidence learning matters for pseudo-label selection. Since label errors prevail in the pseudolabels generated by weak supervision, it is often\nnecessary to select the pseudo-labels before incorporating them into training (Wang et al., 2021; Mekala et al., 2022). A common method to select those pseudo-labels is to use the model confidence, namely the probability score associated with a deep classifier\u2019s prediction, to determine whether a given pseudo-label is correct or not (Guo et al., 2017). However, such confidence often cannot genuinely reflect the correctness of the pseudo-label generated by weak supervision, in that pseudolabels with high confidence are not necessarily correct (Mekala et al., 2022) Backdoor attack and defense. A problem related to seed matching is the backdoor attack for text classification based on trigger words (Dai et al., 2019; Kurita et al., 2020; Chen et al., 2021). Such attacks corrupt a dataset by inserting a particular word (i.e., trigger) into several documents and change their corresponding labels as ones specified by the attacker. A model fine-tuned on such a dataset will predict the label specified by the attacker whenever a document contains the trigger word. This is largely because the model would overfit the malicious correlation between the trigger word and the specified label, which is similar to the problem when learning pseudo-labels generated by seed matching. Therefore, trigger-based backdoor attacks may be defended by the methods proposed in this work as well, especially random deletion since the attacker will not reveal the trigger word."
        },
        {
            "heading": "3 Method",
            "text": ""
        },
        {
            "heading": "3.1 Seed deletion",
            "text": "We describe the details of seed deletion. Specifically, we denote an input document composed of a set of words as x = {t1, t2,\u22ef, tn} and its pseudolabel given by seed matching as y\u0303. We denote the set of seed words from class y as Sy. Now for each document in the pseudo-labeled dataset, we generate a corrupted document x\u0302 by deleting any seed word in x that is associated with its pseudo-label, namely x\u0302 = {t\u2223t \u2208 x, t \u2209 Sy\u0303}. We then train a classifier \u03b8\u0302 on the corrupted dataset D\u0302 = {(x\u0302, y\u0303)} and use its confidence score at the pseudo-label P\u03b8\u0302(y\u0303\u2223x) as an uncertainty measure to select the correct pseudo-labels.\nNote that when generating the uncertainty measure on a (document, pseudo-label) pair, one can either evaluate the classifier on the original document or the corrupted document. Empirically we found that evaluating the classifier on the original\ndocument would produce a minor gain."
        },
        {
            "heading": "3.2 Random deletion",
            "text": "In real-world applications, the seed words provided by the user may not always be accessible due to privacy concerns or simply because they are lost when processing and integrating the data. We show that it is still feasible to perform seed deletion in a probabilistic manner without knowing seed words, while remaining effective for confidence-based pseudolabel selection.\nTo achieve this, in fact, we only have to delete the words randomly and independently in a given document. Specifically, give a deletion ratio p, for every document x = {t1, t2,\u22ef, tn}, we randomly sampled a few positions M = {i1, i2,\u22ef, i\u2308pn\u2309}, where \u2308\u22c5\u2309 denotes the ceiling of a number. We then generate a corrupted document by deleting words at those positions, namely x\u0302 = {ti\u2223i \u2208 {1, 2,\u22ef, n}, i \u2209 M}. Now on the corrupted dataset D = {(x\u0302, y\u0303)}, we can train a classifier \u03b8\u0302 and utilize its confidence score P\u03b8\u0302(y\u0303\u2223x) for pseudolabel selection, similar to seed deletion. Random deletion as a probabilistic seed deletion. Despite its simplicity, we show with high probability, random deletion can mitigate the label bias induced by seed matching. The intuition here is that since the document only contains one or a few seed words, by random deletion it is very likely we can delete all seed words while retaining at least some other words that can still help learning.\nSpecifically, we consider a particular type of corrupted document x\u0302 that contains no seed word, i.e., x\u0302 \u2229 Sy\u0303 = \u2205, but contains at least one word that is indicative of the true class, i.e., x\u0302 \u2229 Cy \u2260 \u2205, where Cy denotes the set of words that are indicative of the class y. Since such a document no longer contains the seed word, its pseudo-label is not spuriously correlated with the text. At the same time, it contains class-indicative words that can help the classifier learn meaningful features.\nWe then investigate the probability that a document becomes such a particular type after random deletion. We term such probability as the seeddeletion rate rSD, which is defined as\nrSD \u2236= P (1(x\u0302 \u2229 Sy\u0303 = \u2205, x\u0302 \u2229 Cy \u2260 \u2205)), (1)\nwhere 1(\u22c5) is the indicator function. In an ideal case where rSD = 1, we can completely recover the effect of seed deletion on eliminating label bias.\nNow since each word in the document is independently deleted, we have\nrSD = p ns \u22c5 (1 \u2212 pnc), (2)\nwhere ns \u2254 \u2223Sy\u0303\u2223 denotes the number of seed words in the document and nc \u2254 \u2223Cy\u0303\u2223 denotes the number of words in the document that are indicative of the class. One may find that when nc \u226b ns, rSD can be quite close to 1 as long as p is large. Estimate the best deletion ratio. We estimate the best deletion ratio for random deletion based on some reasonable assumptions. First, it is easy to see that based on Eq. (2), the optimal deletion ratio is\np \u2217 = ( nsns + nc ) 1 nc , (3)\nwhich depends on both the number of seed words ns and the number of class-indicative words nc in the document. For ns, we can simply set it as 1 since the pseudo-label of a document is usually determined by one or two seed words. For nc, we assume that all words in a document are indicative of the true class, except stop words and punctuation. These estimations are acceptable as p\u2217 is almost always close to 1 and is quite robust to the change of ns and nc as long as nc is large (See Figure 2). This condition is likely to be true for realistic datasets (See Table 1). Note that for simplicity, we set one single deletion ratio for a specific dataset. Thus we set nc as the median number of class-indicative words over all documents in a dataset."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Experiment setup",
            "text": "We evaluate the performance of seed word matching equipped with seed deletion or random deletion on text classification.\nDatasets. We report the text classification performance on the following datasets, including New York Times (NYT), 20 Newsgroups (20News), AGNews (Zhang et al., 2015), Rotten tomatoes (Pang and Lee, 2005), as well as NYT and 20News datasets with their fine-grained labels respectively. We select these datasets as they cover diverse data properties in text classification, such as topic classification and sentiment analysis, long and short input documents, coarse-grained and fine-grained labels, and balanced and imbalanced label distributions.\nFor seed word matching, we consider the seed words used in (Mekala and Shang, 2020; Wang et al., 2021). Table 1 shows the statistics of these datasets and the corresponding pseudo-labels given by seed matching. Training setting. We adhere to the following experiment settings for all methods unless otherwise specified. We utilize BERT (bert-base-uncased) (Devlin et al., 2019) as the text classifier since we found that BERT can produce reliable confidence estimates with our methods in our experiments.\nFor pseudo-label selection, we select 50% of the high-quality pseudo-labels for all methods and datasets. For random deletion specifically, we set the deletion ratio following the estimation in Section 3.2. The estimated best deletion ratio of each dataset can be found in Figure 3.\nFinally, we employ the standard self-training protocol to utilize both the documents labeled by weak supervision and additional documents that are not labeled. Note that if we selected a subset of pseudolabels before self-training, those pseudo-labeled documents that were not selected will be merged into unlabeled documents. For the self-training process specifically, we train a text classifier on the labeled documents and generate predictions on unlabeled documents. The top \u03c4 fraction of predictions with the highest confidence are then treated as new pseudo-labels and will be merged with the existing pseudo-labels for another training. In our experiments, we conduct this self-training process for 5 iterations.\nNote that one can use BERT to select highquality pseudo-labels alone following our methods while employing advanced text classifiers for subsequent self-training, which may further improve the performance. Comparative methods. We compare our proposed\nmethod with the following baselines.\n\u2022 Vanilla: Self-training on all the pseudo-labeled provided by seed matching, without pseudo-label selection. \u2022 Standard confidence: Train a classifier on all the pseudo-labeled documents and use its confidence score to select a subset of high-quality pseudolabels. \u2022 O2U-Net (Huang et al., 2019): Train a classifier on all the pseudo-labeled documents and use the normalized loss of each document throughout the training as a metric to select pseudo-labels. \u2022 LOPS (Mekala et al., 2022): Train a classifier on all the pseudo-labeled documents and use the learning order cached during training to select pseudo-labels. We follow the setting recommended in their paper and set \u03c4 = 50%. \u2022 Oracle\u2217: Based on the true labels, we select only those correct pseudo-labels for self-training. Note that this is not a realistic method and is used only for comparison.\nWhenever it is necessary to train a classifier to obtain the confidence, we train for 4 epochs, in line with the setting in LOPS."
        },
        {
            "heading": "4.2 Main results",
            "text": "Seed-based weak supervision. We present the classification performance achieved by different methods in Table 2. One may find that seed deletion and random deletion can significantly boost the performance of seed matching-based weaklysupervised classification. On some datasets (e.g., AGNews), random deletion can approach the oracle selection with almost no gap. This demonstrates the performance of the simple seed matching-based weak supervision is greatly underestimated.\nSeed deletion and random deletion are also on par with or significantly better than other pseudolabel selection methods including those using sophisticated confidence measures such as the normalized loss in O2U-Net and the learning order in LOPS. In fact, seed deletion and random deletion are still using the standard confidence score of a classifier to select pseudo-labels, albeit they first corrupt the pseudo-labeled documents for training the classifier. Nevertheless, the performance improvement compared to the standard confidence score is huge. For example, the improvement on NYT-Fine is as large as \u223c 20% in terms of MacroF1 and \u223c 40% in terms of Micro-F1. This demonstrates that confidence-based pseudo-label selection is greatly underestimated.\nCompare with sophisticated weak supervision. In Table 3, we compare the performance of seed word matching equipped with seed word deletion or random deletion with those methods using sophisticated weak supervision sources, listed as follows.\n\u2022 ConWea (Mekala and Shang, 2020) uses pretrained language models to contextualize the weak supervision in an iterative manner. \u2022 X-Class (Wang et al., 2021) learns class-oriented document representations based on the label surface names. These document representations are aligned to the classes to obtain pseudo labels. \u2022 LOTClass (Meng et al., 2020) obtains synonyms for the class names using pretrained language models and constructs a category vocabulary for each class, which is then used to pseudo-label the documents via string matching. \u2022 ClassKG (Zhang et al., 2021) constructs a keyword graph to discover the correlation between keywords. Pseudo-labeling a document would be translated into annotating the subgraph that represents the document. \u2022 LIME (Park and Lee, 2022) combines seed matching with an entailment model to better pseudo-label documents and refine the final model via self-training.\nFor each method, we report the results obtained directly from the corresponding paper. If the results on some datasets are not reported in the original paper, we cite the results in follow-up papers if there are any. We found that with seed deletion or random deletion, seed word matching can be almost as good as or even better than those sophisticated weak supervisions. We thus believe seed word matching can be a competitive baseline and should be considered when developing more complicated weak supervisions.\nAlternative seed-agnostic debiasing methods. We explore alternative methods to delete the seed words and mitigate the label bias in seed matchingbased weak supervision, without knowing the seed words. We consider the following alternatives. \u2022 MLM-replace: We randomly mask a subset of\nwords in the document and use BERT to predict the masked words. The document is then corrupted by replacing the masked words with the predictions. This follows the idea of random deletion to delete the seed words probabilistically. Such a method is widely used in other applications (Gao et al., 2021; Clark et al., 2020). \u2022 Paraphrase: We generate the paraphrase of a document using the T5 model (Raffel et al., 2019) fine-tuned on a paraphrase dataset APWS (Zhang et al., 2019). We use the publicly available implementation at (Duerr, 2021). This is a straightforward method to delete the seed words. Since these alternative methods only serve as a reference for our main methods, we search their best hyperparameter, namely the mask ratio for MLM-replace and the token-generation temperature for paraphrase respectively. As shown in Table 2, these alternative methods can work as well as or better than random deletion. However, in practice, we would prefer using random deletion since it requires no extra model or knowledge source."
        },
        {
            "heading": "4.3 Study on random deletion",
            "text": "Deletion ratio in random deletion. We verify whether our estimation of the best deletion ratio is reasonable. In Figure 3, we modulate the deletion ratio and check the classification performance of random deletion for different datasets. One can find that as the deletion ratio increases, the performance first increases and then decreases, which is aligned\nwith the trend of the seed-deletion rate rSD analyzed in Section 3.2. The performance peaks when the deletion ratio is large (\u2273 0.9), which matches our estimation of the best deletion ratio. Furthermore, one may find that the best deletion ratio is relatively smaller for datasets with a shorter sequence length (e.g., AGNews and Rotten-Tomatoes), compared to that for datasets with a long sequence length (e.g., 20News and NYT), which is also predicted by our estimation. How does random deletion work?. One may notice that in Table 2, random deletion can outperform seed deletion on a few datasets. This indicates that random deletion has an additional regularization effect on top of deleting seeds, potentially due to more intense data augmentation.\nRandom Deletion\nRandom Deletion (Retain seeds)\nRandom Deletion (Delete all seeds)\n20News-Coarse\n20News-Fine\nHowever, we note that random deletion works not entirely because of this additional regularization effect. To show this, we conduct ablation experiments with two additional methods. The first is random deletion but with the seed words always retained in the document. The second is random deletion but with seed words first deleted completely. For a fair comparison, we search the best deletion ratio for these different methods including the\nstandard random deletion. We experiment on two representative datasets including 20News-Coarse and 20News-Fine due to computational constraints.\nFigure 4 shows that when seed words are always retained, random deletion achieves significantly worse performance than the standard random deletion, although the former is merely deleting one or two words fewer. On the other hand, when seed words are already deleted, further random deletion only slightly improves the performance compared to the standard random deletion. These pieces of evidence demonstrate that the benefit of random deletion may be partly attributed to a regularization effect, but the deletion of seeds and thus the mitigation of label bias is still one important factor. Compare with additional regularization methods. Since random deletion may introduce an ad-\n83 84 85 86 87 88 Macro-F1\nRandom Deletion\nDrop (all)\nDrop (wd-embed)\nDrop2D (wd-embed)\nDrop2D (embed)\n20News-Coarse\n70 72 74 76 78 Macro-F1\n20News-Fine\nFigure 5: Classification performance using dropout as a regularization method for pseudo-label selection. We try two types of dropout including Dropout (\u201cDrop\u201d) and Dropout-2D (\u201cDrop2D\u201d). We try dropout at various positions in the transformer architecture, including all dropouts layers in the original transformer (\u201call\u201d), the embedding layer only (\u201cembed\u201d), and the word embedding layer only (\u201cwd embed\u201d).\nditional regularization effect, we compare it with other regularization methods that can potentially reduce the label bias. We will mainly compare different types of dropout (see below) that are widely\nused in classification tasks, since it is mostly similar to random deletion. We defer other commonly seen regularization methods to the appendix. We consider applying dropout to different positions in the transformer model. For a fair comparison, we search the best dropout ratio for these dropout methods, as well as the best deletion ratio for our random deletion. We experiment on two representative datasets due to computational constraints. \u2022 Dropout (Hinton et al., 2012) is a classic regu-\nlarization method to prevent overfitting. We simply utilize the dropout layers built in the original transformer architecture, including those after the embedding layers, self-attention layers, and feedforward layers, following previous work (Gao et al., 2021). \u2022 Dropout-2D (Tompson et al., 2014) is different from vanilla Dropout in that it drops the entire channel as a whole. We only apply this to the embedding layer in the transformer to drop the entire embedding of a word or a position.\nAs shown in Figure 5, random deletion consistently outperforms other regularization methods. The only regularization method that can compete with random deletion is Dropout-2D applied on the word embedding layer specifically. However, one may note that this dropout variation is in fact almost equivalent to random deletion since the entire embedding of a word will be randomly dropped. These again demonstrate that random deletion works not simply because of a regulariza-\ntion effect. Case study. We manually inspect the pseudolabeled documents after random deletion to see if the label bias can be mitigated. In Table 4, we randomly pick some example documents after random deletion and find that the seed words are indeed deleted and some class-indicative words are still present to allow effective classification."
        },
        {
            "heading": "5 Conclusion and Future Work",
            "text": "In this paper, we revisit the simple seed matchingbased weakly supervised text classification method and show that if its pseudo-labels are properly debiased, it can achieve state-of-the-art accuracy on many popular datasets, outperforming more sophisticated types of weak supervision. Specifically, our controlled experiments show that confidence-base selection of seed matching-based pseudo-labels is ineffective largely because of the label bias injected by the simple, yet erroneous seed-match rule. We propose two effective debiasing methods, seed deletion, and random deletion, which can mitigate the label bias and significantly improve seed matchingbased weakly supervised text classification.\nIn future work, we plan to extend this debiasing methodology to broader problems and methods. For example, for weakly supervised text classification, we wish to explore a generalization of the debiasing strategy to more sophisticated types of weak supervision. It will also be interesting to develop a backdoor defense framework around the\nproposed methods, especially random deletion.\nLimitations\nWe have shown that randomly deleting the words work well for seed-matching-based weak supervision without knowing the seed words. However, this idea might not generalize straightforwardly to more sophisticated types of weak supervision. We have tried to apply random deletion to X-Class, but have not observed a significant improvement in the text classification performance. We hypothesize that this is because the pseudo-labels in X-Class are not generated based on seed word matching, but rather based on the similarity between the label embeddings provided by pretrained language models. We believe a label debiasing method universally applicable to all types of weak supervision is still under-explored.\nEthical Consideration\nThis paper analyzes the difficulty of identifying label errors in the pseudo-labels generated by simple seed-matching weak supervision. This paper proposed methods to better identify such label errors and improve weakly supervised text classifiers. We do not anticipate any major ethical concerns."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank the anonymous reviewers for their helpful feedback. Our work is sponsored in part by NSF CAREER Award 2239440, NSF Proto-OKN Award 2333790, NIH Bridge2AI Center Program under award 1U54HG012510-01, Cisco-UCSD Sponsored Research Project, as well as generous gifts from Google, Adobe, and Teradata. Any opinions, findings, and conclusions or recommendations expressed herein are those of the authors and should not be interpreted as necessarily representing the views, either expressed or implied, of the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for government purposes not withstanding any copyright annotation hereon."
        },
        {
            "heading": "A Appendix",
            "text": "Effect of selection ratio. As mentioned before, our methods do not introduce additional hyperparameters. Nevertheless, for pseudo-label selection in general, the selection fraction could be an important hyperparameter as the noise rate in the selected subset of pseudo-labels can vary significantly if we select different fractions, as also shown in Figure 1. Therefore, we check the performance of the standard confidence-based pseudo-label selection and the confidence-based selection equipped with seed deletion and random deletion, as the selection fraction varies. Figure 6 shows that our proposed methods are consistently better than standard confidence and achieve relatively robust performance as the selection fraction varies. The performance peaks when the selection fraction is moderate (\u223c 50%) for different datasets.\nExperiments on additional confidence regularization methods. We experiment on additional methods for regularizing the confidence learning of the text classifier, including the following.\n\u2022 MC-Dropout (Gal and Ghahramani, 2015) randomizes the network inference process by dropping intermediate activations. The average output over multiple inferences is utilized as a more reliable confidence score.\n\u2022 Early stopping is often utilized as a regularization to help mitigate overfitting. Empirically, it is observed that an early-stopped model is less prone to learning noisy data (Arpit et al., 2017).\nHere, we treat each method as a baseline and compare it with the corresponding method combined with random deletion. For each method, we modulate its most important hyperparameter, namely number of passes for MC-Dropout and number of\ntraining epochs for early stopping respectively. As shown in Figures 7 and 8, random deletion consistently outperforms the baseline for different confidence regularization methods. Random deletion also achieves more robust performance across different hyperparameter settings, which is important for weakly-supervised classification since we often lack a large clean dataset to select the best hyperparameter."
        }
    ],
    "title": "Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak Supervision for Text Classification",
    "year": 2023
}