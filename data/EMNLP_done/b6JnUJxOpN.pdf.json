{
    "abstractText": "Real-world Temporal Knowledge Graphs keep growing with time and new entities and facts emerge continually, necessitating a model that can extrapolate to future timestamps and transfer knowledge for new components. Therefore, our work first dives into this more realistic issue, lifelong TKG reasoning, where existing methods can only address part of the challenges. Specifically, we formulate lifelong TKG reasoning as a temporal-path-based reinforcement learning (RL) framework. Then, we add temporal displacement into the action space of RL to extrapolate for the future and further propose a temporal-rule-based reward shaping to guide the training. To transfer and update knowledge, we design a new edge-aware message passing module, where the embeddings of new entities and edges are inductive. We conduct extensive experiments on three newly constructed benchmarks for lifelong TKG reasoning. Experimental results show the outperforming effectiveness of our model against all well-adapted baselines.",
    "authors": [
        {
            "affiliations": [],
            "name": "Zhongwu Chen"
        },
        {
            "affiliations": [],
            "name": "Chengjin Xu"
        },
        {
            "affiliations": [],
            "name": "Fenglong Su"
        },
        {
            "affiliations": [],
            "name": "Zhen Huang"
        },
        {
            "affiliations": [],
            "name": "Yong Dou"
        }
    ],
    "id": "SP:74e5c6e925bde93ee3e510362465670b18248380",
    "references": [
        {
            "authors": [
                "Antoine Bordes",
                "Nicolas Usunier",
                "Alberto Garc\u00edaDur\u00e1n",
                "Jason Weston",
                "Oksana Yakhnenko."
            ],
            "title": "Translating embeddings for modeling multirelational data",
            "venue": "Advances in Neural Information Processing Systems 26: 27th Annual Conference on",
            "year": 2013
        },
        {
            "authors": [
                "Mingyang Chen",
                "Wen Zhang",
                "Zhen Yao",
                "Xiangnan Chen",
                "Mengxiao Ding",
                "Fei Huang",
                "Huajun Chen."
            ],
            "title": "Meta-learning based knowledge extrapolation for knowledge graphs in the federated setting",
            "venue": "Proceedings of the Thirty-First International Joint Con-",
            "year": 2022
        },
        {
            "authors": [
                "Zhongwu Chen",
                "Chengjin Xu",
                "Fenglong Su",
                "Zhen Huang",
                "Yong Dou."
            ],
            "title": "Incorporating structured sentences with time-enhanced bert for fullyinductive temporal relation prediction",
            "venue": "Proceedings of the 46th International ACM SIGIR Confer-",
            "year": 2023
        },
        {
            "authors": [
                "Zhongwu Chen",
                "Chengjin Xu",
                "Fenglong Su",
                "Zhen Huang",
                "Yong Dou."
            ],
            "title": "Meta-learning based knowledge extrapolation for temporal knowledge graph",
            "venue": "Proceedings of the ACM Web Conference 2023, WWW \u201923, page 2433\u20132443, New York, NY,",
            "year": 2023
        },
        {
            "authors": [
                "Yuanning Cui",
                "Yuxin Wang",
                "Zequn Sun",
                "Wenqiang Liu",
                "Yiqiao Jiang",
                "Kexin Han",
                "Wei Hu."
            ],
            "title": "Inductive knowledge graph reasoning for multi-batch emerging entities",
            "venue": "CIKM.",
            "year": 2022
        },
        {
            "authors": [
                "Yuanning Cui",
                "Yuxin Wang",
                "Zequn Sun",
                "Wenqiang Liu",
                "Yiqiao Jiang",
                "Kexin Han",
                "Wei Hu."
            ],
            "title": "Lifelong embedding learning and transfer for growing knowledge graphs",
            "venue": "AAAI.",
            "year": 2023
        },
        {
            "authors": [
                "Rajarshi Das",
                "Shehzaad Dhuliawala",
                "Manzil Zaheer",
                "Luke Vilnis",
                "Ishan Durugkar",
                "Akshay Krishnamurthy",
                "Alex Smola",
                "Andrew McCallum"
            ],
            "title": "2018. Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement",
            "year": 2018
        },
        {
            "authors": [
                "Alberto Garc\u00eda-Dur\u00e1n",
                "Sebastijan Dumancic",
                "Mathias Niepert."
            ],
            "title": "Learning sequence encoders for temporal knowledge graph completion",
            "venue": "Conference on Empirical Methods in Natural Language Processing.",
            "year": 2018
        },
        {
            "authors": [
                "Zhen Han",
                "Peng Chen",
                "Yunpu Ma",
                "Volker Tresp."
            ],
            "title": "Explainable subgraph reasoning for forecasting on temporal knowledge graphs",
            "venue": "Proc. of ICLR.",
            "year": 2021
        },
        {
            "authors": [
                "Woojeong Jin",
                "Meng Qu",
                "Xisen Jin",
                "Xiang Ren."
            ],
            "title": "Recurrent event network: Autoregressive structure inferenceover temporal knowledge graphs",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP",
            "year": 2020
        },
        {
            "authors": [
                "Jaehun Jung",
                "Jinhong Jung",
                "U Kang."
            ],
            "title": "Learning to walk across time for interpretable temporal knowledge graph completion",
            "venue": "Proc. of KDD.",
            "year": 2021
        },
        {
            "authors": [
                "Timoth\u00e9e Lacroix",
                "Guillaume Obozinski",
                "Nicolas Usunier."
            ],
            "title": "Tensor decompositions for temporal knowledge base completion",
            "venue": "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenRe-",
            "year": 2020
        },
        {
            "authors": [
                "Ren Li",
                "Yanan Cao",
                "Qiannan Zhu",
                "Guanqun Bi",
                "Fang Fang",
                "Yi Liu",
                "Qian Li."
            ],
            "title": "How does knowledge graph embedding extrapolate to unseen data: a semantic evidence view",
            "venue": "AAAI.",
            "year": 2021
        },
        {
            "authors": [
                "Zixuan Li",
                "Xiaolong Jin",
                "Saiping Guan",
                "Wei Li",
                "Jiafeng Guo",
                "Yuanzhuo Wang",
                "Xueqi Cheng."
            ],
            "title": "Search from history and reason for future: Two-stage reasoning on temporal knowledge graphs",
            "venue": "Proceedings of the 59th Annual Meeting of the Associa-",
            "year": 2021
        },
        {
            "authors": [
                "Zixuan Li",
                "Xiaolong Jin",
                "Wei Li",
                "Saiping Guan",
                "Jiafeng Guo",
                "Huawei Shen",
                "Yuanzhuo Wang",
                "Xueqi Cheng."
            ],
            "title": "Temporal knowledge graph reasoning based on evolutional representation learning",
            "venue": "Proceedings of the 44th International ACM SIGIR",
            "year": 2021
        },
        {
            "authors": [
                "Xi Victoria Lin",
                "Richard Socher",
                "Caiming Xiong."
            ],
            "title": "Multi-hop knowledge graph reasoning with reward shaping",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018, Brussels, Belgium, Octo-",
            "year": 2018
        },
        {
            "authors": [
                "Yushan Liu",
                "Yunpu Ma",
                "Marcel Hildebrandt",
                "Mitchell Joblin",
                "Volker Tresp."
            ],
            "title": "Tlogic: Temporal logical rules for explainable link forecasting on temporal knowledge graphs",
            "venue": "AAAI.",
            "year": 2022
        },
        {
            "authors": [
                "David Lopez-Paz",
                "Marc\u2019Aurelio Ranzato"
            ],
            "title": "Gradient episodic memory for continual learning",
            "venue": "In NIPS",
            "year": 2017
        },
        {
            "authors": [
                "Guanglin Niu",
                "Bo Li."
            ],
            "title": "Logic and commonsense-guided temporal knowledge graph completion",
            "venue": "AAAI.",
            "year": 2023
        },
        {
            "authors": [
                "Namyong Park",
                "Fuchen Liu",
                "Purvanshi Mehta",
                "Dana Cristofor",
                "Christos Faloutsos",
                "Yuxiao Dong."
            ],
            "title": "Evokg: Jointly modeling event time and network structure for reasoning over temporal knowledge graphs",
            "venue": "Proceedings of the Fifteenth ACM Interna-",
            "year": 2022
        },
        {
            "authors": [
                "Haohai Sun",
                "Jialun Zhong",
                "Yunpu Ma",
                "Zhen Han",
                "Kun He."
            ],
            "title": "TimeTraveler: Reinforcement learning for temporal knowledge graph forecasting",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages",
            "year": 2021
        },
        {
            "authors": [
                "Komal Teru",
                "Etienne Denis",
                "Will Hamilton."
            ],
            "title": "Inductive relation prediction by subgraph reasoning",
            "venue": "Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine",
            "year": 2020
        },
        {
            "authors": [
                "Th\u00e9o Trouillon",
                "Johannes Welbl",
                "Sebastian Riedel",
                "\u00c9ric Gaussier",
                "Guillaume Bouchard."
            ],
            "title": "Complex embeddings for simple link prediction",
            "venue": "International Conference on Machine Learning.",
            "year": 2016
        },
        {
            "authors": [
                "Hong Wang",
                "Wenhan Xiong",
                "Mo Yu",
                "Xiaoxiao Guo",
                "Shiyu Chang",
                "William Yang Wang."
            ],
            "title": "Sentence embedding alignment for lifelong relation extraction",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Hongwei Wang",
                "Hongyu Ren",
                "Jure Leskovec."
            ],
            "title": "Relational message passing for knowledge graph completion",
            "venue": "KDD \u201921, page 1697\u20131707, New York, NY, USA. Association for Computing Machinery.",
            "year": 2021
        },
        {
            "authors": [
                "Chengjin Xu",
                "Yung-Yu Chen",
                "Mojtaba Nayyeri",
                "Jens Lehmann."
            ],
            "title": "Temporal knowledge graph completion using a linear temporal regularizer and multivector embeddings",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the",
            "year": 2021
        },
        {
            "authors": [
                "Chengjin Xu",
                "Mojtaba Nayyeri",
                "Fouad Alkhoury",
                "Hamed Shariat Yazdi",
                "Jens Lehmann."
            ],
            "title": "TeRo: A time-aware knowledge graph embedding via temporal rotation",
            "venue": "Proceedings of the 28th International Conference on Computational Linguis-",
            "year": 2020
        },
        {
            "authors": [
                "Yi Xu",
                "Junjie Ou",
                "Hui Xu",
                "Luoyi Fu."
            ],
            "title": "Temporal knowledge graph reasoning with historical contrastive learning",
            "venue": "AAAI.",
            "year": 2023
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Knowledge Graphs (KGs) are constructed to store structured facts about human knowledge or the objective world, and formalize facts as entities e (nodes) and relations r (links) between them. Static Knowledge Graphs (SKGs) and Temporal Knowledge Graphs (TKGs) are two typical forms of KGs. SKGs store facts in the form of triples (es, r, eo) and TKGs extend triples to quadruples (es, r, eo, t), where t indicates the happening time. Since realworld events are usually ever-changing and associated with time, TKGs are naturally confronted with issues of continually emerging entities and facts in the future timestamps throughout their whole lifecycle (Chen et al., 2023a). Therefore, this paper investigates TKG link prediction task over incomplete TKGs in the lifelong setting, named lifelong\n*Corresponding Author\nTKG reasoning. Figure 1 is an example in dataset ICEWS14 for temporally growing TKGs.\nHowever, SKG reasoning methods (Trouillon et al., 2016) lack the consideration of temporal changing; conventional transductive TKG reasoning methods (Lacroix et al., 2020) need re-train for their closed-world assumption; and the latest inductive TKG reasoning methods (Chen et al., 2023b) treat emerging entities as simultaneous, oversimplifying the real scenario and thereby leading their genuine performance to be questionable. Hence, our proposed lifelong TKG reasoning issue is more challenging and realistic.\nWe formulate the lifelong TKG reasoning as a temporal-path-based RL framework and design the whole pipeline for extrapolating, transferring and updating. In the following, we introduce our targeted solutions and expound on their advantages over existing methods.\nFirst, we focus on the temporal displacement between timestamps of candidate edge and its preceding edge and add temporal displacement into RL action space. TKGE models (Xu et al., 2021) rely on embeddings of absolute timestamps and are only fit for the past timestamps. Obviously, they do not meet the requirements of lifelong learning. On the contrary, our used transferable temporal dis-\nplacement in RL can be extrapolated from known timestamps to arbitrary future timestamps based on the magnitude of the displacement. In addition, we further design a reward-shaping module based on temporal rules found by RL, which only have the temporal order constraints of relations. This module makes the reasoning get rid of particular entities and will still be applicable for future timestamps.\nSecondly, lifelong TKG reasoning can be considered as multiple consecutive inductive TKG reasoning processes. Recently, inductive TKG reasoning methods (Park et al., 2022; Xu et al., 2023) can only deal with future time, not new components, not to mention their ability to continuously learn as required in lifelong TKG reasoning. Therefore, we design a new edge-aware message passing module, which not only transfers learned relation types to initialize emerging entities, but also updates the embeddings of all entities and edges in new TKGs. We also use the embeddings of specific edges rather than immobile relation types, since we seek to explore the concrete environment for each fact to counteract the influence of rapid TKG growth.\nWe build three new benchmarks based on three popular datasets to simulate the lifelong TKG reasoning scenario. In the experiments, we carefully adapt existing baselines by empowering them with temporal extrapolation or knowledge transfer capabilities. In summary, our main contributions are:\n\u2022 To our knowledge, we are the first to pose and explore the more challenging and realistic lifelong TKG reasoning issue, which simulates growing TKGs in terms of timestamps, entities and facts, and we formulate it as a RL-based framework.\n\u2022 To solve the challenges of temporal extrapolation and knowledge transfer in lifelong TKG reasoning, we propose the targeted solutions: temporal displacement, temporal-rule-based reward shaping and an edge-aware message passing module.\n\u2022 We build three new benchmarks to evaluate our model. Experiments on temporal link prediction show that our model not only achieves the best average performance but also has progressively improving results on growing TKG snapshots."
        },
        {
            "heading": "2 Related Works",
            "text": ""
        },
        {
            "heading": "2.1 Inductive SKG Reasoning",
            "text": "Traditional SKG reasoning models, such as SKG Embedding (SKGE) methods, focus on the trans-\nductive setting where they are trained and tested in a fixed set of components. Recently, inductive SKG reasoning has drawn much attention. GraIL (Teru et al., 2020), SE-GNN (Li et al., 2021a) and MaKEr (Chen et al., 2022) are all GNNbased inductive reasoning models, from the points of view of subgraphs, data relevance and metalearning. PathCon (Wang et al., 2021) leverages relational message passing for relation prediction, however, we aim at the harder entity prediction. Moreover, MINERVA (Das et al., 2018) first introduces RL to search for the tail entity of each query end-to-end. Multi-Hop (Lin et al., 2018) advances MINERVA and does reward shaping based on SKGE methods."
        },
        {
            "heading": "2.2 Inductive TKG Reasoning",
            "text": "Inductive TKG reasoning models mainly deal with seen entities in the future time. xERTE (Han et al., 2021) is delicately designed to forecast future links by an iterative sampling of temporal neighbours. TGAP (Jung et al., 2021) introduces temporally relevant events in GNN for better explainability. For RL-based TKG reasoning, CluSTeR (Li et al., 2021b) regards RL as a clue searching stage, but it strips temporal dimension away from RL and then rearranges the clues in chronological order at the next temporal reasoning stage. However, they can not handle unseen entities emerging with time. TITer (Sun et al., 2021) further defines a relative time encoding to distinguish the same entity in different timestamps and leverage the query information to represent unseen entities. Different from the above models, we introduce temporal displacement of facts in the RL and propose relation-type-based knowledge transferring for emerging entities."
        },
        {
            "heading": "2.3 Lifelong KG Reasoning",
            "text": "Recently, how to retain and reuse previous knowledge in a new environment has become a research highlight (Wang et al., 2019). MBE (Cui et al., 2022) explores inductive SKG reasoning under the multi-batch emergence scenario, which is similar to the concept of lifelong KG reasoning without considering time. Next, LKGE (Cui et al., 2023) first formally studies lifelong SKG reasoning via transferring knowledge and using TransE (Bordes et al., 2013) as the base model. However, they did not pay attention to the crucial temporal factor in TKGs. To this end, we raise lifelong TKG reasoning, which involves both unseen components and future timestamps, making this issue challenging\nand realistic."
        },
        {
            "heading": "3 Methodology",
            "text": ""
        },
        {
            "heading": "3.1 Preliminaries",
            "text": "Growing TKGs in lifelong TKG reasoning can be viewed as a sequence of \u03c1 snapshots: G = (G1,G2, . . . ,G\u03c1), each of which, Gi, contains a collection of fact quadruples over a continuous time period and Gi = {Ei,Ri, Ti,Di}. Ei,Ri, Ti,Di are entity, relation, timestamp and fact sets, and Ei \u2acb Ei+1, Ri = Ri+1, ti < ti+1 (ti \u2208 Ti, ti+1 \u2208 Ti+1), and Di \u2229 Di+1 = \u2205. We use E\u2206i+1 = Ei+1 \u2212 Ei and Di+1 to denote the emerging entities and facts. The TKG link prediction task asks to predict the missing entities of the query edge in incomplete TKGs. For lifelong TKG reasoning, we leverage the TKG link prediction task above to train a new model Mi+1 by transferring and updating knowledge in Mi to fit E\u2206i+1 and Di+1. Specifically, Di in Gi is divided into a training set Fi, a validation set Vi and a test set Qi. After finishing the training on Fi and validation on Vi, the model Mi is evaluated on the accumulated test sets \u222aij=1Qj for overall assessments."
        },
        {
            "heading": "3.2 Model Overview",
            "text": "Figure 2 is the architecture of our model. Along a sequence of growing TKGs, our model transfers and updates knowledge iteratively from the previous TKG snapshot to the next one, avoiding re-training. Inside each Gi, we regard the reasoning as walk-based action selecting process. An agent starts from the query entity, constantly takes actions through temporal edges based on temporal displacement, and expects to reach the target entity within a limited number of steps (Section 3.3). To\nachieve knowledge transferring and updating, we inject embeddings of relation types into emerging entities enew, and then update all the embeddings of entities e and edges g in our proposed edge-aware message passing module (Section 3.4). Section 3.5 describes our designed temporal-rule-based reward shaping."
        },
        {
            "heading": "3.3 Reinforcement Learning Framework",
            "text": "For each edge, we add its reversed edge to Gi, making the reasoning traceable and controllable. For each entity e, we also add self-loop temporal edges at every timestamp to Gi, which allows the agent to stay in a place, and they work as stop actions."
        },
        {
            "heading": "3.3.1 Environment Setting",
            "text": "Our environment can be formulated as a Markov Decision Process (MDP) over TKGs and has the following components. We take Gi as an example.\nStates. Let Si and (eq, rq, ?, tq) denote all possible states of Gi and the query. At step m \u2208 [0,M ], the agent locates at entity em and timestamp tm, so the state sm = (em, tm, eq, rq, tq) \u2208 Si. Specifically, the initial state is s0 = (eq, tq, eq, rq, tq).\nTime-constrained Actions. Let Ai denote the action space of Gi. Let Ami denote the set of optional actions of sm in Gi. Compared with SKGs, the time dimension causes the action space of RL in TKGs extremely large. Hence, we add two temporal constraints to prune the action space, since facts closer to tm in the state sm under consideration are more likely to be directly relevant to the prediction:\nAmi = {(e\u2032, g\u2032, tm \u2212 t\u2032) | g\u2032 = (em, r\u2032, e\u2032, t\u2032) \u2208 Gi, tm \u2212 t\u2032 \u2264 T, t\u2032 \u2264 tm \u2264 tq } ,\n(1)\nwhere g\u2032 is a candidate edge, tm\u2212t\u2032 is the temporal displacement, T is a hyperparameter. Ami naturally considers reversed and self-loop temporal edges.\nTransitions. The transition function \u03c9 : Si \u00d7 Ai \u2192 Si is deterministic under Gi and updates the states depending on the selected actions.\nRewards. In the default formulation, agents receive reward Rb(sM )= I(eM == eans), where sM =(eM , tM , eq, rq, tq) is the final state, eans is the answer to the query and I is a binary indicator function. Our designed reward R(sM ) shaped by temporal rules will be described in Section 3.5."
        },
        {
            "heading": "3.3.2 Policy Network",
            "text": "First, the temporal displacement between timestamps of current state tm\u22121 (t0 = tq) and its subsequent action tm can integrally capture the timerelated dynamics. The temporal displacement is donated as \u03b4tm = tm\u22121 \u2212 tm \u2264 T . Secondly, because of temporally evolving TKGs, even if the relation types of two edges in Gi and Gi+1 are the same, their semantics can change considerably due to different surrounding environments. It is only by taking surrounding edges into account that we can understand their contextual semantics. Moreover, the above operations are also in line with the foundation of RL, which is constant interaction with the environment.\nTherefore, the input of policy network has three parts: uem ,ugm , \u03c4\u03b4tm \u2208 Rd, i.e., the embeddings of entity em, edge gm = (em\u22121, rm, em), and temporal displacement \u03b4tm (uem , ugm are obtained from edge-aware message passing module in Section 3.4, \u03c4\u03b4tm is transferred from Gi\u22121 and updated in Gi). Path history hm in Gi is encoded as follows:\nhm = LSTM(hm\u22121, [uem ,ugm , \u03c4\u03b4tm ]) ;\nh0 = LSTM (0, [ueq ,ur0 , \u03c4\u03b4tq ]), (2)\nwhere hm \u2208 R2d, ur0 \u2208 Rd is the embedding of the special starting relation r0, and \u03b4tq = 0. For a candidate next action a\u2032 = (e\u2032, g\u2032, \u03b4t\u2032) \u2208 Ami (\u03b4t\u2032 = tm\u2212t\u2032) in Eq. 1, we calculate the probability of its state transition based on the correlation of the action and the query in terms of entities and edges:\n\u03d5 ( a\u2032, sm ) = \u03bb\u27e8[ue\u2032 , \u03c4\u03b4t\u2032 ],WeEq\u27e9\n+(1\u2212 \u03bb) \u27e8[ug\u2032 , \u03c4\u03b4t\u2032 ],WgEq\u27e9;\nEq = ReLU ( Wq [ ueq ,urq , \u03c4\u03b4tq ,hm ]) ;\n\u03bb = \u03c3 ( W\u03bb [ ue\u2032 ,ug\u2032 , \u03c4\u03b4t\u2032 ,ueq ,urq , \u03c4\u03b4tq ,hm ]) ,\n(3)\nwhere We,Wg,Wq,W\u03bb are learnable matrices, \u27e8\u00b7, \u00b7\u27e9 is vector dot product. After scoring all actions, policy network \u03c0\u03b8(am+1|sm) is obtained through softmax."
        },
        {
            "heading": "3.3.3 Training and Optimization",
            "text": "We fix the search path length to M . In lifelong TKG reasoning, the policy network is trained by maximizing the expected reward over growing TKG snapshots G1,G2, . . . ,G\u03c1. Hence, our model is required to train over F1,F2, . . . ,F\u03c1 in turn:\nJ(\u03b8) = E(eq ,rq ,eans,tq)\u223cFi [Ea1,...,aM\u223c\u03c0\u03b8 [R(sM |eq,rq,tq)]], (4)\nwhere i \u2208 [1, \u03c1]. Then, we use the REINFORCE algorithm to iteratively optimize our model:\n\u2207\u03b8J(\u03b8)\u2248\u2207\u03b8 \u2211\nm\u2208[0,M ]\nR(sM |eq,rq,tq) log\u03c0\u03b8. (5)"
        },
        {
            "heading": "3.4 Embedding Transfer and Update",
            "text": "SKGs with static entity properties can be seen as long-term valid knowledge and are helpful to generate accurate evolutional embeddings of entities (Li et al., 2021c; Niu and Li, 2023). Therefore, for each TKG snapshot Gi, the timestamps are masked to convert Gi to its corresponding SKG snapshot Gsi .\nWe adopt a relation-type-based transferring layer over Gsi , since the relation types of connected edges provide valuable clues about their natures. Our introduced transferring layer injects learned knowledge about relation types into new entities. Formally, for a new entity e in Gi, we generate its beginning embedding ubi(e) \u2208 Rd:\nubi(e) = tanh (\u2211 (e\u2032,r,e)\u2208N ini (e) Win ur\n+ \u2211\n(e,r,e\u2032)\u2208N outi (e) Wout ur\n) ,\n(6) where N ini (e) = {(e\u2032, r, e) | (e\u2032, r, e) \u2208 Gsi }, N outi (e) = {(e, r, e\u2032) | (e, r, e\u2032) \u2208 Gsi }. Win ,Wout \u2208 Rd\u00d7d are two learnable weight matrices. ur \u2208 Rd, serving as the embedding of relation type r, is learnable throughout the whole lifelong TKG reasoning process. Furthermore, to avoid recalculating for seen entities, we only generate embeddings for emerging entities and inherit the\nembeddings for seen ones from the preceding TKG snapshot Gi\u22121.\nIn order to update embeddings for all components in Gsi , we propose a new edge-aware message passing module via bidirectional communication between edges and nodes. This module enables our model to better adapt to the rapidly changing environment in lifelong TKG learning. For each edge g in Gsi , the links connected to its two endpoints act as a relevant semantic environment.\nTherefore, we alternately pass edge-aware messages between nodes and edges to aggregate unique environment knowledge for each edge as follows. u\u2113i(e) and u \u2113 i(g) are embeddings of entity e and edge g at \u2113-th layer:\nu\u2113+1i (e) = tanh ( W\u2113selfu \u2113 i(e)\n+ \u2211\ng\u2032=(e\u2032,r,e)\u2208N ini (e) W\u2113in \u03c6\n( u\u2113i(e \u2032),u\u2113i(g \u2032) )\n+ \u2211\ng\u2032=(e,r,e\u2032)\u2208N outi (e) W\u2113out \u03c6\n( u\u2113i(e \u2032),u\u2113i(g \u2032) )) ;\n(7) u\u2113+1i (g) =\n\u03c3 ( W\u2113g [ u\u2113i(g),u \u2113+1 i (eleft),u \u2113+1 i (eright) ] +b\u2113g ) ,\n(8) where u0i (e) = u b i(e), u 0 i (e \u2032) = ubi(e \u2032), u0i (g) = ur, u0i (g \u2032) = ur\u2032 , r(r\u2032) is the relation type of g(g\u2032), eleft and eright are two endpoints of edge g. W\u2113self , W\u2113in, W \u2113 out \u2208 Rd\u00d7d; W\u2113g \u2208 Rd\u00d73d and b\u2113g \u2208 Rd are learnable weight matrices. Message transition function \u03c6 ( u\u2113i(e \u2032),u\u2113i(g \u2032) ) =u\u2113i(e\n\u2032) \u25e6 u\u2113i(g\u2032) stores environment knowledge by calculating the correlation between connected entities and edges. \u25e6 is hadamard product.\nAfter L-layer updating, the final representations of each entity e and edge g are uLi (e) and u L i (g). In the absence of ambiguity, we abbreviate them in RL (Section 3.3) as ue and ug, respectively."
        },
        {
            "heading": "3.5 Temporal-Rule-Based Reward Shaping",
            "text": "For a query (eq, rq, ?, tq) with answer eans, RL gives a reasoning trajectory ((eq, r1, e1, t1), (e1, r2, e2, t2), . . . , (eM\u22121, rM , eM , tM )), where tq \u2265 t1 \u2265 t2 \u2265 \u00b7 \u00b7 \u00b7 \u2265 tM . Then, we can extract a temporal rule R : (rM , . . . , r2, r1) \u21d2 rq with nondescending temporal constraints and denote the confidence of R as conf(R). According to Section 3.3.1, since the agent receives a binary reward only based on whether eM is equal to eans, regardless of the quality of the reasoning temporal paths,\nwe introduce a temporal-rule-based reward shaping to guide the training of the agent:\nR(sM ) = Rb(sM ) + conf(R). (9)\nconf(R) is obtained by dividing the rule support by the body support."
        },
        {
            "heading": "4 Constructed Benchmarks",
            "text": "To conduct evaluation for lifelong TKG reasoning, we construct three new TKG benchmarks based on three datasets ICEWS14, ICEWS05-15 (Garc\u00edaDur\u00e1n et al., 2018) and ICEWS18 (Jin et al., 2020) to simulate their growth situation of entities, named as ICEWS14-lifelong, ICEWS05-15-lifelong and ICEWS18-lifelong. Table 1 shows the statistics of the new benchmarks.\n1. Counting. More uniform entity distribution makes the changing of G more concentrated and significant, so we filter entities that occur less than 10 times and count the remaining entities, relations, timestamps as |E|, |R|, |T |.\n2. Lifelong Simulating. New entities emerge at almost all the timestamps. Hence, we accumulate the number of entities in chronological order. First, we define the set of entities at t0 = 0 as the initial Ei (i = 1, . . . , 5). Secondly, we iteratively add the set of entities at the next timestamp to expand Ei. Once |Ei| \u2265 4+i10 |E|, we stop expanding Ei, record the current timestamp ti and then start the searching for ti+1 in the same way. Thirdly, after obtaining five timestamps t1 \u223c t5, we denote the union of TKGs from ti\u22121 to ti as TKG snapshot Gi. Since the relations are dense, we can ensure the number of relations in all Gi, |Ri|, is equal to |R|. For the last TKG snapshot G6, we set t6 = |T | to ensure all facts in D are covered.\n3. Dividing. For each TKG snapshot Gi, we randomly divide Gi into training set Fi, validation set Vi and test set Qi with ratio 3:1:1.\nG1 G2 G3 G4 G5 G6"
        },
        {
            "heading": "5 Experiments",
            "text": ""
        },
        {
            "heading": "5.1 Experimental Setup",
            "text": "Baselines.\nWe compare our model against the SOTA lifelong SKG reasoning model LKGE (Cui et al., 2023). LKGE uses TransE as the knowledge transfer module and can be well-adapted to lifelong TKG reasoning. MBE (Cui et al., 2022) is designed for multi-batch emergence scenario and is also a powerful baseline since it leverages walk-based reasoning and has an inductive entity encoding module. We name MBE adapted for lifelong TKG reasoning as L-MBE.\nBased on the framework of LKGE, we leverage the SOTA TKGE model TeRo (Xu et al., 2020) for L-TeRo, by defining the timestamp embeddings as a linear function. L-TITer, L-TGAP and L-TLogic were modified from TITer (Sun et al., 2021), TGAP (Jung et al., 2021) and TLogic (Liu et al., 2022). TITer is encapsulated according to the requirements of lifelong TKG reasoning, forming L-TITer. TGAP can handle future timestamps, but it is not inductive, so L-TGAP randomly initializes the emerging entities. TLogic is based on entityindependent temporal logical rules, so L-TLogic can be used for lifelong TKG reasoning by transferring its found rules. Evaluation Metrics.\nFollowing the convention, we conduct the experiments on the temporal link prediction task and report Mean Reciprocal Rank (MRR) and Hits@k (k = 3, 10). Then, we evaluate the knowledge lifelong learning capability using forward transfer (FWT) and backward transfer (BWT) (Lopez-Paz and Ranzato, 2017).\nFWT = 1\n\u03c1\u2212 1 \u03c1\u2211 i=2 hi\u22121,i;BWT = 1 \u03c1\u2212 1 \u03c1\u22121\u2211 i=1 (h\u03c1,i \u2212 hi,i) ,\nwhere \u03c1 is the number of TKG snapshots, hi,j is the MRR scores on Qj after training the model Mi on Fi."
        },
        {
            "heading": "5.2 Results on Lifelong TKG Reasoning",
            "text": "We run 10-seed experiments for all models on our three new benchmarks and report average results on the six TKG snapshots. The MRR, Hits@3 and Hits@10 results are shown in Table 2. Although the TransE used in LKGE is efficient to model static relationships of entities, it is not sensitive to temporal change. Therefore, LKGE does not deal with the temporal dimension in lifelong TKG reasoning and confuses the timestamps in growing TKGs. As a result, LKGE only has comparable Hits@10 results. Similar to our model, the adapted L-MBE uses a RL framework, benefiting its reasoning process. The static link augmentation in L-MBE is also proven to be effective in TKG reasoning (Niu and Li, 2023). Even so, the results of L-MBE are still worse than ours. The reason is that our model specifically constructs a more targeted RL environment for lifelong TKG reasoning and further takes temporal displacement into account for temporally extrapolating.\nHowever, the frameworks of LKGE and L-TeRo are based on traditional KGE and TKGE models, limiting their performances in lifelong TKG reasoning. L-TITer, L-TGAP and L-TLogic are adapted from recent powerful TKG link prediction models, but there is a certain degree of reduction in their original performances when used in lifelong TKG reasoning. The reasons are that the IM module in TITer is parameter-free, so the knowledge can not be transferred and updated; TGAP is in the interpolation setting, so the embeddings of future timestamps can not be well initialized; TLogic relies on temporal rules, but the transferred old rules may conflict with the new ones in future TKG snapshots. Therefore, these existing baselines can not perform perfectly in the lifelong TKG reasoning. On the contrary, our model consistently outperforms all the baselines across the three benchmarks. Some results of our model are even twice that of baselines. This is because our model comprehensively considers all the requirements of lifelong TKG reasoning and the proposed three targeted solutions solve the problems of temporal extrapolation, knowledge transfer and knowledge update."
        },
        {
            "heading": "5.3 Performance Evolution",
            "text": "To demonstrate the performance evolution of our model and three baselines during lifelong TKG reasoning, the MRR results on all TKG snapshots are reported in Figure 3.\nWe find: (i) For the same Gi, as our model learns over growing TKGs, the performance of Mi \u223cM6 on Gi remains relatively steady. This suggests that our model has a strong ability to transfer embeddings to emerging components continuously and avoids forgetting previous knowledge. However, the other three baselines all experience rapid degradation in performance and suffer from catastrophic forgetting.\n(ii) For the same Mi, we observe its performance changing on different TKG snapshots. Since old knowledge is not always suitable for new facts, we need to update learned knowledge, otherwise the performance of Mi will drop. The inductive embedding layer in L-MBE sometimes succeeds in updating (from G2 to G3). LKGE and L-TGAP clearly fail to update knowledge for the decreasing MRR. This demonstrates our powerful ability to\nupdate knowledge for new TKGs. Empirically, performance on G1 is the upper bound of our model since G1 injects knowledge to our model and knowledge transfer and update start when G1 grows to G2."
        },
        {
            "heading": "5.4 Knowledge Lifelong Learning Capability",
            "text": "To accurately quantify the knowledge lifelong learning capability of all models in lifelong TKG reasoning, we report the FWT and BWT scores of MRR results in Figure 4. Since we specifically design the whole reasoning pipeline for extrapolating and transferring, the FWT scores of our model are the best among all baselines. LKGE and L-MBE are originally suitable for lifelong KG reasoning, so they work relatively well over SKGs. The FWT scores of L-TLogic are also poor because its rulebased strategy is too restricted by symbolic relations to reason over future TKGs.\nThe BWT scores of baselines are all negative due to the overwriting of relation types embeddings as the result of their update of learned knowledge. On the contrary, our proposed edge-aware message passing module focuses on updating the unique environment of each fact rather than individual relation types, which makes our model introduce richer information for more accurate predictions. The low BWT scores of L-TeRo show the inefficiency of\nTKGE in lifelong TKG reasoning. L-TITer and L-TGAP are well-adapted baselines by combining their original TKG reasoning ability with the demands of lifelong TKG reasoning, so their BWT scores are better than other baselines."
        },
        {
            "heading": "5.5 Case Study",
            "text": "Reasoning Trajectories and Temporal Rules. To demonstrate the reasoning ability of our model over the temporal edges, we perform a case study in Table 3, which shows two positive reasoning trajectories and a negative one for the target query (Sudan, sign formal agreement, Ethiopia, 2014/12/25). Then we further give the scores of confidence of the corresponding temporal rules extracted from the reasoning trajectories. The length of paths is set to 3 and we remove the self-loop actions for clarity. It can be seen that our model succeeds in telling the reasonable temporal rules with high confidence from weak ones with low confidence and thereby guides the action selection stably and efficiently."
        },
        {
            "heading": "5.6 Ablation Study",
            "text": "To further examine the effect of the three proposed solutions for lifelong TKG reasoning in our model, we conduct an ablation study as shown in Table 4.\nFirst, we replace temporal displacement in RL with timestamps (w/o td), i.e., rely on embeddings of explicit timestamps while selecting actions. The\nMRR results decrease by 18.07% on average over three benchmarks, indicating the significance of considering temporal displacement in RL, because it can be temporally extrapolated to the future time.\nSecondly, we remove our proposed edge-aware message passing module (w/o mp) and randomly initialize new entities. In this case, our model can not transfer or update knowledge and the agent can not capture the specific environment of each edge in RL. This leads to a drop of 10.86% on average on MRR, implying the importance of this module.\nFinally, we leverage the original binary reward to replace the temporal-rule-based reward shaping in our model (w/o rs) and obverse a 7.77% performance degradation. This phenomenon means, by the training guidance of temporal rules independent of particular entities, our model obtains comprehensively enhanced ability to select reliable actions."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this work, the lifelong TKG reasoning issue involves continually emerging entities and facts in the future timestamps. To address this new problem, we propose our model under the framework of RL and our model uses temporal displacement in the action space to extrapolate to the future timestamps; uses a new edge-aware message passing module to inductively transfer and update learned knowledge to new entities and facts; and uses a temporal-rule-based reward shaping to guide the training. The experimental results on three newly constructed benchmarks illustrate that our model has the best performance for lifelong TKG reasoning and the strongest knowledge lifelong learning capability.\nLimitations\nThis paper mainly focuses on lifelong TKG reasoning, where we consider emerging entities and facts in the future timestamps as TKG grows, and do not consider the changing case of relations. In most cases, the number of entities in TKGs is much larger than that of relations and the emergence of entities lasts longer and is more common than that of relations. For instance, ICEWS14 has 7128 entities and 230 relations; the accumulated number of relation types in ICEWS14 increases rapidly to 115, half of the total number, in 10 days, on the contrary, the accumulated number of entities is steadily increasing over the entire time period of ICEWS14. Therefore, we study the more severe case of emerging entities and leave the research for emerging relations in lifelong TKG reasoning to future works."
        },
        {
            "heading": "A Appendix",
            "text": "A.1 Implementation Details.\nwe tune the hyperparameters of our model using grid-search: learning rate in {0.0005, 0.0001, 0.001}, batch size in {4096, 8192}, embedding dimension in {100, 200, 300}. The length of the walking path of the agent in RL, M, is tuned in {3, 4, 5}. The layer of our proposed edge-aware message passing module, L, is in a range of {1, 2, 3} The hyperparameter T in Section 3.3.1 is 40 in ICEWS14-lifelong, 300 in ICEWS05-15-lifelong, 29 in ICEWS18-lifelong. While training, The discount factor of REINFORCE is 0.95. We clip gradients greater than 20 to avoid the gradient explosion. While testing, we use beam search to obtain a list of predicted entities with the corresponding scores. The beam size is set to 100. The re-run baselines are based on their public codes and further adapted for our constructed benchmarks for lifelong TKG reasoning. All the experiments are carried out on one A100 GPU.\nA.2 Computational Complexity Analysis.\nTo see the efficiency of our proposed model, we analyze the computational complexity of the process of knowledge transferring and updating. There are two parts in the edge-aware message passing module, one is for initializing the embeddings for new entities, and the other is for updating all components. First, for the first part, the expected time complexity of Eq. 6 in each iteration is O(|E|), where |E| is the maximum number of new entities in the six TKG snapshots. Secondly, for the next\npart, if there are X emerging entities and Y edges connected to new entities, each emerging entity takes E[d] = 2YX elements as input in expectation, where E[d] is the expected node degree. The cost of aggregation is X \u00b7 E[d] = 2Y . Therefore, Eq. 7 has the time complexity O(2|D|). For Eq. 8, it is performed for |D| times and each update takes 3 elements as input. Therefore, the cost of update in each iteration is O(3|D|). We iterate these two updating functions for L times, so the overall time complexity is O(L|D|), where |D| is the maximum number of edges in the six TKG snapshots. Finally, the time complexity of the process of knowledge transferring and updating is O(|E|+ L|D|), where |E| is the maximum number of new entities, |D| is the maximum number of edges in the six TKG snapshots; L is the iteration time."
        }
    ],
    "title": "Temporal Extrapolation and Knowledge Transfer for Lifelong Temporal Knowledge Graph Reasoning",
    "year": 2023
}