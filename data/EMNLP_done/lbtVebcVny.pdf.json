{
    "abstractText": "The de-identification task aims to detect and remove the protected health information from electronic medical records (EMRs). Previous studies generally focus on the within-hospital setting and achieve great successes, while the cross-hospital setting has been overlooked. This study introduces a new de-identification dataset comprising EMRs from three hospitals in China, creating a benchmark for evaluating both withinand cross-hospital generalization. We find significant domain discrepancy between hospitals. A model with almost perfect within-hospital performance struggles when transferred across hospitals. Further experiments show that pretrained language models and some domain generalization methods can alleviate this problem. We believe that our data and findings will encourage investigations on the generalization of medical NLP models.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Yiyang Liu"
        },
        {
            "affiliations": [],
            "name": "Jinpeng Li"
        },
        {
            "affiliations": [],
            "name": "Enwei Zhu"
        },
        {
            "affiliations": [],
            "name": "Ningbo No"
        }
    ],
    "id": "SP:bad9186fab641bf8b42b6f0f96d250fe3ef98ec6",
    "references": [
        {
            "authors": [
                "Ronan Collobert",
                "Jason Weston",
                "L\u00e9on Bottou",
                "Michael Karlen",
                "Koray Kavukcuoglu",
                "Pavel Kuksa."
            ],
            "title": "Natural language processing (almost) from scratch",
            "venue": "Journal of Machine Learning Research, 12(ARTICLE):2493\u20132537.",
            "year": 2011
        },
        {
            "authors": [
                "Yiming Cui",
                "Wanxiang Che",
                "Ting Liu",
                "Bing Qin",
                "Ziqing Yang."
            ],
            "title": "Pre-training with whole word masking for Chinese BERT",
            "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing, 29:3504\u20133514.",
            "year": 2021
        },
        {
            "authors": [
                "Hercules Dalianis",
                "Sumithra Velupillai."
            ],
            "title": "Deidentifying Swedish clinical text-refinement of a gold standard and experiments with conditional random fields",
            "venue": "Journal of Biomedical Semantics, 1(1):1\u201310.",
            "year": 2010
        },
        {
            "authors": [
                "Franck Dernoncourt",
                "Ji Young Lee",
                "Ozlem Uzuner",
                "Peter Szolovits."
            ],
            "title": "De-identification of patient notes with recurrent neural networks",
            "venue": "Journal of the American Medical Informatics Association, 24(3):596\u2013606.",
            "year": 2017
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Aparna Elangovan",
                "Jiayuan He",
                "Karin Verspoor."
            ],
            "title": "Memorization vs",
            "venue": "generalization : Quantifying data leakage in NLP performance evaluation. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Lin-",
            "year": 2021
        },
        {
            "authors": [
                "Cyril Grouin",
                "Aur\u00e9lie N\u00e9v\u00e9ol."
            ],
            "title": "Deidentification of clinical notes in French: towards a protocol for reference corpus development",
            "venue": "Journal of Biomedical Informatics, 50:151\u2013161.",
            "year": 2014
        },
        {
            "authors": [
                "Dan Hendrycks",
                "Xiaoyuan Liu",
                "Eric Wallace",
                "Adam Dziedzic",
                "Rishabh Krishnan",
                "Dawn Song."
            ],
            "title": "Pretrained transformers improve out-of-distribution robustness",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
            "year": 2020
        },
        {
            "authors": [
                "Sepp Hochreiter",
                "J\u00fcrgen Schmidhuber."
            ],
            "title": "Flat minima",
            "venue": "Neural Computation, 9(1):1\u201342.",
            "year": 1997
        },
        {
            "authors": [
                "Sepp Hochreiter",
                "J\u00fcrgen Schmidhuber."
            ],
            "title": "Long short-term memory",
            "venue": "Neural Computation, 9(8):1735\u2013 1780.",
            "year": 1997
        },
        {
            "authors": [
                "P Izmailov",
                "AG Wilson",
                "D Podoprikhin",
                "D Vetrov",
                "T Garipov."
            ],
            "title": "Averaging weights leads to wider optima and better generalization",
            "venue": "34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018, pages 876\u2013885.",
            "year": 2018
        },
        {
            "authors": [
                "Yann LeCun",
                "Yoshua Bengio",
                "Geoffrey Hinton."
            ],
            "title": "Deep learning",
            "venue": "nature, 521(7553):436\u2013444.",
            "year": 2015
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "RoBERTa: A robustly optimized BERT pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Zengjian Liu",
                "Buzhou Tang",
                "Xiaolong Wang",
                "Qingcai Chen."
            ],
            "title": "De-identification of clinical notes via recurrent neural network and conditional random field",
            "venue": "Journal of Biomedical Informatics, 75:S34\u2013 S42.",
            "year": 2017
        },
        {
            "authors": [
                "Ilya Loshchilov",
                "Frank Hutter."
            ],
            "title": "Decoupled weight decay regularization",
            "venue": "International Conference on Learning Representations.",
            "year": 2018
        },
        {
            "authors": [
                "Tomas Mikolov",
                "Ilya Sutskever",
                "Kai Chen",
                "Greg S Corrado",
                "Jeff Dean."
            ],
            "title": "Distributed representations of words and phrases and their compositionality",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2013
        },
        {
            "authors": [
                "Radim \u0158eh\u016f\u0159ek",
                "Petr Sojka"
            ],
            "title": "Software framework for topic modelling with large corpora",
            "venue": "In Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks,",
            "year": 2010
        },
        {
            "authors": [
                "Nitish Srivastava",
                "Geoffrey Hinton",
                "Alex Krizhevsky",
                "Ilya Sutskever",
                "Ruslan Salakhutdinov."
            ],
            "title": "Dropout: a simple way to prevent neural networks from overfitting",
            "venue": "The Journal of Machine Learning Research, 15(1):1929\u20131958.",
            "year": 2014
        },
        {
            "authors": [
                "Pontus Stenetorp",
                "Sampo Pyysalo",
                "Goran Topi\u0107",
                "Tomoko Ohta",
                "Sophia Ananiadou",
                "Jun\u2019ichi Tsujii"
            ],
            "title": "BRAT: a web-based tool for NLP-assisted text annotation",
            "venue": "In Proceedings of the Demonstrations Session at EACL",
            "year": 2012
        },
        {
            "authors": [
                "Amber Stubbs",
                "Michele Filannino",
                "\u00d6zlem Uzuner"
            ],
            "title": "De-identification of psychiatric intake records: Overview of 2016 CEGS N-GRID shared tasks track",
            "year": 2017
        },
        {
            "authors": [
                "Amber Stubbs",
                "Christopher Kotfila",
                "\u00d6zlem Uzuner."
            ],
            "title": "Automated systems for the de-identification of longitudinal clinical narratives: Overview of 2014 i2b2/UTHealth shared task track 1",
            "venue": "Journal of Biomedical Informatics, 58:S11\u2013S19.",
            "year": 2015
        },
        {
            "authors": [
                "Amber Stubbs",
                "\u00d6zlem Uzuner",
                "Christopher Kotfila",
                "Ira Goldstein",
                "Peter Szolovits."
            ],
            "title": "Challenges in synthesizing surrogate PHI in narrative emrs",
            "venue": "Medical Data Privacy Handbook, pages 717\u2013735.",
            "year": 2015
        },
        {
            "authors": [
                "\u00d6zlem Uzuner",
                "Yuan Luo",
                "Peter Szolovits."
            ],
            "title": "Evaluating the state-of-the-art in automatic deidentification",
            "venue": "Journal of the American Medical Informatics Association, 14(5):550\u2013563.",
            "year": 2007
        },
        {
            "authors": [
                "Xing Wu",
                "Chaochen Gao",
                "Meng Lin",
                "Liangjun Zang",
                "Songlin Hu"
            ],
            "title": "Text smoothing: Enhance",
            "year": 2022
        },
        {
            "authors": [
                "Ningyu Zhang",
                "Qianghuai Jia",
                "Kangping Yin",
                "Liang Dong",
                "Feng Gao",
                "Nengwei Hua."
            ],
            "title": "Conceptualized representation learning for chinese biomedical text mining",
            "venue": "arXiv preprint arXiv:2008.10813.",
            "year": 2020
        },
        {
            "authors": [
                "Xiang Zhang",
                "Junbo Zhao",
                "Yann LeCun."
            ],
            "title": "Character-level convolutional networks for text classification",
            "venue": "Advances in Neural Information Processing Systems, 28.",
            "year": 2015
        },
        {
            "authors": [
                "Kaiyang Zhou",
                "Ziwei Liu",
                "Yu Qiao",
                "Tao Xiang",
                "Chen Change Loy."
            ],
            "title": "Domain generalization: A survey",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence.",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "De-identification is a natural language processing (NLP) task to detect and remove the protected health information (PHI) from electronic medical records (EMRs). It is a prerequisite to the distribution of EMRs outside their original institutions for medical NLP research (Uzuner et al., 2007).\nPrevious studies generally focus on the withinhospital setting, where the training and test data are from a same hospital or institution. This includes English tasks like 2006 i2b2 (Uzuner et al., 2007), 2014 i2b2/UTHealth (Stubbs et al., 2015a), 2016 CEGS N-GRID (Stubbs et al., 2017), and others in Swedish (Dalianis and Velupillai, 2010) and French (Grouin and N\u00e9v\u00e9ol, 2014). Deidentification may be regarded as an easy task relative to other NLP tasks, because simple rule-based or shallow neural models can achieve 95%+ F1 scores (Liu et al., 2017; Dernoncourt et al., 2017).\n*Corresponding author. 1Our data and code are available at https://github.\ncom/lanyangyang93/Revisiting-De-Identification.\nHowever, the cross-hospital setting has been largely overlooked.This setting corresponds to a realistic scenario that a de-identification model is deployed across hospitals. This study aims to formally fill the gap. We introduce a new deidentification dataset comprising EMRs from three hospitals in China, establishing a benchmark for evaluating both within- and cross-hospital generalization. The latter poses a challenging domain generalization (DG) task, where hospitals are referred as domains.\nWe find significant domain discrepancy existing between hospitals. A model with almost perfect within-hospital performance encounters dramatic degradation when transferred to other hospitals. Using pretrained language models (PLMs) like BERT (Devlin et al., 2019), or some existing DG methods (Izmailov et al., 2018; Wu et al., 2022) can improve the cross-hospital generalization, but by limited margins. This paper contributes in twofold:\n\u2022 To the best of our knowledge, our dataset provides the first de-identification benchmark that has multiple sources for cross-hospital evaluation. It is also the first de-identification task for Chinese EMRs. The dataset probably interests researchers from a broader community, since DG tasks have been scarce in NLP (Zhou et al., 2022). We will release the data to facilitate further research.\n\u2022 From the DG perspective, our findings enhance Stubbs et al. (2015a, 2017)\u2019s argument that de-identification is not a solved problem, even in the post-BERT era. Our experiments show the effectiveness of PLMs and DG methods, providing a promising direction for investigations on the cross-hospital generalization of medical NLP models."
        },
        {
            "heading": "2 Data and Annotations",
            "text": ""
        },
        {
            "heading": "2.1 Data Sources",
            "text": "HM. Our primary dataset is built from the EMRs of HM2 hospital, a general hospital in Zhejiang Province, China. We obtained a 1.7 TB backup of 671.5K inpatient records. The clinical text is stored in sections like chief complaints, examination reports, progress notes, and discharge summaries.\nWe sample 500 EMRs from 30 representative medical departments for PHI annotation. The resulting annotated corpus is randomly split into training/development/test sets with 300/100/100 EMRs. This is the dataset for within-hospital evaluation.\nIn addition, the HM database provides the largescale clinical text for pretraining Word2Vec embeddings and BERT, named HM-Word2Vec and HM-BERT, respectively. This mitigates the potential domain gap of transferring word embeddings or PLMs trained on common corpora to clinical text. See Section 3 for more details.\nSY. We collect 100 EMRs from SY3 hospital, a general hospital in Hunan Province, China. Similar to those of HM hospital, the EMRs contain various sections of clinical text. After the annotation of PHI, SY dataset serves as a test set for cross-hospital evaluation.\nCCKS. China Conference on Knowledge Graph and Semantic Computing (CCKS) 20174 released a clinical named entity recognition task, which contains 300 EMRs from an anonymous hospital in Hebei Province, China. Each EMR includes four paragraphs from specific sections. We annotate the PHI on the available text, yielding another test set."
        },
        {
            "heading": "2.2 Protected Health Information",
            "text": "Following previous research (Uzuner et al., 2007; Stubbs et al., 2017), we define eight PHI categories:\n\u2022 PERSON: The names of patients or physicians.\n\u2022 LOCATION: Addresses of patients.\n\u2022 HOSPITAL: The names of hospitals.\n\u2022 DATE: Date or time stamps.\n\u2022 ID: IDs of patients or medical tests.\n\u2022 CONTACT: The contact information of patients, physicians or hospitals.\n2Ningbo No.2 Hospital. 3The hospital name is anonymized for policies and regula-\ntions. 4See https://www.sigkg.cn/ccks2017.\n\u2022 AGE: Ages of patients.\n\u2022 PROFESSION: The professions of patients.\nThe BRAT Rapid Annotation Tool (Stenetorp et al., 2012) is employed for the PHI annotation. Table 1 reports the descriptive statistics of the resulting datasets. Appendix A provides some typical examples of the PHI annotations on clinical text."
        },
        {
            "heading": "3 Models and Experimental Settings",
            "text": "Model Architecture. Figure 1 displays the architecture of our model. We employ the neural sequence tagging framework (Collobert et al., 2011), a widely-used and mature solution for the de-identification task.\nSpecifically, the tokens are first mapped to embeddings and fed into the encoder. The encoder can be a 1D CNN (Zhang et al., 2015), a BiLSTM (Hochreiter and Schmidhuber, 1997b), or a pretrained Transformer (Devlin et al., 2019), which\ntransforms the embeddings to hidden representations. Finally, the dense layer classifies the representations into the pre-defined BIO tag space, and the resulting BIO tags can be parsed to identify the boundaries and categories of PHI mentions. An optional conditional random field (CRF) layer can be inserted after the dense layer, which may improve the consistency of the predicted BIO tags.\nPretraining on EMRs. Most publicly available Chinese word embeddings or PLMs are trained on common corpora, which may encounter domain gaps and result in sub-optimal performance when transferred to the clinical domain. To alleviate this issue, we pretrain Word2Vec embeddings (Mikolov et al., 2013) and a Chinese BERT (Devlin et al., 2019) on the large-scale clinical text from the HM database. The resulting embeddings and model are named HM-Word2Vec and HM-BERT, respectively.\nAfter data parsing, cleaning and deduplication, the remaining HM corpus consists of 21.4K EMRs, including clinical text of 2.8 GB (1.1B tokens). HM-Word2Vec has a character-level vocabulary of size 5.7K and embedding size of 100. It is trained for 5 epochs by the Gensim (R\u030cehu\u030ar\u030cek and Sojka, 2010) package with window size 15 and learning rate 1e-3.\nFollowing Cui et al. (2021), we initialize HMBERT from the bert-base-chinese checkpoint released by Hugging Face.5 We then pretrain the model with the optimizer AdamW (Loshchilov and Hutter, 2018), learning rate 1e-4 and batch size 384 for 20 epochs on the whole corpus. A scheduler of linear warmup in the first 20% steps followed by linear decay is applied. The masking rate is 15% for the masked language modeling (MLM) task; the maximum input length is 512. In addition, we apply the whole word masking (Cui et al., 2021) and dynamic masking (Liu et al., 2019) strategies.\nWithin- and Cross-Hospital Evaluation. We train the models on the training set of HM, and use the development set for hyperparameter tuning. We perform the within-hospital evaluation, i.e., evaluating the trained models on the test set of HM; and the cross-hospital evaluation, i.e., evaluating the models on SY and CCKS.\n5See https://huggingface.co/bert-base-chinese.\nHyperparameters.6 For CNN or BiLSTM models, the embedding layer is 100-dimensional, and optionally initialized from HM-Word2Vec; the encoders have one layer with 200 hidden states and dropout rate of 0.5. The kernel size is 15 for CNN. The models are trained for 100 epochs by the AdamW (Loshchilov and Hutter, 2018) optimizer with learning rate 1e-3 and batch size 32.\nFor models with PLMs, we use BERT-wwm (Cui et al., 2021), MC-BERT (Zhang et al., 2020) and HM-BERT, all of a base size (768 hidden size, 12 layers). The MC-BERT is pre-trained on Chinese medical corpora including biomedical question answering, medical encyclopedia and EMRs. The models are trained for 100 epochs by the AdamW optimizer with learning rate 2e-5 and batch size 32.\nEvaluation. A predicted PHI mention is considered correct if its boundaries and category exactly match the ground truth. The evaluation metrics are micro precision rate, recall rate and F1 score on the test sets. All the experiments are repeated for five times and the average metrics are reported."
        },
        {
            "heading": "4 Experimental Results",
            "text": ""
        },
        {
            "heading": "4.1 Main Results",
            "text": "Table 2 presents the results for both within- and cross-hospital evaluation. In the within-hospital evaluation, a single-layer CNN or BiLSTM can achieve 98% F1 scores or higher. This is consistent with the results of previous literature that the deidentification task can be almost perfectly solved by simple models (Dernoncourt et al., 2017; Liu et al., 2017). We add to the findings that more sophisticated neural models like BERT can further improve the performance, although by limited magnitudes.\nHowever, the cross-hospital setting has largely been overlooked in literature. With the help of our multi-source data, we evidence that a decent neural de-identification model easily encounters noticeable performance degradation when transferred across hospitals. Specifically, for CNN and BiLSTM, the F1 scores decrease to 70%\u201380% and 50%\u201360% when transferred to SY and CCKS, respectively. The HM-Word2Vec embeddings and CRF help to resist the performance drop, but the effect is not robust. The BERT-based models also suffer from the cross-hospital setting, but they achieve much better results: 95%+ F1 scores on SY and\n6All the hyperparameters have been extensively tuned and thus empirically optimal. We have tested models with larger sizes, but resulted in lower performance.\n70%\u201380% on CCKS. In particular, HM-BERT outperforms BERT-wwm and MC-BERT on CCKS.\nThese results clearly reveal a noteworthy problem \u2013 severe domain discrepancy exists between EMRs from different hospitals. It may greatly impede the cross-hospital applicability of a perfectlyperforming model. Empirically, using PLMs can effectively alleviate this problem. The PLMs learn universal linguistic patterns from large-scale pretraining data, which help the models to generalize across hospitals.\nWhen focused on within-hospital evaluation, we may conclude that CNN or BiLSTM models are superior to BERT-based models, because the former ones achieve similar performance with better efficiency (fewer parameters and FLOPs, higher speed). However, with the awareness of crosshospital results, we have to rethink this problem.\nAppendix B reports the categorical evaluation results. To avoid PHI leaks and preserve the data usability, we have carefully replaced the PHI mentions by realistic surrogates (Stubbs et al., 2015b) in the release version. This slightly affects the evaluation results, so we report the corresponding results in Appendix D."
        },
        {
            "heading": "4.2 Analysis",
            "text": "We explore some potential reasons for the significant gap between the within- and cross-hospital performance.\nCosine Similarity. Following Elangovan et al. (2021), we represent each data instance with the vector of HM-BERT and compute the cosine sim-\nilarities between them. The average cosine similarity (ACS) over all the test instances is used as an indicator to measure the overlapping extent of training and test data.\nFalse Alarm Rate. Following Hendrycks et al. (2020), we assign the maximum softmax anomaly score for each test instance, to perform out-ofdistribution (OOD) detection, and report the false alarm rate at 95% recall (FAR95).\nTable 3 shows that the CCKS data present the most different distributions from the HM training set. In other words, the overlap between HM and CCKS is the lowest. Hence, the CCKS has representations of more OOD information that the models fail to learn. This is the major reason for the large performance drop on CCKS. We further perform the PCA visualizations of sentence representations on the HM training/test sets, SY, and CCKS. The results are quite similar. See Appendix C for more details."
        },
        {
            "heading": "4.3 Domain Generalization",
            "text": "Given the domain shift between hospitals, we explore some widely used DG methods, verifying whether they can help the models to generalize\nacross hospitals. The results are shown in Table 4.\nMention Substitution. Data augmentation has been a common practice to prevent the models from overfitting and thus improve generalization (LeCun et al., 2015; Zhou et al., 2022). To avoid overfitting to frequent PHI mentions, we add an augmentation module that randomly replaces the PHI mentions with fabricated ones of the same categories. For example, a LOCATION mention can be replaced by random addresses. The resulting effect is unstable.\nText Smoothing. Text smoothing (Wu et al., 2022) is a PLM-based text augmentation approach. It leverages the masked language modeling objective of a dedicated PLM and augments each token according to the predicted probabilities over the vocabulary. Text smoothing slightly improves the generalization performance on SY and CCKS.\nStochastic Weight Averaging. Stochastic weight averaging (Izmailov et al., 2018, SWA) aggregates the model weights along the training trajectory. The ensemble model can achieve flatter minima (Hochreiter and Schmidhuber, 1997a) and thus improves generalization. Specifically, we average the model checkpoints at last 25%, 50%, and 75% training epochs for test. It shows that SWA brings marginal yet robust improvements for either withinor cross-hospital performance.\nDropout and L2 Regularization. Dropout (Srivastava et al., 2014) and L2 regularization are standard strategies against overfitting. We tune the dropout rate and L2 penalty to different values, but obtain lower scores.\nIn summary, text smoothing and SWA can effectively improve the generalization performance by small margins, while the other DG methods result in negative or unstable effects."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this paper, we revisit the EMR de-identification task and create a new dataset. It consists of EMRs from three hospitals and thus asks evaluation for both within- and cross-hospital generalization. The latter poses a challenging DG task, which corresponds to a realistic scenario that a de-identification model is required to deploy across hospitals.\nWith this new benchmark, we find significant domain shift between hospitals. A model with perfect within-hospital performance struggles when transferred across hospitals. Using PLMs or some existing DG methods can alleviate but not address this problem."
        },
        {
            "heading": "6 Limitations",
            "text": "Although we have explored various existing models and DG methods on our proposed task, there are still other approaches worth investigating. It may be more effective to develop new specialized methods to improve the cross-hospital generalization of medical NLP models.\nIn general, this study focuses on end-to-end evaluation. It requires more in-depth analysis, either theoretically or empirically, to answer some crucial questions like (1) how and to what extent is the i.i.d. assumption violated between the clinical text from different hospitals? (2) how to develop invariant representations that generalize across hospitals? (3)\nhow to estimate the risk of generalization failure before the models are deployed? These answers may be the key towards interpretable, robust and reliable medical NLP systems."
        },
        {
            "heading": "7 Ethical Considerations",
            "text": "Our data were collected and used consistently with the terms of use. The EMRs of HM and SY were obtained from the authors\u2019 affiliations, and this work was performed as a part of projects approved by the ethics review committees. CCKS was derived from publicly available data released as a shared task. We authors performed the PHI annotation, with full awareness of the potential impacts and risks.\nThe data of release version have been deidentified. Specifically, we have carefully replaced all the PHI mentions by surrogates (Stubbs et al., 2015b), and manually verified the resulting text so that the risk of privacy leak has been minimized. In particular, any text span is regarded as PHI and removed if it potentially reveals any identity characteristics, even if the risk is impossibly low. In addition, the data will be released upon a data use agreement that forbids any inappropriate use, especially identification of any individuals or institutions.\nWe report data characteristics and experimental results averaged over multiple runs. We will release the data and code, ensuring the reproducibility of our work. Our experiments do not require high computational cost, relative to pretraining PLMs."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank the anonymous reviewers for their insightful comments and feedback. This work is supported by Zhejiang Provincial Natural Science Foundation of China (No. LQ23F020005), National Natural Science Foundation of China (No. 62106248), Ningbo Science and Technology Service Industry Demonstration Project (No. 2020F041), and Ningbo Public Service Technology Foundation (No. 2021S152)."
        },
        {
            "heading": "A Examples of PHI Annotations",
            "text": "All the EMRs are manually annotated by two native speakers. (A master\u2019s degree in computer science and an expert in both the fields of computer science and medicine.) We consider the de-identification task to be easy and straightforward, with very few disagreements during labeling and near-perfect accuracy. We employed some post-processing procedure to ensure the accuracy of the annotations. For example, we perform cross-validation on the whole dataset, and manually check the inconsistencies between the predicted PHI mentions and ground-truth.\nTable 5 shows examples of clinical text and PHI annotations. In principle, a text span is regarded as PHI if it potentially reveals any personal information, even if the risk is impossibly low.\nSome text spans are excluded because of irrelevance to personal information, although they seemingly fall into specific PHI categories. For example, some diseases are named after persons or locations, and these person or location names should not be regarded as PHI. Some clinical text may describe general medical knowledge that relates to ages or jobs, which are also excluded in our annotation."
        },
        {
            "heading": "B Categorical Results",
            "text": "Table 6 presents the evaluation results by PHI categories. The cross-hospital F1 scores are lower than the corresponding within-hospital scores across all categories, while such effect is heterogeneous. Taking HM-BERT as the example, it generalizes relatively well on PERSON, DATE and AGE categories,\nbut struggles on LOCATION, ID and PROFESSION. This plausibly attributes to that the former PHI categories are typically associated with clearer language patterns than the latter ones.\nC Visualization of Sentence Representations\nFigure 2 displays the PCA visualizations of sentence representations on the HM training/test sets, SY, and CCKS. The sentence representations of the HM training and test sets are most similar and overlapping. However, there are significant differences in the distributions of the HM and CCKS\ndatasets in the feature space. In comparison, there is a small overlap between the SY dataset and the HM dataset.\nFurther underlying reasons for the differences in the data distributions would be complicated. For example, different doctors may record information differently, resulting in differences in the format and content of medical records. Different medical institutions may use different electronic medical record systems."
        },
        {
            "heading": "D Results on Data of Release Version",
            "text": "We cannot release our data with the real PHI mentions. Hence, we have carefully replaced the PHI mentions by realistic surrogates (Stubbs et al., 2015b). For example, the PERSON mentions are replaced by combinations of randomly sampled family and given names, where the sampling accords to the frequencies reported by National Bureau of Statistics of China. The LOCATION mentions are replaced by randomly sampled addresses in China. Such process preserves the usability of our data and prevent PHI leak simultaneously.\nTable 7 presents the corresponding evaluation results, which are highly consistent with those on the original data. Hence, experimental results reported on our release data are still indicative."
        }
    ],
    "title": "Revisiting De-Identification of Electronic Medical Records: Evaluation of Within- and Cross-Hospital Generalization",
    "year": 2023
}