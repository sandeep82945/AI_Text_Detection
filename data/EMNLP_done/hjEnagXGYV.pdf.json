{
    "abstractText": "In the last few years, generative dialogue models have shown excellent performance and have been used for various applications. As chatbots become more prevalent in our daily lives, more and more people expect them to behave more like humans, but existing dialogue models do not consider the time information that people are constantly aware of. In this paper, we aim to construct a time-considerable dialogue model that actively utilizes time information. First, we categorize responses by their naturalness at different times and introduce a new metric to classify responses into our categories. Then, we propose a new reranking method to make the existing dialogue model time-considerable using the proposed metric and subjectively evaluate the performances of the obtained time-considerable dialogue models by humans.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Yuiko Tsunomori"
        },
        {
            "affiliations": [],
            "name": "Masakazu Ishihata"
        },
        {
            "affiliations": [],
            "name": "Hiroaki Sugiyama"
        }
    ],
    "id": "SP:cccff9f9862b43fd01d5399ee5e6c67d681812f8",
    "references": [
        {
            "authors": [
                "Daniel Adiwardana",
                "Minh-Thang Luong",
                "David R So",
                "Jamie Hall",
                "Noah Fiedel",
                "Romal Thoppilan",
                "Zi Yang",
                "Apoorv Kulshreshtha",
                "Gaurav Nemade",
                "Yifeng Lu"
            ],
            "title": "Towards a human-like opendomain chatbot",
            "year": 2020
        },
        {
            "authors": [
                "Sanghwan Bae",
                "Donghyun Kwak",
                "Sungdong Kim",
                "Donghoon Ham",
                "Soyoung Kang",
                "Sang-Woo Lee",
                "Woomyoung Park."
            ],
            "title": "Building a role specified open-domain dialogue system leveraging large-scale language models",
            "venue": "Proceedings of the Conference",
            "year": 2022
        },
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are few-shot learners. Advances in neural information processing",
            "year": 2020
        },
        {
            "authors": [
                "Yejin Choi"
            ],
            "title": "The curious case of neural",
            "year": 2020
        },
        {
            "authors": [
                "Zihan Liu",
                "Mostofa Patwary",
                "Ryan Prenger",
                "Shrimai Prabhumoye",
                "Wei Ping",
                "Mohammad Shoeybi",
                "Bryan Catanzaro."
            ],
            "title": "Multi-stage prompting for knowledgeable dialogue generation",
            "venue": "Findings of the Association for Computational Linguistics: ACL,",
            "year": 2022
        },
        {
            "authors": [
                "Hongyuan Lu",
                "Wai Lam",
                "Hong Cheng",
                "Helen Meng."
            ],
            "title": "Partner personas generation for dialogue response generation",
            "venue": "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
            "year": 2022
        },
        {
            "authors": [
                "Yukun Ma",
                "Khanh Linh Nguyen",
                "Frank Z Xing",
                "Erik Cambria."
            ],
            "title": "A survey on empathetic dialogue systems",
            "venue": "Information Fusion, 64:50\u201370.",
            "year": 2020
        },
        {
            "authors": [
                "Bodhisattwa Prasad Majumder",
                "Harsh Jhamtani",
                "Taylor Berg-Kirkpatrick",
                "Julian McAuley."
            ],
            "title": "Achieving conversational goals with unsupervised post-hoc knowledge injection",
            "venue": "Proceedings of the Annual Meeting of the Association for Computational",
            "year": 2022
        },
        {
            "authors": [
                "Teruhisa Misu."
            ],
            "title": "Situated reference resolution using visual saliency and crowdsourcing-based priors for a spoken dialog system within vehicles",
            "venue": "Computer Speech \u2018I&\u2019 Language, 48:1\u201314.",
            "year": 2018
        },
        {
            "authors": [
                "OpenAI."
            ],
            "title": "Gpt-4 technical report",
            "venue": "https:// arxiv.org/abs/2303.08774.",
            "year": 2023
        },
        {
            "authors": [
                "Myle Ott",
                "Sergey Edunov",
                "Alexei Baevski",
                "Angela Fan",
                "Sam Gross",
                "Nathan Ng",
                "David Grangier",
                "Michael Auli."
            ],
            "title": "fairseq: A fast, extensible toolkit for sequence modeling",
            "venue": "Proceedings of the Conference of the North American Chapter of the Association",
            "year": 2019
        },
        {
            "authors": [
                "Paul F Christiano",
                "Jan Leike",
                "Ryan Lowe."
            ],
            "title": "Training language models to follow instructions with human feedback",
            "venue": "Advances in Neural Information Processing Systems (NeurIPS), volume 35, pages 27730\u201327744.",
            "year": 2022
        },
        {
            "authors": [
                "Ashwin Paranjape",
                "Christopher Manning."
            ],
            "title": "Human-like informative conversations: Better acknowledgements using conditional mutual information",
            "venue": "Proceedings of the Conference of the North American Chapter of the Association for Computa-",
            "year": 2021
        },
        {
            "authors": [
                "Prasanna Parthasarathi",
                "Joelle Pineau."
            ],
            "title": "Extending neural generative conversational model using external knowledge sources",
            "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 690\u2013695.",
            "year": 2018
        },
        {
            "authors": [
                "Stephen Roller",
                "Emily Dinan",
                "Naman Goyal",
                "Da Ju",
                "Mary Williamson",
                "Yinhan Liu",
                "Jing Xu",
                "Myle Ott",
                "Eric Michael Smith",
                "Y-Lan Boureau",
                "Jason Weston."
            ],
            "title": "Recipes for building an open-domain chatbot",
            "venue": "Proceedings of the Conference of the Eu-",
            "year": 2021
        },
        {
            "authors": [
                "Shoetsu Sato",
                "Naoki Yoshinaga",
                "Masashi Toyoda",
                "Masaru Kitsuregawa."
            ],
            "title": "Modeling situations in neural chat bots",
            "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL) Student Research Workshop, pages 120\u2013127.",
            "year": 2017
        },
        {
            "authors": [
                "Iulian Serban",
                "Alessandro Sordoni",
                "Yoshua Bengio",
                "Aaron Courville",
                "Joelle Pineau."
            ],
            "title": "Building end-to-end dialogue systems using generative hierarchical neural network models",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence (AAAI),",
            "year": 2016
        },
        {
            "authors": [
                "Vered Shwartz."
            ],
            "title": "Good night at 4 pm?! time expressions in different cultures",
            "venue": "Findings of the Association for Computational Linguistics: ACL, pages 2842\u20132853.",
            "year": 2022
        },
        {
            "authors": [
                "Hiroaki Sugiyama",
                "Masahiro Mizukami",
                "Tsunehiro Arimoto",
                "Hiromi Narimatsu",
                "Yuya Chiba",
                "Hideharu Nakajima",
                "Toyomi Meguro."
            ],
            "title": "Empirical analysis of training strategies of transformer-based japanese chit-chat systems",
            "venue": "Proceedings of IEEE",
            "year": 2023
        },
        {
            "authors": [
                "Romal Thoppilan",
                "Daniel De Freitas",
                "Jamie Hall",
                "Noam Shazeer",
                "Apoorv Kulshreshtha",
                "Heng-Tze Cheng",
                "Alicia Jin",
                "Taylor Bos",
                "Leslie Baker",
                "Yu Du"
            ],
            "title": "Lamda: Language models for dialog applications. https://doi.org/10.48550/arXiv.2201",
            "year": 2022
        },
        {
            "authors": [
                "Dina Utami",
                "Timothy Bickmore."
            ],
            "title": "Collaborative user responses in multiparty interaction with a couples counselor robot",
            "venue": "Proceedings of ACM/IEEE International Conference on HumanRobot Interaction (HRI), pages 294\u2013303.",
            "year": 2019
        },
        {
            "authors": [
                "Oriol Vinyals",
                "Quoc Le."
            ],
            "title": "A neural conversational model",
            "venue": "https://arxiv.org/abs/1506. 05869.",
            "year": 2015
        },
        {
            "authors": [
                "Jian Wang",
                "Junhao Liu",
                "Wei Bi",
                "Xiaojiang Liu",
                "Kejing He",
                "Ruifeng Xu",
                "Min Yang."
            ],
            "title": "Improving knowledge-aware dialogue generation via knowledge base question answering",
            "venue": "Proceedings of the AAAI conference on artificial intelligence, volume 34:05,",
            "year": 2020
        },
        {
            "authors": [
                "Kohei Yamamoto",
                "Kazutaka Shimada."
            ],
            "title": "Acquisition of knowledge with time information from twitter",
            "venue": "Proceedings of International Conference on Asian Language Processing (IALP), pages 148\u2013 153.",
            "year": 2019
        },
        {
            "authors": [
                "Wojciech Zaremba",
                "Ilya Sutskever",
                "Oriol Vinyals."
            ],
            "title": "Recurrent neural network regularization",
            "venue": "https://doi.org/10.48550/arXiv.1409.2329.",
            "year": 2015
        },
        {
            "authors": [
                "Houyu Zhang",
                "Zhenghao Liu",
                "Chenyan Xiong",
                "Zhiyuan Liu."
            ],
            "title": "Grounded conversation generation as guided traverses in commonsense knowledge graphs",
            "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL),",
            "year": 2020
        },
        {
            "authors": [
                "Saizheng Zhang",
                "Emily Dinan",
                "Jack Urbanek",
                "Arthur Szlam",
                "Douwe Kiela",
                "Jason Weston"
            ],
            "title": "Personalizing dialogue agents: I have a dog, do you have pets too",
            "venue": "In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL),",
            "year": 2018
        },
        {
            "authors": [
                "Wangchunshu Zhou",
                "Qifei Li",
                "Chenle Li."
            ],
            "title": "Learning from perturbations: Diverse and informative dialogue generation with inverse adversarial training",
            "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
            "year": 2021
        },
        {
            "authors": [
                "Daniel M Ziegler",
                "Nisan Stiennon",
                "Jeffrey Wu",
                "Tom B Brown",
                "Alec Radford",
                "Dario Amodei",
                "Paul Christiano",
                "Geoffrey Irving."
            ],
            "title": "Fine-tuning language models from human preferences",
            "venue": "https: //arxiv.org/abs/1909.08593.",
            "year": 2019
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "In the last few years, generative dialogue models have achieved outstanding performance (Ziegler et al., 2019; Adiwardana et al., 2020; Ouyang et al., 2022; Thoppilan et al., 2022) and have been used in various applications, including search engines, recommendations, healthcare, finance, and more (Ling et al., 2023). As chatbots permeate our daily lives, more and more people expect chatbots to behave in a human-like manner. Examples of research to make chatbots more human-like include the introduction of common sense (Wang et al., 2020), empathy (Ma et al., 2020), personas (Zhang et al., 2018), and so forth. The common point among these studies is that they have achieved richer dialogue by actively utilizing not only internal information obtained through the conversation but also external information that does not appear in the current dialogue. On the other hand, time information,\n1The detailed information about our dataset is available at https://github.com/nttcslab/ time-considerable-dialogue-model\nthe most basic and important external information, still does not seem to be considered important in dialogue models.\nHumans are basically always aware of time in conversation, whether explicitly or implicitly, because the naturalness of utterances and responses may change based on their spoken times (e.g., time of the day, day of the week, and season). Given an utterance and its spoken time, a response can be categorized into the following four types by focusing on the time variations of its naturalness:\n\u2022 AN: always natural\n\u2022 TN: temporarily natural at the spoken time\n\u2022 TU: temporarily unnatural at the spoken time\n\u2022 AU: always unnatural\nFigure 1 shows examples of the above four types of responses. Assume two time periods, day and night, where responses (1)-(4) have different levels of naturalness at different times. Responses (1) and (2) (N \u225c AN \u222a TN) are natural to a given utterance at a spoken time, although not (3) and (4)\n(U \u225c TU \u222aAU). On the other hand, the naturalness of (2) and (3) (T \u225c TN\u222aTU) changes with the spoken time (day or night), and that of (1) and (4) (A \u225c AN \u222aAU) remains unchanged. Hereafter in this paper, we refer to such categorization of responses as the NUTA categories.\nFor a dialogue model to achieve natural conversation, it is expected to generate natural responses N and to avoid generating unnatural responses U. If a dialogue model correctly evaluates the naturalness of responses considering the spoken time, we call it time-aware; otherwise, we call it time-unaware. Many existing dialogue models are time-unaware because they are trained on datasets without time information. As a result, a time-unaware dialogue model may consider TU responses as natural as N responses because they are natural at some time. In other words, it may generate a TU response, which is inappropriate at the spoken time. The simplest way to construct a time-aware dialogue model is to train a general dialogue model with time information (Sato et al., 2017). Recently, the output of a large language model (LLM) was adjusted by giving an appropriate prompt (Lester et al., 2021; Bae et al., 2022; Liu et al., 2022), and prompting the time information to an LLM is another promising way to achieve a time-aware dialogue model. The difference between time-unaware and timeaware dialogue models is that the former considers a response as natural if it is natural at some time, while the latter does if it is natural at its spoken time; namely, time-aware dialogue models avoid generating TU responses.\nPrior research has shown that users\u2019 impressions of dialogue models are improved by actively utilizing external information (Vinyals and Le, 2015; Li et al., 2016; Zhou et al., 2021). Referring to this fact, we assume that users\u2019 impressions will be similarly improved by actively utilizing time information; namely, users prefer TN to AN (we empirically verify this assumption in Section 3). Under this assumption, we aim to realize a timeconsiderable dialogue model that actively outputs more TN than AN. The difference between timeaware and time-considerable models is that the former only considers time information to evaluate the naturalness of responses at a given spoken time (time-aware naturalness), while the latter actively generates responses whose naturalness varies with time. To realize time-considerable models, we need a new criterion to distinguish between TN\nand AN and a new mechanism to generate TN responses.\nIn this paper, we propose a new reranking method that is a post-processing method to make existing dialogue models more time-considerable. As a preliminary analysis, we first verify our assumption users tend to prefer TN to AN by human evaluation in Section 3. We next formally define the NUTA categories and propose an automatic metric for the NUTA categories in Section 4. In Section 5, we propose a new reranking method using the proposed automatic metric to make existing dialogue models time-considerable and subjectively evaluate obtained time-considerable models to verify whether our reranking method improves response qualities."
        },
        {
            "heading": "2 Related Work",
            "text": "Previous studies have pointed out that general dialogue models trained on large-scale datasets tend to generate neutral (bland, generic, and hackneyed) responses (Li et al., 2016; Serban et al., 2016). To tackle this issue, some dialogue models utilizing external information to generate interesting and informative responses have been proposed, where examples of external information include system/user persona (Zhang et al., 2018; Roller et al., 2021; Lu et al., 2022), knowledge graphs (Zhang et al., 2020), knowledge sources (Parthasarathi and Pineau, 2018; Majumder et al., 2022), interpersonal relationships (Utami and Bickmore, 2019), and situated environments (Misu, 2018). Some studies have empirically shown that generating responses specific to external information improved users\u2019 impression of the dialogue models (Vinyals and Le, 2015; Li et al., 2016; Zhou et al., 2021). In this paper, we introduce the time information as external information and consider that T responses, whose naturalness varies with time, are specific to time information. Furthermore, to verify whether the time information improves model performance as well as other external information, we evaluate the qualities of T responses by human evaluations.\nIn this paper, we define a dialogue model as timeaware if the model evaluates the naturalness of responses considering their spoken times. Sato et al. (2017) proposed a time-aware dialogue model that is an encoder-decoder model based on Long-Short Term Memory (LSTM) (Zaremba et al., 2015) inspired by Johnson et al. (2017) and trained on utterance-response pairs with their timestamps ex-\ntracted from Twitter. Another recent technique to achieve a time-aware dialogue model is prompting LLMs, where prompting is a technique to guide LLMs in generating high-quality and relevant responses by providing detailed descriptions and/or input-output examples of the target task as input (Brown et al., 2020). Various promptingbased methods for utilizing external information have been proposed, and their examples include system/user persona information (Kasahara et al., 2022; Lee et al., 2022), knowledge sources (Liu et al., 2022), and fictional character\u2019s style (Han et al., 2022). In this paper, we aim to construct a time-considerable dialogue model, which actively utilizes the time information, and propose a new reranking method to make the existing dialogue models more time-considerable using time-aware naturalness represented by a time-aware dialogue model. While time-aware dialogue models only consider time to evaluate the naturalness of responses, time-considerable dialogue models actively generate responses whose naturalness varies with time."
        },
        {
            "heading": "3 Preliminary Analysis",
            "text": "Through this paper, we assume users prefer TN to AN, and in this section, we verify this assumption by human evaluations. We first constructed a NUTA dataset consisting of the tuples of utterances, their spoken times, their responses, and their NUTA categories: AN,TN,TU, and AU. Then, we conducted a subjective evaluation to determine which category of responses users found most interesting and informative."
        },
        {
            "heading": "3.1 The NUTA Dataset",
            "text": "We constructed a NUTA dataset, which is a collection of tuples t \u225c \u27e8u, t, r, c\u27e9, where u is an utterance, t \u2208 T \u225c {0, 1, . . . , 23} is its spoken time in 24-hour time format, r is a response to u, and c \u2208 {AN,TN,TU,AU} is its NUTA category.\nWe first prepared a set of utterances U . We extracted Japanese tweets posted between May and December 2022 with filtering rules described in Appendix A.1 and randomly selected 1,000 tweets. We manually deleted tweets containing discriminatory, violent, or other inappropriate expressions. As a result, we obtained 640 appropriate tweets and used them as utterances U .\nWe next obtained responses to the prepared utterances U by crowdsourcing, where we used\nLancers2, a Japanese crowdsourcing service. We assigned one crowd worker to each utterance u \u2208 U and asked them to perform the following tasks to create responses:\n1. Create response rANu to u that is natural at any time.\n2. Select two time periods tN and tU (tN, tU \u2208 T ) and create response rTNu to u that is natural at tN but not at tU.\nFor instance, given utterance u = \u201cIt seems the train is stopped,\u201d the crowd worker selected two time periods t = 22 and t\u2032 = 6 and created two responses rANu = \u201cReally? I wonder when it will start moving.\u201d and rTNu = \u201cWow, it\u2019s almost the last train. I wonder what\u2019s going to happen?\u201d\nFinally, we constructed a NUTA dataset by creating the following four tuples for each utterance u \u2208 U , where u\u2032 was randomly chosen from U so that u \u0338= u\u2032:\n\u27e8u, tN, rANu ,AN\u27e9, \u27e8u, tN, rTNu ,TN\u27e9, \u27e8u, tU, rTNu ,TU\u27e9, \u27e8u, tN, rANu\u2032 ,AU\u27e9.\nThus, the dataset consists of 2,560 (= |U| \u00d7 4) tuples. Table 1 shows examples of four created tuples for the same utterance."
        },
        {
            "heading": "3.2 Subjective Evaluation",
            "text": "We conducted a subjective evaluation to determine which response category is the most interesting and informative for humans.\nWe introduced a new metric to measure the quality of responses considering time information. The metric is in the range [0, 1] and based on the Sensibleness, Specificity, Interestingness (SSI) metric (Thoppilan et al., 2022) for evaluating responses based on context. Our metric, denoted by SSI-t, averages the following four scores:\n\u2022 Sensibleness for the utterance (SU): If its spoken time is ignored, is the response reasonable to its utterance?\n\u2022 Sensibleness for the spoken time (ST): If its utterance is ignored, is the response reasonable to its spoken time?\n\u2022 Specificity to time (S): Is the response specific to any time regardless of its spoken time?\n\u2022 Interestingness (I): Is the response interesting or informative?\n2https://www.lancers.jp/\nu . The utterance and all responses were originally written in Japanese and\ntranslated into English by the authors.\nFor example, a score SU of 1.0 indicates r is a perfect response to u if t is ignored, and a score S of 0.0 indicates the naturalness of r never changes over time.\nWe randomly selected 25 tuples for each NUTA category (100 tuples in total). For any tuple t = \u27e8u, t, r, c\u27e9 and any score SC \u2208 {SU, ST, S, I}, we asked two expert annotators, who are in-house workers specialized in annotating dialogues and have worked in their positions for at least five years, to rate SC of t with either 0 or 1. We defined the SC value of t as the average of two obtained rates and the SSI-t value of t as the average of all SC values of t. Finally, for any NUTA category c and any score SC \u2208 {SU, ST, S, I, SSI-t}, we obtained the SC value of c by averaging those of all tuples t whose categories are c. Table 2 shows four examples of tuples and their obtained values.\nTable 3 shows the SSI-t scores for each NUTA category and indicates that TN achieved the highest quality (SSI-t): more specifically, the highest ST and I scores. We believe that the results support our assumption that users prefer TN to AN, and based on this assumption, we will propose a method to realize a time-considerable dialogue model that actively outputs more TN than AN."
        },
        {
            "heading": "4 Automatic Metric for NUTA Categories",
            "text": "We propose a new automatic metric for classifying the NUTA categories of given responses and experimentally show that our metric can correctly categorize the responses of the NUTA dataset."
        },
        {
            "heading": "4.1 Definition",
            "text": "We mathematically introduce the time-aware naturalness and the time dependency of responses and define the NUTA categories using those quantities. Let u, r, and t be an utterance, a response to u, and the time at which the conversation took place.\nTime-aware naturalness We assume that the time-aware naturalness (TAN) of u and r at t is implicitly defined by conditional probability distribution p(u, r | t) = p(u | t) p(r | u, t), where p(u | t) and p(r | u, t) indicate the TANs of u at t and r given u at t. We consider N responses of the NUTA categories as natural at spoken time t; i.e., response r is classified as N (resp. U) iff p(r | u, t) is high (resp. low). Since it is very difficult to know the true TAN p, throughout this paper, we assume that TAN p is given as a time-aware dialogue model that allows us to evaluate p(r | u, t) for any u, r, and t.\nChange of naturalness Using TAN p, we define the change of (log) naturalness (CN) from t\u2032 to t as\nCNt\u2032:t(u, r) \u225c ln p(u, r | t) p(u, r | t\u2032) , (1)\nCNt\u2032:t(u) \u225c ln p(u | t) p(u | t\u2032) , (2)\nCNt\u2032:t(r | u) \u225c ln p(r | u, t) p(r | u, t\u2032) . (3)\nBy definition, the following equation must hold:\nCNt\u2032:t(u, r) = CNt\u2032:t(u) + CNt\u2032:t(r | u) , (4)\nwhere the CN of conversation (u, r) can be factorized into the CNs of u and r given u. For instance, CNt\u2032:t(u, r) > 0 holds iff the conversation (u, r) is more natural at t than at t\u2032.\nTime dependency Using the above CN, we define time dependency (TD) of r given u as\nTD(r | u, t) \u225c max tU\u2208T CNtU:t(r | u) , (5)\nTD(r | u) \u225c max tN\u2208T\nTD ( r | u, tN ) . (6)\nTD(r | u, t), denoted by TD@t, is the CN of r given u from the most unnatural time tU to spoken\ntime t, which evaluates whether r is specific to spoken time t. Consequently, r has a high TD@t if it is natural at t but unnatural at another time and a low TD (i.e., near zero) if its naturalness remains unchanged as time changes. On the other hand, TD(r | u), denoted by TD@all, is the CN from the most unnatural time tU to the most natural time tN, which evaluates whether r is specific to time or not. So, r has a high TD@all if it is natural at some time but not at another time. Since we consider the naturalness of T responses of the NUTA categories varies with time, r is classified as T (resp. A) iff TD(r | u) is high (resp. low).\nNUTA category By the definitions of TAN p(r | u, t) and TD@all TD(r | u), we define each NUTA category by Table 4. For instance, response r is classified as TN iff both p(r | u, t) and TD(r | u) are high, and r is classified as AU iff both p(r | u, t) and TD(r | u) are low. Strictly speaking, to use this definition, two thresholds must be set that distinguish between the high and low of p(r | u, t) and TD(r | u); however, since we believe that determining these thresholds in advance is difficult, all the methods proposed in this paper are designed so that they do not require such thresholds.\nRelated criteria In natural language processing, various criteria have been proposed for measuring the dependency between two sentences. Li et al. (2016) proposed pointwise mutual information (PMI) to choose appropriate response r to given utterance u:\nPMI(r | u) \u225c log p(r | u) p(r) . (7)\nAs an extension of PMI, Paranjape and Manning (2021) proposed pointwise conditional mutual information (PCMI) to cope with additional external information other than utterance u to evaluate an appropriate response to u. Given utterance u, response r, and time information t as external information, PCMI@t is defined as\nPCMI(r | u, t) \u225c log p(r | u, t) p(r | u) , (8)\nwhere let p(r | u) be the time-unaware naturalness (TUN). While TD@t in Eq. (5) is the CN of r given u from the most unnatural time tU to the current time t, PCMI@t is the CN of r given u when the naturalness changes from TUN to TAN at t. In a similar manner as TD@all, we define PCMI@all as PCMI(r | u) \u225c maxtN\u2208T PCMI ( r | u, tN ) .\nWe believe our TD is a more appropriate metric for time information than PCMI. PCMI considers the presence or absence of time information, not its change; however, time information always exists and changes, unlike such common external information as user persona and knowledge graphs. Therefore, PCMI is expected to be more blurred in its evaluation than TD. For instance, suppose two time ranges, t1 and t2, such that p(t1) = p(t2) = 0.5 where (u, r) is a strongly time-specific response such that p(r | u, t1) = 0 (i.e., r cannot be a response to u at t1) and p(r | u, t2) = 1 (i.e., r is a perfect response to u at t2). Then, p(r | u) = 0.5 since p(r | u) =\u2211\nt\u2208{t1,t2} p(t)p(r | u, t). By Eqs. (3), (5) and (6), TD(r | u) = \u221e where TD@all considers r as a strongly time-specific response. On the other hand, PCMI(r | u, t) = ln 2 \u2248 0.69 where PCMI@all considers r as not so time-specific. Thus, using TUN p(r | u) blurs the evaluation of time dependency, and our TD@all is expected to detect timespecific responses more clearly than PCMI@all."
        },
        {
            "heading": "4.2 Experiments",
            "text": "We conducted experiments to show that our automatic metric for the NUTA categories correctly orders responses of the NUTA dataset of Section 3.1."
        },
        {
            "heading": "4.2.1 Experimental Settings",
            "text": "For each utterance u \u2208 U , we ranked four tuples containing u in the NUTA dataset by each quantity: TUN p(r | u), TAN p(r | u, t), TD@all TD(r | u), TD@t TD(r | u, t), PCMI@all PCMI(r | u), and PCMI@t PCMI(r | u, t). We attached a label high (resp. low) to the top (resp. bottom) of two tuples in each ranking for each quantity and used the obtained labels to classify NUTA categories.\nAs TUN p(r | u), we used the Transformerbased Japanese dialogue model (TJD) (Sugiyama et al., 2023) with 1.6B parameters trained on more than two billion tweet-reply pairs: (u, r). We constructed TAN p(r | u, t) by fine-tuning the above model using tweet-reply-time triplets: (u, r, t), where the fine-tuning dataset was obtained similarly as (Sato et al., 2017): we collected Japanese tweets with replies from August 2021 to April 2022 with filtering rules described in Appendix A.1 and obtained 470,255,625 triplets. We denote the fine-tuned time-aware TJD by TJD-t and used TJD p(r | u) and TJD-t p(r | u, t) to evaluate TD@all/t and PCMI@all/t. Detailed implementational settings are shown in Appendix A.2."
        },
        {
            "heading": "4.2.2 Experimental Results",
            "text": "We first checked whether TAN p(r | u, t) and TD@all TD(r | u) correctly classified N and T. Using high/low labels obtained by each quantity, we categorized tuples with high (resp. low) labels as N (resp. U) and computed the accuracy of the N category of each quantity. Similarly, we also computed the accuracy of the T category. Table 5 shows the accuracies of each quantity and indicates that TAN and TD@all achieved the highest accuracy of N and T. Consequently, TAN and TD@all are appropriate quantities for evaluating the naturalness and time dependency of responses.\nNext, we checked whether the combination of TAN and TD@all correctly classified each NUTA category. We categorized tuples into one of AN, TN, TU, and AU according to Table 4 using the combination of high/low labels obtained by TAN and those obtained by one of TD@all, TD@t, PCMI@all, and PCMI@t. Table 6 shows the accuracy of each NUTA category of each combination and indicates that TD@all achieved the best average accuracy; however, for the TN category, TD@t achieved the best. Since TD@t evaluates whether response r is specific to the current time t but not to other times, it is more effective to detect TN responses than TU responses. Because our original motivation for using these quantities as automatic metrics for the NUTA categories is to detect TN responses that users prefer than AN, we conclude that TD@t TD(r | u, t) is the most appropriate metric for constructing a timeconsiderable dialogue model."
        },
        {
            "heading": "5 Time-Considerable Dialogue Models",
            "text": "We propose a new reranking method to make existing dialogue models time-considerable. We applied our method to various existing models, including GPT-4, which is a state-of-the-art LLM, and evaluated the time-considerable dialogue models to verify whether they improved response qualities."
        },
        {
            "heading": "5.1 Proposed Reranking method",
            "text": "Let M be any dialogue model that can generate multiple responses to the same utterance. Our proposed reranking method extends M to be timeconsiderable. Given base dialogue model M, TAN p(r | u, t), positive integer N , and probability \u03b4, we obtain time-considerable response r\u2217 to utterance u at time t by the following manner:\n1. Generate N candidate responses to u at t, denoted by R \u225c {ri | i \u2208 [N ]}, from base dialogue model M,\n2. Evaluate TAN p(ri | u, t) for all ri \u2208 R and delete ri from R if r has no sufficient naturalness; i.e., p(ri | u, t) \u2264 \u03b4,\n3. Evaluate TD@t TD(ri | u, t) for all ri \u2208 R and find the most time-specific response r\u2217 \u2208 maxr\u2208RTD(r | u, t), 4. Return obtained r\u2217 as a time-considerable response to u at t.\nSince Step 2 removes candidate responses with lower naturalness than threshold \u03b4, the filtering mechanism may improve the naturalness of the final response r\u2217 when the response generation model is weak.\nOur proposed reranking method is simple but strong because we can create various timeconsiderable dialogue models by combining existing base dialogue models and TANs, where\nbase dialogue model M is required only to generate multiple responses for the same utterance and TAN p(r | u, t) only to be evaluable. Namely, our method can be applied to dialogue models whose architectures and parameters are not publicly available but are provided as APIs. Of course, if M is time-aware and evaluable, it can also be used as TAN p(r | u, t)."
        },
        {
            "heading": "5.2 Experiments",
            "text": "We applied our proposed reranking method to existing dialogue models and gauged their performance by human subjective evaluations."
        },
        {
            "heading": "5.2.1 Experimental Settings",
            "text": "We briefly explain our experimental settings, and the detailed settings are shown in Appendix A.2.\nBase dialogue models We used the following four dialogue models as base dialogue model M of our proposed reranking method:\n1. TJD is a transformer-based Japanese dialogue model with 1.6B parameters trained on over two billion tweet-reply pairs (Sugiyama et al., 2023) described in Section 4.2.\n2. TJD-t is a time-aware TJD obtained by finetuning described in Section 4.2.\n3. GPT-3.5 is an extension LLM of GPT3 (Brown et al., 2020) with 355B parameters and supports various tasks in many languages. gpt-3.5-turbo is a specialized GPT-3.5 for dialogue tasks and is provided as an API.\n4. GPT-4 is a large-scale multimodal model that extends GPT-3.5 (OpenAI, 2023). gpt-4 is a specialized GPT-4 for dialogue tasks and is provided as an API.\nAll models can generate multiple responses for the same utterance by top-p sampling (Holtzman et al., 2020), where p is a hyperparameter and set to 0.9 through the experiments. Since GPT-3.5 and GPT-4 do not treat time information as input, they are originally time-unaware; however, in our experiment, we used them with prompts to generate time-aware responses. We created prompts based on a sample prompt for dialogue tasks provided by OpenAI and shown in Appendix A.2.\nSettings on proposed reranking method For any base dialogue model M, we denote timeconsiderable M achieved by our proposed reranking method by TC-M (e.g., TC-TJD, TC-GPT4). Throughout the experiments, we used TJD-t as TAN p(r | u, t) and set N = 20 and \u03b4 = 0, where N is the number of candidate responses to be generated and \u03b4 is a threshold for filtering candidate responses by their naturalness. We set \u03b4 = 0 because we used sufficiently strong models for response generation and did not aim to improve their naturalness.\nTime intervals Since TD@t is the maximum of CNtU:t(r | u) for all possible tU \u2208 T , tU could be very close to spoken time t, and in such cases, the time dependency of r might be not interpretable for humans since it is too short-term. To avoid detecting such short-term time dependency, we divided 24 hours into three intervals, morning (3 to 8), noon (9 to 17), and night (18 to 2), and defined their representatives as 6, 13, and 22, with reference to Yamamoto and Shimada (2019). The reason of adopting the above intervals is that morning/noon/night is defined based on the human lifecycle; thus, this interval is more intuitive for human understanding. We evaluated TD@t by Eq. (5) with T as representatives except for one of spoken time t (e.g., t = 10 \u21d2 T = {6, 22}).\nEvaluation dataset As an evaluation dataset, we prepared 100 utterance-time pairs in the same manner as U in Section 3.1, where we excluded the same tweets as the NUTA dataset. Given utterance u and its spoken time t, for each base dialogue model M \u2208 {TJD, TJD-t, GPT-3.5, GPT-4}, we generated the best response of M and a timeconsiderable response of TC-M, denoted by r\u0304M and r\u2217M. Thus, the evaluation dataset consisted of 100 tuples of u, t, and responses r\u0304M and r\u2217M for each M.\nEvaluation criteria For each dialogue model, we computed the average output response length (len) and distinct-N (N = 1, 2), which is the ratio of the number of unique N -grams to the total words generated by the dialogue model, for evaluating its diversity (Li et al., 2016). We also obtained the ST, SU, S, I, and SSI-t scores defined in Section 3.2 by human subjective evaluations. We assigned five crowd workers for each response and asked them to evaluate its SU, ST, S, and I scores with a fivepoint Likert scale (1 to 5) and normalized them into [0, 1] scale. We obtained the SU, ST, S, and I values of each model by averaging the annotated values of responses generated by the model. Finally, we obtained its SSI-t value as the average of those values."
        },
        {
            "heading": "5.2.2 Experimental Results",
            "text": "Table 7 shows the values of each model for the eight indicates: the average output response length (len), distinct-N (N = 1, 2), SU, ST, S, I, and SSIt scores. For any score except len, a higher value denotes a better result. In the table, if the score of TC-M exceeds the original M, we highlighted it in bold; in other words, bold scores were improved by our proposed reranking method.\nTC-M improved the ST, S, and SSI-t scores for almost all M; namely, it was more timeconsiderable than the original M. TC-M tended to prefer a short response to M because the len of TC-M is smaller than M for each model. For GPTs, the distinct-N , SU, and I scores of TCM were slightly lower than M. This is because those scores of M were already sufficiently high, and our reranking method aims to improve timeconsiderability but not diversity and general sensibility of naturalness. Consequently, we confirmed that our reranking method improved the quality of the existing dialogue models.\nOne interesting observation from this experiment is that TJD-t, which we used as TAN p(r | u, t), had lower quality than TJD. This fact suggests that fine-tuning explained in 4.2 was not enough and that our reranking method improved the performance of the existing dialogue models even if TAN\u2019s performance is somewhat low. However, of course, using TAN with low performance is not desirable. For GPTs, TC-M achieved a higher S score but lower SU and I scores than the original M. We believe this deterioration of SU and I scores can be easily avoided using a more accurate model as TAN, such as GPT-4.\nTable 8 shows example responses r\u0304M and r\u2217M generated by each M and TC-M, where r\u0304M and r\u2217M are shown in white and gray rows. The result indicates r\u2217M contained more time-specific expressions than r\u0304M; e.g., \u201cI overslept\u201d in the morning and \u201cthanks for today\u201d at night. The detailed analysis is described in Appendix A.3. For the first utterance, the original GPT-4 already generated time-specific responses, and TC-GPT-4 selected the same response as its output; namely, in this example, TC-GPT-4 considered that the original response was sufficiently time-considerable."
        },
        {
            "heading": "6 Conclusion",
            "text": "We proposed a new reranking method to construct time-considerable dialogue models that distinguish between always natural responses AN and temporally natural responses TN and actively output TN. We verified the assumption users prefer TN to AN by human evaluations and introduced a new metric to classify the NUTA categories of responses. We proposed a new reranking method to make existing dialogue models time-considerable using the metric and empirically showed that our\nmethod improved the qualities of existing models. A promising future study is to control the degree to which a time-considerable dialogue model actively uses time information in different situations. Not only time information but all external information is valuable when used appropriately, but excessive use may harm the users\u2019 impression. Therefore, we plan to develop a mechanism to estimate an appropriate TD@t value that a response should have in the current situation and to output or generate a response with the estimated value."
        },
        {
            "heading": "Acknowledgements",
            "text": "This work was supported by JSPS KAKENHI Grant Number 19H05693.\nLimitations\nEffect of TAN\u2019s quality In our proposed reranking method, we used TJD-t, which is a time-aware transformer-based Japanese dialogue model obtained by fine-tuning, as TAN, but our experimental result showed the quality of TJD-t was lower than the other models. One of our contributions is that we empirically showed that our reranking method\nsuccessfully improved the S (specificity to time) score of each model even though the quality of TAN (TJD-t) is somewhat low. However, it would be desirable to investigate how the effectiveness of our proposed method changes as the quality of TAN changes.\nDifferent types of time information In this paper, we used the time of day as time information. However, there are other types of time information that have longer periods, such as day of the week and seasons. It is promising future research to investigate how the quality of dialogues changes with the use of such longer periodic time information.\nCultural differences in time information In this paper, we investigate the effect of the use of time information on dialogues in Japanese; however, it has been shown that the time-specific expression varies depending on the country and culture (Shwartz, 2022). Therefore, it is desirable to investigate whether the proposed method can produce timeconsiderable responses for different languages.\nEthics Statement\nIn this paper, we employed workers using a crowdsourcing service. We made sure that the workers were paid above the minimum wage. It applies to all crowdsourcing experiments in this paper."
        },
        {
            "heading": "A Appendix",
            "text": "A.1 Dataset Construction We describe the filtering rules used to obtain the NUTA dataset in Section 3 and the fine-tuning dataset in Section 4.\nNUTA dataset In Section 3, we constructed the NUTA dataset which is a collection of tuples of utterances, their spoken times, their responses, and their NUTA categories. As utterances, we extracted Japanese tweets posted between May and December 2022 that satisfied the following conditions:\n\u2022 Do not contain URLs, usernames, other tweets, parentheses, \u2022 Consists of 6 to 30 characters, \u2022 Not posted by users whose names contain\n\u201cbot\u201d, \u2022 Not Replied to another tweet.\nWe randomly selected 1,000 tweets from the extracted tweets and manually deleted tweets containing discriminatory, violent, or inappropriate expressions. As a result, we obtained 640 appropriate tweets and used them as utterances U .\nFine-tuning dataset In Section 4, we constructed a fine-tuning dataset in the same manner as Shwartz (2022) to obtain time-aware TJD by training TJD on the obtained dataset. We collected Japanese tweet-reply pairs with their timestamp posted between August 2021 to April 2022 that do not contains URLs or other tweets. As a result, we obtained 470,255,625 triplets.\nA.2 Implementational and Experimental Settings\nWe here describe the detailed settings of our implementation and experiments.\nTJD and TJD-t For a time-unaware dialogue model, we used TJD which is a transformerbased Japanese dialogue model with 1.6B parameters trained on over two billion tweet-reply pairs (Sugiyama et al., 2023). We downloaded the trained TJD 3 and obtained a time-aware TJD, denoted by TJD-t, by fine-tuning TJD on Fairseq 4 (Ott et al., 2019), which is a sequence modeling toolkit to train custom models for various takes including translation, summarization,\n3https://github.com/nttcslab/ japanese-dialog-transformers\n4https://github.com/facebookresearch/fairseq\nlanguage modeling, and other text generation tasks. In fine-tuning, we used SentencePiece 5 (Kudo and Richardson, 2018) to tokenize utterances and responses written in Japanese. Table 9 shows the hyperparameters we set to in fine-tuning. We used the computational resource of AI Bridging Cloud Infrastructure (ABCI) provided by the National Institute of Advanced Industrial Science and Technology (AIST).\nGPT-3.5/4 We used GPT-3.5 and GPT-4 (OpenAI, 2023) as state-of-the-art dialogue models. Since architectures and parameters of GPT-3.5/4 were not publicly available, we used OpenAI APIs gpt-3.5-turbo and gpt-4 to generate responses of GPT-3.5/4. We created the following prompt based on a sample prompt for dialogue tasks provided by OpenAI and gave the prompt as input to GPT-3.5/4 to generate a time-aware response.\nThe current time is [hour], and A and B are having a conversation. Taking into account the current time, generate the following B's response to A's utterance. However, avoid expressions like \"it's [hour] o'clock now.\" A: [utterance] B:\nTD@t in our proposed reranking method As shown in Eq. (5),TD@t is the maximum of CNtU:t(r | u) for all possible tU \u2208 T , and tU could be very close to spoken time t. In such cases, the time dependency of r might be difficult for humans to understand since its naturalness varies in too short-term. To avoid detecting such shortterm time dependency, we divided 24 hours into three intervals, morning (3 to 8), noon (9 to 17),\n5https://github.com/google/sentencepiece\nand night (18 to 2). We used 6, 13, and 22 as the representatives of morning, noon, and night, respectively. The division and their representatives were determined with reference to Yamamoto and Shimada (2019). We computed TD@t by Eq. 5 using the above T excluding the representative of spoken time t. For instance, for t = 10, we use T = {6, 22} to evaluate TD@t because the representative of 10 is defined as 13. We conducted the same experiments as Section 4 using the above TD@t, and Table 10 and 11 show the results. The results indicate that the accuracy of TN classification was slightly improved by introducing the above time intervals but not for the average accuracy. Therefore, it cannot be said that either TD with intervals is better than the original TD."
        },
        {
            "heading": "N 0.60 0.68 0.48 0.61 0.48 0.55",
            "text": ""
        },
        {
            "heading": "T 0.54 0.54 0.65 0.58 0.51 0.48",
            "text": ""
        },
        {
            "heading": "AN 0.50 0.39 0.41 0.38",
            "text": ""
        },
        {
            "heading": "TN 0.48 0.61 0.39 0.51",
            "text": ""
        },
        {
            "heading": "TU 0.41 0.15 0.30 0.14",
            "text": ""
        },
        {
            "heading": "AU 0.46 0.45 0.34 0.32",
            "text": "A.3 Time-specific Expressions We conducted a subjective evaluation to count the number of time-specific expressions by authors. As a result, our method increased their occurrences by 80% and 8% for TJD-t and GPT-4, respectively. These results on occurrences of time-specific expression are consistent with the improvements in S shown in Table 7."
        }
    ],
    "title": "Time-Considerable Dialogue Models via Reranking by Time Dependency",
    "year": 2023
}