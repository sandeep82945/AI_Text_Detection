{
    "abstractText": "In this work, we propose a weak supervision pipeline SWEET: Supervise Weakly for Entity Extraction to fight Trafficking for extracting person names from noisy escort advertisements. Our method combines the simplicity of rulematching (through antirules, i.e., negated rules) and the generalizability of large language models fine-tuned on benchmark, domain-specific and synthetic datasets, treating them as weak labels. One of the major challenges in this domain is limited labeled data. SWEET addresses this by obtaining multiple weak labels through labeling functions and effectively aggregating them. SWEET outperforms the previous supervised SOTA method for this task by 9% F1 score on domain data and better generalizes to common benchmark datasets. Furthermore, we also release HTGEN, a synthetically generated dataset of escort advertisements (built using ChatGPT) to facilitate further research within the community.",
    "authors": [
        {
            "affiliations": [],
            "name": "Javin Liu"
        },
        {
            "affiliations": [],
            "name": "Hao Yu"
        },
        {
            "affiliations": [],
            "name": "Vidya Sujaya"
        },
        {
            "affiliations": [],
            "name": "Pratheeksha Nair"
        },
        {
            "affiliations": [],
            "name": "Kellin Pelrine"
        },
        {
            "affiliations": [],
            "name": "Reihaneh Rabbany"
        }
    ],
    "id": "SP:7925cb1fe2a277ba76e7e8151cee7dc22a506b9f",
    "references": [
        {
            "authors": [
                "Alan Akbik",
                "Tanja Bergmann",
                "Duncan Blythe",
                "Kashif Rasul",
                "Stefan Schweter",
                "Roland Vollgraf."
            ],
            "title": "FLAIR: An easy-to-use framework for state-of-theart NLP",
            "venue": "NAACL 2019, 2019 Annual Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Alan Akbik",
                "Duncan Blythe",
                "Roland Vollgraf."
            ],
            "title": "Contextual string embeddings for sequence labeling",
            "venue": "Proceedings of the 27th International Conference on Computational Linguistics, pages 1638\u20131649, Santa Fe, New Mexico, USA. Associa-",
            "year": 2018
        },
        {
            "authors": [
                "Alan Akbik",
                "Duncan Blythe",
                "Roland Vollgraf."
            ],
            "title": "Contextual string embeddings for sequence labeling",
            "venue": "COLING 2018, 27th International Conference on Computational Linguistics, pages 1638\u2013 1649.",
            "year": 2018
        },
        {
            "authors": [
                "Emily M Bender",
                "Timnit Gebru",
                "Angelina"
            ],
            "title": "McMillanMajor, and Shmargaret Shmitchell",
            "year": 2021
        },
        {
            "authors": [
                "Stephen Bonifacio"
            ],
            "title": "Creating a chatgpt based chatbot using \u201cin-context learning",
            "year": 2023
        },
        {
            "authors": [
                "Nicholas Carlini",
                "Florian Tramer",
                "Eric Wallace",
                "Matthew Jagielski",
                "Ariel Herbert-Voss",
                "Katherine Lee",
                "Adam Roberts",
                "Tom B Brown",
                "Dawn Song",
                "Ulfar Erlingsson"
            ],
            "title": "Extracting training data from large language models",
            "year": 2021
        },
        {
            "authors": [
                "Lingjiao Chen",
                "Matei Zaharia",
                "James Zou"
            ],
            "title": "How is chatgpt\u2019s behavior changing over time? arXiv preprint arXiv:2307.09009",
            "year": 2023
        },
        {
            "authors": [
                "Leon Derczynski",
                "Kalina Bontcheva",
                "Ian Roberts."
            ],
            "title": "Broad Twitter corpus: A diverse named entity recognition resource",
            "venue": "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 1169\u2013",
            "year": 2016
        },
        {
            "authors": [
                "Leon Derczynski",
                "Eric Nichols",
                "Marieke van Erp",
                "Nut Limsopatham."
            ],
            "title": "Results of the WNUT2017 shared task on novel and emerging entity recognition",
            "venue": "Proceedings of the 3rd Workshop on Noisy User-generated Text, pages 140\u2013147, Copenhagen,",
            "year": 2017
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "arXiv preprint arXiv:1810.04805.",
            "year": 2018
        },
        {
            "authors": [
                "Ning Ding",
                "Guangwei Xu",
                "Yulin Chen",
                "Xiaobin Wang",
                "Xu Han",
                "Pengjun Xie",
                "Haitao Zheng",
                "Zhiyuan Liu."
            ],
            "title": "Few-NERD: A few-shot named entity recognition dataset",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational",
            "year": 2021
        },
        {
            "authors": [
                "Fabrizio Gilardi",
                "Meysam Alizadeh",
                "Ma\u00ebl Kubli."
            ],
            "title": "Chatgpt outperforms crowd-workers for textannotation tasks",
            "venue": "arXiv preprint arXiv:2303.15056.",
            "year": 2023
        },
        {
            "authors": [
                "Pengcheng He",
                "Jianfeng Gao",
                "Weizhu Chen."
            ],
            "title": "Debertav3: Improving deberta using electra-style pretraining with gradient-disentangled embedding sharing",
            "venue": "arXiv preprint arXiv:2111.09543.",
            "year": 2021
        },
        {
            "authors": [
                "Matthew Honnibal",
                "Ines Montani",
                "Sofie Van Landeghem",
                "Adriane Boyd"
            ],
            "title": "spacy: Industrialstrength natural language processing in python",
            "year": 2020
        },
        {
            "authors": [
                "Fan Huang",
                "Haewoon Kwak",
                "Jisun An."
            ],
            "title": "Is chatgpt better than human annotators? potential and limitations of chatgpt in explaining implicit hate speech",
            "venue": "arXiv preprint arXiv:2302.07736.",
            "year": 2023
        },
        {
            "authors": [
                "Fan Huang",
                "Haewoon Kwak",
                "Jisun An."
            ],
            "title": "Is {ChatGPT} better than human annotators? potential and limitations of {ChatGPT} in explaining implicit hate speech",
            "venue": "Companion Proceedings of the ACM Web Conference 2023. ACM.",
            "year": 2023
        },
        {
            "authors": [
                "Ben Hutchinson",
                "Vinodkumar Prabhakaran",
                "Emily Denton",
                "Kellie Webster",
                "Yu Zhong",
                "Stephen Denuyl."
            ],
            "title": "Social biases in NLP models as barriers for persons with disabilities",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational",
            "year": 2020
        },
        {
            "authors": [
                "International Labour Organization."
            ],
            "title": "Global estimates of modern slavery: forced labour and forced marriage",
            "venue": "https://www.ilo.org/ wcmsp5/groups/public/---ed_norm/---ipec/ documents/publication/wcms_854733.pdf.",
            "year": 2022
        },
        {
            "authors": [
                "Hang Jiang",
                "Yining Hua",
                "Doug Beeferman",
                "Deb Roy."
            ],
            "title": "Annotating the tweebank corpus on named entity recognition and building NLP models for social media analysis",
            "venue": "CoRR, abs/2201.07281.",
            "year": 2022
        },
        {
            "authors": [
                "Mayank Kejriwal",
                "Rahul Kapoor."
            ],
            "title": "Networktheoretic information extraction quality assessment in the human trafficking domain",
            "venue": "Applied Network Science, 4(1):1\u201326.",
            "year": 2019
        },
        {
            "authors": [
                "Mayank Kejriwal",
                "Pedro Szekely",
                "Craig Knoblock."
            ],
            "title": "Investigative knowledge discovery for combating illicit activities",
            "venue": "IEEE Intelligent Systems, 33(1):53\u201363.",
            "year": 2018
        },
        {
            "authors": [
                "Keita Kurita",
                "Nidhi Vyas",
                "Ayush Pareek",
                "Alan W Black",
                "Yulia Tsvetkov."
            ],
            "title": "Measuring bias in contextualized word representations",
            "venue": "Proceedings of the First Workshop on Gender Bias in Natural Language Processing, pages 166\u2013172, Florence, Italy.",
            "year": 2019
        },
        {
            "authors": [
                "Meng-Chieh Lee",
                "Catalina Vajiac",
                "Aayushi Kulshrestha",
                "Sacha Levy",
                "Namyong Park",
                "Cara Jones",
                "Reihaneh Rabbany",
                "Christos Faloutsos."
            ],
            "title": "Infoshield: Generalizable information-theoretic humantrafficking detection",
            "venue": "2021 IEEE 37th Inter-",
            "year": 2021
        },
        {
            "authors": [
                "Lagunas",
                "Alexander Rush",
                "Thomas Wolf."
            ],
            "title": "Datasets: A community library for natural language processing",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 175\u2013184, Online",
            "year": 2021
        },
        {
            "authors": [
                "Haoran Li",
                "Dadi Guo",
                "Wei Fan",
                "Mingshi Xu",
                "Jie Huang",
                "Fanpu Meng",
                "Yangqiu Song"
            ],
            "title": "Multi-step jailbreaking privacy attacks on chatgpt",
            "year": 2023
        },
        {
            "authors": [
                "Yifei Li",
                "Pratheeksha Nair",
                "Kellin Pelrine",
                "Reihaneh Rabbany."
            ],
            "title": "Extracting person names from user generated text: Named-entity recognition for combating human trafficking",
            "venue": "Findings of the Association for Computational Linguistics: ACL 2022, pages",
            "year": 2022
        },
        {
            "authors": [
                "Pierre Lison",
                "Jeremy Barnes",
                "Aliaksandr Hubin."
            ],
            "title": "skweak: Weak supervision made easy for NLP",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language",
            "year": 2021
        },
        {
            "authors": [
                "Yi Liu",
                "Gelei Deng",
                "Zhengzi Xu",
                "Yuekang Li",
                "Yaowen Zheng",
                "Ying Zhang",
                "Lida Zhao",
                "Tianwei Zhang",
                "Yang Liu"
            ],
            "title": "Jailbreaking chatgpt via prompt engineering: An empirical study",
            "year": 2023
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Ilya Loshchilov",
                "Frank Hutter."
            ],
            "title": "Decoupled weight decay regularization",
            "venue": "arXiv preprint arXiv:1711.05101.",
            "year": 2017
        },
        {
            "authors": [
                "Xinhao Mei",
                "Chutong Meng",
                "Haohe Liu",
                "Qiuqiang Kong",
                "Tom Ko",
                "Chengqi Zhao",
                "Mark D. Plumbley",
                "Yuexian Zou",
                "Wenwu Wang"
            ],
            "title": "Wavcaps: A chatgpt-assisted weakly-labelled audio captioning dataset for audio-language multimodal research",
            "year": 2023
        },
        {
            "authors": [
                "S.D. MINOR"
            ],
            "title": "A report on the use of technology to recruit, groom and sell domestic minor sex trafficking",
            "year": 2015
        },
        {
            "authors": [
                "Shubhanshu Mishra",
                "Jana Diesner."
            ],
            "title": "Semisupervised named entity recognition in noisy-text",
            "venue": "Proceedings of the 2nd Workshop on Noisy Usergenerated Text (WNUT), pages 203\u2013212.",
            "year": 2016
        },
        {
            "authors": [
                "Chirag Nagpal",
                "Kyle Miller",
                "Benedikt Boecking",
                "Artur Dubrawski."
            ],
            "title": "An entity resolution approach to isolate instances of human trafficking online",
            "venue": "Proceedings of the 3rd Workshop on Noisy Usergenerated Text, pages 77\u201384, Copenhagen, Denmark.",
            "year": 2017
        },
        {
            "authors": [
                "Joel Nothman",
                "Nicky Ringland",
                "Will Radford",
                "Tara Murphy",
                "James R. Curran."
            ],
            "title": "Learning multilingual named entity recognition from Wikipedia",
            "venue": "Artificial Intelligence, 194:151\u2013175.",
            "year": 2012
        },
        {
            "authors": [
                "Matthew E. Peters",
                "Mark Neumann",
                "Mohit Iyyer",
                "Matt Gardner",
                "Christopher Clark",
                "Kenton Lee",
                "Luke Zettlemoyer."
            ],
            "title": "Deep contextualized word representations",
            "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for",
            "year": 2018
        },
        {
            "authors": [
                "Reihaneh Rabbany",
                "David Bayani",
                "Artur Dubrawski."
            ],
            "title": "Active search of connections for case building and combating human trafficking",
            "venue": "Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 2120\u2013",
            "year": 2018
        },
        {
            "authors": [
                "Lev Ratinov",
                "Dan Roth."
            ],
            "title": "Design challenges and misconceptions in named entity recognition",
            "venue": "Proceedings of the thirteenth conference on computational natural language learning (CoNLL-2009), pages 147\u2013155.",
            "year": 2009
        },
        {
            "authors": [
                "Alexander J Ratner",
                "Christopher M De Sa",
                "Sen Wu",
                "Daniel Selsam",
                "Christopher R\u00e9."
            ],
            "title": "Data programming: Creating large training sets, quickly",
            "venue": "Advances in neural information processing systems, 29.",
            "year": 2016
        },
        {
            "authors": [
                "Leanne Maree Rhodes."
            ],
            "title": "Human trafficking as cybercrime",
            "venue": "AGORA INTERNATIONAL OF ADMINISTRATION SCIENCES, 4:23\u201329.",
            "year": 2016
        },
        {
            "authors": [
                "Thorn."
            ],
            "title": "Report on the use of technology to recruit, groom and sell domestic minor sex trafficking victims",
            "venue": "https: //27l51l1qnwey246mkc1vzqg0-wpengine. netdna-ssl.com/wp-content/uploads/2015/",
            "year": 2015
        },
        {
            "authors": [
                "Erik F. Tjong Kim Sang",
                "Fien De Meulder."
            ],
            "title": "Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition",
            "venue": "Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, pages 142\u2013",
            "year": 2003
        },
        {
            "authors": [
                "Yiqi Tong",
                "Yidong Chen",
                "Xiaodong Shi."
            ],
            "title": "A multi-task approach for improving biomedical named entity recognition by incorporating multi-granularity information",
            "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages",
            "year": 2021
        },
        {
            "authors": [
                "Scao",
                "Sylvain Gugger",
                "Mariama Drame",
                "Quentin Lhoest",
                "Alexander M. Rush."
            ],
            "title": "Transformers: State-of-the-art natural language processing",
            "venue": "Proceedings of the 2020 Conference on Empirical",
            "year": 2020
        },
        {
            "authors": [
                "Ikuya Yamada",
                "Akari Asai",
                "Hiroyuki Shindo",
                "Hideaki Takeda",
                "Yuji Matsumoto."
            ],
            "title": "LUKE: Deep contextualized entity representations with entityaware self-attention",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Lan-",
            "year": 2020
        },
        {
            "authors": [
                "Yuhao Zhang",
                "Victor Zhong",
                "Danqi Chen",
                "Gabor Angeli",
                "Christopher D. Manning."
            ],
            "title": "Position-aware attention and supervised data improve slot filling",
            "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages",
            "year": 2017
        },
        {
            "authors": [
                "Yiming Zhu",
                "Peixian Zhang",
                "Ehsan-Ul Haq",
                "Pan Hui",
                "Gareth Tyson"
            ],
            "title": "Can chatgpt reproduce human-generated labels? a study of social computing tasks",
            "year": 2023
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Over 6.3 million people worldwide are victims of forced sexual exploitation or human trafficking (HT) on any given day (International Labour Organization), and the majority of the victims have been advertised online (Polaris, 2021; MINOR, 2015) through escort websites (Rhodes, 2016). HT is an organized crime and traffickers tend to advertise multiple victims simultaneously. Hence, finding connections between online escort advertisements hints towards them being posted by the same individual and strongly indicates organized activity.\nSeveral methods have previously taken the approach of uncovering connections between ads by looking for repeated phrases, phone numbers, locations, prices, service types, etc., in the text (Lee et al., 2021; Tong et al., 2021; Rabbany et al., 2018). Hence, efficient entity extractors must extract accurate and relevant information from ad text (Nagpal\n\u2217These authors contributed equally to this research.\net al., 2017; Li et al., 2022; Kejriwal et al., 2018; Kejriwal and Kapoor, 2019). However, this is very challenging because the text is often noisy, ungrammatical, and obscured. Information related to the names of individuals, services, locations, etc, often have letters replaced by symbols or emojis. The writing style constantly evolves and is made adversarial to avoid detection by online filters and moderators.\nBased on discussions with domain experts, including criminologists, law enforcement, and other groups fighting trafficking, it was determined that extracting advertised names from the ads is particularly important. Traffickers tend to control, on average, four to six victims and often post advertisements on their behalf (Thorn, 2015). Hence, multiple people being advertised in the same or similar ads is a strong indicator of trafficking (Lee et al., 2021). Other entities such as locations, phone numbers and email addresses could also be informative. However, most websites have explicit fields for these entities which makes them more straightforward to extract. The same is not true for person names which are usually embedded inside the text of the ads and are much more complex to extract.\nTraditional extraction methods, such as the embedding-based Flair (Akbik et al., 2018a) and Spacy NLP models, do not do well on this type of data because they are sensitive to noise and tend to decrease in performance as more noise is injected into the data (Li et al., 2022). NEAT (Li et al., 2022) stands as the current SOTA name extractor in this domain and uses an ad-hoc combination of a name dictionary, a rule dictionary, and a BERT-based disambiguation layer. Moreover, NEAT relies on a sample of manually labeled data to provide optimal results. This is a challenge because the relevant datasets for this task are typically curated in-house and not shared publicly due to their sensitive nature. Similar constraints also apply to methods such as crowd-sourcing.\nTo address these challenges, we propose a weakly supervised method SWEET (Supervise Weakly for Entity Extraction to fight Trafficking)1, that efficiently extracts person names from escort ads and is independent of training labels. We define label-independence in the scope of our work as not requiring domain or task-specific labels. SWEET uses a novel combination of fine-tuned language models (elucidated in Section 3), antirules, and an HMM-based method of aggregating them. Our contributions are:\n\u2022 Novel: We study the problem of name extraction from noisy text through the novel lens of weak supervision and propose a new method.\n\u2022 Effective: The proposed method SWEET is very effective and outperforms the previous SOTA in person name extraction on domain data by 9% F1 score.\n\u2022 Label-efficient: SWEET leverages weak labels that are easy and cheap to obtain. This is very useful in several real-world applications, particularly in the HT domain, where obtaining labels is expensive and challenging due to the sensitive nature of the data.\n\u2022 Improving reproducibility: We also introduce HTGEN, a synthetically generated dataset of escort ads which, unlike the real-world datasets used in papers in this domain, can be published for further research and helps with reproducibility."
        },
        {
            "heading": "2 Background",
            "text": "In this section, we cover the background information and related works necessary to understand this paper\u2019s context better.\nNamed Entity Recognition Named Entity Recognition (NER) is the task of identifying elements in the text that correspond to high-level categories like PERSON, ORGANIZATION, LOCATION, DATES, and other concrete concepts that can be explicitly named. The NER task aims to extract all occurrences of such entities. In this paper, the focus is on human names because they are most associated with an HT victim and names are the most common entity type to appear in escort ads.\n1Our code is available at https://github.com/ComplexDataMILA/HT-NER\nEntity extraction from escort ads This is an important task that involves identifying and extracting named entities from a given ad. Rule-based models typically rely on regular expressions, handcrafted rules, and gazetteer-based approaches. For person names, NEAT (Li et al., 2022) is the SOTA method that combines a gazetteer (person name dictionary) with a regular expression extractor (rule dictionary) and a RoBERTa (Liu et al., 2019) based disambiguation layer called HT-bert. Such rulebased systems were shown(Li et al., 2022) to have a better performance over statistical models (Devlin et al., 2018; Peters et al., 2018; Liu et al., 2019) on the noisy escort ads dataset. However, on benchmark NER datasets, NEAT performs much worse. This is a likely result of its rule-based components designed to capture patterns in escort ads. Rule-based approaches can also be complementary to statistical-based approaches. In other domains, (Ratinov and Roth, 2009) argued that the NER task relies highly on external knowledge and shows that a statistical model combined with a rulebased gazetteer match makes a better-performing hybrid model.\nWeak supervision Since we consider multiple sources of weak labels for our task, we rely on a popular weak-supervision framework, Skweak, for label aggregation and learning. Skweak (Lison et al., 2021) is a Python-based weak supervision framework made specifically for NER tasks. It works together with the Spacy library (Honnibal et al., 2020), allowing users to create labeling functions (LFs) that label an input text token as a type of entity and facilitates downstream processing. Skweak provides a variety of different LF types: heuristics, gazetteers and document-level functions allowing us to easily combine weak signals from our proposed combination of rule based systems and LLMs. These make Skweak a better choice compared to other weak label aggregators such as Snorkel (Ratner et al., 2016). The labels obtained from these LFs are later aggregated using a Hidden Markov Model (HMM).\nThe HMM\u2019s states and observations correspond to the true labels and LF outputs respectively. Skweak relies on a majority vote strategy (where each LF is a voter) to get a predicted label. This is then used to calculate the HMM\u2019s initial transition and emission probabilities, which are then updated until convergence using the Baum-Welch algorithm. To account for possible dependencies\nbetween LFs, Skweak tempers the probability density (weight) of an LF depending on its redundancy. It decreases the weight of an LF that produces a label of type \u2018PERSON\u2019, for example, if it shows high recall with other LFs that also produce \u2018PERSON\u2019 labels (high overlap in predictions). Post aggregation, a separate classifier model can be trained on the HMM\u2019s aggregated results and used directly on other datasets without requiring the LFs or the HMM.\nLarge Language Models Recent works (Gilardi et al., 2023; Huang et al., 2023a) have shown that ChatGPT can be used as a data annotator and addresses ethical concerns regarding using human labelers on datasets that contain sensitive information. We experimented with using ChatGPT to extract person names from ads and used this labeled set to fine-tune BERT-based models as LFs in our framework.\nWe also experimented with using ChatGPT for generating escort ads to create an additional domain dataset. It has been shown that LLMs like ChatGPT exhibit stochastic behaviours (Bender et al., 2021) and are susceptible to biases from the real world internet data it was trained on. Recently, several works (Li et al., 2023) (Liu et al., 2023) have demonstrated effective jailbreak techniques that bypass the content filters that are imposed on ChatGPT to limit the level of bias and toxic language output by ChatGPT. (Carlini et al., 2021) could also extract training data directly from GPT LLMs."
        },
        {
            "heading": "3 Methodology",
            "text": "In this paper, we introduce a hybrid weakly supervised Skweak-based model that uses both rulebased approaches (such as \"antirules\" detailed below) and statistical-based approaches (such as DeBERTa and RoBERTa models trained on different NER datasets) as labeling functions and combine them into a single, more effective predictor. Our methodology pipeline is in Figure 1.\nThe proposed weak supervision pipeline in SWEET consists of 2 main types of LFs:\n1. Antirules: Rules that determine entities as not person-names. The top X% most frequent words of the dataset (X \u2208 {10, 20, 30, 40, 50}) are annotated as \u201cNOT_NAME\u201d, resulting in 5 antirule LFs in total. The antirules help counteract possible noise.\n2. Fine-tuned Models: We fine-tune base versions of RoBERTa (Liu et al., 2019) and DeBERTav3 (He et al., 2021) for the task of Named Entity Recognition on six different datasets, namely: the train splits of CoNLL2003 (Tjong Kim Sang and De Meulder, 2003), WNUT2017 (Derczynski et al., 2017), Few-NERD (Ding et al., 2021) (Only Level 1), WikiNER (English) (Nothman et al., 2012), a domain dataset labelled by ChatGPT called HTUNSUP, and a domain dataset generated and labeled by ChatGPT called HTGEN. The details and labeling method of HTUNSUP are provided in Section 4.6 and Appendix A, respectively. In total, 12 fine-tuned models (one per dataset and model type) act as LFs in SWEET. Any word predicted by a fine-tuned model, that matches a white-space-separated word in the ad text, gets annotated as a \u201cPERSON_NAME\u201d according to that LF.\nUsing the Skweak framework, we fit an HMM on the annotated train set and apply the fitted model on the annotations to obtain a final set of aggregated labels. The HMM\u2019s initial parameters are obtained using a majority voter that treats each LF as a voter of equal weight to get a predicted label.\nWe also experimented with using the three components of previous SOTA NEAT (Li et al., 2022) as LFs but ultimately found it did not boost performance (see NEAT (Weakly Supervised) in Table 3). Specifically, we considered:\n1. Context Rules: extract person names based on part-of-speech (POS) tags and common phrases that include names. The rules consist of regular expressions that work to capture the most common contexts where names are seen. (eg. I\u2019m NNP, My name is NNP, You can call me NNP).\n2. Name Dictionary: common names with confidence scores tuned based on frequency in indomain data. These names are used in gazetteer matching, where the names are used as the gazetteer and the pipeline, given a word in a sentence, will check if it is a word in this dictionary/gazetteer.\n3. Word Disambiguation: filters results of the weighted output of rule and dictionary extractor with the help of a DeBERTaV3 model that was fine-tuned for the task of masked language modeling on a domain dataset (Li et al., 2022).\nDuring the training of the DeBERTaV3 model, individual words are masked and the task for the model is to predict these masked words. A word\u2019s context is passed to the fill mask, and the number of correct predictions (the number of predictions by the fill mask that is in the name dictionary) is divided by the total number of predictions by the fill mask to get a confidence score for the disambiguation."
        },
        {
            "heading": "4 Datasets",
            "text": "To fine-tune SWEET LFs, we used 4 open-source datasets, namely the training sets of CoNLL2003, WNUT2017, FewNERD-L1, and WikiNER-en, and 2 escort ad datasets, namely HTUNSUP and HTGEN. To evaluate SWEET, we used the test sets of CoNLL2003, WNUT2017, BTC, Tweebank and an escort ad dataset called HTNAME. We also generated a domain dataset HTGEN whose train set was used for fine-tuning LFs and test set was used for evaluating SWEET. We provide the dataset statistics in Table 1, and the descriptions below."
        },
        {
            "heading": "4.1 CoNLL2003",
            "text": "CoNLL2003(Tjong Kim Sang and De Meulder, 2003) is a very popular baseline for evaluating the performance of different NLP systems and algorithms. Our experiments use CoNLL2003 data from the HuggingFace which is in English. For evaluation, we only consider the name annotations (i.e, B-PER and I-PER) and ignore other entity classes."
        },
        {
            "heading": "4.2 WNUT2017",
            "text": "WNUT2017(Derczynski et al., 2017) consists of user-generated text and contains many examples of informal language, abbreviations, misspellings, and other noisy characteristics. Due to this, models tend to have lower recall values on WNUT2017.\nSimilar to CoNLL2003, we use only the B-PER and I-PER classes for evaluation."
        },
        {
            "heading": "4.3 Broad Twitter Corpus (BTC)",
            "text": "The Broad Twitter Corpus (BTC) (Derczynski et al., 2016) dataset is a large, diverse, and high-quality annotated corpus, created for the development and evaluation of NER in social media. BTC includes tweets from different regions, time periods, and types of Twitter users. It was annotated by a combination of NLP experts and crowd workers, ensuring both high quality and crowd recall."
        },
        {
            "heading": "4.4 Tweebank",
            "text": "Tweebank(Jiang et al., 2022) was developed to address the challenges of analyzing social media data, specifically Twitter messages through NER and syntactic parsing. The researchers created a new English NER corpus called Tweebank-NER based on Tweebank and annotated it using Amazon Mechanical Turk."
        },
        {
            "heading": "4.5 HTNAME",
            "text": "This is a modified version of the HT1k dataset from (Li et al., 2022) consisting of 995 escort advertisements in English and French, where we rectified three main types of labeling errors. 1. Parsing issues - in cases where the first name\nand last name were joined as a single string (FirstNameLastName) were not correctly annotated as \u201cFirstName, LastName\u201d. 2. Apostrophe issue - cases where an extra s is added to the name. Examples like \u2018Mizz Mercede\u2019s parlour\u2019 was wrongly annotated as \u2018Mercedes\u2019 (the s should not be included as the name). 3. Blank labels - a significant number of examples were missing true labels. We manually added the missing labels and reintroduce this dataset as HTNAME."
        },
        {
            "heading": "4.6 HTUNSUP",
            "text": "HTUNSUP was gathered by us from private escort websites and has around 6000 ads. Multiple recent works have shown that ChatGPT\u2019s strong performance on text related tasks makes it a strong candidate for automatic labeling of certain types of data (Huang et al., 2023b; Mei et al., 2023; Zhu et al., 2023). Additionally, due to its outstanding performance on HTNAME (Table 2), we use it to generate pseudo labels for HTUNSUP, which we treat as ground-truth.\nWeak Labeling of HTUNSUP We used the ChatGPT API (gpt-3.5-turbo) to extract person-name entities from ads. The average token count including the prompt, ad and response was 263. Due to content moderation and dialogue optimization, on encountering improper or explicit text (as in the case of escort ads), ChatGPT responds incoherently and for such cases, we return \u201cno entity detected\u201d.\nThe prompt used was: \"I want you to act as a natural and no-bias labeler, extract human names and location or address and social media link or tag in the format \u2018Names: \\nLocations: \\nSocial:\n\u2019. If multiple entities exist, separate them by |. If no entity exists, say N. Your words should extract from the given text, can\u2019t add/modify any other words, should be as short as possible, remember don\u2019t include the phone number. For one name, it should be less than 3 words.\"\nAfter post-processing and removing certain rare, high-frequency wrong predictions manually, we obtain HTUNSUP with high-quality pseudo labels and use it for fine-tuning BERT models."
        },
        {
            "heading": "4.7 HTGEN: Generated escort ads dataset",
            "text": "We explore ChatGPT\u2019s ability to generate escort ads with the motivation of developing a shareable domain specific dataset for furthering research in this field2.\nWe used role playing to convince ChatGPT (API with GPT-3.5-turbo-0301) that it is a researcher studying patterns in escort ads. This bypasses the filters meant to reduce inappropriate outputs, misuse, and generation of text found in such ads. We followed up with a description of the entities in the ads and some of the patterns unique to the HT domain. (Bonifacio, 2023) had shown that providing the context before every question often helped improve the output quality. We also provided a sample conversation between a user (who provides the prompt) and ChatGPT (providing the required generated response) from three examples taken from our private HTNAME dataset. We scrambled phone numbers and other sensitive data for privacy reasons. In this manner, we generated 10,000 synthetic escort ads called HTGEN and used them to fine-tune a BERT model. At the time of writing, it costs $0.002 per 1000 tokens, and for 10,000 ads, it costs approximately $4.40 USD. This is significantly cheaper than hiring manual labelers.\nWe provide examples of ads from HTNAME and HTGEN in appendix D but note that some contain explicit language. The ads generated by ChatGPT are pretty similar to those in HTNAME, and ChatGPT was successfully able to replicate the patterns and noise of the HT domain."
        },
        {
            "heading": "5 Experimental Setup",
            "text": ""
        },
        {
            "heading": "5.1 Baselines",
            "text": "We compare SWEET with eight baselines, including off-the-shelf libraries, BERT-based models, domain-specific NER methods and a simple majority vote for aggregating weak labels as opposed to Skweak, ordered by their appearance in our result tables.\n\u2022 Spacy3 \u2013 A popular open-source Python library for natural language processing tasks. The Spacy NER package uses statistical models, neural network architectures and deep learning techniques trained on large amounts of data.\n2The exact prompts used and the code for the dataset generation can be provided upon request.\n3https://spacy.io/usage/linguistic-features# named-entities\n\u2022 TwitterNER (Mishra and Diesner, 2016) \u2013 semi-supervised approach that combines text cluster information and word embeddings and uses a CRF for NER \u2022 LUKE (Yamada et al., 2020) \u2013 transformer based model that learns contextualized embeddings, fine-tuned on TACRED dataset (Zhang et al., 2017) \u2022 ELMo (Peters et al., 2018) \u2013 model that learns contextualized word representations, tuned for NER \u2022 Flair (Akbik et al., 2018b) \u2013 trained character language model that learns contextualized string embeddings, tuned for NER \u2022 NEAT (Li et al., 2022) \u2013 previous SOTA for person name extraction from escort ads \u2022 NEAT (Weakly Supervised) \u2013 a variation of NEAT where each individual component is treated as an LF in our weak supervision pipeline \u2022 Majority Vote \u2013 a simple strategy of choosing the label based on consensus of majority of the weak labels, competitor to Skweak."
        },
        {
            "heading": "5.2 Evaluation Settings",
            "text": "We compare the performance of SWEET with its variants and the baselines using the average F1 classification score on 5-folds of the test set. For each run, 1 fold acted as the test set while the remaining were used to fit the HMM. Since we only consider the \u2018PERSON\u2019 class, we adopt the following evaluation metrics to better fit our use case.\n\u2022 Word-level matching: both ground truth and prediction are split into words (separated by a space) and each word is treated as a separate entity. \u2022 Lowercase: both the ground truth and predictions are converted to lowercase. \u2022 Exact Match: since the entity matching is on the word level, we consider strict match as a True Positive sample."
        },
        {
            "heading": "5.3 Results",
            "text": "Tables 3 and 4 summarize the results of our experiments for the general and HT domain datasets respectively.\nOverall performance of SWEET: SWEET obtains the highest F1 score and recall on 4 out of 6 datasets, and beats NEAT on all datasets. On the HT datasets, SWEET performs the best. On general noisy datasets, WNUT2017 and BTC, SWEET similarly performs the best. On CoNLL2003, Flair\nand ELMo achieve higher scores than SWEET, but SWEET is the next best performing model. On Tweebank, TwitterNER, designed specifically for tweets, is the best performing method. Please note that on re-evaluating NEAT on HTNAME, we found an increase in the strict F1 score from the previous results (0.76 from Table 2 in Li et al. (2022) becomes 0.78), and use this stronger performance as the baseline, as reported in Table 4.\nComparison of SWEET with NEAT: When compared with NEAT on the domain datasets, SWEET increases F1 score and recall by 9% and 18% respectively whilst maintaining precision. Furthermore, SWEET significantly surpasses NEAT on CoNLL2003, WNUT2017, BTC and Tweebank. This may be attributed to signals from the finetuned DeBERTa and RoBERTa LFs as well as false positive reduction due to the antirules.\nPerformance of SWEET v.s. individual LFs: In Table 5, we report the performance of individual labeling functions. When compared to the performance of SWEET in Table 4, we can see that SWEET successfully combines different fine-tuned models resulting in an aggregated model that outperforms these individual models, even those finetuned on domain data (HTUNSUP and HTGEN). SWEET\u2019s recall and precision scores being higher than all individual fine-tuned LFs (except for precision on HTNAME which is on-par with HTUNSUP), shows the success of weak supervision in using weaker sources (LFs) to produce a stronger final model. The weak supervision methodology however can impact the performance significantly as we can see in Table 3 and Table 4, when comparing a simple majority vote performance with the proposed SWEET. The majority vote baseline still performs relatively well, and shows strong recall, however, SWEET performs significantly better in 5 out of 6 datasets.\nAblation Study Table 6 shows the results of ablation experiments of SWEET, focused on the HT datasets. Firstly, removing antirules decrease precision, showing that they are helpful in informing the model on what is not a name. Meanwhile, we see a mixed effect of domain LFs in the model. In row 3, we observe the highest precision and F1 scores on HTName with the removal of in-domain LFs. On HTGen, we instead see a significant decrease, but note that it is still higher than other baselines in Table 4. In the last rows, we observe that using only\ndomain LFs yields similar F1 scores with SWEET, but compromises recall for precision. We note that without using any domain data (second to last row of Table 4), SWEET is able to achieve the same F1 score as a setup that uses only domain data.\nWe also observe that removing HTUNSUP LFs results in an F1 score decrease only on HTNAME. Moreover, these LFs do as well on their own (last four rows in Table 6), although they are still lower than SWEET on HTNAME, showing that the aggregation of LFs fine-tuned on diverse datasets is a key component of SWEET."
        },
        {
            "heading": "6 Discussion",
            "text": ""
        },
        {
            "heading": "6.1 Effect of using ChatGPT",
            "text": "Although ChatGPT is the best performing model on HTNAME (Table 2), there are concerns regarding its use on escort ads. First, there is some financial cost associated with employing ChatGPT on large datasets of escort ads which limits its accessibility whereas our method is open-source and completely free to use. Second, the stability of the OpenAI API output is a concern as discussed in (Chen et al., 2023). While this does not hurt our method much where one only needs to get good performance a single time (to provide weak labels on a fixed dataset), and one could consider even the more powerful GPT-4, it means it would be unreliable to build a system for real-world applications based on ChatGPT alone. Finally, depending on the method used to access ChatGPT, there can be privacy concerns with this sensitive data. The intended use of our method is on large scale real-time ads with sensitive information, and using ChatGPT, is not feasible due to cost, stability and privacy issues mentioned above.\nMoreover, although ChatGPT is a valuable ingredient in SWEET, our ablations directly show that it is not sufficient. In the target domain our full system achieves 87% F1 (Table 4). Simply apply-\ning language models trained on ChatGPT-labeled data achieves 82% at best (Table 5), significantly lower. Conversely, our approach without using any ChatGPT-labeled data maintains 88% F1 (Table 6, \u201cSWEET\u2013 DomainData\u201d)."
        },
        {
            "heading": "6.2 Label Efficiency",
            "text": "Our pipeline eliminates the need for human labelers as it is independent of training labels for the task at hand, making use of existing open-source labeled data for fine-tuning language models instead. This is advantageous over other label-dependent NER models, especially in the HT domain where data labeling is costly and time-consuming. Being label independent is also beneficial in terms of ethics and privacy as the HT domain contains many examples of private information like names, locations, social media tags, and phone numbers. These types of data would no longer need to be read by a crowdsource worker or human labeler in order to generate labels for training. More importantly, our method is also independent of LFs trained on the same data as the domain. For e.g, SWEET excluding LFs trained on HTGEN and HTUNSUP (SWEET \u2212 DomainData) performs as well or even better than SWEET."
        },
        {
            "heading": "7 Conclusion",
            "text": "In this paper, we introduced SWEET, a weak supervision pipeline that extracts person names from escort ads without the need for manual labeling. The experimental evaluations show that SWEET achieves SOTA results on the HTNAME dataset with an F1 score of 0.87, outperforming the previous SOTA by 9% while also generalizing better to CoNLL2003 and WNUT2017 datasets. Moreover,\nSWEET maintains or improves this performance on removing any LFs trained on relevant domain data. SWEET does not require any human annotators and labeling which is a very important improvement over previous methods because it allows it to be applied easily to real-world datasets. It can also be easily adapted to other domains by designing specific new labeling functions. We also release a new public escort ad dataset HTGEN that uses ChatGPT for both data generation and labeling, which will improve reproducibility and benchmarking in this domain where most data cannot be shared publicly, as it contains personal information."
        },
        {
            "heading": "8 Limitations",
            "text": "Despite SWEET having achieved SOTA results on HTNAME, several limitations need to be considered while interpreting the findings.\n1. Dataset Size and Diversity: The HTNAME database used in this research is a modified version of HT1k from Li et al. (2022). The dataset contains a limited number of data (around 1000 ads). 5-fold evaluation is deployed to accommodate for this small size. While generating HTGEN, although efforts were made to ensure its representativeness and diversity, HTGen\u2019s data may still not be 100% representative of real data. This may limit the generalizability of the models trained on it to other domains or datasets. 2. Explainability and transparency: HT is a high-stakes application domain and transparency, explainability, and accuracy are all equally important. SWEET has the ability to aggregate multiple models together to get a final\nprediction. However, it uses HMM for aggregation which is more complex and less explainable than the ad-hoc way deployed by Li et al. (2022). Moreover, the output of the fine-tuned LFs is also less interpretable. SWEET sacrifices some explainability for increased performance. However, thanks to its modularity, the HMM aggregator can be swapped out for a more explainable method. 3. Cost: We were able to improve performance by aggregating BERT models fine-tuned on a variety of NER datasets. This is time-consuming and costly. We used industrial-grade GPUs (RTX8000, V100 and A100) to fine-tune the BERT models. 4. Privacy: The HT domain contains private information like a person\u2019s name, address, social media tag, email, and phone number. Although the HTNAME and HTUNSUP datasets consists of ads scraped from public websites, these websites may not be fully regulated, and thus, data coming from these ads may violate the privacy of individuals being advertised in those ads. We had to refrain from releasing these datasets because of privacy and ethical concerns. Thus, directly replicating our results on HTNAME and HTUNSUP is not possible. To help counteract this and improve reproducibility, we released HTGEN. 5. Lack of variety: We have shown that the HTGEN dataset generated by ChatGPT contains realistic-sounding ads. However, the ads tend to be more repetitive than our datasets (HTUNSUP, HTNAME) with real data scraped from the web. Changing the temperature settings and other parameters showed promise at boosting the variation in the generations but the model was more inclined to produce nonsensical sentences. Future work should aim at increasing variety in the generated ads and keep noise withing a desired range. With more variety of data in the generations, it would also be possible to decrease the size of HTGEN by reducing the number of redundant examples.\nEthics Statement\nRigorous ethical considerations were taken during the process of this research. The data we use is publicly available, and due to the nature of the advertisements, there are no reasonable expectations for privacy. However, due to the sensitivity of the data, Ethics Approval has been obtained from the\nResearch Ethics Board Office at the authors\u2019 university for using this type of data. We have also studied the current best practices for the project through a commissioned Responsible AI Institute evaluation, one of whose recommendation was to focus on a human-centered design. To this end, we have biweekly consultations with human trafficking survivors and have been mindful of not reproducing biases in the design of the algorithm. No personal attributes such as age, physical descriptors, ethnicity, etc were used. In addition, we have also reviewed the current law and policy implications through a comprehensive legal risk assessment and mitigation memorandum from a law firm. As the laws and policies in this domain are catching up with the technologies, we also plan to conduct research in close collaboration with domain experts into the most ethical approach to AI in this domain. Lastly, for transparency and accountability, all of the algorithms being developed will be made available online. Data scraping scripts and our datasets (except those synthetically generated) will not be shared publicly to maintain confidentiality and anonymity."
        },
        {
            "heading": "9 Acknowledgements",
            "text": "This research is partially funded by the Canada CIFAR AI Chairs Program and Samsung-Mila Research Grant."
        },
        {
            "heading": "A Labeling Functions",
            "text": "Fine-tuned Models For fine-tuning the TokenClassification models, we use a wrapper from Huggingface (Wolf et al., 2020) AutoModelForTokenClassification class to compile different backbones, here RoBERTa and DeBERTaV3. We adopt the train-test split of CONLL2003 and WNUT2017 from the Huggingface datasets (Lhoest et al., 2021) for the convenience of reproducing the results (\"wnut_17\" for WNUT2017, \"conll2003\" for CoNLL2003). For FewNERD-L1 and WikiNERen, we directly downloaded the official stored file and parsed it to the same format as a Dataset loaded from the Datasets Library for running the experiments.\nIn the training stage, the learning rate is relative to batch size, which is 2 \u00d7 10\u22125 \u00d7 (batch_size/128). We train for 5 epochs with AdamW optimizer (Loshchilov and Hutter, 2017) (weight_decay=0.01) on one A100 (40GB) GPU. Detailed information about both the size of the training datasets and the used training batch size are listed in Table 1.\nIndividual Labeling Functions We provide the performance of individual labeling functions in this section. Table 7 shows the performance of LFs used in the NEAT (Weakly Supervised) experiment in Table 3. Table 8 and Table 9 shows the results of individual fine-tuned models used as LFs in SWEET."
        },
        {
            "heading": "B ChatGPT and the HT Domain",
            "text": "ChatGPT is an advanced language model developed by OpenAI and built upon the GPT architecture. Although the training data that is used to train ChatGPT is not made public, it is built upon the GPT (Generative Pre-trained Transformer). These models were trained on Common Crawl, a dataset that includes a wide range of web content and adrelated content. By providing essential background and convincing ChatGPT that it is a researcher that studies human trafficking, we were able to guide it to generate a list of patterns generally seen in escort ads (Figure 2)."
        },
        {
            "heading": "C Problems with LLMs",
            "text": "Large language models, such as ChatGPT have garnered recognition from researchers for their versatility on a wide range of NLP tasks while exhibiting commendable performance compared to other SOTA models. Nevertheless, it is imperative to acknowledge that these models have also faced significant scrutiny and critical appraisals. In this context, we mainly highlight the issue of Encoding Bias.\nDue to the large size of the datasets used to train LLMs, it is very difficult to check and verify every part of the training dataset for potential bias. Thus, it is common for large language models to exhibit various types of bias as stated in (Bender et al., 2021; Hutchinson et al., 2020; Kurita et al., 2019). When building HTGEN, we observed that the generated text had a propensity to include derogatory language (Figure 3), and sexually explicit words (Figure 4). It also generated ads that have a negative sentiment towards the black community (Figure 5). Of all the examples generated in HTGEN, black people are denied services more than any other ethnic group. No mention of the words found in Figures 3 and 4 had occurred in any prompting processes. This ability to generate realistic sounding ads suggests that there is a good chance it had exposure to escort ads during its training process.\nD Examples of escort ads"
        }
    ],
    "title": "SWEET: Weakly Supervised Person Name Extraction for Fighting Human Trafficking",
    "year": 2023
}