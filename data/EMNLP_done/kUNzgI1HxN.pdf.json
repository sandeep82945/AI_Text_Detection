{
    "abstractText": "The use of large language models (LLMs) in natural language processing (NLP) tasks is rapidly increasing, leading to changes in how researchers approach problems in the field. To fully utilize these models\u2019 abilities, a better understanding of their behavior for different input protocols is required. With LLMs, users can directly interact with the models through a text-based interface to define and solve various tasks. Hence, understanding the conversational abilities of these LLMs, which may not have been specifically trained for dialog modeling, is also important. This study examines different approaches for building dialog systems using LLMs by considering various aspects of the prompt. As part of prompt tuning, we experiment with various ways of providing instructions, exemplars, current query and additional context. The research also analyzes the representations of dialog history that have the optimal usable-information density. Based on the findings, the paper suggests more compact ways of providing dialog history information while ensuring good performance and reducing model\u2019s inference-API costs. The research contributes to a better understanding of how LLMs can be effectively used for building interactive systems.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Bishal Santra"
        },
        {
            "affiliations": [],
            "name": "Sakya Basak"
        },
        {
            "affiliations": [],
            "name": "Abhinandan De"
        },
        {
            "affiliations": [],
            "name": "Manish Gupta"
        },
        {
            "affiliations": [],
            "name": "Pawan Goyal"
        }
    ],
    "id": "SP:d0ba681b672bb7e8674fa885e65044d6f31de937",
    "references": [
        {
            "authors": [
                "Daniel Adiwardana",
                "Minh-Thang Luong",
                "David R So",
                "Jamie Hall",
                "Noah Fiedel",
                "Romal Thoppilan",
                "Zi Yang",
                "Apoorv Kulshreshtha",
                "Gaurav Nemade",
                "Yifeng Lu"
            ],
            "title": "Towards a human-like open-domain chatbot",
            "venue": "arXiv preprint arXiv:2001.09977",
            "year": 2020
        },
        {
            "authors": [
                "Satanjeev Banerjee",
                "Alon Lavie."
            ],
            "title": "Meteor: An automatic metric for mt evaluation with improved correlation with human judgments",
            "venue": "Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summariza-",
            "year": 2005
        },
        {
            "authors": [
                "Siqi Bao",
                "Huang He",
                "Fan Wang",
                "Hua Wu",
                "Haifeng Wang."
            ],
            "title": "Plato: Pre-trained dialogue generation model with discrete latent variable",
            "venue": "arXiv preprint arXiv:1910.07931.",
            "year": 2019
        },
        {
            "authors": [
                "Iz Beltagy",
                "Matthew E. Peters",
                "Arman Cohan."
            ],
            "title": "Longformer: The long-document transformer",
            "venue": "ArXiv, abs/2004.05150.",
            "year": 2020
        },
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are few-shot learners. Advances in neural information processing",
            "year": 2020
        },
        {
            "authors": [
                "Mark Chen",
                "Jerry Tworek",
                "Heewoo Jun",
                "Qiming Yuan",
                "Henrique Ponde de Oliveira Pinto",
                "Jared Kaplan",
                "Harri Edwards",
                "Yuri Burda",
                "Nicholas Joseph",
                "Greg Brockman"
            ],
            "title": "Evaluating large language models trained on code",
            "year": 2021
        },
        {
            "authors": [
                "Yulong Chen",
                "Yang Liu",
                "Liang Chen",
                "Yue Zhang."
            ],
            "title": "Dialogsum: A real-life scenario dialogue summarization dataset",
            "venue": "arXiv preprint arXiv:2105.06762.",
            "year": 2021
        },
        {
            "authors": [
                "Aakanksha Chowdhery",
                "Sharan Narang",
                "Jacob Devlin",
                "Maarten Bosma",
                "Gaurav Mishra",
                "Adam Roberts",
                "Paul Barham",
                "Hyung Won Chung",
                "Charles Sutton",
                "Sebastian Gehrmann"
            ],
            "title": "Palm: Scaling language modeling with pathways",
            "year": 2022
        },
        {
            "authors": [
                "Hyung Won Chung",
                "Le Hou",
                "Shayne Longpre",
                "Barret Zoph",
                "Yi Tay",
                "William Fedus",
                "Eric Li",
                "Xuezhi Wang",
                "Mostafa Dehghani",
                "Siddhartha Brahma"
            ],
            "title": "Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416",
            "year": 2022
        },
        {
            "authors": [
                "Emily Dinan",
                "Stephen Roller",
                "Kurt Shuster",
                "Angela Fan",
                "Michael Auli",
                "Jason Weston."
            ],
            "title": "Wizard of wikipedia: Knowledge-powered conversational agents",
            "venue": "arXiv preprint arXiv:1811.01241.",
            "year": 2018
        },
        {
            "authors": [
                "Kawin Ethayarajh",
                "Yejin Choi",
                "Swabha Swayamdipta."
            ],
            "title": "Understanding dataset difficulty with V-usable information",
            "venue": "Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine",
            "year": 2022
        },
        {
            "authors": [
                "Tianyu Gao",
                "Xingcheng Yao",
                "Danqi Chen."
            ],
            "title": "Simcse: Simple contrastive learning of sentence embeddings",
            "venue": "arXiv preprint arXiv:2104.08821.",
            "year": 2021
        },
        {
            "authors": [
                "Bogdan Gliwa",
                "Iwona Mochol",
                "Maciej Biesek",
                "Aleksander Wawer."
            ],
            "title": "Samsum corpus: A humanannotated dialogue dataset for abstractive summarization",
            "venue": "arXiv preprint arXiv:1911.12237.",
            "year": 2019
        },
        {
            "authors": [
                "Hila Gonen",
                "Srini Iyer",
                "Terra Blevins",
                "Noah A Smith",
                "Luke Zettlemoyer."
            ],
            "title": "Demystifying prompts in language models via perplexity estimation",
            "venue": "arXiv preprint arXiv:2212.04037.",
            "year": 2022
        },
        {
            "authors": [
                "Karthik Gopalakrishnan",
                "Behnam Hedayatnia",
                "Qinlang Chen",
                "Anna Gottardi",
                "Sanjeev Kwatra",
                "Anu Venkatesh",
                "Raefer Gabriel",
                "Dilek Hakkani-T\u00fcr."
            ],
            "title": "Topical-chat: Towards knowledge-grounded open-domain conversations",
            "venue": "Proc. Interspeech 2019,",
            "year": 2019
        },
        {
            "authors": [
                "Jianping Gou",
                "Baosheng Yu",
                "Stephen J Maybank",
                "Dacheng Tao."
            ],
            "title": "Knowledge distillation: A survey",
            "venue": "International Journal of Computer Vision, 129:1789\u20131819.",
            "year": 2021
        },
        {
            "authors": [
                "Manish Gupta",
                "Puneet Agrawal."
            ],
            "title": "Compression of deep learning models for text: A survey",
            "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD), 16(4):1\u201355.",
            "year": 2022
        },
        {
            "authors": [
                "Prakhar Gupta",
                "Jeffrey P Bigham",
                "Yulia Tsvetkov",
                "Amy Pavel."
            ],
            "title": "Controlling dialogue generation with semantic exemplars",
            "venue": "arXiv preprint arXiv:2008.09075.",
            "year": 2020
        },
        {
            "authors": [
                "Karl Moritz Hermann",
                "Tomas Kocisky",
                "Edward Grefenstette",
                "Lasse Espeholt",
                "Will Kay",
                "Mustafa Suleyman",
                "Phil Blunsom."
            ],
            "title": "Teaching machines to read and comprehend",
            "venue": "Advances in neural information processing systems, 28.",
            "year": 2015
        },
        {
            "authors": [
                "Geoffrey Hinton",
                "Oriol Vinyals",
                "Jeff Dean."
            ],
            "title": "Distilling the knowledge in a neural network",
            "venue": "arXiv preprint arXiv:1503.02531.",
            "year": 2015
        },
        {
            "authors": [
                "Nikita Kitaev",
                "Lukasz Kaiser",
                "Anselm Levskaya."
            ],
            "title": "Reformer: The efficient transformer",
            "venue": "ArXiv, abs/2001.04451.",
            "year": 2020
        },
        {
            "authors": [
                "Mojtaba Komeili",
                "Kurt Shuster",
                "Jason Weston."
            ],
            "title": "Internet-augmented dialogue generation",
            "venue": "ArXiv preprint, abs/2107.07566.",
            "year": 2021
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdelrahman Mohamed",
                "Omer Levy",
                "Ves Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
            "year": 2019
        },
        {
            "authors": [
                "Chia-Wei Liu",
                "Ryan Lowe",
                "Iulian Serban",
                "Mike Noseworthy",
                "Laurent Charlin",
                "Joelle Pineau."
            ],
            "title": "How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation",
            "venue": "Proceedings of",
            "year": 2016
        },
        {
            "authors": [
                "Pengfei Liu",
                "Weizhe Yuan",
                "Jinlan Fu",
                "Zhengbao Jiang",
                "Hiroaki Hayashi",
                "Graham Neubig."
            ],
            "title": "Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing",
            "venue": "ACM Computing Surveys, 55(9):1\u201335.",
            "year": 2023
        },
        {
            "authors": [
                "Andrea Madotto",
                "Zhaojiang Lin",
                "Genta Indra Winata",
                "Pascale Fung."
            ],
            "title": "Few-shot bot: Promptbased learning for dialogue systems",
            "venue": "arXiv preprint arXiv:2110.08118.",
            "year": 2021
        },
        {
            "authors": [
                "Long Ouyang",
                "Jeffrey Wu",
                "Xu Jiang",
                "Diogo Almeida",
                "Carroll Wainwright",
                "Pamela Mishkin",
                "Chong Zhang",
                "Sandhini Agarwal",
                "Katarina Slama",
                "Alex Ray"
            ],
            "title": "Training language models to follow instructions with human",
            "year": 2022
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych."
            ],
            "title": "Sentence-bert: Sentence embeddings using siamese bert-networks",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th",
            "year": 2019
        },
        {
            "authors": [
                "Stephen Roller",
                "Emily Dinan",
                "Naman Goyal",
                "Da Ju",
                "Mary Williamson",
                "Yinhan Liu",
                "Jing Xu",
                "Myle Ott",
                "Eric Michael Smith",
                "Y-Lan Boureau",
                "Jason Weston."
            ],
            "title": "Recipes for building an open-domain chatbot",
            "venue": "Proceedings of the 16th Conference of",
            "year": 2021
        },
        {
            "authors": [
                "Ananya B Sai",
                "Akash Kumar Mohankumar",
                "Siddhartha Arora",
                "Mitesh M Khapra."
            ],
            "title": "Improving dialog evaluation with a multi-reference adversarial dataset and large scale pretraining",
            "venue": "Transactions of the Association for Computational Linguistics, 8:810\u2013",
            "year": 2020
        },
        {
            "authors": [
                "Victor Sanh",
                "Lysandre Debut",
                "Julien Chaumond",
                "Thomas Wolf."
            ],
            "title": "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter",
            "venue": "ArXiv, abs/1910.01108.",
            "year": 2019
        },
        {
            "authors": [
                "Victor Sanh",
                "Albert Webson",
                "Colin Raffel",
                "Stephen H Bach",
                "Lintang Sutawika",
                "Zaid Alyafeai",
                "Antoine Chaffin",
                "Arnaud Stiegler",
                "Teven Le Scao",
                "Arun Raja"
            ],
            "title": "Multitask prompted training enables zero-shot task generalization",
            "venue": "ICLR",
            "year": 2022
        },
        {
            "authors": [
                "Bishal Santra",
                "Potnuru Anusha",
                "Pawan Goyal."
            ],
            "title": "Hierarchical transformer for task oriented dialog systems",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-",
            "year": 2021
        },
        {
            "authors": [
                "Timo Schick",
                "Hinrich Sch\u00fctze."
            ],
            "title": "Exploiting cloze-questions for few-shot text classification and natural language inference",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,",
            "year": 2021
        },
        {
            "authors": [
                "Timo Schick",
                "Hinrich Sch\u00fctze."
            ],
            "title": "It\u2019s not just size that matters: Small language models are also fewshot learners",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
            "year": 2021
        },
        {
            "authors": [
                "Thibault Sellam",
                "Dipanjan Das",
                "Ankur P Parikh."
            ],
            "title": "Bleurt: Learning robust metrics for text generation",
            "venue": "arXiv preprint arXiv:2004.04696.",
            "year": 2020
        },
        {
            "authors": [
                "Iulian Vlad Serban",
                "Alessandro Sordoni",
                "Ryan Lowe",
                "Laurent Charlin",
                "Joelle Pineau",
                "Aaron C. Courville",
                "Yoshua Bengio."
            ],
            "title": "A hierarchical latent variable encoder-decoder model for generating dialogues",
            "venue": "Proceedings of the Thirty-First AAAI Conference",
            "year": 2017
        },
        {
            "authors": [
                "Xiaoyu Shen",
                "Hui Su",
                "Yanran Li",
                "Wenjie Li",
                "Shuzi Niu",
                "Yang Zhao",
                "Akiko Aizawa",
                "Guoping Long."
            ],
            "title": "A conditional variational framework for dialog generation",
            "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Vol-",
            "year": 2017
        },
        {
            "authors": [
                "Kurt Shuster",
                "Jing Xu",
                "Mojtaba Komeili",
                "Da Ju",
                "Eric Michael Smith",
                "Stephen Roller",
                "Megan Ung",
                "Moya Chen",
                "Kushal Arora",
                "Joshua Lane"
            ],
            "title": "Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage",
            "year": 2022
        },
        {
            "authors": [
                "Emma Strubell",
                "Ananya Ganesh",
                "Andrew McCallum."
            ],
            "title": "Energy and policy considerations for deep learning in nlp",
            "venue": "arXiv preprint arXiv:1906.02243.",
            "year": 2019
        },
        {
            "authors": [
                "Yi Tay",
                "Mostafa Dehghani",
                "Dara Bahri",
                "Donald Metzler."
            ],
            "title": "Efficient transformers: A survey",
            "venue": "ACM Comput. Surv., 55(6).",
            "year": 2022
        },
        {
            "authors": [
                "Romal Thoppilan",
                "Daniel De Freitas",
                "Jamie Hall",
                "Noam Shazeer",
                "Apoorv Kulshreshtha",
                "Heng-Tze Cheng",
                "Alicia Jin",
                "Taylor Bos",
                "Leslie Baker",
                "Yu Du"
            ],
            "title": "Lamda: Language models for dialog applications",
            "venue": "arXiv preprint arXiv:2201.08239",
            "year": 2022
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems, 30.",
            "year": 2017
        },
        {
            "authors": [
                "Ben Wang",
                "Aran Komatsuzaki."
            ],
            "title": "GPTJ-6B: A 6 Billion Parameter Autoregressive Language Model",
            "venue": "https://github.com/ kingoflolz/mesh-transformer-jax.",
            "year": 2021
        },
        {
            "authors": [
                "Sinong Wang",
                "Belinda Z. Li",
                "Madian Khabsa",
                "Han Fang",
                "Hao Ma."
            ],
            "title": "Linformer: Self-attention with linear complexity",
            "venue": "ArXiv, abs/2006.04768.",
            "year": 2020
        },
        {
            "authors": [
                "Yizhong Wang",
                "Swaroop Mishra",
                "Pegah Alipoormolabashi",
                "Yeganeh Kordi",
                "Amirreza Mirzaei",
                "Atharva Naik",
                "Arjun Ashok",
                "Arut Selvan Dhanasekaran",
                "Anjana Arunkumar",
                "David Stap"
            ],
            "title": "Supernaturalinstructions: Generalization via declarative",
            "year": 2022
        },
        {
            "authors": [
                "Jason Wei",
                "Maarten Bosma",
                "Vincent Y Zhao",
                "Kelvin Guu",
                "Adams Wei Yu",
                "Brian Lester",
                "Nan Du",
                "Andrew M Dai",
                "Quoc V Le."
            ],
            "title": "Finetuned language models are zero-shot learners",
            "venue": "arXiv preprint arXiv:2109.01652.",
            "year": 2021
        },
        {
            "authors": [
                "Jason Wei",
                "Yi Tay",
                "Rishi Bommasani",
                "Colin Raffel",
                "Barret Zoph",
                "Sebastian Borgeaud",
                "Dani Yogatama",
                "Maarten Bosma",
                "Denny Zhou",
                "Donald Metzler"
            ],
            "title": "Emergent abilities of large language models. arXiv preprint arXiv:2206.07682",
            "year": 2022
        },
        {
            "authors": [
                "Yu Wu",
                "Furu Wei",
                "Shaohan Huang",
                "Yunli Wang",
                "Zhoujun Li",
                "Ming Zhou."
            ],
            "title": "Response generation by context-aware prototype editing",
            "venue": "The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Ap-",
            "year": 2019
        },
        {
            "authors": [
                "Jing Xu",
                "Arthur Szlam",
                "Jason Weston."
            ],
            "title": "Beyond goldfish memory: Long-term open-domain conversation",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5180\u20135197.",
            "year": 2022
        },
        {
            "authors": [
                "Manzil Zaheer",
                "Guru Guruganesh",
                "Kumar Avinava Dubey",
                "Joshua Ainslie",
                "Chris Alberti",
                "Santiago Onta\u00f1\u00f3n",
                "Philip Pham",
                "Anirudh Ravula",
                "Qifan Wang",
                "Li Yang",
                "Amr Ahmed."
            ],
            "title": "Big bird: Transformers for longer sequences",
            "venue": "ArXiv,",
            "year": 2020
        },
        {
            "authors": [
                "Jingqing Zhang",
                "Yao Zhao",
                "Mohammad Saleh",
                "Peter Liu."
            ],
            "title": "Pegasus: Pre-training with extracted gap-sentences for abstractive summarization",
            "venue": "International Conference on Machine Learning, pages 11328\u201311339. PMLR.",
            "year": 2020
        },
        {
            "authors": [
                "Yizhe Zhang",
                "Siqi Sun",
                "Michel Galley",
                "Yen-Chun Chen",
                "Chris Brockett",
                "Xiang Gao",
                "Jianfeng Gao",
                "Jingjing Liu",
                "Bill Dolan."
            ],
            "title": "Dialogpt: Large-scale generative pre-training for conversational response generation",
            "venue": "arXiv preprint arXiv:1911.00536.",
            "year": 2019
        },
        {
            "authors": [
                "Tiancheng Zhao",
                "Ran Zhao",
                "Maxine Eskenazi."
            ],
            "title": "Learning discourse-level diversity for neural dialog models using conditional variational autoencoders",
            "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume",
            "year": 2017
        },
        {
            "authors": [
                "Qingfu Zhu",
                "Lei Cui",
                "Weinan Zhang",
                "Furu Wei",
                "Ting Liu."
            ],
            "title": "Retrieval-enhanced adversarial training for neural response generation",
            "venue": "arXiv preprint arXiv:1809.04276.",
            "year": 2018
        },
        {
            "authors": [
                "Zhu"
            ],
            "title": "2018). Although large scale pretrained models like 175B Blenderbot-3 (Shuster et al., 2022) or the 137B LaMDA (Thoppilan et al., 2022) lead to high accuracies across multiple dialog",
            "year": 2022
        },
        {
            "authors": [
                "Marvel"
            ],
            "title": "Worldwide\u2019s parent company..Marvel",
            "year": 1939
        },
        {
            "authors": [
                "Morgan Freeman"
            ],
            "title": "won an Academy Award in 2005 for Best Supporting Actor with Million Dollar Baby ..He has received Oscar nominations",
            "year": 2005
        }
    ],
    "sections": [
        {
            "text": "1 Introduction\nLarge Language Models (LLMs) have rapidly transformed the landscape of natural language processing (NLP) research through emergent capabilities like prompt-based learning, in-context learning (ICL), and conversational capabilities (Wei et al., 2022). While these novel approaches are being applied to various domains and tasks with an unrealistic speed and effectiveness, many dimensions\n\u2217 Equal contribution 1We make the code publicly available on following\ntwo repos: 1) https://github.com/bsantraigi/ Frugal-Prompting 2) https://github.com/ bsantraigi/Frugal-Prompting-Analysis.\nof LLMs remain unexplored. For instance, since we do not need to follow a fixed schema for the textual inputs anymore (like standard supervised learning for text), the ways in which input-text can be presented, and its impact on task performance is an essential aspect that needs to be investigated. Additionally, as various LLM-inference APIs are becoming available for a price, trade-off between performance gain and prompting (inference) cost is another dimension that requires attention.\nWhile efforts have been made to reduce inferencing costs of Transformer (Vaswani et al., 2017) models, these contributions have mostly been at the architecture level and require access to the model weights and source codes (Tay et al., 2022). As many models like GPT-3 (Brown et al., 2020), CODEX (Chen et al., 2021a), LaMDA (Thoppilan et al., 2022), and PaLM (Chowdhery et al., 2022) are now closed source, it is not possible for the end-user to optimize the model\u2019s costs using these approaches.\nIn recent prompt engineering literature, the focus has been on optimizing the prompt to improve downstream task accuracy (Chung et al., 2022; Wei et al., 2021), with the majority of past efforts targeting single-turn tasks (e.g., classification, reading comprehension, question answering, etc.). However, for longer inputs, another critical factor is the inferencing API cost, which has largely been ignored in prior works. This is especially true for interactive or dialog tasks.\nThis paper explores the trade-off between cost and performance for LLMs in a prompt-based/incontext learning (ICL) setup. We propose the idea of frugal prompting in the context of dialog models, which involves input optimization methods to maintain performance gains while minimizing costs. To compare effectiveness of input representations for in-context learning based methods while considering both cost and task performance, we introduce a new metric called Usable Information\nDensity (UID). Using this metric, we gain insights into the capabilities of various ICL model families for understanding and accessing information from different input representations.\nOverall, we make the following contributions in this paper. (1) We explore the effectiveness of various ICL models and input formats for dialog modeling. (2) We propose a new metric, UID, that captures the tradeoff between accuracy and length for various (input format, ICL model) combinations. (3) Extensive experiments on two benchmark dialog datasets (MSC and TC) and four ICL models show that (a) Adding more context as part of the input does not necessarily improve UID by similar amounts across all ICL models. (b) For most ICL models, using the most semantically related utterance from dialog history is more cost effective compared to using full history, summarized dialog history or most recent utterance.\n2 Literature Review\nLarge language models (LLMs) for Dialog modeling: A large number of recent dialog generation models have been based on pretrained LLMs like DialoGPT (Zhang et al., 2019), Plato (Bao et al., 2019), Blenderbot (Roller et al., 2021; Shuster et al., 2022), Meena (Adiwardana et al., 2020), and LaMDA (Thoppilan et al., 2022) which use the transformer architecture. Although large scale pretrained models like 175B Blenderbot-3 (Shuster et al., 2022) or the 137B LaMDA (Thoppilan et al., 2022) lead to high accuracies across multiple dialog datasets, these approaches can be prohibitively expensive due to the ever-increasing size of models. In-context learning (ICL) (Brown et al., 2020) with prompt-based models helps avoid expensive finetuning. Further, better accuracies have been obtained using instruction finetuning in models like T0 (Sanh et al., 2022), FLAN (Chung et al., 2022), Tk-Instruct (Wang et al., 2022), etc. But the increased inference costs due to large prompts sizes remains an open challenge. Ways to optimize computation for LLMs: Following environmental impact discussion of the training process of these LLMs (Strubell et al., 2019), multiple studies have proposed these two main lines of work on optimizing costs of LLMs: (1) Model distillation-based (Hinton et al., 2015; Sanh et al., 2019; Gou et al., 2021; Gupta and Agrawal, 2022) methods train a smaller, simplified model to approximate the predictions of a larger,\nmore complex model. (2) Efficient transformer architectures (Kitaev et al., 2020; Wang et al., 2020; Zaheer et al., 2020; Beltagy et al., 2020) aim to reduce the quadratic complexity of the standard transformer architecture by using more efficient self-attention mechanisms. In this paper, we examine the costs associated with the use of prompts in LLMs and suggest a new method for assessing the cost-performance trade-offs involved, as well as strategies for optimizing the inference cost with regard to the inputs. Please refer to Appendix F for more detailed literature review.\n3 Prompting Methods for Dialog Systems\nWe first present the necessary ingredients of a prompt for dialog systems. Next, we discuss recipes for manual and algorithmically optimized prompts. Lastly, we present ways of effectively including context information as part of prompts.\n3.1 Prompt Ingredients for Dialog Systems\nTo build a prompt-based dialog system using LLMs, the following components or information sources are an important part of the prompt template. (1) Task Instruction: The instruction is used to explain the task of a dialog response generation model. We also assign a system-role for the LLM (also called Person2) to play through the instruction for example the role of \u201can automated chat system\u201d. (2) Dialog Context: As part of the dialog context, several components can be included like dialog history, persona information and Person1\u2019s latest utterance. (a) Dialog history: This refers to the past conversation between Person1 and Person2 that provides the context for the current conversation. (b) Background Information (BI): We also make use of some additional information like persona or knowledge sections when available. Persona is a fictional representation of a user consisting of series of sentences describing their characteristics, events and opinions. This is used to create a personalized experience during a conversation. Knowledge sections are short paragraphs from different data sources (Wikipedia, Reddit, and Washington Post) that are related to the topic of the conversation. We experiment with various combinations of different pieces of information to understand their impact on the accuracy versus inference cost. (3) Person1\u2019s latest utterance: This is the most recent statement or question uttered by Person1 in\nimplies corresponding elements are for the exemplar.\n3.2 Manual versus Perplexity Prompts\nWe experimented with two ways to design prompt templates: manual and automatically optimized prompts using a perplexity-based search method. Manually Designed Prompts: Manual prompts\nwere designed keeping in mind general principles of prompt design (Liu et al., 2023) like role based prompting (Schulhoff and Contributors, 2022), specifically adding requirements like \u201cgenerate a consistent, diverse response\u201d so as not to get repetitive, dull responses and maintain consistency with respect to the current utterance and context. Table 2 illustrates one of our manually designed prompt template, with summary of dialog history, persona and current user utterance as dialog context and with one exemplar. Perplexity Optimized Prompts: We followed the strategy highlighted in Gonen et al. (2022) which claims that the performance of a prompt is coupled with the extent to which the model is familiar with its language, and this can be measured by the perplexity of the prompt. Given an LLM, we took the manually engineered prompt template, and created candidate prompt variants by using GPT3 and back translation. Further, we instantiated all such prompt templates using 100 instances (with full prompt sequence, including the input itself, and without the label), and computed average perplexity per template using the LLM. The lowest perplexity template was chosen.\n3.3 Optimizing the Dialog History Input\nRedundancies in conversations: In conversational agents, dialog history plays a crucial role in generating meaningful responses. It provides context and continuity, and enables the agent to remember previous interactions with the user. However, the dialog history can also be redundant, especially when it contains back-channeling, clarification, and mistake correction. While these elements are necessary for a natural and useful conversation, they increase the length of the dialog history without adding any new information. In addition, responses from some dialog models (like Instruct-\nGPT (Ouyang et al., 2022)-based models \u2013 textdavinci-003) could be elaborate and long.\nShortening Dialog Histories: To reduce the prompt length, we can compress the dialog history by removing redundancies. The goal is to give the agent only the parts that are relevant and informative for generating the next response. Two possible approaches to compress the dialog history into a shorter and more informative representation are selection and summarization.\n\u2022 Selection: Two possible ways to select parts of dialog history are as follows. (1) Recent-k: The simplest approach is to use a fixed-length dialog history from the most recent utterances. However, this approach may not be optimal, as users may refer back to context beyond the fixed length window and expect the system to understand. (2) Semantic-k: In this approach, the most relevant k utterances from the dialog history are selected with respect to the current utterance. This method is simple, but its performance depends on the quality of the similarity measure used. We used the average of the similarity obtained using SimCSE model (Gao et al., 2021) and Sentence Transformers (Reimers and Gurevych, 2019) to measure the overall similarity between utterances.\n\u2022 Summarization: An alternative approach is to use a summary of the full dialog history. We considered two Transformer-based encoder-decoder abstractive summarization models (BART (Lewis et al., 2019) and Pegasus (Zhang et al., 2020)) finetuned on generic as well as dialog datasets like CNN/DailyMail (Hermann et al., 2015), SAMSum (Gliwa et al., 2019) and DialogSum (Chen et al., 2021b). These methods are more complex, but they can generate a summary that is more informative and short.\nShortening Background Information: Often dialog datasets also include other background information like persona information (Xu et al., 2022), reading sets (Gopalakrishnan et al., 2019) and knowledge facts (Dinan et al., 2018). Transformer-based encoder-decoder abstractive summarization models (BART (Lewis et al., 2019) and Pegasus (Zhang et al., 2020)) can be used to shorten such background information as well.\n4 Experimental Setup\n4.1 Datasets\nWe experiment with two dialog datasets for comparing various methods on accuracy versus inference cost for prompt-based dialog systems: Multisession Chat (MSC) (Xu et al., 2022) and Topical Chat (TC) (Gopalakrishnan et al., 2019). We chose these datasets because of their varying characteristics and the length of the dialog history.\nThe MSC dataset consists of multiple chat sessions whereby the speaking partners learn about each other\u2019s interests and discuss the things they have learnt from past sessions. Each user participating in these sessions (or conversations) is asked to play a role (persona) while having the conversation. On the other hand, in the TC dataset, each pair of users is assigned one or more topics along with some facts or knowledge about the topic, and the users are asked to have a conversation about the topic. Users have no persona in the TC dataset but there are knowledge sections associated with the conversations. The test set contains 16,299 and 7,512 context response pairs in the MSC and TC datasets, respectively. Also, there are 11.9 and 20.0 average number of utterances in full conversations in the MSC and TC datasets, respectively.\nSince we do not train or finetune any specific models, we do not use train splits of these datasets. For perplexity-based prompt optimization, we use validation splits of these datasets. We discuss detailed preprocessing steps in the Appendix A.\n4.2 Summarization of Dialog and Background Information\nWe used BART and Pegasus models for summarization. However, in dialog summarization, the objective is to distill the most important information or key points from a conversation, which can be quite challenging because conversations tend to be more dynamic and context-dependent than normal documents. Unlike traditional summarization, in dialog summarization, there is a greater emphasis on preserving the coherence and context of the conversation. Hence, we used dialog summary datasets like DialogSum, SAMSum and CNN/DailyMail to finetune abstractive summary models like Pegasus and BART and picked up the best model for use in terms of summarization performance by calculating ROUGE metric on dialog summarization data.\nWe process the DialogSum and SAMSum datsets to remove all conversation instances having more than two speakers and normalized the speaker names to Person1 and Person2 so that the model does not hallucinate random names during summary generation.\nOverall, we train three models: (1) BART-D: facebook/bart-large model finetuned on DialogSum, with 12 encoder and 12 decoder layers. (2) Pegasus-CD: google/pegasus-cnn_dailymail model (which has been finetuned on CNN-DailyMail corpus, with 16 encoder and 16 decoder layers. (3) Pegasus-DS: google/pegasus-cnn_dailymail model further finetuned on both DialogSum and SAMSum data, with 16 encoder and 16 decoder layers. Training hyper-parameters are in Appendix B.\n4.3 Models and Prompt Design\nFor this study, we used GPT-3 (text-davinci-003), one of the most prominent models for promptbased or ICL. Along with GPT-3, we also included other open-source models that are capable of ICL: FLAN-T5 (google/flan-t5-xl), T0 (bigscience/T0_3B), and Tk-Instruct (allenai/tkinstruct-3b-def for zero shot and allenai/tk-instruct3b-def-pos for few shot). These open-source models are generally smaller in size compared to GPT3 (175B) and have the capability of ICL through instruction-finetuning based training.\nWe experiment with several input prompt settings: (1) Zero shot versus few shot. (2) Manually designed versus perplexity optimized prompts. (3) Settings based on usage of dialog history: (a) full history, (b) summarized dialog history (using any of the three summarization models), or (c) Recentk or semantic-k selection from history. (4) With and without summarized background-information.\nIn case of few shot, we use only one exemplar since (1) previous work (Madotto et al., 2021) has shown that one exemplar is enough, and (2) we wish to find methods which retain good accuracy with short input lengths. The exemplar is also formatted in the same way as the actual input. For example, if the actual input setting is to use persona with few shot, the exemplar also includes persona information. Similarly, if the actual input setting is to use summarized dialog history with input, the exemplar also includes summarized dialog history.\nThe exemplar is chosen based on the immediately previous utterances if available, else it is randomly chosen from the dataset. Thus, for each in-\nstance, the exemplar is different. For example, consider the Recent-4 few shot setting. Let ABCDEFG be the utterances in the conversation. Thus, the instance will have G as the target response, and input contains F as the current utterance and BCDE as the recent-4 dialog history. The input for this instance will also consist of an exemplar where the target response will be F and input for exemplar will contain E as current utterance and ABCD as the recent-4 dialog history.\n4.4 Metrics\nPerformance We evaluate the performance of the models using several popular metrics: METEOR, BLEURT and DEB. METEOR (Banerjee and Lavie, 2005) is widely used for various text-generation tasks (machine translation, dialog generation, etc.). It measures lexical-overlap between n-grams of the predicted and ground truth response. BLEURT (Sellam et al., 2020) uses a pre-trained BERT model for evaluating text generation models. DEB (Sai et al., 2020) is a BERTbased dialog metric further pre-trained on dialog data for next response classification using the nextsentence-prediction (NSP) loss.\nInference Cost To evaluate the effectiveness of different prompting methods for dialog systems, we need a metric that takes into account both the performance gain and the inference cost reduction. The cost is measured in terms of the length of the overall input, as longer inputs incur more inferenceAPI costs and also slow down the inference.\nWe propose a new benefit-cost based metric to simultaneously consider both model performance and the inference cost incurred: the usableinformation-density (UID). UID with respect to metric M is defined as UIDM (a) = (MH)a/LH where MH is the average performance of the model as per metric M , LH is the overall combined size of input and output averaged across all the test examples, a is a metric-importance parameter. In the main paper, we present results using a=1, but show impact of varying a in the Appendix. With a=1, UID is defined as the ratio of performance to cost measured in terms of size of the input and output. The UID captures the amount of information, per token, usable by a model (Ethayarajh et al., 2022) for a given input/prompt configuration. The UID metric can be used to evaluate the effectiveness of different prompting methods.\n150\n200\n250\n300\n350\n400\n450\n500\nMSC-Zero shot-Manual\nMSC-Zero shot-Perplexity-optimized\nTC-Zero shot-Manual\nTC-Zero shot-Perplexity-optimized\n5 Results and Analysis\n5.1 Size Comparison across different Input Formats\nFig. 1 shows the variation in the average input prompt size as we vary the prompt constituents, dialog history (DH) and background information (BI), for the few shot. We show a similar figure (Fig. 4) for zero shot cases in the Appendix. We plot the variation for manually engineered as well as perplexity optimized prompts for both the datasets (MSC and TC). Y -axis indicates the overall length of the input prompt, which is fed to the large language models (LLM) without further processing. We observe that the complete dialog history is significantly longer compared to summarized or selection forms. Since we use one demonstration exemplar in few shot cases, the few shot prompts are typically twice as long as their corresponding zero shot prompts. Perplexity optimized prompts are slightly shorter than manually engineered prompts on average. Pegasus-DS summarized dialog history is almost 3 times shorter; Pegasus-DS summaries are shorter than Pegasus-CD summaries while BART-D summaries are shorter than PegasusDS summaries. Sizes of recent-2 (or semantic-2) are similar to the summarized dialog histories in terms of the final length of the input context to the model. However, we expect that the summarized dialog history will have more useful information stored in a compressed form compared to the greedy choice of only the recent-2 or semantic-2 utterances. In case of Pegasus-DS + BI, we use the BI summarized using Pegasus-CD model. Note\nBLEURT DEB METEOR FLAN-T5 0.357 0.765 0.139 T0 0.347 0.912 0.153 GPT-3 0.386 0.929 0.182MSC\nTk-Instruct 0.355 0.832 0.133 FLAN-T5 0.345 0.803 0.124 T0 0.321 0.868 0.133 GPT-3 0.342 0.885 0.147TC\nTk-Instruct 0.338 0.852 0.119\nBA R\nTD\nPe ga\nsu s-\nCD\nPe ga\nsu s-\nD S\nPe ga\nsu s-\nD S\n+ BI\nR ec\nen t-\n1\nR ec\nen t-\n2\nR ec\nen t-\n4\nR ec\nen t-\n8\nR ec\nen t-\n10\nSe m\nan ti\nc1\nSe m\nan ti\nc2\nSe m\nan ti\nc4\nSe m\nan ti\nc8\nSe m\nan ti\nc10 Fu ll\nHistory Signal\n0.6\n0.7\n0.8\n0.9\nD EB\nModel Avg. (ZS+Manual) Model Avg. (FS+Manual)\nModel Avg. (ZS+PPL) Model Avg. (FS+PPL)\nB A\nR TD Pe ga su sCD Pe ga su sD S\nPe ga\nsu s-\nD S\n+ BI\nR ec\nen t-\n1\nR ec\nen t-\n2\nR ec\nen t-\n4\nR ec\nen t-\n8\nR ec\nen t-\n10\nSe m\nan ti\nc1\nSe m\nan ti\nc2\nSe m\nan ti\nc4\nSe m\nan ti\nc8\nSe m\nan ti\nc10 Fu ll\nHistory Signal\n0.30\n0.31\n0.32\n0.33\n0.34\n0.35\nB LE\nU R\nT\nModel Avg. (ZS+Manual) Model Avg. (FS+Manual)\nModel Avg. (ZS+PPL) Model Avg. (FS+PPL)\nB A\nR TD Pe ga su sCD Pe ga su sD S\nPe ga\nsu s-\nD S\n+ B\nI\nR ec\nen t-\n1\nR ec\nen t-\n2\nR ec\nen t-\n4\nR ec\nen t-\n8\nR ec\nen t-\n10\nSe m\nan ti\nc1\nSe m\nan ti\nc2\nSe m\nan ti\nc4\nSe m\nan ti\nc8\nSe m\nan ti\nc10 Fu ll\nHistory Signal\n0.110\n0.115\n0.120\n0.125\n0.130\n0.135\n0.140\n0.145\nM ET\nEO R\nModel Avg. (ZS+Manual) Model Avg. (FS+Manual)\nModel Avg. (ZS+PPL) Model Avg. (FS+PPL)\nManual Prompt Perplexity Prompt BLEURT DEB METEOR BLEURT DEB METEORHistory\nZS FS ZS FS ZS FS ZS FS ZS FS ZS FS BART-D 19.79 9.03 46.56 22.57 7.75 3.91 20.27 8.94 45.58 23.81 7.25 3.86 Pegasus-CD 17.76 8.22 44.58 21.07 7.14 3.60 17.75 8.06 41.14 22.22 6.49 3.68 Pegasus-DS 19.72 9.31 46.49 20.51 7.78 3.72 20.22 8.90 45.40 17.69 7.25 3.41 Pegasus-DS + BI 12.23 5.87 29.65 15.21 4.93 2.59 11.97 5.57 27.50 14.27 4.34 2.34 Recent-1 22.22 9.82 53.35 23.84 8.96 4.17 22.29 9.59 46.07 21.59 8.50 3.99 Recent-2 19.38 8.72 46.49 20.88 7.92 3.68 19.65 8.52 42.84 19.33 7.49 3.60 Recent-4 15.18 6.96 36.77 16.78 6.34 2.95 15.28 6.68 34.54 15.78 5.92 2.86 Recent-8 11.35 5.31 27.91 12.94 4.75 2.27 11.25 5.04 26.60 12.14 4.38 2.17 Recent-10 10.05 4.85 25.08 11.92 4.08 2.08 10.14 4.59 24.40 11.19 3.94 1.99 Semantic-1 23.51 10.18 51.11 22.75 9.03 4.36 24.23 10.13 50.94 21.48 8.85 4.20 Semantic-2 19.86 8.73 44.19 19.85 7.88 3.78 20.42 8.68 43.63 19.34 7.56 3.60 Semantic-4 15.50 6.98 38.57 17.87 6.52 3.08 15.62 6.87 36.93 18.02 6.05 2.99 Semantic-8 11.07 5.00 25.58 12.02 4.56 2.25 11.20 4.85 25.06 11.91 4.14 2.06 Semantic-10 9.72 4.46 22.62 10.72 4.02 2.00 9.80 4.29 22.12 10.64 3.63 1.84 MSC\nFull 6.97 3.44 18.03 8.84 2.91 1.56 6.66 3.31 17.63 8.56 2.65 1.53 BART-D 24.56 11.11 57.75 24.46 8.67 4.02 25.64 11.00 59.05 22.42 8.46 3.71 Pegasus-CD 18.59 8.77 48.79 20.14 6.96 3.33 19.24 8.54 48.96 16.31 6.63 3.00 Pegasus-DS 24.37 11.00 57.61 24.39 8.64 3.99 25.47 10.96 58.82 22.49 8.43 3.70 Pegasus-DS + BI 7.67 3.88 20.75 9.09 2.94 1.57 7.59 3.63 20.76 8.27 2.68 1.43 Recent-1 24.17 10.62 60.36 26.08 9.09 4.13 24.98 10.83 58.37 28.06 8.83 4.05 Recent-2 20.35 9.14 51.54 22.58 7.89 3.59 21.25 9.27 51.71 24.58 7.72 3.67 Recent-4 15.99 7.35 40.57 17.98 6.31 2.87 16.66 7.29 41.21 19.82 6.15 2.95 Recent-8 11.92 5.54 30.56 13.65 4.73 2.19 12.24 5.47 30.85 14.93 4.52 2.23 Recent-10 10.77 5.04 27.94 12.53 4.26 2.00 10.95 4.98 28.26 13.64 4.08 2.04 Semantic-1 24.02 10.50 60.06 27.05 8.76 4.19 25.48 10.73 62.63 28.87 8.88 4.17 Semantic-2 20.15 8.95 51.40 23.47 7.64 3.62 21.43 9.12 53.68 25.16 7.65 3.61 Semantic-4 15.34 7.23 41.73 18.90 6.41 2.93 16.31 7.31 42.70 20.07 6.36 2.99 Semantic-8 11.57 5.29 30.20 13.92 4.49 2.15 12.01 5.30 31.14 14.94 4.34 2.14 Semantic-10 10.38 4.81 27.45 12.67 4.03 1.96 10.68 4.83 28.29 13.57 3.86 1.95 TC\nFull 8.45 4.06 23.13 10.94 3.44 1.72 8.47 4.06 23.50 11.57 3.32 1.73\nis the best from both accuracy as well as usable information perspective. Overall, our results highlight the importance of carefully balancing model performance and cost in interactive tasks that rely on dialog history.\n7 Acknowledgments\nThis work was partially supported by Microsoft Academic Partnership Grant (MAPG) 2022. The first author was also supported by Prime Minister\u2019s Research Fellowship (PMRF), India.\n8 Limitations\nWe experimented with datasets and models trained on languages with limited morphology like English. While we hope that these results will generalize to models trained on multi-lingual datasets; empirical validation needs to be done.\nWhile the study examines TC and MSC, these conclusions may only apply to these datasets and to general open-domain chit-chat dialogue. However, there are many more dialogue settings than just these two. For example, it needs to be validated if the conclusions would apply to more information-critical dialogues (e.g. task-oriented dialogue datasets like MultiWOZ).\nFor task-oriented dialog systems with welldefined ontologies and belief states, the experimental design would need to be reconsidered, including aspects like prompts, summarization methods, and evaluation metrics. Standard summarization techniques may need to be adapted to better retain key belief state information in the summary. Although we believe that the well-defined ontology could potentially allow further optimization of prompt lengths compared to open-domain dialog. While the lower-level details would differ in applying frugal prompting notions to task-oriented dialogs, we are optimistic that similar beneficial findings around balancing model performance and computational costs could emerge.\n9 Ethics Statement\nIn this paper, we studied how to efficiently use dialog generation models. Although we did not explicitly train our own dialog models, we would like to make the readers aware about potential risks in usage of such models. Many pretrained language representation models have learned patterns associated with exposure bias. Interpretability associated with the output is rather limited, hence users\nshould use the outputs carefully. These models generate possible response candidates, and do not filter out any \u201cproblematic\u201d candidates. Thus, for applications, where candidate responses could be problematic, (e.g., offensive, hateful, abusive, etc.), users should carefully filter them out before using the output from such models.\nAll the datasets used in this work are publicly available. We did not collect any new dataset as part of this work.\nMSC dataset: The dataset was downloaded from https://parl.ai/projects/msc/. Xu et al. (Xu et al., 2022) describes details about creation of the dataset. Parl.ai makes models and datasets available under MIT License.\nTC dataset: The dataset was downloaded from https://github.com/alexa/ Topical-Chat. The dataset is available under Community Data License Agreement.\nWe used 4 models in this work: T0, Tk-Instruct, FLAN T5 and GPT-3 API. T0, Tk-Instruct and FLAN T5 are all provided under Apache 2.0 License on Huggingface. We used the publicly available GPT-3 API by signing up at OpenAI.\nReferences Daniel Adiwardana, Minh-Thang Luong, David R So,\nJamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, et al. 2020. Towards a human-like open-domain chatbot. arXiv preprint arXiv:2001.09977.\nSatanjeev Banerjee and Alon Lavie. 2005. Meteor: An automatic metric for mt evaluation with improved correlation with human judgments. In Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization, pages 65\u201372.\nSiqi Bao, Huang He, Fan Wang, Hua Wu, and Haifeng Wang. 2019. Plato: Pre-trained dialogue generation model with discrete latent variable. arXiv preprint arXiv:1910.07931.\nIz Beltagy, Matthew E. Peters, and Arman Cohan. 2020. Longformer: The long-document transformer. ArXiv, abs/2004.05150.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901.\nHengyi Cai, Hongshen Chen, Yonghao Song, Xiaofang Zhao, and Dawei Yin. 2021. Exemplar guided\nneural dialogue generation. In Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence, pages 3601\u20133607.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021a. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374.\nYulong Chen, Yang Liu, Liang Chen, and Yue Zhang. 2021b. Dialogsum: A real-life scenario dialogue summarization dataset. arXiv preprint arXiv:2105.06762.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311.\nHyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416.\nEmily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston. 2018. Wizard of wikipedia: Knowledge-powered conversational agents. arXiv preprint arXiv:1811.01241.\nKawin Ethayarajh, Yejin Choi, and Swabha Swayamdipta. 2022. Understanding dataset difficulty with V-usable information. In Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pages 5988\u20136008. PMLR.\nTianyu Gao, Xingcheng Yao, and Danqi Chen. 2021. Simcse: Simple contrastive learning of sentence embeddings. arXiv preprint arXiv:2104.08821.\nBogdan Gliwa, Iwona Mochol, Maciej Biesek, and Aleksander Wawer. 2019. Samsum corpus: A humanannotated dialogue dataset for abstractive summarization. arXiv preprint arXiv:1911.12237.\nHila Gonen, Srini Iyer, Terra Blevins, Noah A Smith, and Luke Zettlemoyer. 2022. Demystifying prompts in language models via perplexity estimation. arXiv preprint arXiv:2212.04037.\nKarthik Gopalakrishnan, Behnam Hedayatnia, Qinlang Chen, Anna Gottardi, Sanjeev Kwatra, Anu Venkatesh, Raefer Gabriel, and Dilek Hakkani-T\u00fcr. 2019. Topical-chat: Towards knowledge-grounded open-domain conversations. Proc. Interspeech 2019, pages 1891\u20131895.\nJianping Gou, Baosheng Yu, Stephen J Maybank, and Dacheng Tao. 2021. Knowledge distillation: A survey. International Journal of Computer Vision, 129:1789\u20131819.\nManish Gupta and Puneet Agrawal. 2022. Compression of deep learning models for text: A survey. ACM Transactions on Knowledge Discovery from Data (TKDD), 16(4):1\u201355.\nPrakhar Gupta, Jeffrey P Bigham, Yulia Tsvetkov, and Amy Pavel. 2020. Controlling dialogue generation with semantic exemplars. arXiv preprint arXiv:2008.09075.\nKarl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, and Phil Blunsom. 2015. Teaching machines to read and comprehend. Advances in neural information processing systems, 28.\nGeoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531.\nNikita Kitaev, Lukasz Kaiser, and Anselm Levskaya. 2020. Reformer: The efficient transformer. ArXiv, abs/2001.04451.\nMojtaba Komeili, Kurt Shuster, and Jason Weston. 2021. Internet-augmented dialogue generation. ArXiv preprint, abs/2107.07566.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461.\nChia-Wei Liu, Ryan Lowe, Iulian Serban, Mike Noseworthy, Laurent Charlin, and Joelle Pineau. 2016. How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2122\u20132132, Austin, Texas. Association for Computational Linguistics.\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2023. Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing. ACM Computing Surveys, 55(9):1\u201335.\nAndrea Madotto, Zhaojiang Lin, Genta Indra Winata, and Pascale Fung. 2021. Few-shot bot: Promptbased learning for dialogue systems. arXiv preprint arXiv:2110.08118.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35:27730\u201327744.\nNils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th"
        },
        {
            "heading": "International Joint Conference on Natural Language",
            "text": "Processing (EMNLP-IJCNLP), pages 3982\u20133992.\nStephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Eric Michael Smith, Y-Lan Boureau, and Jason Weston. 2021. Recipes for building an open-domain chatbot. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 300\u2013325, Online. Association for Computational Linguistics.\nAnanya B Sai, Akash Kumar Mohankumar, Siddhartha Arora, and Mitesh M Khapra. 2020. Improving dialog evaluation with a multi-reference adversarial dataset and large scale pretraining. Transactions of the Association for Computational Linguistics, 8:810\u2013 827.\nVictor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019. Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter. ArXiv, abs/1910.01108.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2022. Multitask prompted training enables zero-shot task generalization. In ICLR 2022-Tenth International Conference on Learning Representations.\nBishal Santra, Potnuru Anusha, and Pawan Goyal. 2021. Hierarchical transformer for task oriented dialog systems. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5649\u20135658.\nTimo Schick and Hinrich Sch\u00fctze. 2021a. Exploiting cloze-questions for few-shot text classification and natural language inference. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 255\u2013269.\nTimo Schick and Hinrich Sch\u00fctze. 2021b. It\u2019s not just size that matters: Small language models are also fewshot learners. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2339\u20132352.\nSander Schulhoff and Community Contributors. 2022. Learn Prompting.\nThibault Sellam, Dipanjan Das, and Ankur P Parikh. 2020. Bleurt: Learning robust metrics for text generation. arXiv preprint arXiv:2004.04696.\nIulian Vlad Serban, Alessandro Sordoni, Ryan Lowe, Laurent Charlin, Joelle Pineau, Aaron C. Courville, and Yoshua Bengio. 2017. A hierarchical latent variable encoder-decoder model for generating dialogues."
        },
        {
            "heading": "In Proceedings of the Thirty-First AAAI Conference",
            "text": "on Artificial Intelligence, February 4-9, 2017, San\nFrancisco, California, USA, pages 3295\u20133301. AAAI Press.\nXiaoyu Shen, Hui Su, Yanran Li, Wenjie Li, Shuzi Niu, Yang Zhao, Akiko Aizawa, and Guoping Long. 2017. A conditional variational framework for dialog generation. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 504\u2013509, Vancouver, Canada. Association for Computational Linguistics.\nKurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller, Megan Ung, Moya Chen, Kushal Arora, Joshua Lane, et al. 2022. Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage. arXiv preprint arXiv:2208.03188.\nEmma Strubell, Ananya Ganesh, and Andrew McCallum. 2019. Energy and policy considerations for deep learning in nlp. arXiv preprint arXiv:1906.02243.\nYi Tay, Mostafa Dehghani, Dara Bahri, and Donald Metzler. 2022. Efficient transformers: A survey. ACM Comput. Surv., 55(6).\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems, 30.\nBen Wang and Aran Komatsuzaki. 2021. GPTJ-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/ kingoflolz/mesh-transformer-jax.\nSinong Wang, Belinda Z. Li, Madian Khabsa, Han Fang, and Hao Ma. 2020. Linformer: Self-attention with linear complexity. ArXiv, abs/2006.04768.\nYizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva Naik, Arjun Ashok, Arut Selvan Dhanasekaran, Anjana Arunkumar, David Stap, et al. 2022. Supernaturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 5085\u20135109.\nJason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 2021. Finetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652.\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682.\nYu Wu, Furu Wei, Shaohan Huang, Yunli Wang, Zhoujun Li, and Ming Zhou. 2019. Response generation by context-aware prototype editing. In The"
        },
        {
            "heading": "Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Ap-",
            "text": "plications of Artificial Intelligence Conference, IAAI"
        },
        {
            "heading": "2019, The Ninth AAAI Symposium on Educational",
            "text": "Advances in Artificial Intelligence, EAAI 2019, Honolulu, Hawaii, USA, January 27 - February 1, 2019, pages 7281\u20137288. AAAI Press.\nJing Xu, Arthur Szlam, and Jason Weston. 2022. Beyond goldfish memory: Long-term open-domain conversation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5180\u20135197.\nManzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Onta\u00f1\u00f3n, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, and Amr Ahmed. 2020. Big bird: Transformers for longer sequences. ArXiv, abs/2007.14062.\nJingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter Liu. 2020. Pegasus: Pre-training with extracted gap-sentences for abstractive summarization. In International Conference on Machine Learning, pages"
        },
        {
            "heading": "11328\u201311339. PMLR.",
            "text": "Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, and Bill Dolan. 2019. Dialogpt: Large-scale generative pre-training for conversational response generation. arXiv preprint arXiv:1911.00536.\nTiancheng Zhao, Ran Zhao, and Maxine Eskenazi. 2017. Learning discourse-level diversity for neural dialog models using conditional variational autoencoders."
        },
        {
            "heading": "In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume",
            "text": "1: Long Papers), pages 654\u2013664, Vancouver, Canada. Association for Computational Linguistics.\nQingfu Zhu, Lei Cui, Weinan Zhang, Furu Wei, and Ting Liu. 2018. Retrieval-enhanced adversarial training for neural response generation. arXiv preprint arXiv:1809.04276.\nA Data Preprocessing\nThe MSC dataset is divided into multiple sessions, the first of which uses dialogs from the PersonaChat dataset. Each session has metadata information such as time elapsed from the past conversation and previous dialogs. Examples from Session 1 do not have enough context. Hence, we experiment with examples from sessions 2, 3 and 4 are used, and the results are averaged across the three. As per the dataset construction, a single conversation has been conducted across multiple sessions. Hence, as a first step, we aggregate all\nturns for a conversation across sessions 1, 2, 3 and 4 by concatenating them in a temporal way. Further, context-response example pairs for our experiments have been created by considering (i) second utterance of each turn of sessions 2, 3 and 4 as a response and (ii) first utterance of corresponding turn and entire conversation history as context. We also use the persona information as background information when constructing input for various dialog models.\nThe test split of the TC dataset includes two sections: frequent and rare. This is based on the frequency of the associated entities as observed in the training set. We combine these splits to create our test set and pursue our analysis. The conversations begin with a preprocessed reading set which is retrieved from Wikipedia. Further, context-response example pairs for our experiments have been created by considering (i) second utterance of each turn as a response and (ii) first utterance of corresponding turn and entire conversation history as context.\nIn both datasets, for each sample, we normalize the utterances by removing trailing whitespaces, and capitalizing first word of every sentence.\nB Hyper-parameters for training dialog summarization models\nWe used a batch size of 8 and finetuned the models for 10 epochs. We tried using various learning rates (1e-5, 5e-5, 1e-4, 5e-4, 1e-3) and finally picked a learning rate of 1e-4 since that gave the most optimal performance on the validation set. During training we limited the maximum length of generated summary to 128 and set the number of beams to 5.\nC Overall input length\nRefer to Fig. 4 for a comparison of overall input length for various representations of dialog prompt across the two datasets for the zero shot setting.\nD Detailed Model-wise Performance Results\nIn Figs. 5 to 8, we analyze the absolute performances of various LLM model-families using prompts based on various input representations for TC and MSC resp. We show model-wise results for few shot (FS) as well as zero shot (ZS) cases across three popular metrics \u2013 BLEURT, DEB and\n100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n1100\nSe m\nan tic -1 Re ce nt -1 BA RT -D\nPe ga\nsu s-\nD S\nSe m\nan tic -2 Re ce nt -2 Pe ga su sCD Re ce nt -4 Se m an tic -4 Se m an tic -8\nPe ga\nsu s-\nD S\n+ BI\nRe ce\nnt -8\nSe m\nan tic\n-1 0\nRe ce\nnt -1\n0 Fu\nll\nMSC-Few shot-Manual\nMSC-Few shot-Perplexity-optimized\nTC-Few shot-Manual\nTC-Few shot-Perplexity-optimized\n0\n50\n100\n150\n200\n250\n300\n350\n400\n450\n500\nSe m\nan tic -1 Re ce nt -1 BA RT -D\nPe ga\nsu s-\nD S\nSe m\nan tic -2 Re ce nt -2\nPe ga\nsu sCD Re ce nt -4 Se m an tic -4 Se m an tic -8 Pe ga su sD S + BI Re ce nt -8 Se m an tic -1 0 Re ce nt -1 0 Fu ll\nMSC-Zero shot-Manual\nMSC-Zero shot-Perplexity-optimized\nTC-Zero shot-Manual\nTC-Zero shot-Perplexity-optimized\nMETEOR. We also show results for manually engineered as well as perplexity optimized prompts averaged across various models (FLAN-T5, T0, TkInstruct and GPT-3). Since we do not have access to logits from GPT-3 model, we cannot optimize prompts for GPT-3 using perplexity.\nE Detailed Model-wise UID Results\nWe show the model-wise UID results in Tables 5, 6, 7, and 8 for FLAN-T5, T0, Tk-Instruct and GPT-3 respectively. We show results for few shot as well as zero shot cases, and for both the datasets (MSC and TC). We also show UID results across three different metrics \u2013 BLEURT, DEB and METEOR. For each of these combinations, we show results for different input prompt combinations: (1) Full dialog history, (2) Summary of dialog history using BART-D or Pegasus-DS or Pegasus-CD, (3) Pegasus-DS summary of dialog history as well as Pegasus-CD summary of background information (BI), (4) Recent-k selected dialog utterances, and (5) Semantic-k selected dialog utterances, where k is varied as 1, 2, 4, 8, and 10.\nF Detailed literature review\nF.1 Dialog modeling The development of open-domain chatbot systems that possess long-term memory, generate engaging and coherent responses, and perform equally well on a variety of dialog tasks has been a longstanding\nF.3 Compute Intensive LLMs\nOne of the most critical drawbacks of these LLMs is the training and inferencing cost, especially for long sequences. Other than the complexity of a single forward pass, there are other costs involved in training an effective transformer LLM, e.g., amount of training data and compute needed (FLOP). Strubell et al. (2019) discusses the environmental impact that the training process of these LLMs has, in terms of total CO2 emissions. Optimizing costs of LMs has mainly been explored from the perspective of increasing the efficiency of the inference step of a transformer. Model distillation-based (Hinton et al., 2015; Sanh et al., 2019; Gou et al., 2021; Gupta and Agrawal, 2022) methods train a smaller, simplified model to approximate the predictions of a larger, more complex model. Efficient transformer architectures, such as Reformer (Kitaev et al., 2020), Linformer (Wang et al., 2020), BigBird (Zaheer et al., 2020), and Longformer (Beltagy et al., 2020), aim to reduce the quadratic complexity of the standard transformer architecture by using more efficient selfattention mechanisms. In this paper, we examine the costs associated with the use of Large Language Model (LLMs)\nand suggest new metrics for assessing the costperformance trade-offs involved, as well as strategies for optimizing the inference cost with regard to the inputs.\nG Full list of prompts\nG.1 Manually engineering prompts\nIn this section, we provide a full list of manually engineering prompts. Tables 9 to 14 show prompt instances for six different settings: zero-shot versus few-shot, and passing persona versus dialog history summary versus both as context. The generations"
        },
        {
            "heading": "MSC",
            "text": "are from the GPT3 model. Rather than the persona, when we use knowledge facts, the prompt templates remain the same. When the dialog context consists of components other than summary, e.g., full history or recent-k utterances or semantick utterances, \u201csummary\u201d in prompt templates is replaced with \u201cfull history\u201d or \u201clist of recent-k utterances\u201d or \u201clist of semantic-k utterances\u201d respectively.\nG.2 Perplexity optimized prompts Since we have only API access to the GPT3 model, we could perform perplexity optimization for only Flan T5 XL, T0 and Tk-Instruct models. Tables 15 to 19 show perplexity optimized prompts (templates as well as instance) for FlanT5XL, T0 and Tk-Instruct models under various settings like (a) zero shot versus few shot, and (b) persona, summary, knowledge section or combinations as dialog context.\nH Impact of varying metric-importance index (a)\nWe vary a as [0.5, 1, 2, 5, 10]. This updated formulation of the UID metric, with MH raised to an exponent \u201ca\u201d, can be used to capture the importance assigned by the user on the model performance MH , e.g., when inference cost is less of a\nbottleneck. We analyzed the accuracy-length tradeoff using different values for the parameter \u201ca\u201d to capture various types of user requirements in terms of the allowed expenses towards the inference process. The average UID values (for zero-shot manual prompts) across all the models are shown in Tables 20 and 21. Based on these experiments, we found the following insightful observations. These tables show that for both MSC and TC, for DEB and METEOR, as the value of \u201ca\u201d is increased, summary-based dialog history variants tend to become better in terms of UID while Recent-k and Semantic-k variants tend to become less impressive. Although, in terms of BLEURT (UID), the ranking is in favour of Semantic-1 or 2 and Recent-1 or 2 throughout the complete range of \u201ca\u201d that we have explored. This might be because BLEURT measures normal sentence semantic similarity but not context-response relevance as measured by DEB.\nTo fully understand how the rank of various history signals vary over the value of the metricimportance \u201ca\u201d, we plot the rank-order of all history signal types vs. the value of \u201ca\u201d (increased from 0.5 to 10) as show in Fig. 9. This rank order dynamics helps us clearly understand, as we give more and more importance to the model performance and ignore the cost of inference, how the choices over the history signal change. For example, in terms of the UID (DEB) metric on the MSC dataset, the average trend across models is that Recent-1 and Semantic-1 are the recom-\nmended ways to summarize the context information if cost is an important factor to the user. Whereas, if cost is of less importance, then longer dialog summaries such as Pegasus-CD and Semantic-4\nare recommended approaches for MSC. Additionally, we observe that some models like Recent-10, Semantic-8, Semantic-10 and Full are always bad choices, while some (BART-D, Pegasus-DS) are\nquite robust across the whole range of values of \u201ca\u201d."
        }
    ],
    "title": "Frugal Prompting for Dialog Models",
    "year": 2023
}