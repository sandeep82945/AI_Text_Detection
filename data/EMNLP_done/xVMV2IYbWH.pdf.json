{
    "abstractText": "The de facto way of utilizing black-box large language models (LLMs) to perform various downstream tasks is prompting. However, obtaining suitable prompts for specific tasks is still a challenging problem. While existing LLM-based methods demonstrate promising performance in the task-oriented dialogue (TOD) task, they often require manual adjustment in prompt selection or focus solely on dialogue understanding or generation. To address these issues, we propose an adaptive prompt generation framework to fully unleash the potential of LLMs for the comprehensive TOD system. Firstly, we design a trainable slot generator (TSG) that can generate domain and slot information in the belief state, which serves as prior knowledge for subsequent prompt generation. Next, we propose an adaptive prompt generator (APG) that utilizes the prior knowledge to generate prompts for the LLM, deriving the belief state and system response of the dialogue for evaluation. Finally, we evaluate our framework on the MultiWOZ 2.0 dataset. Extensive experiments demonstrate that our method outperforms existing methods. Our code and data will be released.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jun Gao"
        },
        {
            "affiliations": [],
            "name": "Liuyu Xiang"
        },
        {
            "affiliations": [],
            "name": "Huijia Wu"
        },
        {
            "affiliations": [],
            "name": "Han Zhao"
        },
        {
            "affiliations": [],
            "name": "Yiqi Tong"
        },
        {
            "affiliations": [],
            "name": "Zhaofeng He"
        },
        {
            "affiliations": [],
            "name": "Didi chuxing"
        }
    ],
    "id": "SP:d0752391d2e068fd8a493b0023200f4f34fce465",
    "references": [
        {
            "authors": [
                "Yejin Bang",
                "Samuel Cahyawijaya",
                "Nayeon Lee",
                "Wenliang Dai",
                "Dan Su",
                "Bryan Wilie",
                "Holy Lovenia",
                "Ziwei Ji",
                "Tiezheng Yu",
                "Willy Chung",
                "Quyet V. Do",
                "Yan Xu",
                "Pascale Fung"
            ],
            "title": "A multitask, multilingual, multimodal evaluation of chatgpt on reasoning",
            "year": 2023
        },
        {
            "authors": [
                "Pawe\u0142 Budzianowski",
                "Tsung-Hsien Wen",
                "Bo-Hsiang Tseng",
                "I\u00f1igo Casanueva",
                "Stefan Ultes",
                "Osman Ramadan",
                "Milica Ga\u0161i\u0107"
            ],
            "title": "Multiwoz \u2013 a largescale multi-domain wizard-of-oz dataset for taskoriented dialogue modelling",
            "year": 2020
        },
        {
            "authors": [
                "Sutskever",
                "Wojciech Zaremba"
            ],
            "title": "Evaluating large language models trained on code",
            "year": 2021
        },
        {
            "authors": [
                "Meier-Hellstern",
                "Douglas Eck",
                "Jeff Dean",
                "Slav Petrov",
                "Noah Fiedel"
            ],
            "title": "2022. Palm: Scaling language modeling with pathways",
            "year": 2022
        },
        {
            "authors": [
                "Shizhe Diao",
                "Zhichao Huang",
                "Ruijia Xu",
                "Xuechun Li",
                "Yong Lin",
                "Xiao Zhou",
                "Tong Zhang"
            ],
            "title": "Blackbox prompt learning for pre-trained language models",
            "year": 2023
        },
        {
            "authors": [
                "Tianyu Gao",
                "Adam Fisch",
                "Danqi Chen"
            ],
            "title": "Making pre-trained language models better few-shot learners",
            "year": 2021
        },
        {
            "authors": [
                "Yuxian Gu",
                "Xu Han",
                "Zhiyuan Liu",
                "Minlie Huang"
            ],
            "title": "Ppt: Pre-trained prompt tuning for few-shot learning",
            "year": 2022
        },
        {
            "authors": [
                "Brian Lester",
                "Rami Al-Rfou",
                "Noah Constant"
            ],
            "title": "The power of scale for parameter-efficient prompt tuning",
            "year": 2021
        },
        {
            "authors": [
                "Zekun Li",
                "Baolin Peng",
                "Pengcheng He",
                "Michel Galley",
                "Jianfeng Gao",
                "Xifeng Yan"
            ],
            "title": "Guiding large language models via directional stimulus prompting",
            "year": 2023
        },
        {
            "authors": [
                "Maddie Simens",
                "Amanda Askell",
                "Peter Welinder",
                "Paul Christiano",
                "Jan Leike",
                "Ryan Lowe"
            ],
            "title": "Training language models to follow instructions with human feedback",
            "year": 2022
        },
        {
            "authors": [
                "Wenbo Pan",
                "Qiguang Chen",
                "Xiao Xu",
                "Wanxiang Che",
                "Libo Qin"
            ],
            "title": "A preliminary evaluation of chatgpt for zero-shot dialogue understanding",
            "year": 2023
        },
        {
            "authors": [
                "Baolin Peng",
                "Chunyuan Li",
                "Jinchao Li",
                "Shahin Shayandeh",
                "Lars Liden",
                "Jianfeng Gao"
            ],
            "title": "Soloist: Building task bots at scale with transfer learning and machine teaching",
            "year": 2021
        },
        {
            "authors": [
                "Timo Schick",
                "Hinrich Sch\u00fctze"
            ],
            "title": "Exploiting cloze questions for few shot text classification and natural language inference",
            "year": 2021
        },
        {
            "authors": [
                "Taylor Shin",
                "Yasaman Razeghi",
                "Robert L. Logan IV au",
                "Eric Wallace",
                "Sameer Singh"
            ],
            "title": "Autoprompt: Eliciting knowledge from language models with automatically generated prompts",
            "year": 2020
        },
        {
            "authors": [
                "Tianxiang Sun",
                "Yunfan Shao",
                "Hong Qian",
                "Xuanjing Huang",
                "Xipeng Qiu"
            ],
            "title": "Black-box tuning for language-model-as-a-service",
            "year": 2022
        },
        {
            "authors": [
                "Sandesh Swamy",
                "Narges Tabari",
                "Chacha Chen",
                "Rashmi Gangadharaiah"
            ],
            "title": "Contextual dynamic prompting for response generation in task-oriented dialog systems",
            "year": 2023
        },
        {
            "authors": [
                "Aroyo",
                "Ravi Rajakumar",
                "Alena Butryna",
                "Matthew Lamm",
                "Viktoriya Kuzmina",
                "Joe Fenton",
                "Aaron Cohen",
                "Rachel Bernstein",
                "Ray Kurzweil",
                "Blaise AgueraArcas",
                "Claire Cui",
                "Marian Croak",
                "Ed Chi",
                "Quoc Le"
            ],
            "title": "Lamda: Language models for dialog",
            "year": 2022
        },
        {
            "authors": [
                "Pengfei Zhang",
                "Tingting Chai",
                "Yongdong Xu"
            ],
            "title": "Adaptive prompt learning-based few-shot sentiment analysis",
            "year": 2022
        },
        {
            "authors": [
                "Rui Zhang",
                "Yajing Sun",
                "Jingyuan Yang",
                "Wei Peng"
            ],
            "title": "2023a. Knowledge-augmented frame semantic parsing with hybrid prompt-tuning",
            "year": 2023
        },
        {
            "authors": [
                "Xiaoying Zhang",
                "Baolin Peng",
                "Kun Li",
                "Jingyan Zhou",
                "Helen Meng."
            ],
            "title": "Sgp-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting",
            "venue": "arXiv, abs/2305.09067.",
            "year": 2023
        }
    ],
    "sections": [
        {
            "text": "The de facto way of utilizing black-box large language models (LLMs) to perform various downstream tasks is prompting. However, obtaining suitable prompts for specific tasks is still a challenging problem. While existing LLM-based methods demonstrate promising performance in the task-oriented dialogue (TOD) task, they often require manual adjustment in prompt selection or focus solely on dialogue understanding or generation. To address these issues, we propose an adaptive prompt generation framework to fully unleash the potential of LLMs for the comprehensive TOD system. Firstly, we design a trainable slot generator (TSG) that can generate domain and slot information in the belief state, which serves as prior knowledge for subsequent prompt generation. Next, we propose an adaptive prompt generator (APG) that utilizes the prior knowledge to generate prompts for the LLM, deriving the belief state and system response of the dialogue for evaluation. Finally, we evaluate our framework on the MultiWOZ 2.0 dataset. Extensive experiments demonstrate that our method outperforms existing methods. Our code and data will be released."
        },
        {
            "heading": "1 Introduction",
            "text": "In recent years, significant progress has been made in LLMs, such as Instruct-GPT (Ouyang et al., 2022) and GPT4, and remarkable results have been achieved in their application to various downstream tasks such as task-oriented dialogue (TOD) and text summarization (Bang et al., 2023). Prompting has become a de facto method for utilizing black-box LLMs, as appropriate prompts can significantly enhance the capabilities of these models. However, different tasks require different prompts, and obtaining these prompts often requires manual adjustment. This is particularly challenging in dynamic\n\u2217 Corresponding author.\nscenarios like the TOD task, where prompt selection should adapt, usually indicating a large amount of manual labor is required.\nIn the context of the TOD system, two crucial components for measuring the success of a dialogue are belief state and system response. When using prompts to generate the system response from black-box LLMs, a problem arises: belief states and system responses vary with the domains and slots involved in dialogues. If the same prompt is used for all dialogues, the prompt becomes overly long and complex, resulting in hallucinations in LLMs. On the other hand, manually designing different prompts for different dialogues would incur a significantly higher labor cost and would be in-\nconvenient when extending the approach to new domains.\nTo address these issues, an automated method is needed to generate appropriate prompts for TOD tasks. One approach is the continuous prompt learning method, where prompts are represented as trainable vectors that can be concatenated with inputs (Shin et al., 2020; Zhang et al., 2022, 2023a; Swamy et al., 2023), enabling the acquisition of prompts suitable for the current input through gradient backpropagation. However, this approach lacks interpretability and requires model fine-tuning, making it unsuitable for black-box models (Diao et al., 2023). Another approach is to represent prompts using discrete tokens, which overcomes the limitations of vector-based prompts (Shin et al., 2020). However, this approach requires designing suitable prompts for different scenarios and these prompts often cannot be learned through training. As a result, it may lead to the suboptimal performance of LLMs and hallucinatory outputs (Bang et al., 2023).\nTraditional methods rely on static or heuristic rules to construct prompts, but such methods are only suitable for simple scenarios. Recent approaches have achieved promising results in prompt generation. Sun et al. (2022) propose a black-box tuning framework but only applicable to continuous prompts. Diao et al. (2023) use policy gradient algorithm to find the optimal prompts, but only focus on classification tasks Li et al. (2023) propose a framework to provide prompt guidance for black-box frozen LLMs, but only focus on dialog response generation. Zhang et al. (2023b) propose a schema-guided prompting method for the TOD system, which still requires manual prompt design. Hence, there is currently no cost-effective method available to address the problem of adaptive prompt generation for black-box LLM-based\nTOD systems. In this paper, we propose an adaptive prompt generation framework for the comprehensive blackbox LLM-based TOD system to address the aforementioned challenges. To obtain appropriate prompts with minimal data, we first extract domain and slot information from the belief state as training data and introduce a trainable slot generator (TSG) that can generate domains and slots involved in each dialogue turn. This approach reduces the annotation cost when expanding to other domains. We then design a generator (APG) using this information to generate domains and slots as prior knowledge for subsequent prompt generation. To automatically generate prompts suitable for the current dialogue state, we maintain a query table of prior knowledge and candidate values. We utilize the previously generated prior knowledge to select suitable entries from the list and compose prompts that capture the current dialogue belief state and system response. This way, the content generated by the LLM is precisely constrained by tailored prompts, which include the desired candidates without introducing redundant content.\nThe main contributions of our work can be summarized as follows:\n1. We design a prompt construction method based on domain and slot information.\n2. We proposed an adaptive prompt generation framework for the comprehensive black-box LLMbased TOD system.\n3. Experimental results demonstrate the effectiveness of our approach in enhancing the capabilities of LLMs."
        },
        {
            "heading": "2 Related work",
            "text": ""
        },
        {
            "heading": "2.1 Black-Box LLMs in Downstream Tasks",
            "text": "In recent years, there has been a proliferation of large language models such as Codex (Chen et al.,\n2021), LaMDA (Thoppilan et al., 2022), PaLM (Chowdhery et al., 2022), chatGPT, GPT4, etc., which have greatly enhanced various downstream tasks in NLP. However, most of these LLMs are not open source and can only be accessed through query and prediction interface (Diao et al., 2023). As a result, a multitude of studies have emerged that focus on prompting methods tailored to specific tasks for black-box LLMs. (Sun et al., 2022) propose a black-box tuning framework but only applicable to common language understanding tasks. (Diao et al., 2023) use policy gradient algorithm to find the optimal prompts, but only focus on classification tasks. (Li et al., 2023) propose a framework to provide prompt guidance for black-box frozen LLMs, but only focus on dialog response generation. (Pan et al., 2023) specifically focuses on optimizing prompts for the dialogue understanding task. In summary, they are not applicable to our task. In our work, we propose an adaptive prompt generation framework for the comprehensive TOD system."
        },
        {
            "heading": "2.2 Prompt Learning",
            "text": "Another line of our work involves prompt learning which finds optimal prompts suitable for specific tasks. One common approach is to train continuous prompts (Liu et al., 2021; Lester et al., 2021; Gu et al., 2022). However, these prompt types are not easily interpretable and require LLMs for training or fine-tuning. Consequently, some studies have proposed constructing prompts in a discrete manner (Shin et al., 2020; Gao et al., 2021; Sun et al., 2022), using generated or manually crafted prompts. (Schick and Sch\u00fctze, 2021) propose the pattern-verbalizer pair (PVP) method, which constructs prompts by selecting appropriate patterns and verbalizers. Inspired by the aforementioned work, we propose a novel approach to generate appropriate prompts for the comprehensive TOD system."
        },
        {
            "heading": "3 Method",
            "text": "Due to the phenomenon of hallucination that occurs during the application of black-box LLMs, it is hard to generate belief states accurately required for TOD tasks. Moreover, as the prompt becomes more complex, the content generated by black-box LLMs, like ChatGPT, becomes even more uncontrollable. Therefore, a method is needed to constrain the content generated by ChatGPT."
        },
        {
            "heading": "3.1 Data Preparation",
            "text": "In this section, we describe the steps involved in preparing the data for our experiments. Our approach involves selecting a small subset of belief states from different domains in the MultiWOZ 2.0 dataset, based on the settings of SOLOIST. Subsequently, the selected data is processed to remove the value component.\nSelection of Belief State Data Subset: We follow the setting of SOLOIST (Peng et al., 2021) and choose a limited number of dialogues that contain only one domain from the MultiWOZ 2.0 dataset. The data statistics of each domain are shown in Table1.\nProcessing of Selected Data: To train a generator that only generates domains and slots of the belief state, we perform further processing to eliminate the value component from the belief state. This step involves removing the actual values associated with each slot in the belief state while retaining the slots and domains. By removing the value component, we focus solely on the task of predicting the belief state without considering specific slot values.\nBy following these steps, we prepare the dataset for our experiments, which enables us to train and evaluate TSG."
        },
        {
            "heading": "3.2 Trainable Slot Generator",
            "text": "In Dialogue State Tracking (DST) task, We use SOLOIST with pre-trained weights and then finetuned on a small amount of data obtained in Section 3.1. Nevertheless, unlike SOLOIST, our model is fine-tuned to generate domains and slots of belief states only. In this process, the TSG will generate prior knowledge which can be used to generate prompts in subsequent adaptive prompt generation framework.\nSpecifically, we can represent each dialog turn in the training dataset as :\nx = (s, b)\nwhere s is the dialog history up to the current dialog turn, b is the annotated belief state only with domain and slots.\nIn the TOD system, the joint probability p(x) can be expressed in the form of an autogressive model:\np(x) = p(b, s)\n= p(b | s)p(s) where p(b | s) refers to predicting the slots in the belief state. Note that we solely focus on predicting the domains and slots of belief states, excluding the values of belief state and system response, as they are generated in the subsequent part.\nIf we define the length of the belief state, which consists solely of domains and slots, as T , the training objective for this process can be denoted as:\nL1 = log p(b | s) = T\u2211 t=1 log p\u03b8 (bt | b<t, s)\nwhere \u03b8 represents the model parameters to be learned.\nIn line with the approach of SOLOIST, we have also incorporated a contrastive learning training objective to improve the efficiency of our model\u2019s learning process. However, unlike SOLOIST, when constructing negative examples (represented as x\u2032), we do not perform a complete replacement of the entire belief state. Instead, we perform separate replacements on the domain and slots components within the altered belief state b. We can define the label for a belief match as y = 1 and the label for a non-match as y = 0. In this case, the training objective of contrastive learning can be formulated as:\nL2 = y log (p\u03b8(x)) + (1\u2212 y) log ( 1\u2212 p\u03b8 ( x\u2032 ))\nThe three types of negative samples generated by our approach are as follows:\n\u2022 Only replacing the domain component of the modified belief state.\n\u2022 Only replacing the slots component of the modified belief state.\n\u2022 Simultaneously replacing both the domain and slots components of the modified belief state.\nFinally, the proposed method in this section is model-agnostic and can be applied with other models interchangeably. However, due to code and data availability, we have only validated the approach using the SOLOIST model in this paper."
        },
        {
            "heading": "3.3 Adaptive Prompt Generation Framework for TOD System",
            "text": "In the TOD task, the belief state serves as an indication of the user\u2019s intent and also acts as an intermediate state for extracting external information. Existing methods have demonstrated that LLMs perform well in acquiring the belief state. However, they also face certain challenges. One important factor is that large-scale models are sensitive to prompts. Clear and concise prompts tend to yield better results, while vague and lengthy prompts may lead to unexpected outcomes.\nThe TOD task differs from traditional tasks in that the domain and intent of user utterances change in each dialogue turn. When extracting information from such dialogues using LLMs, using the same prompt may not effectively capture the required belief state information. On the other hand, using different prompts for each dialogue can significantly increase manual effort.\nTo address this, we propose a model-agnostic adaptive prompt generation framework in this section. This framework assists LLMs in generating the belief state and system response of dialogues. The overall structure of the framework is illustrated in Figure 2.\nAdaptive Prompt Generator (APG): The main function of this generator is to generate prompts that are required to obtain the final belief state and system response. Since the prompts dynamically change based on the dialogue process, we utilize the partial belief state generated in Section 3.2. In addition to this, the candidate lists of domains and slots Lds are required to obtain the complete belief state, as well as the special token lists Lst are required to generate the system response. Next, it is necessary to parse the generated partial belief state b and generate domain sd and slot information ss. We can consider the prompts input to the LLM as a function related to the partial belief state b. The prompts for generating the complete belief state and system response can be represented as f1 and f2, respectively.\nPrompt for Belief State: The prompt for generating the complete belief state consists of two parts: static and dynamic. The static part includes standard prompt and data examples, partly referenced from (Bang et al., 2023), and can be represented as Prompts1. The dynamic part involves domain slots and candidates matched by s and can be de-\nfined as Promptd1. The candidates of slots can be divided into two categories: one category includes slots with limited candidates that can be obtained from the dataset, such as the \u2019area\u2019 slot with candidates [\u2019centre\u2019, \u2019east\u2019, \u2019north\u2019, \u2019south\u2019, \u2019west\u2019]. The other category includes candidates that cannot be exhaustively listed, such as the name slot representing various entity names related to different domains in user intents. The prompt function for generating the complete belief state utilizes the previously partial belief state containing only the domain and slot information, and can be represented as follows:\nf1(b) = Prompts1 + Promptd1(b, Lds)\nwhere specific b has a fixed mapping relationship with the elements in Lds.\nOnce we have the partial belief state b containing only the domain and slot information, we can use its prompt function f1 to generate the prompt. This prompt is then inputted into the LLM, pLLM , to obtain the final result:\ns\u2217 = pLLM (f1(b), s)\nwhere s\u2217 represents the complete belief state in the current dialogue state.\nPrompt for System Response: The prompt for generating the system response also consists of static and dynamic components. The static part serves as a guidance for the LLM to simulate the generation of system response and can be represented as Prompts2. The dynamic part involves matching special tokens based on sd, which are placeholders used to represent systemrecommended entities. The correct selection of these special tokens is crucial for evaluating the success of the dialogue and can be represented as Promptd2. The prompt function for generating the system response requires the dialogue history s and can be represented as:\nf2(sd) = Prompts2 + Promptd2(sd, Lst)\nwhere specific sd has a fixed mapping relationship with the elements in Lst, and both f1, Prompts1, Promptd1, f2, Prompts2, Promptd2 are all in string format, and the \"+\" operator denotes direct string concatenation.\nNext, we need to obtain the system response using the LLM. Based on the previously obtained\nprompt function, the final result can be represented as:\nr = pLLM (f2(s), s)\nwhere r represents the delexicalized system response.\nTherefore, the combined output of the belief state and system response generated by the LLM for evaluation is:\ny = pLLM (f1(b), s) + pLLM (f2(s), s)."
        },
        {
            "heading": "4 Experiment",
            "text": ""
        },
        {
            "heading": "4.1 Dataset and Evaluation",
            "text": "We evaluated the effectiveness of the proposed method on the MultiWOZ single-domain dialog datasets (Budzianowski et al., 2020), reorganized by (Peng et al., 2021). This dataset consists of four domains: Attraction, Hotel, Restaurant, and Train.\nIn the TSG component, we used the standard metric in DST: joint goal accuracy (JGA). This metric compares the predicted belief state with the ground truth belief state to determine if they are completely identical. A successful prediction is achieved when the predicted belief state matches the ground truth belief state entirely. Note that the JGA metric requires both value and slot information to match for a successful evaluation. In our work, the trainable slot generator only generates domain and slot information of the belief state and does not include value information. Therefore, the evaluation is performed by complementing the value information using the LLM in the second part before conducting the evaluation.\nFor the evaluation of the entire dialogue, we concatenate the belief state and system response generated by the LLM in the order of the dialogue and then evaluate them. We employ the following evaluation metrics: Inform, which measures whether the provided entities satisfy the user\u2019s needs correctly; Success, which measures whether all requested attributes are addressed; BLEU is not adopted because it measures the similarity between the generated response and the reference response, and there may be significant differences between the responses generated by the LLM and the reference responses."
        },
        {
            "heading": "4.2 Implementation Details",
            "text": "The slot generator and adaptive prompt framework proposed in our approach are not restricted to specific models. In this paper, the TSG is based on\nGPT-2 with 117M parameters and initialized with pretraining weights from SOLOIST. SOLOIST is pre-trained on corpora from multiple task-oriented dialogue datasets (Schema and Taskmaster) and performs tasks such as belief state prediction and response generation. Specifically, the input for the belief state prediction task is the current dialogue and all dialogue history, and the output is a text sequence corresponding to the current dialogue state. In our task, we only need the domain and slot information from the belief state. An intuitive approach would be to directly extract domain and slot information from the belief state generated by the original model. However, this method would result in more complex and longer text sequences, requiring more time but not improving accuracy. Therefore, we only trained the model using the domain and slot parts of the belief state.\nIn the experimental part of the adaptive prompt framework, the LLM we use is chatgpt-3.5-turbo. We generated belief states and system responses of dialogues by calling OpenAI\u2019s API. We find the format of the generated content can affect its accuracy, if we use curly braces to restrict the belief state, such as \"{belief state: attraction type = entertainment}\", the result is better than when not using curly braces, like \"belief state: attraction type = entertainment\". Based on our experience, we control the format of the generated content to achieve optimal results. Therefore, belief states and system responses generated during the intermediate process may differ slightly in format from those in SOLOIST."
        },
        {
            "heading": "4.3 Trainable Slot Generator (TSG)",
            "text": ""
        },
        {
            "heading": "4.3.1 Setup",
            "text": "The goal of the TSG is to generate belief states that only contain slot information. We use SOLOIST as a baseline to compare the improvement of our method on the final results. First, we train the TSG following SOLOIST, and the data statistics of dataset are shown in Table 1. The training epoch is 30, the learning rate is 5e-5, and the batch size is 1. During testing, Nucleus filtering is used for decoding with a top-p value of 0.4 and a temperature of 0.3 to obtain the belief state. Since we only need the slot part of the belief state, we parsed the belief state and generated a new belief state that only includes the domain and slot information using rules-based methods.\nFor our proposed method, we only used the do-\nmain and slot information from the belief state instead of the complete belief state for training. This approach has two advantages as follows:"
        },
        {
            "heading": "4.3.2 Results",
            "text": "The results obtained by different methods are shown in Table 2. We observe that directly utilizing ChatGPT for extracting slot information of belief state is not particularly effective. The method trained with shorter belief states surpasses the results obtained by extracting slot information from the original SOLOIST method, and is also better than PPTOD and ChatGPT. We can observe that in more complex domains, such as hotels, the improvement becomes more pronounced as the belief state becomes more complex. This indicates that using less information for training can lead to more\naccurate results, validating the potential of our proposed method. It is worth noting that the JGA metric of belief states containing only domain and slot information reflects the algorithm\u2019s advantage from one aspect. Further application in subsequent methods is needed to verify its actual improvement in the final dialogue evaluation.\nTo assess the generalizability of our proposed method, we applied the TSG to the Camrest676 dataset. The results as shown in Table 3 indicate that, even when tested on a novel dataset, our proposed method consistently enhances the results. This observation underscores the method\u2019s capacity to generalize to datasets beyond its training domain."
        },
        {
            "heading": "4.4 Adaptive Prompt Framework",
            "text": ""
        },
        {
            "heading": "4.4.1 Setup",
            "text": "The purpose of the Adaptive Prompt Framework is to generate suitable prompts for inputting the current dialogue into the LLM to obtain the corresponding belief state and system response. The underlying assumption is that the LLM possesses strong comprehension and generalization capabilities and can adapt to various downstream tasks by designing appropriate prompts. Specifically, the Adaptive Prompt Framework consists of two parts:\nPart 1 involves refining the results from the TSG. Firstly, a candidate list of domains, slots, and their corresponding values is compiled based on the dataset. This list serves the purpose of retrieving the candidate values for a given domain and slot when we obtain the domain and slot information. This candidate list includes two types of entries. The first type comprises slots with limited values, where the values can be represented by short-word sequences, such as slots indicating time or direction. The second type consists of slots with potentially infinite values, where the values may vary during the conversation, such as the \"name\" slot that may change with different entities discussed in the dialogue. These entries cannot be exhaustively enumerated, and thus we use \"?\" to represent candidate values. Each entry in the candidate list pertains to a single domain and slot but can contain multiple candidate values.\nNext, we incorporate the static prompt section, based on existing work on generating prompts for belief states. However, these prompts are not adaptable to subsequent dynamic utterances. Therefore, we adjust them by adding instructions on how to\nuse the subsequent dynamic section and include an example to provide constraints on the generated format.\nThen, we parse the results generated by the TSG, extract the domain and slot information, and select the relevant entries from the existing domainslot-value candidate list to form a list of candidate entries.\nFinally, we process the input dialogue information to generate the second dynamic part of the prompt. This part consists of current user utterances, dialogue history, and partial belief state, combined into a string list format. The partial belief state is represented as \"{slot =?}\". The example prompt is presented in Appendix A.\nPart 2 involves generating the system response based on the user utterance and dialogue history in the current conversation. The purpose of this part is to have the LLM act as an agent in the TOD system and respond to user requests by generating delexicalized system responses. It is important to note that, for the convenience of evaluating the success rate of subsequent dialogue, recommended or queried entities in the generated response need to be replaced with special tokens. The complete response is then generated through post-processing.\nSimilar to the previous part, we need to compile a list of domains and corresponding special tokens based on the dataset. This list serves the purpose of retrieving candidate values for a given domain using table lookup when we obtain the domain information, to provide the LLM with options for generating the final system response. This candidate list includes two types of special tokens. The first type consists of domain-specific special tokens represented in the form of domain-slot, such as \"attraction-name\". The second type comprises special tokens that are universally applicable across all domains and are represented as value-slot, such as \"value-time\". These special tokens represent some commonly occurring entities that may be encountered in all domains.\nNext, we incorporate the static prompt section for generating the system response based on the belief state prompt generated in the previous part.\nThen, we generate the second dynamic section of the system response prompt using the current user utterance and dialogue history.\nFinally, based on the parsing results from the slot generator, we obtain the domain information and select the relevant entries from the domain-\nspecial token candidate list to form a list of candidate entries. The example prompt is presented in Appendix A."
        },
        {
            "heading": "4.4.2 Compared Methods",
            "text": "To demonstrate the effectiveness of our proposed method, we compared it with several different combinations of methods for validation. The main methods we employed are as follows:\n\u2022 SOLOIST: Using SOLOIST alone to generate belief states and system responses, followed by direct evaluation.\n\u2022 ChatGPT: Generating belief states and system responses separately using ChatGPT. Then, the two parts are concatenated for evaluation. In contrast to our proposed method in this section, this approach uses static prompts. Specifically, when generating belief states, the dynamic prompt section from our proposed method, which consists of the candidate list based on the output of TSG, is replaced with the complete domain-slot-value list. Similarly, when generating system responses, the dynamic prompt part from our proposed method, which consists of the candidate list based on the domain information, is replaced with the complete domain-special token list. In other words, this method solely relies on ChatGPT to generate the required information, aiming to verify if ChatGPT is capable of completing the entire task.\n\u2022 ours w/o APG: The domain and slot information is generated using TSG, and then the static prompt is used to input into ChatGPT for generating the final belief state and system response.\n\u2022 ours w/o TSG: Using SOLOIST to generate belief states. After that, the prompt is generated using APG and input into ChatGPT to generate system responses.\nThese methods were evaluated by concatenating the corresponding components and assessing their performance."
        },
        {
            "heading": "4.4.3 Results",
            "text": "The final evaluation results are presented in Table 4. We use SOLOIST as the baseline. It can be observed that the ours w/o TSG method achieves an average improvement of 5 points. This improvement can be attributed to the powerful comprehension and generation capabilities of ChatGPT, allowing it to generate responses that align well with the conversational context. The ChatGPT method alone brings an average improvement of 1 point, indicating its capability to generate belief states effectively. However, we noticed that ChatGPT performs better in generating simple belief states (e.g., in the attraction domain) but struggles with complex belief states (e.g., in the train domain). We speculate that this discrepancy is due to complex belief states containing more information, and ChatGPT\u2019s instability in generating longer pieces of information. Ultimately, our proposed method\noutperforms the ChatGPT method with an average improvement of 8 points. This indicates our framework effectively mitigates the issue of hallucination in ChatGPT."
        },
        {
            "heading": "5 Analysis",
            "text": "High-frequency Errors. For the unsuccess dialogues, we analyze high-frequency errors comparing the chatgpt method in the restaurant domain with our proposed method, as shown in Figure 3. Specifically, \"format error\" is the error that prevents the belief state from being parsed, \"dialogue generation error\" refers to the result of a system response that does not align with logic, and \"belief state error\" refers to unmatched content.\nOur method significantly reduces the number of evaluation failures caused by format errors owing to the inclusion of precise constraints in the prompt. Furthermore, the proportion of dialogue generation errors is also reduced. Lastly, the occurrence of belief states\u2019 errors has been mitigated due to the trainable slot generator.\nDrawback of Static Prompt. While the present study has already included a comparison between static and dynamic prompts, to more distinctly illustrate the differences between existing methods and our proposed approach, we conducted a com-\nparative analysis of the effects of prompts using the frameworks presented in Bang et al. (2023) and Pan et al. (2023).\nAs depicted in Table 7, the dynamic prompt exhibits a significantly higher performance in the inform metric compared to existing static prompt methods. This is attributed to the inability of static prompts to adapt to different domains.\nSimilarly, to investigate the impact of static and dynamic prompts on system response, we supplemented our study with more detailed experiments to compare their effects on the final results. Specifically, we replaced the dynamic part of the prompt with a static prompt containing all entries. As shown in Table n, using only a static prompt has a significant impact on success, resulting in a decrease in the combined score.\nNecessity of Belief State in TOD. Due to the inability of LLMs to interact extensively with external knowledge, such as querying restaurant availability from a DB, we still need to retrieve keywords from the belief state to perform DB queries. While there may be better approaches in the future, currently, querying external knowledge through the belief state remains a more reliable method."
        },
        {
            "heading": "6 Conclusion",
            "text": "To address the issue of prompt generation of LLMs in the TOD task, we propose an adaptive prompt generation framework for the comprehensive TOD system which consists of two parts: trainable slot generator (TSG) and adaptive prompt generator (APG). The framework tackles the limitation of fixed prompts in TOD and focuses on both dialogue understanding and dialogue generation. Experimental results demonstrate that our proposed method significantly improves the performance compared to existing approaches.\nLimitations\nLimitations There are several aspects of this article that can be improved in the future:\nResult Updates: As ChatGPT continues to evolve, we can continue using newer versions to enhance performance.\nMore Scenarios: Currently, we have only experimented with single-domain task-oriented dialogues. In the future, we can improve the model\u2019s performance in multi-domain scenarios or incorporate additional information, such as database query information, into the prompts.\nGeneralization validation: In the future, we can expand our approach to compare it with other methods in a broader range of tasks and validate its generalization capabilities."
        },
        {
            "heading": "Acknowledgements",
            "text": "The authors would like to thank Xiaoying Zhang for useful discussions. This work is supported by National Key R&D Program of China (Grant No.2022YFF1202400), Major Technology Innovation Program of Hangzhou, China (Grant 2022AIZD0154), National Natural Science Foundation of China (No.62176025), National Natural Science Foundation of China (No.62301066), Beijing Nova Program 20220484161, and the Fundamental Research Funds for the Central Universities 2023RC72. This work is also sponsored by CCF-DiDi GAIA Collaborative Research Funds for Young Scholars."
        },
        {
            "heading": "A Appendix",
            "text": "A.1 Prompt for Belief State The various parts of the prompt for obtaining the belief state are presented in Table 8. The dynamic part automatically adapts based on different inputs to generate the optimal prompt.\nA.2 Prompt for System Response Similarly, the prompt for obtaining the system response is presented in Table 9. The dynamic part also selects relevant entries based on the output of TSG."
        }
    ],
    "title": "An Adaptive Prompt Generation Framework for Task-oriented Dialogue System",
    "year": 2023
}