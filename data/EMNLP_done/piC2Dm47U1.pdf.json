{
    "abstractText": "Conventional approaches to relation extraction can only recognize predefined relation types. In the real world, new or out-of-scope relation types may keep challenging the deployed models. In this paper, we formalize such a challenging problem as Novel Relation Detection (NRD), which aims to discover potential new relation types based on training samples of known relations. To this end, we construct two NRD datasets and exhaustively investigate a variety of out-of-scope detection methods. We further propose an effective NRD method that utilizes multi-strategy self-supervised learning to handle the problem of shallow semantic similarity in the NRD task. Experimental results demonstrate the effectiveness of our method, which significantly outperforms previous stateof-the-art methods on both datasets.",
    "authors": [
        {
            "affiliations": [],
            "name": "Qingbin Liu"
        },
        {
            "affiliations": [],
            "name": "Yin Kung"
        },
        {
            "affiliations": [],
            "name": "Yanchao Hao"
        },
        {
            "affiliations": [],
            "name": "Dianbo Sui"
        },
        {
            "affiliations": [],
            "name": "Siyuan Cheng"
        },
        {
            "affiliations": [],
            "name": "Xi Chen"
        },
        {
            "affiliations": [],
            "name": "Ningyu Zhang"
        },
        {
            "affiliations": [],
            "name": "Jiaoyan Chen"
        }
    ],
    "id": "SP:db8f8b1de5a76e8c02250598fb49b808499308a7",
    "references": [
        {
            "authors": [
                "Markus M. Breunig",
                "Hans-Peter Kriegel",
                "Raymond T. Ng",
                "J\u00f6rg Sander."
            ],
            "title": "LOF: identifying densitybased local outliers",
            "venue": "Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, pages 93\u2013104.",
            "year": 2000
        },
        {
            "authors": [
                "Varun Chandola",
                "Arindam Banerjee",
                "Vipin Kumar."
            ],
            "title": "Anomaly detection: A survey",
            "venue": "ACM Comput. Surv., 41(3):15:1\u201315:58.",
            "year": 2009
        },
        {
            "authors": [
                "Lei Cui",
                "Furu Wei",
                "Ming Zhou."
            ],
            "title": "Neural open information extraction",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 407\u2013 413.",
            "year": 2018
        },
        {
            "authors": [
                "Li Cui",
                "Deqing Yang",
                "Jiaxin Yu",
                "Chengwei Hu",
                "Jiayang Cheng",
                "Jingjie Yi",
                "Yanghua Xiao."
            ],
            "title": "Refining sample embeddings with relation prototypes to enhance continual relation extraction",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for",
            "year": 2021
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Tianyu Gao",
                "Xu Han",
                "Hao Zhu",
                "Zhiyuan Liu",
                "Peng Li",
                "Maosong Sun",
                "Jie Zhou"
            ],
            "title": "FewRel 2.0: Towards more challenging few-shot relation classification",
            "venue": "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
            "year": 2019
        },
        {
            "authors": [
                "Zhijiang Guo",
                "Yan Zhang",
                "Wei Lu."
            ],
            "title": "Attention guided graph convolutional networks for relation extraction",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 241\u2013251.",
            "year": 2019
        },
        {
            "authors": [
                "Xu Han",
                "Hao Zhu",
                "Pengfei Yu",
                "Ziyun Wang",
                "Yuan Yao",
                "Zhiyuan Liu",
                "Maosong Sun."
            ],
            "title": "FewRel: A large-scale supervised few-shot relation classification dataset with state-of-the-art evaluation",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods",
            "year": 2018
        },
        {
            "authors": [
                "Ethan Harris",
                "Antonia Marcu",
                "Matthew Painter",
                "Mahesan Niranjan",
                "Adam Pr\u00fcgel-Bennett",
                "Jonathon Hare."
            ],
            "title": "FMix: Enhancing Mixed Sample Data Augmentation",
            "venue": "arXiv e-prints, page arXiv:2002.12047.",
            "year": 2020
        },
        {
            "authors": [
                "Iris Hendrickx",
                "Su Nam Kim",
                "Zornitsa Kozareva",
                "Preslav Nakov",
                "Diarmuid \u00d3 S\u00e9aghdha",
                "Sebastian Pad\u00f3",
                "Marco Pennacchiotti",
                "Lorenza Romano",
                "Stan Szpakowicz"
            ],
            "title": "SemEval-2010 task 8: Multiway classification of semantic relations between pairs",
            "year": 2010
        },
        {
            "authors": [
                "Dan Hendrycks",
                "Kevin Gimpel."
            ],
            "title": "A baseline for detecting misclassified and out-of-distribution examples in neural networks",
            "venue": "5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track",
            "year": 2017
        },
        {
            "authors": [
                "Dan Hendrycks",
                "Mantas Mazeika",
                "Thomas G. Dietterich."
            ],
            "title": "Deep anomaly detection with outlier exposure",
            "venue": "7th International Conference on Learning Representations.",
            "year": 2019
        },
        {
            "authors": [
                "Victoria J. Hodge",
                "Jim Austin."
            ],
            "title": "A survey of outlier detection methodologies",
            "venue": "Artif. Intell. Rev., 22(2):85\u2013126.",
            "year": 2004
        },
        {
            "authors": [
                "Keshav Kolluru",
                "Muqeeth Mohammed",
                "Shubham Mittal",
                "Soumen Chakrabarti",
                "Mausam ."
            ],
            "title": "Alignment-augmented consistent translation for multilingual open information extraction",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for",
            "year": 2022
        },
        {
            "authors": [
                "Kimin Lee",
                "Honglak Lee",
                "Kibok Lee",
                "Jinwoo Shin."
            ],
            "title": "Training confidence-calibrated classifiers for detecting out-of-distribution samples",
            "venue": "6th International Conference on Learning Representations.",
            "year": 2018
        },
        {
            "authors": [
                "Pengfei Li",
                "Kezhi Mao",
                "Xuefeng Yang",
                "Qi Li."
            ],
            "title": "Improving relation extraction with knowledgeattention",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natu-",
            "year": 2019
        },
        {
            "authors": [
                "Ting-En Lin",
                "Hua Xu."
            ],
            "title": "Deep unknown intent detection with margin loss",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5491\u20135496.",
            "year": 2019
        },
        {
            "authors": [
                "Yankai Lin",
                "Shiqi Shen",
                "Zhiyuan Liu",
                "Huanbo Luan",
                "Maosong Sun."
            ],
            "title": "Neural relation extraction with selective attention over instances",
            "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
            "year": 2016
        },
        {
            "authors": [
                "Fangchao Liu",
                "Lingyong Yan",
                "Hongyu Lin",
                "Xianpei Han",
                "Le Sun."
            ],
            "title": "Element intervention for open relation extraction",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Confer-",
            "year": 2021
        },
        {
            "authors": [
                "Diego Marcheggiani",
                "Ivan Titov."
            ],
            "title": "Discretestate variational autoencoders for joint discovery and factorization of relations",
            "venue": "Transactions of the Association for Computational Linguistics, 4:231\u2013244.",
            "year": 2016
        },
        {
            "authors": [
                "Sebastian Riedel",
                "Limin Yao",
                "Andrew McCallum",
                "Benjamin M. Marlin."
            ],
            "title": "Relation extraction with matrix factorization and universal schemas",
            "venue": "Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational",
            "year": 2013
        },
        {
            "authors": [
                "Seonghan Ryu",
                "Sangjun Koo",
                "Hwanjo Yu",
                "Gary Geunbae Lee."
            ],
            "title": "Out-of-domain detection based on generative adversarial network",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 714\u2013718.",
            "year": 2018
        },
        {
            "authors": [
                "Oscar Sainz",
                "Oier Lopez de Lacalle",
                "Gorka Labaka",
                "Ander Barrena",
                "Eneko Agirre."
            ],
            "title": "Label verbalization and entailment for effective zero and few-shot relation extraction",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language",
            "year": 2021
        },
        {
            "authors": [
                "Bernhard Sch\u00f6lkopf",
                "John C. Platt",
                "John Shawe-Taylor",
                "Alex J. Smola",
                "Robert C. Williamson."
            ],
            "title": "Estimating the Support of a High-Dimensional Distribution",
            "venue": "Neural Computation, 13(7):1443\u20131471.",
            "year": 2001
        },
        {
            "authors": [
                "Lei Shu",
                "Hu Xu",
                "Bing Liu."
            ],
            "title": "DOC: Deep open classification of text documents",
            "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2911\u20132916.",
            "year": 2017
        },
        {
            "authors": [
                "Denny Vrandecic",
                "Markus Kr\u00f6tzsch."
            ],
            "title": "Wikidata: a free collaborative knowledgebase",
            "venue": "Commun. ACM, 57(10):78\u201385.",
            "year": 2014
        },
        {
            "authors": [
                "Hong Wang",
                "Wenhan Xiong",
                "Mo Yu",
                "Xiaoxiao Guo",
                "Shiyu Chang",
                "William Yang Wang."
            ],
            "title": "Sentence embedding alignment for lifelong relation extraction",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Yijun Wang",
                "Changzhi Sun",
                "Yuanbin Wu",
                "Hao Zhou",
                "Lei Li",
                "Junchi Yan."
            ],
            "title": "UniRE: A unified label space for entity relation extraction",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International",
            "year": 2021
        },
        {
            "authors": [
                "Ruidong Wu",
                "Yuan Yao",
                "Xu Han",
                "Ruobing Xie",
                "Zhiyuan Liu",
                "Fen Lin",
                "Leyu Lin",
                "Maosong Sun."
            ],
            "title": "Open relation extraction: Relational knowledge transfer from supervised data to unsupervised data",
            "venue": "Proceedings of the 2019 Conference on Empirical",
            "year": 2019
        },
        {
            "authors": [
                "Yanan Wu",
                "Zhiyuan Zeng",
                "Keqing He",
                "Hong Xu",
                "Yuanmeng Yan",
                "Huixing Jiang",
                "Weiran Xu."
            ],
            "title": "Novel slot detection: A benchmark for discovering unknown slot types in the task-oriented dialogue system",
            "venue": "Proceedings of the 59th Annual Meet-",
            "year": 2021
        },
        {
            "authors": [
                "Hong Xu",
                "Keqing He",
                "Yuanmeng Yan",
                "Sihong Liu",
                "Zijun Liu",
                "Weiran Xu."
            ],
            "title": "A deep generative distance-based classifier for out-of-domain detection with mahalanobis space",
            "venue": "Proceedings of the 28th International Conference on Computational Linguis-",
            "year": 2020
        },
        {
            "authors": [
                "Guangfeng Yan",
                "Lu Fan",
                "Qimai Li",
                "Han Liu",
                "Xiaotong Zhang",
                "Xiao-Ming Wu",
                "Albert Y.S. Lam."
            ],
            "title": "Unknown intent detection using Gaussian mixture model with an application to zero-shot intent classification",
            "venue": "Proceedings of the 58th Annual Meeting of",
            "year": 2020
        },
        {
            "authors": [
                "Limin Yao",
                "Aria Haghighi",
                "Sebastian Riedel",
                "Andrew McCallum."
            ],
            "title": "Structured relation discovery using generative models",
            "venue": "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1456\u20131466.",
            "year": 2011
        },
        {
            "authors": [
                "Jun Zhao"
            ],
            "title": "Relation classification via",
            "year": 2014
        },
        {
            "authors": [
                "Jun Zhao"
            ],
            "title": "Extracting relational facts by",
            "year": 2018
        },
        {
            "authors": [
                "David Lopez-Paz"
            ],
            "title": "mixup: Beyond empirical",
            "year": 2018
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Relation extraction (RE) is an important task in structured information extraction, which aims to recognize the relations of entity pairs from texts (Riedel et al., 2013; Zeng et al., 2014; Lin et al., 2016). For example, given the sentence \u201cWestworld is a science fiction western series directed by Jonathan Nolan.\u201d and the entity pair [Jonathan Nolan, Westworld], an RE model should output the relation type \u201cthe director of \u201d.\nExisting RE methods typically follow the closedworld classification assumption and can only recognize predefined relation types. However, such an assumption limits the usage of these methods in real-world applications, as new or out-of-scope (OOS) relation types may continually emerge after the model is deployed. For example, in the Wikidata knowledge graph (Vrandecic and Kr\u00f6tzsch,\n\u2217Equal Contribution. \u2020Corresponding author.\n2014), new items and properties keep appearing over time1. These new relations may mislead the deployed RE model, making it incorrectly assign known relations to the data of new relations, as shown in Figure 1. In addition, existing methods cannot automatically discover new relations for future development.\nTo handle this problem, we propose a more realistic and challenging task, Novel Relation Extraction (NRE), which aims to discover potential new relation types based on training samples of known relations. Note that we define novel relations as OOS relations that are not included in the predefined relation set. In the NRE task, we group the novel relation types into a new class and convert the traditional k-class RE task into a (k + 1)-class RE task. The (k + 1)-th class represents the novel relation. This task requires RE models to correctly identify not only the known relations but also the novel relation. Based on the OOS data collected by the NRE model, developers can easily and purposefully annotate the data and update the model, as shown in Figure 1.\nThe novel relation class in the NRE task is differ-\n1https://www.wikidata.org/wiki/Wikidata:News\nent from the \u201cno relation\u201d class and the \u201cother relation\u201d class in existing RE tasks (Hendrickx et al., 2010; Zhang et al., 2017). Previous developers always assume that the \u201cno relation\u201d class and the \u201cother relation\u201d class are known in the development phase, and they can annotate a large amount of training data for these two relations to train RE models. However, the novel relation class indicates that the text contains new or OOS relations whose distribution is unknown and unpredictable in the development phase. It is infeasible for developers to annotate training data for the novel relation class in real-world applications since real test data is usually unknown and continually changing.\nThere are two lines of previous work related to NRE, open RE (Yao et al., 2011; Marcheggiani and Titov, 2016; Wu et al., 2019; Liu et al., 2021) and OOS detection (Hodge and Austin, 2004; Chandola et al., 2009; Lin and Xu, 2019; Wu et al., 2021). Open RE means that there are no predefined relation types and no labeled data. Open RE extracts phrases and arguments as specific relations and discovers new relations by clustering or heuristics. Compared to open RE, NRE strengthens the capability of the conventional RE methods and aims to automatically discover novel relation types that are not in the predefined relation set, while providing accurate predictions for known relations. Another line of related work is OOS detection, which aims to recognize OOS data that does not belong to any predefined class. Although OOS detection has been widely investigated in other NLP tasks, its exploration in RE is relatively rare.\nTherefore, in this paper, we formalize the NRE task and construct two NRE datasets based on two widely used RE datasets, FewRel (Han et al., 2018) and TACRED (Zhang et al., 2017). Then, to establish NRE\u2019s baselines, we exhaustively investigate a variety of OOS detection methods (Hendrycks and Gimpel, 2017; Lin and Xu, 2019; Yan et al., 2020). In general, previous OOS detection methods usually learn the decision boundaries of known classes based on the feature or probability distributions of known training data. In the testing phase, they use confidence scores to identify samples outside the decision boundaries as OOS data.\nHowever, when applying existing OOS detection methods in the NRE task, we find a shallow semantic similarity problem. Specifically, sentences with OOS relations may have similar surface information, such as entity overlapping and similar syntac-\ntic structures, to sentences with known relations, as shown in Figure 2. Previous methods only use training samples of known relations to train models, which makes them difficult to handle OOS data with similar surface information. They may predict similar features or probabilities for these OOS data and known training data, eventually leading to confusion between the novel and known relations.\nTo address the above problem, we propose an effective NRE method, called Multi-Strategy SelfSupervised Learning (M3S), which explicitly models OOS data with similar semantic information by constructing pseudo-OOS data. Specifically, M3S uses features of known training data to construct various pseudo-OOS data. In the semantic feature space, these pseudo data are close to the known data. Then, M3S utilizes these pseudo-OOS data to train the model, thus improving the generalization in the novel relation. Experimental results show that M3S significantly outperforms previous stateof-the-art OOS detection methods.\nIn summary, the contributions of this work are as follows: (1) To the best of our knowledge, we are the first to formally introduce OOS detection into RE and we construct two NRE benchmarks through two widely used RE datasets. (2) We investigate a variety of existing OOS detection methods and further propose multi-strategy self-supervised learning, which can effectively handle the problem of shallow semantic similarity in the NRE task. (3) Experimental results show that M3S significantly outperforms previous OOS detection methods on the two benchmarks. The source code and benchmarks will be released for further research (https://github.com/liuqingbin2022/NRE)."
        },
        {
            "heading": "2 Task Formulation",
            "text": ""
        },
        {
            "heading": "2.1 Relation Extraction",
            "text": "The traditional RE task is usually formulated as a text classification task (Zhang et al., 2017; Han et al., 2018). Given a sentence x that contains a pair of entities, the traditional RE task is to predict a\nrelation y for these two entities. This task assumes y \u2208 Y , where Y denotes a predefined relation set."
        },
        {
            "heading": "2.2 Novel Relation Extraction",
            "text": "The NRE task aims to identify the data of OOS relations while correctly classifying the data of known relations. We denote the data of known relations as Do = (Do1,Do2, ...,Dok). Doi is the data of the i-th known relation, which has its own training, validation, and test sets (Dtrain,oi , D valid,o i , D test,o i ). To match the realistic environment, there is no training and validation data for the novel relation type. In the development phase, the NRE model can only access the training and validation data of known relations. In the test phase, the NRE model should classify each sample into (k + 1)-class relations, where the (k+1)-th class is the novel relation type. Therefore, in the test phase, we employ the test data of both known and novel relations to evaluate the model. Due to the lack of OOS training data, it is difficult for previous RE methods to make accurate predictions for the novel relation type."
        },
        {
            "heading": "3 Dataset",
            "text": "To the best of our knowledge, we are the first to formally introduce the NRE task. Therefore, we construct two NRE datasets based on two widely used RE datasets. In this section, we first briefly introduce the original RE datasets and then describe the construction method of the NRE datasets. Finally, we show the statistics of these datasets."
        },
        {
            "heading": "3.1 Original Relation Extraction Datasets",
            "text": "FewRel (Han et al., 2018) is a few-shot RE dataset, which contains 100 relations. In our work, we use the publicly available 80 relations as the original dataset. Since FewRel contains a sufficient number of relation types, we can use FewRel to simulate various OOS relations well. Each relation in the FewRel dataset has 700 labeled data. TACRED (Zhang et al., 2017) is an RE dataset that contains 42 relations. In the TACRED dataset, there are 68124, 22631, and 15509 samples in the training, validation, and test sets, respectively."
        },
        {
            "heading": "3.2 NRE Dataset Construction",
            "text": "For an original RE dataset, we randomly select some relations as OOS relations according to a specific ratio. Since many relations can be predefined in practical applications, we adopt three reasonable ratios, 10%, 20%, and 30%, in this paper. For\nthese OOS relations, we remove their training and validation data and keep their test data as the test data of the novel relation type. Based on FewRel and TACRED, we propose two instantiations of the above construction method. FewRel-NRE: Since the original FewRel dataset does not provide data splitting, we split the data of each relation in a 3:1:1 ratio into the training, validation, and test sets. TACRED-NRE: Considering the severe class imbalance in TACRED, we use the top 20 most frequent relations and limit the number of training, validation, and test samples of each relation to 180, 60, and 60, respectively. We treat the \u201cno relation\u201d class in TACRED as a known relation to fit the realworld setting. To avoid randomness, we construct 5 different datasets with 5 different random seeds for each specific ratio. These datasets can well simulate unpredictable and diverse OOS relations in the real world. Table 1 shows the statistics of the two constructed datasets in which 20% of the relations are selected as OOS relations."
        },
        {
            "heading": "4 Previous OOS Detection Methods",
            "text": "In other OOS detection tasks, recent work has attempted to find an appropriate decision boundary to balance the performance of both known and OOS relations. We roughly divide previous methods into two categories: probability-based methods (Hendrycks and Gimpel, 2017; Shu et al., 2017) and feature-based methods (Lin and Xu, 2019; Yan et al., 2020). We apply these methods to the NRE task and provide a detailed quantitative analysis."
        },
        {
            "heading": "4.1 Probability-Based Methods",
            "text": "Probability-based methods assume that the updated model will not be overconfident in the OOS data. In the training phase, probability-based methods use the training data of known relations to update the model. In the test phase, these methods derive a confidence score from the probability distribution of each sample. If the confidence score of a test\nsample is below a threshold, it is treated as OOS data. For example, MSP (Hendrycks and Gimpel, 2017) adopts the maximum softmax probability as the confidence score.\nHowever, we find that these methods perform poorly in the NRE task. To give a clear analysis, we present the maximum probabilities of test samples with known relations and OOS relations separately in Figure 3. From the results, we can see that both the MSP and DOC (Shu et al., 2017) methods tend to overconfidently assign known relations to OOS data. We speculate that since these models have not learned the OOS data, they may not generalize well to the OOS data with similar surface information, leading to incorrect predictions. Besides, these methods require an additional validation set containing OOS data to obtain the threshold (\u03c4 )."
        },
        {
            "heading": "4.2 Feature-Based Methods",
            "text": "Feature-based methods derive the confidence score from the feature distribution. In the training phase, these methods employ specific optimization objectives to constrain the feature distribution of known classes. In the test phase, they use distance-based outlier detection algorithms, such as LOF (Breunig et al., 2000), to derive the confidence score from the feature distribution. For example, SEG (Yan et al., 2020) is a typical feature-based method that assumes the features of known classes follow a Gaussian mixture distribution.\nTo verify the effectiveness of feature-based methods on the NRE task, we provide the feature visualization of the SEG method in Figure 4. We can see that many features of OOS relations are con-\nfused with features of known relations. Since the SEG method has not learned OOS data, it may have difficulty extracting valid features for these OOS samples, which ultimately hurts the performance."
        },
        {
            "heading": "5 Methodology",
            "text": "To address the above problem, we propose MultiStrategy Self-Supervised Learning, which explicitly models OOS data with similar surface information by constructing various pseudo-OOS data."
        },
        {
            "heading": "5.1 Input Encoding",
            "text": "We adopt BERT (Devlin et al., 2019), which is a powerful pre-trained language model, as the text encoder. The BERT encoder outputs a contextual representation for each input sequence as:\nhx = BERT(x) (1)\nwhere hx is the hidden state. We use the hidden state of the [CLS] token as the feature representation (f(x)) of each sequence. Note that our method is agnostic to the model architecture. Other encoders can also be adopted."
        },
        {
            "heading": "5.2 Multi-Strategy Self-Supervised Learning",
            "text": "In M3S, we design three self-supervised strategies to construct pseudo-OOS data, including convex combination, regional replacement, and irregular replacement. These pseudo-OOS data, together with the training data of known relations, are used to update the model to improve its generalization. The framework of M3S is shown in Figure 5."
        },
        {
            "heading": "5.2.1 Convex Combination",
            "text": "For this strategy, we use convex combinations of sample features from different relations as pseudo-\nOOS data, which can be formalized as:\nf cc = \u03b1 \u2217 f(x1) + (1\u2212 \u03b1) \u2217 f(x2) (2)\nwhere x1 and x2 are two training samples with different known relations. These two samples are randomly selected from the same training batch. f cc is the synthetic OOS data. \u03b1 is a scalar that is randomly sampled from a uniform distribution U(0, 1). If \u03b1 is close to 0 or 1, f cc will be close to the features of known relations in the semantic feature space. These synthetic features can thus simulate real OOS data that have similar semantic information as known training data.\nThese synthetic features are assigned to the novel relation type to form a new training set: Dtrain,cc =\u22c3N\ni=1 f cc i . Since these samples are constructed in the feature space, it is very efficient to construct a large number of pseudo data."
        },
        {
            "heading": "5.2.2 Regional Replacement",
            "text": "Since the distribution of real OOS data is often arbitrary and diverse, we further propose a regional replacement strategy to construct diverse pseudoOOS data. This strategy constructs pseudo samples by replacing a random region of the feature of x1 with the corresponding region of the feature of x2:\nf rr = M \u2299 f(x1) + (1\u2212M)\u2299 f(x2) (3)\nwhere M is a binary mask vector that indicates the region of replacement. x1 and x2 are two training samples with different known relations. \u2299 is the element-wise multiplication.\nTo get the mask vector M , we first sample a random value \u03b2 from a uniform distribution U(0, 1). Then, we calculate the region length as: l = \u03b2 \u2217 d, where d is the dimensional size of features. Finally, we calculate the region coordinates:\nt \u223c U(1, d) rs = t \u2212 | l/2 |, re = t + | l/2 |\n(4)\nwhere t is a random integer between 1 and d. rs and re are the start and end coordinates of the selected region. In this region, the value of the mask vector is 0, otherwise it is 1. This strategy forms another new OOS training set: Dtrain,rr = \u22c3N i=1 f rr i ."
        },
        {
            "heading": "5.2.3 Irregular Replacement",
            "text": "Moreover, we design an irregular replacement. Different from regional replacement, irregular replacement randomly selects some discontinuous dimensions to replace, instead of a continuous region.\nTo obtain the mask vector M of this strategy, we first sample the random value \u03b2 and calculate the number of replaced dimensions as: l = \u03b2 \u2217 d. Then, we assign a coefficient \u03b3, which is randomly selected from the uniform distribution U(0, 1), for each dimension. Finally, we select the top l dimensions that get larger coefficients for replacement. In the mask vector, we set these selected dimensions to 0 and the others to 1. We use the mask vector to construct the pseudo-OOS data f ir and obtain a new training set: Dtrain,ir = \u22c3N i=1 f ir i ."
        },
        {
            "heading": "5.3 Optimization",
            "text": "In each training batch, we combine the original features with the synthetic OOS features as the training set, i.e., Dtrain = Dtrain,o \u222a Dtrain,cc \u222a Dtrain,rr \u222a Dtrain,ir. Thus, we can train a uniform (k+ 1)-class classifier without additional post-processing. In our method, we employ the softmax classifier and use the cross-entropy loss to optimize the model:\nLCE = \u2212 \u2211|Dtrain|\ni=1 log e\u03d5j(fi)/T\u2211|C| n=1 e\u03d5n(fi)/T\n(5)\nwhere \u03d5j(fi) denotes the output logit of the groundtruth class j of the feature fi. C is the entire (k+1)class relation set. T is the temperature scalar. In the testing phase, M3S is able to directly predict known relations while identifying the novel relation."
        },
        {
            "heading": "6 Experiments",
            "text": ""
        },
        {
            "heading": "6.1 Baselines",
            "text": "To provide a comprehensive comparison, we employ multiple OOS detection methods as baselines.\nMSP (Hendrycks and Gimpel, 2017) obtains the confidence score from the maximum softmax probability and treats samples that get lower scores as OOS data. DOC (Shu et al., 2017) uses multiple 1-vs-rest sigmoid classifiers to optimize the probability distribution. LMCL (Lin and Xu, 2019) utilizes a large margin cosine loss to learn discriminative features and detects outliers via the LOF algorithm. SEG (Yan et al., 2020) assumes that the features of known classes follow a Gaussian mixture distribution. It also uses LOF to detect outliers. SEG-SF (Yan et al., 2020) uses a softmax\nclassifier in the original SEG method. GDA (Xu et al., 2020) utilizes the Mahalanobis distance between each feature and the class prototype as the confidence score.\nMSP and GDA require a specific validation set that contains OOS data to adjust their thresholds. We provide such a validation set for MSP and GDA by integrating the validation data of OOS relations. Our method and other baselines only use the data of known relations for training and validation, which is a more realistic setting."
        },
        {
            "heading": "6.2 Experimental Settings",
            "text": "We use the HuggingFace\u2019s Transformer library2 to implement the BERT-based model. To ensure a fair comparison, all baselines employ the same BERT encoder. As suggested by Devlin et al. (2019), the learning rate is 1e-5. The temperature scalar T is 0.1. The batch sizes for FewRel and TACRED are 32 and 16. Each self-supervised strategy constructs a batch size pseudo-OOS samples. The hyper-parameters are obtained by a grid search on the validation set.\n2https://github.com/huggingface"
        },
        {
            "heading": "6.3 Evaluation Metrics",
            "text": "Following other OOS detection tasks (Yan et al., 2020; Zhang et al., 2021), we use the overall accuracy and the macro F1 score as evaluation metrics. In addition, we report the macro F1 scores of the known relations and the novel relation separately. For each OOS rate, we construct 5 different datasets and report the average results."
        },
        {
            "heading": "6.4 Main Results",
            "text": "The main results are shown in Table 2. From these results, we can see that:\n(1) Our method M3S significantly outperforms other baselines and achieves state-of-the-art performance on all datasets. For example, compared to GDA, our method achieves 2.38% and 6.56% improvements in terms of the F1 of the novel relation type on FewRel-NRE-20% and TACREDNRE-20% datasets, respectively. It verifies the effectiveness of our method on the NRE task.\n(2) Under each rate, there is a significant performance gap between the baselines and our method. The reason is that previous methods ignore the shallow semantic similarity problem in the NRE task, which makes them difficult to identify OOS data with similar surface information. Besides, we find\nthat, without additional OOS validation data, SEG tends to overfit known relations quickly, leading to performance degradation.\n(3) Although MSP and GDA achieve acceptable performance, they require additional OOS validation data to adjust their thresholds. Our method does not require such data and still outperforms MSP and GDA methods."
        },
        {
            "heading": "6.5 Ablation Study",
            "text": "To gain more insights into the multi-strategy selfsupervised learning, we conduct ablation studies by evaluating multiple variants of M3S. The results are shown in Table 3. To reduce the effect of the number of pseudo-OOS data, we keep the total number of pseudo-OOS data per batch for all variants the same as M3S.\nFrom the results, we can see that: Removing any self-supervised strategy, i.e., convex combination (CC), regional replacement (RR), or irregular replacement (IR), brings performance degradation. This proves the effectiveness of each selfsupervised strategy. We infer that these strategies can effectively construct diverse pseudo-OOS data to improve performance. When we remove the three strategies (- M3S), the performance drops significantly. This indicates that OOS detection is critical for RE models in real-world applications."
        },
        {
            "heading": "6.6 Effect of the Number of Pseudo-OOS Data",
            "text": "We further investigate the effect of varying the number of pseudo-OOS data. As shown in Figure 6, we increase the number of pseudo-OOS data constructed by each self-supervised strategy from 0 to 160. Note that 32 is the default value of our method on the FewRel-NRE dataset. From the results, we can see that:\n(1) As shown in Figure 6 (d), with the increase of synthetic OOS data, M3S achieves comparable\nperformance in terms of the F1 of the novel relation. This proves that our method is robust over a wide range of numbers. Our method is capable of constructing effective and precise pseudo-OOS data for the novel relation type.\n(2) For the other metrics, the performance first increases and then slightly drops as the number increases. We speculate that as the number increases, the constructed OOS data grows rapidly, which leads to a severe data imbalance between the novel relation and the known relations. The data imbalance problem makes the model significantly biased towards learning the synthetic OOS data, affecting the performance of known relations. In this paper, we leave this problem for future work.\n(3) Compared to the model without pseudo data, our method not only achieves improvements in the novel relation but also brings a positive effect on known relations. This is mainly due to the fact that our method is able to correctly assign the novel relation to OOS data rather than known relations, thus boosting the overall performance."
        },
        {
            "heading": "6.7 Efficiency",
            "text": "To demonstrate the efficiency of our method, we compare the average training time per epoch and the total test time of different methods. The results are shown in Figure 7. Even with pseudo-OOS samples, the training time of our method M3S is comparable to that of these baselines. The training time per epoch of our method is even lower than that of the SEG model. Importantly, the test time of our method is comparable to that of the MSP model and significantly lower than other baselines. This is due to the fact that our method does not require additional post-processing modules and it classifies all test data in a uniform manner."
        },
        {
            "heading": "7 Related Work",
            "text": ""
        },
        {
            "heading": "7.1 Relation Extraction",
            "text": "Recently, there are many research works on RE (Zelenko et al., 2002; Zeng et al., 2018; Li et al., 2019; Ye et al., 2022). Guo et al. (2019) propose attention-guided graph convolutional networks to select useful substructures from dependency trees for RE. Wang et al. (2021) use a unified label space to model the information between entities and relations. In addition, the few-shot RE task aims to train an RE model using a few samples (Han et al., 2018; Sainz et al., 2021). The continual RE task enables RE models to continually learn new labeled data (Wang et al., 2019; Cui et al., 2021).\nDespite the great progress in RE tasks, these existing methods usually ignore the discovery of novel relations, which limits their application in\nthe real world. Open RE extracts phrases and arguments as specific relations and discovers new relations by clustering or heuristics (Yao et al., 2011; Cui et al., 2018; Kolluru et al., 2022). However, it can not automatically discover novel relations that are not in the predefined relation set. Gao et al. (2019) focus on OOS detection in the few-shot RE task. Compared to these works, we formally propose a realistic and challenging task, i.e., OOS detection for the traditional RE task."
        },
        {
            "heading": "7.2 Out-of-Scope Detection",
            "text": "Out-of-scope detection is a long-standing research topic in machine learning, which enables models to identify OOS data as a new/open class (Hodge and Austin, 2004; Zimek et al., 2012; Lee et al., 2018; Zhang et al., 2021). Existing mainstream OOS detection methods can be roughly divided into two categories: probability-based methods (Hendrycks and Gimpel, 2017; Shu et al., 2017) and featurebased methods (Lin and Xu, 2019; Yan et al., 2020; Xu et al., 2020). Probability-based methods derive the confidence score from the probability distribution. Feature-based methods generally employ outlier detection methods, such as LOF (Breunig et al., 2000) or one-class SVM (Sch\u00f6lkopf et al., 2001), to detect OOS data. In addition, there are some research efforts that use synthetic or real OOS data to aid model training (Ryu et al., 2018; Lee et al., 2018; Hendrycks et al., 2019). Zhan et al. (2021) utilize a data augmentation method similar to Mixup (Zhang et al., 2018) to synthesize outliers. Inspired by Zhan et al. (2021) and other data augmentation methods (Yun et al., 2019; Harris et al., 2020), we propose multi-strategy self-supervised learning for the NRE task."
        },
        {
            "heading": "8 Conclusion",
            "text": "In this paper, we introduce OOS detection into relation detection, which can automatically discover the data with OOS relations while correctly classifying the data with known relations. To cope with shallow semantic similarity, we propose multistrategy self-supervised learning. We construct two datasets for the NRE task and compare our method with multiple strong baselines. The results demonstrate the effectiveness of our method.\nLimitations\nIn this paper, each self-supervised strategy constructs the same amount of pseudo-OOS data. In fact, different strategies bring different improvements as shown in Table 3. Therefore, in future work, we hope to find better ways to fuse these strategies."
        },
        {
            "heading": "Acknowledgements",
            "text": "This work was supported by the National Natural Science Foundation of China (Grant No.62306087) and the Natural Science Foundation of Shandong Province (Grant No.ZR2023QF154)."
        }
    ],
    "title": "Novel Relation Detection: Discovering Unknown Relation Types via Multi-Strategy Self-Supervised Learning",
    "year": 2023
}