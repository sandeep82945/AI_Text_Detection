{
    "abstractText": "Using a narrative style is an effective way to communicate health information both on and off social media. Given the amount of misinformation being spread online and its potential negative effects, it is crucial to investigate the interplay between narrative communication style and misinformative health content on user engagement on social media platforms. To explore this in the context of Twitter, we start with previously annotated health misinformation tweets (n \u2248 15, 000) and annotate a subset of the data (n = 3, 000) for the presence of narrative style. We then use these manually assigned labels to train text classifiers, experimenting with supervised fine-tuning and incontext learning for automatic narrative detection. We use our best model to label remaining portion of the dataset, then statistically analyze the relationship between narrative style, misinformation, and user-level features on engagement, finding that narrative use is connected to increased tweet engagement and can, in some cases, lead to increased engagement with misinformation. Finally, we analyze the general categories of language used in narratives and health misinformation in our dataset.",
    "authors": [
        {
            "affiliations": [],
            "name": "Achyutarama R. Ganti"
        },
        {
            "affiliations": [],
            "name": "Eslam Hussein"
        },
        {
            "affiliations": [],
            "name": "Steven R. Wilson"
        },
        {
            "affiliations": [],
            "name": "Zexin Ma"
        },
        {
            "affiliations": [],
            "name": "Xinyan Zhao"
        }
    ],
    "id": "SP:bdab685db81850f69ec21306cb5f2c687a5ae739",
    "references": [
        {
            "authors": [
                "H. Porter Abbott."
            ],
            "title": "The Cambridge Introduction to Narrative, 2 edition",
            "venue": "Cambridge Introductions to Literature. Cambridge University Press.",
            "year": 2008
        },
        {
            "authors": [
                "RM Adelson."
            ],
            "title": "Compound poisson distributions",
            "venue": "Journal of the Operational Research Society, 17(1):73\u201375.",
            "year": 1966
        },
        {
            "authors": [
                "Anietie Andy",
                "Brian Chu",
                "Ramie Fathy",
                "Barrington Bennett",
                "Daniel Stokes",
                "Sharath Chandra Guntuku."
            ],
            "title": "Understanding social support expressed in a COVID-19 online forum",
            "venue": "Proceedings of the 12th International Workshop on Health Text Mining and",
            "year": 2021
        },
        {
            "authors": [
                "Francesco Barbieri",
                "Jose Camacho-Collados",
                "Luis Espinosa-Anke",
                "Leonardo Neves."
            ],
            "title": "TweetEval:Unified Benchmark and Comparative Evaluation for Tweet Classification",
            "venue": "Proceedings of Findings of EMNLP.",
            "year": 2020
        },
        {
            "authors": [
                "Cornelia Betsch",
                "Corina Ulsh\u00f6fer",
                "Frank Renkewitz",
                "Tilmann Betsch."
            ],
            "title": "The influence of narrative v",
            "venue": "statistical information on perceiving vaccination risks. Medical decision making : an international journal of the Society for Medical Decision Making,",
            "year": 2011
        },
        {
            "authors": [
                "Ryan L Boyd",
                "Ashwini Ashokkumar",
                "Sarah Seraj",
                "James W Pennebaker."
            ],
            "title": "The development and psychometric properties of liwc-22",
            "venue": "Austin, TX: University of Texas at Austin.",
            "year": 2022
        },
        {
            "authors": [
                "Ryan L. Boyd",
                "Kate G. Blackburn",
                "James W. Pennebaker."
            ],
            "title": "The narrative arc: Revealing core narrative structures through text analysis",
            "venue": "Science Advances, 6(32):eaba2196.",
            "year": 2020
        },
        {
            "authors": [
                "Michael F. Dahlstrom."
            ],
            "title": "The narrative truth about scientific misinformation",
            "venue": "Proceedings of the National Academy of Sciences, 118(15):e1914085117.",
            "year": 2021
        },
        {
            "authors": [
                "Daria Dayter."
            ],
            "title": "Small stories and extended narratives on twitter",
            "venue": "Discourse, Context & Media, 10.",
            "year": 2015
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "AR Dirkson",
                "Suzan Verberne",
                "Wessel Kraaij",
                "AM Jorge",
                "R Campos",
                "A Jatowt",
                "S Bhatia."
            ],
            "title": "Narrative detection in online patient communities",
            "venue": "Proceedings of Text2Story\u2014Second Workshop on Narrative Extraction From Texts co-located with 41th European",
            "year": 2019
        },
        {
            "authors": [
                "Olive Jean Dunn."
            ],
            "title": "Multiple comparisons among means",
            "venue": "Journal of the American statistical association, 56(293):52\u201364.",
            "year": 1961
        },
        {
            "authors": [
                "Achyutarama Ganti",
                "Steven Wilson",
                "Zexin Ma",
                "Xinyan Zhao",
                "Rong Ma."
            ],
            "title": "Narrative detection and feature analysis in online health communities",
            "venue": "Proceedings of the 4th Workshop of Narrative Understanding (WNU2022), pages 57\u201365, Seattle, United",
            "year": 2022
        },
        {
            "authors": [
                "Jeanine P.D. Guidry",
                "Kellie Carlyle",
                "Marcus Messner",
                "Yan Jin."
            ],
            "title": "On pins and needles: How vaccines are portrayed on pinterest",
            "venue": "Vaccine, 33(39):5051\u20135056.",
            "year": 2015
        },
        {
            "authors": [
                "Kadhim Hayawi",
                "Sakib Shahriar",
                "Mohamed Adel Serhani",
                "Ikbal Taleb",
                "Sujith Samuel Mathew."
            ],
            "title": "Anti-vax: a novel twitter dataset for covid-19 vaccine misinformation detection",
            "venue": "Public health, 203:23\u201330.",
            "year": 2022
        },
        {
            "authors": [
                "Pengcheng He",
                "Jianfeng Gao",
                "Weizhu Chen"
            ],
            "title": "Debertav3: Improving deberta using electra-style pretraining with gradient-disentangled embedding sharing",
            "year": 2021
        },
        {
            "authors": [
                "Eva Janssen",
                "Liesbeth van Osch",
                "Hein de Vries",
                "Lilian Lechner."
            ],
            "title": "The influence of narrative risk communication on feelings of cancer risk",
            "venue": "British Journal of Health Psychology, 18(2):407\u2013419.",
            "year": 2013
        },
        {
            "authors": [
                "Matthew Kreuter",
                "Melanie Green",
                "Joseph Cappella",
                "Michael Slater",
                "Meg Wise",
                "Douglas Storey",
                "Eddie Clark",
                "Daniel O\u2019Keefe",
                "Deborah Erwin",
                "Kathleen Holmes",
                "Leslie Hinyard",
                "Thomas Houston",
                "Sabra Woolley"
            ],
            "title": "Narrative communication",
            "year": 2007
        },
        {
            "authors": [
                "Matthew W Kreuter",
                "Kathleen Holmes",
                "Kassandra Alcaraz",
                "Bindu Kalesan",
                "Suchitra Rath",
                "Melissa Richert",
                "Amy McQueen",
                "Nikki Caito",
                "Lou Robinson",
                "Eddie M Clark"
            ],
            "title": "Comparing narrative and informational videos to increase mammography",
            "year": 2010
        },
        {
            "authors": [
                "Jiyoung Lee",
                "Soo Yun Shin."
            ],
            "title": "Something that they never said: Multimodal disinformation and source vividness in understanding the power of aienabled deepfake news",
            "venue": "Media Psychology, pages 1\u201316.",
            "year": 2022
        },
        {
            "authors": [
                "Heidi Oi-Yee Li",
                "Adrian Bailey",
                "David Huynh",
                "James Chan"
            ],
            "title": "Youtube as a source of information on covid-19: a pandemic of misinformation",
            "venue": "BMJ Global Health,",
            "year": 2020
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Zexin Ma."
            ],
            "title": "The role of narrative pictorial warning labels in communicating alcohol-related cancer risks",
            "venue": "Health Communication, pages 1\u20139.",
            "year": 2021
        },
        {
            "authors": [
                "Zexin Ma",
                "Guolan Yang."
            ],
            "title": "Show me a photo of the character: Exploring the interaction between text and visuals in narrative persuasion",
            "venue": "Journal of Health Communication, 27(2):125\u2013133. PMID: 35422202.",
            "year": 2022
        },
        {
            "authors": [
                "H.B. Mann",
                "D.R. Whitney."
            ],
            "title": "On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other",
            "venue": "The Annals of Mathematical Statistics, 18(1):50 \u2013 60.",
            "year": 1947
        },
        {
            "authors": [
                "Willard G Manning",
                "John Mullahy"
            ],
            "title": "Estimating log models: to transform or not to transform",
            "venue": "Journal of health economics,",
            "year": 2001
        },
        {
            "authors": [
                "Elizabeth J. Marsh",
                "Brenda W. Yang."
            ],
            "title": "One believing things that are not true: A cognitive science perspective on misinformation",
            "venue": "Misinformation and Mass Audiences.",
            "year": 2018
        },
        {
            "authors": [
                "Shahan Ali Memon",
                "Kathleen M Carley."
            ],
            "title": "Characterizing covid-19 misinformation communities using a novel twitter dataset",
            "venue": "arXiv preprint arXiv:2008.00791.",
            "year": 2020
        },
        {
            "authors": [
                "Shahan Ali Memon",
                "Aman Tyagi",
                "David R. Mortensen",
                "Kathleen M. Carley."
            ],
            "title": "Characterizing sociolinguistic variation in the competing vaccination communities",
            "venue": "Social, Cultural, and Behavioral Modeling: 13th International Conference, SBP-",
            "year": 2020
        },
        {
            "authors": [
                "Sheila T. Murphy",
                "Lauren B. Frank",
                "Joyee S. Chatterjee",
                "Lourdes Baezconde-Garbanati."
            ],
            "title": "Narrative Versus Nonnarrative: The Role of Identification, Transportation, and Emotion in Reducing Health Disparities",
            "venue": "Journal of Communication, 63(1):116\u2013137.",
            "year": 2013
        },
        {
            "authors": [
                "John Ashworth Nelder",
                "Robert WM Wedderburn."
            ],
            "title": "Generalized linear models",
            "venue": "Journal of the Royal Statistical Society: Series A (General), 135(3):370\u2013384.",
            "year": 1972
        },
        {
            "authors": [
                "Rasmus Nielsen",
                "Richard Fletcher",
                "Nic Newman",
                "J Brennen",
                "Philip Howard."
            ],
            "title": "Navigating the \u2018infodemic\u2019: How people in six countries access and rate news and information about coronavirus",
            "venue": "Reuters Institute for the Study of Journalism.",
            "year": 2020
        },
        {
            "authors": [
                "Janine A. Overcash."
            ],
            "title": "Narrative research: a review of methodology and relevance to clinical practice",
            "venue": "Critical Reviews in Oncology/Hematology, 48(2):179\u2013184.",
            "year": 2003
        },
        {
            "authors": [
                "F. Pedregosa",
                "G. Varoquaux",
                "A. Gramfort",
                "V. Michel",
                "B. Thirion",
                "O. Grisel",
                "M. Blondel",
                "P. Prettenhofer",
                "R. Weiss",
                "V. Dubourg",
                "J. Vanderplas",
                "A. Passos",
                "D. Cournapeau",
                "M. Brucher",
                "M. Perrot",
                "E. Duchesnay"
            ],
            "title": "Scikit-learn: Machine learning",
            "year": 2011
        },
        {
            "authors": [
                "Wei Peng",
                "Sue Lim",
                "Jingbo Meng."
            ],
            "title": "Persuasive strategies in online health misinformation: a systematic review",
            "venue": "Information, Communication & Society, 0(0):1\u201318.",
            "year": 2022
        },
        {
            "authors": [
                "James W. Pennebaker."
            ],
            "title": "The secret life of pronouns",
            "venue": "New Scientist, 211(2828):42\u201345.",
            "year": 2011
        },
        {
            "authors": [
                "Victor Sanh",
                "Lysandre Debut",
                "Julien Chaumond",
                "Thomas Wolf."
            ],
            "title": "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter",
            "venue": "arXiv preprint arXiv:1910.01108.",
            "year": 2019
        },
        {
            "authors": [
                "Gautam Kishore Shahi",
                "Anne Dirkson",
                "Tim A. Majchrzak."
            ],
            "title": "An exploratory study of covid-19 misinformation on twitter",
            "venue": "Online Social Networks and Media, 22:100104.",
            "year": 2021
        },
        {
            "authors": [
                "Filipo Sharevski",
                "Raniem Alsaadi",
                "Peter Jachim",
                "Emma Pieroni."
            ],
            "title": "Misinformation warnings: Twitter\u2019s soft moderation effects on covid-19 vaccine belief echoes",
            "venue": "Computers & Security, 114:102577.",
            "year": 2022
        },
        {
            "authors": [
                "Brian G. Southwell",
                "J. Scott Babwah Brennen",
                "Ryan Paquin",
                "Vanessa Boudewyns",
                "Jing Zeng."
            ],
            "title": "Defining and measuring scientific misinformation",
            "venue": "The ANNALS of the American Academy of Political and Social Science, 700(1):98\u2013111.",
            "year": 2022
        },
        {
            "authors": [
                "William J Thompson."
            ],
            "title": "Poisson distributions",
            "venue": "Computing in Science & Engineering, 3(3):78\u201382.",
            "year": 2001
        },
        {
            "authors": [
                "Suzan Verberne",
                "Anika Batenburg",
                "Remco Sanders",
                "Mies van Eenbergen",
                "Enny Das",
                "Mattijs S Lambooij"
            ],
            "title": "Analyzing empowerment processes among cancer patients in an online community: A text mining approach",
            "venue": "JMIR cancer,",
            "year": 2019
        },
        {
            "authors": [
                "Emily K. Vraga",
                "Leticia Bode."
            ],
            "title": "Defining misinformation and understanding its bounded nature: Using expertise and evidence for describing misinformation",
            "venue": "Political Communication, 37(1):136\u2013144.",
            "year": 2020
        },
        {
            "authors": [
                "Teven Le Scao",
                "Sylvain Gugger",
                "Mariama Drame",
                "Quentin Lhoest",
                "Alexander M. Rush"
            ],
            "title": "Huggingface\u2019s transformers: State-of-the-art natural language processing",
            "year": 2019
        },
        {
            "authors": [
                "Xinyan Zhao",
                "Stephanie Tsang."
            ],
            "title": "How people process different types of misinformation on social media: A taxonomy based on falsity level and evidence type",
            "venue": "SSRN, pages 1\u201339.",
            "year": 2023
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "A narrative is a fundamental form of human communication. Although colloquially used interchangeably with \u201cstory\u201d, the formal concept of narrative is defined more broadly\u2014consisting of both story (connected events and characters) and narrative discourse (how the story is told) (Abbott, 2008). In other words, a narrative represents the presentation of a sequence of events experienced by a character or characters (Bilandzic and Busselle, 2012a; Dahlstrom, 2021). This study uses this definition to label and classify tweets into narrative and non-narrative based on whether or not they are written in a narrative style. An example\n\u2217*Equal contribution, listed in alphabetical order.\nnarrative tweet is, \u201cWe got our first dose of the vaccine! Can\u2019t tell you how excited and thankful we feel, and can\u2019t wait to get the next dose\u201d.\nConsidering the power of narrative information in influencing individuals\u2019 health-related beliefs, attitudes, and behaviors (Ma and Yang, 2022; Murphy et al., 2013), it is important to understand and address narrative misinformation on social media. In particular, research has found that online health misinformation is often created using narratives (Peng et al., 2022). Further, emerging research indicates that individuals are less likely to discern or verify misinformation when it is presented in a narrative (vs. non-narrative) format, possibly because narrative misinformation is perceived as more relatable and engaging (Zhao and Tsang, 2023). Therefore, it is crucial to classify misinformation as narrative and non-narrative and examine how this affects user engagement on social media.\nMisinformation is defined as false or misleading information that is contrary to the consensus of the scientific community based on the best available evidence at the time (Vraga and Bode, 2020). The prevalence and diffusion of incorrect information and fabricated narratives on social media have been a growing concern (Southwell et al., 2022). According to one study, 28% of the most viewed coronavirus videos included non-factual information, totaling 62 million views as of March 21, 2020 (Li et al., 2020). US-based respondents of another survey estimate that about 33% of social media content that they view contains some misinformation (Nielsen et al., 2020).\nHow individuals assess and act on misinformation can be affected by many factors, such as message features, source credibility, and individual motivations and emotions (Marsh and Yang, 2018). Existing research has shown that individuals are particularly susceptible to narrative misinformation that uses negative emotions such as anger or fear, incorrect personal stories, and made-up testimonials\n(Zhao and Tsang, 2023; Lee and Shin, 2022). Yet, most studies were conducted in a laboratory setting, limiting their ecological validity and generalizability. Further, prior studies have not quantitatively examined how social media misinformation in the narrative (vs. non-narrative) form affects user engagement at scale. Therefore, in this study, we use a large set of health tweets to investigate the presence of narrative misinformation and its impact on user engagement, and explore the features of both narratives and misinformation on Twitter.\nThe contributions1 of this work are (1) narrativity annotations for two existing misinformation datasets, which can be used to study the interaction between narrative and misinformation on Twitter; (2) experiments with several types of models for narrative detection, and the use of the best model to label all of the available data; and (3) analyses of the relationship between narrative style and user engagement in the presence of misinformation, as well as variations in the categories of language used in both narrative and non-narrative tweets. We find that tweets containing narratives typically had higher engagement, while the presence of misinformation was associated with less engagement. Especially in the context of vaccine-related content, using narratives was related to increased engagement with misinformation, even while controlling for number of followers. Additionally, through our analyses, we find supporting evidence for existing studies on the linguistic features of narratives even in the social media context."
        },
        {
            "heading": "2 Related Work",
            "text": "Prior work established the importance of narratives both on social media and in the context of sharing health-related information. On Twitter, specifically, Dayter (2015) analyzed multi-tweet stories to study the importance of storytelling for identity construction. In the health domain, Overcash (2003) emphasized the importance of narrative research in developing healthcare services for patients, while Andy et al. (2021) studied how users on online health communities show support for one another. Prior research suggests that narratives are more effective at communicating health risks than nonnarratives (Janssen et al., 2013; Ma, 2021) and promoting health behavior change (Kreuter et al., 2010). Guidry et al. (2015) found that anti-vaccine\n1Code and other resources related to this work available at: https://github.com/ou-nlp/NarrMisinfoEMNLP23\npins on pinterest used more narrative information while pro-vaccine used more statistical information, and that the latter type had higher levels of user engagement. Additionally, Betsch et al. (2011) studied the influence of narratives on the perception of vaccination risks, and highlighted the effectiveness of narrative communication in influencing human decision making about vaccine risk.\nIssues with the spread of misinformation on platforms like Twitter are also widely researched. For example, Sharevski et al. (2022) studied COVID19 misinformation on Twitter and the change in user perception of COVID-19 vaccine content as a result of soft moderation of misinformation content on the platform. The spread of misinformation on social media is not just limited to the common public: a study done by Shahi et al. (2021) reveals that verified Twitter handles(organizations/celebrities) are also responsible for creating and spreading misinformation. The authors also observed that fake claims propagate faster than semi-fake claims, and tweets containing misinformation often attempt to discredit other information on social media.\nWhile most studies of narratives have relied on manual annotations, Dirkson et al. (2019) and Verberne et al. (2019) used human-assigned labels to train text classification models to detect narrativity in social media posts in the health domain. Both studies focused on bag-of-words models with ngram features, while more recent research found that deep learning models were more successful than classical machine learning models at detecting narratives in Facebook posts (Ganti et al., 2022). These studies suggest that automatic narrative classification could enable the labeling of even larger social media datasets."
        },
        {
            "heading": "3 Data Collection and Annotation",
            "text": "We leveraged existing misinformation datasets and provided new annotations for the presence of narratives to create a single dataset that contained both sets of labels for each text: misinformation (or not) and narrative (or not)."
        },
        {
            "heading": "3.1 Data Collection",
            "text": "We selected two datasets: ANTiVax (Hayawi et al., 2022), and CMU-MisCov19 (Memon et al., 2020) based on three criteria: the quality of the annotation, relevance to the topic investigated, and the amount of data. Each dataset was annotated for medical misinformation by subject matter experts.\nTable 1 shows the number of tweets collected by the authors of each dataset and the number of hydrated tweets that were available at the time of our data collection (September 2022), which is the set of tweets used in this work. Most of the unavailable tweets fall under the misinformation category.\nThe ANTiVax dataset was collected to train machine learning algorithms to classify and detect COVID-19 vaccine misinformation. Authors used the Twitter API to collect tweets related to the COVID-19 vaccines using keywords (e.g., vaccine, Pfizer, Moderna). Tweets were annotated into misinformation (misinformed) tweets and general vaccine-related tweets (informed), and annotations were verified by medical experts.\nThe CMU-MisCov19 dataset was collected based on tweets of two groups: informed and misinformed users who wrote tweets related to COVID19. Authors used the Twitter API to collect tweets related to COVID-19 using keywords (e.g., coronavirus, covid). Tweets were annotated into five false information categories and five true information categories, which we merge into one misinformed and one informed category, respectively."
        },
        {
            "heading": "3.2 Annotation Process",
            "text": "Our annotation guidelines were developed iteratively through discussion and revision. During each of our four pilot annotation phases, three of the authors annotated between 20-100 randomly sampled tweets for narrative style. After each round of annotation, the annotators met together along with experts in narrative communication to discuss the annotated tweets, and updated the annotation guidelines from the previous round. After four rounds, all authors reached a consensus on the final annotation guidelines (appendix A).\nAfter finalizing the annotation guidelines, we sampled 3,000 tweets (20.6% of the 14,561 hydrated tweets in our dataset) stratified with respect to dataset and misinformation stance. Each tweet was initially independently annotated by two of the three annotators who developed the guidelines, with agreement measured using Krippendorff\u2019s al-\npha = 0.71. If the two annotators agreed, the agreed upon label was used, otherwise the third annotator stepped in to break the tie and the majority label was used in our final dataset."
        },
        {
            "heading": "4 Narrative Detection",
            "text": "Given the annotated tweets, we then set out to train classification models that could be used to label the entirety of the misinformation datasets that we collected."
        },
        {
            "heading": "4.1 Classification Methodology",
            "text": "The annotated data were shuffled and split 80-10- 10 for training, validation, and testing. We explore three categories of models: classical machine learning models with bag-of-words features, fine-tuned transformer encoder models, and auto-regressive generative models with in-context learning. All models are trained three times with different random seeds, and the average results are presented.\nThe bag-of-words-based machine learning models we used were scikit-learn\u2019s (Pedregosa et al., 2011) implementations of Naive Bayes, Support Vector Machine classification, and Logistic Regression. We conducted hyperparameter tuning as outlined in Appendix B.\nFor the transformer-based deep-learning models, we considered BERT (Devlin et al., 2019), DistilBERT (Sanh et al., 2019), RoBERTa (Liu et al., 2019), CardifNLP\u2019s TwitterRoBERTa (Barbieri et al., 2020) and DeBERTa (He et al., 2021) models available on HuggingFace Wolf et al. (2019) using bert-base-uncased, distilbert-base-uncased, roberta-base, cardiffnlp/twitter-roberta-base and microsoft/deberta-v3-base checkpoints, each with their default tokenizers and the output of the [CLS] input token as the input to a trainable classification layer. (training hyperparameters listed in Appendix B).\nFor the generative models, we used the gpt-3.5-turbo and GPT-3 (Brown et al., 2020) text-davinci-003 models from the OpenAI API 2. Both models take in an instruction or a prompt as the input and respond with completion to match our context or question. The goal of this experiment was to investigate if auto-regressive models such as GPT-3 and GPT-3.5-Turbo are capable of detecting the presence of narratives in tweets with little or no training data, which, if very successful,\n2https://openai.com/product\ncould reduce or avoid the entire manual annotation process that was required to obtain our initial set of narrative labels.\nThe experimental setup for the auto-regressive models consists of two main settings: zero-shot and few-shot. In the zero-shot setting, the model is shown the target tweet and asked \"Is this tweet a narrative?\", while in the few-shot setting, several example tweets with their correct labels are prepended to the prompt in a question-answer format, with the labeled examples being evenly distributed across the two datasets and narrativity labels, i.e., n narratives and n non-narratives from each dataset are used, leading to 4n total examples. We tune the value of n using the validation set and set n = 5 for our experiments. Within each setting (zero- or few-shot), we also experimented with the inclusion of the definitions of narratives and additional guidelines that the annotators developed and used during the annotation process. A summary of the components that can be included or removed from the prompt is outlined in Figure 1."
        },
        {
            "heading": "4.2 Experimental Results",
            "text": "Given that we explore eight configurations for the GPT models, we first use the validation set to select the best performing setup (Table 2). The F1 scores for both the GPT models across all the few-shot\nexperiments is reported in Appendix C. The GPT3 based text-davinci-003 model outperforms gpt-3.5-turbo in nearly all of the zero-shot and few-shot experiments. The best overall GPT model, based on text-davinci-003 used few-shot learning and included the narrative definitions and labeling guidelines in the prompt, and we evaluate this model on the test set (GPT-3 in Table 3).\nThe results for all models on the test set are presented in Table 3. Our findings align with those of Ganti et al. (2022), who found that transformer-based models consistently outperform bag-of-words models for narrative detection, with the fine-tuned base RoBERTa model performing best overall, outperforming even the version of RoBERTa pretrained specifically on Twitter data. The GPT-3 text-davinci-003 model achieved high precision but lacked in recall, resulting in an F1-score similar to the bag-of-words models, though it requires less than 1% of the amount of training data (in the form of examples for in-context learning). In the end, we use our top performing fine-tuned RoBERTa model to label our entire dataset, which we analyze in the next section."
        },
        {
            "heading": "5 Narrative and Misinformation",
            "text": "In this section, we investigate the effect of narrativity and misinformation on user engagement metrics and variations in linguistic features. First, we analyze the distribution of each category of tweets in the full set of \u223c 14.5k tweets labeled by our annotators and the best RoBERTa model from the previous section. Second, we discuss how the dimensions of narrativity and misinformation affect user engagement (i.e., counts of retweets and likes). Finally, we investigate how linguistic variations are significant between narratives and non-narratives and between informed and misinformed tweets."
        },
        {
            "heading": "5.1 Data Analysis",
            "text": "After applying the best model on the unlabeled portion of the dataset, we have the narrativity distribution in table 4. Where 46.4%, 13.7%, and 40.7% are narrative tweets of the ANTiVax, CMUMisCov19, and combined datasets, respectively.\nNarrativity. Although the ratio between informed and misinformed tweets in the ANTiVax, CMU-MisCov19 datasets are 2.07 and 2.24, respectively, we notice that narrativity is used more in informed than misinformed tweets, where informed narratives are 10.32, 3.51, and 9.39 times more common than misinformed narratives in the ANTiVax, CMU-MisCov19, and combined datasets, respectively. On the other hand, the non-narrative style is used more in misinformed tweets in ANTiVax and more in informed tweets in the CMUMisCov19 and combined datasets. We can see that narrativity is a more commonly used communication style among informed users to share their vaccination and COVID-19 experiences than misinformed users. We also observe that narrativity is less prevalent in the CMU-MisCov19 than the ANTiVax dataset, with narrative to non-narrative ratios of 0.27 and 1.14, respectively.\nMisinformation. Informed tweets are more prevalent in the ANTiVax and CMU-MisCov19 datasets by a ratio of 2.05 and 2.24, respectively, where narrative to non-narrative informed tweets\nhave ratios of 1.70 and 0.18 in each dataset, respectively, while the ratio of narrative to non-narrative misinformed tweets is 0.14 and 0.11 in each dataset, respectively.\nWe believe the discrepancies in percentages between both datasets can be attributed to the nature of each dataset, where ANTiVax was collected to study COVID-19\u2019s vaccine misinformation specifically, and CMU-MisCov19 was collected to study misinformation related to COVID-19 in general. Hence, ANTiVax may contain more vaccination experiences that were shared by users in a narrative style compared to CMU-MisCov19. Also, each dataset was annotated by different annotators and annotation methods."
        },
        {
            "heading": "5.2 Engagement with Narrative Tweets in the Presence of Misinformation",
            "text": "In this section, we investigate how narrativity and misinformation affect users\u2019 engagement (i.e., likes/favorites and retweets) with tweets. Our alternate hypothesis is that narrativity and misinformation are related to an increase or decrease in the count of likes (favorites) and retweets of a tweet. We control for the number of followers of a tweet\u2019s author since this might also affect the engagement with their tweets.\nFigure 2 depicts box plots of counts of favorites\n(likes) and retweets after removing outliers. Misinformed tweets receive significantly fewer likes than informed tweets, regardless of their narrativity, across both datasets. Narrative tweets typically received more favorites than their non-narrative counterparts within a given dataset and the absence or presence of misinformation. For the ANTiVax dataset, informed narrative tweets have the least number of retweets (zero) compared to the other three categories of tweets in that dataset. For the CMU-MisCov19 dataset, informed nonnarrative tweets have a higher number of retweets than the other groups, where both misinformed narrative and non-narrative tweets typically received no retweets.\nNext, we built statistical models of the relationships between narrativity, misinformation, follower count, and user engagement. Given that distributions of both likes and retweets follow a Poisson distribution with many tweets having a value of zero likes or retweets, and a heavy right skew for the other values, we utilize generalized linear models (GLM) (Nelder and Wedderburn, 1972) with a Poisson distribution (Adelson, 1966; Thompson, 2001) (as our dependent variables are counts) and the canonical log link function (Manning and Mullahy, 2001). We fit six GLM model on the variables: for each dataset (and for both combined), we fit one model with likes as the outcome variable and another with retweets as the outcome. The independent variables are the annotations for misinformation and narrativity, the count of followers, and the interactions between those three main variables.\nTable 5 shows the results of the GLMs, with\nthe set of coefficients for one model listed in each column. We normalized each of the numbers of followers, retweets, and favorites so that they are in the range [0-1]. Similar trends can generally be observed in the cases of favorites and retweets. Tweets that use misinformation had a lower engagement, and tweets with narrative had a higher engagement, but tweets that used narratives in the context of misinformation (narrative x misinfo) had higher engagement only in the ANTiVax dataset. This suggests that false narratives about receiving vaccinations got more engagement than narratives containing misinformation in a general set of COVID-19 tweets, which actually got less engagement. When considering follower count and its interaction with these variables, raw follower count does have a positive relationship with the number of likes or retweets that a tweet gets, and this effect is actually amplified if the tweet contains misinformation (misinfo x follower count) and even more so if the tweet uses narrative style (narrative x misinfo x follower count)."
        },
        {
            "heading": "5.3 The Language of Narratives and Misinformation",
            "text": "To study the linguistic variations between narrative and non-narrative tweets and between informed and misinformed tweets, we analyzed tweets from each pair of groups using the 2022 version of the Linguistic Inquiry and Word Count (LIWC) program (Boyd et al., 2022). LIWC is a text analysis tool that examines different lexical categories considered psychologically meaningful. It calculates the percentage of words from various lexical categories that are present in a given text. We ran the LIWC analysis on all tweets from the two datasets.\nWe use the nonparametric independent MannWhitney U test (Mann and Whitney, 1947) to establish statistical significance by determining the difference in means. The mean LIWC score for each category served as the test statistic. Since we perform an extensive set of statistical tests, we may find significant differences stemming from type I errors (i.e., false positives). Hence, we apply the Bonferroni correction method (Dunn, 1961) to avoid such errors by setting \u03b1 = 0.05/nt, where nt is the number of tests performed. Then we assume the significance of the difference between means if p-value < \u03b1 (i.e., accept H1 hypothesis).\nWe follow three approaches to examine the content of tweets that share narratives: based on as-\npects of our definition of narrative used in annotation, based on the analysis of Boyd et al. (2020) about how narrative is structurally and linguistically built, and we follow an approach that examines LIWC linguistic dimensions, slightly similar to the approach proposed by Memon and Carley (2020) which examines the linguistic dimensions between Twitter communities that share narratives about COVID-19."
        },
        {
            "heading": "5.3.1 Narrative Definition",
            "text": "Dahlstrom (2021) defines a narrative as a triad of character, causality, and temporality, where a character shares a set of related (i.e. causality) events and experiences over a period of time (i.e. temporality). Based on that definition, we utilize LIWC\u201922 categories that correspond to characters (pronoun), causality (cause), and temporality (Time). In table 6, Narrative tweets show significantly higher usage of pronouns and Time words than non-narrative tweets, which aligns with the definitions. We also note that family (e.g., parent, baby, son) and friend (e.g., dude, boyfriend) categories, indicative of characters, are used significantly more when in expressing narratives than non-narratives for both datasets. This aligns with\nPennebaker (2011); Boyd et al. (2020) and the definition of a narrative (Dahlstrom, 2021), where such categories are often used to represent characters. On the other hand, cause words show insignificant differences in most tests or a significantly fewer cause words in the ANTiVax dataset. We believe the discrepancy in causality results from the high amount of non-narrative information that explicitely uses causality-related language (\u201c5G causes COVID-19!\u201d), skewing the ratio of casual language away from the narrative class."
        },
        {
            "heading": "5.3.2 Narrative Arc",
            "text": "In LIWC\u201922 (Boyd et al., 2022), Narrative Arc analysis was introduced to understand and measure the text\u2019s narrativity (Boyd et al., 2020). The Arc of a narrative is defined as three stages: 1. Staging, where a storyteller uses more articles and prepositions to introduce their narrative. 2. Plot Progression, where staging declines and uses more words \u2013 pronouns, auxiliary verbs, conjunctions, and negations \u2013 which signal events and who is involved in those events and how events progress. 3. Cognitive Tension, where more Insight, Causation, Discrepancy, Tentative and Certitude words are used to describe psychological tension and conflict, where characters strife to achieve possible goals. While we found tweets to be too short to use the full narrative arc feature of LIWC\u201922, we examine the scores for several of the important categories found to be related to narratives.\nStaging. From table 6, we can see that the use of articles and prepositions significantly differs between narrative and non-narrative tweets for the whole dataset. Where narratives use fewer words of those categories than non-narratives. For CMUMisCov19, all tests show no significant differences between narrative and non-narratives. For the ANTiVax dataset, only the misinformed tweets show no significant differences in the use of articles and more use of prepositions.\nPlot Progression. Only pronouns show higher significant usage in narrative tweets. Contrary to pronouns, the other categories show insignificant differences in most tests or significance when fewer words are used in narrative than in non-narrative tweets, except for conjunctions.\nCognitive Tension. In LIWC\u201922, Cognition is a super category that sums the indices of all insight, causation, discrepancy, tentative, and certitude subcategories. From table 6, cognition is significantly lower in narrative than non-narrative tweets for the ANTiVax dataset, while it\u2019s insignificant for CMU-MisCov19.\nWe believe that the short length of tweets forced by the platform hinders Twitter users from using more words that would fall under the LIWC categories proposed by Boyd et al. (2020) which were intended to measure narrative arcs in longer stories. This also justifies the discrepancies between our results and those of Boyd et al. (2020), where they concluded those categories after analyzing a large set of corpora collected from long novels, film transcripts, short stories, etc., where the average word count ranges from a few hundred to tens of thousands of words."
        },
        {
            "heading": "5.3.3 Linguistic Dimensions of Narratives and Misinformation",
            "text": "Analytical and Authentic. The LIWC categories Analytic and Authentic are two summary variables that measure 1) logical and formal thinking and 2) perceived honesty and genuineness, respectively. We observe from table 6, that narratives have significantly lower analytic and higher authentic scores than non-narratives in both datasets. This also aligns with Boyd et al. (2022); Memon and Carley (2020). Additionally, we notice from table 7 that misinformed tweets are less honest and more analytical in both datasets than informed tweets.\nTones and Emotions. Tone measures how positive or negative a sentiment a piece of text has. LIWC, calculate two categories tone_pos and\ntone_neg, where the higher the score, the more positive or negative the tone is, respectively. Emotion measures how much a text has positive or negative emotions (e.g., anxiety, anger, sadness) that correspond to the LIWC categories emo_pos and emo_neg, respectively. According to table 6, narrative tweets significantly share more positive tones and emotions than non-narrative tweets in ANTiVax, while it\u2019s insignificant in almost all cases for CMU-MisCov19. While negative tones and emotions are more commonly shared among nonnarrative tweets. Table 7 shows that in ANTiVax dataset, misinformation was not as clearly related to tone, though in cases where significant results were found, positive tone and emotion were used less in tweets that contained misinformation. While for CMU-MisCov19, it is all insignificant.\nHealth and Death. The health LIWC category contains 715 words related to health, illness, wellness, and mental health (e.g., medic, patient, hospital, gym, ... etc). The death category has 109 words (e.g., dead, kill, ... etc). From table 6, we find that health words are overall significantly used more in narrative than non-narrative tweets, while death words are overall used more in nonnarrative tweets, and that might be attributed to having many tweets where news agencies sharing COVID-19-related deaths in a non-narrative formal style. Investigating how health and death are shared among informed and misinformed tweets, we find in table 7 that the CMU-MisCov19 dataset mainly shows insignificant differences in means. While for the ANTiVax dataset, misinformed tweets share fewer health words and many more death words than informed tweets, which shows that COVID-19 vaccine-related misinformation is often focused on death and negative side effects."
        },
        {
            "heading": "6 Thematic Analysis",
            "text": "In order to understand the prevalent themes within the discourse surrounding COVID-19 vaccinations on social media, we conducted a manual thematic analysis on a selected sample of 400 tweets, equally balanced across each of the following categories: narrative information, non-narrative information, narrative misinformation, and non-narrative misinformation (100 tweets from each category). We first examined the sampled tweets to uncover the recurring themes, and then labeled each tweet according to the predominant theme present. Table 8 presents the most common themes within each sub-\nset, along with their respective percentages within the subset. Appendix E presents detailed thematic analysis results with paraphrased examples.\nWe find that a majority of the informative narratives described people\u2019s experiences with getting the vaccine, or expressing excitement that a loved one was vaccinated. This focus on vaccinationrelated stories can be partially attributed to the larger size of the ANTiVax, which is specifically focused on vaccine-related information and misinformation, relative to the CMU-MisCov19 dataset, which is more generally about COVID-19. However, even across both datasets, we find that many users\u2019 stories centered around either vaccine experiences or experiences with COVID-19 itself, as these were some the main ways that everyday users were personally affected by the pandemic. Misinformative narratives typically centered around storylines that provided evidence for conspiracy theories or harmful side effects of the vaccine, and were less often written as first-person narratives. When users did talk about themselves in the misinformative narrative category, the stories described trying home remedies or hypothetical stories justifying why they would not get vaccinated.\nNon-narrative informative (i.e., those not labeled as misinformation or narrative) tweets contained a wide range of topics, from sharing news and public health tips to memes in the form \u201cIf X, don\u2019t worry about what\u2019s in the vaccine\u201d, where X is something commonly done yet potentially unhealthy, such as eating fast food. These tweets are meant to downplay concerns others may be expressing about getting vaccinated. Misinformative\nnon-narratives presented similar ideas to the misinformative narratives, but these were presented in the form of \u201cfacts\u201d about the dangers of vaccines or supporting conspiracy theories, rather than stories."
        },
        {
            "heading": "7 Conclusion",
            "text": "In this paper, we study the relationship between narrative communication and health misinformation on social media, specifically in the context of Twitter. We manually labeled a subset of tweets from misinformation datasets to add labels for narrative, and trained models to extend these labels to the entire datasets. Then, using statistical modeling, we find that narrativity is connected to higher user engagement and misinformation to less engagement, but narrativity may help increase engagement of misinformation in some contexts such as for users with many followers. This finding may have implications for better promoting accurate health information by presenting and amplifying narrative messages. In line with studies of other domains, narratives showed more authenticity, had more mentions of people, time and many more expressions of positive emotion, while misinformation was less authentic used more analytic language, and had dramatically more references to death. Many narratives focused on experiences of vaccines, illness, or home remedies, while nonnarratives focused more on news updates, public health information, and conspiracy theories. These findings shed light on how both the style and content of messages can relate to how users engage with then, suggesting that both are important when seeking to combat misinformation."
        },
        {
            "heading": "8 Limitations",
            "text": "As we used English-language data from Twitter during the COVID-19 pandemic, the language present in the dataset will be biased to this particular population and may limit the ability to extrapolate conclusions about narrativity and misinformation to other contexts. For example, given the universality of the pandemic, everyday users may have already been more invested in searching for and understanding health related information than they would have for other health issues. In the future, research should focus on other languages, platforms, and health contexts.\nFurther, the tweets were rehydrated based on their IDs, and some portion of the tweets were no longer available, disproportionately affecting the misinformation-related tweets (and potentially some of the higher-engagement misinformation tweets, since those may have been more likely to be debunked and subsequently deleted). In a less transparent way, Twitter\u2019s own content moderation policy also likely affected how much misinformation was shown to users, decreasing engagement, though we are unsure to what extent. Lastly, with recent changes to the Twitter (recently re-branded as \u201cX\u201d) it is unclear how available Twitter-based datasets will be in the future 3.\nThis paper uses the LIWC (Language Inquiry with Word Count) tool, which, though very popular, only uses surface-level analysis in the form of word count analysis and fails to provide an in-depth interpretation of the data. Despite participating in three rounds of training sessions, the annotators still encountered several disagreements among each other which were resolved through discussion. With additional training, it may be possible to achieve an even higher inter-coder agreement and more reliable annotations.\nAdditionally, the narrative labels used for the full dataset are based on the predictions of a deeplearning model with imperfect predictive power, and if errors are made in a systematic with respect to the relationship between narrative and misinformation, some of the later analyses could be slightly skewed by this. We illustrate the extent of some possible differences in Appendix D, showing that the overall conclusions are unlikely to change.\n3Those seeking to access the dataset for replication purposes are encouraged to reach out to the authors of the paper for a discussion of how data may or may not be shared based on the evolution of the current situation and best practices.\nEthics Statement\nIn this study, only pre-released Twitter datasets were used and collected via the official Twitter API using their IDs. Tweets that had been removed by their authors or by Twitter were not used in the study. All example tweets presented in the paper are paraphrased in order to preserve the anonymity of their original authors and in accordance, and data will only be shared as a list of tweet IDs with our own additional annotations. The annotators used in the study were all authors and all are employed in research-related positions which compensate them for their work. While it is possible that the findings in this paper could be leveraged in order to help spread misinformation through the effective use of narratives, we do not provide any causal connections between narrativity and engagement nor do we aim to provide specific recommendations about how to increase tweet engagement, and this work may also help to provide new lenses through which to study misinformation and its spread in order to better combat it."
        },
        {
            "heading": "A Annotation Guidelines",
            "text": "Below are the guidelines developed during the annotation process and agreed upon by the annotators. Note that these guidelines were specifically developed for annotating tweets and should not be directly used annotating other types of text as narrative before considering and adapting to other contexts and media. All examples provided are related to vaccines and/or COVID-19.\nA.1 Narrative definitions\nAccording to (Kreuter et al., 2007), a narrative is defined as a representation of connected events and characters that has an identifiable structure, is bounded in space and time, and contains implicit or explicit messages about the topic being addressed.\n(Bilandzic and Busselle, 2012b) say that a narrative refers to a presentation of an event(s) experienced by a specific character(s) in a setting.\nAnd according to (Dahlstrom, 2021), a narrative is defined as a message that describes the experience of specific characters across a series of related events over a defined time period\u2014a triumvirate of character, causality, and temporality. At its core, narrative is the telling of someone\u2019s experience about something.\nA.2 Rules\nBased on the definitions provided, the rules for labeling the tweets are as follows: the tweet must contain (1) at least one specific character (normally is a person) who experiences (2) a series of related events. You may assume that the presence of multiple events implies temporality and do not need to specifically check for temporality during annotation.\nA.2.1 Characters Character/characters need to refer to specific individuals. Characters can be the author of the text (1st person), but can also be someone else who is mentioned in the text (2nd or 3rd person).\nExamples: \u201cScientist\u201d, \u201cCDC\u201d, any mentions like \u201cthis journalist\u201d, \u201c14 people\u201d (where this refers to a specific set of individuals that you could hypothetically identify) etc., can be considered characters. \u201cPeople\u201d, \u201chumanity\u201d, \u201cthe world\u201d, etc. don\u2019t count as characters. \u2018You\u2019 or \u2018your\u2019 (and they) can also be used in a generic way that does not refer to a specific person and should therefore only be considered a character if it directly refers to someone specific such as \u201cJoe Biden, you should consider giving more free covid tests\u201d. \u201cWe\u201d and \u201cus\u201d can be a character because it includes the author. Mentions of a country or country\u2019s government in general (\u201cThe U.S.\u201d) are usually too vague to be considered a character, but identifiable individuals (\u201cThe United States Supreme Court\u201d) within the government could be characters.\nA.2.2 Events Emotions, thoughts, or other non-observable actions can be considered an event. Emojis and punctuation can indicate emotions. The characters involved don\u2019t necessarily need to take any actions, but should be involved in or experiencing the events somehow. Events can be fictional, false, or occurring in the future. They don\u2019t need to be actual things that have definitely happened.\nExamples: \u201cI am so happy that I got the covid vaccine\u201d can be a narrative because the person is\nhappy now and the vaccine is in the past, so there is temporality and causality. Only saying \u201cI got the vaccine\u201d is not a narrative for our study because it does not reflect a series of related events.\nA.2.3 Additional cases to consider Hypothetical situations using an if-then format, such as \u201cif I had been to Dr. Dennis as a child, then I would be naturally immune to covid\u201d are not narratives. It could be rewritten as \u201cI went to Dr. Dennis as a child, and now I have natural immunity to covid\u201d which conveys the same information, but in more of a narrative form. The narrative is not only about what information is being presented, but the style of communication being used (how it is presented). Quotes like \u201cCDC director said \u2018there are 1000 new covid cases\u2019\u201d is not a narrative if it is just mentioning that someone said a fact but there is no story. But if the CDC director says \u201cI have been sick for three days and the medicine didn\u2019t have any effect on me. . . \u201c this can be considered a narrative. Similarly, narratives within jokes/non-serious texts are still considered narratives. E.g., \u201cBill Gates is going to come to my house to get the tracker out of my arm from the covid vaccine.\u201d This is a narrative. Advice is not a narrative: \u201cYou should get your covid vaccine\u201d. News headlines can be narratives, but they are not always narratives. For example, \u201cVaccine Mass Sterilization Depopulation Agenda Revealed on Amazon \u2019Utopia\u2019 Show\u201d is not a narrative. In general, try not to overthink it and perform mental gymnastics to determine how a tweet might possibly meet the criteria. Ask yourself: does this tweet tell a story about someone\u2019s experience of something? If so, it is a narrative.\nA.3 Examples of difficult cases\nDuring pilot rounds of annotation, the following cases were difficult to come to an agreement about. After further discussion with communication research experts, the following decisions and rationales were made and provided as guidance for the final annotation process. Note that these were some of the most difficult-to-annotate (according to the annotators) edge cases, and are not representative of a majority of the dataset.\n1. New Jersey has launched a website to debunk rumors and hoaxes associated with the spread of the coronavirus, following a false text message of impending national lockdown that circulated widely across the U.S.\nLabel: Not a narrative\nReason: New Jersey [government] is not a character because it is too vague.\n2. CIA knew about #coronavirus #BioWeapons before Chinese health authorities #USNews #COVID19 was released by #DonaldTrump\nLabel: Narrative\nReason: There are two events that are connected: CIA knowing about bioweapons before Chinese health authorities, and Donald Trump releasing COVID-19.\n3. Me thinks so too! The gov can\u2019t say they have been poisoning us for years - imagine the uproar - it affects us all - eating synthetic foods for decades. Why does supermarket meat taste like Rubber? coronvirus smokescreen.. ..but then there is COVID-19 is that the bioweapon?\nLabel: Narrative\nReason: This tells someone\u2019s (the tweet author\u2019s) experience of something: the government poisoning food and supermarket meat tasting like rubber.\n4. Got my first vaccine dose today!\nLabel: Narrative\nReason: The ! at the end conveys an emotion that the author is experiencing after getting the vaccine.\n5. #vaccinated can I fly on #americanairlines after the second COVID-19 vaccine?\nLabel: Narrative\nReason: The author expresses that they got their second COVID-19 vaccine (#vaccinated) and is now wondering about the possibility of air travel.\n6. I have had my money on Oxford-AstraZeneca from day 1. So excited to hear this news!\nLabel: Narrative\nReason: The author has been hoping OxfordAstraZeneca would be successful and is now expressing excitement about the fact that they were.\n7. @RudyGiuliani Many of us have taken this drug for Malaria prevention but never while\nsuffering from COVID19. You are misleading the public with dangerous misinformation\nLabel: Narrative\nReason: This tweet author \u201cspeaks\u201d directly to Rudy Giuliani. The author is one of the \u201cmany of us\" who has taken the drug."
        },
        {
            "heading": "B Hyperparameter Tuning and Preprocessing",
            "text": "For SVM classification, we used a grid search over both kernel type (linear, polynomial, or RBF) and degree (1, 2, and 3), with a polynomial kernel and a degree of 1 giving the best results on the validation set. For logistic regression, we considered C = {1, 2, 3} and C = 2 led to the best results.\nFor the bag-of-words models, we also experimented with various pre-processing techniques, including lowercasing, lemmatization, removal of URLs, stop words, and hashtags. We used a combination of these techniques along with hyperparameter tuning that gave us the best performance on the validation set and used that model to predict the labels for the test set. The best results for all bag-of-words models were achieved when removing stopwords, URLs, and hashtag symbols (\u2019#\u2019) while keeping the text of the hashtag itself.\nFor the transformer-based deep learning models, we initialize each from the model checkpoint and fine-tune on our training data for 5 epochs with a batch size of 16, weight decay of 0.01, and a learning rate of 2e-5."
        },
        {
            "heading": "C Few-Shot Experiments",
            "text": "This section presents detailed results on the effect of the number of in-context examples that are provided to the GPT models for few-shot learning. In each case, we balance the number of narrative and non-narrative examples from each of the two source datasets, meaning that our number of training examples, k is always multiple of 4 to maintain this balance. From results on our development set, we find that the overall best results occur when k = 20, and therefore we select this value for the rest of our experiments in the paper. This means that we have n = 5 narratives from each dataset and n = 5 non-narratives from each of the two datasets. The results for the GPT-3 Davinci model are presented in Table 9, and the results for the GPT-3.5-Turbo model are presented in Table 10."
        },
        {
            "heading": "D LIWC analysis of manual-annotations versus machine-annotations",
            "text": "In this appendix, we computed the LIWC scores similar to both tables 6 and 7 for only the 3,000 tweets that were manually annotated. See tables 11 and 12. We found that there is no meaningful difference between the LIWC scores of the 3000 tweets annotated by the authors and all the 14561 tweets annotated by the best-performing model (RoBERTa). The means of differences of LIWC scores between human-annotated data and modelannotated data are 0.225 and 0.282 with standard deviation of 0.601 and 0.927 for all values in tables 6 and 11, and tables 7 and 12, respectively. These small differences reflect the strength of the best-performing RoBERTa model that achieved an F1-score of 0.924, and we did not identify any values that contradict the claims made in the paper. However, we did notice that fewer claims could be reliably made given the smaller size of the data when using only 3,000 versus 14,561 texts. The number of LIWC scores that were not statistically significant in human-annotated data only, but were statistically significant in the full human+modelannotated data, is 40 scores and 28 scores for tables 6 and 7 respectively. This can be attributed to the increased size of the dataset, making a larger number of the results statistically significant while still controlling for multiple comparisons."
        },
        {
            "heading": "E Thematic Analysis with Examples",
            "text": "In this section of the appendix, we present a breakdown of our thematic analysis results of COVID-19 tweets. Here each subset of the analysis is pre-\nsented individually with paraphrased examples, included to preserve the anonymity of the authors while still capturing the main types of messages that existed in each theme. Discussion of the themes was originally presented in Section 6.\nTable 13 shows the predominant themes occurring in the non-narrative misinformation subset. These are the tweets that were originally labeled as misinformation from the source datasets, and labeled as narratives through our methodology. The themes presented in this table predominantly re-\nvolve around various conspiracy theories and misinformation regarding COVID-19 and the vaccines. They touch upon unfounded claims such as the virus being a bioweapon, and concerns about the vaccine\u2019s safety and potential side effects.\nTable 14 describes themes from the nonnarrative information category, and predominantly captures the various facets of public sentiment and discourse regarding COVID-19 but in a nonnarrative style. The themes range from humorous takes and encouragement for vaccination to the\nactive debunking of conspiracy theories, and so on.\nTable 15 highlight various forms of misinformation and misconceptions surrounding COVID-19 and its vaccines which were presented using narrative style. They capture sentiments from deeply entrenched conspiracy theories and fears related to vaccine side effects. The nature of these themes present the challenge of battling misinformation in the era of the pandemic.\nFinally, in the themes presented in Table 16 revolve around personal experiences, emotions, and perspectives related to the COVID-19 vaccination process, which were presented in narrative style.\nThese themes capture sentiments ranging from gratitude and optimism after receiving the vaccine to challenges faced during the vaccine scheduling and concerns about side effects."
        }
    ],
    "title": "Narrative Style and the Spread of Health Misinformation on Twitter",
    "year": 2023
}