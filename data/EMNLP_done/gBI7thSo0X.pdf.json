{
    "abstractText": "With language technology increasingly affecting individuals\u2019 lives, many recent works have investigated the ethical aspects of NLP. Among other topics, researchers focused on the notion of morality, investigating, for example, which moral judgements language models make. However, there has been little to no discussion of the terminology and the theories underpinning those efforts and their implications. This lack is highly problematic, as it hides the works\u2019 underlying assumptions and hinders a thorough and targeted scientific debate of morality in NLP. In this work, we address this research gap by (a) providing an overview of some important ethical concepts stemming from philosophy and (b) systematically surveying the existing literature on moral NLP w.r.t. their philosophical foundation, terminology, and data basis. For instance, we analyse what ethical theory an approach is based on, how this decision is justified, and what implications it entails. Our findings surveying 92 papers show that, for instance, most papers neither provide a clear definition of the terms they use nor adhere to definitions from philosophy. Finally, (c) we give three recommendations for future research in the field. We hope our work will lead to a more informed, careful, and sound discussion of morality in language technology.",
    "authors": [
        {
            "affiliations": [],
            "name": "Karina Vida"
        },
        {
            "affiliations": [],
            "name": "Judith Simon"
        },
        {
            "affiliations": [],
            "name": "Anne Lauscher"
        }
    ],
    "id": "SP:22919a317a77e9af9e599258f42b047fed7c667c",
    "references": [
        {
            "authors": [
                "Larry Alexander",
                "Michael Moore."
            ],
            "title": "Deontological Ethics",
            "venue": "Edward N. Zalta, editor, The Stanford Encyclopedia of Philosophy, Winter 2021 edition. Metaphysics Research Lab, Stanford University.",
            "year": 2021
        },
        {
            "authors": [
                "Mark Alfano",
                "Andrew Higgins",
                "Jacob Levernier."
            ],
            "title": "Identifying virtues and values through obituary data-mining",
            "venue": "The Journal of Value Inquiry, 52:59\u2013",
            "year": 2018
        },
        {
            "authors": [
                "Areej Alhassan",
                "Jinkai Zhang",
                "Viktor Schlegel"
            ],
            "title": "am I the bad one\u2019? predicting the moral judgement of the crowd using pre\u2013trained language models",
            "venue": "In Proceedings of the Thirteenth Language Resources and Evaluation Conference,",
            "year": 2022
        },
        {
            "authors": [
                "Khaled M Alhawiti."
            ],
            "title": "Natural language processing and its use in education",
            "venue": "International Journal of Advanced Computer Science and Applications, 5(12).",
            "year": 2014
        },
        {
            "authors": [
                "Abdallah Khalaf Alsaad."
            ],
            "title": "Ethical judgment, subjective norms, and ethical consumption: The moderating role of moral certainty",
            "venue": "Journal of Retailing and Consumer Services, 59:102380.",
            "year": 2021
        },
        {
            "authors": [
                "Milad Alshomary",
                "Roxanne El Baff",
                "Timon Gurcke",
                "Henning Wachsmuth."
            ],
            "title": "The moral debater: A study on the computational generation of morally framed arguments",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational",
            "year": 2022
        },
        {
            "authors": [
                "Erkin Altuntas",
                "Peter A. Gloor",
                "Pascal Budner."
            ],
            "title": "Measuring ethical values with AI for better teamwork",
            "venue": "Future Internet, 14(5):133.",
            "year": 2022
        },
        {
            "authors": [
                "Prithviraj Ammanabrolu",
                "Liwei Jiang",
                "Maarten Sap",
                "Hannaneh Hajishirzi",
                "Yejin Choi."
            ],
            "title": "Aligning to social norms and values in interactive narratives",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computa-",
            "year": 2022
        },
        {
            "authors": [
                "M. Anderson",
                "S.L. Anderson",
                "C. Armen."
            ],
            "title": "An approach to computing ethics",
            "venue": "IEEE Intelligent Systems, 21(4):56\u201363.",
            "year": 2006
        },
        {
            "authors": [
                "Oscar Araque",
                "Lorenzo Gatti",
                "Kyriaki Kalimeri."
            ],
            "title": "Moralstrength: Exploiting a moral lexicon and embedding similarity for moral foundations prediction",
            "venue": "Knowledge-based systems, 191:105184.",
            "year": 2020
        },
        {
            "authors": [
                "Florentin Arsene"
            ],
            "title": "Evaluating catastrophic forgetting of state-of-the-art nlp models for predicting moral values",
            "year": 2021
        },
        {
            "authors": [
                "Amanda Askell",
                "Yuntao Bai",
                "Anna Chen",
                "Dawn Drain",
                "Deep Ganguli",
                "Tom Henighan",
                "Andy Jones",
                "Nicholas Joseph",
                "Ben Mann",
                "Nova DasSarma"
            ],
            "title": "A general language assistant as a laboratory",
            "year": 2021
        },
        {
            "authors": [
                "Luigi Asprino",
                "Luana Bulla",
                "Stefano De Giorgis",
                "Aldo Gangemi",
                "Ludovica Marinucci",
                "Misael Mongiovi."
            ],
            "title": "Uncovering values: Detecting latent moral content from natural language with explainable and non-trained methods",
            "venue": "Proceedings of Deep Learn-",
            "year": 2022
        },
        {
            "authors": [
                "Yejin Bang",
                "Nayeon Lee",
                "Tiezheng Yu",
                "Leila Khalatbari",
                "Yan Xu",
                "Dan Su",
                "Elham J. Barezi",
                "Andrea Madotto",
                "Hayden Kee",
                "Pascale Fung."
            ],
            "title": "Aisocrates: Towards answering ethical quandary questions",
            "venue": "ArXiv, abs/2205.05989.",
            "year": 2022
        },
        {
            "authors": [
                "Lisa Feldman Barrett",
                "Ralph Adolphs",
                "Stacy Marsella",
                "Aleix M. Martinez",
                "Seth D. Pollak."
            ],
            "title": "Emotional expressions reconsidered: Challenges to inferring emotion from human facial movements",
            "venue": "Psychological Science in the Public Interest, 20(1):1\u201368.",
            "year": 2019
        },
        {
            "authors": [
                "Nicholas Botzer",
                "Shawn Gu",
                "Tim Weninger."
            ],
            "title": "Analysis of moral judgment on reddit",
            "venue": "IEEE Transactions on Computational Social Systems.",
            "year": 2022
        },
        {
            "authors": [
                "Rachel Cohon."
            ],
            "title": "Hume\u2019s Moral Philosophy",
            "venue": "Edward N. Zalta, editor, The Stanford Encyclopedia of Philosophy, Fall 2018 edition. Metaphysics Research Lab, Stanford University.",
            "year": 2018
        },
        {
            "authors": [
                "Ionut Constantinescu"
            ],
            "title": "Evaluating interpretability of state-of-the-art nlp models for predicting moral values",
            "year": 2021
        },
        {
            "authors": [
                "David Copp",
                "editor"
            ],
            "title": "The Oxford Handbook of Ethical Theory",
            "year": 2007
        },
        {
            "authors": [
                "Daniel Dahlmeier."
            ],
            "title": "Learning the peculiar value of actions",
            "venue": "Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 63\u201368, Dublin, Ireland. Association for Computational Linguistics and Dublin City",
            "year": 2014
        },
        {
            "authors": [
                "Charles Darwin."
            ],
            "title": "The expression of the emotions in man and animals, 200 edition",
            "venue": "HarperPerennial, London, England.",
            "year": 1999
        },
        {
            "authors": [
                "Morteza Dehghani",
                "Emmett Tomai",
                "Kenneth D. Forbus",
                "Matthew Evans Klenk."
            ],
            "title": "An integrated reasoning approach to moral decision-making",
            "venue": "AAAI Conference on Artificial Intelligence.",
            "year": 2008
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "arXiv preprint arXiv:1810.04805.",
            "year": 2018
        },
        {
            "authors": [
                "Alin Dondera"
            ],
            "title": "Estimating the transferability of state-of-the-art models in predicting moral values",
            "year": 2021
        },
        {
            "authors": [
                "Julia Driver."
            ],
            "title": "Moral Theory",
            "venue": "Edward N. Zalta and Uri Nodelman, editors, The Stanford Encyclopedia of Philosophy, Fall 2022 edition. Metaphysics Research Lab, Stanford University.",
            "year": 2022
        },
        {
            "authors": [
                "Ion Stagkos Efstathiadis",
                "Guilherme Paulino-Passos",
                "Francesca Toni."
            ],
            "title": "Explainable patterns for distinction and prediction of moral judgement on reddit",
            "venue": "arXiv preprint arXiv:2201.11155.",
            "year": 2022
        },
        {
            "authors": [
                "Denis Emelin",
                "Ronan Le Bras",
                "Jena D. Hwang",
                "Maxwell Forbes",
                "Yejin Choi"
            ],
            "title": "Moral stories: Situated reasoning about norms, intents",
            "year": 2021
        },
        {
            "authors": [
                "Maxwell Forbes",
                "Jena D. Hwang",
                "Vered Shwartz",
                "Maarten Sap",
                "Yejin Choi."
            ],
            "title": "Social chemistry 101: Learning to reason about social and moral norms",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
            "year": 2020
        },
        {
            "authors": [
                "Kar\u00ebn Fort",
                "Alain Couillault."
            ],
            "title": "Yes, we care! results of the ethics and natural language processing surveys",
            "venue": "Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC\u201916), pages 1593\u20131600, Portoro\u017e, Slovenia.",
            "year": 2016
        },
        {
            "authors": [
                "Kathleen C. Fraser",
                "Svetlana Kiritchenko",
                "Esma Balkir."
            ],
            "title": "Does moral code have a moral code? probing delphi\u2019s moral philosophy",
            "venue": "Proceedings of the 2nd Workshop on Trustworthy Natural Language Processing (TrustNLP 2022), pages 26\u201342,",
            "year": 2022
        },
        {
            "authors": [
                "Justin Garten",
                "Reihane Boghrati",
                "Joe Hoover",
                "Kate M. Johnson",
                "Morteza Dehghani."
            ],
            "title": "Morality between the lines : Detecting moral sentiment in text",
            "venue": "Proceedings of IJCAI 2016 workshop on Computational Modeling of Attitudes.",
            "year": 2016
        },
        {
            "authors": [
                "Samuel Gehman",
                "Suchin Gururangan",
                "Maarten Sap",
                "Yejin Choi",
                "Noah A. Smith."
            ],
            "title": "RealToxicityPrompts: Evaluating neural toxic degeneration in language models",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages",
            "year": 2020
        },
        {
            "authors": [
                "Bernard Gert",
                "Joshua Gert."
            ],
            "title": "The Definition of Morality",
            "venue": "Edward N. Zalta, editor, The Stanford Encyclopedia of Philosophy, Fall 2020 edition. Metaphysics Research Lab, Stanford University.",
            "year": 2020
        },
        {
            "authors": [
                "Peter Gloor",
                "Andrea Fronzetti Colladon",
                "Francesca Grippa."
            ],
            "title": "Measuring ethical behavior with ai and natural language processing to assess business success",
            "venue": "Scientific Reports, 12(1):10228.",
            "year": 2022
        },
        {
            "authors": [
                "Jesse Graham",
                "Jonathan Haidt",
                "Sena Koleva",
                "Matt Motyl",
                "Ravi Iyer",
                "Sean P Wojcik",
                "Peter H Ditto."
            ],
            "title": "Moral foundations theory: The pragmatic validity of moral pluralism",
            "venue": "Advances in experimental social psychology, volume 47, pages 55\u2013130.",
            "year": 2013
        },
        {
            "authors": [
                "Jesse Graham",
                "Jonathan Haidt",
                "Matt Motyl",
                "Peter Meindl",
                "Carol Iskiwitch",
                "Marlon Mooijman."
            ],
            "title": "Moral foundations theory",
            "venue": "Atlas of moral psychology, 211.",
            "year": 2018
        },
        {
            "authors": [
                "Yuling Gu",
                "Bhavana Dalvi",
                "Peter Clark."
            ],
            "title": "DREAM: Improving situational QA by first elaborating the situation",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human",
            "year": 2022
        },
        {
            "authors": [
                "Jian Guan",
                "Ziqi Liu",
                "Minlie Huang."
            ],
            "title": "A corpus for understanding and generating moral stories",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,",
            "year": 2022
        },
        {
            "authors": [
                "Christian Haerpfer",
                "Ronald Inglehart",
                "Alejandro Moreno",
                "Christian Welzel",
                "Kseniya Kizilova",
                "Jaime Diez-Medrano",
                "Marta Lagos",
                "Pippa Norris",
                "Eduard Ponarin",
                "Bi Puranen"
            ],
            "title": "World values survey: round seven\u2013country-pooled datafile",
            "year": 2020
        },
        {
            "authors": [
                "Thilo Hagendorff",
                "David Danks."
            ],
            "title": "Ethical and methodological challenges in building morally informed AI systems",
            "venue": "AI and Ethics.",
            "year": 2022
        },
        {
            "authors": [
                "Katharina H\u00e4mmerl",
                "Bj\u00f6rn Deiseroth",
                "Patrick Schramowski",
                "Jind\u0159ich Libovick\u1ef3",
                "Alexander Fraser",
                "Kristian Kersting"
            ],
            "title": "2022a. Do multilingual language models capture differing moral norms? arXiv preprint arXiv:2203.09904",
            "year": 2022
        },
        {
            "authors": [
                "Katharina H\u00e4mmerl",
                "Bj\u00f6rn Deiseroth",
                "Patrick Schramowski",
                "Jind\u0159ich Libovick\u1ef3",
                "Constantin A Rothkopf",
                "Alexander Fraser",
                "Kristian Kersting."
            ],
            "title": "Speaking multiple languages affects the moral bias of language models",
            "venue": "arXiv preprint",
            "year": 2022
        },
        {
            "authors": [
                "Dan Hendrycks",
                "Collin Burns",
                "Steven Basart",
                "Andrew Critch",
                "Jerry Li",
                "Dawn Song",
                "Jacob Steinhardt."
            ],
            "title": "Aligning ai with shared human values",
            "venue": "arXiv preprint arXiv:2008.02275.",
            "year": 2020
        },
        {
            "authors": [
                "Dan Hendrycks",
                "Mantas Mazeika",
                "Andy Zou",
                "Sahil Patel",
                "Christine Zhu",
                "Jesus Navarro",
                "Dawn Song",
                "Bo Li",
                "Jacob Steinhardt."
            ],
            "title": "What would jiminy cricket do? towards agents that behave morally",
            "venue": "arXiv preprint arXiv:2110.13136.",
            "year": 2021
        },
        {
            "authors": [
                "Marius Hessenthaler",
                "Emma Strubell",
                "Dirk Hovy",
                "Anne Lauscher."
            ],
            "title": "Bridging fairness and environmental sustainability in natural language processing",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages",
            "year": 2022
        },
        {
            "authors": [
                "Christina Park",
                "Tingyee E. Chang",
                "Jenna Chin",
                "Christian Leong",
                "Jun Yen Leung",
                "Arineh Mirinjian",
                "Morteza Dehghani."
            ],
            "title": "Moral foundations twitter corpus: A collection of 35k tweets annotated for moral sentiment",
            "venue": "Social Psychological and Personal-",
            "year": 2019
        },
        {
            "authors": [
                "Frederic R. Hopp",
                "Jacob T. Fisher",
                "Devin Cornell",
                "Richard Huskey",
                "Ren\u00e9 Weber."
            ],
            "title": "The extended moral foundations dictionary (eMFD): Development and applications of a crowd-sourced approach to extracting moral intuitions from text",
            "venue": "Be-",
            "year": 2020
        },
        {
            "authors": [
                "Dirk Hovy",
                "Shannon L. Spruit."
            ],
            "title": "The social impact of natural language processing",
            "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 591\u2013598, Berlin, Germany. Association",
            "year": 2016
        },
        {
            "authors": [
                "Daniel Devatman Hromada."
            ],
            "title": "Narrative fostering of morality in artificial agents: Constructivism, machine learning and story-telling",
            "venue": "L\u2019esprit au-del\u00e0 du droit.",
            "year": 2015
        },
        {
            "authors": [
                "Xiaolei Huang",
                "Alexandra Wormley",
                "Adam Cohen."
            ],
            "title": "Learning to adapt domain shifts of moral values via instance weighting",
            "venue": "Proceedings of the 33rd ACM Conference on Hypertext and Social Media. ACM.",
            "year": 2022
        },
        {
            "authors": [
                "Jonathan Kobbe",
                "Heiner Stuckenschmidt",
                "Graeme Hirst"
            ],
            "title": "Knowledge graphs meet moral values",
            "venue": "In Proceedings of the Ninth Joint Conference on Lexical and Computational Semantics,",
            "year": 2020
        },
        {
            "authors": [
                "Rosalind Hursthouse",
                "Glen Pettigrove."
            ],
            "title": "Virtue Ethics",
            "venue": "Edward N. Zalta and Uri Nodelman, editors, The Stanford Encyclopedia of Philosophy, Winter 2022 edition. Metaphysics Research Lab, Stanford University.",
            "year": 2022
        },
        {
            "authors": [
                "William James"
            ],
            "title": "What is emotion? 1884",
            "year": 1948
        },
        {
            "authors": [
                "Sophie Jentzsch",
                "Patrick Schramowski",
                "Constantin Rothkopf",
                "Kristian Kersting."
            ],
            "title": "Semantics derived automatically from language corpora contain human-like moral choices",
            "venue": "Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and So-",
            "year": 2019
        },
        {
            "authors": [
                "Shaoxiong Ji",
                "Tianlin Zhang",
                "Luna Ansari",
                "Jie Fu",
                "Prayag Tiwari",
                "Erik Cambria."
            ],
            "title": "MentalBERT: Publicly available pretrained language models for mental healthcare",
            "venue": "Proceedings of the Thirteenth Language Resources and Evaluation Confer-",
            "year": 2022
        },
        {
            "authors": [
                "Liwei Jiang",
                "Jena D. Hwang",
                "Chandra Bhagavatula",
                "Ronan Le Bras",
                "Jenny Liang",
                "Jesse Dodge",
                "Keisuke Sakaguchi",
                "Maxwell Forbes",
                "Jon Borchardt",
                "Saadia Gabriel",
                "Yulia Tsvetkov",
                "Oren Etzioni",
                "Maarten Sap",
                "Regina Rini",
                "Yejin Choi"
            ],
            "title": "2021b. Can machines",
            "year": 2021
        },
        {
            "authors": [
                "Zhijing Jin",
                "Sydney Levine",
                "Fernando Gonzalez",
                "Ojasv Kamal",
                "Maarten Sap",
                "Mrinmaya Sachan",
                "Rada Mihalcea",
                "Joshua B. Tenenbaum",
                "Bernhard Sch\u00f6lkopf."
            ],
            "title": "When to make exceptions: Exploring language models as accounts of human moral judgment",
            "venue": "ArXiv,",
            "year": 2022
        },
        {
            "authors": [
                "Kristen Johnson",
                "Dan Goldwasser."
            ],
            "title": "Classification of moral foundations in microblog political discourse",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 720\u2013730, Melbourne,",
            "year": 2018
        },
        {
            "authors": [
                "Kristen Johnson",
                "Dan Goldwasser."
            ],
            "title": "Modeling behavioral aspects of social media discourse for moral classification",
            "venue": "Proceedings of the Third Workshop on Natural Language Processing and Computational Social Science, pages 100\u2013109, Minneapo-",
            "year": 2019
        },
        {
            "authors": [
                "Pratik Joshi",
                "Sebastin Santy",
                "Amar Budhiraja",
                "Kalika Bali",
                "Monojit Choudhury."
            ],
            "title": "The state and fate of linguistic diversity and inclusion in the NLP world",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages",
            "year": 2020
        },
        {
            "authors": [
                "Pawel Kamocki",
                "Andreas Witt."
            ],
            "title": "Ethical issues in language resources and language technology \u2013 tentative categorisation",
            "venue": "Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 559\u2013563, Marseille, France. European",
            "year": 2022
        },
        {
            "authors": [
                "Rishemjit Kaur",
                "Kazutoshi Sasahara."
            ],
            "title": "Quantifying moral foundations from various topics on twitter conversations",
            "venue": "2016 IEEE International Conference on Big Data (Big Data), pages 2505\u20132512.",
            "year": 2016
        },
        {
            "authors": [
                "Brendan Kennedy",
                "Mohammad Atari",
                "Aida Mostafazadeh Davani",
                "Joe Hoover",
                "Ali Omrani",
                "Jesse Graham",
                "Morteza Dehghani."
            ],
            "title": "Moral concerns are differentially observable in language",
            "venue": "Cognition, 212:104696.",
            "year": 2021
        },
        {
            "authors": [
                "Johannes Kiesel",
                "Milad Alshomary",
                "Nicolas Handke",
                "Xiaoni Cai",
                "Henning Wachsmuth",
                "Benno Stein."
            ],
            "title": "Identifying the human values behind arguments",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Vol-",
            "year": 2022
        },
        {
            "authors": [
                "Wonchul Kim",
                "Keeheon Lee."
            ],
            "title": "Building ethical ai from news articles",
            "venue": "2020 IEEE / ITU International Conference on Artificial Intelligence for Good (AI4G), pages 210\u2013217.",
            "year": 2020
        },
        {
            "authors": [
                "Heiner Stuckenschmidt"
            ],
            "title": "Exploring morality in argumentation",
            "venue": "In Proceedings of the 7th Workshop on Argument Mining, pages 30\u201340,",
            "year": 2020
        },
        {
            "authors": [
                "Radoslaw Komuda",
                "Rafal Rzepka",
                "Kenji Araki."
            ],
            "title": "Aristotelian approach and shallow search settings for fast ethical judgment",
            "venue": "International Journal of Computational Linguistics Research, 4(1):14\u201322.",
            "year": 2013
        },
        {
            "authors": [
                "Klaus Krippendorff"
            ],
            "title": "Computing krippendorff\u2019s alpha-reliability",
            "year": 2011
        },
        {
            "authors": [
                "Alex Gwo Jen Lan",
                "Ivandr\u00e9 Paraboni."
            ],
            "title": "Textand author-dependent moral foundations classification",
            "venue": "New Review of Hypermedia and Multimedia, 28(1-2):18\u201338.",
            "year": 2022
        },
        {
            "authors": [
                "J. Richard Landis",
                "Gary G. Koch."
            ],
            "title": "The measurement of observer agreement for categorical data",
            "venue": "Biometrics, 33(1):159.",
            "year": 1977
        },
        {
            "authors": [
                "Anne Lauscher",
                "Archie Crowley",
                "Dirk Hovy."
            ],
            "title": "Welcome to the modern world of pronouns: Identityinclusive natural language processing beyond gender",
            "venue": "Proceedings of the 29th International Conference on Computational Linguistics, pages 1221\u2013",
            "year": 2022
        },
        {
            "authors": [
                "Anne Lauscher",
                "Henning Wachsmuth",
                "Iryna Gurevych",
                "Goran Glava\u0161."
            ],
            "title": "Scientia Potentia Est\u2014On the Role of Knowledge in Computational Argumentation",
            "venue": "Transactions of the Association for Computational Linguistics, 10:1392\u20131422.",
            "year": 2022
        },
        {
            "authors": [
                "Jochen L. Leidner",
                "Vassilis Plachouras."
            ],
            "title": "Ethical by design: Ethics best practices for natural language processing",
            "venue": "Proceedings of the First ACL Workshop on Ethics in Natural Language Processing, pages 30\u201340, Valencia, Spain. Association for",
            "year": 2017
        },
        {
            "authors": [
                "Stephanie Lin",
                "Jacob Hilton",
                "Owain Evans."
            ],
            "title": "Truthfulqa: Measuring how models mimic human falsehoods",
            "venue": "arXiv preprint arXiv:2109.07958.",
            "year": 2021
        },
        {
            "authors": [
                "Ying Lin",
                "Joe Hoover",
                "Gwenyth Portillo-Wightman",
                "Christina Park",
                "Morteza Dehghani",
                "Heng Ji."
            ],
            "title": "Acquiring background knowledge to improve moral value prediction",
            "venue": "2018 IEEE/ACM International Conference on Advances in Social Networks Analysis",
            "year": 2018
        },
        {
            "authors": [
                "Enrico Liscio",
                "Alin Dondera",
                "Andrei Geadau",
                "Catholijn Jonker",
                "Pradeep Murukannaiah."
            ],
            "title": "Crossdomain classification of moral values",
            "venue": "Findings of the Association for Computational Linguistics: NAACL 2022, pages 2727\u20132745, Seattle, United",
            "year": 2022
        },
        {
            "authors": [
                "Ruibo Liu",
                "Ge Zhang",
                "Xinyu Feng",
                "Soroush Vosoughi."
            ],
            "title": "Aligning generative language models with human values",
            "venue": "Findings of the Association for Computational Linguistics: NAACL 2022, pages 241\u2013252, Seattle, United States. Association",
            "year": 2022
        },
        {
            "authors": [
                "Nicholas Lourie",
                "Ronan Le Bras",
                "Yejin Choi."
            ],
            "title": "SCRUPLES: A corpus of community ethical judgments on 32, 000 real-life anecdotes",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, 35(15):13470\u201313479.",
            "year": 2021
        },
        {
            "authors": [
                "Tushar Maheshwari",
                "Aishwarya N. Reganti",
                "Samiksha Gupta",
                "Anupam Jamatia",
                "Upendra Kumar",
                "Bj\u00f6rn Gamb\u00e4ck",
                "Amitava Das."
            ],
            "title": "A societal sentiment analysis: Predicting the values and ethics of individuals by analysing social media content",
            "venue": "In",
            "year": 2017
        },
        {
            "authors": [
                "Nischal Mainali",
                "Liam Meier",
                "Elliott Ash",
                "Daniel L. Chen."
            ],
            "title": "Automated classification of modes of moral reasoning in judicial decisions",
            "venue": "Computational Legal Studies. Edward Elgar Publishing.",
            "year": 2020
        },
        {
            "authors": [
                "Stacy Marsella",
                "Jonathan Gratch",
                "Paolo Petta"
            ],
            "title": "Computational models of emotion. A Blueprint for Affective Computing-A sourcebook and manual, 11(1):21\u201346",
            "year": 2010
        },
        {
            "authors": [
                "Akiko Matsuo",
                "Kazutoshi Sasahara",
                "Yasuhiro Taguchi",
                "Minoru Karasawa."
            ],
            "title": "Development and validation of the japanese moral foundations dictionary",
            "venue": "PLOS ONE, 14(3):e0213343.",
            "year": 2019
        },
        {
            "authors": [
                "Tuan Le Mau",
                "Katie Hoemann",
                "Sam H. Lyons",
                "Jennifer M.B. Fugate",
                "Emery N. Brown",
                "Maria Gendron",
                "Lisa Feldman Barrett."
            ],
            "title": "Professional actors demonstrate variability, not stereotypical expressions, when portraying emotional states in photographs",
            "venue": "Na-",
            "year": 2021
        },
        {
            "authors": [
                "Barbara A Mellers",
                "Alan Schwartz",
                "Katty Ho",
                "Ilana Ritov."
            ],
            "title": "Decision affect theory: Emotional reactions to the outcomes of risky options",
            "venue": "Psychological Science, 8(6):423\u2013429.",
            "year": 1997
        },
        {
            "authors": [
                "Negar Mokhberian",
                "Andr\u00e9s Abeliuk",
                "Patrick Cummings",
                "Kristina Lerman."
            ],
            "title": "Moral framing and ideological bias of news",
            "venue": "Social Informatics: 12th International Conference, SocInfo 2020, Pisa, Italy, October 6\u20139, 2020, Proceedings 12, pages 206\u2013219.",
            "year": 2020
        },
        {
            "authors": [
                "Marlon Mooijman",
                "Joe Hoover",
                "Ying Lin",
                "Heng Ji",
                "Morteza Dehghani."
            ],
            "title": "Moralization in social networks and the emergence of violence during protests",
            "venue": "Nature Human Behaviour, 2(6):389\u2013396.",
            "year": 2018
        },
        {
            "authors": [
                "Ece \u00c7i\u011fdem Mutlu",
                "Toktam Oghaz",
                "Ege T\u00fct\u00fcnc\u00fcler",
                "Ivan Garibay."
            ],
            "title": "Do bots have moral judgement? the difference between bots and humans in moral rhetoric",
            "venue": "2020 IEEE/ACM International Conference on Advances in Social Networks Analysis and",
            "year": 2020
        },
        {
            "authors": [
                "Pegah Nokhiz",
                "Fengjun Li."
            ],
            "title": "Understanding rating behavior based on moral foundations: The case of yelp reviews",
            "venue": "2017 IEEE International Conference on Big Data (Big Data), pages 3938\u2013 3945.",
            "year": 2017
        },
        {
            "authors": [
                "Peter Francis North",
                "Carl Vogel"
            ],
            "title": "A comprehensive review of ethical frameworks in natural language processing",
            "year": 2019
        },
        {
            "authors": [
                "Naoki Otani",
                "Eduard Hovy."
            ],
            "title": "Toward comprehensive understanding of a sentiment based on human motives",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4672\u20134677, Florence, Italy. Association for",
            "year": 2019
        },
        {
            "authors": [
                "Carla Parra Escart\u00edn",
                "Wessel Reijers",
                "Teresa Lynn",
                "Joss Moorkens",
                "Andy Way",
                "Chao-Hong Liu."
            ],
            "title": "Ethical considerations in NLP shared tasks",
            "venue": "Proceedings of the First ACL Workshop on Ethics in Natural Language Processing, pages 66\u201373, Valencia,",
            "year": 2017
        },
        {
            "authors": [
                "Matheus Camasmie Pavan",
                "Vitor Garcia dos Santos",
                "Alex Gwo Jen Lan",
                "Jo\u00e3o Trevisan Martins",
                "Wesley Ramos dos Santos",
                "Caio Deutsch",
                "Pablo Botton da Costa",
                "Fernando Chiu Hsieh",
                "Ivandr\u00e9 Paraboni"
            ],
            "title": "Morality classification in natural",
            "year": 2023
        },
        {
            "authors": [
                "Matheus Camasmie Pavan",
                "Wesley Ramos dos Santos",
                "Ivandr\u00e9 Paraboni."
            ],
            "title": "Twitter moral stance classification using long short-term memory networks",
            "venue": "Intelligent Systems, pages 636\u2013647. Springer International Publishing.",
            "year": 2020
        },
        {
            "authors": [
                "Yan Peng",
                "Penghe Chen",
                "Yu Lu",
                "Qinggang Meng",
                "Qi Xu",
                "Shengquan Yu."
            ],
            "title": "A task-oriented dialogue system for moral education",
            "venue": "International Conference on Artificial Intelligence in Education.",
            "year": 2019
        },
        {
            "authors": [
                "Henry Penikas",
                "E.A. Fedorova",
                "A.R. Nevredinov",
                "S.M. Druchok."
            ],
            "title": "Textual analysis of moral components in islamic and non-islamic business in russia",
            "venue": "2021 International Conference on Sustainable Islamic Business and Finance, pages 140\u2013143.",
            "year": 2021
        },
        {
            "authors": [
                "Rosalind W. Picard."
            ],
            "title": "Affective computing",
            "venue": "MIT press.",
            "year": 2000
        },
        {
            "authors": [
                "Nicholas Proferes",
                "Naiyan Jones",
                "Sarah Gilbert",
                "Casey Fiesler",
                "Michael Zimmer."
            ],
            "title": "Studying reddit: A systematic overview of disciplines, approaches, methods, and ethics",
            "venue": "Social Media+ Society, 7(2):20563051211019004.",
            "year": 2021
        },
        {
            "authors": [
                "Ming Qian",
                "Jaye Laguardia",
                "Davis Qian."
            ],
            "title": "Morality beyond the lines: Detecting moral sentiment using AI-generated synthetic context",
            "venue": "Artificial Intelligence in HCI, pages 84\u201394. Springer International Publishing.",
            "year": 2021
        },
        {
            "authors": [
                "Aida Ramezani",
                "Zining Zhu",
                "Frank Rudzicz",
                "Yang Xu."
            ],
            "title": "An unsupervised framework for tracing textual sources of moral change",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, pages 1215\u20131228, Punta Cana, Dominican Re-",
            "year": 2021
        },
        {
            "authors": [
                "Hannah Rashkin",
                "Antoine Bosselut",
                "Maarten Sap",
                "Kevin Knight",
                "Yejin Choi."
            ],
            "title": "Modeling naive psychology of characters in simple commonsense stories",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1:",
            "year": 2018
        },
        {
            "authors": [
                "Rezvaneh Rezapour",
                "Priscilla Ferronato",
                "Jana Diesner."
            ],
            "title": "How do moral values differ in tweets on social movements? In Conference Companion Publication of the 2019 on Computer Supported Cooperative Work and Social Computing",
            "venue": "ACM.",
            "year": 2019
        },
        {
            "authors": [
                "Rezvaneh Rezapour",
                "Saumil H. Shah",
                "Jana Diesner."
            ],
            "title": "Enhancing the measurement of social effects by capturing morality",
            "venue": "Proceedings of the Tenth Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages",
            "year": 2019
        },
        {
            "authors": [
                "Shamik Roy",
                "Dan Goldwasser."
            ],
            "title": "Analysis of nuanced stances and sentiment towards entities of US politicians through the lens of moral foundation theory",
            "venue": "Proceedings of the Ninth International Workshop on Natural Language Processing for Social",
            "year": 2021
        },
        {
            "authors": [
                "Shamik Roy",
                "Maria Leonor Pacheco",
                "Dan Goldwasser."
            ],
            "title": "Identifying morality frames in political tweets using relational learning",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 9939\u20139958, Online",
            "year": 2021
        },
        {
            "authors": [
                "Javier Ruiz Soler"
            ],
            "title": "Twitter research for social scientists: A brief introduction to the benefits, limitations and tools for analysing twitter data",
            "year": 2017
        },
        {
            "authors": [
                "Rafal Rzepka",
                "Kenji Araki."
            ],
            "title": "Polarization of consequence expressions for an automatic ethical judgment based on moral stages theory",
            "venue": "IPSJ SIG Notes, 14:1\u20134.",
            "year": 2012
        },
        {
            "authors": [
                "Rafal Rzepka",
                "Kenji Araki."
            ],
            "title": "Toward artificial ethical learners that could also teach you how to be a moral man",
            "venue": "IJCAI 2015 Workshop on Cognitive Knowledge Acquisition and Applications (Cognitum 2015). IJCAI.",
            "year": 2015
        },
        {
            "authors": [
                "Eyal Sagi",
                "Morteza Dehghani."
            ],
            "title": "Measuring moral rhetoric in text",
            "venue": "Social Science Computer Review, 32(2):132\u2013144.",
            "year": 2013
        },
        {
            "authors": [
                "Wesley Santos",
                "Ivandr\u00e9 Paraboni."
            ],
            "title": "Moral stance recognition and polarity classification from Twitter and elicited text",
            "venue": "Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019), pages 1069\u2013",
            "year": 2019
        },
        {
            "authors": [
                "Maarten Sap",
                "Saadia Gabriel",
                "Lianhui Qin",
                "Dan Jurafsky",
                "Noah A. Smith",
                "Yejin Choi."
            ],
            "title": "Social bias frames: Reasoning about social and power implications of language",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational",
            "year": 2020
        },
        {
            "authors": [
                "Geoff Sayre-McCord."
            ],
            "title": "Metaethics",
            "venue": "Edward N. Zalta and Uri Nodelman, editors, The Stanford Encyclopedia of Philosophy, Spring 2023 edition. Metaphysics Research Lab, Stanford University.",
            "year": 2023
        },
        {
            "authors": [
                "Chelsea Schein."
            ],
            "title": "The importance of context in moral judgments",
            "venue": "Perspectives on Psychological Science, 15(2):207\u2013215.",
            "year": 2020
        },
        {
            "authors": [
                "K.R. Scherer",
                "Martin Peper",
                "F. Boller",
                "J. Grafman."
            ],
            "title": "psychological theories of emotion and neuropsychological research,\" in handbook of neuropsychology, eds f",
            "venue": "Boller and J. Grafman (Amsterdam: Elsevier), 5:17\u201348.",
            "year": 2001
        },
        {
            "authors": [
                "Patrick Schramowski",
                "Cigdem Turan",
                "Nico Andersen",
                "Constantin A. Rothkopf",
                "Kristian Kersting."
            ],
            "title": "Large pre-trained language models contain humanlike biases of what is right and wrong to do",
            "venue": "Nature Machine Intelligence, 4(3):258\u2013268.",
            "year": 2022
        },
        {
            "authors": [
                "Patrick Schramowski",
                "Cigdem Turan",
                "Sophie F. Jentzsch",
                "Constantin A. Rothkopf",
                "Kristian Kersting."
            ],
            "title": "Bert has a moral compass: Improvements of ethical and moral values of machines",
            "venue": "ArXiv, abs/1912.05238.",
            "year": 2019
        },
        {
            "authors": [
                "Patrick Schramowski",
                "Cigdem Turan",
                "Sophie F. Jentzsch",
                "Constantin A. Rothkopf",
                "Kristian Kersting."
            ],
            "title": "The moral choice machine",
            "venue": "Frontiers in Artificial Intelligence, 3.",
            "year": 2020
        },
        {
            "authors": [
                "Tao Shen",
                "Xiubo Geng",
                "Daxin Jiang."
            ],
            "title": "Social norms-grounded machine ethics in complex narrative situation",
            "venue": "Proceedings of the 29th International Conference on Computational Linguistics, pages 1333\u20131343, Gyeongju, Republic of Korea. In-",
            "year": 2022
        },
        {
            "authors": [
                "Walter Sinnott-Armstrong."
            ],
            "title": "Consequentialism",
            "venue": "Edward N. Zalta and Uri Nodelman, editors, The Stanford Encyclopedia of Philosophy, Winter 2022 edition. Metaphysics Research Lab, Stanford University.",
            "year": 2022
        },
        {
            "authors": [
                "Megha Srivastava",
                "Noah Goodman."
            ],
            "title": "Question generation for adaptive education",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
            "year": 2021
        },
        {
            "authors": [
                "Titus Stahl"
            ],
            "title": "Einf\u00fchrung in Die Metaethik",
            "year": 2013
        },
        {
            "authors": [
                "Marco Stranisci",
                "Michele De Leonardis",
                "Cristina Bosco",
                "Viviana Patti."
            ],
            "title": "The expression of moral values in the twitter debate: a corpus of conversations",
            "venue": "Italian Journal of Computational Linguistics, 7(1 | 2):113\u2013132.",
            "year": 2021
        },
        {
            "authors": [
                "P.F. Strawson."
            ],
            "title": "Social morality and individual ideal",
            "venue": "Philosophy, 36(136):1\u201317.",
            "year": 1961
        },
        {
            "authors": [
                "Shahbaz Syed",
                "Michael V\u00f6lske",
                "Nedim Lipka",
                "Benno Stein",
                "Hinrich Sch\u00fctze",
                "Martin Potthast."
            ],
            "title": "Towards summarization for social media - results of the TL;DR challenge",
            "venue": "Proceedings of the 12th International Conference on Natural Language Gen-",
            "year": 2019
        },
        {
            "authors": [
                "Zeerak Talat",
                "Hagen Blix",
                "Josef Valvoda",
                "Maya Indira Ganesh",
                "Ryan Cotterell",
                "Adina Williams"
            ],
            "title": "A word on machine ethics: A response to jiang et al.(2021)",
            "venue": "arXiv preprint arXiv:2111.04158",
            "year": 2021
        },
        {
            "authors": [
                "Zeerak Talat",
                "Hagen Blix",
                "Josef Valvoda",
                "Maya Indira Ganesh",
                "Ryan Cotterell",
                "Adina Williams."
            ],
            "title": "On the machine learning of ethical judgments from natural language",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Asso-",
            "year": 2022
        },
        {
            "authors": [
                "Yi Tay",
                "Donovan Ong",
                "Jie Fu",
                "Alvin Chan",
                "Nancy Chen",
                "Anh Tuan Luu",
                "Chris Pal."
            ],
            "title": "Would you rather? a new benchmark for learning machine alignment with cultural values and social preferences",
            "venue": "Proceedings of the 58th Annual Meeting of the Asso-",
            "year": 2020
        },
        {
            "authors": [
                "Livia Teernstra",
                "Peter van der Putten",
                "Liesbeth Noordegraaf-Eelens",
                "Fons Verbeek."
            ],
            "title": "The morality machine: Tracking moral values in tweets",
            "venue": "Advances in Intelligent Data Analysis XV: 15th International Symposium, IDA 2016, Stockholm, Swe-",
            "year": 2016
        },
        {
            "authors": [
                "Jackson Trager",
                "Alireza S Ziabari",
                "Aida Mostafazadeh Davani",
                "Preni Golazazian",
                "Farzan KarimiMalekabadi",
                "Ali Omrani",
                "Zhihe Li",
                "Brendan Kennedy",
                "Nils Karl Reimer",
                "Melissa Reyes"
            ],
            "title": "The moral foundations reddit",
            "year": 2022
        },
        {
            "authors": [
                "Eline van den Broek-Altenburg",
                "Robert Gramling",
                "Kelly Gothard",
                "Maarten Kroesen",
                "Caspar Chorus."
            ],
            "title": "Using natural language processing to explore heterogeneity in moral terminology in palliative care consultations",
            "venue": "BMC Palliative Care, 20(1).",
            "year": 2021
        },
        {
            "authors": [
                "Anne Fleur van Luenen"
            ],
            "title": "Recognising moral foundations in online extremist discourse: A crossdomain classification study",
            "year": 2020
        },
        {
            "authors": [
                "Dragos Vecerdea"
            ],
            "title": "Moral embeddings: A closer look at their performance, generalizability and transferability",
            "year": 2021
        },
        {
            "authors": [
                "Yue Wang",
                "Jing Li",
                "Hou Pong Chan",
                "Irwin King",
                "Michael R. Lyu",
                "Shuming Shi."
            ],
            "title": "Topicaware neural keyphrase generation for social media language",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,",
            "year": 2019
        },
        {
            "authors": [
                "Laura Weidinger",
                "John Mellor",
                "Maribeth Rauh",
                "Conor Griffin",
                "Jonathan Uesato",
                "Po-Sen Huang",
                "Myra Cheng",
                "Mia Glaese",
                "Borja Balle",
                "Atoosa Kasirzadeh"
            ],
            "title": "Ethical and social risks of harm from language models. arXiv preprint arXiv:2112.04359",
            "year": 2021
        },
        {
            "authors": [
                "Jing Yi Xie",
                "Renato Ferreira Pinto Junior",
                "Graeme Hirst",
                "Yang Xu."
            ],
            "title": "Text-based inference of moral sentiment change",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference",
            "year": 2019
        },
        {
            "authors": [
                "Jing Yi Xie",
                "Graeme Hirst",
                "Yang Xu."
            ],
            "title": "Contextualized moral inference",
            "venue": "arXiv preprint arXiv:2008.10762.",
            "year": 2020
        },
        {
            "authors": [
                "Mengyao Xu",
                "Zhujin Guo."
            ],
            "title": "Objectivity and moral judgment in us news narratives: A natural language processing analysis of \u2018culture war\u2019coverage",
            "venue": "Journal of Media Ethics, 38(1):16\u201333.",
            "year": 2023
        },
        {
            "authors": [
                "Masahiro Yamamoto",
                "Masafumi Hagiwara."
            ],
            "title": "Moral judgment system using evaluation expressions",
            "venue": "2014 Joint 7th International Conference on Soft Computing and Intelligent Systems (SCIS) and 15th International Symposium on Advanced Intelligent",
            "year": 2014
        },
        {
            "authors": [
                "Han Yu",
                "Zhiqi Shen",
                "Chunyan Miao",
                "Cyril Leung",
                "Victor R. Lesser",
                "Qiang Yang."
            ],
            "title": "Building ethics into artificial intelligence",
            "venue": "Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence. International Joint Conferences",
            "year": 2018
        },
        {
            "authors": [
                "Chunxu Zhao",
                "Pengyuan Liu",
                "Dong Yu."
            ],
            "title": "From polarity to intensity: Mining morality from semantic space",
            "venue": "Proceedings of the 29th International Conference on Computational Linguistics, pages 1250\u2013 1262, Gyeongju, Republic of Korea. International",
            "year": 2022
        },
        {
            "authors": [
                "Jieyu Zhao",
                "Daniel Khashabi",
                "Tushar Khot",
                "Ashish Sabharwal",
                "Kai-Wei Chang"
            ],
            "title": "Ethical-advice taker: Do language models understand natural language interventions? In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
            "year": 2021
        },
        {
            "authors": [
                "Caleb Ziems",
                "Jane Yu",
                "Yi-Chia Wang",
                "Alon Halevy",
                "Diyi Yang."
            ],
            "title": "The moral integrity corpus: A benchmark for ethical dialogue systems",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Pa-",
            "year": 2022
        },
        {
            "authors": [
                "Dehghani"
            ],
            "title": "Moral Sentiment These papers analyse moral sentiment and thus focus on the emotional polarity of a text or statement",
            "year": 2008
        },
        {
            "authors": [
                "Santos",
                "Paraboni",
                "Pavan"
            ],
            "title": "Quantification Under the broad category of \u2018quantification\u2019 fall all papers that measure \u2018morality\u2019 or \u2018ethics",
            "year": 2020
        },
        {
            "authors": [
                "2020 Mutlu et al",
                "2019 Xie et al",
                "Qian"
            ],
            "title": "Hulpus, et al., 2020) (Kennedy et al., 2021; van den Broek-Altenburg et al., 2021",
            "venue": "Nokhiz and Li,",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "With Natural Language Processing (NLP) receiving widespread attention in various domains, including healthcare (e.g., Krahmer et al., 2022; Ji et al., 2022), education (e.g., Alhawiti, 2014; Srivastava and Goodman, 2021), and social media (e.g., Wang et al., 2019; Syed et al., 2019), the ethical aspects and the social impact of language technology have become more and more important (Hovy and Spruit, 2016; Blodgett et al., 2020; Weidinger et al., 2021).\nIn this context, recent research focused on the notion of morality (e.g., Araque et al., 2020;\nHendrycks et al., 2020; H\u00e4mmerl et al., 2022b, inter alia), for instance, with the goal of extracting morality and moral values automatically from text. The existing research landscape is manifold (cf. Figure 1), ranging, for example, from creating suitable data sets (e.g., Forbes et al., 2020; Sap et al., 2020), over investigating moral consistency in different languages (e.g., H\u00e4mmerl et al., 2022b) to constructing NLP models that are able to make moral judgements about input sentences (e.g., Shen et al., 2022; Alhassan et al., 2022).\nSuch attempts have also sparked controversy in the research community and the public media. As a widely discussed1 example, DELPHI (Jiang et al., 2021a), has been criticised, among other reasons, for the normative nature of its judgements given the authors\u2019 goal of creating a model of descriptive ethics (Talat et al., 2022). We argue that this mismatch relates to a bigger problem in our community: a lack of clear definitions coupled with a\n1E.g., coverage in New York Times: https: //www.nytimes.com/2021/11/19/technology/ can-a-machine-learn-morality.html\nconfusion about important underlying concepts stemming from philosophy, psychology, and beyond. As a result, it is unclear to what extent the foundations of moral philosophy can even be found in NLP research on morality and whether and how researchers are considering ethical theories and related philosophical concepts in NLP. In-depth knowledge on how NLP is dealing with the different shades of morality is missing \u2013 hindering a targeted scientific discussion in the field.\nContributions. We address this gap by surveying the state of research on the interplay of morality and NLP. Concretely, (1) we analyse 92 publications on morality in NLP resulting in the only survey on this topic to-date. We draw a map of the existing NLP tasks dealing with morality (e.g., classification of moral values), analyse the moral (i.e., philosophical and/or psychological) foundations pertaining to current research, and examine the existing data sets. To this end, (2) we are the first to provide a thorough overview of the most important concepts relating to morality for NLP. For instance, we discuss the different branches of moral philosophy and three main families of ethical theories (consequentialism, deontological ethics, and virtue ethics) to clarify common misconceptions in the community. We find, for instance, that (a) most papers do not refer to ethical principles, that (b) relevant philosophical terms (e.g., \u2018morality\u2019, \u2018ethics\u2019, and \u2018value\u2019) are often used interchangeably; and that (c) clarifying definitions of the terms used are rarely provided. Finally, (3) we use our insights to provide three recommendations for future research."
        },
        {
            "heading": "2 Background and Terminology",
            "text": "Ethics has undeniably become a critical topic within NLP.2 However, as we show in \u00a74, the term is often used without specification, leaving ambiguity about what branch of moral philosophy authors refer to. Here, we introduce the precise terminology we will use in the remainder of this work.\nEthics. The branch of philosophy that deals with human practice, i.e., human actions and their evaluation, is called ethics. Ethics is composed of four branches, each with a different focus on human action: metaethics, normative ethics, applied ethics, and descriptive ethics (Stahl, 2013). We provide an overview on these disciplines, subject areas, and methodological foundations in Table 1.\n2As also reflected by the many top-tier NLP conferences with dedicated ethics submission tracks, e.g., EMNLP 2023.\nMorality. Examining ethical frameworks brings us to the concept of morality itself, which is defined differently depending on the ethical perspective at hand. The concrete definition is crucial for ethical reflection in language technology, as \u2018morality\u2019 can be used in both a descriptive and a normative sense. In the normative sense, morality is seen as a set of principles that govern human behaviour (Strawson, 1961), or as a socially constructed concept shaped by cultural and individual perspectives (Gert and Gert, 2020). In the descriptive sense, however, \u2018morality\u2019 refers \u201cto certain codes of conduct put forward by a society or a group (such as a religion), or accepted by an individual for her own behaviour\u201d (Gert and Gert, 2020).\nMetaethics. We refer to the ethical branch which provides the analytical foundations for the other three sub-disciplines (normative, applied, and descriptive ethics) as metaethics. It is concerned with the universal linguistic meanings of the structures of moral speech as well as the power of ethical theories (Sayre-McCord, 2023), and deals with general problems underlying ethical reasoning, like questions around moral relativism.\nNormative Ethics. This sub-discipline investigates universal norms and values as well as their justification (Copp, 2007). We operate within the normative framework if we make moral judgements and evaluate an action as right or wrong. It thus represents the core of general ethics and is often referred to as moral philosophy or simply ethics.\nEthical Theories and their Families. Within normative ethics, philosophers have presented various reasoning frameworks, dubbed ethical theories, that determine whether and why actions are right and wrong, starting from specific assumptions (Driver, 2022). These theories can be \u2013 in western philosophy \u2013 roughly assigned to three competing ethical families (or are hybrids): virtue ethics, deontological ethics, and consequentialism. While virtue ethics focuses on cultivating the moral character and integrity of the person guiding moral action (Hursthouse and Pettigrove, 2022), deontological ethics and consequentialism emphasise the status of the action, disposition or rule. Concretely, the former focuses on duty, rules and obligations, regardless of an action\u2019s consequences (Alexander and Moore, 2021), while the latter focuses on the consequences of actions and places moral value based on the outcomes (Sinnott-Armstrong, 2022).\nApplied Ethics. Applied ethics builds upon the general normative ethics framework but deals with individual ethics in concrete situations (Petersen and Ryberg, 2010). This includes, for example, bioethics, machine ethics, medical ethics, robot ethics, and the ethics of AI.\nDescriptive Ethics. The aforementioned subbranches of ethics starkly contrast with descriptive ethics (which is why it is not always counted among the main disciplines of ethics). Descriptive ethics represents an empirical investigation and describes preferences for action or empirically found systems of values and norms (Britannica, 2023). The most important distinction from the previous two disciplines is that it does not make moral judgements and merely describes or explains found criteria within a society, e.g., via surveys such as the World Value Survey (Haerpfer et al., 2020).\nMoral Psychology. Finally, we distinguish between moral philosophy and moral psychology. As mentioned, moral philosophy can be understood as normative ethics and thus deals with the question of right action and represents a judgemental action. In contrast, moral psychology relates to descriptive ethics. It explores moral judgements and existing systems of values and norms to understand how people make moral judgements and decisions. This distinction is crucial, as many models and methods covered in our survey refer to the Moral Foundation Theory (MFT). This social psychology theory aims to explain the origin and variation of human moral reasoning based on innate, modular foundations (Graham et al., 2013, 2018)."
        },
        {
            "heading": "3 Survey Methodology",
            "text": "Our approach to surveying works dealing with morality in NLP consists of three steps: (1) scope definition and paper identification, (2) manual analysis of the relevant papers, and (3) validation."
        },
        {
            "heading": "3.1 Search Scope and Paper Identification",
            "text": "To identify relevant publications, we queried the ACL Anthology,3 Google Scholar,4 and the ACM Digital Library5 for the following keywords: \u2018consequentialism\u2019, \u2018deontology\u2019, \u2018deontological\u2019, \u2018ethical\u2019, \u2018ethics\u2019, \u2018ethical judgement\u2019,\n\u2018moral\u2019, \u2018moral choice\u2019, \u2018moral judgement(s)\u2019, \u2018moral norm(s)\u2019, \u2018moral value(s)\u2019, \u2018morality\u2019, \u2018utilitarianism\u2019, \u2018virtues\u2019.6 We conducted this initial search between 25/01/2023 and 27/01/2023. For each engine, we considered the first 100 search results (sorted by relevance) and made an initial relevance judgement based on the abstract. After removing duplicates, we ended up with 155 papers. Since our survey is limited to papers that deal with morality in the context of NLP, we examined these 155 papers more closely concerning our topic of interest (e.g., by scanning the manuscript\u2019s introduction and checking for ethics buzzwords) during multiple rounds of annotation. Of the original 155 papers, we identified 71 as irrelevant. We have, for example, classified as \u201cirrelevant\u201d papers that deal with judicial judgements, ethical decisions in autonomous vehicles, meta-analyses in NLP, and papers that deal with ethical issues in NLP on a general level or that have no particular relation to NLP. This left us with 84 remaining publications fitting our scope. Based on the references provided in this initial set, we expanded our set by eight more papers, leading us to a list of 92 papers."
        },
        {
            "heading": "3.2 Manual Analysis",
            "text": "Next, we analysed our collection manually. To this end, we developed an annotation scheme consisting of four main aspects, which we iteratively\n3https://aclanthology.org 4https://scholar.google.com 5https://dl.acm.org 6For Google Scholar and ACM Digital Library searches, we added the keyword \u2018NLP\u2019. E.g., instead of \u2018consequentialism\u2019, we searched for \u2018consequentialism NLP\u2019 to narrow down the retrieved papers to those fitting our search scope.\nrefined during the analysis (e.g., adding a subcategory whenever we found it necessary):\nGoal: What is the overall goal of this work? Do authors tackle a specific NLP task?\nFoundation: Do authors mention a theoretical foundation as basis for their work? If yes, which and to which family of thought does it belong to (e.g., moral psychology vs. moral philosophy)?\nTerminology: Do authors use terms stemming from philosophy? How? Do they provide definitions?\nData: What data is used? What is the origin of this data, and which languages are represented?\nWe provide the full scheme with all sub-codes in the Appendix D. We conducted the analysis in multiple stages, from more coarse-grained to more finegrained, re-analysing the papers when adding a new label. We relied on the qualitative data analysis software MAXQDA Analytics Pro 2022 to support the whole process. After four rounds of analysis, we ended up with 4,988 annotations."
        },
        {
            "heading": "3.3 Validation",
            "text": "To ensure the validity of our results, we designed an additional annotation task, for which we devised a series of 14 questions dealing with the most important aspects of our analysis. For instance, we ask whether a publication is relevant for our analysis, whether it discusses the underlying philosophical or psychological foundations, whether it proposes a new framework to measure morality, analyses moral sentiment, etc. We explain the whole design of this task in Appendix B. We hired two annotators for the task who are proficient English speakers and explained the terminology we adhere to and the annotation task to them. Next, we randomly sampled 25 papers from our collection and assigned ten and fifteen respectively to each annotator. We compared the annotators\u2019 answers to our analysis and obtained an inter-annotator agreement of 0.707 Krippendorff\u2019s \u03b1 (Krippendorff, 2011) (computed over 229 annotations) indicating substantial agreement (Landis and Koch, 1977)."
        },
        {
            "heading": "4 The Status Quo",
            "text": "We describe our findings.\nOverall Findings. We show the 92 papers surveyed, sorted by year of publication (Figure 2) and provide a diachronic analysis of paper goals (Figure 3). Most papers were published after 2018,"
        },
        {
            "heading": "NLP Tasks Num. Papers",
            "text": "with the maximum number (27) published in 2022 \u2013 morality is a trendy topic in NLP. The first paper on morality in NLP was published in 2006, already then dealing with providing \u2019ethical advice\u2019. Overall, we observe a variety of such goals, which we classified into 13 categories (see Table 2; an extensive list of the papers falling into the different tasks can be found in Appendix A).\nOut of the 92 works, more than one quarter (24) deal with predicting moral values from text (e.g., Pavan et al., 2023; Gloor et al., 2022) and 14 papers deal with classification more broadly (e.g., \u2018ethics classification\u2019 (Mainali et al., 2020), classification of ethical arguments according to the three ethical families, and \u2018moral sentiment\u2019 and \u2018moral stance\u2019 classification (e.g., Mooijman et al., 2018; Garten et al., 2016; Botzer et al., 2022)), and thus fall under the umbrella of descriptive ethics. Another 14 papers focus primarily on the production of \u2018moral data sets\u2019, either based on MFT (e.g., Matsuo et al.,\n2019; Hopp et al., 2020) or of a more general nature (e.g., Hendrycks et al., 2020; Lourie et al., 2021; Hoover et al., 2019). Twelve papers fall into \u2018quantification\u2019. This includes approaches which, e.g., based on moral psychological approaches, establish further metrics for \u2018measuring morality\u2019 (e.g.,\n\u2018moral concern\u2019, \u2018moral inclination\u2019, \u2018moral intensity\u2019 (e.g., Sagi and Dehghani, 2013; Zhao et al., 2022; Kim and Lee, 2020)) or measure the \u2019ethicality\u2019 of a text. In addition, nine papers present models providing moral advice judging actions as \u2018ethical advisors\u2019 (e.g., Zhao et al., 2021; Jin et al., 2022; Jiang et al., 2021a) and four papers deal with models making normative judgements based on descriptive data (e.g., Yamamoto and Hagiwara, 2014; Alhassan et al., 2022).\nFoundations of Studying Morality. We identified varying foundations pertaining to the works we surveyed (cf. Figure 4). Overall, 59 papers mention at least one moral psychology framework. Out of these, 49 base their approach on the Moral Founda-\ntion Theory (MFT) (e.g., Fraser et al., 2022; H\u00e4mmerl et al., 2022b; Stranisci et al., 2021; Hoover et al., 2019; Alshomary et al., 2022; Mutlu et al., 2020), while six (also) rely on Schwartz\u2019 Values Theory (e.g., Kiesel et al., 2022; Gloor et al., 2022; Maheshwari et al., 2017) and one on Kohlberg\u2019s Theory (Rzepka and Araki, 2012). Eight documents mention moral psychology in general but do not state a specific framework. Our analysis yields 26 publications mentioning one of the ethical theories we describe above (consequentialism, deontology, virtue ethics), while just 16 go further into detail. Six documents mention aspects related to moral psychology as well as to ethical theories (Fraser et al., 2022; Alfano et al., 2018; Botzer et al., 2022; Dehghani et al., 2008; Mainali et al., 2020; Jiang et al., 2021b). In contrast, Rzepka and Araki (2015) mention that they decided to exclude ethical theories from their study and base their approach solemnly on commonsense knowledge about norms. Teernstra et al. (2016) state that MFT is an ethical framework. This is, as we outline above, not true since it is a theory of moral psychology and not moral philosophy (which provides ethical principles to what is right and wrong). To sum up, we find that there is a lack of clarity and consistency as to whether morality in NLP is addressed purely empirically or also normatively. This lack of clarity persists also in regards to the further usage of ethical terminology.\nUsage of Philosophical Terms. We conduct an even finer-grained analysis of how philosophical terms are used. In total, we note that most papers (66.3%) do not define the terminology they adopt (61 papers vs. 31 papers). Some works seem to use the terms \u201cmoral\u201d and \u201cethics\u201d interchangeably (Jentzsch et al., 2019; Schramowski et al., 2020). For instance, Penikas et al. (2021) want \u201cto assess the moral and ethical component\nof a text\u201d. Similarly, we found some use \u201cmorality\u201d as a synonym of \u201cvalue\u201d and \u201cmoral foundation\u201d (Rezapour et al., 2019b,a; Lan and Paraboni, 2022; Huang et al., 2022; Liscio et al., 2022). We provide an extensive list of definitions in Table 3. NLP literature also introduces novel terms for which, sometimes, definitions are lacking. As such Hopp et al. (2020) introduce \u201cmoral intuition\u201d but leave unclear what exactly they mean. (Xie et al., 2020) introduce \u201cmoral vignette\u201d, possibly referring to moral values or norms, but do not provide a definition. Importantly, some authors state they base their work on applied or descriptive ethics but ultimately provide normative judgements with their models when using them to predict (or judge) new, unseen situations (Ziems et al., 2022; Forbes et al., 2020; Lourie et al., 2021; Hendrycks et al., 2020; Schramowski et al., 2022; Zhao et al., 2021; Jiang et al., 2021a,b; Botzer et al., 2022; Yamamoto and Hagiwara, 2014; Alhassan et al., 2022). This is problematic, since here, normative judgements are made from empirical data or without any normative justification. We conclude that clear definitions of the terminology are mostly lacking.\nUnderlying Data. In total, we identify 25 different data sets that underpin the studies we analyse (see Appendix C). Partially, however, those corpora are derivatives of each other, e.g., Matsuo et al. (2019), Hopp et al. (2020), and Araque et al. (2020) all extend the Moral Foundations Dictionary (MFD).7 As a result, some of the data sets are very popular and widely used in the respective subfields they relate to (e.g., the original MFD is used in 35 publications). Similarly, we observe heavy reliance on social media data: Twitter is used in 32 publications (e.g., Hoover et al., 2019; Stranisci et al., 2021) and in nine papers, researchers rely on Reddit data (e.g., Trager et al., 2022; Alhassan et al., 2022). As previously observed in NLP (Joshi et al., 2020), the distribution of languages the works we survey deal with are highly skewed (see Figure 5). Out of 33 papers that explicitly state the language they deal with, we find that the vast majority (75.8%) deal with English. Also, the interrelation of multilinguality and morality is still underresearched with only four papers dealing with more than one language (H\u00e4mmerl et al., 2022a,b; Guan et al., 2022; Lan and Paraboni, 2022). To conclude, we find that the data sets used are heavily skewed w.r.t. source and linguistic diversity.\n7https://moralfoundations.org"
        },
        {
            "heading": "5 Challenges",
            "text": "Based on our findings, we discuss the scientific methodological problems and the resulting ethical challenges in the current landscape of work on language technology and morality.\nMissing Foundations. Our findings indicate that the underlying foundations of morality in NLP, as well as the respective terminologies, are diverse but often unclear and left implicit. The foundations are, however, a crucial aspect of these studies: there exist different definitions of morals (and values, norms, etc.) and what they imply. Our findings show that the underlying foundations of morality in NLP and the corresponding terminologies are diverse but often unclear and remain implicit. However, the foundations are a crucial aspect of these studies: there are different definitions of morality (and values, norms, etc.) and what it implies. Consequently, different disciplines may have a completely different focus, such as in the distinction of moral psychology vs. moral philosophy, where the descriptive and normative bases are contrasted. This distinction is crucial because of the following implications, as already outlined in \u00a72. Within moral philosophy, we must continue to compare different ethical theories as they may compete with each other (e.g., deontology vs. consequentialism). We can draw parallels to the field of Affective Computing8 here: theories on emotions are similarly diverse (e.g., James, 1948; Darwin, 1999; Mellers et al., 1997; Scherer et al., 2001) and similarly influence the research outcome (cf. Barrett et al., 2019; Mau et al., 2021). However, we find that, in affec-\n8Rosalind Picard defines Affective Computing as \u2019computing that relates to, arises from, or deliberately influences emotions\u2019 (Picard, 2000, p. 3)."
        },
        {
            "heading": "Paper Foundation Definition Concept",
            "text": "(Schramowski et al., 2022) \u201cmorality has referred to the \u201cright\u201d and \u201cwrong\u201d of actions at the individual\u2019s level, i.e., an agent\u2019s first-personal practical reasoning about what they ought to do.\u201d right and wrong of actions (Roy et al., 2021) MFT Morality is \u201ca set of principles to distinguish be-tween right and wrong\u201d set of principles\n(Jiang et al., 2021a) MFT, P\n\u201cPhilosophers broadly consider morality in two ways: morality is a set of objectively true principles that can exist a priori without empirical grounding (Kant, 1785/2002; Parfit, 2011); and morality is an expression of the biological and social needs of humans, driven by specific contexts (e.g., time and culture, Smith, 1759/2022; Wong, 2006; Street, 2012).\u201d\nset of principles and expression of needs\n(Jiang et al., 2021b) MFT, P \u201cformalize morality as socially constructed expectations about acceptability and preference.\u201d expectations (Lan and Paraboni, 2022) MFT morality is \u201ca system of values and principles that determines what is admissible or not within a social group\u201d system of values (Rezapour et al., 2019b) MFT \u201cTo extract human values (in this paper, morality) and measure social effects (morality and stance) ...\u201d Morality = Moral Value (Rezapour et al., 2019a) MFT \u201cTo capture morality in tweets, we found and counted all words that matched entries in the enhanced MFD\u201d Morality = Moral Value (Huang et al., 2022) MFT \u201cwe focus on the morality classification task\u201d Morality = Moral Value (Liscio et al., 2022) MFT \u201cMorality helps humans discern right from wrong. Pluralist moral philosophers argue that human morality can be represented, understood, and explained by a finite number of irreducible basic elements, referred to as moral values (Graham et al., 2013).\u201d Morality = Moral Value (Asprino et al., 2022) MFT \u201cMorality [is] a set of social and acceptable behavioral norms\u201d, \u201cMoral values [are] commonsense norms shape [that] our everyday individual and community behavior.\u201d norms (Araque et al., 2020) MFT \u201cMoral values are considered to be a higher level construct with respect to personality traits, determining how and when dispositions and attitudes relate with our life stories and narratives [27].\u201d dispositions (Vecerdea, 2021) MFT moral values are \u201cabstract ideas that ground our judgement towards what is right or wrong\u201d abstract ideas (Constantinescu, 2021) MFT \u201cpersonal values are the abstract motivations that drive our opinions and actions\u201d abstract motivations (Dondera, 2021) MFT \u201cMoral values are the abstract motivations that drive our opinions and actions.\u201d abstract motivations (Arsene, 2021) MFT \u201cMoral values represent the underlying motivation behin[d] people\u2019s opinions, which influence their day-to-day actions.\u201d underlying motivations (Lin et al., 2018) MFT \u201cMoral values are principles that define right and wrong for a given individual. They influence decision making, social judgements, motivation, and behaviour and are thought of as the glue that binds society together (Haidt)\u201d principles\nTable 3: The different definitions for \u2018morality\u2019 and \u2018moral values\u2019 in the papers. In the \u2018Foundation\u2019 column, we distinguish between Moral Foundation Theory (MFT), and Philosophy (P).\ntive computing, these theories are considered and adapted, and accordingly, corresponding models are developed (Marsella et al., 2010). Thus, these studies mostly have an explicit root in certain theories of emotion psychology. In contrast, such a systematic approach is currently missing for tasks regarding morality in NLP.\nMissing Context. Essential aspects and dimensions of morality are lost when trying to derive moral values or ethical attitudes from text alone and from incomplete textual descriptions. Moral judgements are always context-dependent, and without an accurate description of the context, valuable information is lost (Schein, 2020). Most approaches, however, disregard the broader context completely. They focus only on the presence of certain words, which, for example, are tied to specific moral values (Jentzsch et al., 2019; Lourie et al., 2021; Yamamoto and Hagiwara, 2014; Kaur and Sasahara, 2016, e.g.,). Some also focus on so-called atomic actions, which severely limits the ability to make an accurate judgement (Schramowski et al., 2019, 2020, 2022). This problem also relates to the data sets used. For instance, the context available in Twitter data is directly constrained by the character limit of tweets. While context-dependency and missing knowledge is a general problem in NLP (cf. Lauscher et al., 2022b), the problem is likely more severe when it comes to morality: moral models\ntrained on such limited data sets may introduce or reinforce existing social biases in individuals when deriving moral judgements, leading to unfair evaluations and misrepresentations of people and situations. This could have detrimental consequences for their personal and professional lives, as the beliefs about the morality of users of such moral models may be influenced.\nMissing Diversity. Another challenge is that there is no universal ground truth for moral judgements and ethics in general (yet). Morality is the subject of constant philosophical and cultural debate and has evolved. Although Aristotle defined the concept of ethics already ca. 350 B.C.E. (in the Western philosophical tradition) as the branch of philosophy concerned with habits, customs and traditions (Aristotle, ca. 350 B.C.E/2020), to this day, there is no universally accepted ethical framework that defines the one ethic as the \u2018right\u2019 one (Aristotle, ca. 350 B.C.E/2020). Consequently, subjective interpretations of moral concepts, often used as a basis for training data, can vary depending on the individual, cultural and societal circumstances (Alsaad, 2021; Driver, 2022). This recognition stands in stark contrast to the heavily skewed data sets available. For instance, as we showed, languages other than English have been mostly ignored, and data sets are mostly based on two(!) social media platforms, which, making things worse, mostly at-\ntract male users from the USA (Ruiz Soler, 2017; Proferes et al., 2021). This suggest a severe lack of cultural and sub-cultural diversity.\nIs-ought Problem. Research on morality in NLP often aims at extracting normative judgements from their empirical analyses (Jiang et al., 2021a,b; Shen et al., 2022; Yamamoto and Hagiwara, 2014; Efstathiadis et al., 2022; Alhassan et al., 2022; Schramowski et al., 2022; Lourie et al., 2021; Forbes et al., 2020; Ziems et al., 2022). In doing this, they face the so called is-ought problem (Cohon, 2018): it is not ethically legitimate to derive normative judgements from empirical observations \u2013 is does not imply ought. Put differently: just because many people think something is morally right, does not mean it is ethically justified. Normative judgements require grounding in ethical theories or principles that go beyond the mere observation of language use (Cohon, 2018). Without a clear ethical theory to guide the derivation of normative judgements, models may inadvertently perpetuate biases or reinforce existing social norms, leading to unjust or discriminatory outcomes. Especially when subjective judgements are used as the basis instead of ethical theories, specific biases may be unintentionally imposed by relying exclusively on the patterns or norms in the data. Such an approach does not consider legitimate differences in moral reasoning and results in a narrow and biased understanding of normative judgements.\nOverall, we conclude that including morality in NLP models, not only limited to making moral judgements, is a constant challenge. The \u2018is-ought\u2019 problem, the lack of ethical foundations, contextual complexity, subjectivity and pluralism highlight our current limitations and potential pitfalls."
        },
        {
            "heading": "6 Recommendations",
            "text": "We propose three recommendations (R\u2019s) to help research with avoiding the pitfalls described above.\n(R1) Integrate fundamental ethics approaches into NLP systems that explore ethical theories. Moral philosophical approaches provide wellestablished foundations for understanding and evaluating ethical principles and judgements. Only by incorporating established foundations and theories we can develop a more robust framework that goes beyond a purely descriptive analysis. This will allow for a more comprehensive and nuanced exploration of moral issues and facilitate the development of language models consistent with widely\naccepted ethical theories. At the same time, it will also maintain the ethical consistency of language models in decision-making processes. Using philosophical foundations ensures that the moral judgements automatically made are consistent with consistent principles and avoid contradictory or arbitrary assessments. Furthermore, as ethical theories often emphasise the importance of context and recognise the diversity of moral values and perspectives, we will promote the analysis of moral judgements in context and avoid over-generalisations or biased interpretations.\n(R2) Include and explicitly name ethical theories to which the model refers, as well as terms that come from philosophy when used otherwise. The explicit use and naming of underlying ethical theories creates clarity and ensures consistency in moral discussions in NLP. By naming specific approaches, researchers and users can create a common language and framework for morality in NLP. This promotes a shared understanding of the underlying principles and concepts, enabling more effective communication and collaboration. Incorporating ethical theories into language technology research also allows researchers to conduct more robust analyses of moral judgements, considering different perspectives and applying established criteria for ethical evaluation. It also prompts ethical reflection and examination. By explicitly naming ethical theories, researchers are encouraged to reflect on the extent to which their research or (computational) model conforms to or deviates from these theories, further promoting ethical awareness and accountability. Importantly, the explicit use of ethical theories and a shared terminology will facilitate interdisciplinary collaboration between NLP researchers and ethicists. By using established ethical theories and definitions of the relevant terminology, researchers from different disciplines can effectively communicate with each other, bridge gaps, and draw on expertise from multiple fields. This collaboration can thus lead to more comprehensive and informed research findings.\n(R3) Use a consistent vocabulary regarding crucial terms such as \u2018ethics\u2019, \u2018morality\u2019, \u2018values\u2019 or \u2018norms\u2019. Define introduced terms and check whether the terminology has been used in the literature before. Consistent vocabulary brings clarity and precision to discussions and research on morality in NLP. Researchers can thus effectively communicate their ideas, findings, and arguments\nusing well-defined and commonly accepted terms. This helps avoid confusion or misinterpretation between scholars and readers and facilitates accurate knowledge exchange. A uniform terminology also ensures conceptual alignment with the existing literature. Established terms allow researchers to build on previous research and link their work to a broader, more interdisciplinary body of knowledge."
        },
        {
            "heading": "7 Related Work",
            "text": "There exist a plethora of works dealing with ethical issues and the social impact of NLP (e.g., Hovy and Spruit, 2016; Leidner and Plachouras, 2017; Parra Escart\u00edn et al., 2017; Lauscher et al., 2022a; Hessenthaler et al., 2022; Kamocki and Witt, 2022, inter alia). Accordingly, in this realm, researchers also have provided systematic overviews of the literature, e.g., on \u2018bias\u2019 in NLP (Blodgett et al., 2020) and \u2018ethics\u2019 within the NLP community (Fort and Couillault, 2016). North and Vogel (2019) presented a categorisation of ethical frameworks of NLP into different ethical families. Yu et al. (2018) took a closer look at technical approaches for ethical AI and provide a taxonomy for the field of AI Governance. Closest to us, Hagendorff and Danks (2022) presented a meta-view of moral decisionmaking in AI outlining ethical and methodological challenges, focusing, like Talat et al. (2022) on the example of DELHPI (Jiang et al., 2021a)."
        },
        {
            "heading": "8 Conclusion",
            "text": "In reviewing 92 papers dealing with morality in NLP, we found that (a) the majority of the papers do not use ethical theories as a basis but predominantly take descriptive approaches, whereby judgements derived from them are subject to the \u2018isought\u2019 problem; (b) relevant terms such as \u2018moral\u2019, \u2018ethics\u2019 or \u2018value\u2019 are often not properly defined nor distinguished; and (c) explanatory definitions are rarely provided. Based on our analysis, we then provided three recommendations to help researchers avoid the resulting pitfalls. These recommendations involve a stronger integration of philosophical considerations to guide the field in a more targeted and sound direction."
        },
        {
            "heading": "Acknowledgements",
            "text": "This work is in part funded under the Excellence Strategy of the Federal Government and the L\u00e4nder. We thank the anonymous reviewers for their insightful comments."
        },
        {
            "heading": "Limitations",
            "text": "We recognise that this work is limited in several aspects. First, the papers we consider are determined using the selected databases and the English language. Furthermore, our foundational philosophical chapters are based on a Western understanding, which means that our definitions were developed within Western academic traditions and therefore have the limitations that come with them. Through the papers analysed, we have also intensely focused on the widely cited \u201cMoral Foundation Theory\u201d of Graham and Haidt, which is why other theories of moral psychology have been neglected. Future papers may therefore address and analyse other moral psychological and moral philosophical theories in NLP. As part of our analysis, we have only limited ourselves to the are of NLP, which the selection of our databases and papers already shows. Accordingly, the results presented in this paper relate only to the are of NLP and not other AI/ML related fields. Finally, it should be noted that our recommendations are not comprehensive and should be used to develop further questions and strategies."
        },
        {
            "heading": "A Categorisation details",
            "text": ""
        },
        {
            "heading": "A.1 Alignment",
            "text": "Papers in the category \u2018alignment\u2019 deal with the moral orientation of AI. Human moral values are taken as the basis on which the alignment should take place. (Ammanabrolu et al., 2022; Hendrycks et al., 2021; Liu et al., 2022; Tay et al., 2020)"
        },
        {
            "heading": "A.2 Analyses",
            "text": "This work primarily relates to the \u2018Delphi Model\u2019 (Jiang et al., 2021a,b) and analyses the approach to making automatic moral judgements. (Fraser et al., 2022; Talat et al., 2021, 2022)"
        },
        {
            "heading": "A.3 Data Sets",
            "text": "Within this category are papers that focus primarily on constructing a \u2018moral data set\u2019. These papers can be divided into two approaches. On the one hand, papers based on Moral Foundation Theory (Graham et al., 2013) extend the Moral Foundation Dictionary. (Matsuo et al., 2019; Hopp et al., 2020; Araque et al., 2020)\nA second group of papers deals with more general datasets, such as Twitter, Reddit, or datasets created by annotators. All documents in this superordinate category have in common that they are in some way related to moral values, norms or ethics and can be used for morality in NLP. (Guan et al., 2022; Hendrycks et al., 2020; Stranisci et al., 2021; Rzepka and Araki, 2012; Sap et al., 2020; Hoover et al., 2019; Emelin et al., 2021; Lourie et al., 2021; Forbes et al., 2020; Trager et al., 2022; Ziems et al., 2022)"
        },
        {
            "heading": "A.4 Ethical Advisor",
            "text": "Papers in this category present models intended to act as ethical advisors. These papers have in common that they propose a model that should be able to make moral decisions and advise the user on whether the decision is \u2018good\u2019 or \u2018bad\u2019. The models in this category are primarily trained on descriptive approaches and are then supposed to be able to make normative judgements. (Zhao et al., 2021; Peng et al., 2019; Bang et al., 2022; Jiang et al., 2021a,b; Gu et al., 2022; Komuda et al., 2013; Jin et al., 2022; Anderson et al., 2006)"
        },
        {
            "heading": "A.5 Ethical Judgement",
            "text": "Papers in this category present models trained to make moral judgements based on descriptive data and produce their normative judgements as output.\nSimilar to papers in the \u2018Ethical Advisor\u2019 category, this category also faces the \u2018is-ought\u2019 problem. (Shen et al., 2022; Yamamoto and Hagiwara, 2014; Efstathiadis et al., 2022; Alhassan et al., 2022)"
        },
        {
            "heading": "A.6 Ethics Classification",
            "text": "Papers in this category are concerned with classifying moral reasoning within the three prominent families of ethics, deontology, consequentialism and virtue ethics. (Mainali et al., 2020)"
        },
        {
            "heading": "A.7 Generation of Moral Text",
            "text": "This category includes papers that deal with generating and analysing moral arguments. (Alshomary et al., 2022)"
        },
        {
            "heading": "A.8 Moral Bias",
            "text": "Papers in this category represent work to analyse and map the moral bias of large language models such as BERT (Devlin et al., 2018). Due to the underlying training data, language models have their own \u2018moral compass\u2019, which can be mapped. At the same time, the approaches are to be used to reduce moral bias. (Schramowski et al., 2019; Jentzsch et al., 2019; H\u00e4mmerl et al., 2022a; Schramowski et al., 2022; H\u00e4mmerl et al., 2022b; Schramowski et al., 2020)"
        },
        {
            "heading": "A.9 Moral Decision Making",
            "text": "Papers in the category \u2018Moral Decision Making\u2019 are primarily concerned with modelling the process of moral decision-making and attempting to reconstruct it. These papers propose frameworks on how to model moral decisions. (Hromada, 2015; Dehghani et al., 2008)"
        },
        {
            "heading": "A.10 Moral Sentiment",
            "text": "These papers analyse moral sentiment and thus focus on the emotional polarity of a text or statement. This usually involves a classification into \u2018positive\u2019, \u2018neutral\u2019, and \u2018bad\u2019. (Rzepka and Araki, 2015; Mooijman et al., 2018; Ramezani et al., 2021; Garten et al., 2016; Otani and Hovy, 2019; Xie et al., 2019; Qian et al., 2021; Kobbe et al., 2020; Roy et al., 2021)"
        },
        {
            "heading": "A.11 Moral Stance",
            "text": "Papers dealing with moral stances focus on expressing the speaker\u2019s point of view and judgment concerning a particular statement. These papers focus on identifying a person\u2019s moral standpoint on a topic. (Roy and Goldwasser, 2021; Botzer\net al., 2022; Santos and Paraboni, 2019; Pavan et al., 2020)"
        },
        {
            "heading": "A.12 Quantification",
            "text": "Under the broad category of \u2018quantification\u2019 fall all papers that measure \u2018morality\u2019 or \u2018ethics\u2019 in some way. These papers cannot be assigned to one of the other categories, as new terms and metrics are often introduced. The only thing they have in common is the quantification of \u2018morality\u2019. (Kim and Lee, 2020; Zhao et al., 2022; Sagi and Dehghani, 2013; Mutlu et al., 2020; Hulpus, et al., 2020; Nokhiz and Li, 2017; Penikas et al., 2021; Kennedy et al., 2021; Xie et al., 2020; Xu and Guo, 2023; Kaur and Sasahara, 2016)\nA.13 Value Prediction All work to classify moral values falls under this category. Most of these papers are based on Moral Foundation Theory, with a few exceptions (see \u00a7 4). (van den Broek-Altenburg et al., 2021; Altuntas et al., 2022; Rezapour et al., 2019b; van Luenen, 2020; Rezapour et al., 2019a; Vecerdea, 2021; Lan and Paraboni, 2022; Asprino et al., 2022; Constantinescu, 2021; Arsene, 2021; Dondera, 2021; Lin et al., 2018; Huang et al., 2022; Liscio et al., 2022; Pavan et al., 2023; Mokhberian et al., 2020; Teernstra et al., 2016; Johnson and Goldwasser, 2019; Maheshwari et al., 2017; Gloor et al., 2022; Alfano et al., 2018; Dahlmeier, 2014; Kiesel et al., 2022; Johnson and Goldwasser, 2018)\nB Validation Task\n1. Is the topic of the paper related to the concepts of \u2018natural language processing\u2019 (NLP) and \u2018morality\u2019? (e.g. the paper uses methods or algorithms of NLP and deals with for example moral judgement, values, norms, morality, or ethics) - yes no\n2. Does the paper state/use any philosophical foundations (e.g. underlying ethics family <deontology, consequentialism, virtue ethics>, definitions of morality or familiar terms used)? - yes (please specify) no\n3. Does the paper state/use any psychological foundations (e.g. \u2018Moral Foundation Theory\u2019 or \u2018Schwartz Value Theory\u2019) - yes (please specify) no\n4. Does this paper deal with the classification of moral values, norms or other concepts related to \u2018morality\u2019 in general? - yes (please specify what is classified) no\n5. Does the paper propose a new framework to measure or quantify morality or related concepts? - yes (please specify the name of the proposed framework and what is quantified) no\n6. Does the paper investigate ethical or moral bias in models? - yes no\n7. Is the paper concerned with the alignment of human values? (e.g. does the paper use morality or moral values as a way to align AI with human values?) - yes no\n8. Does the paper analyse moral sentiment or moral stance? - yes no\n9. Does the paper try to model moral decision making? - yes no\n10. Does this paper present some kind of ethical advisor, i.e. an algorithm which is able to answer questions relating to morality or generate moral judgements? - yes no\n11. Does the paper make any predictions regarding human values or moral judgement which go beyond mere classification of such? (E.g. is the model able to make its own moral judgements?) - yes (please specify in what ways) no\n12. Does the paper introduce a new data set? - yes (please name) no\n13. Which data source(s) does the paper use? - Twitter Reddit MFD other (please specify) not stated\n14. Which language(s) are processed? - English other (please specify)"
        },
        {
            "heading": "C Overview of Datasets used",
            "text": ""
        },
        {
            "heading": "Dataset Used in",
            "text": "ANECDOTES (Lourie et al., 2021) (Shen et al., 2022) BR Moral Corpus (Pavan et al., 2020) (Lan and Paraboni, 2022)"
        },
        {
            "heading": "DILEMMAS",
            "text": "(Lourie et al., 2021) (Shen et al., 2022)"
        },
        {
            "heading": "ETHICS",
            "text": "(Hendrycks et al., 2020) (Jiang et al., 2021a,b; Liu et al., 2022; Gu et al., 2022) (Ammanabrolu et al., 2022) extended Moral Foundation Dictionary (Hopp et al., 2020) (Mutlu et al., 2020; Ziems et al., 2022; Rezapour et al., 2019a) Helpful, Honest & Harmless (Askell et al., 2021) (Liu et al., 2022) Japanese Lexicon (Rzepka and Araki, 2012) Japanese MFD (Matsuo et al., 2019) MACS (Tay et al., 2020) MoralConvIta (Stranisci et al., 2021) MoralExceptQA (Jin et al., 2022)\nMoral Foundation Dictionary https://moralfoundations.org/\n(Mutlu et al., 2020; Xie et al., 2019; Qian et al., 2021; Hulpus, et al., 2020) (Kennedy et al., 2021; van den Broek-Altenburg et al., 2021; Nokhiz and Li, 2017) (Rezapour et al., 2019b; Lin et al., 2018) (Johnson and Goldwasser, 2018) (Rezapour et al., 2019a; Sagi and Dehghani, 2013; Penikas et al., 2021)\nMoral Foundation Reddit Corpus (Trager et al., 2022)\nMoral Foundation Twitter Corpus (Hoover et al., 2019)\n(Trager et al., 2022; Constantinescu, 2021; Lan and Paraboni, 2022) (Dondera, 2021; Araque et al., 2020; Asprino et al., 2022) (Ramezani et al., 2021; Huang et al., 2022) (Roy and Goldwasser, 2021; Vecerdea, 2021) (Liscio et al., 2022; van Luenen, 2020; Arsene, 2021)\nMoral Strength (Araque et al., 2020) Moral Stories (Emelin et al., 2021) (Gu et al., 2022; Jiang et al., 2021a,b; Liu et al., 2022) (Bang et al., 2022; Zhao et al., 2022; Ammanabrolu et al., 2022) RealToxicityPrompts (Gehman et al., 2020) (Liu et al., 2022; Schramowski et al., 2022)"
        },
        {
            "heading": "SCRUPLES",
            "text": "(Lourie et al., 2021) (Jiang et al., 2021a,b; Ammanabrolu et al., 2022)"
        },
        {
            "heading": "SOCIAL-CHEM-101",
            "text": "(Forbes et al., 2020) (Gu et al., 2022; Emelin et al., 2021; Jiang et al., 2021a,b) (Ziems et al., 2022; ?; Bang et al., 2022; Shen et al., 2022; Ammanabrolu et al., 2022) SOCIAL BIAS INFERENCE CORPUS (Sap et al., 2020) (Jiang et al., 2021a,b; Ammanabrolu et al., 2022) STORAL (Guan et al., 2022) Story Commonsense (Rashkin et al., 2018) (Gu et al., 2022) TrustfulQA (Lin et al., 2021) (Liu et al., 2022)\nTable 4: Overview of the different datasets used."
        },
        {
            "heading": "D Overview of Labels",
            "text": ""
        },
        {
            "heading": "Label Sub-Labels N",
            "text": "Data Sets\nANNECDOTES, AITA Dataset, BR Moral Corpus, Common Sense Norm Bank, DILEMMAS, ETHICS, Helpful, Honest & Harmless, MACS, MFD, Moral Integrity Corpus, Moral Stories, MoralConvITA, MoralExceptQA, NYT, RealToxicityPrompts, ROCStories, SCRUPLES, Social Bias Inference Corpus, Social-Chem-101, STORAL, Story Commonsense, Trustful QA\n214\nDefinitions Definitions, No Definitions 107 Ethics Family Consequentialism, Deontology, Virtue Ethics, ANY: Virtue Ethics Deontology Consequentialism (AC) 228 Goals Classification, Data Set Introduction, Dimensions, Generation, Framework, Prediction 550 Interesting Passages 176 Keywords Consequentialism, Deontology, Ethical/Ethics, Ethical Judgement, Inductive Paper, Moral Choice, Moral Judgement, Moral NLP, Moral Norms, Moral NLP, Morality, Utilitarianism, Virtues 285 Language 38 Methodology Assumptions, Caution Statement, Motivation 250 Model 106 Moral Psychology Cheng & Fleischmann, DOSPERT Values, Kohlberg\u2019s Theory, Moral Foundation Theory, NEO FFI-R personality survey, Schwartz Values Theory, Shweder Big Three, Moral Foundation Theory (AC) 231 Philosophical Terms Applied Ethics, Common Sense Knowledge, Descriptive Ethics, Ethical X, Ethics, Moral, Moral X, Morality, Moral Philosophy, Normative Ethics, Norms, Virtue/Vice 748\nProposed Frameworks AISocrates, CAMILLA, Delphi, DREAM, Frame-based Value Detector Model, GALAD, Jimminy Cricket Environment, Moral Choice Machine, MoralCOT, MoralDirection Framework, MoralDM, MoralScore, Morality Frames, Ned, Neural Norm Transformer, Project Debater, SENSEI, The Morality Machine\n46"
        }
    ],
    "title": "Values, Ethics, Morals? On the Use of Moral Concepts in NLP Research",
    "year": 2023
}