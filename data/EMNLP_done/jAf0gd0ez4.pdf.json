{
    "abstractText": "Users interact with text, image, code, or other editors on a daily basis. However, machine learning models are rarely trained in the settings that reflect the interactivity between users and their editor. This is understandable as training AI models with real users is not only slow and costly, but what these models learn may be specific to user interface design choices. Unfortunately, this means most of the research on text, code, and image generation has focused on non-interactive settings, whereby the model is expected to get everything right without accounting for any input from a user who may be willing to help. We introduce a new Interactive Text Generation task that allows training generation models interactively without the costs of involving real users, by using user simulators that provide edits that guide the model towards a given target text. We train our interactive models using Imitation Learning, and our experiments against competitive non-interactive generation models show that models trained interactively are superior to their non-interactive counterparts, even when all models are given the same budget of user inputs or edits.",
    "authors": [
        {
            "affiliations": [],
            "name": "Felix Faltings"
        },
        {
            "affiliations": [],
            "name": "Michel Galley"
        },
        {
            "affiliations": [],
            "name": "Kiant\u00e9 Brantley"
        },
        {
            "affiliations": [],
            "name": "Baolin Peng"
        },
        {
            "affiliations": [],
            "name": "Weixin Cai"
        },
        {
            "affiliations": [],
            "name": "Yizhe Zhang"
        },
        {
            "affiliations": [],
            "name": "Jianfeng Gao"
        },
        {
            "affiliations": [],
            "name": "Bill Dolan"
        }
    ],
    "id": "SP:bfdf919f1322853398c526a21eaf457ca7bdacd9",
    "references": [
        {
            "authors": [
                "Nader Akoury",
                "Shufan Wang",
                "Josh Whiting",
                "Stephen Hood",
                "Nanyun Peng",
                "Mohit Iyyer."
            ],
            "title": "Storium: A dataset and evaluation platform for machine-in-the-loop story generation",
            "venue": "arXiv preprint arXiv:2010.01717.",
            "year": 2020
        },
        {
            "authors": [
                "Yejin Bang",
                "Samuel Cahyawijaya",
                "Nayeon Lee",
                "Wenliang Dai",
                "Dan Su",
                "Bryan Wilie",
                "Holy Lovenia",
                "Ziwei Ji",
                "Tiezheng Yu",
                "Willy Chung"
            ],
            "title": "A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity",
            "year": 2023
        },
        {
            "authors": [
                "Nicholas J. Belkin",
                "Colleen Cool",
                "Adelheit Stein",
                "Ulrich Thiel."
            ],
            "title": "Cases, scripts, and informationseeking strategies: On the design of interactive information retrieval systems",
            "venue": "Expert Systems With Applications, 9:379\u2013395.",
            "year": 1995
        },
        {
            "authors": [
                "Emily M. Bender",
                "Timnit Gebru",
                "Angelina McMillanMajor",
                "Shmargaret Shmitchell"
            ],
            "title": "On the dangers of stochastic parrots: Can language models be too big",
            "venue": "Proceedings of the 2021 ACM Conference on Fairness, Accountability,",
            "year": 2021
        },
        {
            "authors": [
                "Lucia Zheng",
                "Kaitlyn Zhou",
                "Percy Liang."
            ],
            "title": "On the opportunities and risks of foundation models",
            "venue": "ArXiv, abs/2108.07258.",
            "year": 2021
        },
        {
            "authors": [
                "Morikawa",
                "Alec Radford",
                "Matthew Knight",
                "Miles Brundage",
                "Mira Murati",
                "Katie Mayer",
                "Peter Welinder",
                "Bob McGrew",
                "Dario Amodei",
                "Sam McCandlish",
                "Ilya Sutskever",
                "Wojciech Zaremba."
            ],
            "title": "Evaluating large language models trained on code",
            "venue": "arXiv.",
            "year": 2021
        },
        {
            "authors": [
                "Elizabeth Clark",
                "Anne Spencer Ross",
                "Chenhao Tan",
                "Yangfeng Ji",
                "Noah A Smith."
            ],
            "title": "Creative writing with a machine in the loop: Case studies on slogans and stories",
            "venue": "23rd International Conference on Intelligent User Interfaces, pages 329\u2013340.",
            "year": 2018
        },
        {
            "authors": [
                "J. Dhamala",
                "Tony Sun",
                "Varun Kumar",
                "Satyapriya Krishna",
                "Yada Pruksachatkun",
                "Kai-Wei Chang",
                "Rahul Gupta."
            ],
            "title": "BOLD: Dataset and metrics for measuring biases in open-ended language generation",
            "venue": "Proceedings of the 2021 ACM Conference on",
            "year": 2021
        },
        {
            "authors": [
                "Wanyu Du",
                "Zae Myung Kim",
                "Vipul Raheja",
                "Dhruv Kumar",
                "Dongyeop Kang."
            ],
            "title": "Read, revise, repeat: A system demonstration for humanin-the-loop iterative text revision",
            "venue": "arXiv preprint arXiv:2204.03685.",
            "year": 2022
        },
        {
            "authors": [
                "Wanyu Du",
                "Vipul Raheja",
                "Dhruv Kumar",
                "Zae Myung Kim",
                "Melissa Lopez",
                "Dongyeop Kang."
            ],
            "title": "Understanding iterative revision from human-written text",
            "venue": "ArXiv, abs/2203.03802.",
            "year": 2022
        },
        {
            "authors": [
                "Felix Faltings",
                "Michel Galley",
                "Gerold Hintz",
                "Chris Brockett",
                "Chris Quirk",
                "Jianfeng Gao",
                "Bill Dolan."
            ],
            "title": "Text editing by command",
            "venue": "NAACL-HLT.",
            "year": 2021
        },
        {
            "authors": [
                "Angela Fan",
                "Mike Lewis",
                "Yann Dauphin."
            ],
            "title": "Strategies for structuring story generation",
            "venue": "ACL.",
            "year": 2019
        },
        {
            "authors": [
                "Katja Filippova."
            ],
            "title": "Controlled hallucinations: Learning to generate faithfully from noisy data",
            "venue": "Findings of EMNLP.",
            "year": 2020
        },
        {
            "authors": [
                "William A. Gale",
                "Kenneth Ward Church"
            ],
            "title": "A program for aligning sentences in bilingual corpora",
            "venue": "Computational linguistics,",
            "year": 1994
        },
        {
            "authors": [
                "Jianfeng Gao",
                "Michel Galley",
                "Lihong Li."
            ],
            "title": "Neural approaches to conversational AI",
            "venue": "Foundations and Trends in Information Retrieval, 13(2-3):127\u2013298.",
            "year": 2019
        },
        {
            "authors": [
                "Jianfeng Gao",
                "Chenyan Xiong",
                "Paul Bennett",
                "Nick Craswell."
            ],
            "title": "Neural approaches to conversational information retrieval",
            "venue": "arXiv.",
            "year": 2022
        },
        {
            "authors": [
                "Samuel Gehman",
                "Suchin Gururangan",
                "Maarten Sap",
                "Yejin Choi",
                "Noah A. Smith."
            ],
            "title": "RealToxicityPrompts: Evaluating neural toxic degeneration in language models",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages",
            "year": 2020
        },
        {
            "authors": [
                "Marjan Ghazvininejad",
                "Xing Shi",
                "Yejin Choi",
                "Kevin Knight."
            ],
            "title": "Generating topical poetry",
            "venue": "EMNLP.",
            "year": 2016
        },
        {
            "authors": [
                "Zhibin Gou",
                "Zhihong Shao",
                "Yeyun Gong",
                "Yelong Shen",
                "Yujiu Yang",
                "Nan Duan",
                "Weizhu Chen."
            ],
            "title": "Critic: Large language models can self-correct with tool-interactive critiquing",
            "venue": "arXiv preprint arXiv:2305.11738.",
            "year": 2023
        },
        {
            "authors": [
                "Jiatao Gu",
                "Changhan Wang",
                "Junbo Zhao."
            ],
            "title": "Levenshtein transformer",
            "venue": "Advances in Neural Information Processing Systems, 32.",
            "year": 2019
        },
        {
            "authors": [
                "Kelvin Guu",
                "Tatsunori B Hashimoto",
                "Yonatan Oren",
                "Percy Liang."
            ],
            "title": "Generating sentences by editing prototypes",
            "venue": "Transactions of the Association for Computational Linguistics, 6:437\u2013450.",
            "year": 2018
        },
        {
            "authors": [
                "Assaf Hallak",
                "Dotan Di Castro",
                "Shie Mannor."
            ],
            "title": "Contextual markov decision processes",
            "venue": "arXiv preprint arXiv:1502.02259.",
            "year": 2015
        },
        {
            "authors": [
                "Wei He",
                "Zhongjun He",
                "Hua Wu",
                "Haifeng Wang."
            ],
            "title": "Improved neural machine translation with smt features",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, 30(1).",
            "year": 2016
        },
        {
            "authors": [
                "Hengyuan Hu",
                "Denis Yarats",
                "Qucheng Gong",
                "Yuandong Tian",
                "Mike Lewis."
            ],
            "title": "Hierarchical decision making by generating and following natural language instructions",
            "venue": "NeurIPS.",
            "year": 2019
        },
        {
            "authors": [
                "Jiaxin Huang",
                "Shixiang Shane Gu",
                "Le Hou",
                "Yuexin Wu",
                "Xuezhi Wang",
                "Hongkun Yu",
                "Jiawei Han."
            ],
            "title": "Large language models can self-improve",
            "venue": "arXiv preprint arXiv:2210.11610.",
            "year": 2022
        },
        {
            "authors": [
                "Parag Jain",
                "Priyanka Agrawal",
                "Abhijit Mishra",
                "Mohak Sukhwani",
                "Anirban Laha",
                "Karthik Sankaranarayanan."
            ],
            "title": "Story generation from sequence of independent short descriptions",
            "venue": "ArXiv, abs/1707.05501.",
            "year": 2017
        },
        {
            "authors": [
                "Ziwei Ji",
                "Nayeon Lee",
                "Rita Frieske",
                "Tiezheng Yu",
                "Dan Su",
                "Yan Xu",
                "Etsuko Ishii",
                "Yejin Bang",
                "Andrea Madotto",
                "Pascale Fung."
            ],
            "title": "Survey of hallucination in natural language generation",
            "venue": "ArXiv, abs/2202.03629.",
            "year": 2022
        },
        {
            "authors": [
                "Keenan Jones",
                "Enes Altuncu",
                "Virginia N.L. Franqueira",
                "Yichao Wang",
                "Shujun Li."
            ],
            "title": "A comprehensive survey of natural language generation advances from the perspective of digital deception",
            "venue": "arXiv.",
            "year": 2022
        },
        {
            "authors": [
                "Svetlana Kiritchenko",
                "Isar Nejadgholi",
                "Kathleen C. Fraser."
            ],
            "title": "Confronting abusive language online: A survey from the ethical and human rights perspective",
            "venue": "ArXiv, abs/2012.12305.",
            "year": 2021
        },
        {
            "authors": [
                "Ahmed Hassan Awadallah."
            ],
            "title": "Interactive grounded language understanding in a collaborative environment: IGLU 2021",
            "venue": "NeurIPS 2021 Competitions and Demonstrations Track, pages 146\u2013161. PMLR.",
            "year": 2022
        },
        {
            "authors": [
                "Shuvendu K. Lahiri",
                "Aaditya Naik",
                "Georgios Sakkas",
                "Piali Choudhury",
                "Curtis von Veh",
                "Madanlal Musuvathi",
                "Jeevana Priya Inala",
                "Chenglong Wang",
                "Jianfeng Gao"
            ],
            "title": "Interactive code generation via test-driven user-intent formalization",
            "year": 2022
        },
        {
            "authors": [
                "Jason Lee",
                "Elman Mansimov",
                "Kyunghyun Cho."
            ],
            "title": "Deterministic non-autoregressive neural sequence modeling by iterative refinement",
            "venue": "arXiv.",
            "year": 2018
        },
        {
            "authors": [
                "Mina Lee",
                "Percy Liang",
                "Qian Yang."
            ],
            "title": "CoAuthor: Designing a human-ai collaborative writing dataset for exploring language model capabilities",
            "venue": "CHI.",
            "year": 2022
        },
        {
            "authors": [
                "Lagunas",
                "Alexander Rush",
                "Thomas Wolf."
            ],
            "title": "Datasets: A community library for natural language processing",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 175\u2013184, Online",
            "year": 2021
        },
        {
            "authors": [
                "Xiujun Li",
                "Zachary C Lipton",
                "Bhuwan Dhingra",
                "Lihong Li",
                "Jianfeng Gao",
                "Yun-Nung Chen."
            ],
            "title": "A user simulator for task-completion dialogues",
            "venue": "arXiv preprint arXiv:1612.05688.",
            "year": 2016
        },
        {
            "authors": [
                "Zhiyu Li",
                "Shuai Lu",
                "Daya Guo",
                "Nan Duan",
                "Shailesh Jannu",
                "Grant Jenks",
                "Deep Majumder",
                "Jared Green",
                "Alexey Svyatkovskiy",
                "Shengyu Fu"
            ],
            "title": "CodeReviewer: Pre-training for automating code review activities",
            "venue": "arXiv preprint arXiv:2203.09095",
            "year": 2022
        },
        {
            "authors": [
                "Chin-Yew Lin."
            ],
            "title": "Rouge: A package for automatic evaluation of summaries",
            "venue": "Text summarization branches out, pages 74\u201381.",
            "year": 2004
        },
        {
            "authors": [
                "Hsien-Chin Lin",
                "Christian Geishauser",
                "Shutong Feng",
                "Nurul Lubis",
                "Carel van Niekerk",
                "Michael Heck",
                "Milica Ga\u0161i\u0107."
            ],
            "title": "GenTUS: Simulating user behaviour and language in task-oriented dialogues with generative transformers",
            "venue": "arXiv preprint",
            "year": 2022
        },
        {
            "authors": [
                "Lara J. Martin",
                "Prithviraj Ammanabrolu",
                "William Hancock",
                "S. Singh",
                "Brent Harrison",
                "Mark O. Riedl."
            ],
            "title": "Event representations for automated story generation with deep neural nets",
            "venue": "AAAI.",
            "year": 2017
        },
        {
            "authors": [
                "Kenton Murray",
                "David Chiang."
            ],
            "title": "Correcting length bias in neural machine translation",
            "venue": "Proceedings of the Third Conference on Machine Translation: Research Papers, pages 212\u2013223, Brussels, Belgium.",
            "year": 2018
        },
        {
            "authors": [
                "Ramesh Nallapati",
                "Bowen Zhou",
                "Cicero Nogueira dos santos",
                "Caglar Gulcehre",
                "Bing Xiang."
            ],
            "title": "Abstractive text summarization using sequence-tosequence RNNs and beyond",
            "venue": "Proceedings of the 20th SIGNLL Conference on Computational Natural",
            "year": 2016
        },
        {
            "authors": [
                "Saul B Needleman",
                "Christian D Wunsch."
            ],
            "title": "A general method applicable to the search for similarities in the amino acid sequence of two proteins",
            "venue": "Journal of molecular biology, 48(3):443\u2013453.",
            "year": 1970
        },
        {
            "authors": [
                "Robert N. Oddy."
            ],
            "title": "Information retrieval through man-machine dialogue",
            "venue": "Journal of Documentation, 33:1\u201314.",
            "year": 1977
        },
        {
            "authors": [
                "ter Welinder",
                "Paul Francis Christiano",
                "Jan Leike",
                "Ryan J. Lowe"
            ],
            "title": "Training language models to follow instructions with human feedback. ArXiv, abs/2203.02155",
            "year": 2022
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "BLEU: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311\u2013318.",
            "year": 2002
        },
        {
            "authors": [
                "Maja Popovi\u0107."
            ],
            "title": "chrF: character n-gram F-score for automatic MT evaluation",
            "venue": "Proceedings of the Tenth Workshop on Statistical Machine Translation, pages 392\u2013395.",
            "year": 2015
        },
        {
            "authors": [
                "Matt Post."
            ],
            "title": "A call for clarity in reporting BLEU scores",
            "venue": "Proceedings of the Third Conference on Machine Translation: Research Papers, pages 186\u2013 191, Belgium, Brussels.",
            "year": 2018
        },
        {
            "authors": [
                "Filip Radlinski",
                "Nick Craswell."
            ],
            "title": "A theoretical framework for conversational search",
            "venue": "Proceedings of the 2017 Conference on Conference Human Information Interaction and Retrieval.",
            "year": 2017
        },
        {
            "authors": [
                "Aditya Ramesh",
                "Mikhail Pavlov",
                "Gabriel Goh",
                "Scott Gray",
                "Chelsea Voss",
                "Alec Radford",
                "Mark Chen",
                "Ilya Sutskever."
            ],
            "title": "Zero-shot text-to-image generation",
            "venue": "arXiv.",
            "year": 2021
        },
        {
            "authors": [
                "Hannah Rashkin",
                "Asli Celikyilmaz",
                "Yejin Choi",
                "Jianfeng Gao."
            ],
            "title": "PlotMachines: Outlineconditioned generation with dynamic plot state tracking",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
            "year": 2020
        },
        {
            "authors": [
                "Mark O Riedl",
                "Robert Michael Young."
            ],
            "title": "Narrative planning: Balancing plot and character",
            "venue": "Journal of Artificial Intelligence Research.",
            "year": 2010
        },
        {
            "authors": [
                "Stephane Ross",
                "Geoffrey Gordon",
                "Drew Bagnell."
            ],
            "title": "A reduction of imitation learning and structured prediction to no-regret online learning",
            "venue": "Proc. of AISTATS, pages 627\u2013635. PMLR.",
            "year": 2011
        },
        {
            "authors": [
                "Jost Schatzmann",
                "Blaise Thomson",
                "Karl Weilhammer",
                "Hui Ye",
                "Steve Young."
            ],
            "title": "Agenda-based user simulation for bootstrapping a pomdp dialogue system",
            "venue": "Human Language Technologies 2007: The Conference of the North American Chapter of the As-",
            "year": 2007
        },
        {
            "authors": [
                "Thibault Sellam",
                "Dipanjan Das",
                "Ankur Parikh."
            ],
            "title": "BLEURT: Learning robust metrics for text generation",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7881\u20137892, Online.",
            "year": 2020
        },
        {
            "authors": [
                "Hua Shen",
                "Tongshuang Wu."
            ],
            "title": "Parachute: Evaluating interactive human-lm co-writing systems",
            "venue": "arXiv preprint arXiv:2303.06333.",
            "year": 2023
        },
        {
            "authors": [
                "T. Shen",
                "Victor Quach",
                "R. Barzilay",
                "T. Jaakkola."
            ],
            "title": "Blank language models",
            "venue": "EMNLP.",
            "year": 2020
        },
        {
            "authors": [
                "Temple F Smith",
                "Michael S Waterman"
            ],
            "title": "Identification of common molecular subsequences",
            "venue": "Journal of molecular biology,",
            "year": 1981
        },
        {
            "authors": [
                "Mitchell Stern",
                "William Chan",
                "Jamie Kiros",
                "Jakob Uszkoreit."
            ],
            "title": "Insertion transformer: Flexible sequence generation via insertion operations",
            "venue": "International Conference on Machine Learning, pages 5976\u20135985. PMLR.",
            "year": 2019
        },
        {
            "authors": [
                "Richard S. Sutton",
                "Andrew G. Barto."
            ],
            "title": "Introduction to Reinforcement Learning",
            "venue": "The MIT Press.",
            "year": 1998
        },
        {
            "authors": [
                "Robert S. Taylor."
            ],
            "title": "Question-negotiation and information seeking",
            "venue": "Coll. Res. Libr.",
            "year": 1968
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141 ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "NeurIPS.",
            "year": 2017
        },
        {
            "authors": [
                "Birhane",
                "Julia Haas",
                "Laura Rimell",
                "Lisa Anne Hendricks",
                "William S. Isaac",
                "Sean Legassick",
                "Geoffrey Irving",
                "Iason Gabriel."
            ],
            "title": "Ethical and social risks of harm from language models",
            "venue": "ArXiv.",
            "year": 2021
        },
        {
            "authors": [
                "Lindsay Weinberg."
            ],
            "title": "Rethinking fairness: An interdisciplinary survey of critiques of hegemonic ML fairness approaches",
            "venue": "J. Artif. Intell. Res., 74:75\u2013109.",
            "year": 2022
        },
        {
            "authors": [
                "Johannes Welbl",
                "Amelia Glaese",
                "Jonathan Uesato",
                "Sumanth Dathathri",
                "John F.J. Mellor",
                "Lisa Anne Hendricks",
                "Kirsty Anderson",
                "Pushmeet Kohli",
                "Ben Coppin",
                "Po-Sen Huang."
            ],
            "title": "Challenges in detoxifying language models",
            "venue": "ArXiv, abs/2109.07445.",
            "year": 2021
        },
        {
            "authors": [
                "Sean Welleck",
                "Kiant\u00e9 Brantley",
                "Hal Daum\u00e9 Iii",
                "Kyunghyun Cho."
            ],
            "title": "Non-monotonic sequential text generation",
            "venue": "International Conference on Machine Learning, pages 6716\u20136726. PMLR.",
            "year": 2019
        },
        {
            "authors": [
                "Sean Welleck",
                "Ximing Lu",
                "Peter West",
                "Faeze Brahman",
                "Tianxiao Shen",
                "Daniel Khashabi",
                "Yejin Choi."
            ],
            "title": "Generating sequences by learning to self-correct",
            "venue": "ArXiv, abs/2211.00053.",
            "year": 2022
        },
        {
            "authors": [
                "Sam Wiseman",
                "Stuart Shieber",
                "Alexander Rush."
            ],
            "title": "Challenges in data-to-document generation",
            "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2253\u20132263, Copenhagen, Denmark.",
            "year": 2017
        },
        {
            "authors": [
                "Scao",
                "Sylvain Gugger",
                "Mariama Drame",
                "Quentin Lhoest",
                "Alexander M. Rush."
            ],
            "title": "Transformers: State-of-the-art natural language processing",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System",
            "year": 2020
        },
        {
            "authors": [
                "Canwen Xu",
                "Zexue He",
                "Zhankui He",
                "Julian McAuley."
            ],
            "title": "Leashing the inner demons: Selfdetoxification for language models",
            "venue": "AAAI.",
            "year": 2022
        },
        {
            "authors": [
                "Weijia Xu",
                "Marine Carpuat."
            ],
            "title": "Editor: an editbased transformer with repositioning for neural machine translation with soft lexical constraints",
            "venue": "Transactions of the Association for Computational Linguistics, 9:311\u2013328.",
            "year": 2021
        },
        {
            "authors": [
                "Rui Yan."
            ],
            "title": "i, poet: Automatic poetry composition through recurrent neural networks with iterative polishing schema",
            "venue": "IJCAI.",
            "year": 2016
        },
        {
            "authors": [
                "Pengcheng Yin",
                "Graham Neubig",
                "Miltiadis Allamanis",
                "Marc Brockschmidt",
                "Alexander L Gaunt."
            ],
            "title": "Learning to represent edits",
            "venue": "arXiv preprint arXiv:1810.13337.",
            "year": 2018
        },
        {
            "authors": [
                "Weizhe Yuan",
                "Graham Neubig",
                "Pengfei Liu."
            ],
            "title": "BARTScore: Evaluating generated text as text generation",
            "venue": "ArXiv, abs/2106.11520.",
            "year": 2021
        },
        {
            "authors": [
                "Jiyang Zhang",
                "Sheena Panthaplackel",
                "Pengyu Nie",
                "Junyi Jessy Li",
                "Milos Gligoric."
            ],
            "title": "CoditT5: Pretraining for source code and natural language editing",
            "venue": "arXiv preprint arXiv:2208.05446.",
            "year": 2022
        },
        {
            "authors": [
                "Xuchao Zhang",
                "Dheeraj Rajagopal",
                "Michael Gamon",
                "Sujay Kumar Jauhar",
                "ChangTien Lu."
            ],
            "title": "Modeling the relationship between user comments and edits in document revision",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natu-",
            "year": 2019
        },
        {
            "authors": [
                "Yizhe Zhang",
                "Guoyin Wang",
                "Chunyuan Li",
                "Zhe Gan",
                "Chris Brockett",
                "Bill Dolan."
            ],
            "title": "Pointer: Constrained text generation via insertion-based generative pre-training",
            "venue": "ArXiv, abs/2005.00558.",
            "year": 2020
        },
        {
            "authors": [
                "Asli \u00c7elikyilmaz",
                "Elizabeth Clark",
                "Jianfeng Gao."
            ],
            "title": "Evaluation of text generation: A survey",
            "venue": "ArXiv, abs/2006.14799.",
            "year": 2020
        },
        {
            "authors": [
                "Smith"
            ],
            "title": "This score can be easily optimized using dynamic programming (see for example Gale et al",
            "venue": "Needleman and Wunsch",
            "year": 1970
        },
        {
            "authors": [
                "\u03c0\u03b8(stop|a",
                "Sh"
            ],
            "title": "The last line comes from Jensen\u2019s inequality, where the sum over permutations became an expectation. Using the same trick of rearranging the sum over time steps and orderings",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Advances in generative modeling have made it possible to automatically generate high-quality texts (Brown et al., 2020), code (Chen et al., 2021), and images (Ramesh et al., 2021), but these creations can be unsatisfactory in many respects. For example, they often suffer from content errors\u2014e.g., hallucinations (Ji et al., 2022)\u2014that may require help from the user. Even if the generation is of good quality, it may not be the kind of text, code, or image that the user was hoping to obtain. Indeed, open-ended and complex generation tasks are often underspecified (e.g., from a simple prompt), which makes it almost impossible for the model to\n\u2217 Corresponding authors: faltings@mit.edu, {mgalley, jfgao}@microsoft.com. Yizhe Zhang is currently at Apple.\nsatisfy user needs without additional information. Distinguishing the real user need from the need as initially presented to the system has been the focus of decades of research (Taylor, 1968), and usually requires interacting with users to clarify their needs (Gao et al., 2022). Unfortunately, much of the research in generative models have been in \u201cone-shot\u201d settings, which don\u2019t allow any kind of iterative refinements to steer the generation towards what the user really wants.\nThis paper introduces a new end-to-end generation task, Interactive Text Generation, that accounts for interactivity without requiring real users during training. The framework is illustrated in Figure 1, where the model and a \u201cuser\u201d take turns editing the text until a given stopping criterion is met. As this setup would be impractical to train with real users, we rely on a user simulator that provides a few high-quality edits that guide the model towards a given target text. This interspersion of user edits in the generation process allows text generation models to more efficiently use inferential capabilities of large language models (LLM). Contrast interactive text generation in Figure 1 with conventional text generation, where both systems are given exactly three user input words. Interactive text generation leverages LLM\u2019s capability to infer, e.g., \u201cspace-\ncraft\u201d from \u201cNASA\u201d and allows it to focus on parts of the text (e.g., \u201cMonday\u201d) that are more difficult to predict, and this allows the interactive approach to generate text that better meets user\u2019s needs.\nOur work makes the following contributions: \u2022 We propose a task and framework for interactive\ntext generation, and release models, a dataset, and user simulators. Crucially, this task evaluates generation models with the same budget of user inputs or edits, to ensure the comparison between interactive and non-interactive models is fair. \u2022 We present methods to train Transformer-based (Vaswani et al., 2017) interactive text editing models using imitation learning, where our models learn to imitate an expert that dynamically constructs a trajectory from the current document state to the goal state (target document). Our editing models include both autoregressive and non-autoregressive versions, with the nonautoregressive one achieving the best results. \u2022 We show that interactivity indeed does help thanks to imitation learning when compared to their non-interactive counterparts, across different evaluation metrics, model types, and model sizes and with the same amount of user inputs. This finding is consistent with prior work showing that user needs are often best handled interactively (Oddy, 1977; Belkin et al., 1995; Radlinski and Craswell, 2017; Gao et al., 2022), and confirms that our benchmark helps quantify the benefit of interactivity in text generation. \u2022 As user simulation is a key component of this new task, we contribute different user simulators. Our experiments show performance of our models remains consistent with different user simulators, which highlights the robustness of our new benchmark. Another contribution is that text generation in this work is not merely aimed at producing well-formed text, but also at creating text that is tied to user needs. We release this framework with the hope it will help researchers in NLP, Imitation Learning, Reinforcement Learning, and AI in general as it provides an environment to train AI agents that directly interact with users and user simulators.1"
        },
        {
            "heading": "2 Task: Interactive Text Generation",
            "text": "The task introduced in this paper considers a simple setting in which the system and user collaboratively write a document. As our goal is to train\n1Code and models for this paper will be made public.\ngeneration models that can do most of the heavy lifting, this task gives a more directional role to the user, while the bulk of the text is generated by the system. Therefore, our task is similar to the instructor-executor frameworks (Hu et al., 2019; Kiseleva et al., 2022) seen in other tasks. In the case of text generation, motivational examples of such instructor-executor interactions include a student writing a paper while getting occasional feedback from an advisor, or a freelance writer getting instructions from a client.\nOur task models the interaction between a user and system, where the two parties successively take turns making changes to a draft document. As this interaction applies to both training and testing, it would be unrealistic to assume we have real users in both cases, and we therefore rely on user simulators. Although building effective user simulators is notoriously hard in tasks such as dialog (Schatzmann et al., 2007; Li et al., 2016; Lin et al., 2022; Gao et al., 2019), it is less so in our work given how we frame the interactive generation task: We assume that there is a goal text which one can think of as representing the user\u2019s desire or needs. The system does not know the goal, but the user simulator does. The objective of the agent is to get as close to the goal text as possible, while minimizing the number of edits the user simulator needs to make.\nThis framing makes it much easier to design effective user simulators, as a comparison between the current draft and goal text can help infer useful text edits. While agents in this setup are given an advantage by interacting with an oracle that has knowledge of the goal document, the number of oracle edits is generally set to be small, and we ensure comparisons between all models (including non-interactive models) are fair by giving each model the same budget of edits or inputs derived from the goal document."
        },
        {
            "heading": "2.1 Task Formulation",
            "text": "We can formalize our task by the following protocol. There are two players in the game, the agent and user. Starting from a blank document, the players take turns producing drafts over H rounds.2 The user has a goal document G, and the objective of the game is to get as close to the goal as possible. Closeness is quantified by a scoring function\n2Except for index ranges, e.g. t = 1, ..., T , we will use capital letters to denote random variables, and lower case letters to denote realizations.\ns(\u00b7;G), and a tolerance \u03b4 > 0. We denote the agent draft at step h by Ah, and the user draft at step h by Uh. If we then fix a goal document G, the protocol is as follows. For h = 1, ...,H:\n1. User observes Ah\u22121. If s(Ah\u22121;G) > 1\u2212 \u03b4, stop. Otherwise, the user produces Uh according to G and Ah\u22121.\n2. Agent observes Uh and produces Ah.\nHere A0 is a blank document. The tolerance \u03b4 represents how close the agent needs to get to the target for the user to be satisfied. Let T \u2264 H be the time at which the interaction stopped. We evaluate the task by looking at s(AT ;G) and T . The higher s(AT ;G), the better the produced document, and the lower T , the more time the user saved.\nWe assumed here that each instance of the task is parameterized by a goal document G. However, one could instead use multiple goal documents, G1, ..., GM , or even replace s(\u00b7;G) with some general score function s(\u00b7) that is independent of any goal document, which one could think of as a utility function for the user.\nIn this work, we assume that the user behavior is fixed and we will learn an agent policy."
        },
        {
            "heading": "3 User Simulator",
            "text": "This section describes the user simulator used in our work. Throughout this section and the next, we refer the reader to the Appendix for more details.\nWhere appropriate, we indicate references to the appendix in parentheses."
        },
        {
            "heading": "3.1 Edits",
            "text": "Both our simulated user described below, and our model described in Section 4, operate by making edits to a document. We will consider single-word edits of three types: inserting a word, deleting a word, or substituting one word for another. If we denote an edit by e, and a document by x, then y = [e](x) will denote the action of e on document x, producing a new document y. Note that y will differ from x by a single word. If we have multiple single-word edits e1, ..., eN , we can apply them one after another, as in y = [e1...eN ](x)."
        },
        {
            "heading": "3.2 Simulated User",
            "text": "Because the user has knowledge of the goal document G, we can easily define a sensible user simulator. Given a current draft produced by the agent Ah, we can compute sequences of edits e1, ..., eN such that G = [e1...eN ](Ah), as detailed in Section 3.3 below. The user will produce a draft Uh+1 = [e1...en](Ah) only by applying some small number of these edits n \u2264 N , where the edits are chosen according to a heuristic (App. B). An example heuristic would be to pick edits e1, ..., en that insert informative words first. This way, the user provides information to the agent by producing a draft Uh+1 that is a few steps closer to G than Ah. This is like providing a gradient in the direction of G. Note that while this represents one\nway to build a user simulator, our task formulation is completely agnostic to the user behavior.\nIn our experiments we ensure that comparisons between non-interactive and interactive systems are fair by fixing the total number of single-word edits made by the user at N . In the non-interactive case, all N edits are made at the start. In the interactive setting, the N edits are spread out over M rounds of editing, where at each round the user only makes N/M edits."
        },
        {
            "heading": "3.3 Alignments",
            "text": "For any x, y there may be many sequences e1, ..., eN such that y = [e1...eN ](x). There is always such a sequence since we can delete x completely and generate y. Practically, we can compute a set of such sequences of edits e1, ..., eN by finding an alignment between x and y, as illustrated in Figure 2. The alignment defines which words in x map to words in y, and which words were deleted or inserted. Words that match to identical words are conserved, whereas mismatches correspond to substitutions. From there it is easy to get the edits e1, ..., eN that transform x into y. We will denote this set by A(x, y). We use contextual word embeddings from BERT to compute these alignments, so that words in x map to words in y with similar meaning, as we found that this tends to produce more natural alignments (App. A.3)."
        },
        {
            "heading": "4 Imitation Learning Model",
            "text": "The agent policy \u03c0\u03b8 will parameterize a distribution over documents, so that at each step of the interaction we draw Ah \u223c \u03c0\u03b8(\u00b7|Sh). Here Sh is the his-\ntory of drafts (A0, U1), . . . , (Ah\u22121, Uh) exchanged so far. This information is necessary for the agent to make inferences about the goal G. However, this history can become very long, especially since each element is an entire document. Therefore, in practice we only give the policy \u03c0\u03b8 access to the last set of drafts, (Ah\u22121, Uh), which we represent as a diff (App. B), as illustrated in Figure 2."
        },
        {
            "heading": "4.1 Left to Right Autoregressive Model",
            "text": "The first agent model that we consider is a simple sequence to sequence (S2S) model that generates outputs in a left-to-right autoregressive manner,\n\u03c0\u03b8(Ah = a|Sh) = H\u220f i=1 \u03c0\u03b8(ai|a<i, Sh),\nwhere a = (a1, ..., aL) and a<i = (a1, ..., ai\u22121). Note that this model autoregressively generates the new draft from scratch."
        },
        {
            "heading": "4.2 Token Editing Model",
            "text": "While our S2S model forms a reasonable baseline, we note that it is not particularly adapted for the task. Instead, we also propose a token editing model that directly edits the previous draft Uh to produce its revised draft Ah by making a series of edits. This way, both the agent and user operate by making edits. Additionally, we add a stopping action to allow the model to decide when to stop editing. Concretely, we parameterize the model as a distribution over edits (and the stopping action), \u03c0\u03b8(\u00b7|[e1...et\u22121](Uh), Sh). In other words, based on the previous edits it made, and the current state, the model decides what edit to make next. The probability of producing a particular draft a is,\u2211 \u03c4 \u03c0\u03b8(stop|a, Sh) M\u220f k=1 \u03c0\u03b8(ek|[e1...ek\u22121(Uh), Sh),\nwhere the sum is over all sequences of edits \u03c4 = (e1, ..., eM ) such that [e1...eM ](Uh) = a. See Figure 2 for an illustration."
        },
        {
            "heading": "4.3 Training",
            "text": "We train our model to copy an expert policy \u03c0\u03b8 that would perform well in our task. Because this expert is only used at training time, it is very simple: it produces the goal G. See Figure 3 for an illustration. We follow the DAgger (Ross et al., 2011) algorithm as outlined in Algorithm 1, which tries to minimize the following objective:\nL(\u03b8) = EG\u223c\u03bdESh\u223c\u03c0 [\u2212 log \u03c0\u03b8(G|Sh)] ,\nAlgorithm 1: DAgger Initialize \u03c0\u03b8; Initialize D \u2190 \u2205; \u03b2 \u2190 1; repeat\n\u03c0 \u2190 \u03b2\u03c0E + (1\u2212 \u03b2)\u03c0\u03b8; Sample goal documents g1, ..., gC \u223c \u03bd; Sample trajectories from \u03c0 with\ncontexts g1, ..., gC ; Collect B states from sampled\ntrajectories into D; Aggregate D \u2190 D \u222aD; Train policy \u03c0\u03b8 on D; \u03b2 \u2190 \u03bb\u03b2;\nuntil convergence;\nwhere \u03c0 is the roll-in, or sampling policy, \u03bd is a distribution over goals, and the second expectation is over histories produced by running our task protocol with the policy \u03c0 as the agent (App. A.4). Setting \u03c0 to \u03c0\u03b8 would allow us to train on-policy, but since \u03c0\u03b8 will start off as a poor policy that visits many unnecessary states, DAgger uses a mixture between the agent and expert policies, so \u03c0 = \u03b2\u03c0\u2217+(1\u2212\u03b2)\u03c0\u03b8, where \u03b2 \u2208 [0, 1] is annealed to 0 during training."
        },
        {
            "heading": "4.4 Likelihood Estimation",
            "text": "The training objective from Section 4.3 requires the computation of the negative log-likelihood \u2212 log \u03c0\u03b8(G|Sh). For the autoregressive model, this can be directly computed as a simple product as described in Section 4.1. On the other hand, the likelihood for the token editing model involves a sum over sequences of edits which quickly becomes intractable. Instead, we optimize an upper bound on it. Using the alignments defined previously, we can specify a set of edit trajectories, denoted A(Uh, G), that are indexed by permutations \u03c3 \u2208 SM , where M is the length of the edit trajectories (App. A.3). So, an edit trajectory in A(Uh, G) will be written e\u03c31 , ..., e \u03c3 M , and [e \u03c3 1 , ..., e \u03c3 M ](Uh) = G for all \u03c3. We can then assume that most alternative trajectories3 will have low probability, so we restrict the sum to all trajectories in A(Uh, G). For convenience, we will write X\u03c3k = [e \u03c3 1 , ..., e \u03c3 k ](Uh). This gives the\n3For example the infinite number of trajectories that involve inserting and deleting the same word.\nupper bound (App. A.5),\n\u2212EkE\u03c31:k M + 1 nk \u2211 \u03c3k+1 log \u03c0\u03b8(e \u03c3 k+1|X\u03c3k , Sh)  , where the two expectations are over uniform distributions, and nk is the number of terms in the sum. The first expectation ranges over prefixes of edit sequences e\u03c31 , ..., e \u03c3 k for \u03c3 \u2208 SM , and the sum ranges of over distinct edits e\u03c3k+1. In words, this objective says that we select a random number k of edits, in random order \u03c3, that move us toward G, giving us the intermediate draft X\u03c3k . We then try to predict the next edit that brings us closer to G. We evaluate this objective stochastically as described in Algorithm 2 (App. A.5)."
        },
        {
            "heading": "4.5 Decoding",
            "text": "When decoding from the autoregressive model, we use standard algorithms such as beam search. For the token editing model, we sequentially sample edits from the model until the model\u2019s probability of stopping reaches a given threshold or we exceed a maximum number of decoding steps. If we hit the timeout, we return the draft that had the highest stopping probability according to the model. This ensures that whatever draft the agent returns it is highly confident that it is a finished document. For example, if the model were editing \u201cthe man\u201d into \u201cthe man and the dog\u201d, we would not want to stop and return the draft \u201cthe man the dog\u201d where the model hasn\u2019t yet added the word \u201cand\u201d. Algorithm 4 outlines this procedure (App. A.7)."
        },
        {
            "heading": "5 Experiments",
            "text": "Because of the novelty of our task, the main goal of our experiments is to assess the benefit of interactivity in text generation. We also provide example interactions between the learned agent and user simulator. Ablations and additional details on experiment settings are in the appendix."
        },
        {
            "heading": "5.1 Setup",
            "text": "Data We consider single sentences from CNN/DailyMail article summaries (Nallapati et al., 2016). While we only consider single sentences for ease of implementation, we can extend our models to full documents in a straightforward way. Using news articles gives complex and factually grounded sentences, while restricting our attention to the summaries keeps the sentences\nself-contained. This dataset forms the distribution over goal documents G.\nModel We implement our models using pretrained transformer models, with additional MLP heads to predict the edit actions in the case of the token editing model.\nMetrics We evaluated generation using BLEU (Papineni et al., 2002), CHRF (Popovic\u0301, 2015) BLEURT (Sellam et al., 2020), BARTSCORE (Yuan et al., 2021), and ROUGE (Lin, 2004). As BARTSCORE returns a score interpretable as a logprobability, we report the natural exponent of that score. In the case of both BLEU and ROUGE, we evaluate with their unigram versions (BLEU-1 and ROUGE-1) as they provide interpretability of the results at the token level."
        },
        {
            "heading": "5.2 Interactivity",
            "text": "To probe whether interactivity helps, we compared the performance of our model given different levels of interactivity. Concretely, we take a fixed number of edits N provided by the user, and compare the performance of the model when those edits are provided over a varying number of episodes M . Thus, for given M , the user and agent interact over M episodes, with the user making N/M edits at each episode. Note that the total amount of information provided by the user in each setting is thus the same. The only difference is that in interactive settings the agent is able to make changes in between receiving edits from the user. While this setup is not able to probe the advantages that interactivity provides in terms of human-computer interaction, we still expect to see better performance in the interactive case. For example, the model may be able to preempt some of the edits the user makes, allowing the user to use its budget to make other edits."
        },
        {
            "heading": "6 Results",
            "text": "Automatic evaluation Figure 4 presents our main results on interactivity. We can see that for our main model, splitting the same number of user edits over more episodes leads to better scores across BLEU, BLEURT and BERTSCORE. For example, comparing the setting where the model receives all 6 user edits at the start in one episode, against the setting where the edits are given across 3 episodes, we see improvements of about 7%, 4% and 5% (absolute % gains) in terms of BLEU, BLEURT, and BERTSCORE respectively. While these differences are not large in absolute terms, we emphasize that this gain comes exclusively from interactivity. The amount of information given to the model is the same in both settings. This suggests that, even in this narrow sense, interactivity helps. Note that there may also be many more benefits from a human-computer interaction standpoint that we cannot quantify here.\nWe also note that our token editing model (Editor) outperforms the left-to-right, autoregressive sequence to sequence (S2S) model4. While the difference is not staggering, it is notable given the success of standard S2S models across a variety of text generation tasks. As motivated in Section 4, the token editing model is more naturally suited to the task, and we argue that it constitutes the starting point for more interesting interactive models. For example, one could foresee training the model using reinforcement learning, in which case\n4In the case of the S2S model, we added a word reward feature (He et al., 2016), which is sometimes called \u201clength penalty\u201d. We tuned this feature on a validation set of 500 instances. We added this feature due to the observation that S2S outputs in our task are often too short, which has been noted in other tasks such as machine translation (Murray and Chiang, 2018). This feature was only necessary with the S2S model, and resulted in the three models of Figure 4 having average lengths close to one another (within 6%).\nthe structure of the editing model based on editing actions is better suited than a S2S model.\nHuman evaluation We conducted a human evaluation (Table 1) to compare interactive and noninteractive generation, similar to the automatic evaluation in Figure 4. We selected the best-performing model (BART Large) and compared 3-episode generation against 1 episode on 1k test instances. Each instance was evaluated by 5 mechanical turkers. The judges were asked to compare each pair of generations based on semantic similarity to the gold text (\u201cmeaning\u201d) and linguistic quality (\"fluency\") using a 5-point Likert scale. Table 1 shows that interactivity improves performance, as the interactive system is generally semantically closer to the target (significance at p < 1e\u2212 7). The interactive system exhibits slightly lower fluency on average, although the level of significance is weaker here (p = .037). We hypothesize this slight decrease in fluency is due to multiple rounds of generation.\nAblations We provide extensive ablations of model variants. As a benchmark for comparison, we look at the quality of the text produced by our models after interacting with the user over several episodes. For better comparisons we use a fixed number of episodes and a fixed number of user edits per episode. We use 3 edits and 4 episodes. Tables 2 and 3 present our ablations. Note that these results use 4 episodes, with 3 user hints per episode (a total of 12 user hints) compared to the 6 total user hints in Figure 4, so the overall results are higher.\nThe baseline model is trained with a noise level of \u03c3 = 0.3, an unrestricted user and a sampling annealing rate of 0.9. All models in Table 2 were evaluated with the adjacent and contiguous user heuristics. Table 2 presents variations on training parameters. The noise level is the amount of noise injected during training, the user is the (sole) heuristic used for the user during training, and the\nsampling annealing rate indicates how quickly we anneal from the expert to the trained model while sampling (lower is faster). Table 3 compares different user heuristics at test time.\nWe note that adding noise during training improves results (e.g. noise level 0.1 vs. 0.0), while annealing too fast can hurt performance (annealing rate 0.8 vs. baseline). Interestingly, training with a user that better matches the inference-time user leads to worse performance (e.g. adj+contig vs. baseline). It seems that using the most informative user (which simply returns the most informative edits, without restriction) leads to the best model (baseline). Comparing different user simulators at inference time, we see that adding restrictions to the user leads to decreased scores, as expected. Interestingly, we see that the most impactful restriction seems to be enforcing contiguous edits. We suspect that this is because contiguous edits are highly predictable. For example, predicting \u201cObama\u201d after \u201cBarack\u201d is fairly obvious. Thus, if the user didn\u2019t provide contiguous edits, and only inserted the word \u201cBarack\u201d, the model could score an easy win by predicting \u201cObama\u201d.\nExamples Table 4 provides two examples of interactions between the agent and user. We emphasize that these examples were not cherrypicked. Note how the agent is able to revise its previous version of the text based on the new information provided by the user at each step. Qualitatively, these interactions could be much more natural for a user than the one shot setting that is prevalent in the literature. However, a systematic evaluation of this claim requires a more comprehensive user study that lies out of the scope of this work."
        },
        {
            "heading": "7 Related Work",
            "text": "Text Generation Prior work on natural language generation (NLG) has largely focused on noninteractive settings that have become increasingly more challenging and open-ended, e.g., with generation from prompts (Fan et al., 2019), outlines (Rashkin et al., 2020), topics or keywords (Ghazvininejad et al., 2016; Yan, 2016), plots (Riedl and Young, 2010), descriptions (Jain et al., 2017), events (Martin et al., 2017). This increase of difficulty can make NLG more prone to content quality issues, such as hallucinations (Wiseman et al., 2017; Filippova, 2020; \u00c7elikyilmaz et al., 2020; Ji et al., 2022), that can require post-editing from the user. Several works explored ways for LLMs to improve their outputs by iteration and self-critiquing (Huang et al., 2022; Gou et al., 2023; Welleck et al., 2022). In particular, Welleck et al. (2022) presented models for text generation and self-correction that also incorporated external feedback. However, in their case the feedback is used at training time to learn a corrector. In our task, the user feedback comes at inference time and the agent must use that feedback to guess what the user would like to generate.\nNon Autoregressive Generation Several works considered non-autoregressive text generation (Gu et al., 2019; Shen et al., 2020; Xu and Carpuat, 2021; Stern et al., 2019; Zhang et al., 2020; Welleck et al., 2019), but these models all focus on one-shot text generation. While some models are able to edit text (Gu et al., 2019; Xu and Carpuat, 2021), it is primarily used as a means to refine the model\u2019s generations. On the other hand, we consider editing text into a completely different version conditioned on a given set of user-provided edits.\nText Editing Text editing has previously been considered from two different angles. On the one\nhand, various works (Zhang et al., 2019; Du et al., 2022b) have studied the types of revisions made by humans. On the other hand, works have focused on modeling text edits (Guu et al., 2018; Yin et al., 2018; Faltings et al., 2021; Akoury et al., 2020), but they have generally been restricted to modeling a single episode of user edits at a time. In our framework, model edits and user edits are interleaved. We note that (Du et al., 2022a) presented an interactive revision system, but their model was nevertheless trained on a corpus of edits, rather than in an interactive environment as in our case. The recent versions of GPT-3 (Brown et al., 2020; Ouyang et al., 2022) and ChatGPT5 also offer text editing capabilities. For example, ChatGPT can handle a prompt containing a piece of text and instruction to improve the text, and ChatGPT\u2019s ability to execute that command is often quite impressive. The ability of ChatGPT to interact with users was somewhat explored in (Bang et al., 2023), although not in the context of text editing. We think our work is complementary to GPT-3 and ChatGPT, as we provide a framework for both modeling and evaluating edit models in a more end-to-end setting. Our model of interaction between user and system, where the user and system are both editing the text, may also be more natural than dialogue. Ultimately, we think it will be beneficial to fine-tune very large language models such as GPT-3 in an environment that exposes them to interaction with a user or a user simulator (i.e., akin to user-in-the-loop training). This benefit is currently somewhat captured using reinforcement learning (RL) to tune large language models from human feedback (Ouyang et al., 2022), except that our approach features an actual environment representative of the end-user experience while Ouyang et al. (2022) is more akin to offline RL.\nInteractivity Several works have explored interactivity between humans and models to complete tasks collaboratively. Lee et al. (2022) presented a dataset to reveal large language models\u2019 capabilities in assisting creative writing. Zhang et al. (2022); Li et al. (2022) explored pre-trained language models for code editing based on humanwritten comments. Closer to our work, Lahiri et al. (2022) created an interactive framework to refine user intents through test case generations and user feedback, and Kiseleva et al. (2022) studied an interactive agent that can interact with humans\n5https://chat.openai.com/chat\nand follow natural language instructions to achieve goals in Minecraft. Finally, interactivity has also been studied from a Human-Computer Interaction viewpoint (Clark et al., 2018; Shen and Wu, 2023)."
        },
        {
            "heading": "8 Conclusions",
            "text": "We presented a new task and benchmark for text generation that operationalizes interactivity between an agent and a user, without the need to involve real users during training. Our framework compares interactive and non-interactive systems that are given the same amount of user inputs, and shows that interactive text generation leads to text of higher quality according to multiple automated evaluation metrics and human evaluations. We also present a non-autoregressive editing model that outperforms a standard sequence-to-sequence Transformer in various settings. All baseline, data, and models of this paper will be made public."
        },
        {
            "heading": "Limitations",
            "text": "A long-term goal of this research is to enable interactive editing of full documents. For practical reasons and to facilitate adoption, we limited text length to 64 tokens, but we plan to extend our benchmark and released datasets to also include paragraph-level and multi-paragraph texts. Another limitation of our work is that training is done with simulated instead of real users, as training with users in the loop can be extremely slow and costly. To make our approximation of user behavior realistic, our work relies on user inputs that real-world users perform routinely (i.e., word insertion, deletions, and substitutions) even settings that are not assisted with AI. However, we recognize that the behavior of real users in a AI-user collaborative setting may differ from that of our user simulators, and leave the study of such behavior for future work. Finally, while the need for interactivity ap-\nplies to any kind of AI creation (e.g., also code and images), we leave the application to other generation tasks for future work. We note, however, that this paper treats text as simple sequences of symbols, and our work could readily be applied to other symbolic creations (e.g., code generation)."
        },
        {
            "heading": "Ethics Statement",
            "text": "Text generation systems, including those relying on large language models, run the risk of generating text that is unsafe (Bender et al., 2021; Bommasani et al., 2021; Weidinger et al., 2021), and this also applies to generation models developed in this work. While we have not observed generations that are overtly toxic or hateful, our models can generate texts that are biased and offensive to some readers. As our work focuses on generation of non-fictional texts (in contrast to prior work on story generation), our models also run the risk of generating text that is factually incorrect. However, the focus of our research is to provide interactive capabilities to generation systems, and to make them more in control of the user. As illustrated in Figure 1, a back-and-forth between system and user can make the generated text more factual, and the same kind of interaction can also help increase its safety. Such sanitization of generated texts in our framework may still expose users with unsafe content, so it is still recommended to use current safeguards against hallucinations (Ji et al., 2022), biases (Dhamala et al., 2021; Weinberg, 2022), and other offensive content (Gehman et al., 2020; Welbl et al., 2021; Kiritchenko et al., 2021; Jones et al., 2022; Xu et al., 2022) before displaying text to real users. In that sense, we think our work is complementary to current NLG research on hallucination and safety."
        },
        {
            "heading": "Acknowledgments",
            "text": "We thank Regina Barzilay, Faeze Brahman, Chris Brockett, Si-Qing Chen, Javier Gonz\u00e1lez Hern\u00e1ndez, Gerold Hintz, Qiuyuan Huang, Tommi Jaakkola, Zhang Li, Lars Liden, Kosh Narayanan, Hoifung Poon, Victor Quach, Chris Quirk, Sudha Rao, Chenglong Wang, Bin Yu, Zhou Yu, as well as members of the NLP and Deep Learning groups at Microsoft Research for helpful discussions. This work was partly supported by the Eric and Wendy Schmidt Center at the Broad Institute."
        },
        {
            "heading": "A Methods Details",
            "text": "This section gives more formal and precise definitions of the notions of document, edits and alignments introduced in the main text. We follow by a more detailed description of the token editing model and the derivation of the log-likelihood lower bound."
        },
        {
            "heading": "A.1 Documents",
            "text": "We consider documents to be elements of V L, the space of strings of length L formed by words in vocabulary V . We assume V contains a blank token _, so that V L corresponds to all documents of length up to L."
        },
        {
            "heading": "A.2 Edits",
            "text": "In this work we consider three types of single-word edits: insertions, deletions, and substitutions. In particular, we do not consider word movements, i.e. changing the position of a word in a document. This will simplify the alignments we use to define the user simulator behavior. We formally define an edit as a 3-tuple specifying: a location l \u2208 [L] = 1, ..., L, an operation o \u2208 {ins, del, sub}, and a word w \u2208 V . An edit e = (l, o, w) \u2208 [L]\u00d7 {ins, del, sub} \u00d7 V can then be applied to a document x \u2208 V L, which we denote by [e](x), as defined by the following rules:\n1. If o = ins: [e](x) = x1...xl\u22121wxl...xL\u22121\n2. If o = del: [e](x) = x1...xl\u22121xl+1...xL_\n3. If o = sub: [e](x) = x1...xl\u22121wxl+1...xL\nWhen performing multiple edits e1, ..., eN in sequence, we will write6 [e1...eN ](x) = [eN ](...[e1](x)) as a shorthand. Note that the edits are not permutation invariant because of the location parameter l. For example, if x is a blank document, and e1 and e2 each correspond to inserting \u201cthe\u201d and \u201cdog\u201d respectively at the start of the document, i.e. e1 = (1, ins, the) and e2 = (1, ins, dog), then [e2e1](x) = \u201cthe dog\u201d whereas [e1e2](x) = \u201cdog the\u201d.\n6A more operator-like way to write this would have been [eN ...e1], but we opt for the other order, where the interpretation is that the brackets [] map the sequence of edits e1, ..., eN to an operator [e1...eN ] which is equivalent to performing the edits in sequence."
        },
        {
            "heading": "A.3 Alignments",
            "text": "Given two documents x, y, an alignment will give us a convenient way to find a sequence of edits e1, ..., eN such that [e1...eN ](x) = y. We use this to define the user simulator behavior, as well as for training our token edit model. Loosely speaking, an alignment between x and y is a partial mapping between words in x and words in y. More formally, it is an undirected bipartite graph with vertex sets Vx = {x1, ..., xL} and Vy = {y1, ..., yL}, and edges E. The edges then match words in x to words in y, where some words in x or y may not be matched. A monotonic alignment is one where the edges in the graph do not cross.\nFor our purposes it will be convenient to represent alignments in a particular way. Rather than a graph, an alignment between x and y will be a pair x\u0304, y\u0304 \u2208 V 2L, where x, resp. y, is a subsequence of x\u0304, resp y\u0304. Moreover, x\u0304 and y\u0304 only contain blank tokens otherwise. See Figure 2 for an example. Then each pair (x\u0304i, y\u0304i), i = 1, ..., 2L is interpreted as an operation:\n1. insertion if x\u0304i = _ and y\u0304i \u0338= _\n2. deletion if y\u0304i = _ and x\u0304i \u0338= _\n3. substitution if _ \u0338= y\u0304i \u0338= x\u0304i \u0338= _\nPairs of blanks (_, _) are ignored. Note that the the positions where neither x\u0304i or y\u0304i are blank give a monotonic alignment. The converse is not true because we could construct many pairs (x\u0304, y\u0304) that correspond to the same alignment. This is because we can rearrange the order of the positions corresponding to insertions and deletions since this won\u2019t affect the alignment. We therefore require all insertions to come before deletions so that monotonic alignments between x and y correspond oneto-one to pairs (x\u0304, y\u0304).\nGiven x and y, there may be many possible alignments. We therefore define a score on alignments and choose an alignment that maximizes the score. Given alignment (x\u0304, y\u0304), the score is\nS(x\u0304, y\u0304) = 2L\u2211 i=1 s(x\u0304i, y\u0304i|x, y),\nwhere s(x\u0304i, y\u0304i|x, y) scores the pair (x\u0304i, y\u0304i) given the contexts x and y. If both x\u0304i and y\u0304i are blank, the score is 0. If only one is blank, we assign a baseline score b. If neither is blank, then x\u0304i will correspond to some xk in x. Similarly y\u0304i corresponds to yl in y.\nWe use the cosine similarity between the BERT embeddings of xk and yl as their score. We found that using BERT embeddings gave more natural alignments where words of similar meaning or function are matched together. For example, consider two single word documents \u201cred\u201d and \u201cblue\u201d. Then it makes more sense to consider the change from \u201cred\u201d to \u201cblue\u201d a substitution rather than a deletion followed by an insertion. On the other hand, \u201cred\u201d to \u201ccar\u201d makes less sense as a substitution. This score can be easily optimized using dynamic programming (see for example Gale et al. (1994); Smith et al. (1981); Needleman and Wunsch (1970) for more details).\nGiven an alignment x\u0304 and y\u0304, the set of indices A = {i : x\u0304i \u0338= y\u0304i} naturally give a set of edits. We can split A = I \u222aD \u222a S into the union of indices corresponding respectively to insertions, deletions, and substitutions. These edits can be performed in any order, so the alignment gives a whole set of edit sequences, one for each permutation of A. For any \u03c3 \u2208 SM a permutation of A, where M = |A| is the size of A, there is a sequence of corresponding edits e\u03c31 , ..., e \u03c3 M . The delicate part about getting these edits is determining their location parameters since these will depend on the order \u03c3. We will need the following two quantities:\n1. I\u03c3i = |{j < i : A\u03c3(j) < A\u03c3(i), A\u03c3(j) \u2208 I}|\n2. D\u03c3i = |{j < i : A\u03c3(j) < A\u03c3(i), A\u03c3(j) \u2208 D}|\nThese correspond to the number of insertions and deletions that come before edit e\u03c3i and which will affect its location parameter. Let B\u03c3i = |{j < A\u03c3(i) : x\u0304j = _}| be the number of blanks before position A\u03c3(i) in x\u0304. Then, for i = 1, ...,M , the location parameter will be l\u03c3i = A\u03c3(i) \u2212 B\u03c3i \u2212 D\u03c3i + I \u03c3 i . Note that this is just keeping track of where the edit needs to be made in the document [e\u03c31 , ..., e \u03c3 i\u22121](x) after applying the first i\u2212 1 edits. We then treat the three operations separately:\n1. A\u03c3(i) \u2208 I: e\u03c3i = (li, ins, y\u0304A\u03c3(i))\n2. A\u03c3(i) \u2208 D: e\u03c3i = (li, del, _)\n3. A\u03c3(i) \u2208 S: e\u03c3i = (li, sub, y\u0304A\u03c3(i))\nIn summary, for documents x, y we can compute a unique alignment (x\u0304, y\u0304). We then denote the set of edit sequences {e\u03c31 , ..., e\u03c3M , \u03c3 \u2208 SM} as defined above by A(x, y).\nAlgorithm 2: Token Edit Model Objective"
        },
        {
            "heading": "Data: a, sh",
            "text": "Compute edits A(uh, a,); Uniformly sample permutation \u03c3 \u2208 SM ; Uniformly sample k \u2208 {1, 2, ...,M + 1}; Compute x\u03c3k\u22121 = [e \u03c3 1 , ..., e \u03c3 k\u22121](uh);\nreturn M+1nk \u2211 \u03c3k log \u03c0\u03b8(e \u03c3 k |x\u03c3k\u22121, sh);"
        },
        {
            "heading": "A.4 Markov Decision Process",
            "text": "As stated in Section 2, we fix the user behavior and learn a policy for the agent. To do so, we model our task as a finite-horizon Contextual Markov Decision Process (Sutton and Barto, 1998; Hallak et al., 2015) (S,A, C, P,R,H, \u03c1, \u03bd) where S is the state space, A is the action space, C is the context space, P : S \u00d7 A \u00d7 C 7\u2192 \u2206(S) is the transition function, R : S \u00d7 A \u00d7 C 7\u2192 [0,\u221e) is a state-actioncontext dependent reward function that models the user\u2019s utility, H is the horizon, and \u03c1 \u2208 \u2206(S) and \u03bd \u2208 \u2206(C) are the initial distribution over the state space and a distribution over contexts. The action and context spaces correspond to V L, the sequences of length L over vocabulary V , where the context is the goal document G. The state space is a history of drafts produced so far. Because the agent is ignorant of G, having access to the history of drafts allows the agent to make inferences about the goal G. The reward models a tradeoff between minimizing T , the time it takes to get to a satisfactory document, and s(AT ;G), the quality of the produced document. The user is modeled by the transition function P . Given previous state (i.e. history of drafts) Sh\u22121, the agent\u2019s draft Ah\u22121, and the target G, the environment transitions to state [Sh\u22121|(Ah\u22121, Uh)], where | denotes concatenation, and Uh is the user\u2019s draft produced according to Ah\u22121 and G. This framework allows us to use tools like imitation learning to train a policy \u03c0\u03b8 for this MDP, as done in Section 4.3."
        },
        {
            "heading": "A.5 Token Edit Model Likelihood Lower Bound",
            "text": "Recall that at step h, the likelihood under the token editing model model of a document a, given the current history Sh, and latest draft Uh will be,\n\u03c0\u03b8(Ah = a|Sh) =\u2211 \u03c4 \u03c0\u03b8(stop|a, Sh) M\u220f k=1 \u03c0\u03b8(ek|[e1...ek\u22121(Uh), Sh),\nwhere the sum is over all sequences of edits e1, ..., eM such that [e1...eM ](Uh) = a. We first lower bound the likelihood by discarding sequences outside of the set A(Uh, a), so\n\u03c0\u03b8(a|Sh) \u2265\u2211 \u03c3\u2208SM \u03c0\u03b8(stop|a, Sh) M\u220f k=1 \u03c0\u03b8(e \u03c3 k |X\u03c3k\u22121, Sh),\nwhere X\u03c3k\u22121 = [e \u03c3 1 ...e \u03c3 k\u22121](Uh). This is the same type of sum as in (Shen et al., 2020). Following their derivation,\nlog \u03c0\u03b8(a|Sh) \u2265\nlog \u2211\n\u03c3\u2208SM \u03c0\u03b8(stop|a, Sh) M\u220f k=1 \u03c0\u03b8(e \u03c3 k |X\u03c3k\u22121, Sh) \u2265\nC + 1\nM ! \u2211 \u03c3\u2208SM M\u2211 k=1 log \u03c0\u03b8(e \u03c3 k |X\u03c3k\u22121, Sh),\nwhere C = log(M !)+log \u03c0\u03b8(stop|a, Sh). The last line comes from Jensen\u2019s inequality, where the sum over permutations became an expectation. Using the same trick of rearranging the sum over time steps and orderings as in Shen et al. (2020), we can rewrite the second term as,\n1\nM ! \u2211 \u03c3\u2208SM M\u2211 k=1 log \u03c0\u03b8(e \u03c3 k |X\u03c3k\u22121, Sh) =\nEkE\u03c30:k\u22121  M M \u2212 k + 1 \u2211 e\u03c3k log \u03c0\u03b8(e \u03c3 k |X\u03c3k\u22121, Sh) \nwhere the sum is over the set {e : e\u03c3k = e, some \u03c3 \u2208 SM}. We then fold the log \u03c0\u03b8(stop|a, Sh) term into the expectation over k. This gives the objective,\nEkE\u03c30:k\u22121\n[ M + 1\nnk \u2211 \u03c3k log \u03c0\u03b8(e \u03c3 k |X\u03c3k\u22121, Sh)\n] ,\nwhere the expectation is now over k = 1, ...,M+1, e\u03c3M+1 = stop for all \u03c3 \u2208 SM , and\nnk = { M \u2212 k + 1, if k \u2264M 1, if k = M + 1\nAlgorithm 3: Noisy Edit Trajectory Sampling Data: a, uh, \u03c3 Result: Edits e1, ..., eM x\u2190 uh; k \u2190 1; repeat\nCompute A(x, a); Sample e from A(x, a)1; p\u2190 Bernoulli(\u03c3); if p = 1 then\nek \u2190 random edit; else\nek \u2190 e; end x\u2190 [ek](x); k \u2190 k + 1;\nuntil x = a; return e1, ..., ek"
        },
        {
            "heading": "A.6 Denoising",
            "text": "In practice, the lower bound derived above may be very loose because we are only considering edits in A(Uh, a,). In other words, the learned policy \u03c0\u03b8 will inevitably find itself out of distribution at inference time by making mistakes.\nIn order to make the model robust, we leverage denoising training (Lee et al., 2018). To do so, we notice that in Algorithm 2 we are essentially sampling a trajectory of edits e1, ...eM such that [e1...eM ](Uh) = a, and then randomly sampling a point along this trajectory. Instead, we sample noisy trajectories of edits, where we intersperse random edits, as in Algorithm 3. This simulates mistakes that the trained policy might make at inference time. Given this random prefix of edits e1, ..., ek\u22121, we get a noised, intermediate document, x\u0303k\u22121. We compute the same loss as before over the set of edits {e : \u03c41 = e, \u03c4 \u2208 A(x\u0303k\u22121, a)}. This is the set of first elements of edit trajectories from x\u0303k\u22121 to a, and we\u2019ll denote it by A(x\u0303k\u22121, a)1. The objective becomes,\nM + 1\nnk \u2211 e\u2208A(x\u0303k\u22121,a)1 log \u03c0\u03b8(e|x\u0303k\u22121, Sh),\nwhere now nk = |A(x\u0303k\u22121, a)1|. Intuitively, this is like using a noisy roll-in policy to get to x\u0303k\u22121, and then matching an expert policy that can produce a.\nAlgorithm 4: Token Edit Model Sampling Data: s, u, \u03b1,N Result: Generation fro \u03c0\u03b8(\u00b7|s) x0 \u2190 u; s0 \u2190 0; i\u2190 0; repeat\nsi \u2190 \u03c0\u03b8(stop|xi, s); Sample non-stopping edit ei\nfrom \u03c0\u0303\u03b8(\u00b7|xi, s); xi+1 \u2190 [ei](xi); i\u2190 i+ 1;\nuntil si > \u03b1 or i > N ; j \u2190 argmax{si}; return xj"
        },
        {
            "heading": "A.7 Decoding",
            "text": "To decode from the token editing model we use ancestral sampling with a few modifications. First, when sampling an edit (or stopping action) from \u03c0\u03b8, we only sample from the top k edits. Just as for autoregressive models, we found that this improves generation quality, since the low-probability edits are usually of poor quality and will figuratively speaking throw a wrench in the decoding process. For long sequences of edits, the probability of sampling a bad edit also becomes non-negligible.\nThe model also has a tendency to stop early. Again, this is because the probability of stopping erroneously increases as we sample more and more edits. In contrast to other types of mistakes, stopping early is especially bad because there is no way to recover, as opposed to other mistakes that can be fixed with another edit later on. Therefore, we explicitly avoid sampling the stopping action, and instead decode edits until either the model\u2019s stopping probability exceeds a threshold, or we reach a maximum number of edits. We then return the document that had the highest stopping probability. The whole decoding procedure is given in Algorithm 4."
        },
        {
            "heading": "B Experiment Details",
            "text": ""
        },
        {
            "heading": "B.1 Data",
            "text": "We use version 3.0.0 of the CNN/DailyMail dataset from the HuggingFace dataset hub (Lhoest et al., 2021). We take the article summaries, which we split into sentences and then filter to sentences with less than 64 tokens, where the tokens are determined by the BART tokenizer from HuggingFace\n(Wolf et al., 2020). We then split the data into train, test, and validation splits, with (approximately) 1M, 55K, and 45K instances respectively."
        },
        {
            "heading": "B.2 User Simulator Heuristics",
            "text": "The environment of our contextual MDP is determined by the behavior of the user simulator. We consider the following methods for generating user edits:\nRanking Given a set of edits, we rank them based on their informativeness. As a measure of informativeness, we use IDF scores.\nAdjacent Edits If the user simulator simply returns the most informative edits, it will have a tendency to make edits in disparate parts of the text. For example, it might return keywords from the end of the document, when the current draft only covers the start. In a realistic setting, users make edits related to the current draft, they do not preempt the end of the document. Thus, we limit the user simulator to producing adjacent edits, where an edit is adjacent if it is adjacent to a match in the alignment to the target.\nContiguous Edits While adjacency will keep the user simulator edits relevant to the current draft, it may still have a tendency to produce a disconnected set of edits. Instead, we limit it to only produce contiguous edits.\nComplete Words Finally, since the user simulator operates on tokenized text, and the tokens may break up words, we also constrain its edits to complete words."
        },
        {
            "heading": "B.3 Models and Training",
            "text": "Implementation Models were implemented with Transformer architectures with additional MLP layers on top. Specifically, we used the BART base and BART large checkpoints made available through the HuggingFace transformers library (Wolf et al., 2020). The models have (approximately) 140M and 400M parameters respectively.\nFor fixed document x and state s, the token editing model parametrizes a distribution over edits along with a stopping action. We refer to the union as edit actions, which are four tuples (s, l, o, w), where s \u2208 {0, 1} indicates the stopping action, and l, o, w, are as defined for edits. The probability of an edit action e = (s, l, o, w) is parameterized as a product of four probabilities, depending on three\ncases. If s = 1, then\n\u03c0\u03b8(e|x, s) = \u03c0s\u03b8(1|x, s).\nIf s = 0, o = del, then\n\u03c0\u03b8(e|x, s) = \u03c0s\u03b8(0|x, s)\u03c0l\u03b8(l|x, s)\u03c0o\u03b8(o|l, x, s).\nOtherwise,\n\u03c0\u03b8(e|x, s) = \u03c0s\u03b8(0|x, s)\u03c0l\u03b8(l|x, s)\u03c0o\u03b8(o|l, x, s)\u03c0w\u03b8 (w|o, l, x, s).\nEach of \u03c0s\u03b8, \u03c0 l \u03b8, \u03c0 o \u03b8 , \u03c0 w \u03b8 is implemented as a separate MLP head.\nModel Inputs The history of drafts Sh could become prohibitively large, so we keep track of only the last three drafts, denoted by Uh\u22121, Ah\u22121 and Uh. This allows the agent to reason about the edits it made at the last step and how the user responded. Additionally, we track all words inserted by the user along the entire history. This is easy to do by marking the relevant words, and allows the agent to know which words in the current draft came from the user. In practice, all these features are represented as a diff. See Figure 2 for an illustration, where the different coloring and markings represent which words were inserted or deleted by the agent or user. Practically, we implement this by adding labels to the tokens in the draft Uh. We can easily track these labels for the user and token edit models because they operate by making edits. So if the model or user deletes a word, we can mark it as deleted. For the Seq2Seq model this isn\u2019t possible because it returns an entire new draft. For example, we couldn\u2019t tell if a word was deleted or substituted for another. Instead, we compute the alignment between Uh\u22121 and Ah\u22121, from which we can read off which tokens were inserted, deleted or substituted. Because words inserted by the user should likely never be deleted by the agent, we keep the labels on all words inserted by the user so that they persist throughout the entire interaction.\nTraining Models were trained on a single 16GB V100 GPU for 600 iterations with a sampling batch size of B = 104 and a sampling annealing rate of \u03bb = 0.9. We also used 300 warmup iterations (where \u03bb was not annealed). For the token editing model we used a noise level of \u03c3 = 0.3.\nDecoding We decode from the S2S autoregressive model using beam search with a beam size of 10. For the token editing model we used top 10 sampling of actions, a stopping probability threshold of \u03b1 = 0.95 and a maximum number of edits of N = 64."
        },
        {
            "heading": "B.4 Metrics",
            "text": "We evaluated generation using BLEU (Papineni et al., 2002) and CHRF (Popovic\u0301, 2015) with the SacreBLEU implementation (Post, 2018). We also evaluate using BLEURT (Sellam et al., 2020) and BARTSCORE (Yuan et al., 2021), which are modelbased metrics that have been shown to correlate well with human judgment on various text generation tasks. As BARTSCORE returns a score interpretable as a log-probability, we report the natural exponent of that score. We also use ROUGE (Lin, 2004) for evaluation as an alternative to BLEU, as its scores tend to be less sensitive to length. In the case of both BLEU and ROUGE, we perform evaluation with their unigram versions (BLEU-1 and ROUGE-1) as they provide interpretability of the results at the token level."
        }
    ],
    "title": "Interactive Text Generation",
    "year": 2023
}