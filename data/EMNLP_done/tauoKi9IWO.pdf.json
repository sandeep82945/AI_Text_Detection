{
    "abstractText": "Generated texts from large language models (LLMs) are remarkably close to high-quality human-authored text, raising concerns about their potential misuse in spreading false information and academic misconduct. Consequently, there is an urgent need for a highly practical detection tool capable of accurately identifying the source of a given text. However, existing detection tools typically rely on access to LLMs and can only differentiate between machine-generated and human-authored text, failing to meet the requirements of fine-grained tracing, intermediary judgment, and rapid detection. Therefore, we propose LLMDet, a model-specific, secure, efficient, and extendable detection tool, that can source text from specific LLMs, such as GPT-2, OPT, LLaMA, and others. In LLMDet, we record the nexttoken probabilities of salient n-gram as features to calculate proxy perplexity for each LLM. By jointly analyzing the proxy perplexities of LLMs, we can determine the source of the generated text. Experimental results show that LLMDet yields impressive detection performance while ensuring speed and security, achieving 98.54% precision and about \u00d75.0 faster for recognizing human-authored text. Additionally, LLMDet can effortlessly extend its detection capabilities to a new open-source model. We will provide an open-source tool at https://github.com/TrustedLLM/LLMDet.",
    "authors": [
        {
            "affiliations": [],
            "name": "Kangxi Wu"
        },
        {
            "affiliations": [],
            "name": "Liang Pang"
        },
        {
            "affiliations": [],
            "name": "Huawei Shen"
        },
        {
            "affiliations": [],
            "name": "Xueqi Cheng"
        },
        {
            "affiliations": [],
            "name": "Tat-Seng Chua"
        }
    ],
    "id": "SP:70aa45fcd44d51d9180db9170f730fab94a14e99",
    "references": [
        {
            "authors": [
                "Sahar Abdelnabi",
                "Mario Fritz."
            ],
            "title": "Adversarial watermarking transformer: Towards tracing text provenance with data hiding",
            "venue": "2021 IEEE Symposium on Security and Privacy (SP), pages 121\u2013140. IEEE.",
            "year": 2021
        },
        {
            "authors": [
                "Rohan Anil",
                "Andrew M. Dai",
                "Orhan Firat",
                "Melvin Johnson",
                "Dmitry Lepikhin",
                "Alexandre Passos",
                "Siamak Shakeri"
            ],
            "title": "Palm 2 technical report",
            "year": 2023
        },
        {
            "authors": [
                "Tanya Aplin",
                "Giulia Pasqualetto."
            ],
            "title": "Artificial intelligence and copyright protection",
            "venue": "Chapter in Rosa Maria Ballardini, Petri Kuoppam\u00e4ki, Olli Pitk\u00e4nen (eds) Regulating Industrial Internet Through IPR, Data Protection and Competition Law (Kluwer,",
            "year": 2019
        },
        {
            "authors": [
                "Anton Bakhtin",
                "Sam Gross",
                "Myle Ott",
                "Yuntian Deng",
                "Marc\u2019Aurelio Ranzato",
                "Arthur Szlam"
            ],
            "title": "Real or fake? learning to discriminate machine from human generated text",
            "year": 2019
        },
        {
            "authors": [
                "Sid Black",
                "Leo Gao",
                "Phil Wang",
                "Connor Leahy",
                "Stella Biderman."
            ],
            "title": "Gpt-neo: Large scale autoregressive language modeling with mesh-tensorflow, 2021",
            "venue": "URL: https://doi. org/10.5281/zenodo, 5297715.",
            "year": 2022
        },
        {
            "authors": [
                "Souradip Chakraborty",
                "Amrit Singh Bedi",
                "Sicheng Zhu",
                "Bang An",
                "Dinesh Manocha",
                "Furong Huang"
            ],
            "title": "On the possibilities of ai-generated text detection",
            "year": 2023
        },
        {
            "authors": [
                "Long Dai",
                "Jiarong Mao",
                "Xuefeng Fan",
                "Xiaoyi Zhou."
            ],
            "title": "Deephider: A multi-module and invisibility watermarking scheme for language model",
            "venue": "arXiv preprint arXiv:2208.04676.",
            "year": 2022
        },
        {
            "authors": [
                "Li Dong",
                "Nan Yang",
                "Wenhui Wang",
                "Furu Wei",
                "Xiaodong Liu",
                "Yu Wang",
                "Jianfeng Gao",
                "Ming Zhou",
                "Hsiao-Wuen Hon."
            ],
            "title": "Unified language model pre-training for natural language understanding and generation",
            "venue": "Advances in neural information process-",
            "year": 2019
        },
        {
            "authors": [
                "Zhengxiao Du",
                "Yujie Qian",
                "Xiao Liu",
                "Ming Ding",
                "Jiezhong Qiu",
                "Zhilin Yang",
                "Jie Tang."
            ],
            "title": "Glm: General language model pretraining with autoregressive blank infilling",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational",
            "year": 2022
        },
        {
            "authors": [
                "Tiziano Fagni",
                "Fabrizio Falchi",
                "Margherita Gambini",
                "Antonio Martella",
                "Maurizio Tesconi."
            ],
            "title": "Tweepfake: About detecting deepfake tweets",
            "venue": "Plos one, 16(5):e0251415.",
            "year": 2021
        },
        {
            "authors": [
                "Leon Fr\u00f6hling",
                "Arkaitz Zubiaga."
            ],
            "title": "Featurebased detection of automated language models: tackling gpt-2, gpt-3 and grover",
            "venue": "PeerJ Computer Science, 7:e443.",
            "year": 2021
        },
        {
            "authors": [
                "Sebastian Gehrmann",
                "Hendrik Strobelt",
                "Alexander M. Rush"
            ],
            "title": "Gltr: Statistical detection and visualization of generated text",
            "year": 2019
        },
        {
            "authors": [
                "Biyang Guo",
                "Xin Zhang",
                "Ziyuan Wang",
                "Minqi Jiang",
                "Jinran Nie",
                "Yuxuan Ding",
                "Jianwei Yue",
                "Yupeng Wu."
            ],
            "title": "How close is chatgpt to human experts? comparison corpus, evaluation, and detection",
            "venue": "arXiv preprint arxiv:2301.07597.",
            "year": 2023
        },
        {
            "authors": [
                "Ryuichiro Hataya",
                "Han Bao",
                "Hiromi Arai"
            ],
            "title": "Will large-scale generative models corrupt future datasets? arXiv preprint arXiv:2211.08095",
            "year": 2022
        },
        {
            "authors": [
                "Tim Jansen",
                "Yangling Tong",
                "Victoria Zevallos",
                "Pedro Ortiz Suarez."
            ],
            "title": "Perplexed by quality: A perplexity-based method for adult and harmful content detection in multilingual heterogeneous web data",
            "venue": "arXiv preprint arXiv:2212.10440.",
            "year": 2022
        },
        {
            "authors": [
                "John Kirchenbauer",
                "Jonas Geiping",
                "Yuxin Wen",
                "Jonathan Katz",
                "Ian Miers",
                "Tom Goldstein"
            ],
            "title": "A watermark for large language models",
            "year": 2023
        },
        {
            "authors": [
                "Keita Kurita",
                "Paul Michel",
                "Graham Neubig."
            ],
            "title": "Weight poisoning attacks on pretrained models",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2793\u2013 2806, Online. Association for Computational Lin-",
            "year": 2020
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdelrahman Mohamed",
                "Omer Levy",
                "Ves Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
            "year": 2019
        },
        {
            "authors": [
                "Jing Liu",
                "Xinxin Zhu",
                "Fei Liu",
                "Longteng Guo",
                "Zijia Zhao",
                "Mingzhen Sun",
                "Weining Wang",
                "Hanqing Lu",
                "Shiyu Zhou",
                "Jiajun Zhang"
            ],
            "title": "Opt: Omniperception pre-trainer for cross-modal understanding and generation",
            "venue": "arXiv preprint arXiv:2107.00249",
            "year": 2021
        },
        {
            "authors": [
                "Eric Mitchell",
                "Yoonho Lee",
                "Alexander Khazatsky",
                "Christopher D. Manning",
                "Chelsea Finn"
            ],
            "title": "Detectgpt: Zero-shot machine-generated text detection using probability curvature",
            "year": 2023
        },
        {
            "authors": [
                "Shashi Narayan",
                "Shay B. Cohen",
                "Mirella Lapata."
            ],
            "title": "Don\u2019t give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Lan-",
            "year": 2018
        },
        {
            "authors": [
                "Liang Pang",
                "Yanyan Lan",
                "Jiafeng Guo",
                "Jun Xu",
                "Shengxian Wan",
                "Xueqi Cheng."
            ],
            "title": "Text matching as image recognition",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 30.",
            "year": 2016
        },
        {
            "authors": [
                "Alec Radford",
                "Jeffrey Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "venue": "OpenAI blog,",
            "year": 2019
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J Liu."
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "The Journal of Machine Learning Research,",
            "year": 2020
        },
        {
            "authors": [
                "Pranav Rajpurkar",
                "Jian Zhang",
                "Konstantin Lopyrev",
                "Percy Liang."
            ],
            "title": "SQuAD: 100,000+ questions for machine comprehension of text",
            "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2383\u20132392, Austin,",
            "year": 2016
        },
        {
            "authors": [
                "Vinu Sankar Sadasivan",
                "Aounon Kumar",
                "Sriram Balasubramanian",
                "Wenxiao Wang",
                "Soheil Feizi"
            ],
            "title": "Can ai-generated text be reliably detected",
            "year": 2023
        },
        {
            "authors": [
                "Teven Le Scao",
                "Angela Fan",
                "Christopher Akiki",
                "Ellie Pavlick",
                "Suzana Ili\u0107",
                "Daniel Hesslow",
                "Roman Castagn\u00e9",
                "Alexandra Sasha Luccioni",
                "Fran\u00e7ois Yvon",
                "Matthias Gall\u00e9"
            ],
            "title": "Bloom: A 176bparameter open-access multilingual language model",
            "year": 2022
        },
        {
            "authors": [
                "Irene Solaiman",
                "Miles Brundage",
                "Jack Clark",
                "Amanda Askell",
                "Ariel Herbert-Voss",
                "Jeff Wu",
                "Alec Radford",
                "Gretchen Krueger",
                "Jong Wook Kim",
                "Sarah Kreps"
            ],
            "title": "Release strategies and the social impacts of language models",
            "year": 2019
        },
        {
            "authors": [
                "Ruixiang Tang",
                "Yu-Neng Chuang",
                "Xia Hu"
            ],
            "title": "The science of detecting llm-generated texts",
            "year": 2023
        },
        {
            "authors": [
                "Silva",
                "Eric Michael Smith",
                "Ranjan Subramanian",
                "Xiaoqing Ellen Tan",
                "Binh Tang",
                "Ross Taylor",
                "Adina Williams",
                "Jian Xiang Kuan",
                "Puxin Xu",
                "Zheng Yan"
            ],
            "title": "2023b. Llama 2: Open foundation and finetuned chat models",
            "year": 2023
        },
        {
            "authors": [
                "Adaku Uchendu",
                "Thai Le",
                "Kai Shu",
                "Dongwon Lee."
            ],
            "title": "Authorship attribution for neural text generation",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8384\u20138395, Online. Association for",
            "year": 2020
        },
        {
            "authors": [
                "Honai Ueoka",
                "Yugo Murawaki",
                "Sadao Kurohashi."
            ],
            "title": "Frustratingly easy edit-based linguistic steganography with a masked language model",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computa-",
            "year": 2021
        }
    ],
    "sections": [
        {
            "text": "1 Introduction\nRecently, the emergence of ChatGPT1 has heralded a \"Cambrian Explosion\" for generative large language models (LLMs). GPT-4 (OpenAI, 2023), Bard2, PaLM-2 (Anil et al., 2023), and other LLMs from internet companies are currently flourishing, while open-source communities are witnessing a proliferation of open-source models like\n\u2217Corresponding author 1https://openai.com/product/chatgpt 2https://bard.google.com\nLLaMA (Touvron et al., 2023a), OPT (Liu et al., 2021), ChatGLM (Du et al., 2022). These models are capable of generating coherent, fluent, and meaningful text. However, the formidable text generation capabilities of generative language models have also raised concerns about their potential misuse in domains such as phishing, spreading false information, and academic fraud. Additionally, with the application of products like ChatGPT, the future abundance of machine-generated text data has the potential to contaminate genuine humangenerated data (Hataya et al., 2022), altering the data ecosystem of the real world.\nAccordingly, the study of practical content generation detection tools has attracted widespread attention from the community. Recently, the primary focus of research is on approaching the text detection problem as a binary classification task to distinguish machine-generated text and humanauthored text, making it hard to assign responsibility to a specific model or its provider. Nevertheless, Watermarking (Kirchenbauer et al., 2023) methods necessitate altering the text generation process, leading to a compromise in the quality of the generated content. Techniques like GPT-zero3, DetectGPT (Mitchell et al., 2023), and the classifier in OpenAI (OpenAI, 2023) require access to the deployed model, thereby resulting in high cost and intractability for third parties.\nThus, a practical LLM detection tool should possess the following capabilities, which are also the objectives of our method: Specificity: Merely focusing on identifying human and machinegenerated text is insufficient for duty attribution. There is a pressing need for the ability to recognize the specific model responsible for generating the text. Safety: Ensuring model security and mitigating potential risks require a detection method that does not require accessing model parameters. This need is particularly urgent for commercial mod-\n3https://gptzero.me\nels. Efficiency: With the increasing demand for detection and the exponential growth of models, it is crucial to develop detection algorithms that have low resource and low latency requirements. Extendibility: The detection tool should inherently possess the capacity to seamlessly accommodate emerging model paradigms. This capability plays a pivotal role in refining the detection ecosystem and effectively addressing the ever-expanding variety of LLMs.\nGuided by the aforementioned capabilities, we propose a pragmatic third-party detection method called LLMDet. Our approach is inspired by the observation that perplexity serves as a reliable signal for distinguishing the source of generated text, a finding that has been validated in previous work (Solaiman et al., 2019; Jansen et al., 2022; Mitchell et al., 2023). However, directly calculating perplexity requires access to LLMs, which compromises both safety and efficiency. In LLMDet, we address this challenge by capturing the next token probabilities of prominent n-gram in texts as priors. This enables us to efficiently compute a proxy perplexity for each LLM. By comprehensively analyzing the proxy perplexities of LLMs, we can accurately trace the specific language model responsible for generating the text. Notably, our method eliminates the need to access the model at the detection end, ensuring the security of parameters in large-scale models. It also offers the potential for seamless integration with emerging open-source models, as well as proprietary models under appropriate licensing. These factors contribute to the widespread adoption of our approach.\nLLMDet exhibits outstanding overall detection performance, with an F1-Macro score of 88.14% and near-perfect results for R@2, indicating that highly ranked predictions cover the correct labels for the majority of instances. Particularly notable is its exceptional discriminative ability in human text, LLaMA-generated text, and BART-generated text. In terms of detection efficiency, LLMDet significantly outperforms other similar methods such as fine-tuned RoBERTa, GPT-zero4, DetectGPT (Mitchell et al., 2023), and True-PPL with respect to speed. And, it has very low resource requirements, as text detection can be accomplished solely on a CPU, enabling easy accessibility for a wider range of users. Additionally, when tested on perturbated text data, LLMDet produces satisfac-\n4https://gptzero.me\ntory detection results, demonstrating its robustness and adaptability.\n2 Related Work\nThe existing methods for detecting generated text can be broadly categorized into two types: blackbox and white-box detection (Tang et al., 2023).\n2.1 Black-box Detection\nBlack-box detection methods can be further divided into three main branches: statistical learning methods, supervised learning methods, and unsupervised learning methods. Traditional approaches utilize statistical metrics such as entropy, perplexity, and n-gram frequency for text classification (Gehrmann et al., 2019; Fr\u00f6hling and Zubiaga, 2021).\nCompared to statistical learning methods, supervised learning methods are more commonly used in text detection. These works leverage text features to train a supervised classification model specifically designed for the detection of machinegenerated text (Bakhtin et al., 2019; Uchendu et al., 2020; Fagni et al., 2021; OpenAI, 2023).\nHowever, the study conducted by (Uchendu et al., 2020; Chakraborty et al., 2023) demonstrates that a limitation of supervised models is the potential occurrence of overfitting within the domain, resulting in poor detection performance outside the domain.\nTo address the limitations of supervised learning methods, unsupervised learning methods such as DetectGPT (Mitchell et al., 2023) and GPT-Zero have been developed. These approaches utilize checks on perplexity and burstiness in the text to determine whether it is artificially generated or authored by a human.\n2.2 White-box Detection\nWhite-box detection methods require full access to LLMs, thereby enabling control over the generation behavior of the model or embedding watermark within the generated text (Abdelnabi and Fritz, 2021; Ueoka et al., 2021; Dai et al., 2022). This enables the tracking and detection of machinegenerated text within white-box settings.\nThe current state-of-the-art approach, as proposed by (Kirchenbauer et al., 2023), partitions the model\u2019s vocabulary into whitelist and blacklist tokens when predicting the next token given a prompt. During text generation, the goal is to\nproduce whitelist tokens as much as possible, effectively creating a strong watermark. Third parties can determine if the text is machine-generated by analyzing the frequency of whitelist tokens within the text. While watermarking methods offer robustness and interpretability, they can compromise the quality of the generated text and may not be highly practical in certain scenarios (Sadasivan et al., 2023).\n3 Motivation\nA practical LLMs detection method should possess the characteristics of being specific, secure, efficient, and extensible, which serve as the intention for developing our third-party detection tool.\nSpecificity: The field of LLMs constantly evolves, indicating that a sole focus on identifying human and machine-generated text is insufficient to meet detection requirements. From the perspective of copyright protection for works generated by artificial intelligence (Aplin and Pasqualetto, 2019), an ideal detection tool should be capable of identifying the specific language model responsible for generating the text, thereby exerting a lasting impact on intellectual property rights protection.\nSafety: The majority of existing detection methods require accessing or modifying model parameters, which is deemed unacceptable for commercial models. Once the model is loaded, it represents a financial loss for the owner and can also expose the model to potential attacks (Kurita et al., 2020). Hence, considering the security of the model, it is desirable to minimize the need for model loading during the detection process.\nEfficiency: With the growing number of users utilizing large-scale models, the future of text detection is poised for exponential expansion in terms of demand and user base. For instance, in the realm of education, there is a significant need for text detection to combat cheating and plagiarism (Cotton et al.), despite often constrained hardware conditions. This poses a formidable challenge to existing detection methods. Hence, the pursuit of rapid and resource-efficient approaches has become a pivotal direction in developing efficient detection algorithms.\nExtendibility: As for multi-model generated text detection approaches, it is crucial to seamlessly adapt to emerging model paradigms and extend detection capabilities to new models. This is because an excellent detection tool is not static but needs\nto keep up with technological advancements and continuously enhance its own detection ecosystem to address the challenges posed by new models.\n4 LLMDet\nCombining the aforementioned motivations, we introduce LLMDet, a text detection tool capable of identifying the sources from which the text was generated, such as Human, LLaMA, OPT, or others. The overall framework of the system is illustrated in Figure 1 and consists of two main components: Dictionary Construction (see \u00a7 4.1) and Text Detection (see \u00a7 4.2).\nThe construction of the dictionary is performed offline by us or provided by the model owner, ensuring its independence from external systems. This ensures the fulfillment of the four characteristics proposed for our detection tool in \u00a7 3. The text detection component can be distributed to tool users, allowing third-party detection without requiring the possession of the model. For the specific algorithm, please refer to Appendix A.\n4.1 Dictionary Construction\nDrawing from previous detection works, such as DetectGPT (Mitchell et al., 2023) and GPT-Zero5, perplexity has shown promising results in detecting machine-generated text. Therefore, we consider utilizing perplexity as a measurement of identifying the generated text from different LLMs. However, calculating the actual perplexity requires access to LLMs, which goes against the safety and efficiency characteristics of the practical LLMs detection method.\nPerplexity is a measure used to evaluate the performance of language models. Specifically, it is the exponential average of the negative log-likelihood of a sequence generated by the model. The perplexity score is calculated based on the probability of generating the next word, given all the previous words in the sequence, e.g. p(xi, x<i). In order to calculate the perplexity of text without accessing the model, we need approximate p(xi, x<i) by replacing x<i with a n-gram , thus a dictionary should be constructed, with n-gram as keys and the next token probabilities as values. This dictionary serves as prior information during the detection process, allowing us to compute the proxy perplexity of the text instead of the true perplexity. The construction process can be divided into three steps:\n5https://gptzero.me\n1) Generated Text Sampling: Due to the absence of readily available model-generated text data, it is necessary to collect a sufficient number of corresponding generated texts for each model. We provide a prompt dataset and, for each model, randomly sample an equal number of prompts. We use these prompts to generate corresponding texts and collect the required text data.\n2) Word Frequency Statistics: In this phase, we first utilize the generated texts collected in the previous step to perform n-gram word frequency statistics (Pang et al., 2016). The n-gram range from 2-gram to n-gram. Subsequently, we select the top-k n-gram based on their frequency.\n3) Next Token Probability Sampling: In this phase, we use each n-gram s obtained from word frequency statistics as samples. We input the first n\u2212 1 token s[1:n\u22121] into the corresponding generative models for predicting next-token probabilities pw = [pw1 , . . . , p w |W|], where |W| is the size of vocabulary. Subsequently, we sample the top-K words based on next-token probabilities. For ngram with different values of n, the optimal value of K for top-K sampling may vary.\nWe should consider the optimal values, the degree of n-gram, the number of n-gram k, and the number of next token probabilities K from two aspects: detection performance and storage cost.\nIn terms of detection performance, the larger n, k, and K may improve the detection performance of LLMDet, as this enables the proxy perplexity to approximate the true perplexity.\nIn terms of storage cost, due to the data type of the sampling probabilities being Float64 and ngram being a string, a significant amount of storage\nspace is required, e.g. O(nkK). If n is set to 4, k is set to 100,000 (much smaller than the number of 4-gram), and K is set to 10,000 (most vocabulary size is larger than that), we need almost 22GB to store only probabilities for one model. Thus, we have to reduce the storage in practical use. The reduction can be considered in two folds, 1) select a suitable n, k and K, 2) reduce Float64 to Float16 and represent n-gram as Int16. We find that does not significantly affect LLMDet, while it reduces storage costs by approximately 11 times about 0.5GB.\nIn the end, we constructed an n-gram and probability dictionary for each LLM, which was utilized for calculating proxy perplexity. The above three steps are repeated on GPT-2 (Radford et al., 2019), OPT (Liu et al., 2021), UniLM (Dong et al., 2019), LLaMA (Touvron et al., 2023a), BART (Lewis et al., 2019), T5 (Raffel et al., 2020), Bloom (Scao et al., 2022) and GPT-neo (Black et al., 2022), respectively.\n4.2 Text Detection\nIn \u00a7 4.1, we have obtained the dictionary of n-gram and their probabilities. Therefore, we can use the corresponding dictionary of each model as prior information for third-party detection to calculate the proxy perplexity of the text being detected on each model. Immediately after, by inputting the proxy perplexity as a feature into a trained text classifier, we can obtain the corresponding detection results.\n4.2.1 Proxy Perplexity Estimating During text detection, for the input text X , our initial task is to estimate the proxy perplexity of\nthis text across various large language models as a vector of feature information.\nTaking the estimation of proxy perplexity on Modelm as an example, we begin by tokenizing the input text X to obtain its sequence X = [x1, x2, ..., xt], assuming the length of the tokenized sequence is denoted as t.\nThen, the proxy perplexity of the sequence X on Modelm can be mathematically represented by the following function, denoted as Proxy_PPL:\nProxy_PPL(X) = \u22121 t t\u2211 i=0 log p (xi | n-gram) . (1)\nMore specifically, log p (xi | n-gram) represents the logarithmic likelihood of the i-th token, conditioned on the preceding tokens x<i matching the n-gram in the dictionary of Modelm. The likelihood probability p (xi | n-gram) corresponds to the value associated with the matching n-gram in the dictionary.\nSimilarly, by repeating the above procedure on other models, we can obtain the proxy perplexity of the detection text on the respective models. These proxy perplexities constitute the feature information vector for detection, denoted as F = [Proxy_PPL1,Proxy_PPL2, ...,Proxy_PPLc], subscript c denotes the number of LLMs.\n4.2.2 Result Ranking\nBefore result ranking, we initially estimate the proxy perplexity of the generated texts from each language model and human-generated texts. This estimation allows us to obtain a separate feature information vector for each text. Subsequently, these vectors are employed to train a text detector.\nNext, we input the feature information vectors F, obtained during the proxy perplexity estimation phase, of the text to be detected into the trained text detector for result prediction, yielding a prediction result, such as for a given Modeli, the probability is denoted as pi. It is important to note that we denote the probability of Human as p0.\nHowever, due to the fact that the text detector is trained based on perplexity as a feature, it is not sensitive to the length information of the detected text, resulting in suboptimal detection performance for some short texts. Therefore, it is necessary to apply a smoothing technique to the probabilities of the detection results in order to enhance the success rate of detecting short texts. The smoothing process\nis denoted as,\np\u0303i = log (pi) + 1\nL log\n( 1\nc+ 1\n) , (2)\nwith L is the length of the text to be detected, c denotes the number of LLMs.\nFinally, we apply softmax to the smoothed probabilities to obtain [p\u03020, p\u03021, ..., p\u0302c]. Consequently, the detection results are transformed into the probability of Modeli is p\u0302i. Subsequently, the detection results are sorted based on the magnitude of the probability values in the result dictionary, yielding the final detection outcome,\n[p\u03020, p\u03021, ..., p\u0302c] = softmax ([p\u03030, p\u03031, ..., p\u0303c]) . (3)\n5 Experiments\nWe conduct experiments based on proxy perplexity and true perplexity according to the methods proposed in \u00a7 4. By comparing the performance of the text detectors based on fine-tuned RoBERTa, proxy perplexity, and ture perplexity, we find that our proposed method outperforms existing methods in terms of detection efficiency, security, and scalability while ensuring the performance of the detector.\n5.1 Datasets In our experiments, we use Wikipedia paragraphs from the SQuAD context (Rajpurkar et al., 2016) and news articles from the Xsum (Narayan et al., 2018) dataset for extraction. We extract the first 5 phrases of each text data to form a prompt dataset. During the text generation phase, for each LLM, we randomly select 32,000 data samples from the prompt dataset as input and have the model generate corresponding text. The generated text from each model is evenly split into two parts: 16,000 samples for the statistical dataset and 16,000 samples for the validation dataset. The statistical dataset is used for n-gram frequency counting. The validation dataset from LLMs, along with 16,000 samples collected from HC3 (Guo et al., 2023) as human-generated text, form a combined dataset for the training and validation of text detectors.\n5.2 Metrics To evaluate the ability of the detector to distinguish between text generated by different LLMs and human-written text, we employ precision (P ), recall (R), and F1 score to assess the discriminative\nperformance of the text detector on each of LLMs and human-generated text. Additionally, F1-Macro, R@1, R@2, and R@3 metrics are used to analyze the overall performance of the detector,\nF1i = 2PiRi Pi +Ri\n, F1-Macro = \u2211N\ni=1 F1i N , (4)\nR@k =\n\u2211M j=1 IGj\u2208Kj\nM , (5)\nwhere Pi, Ri and F1i respectively represent the precision, recall, and F1 score of Modeli. N denotes the total number of categories, M represents the number of texts being tested. Gj represents the ground label of Text j, Kj refers to the top-k categories with the highest probabilities in the predicted results, IGj\u2208Kj takes the value of 1 when Gj \u2208 Kj , and 0 otherwise.\n5.3 Research Quesitons\nBased on the characteristics and assumptions of our proposed detection tool in \u00a7 3, we formulate four research questions regarding LLMDet.\n\u2022 RQ1: Can perplexity-based methods trace the source of text from certain LLM?\n\u2022 RQ2: How significant is the impact of the proxy perplexity-based approach on detection performance?\n\u2022 RQ3: Can LLMDet achieve the expected level of efficiency compared to existing methods?\n\u2022 RQ4: How is the extendibility of LLMDet demonstrated?\n5.4 Experiments & Results We conducted experimental verification for the aforementioned raised questions.\nFor Specificity (RQ1): We first compute the true perplexity of the combined datasets constructed in \u00a7 5.1 on GPT-2, GPT-2-Large, OPT1.3B, OPT-2.7B, UniLM, LLaMA-7B, BART, T5Base, Bloom-650M and GPT-Neo-2.7B models. Subsequently, we joint these perplexity values to train a text classifier based on LightGBM (Ke et al., 2017).\nThe classifier is then tested, and the results are presented in Table 1. We observe that the text detector based on true perplexity achieved excellent detection success rates when confronted with texts generated by different models, with the exception of the generated texts by UniLM. Despite\nthe comparatively lower detection performance for UniLM-generated texts, the F1 score reaches 80.60%, which is significantly higher than random guessing. These experimental results robustly validate the applicability of perplexity as a distinguishing metric for models that identify specific sources of text.\nFor Safety (RQ2): We utilize the statistical datasets generated on GPT-2, GPT-2-Large, OPT1.3B, OPT-2.7B, UniLM, LLaMA-7B, BART, T5Base, Bloom-650M, and GPT-Neo-2.7B, as mentioned in the \u00a7 5.1, to construct dictionaries for each model using the method described in the \u00a7 4.1. Then, we employ these dictionaries to calculate the proxy perplexity of the combined dataset as features for training a text classifier based on LightGBM (Ke et al., 2017).\nThe classifier is then tested, and the results are presented in Table 1. Our proposed method based on proxy perplexity achieves comparable results to the text detector based on real perplexity on Human, LLaMA-generated, and BART-generated texts, with detection success rates exceeding 95%. Additionally, our method outperforms the true perplexity-based detector when it comes to detecting UniLM-generated texts. Furthermore, the F1 score for detecting texts from other sources is at least 76.39%, significantly higher than random guessing. Based on the confusion matrix in Figure 2, it can be observed that there is a tendency for the text generated by GPT-2 and OPT to be easily confused with each other, while text generated by T5, Bloom, and GPT-Neo also exhibit a tendency to be easily confused. Although the overall performance is not as high as the real perplexity-based text classifier, our proposed method does not require model access during detection and offers advantages such as speed, scalability, and enhanced security.\nTo assess the comprehensive detection capability of the detector, we compute the F1-Macro, R@1, R@2 and R@3 values. From Table 2, it is evident that our proposed method achieves an R@2 value of 98.00%. This indicates that, among the top two text sources with the highest predicted probabilities, there is typically one source that corresponds to the true source of the text.\nFor Efficiency (RQ3): In order to compare the efficiency of various methods, in addition to the main experiment in Table 2, we also conduct tests using the same set of 1000 texts to measure the efficiency required for detection in GPT-Zero, De-\ntectGPT, True-PPL, and LLMDet. In terms of resource requirements, both DetectGPT and TruePPL methods are run on a V100-SXM-32GB, GPTZero utilizes its API for detection on a GPU, while LLMDet only requires a GPU for the completion of the detection process.\nBased on the efficiency analysis in Table 2 and Table 3, it can be observed that LLMDet outperforms other detection methods significantly. Furthermore, in terms of resource requirements, our approach exhibits the lowest demands. Consequently, our detection tool demonstrates a substantially higher efficiency compared to other methods, making it more aligned with future detection needs.\nFor Extendibility (RQ4): To illustrate the extendibility of the LLMDet method, we expand its detection capability from one model to eight. Specifically, We sequentially add the LLM model into our LLMDet tool in the following sequence: GPT-2, LLaMA, OPT, UniLM, BART, T5, Bloom, and GPT-Neo. Thereby, continuously extending the detection capability to these models. Additionally, with each expansion, we retrain the text detector (LightGBM) and assessed the resultant changes in overall performance.\nFrom Figure 3, it can be observed that during the expansion of LLMDet, there is only a slight fluctuation in the value of F1-Macro, which remains\nconsistently around 85%. Therefore, it can be concluded that in the future, LLMDet can be easily expanded to a new model with sightly performance affection.\nIn addition, in order to explore the performance changes of LLMDet when using newer and larger LLM, we also conducted additional experiments. The detailed experimental steps and results can be seen in Appendix B.\n6 Analysis\nIn this section, we conduct several additional experiments to facilitate a more comprehensive analysis of LLMDet. Firstly, we verify the detection robustness of LLMDet. Subsequently, we investigate the impact of n-gram in dictionary construction on the detection performance of LLMDet. Finally, we explore the influence of the top-k of the next token samples in dictionary construction on the detection performance of LLMDet.\n6.1 The Robustness Testing of Detector\nMany LLMs can change their probability of the next token via different methods, for example, changing hyperparameters like temperature, or even updating weight by fine-tuning. Furthermore, generated text may encounter deliberate perturbation, such as random deletions. It is worth considering the robustness of this method in these situations.\nFor hyperparameter changes, we use the approach outlined in \u00a7 5.1 of this article to generate 16,000 text instances using LLaMA-7B at temperatures of 0.1, 0.4, 0.7, and 1.0 respectively.\nFor random deletion, we use the approach out-\nlined in \u00a7 5.1 to generate 16,000 text instances using LLaMA-7B. For the generated text, we set the deletion rates at 0.1, 0.3, and 0.5, respectively, subsequently introducing corresponding perturbed texts by randomly removing words from the text according to these specified rates.\nFor weight updates, we employ the approach outlined in \u00a7 5.1 to generate 16,000 text instances using the Vicuna-7B, an instruction fine-tuned version of LLaMA-7B.\nThese text instances are then utilized as test data to assess the robustness of LLMDet, and the experimental outcomes are presented in Table 4. LLMDet exhibits strong robustness against certain types of perturbations in the text, such as random deletions, slight weight updates in the generative model, and adjustments to temperature settings. For more analysis of experimental results, please see Appendix C.\n6.2 The Influence of N -gram We compute the proxy perplexity of each model for the combined dataset in the \u00a7 4.1 using dictionaries built on 2-gram, 3-gram, and 4-gram, respectively. By jointly analyzing the proxy perplexities to train and test the text classifier using the LightGBM. It should be noted that (n-1)-gram are a subset of n-gram. Based on the results shown in Table 5, it can be observed that the overall detection performance of text within the domain does not increase significantly as the value of n increases, but rather exhibits a slight improvement. Considering that the number of n-gram increases exponentially as n increases, we only consider 4-gram in LLMDet.\n6.3 Next Token Top-K Sampling The construction of the dictionary incurs significant storage overhead due to the necessity of storing the top-K probabilities along with their corresponding n-gram, presenting a challenge to our method. Consequently, determining the optimal value of K requires a comprehensive consideration of both detection performance and storage costs.\nIn order to gain a more intuitive understanding of the impact of the K value on the detection performance of LLMDet, while keeping the number of 2-gram, we solely vary the K value and examine the changes in F1-Macro of LLMDet across different K values. The result is presented in Figure 4.\nWe observe that as the value of K increases, the detection performance of LLMDet gradually improves. However, the performance improvement\nbecomes less pronounced after K reaches 1500. Nonetheless, the corresponding storage overhead still increases linearly. Therefore, considering the overall trade-off between detection performance and storage cost, we recommend adopting a top2000 sampling for 2-gram. For 3-gram and 4-gram, their quantities are immense. Therefore, following the completion of similar experimental analyses, we employ a top-100 sampling for these n-gram .\n7 Conclusions and Future Work\nIn the era dominated by machine-generated text, there is a growing need for an efficient and secure detection tool. However, existing detection methods typically require interaction with language models, which inherently compromises speed and security. Our proposed detection tool, LLMDet, overcomes these limitations by leveraging premined prior probability information to compute proxy perplexity, ensuring both speed and secu-\nrity in the detection process. Additionally, our method enables text tracking, allowing for the identification of the underlying language model from which the text originates. Importantly, our detection tool can be continuously enhanced by expanding to new open-source LLMs, enabling ongoing improvements.\nIn the future, we aim to further refine our detection tool. Firstly, we will improve the dictionaries used to compute proxy perplexity, thereby enhancing the detection performance. Secondly, for closed-source models, we are unable to build their corresponding dictionaries. To mitigate it to some extent, we have considered two possible approaches:\n1) In the process of implementing LLMDet, we offer not only detection capabilities but also an extensible interface for closed-source model owners. Details about this implementation can be found in Algorithm 1 of Appendix A. The extended interface aims to secure the model effectively without compromising the interests of the model owners. Through this approach, we hope to encourage more closed-source model owners to participate and contribute to the continuous improvement of the detection ecosystem of LLMDet.\n2) We have also explored using statistical techniques to estimate the next-token probability in proprietary commercial models. However, due to limited data volume, achieving the anticipated results has been challenging. Additionally, generating a significant amount of statistical data comes with considerable costs. As a result, we have included this approach on our list of future work items.\nFurthermore, the distillation method is a valuable avenue for future exploration. We will certainly consider it in our future research endeavors.\nLimitations\nOne of the limitations of the current LLMDet is its restriction to detecting English text, thus unable to detect text in other languages. In the future, we can\nextend our approach to encompass models for other languages, thereby equipping it with the capability to detect text in diverse languages.\nFurthermore, at present, the number of models detectable by LLMDet is limited. We will expand the capabilities of our detection tool to encompass a broader range of models, providing more possibilities for text tracing and attribution.\nEthics Statement\nWe honor and support the ethical guidelines of EMNLP. This paper primarily focuses on the detection of text generated by LLMs, aiming to construct a detection tool suitable for the user base from various domains. The tool is designed to efficiently and securely perform text detection to prevent the misuse of generated text. Overall, our approach exhibits advantages over previous methods in terms of efficiency and granularity of detection, making this work meaningful. Additionally, the datasets used in this study are sourced from previously published works and do not involve any privacy or ethical concerns.\nAcknowledgements\nThis work was supported by the National Key R&D Program of China (2022YFB3103700, 2022YFB3103704), the National Natural Science Foundation of China (NSFC) under Grants No. 62276248, and the Youth Innovation Promotion Association CAS under Grants No. 2023111.\nReferences Sahar Abdelnabi and Mario Fritz. 2021. Adversarial wa-\ntermarking transformer: Towards tracing text provenance with data hiding. In 2021 IEEE Symposium on Security and Privacy (SP), pages 121\u2013140. IEEE.\nRohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, and Siamak Shakeri et al. 2023. Palm 2 technical report.\nTanya Aplin and Giulia Pasqualetto. 2019. Artificial intelligence and copyright protection. Chapter in Rosa Maria Ballardini, Petri Kuoppam\u00e4ki, Olli Pitk\u00e4nen (eds) Regulating Industrial Internet Through IPR, Data Protection and Competition Law (Kluwer, 2019).\nAnton Bakhtin, Sam Gross, Myle Ott, Yuntian Deng, Marc\u2019Aurelio Ranzato, and Arthur Szlam. 2019. Real or fake? learning to discriminate machine from human generated text.\nSid Black, Leo Gao, Phil Wang, Connor Leahy, and Stella Biderman. 2022. Gpt-neo: Large scale autoregressive language modeling with mesh-tensorflow, 2021. URL: https://doi. org/10.5281/zenodo, 5297715.\nSouradip Chakraborty, Amrit Singh Bedi, Sicheng Zhu, Bang An, Dinesh Manocha, and Furong Huang. 2023. On the possibilities of ai-generated text detection.\nDebby RE Cotton, Peter A Cotton, and J Reuben Shipway. Chatting and cheating: Ensuring academic integrity in the era of chatgpt.\nLong Dai, Jiarong Mao, Xuefeng Fan, and Xiaoyi Zhou. 2022. Deephider: A multi-module and invisibility watermarking scheme for language model. arXiv preprint arXiv:2208.04676.\nLi Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, and Hsiao-Wuen Hon. 2019. Unified language model pre-training for natural language understanding and generation. Advances in neural information processing systems, 32.\nZhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. Glm: General language model pretraining with autoregressive blank infilling. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 320\u2013335.\nTiziano Fagni, Fabrizio Falchi, Margherita Gambini, Antonio Martella, and Maurizio Tesconi. 2021. Tweepfake: About detecting deepfake tweets. Plos one, 16(5):e0251415.\nLeon Fr\u00f6hling and Arkaitz Zubiaga. 2021. Featurebased detection of automated language models: tackling gpt-2, gpt-3 and grover. PeerJ Computer Science, 7:e443.\nSebastian Gehrmann, Hendrik Strobelt, and Alexander M. Rush. 2019. Gltr: Statistical detection and visualization of generated text.\nBiyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie, Yuxuan Ding, Jianwei Yue, and Yupeng Wu. 2023. How close is chatgpt to human experts? comparison corpus, evaluation, and detection. arXiv preprint arxiv:2301.07597.\nRyuichiro Hataya, Han Bao, and Hiromi Arai. 2022. Will large-scale generative models corrupt future datasets? arXiv preprint arXiv:2211.08095.\nTim Jansen, Yangling Tong, Victoria Zevallos, and Pedro Ortiz Suarez. 2022. Perplexed by quality: A perplexity-based method for adult and harmful content detection in multilingual heterogeneous web data. arXiv preprint arXiv:2212.10440.\nGuolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu.\n2017. Lightgbm: A highly efficient gradient boosting decision tree. Advances in neural information processing systems, 30.\nJohn Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein. 2023. A watermark for large language models.\nKeita Kurita, Paul Michel, and Graham Neubig. 2020. Weight poisoning attacks on pretrained models. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2793\u2013 2806, Online. Association for Computational Linguistics.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461.\nJing Liu, Xinxin Zhu, Fei Liu, Longteng Guo, Zijia Zhao, Mingzhen Sun, Weining Wang, Hanqing Lu, Shiyu Zhou, Jiajun Zhang, et al. 2021. Opt: Omniperception pre-trainer for cross-modal understanding and generation. arXiv preprint arXiv:2107.00249.\nEric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D. Manning, and Chelsea Finn. 2023. Detectgpt: Zero-shot machine-generated text detection using probability curvature.\nShashi Narayan, Shay B. Cohen, and Mirella Lapata. 2018. Don\u2019t give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1797\u20131807, Brussels, Belgium. Association for Computational Linguistics.\nOpenAI. 2023. Gpt-4 technical report.\nLiang Pang, Yanyan Lan, Jiafeng Guo, Jun Xu, Shengxian Wan, and Xueqi Cheng. 2016. Text matching as image recognition. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 30.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research, 21(1):5485\u20135551.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ questions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2383\u20132392, Austin, Texas. Association for Computational Linguistics.\nVinu Sankar Sadasivan, Aounon Kumar, Sriram Balasubramanian, Wenxiao Wang, and Soheil Feizi. 2023. Can ai-generated text be reliably detected?\nTeven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic\u0301, Daniel Hesslow, Roman Castagn\u00e9, Alexandra Sasha Luccioni, Fran\u00e7ois Yvon, Matthias Gall\u00e9, et al. 2022. Bloom: A 176bparameter open-access multilingual language model. arXiv preprint arXiv:2211.05100.\nIrene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford, Gretchen Krueger, Jong Wook Kim, Sarah Kreps, et al. 2019. Release strategies and the social impacts of language models. arXiv preprint arXiv:1908.09203.\nRuixiang Tang, Yu-Neng Chuang, and Xia Hu. 2023. The science of detecting llm-generated texts.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023a. Llama: Open and efficient foundation language models.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, and Zheng Yan. 2023b. Llama 2: Open foundation and finetuned chat models.\nAdaku Uchendu, Thai Le, Kai Shu, and Dongwon Lee. 2020. Authorship attribution for neural text generation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8384\u20138395, Online. Association for Computational Linguistics.\nHonai Ueoka, Yugo Murawaki, and Sadao Kurohashi. 2021. Frustratingly easy edit-based linguistic steganography with a masked language model. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5486\u20135492, Online. Association for Computational Linguistics.\nA Algorithm of LLMDet\nFor the detailed implementation process of LLMDetd, please refer to the pseudocode provided below. Algorithm 1 is a dictionary construction algorithm that is completed offline by us or provided to the model holder independently of external systems. Algorithm 2 will be provided to users as a third-party tool.\nAlgorithm 1: Dictionary Construction Input :A prompt dataset P\nA large language model M Output :A dictionary D for M\n// Step1: Generate text samples Procedure GenerationText(M , P )\n// T is a generation text set T \u2190 \u2205 ; for x in P do\n// Use M to generate text t\u2190M.generate(x) ; T .append(t) ;\nend return T\n// Step2: Word frequency statistic Procedure WordStatistic(T , n)\n// Do counter for text sequence to get top-k n-gram n-gram\u2190 CountNgram(T, n, k) ; return n-gram\n// Step3: Next token probability sampling Procedure NextTokenSampling(M , P , K) // DM stores information for\nmodel M DM \u2190 \u2205 is empty list; T \u2190 GenerationText(M,P ) ; for n in {2, 3, 4} do\nDn is an empty dictionary ; n-gram\u2190 WordStatistic(T, n) ; for s in n-gram do\npw \u2190M .next_token(s[1:n\u22121]) ; Dn.add({s[1:n\u22121] : pw[1:K]}) ;\nend DM .append(Dn) ;\nend return DM\nAlgorithm 2: Text Detection Input :A piece of text t for detecting\nA list D = [DM0 , . . . , DMc ] for c LLMs and DM0 denotes human Output :A detection result R\n// Step4: Proxy perplexity estimation Procedure ProxyPerplexity(t, DM ) // Ngram () generate one text\nspan in t with length n for s, n in Ngram (t) do\nGet Dn from DM ; if s[1:n\u22121] in Dn then\np\u2190 - log(Dn.index(s[1:n\u22121])); Proxy_PPL += p ;\nend end return Proxy_PPL\n// Step5: Result ranking Procedure Rank(t,D)\nfor i in {0, . . . , c} do PPLi \u2190 ProxyPerplexity(t,DMi); end p\u2190 Classifier([PPL0, . . . ,PPLc]) ; p\u0303\u2190 smooth(p) ; p\u0302\u2190 softmat(p\u0303) ; R\u2190 sort(p\u0302) ; return R\nB LLMDet Using Newer and Larger LLM\nIn order to explore whether the gap between proxy perplexity (our method) and true perplexity becomes more apparent as the size of LLMs increases, we conduct additional experiments. We replace LLaMA-7B with LLaMA2-13B (Touvron et al., 2023b) while keeping all other experimental settings the same as in the original paper. The detailed experimental results are shown in Table 6 and Table 7.\nFrom the experimental results, when we replace the original LLM with a better-performing and larger-scale LLM, such as replacing LLaMA7B with LLaMA2-13B, the detection performance remains essentially consistent with the original performance. This indicates that when a betterperforming and larger-size LLM is used, the performance gap between proxy perplexity (our method)\nP \u2191 LLMDet with LLaMA-7B 98.54 76.09 79.08 90.81 95.61 97.55 86.86 84.67 84.45 LLMDet with LLaMA2-13B 98.45 74.67 79.97 91.47 95.70 97.46 86.64 83.15 84.60\nTrue perplexity 97.97 98.54 98.25 79.02 98.54 98.94 89.77 94.41 97.09\nR \u2191 LLMDet with LLaMA-7B 99.00 78.13 73.88 91.74 97.30 98.41 87.56 83.08 83.90 LLMDet with LLaMA2-13B 99.04 79.07 72.64 90.53 97.49 98.11 86.99 83.15 83.98\nTrue perplexity 98.99 95.92 95.70 82.25 98.46 99.73 88.44 94.29 97.61\nF1 \u2191 LLMDet with LLaMA-7B 98.77 77.09 76.39 91.27 96.44 97.98 87.21 83.87 84.18 LLMDet with LLaMA2-13B 98.74 76.80 76.13 91.00 96.58 97.78 86.82 83.47 84.29\nTrue perplexity 98.48 97.22 96.96 80.60 98.85 99.34 89.10 94.35 97.35\nand true perplexity does not become more obvious.\nC Additional Analysis for Robustness Testing\nFrom Table 4, it can be observed that as the temperature increases, the accuracy of text generation detection improves.\nRegarding this phenomenon, what we need to clarify is that our method calculates proxy perplexity by building a dictionary based on the probability of sampling the next token. When calculating the probability of the next token, we directly use the softmax with a default temperature of 1.0. When the temperature of LLM is set to 1.0, the generated text actually conforms more closely to the probability distribution of the next token in the dictionary we have constructed. At this point, the calculated proxy perplexity is closer to the true perplexity, resulting in higher detection accuracy. Therefore, we can observe that when the temperature is higher, the text distribution generated by the LLM is closer to the probability distribution of the next token in the dictionary, leading to higher detection accuracy.\nD Sample of n-gram for each LLM\nSpecific examples of 2-gram, 3-gram, and 4-gram for each LLM can be referred to in the tables. Table 8 shows the samples for GPT-2. Table 9 shows\nthe samples for OPT. Table 10 shows the samples for LLaMA. Table 11 shows the samples for T5. Table 12 shows the samples for UniLM. Table 13 shows the samples for BART. Table 14 shows the samples for GPT-Neo. Table 15 shows the samples for Bloom.\n(\u2019political\u2019, \u2019campaigning\u2019) (\u2019tower\u2019, \u2019also\u2019, \u2019features\u2019) (\u2019the\u2019, \u2019rule\u2019, \u2019to\u2019, \u2019mean\u2019) (\u2019with\u2019, \u2019patients\u2019) (\u2019lost\u2019, \u2019both\u2019, \u2019matches\u2019) (\u2019to\u2019, \u2019get\u2019, \u2019away\u2019, \u2019with\u2019) (\u2019the\u2019, \u2019Common\u2019) (\u2019of\u2019, \u2019soccer\u2019, \"\u2019\") (\u2019she\u2019, \u2019was\u2019, \u2019g\u2019, \u2019ored\u2019) (\u2019private\u2019, \u2019men\u2019) (\u2019have\u2019, \u2019been\u2019, \u2019accused\u2019) (\u2019the\u2019, \u2019area\u2019, \u2019.]\u2019, \u2019C\u2019)\n(\u2019were\u2019, \u2019victorious\u2019) (\u2019forms\u2019, \u2019of\u2019, \u2019discipline\u2019) (\u2019world\u2019, \u2019economic\u2019, \u2019crisis\u2019, \u2019,\u2019) (\u2019young\u2019, \u2019team\u2019) (\u2019man\u2019, \u2019who\u2019, \u2019may\u2019) (\u2019to\u2019, \u2019Argentina\u2019, \u2019)\u2019, \u2019on\u2019)\n(\u2019said\u2019, \u2019Se\u2019) (\u2019guessing\u2019, \u2019you\u2019, \u2019might\u2019) (\u2019people\u2019, \u2019who\u2019, \u2019are\u2019, \u2019loyal\u2019) (\u2019or\u2019, \u2019suspects\u2019) (\u2019the\u2019, \u2019court\u2019, \u2019ruled\u2019) (\u2019partners\u2019, \u2019.\u2019, \u2019C\u2019, \u2019G\u2019)\n(\u2019sound\u2019, \u2019energy\u2019) (\u2019service\u2019, \u2019.\u2019, \u2019I\u2019) (\u2019our\u2019, \u2019community\u2019, \u2019from\u2019, \u2019this\u2019) (\u2019she\u2019, \u2019beat\u2019) (\u2019physical\u2019, \u2019.\u2019, \u2019If\u2019) (\u2019train\u2019, \u2019young\u2019, \u2019boys\u2019, \u2019about\u2019)\n(\u2019political\u2019, \u2019career\u2019) (\u2019that\u2019, \u2019Mexicans\u2019, \u2019who\u2019) (\u2019the\u2019, \u2019problem\u2019, \u2019.\u2019, \u2019\"\u2019) (\u2019not\u2019, \u2019propose\u2019) (\u2019one\u2019, \u2019.\u2019, \u2019We\u2019) (\u2019to\u2019, \u2019Barb\u2019, \u2019ados\u2019, \u2019on\u2019) (\u2019today\u2019, \u2019accepted\u2019) (\u2019share\u2019, \u2019of\u2019, \u2019online\u2019) (\u2019them\u2019, \u2019.\u2019, \u2019I\u2019, \"\u2019m\") (\u2019was\u2019, \u2019slow\u2019) (\u2019was\u2019, \u2019walking\u2019, \u2019with\u2019) (\u2019of\u2019, \u2019the\u2019, \u2019UEFA\u2019, \u2019presidential\u2019)\n(\u2019receive\u2019, \u2019government\u2019) (\u2019the\u2019, \u2019largest\u2019, \u2019ever\u2019) (\u2019questioned\u2019, \u2019for\u2019, \u2019a\u2019, \u2019week\u2019) (\u2019v\u2019, \u2019Arsenal\u2019) (\u2019the\u2019, \u2019shark\u2019, \u2019,\u2019) (\u2019think\u2019, \u2019this\u2019, \u2019is\u2019, \u2019incorrect\u2019) (\u2019the\u2019, \u2019notes\u2019) (\u2019to\u2019, \u2019have\u2019, \u2019abused\u2019) (\u2019who\u2019, \u2019had\u2019, \u2019been\u2019, \u2019shot\u2019)\n(\u2019smooth\u2019, \u2019and\u2019) (\u2019inquest\u2019, \u2019is\u2019, \u2019now\u2019) (\u2019other\u2019, \u2019animals\u2019, \u2019that\u2019, \u2019have\u2019) (\u2019their\u2019, \u2019views\u2019) (\u2019meet\u2019, \u2019President\u2019, \u2019Ts\u2019) (\u2019sale\u2019, \u2019on\u2019, \u2019the\u2019, \u2019market\u2019)\n(\u2019powerful\u2019, \u2019laser\u2019) (\u2019in\u2019, \u2019the\u2019, \u2019procession\u2019) (\u2019struck\u2019, \u2019our\u2019, \u2019city\u2019, \u2019.\u2019) (\u2019perspective\u2019, \u2019\"\u2019) (\u2019that\u2019, \u2019is\u2019, \u2019littered\u2019) (\u2019on\u2019, \u2019Sky\u2019, \u2019Sports\u2019, \u20191\u2019) (\u2019was\u2019, \u2019introduced\u2019) (\u2019own\u2019, \u2019right\u2019, \u2019which\u2019) (\u2019of\u2019, \u2019the\u2019, \u2019film\u2019, \u2019has\u2019) (\u2019said\u2019, \u2019Theresa\u2019) (\u2019justice\u2019, \u2019is\u2019, \u2019fair\u2019) (\u2019that\u2019, \u2019is\u2019, \u2019made\u2019, \u2019for\u2019)\n(\u2019train\u2019, \u2019.\u2019) (\u2019it\u2019, \u2019was\u2019, \u2019before\u2019) (\u2019where\u2019, \u2019Richard\u2019, \u2019III\u2019, \u2019was\u2019) (\u2019was\u2019, \u2019initially\u2019) (\u2019to\u2019, \u2019get\u2019, \u2019land\u2019) (\u2019teaching\u2019, \u2019children\u2019, \u2019about\u2019, \u2019\"\u2019)\n(\u2019to\u2019, \u2019rect\u2019) (\u2019has\u2019, \u2019remained\u2019, \u2019silent\u2019) (\u2019winner\u2019, \u2019will\u2019, \u2019receive\u2019, \u2019a\u2019) (\u2019now\u2019, \u2019no\u2019) (\u2019match\u2019, \u2019C\u2019, \u2019-\u2019) (\u2019the\u2019, \u2019state\u2019, \u2019government\u2019, \u2019dissolved\u2019)\n(\u2019their\u2019, \u2019tuition\u2019) (\u2019in\u2019, \u2019these\u2019, \u2019jobs\u2019) (\u2019the\u2019, \u2019money\u2019, \u2019,\u2019, \u2019people\u2019) (\u2019seas\u2019, \u2019off\u2019) (\u2019installed\u2019, \u2019with\u2019, \u2019proper\u2019) (\u2019the\u2019, \u2019Irish\u2019, \u2019Cup\u2019, \u2019in\u2019)\n(\u2019play\u2019, \u2019Miss\u2019) (\u2019season\u2019, \u2019at\u2019, \u2019Villa\u2019) (\u2019on\u2019, \u2019the\u2019, \u2019Rights\u2019, \u2019of\u2019) (\u2019then\u2019, \u2019punched\u2019) (\u2019same\u2019, \u2019venue\u2019, \u2019(\u2019) (\u2019shore\u2019, \u2019line\u2019, \u2019.\u2019, \u2019It\u2019) (\u2019patients\u2019, \u2019living\u2019) (\u2019when\u2019, \u2019a\u2019, \u2019report\u2019) (\u2019production\u2019, \u2019company\u2019, \u2019.\u2019, \u2019C\u2019)\n(\u2019not\u2019, \u2019right\u2019) (\u2019that\u2019, \u2019Mrs\u2019, \u2019Mat\u2019) (\u2019play\u2019, \u2019a\u2019, \u2019movie\u2019, \u2019,\u2019) (\u2019spin\u2019, \u2019a\u2019) (\u2019great\u2019, \u2019work\u2019, \u2019we\u2019) (\u2019remember\u2019, \u2019that\u2019, \u2019mid\u2019, \u2019-\u2019) (\u2019usual\u2019, \u2019\"\u2019) (\u2019the\u2019, \u2019group\u2019, \u2019of\u2019) (\u2019to\u2019, \u2019say\u2019, \u2019that\u2019, \u2019your\u2019)\n(\u2019push\u2019, \u2019their\u2019) (\u2019for\u2019, \u2019all\u2019, \u2019involved\u2019) (\u2019taken\u2019, \u2019it\u2019, \u2019down\u2019, \u2019.\u2019) (\u2019zoo\u2019, \u2019or\u2019) (\u2019i\u2019, \u2019h\u2019, \u2019lf\u2019) (\u2019that\u2019, \u2019E\u2019, \u2019On\u2019, \u2019continues\u2019)\n(\u2019was\u2019, \u2019talking\u2019) (\u2019on\u2019, \u2019all\u2019, \u2019his\u2019) (\u2019to\u2019, \u2019a\u2019, \u2019harmful\u2019, \u2019retribution\u2019) (\u2019obvious\u2019, \u2019:\u2019) (\u2019time\u2019, \u2019.\u2019, \u2019They\u2019) (\u2019still\u2019, \u2019in\u2019, \u2019college\u2019, \u2019in\u2019) (\u2019said\u2019, \u2019Pac\u2019) (\u2019new\u2019, \"\u2019s\", \u2019ocial\u2019) (\u2019violence\u2019, \u2019in\u2019, \u2019the\u2019, \u2019gay\u2019)\n(\u2019overflow\u2019, \u2019lane\u2019) (\u2019the\u2019, \u2019pub\u2019, \u2019in\u2019) (\u2019with\u2019, \u2019him\u2019, \u2019.\u2019, \u2019His\u2019) (\u2019the\u2019, \u2019Gibraltar\u2019) (\u2019let\u2019, \u2019out\u2019, \u2019\"\u2019) (\u2019where\u2019, \u2019they\u2019, \u2019train\u2019, \u2019for\u2019) (\u2019showed\u2019, \u2019great\u2019) (\u2019was\u2019, \u2019released\u2019, \u2019on\u2019) (\u2019our\u2019, \u2019finances\u2019, \u2019.\u2019, \u2019We\u2019)\n(\u2019that\u2019, \u2019year\u2019) (\u2019the\u2019, \u2019couple\u2019, \u2019with\u2019) (\u2019to\u2019, \u2019ensure\u2019, \u2019their\u2019, \u2019success\u2019) (\u2019yours\u2019, \u2019,\u2019) (\u2019is\u2019, \u2019at\u2019, \u2019.\"\u2019) (\u2019the\u2019, \u2019stolen\u2019, \u2019car\u2019, \u2019,\u2019)\n(\u2019of\u2019, \u2019investments\u2019) (\u2019have\u2019, \u2019obtained\u2019, \u2019a\u2019) (\u2019to\u2019, \u2019prevent\u2019, \u2019future\u2019, \u2019attacks\u2019) (\u2019other\u2019, \u2019hints\u2019) (\u2019to\u2019, \u2019let\u2019, \u2019it\u2019) (\u2019our\u2019, \u2019series\u2019, \u2019and\u2019, \u2019will\u2019)\n(\u2019of\u2019, \u2019Mosul\u2019) (\u2019private\u2019, \u2019college\u2019, \u2019should\u2019) (\u2019started\u2019, \u2019collaborating\u2019, \u2019to\u2019, \u2019solve\u2019) (\u2019recent\u2019, \u2019video\u2019) (\u2019then\u2019, \u2019come\u2019, \u2019back\u2019) (\u2019the\u2019, \u2019Guardian\u2019, \u2019last\u2019, \u2019year\u2019)\n(\u2019o\u2019, \u2019lymp\u2019) (\u2019idiot\u2019, \u2019.\u2019, \u2019This\u2019) (\u2019other\u2019, \u2019candidates\u2019, \u2019.\u2019, \u2019C\u2019) (\u2019to\u2019, \u2019Sel\u2019) (\u2019on\u2019, \u2019to\u2019, \u2019her\u2019) (\u2019tourist\u2019, \u2019was\u2019, \u2019missing\u2019, \u2019,\u2019) (\u2019requests\u2019, \u2019to\u2019) (\u2019pl\u2019, \u2019umes\u2019, \u2019was\u2019) (\u2019outfit\u2019, \u2019for\u2019, \u2019a\u2019, \u2019wedding\u2019) (\u2019that\u2019, \u2019four\u2019) (\u2019material\u2019, \u2019.\u2019, \u2019He\u2019) (\u2019who\u2019, \u2019Mar\u2019, \u2019low\u2019, \u2019e\u2019) (\u2019pattern\u2019, \u2019.\u2019) (\u2019doctor\u2019, \u2019prescribed\u2019, \u2019me\u2019) (\u2019seen\u2019, \u2019used\u2019, \u2019on\u2019, \u2019the\u2019)\n(\u2019ultimate\u2019, \u2019opportun\u2019) (\u2019to\u2019, \u2019win\u2019, \u2019promotion\u2019) (\u2019managed\u2019, \u2019to\u2019, \u2019maintain\u2019, \u2019my\u2019) (\u2019you\u2019, \u2019if\u2019) (\u2019got\u2019, \u2019no\u2019, \u2019problem\u2019) (\u2019of\u2019, \u2019the\u2019, \u2019London\u2019, \u2019bombings\u2019)\n(\u2019team\u2019, \u2019players\u2019) (\u2019published\u2019, \u2019in\u2019, \u2019February\u2019) (\u2019run\u2019, \u2019.\u2019, \u2019The\u2019, \u2019problem\u2019) (\u2019quicker\u2019, \u2019.\u2019) (\u2019want\u2019, \u2019to\u2019, \u2019move\u2019) (\u2019this\u2019, \u2019movie\u2019, \u2019is\u2019, \u2019complete\u2019) (\u2019systems\u2019, \u2019\"\u2019) (\u2019offence\u2019, \u2019of\u2019, \u2019\"\u2019) (\u2019the\u2019, \u2019front\u2019, \u2019door\u2019, \u2019to\u2019) (\u2019team\u2019, \u2019culture\u2019) (\u2019without\u2019, \u2019undermining\u2019, \u2019the\u2019) (\u2019page\u2019, \u2019of\u2019, \u2019the\u2019, \u2019Hong\u2019) (\u2019son\u2019, \u2019away\u2019) (\u2019event\u2019, \u2019on\u2019, \u2019February\u2019) (\u2019vandalism\u2019, \u2019without\u2019, \u2019the\u2019, \u2019people\u2019) (\u2019themselves\u2019, \u2019for\u2019) (\u2019not\u2019, \u2019officially\u2019, \u2019recognised\u2019) (\u2019the\u2019, \u2019energy\u2019, \u2019sector\u2019, \u2019in\u2019) (\u2019your\u2019, \u2019school\u2019) (\u2019than\u2019, \u2019a\u2019, \u2019typical\u2019) (\u2019natural\u2019, \u2019selection\u2019, \u2019.\u2019, \u2019Sometimes\u2019) (\u2019winding\u2019, \u2019roads\u2019) (\u2019first\u2019, \u2019.\u2019, \u2019If\u2019) (\u2019the\u2019, \u2019same\u2019, \u2019stadium\u2019, \u2019and\u2019) (\u2019of\u2019, \u2019Idlib\u2019) (\u2019effort\u2019, \u2019from\u2019, \u2019C\u2019) (\u2019selling\u2019, \u2019information\u2019, \u2019regarding\u2019, \u2019a\u2019) (\u2019of\u2019, \u2019seven\u2019) (\u2019progressed\u2019, \u2019through\u2019, \u2019the\u2019) (\u2019limit\u2019, \u2019,\u2019, \u2019especially\u2019, \u2019in\u2019)\n(\u2019subsequently\u2019, \u2019charged\u2019) (\u2019the\u2019, \u2019Blues\u2019, \u2019.\u2019) (\u2019that\u2019, \u2019.\u2019, \u2019I\u2019, \u2019just\u2019) (\u2019site\u2019, \u2019AH\u2019) (\u2019tigers\u2019, \u2019in\u2019, \u2019captivity\u2019) (\u2019some\u2019, \u2019sort\u2019, \u2019,\u2019, \u2019at\u2019)\n(\u2019perform\u2019, \u2019tasks\u2019) (\u2019gl\u2019, \u2019iding\u2019, \u2019.\u2019) (\u2019one\u2019, \u2019is\u2019, \u2019the\u2019, \u2019most\u2019) (\u2019to\u2019, \u2019these\u2019) (\u2019this\u2019, \u2019has\u2019, \u2019not\u2019) (\u2019to\u2019, \u2019Deputy\u2019, \u2019First\u2019, \u2019Minister\u2019)\n(\u2019remember\u2019, \u2019who\u2019) (\u2019hosts\u2019, \u2019Japan\u2019, \u2019,\u2019) (\u2019lists\u2019, \u2019and\u2019, \u2019the\u2019, \u2019fact\u2019) (\u2019participate\u2019, \u2019and\u2019) (\u2019signed\u2019, \u201920\u2019, \u2019-\u2019) (\u2019they\u2019, \"\u2019re\", \u2019old\u2019, \u2019enough\u2019) (\u2019worked\u2019, \u2019because\u2019) (\u2019term\u2019, \u2019\"\u2019, \u2019less\u2019) (\u2019pay\u2019, \u2019a\u2019, \u2019tax\u2019, \u2019in\u2019)\n(\u2019too\u2019, \u2019if\u2019) (\u2019excessive\u2019, \u2019force\u2019, \u2019against\u2019) (\u2019their\u2019, \u2019fury\u2019, \u2019and\u2019, \u2019carnage\u2019) (\u2019otherwise\u2019, \u2019damaged\u2019) (\u2019make\u2019, \u2019the\u2019, \u2019match\u2019) (\u2019were\u2019, \u2019to\u2019, \u2019acknowledge\u2019, \u2019him\u2019)\n(\u2019on\u2019, \u2019Ukrainian\u2019) (\u2019to\u2019, \u2019Europe\u2019, \u2019,\u2019) (\u2019now\u2019, \u2019.\u2019, \u2019I\u2019, \u2019don\u2019) (\u2019smack\u2019, \u2019in\u2019) (\u2019which\u2019, \u2019won\u2019, \u2019the\u2019) (\u2019that\u2019, \u2019the\u2019, \u2019collision\u2019, \u2019was\u2019)\n(\u2019l\u2019, \u2019[\u2019) (\u2019think\u2019, \u2019he\u2019, \"\u2019d\") (\u2019repeat\u2019, \u2019of\u2019, \u2019the\u2019, \u2019previous\u2019) (\u2019owner\u2019, \u2019did\u2019) (\u2019no\u2019, \u2019and\u2019, \u2019they\u2019) (\u2019then\u2019, \u2019,\u2019, \u2019of\u2019, \u2019course\u2019) (\u2019single\u2019, \u2019run\u2019) (\u2019of\u2019, \u2019glass\u2019, \u2019and\u2019) (\u2019man\u2019, \u2019who\u2019, \u2019beat\u2019, \u2019the\u2019) (\u2019was\u2019, \u2019pulling\u2019) (\u2019how\u2019, \u2019his\u2019, \u2019team\u2019) (\u2019of\u2019, \u2019someone\u2019, \u2019on\u2019, \u2019that\u2019) (\u2019the\u2019, \u2019influenza\u2019) (\u2019of\u2019, \u2019data\u2019, \u2019that\u2019) (\u2019when\u2019, \u2019the\u2019, \u2019victim\u2019, \u2019was\u2019) (\u2019of\u2019, \u2019pressure\u2019) (\u2019friend\u2019, \u2019who\u2019, \u2019suffers\u2019) (\u2019said\u2019, \u2019captain\u2019, \u2019Jamie\u2019, \u2019Stir\u2019)\n(\u2019services\u2019, \u2019during\u2019) (\u2019their\u2019, \u2019compla\u2019, \u2019ints\u2019) (\u2019the\u2019, \u2019Masters\u2019, \u2019in\u2019, \u2019his\u2019) (\u2019the\u2019, \u2019IT\u2019) (\u2019professional\u2019, \u2019Hollywood\u2019, \u2019set\u2019) (\u2019to\u2019, \u2019follow\u2019, \u2019the\u2019, \u2019next\u2019)\n(\u2019woman\u2019, \u2019on\u2019) (\u2019the\u2019, \u2019streets\u2019, \u2019.\u2019) (\u2019walking\u2019, \u2019along\u2019, \u2019the\u2019, \u2019edge\u2019) (\u2019while\u2019, \u2019G\u2019) (\u2019strong\u2019, \u2019squad\u2019, \u2019,\u2019) (\u2019will\u2019, \u2019use\u2019, \u2019the\u2019, \u2019E\u2019)\n(\u2019reports\u2019, \u2019make\u2019) (\u2019per\u2019, \u2019day\u2019, \u2019.\u2019) (\u2019the\u2019, \u2019injured\u2019, \u2019were\u2019, \u2019children\u2019) (\u2019signed\u2019, \u2019Ar\u2019) (\u2019touched\u2019, \u2019as\u2019, \u2019a\u2019) (\u2019the\u2019, \u2019Title\u2019, \u2019VII\u2019, \u2019of\u2019)\n(\u2019workers\u2019, \u2019above\u2019) (\u2019to\u2019, \u2019light\u2019, \u2019after\u2019) (\u2019to\u2019, \u2019Son\u2019, \u2019ar\u2019, \u2019Qu\u2019) (\u2019requirement\u2019, \u2019does\u2019) (\u2019tent\u2019, \u2019that\u2019, \u2019he\u2019) (\u2019the\u2019, \u2019resources\u2019, \u2019to\u2019, \u2019respond\u2019) (\u2019some\u2019, \u2019thousands\u2019) (\u2019opening\u2019, \u2019took\u2019, \u2019place\u2019) (\u2019volunte\u2019, \u2019ering\u2019, \u2019at\u2019, \u2019her\u2019)\n(\u2019the\u2019, \u2019bigger\u2019) (\u2019play\u2019, \u2019,\u2019, \u2019Henry\u2019) (\u2019which\u2019, \u2019are\u2019, \u2019responsible\u2019, \u2019for\u2019) (\u2019study\u2019, \u2019but\u2019) (\u2019tie\u2019, \u2019against\u2019, \u2019D\u2019) (\u2019shows\u2019, \u2019ins\u2019, \u2019ur\u2019, \u2019ers\u2019) (\u2019then\u2019, \u2019return\u2019) (\u2019officials\u2019, \u2019in\u2019, \u2019Py\u2019) (\u2019to\u2019, \u2019current\u2019, \u2019Health\u2019, \u2019Secretary\u2019) (\u2019the\u2019, \u2019purs\u2019) (\u2019of\u2019, \u2019negative\u2019, \u2019economic\u2019) (\u2019way\u2019, \u2019to\u2019, \u2019New\u2019, \u2019Hope\u2019) (\u2019the\u2019, \u2019tall\u2019) (\u2019should\u2019, \u2019consider\u2019, \u2019an\u2019) (\u2019to\u2019, \u2019the\u2019, \u2019aircraft\u2019, \u2019,\u2019)\n(\u2019remain\u2019, \u2019unclear\u2019) (\u2019year\u2019, \u2019reve\u2019, \u2019als\u2019) (\u2019signs\u2019, \u2019to\u2019, \u2019better\u2019, \u2019represent\u2019) (\u2019stronger\u2019, \u2019start\u2019) (\u2019that\u2019, \u2019libraries\u2019, \u2019offer\u2019) (\u2019the\u2019, \u2019Australian\u2019, \u2019Government\u2019, \u2019has\u2019)\n(\u2019that\u2019, \u2019while\u2019) (\u2019on\u2019, \u2019Russia\u2019, \u2019,\u2019) (\u2019under\u2019, \u2019ne\u2019, \u2019ath\u2019, \u2019.\u2019) (\u2019with\u2019, \u2019Niger\u2019) (\u2019the\u2019, \u2019super\u2019, \u2019visor\u2019) (\u2019week\u2019, \u2019in\u2019, \u2019the\u2019, \u2019U\u2019) (\u2019she\u2019, \u2019holds\u2019) (\u2019r\u2019, \u2019ides\u2019, \u2019.\u2019) (\u2019the\u2019, \u2019trip\u2019, \u2019to\u2019, \u2019S\u2019) (\u2019spot\u2019, \u2019where\u2019) (\u2019sector\u2019, \u2019,\u2019, \u2019to\u2019) (\u2019shooting\u2019, \u2019on\u2019, \u2019Sunday\u2019, \u2019morning\u2019) (\u2019spot\u2019, \u2019,\"\u2019) (\u2019su\u2019, \u2019cker\u2019, \u2019p\u2019) (\u2019the\u2019, \u2019discovery\u2019, \u2019of\u2019, \u2019the\u2019)\n(\u2019take\u2019, \u2019responsibility\u2019) (\u2019put\u2019, \u2019an\u2019, \u2019end\u2019) (\u2019to\u2019, \u2019a\u2019, \u2019Liberal\u2019, \u2019Dem\u2019) (\u2019week\u2019, \u2019since\u2019) (\u2019use\u2019, \u2019the\u2019, \u2019art\u2019) (\u2019to\u2019, \u2019take\u2019, \u2019action\u2019, \u2019.\u2019)\n(\u2019what\u2019, \u2019actions\u2019) (\u2019some\u2019, \u2019new\u2019, \u2019people\u2019) (\u2019went\u2019, \u2019wrong\u2019, \u2019.\u2019, \u2019I\u2019) (\u2019week\u2019, \u2019announced\u2019) (\u2019team\u2019, \u2019call\u2019, \u2019-\u2019) (\u2019young\u2019, \u2019woman\u2019, \u2019while\u2019, \u2019she\u2019)\n(\u2019were\u2019, \u2019split\u2019) (\u2019of\u2019, \u2019CR\u2019, \u2019PF\u2019) (\u2019with\u2019, \u2019clubs\u2019, \u2019such\u2019, \u2019as\u2019) (\u2019sensitive\u2019, \u2019.\u2019) (\u2019province\u2019, \u2019of\u2019, \u2019Gal\u2019) (\u2019total\u2019, \u2019,\u2019, \u2019approximately\u2019, \u201d) (\u2019the\u2019, \u2019stem\u2019) (\u2019slo\u2019, \u2019ppy\u2019, \u2019at\u2019) (\u2019these\u2019, \u2019suspect\u2019, \u2019s\u2019, \u2019are\u2019) (\u2019with\u2019, \u2019cred\u2019) (\u2019when\u2019, \u2019she\u2019, \u2019fought\u2019) (\u2019the\u2019, \u2019pool\u2019, \u2019f\u2019, \u2019encing\u2019) (\u2019regarding\u2019, \u2019Islam\u2019) (\u2019pay\u2019, \u2019rise\u2019, \u2019they\u2019) (\u2019the\u2019, \u2019process\u2019, \u2019is\u2019, \u2019that\u2019) (\u2019this\u2019, \u2019before\u2019) (\u2019to\u2019, \u2019the\u2019, \u2019bands\u2019) (\u2019visitors\u2019, \u2019a\u2019, \u2019year\u2019, \u2019,\u2019) (\u2019their\u2019, \u2019hands\u2019) (\u2019our\u2019, \u2019operations\u2019, \u2019and\u2019) (\u2019to\u2019, \u2019Gl\u2019, \u2019ouc\u2019, \u2019esters\u2019) (\u2019supp\u2019, \u2019lier\u2019) (\u2019underlying\u2019, \u2019coll\u2019, \u2019ater\u2019) (\u2019with\u2019, \u201d, \u20191\u2019, \u20199\u2019) (\u2019shoot\u2019, \u2019and\u2019) (\u2019now\u2019, \u2019,\"\u2019, \u2019she\u2019) (\u2019surv\u2019, \u2019ive\u2019, \u2019\u201d\u2019, \u2019and\u2019) (\u2019recovery\u2019, \u2019.\u2019) (\u2019of\u2019, \u2019deb\u2019, \u2019ts\u2019) (\u2019was\u2019, \u2019still\u2019, \u2019very\u2019, \u2019tight\u2019) (\u2019to\u2019, \u2019migr\u2019) (\u2019team\u2019, \u2019that\u2019, \u2019took\u2019) (\u2019tax\u2019, \u2019bill\u2019, \u2019ever\u2019, \u2019handed\u2019)\n(\u2019struggling\u2019, \u2019this\u2019) (\u2019remaining\u2019, \u2019to\u2019, \u2019take\u2019) (\u2019wild\u2019, \u2019f\u2019, \u2019ires\u2019, \u2019that\u2019) (\u2019summar\u2019, \u2019ize\u2019) (\u2019of\u2019, \u2019the\u2019, \u2019del\u2019) (\u2019vehicle\u2019, \u2019and\u2019, \u2019a\u2019, \u2019ped\u2019)\n(\u2019society\u2019, \u2019which\u2019) (\u2019the\u2019, \u2019problem\u2019, \u2019before\u2019) (\u2019simple\u2019, \u2019concept\u2019, \u2019.\u2019, \u2019Well\u2019) (\u2019settlement\u2019, \u2019with\u2019) (\u2019whose\u2019, \u2019client\u2019, \u2019died\u2019) (\u2019to\u2019, \u2019driving\u2019, \u2019an\u2019, \u2019older\u2019)\n(\u2019that\u2019, \u2019fac\u2019) (\u2019yard\u2019, \u2019lines\u2019, \u2019and\u2019) (\u2019which\u2019, \u2019he\u2019, \u2019highlight\u2019, \u2019ed\u2019) (\u2019was\u2019, \u2019smart\u2019) (\u2019recip\u2019, \u2019ient\u2019, \u2019will\u2019) (\u2019thr\u2019, \u2019illing\u2019, \u2019cl\u2019, \u2019ash\u2019)\n(\u2019\u2018\u2019, \u2019K\u2019) (\u2019series\u2019, \u2019,\u2019, \u2019winning\u2019) (\u2019village\u2019, \u2019of\u2019, \u2019V\u2019, \u2019ran\u2019)\n(\u2019the\u2019, \u2019events\u2019) (\u2019who\u2019, \u2019are\u2019, \u2019assigned\u2019) (\u2019waste\u2019, \u2019must\u2019, \u2019be\u2019, \u2019removed\u2019) (\u2019proposed\u2019, \u2019location\u2019) (\u2019the\u2019, \u2019Syrian\u2019, \u2019people\u2019) (\u2019which\u2019, \u2019is\u2019, \u2019funded\u2019, \u2019by\u2019)\n(\u2019way\u2019, \u2019our\u2019) (\u2019sold\u2019, \u2019in\u2019, \u20191986\u2019) (\u2019the\u2019, \u2019British\u2019, \u2019government\u2019, \u2019is\u2019) (\u2019working\u2019, \u2019pitches\u2019) (\u2019report\u2019, \u2019his\u2019, \u2019disappear\u2019) (\u2019the\u2019, \u2019anterior\u2019, \u2019anterior\u2019, \u201d)\n(\u2019sixth\u2019, \u2019minutes\u2019) (\u2019which\u2019, \u2019was\u2019, \u2019discovered\u2019) (\u2019very\u2019, \u2019difficult\u2019, \u2019job\u2019, \u2019,\"\u2019) (\u2019thirst\u2019, \u2019.\u2019) (\u2019was\u2019, \u2019given\u2019, \u2019bail\u2019) (\u2019was\u2019, \u2019to\u2019, \u2019be\u2019, \u201d)\n(\u2019successor\u2019, \u2019.\u2019) (\u2019the\u2019, \u2019experience\u2019, \u2019and\u2019) (\u2019troops\u2019, \u2019are\u2019, \u2019transferred\u2019, \u2019to\u2019) (\u2019we\u2019, \u2019all\u2019) (\u2019to\u2019, \u2019the\u2019, \u2019left\u2019) (\u2019what\u2019, \u2019we\u2019, \u2019did\u2019, \u2019.\u2019)\n(\u2019want\u2019, \u2019me\u2019) (\u2019under\u2019, \u2019the\u2019, \u2019following\u2019) (\u2019to\u2019, \u2019provide\u2019, \u2019for\u2019, \u2019their\u2019) (\u2019returned\u2019, \u2019with\u2019) (\u2019that\u2019, \u2019Mr\u2019, \u2019Cro\u2019) (\u2019the\u2019, \u2019math\u2019, \u2019is\u2019, \u2019only\u2019)\n(\u2019was\u2019, \u2019watch\u2019) (\u2019station\u2019, \u2019in\u2019, \u2019London\u2019) (\u2019track\u2019, \u2019.\u2019, \u2019The\u2019, \u2019San\u2019) (\u2019their\u2019, \u2019faces\u2019) (\u2019seek\u2019, \u2019to\u2019, \u2019promote\u2019) (\u2019website\u2019, \u2019.\u2019, \u2019Mr\u2019, \u2019Burke\u2019) (\u2019shot\u2019, \u2019past\u2019) (\u2019office\u2019, \u2019closed\u2019, \u2019.\u2019) (\u2019the\u2019, \u2019first\u2019, \u2019lady\u2019, \u2019is\u2019) (\u2019trainer\u2019, \u2019Dan\u2019) (\u2019that\u2019, \u2019Walt\u2019, \u2019Disney\u2019) (\u2019was\u2019, \u2019cleared\u2019, \u2019of\u2019, \u2019all\u2019) (\u2019the\u2019, \u2019lower\u2019) (\u2019seemed\u2019, \u2019like\u2019, \u2019it\u2019) (\u2019work\u2019, \u2019due\u2019, \u2019to\u2019, \u201d)\n(\u2019the\u2019, \u2019Caribbean\u2019) (\u2019very\u2019, \u2019few\u2019, \u2019people\u2019) (\u2019to\u2019, \u2019use\u2019, \u2019its\u2019, \u2019own\u2019) (\u2019wildlife\u2019, \u2019groups\u2019) (\u2019unhealthy\u2019, \u2019fat\u2019, \u2019fat\u2019) (\u2019while\u2019, \u2019,\u2019, \u2019but\u2019, \u2019the\u2019)\n(\u2019the\u2019, \u2019Bee\u2019) (\u2019of\u2019, \u2019the\u2019, \u2019heavy\u2019) (\u2019with\u2019, \u2019the\u2019, \u2019Securities\u2019, \u2019and\u2019) (\u2019your\u2019, \u2019advanced\u2019) (\u2019strong\u2019, \u2019transport\u2019, \u2019network\u2019) (\u2019that\u2019, \u2019an\u2019, \u2019arrest\u2019, \u2019has\u2019) (\u2019winning\u2019, \u2019player\u2019) (\u2019so\u2019, \u2019unfortunately\u2019, \u2019no\u2019) (\u2019was\u2019, \u201d, \u2019largely\u2019, \u2019used\u2019)\n(\u2019successful\u2019, \u2019?\u2019) (\u2019\u201c\u2019, \u2019Un\u2019, \u2019der\u2019) (\u2019there\u2019, \"\u2019\", \u2019s\u2019, \u2019more\u2019) (\u2019were\u2019, \u2019disappointed\u2019) (\u2019was\u2019, \u2019driving\u2019, \u2019,\u2019) (\u2019the\u2019, \u201d, \u2019i\u2019, \u2019Gen\u2019)\n(\u2019why\u2019, \u2019an\u2019) (\u2019project\u2019, \u2019has\u2019, \u2019raised\u2019) (\u2019the\u2019, \u2019best\u2019, \u2019known\u2019, \u2019play\u2019) (\u2019represented\u2019, \u2019her\u2019) (\u2019opportunity\u2019, \u2019to\u2019, \u2019help\u2019) (\u2019then\u2019, \u2019charged\u2019, \u201d, \u2019a\u2019)\n(\u2019promote\u2019, \u2019investment\u2019) (\u2019our\u2019, \u2019products\u2019, \u2019and\u2019) (\u2019the\u2019, \u2019drug\u2019, \u2019on\u2019, \u2019the\u2019) (\u2019soldier\u2019, \u2019and\u2019) (\u2019plunge\u2019, \u2019in\u2019, \u2019the\u2019) (\u2019them\u2019, \u2019from\u2019, \u2019becoming\u2019, \u2019the\u2019)\n(\u2019started\u2019, \u2019shooting\u2019) (\u2019or\u2019, \u2019delete\u2019, \u2019any\u2019) (\u2019to\u2019, \u2019tell\u2019, \u2019.\u2019, \u2019It\u2019) (\u2019visiting\u2019, \u2019the\u2019) (\u2019of\u2019, \u2019my\u2019, \u2019way\u2019) (\u2019which\u2019, \u2019ran\u2019, \u2019from\u2019, \u201912\u2019) (\u2019questions\u2019, \u2019.\"\u2019) (\u2019raised\u2019, \u2019the\u2019, \u2019limit\u2019) (\u2019that\u2019, \u2019Scotland\u2019, \u2019can\u2019, \u2019win\u2019)\n(\u2019informal\u2019, \u2019economy\u2019) (\u2019earnings\u2019, \u2019were\u2019, \u2019affected\u2019) (\u2019scored\u2019, \u2019a\u2019, \u2019few\u2019, \u2019goals\u2019) (\u2019sword\u2019, \u2019that\u2019) (\u2019round\u2019, \u2019stone\u2019, \u2019co\u2019) (\u2019he\u2019, \u2019was\u2019, \u2019talking\u2019, \u2019about\u2019) (\u2019great\u2019, \u2019are\u2019) (\u2019ka\u2019, \u2019wasaki\u2019, \u2019from\u2019) (\u2019parked\u2019, \u2019his\u2019, \u2019car\u2019, \u2019in\u2019)\n(\u2019which\u2019, \u2019features\u2019) (\u2019super\u2019, \u2019sh\u2019, \u2019ow\u2019) (\u2019national\u2019, \u2019team\u2019, \u2019,\u2019, \u2019winning\u2019) (\u2019responsibility\u2019, \u2019is\u2019) (\u2019modern\u2019, \u2019\"\u2019, \u2019d\u2019) (\u2019out\u2019, \u2019her\u2019, \u2019j\u2019, \u2019an\u2019) (\u2019was\u2019, \u2019convicted\u2019) (\u2019and\u2019, \u2019investment\u2019, \u2019.\u2019) (\u2019would\u2019, \u2019see\u2019, \u2019her\u2019, \u2019father\u2019) (\u2019grandparents\u2019, \u2019.\u2019) (\u2019division\u2019, \u2019was\u2019, \u2019never\u2019) (\u2019say\u2019, \u2019it\u2019, \"\u2019\", \u2019s\u2019)\n(\u2019she\u2019, \u2019gets\u2019) (\u2019facto\u2019, \u2019\"\u2019, \u2019protector\u2019) (\u2019the\u2019, \u2019mid\u2019, \u2019-\u2019, \u201918th\u2019) (\u2019showing\u2019, \u2019the\u2019) (\u2019nak\u2019, \u2019a\u2019, \u2019,\u2019) (\u2019they\u2019, \u201d\u2019, \u2019re\u2019, \u2019spa\u2019)\n(\u2019is\u2019, \u2019really\u2019) (\u201924\u2019, \u2019de\u2019, \u2019c\u2019) (\u2019in\u2019, \u2019thieves\u2019, \u201d\u2019, \u2019den\u2019) (\u2019thank\u2019, \u2019goodness\u2019) (\u2019changes\u2019, \u2019to\u2019, \u2019the\u2019) (\u2019the\u2019, \u2019throat\u2019, \u2019of\u2019, \u2019ka\u2019)\n(\u2019smaller\u2019, \u2019bathroom\u2019) (\u2019new\u2019, \u2019estimate\u2019, \u2019.\u2019) (\u2019to\u2019, \u2019the\u2019, \u2019haze\u2019, \u2019ln\u2019) (\u2019main\u2019, \u2019reason\u2019) (\u2019g\u2019, \u2019ba\u2019, \u2019,\u2019) (\u2019the\u2019, \u2019title\u2019, \u2019is\u2019, \u2019initially\u2019)\n(\u2019not\u2019, \u2019con\u2019) (\u2019her\u2019, \u2019pain\u2019, \u2019.\u2019) (\u2019ransom\u2019, \u2019ware\u2019, \u2019.\u2019, \u2019it\u2019) (\u2019team\u2019, \u2019,\u2019) (\u2019her\u2019, \u2019were\u2019, \u2019at\u2019) (\u2019nak\u2019, \u2019hir\u2019, \u2019ni\u2019, \u2019sa\u2019) (\u2019my\u2019, \u2019ear\u2019) (\u2019that\u2019, \u2019the\u2019, \u2019hero\u2019) (\u2019of\u2019, \u2019the\u2019, \u2019following\u2019, \u2019:\u2019)\n(\u2019parking\u2019, \u2019lots\u2019) (\u2019con\u2019, \u2019ni\u2019, \u2019tor\u2019) (\u2019put\u2019, \u2019pressure\u2019, \u2019on\u2019, \u2019people\u2019) (\u2019in\u2019, \u2019terror\u2019) (\u2019that\u2019, \u2019the\u2019, \u2019uk\u2019) (\u2019s\u2019, \u2019a\u2019, \u2019little\u2019, \u2019more\u2019)\n(\u2019n\u2019, \u2019wy\u2019) (\u2019the\u2019, \u2019official\u2019, \u2019w\u2019) (\u2019ho\u2019, \u2019isted\u2019, \u2019itself\u2019, \u2019into\u2019) (\u2019re\u2019, \u2019journalists\u2019) (\u2019the\u2019, \u2019crowd\u2019, \u2019was\u2019) (\u2019in\u2019, \u2019their\u2019, \u201949\u2019, \u2019-\u2019) (\u2019native\u2019, \u2019town\u2019) (\u2019-\u2019, \u2019black\u2019, \u2019boy\u2019) (\u2019sure\u2019, \u2019what\u2019, \u2019he\u2019, \u2019meant\u2019)\n(\u2019protect\u2019, \u2019.\u2019) (\u2019most\u2019, \u2019k\u2019, \u2019usa\u2019) (\u2019sa\u2019, \u2019ssa\u2019, \u2019was\u2019, \u2019a\u2019) (\u2019happy\u2019, \u2019features\u2019) (\u2019performed\u2019, \u2019\"\u2019, \u2019m\u2019) (\u2019have\u2019, \u2019us\u2019, \u2019here\u2019, \u2019yet\u2019)\n(\u2019they\u2019, \u2019turned\u2019) (\u2019here\u2019, \u2019and\u2019, \u2019you\u2019) (\u2019hot\u2019, \u2019,\u2019, \u2019\u201d\u2019, \u2019s\u2019) (\u2019so\u2019, \u2019d\u2019) (\u2019published\u2019, \u2019in\u2019, \u20191977\u2019) (\u2019the\u2019, \u2019floor\u2019, \u2019.\u2019, \u2019m\u2019) (\u2019si\u2019, \u2019un\u2019) (\u201926\u2019, \u2019/\u2019, \u201922\u2019) (\u2019he\u2019, \u2019pa\u2019, \u2019,\u2019, \u2019and\u2019)\n(\u2019no\u2019, \u2019organised\u2019) (\u2019them\u2019, \u2019as\u2019, \u2019independent\u2019) (\u2019girl\u2019, \u2019who\u2019, \u2019he\u2019, \u2019would\u2019) (\u2019u\u2019, \u2019bu\u2019) (\u2019into\u2019, \u2019the\u2019, \u2019water\u2019) (\u2019with\u2019, \u2019a\u2019, \u2019fellow\u2019, \u2019r\u2019)\n(\u2019her\u2019, \u2019album\u2019) (\u2019on\u2019, \u2019plan\u2019, \u2019kt\u2019) (\u2019won\u2019, \u2019every\u2019, \u2019tournament\u2019, \u2019.\u2019) (\u2019v\u2019, \u2019il\u2019) (\u2019library\u2019, \u2019and\u2019, \u2019archives\u2019) (\u2019verdict\u2019, \u2019was\u2019, \u2019overturned\u2019, \u2019by\u2019)\n(\u2019partner\u2019, \u2019\"\u2019) (\u2019br\u2019, \u2019id\u2019, \u2019si\u2019) (\u2019see\u2019, \u2019the\u2019, \u2019last\u2019, \u2019one\u2019) (\u2019respectively\u2019, \u2019.\u2019) (\u2019cafe\u2019, \u2019s\u2019, \u2019,\u2019) (\u2019order\u2019, \u2019of\u2019, \u2019the\u2019, \u2019ta\u2019) (\u2019second\u2019, \u2019fastest\u2019) (\u2019terror\u2019, \u2019.\u2019, \u2019the\u2019) (\u2019they\u2019, \u2019moved\u2019, \u2019into\u2019, \u2019a\u2019)\n(\u2019marry\u2019, \u2019men\u2019) (\u2019money\u2019, \u2019for\u2019, \u2019life\u2019) (\u2019saying\u2019, \u2019,\u2019, \u2019\"\u2019, \u2019it\u2019) (\u2019my\u2019, \u2019lady\u2019) (\u2019are\u2019, \u2019b\u2019, \u2019on\u2019) (\u2019innocent\u2019, \u2019people\u2019, \u2019.\u2019, \u2019o\u2019) (\u2019were\u2019, \u2019found\u2019) (\u2019had\u2019, \u2019taken\u2019, \u2019her\u2019) (\u2019would\u2019, \u2019not\u2019, \u2019book\u2019, \u2019the\u2019) (\u2019sixth\u2019, \u2019,\u2019) (\u2019with\u2019, \u2019a\u2019, \u2019video\u2019) (\u2019the\u2019, \u2019album\u2019, \u2019\"\u2019, \u2019is\u2019)\n(\u2019fund\u2019, \u2019has\u2019) (\u2019mit\u2019, \u2019e\u2019, \u2019cht\u2019) (\u2019the\u2019, \u2019north\u2019, \u2019k\u2019, \u2019ore\u2019) (\u2019years\u2019, \u2019and\u2019) (\u2019you\u2019, \u2019what\u2019, \u2019.\u2019) (\u2019had\u2019, \u2019killed\u2019, \u2019her\u2019, \u2019.\u2019)\n(\u2019transaction\u2019, \u2019details\u2019) (\u2019the\u2019, \u2019reason\u2019, \u2019for\u2019) (\u2019were\u2019, \u2019cited\u2019, \u2019including\u2019, \u2019:\u2019) (\u2019trouble\u2019, \u2019Officials\u2019) (\u2019would\u2019, \u2019choose\u2019, \u2019this\u2019) (\u2019then\u2019, \u2019he\u2019, \u2019born\u2019, \u2019here\u2019)\n(\u2019victim\u2019, \u2019left\u2019) (\u2019the\u2019, \u2019strong\u2019, \u2019man\u2019) (\u2019with\u2019, \u2019force\u2019, \u2019,\u2019, \u2019they\u2019) (\u2019use\u2019, \u2019There\u2019) (\u2019G\u00a6\u2019, \u2019Dean\u2019, \u2019Andrews\u2019) (\u2019was\u2019, \u2019jailed\u2019, \u2019in\u2019, \u20192010\u2019) (\u2019team\u2019, \u2019......\u2019) (\u2019while\u2019, \u2019his\u2019, \u2019comments\u2019) (\u2019victories\u2019, \u2019being\u2019, \u2019scored\u2019, \u2019.\u2019) (\u2019A\u2019, \u2019School\u2019) (\u2019the\u2019, \u2019report\u2019, \u2019includes\u2019) (\u2019they\u2019, \u2019start\u2019, \u2019again\u2019, \u2019After\u2019) (\u2019wrong\u2019, \u2019......\u2019) (\u2019were\u2019, \u2019.....\u2019, \u2019they\u2019) (\u2019the\u2019, \u2019suspects\u2019, \u2019.\u2019, \u2019The\u2019) (\u2019worlds\u2019, \u2019.\u2019) (\u2019they\u2019, \u2019are\u2019, \u2019working\u2019) (\u2019this\u2019, \u2019youthful\u2019, \u2019group\u2019, \u2019of\u2019) (\u2019to\u2019, \u2019abolish\u2019) (\u2019still\u2019, \u2019is\u2019, \u2019a\u2019) (\u2019were\u2019, \u2019false\u2019, \u2019claims\u2019, \u2019that\u2019) (\u2019was\u2019, \u2019among\u2019) (\u2019universe\u2019, \u2019.\u2019, \u2019The\u2019) (\u2019to\u2019, \u2019explain\u2019, \u2019why\u2019, \u2019??\u2019)\n(\u2019to\u2019, \u2019Chad\u2019) (\u2019was\u2019, \u2019sentenced\u2019, \u2019for\u2019) (\u2019train\u2019, \u2019operators\u2019, \u2019The\u2019, \u2019train\u2019) (\u2019took\u2019, \u20194\u2019) (\u2019walk\u2019, \u2019out\u2019, \u2019end\u2019) (\u2019the\u2019, \u2019whole\u2019, \u2019series\u2019, \u2019is\u2019)\n(\u2019team\u2019, \u2019Behind\u2019) (\u2019then\u2019, \u2019he\u2019, \u2019and\u2019) (\u2019wishes\u2019, \u2019to\u2019, \u2019remain\u2019, \u2019anonymous\u2019) (\u2019visitor\u2019, \u2019st\u2019) (\u2019the\u2019, \u2019.\u2019, \u2019Pl\u2019) (\u2019thee\u2019, \u2019to\u2019, \u2019the\u2019, \u2019number\u2019)\n(\u2019that\u2019, \u2019North\u2019) (\u2019who\u2019, \u2019is\u2019, \u2019based\u2019) (\u2019unbeaten\u2019, \u2019and\u2019, \u2019the\u2019, \u2019victory\u2019) (\u2019stand\u2019, \u2019-\u2019) (\u2019the\u2019, \u2019first\u2019, \u2019....\u2019) (\u2019want\u2019, \u2019them\u2019, \u2019!\u2019, \u2019They\u2019) (\u2019your\u2019, \u2019thing\u2019) (\u2019thousand\u2019, \u2019people\u2019, \u2019missing\u2019) (\u2019years\u2019, \u2019ago\u2019, \u2019The\u2019, \u2019strike\u2019) (\u2019the\u2019, \u2019Greek\u2019) (\u2019was\u2019, \u2019hes\u2019, \u2019over\u2019) (\u2019the\u2019, \u2019slot\u2019, \u2019...\u2019, \u2019Brian\u2019)\n(\u2019Is\u2019, \u2019My\u2019) (\u2019weather\u2019, \u2019forecast\u2019, \u2019keeps\u2019) (\u2019was\u2019, \u2019at\u2019, \u2019board\u2019, \u2019.\u2019) (\u2019they\u2019, \u2019!!!\u2019) (\u2019singers\u2019, \u2019and\u2019, \u2019designers\u2019) (\u2019which\u2019, \u2019stand\u2019, \u2019Hide\u2019, \u2019Transcript\u2019) (\u2019wheel\u2019, \u2019is\u2019) (\u2019will\u2019, \u2019merge\u2019, \u2019it\u2019) (\u2019the\u2019, \u2019university\u2019, \u2019.\u2019, \u2019G\u00a6\u2019)\n(\u2019tower\u2019, \u2019house\u2019) (\u2019to\u2019, \u2019saying\u2019, \u2019goodbye\u2019) (\u2019the\u2019, \u2019service\u2019, \u2019that\u2019, \u2019does\u2019) (\u2019the\u2019, \u2019dig\u2019) (\u2019.\u2019, \u2019Assistant\u2019, \u2019manager\u2019) (\u2019their\u2019, \u2019website\u2019, \u2019|\u2019, \u2019TV\u2019)\n(\u2019verified\u2019, \u2019.\u2019) (\u2019through\u2019, \u2019its\u2019, \u2019share\u2019) (\u2019who\u2019, \u2019were\u2019, \u2019sacked\u2019, \u2019in\u2019) (\u2019the\u2019, \u2019bastard\u2019) (\u2019selling\u2019, \u2019properties\u2019, \u2019,\u2019) (\u2019to\u2019, \u2019passing\u2019, \u2019the\u2019, \u2019mark\u2019) (\u2019targeted\u2019, \u2019it\u2019) (\u2019sure\u2019, \u2019.\u2019, \u2019Especially\u2019) (\u2019yet\u2019, \u2019.......\u2019, \u2019And\u2019, \u2019......\u2019) (\u2019weeks\u2019, \u2019later\u2019) (\u2019speak\u2019, \u2019is\u2019, \u2019sure\u2019) (\u2019this\u2019, \u2019club\u2019, \u2019:\u2019, \u2019Article\u2019) (\u2019summer\u2019, \u2019.\u2019) (\u2019who\u2019, \u2019was\u2019, \u201982\u2019) (\u2019was\u2019, \u2019likely\u2019, \u2019disappointed\u2019, \u2019in\u2019) (\u2019then\u2019, \u2019is\u2019) (\u2019was\u2019, \u2019And\u2019, \u2019That\u2019) (\u2019us\u2019, \u2019:\u2019, \u2019)\u2019, \u2019??\u2019)\n(\u2019the\u2019, \u2019Sam\u2019) (\u2019who\u2019, \u2019came\u2019, \u2019to\u2019) (\u2019they\u2019, \u2019say\u2019, \u2019:\u2019, \u2019Turn\u2019) (\u2019team\u2019, \u2019is\u2019) (\u2019the\u2019, \u2019race\u2019, \u2019was\u2019) (\u2019who\u2019, \u2019the\u2019, \u2019artist\u2019, \u2019The\u2019) (\u2019topic\u2019, \u2019-\u2019) (\u2019services\u2019, \u2019are\u2019, \u2019resumed\u2019) (\u2019the\u2019, \u2019south\u2019, \u2019Crew\u2019, \u2019sm\u2019)\n(\u2019spotted\u2019, \u2019nearby\u2019) (\u2019today\u2019, \u2019:\u2019, \u2019Jack\u2019) (\u2019with\u2019, \u2019a\u2019, \u2019golf\u2019, \u2019club\u2019) (\u2019understandable\u2019, \u2019to\u2019) (\u2019she\u2019, \u2019never\u2019, \u2019heard\u2019) (\u2019G\u00a6\u2019, \u2019The\u2019, \u2019Un\u2019, \u2019ail\u2019)\n(\u2019victim\u2019, \u2019refused\u2019) (\u2019with\u2019, \u2019the\u2019, \u2019age\u2019) (\u2019while\u2019, \u2019....\u2019, \u2019.\",\u2019, \u2019as\u2019) (\u2019A\u00b7\u2019, \u2019advertisement\u2019) (\u2019survives\u2019, \u2019military\u2019, \u2019tests\u2019) (\u2019with\u2019, \u2019women\u2019, \u2019are\u2019, \u2019is\u2019)\n(\u2019strife\u2019, \u2019G\u00a6\u2019) (\u2019to\u2019, \u2019gain\u2019, \u2019insights\u2019) (\u2019trial\u2019, \u2019was\u2019, \u2019strike\u2019, \u2019after\u2019) (\u2019trader\u2019, \u2019Bryan\u2019) (\u2019the\u2019, \u2019holidays\u2019, \u2019will\u2019) (\u2019where\u2019, \u2019are\u2019, \u2019you\u2019, \u2019?,\u2019)\n(\u2019temples\u2019, \u2019From\u2019) (\u2019space\u2019, \u2019The\u2019, \u2019policy\u2019) (\u2019unavailable\u2019, \u2019.\u2019, \u2019for\u2019, \u2019Advertisement\u2019) (\u2019surprised\u2019, \u2019and\u2019) (\u2019the\u2019, \u2019items\u2019, \u2019They\u2019) (\u2019was\u2019, \u2019attacked\u2019, \u2019she\u2019, \u2019was\u2019) (\u2019widespread\u2019, \u2019as\u2019) (\u2019starts\u2019, \u2019!\u2019, \u2019When\u2019) (\u2019G\u00a6\u2019, \u2019The\u2019, \u2019former\u2019, \u2019...\u2019)\n(\u2019two\u2019, \u2019titles\u2019) (\u2019union\u2019, \u2019and\u2019, \u2019to\u2019) (\u2019were\u2019, \u2019there\u2019, \u2019were\u2019, \u2019some\u2019) (\u2019whose\u2019, \u2019whose\u2019) (\u2019to\u2019, \u2019change\u2019, \u2019A\u2019) (\u2019website\u2019, \u2019said\u2019, \u2019:\u2019, \u2019advertisement\u2019)\n(\u2019than\u2019, \u2019live\u2019) (\u2019y\u2019, \u2019rs\u2019, \u2019.\u2019) (\u2019then\u2019, \u2019travels\u2019, \u2019C\u2019, \u2019hen\u2019)\n(\u2019state\u2019, \u2019might\u2019) (\u2019their\u2019, \u2019recent\u2019, \u2019poor\u2019) (\u2019two\u2019, \u2019appearances\u2019, \u2019for\u2019, \u2019Portugal\u2019) (\u2019theatre\u2019, \u2019special\u2019) (\u2019were\u2019, \u2019the\u2019, \u2019Reds\u2019) (\u2019time\u2019, \u2019that\u2019, \u2019they\u2019, \u2019have\u2019)\n(\u2019strategic\u2019, \u2019planning\u2019) (\u2019used\u2019, \u2019for\u2019, \u2019advertising\u2019) (\u2019Gl\u2019, \u2019Women\u2019, \u2019with\u2019, \u2019Phot\u2019) (\u2019were\u2019, \u201983\u2019) (\u2019up\u2019, \u2019the\u2019, \u2019Blue\u2019) (\u2019unclear\u2019, \u2019whether\u2019, \u2019or\u2019, \u2019not\u2019)\n(\u2019the\u2019, \u2019General\u2019) (\u2019the\u2019, \u2019same\u2019, \u2019pricing\u2019) (\u2019using\u2019, \u2019this\u2019, \u2019again\u2019, \u2019.\u2019) (\u2019wrote\u2019, \u2019is\u2019) (\u2019total\u2019, \u2019annual\u2019, \u2019revenue\u2019) (\u2019who\u2019, \u2019is\u2019, \u2019still\u2019, \u2019chairman\u2019) (\u2019wife\u2019, \u2019met\u2019) (\u2019tests\u2019, \u2019and\u2019, \u2019normal\u2019) (\u2019tool\u2019, \u2019to\u2019, \u2019educ\u2019, \u2019ate\u2019)\n(\u2019student\u2019, \u2019assaulted\u2019) (\u2019transport\u2019, \u2019ing\u2019, \u2019US\u2019) (\u2019unit\u2019, \u2019in\u2019, \u2019the\u2019, \u2019nation\u2019) (\u2019special\u2019, \u2019equipment\u2019) (\u2019surrounding\u2019, \u2019it\u2019, \u2019.\u2019) (\u2019trial\u2019, \u2019court\u2019, \u2019,\u2019, \u2019he\u2019)\n(\u2019vessel\u2019, \u2019with\u2019) (\u2019suite\u2019, \u2019.\u2019, \u2019The\u2019) (\u2019was\u2019, \u2019a\u2019, \u2019handsome\u2019, \u2019young\u2019) (\u2019top\u2019, \u2019employers\u2019) (\u2019use\u2019, \u2019in\u2019, \u2019this\u2019) (\u2019think\u2019, \u2019he\u2019, \u2019GL\u2019, \u2019ll\u2019)\n(\u2019undoubtedly\u2019, \u2019have\u2019) (\u2019the\u2019, \u2019House\u2019, \u2019Finance\u2019) (\u2019treatment\u2019, \u2019of\u2019, \u2019any\u2019, \u2019individual\u2019) (\u2019type\u2019, \u2019at\u2019) (\u2019were\u2019, \u2019arrested\u2019, \u2019by\u2019) (\u2019woman\u2019, \u2019claiming\u2019, \u2019she\u2019, \u2019was\u2019)\n(\u2019the\u2019, \u2019fiscal\u2019) (\u2019staff\u2019, \u2019.\u2019, \u2019C\u2019) (\u2019will\u2019, \u2019return\u2019, \u2019from\u2019, \u2019the\u2019) (\u2019with\u2019, \u2019obs\u2019) (\u2019was\u2019, \u2019a\u2019, \u2019bank\u2019) (\u2019you\u2019, \u2019can\u2019, \u2019hear\u2019, \u2019me\u2019)\n(\u2019wedding\u2019, \u2019plan\u2019) (\u2019visitors\u2019, \u2019.\u2019, \u2019These\u2019) (\u2019use\u2019, \u2019their\u2019, \u2019violence\u2019, \u2019.\u2019) (\u2019tumor\u2019, \u2019and\u2019) (\u2019the\u2019, \u2019brain\u2019, \u2019(\u2019) (\u2019was\u2019, \u2019mentally\u2019, \u2019ill\u2019, \u2019after\u2019) (\u2019small\u2019, \u2019fee\u2019) (\u2019with\u2019, \u2019new\u2019, \u2019talent\u2019) (\u2019these\u2019, \u2019materials\u2019, \u2019.\u2019, \u2019The\u2019) (\u2019unnecessary\u2019, \u2019burden\u2019) (\u2019that\u2019, \u2019is\u2019, \u2019distinguished\u2019) (\u2019to\u2019, \u2019the\u2019, \u2019Detroit\u2019, \u2019Pist\u2019) (\u2019yet\u2019, \u2019reviewed\u2019) (\u2019so\u2019, \u2019impressed\u2019, \u2019with\u2019) (\u2019think\u2019, \u2019there\u2019, \u2019is\u2019, \u2019very\u2019) (\u2019yarn\u2019, \u2019having\u2019) (\u2019with\u2019, \u2019Jon\u2019, \u2019ah\u2019) (\u2019was\u2019, \u2019then\u2019, \u2019advised\u2019, \u2019that\u2019) (\u2019wonder\u2019, \u2019over\u2019) (\u2019technology\u2019, \u2019and\u2019, \u2019financial\u2019) (\u2019which\u2019, \u2019is\u2019, \u2019their\u2019, \u2019honey\u2019)\n(\u2019stop\u2019, \u2019;\u2019) (\u2019someone\u2019, \u2019enjoy\u2019, \u2019s\u2019) (\u2019which\u2019, \u2019is\u2019, \u2019widely\u2019, \u2019regarded\u2019) (\u2019tennis\u2019, \u2019game\u2019) (\u2019up\u2019, \u2019over\u2019, \u20194\u2019) (\u2019to\u2019, \u2019be\u2019, \u2019much\u2019, \u2019of\u2019) (\u2019the\u2019, \u2019micro\u2019) (\u2019successful\u2019, \u2019films\u2019, \u2019ever\u2019) (\u2019to\u2019, \u2019write\u2019, \u2019the\u2019, \u2019article\u2019) (\u2019three\u2019, \u2019aspects\u2019) (\u2019the\u2019, \u2019American\u2019, \u2019Bar\u2019) (\u2019years\u2019, \u2019.\u2019, \u2019Le\u2019, \u2019igh\u2019) (\u2019website\u2019, \u2019,\u2019) (\u2019will\u2019, \u2019have\u2019, \u2019lots\u2019) (\u2019used\u2019, \u2019to\u2019, \u2019identify\u2019, \u2019new\u2019) (\u2019will\u2019, \u2019rise\u2019) (\u2019the\u2019, \u2019pandemic\u2019, \u2019continues\u2019) (\u2019to\u2019, \u2019my\u2019, \u2019daughter\u2019, \u2019GL\u2019) (\u2019your\u2019, \u2019C\u2019) (\u2019wave\u2019, \u2019had\u2019, \u2019reached\u2019) (\u2019to\u2019, \u2019worry\u2019, \u2019about\u2019, \u2019my\u2019)\n(\u2019that\u2019, \u2019orph\u2019) (\u2019the\u2019, \u2019opposition\u2019, \u2019play\u2019) (\u2019was\u2019, \u2019a\u2019, \u2019shot\u2019, \u2019from\u2019) (\u2019west\u2019, \u2019-\u2019) (\u2019statements\u2019, \u2019that\u2019, \u2019are\u2019) (\u2019top\u2019, \u20193\u2019, \u2019,\u2019, \u2019and\u2019)\n(\u2019will\u2019, \u2019state\u2019) (\u2019unemployed\u2019, \u2019was\u2019, \u2019around\u2019) (\u2019to\u2019, \u2019do\u2019, \u2019a\u2019, \u2019lot\u2019) (\u2019your\u2019, \u2019pocket\u2019) (\u2019to\u2019, \u2019data\u2019, \u2019compiled\u2019) (\u2019weight\u2019, \u2019of\u2019, \u2019the\u2019, \u2019animal\u2019) (\u2019the\u2019, \u2019Andes\u2019) (\u2019with\u2019, \u2019a\u2019, \u2019project\u2019) (\u2019to\u2019, \u2019keep\u2019, \u2019our\u2019, \u2019state\u2019) (\u2019train\u2019, \u2019had\u2019) (\u2019would\u2019, \u2019not\u2019, \u2019back\u2019) (\u2019varies\u2019, \u2019from\u2019, \u20190\u2019, \u2019.\u2019) (\u2019trusted\u2019, \u2019.\u2019) (\u2019the\u2019, \u2019Summer\u2019, \u2019Olympics\u2019) (\u2019up\u2019, \u2019a\u2019, \u2019new\u2019, \u2019office\u2019)\n(\u2019will\u2019, \u2019know\u2019) (\u2019the\u2019, \u2019British\u2019, \u2019off\u2019) (\u2019they\u2019, \u2019have\u2019, \u2019looked\u2019, \u2019to\u2019) (\u2019time\u2019, \u2019varies\u2019) (\u2019the\u2019, \u2019storm\u2019, \u2019had\u2019) (\u2019to\u2019, \u2019fall\u2019, \u2019asleep\u2019, \u2019in\u2019) (\u2019training\u2019, \u2019(\u2019) (\u2019violence\u2019, \u2019,\u2019, \u2019exploitation\u2019) (\u2019vessel\u2019, \u2019which\u2019, \u2019was\u2019, \u2019responsible\u2019) (\u2019who\u2019, \u2019ran\u2019) (\u2019was\u2019, \u2019Gl\u2019, \u2019perfect\u2019) (\u2019to\u2019, \u2019the\u2019, \u2019Governor\u2019, \u2019for\u2019) (\u2019that\u2019, \u2019treaty\u2019) (\u2019substance\u2019, \u2019use\u2019, \u2019,\u2019) (\u2019to\u2019, \u2019the\u2019, \u2019Dallas\u2019, \u2019Cow\u2019) (\u2019to\u2019, \u20192014\u2019) (\u2019two\u2019, \u2019human\u2019, \u2019B\u2019) (\u2019variety\u2019, \u2019of\u2019, \u2019insight\u2019, \u2019into\u2019)\n(\u2019store\u2019, \u2019page\u2019) (\u2019to\u2019, \u2019assist\u2019, \u2019Liverpool\u2019) (\u2019video\u2019, \u2019playback\u2019, \u2019.\u2019, \u2019The\u2019) (\u2019they\u2019, \u2019satisfied\u2019) (\u2019together\u2019, \u2019for\u2019, \u2019nearly\u2019) (\u2019very\u2019, \u2019strong\u2019, \u2019team\u2019, \u2019.\u2019) (\u2019the\u2019, \u2019effective\u2019) (\u2019well\u2019, \u2019supported\u2019, \u2019by\u2019) (\u2019where\u2019, \u2019we\u2019, \u2019need\u2019, \u2019to\u2019)"
        }
    ],
    "title": "LLMDet: A Third Party Large Language Models Generated Text Detection Tool",
    "year": 2023
}