{
    "abstractText": "The translation of ambiguous text presents a challenge for translation systems, as it requires using the surrounding context to disambiguate the intended meaning as much as possible. While prior work has studied ambiguities that result from different grammatical features of the source and target language, we study semantic ambiguities that exist in the source (English in this work) itself. In particular, we focus on idioms that are open to both literal and figurative interpretations (e.g., goose egg), and collect TIDE,1 a dataset of 512 pairs of English sentences containing idioms with disambiguating context such that one is literal (it laid a goose egg) and another is figurative (they scored a goose egg, as in a score of zero). In experiments, we compare MT-specific models and language models for (i) their preference when given an ambiguous subsentence, (ii) their sensitivity to disambiguating context, and (iii) the performance disparity between figurative and literal source sentences. We find that current MT models consistently translate English idioms literally, even when the context suggests a figurative interpretation. On the other hand, LMs are far more context-aware, although there remain disparities across target languages. Our findings underline the potential of LMs as a strong backbone for context-aware translation.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jaechan Lee"
        },
        {
            "affiliations": [],
            "name": "Alisa Liu"
        },
        {
            "affiliations": [],
            "name": "Orevaoghene Ahia"
        },
        {
            "affiliations": [],
            "name": "Hila Gonen"
        },
        {
            "affiliations": [],
            "name": "Noah A. Smith"
        }
    ],
    "id": "SP:32e7e7e810e88da3235d1119ea70a4b44909476b",
    "references": [
        {
            "authors": [
                "Yehoshua Bar-Hillel."
            ],
            "title": "Some linguistic problems connected with machine translation",
            "venue": "Philosophy of Science, 20(3):217\u2013225.",
            "year": 1953
        },
        {
            "authors": [
                "Rachel Bawden",
                "Rico Sennrich",
                "Alexandra Birch",
                "Barry Haddow."
            ],
            "title": "Evaluating discourse phenomena in neural machine translation",
            "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics:",
            "year": 2018
        },
        {
            "authors": [
                "Christos Baziotis",
                "Prashant Mathur",
                "Eva Hasler."
            ],
            "title": "Automatic evaluation and analysis of idioms in neural machine translation",
            "venue": "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 3682\u2013",
            "year": 2023
        },
        {
            "authors": [
                "Tuhin Chakrabarty",
                "Arkadiy Saakyan",
                "Debanjan Ghosh",
                "Smaranda Muresan."
            ],
            "title": "FLUTE: Figurative language understanding through textual explanations",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages",
            "year": 2022
        },
        {
            "authors": [
                "Alexis Conneau",
                "Kartikay Khandelwal",
                "Naman Goyal",
                "Vishrav Chaudhary",
                "Guillaume Wenzek",
                "Francisco Guzm\u00e1n",
                "Edouard Grave",
                "Myle Ott",
                "Luke Zettlemoyer",
                "Veselin Stoyanov"
            ],
            "title": "Unsupervised cross-lingual representation learning at scale",
            "year": 2020
        },
        {
            "authors": [
                "Verna Dankers",
                "Christopher Lucas",
                "Ivan Titov."
            ],
            "title": "Can transformer be too compositional? analysing idiom processing in neural machine translation",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1:",
            "year": 2022
        },
        {
            "authors": [
                "Zi-Yi Dou",
                "Graham Neubig"
            ],
            "title": "Word alignment by fine-tuning embeddings on parallel corpora",
            "year": 2021
        },
        {
            "authors": [
                "Marzieh Fadaee",
                "Arianna Bisazza",
                "Christof Monz."
            ],
            "title": "Examining the tip of the iceberg: A data set for idiom translation",
            "venue": "Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan. European",
            "year": 2018
        },
        {
            "authors": [
                "Patrick Fernandes",
                "Kayo Yin",
                "Emmy Liu",
                "Andr\u00e9 Martins",
                "Graham Neubig."
            ],
            "title": "When does translation require context? a data-driven, multilingual exploration",
            "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics",
            "year": 2023
        },
        {
            "authors": [
                "Pablo Gamallo",
                "Marcos Garcia."
            ],
            "title": "Unsupervised compositional translation of multiword expressions",
            "venue": "Proceedings of the Joint Workshop on Multiword Expressions and WordNet (MWE-WN 2019), pages 40\u201348, Florence, Italy. Association for Com-",
            "year": 2019
        },
        {
            "authors": [
                "Marcos Garcia",
                "Tiago Kramer Vieira",
                "Carolina Scarton",
                "Marco Idiart",
                "Aline Villavicencio."
            ],
            "title": "Probing for idiomaticity in vector space models",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics:",
            "year": 2021
        },
        {
            "authors": [
                "Hila Gonen",
                "Kellie Webster."
            ],
            "title": "Automatically identifying gender issues in machine translation using perturbations",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1991\u20131995, Online. Association for Computational",
            "year": 2020
        },
        {
            "authors": [
                "Wang",
                "Tao Wang",
                "John Wieting",
                "Yuhuai Wu",
                "Kelvin Xu",
                "Yunhan Xu",
                "Linting Xue",
                "Pengcheng Yin",
                "Jiahui Yu",
                "Qiao Zhang",
                "Steven Zheng",
                "Ce Zheng",
                "Weikang Zhou",
                "Denny Zhou",
                "Slav Petrov",
                "Yonghui Wu"
            ],
            "title": "Palm 2 technical report",
            "year": 2023
        },
        {
            "authors": [
                "Hessel Haagsma",
                "Johan Bos",
                "Malvina Nissim."
            ],
            "title": "MAGPIE: A large corpus of potentially idiomatic expressions",
            "venue": "Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 279\u2013287, Marseille, France. European Language Re-",
            "year": 2020
        },
        {
            "authors": [
                "Amr Hendy",
                "Mohamed Abdelrehim",
                "Amr Sharaf",
                "Vikas Raunak",
                "Mohamed Gabr",
                "Hitokazu Matsushita",
                "Young Jin Kim",
                "Mohamed Afify",
                "Hany Hassan Awadalla"
            ],
            "title": "How good are gpt models at machine translation? a comprehensive evaluation",
            "year": 2023
        },
        {
            "authors": [
                "Anubha Kabra",
                "Emmy Liu",
                "Simran Khanuja",
                "Alham Fikri Aji",
                "Genta Winata",
                "Samuel Cahyawijaya",
                "Anuoluwapo Aremu",
                "Perez Ogayo",
                "Graham Neubig."
            ],
            "title": "Multi-lingual and multi-cultural figurative language understanding",
            "venue": "Findings of the Asso-",
            "year": 2023
        },
        {
            "authors": [
                "Jungo Kasai",
                "Keisuke Sakaguchi",
                "Ronan Le Bras",
                "Lavinia Dunagan",
                "Jacob Morrison",
                "Alexander Fabbri",
                "Yejin Choi",
                "Noah A. Smith."
            ],
            "title": "Bidimensional leaderboards: Generate and evaluate language hand in hand",
            "venue": "Proceedings of the 2022 Conference of",
            "year": 2022
        },
        {
            "authors": [
                "Shaohui Kuang",
                "Deyi Xiong",
                "Weihua Luo",
                "Guodong Zhou."
            ],
            "title": "Modeling coherence for neural machine translation with dynamic and topic caches",
            "venue": "Proceedings of the 27th International Conference on Computational Linguistics, pages 596\u2013606, Santa Fe,",
            "year": 2018
        },
        {
            "authors": [
                "Alisa Liu",
                "Swabha Swayamdipta",
                "Noah A. Smith",
                "Yejin Choi."
            ],
            "title": "WANLI: Worker and AI collaboration for natural language inference dataset creation",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022, pages 6826\u20136847, Abu",
            "year": 2022
        },
        {
            "authors": [
                "Alisa Liu",
                "Zhaofeng Wu",
                "Julian Michael",
                "Alane Suhr",
                "Peter West",
                "Alexander Koller",
                "Swabha Swayamdipta",
                "Noah A. Smith",
                "Yejin Choi."
            ],
            "title": "We\u2019re afraid language models aren\u2019t modeling ambiguity",
            "venue": "arXiv.",
            "year": 2023
        },
        {
            "authors": [
                "Sewon Min",
                "Julian Michael",
                "Hannaneh Hajishirzi",
                "Luke Zettlemoyer."
            ],
            "title": "AmbigQA: Answering ambiguous open-domain questions",
            "venue": "Proceedings of",
            "year": 2020
        },
        {
            "authors": [
                "Mathias M\u00fcller",
                "Annette Rios",
                "Elena Voita",
                "Rico Sennrich."
            ],
            "title": "A large-scale test set for the evaluation of context-aware pronoun translation in neural machine translation",
            "venue": "Proceedings of the Third Conference on Machine Translation: Research Pa-",
            "year": 2018
        },
        {
            "authors": [
                "Steven T. Piantadosi",
                "Harry Tily",
                "Edward Gibson."
            ],
            "title": "The communicative function of ambiguity in language",
            "venue": "Cognition, 122(3):280\u2013291.",
            "year": 2012
        },
        {
            "authors": [
                "Maja Popovi\u0107."
            ],
            "title": "chrF: character n-gram F-score for automatic MT evaluation",
            "venue": "Proceedings of the Tenth Workshop on Statistical Machine Translation, pages 392\u2013395, Lisbon, Portugal. Association for Computational Linguistics.",
            "year": 2015
        },
        {
            "authors": [
                "Marcelo O.R. Prates",
                "Pedro H. Avelar",
                "Lu\u00eds C. Lamb."
            ],
            "title": "Assessing gender bias in machine translation: a case study with google translate",
            "venue": "Neural Computing and Applications.",
            "year": 2019
        },
        {
            "authors": [
                "Ella Rabinovich",
                "Hila Gonen",
                "Suzanne Stevenson"
            ],
            "title": "Pick a fight or bite your tongue: Investigation of gender differences in idiomatic language usage",
            "year": 2020
        },
        {
            "authors": [
                "Vikas Raunak",
                "Arul Menezes",
                "Matt Post",
                "Hany Hassan"
            ],
            "title": "Do GPTs produce less literal translations? In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume",
            "year": 2023
        },
        {
            "authors": [
                "Mat\u0131\u0304ss Rikters",
                "Ond\u0159ej Bojar"
            ],
            "title": "Paying attention to multi-word expressions in neural machine translation",
            "venue": "In Proceedings of Machine Translation Summit XVI: Research Track,",
            "year": 2017
        },
        {
            "authors": [
                "Beatrice Savoldi",
                "Marco Gaido",
                "Luisa Bentivogli",
                "Matteo Negri",
                "Marco Turchi."
            ],
            "title": "Gender bias in machine translation",
            "venue": "Transactions of the Association for Computational Linguistics, 9:845\u2013874.",
            "year": 2021
        },
        {
            "authors": [
                "Prateek Saxena",
                "Soma Paul"
            ],
            "title": "Epie dataset: A corpus for possible idiomatic expressions",
            "year": 2020
        },
        {
            "authors": [
                "Andrea Schioppa",
                "David Vilar",
                "Artem Sokolov",
                "Katja Filippova."
            ],
            "title": "Controlling machine translation for multiple attributes with additive interventions",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages",
            "year": 2021
        },
        {
            "authors": [
                "Thibault Sellam",
                "Dipanjan Das",
                "Ankur P. Parikh"
            ],
            "title": "Bleurt: Learning robust metrics for text generation",
            "year": 2020
        },
        {
            "authors": [
                "Elias Stengel-Eskin",
                "Jimena Guallar-Blasco",
                "Yi Zhou",
                "Benjamin Van Durme"
            ],
            "title": "Why did the chicken cross the road? rephrasing and analyzing ambiguous questions in VQA",
            "year": 2023
        },
        {
            "authors": [
                "Tianxiang Sun",
                "Junliang He",
                "Xipeng Qiu",
                "Xuanjing Huang."
            ],
            "title": "BERTScore is unfair: On social bias in language model-based metrics for text generation",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2022
        },
        {
            "authors": [
                "Kenan Tang"
            ],
            "title": "Petci: A parallel english translation dataset of chinese idioms",
            "year": 2022
        },
        {
            "authors": [
                "J\u00f6rg Tiedemann."
            ],
            "title": "The tatoeba translation challenge \u2013 realistic data sets for low resource and multilingual MT",
            "venue": "Proceedings of the Fifth Conference on Machine Translation, pages 1174\u20131182, Online. Association for Computational Linguistics.",
            "year": 2020
        },
        {
            "authors": [
                "J\u00f6rg Tiedemann",
                "Santhosh Thottingal."
            ],
            "title": "OPUSMT \u2013 building open translation services for the world",
            "venue": "Proceedings of the 22nd Annual Conference of the European Association for Machine Translation, pages 479\u2013480, Lisboa, Portugal. European Associa-",
            "year": 2020
        },
        {
            "authors": [
                "Elena Voita",
                "Rico Sennrich",
                "Ivan Titov."
            ],
            "title": "Context-aware monolingual repair for neural machine translation",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference",
            "year": 2019
        },
        {
            "authors": [
                "Elena Voita",
                "Rico Sennrich",
                "Ivan Titov."
            ],
            "title": "When a good translation is wrong in context: Contextaware machine translation improves on deixis, ellipsis, and lexical cohesion",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational",
            "year": 2019
        },
        {
            "authors": [
                "Billy T.M. Wong",
                "Chunyu Kit."
            ],
            "title": "Extending machine translation evaluation metrics with lexical cohesion to document level",
            "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural",
            "year": 2012
        },
        {
            "authors": [
                "Kayo Yin",
                "Patrick Fernandes",
                "Danish Pruthi",
                "Aditi Chaudhary",
                "Andr\u00e9 F.T. Martins",
                "Graham Neubig"
            ],
            "title": "Do context-aware translation models pay the right attention",
            "venue": "In Proceedings of the 59th Annual Meeting of the Association",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Natural language is inherently ambiguous due to the competing pressures of efficiency and clarity in communication (Zipf, 1949; Piantadosi et al., 2012). As communicators, we disambiguate meanings on the basis of a wide range of contextual factors, or ask clarifying questions when such context is not available. Though sometimes overlooked, the role of ambiguity in NLP has gained growing interest in recent work (Min et al., 2020; Liu et al., 2023; Stengel-Eskin et al., 2023).\n1Data and code can be found at https://github.com/ jaechan-repo/mt-ambiguity.\nIn machine translation (MT), it has long been recognized that ambiguities arise when the source language does not encode grammatical attributes that the target language requires (Bar-Hillel, 1953; Prates et al., 2019; Savoldi et al., 2021; Gonen and Webster, 2020, i.a.). For instance, the English sentence \u201cI am a doctor\u201d would require disambiguating the doctor\u2019s gender for translation to German, which has no gender-neutral word for \u201cdoctor.\u201d Prior work created contrastive test sets for such phenomena, to evaluate whether MT models correctly translate an ambiguous word (here, \u201cdoctor\u201d) when disambiguating context is available (e.g., \u201cShe is a doctor\u201d) (M\u00fcller et al., 2018; Bawden et al., 2018; Voita et al., 2019b).\nIn contrast with grammatical ambiguity with respect to a target language, it is relatively less understood how MT systems handle semantic ambiguity present in the source text itself. For instance, \u201cI have bigger fish to fry\u201d is ambiguous between figurative (\u201c... at work\u201d) and literal (\u201c... for the dinner\u201d) interpretations in English, outside of the\ncontext of translation. Therefore, we extend the line of work on context-aware translation to semantically ambiguous phrases in English.\nTo this end, we create TIDE, Translations of Idioms in Disambiguating context in English, a dataset of 512 example triples. Each triple consists of an ambiguous subsentence and a pair of contrastive sentences that contain the subsentence but add disambiguating context: one to produce a figurative interpretation of the idiom, and another to produce a literal interpretation of it (see Figure 1 for an example). Our creation process for the triples combines automatic text generation with human annotation: we use GPT-4 to draft the triples, which are then scrutinized by human annotators. Following this, we engage native speakers from four languages to craft reference translations for a subset of the dataset.\nIn our experiments, we evaluate both traditional neural MT models and language models (LMs). MT-specific models are trained on large corpora of parallel sentences, and have formed the foundation of translation research; LMs are trained without any explicit supervision for translation, yet recently demonstrate impressive translation ability (Hendy et al., 2023). Using TIDE, we compare how these two types of systems handle ambiguity, and evaluate their sensitivity to disambiguating context. We find that on ambiguous input, LMs demonstrate roughly balanced preference between literal and figurative interpretations, whereas MT-specific models consistently prefer literal ones (\u00a74.1). Given disambiguating context, LMs are substantially more context-aware, though this sensitivity declines for more low-resource target languages; in contrast, MT-specific models tend to translate idioms literally irrespective of context (\u00a74.2). Finally, MTspecific models are better at translation of literal text than figurative text, whereas this disparity in LMs is much narrower (\u00a74.3).\nWe summarize our contributions as follows: (1) We formalize the challenge of ambiguous idiomatic language in MT; (2) we create a new translation benchmark, TIDE, that includes sentences with idioms along with disambiguating contexts (literal and figurative); (3) we analyze MT systems\u2019 behavior with and without disambiguating contexts, pointing to interesting trends and differences between LMs and MT-specific models."
        },
        {
            "heading": "2 Creating TIDE",
            "text": "Idioms, though commonplace in daily communication, pose a challenge for MT systems due to its inherent ambiguity between literal and non-literal meanings. Generating the most appropriate translation among potential disambiguations of the idiom involves an understanding that extends beyond the idiom itself, as an MT system must use broader context clues to discern the most fitting translation.\nWe present TIDE, a dataset of 512 example triples. Each triple consists of an ambiguous subsentence, a figurative sentence, and a literal sentence in English, all including the same idiom. The ambiguous subsentence permits both figurative and literal interpretations of the idiom, while the figurative and literal sentences introduce additional context that resolves the ambiguity to figurative and literal readings, respectively. We design subsentences (e.g., \u201chad a card up his sleeve\u201d) to be more than an idiom itself (here, \u201ccard up sleeve\u201d), as idioms alone can often be unnatural as standalone input to an MT system.\nWe construct TIDE through a human-AI collaborative approach following a line of recent work (Liu et al., 2022; Chakrabarty et al., 2022). We first manually select candidate idioms from two large idiom corpora (\u00a72.1). Next, we leverage the generative power of GPT-4 to efficiently produce diverse and high-quality text, by prompting it to write a complete triple for each idiom (\u00a72.2). To ensure quality and correctness, we then involve human annotators to filter out invalid triples (\u00a72.3). Finally, we collect gold translations for a subset of the dataset among native speakers (\u00a72.4)."
        },
        {
            "heading": "2.1 Collection of Idioms",
            "text": "To collect idioms, we scrape THE IDIOMS dictionary2 to obtain 1409 idioms, and additionally use a dataset of 905 idioms from Rabinovich et al. (2020); both sources contain corresponding idiom definitions. We discard duplicate idioms (including those that appear in different conjugations) and proverbs (e.g., All that glitters is not gold), which are often too self-contained to be disambiguated with context. Then, we manually select idioms that are available to a natural and plausible literal interpretation, in addition to their figurative meanings. This results in a set of 700 idioms with definitions.\n2https://www.theidioms.com/"
        },
        {
            "heading": "2.2 Generation of Idioms in Context",
            "text": "Next, we draft an example triple for each idiom by prompting GPT-4 with a fixed prompt, containing two in-context examples along with additional guidelines (details in Appendix A). We write a set of heuristics to automatically identify some types of ill-formed output, such as when the subsentence is not an exact substring of the full sentences. When a rule is violated, we add an additional turn of dialogue instructing the model to revise its output to follow the broken rule. We repeat this until all rules are followed, or when two revisions are attempted without success. After this, we have 700 English triples, each associated with a unique idiom."
        },
        {
            "heading": "2.3 Human Annotation",
            "text": "Of course, the triples collected in \u00a72.2 may not correctly use idioms literally and figuratively, and generated text is susceptible to fluency and coherence issues. To ensure data quality, we recruit crowdworkers on Amazon Mechanical Turk to label each of the full sentences as using either the literal or the figurative sense of an idiom. We present each full sentence independently (not as a pair) to two different crowdworkers, who are asked to label it as figurative, literal, or ambiguous with respect to how it uses the given idiom. They may also indicate that the sentence is invalid if it is offensive or has fluency issues (see Appendix B for details).\nThe annotators achieved substantial agreement on this task, with a Fleiss \u03ba score of 0.721. Furthermore, for 82.9% of examples, there is a complete agreement between both annotators and the intended label (the label which we ask GPT-4 to follow when generating triples).\nBased on the annotations, we discard triples\nwhere the intended-figurative sentences received no votes for figurative, or the intended-literal sentences received at least one vote not for literal. This asymmetry in the filtering heuristic is because we observe that GPT-4 was far more reliable at generating figurative uses of idioms than literal ones, and therefore we enforce a lower bar for retaining figurative sentences. We also discard all the triples that contain at least one vote for discard. In this way, we obtain the 512 English triples which constitute TIDE."
        },
        {
            "heading": "2.4 Collecting Translations",
            "text": "Finally, for a randomly subset of 50 idioms, we gather reference translations for the contrastive pairs of figurative and literal sentences from native speakers of Hebrew, Yoruba, Korean, and Chinese."
        },
        {
            "heading": "3 Experimental Setup",
            "text": "In this section we outline the models (\u00a73.1) and languages (\u00a73.2) we evaluate, our automatic metrics (\u00a73.3), and our setup for collecting human evaluations of generated translations (\u00a73.4)."
        },
        {
            "heading": "3.1 Models",
            "text": "We evaluate two classes of translation systems: MTspecific models and LMs. Here, the MT-specific models use an encoder-decoder architecture and are trained on large amounts of parallel data, whereas the LMs are decoder-only models trained to maximize likelihood (i.e., next-token prediction) on predominantly-English text.\nMT-Specific Models We evaluate NLLB (Meta, 2022) and Opus MT (Tiedemann and Thottingal, 2020; Tiedemann, 2020). NLLB is trained on par-\ntially synthetic parallel data, and covers 202 languages.3 Opus MT is a collection of models, each with a fixed source and target language.4 For both models, we decode the translation greedily.\nLanguage Models We evaluate ChatGPT (gpt-3.5-turbo; OpenAI 2022)5 and PaLM 2 (text-bison-001; Google et al. 2023).6 We do not include GPT-4 as it partially authored the examples in the dataset.\nBoth models were trained on a mixture of different languages, and in particular PaLM 2\u2019s training corpus included parallel data for hundreds of languages. However, both LMs are trained for the next-token-prediction objective.\nWe prompt the LM to generate translations zeroshot with the prompt \u201cTranslate the following English sentence to [target language]: [source sentence],\u201d and greedily decode the continuation. We do not provide in-context examples or further instructions about figurative language, in order to create a setting comparable to the evaluation of MT-specific models.\nGoogle Translate We also include Google Translate7 for reference due to its popularity in commercial use. We do not classify it as either an MT-specific model or LM due to the lack of public understanding of how it works."
        },
        {
            "heading": "3.2 Languages",
            "text": "We consider the eight target languages: Spanish (Es), Hindi (Hi), German (De), Hungarian (Hu), Korean (Ko), Chinese (Zh), Hebrew (He), and Yoruba (Yo), which vary in resource-availability and are typologically and culturally diverse. When the evaluation requires a gold translation, we focus on the last four languages for which TIDE contains human-written references.\n3https://huggingface.co/facebook/nllb-200-3. 3B\n4The most recent model for each language pair was downloaded from https://github.com/Helsinki-NLP/ Tatoeba-Challenge/tree/master/models: transformerbig for De, Es, and Hu, transformer-align for He, Hi, and Yo. Their most recent English to Chinese models by July 2023 do not produce coherent outputs, so we proceed with the earlier version available on HuggingFace: https://huggingface. co/Helsinki-NLP/opus-mt-en-zh. English to Korean models are not evaluated due to an issue with their PyTorch implementation, as reported by multiple users.\n5API last accessed on June 18, 2023. 6API last accessed on June 17, 2023. 7https://translate.google.com/. API last accessed\non June 14, 2023."
        },
        {
            "heading": "3.3 Automatic Metrics",
            "text": "We use different sets of metrics to evaluate translations for their literalness and for the overall translation quality.\nLiteralness Following Hendy et al. (2023), we use two metrics to assess the literalness of the translation: (1) Unaligned Source Words (USW) represents the number of source words unaligned with words in the translation, and (2) Non-Monotonicity (NM; Schioppa et al., 2021) determines the extent of reordering in the word-to-word alignments from the source sentence to its translation. For both metrics, we use the bitext alignments from the awesome-align framework (Dou and Neubig, 2021) which extract word alignments from mBERT embeddings.\nTranslation quality We evaluate translation quality based on sentence similarity between reference and predicted translations. We use chrF (Popovic\u0301, 2015), BERTScore (Sun et al., 2022), and BLEURT (Sellam et al., 2020). chrF measures precision, recall, and F-score of character n-grams. BERTScore is a contextual embedding-based evaluation metric that leverages the pretrained language model.8 BLEURT is a learned regression metric for automatic evaluation of generated text, which utilizes BERT for training on pairwise comparisons of reference and candidate sentences, calibrated on human quality judgments."
        },
        {
            "heading": "3.4 Human Evaluation",
            "text": "Due to the documented limitations of automatic evaluation for translation (Kasai et al., 2022), we additionally perform human evaluation of modelgenerated translations for Chinese, Korean, Hebrew, and Yoruba. We recruit one native speaker for each language, who are presented with the source sentences in each triple, along with generated translations from NLLB, Opus MT, ChatGPT, and PaLM 2. The model-generated translations are presented in a random order not shown to the annotator. For each sentence, they are asked: (1) Does the translation use the figurative meaning of the idiom, the literal meaning of the idiom, preserve the ambiguity due to an equivalent idiom in their language, or is it too nonsensical to determine? (2) Overall, is the translation perfectly correct, containing slight errors, or containing major errors? We use the same subset\n8We use XLM-RoBERTa-base embeddings for BERTScore. (Conneau et al., 2020)\nTranslations from pretrained LMs are less literal than those of MT-specific models, suggesting that LMs prefer less literal translations of ambiguous input (i.e., without disambiguating context). En \u2192 Ko Opus MT models are not evaluated due to an issue with their implementation.\nwhether each translation is figurative, literal, ambiguous due to an equivalent idiom, or is nonsensical. ChatGPT and PaLM 2 are more balanced in their preference between figurative and literal translations; Opus and NLLB overwhelmingly prefer literal translations.\nof 50 triples from \u00a72.4. With 3 sentences per triple and 4 source models for each triple, annotators each evaluate 600 translations."
        },
        {
            "heading": "4 Experimental Results",
            "text": "In our experiments, we explore MT-specific and LM systems\u2019 translation behavior on ambiguous subsentences (\u00a74.1), their sensitivity to disambiguating context (\u00a74.2), and their overall competence at translating literal versus figurative input (\u00a74.3)."
        },
        {
            "heading": "4.1 RQ1: How do MT systems translate ambiguous subsentences?",
            "text": "First, we investigate how MT systems behave on ambiguous subsentences without disambiguating context, in order to measure their preference for translating them figuratively or literally. We hypothesize that LMs are more likely to produce less literal translations of ambiguous subsentences than MT-specific systems, based on recent findings in Raunak et al. (2023). Unlike their setting, here the source sentences are always ambiguous, so both literal and figurative translations are correct.\nAutomatic Evaluation We measure the literalness of translations using USW and NM, where higher values mean less literal translations (\u00a73.3). Within each language, we normalize values by the average across systems in that language. This is because the metrics are not comparable across target languages, as they depend on linguistic properties of each target language. Shown in Figure 2, LMs (in blue) produce translations with higher USW scores than MT-specific models (in orange), across all target languages. In particular, Opus MT is the most literal model across all target languages. Moreover, we observe that the differences between LMs and MT-specific models become less pronounced for more under-resourced languages (the languages are ordered left to right based on count of pages in Common Crawl9).\n9https://commoncrawl.github.io/ cc-crawl-statistics/plots/languages\nin-language mean. LMs generally demonstrate greater context-awareness than MT-specific models.\nated translations is considered context-sensitive when it uses the figurative (or literal) sense of an idiom given figurative (or literal) disambiguating context. ChatGPT and PaLM 2 are much more context-sensitive than Opus MT and NLLB, which tend to translate idioms literally irrespective of context.\nResults based on NM (shown in Appendix C) corroborate our findings for SVO languages. This metric is inherently limited to target languages with the same word order as the source language (English in this work, with SVO order).\nHuman Evaluation In Figure 3, we show the human judgments of translations of ambiguous subsentences, indicating whether the translation is ambiguous, literal, figurative or nonsense. These results corroborate findings from automatic evaluation, and show even clearer distinctions. Overall, ChatGPT and PaLM 2 demonstrate much more balanced preferences between figurative and literal translations, compared to Opus MT and NLLB. For\nthe target language Chinese, ChatGPT prefers a figurative translation 62% of the time; however, that preference declines dramatically as the target language becomes more low-resource, dropping to 6% for Yoruba. PaLM 2 demonstrates more robust preferences across target languages, consistently preferring figurative translations 28% to 46% of the time. In contrast, Opus MT and NLLB overwhelmingly prefer literal translations, choosing a figurative translation only 4% to 20% of the time."
        },
        {
            "heading": "4.2 RQ2: How sensitive are MT systems to disambiguating context?",
            "text": "We next explore to what extent the predicted translation of an ambiguous subsentence changes when disambiguating context is available.\nAutomatic Evaluation Intuitively, if the LM is not sensitive to context, then the translation of the ambiguous subsentence, pa, should be equally contained in the translation p\u2113 for the literal sentence, and the translation pf for the figurative sentence. That is, the way the ambiguous subsentence a is translated should not be affected by the added context. On the other hand, if pa is more contained in p\u2113 than in pf (or vice versa), that would mean how the model handles a changes with the context.\nTherefore, we operationalize the sensitivity to disambiguating context as\n|contained_in(pa, pl)\u2212 contained_in(pa, pf )|\nwhere contained_in() is a measure of unidirectional sentence similarity. Here, we use chrP and\nBLEURT between the reference and prediction. While LMs and MT-specific models show comparable performance in translating literal sentences, NMT models are much weaker on figurative source sentences.\nBERTScore-P, the precision outputs of chrF and BERTScore, both ranging from 0 to 1. A higher value of sensitivity (close to 1) indicates high sensitivity to disambiguating contexts.\nFigure 4 shows the sensitivity results for the different models. The LMs, PaLM 2 and ChatGPT, generally exhibit a higher degree of sensitivity across most language pairs. Comparatively, the MT-specific models, Opus MT and NLLB, show less sensitivity. Opus MT, in particular, consistently demonstrates the lowest context sensitivity for all target languages.\nHuman Evaluation In human evaluation, a model is considered context-sensitive on a triple if annotators indicate that the idiom is translated figuratively for the figurative sentence, and literally for the literal sentence. Otherwise, the model is insensitive. As shown in Figure 5, both ChatGPT and PaLM 2 are very sensitive to context, though there is still room for improvement. For instance, for En\u2192Zh translation, ChatGPT and PaLM 2 translate correctly for 76% and 72% of idioms, respectively. Yet, the sensitivity of both models declines monotonically as the target language becomes more low-resource. In particular, for En\u2192Yo translation, ChatGPT translations are entirely nonsensical, and are qualitatively reported as frequently containing hallucinations completely unrelated to the source.\nNonetheless, Opus MT and NLLB are substantially less context-aware, correctly adapting to disambiguating context only 11.5% and 34.5% of the time, respectively. Yet, their more consistent performance across languages suggests that dedicated\ntraining for translation leads to better results on low-resource languages."
        },
        {
            "heading": "4.3 RQ3: Are there performance disparities between figurative and literal translations?",
            "text": "Finally, we investigate if translation systems have systematic performance gaps between translating figurative versus literal input.\nAutomatic Evaluation We use the reference translations collected in \u00a72.4, and measure text similarity between predicted and reference translation with BLEURT.\nThe results are shown in Figure 6. Across the board, models are more capable at literal translation than figurative translation. Yet, the gap is more pronounced for MT-specific models compared to LMs. ChatGPT and PaLM 2 exhibit performance gaps of 2.92% and 4.85%, respectively, between literal (higher) and figurative translations, on average across languages. For OPUS and NLLB this disparity is higher: 16.4% and 11.7%, respectively.\nOverall, MT-specific models and LMs demonstrate comparable performance on literal translations, while NMT models lag behind LMs on figurative translations.\nHuman Evaluation In Figure 7, we compare how human annotators evaluate the correctness of translations overall, with the options perfect, minor mistakes, and major mistakes. Consistent with findings from automatic evaluation, ChatGPT and PaLM 2 demonstrate more consistent performance across\nliteral and figurative translations. However, Opus and NLLB are notably stronger at literal translations than figurative ones.\nWe additionally observe that on Yoruba, the most low-resource language we study, Opus MT and NLLB actually far outperform ChatGPT and PaLM 2. We speculate that pretrained LMs are particularly strong on languages that were well-represented during pretraining; when this is not the case, it may produce degenerate text by entirely failing to grasp the translation task."
        },
        {
            "heading": "5 Related Work",
            "text": "Ambiguity in translation Context-aware translation usually focuses on grammatical features that the source language does not encode but the target language requires, such as formality (e.g., Chinese has a formal and informal \u201cyou\u201d; Voita et al., 2019a), gendered pronouns (e.g., French has a male and female \u201cit\u201d; M\u00fcller et al., 2018; Yin et al., 2021), verb form (e.g., Spanish has six verb forms for past tense; Fernandes et al., 2023), and ellipses (e.g., \u201cWe all did\u201d in English cannot be translated to Russian without identifying the elided verb; Voita et al., 2019b). Another well-studied issue is lexical cohesion, where the same phrase in the source sentence (e.g., a named entity like \u201cJulia\u201d) should be translated consistently each time (Wong and Kit, 2012; Kuang et al., 2018). In contrast, our work extends the study of context-aware translation to expressions which are ambiguous in the source language alone, focusing on idiomatic expressions.\nTIDE joins a family of contrastive datasets that test model sensitivity to contextual information (M\u00fcller et al., 2018; Bawden et al., 2018; Voita et al., 2019b, i.a.).\nTranslation of figurative language Figurative language has received considerable attention in MT research. Some work has studied the hidden representations or attention patterns of MT-specific models when processing multi-word expressions (Rikters and Bojar, 2017; Garcia et al., 2021; Dankers et al., 2022), or proposed methods to improve translation of these expressions (Zaninello and Birch, 2020; Gamallo and Garcia, 2019). In particular, Baziotis et al. (2023) show that monolingual pretraining improves figurative translation, which may explain our finding that pretrained LMs generate less literal translations and are more sensitive to disambiguating context.\nThe most closely related work, Raunak et al. (2023), compare how LMs and MT-specific systems translate sentences with idiomatic expressions, and similarly find that LMs produce substantially less literal translations. We go further by evaluating how these models handle ambiguous input and their sensitivity to disambiguating context.\nDatasets for idiom translation Fadaee et al. (2018) introduced the first extensive dataset for idiom translation, identifying data scarcity as one of core challenges in this domain. EPIE (Saxena and Paul, 2020) is a large-scale corpus with 25K potentially idiomatic expressions (PIEs), with rep-\nresentation of both figurative and literal usages. MAGPIE (Haagsma et al., 2020) is a more expansive dataset of 50K samples that also contain genre labels. PECTI (Tang, 2022) curated a parallel English translation dataset of Chinese idioms. While these datasets offer a general-purpose testbed, the contrastive sentence pairs in TIDE enable finergrained analysis, while the fluency of source sentences matches (if not exceeding) that of naturallyoccurring datasets."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this work we focus on semantic ambiguity in machine translation, specifically when using idiomatic language. We introduce a new benchmark (TIDE) of sentences that include idioms, along with disambiguating contexts (both literal and figurative). We then use TIDE to investigate the behavior of different translation systems on ambiguous input and their sensitivity to disambiguating context, uncovering new strengths of pretrained LMs compared to MT-specific models.\nOur findings point to pretrained LMs as a promising backbone for translation systems, and we foresee a future that combines the strong language understanding of LMs with dedicated supervision for translation."
        },
        {
            "heading": "Acknowledgments",
            "text": "We would like to thank the UW NLP community for valuable discussion of this work. We are grateful to Weijia Shi, Jiacheng (Gary) Liu, and Xiaochuang Han for their help in writing and evaluating Chinese translations, and Zhaofeng Wu for feedback on the draft and figures.\nWe thank the reviewers for their valuable feedback and suggestions, and OpenAI for offering access to their models through the API.\nLimitations\nIn this work we study ambiguous source sentences specifically through idioms that are available to both literal and figurative interpretations. While this allows us to efficiently collect a dataset and perform focused evaluation, ambiguity occurs in more diverse forms, and we encourage future work to collect more data in the form of TIDE. Contemporary work collects a dataset of ambiguous sentences (with direct disambiguations, rather than disambiguating context), and is a promising start (Liu et al., 2023).\nIn addition, we only study the behavior of translation systems when English is the source language, due to the availability of English idiom collections. Yet figurative expressions vary greatly across languages (Kabra et al., 2023), and our conclusions may not necessarily generalize to translation from other languages."
        },
        {
            "heading": "A TIDE Creation Details",
            "text": "A.1 Sentence generation\nWe use GPT-4 to generate the 700 triples consisting of an ambiguous subsentence, a figurative sentence, and a literal sentence. The configuration parameters were set as follows: max_tokens=512, temperature=0, and top_p=1. The prompt is shown in Table 2.\nIn addition, the generation process undergoes iterative refinements under a set of criteria, during which we prompt the GPT-4 instance to rewrite the entire triple if the generation included any prohibited words: \u201cliterally\u201d, \u201cfiguratively\u201d, \u201cambiguously\u201d, \u201cphysically\u201d, \u201cmetaphorically\u201d, and \u201cbecause\u201d. These words are observed to potentially degrade sentence quality, as they often prompt the GPT-4 to merely provide working definitions of the idioms instead of generating novel context. We also ensure through these refinements that the ambiguous subsentence is indeed a substring of the figurative and literal sentences.\nA.2 Processing pronouns\nAs written in the generation prompt (Table 2), we ban GPT-4 from including subjects in the ambiguous subsentence as we observe that GPT-4 frequently uses personal pronouns which end up disambiguating the whole subsentence (e.g., He is a chip off the old block is not ambiguous due to the pronoun he). Following the generation stage, we conduct additional rule-based modifications to the sentences to facilitate the translation process for MT models. In cases where the ambiguous subsentence begins with a lexical verb, and both the literal and figurative sentences include interchangeable subjects preceding the verb, we make alterations so that both use the same pronoun, which are then incorporated into the shared subsentence. These alterations include converting \u201che\u201d to \u201cshe\u201d, \u201cshe\u201d to \u201che\u201d, and \u201che\u201d/\u201cshe\u201d to \u201cthey\u201d to have the pronoun shared between the figurative and literal sentence."
        },
        {
            "heading": "B Amazon Mechanical Turk (MTurk) details",
            "text": "We employ Amazon Mechanical Turk (MTurk), a crowdsourcing marketplace, to collect well-formed triples, composed of an idiom and corresponding ambiguous subsentence, figurative sentence, and literal sentence, generated by GPT-4 as described in \u00a72.2.\nWe select 30 workers based on their scores in a qualification test human intelligence task (HIT) that we administer. This test, which typically requires less than 30 minutes to complete, consists of 20 handcrafted problems in the exact format as the main HIT. Upon completion, workers receive a payment of $7.\nIn both the qualification test and the main task, each problem presents an English utterance derived from a randomly shuffled pool of 700 ambiguous subsentences, 700 figurative sentences, and 700 literal sentences. The problem also provides the corresponding idiom in use and its dictionary (figurative) definition. With this information, workers must ascertain whether the idiom was used in a figurative, literal, or ambiguous context, or if the utterance should be discarded. The option to discard is included to eliminate nonsensical or offensive generations.\nFor the main task, we gather multiple gold labels for each problem to ensure accuracy and credibility. This means that multiple workers are assigned the same problem. We initially release a batch of first 50 problems of the pool, collecting 4 gold labels for each to examine interannotator agreement. Based on our observation that 2 gold labels are sufficient, we proceed to collect only 2 labels for the remaining batches. Workers are remunerated at a rate of $0.30 for every 5 problems completed, an interval expected to take 1 minute.\nFor how we utilize these labels, see \u00a72.3."
        },
        {
            "heading": "C Additional results",
            "text": "See Figure 9 and Figure 10 for additional results on RQ1 and RQ2, respectively."
        }
    ],
    "title": "That was the last straw, we need more: Are Translation Systems Sensitive to Disambiguating Context?",
    "year": 2023
}