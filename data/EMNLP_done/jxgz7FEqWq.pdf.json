{
    "abstractText": "Fine-tuning pre-trained large language models in a parameter-efficient manner is widely studied for its effectiveness and efficiency. The popular method of low-rank adaptation (LoRA) offers a notable approach, hypothesizing that the adaptation process is intrinsically low-dimensional. Although LoRA has demonstrated commendable performance, it is implemented with a fixed and unalterable intrinsic rank that might not always be the ideal choice. Recognizing the need for more flexible adaptation, we extend the methodology of LoRA to an innovative approach we call sparse low-rank adaptation (SoRA) that enables dynamic adjustments to the intrinsic rank during the adaptation process. We achieve this through the incorporation of a gate unit optimized with proximal gradient method in the training stage, controlling the cardinality of rank under the sparsity of the gate. In the subsequent inference stage, we eliminate the parameter blocks corresponding to the zeroed-out ranks, to reduce each SoRA module back to a concise yet rankoptimal LoRA. Our approach strengthens the representation power of LoRA by initializing it with a higher rank, while efficiently taming a temporarily increased number of parameters via updating in a sparse way. We further introduce a sparsifying scheduler for SoRA, aiming to examine the impact of the number of nonzero parameters on the model\u2019s memorization and generalization. Our experimental results demonstrate that SoRA can outperform other baselines even with 70% retained parameters and 70% training time.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ning Ding"
        },
        {
            "affiliations": [],
            "name": "Xingtai Lv"
        },
        {
            "affiliations": [],
            "name": "Qiaosen Wang"
        },
        {
            "affiliations": [],
            "name": "Yulin Chen"
        },
        {
            "affiliations": [],
            "name": "Bowen Zhou"
        },
        {
            "affiliations": [],
            "name": "Zhiyuan Liu"
        },
        {
            "affiliations": [],
            "name": "Maosong Sun"
        }
    ],
    "id": "SP:32fa84ff6f7eb66f9a672aa01327788c51c1a887",
    "references": [
        {
            "authors": [
                "Amir Beck",
                "Marc Teboulle."
            ],
            "title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems",
            "venue": "SIAM journal on imaging sciences, 2(1):183\u2013202.",
            "year": 2009
        },
        {
            "authors": [
                "Luisa Bentivogli",
                "Peter Clark",
                "Ido Dagan",
                "Danilo Giampiccolo."
            ],
            "title": "The fifth pascal recognizing textual entailment challenge",
            "venue": "Proceedings of Text Analysis Conference.",
            "year": 2009
        },
        {
            "authors": [
                "Rishi Bommasani",
                "Drew A Hudson",
                "Ehsan Adeli",
                "Russ Altman",
                "Simran Arora",
                "Sydney von Arx",
                "Michael S Bernstein",
                "Jeannette Bohg",
                "Antoine Bosselut",
                "Emma Brunskill"
            ],
            "title": "On the opportunities and risks of foundation models",
            "year": 2021
        },
        {
            "authors": [
                "Alec Radford",
                "Ilya Sutskever",
                "Dario Amodei."
            ],
            "title": "Language models are few-shot learners",
            "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12,",
            "year": 2020
        },
        {
            "authors": [
                "Emmanuel J Candes",
                "Justin K Romberg",
                "Terence Tao."
            ],
            "title": "Stable signal recovery from incomplete and inaccurate measurements",
            "venue": "Communications on Pure and Applied Mathematics: A Journal Issued by the Courant Institute of Mathematical Sciences,",
            "year": 2006
        },
        {
            "authors": [
                "Antonin Chambolle",
                "Ronald A De Vore",
                "Nam-Yong Lee",
                "Bradley J Lucier."
            ],
            "title": "Nonlinear wavelet image processing: variational problems, compression, and noise removal through wavelet shrinkage",
            "venue": "IEEE Transactions on Image Processing, 7(3):319\u2013335.",
            "year": 1998
        },
        {
            "authors": [
                "Ido Dagan",
                "Oren Glickman",
                "Bernardo Magnini."
            ],
            "title": "The pascal recognising textual entailment challenge",
            "venue": "Machine Learning Challenges Workshop, pages 177\u2013190. Springer.",
            "year": 2005
        },
        {
            "authors": [
                "Tim Dettmers",
                "Artidoro Pagnoni",
                "Ari Holtzman",
                "Luke Zettlemoyer."
            ],
            "title": "Qlora: Efficient finetuning of quantized llms",
            "venue": "arXiv preprint arXiv:2305.14314.",
            "year": 2023
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Ning Ding",
                "Yujia Qin",
                "Guang Yang",
                "Fuchao Wei",
                "Zonghan Yang",
                "Yusheng Su",
                "Shengding Hu",
                "Yulin Chen",
                "Chi-Min Chan",
                "Weize Chen"
            ],
            "title": "Parameter-efficient fine-tuning of large-scale pretrained language models",
            "year": 2023
        },
        {
            "authors": [
                "Bill Dolan",
                "Chris Brockett."
            ],
            "title": "Automatically constructing a corpus of sentential paraphrases",
            "venue": "Third International Workshop on Paraphrasing (IWP2005).",
            "year": 2005
        },
        {
            "authors": [
                "Dan Friedman",
                "Ben Dodge",
                "Danqi Chen."
            ],
            "title": "Single-dataset experts for multi-dataset question answering",
            "venue": "ArXiv preprint, abs/2109.13880.",
            "year": 2021
        },
        {
            "authors": [
                "Peng Gao",
                "Jiaming Han",
                "Renrui Zhang",
                "Ziyi Lin",
                "Shijie Geng",
                "Aojun Zhou",
                "Wei Zhang",
                "Pan Lu",
                "Conghui He",
                "Xiangyu Yue"
            ],
            "title": "Llama-adapter v2: Parameter-efficient visual instruction model",
            "venue": "arXiv preprint arXiv:2304.15010",
            "year": 2023
        },
        {
            "authors": [
                "Danilo Giampiccolo",
                "Bernardo Magnini",
                "Ido Dagan",
                "Bill Dolan."
            ],
            "title": "The third PASCAL recognizing textual entailment challenge",
            "venue": "Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, pages 1\u20139, Prague. Association for",
            "year": 2007
        },
        {
            "authors": [
                "Demi Guo",
                "Alexander Rush",
                "Yoon Kim."
            ],
            "title": "Parameter-efficient transfer learning with diff pruning",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Lan-",
            "year": 2021
        },
        {
            "authors": [
                "R Bar Haim",
                "Ido Dagan",
                "Bill Dolan",
                "Lisa Ferro",
                "Danilo Giampiccolo",
                "Bernardo Magnini",
                "Idan Szpektor."
            ],
            "title": "The second pascal recognising textual entailment challenge",
            "venue": "Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual",
            "year": 2006
        },
        {
            "authors": [
                "Zhao",
                "Jun Zhu."
            ],
            "title": "Pre-trained models: Past, present and future",
            "venue": "AI Open.",
            "year": 2021
        },
        {
            "authors": [
                "Junxian He",
                "Chunting Zhou",
                "Xuezhe Ma",
                "Taylor BergKirkpatrick",
                "Graham Neubig."
            ],
            "title": "Towards a unified view of parameter-efficient transfer learning",
            "venue": "International Conference on Learning Representations.",
            "year": 2022
        },
        {
            "authors": [
                "Pengcheng He",
                "Jianfeng Gao",
                "Weizhu Chen."
            ],
            "title": "Debertav3: Improving deberta using electra-style pretraining with gradient-disentangled embedding sharing",
            "venue": "arXiv preprint arXiv:2111.09543.",
            "year": 2021
        },
        {
            "authors": [
                "Pengcheng He",
                "Xiaodong Liu",
                "Jianfeng Gao",
                "Weizhu Chen."
            ],
            "title": "Deberta: Decoding-enhanced bert with disentangled attention",
            "venue": "arXiv preprint arXiv:2006.03654.",
            "year": 2020
        },
        {
            "authors": [
                "Neil Houlsby",
                "Andrei Giurgiu",
                "Stanislaw Jastrzebski",
                "Bruna Morrone",
                "Quentin de Laroussilhe",
                "Andrea Gesmundo",
                "Mona Attariyan",
                "Sylvain Gelly."
            ],
            "title": "Parameter-efficient transfer learning for NLP",
            "venue": "Proceedings of the 36th International Conference on Ma-",
            "year": 2019
        },
        {
            "authors": [
                "Edward J Hu",
                "Yelong Shen",
                "Phillip Wallis",
                "Zeyuan Allen-Zhu",
                "Yuanzhi Li",
                "Shean Wang",
                "Lu Wang",
                "Weizhu Chen."
            ],
            "title": "Lora: Low-rank adaptation of large language models",
            "venue": "ArXiv preprint, abs/2106.09685.",
            "year": 2021
        },
        {
            "authors": [
                "Shengding Hu",
                "Zhen Zhang",
                "Ning Ding",
                "Yadao Wang",
                "Yasheng Wang",
                "Zhiyuan Liu",
                "Maosong Sun."
            ],
            "title": "Sparse structure search for parameter-efficient tuning",
            "venue": "arXiv preprint arXiv:2206.07382.",
            "year": 2022
        },
        {
            "authors": [
                "Rabeeh Karimi Mahabadi",
                "James Henderson",
                "Sebastian Ruder."
            ],
            "title": "Compacter: Efficient low-rank hypercomplex adapter layers",
            "venue": "Advances in Neural Information Processing Systems, 34:1022\u20131035.",
            "year": 2021
        },
        {
            "authors": [
                "Brian Lester",
                "Rami Al-Rfou",
                "Noah Constant."
            ],
            "title": "The power of scale for parameter-efficient prompt tuning",
            "venue": "ArXiv preprint, abs/2104.08691.",
            "year": 2021
        },
        {
            "authors": [
                "Lagunas",
                "Alexander Rush",
                "Thomas Wolf."
            ],
            "title": "Datasets: A community library for natural language processing",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 175\u2013184, Online",
            "year": 2021
        },
        {
            "authors": [
                "Xiang Lisa Li",
                "Percy Liang."
            ],
            "title": "Prefix-tuning: Optimizing continuous prompts for generation",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language",
            "year": 2021
        },
        {
            "authors": [
                "Peiyu Liu",
                "Ze-Feng Gao",
                "Wayne Xin Zhao",
                "Zhong-Yi Lu",
                "Ji-Rong Wen."
            ],
            "title": "Enabling lightweight fine-tuning for pre-trained language model compression based on matrix product operators",
            "venue": "arXiv preprint arXiv:2106.02205.",
            "year": 2021
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "ArXiv preprint, abs/1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Adam Paszke",
                "Sam Gross",
                "Francisco Massa",
                "Adam Lerer",
                "James Bradbury",
                "Gregory Chanan",
                "Trevor Killeen",
                "Zeming Lin",
                "Natalia Gimelshein",
                "Luca Antiga"
            ],
            "title": "Pytorch: An imperative style, high-performance deep learning library",
            "year": 2019
        },
        {
            "authors": [
                "Yujia Qin",
                "Xiaozhi Wang",
                "Yusheng Su",
                "Yankai Lin",
                "Ning Ding",
                "Zhiyuan Liu",
                "Juan-Zi Li",
                "Lei Hou",
                "Peng Li",
                "Maosong Sun",
                "Jie Zhou."
            ],
            "title": "Exploring low-dimensional intrinsic task subspace via prompt tuning",
            "venue": "ArXiv, abs/2110.07867.",
            "year": 2021
        },
        {
            "authors": [
                "Pranav Rajpurkar",
                "Jian Zhang",
                "Konstantin Lopyrev",
                "Percy Liang."
            ],
            "title": "Squad: 100,000+ questions for machine comprehension of text",
            "venue": "arXiv preprint arXiv:1606.05250.",
            "year": 2016
        },
        {
            "authors": [
                "Oren Rippel",
                "Michael Gelbart",
                "Ryan Adams."
            ],
            "title": "Learning ordered representations with nested dropout",
            "venue": "International Conference on Machine Learning, pages 1746\u20131754. PMLR.",
            "year": 2014
        },
        {
            "authors": [
                "Simone Scardapane",
                "Danilo Comminiello",
                "Amir Hussain",
                "Aurelio Uncini."
            ],
            "title": "Group sparse regularization for deep neural networks",
            "venue": "Neurocomputing, 241:81\u201389.",
            "year": 2017
        },
        {
            "authors": [
                "Richard Socher",
                "Alex Perelygin",
                "Jean Wu",
                "Jason Chuang",
                "Christopher D Manning",
                "Andrew Y Ng",
                "Christopher Potts."
            ],
            "title": "Recursive deep models for semantic compositionality over a sentiment treebank",
            "venue": "Proceedings of the 2013 conference on empiri-",
            "year": 2013
        },
        {
            "authors": [
                "Yusheng Su",
                "Chi-Min Chan",
                "Jiali Cheng",
                "Yujia Qin",
                "Yankai Lin",
                "Shengding Hu",
                "Zonghan Yang",
                "Ning Ding",
                "Zhiyuan Liu",
                "Maosong Sun."
            ],
            "title": "Arbitrary few parameters are good enough for adapting large-scale pre-trained language models",
            "venue": "arXiv",
            "year": 2023
        },
        {
            "authors": [
                "Yi-Lin Sung",
                "Jaemin Cho",
                "Mohit Bansal."
            ],
            "title": "Lst: Ladder side-tuning for parameter and memory efficient transfer learning",
            "venue": "arXiv preprint arXiv:2206.06522.",
            "year": 2022
        },
        {
            "authors": [
                "Robert Tibshirani."
            ],
            "title": "Regression shrinkage and selection via the lasso",
            "venue": "Journal of the Royal Statistical Society: Series B (Methodological), 58(1):267\u2013288.",
            "year": 1996
        },
        {
            "authors": [
                "Hugo Touvron",
                "Thibaut Lavril",
                "Gautier Izacard",
                "Xavier Martinet",
                "Marie-Anne Lachaux",
                "Timoth\u00e9e Lacroix",
                "Baptiste Rozi\u00e8re",
                "Naman Goyal",
                "Eric Hambro",
                "Faisal Azhar"
            ],
            "title": "Llama: Open and efficient foundation language models",
            "year": 2023
        },
        {
            "authors": [
                "Mojtaba Valipour",
                "Mehdi Rezagholizadeh",
                "Ivan Kobyzev",
                "Ali Ghodsi."
            ],
            "title": "Dylora: Parameter efficient tuning of pre-trained models using dynamic search-free low-rank adaptation",
            "venue": "arXiv preprint arXiv:2210.07558.",
            "year": 2022
        },
        {
            "authors": [
                "Alex Warstadt",
                "Amanpreet Singh",
                "Samuel R Bowman."
            ],
            "title": "Neural network acceptability judgments",
            "venue": "Transactions of the Association for Computational Linguistics, 7:625\u2013641.",
            "year": 2019
        },
        {
            "authors": [
                "Wei Wen",
                "Chunpeng Wu",
                "Yandan Wang",
                "Yiran Chen",
                "Hai Li."
            ],
            "title": "Learning structured sparsity in deep neural networks",
            "venue": "Advances in neural information processing systems, 29.",
            "year": 2016
        },
        {
            "authors": [
                "Adina Williams",
                "Nikita Nangia",
                "Samuel R Bowman."
            ],
            "title": "A broad-coverage challenge corpus for sentence understanding through inference",
            "venue": "arXiv preprint arXiv:1704.05426.",
            "year": 2017
        },
        {
            "authors": [
                "Thomas Wolf",
                "Lysandre Debut",
                "Victor Sanh",
                "Julien Chaumond",
                "Clement Delangue",
                "Anthony Moi",
                "Pierric Cistac",
                "Tim Rault",
                "R\u00e9mi Louf",
                "Morgan Funtowicz"
            ],
            "title": "Transformers: State-of-the-art natural language processing",
            "year": 2020
        },
        {
            "authors": [
                "Elad Ben Zaken",
                "Shauli Ravfogel",
                "Yoav Goldberg."
            ],
            "title": "Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked languagemodels",
            "venue": "ArXiv preprint, abs/2106.10199.",
            "year": 2021
        },
        {
            "authors": [
                "Qingru Zhang",
                "Minshuo Chen",
                "Alexander Bukharin",
                "Pengcheng He",
                "Yu Cheng",
                "Weizhu Chen",
                "Tuo Zhao."
            ],
            "title": "Adaptive budget allocation for parameter-efficient fine-tuning",
            "venue": "arXiv preprint arXiv:2303.10512.",
            "year": 2023
        },
        {
            "authors": [
                "Mengjie Zhao",
                "Tao Lin",
                "Fei Mi",
                "Martin Jaggi",
                "Hinrich Sch\u00fctze."
            ],
            "title": "Masking as an efficient alternative to finetuning for pretrained language models",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Adapting large-scale pre-trained language models (Devlin et al., 2019; Brown et al., 2020; He et al., 2020; Bommasani et al., 2021; Han et al., 2021; Touvron et al., 2023) in a parameter-efficient (He\n\u2217 equal contributions \u2020 corresponding authors\net al., 2022; Ding et al., 2023; Hu et al., 2023) manner is increasingly gaining traction within the research community. The methods of this paradigm typically keep most of the parameters of the underlying model unchanged, either insert additional trainable parameters into the model (Houlsby et al., 2019; Li and Liang, 2021), or specify a small number of parameters (Zaken et al., 2021; Liu et al., 2021; Su et al., 2023) to be trainable or reparameterize the adaptation process into a more efficient form (Hu et al., 2021; Qin et al., 2021). They have been validated to be effective across various models and tasks, often yielding comparable or even better results than full-parameter fine-tuning.\nThe development potential of parameter-efficient fine-tuning became evident after extensive validation of its performance. These methods offer the opportunity to adapt the base model to fit any data, allowing for enhancements and customization of language models tailored to specific tasks and personalized user characteristics. Due to the lightweight nature of the optimized parameters, they can be seamlessly plugged into the model, allowing targeted enhancements to be made. Among these methods, low-rank adaptation (LORA (Hu et al., 2021)) is considered one of the most efficient methods at present. It assumes that the change of the model\u2019s parameters after adaptation is \"intrinsically low-dimensional\" and performs adaptation by optimizing the matrix obtained from low-rank decomposition. LoRA avoids forward propagation latency caused by inserting additional neural modules while demonstrating stable performance. Although effective, the setup of the intrinsic rank (normally as a hyperparameter) is still unclear. Intuitively, a larger rank brings larger optimization space and creates the capacity to handle more challenging tasks. However, in practice, the optimal intrinsic rank would vary according to multiple factors such as the backbone model and the task.\nGiven the enormous computational cost of\nsearching hyperparameters on large-scale models (such as GPT-3 (Brown et al., 2020) with 175 billion parameters and LLaMA (Touvron et al., 2023) with 700 million to 65 billion parameters), developing a method based on adaptive ranks is a natural approach. Some existing work has attempted to explore this direction (Valipour et al., 2022; Zhang et al., 2023), but they are largely heuristic or introduce additional costs. In this paper, we propose SoRA, a simple, effective, and automated method for adaptive parameter-efficient fine-tuning. We introduce a gating module with a proximal gradient decent update under L1 regularization to control the sparsity of the updated matrices. After training, the zero entry of the gating vector records the columns of the down-projection matrix and the rows of the up-projection matrix, which can be simply dropped and stored in a more parameterefficient manner. Compared to other adaptive approaches, the proximal gradient method has a clear mathematical meaning and does not have to involve other computations and heuristics. For example, AdaLoRA (Zhang et al., 2023) introduces an additional regularizer to ensure that the lower and upper projection matrices strictly adhere to the definition of singular value decomposition (SVD), with each matrix being orthogonal. However, this regularization term incurs substantial computational overhead due to the gradient calculations. In contrast, we eliminate this requirement and instead selectively filter low-rank components by controlling the intermediate diagonal matrix. We detailedly compare SoRA and related methods in Section 3.\nThe mechanism of SoRA also allows us to control the sparsity temporarily and investigate the relationship between the number of non-zero trainable parameters and memorization and generalization capabilities. We propose a sparsifying scheduler and find that the process of model adaptation exhibits a strong \u201ccompression capability\u201d, and even a tiny portion of parameters (lower than LoRA rank being 1) could retain considerable performance. Extensive experiments are conducted to demonstrate the effectiveness of our method. Particularly, our model could consistently outperform parameter-efficient baselines with fewer parameters and 30% shorter training time on a wide range of downstream tasks. The code of this work will be publicly available at https://github.com/ TsinghuaC3I/SoRA."
        },
        {
            "heading": "2 A Closer Look to Adaptive Rank",
            "text": "Related Work. Before introducing our approach, we first briefly recap parameter-efficient tuning and our backbone low-rank adaptation (LoRA). Parameter-efficient tuning is a set of methods that only optimize a small portion of parameters and keep the main model untouched for adaptation. Some parameter-efficient methods would insert additional neural modules or parameters to the backbone model, such as Adapter (Houlsby et al., 2019), Prefix and Prompt Tuning (Li and Liang, 2021; Lester et al., 2021). And another line of such methods attempts to specify particular parameters to be trainable or prunable (Guo et al., 2021; Zhao et al., 2020; Zaken et al., 2021). Researchers derive a series of variants of parameter-efficient methods to improve the effectiveness or efficiency (Karimi Mahabadi et al., 2021; Hu et al., 2022; Sung et al., 2022; He et al., 2022). Recently, the applications of parameter-efficient fine-tuning are expanded to multi-modal and instruction-tuning scenarios (Gao et al., 2023; Dettmers et al., 2023). In this paper, we focus more on LoRA (Hu et al., 2021), which uses low-rank matrices to approximate the change of weights.\nIn LoRA, pre-trained weights (denoted as W0 \u2208 Rp\u00d7q) are frozen, and the trainable LoRA modules are low-rank decomposition matrices Wd \u2208 Rr\u00d7q and Wu \u2208 Rp\u00d7r of the change of each weight matrix \u2206 = WuWd \u2208 Rp\u00d7q. In this way, the output of the current layer h could be represented as\ny\u2190\u2212W0x+WuWdx, (1) where r \u226a min{p, q} is a hyper-parameter of \u201cintrinsic dimension\u201d that controls the size of low-rank matrices and the number of trainable parameters. In this section, we primarily focus on the last term, denoting z\u2190\u2212WuWdx. Adaptive Rank on LoRA. Despite a great step forward in tractability and efficiency, LoRA is still restricted by its inflexibility in selecting the optimal rank r. Unlike continuous hyperparameters such as learning rate and weight decay that can be tuned adaptively online during the training process, LoRA rank r takes discrete values \u2013 the change of which will directly alter the model structures. The optimal choice of rank can vary across different backbone models and downstream tasks. A conservative choice of huge rank r can waste training time and computation resources, while progressively setting r tiny may degrade model performance and\n\u00b7 \u00b7\n\u00b7 <latexit sha1_base64=\"cAiOZblwH8iALsf/vkdYLcRxSgQ=\">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit> \u00b7[\n[\n\u00b7<latexit sha1_base64=\"cAiOZblwH8iALsf/vkdYLcRxSgQ=\">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit> \u00b7 [\n[\n<latexit sha1_base64=\"UjUn3B7ufgCOmxVTlETrJ0C/vJY=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>\nx <latexit sha1_base64=\"7LjW4inxM3IqVcFm0MkAOftM7UI=\">AAAB83icbVDLSsNAFL2pr1pfVZduBovgKiRS1GXBjcsK9gFNKJPJpB06mYSZiVBCfsONC0Xc+jPu/BsnbRbaemDgcM693DMnSDlT2nG+rdrG5tb2Tn23sbd/cHjUPD7pqySThPZIwhM5DLCinAna00xzOkwlxXHA6SCY3ZX+4IlKxRLxqOcp9WM8ESxiBGsjeV6M9TSI8kExDsfNlmM7C6B14lakBRW64+aXFyYki6nQhGOlRq6Taj/HUjPCadHwMkVTTGZ4QkeGChxT5eeLzAW6MEqIokSaJzRaqL83chwrNY8DM1lmVKteKf7njTId3fo5E2mmqSDLQ1HGkU5QWQAKmaRE87khmEhmsiIyxRITbWpqmBLc1S+vk/6V7V7b7Yd2q2NXddThDM7hEly4gQ7cQxd6QCCFZ3iFNyuzXqx362M5WrOqnVP4A+vzB0Ivkcc=</latexit>\nWd<latexit sha1_base64=\"pIWFDq2Tt0ud+NvmF88Xp+emVao=\">AAAB6nicbVBNS8NAEJ34WetX1aOXxSKIh5BIUY8FLx4r2g9oY9lsN+3SzW7Y3Qgh9Cd48aCIV3+RN/+N2zYHbX0w8Hhvhpl5YcKZNp737aysrq1vbJa2yts7u3v7lYPDlpapIrRJJJeqE2JNORO0aZjhtJMoiuOQ03Y4vpn67SeqNJPiwWQJDWI8FCxiBBsr3WeP5/1K1XO9GdAy8QtShQKNfuWrN5AkjakwhGOtu76XmCDHyjDC6aTcSzVNMBnjIe1aKnBMdZDPTp2gU6sMUCSVLWHQTP09keNY6ywObWeMzUgvelPxP6+bmug6yJlIUkMFmS+KUo6MRNO/0YApSgzPLMFEMXsrIiOsMDE2nbINwV98eZm0Llz/0q3d1ap1t4ijBMdwAmfgwxXU4RYa0AQCQ3iGV3hzuPPivDsf89YVp5g5gj9wPn8A/fCNjg==</latexit> y\u21e4\n<latexit sha1_base64=\"z65MLNYS9m9NIMg0IO7wQhtVhZc=\">AAAB8XicbVDLSsNAFL2pr1pfVZduBovgqiQi6rLgxmUF+8A2lMn0ph06mYSZiVBC/8KNC0Xc+jfu/BsnbRbaemDgcM69zLknSATXxnW/ndLa+sbmVnm7srO7t39QPTxq6zhVDFssFrHqBlSj4BJbhhuB3UQhjQKBnWBym/udJ1Sax/LBTBP0IzqSPOSMGis99iNqxkGYjWaDas2tu3OQVeIVpAYFmoPqV38YszRCaZigWvc8NzF+RpXhTOCs0k81JpRN6Ah7lkoaofazeeIZObPKkISxsk8aMld/b2Q00noaBXYyT6iXvVz8z+ulJrzxMy6T1KBki4/CVBATk/x8MuQKmRFTSyhT3GYlbEwVZcaWVLEleMsnr5L2Rd27ql/eX9Ya9aKOMpzAKZyDB9fQgDtoQgsYSHiGV3hztPPivDsfi9GSU+wcwx84nz/gTpEA</latexit>\ng <latexit sha1_base64=\"pcjqgRbl/D1PXi1iZ64D301adTY=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hE1GPBi8eK9gPaUDbbTbt0swm7E6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSQ7uf9as1z/XmIKvEL0gNCjT61a/eIGFZzBUySY3p+l6KQU41Cib5tNLLDE8pG9Mh71qqaMxNkM9PnZIzqwxIlGhbCslc/T2R09iYSRzazpjiyCx7M/E/r5thdBPkQqUZcsUWi6JMEkzI7G8yEJozlBNLKNPC3krYiGrK0KZTsSH4yy+vktaF61+5l/eXtbpbxFGGEziFc/DhGupwBw1oAoMhPMMrvDnSeXHenY9Fa8kpZo7hD5zPHz1kjbg=</latexit> Wu\n<latexit sha1_base64=\"ot/yvaZQPa9zErjmSLBW76zU60o=\">AAACHnicbVDLSitBEO3xba5Xoy7dNAbBu7hhRnwtBV24cKFgVMiEoaZTExt7eobuGiEM8yVu/BU3LhQRXOnf2IlZ+DrQcPqcKqrqxLmSlnz/zRsbn5icmp6Zrf2Z+zu/UF9cOrNZYQS2RKYycxGDRSU1tkiSwovcIKSxwvP4an/gn1+jsTLTp9TPsZNCT8tECiAnRfWtXlRSxf+HSBARDzXECqIeD1OgSwGqPKoif334i5MyPEBFUP2L6g2/6Q/Bf5JgRBpshOOo/hJ2M1GkqEkosLYd+Dl1SjAkhcKqFhYWcxBX0MO2oxpStJ1yeF7F15zS5Ulm3NPEh+rnjhJSa/tp7CoHe9rv3kD8zWsXlOx2SqnzglCLj0FJoThlfJAV70qDglTfERBGul25uAQDglyiNRdC8P3kn+RsoxlsNzdPNht7zVEcM2yFrbJ1FrAdtscO2TFrMcFu2B17YI/erXfvPXnPH6Vj3qhnmX2B9/oOBb2iYA==</latexit> gt \u2318trgL0( )\n<latexit sha1_base64=\"8/UihlMxlt0wyylqbLxBDRogGzg=\">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>T (\u00b7)\n<latexit sha1_base64=\"F+Pa0tnka1i85dgk3KuWQdNTg88=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit> z\n\u00b7<latexit sha1_base64=\"cAiOZblwH8iALsf/vkdYLcRxSgQ=\">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit> \u00b7 [\n[\n<latexit sha1_base64=\"UjUn3B7ufgCOmxVTlETrJ0C/vJY=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>\nx <latexit sha1_base64=\"7LjW4inxM3IqVcFm0MkAOftM7UI=\">AAAB83icbVDLSsNAFL2pr1pfVZduBovgKiRS1GXBjcsK9gFNKJPJpB06mYSZiVBCfsONC0Xc+jPu/BsnbRbaemDgcM693DMnSDlT2nG+rdrG5tb2Tn23sbd/cHjUPD7pqySThPZIwhM5DLCinAna00xzOkwlxXHA6SCY3ZX+4IlKxRLxqOcp9WM8ESxiBGsjeV6M9TSI8kExDsfNlmM7C6B14lakBRW64+aXFyYki6nQhGOlRq6Taj/HUjPCadHwMkVTTGZ4QkeGChxT5eeLzAW6MEqIokSaJzRaqL83chwrNY8DM1lmVKteKf7njTId3fo5E2mmqSDLQ1HGkU5QWQAKmaRE87khmEhmsiIyxRITbWpqmBLc1S+vk/6V7V7b7Yd2q2NXddThDM7hEly4gQ7cQxd6QCCFZ3iFNyuzXqx362M5WrOqnVP4A+vzB0Ivkcc=</latexit>\nWd <latexit sha1_base64=\"pIWFDq2Tt0ud+NvmF88Xp+emVao=\">AAAB6nicbVBNS8NAEJ34WetX1aOXxSKIh5BIUY8FLx4r2g9oY9lsN+3SzW7Y3Qgh9Cd48aCIV3+RN/+N2zYHbX0w8Hhvhpl5YcKZNp737aysrq1vbJa2yts7u3v7lYPDlpapIrRJJJeqE2JNORO0aZjhtJMoiuOQ03Y4vpn67SeqNJPiwWQJDWI8FCxiBBsr3WeP5/1K1XO9GdAy8QtShQKNfuWrN5AkjakwhGOtu76XmCDHyjDC6aTcSzVNMBnjIe1aKnBMdZDPTp2gU6sMUCSVLWHQTP09keNY6ywObWeMzUgvelPxP6+bmug6yJlIUkMFmS+KUo6MRNO/0YApSgzPLMFEMXsrIiOsMDE2nbINwV98eZm0Llz/0q3d1ap1t4ijBMdwAmfgwxXU4RYa0AQCQ3iGV3hzuPPivDsf89YVp5g5gj9wPn8A/fCNjg==</latexit> y\u21e4 <latexit sha1_base64=\"z65MLNYS9m9NIMg0IO7wQhtVhZc=\">AAAB8XicbVDLSsNAFL2pr1pfVZduBovgqiQi6rLgxmUF+8A2lMn0ph06mYSZiVBC/8KNC0Xc+jfu/BsnbRbaemDgcM69zLknSATXxnW/ndLa+sbmVnm7srO7t39QPTxq6zhVDFssFrHqBlSj4BJbhhuB3UQhjQKBnWBym/udJ1Sax/LBTBP0IzqSPOSMGis99iNqxkGYjWaDas2tu3OQVeIVpAYFmoPqV38YszRCaZigWvc8NzF+RpXhTOCs0k81JpRN6Ah7lkoaofazeeIZObPKkISxsk8aMld/b2Q00noaBXYyT6iXvVz8z+ulJrzxMy6T1KBki4/CVBATk/x8MuQKmRFTSyhT3GYlbEwVZcaWVLEleMsnr5L2Rd27ql/eX9Ya9aKOMpzAKZyDB9fQgDtoQgsYSHiGV3hztPPivDsfi9GSU+wcwx84nz/gTpEA</latexit> g <latexit sha1_base64=\"pcjqgRbl/D1PXi1iZ64D301adTY=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hE1GPBi8eK9gPaUDbbTbt0swm7E6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSQ7uf9as1z/XmIKvEL0gNCjT61a/eIGFZzBUySY3p+l6KQU41Cib5tNLLDE8pG9Mh71qqaMxNkM9PnZIzqwxIlGhbCslc/T2R09iYSRzazpjiyCx7M/E/r5thdBPkQqUZcsUWi6JMEkzI7G8yEJozlBNLKNPC3krYiGrK0KZTsSH4yy+vktaF61+5l/eXtbpbxFGGEziFc/DhGupwBw1oAoMhPMMrvDnSeXHenY9Fa8kpZo7hD5zPHz1kjbg=</latexit>\nWu\n<latexit sha1_base64=\"ot/yvaZQPa9zErjmSLBW76zU60o=\">AAACHnicbVDLSitBEO3xba5Xoy7dNAbBu7hhRnwtBV24cKFgVMiEoaZTExt7eobuGiEM8yVu/BU3LhQRXOnf2IlZ+DrQcPqcKqrqxLmSlnz/zRsbn5icmp6Zrf2Z+zu/UF9cOrNZYQS2RKYycxGDRSU1tkiSwovcIKSxwvP4an/gn1+jsTLTp9TPsZNCT8tECiAnRfWtXlRSxf+HSBARDzXECqIeD1OgSwGqPKoif334i5MyPEBFUP2L6g2/6Q/Bf5JgRBpshOOo/hJ2M1GkqEkosLYd+Dl1SjAkhcKqFhYWcxBX0MO2oxpStJ1yeF7F15zS5Ulm3NPEh+rnjhJSa/tp7CoHe9rv3kD8zWsXlOx2SqnzglCLj0FJoThlfJAV70qDglTfERBGul25uAQDglyiNRdC8P3kn+RsoxlsNzdPNht7zVEcM2yFrbJ1FrAdtscO2TFrMcFu2B17YI/erXfvPXnPH6Vj3qhnmX2B9/oOBb2iYA==</latexit> gt \u2318trgL0( )\n<latexit sha1_base64=\"8/UihlMxlt0wyylqbLxBDRogGzg=\">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>T (\u00b7)\n<latexit sha1_base64=\"F+Pa0tnka1i85dgk3KuWQdNTg88=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit> z\n4x3 3x14x14x13x43x1 <latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )\n<latexit sha1_base64=\"NfIpreFiwZKqcEZ9f+kK1kWNKNc=\">AAACRHicdVDLSgMxFM3Ud31VXboJFkFBhowtWheC4EZwo2CrMDMOmTTThmYeJBmhhPk4N36AO7/AjQtF3IrpC1T0QOBw7r3n3pww40wqhJ6s0tT0zOzc/EJ5cWl5ZbWytt6SaS4IbZKUp+ImxJJyltCmYorTm0xQHIecXoe900H9+o4KydLkSvUz6se4k7CIEayMFFRc7Q1NXNEJfY3s2pFBYw/ZdYSQg8YE1QqPG9M29mQeB7p37BS3+rzwWlQo6MVYdcNId4y209sdqYFTBJXqxBBODOHEEDo2GqIKxrgIKo9eOyV5TBNFOJbSdVCmfI2FYoTTouzlkmaY9HCHuoYmOKbS18P7C7htlDaMUmFeouBQ/T6hcSxlPw5N5+Be+bs2EP+qubmKGr5mSZYrmpDRoijnUKVwkChsM0GJ4n1DMBHM3ApJFwtMlMm9bEKY/BT+T1r7tnNg1y/r1RN7HMc82ARbYAc44BCcgDNwAZqAgHvwDF7Bm/VgvVjv1seotWSNZzbAD1ifX4sqrvw=</latexit>\nKX\nk=1\nkg(k)k1\n<latexit sha1_base64=\"fQbJT0bmzDSzA+yL/oTkkH6TgLg=\">AAAB8nicbVDLSgMxFL1TX7W+qi7dBIvgapgRUZcFNy5cVLAPmA4lk2ba0EwyJBmhDP0MNy4UcevXuPNvzLSz0NYDgcM595JzT5Rypo3nfTuVtfWNza3qdm1nd2//oH541NEyU4S2ieRS9SKsKWeCtg0znPZSRXEScdqNJreF332iSjMpHs00pWGCR4LFjGBjpaCfYDMmmOf3s0G94bneHGiV+CVpQInWoP7VH0qSJVQYwrHWge+lJsyxMoxwOqv1M01TTCZ4RANLBU6oDvN55Bk6s8oQxVLZJwyaq783cpxoPU0iO1lE1MteIf7nBZmJb8KciTQzVJDFR3HGkZGouB8NmaLE8KklmChmsyIyxgoTY1uq2RL85ZNXSefC9a/cy4fLRtMt66jCCZzCOfhwDU24gxa0gYCEZ3iFN8c4L86787EYrTjlzjH8gfP5A33vkVc=</latexit>L\n<latexit sha1_base64=\"8uB+wur6y1P5uh20XI3SQtWrgok=\">AAACMHicbVDLSgMxFM34rPVVdekmWJQWYZiRom4KBRcKuqhgH9Bph0yaaUMzmSHJCGWYT3Ljp+hGQRG3foXpY1FbDwTOPffeJOd4EaNSWda7sbS8srq2ntnIbm5t7+zm9vbrMowFJjUcslA0PSQJo5zUFFWMNCNBUOAx0vAGV6N+45EISUP+oIYRaQeox6lPMVJacnPXToBUHyOW3KUn5ZnCtQqN4qnD9FVd5Mg4cJNB+TbtJDx16kQo2OskhUFxUri2m8tbpjUGXCT2lOTBFFU39+J0QxwHhCvMkJQt24pUO0FCUcxImnViSSKEB6hHWppyFBDZTsaGU3islS70Q6EPV3Cszm4kKJByGHh6cuRIzvdG4n+9Vqz8y3ZCeRQrwvHkIT9mUIVwlB7sUkGwYkNNEBZU/xXiPhIIK51xVodgz1teJPUz0z43S/elfMWcxpEBh+AIFIANLkAF3IAqqAEMnsAr+ACfxrPxZnwZ35PRJWO6cwD+wPj5BWUFqb4=</latexit> L = L0(W ) + nX\nk=K\nkg(k)k1\nNon-zero\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( ) <latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )\n<latexit sha1_base64=\"oMVNr0TY+RuNTPo/mXm4PRr/4ks=\">AAAB/XicbVDLSsNAFJ3UV62v+Ni5GSyCq5JIUZdFNy4r2Ac0IUwmk3boJBNmboRair/ixoUibv0Pd/6N0zYLbT0wcDjnXO6dE2aCa3Ccb6u0srq2vlHerGxt7+zu2fsHbS1zRVmLSiFVNySaCZ6yFnAQrJspRpJQsE44vJn6nQemNJfpPYwy5iekn/KYUwJGCuwjT5hwRLBHIwnYY0ACCOyqU3NmwMvELUgVFWgG9pcXSZonLAUqiNY918nAHxMFnAo2qXi5ZhmhQ9JnPUNTkjDtj2fXT/CpUSIcS2VeCnim/p4Yk0TrURKaZEJgoBe9qfif18shvvLHPM1yYCmdL4pzgUHiaRU44opRECNDCFXc3IrpgChCwRRWMSW4i19eJu3zmntRq9/Vq43roo4yOkYn6Ay56BI10C1qohai6BE9o1f0Zj1ZL9a79TGPlqxi5hD9gfX5A/BClOg=</latexit>\n\u00b7 \u2318t <latexit sha1_base64=\"KMS8K7k8Fpgib6SgzOKf+ZCOSwY=\">AAAB/XicbVDLSsNAFJ34rPUVHzs3g0VwFRIp6rLgxmUF+4AmhMlk0g6dTMLMjVBL8VfcuFDErf/hzr9x2mahrQcGDuecy71zolxwDa77ba2srq1vbFa2qts7u3v79sFhW2eFoqxFM5GpbkQ0E1yyFnAQrJsrRtJIsE40vJn6nQemNM/kPYxyFqSkL3nCKQEjhfaxL0w4JtincQbYZ0BCCO2a67gz4GXilaSGSjRD+8uPM1qkTAIVROue5+YQjIkCTgWbVP1Cs5zQIemznqGSpEwH49n1E3xmlBgnmTJPAp6pvyfGJNV6lEYmmRIY6EVvKv7n9QpIroMxl3kBTNL5oqQQGDI8rQLHXDEKYmQIoYqbWzEdEEUomMKqpgRv8cvLpH3heJdO/a5eazhlHRV0gk7ROfLQFWqgW9RELUTRI3pGr+jNerJerHfrYx5dscqZI/QH1ucP6j6U1A==</latexit> \u00b7 \u2318t\n<latexit sha1_base64=\"mgmKsxA3LM5d6Fpw0qC9bgLLcBQ=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx033vi/XLFrbpzkFXi5aQCORr98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVe+yWrurVeokj6MIJ3AK5+DBFdThFhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifP1SZjbw=</latexit> \u21e0\n<latexit sha1_base64=\"2ib/1NcO2EZySJ8nP9FjmEGX2Ic=\">AAAB6nicbVBNSwMxEJ2tX7V+VT16CRaheCi7UtRjwYvHivYD2rVk02wbmk2WJCssS3+CFw+KePUXefPfmLZ70NYHA4/3ZpiZF8ScaeO6305hbX1jc6u4XdrZ3ds/KB8etbVMFKEtIrlU3QBrypmgLcMMp91YURwFnHaCyc3M7zxRpZkUDyaNqR/hkWAhI9hY6T59PB+UK27NnQOtEi8nFcjRHJS/+kNJkogKQzjWuue5sfEzrAwjnE5L/UTTGJMJHtGepQJHVPvZ/NQpOrPKEIVS2RIGzdXfExmOtE6jwHZG2Iz1sjcT//N6iQmv/YyJODFUkMWiMOHISDT7Gw2ZosTw1BJMFLO3IjLGChNj0ynZELzll1dJ+6LmXdbqd/VKo5rHUYQTOIUqeHAFDbiFJrSAwAie4RXeHO68OO/Ox6K14OQzx/AHzucP/CKNiA==</latexit> y\u21e4\nInput & Output\n\u00b7\u00b7\n<latexit sha1_base64=\"UjUn3B7ufgCOmxVTlETrJ0C/vJY=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>\nx <latexit sha1_base64=\"7LjW4inxM3IqVcFm0MkAOftM7UI=\">AAAB83icbVDLSsNAFL2pr1pfVZduBovgKiRS1GXBjcsK9gFNKJPJpB06mYSZiVBCfsONC0Xc+jPu/BsnbRbaemDgcM693DMnSDlT2nG+rdrG5tb2Tn23sbd/cHjUPD7pqySThPZIwhM5DLCinAna00xzOkwlxXHA6SCY3ZX+4IlKxRLxqOcp9WM8ESxiBGsjeV6M9TSI8kExDsfNlmM7C6B14lakBRW64+aXFyYki6nQhGOlRq6Taj/HUjPCadHwMkVTTGZ4QkeGChxT5eeLzAW6MEqIokSaJzRaqL83chwrNY8DM1lmVKteKf7njTId3fo5E2mmqSDLQ1HGkU5QWQAKmaRE87khmEhmsiIyxRITbWpqmBLc1S+vk/6V7V7b7Yd2q2NXddThDM7hEly4gQ7cQxd6QCCFZ3iFNyuzXqx362M5WrOqnVP4A+vzB0Ivkcc=</latexit>\nWd <latexit sha1_base64=\"pcjqgRbl/D1PXi1iZ64D301adTY=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0hE1GPBi8eK9gPaUDbbTbt0swm7E6GE/gQvHhTx6i/y5r9x2+agrQ8GHu/NMDMvTKUw6HnfTmltfWNzq7xd2dnd2z+oHh61TJJpxpsskYnuhNRwKRRvokDJO6nmNA4lb4fj25nffuLaiEQ94iTlQUyHSkSCUbTSQ7uf9as1z/XmIKvEL0gNCjT61a/eIGFZzBUySY3p+l6KQU41Cib5tNLLDE8pG9Mh71qqaMxNkM9PnZIzqwxIlGhbCslc/T2R09iYSRzazpjiyCx7M/E/r5thdBPkQqUZcsUWi6JMEkzI7G8yEJozlBNLKNPC3krYiGrK0KZTsSH4yy+vktaF61+5l/eXtbpbxFGGEziFc/DhGupwBw1oAoMhPMMrvDnSeXHenY9Fa8kpZo7hD5zPHz1kjbg=</latexit> Wu\n<latexit sha1_base64=\"ot/yvaZQPa9zErjmSLBW76zU60o=\">AAACHnicbVDLSitBEO3xba5Xoy7dNAbBu7hhRnwtBV24cKFgVMiEoaZTExt7eobuGiEM8yVu/BU3LhQRXOnf2IlZ+DrQcPqcKqrqxLmSlnz/zRsbn5icmp6Zrf2Z+zu/UF9cOrNZYQS2RKYycxGDRSU1tkiSwovcIKSxwvP4an/gn1+jsTLTp9TPsZNCT8tECiAnRfWtXlRSxf+HSBARDzXECqIeD1OgSwGqPKoif334i5MyPEBFUP2L6g2/6Q/Bf5JgRBpshOOo/hJ2M1GkqEkosLYd+Dl1SjAkhcKqFhYWcxBX0MO2oxpStJ1yeF7F15zS5Ulm3NPEh+rnjhJSa/tp7CoHe9rv3kD8zWsXlOx2SqnzglCLj0FJoThlfJAV70qDglTfERBGul25uAQDglyiNRdC8P3kn+RsoxlsNzdPNht7zVEcM2yFrbJ1FrAdtscO2TFrMcFu2B17YI/erXfvPXnPH6Vj3qhnmX2B9/oOBb2iYA==</latexit> gt \u2318trgL0( )\n<latexit sha1_base64=\"8/UihlMxlt0wyylqbLxBDRogGzg=\">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>T (\u00b7)\n<latexit sha1_base64=\"F+Pa0tnka1i85dgk3KuWQdNTg88=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit> z\nDrop after training\nZero\nNon-zero\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( ) <latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )\n<latexit sha1_base64=\"mgmKsxA3LM5d6Fpw0qC9bgLLcBQ=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx033vi/XLFrbpzkFXi5aQCORr98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVe+yWrurVeokj6MIJ3AK5+DBFdThFhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifP1SZjbw=</latexit> \u21e0\n<latexit sha1_base64=\"2ib/1NcO2EZySJ8nP9FjmEGX2Ic=\">AAAB6nicbVBNSwMxEJ2tX7V+VT16CRaheCi7UtRjwYvHivYD2rVk02wbmk2WJCssS3+CFw+KePUXefPfmLZ70NYHA4/3ZpiZF8ScaeO6305hbX1jc6u4XdrZ3ds/KB8etbVMFKEtIrlU3QBrypmgLcMMp91YURwFnHaCyc3M7zxRpZkUDyaNqR/hkWAhI9hY6T59PB+UK27NnQOtEi8nFcjRHJS/+kNJkogKQzjWuue5sfEzrAwjnE5L/UTTGJMJHtGepQJHVPvZ/NQpOrPKEIVS2RIGzdXfExmOtE6jwHZG2Iz1sjcT//N6iQmv/YyJODFUkMWiMOHISDT7Gw2ZosTw1BJMFLO3IjLGChNj0ynZELzll1dJ+6LmXdbqd/VKo5rHUYQTOIUqeHAFDbiFJrSAwAie4RXeHO68OO/Ox6K14OQzx/AHzucP/CKNiA==</latexit> y\u21e4\nInput & Output\nDrop after training\nZero\nNon-zero\nInput & Output\nLoRA\nSoRA\nMulti-head Attention\nAdd & LayerNorm\nAdd & LayerNorm\nFeed Forward Net\nQ K V\nW W W\nHidden States\nPrefix\nLoRA LoRA\nPrefix\nTransformer Layer \u00d7 L\n+\n\u00b7 <latexit sha1_base64=\"cAiOZblwH8iALsf/vkdYLcRxSgQ=\">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit> \u00b7 [\n[\n<latexit sha1_base64=\"UjUn3B7ufgCOmxVTlETrJ0C/vJY=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit> x\n<latexit sha1_base64=\"8/UihlMxlt0wyylqbLxBDRogGzg=\">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>T (\u00b7)\n<latexit sha1_base64=\"F+Pa0tnka1i85dgk3KuWQdNTg88=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit>\nz\n<latexit sha1_base64=\"NfIpreFiwZKqcEZ9f+kK1kWNKNc=\">AAACRHicdVDLSgMxFM3Ud31VXboJFkFBhowtWheC4EZwo2CrMDMOmTTThmYeJBmhhPk4N36AO7/AjQtF3IrpC1T0QOBw7r3n3pww40wqhJ6s0tT0zOzc/EJ5cWl5ZbWytt6SaS4IbZKUp+ImxJJyltCmYorTm0xQHIecXoe900H9+o4KydLkSvUz6se4k7CIEayMFFRc7Q1NXNEJfY3s2pFBYw/ZdYSQg8YE1QqPG9M29mQeB7p37BS3+rzwWlQo6MVYdcNId4y209sdqYFTBJXqxBBODOHEEDo2GqIKxrgIKo9eOyV5TBNFOJbSdVCmfI2FYoTTouzlkmaY9HCHuoYmOKbS18P7C7htlDaMUmFeouBQ/T6hcSxlPw5N5+Be+bs2EP+qubmKGr5mSZYrmpDRoijnUKVwkChsM0GJ4n1DMBHM3ApJFwtMlMm9bEKY/BT+T1r7tnNg1y/r1RN7HMc82ARbYAc44BCcgDNwAZqAgHvwDF7Bm/VgvVjv1seotWSNZzbAD1ifX4sqrvw=</latexit>\nKX\nk=1\nkg(k)k1 <latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>L0( )\n<latexit sha1_base64=\"mgmKsxA3LM5d6Fpw0qC9bgLLcBQ=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx033vi/XLFrbpzkFXi5aQCORr98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVe+yWrurVeokj6MIJ3AK5+DBFdThFhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifP1SZjbw=</latexit>\n\u21e0\nDrop after training Zero\nNon-zero Input & Output\nProximal Gradient Descent\nGating Downprojection Upprojection\n<latexit sha1_base64=\"SQNLzP+oVKTBulPSpmKN+TfSpd4=\">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJM21oJjMkd4Qy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1gNOE+xEdKREKRtFKj/2I4jgIs/FsUK64NXcBsk68nFQgR3NQ/uoPY5ZGXCGT1Jie5yboZ1SjYJLPSv3U8ISyCR3xnqWKRtz42SLxjFxYZUjCWNunkCzU3xsZjYyZRoGdnCc0q95c/M/rpRje+JlQSYpcseVHYSoJxmR+PhkKzRnKqSWUaWGzEjammjK0JZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMEzvMKbY5wX5935WI4WnHznFP7A+fwB4AWQ+w==</latexit>\nh <latexit sha1_base64=\"HBl2VMqsA9H1oNFDXe3UKmJfeFw=\">AAAB8nicbVDLSgMxFL1TX7W+qi7dBIvYVZmRoi4LblxWsA+YDiWTZtrQTDIkGaEM/Qw3LhRx69e482/MtLPQ1gOBwzn3knNPmHCmjet+O6WNza3tnfJuZW//4PCoenzS1TJVhHaI5FL1Q6wpZ4J2DDOc9hNFcRxy2gund7nfe6JKMykezSyhQYzHgkWMYGMlfxBjMwmjbDK/HFZrbsNdAK0TryA1KNAeVr8GI0nSmApDONba99zEBBlWhhFO55VBqmmCyRSPqW+pwDHVQbaIPEcXVhmhSCr7hEEL9fdGhmOtZ3FoJ/OIetXLxf88PzXRbZAxkaSGCrL8KEo5MhLl96MRU5QYPrMEE8VsVkQmWGFibEsVW4K3evI66V41vOtG86FZa9WLOspwBudQBw9uoAX30IYOEJDwDK/w5hjnxXl3PpajJafYOYU/cD5/AERUkSw=</latexit> h0 <latexit sha1_base64=\"nbqJXXGN5BTEUvsIFXww4ZYe/LA=\">AAAB83icbVDLSgMxFL3xWeur6tJNsAgupMxIUZcFNy4r2Ad0hpLJZNrQTGZIMkIZ+htuXCji1p9x59+YaWehrQcCh3Pu5Z6cIBVcG8f5RmvrG5tb25Wd6u7e/sFh7ei4q5NMUdahiUhUPyCaCS5Zx3AjWD9VjMSBYL1gclf4vSemNE/ko5mmzI/JSPKIU2Ks5HkxMeMgynuzYTis1Z2GMwdeJW5J6lCiPax9eWFCs5hJQwXReuA6qfFzogyngs2qXqZZSuiEjNjAUklipv18nnmGz60S4ihR9kmD5+rvjZzEWk/jwE4WGfWyV4j/eYPMRLd+zmWaGSbp4lCUCWwSXBSAQ64YNWJqCaGK26yYjoki1NiaqrYEd/nLq6R71XCvG82HZr11WdZRgVM4gwtw4QZacA9t6ACFFJ7hFd5Qhl7QO/pYjK6hcucE/gB9/gBBlZHF</latexit> Wd <latexit sha1_base64=\"/zBQzt27borSCLHZJETVK/L3JjQ=\">AAAB83icbVDLSsNAFL2pr1pfVZduBovgQkoipbosuHFZwT6gCWUynbRDJ5MwD6GE/oYbF4q49Wfc+TdO2iy09cDA4Zx7uWdOmHKmtOt+O6WNza3tnfJuZW//4PCoenzSVYmRhHZIwhPZD7GinAna0Uxz2k8lxXHIaS+c3uV+74lKxRLxqGcpDWI8FixiBGsr+X6M9SSMst58aIbVmlt3F0DrxCtIDQq0h9Uvf5QQE1OhCcdKDTw31UGGpWaE03nFN4qmmEzxmA4sFTimKsgWmefowiojFCXSPqHRQv29keFYqVkc2sk8o1r1cvE/b2B0dBtkTKRGU0GWhyLDkU5QXgAaMUmJ5jNLMJHMZkVkgiUm2tZUsSV4q19eJ93rutesNx4atdZVUUcZzuAcLsGDG2jBPbShAwRSeIZXeHOM8+K8Ox/L0ZJT7JzCHzifP1tZkdY=</latexit> Wu <latexit sha1_base64=\"QxHJIYnglv0qz/Wz78YlSTh0Gbg=\">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit> g\n<latexit sha1_base64=\"dNEdt8VzjdxuWRV2qtIdvhVZt+I=\">AAACMnicbZBNS+RAEIY7fq2Oro569NI4LOhhh0REPQp6WMGDgqPCZAiVnsrY2OmE7srCEPKbvPhLBA/rQRGv/gh7xhG/tqDh4X2r6Ko3zpW05Pv/vLHxicmpH9Mztdm5n/ML9cWlU5sVRmBLZCoz5zFYVFJjiyQpPM8NQhorPIsv9wb+2V80Vmb6hPo5dlLoaZlIAeSkqH4QpkAXcVL2qqikiv8OkSAiHmqIFUTlu13xIQtQ5WEV+WtvTriPiqBaj+oNv+kPi3+HYAQNNqqjqH4TdjNRpKhJKLC2Hfg5dUowJIXCqhYWFnMQl9DDtkMNKdpOOTy54r+c0uVJZtzTxIfqx4kSUmv7aew6B3var95A/J/XLijZ6ZRS5wWhFq8fJYXilPFBfrwrDQpSfQcgjHS7cnEBBgS5lGsuhODryd/hdKMZbDU3jzcbu81RHNNsha2yNRawbbbL/rAj1mKCXbFbds8evGvvznv0nl5bx7zRzDL7VN7zC+Blq6w=</latexit> gt \u2318trgL0( )\nUpdate <latexit sha1_base64=\"QxHJIYnglv0qz/Wz78YlSTh0Gbg=\">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit> g\n<latexit sha1_base64=\"cAiOZblwH8iALsf/vkdYLcRxSgQ=\">AAAB7XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeiF48V7Ae0oWw2m3btZjfsboQS+h+8eFDEq//Hm//GTZuDtj4YeLw3w8y8IOFMG9f9dkpr6xubW+Xtys7u3v5B9fCoo2WqCG0TyaXqBVhTzgRtG2Y47SWK4jjgtBtMbnO/+0SVZlI8mGlC/RiPBIsYwcZKnYEMpakMqzW37s6BVolXkBoUaA2rX4NQkjSmwhCOte57bmL8DCvDCKezyiDVNMFkgke0b6nAMdV+Nr92hs6sEqJIKlvCoLn6eyLDsdbTOLCdMTZjvezl4n9ePzXRtZ8xkaSGCrJYFKUcGYny11HIFCWGTy3BRDF7KyJjrDAxNqA8BG/55VXSuah7l/XGfaPWvCniKMMJnMI5eHAFTbiDFrSBwCM8wyu8OdJ5cd6dj0VrySlmjuEPnM8fJIGO2w==</latexit>\n<latexit sha1_base64=\"UjUn3B7ufgCOmxVTlETrJ0C/vJY=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFiG/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB+iOREQ==</latexit>\n<latexit sha1_base64=\"8/UihlMxlt0wyylqbLxBDRogGzg=\">AAAB+3icbVDLSsNAFJ34rPUV69LNYBHqJiRS1GXBjcsKfUETymQyaYdOZsLMRCyhv+LGhSJu/RF3/o2TNgttPTBwOOde7pkTpowq7brf1sbm1vbObmWvun9weHRsn9R6SmQSky4WTMhBiBRhlJOuppqRQSoJSkJG+uH0rvD7j0QqKnhHz1ISJGjMaUwx0kYa2TU/QXqCEcs784aPI6EvR3bdddwF4DrxSlIHJdoj+8uPBM4SwjVmSKmh56Y6yJHUFDMyr/qZIinCUzQmQ0M5SogK8kX2ObwwSgRjIc3jGi7U3xs5SpSaJaGZLJKqVa8Q//OGmY5vg5zyNNOE4+WhOGNQC1gUASMqCdZsZgjCkpqsEE+QRFibuqqmBG/1y+ukd+V4107zoVlvOWUdFXAGzkEDeOAGtMA9aIMuwOAJPINX8GbNrRfr3fpYjm5Y5c4p+APr8we3lpQt</latexit>\n<latexit sha1_base64=\"F+Pa0tnka1i85dgk3KuWQdNTg88=\">AAAB8XicbVDLSgMxFL2pr1pfVZdugkVwNcxIUZcFNy4r2Ae2Q8mkmTY0kxmSjFCH/oUbF4q49W/c+Tdm2llo64HA4Zx7ybknSATXxnW/UWltfWNzq7xd2dnd2z+oHh61dZwqylo0FrHqBkQzwSVrGW4E6yaKkSgQrBNMbnK/88iU5rG8N9OE+REZSR5ySoyVHvoRMeMgzJ5mg2rNddw58CrxClKDAs1B9as/jGkaMWmoIFr3PDcxfkaU4VSwWaWfapYQOiEj1rNUkohpP5snnuEzqwxxGCv7pMFz9fdGRiKtp1FgJ/OEetnLxf+8XmrCaz/jMkkNk3TxUZgKbGKcn4+HXDFqxNQSQhW3WTEdE0WosSVVbAne8smrpH3heJdO/a5eazhFHWU4gVM4Bw+uoAG30IQWUJDwDK/whjR6Qe/oYzFaQsXOMfwB+vwB/S2REw==</latexit>\n<latexit sha1_base64=\"NfIpreFiwZKqcEZ9f+kK1kWNKNc=\">AAACRHicdVDLSgMxFM3Ud31VXboJFkFBhowtWheC4EZwo2CrMDMOmTTThmYeJBmhhPk4N36AO7/AjQtF3IrpC1T0QOBw7r3n3pww40wqhJ6s0tT0zOzc/EJ5cWl5ZbWytt6SaS4IbZKUp+ImxJJyltCmYorTm0xQHIecXoe900H9+o4KydLkSvUz6se4k7CIEayMFFRc7Q1NXNEJfY3s2pFBYw/ZdYSQg8YE1QqPG9M29mQeB7p37BS3+rzwWlQo6MVYdcNId4y209sdqYFTBJXqxBBODOHEEDo2GqIKxrgIKo9eOyV5TBNFOJbSdVCmfI2FYoTTouzlkmaY9HCHuoYmOKbS18P7C7htlDaMUmFeouBQ/T6hcSxlPw5N5+Be+bs2EP+qubmKGr5mSZYrmpDRoijnUKVwkChsM0GJ4n1DMBHM3ApJFwtMlMm9bEKY/BT+T1r7tnNg1y/r1RN7HMc82ARbYAc44BCcgDNwAZqAgHvwDF7Bm/VgvVjv1seotWSNZzbAD1ifX4sqrvw=</latexit>\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>\n<latexit sha1_base64=\"sdBR52GDjKcMlZo0a/JnSibCcuw=\">AAACB3icdVDLSgMxFM3UV62vUZeCBItQN0PGFq27gi5cuKhgH9ApJZNm2tDMgyQjlGF2bvwVNy4UcesvuPNvzEwrqOiBwMk593LvPW7EmVQIfRiFhcWl5ZXiamltfWNzy9zeacswFoS2SMhD0XWxpJwFtKWY4rQbCYp9l9OOOznP/M4tFZKFwY2aRrTv41HAPEaw0tLA3Hd8rMYE8+QqHaBK/nO9xLmgXOH0aGCWkVU906hDZNUQQjaaE1SFtoVylMEczYH57gxDEvs0UIRjKXs2ilQ/wUIxwmlacmJJI0wmeER7mgbYp7Kf5Hek8FArQ+iFQr9AwVz93pFgX8qp7+rKbE/528vEv7xerLx6P2FBFCsakNkgL+ZQhTALBQ6ZoETxqSaYCKZ3hWSMBSZKR1fSIXxdCv8n7WPLPrFq17Vyw5rHUQR74ABUgA1OQQNcgiZoAQLuwAN4As/GvfFovBivs9KCMe/ZBT9gvH0CHcuZbQ==</latexit>\n<latexit sha1_base64=\"mgmKsxA3LM5d6Fpw0qC9bgLLcBQ=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mkqMeCF48V7Qe0oWy2k3bpZhN2N2IJ/QlePCji1V/kzX/jts1BWx8MPN6bYWZekAiujet+O4W19Y3NreJ2aWd3b/+gfHjU0nGqGDZZLGLVCahGwSU2DTcCO4lCGgUC28H4Zua3H1FpHssHM0nQj+hQ8pAzaqx033vi/XLFrbpzkFXi5aQCORr98ldvELM0QmmYoFp3PTcxfkaV4UzgtNRLNSaUjekQu5ZKGqH2s/mpU3JmlQEJY2VLGjJXf09kNNJ6EgW2M6JmpJe9mfif101NeO1nXCapQckWi8JUEBOT2d9kwBUyIyaWUKa4vZWwEVWUGZtOyYbgLb+8SloXVe+yWrurVeokj6MIJ3AK5+DBFdThFhrQBAZDeIZXeHOE8+K8Ox+L1oKTzxzDHzifP1SZjbw=</latexit>\n<latexit sha1_base64=\"SQNLzP+oVKTBulPSpmKN+TfSpd4=\">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJM21oJjMkd4Qy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIJHCoOt+O4WNza3tneJuaW//4PCofHzSNnGqGW+xWMa6G1DDpVC8hQIl7yaa0yiQvBNMbud+54lrI2L1gNOE+xEdKREKRtFKj/2I4jgIs/FsUK64NXcBsk68nFQgR3NQ/uoPY5ZGXCGT1Jie5yboZ1SjYJLPSv3U8ISyCR3xnqWKRtz42SLxjFxYZUjCWNunkCzU3xsZjYyZRoGdnCc0q95c/M/rpRje+JlQSYpcseVHYSoJxmR+PhkKzRnKqSWUaWGzEjammjK0JZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMEzvMKbY5wX5935WI4WnHznFP7A+fwB4AWQ+w==</latexit>\n<latexit sha1_base64=\"HBl2VMqsA9H1oNFDXe3UKmJfeFw=\">AAAB8nicbVDLSgMxFL1TX7W+qi7dBIvYVZmRoi4LblxWsA+YDiWTZtrQTDIkGaEM/Qw3LhRx69e482/MtLPQ1gOBwzn3knNPmHCmjet+O6WNza3tnfJuZW//4PCoenzS1TJVhHaI5FL1Q6wpZ4J2DDOc9hNFcRxy2gund7nfe6JKMykezSyhQYzHgkWMYGMlfxBjMwmjbDK/HFZrbsNdAK0TryA1KNAeVr8GI0nSmApDONba99zEBBlWhhFO55VBqmmCyRSPqW+pwDHVQbaIPEcXVhmhSCr7hEEL9fdGhmOtZ3FoJ/OIetXLxf88PzXRbZAxkaSGCrL8KEo5MhLl96MRU5QYPrMEE8VsVkQmWGFibEsVW4K3evI66V41vOtG86FZa9WLOspwBudQBw9uoAX30IYOEJDwDK/w5hjnxXl3PpajJafYOYU/cD5/AERUkSw=</latexit>\n<latexit sha1_base64=\"nbqJXXGN5BTEUvsIFXww4ZYe/LA=\">AAAB83icbVDLSgMxFL3xWeur6tJNsAgupMxIUZcFNy4r2Ad0hpLJZNrQTGZIMkIZ+htuXCji1p9x59+YaWehrQcCh3Pu5Z6cIBVcG8f5RmvrG5tb25Wd6u7e/sFh7ei4q5NMUdahiUhUPyCaCS5Zx3AjWD9VjMSBYL1gclf4vSemNE/ko5mmzI/JSPKIU2Ks5HkxMeMgynuzYTis1Z2GMwdeJW5J6lCiPax9eWFCs5hJQwXReuA6qfFzogyngs2qXqZZSuiEjNjAUklipv18nnmGz60S4ihR9kmD5+rvjZzEWk/jwE4WGfWyV4j/eYPMRLd+zmWaGSbp4lCUCWwSXBSAQ64YNWJqCaGK26yYjoki1NiaqrYEd/nLq6R71XCvG82HZr11WdZRgVM4gwtw4QZacA9t6ACFFJ7hFd5Qhl7QO/pYjK6hcucE/gB9/gBBlZHF</latexit>\n<latexit sha1_base64=\"/zBQzt27borSCLHZJETVK/L3JjQ=\">AAAB83icbVDLSsNAFL2pr1pfVZduBovgQkoipbosuHFZwT6gCWUynbRDJ5MwD6GE/oYbF4q49Wfc+TdO2iy09cDA4Zx7uWdOmHKmtOt+O6WNza3tnfJuZW//4PCoenzSVYmRhHZIwhPZD7GinAna0Uxz2k8lxXHIaS+c3uV+74lKxRLxqGcpDWI8FixiBGsr+X6M9SSMst58aIbVmlt3F0DrxCtIDQq0h9Uvf5QQE1OhCcdKDTw31UGGpWaE03nFN4qmmEzxmA4sFTimKsgWmefowiojFCXSPqHRQv29keFYqVkc2sk8o1r1cvE/b2B0dBtkTKRGU0GWhyLDkU5QXgAaMUmJ5jNLMJHMZkVkgiUm2tZUsSV4q19eJ93rutesNx4atdZVUUcZzuAcLsGDG2jBPbShAwRSeIZXeHOM8+K8Ox/L0ZJT7JzCHzifP1tZkdY=</latexit>\n<latexit sha1_base64=\"QxHJIYnglv0qz/Wz78YlSTh0Gbg=\">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit>\n<latexit sha1_base64=\"dNEdt8VzjdxuWRV2qtIdvhVZt+I=\">AAACMnicbZBNS+RAEIY7fq2Oro569NI4LOhhh0REPQp6WMGDgqPCZAiVnsrY2OmE7srCEPKbvPhLBA/rQRGv/gh7xhG/tqDh4X2r6Ko3zpW05Pv/vLHxicmpH9Mztdm5n/ML9cWlU5sVRmBLZCoz5zFYVFJjiyQpPM8NQhorPIsv9wb+2V80Vmb6hPo5dlLoaZlIAeSkqH4QpkAXcVL2qqikiv8OkSAiHmqIFUTlu13xIQtQ5WEV+WtvTriPiqBaj+oNv+kPi3+HYAQNNqqjqH4TdjNRpKhJKLC2Hfg5dUowJIXCqhYWFnMQl9DDtkMNKdpOOTy54r+c0uVJZtzTxIfqx4kSUmv7aew6B3var95A/J/XLijZ6ZRS5wWhFq8fJYXilPFBfrwrDQpSfQcgjHS7cnEBBgS5lGsuhODryd/hdKMZbDU3jzcbu81RHNNsha2yNRawbbbL/rAj1mKCXbFbds8evGvvznv0nl5bx7zRzDL7VN7zC+Blq6w=</latexit>\n<latexit sha1_base64=\"QxHJIYnglv0qz/Wz78YlSTh0Gbg=\">AAAB8XicbVDLSgMxFL1TX7W+qi7dBIvQVZmRoi4LblxWsA9sh5JJ77ShmcyQZIQy9C/cuFDErX/jzr8xbWehrQcCh3PuJeeeIBFcG9f9dgobm1vbO8Xd0t7+weFR+fikreNUMWyxWMSqG1CNgktsGW4EdhOFNAoEdoLJ7dzvPKHSPJYPZpqgH9GR5CFn1FjpsR9RMw7CbDQblCtuzV2ArBMvJxXI0RyUv/rDmKURSsME1brnuYnxM6oMZwJnpX6qMaFsQkfYs1TSCLWfLRLPyIVVhiSMlX3SkIX6eyOjkdbTKLCT84R61ZuL/3m91IQ3fsZlkhqUbPlRmApiYjI/nwy5QmbE1BLKFLdZCRtTRZmxJZVsCd7qyeukfVnzrmr1+3qlUc3rKMIZnEMVPLiGBtxBE1rAQMIzvMKbo50X5935WI4WnHznFP7A+fwB3oCQ+g==</latexit>\n<latexit sha1_base64=\"GfJz1eI/r4ne/tVxPM2b6z4LLBs=\">AAACRHicbVBJSwMxGM241rpVPXoJFkFFhowWl4NQ8CJ4UbBVmBmHTJppQzMLSUYoYX6cF3+AN3+BFw+KeBXTdg5uDwKP920vL8w4kwqhJ2ticmp6ZrYyV51fWFxarq2stmWaC0JbJOWpuAmxpJwltKWY4vQmExTHIafXYf90WL++o0KyNLlSg4z6Me4mLGIEKyMFNVd7oyWu6Ia+Rvb+scHRLrIbCCEHlQTtFx43SzvYk3kc6P6JU9zq88JrU6GgF2PVCyPdNdpWf3usBk4R1OrIRiPAv8QpSR2UuAhqj14nJXlME0U4ltJ1UKZ8jYVihNOi6uWSZpj0cZe6hiY4ptLXI/8F3DRKB0apMC9RcKR+n9A4lnIQh6Zz6Ff+rg3F/2purqIjX7MkyxVNyPhQlHOoUjhMFHaYoETxgSGYCGa8QtLDAhNlcq+aEJzfX/5L2nu2c2A3Lhv15k4ZRwWsgw2wBRxwCJrgDFyAFiDgHjyDV/BmPVgv1rv1MW6dsMqZNfAD1ucXMyyuvQ==</latexit>\nlead to from-scratch re-training. These limitations highlight the importance of upgrading LoRA with an adaptive-rank-selection plug-in.\nSeveral remedies have been proposed in recent years to enable the flexible tuning of LoRA rank. For example, rather than setting a fixed rank, Valipour et al. (Valipour et al., 2022) introduce DyLoRA in which a pre-defined discrete distribution pB(\u00b7) is cast over a range of rank choices. This approach is related to but different from nested dropout (Rippel et al., 2014), and can be regarded as optimizing a mixture model with LoRA modules of different ranks.\nNevertheless, tuning LoRA rank straightforwardly and deterministically appears to be a more attractive approach. To devise such an approach, we first gain a crucial hint from the connection between a matrix\u2019s rank and its singular value decomposition (SVD). Let us denote the tunable incremental weight matrix in LoRA by \u2206 := WuWd. We can then formulate its SVD as\n\u2206p\u00d7q = Up\u00d7p\u03a3p\u00d7qV \u22a4 q\u00d7q, (2)\nin which U and V are orthogonal respectively, and \u03a3 is a (rectangular) diagonal matrix with diagonal elements being the singular values of \u2206: \u03c3(\u2206) = {\u03c31 \u2265 \u03c32 \u2265 \u00b7 \u00b7 \u00b7 \u2265 \u03c3min{p,q} \u2265 0}. For notation convenience, we reshape the diagonal of \u03a3 into a column vector\ng := (\u03c31, \u03c32, \u00b7 \u00b7 \u00b7 , \u03c3min{p,q})\u22a4. (3)\nThen, letting d = min{p, q}, we can reformulate the LoRA forward propagation as\nz\u2190\u2212\u2206x = U\u00b7,1:d(g \u2299V\u22a4\u00b7,1:dx), (4)\nwhere \u2299 denotes element-wise dot product (Hadamard product). Note that rank(\u2206) = \u2225g\u22250 which is the \u21130 norm of g. Therefore, tuning the LoRA rank suffices to control the sparsity of the vector g. Zhang et al. precede along this SVD-based track w th their methodology named AdaLoRA (Zhang et al., 2023). In AdaLoRA, the elements in vector g are calibrated such that the number of nonzero entries is smaller than a pre-defined budget b. To be specific, they preserve only the entries with top-b importance score \u2013 which is their newly proposed metric of \"sensitivity\" heuristically constructed from weight-gradient product. The nonnegativity of g entries is reasonably dropped since a negative gi can be simply reduced to the positive case by flipping the sign of either ui or vi. Besides, they transform the constrained optimization problem into its unconstrained version by replacing the orthogonality conditions U\u22a4U = Ip and V\u22a4V = Iq with a regularization term\nR(U,V) = \u2225U\u22a4U\u2212 Ip\u22252F + \u2225V\u22a4V \u2212 Iq\u22252F . (5)\nIn spite of the effectiveness demonstrated through experiments, there are still two problems in AdaLoRA that demand rethinking of the methodology and wait for further improvements. First, the\nsparsity selection criterion in AdaLoRA is based on their newly proposed importance score relied on the moving average of weight-gradient product. Despite its effectiveness in empirical study, this criterion is largely heuristic, lacking theoretical motivation. Second, both the moving average operation of importance scores and the gradients of orthogonality regularization (5) add up to additional computation cost. Compared to AdaLoRA with the aforementioned limitations, our approach, SoRA, serves as an amelioration with highly simplified updating rules and is backed up by the theory of sparsity regularization and proximal gradient methods. Detailed methodology of SoRA will be elaborated in the next section."
        },
        {
            "heading": "3 Our Approach",
            "text": "The key idea of our approach, sparse low-rank adaptation (SoRA), is to dynamically adjust the intrinsic rank in the training process with a sparse gating unit trained by proximal gradient method. SoRA adopts the previously introduced framework of lowrank decomposition because of its widely validated effectiveness and parameter efficiency."
        },
        {
            "heading": "3.1 Sparse Low-rank Adaptation",
            "text": "Module Structure. At the start of building a SoRA module, we pre-define a maximum acceptable rank rmax according to practical or research concerns. Then, each SoRA module will inherit two matrices Wd \u2208 Rrmax\u00d7q and Wu \u2208 Rp\u00d7rmax from LoRA for down projection and up projection. The maximum rank rmax is set to be relatively large, but we will show in the subsequent paragraph how to tame it efficiently in a sparse sense. In fact, this is realized by injecting a gating unit g \u2208 Rrmax between the projection matrices, which imitates the formulation of SVD. The forward propagation of the SoRA module proceeds as follows:\nh down projection\u2190\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212Wdx; (6)\nh\u2032 gating\u2190\u2212\u2212\u2212 g \u2299 h; (7)\nz up projection\u2190\u2212\u2212\u2212\u2212\u2212\u2212\u2212Wuh\u2032; (8)\nor, more compactly,\nz\u2190Wu (g \u2299 (Wdx)) . (9)\nOptimization. We optimize down-projection and up-projection matrices with stochastic gradient\nmethods as in LoRA, while each gate g is updated in a different sparsity-promoting way:\ngt+1 \u2190 T\u03b7t\u00b7\u03bb(gt \u2212 \u03b7t\u2207gL0(\u2206t)), (10) in which L0(\u00b7) is the original loss function of the language model, \u2206 denotes the complete tunable parameter (including the gates), \u03b7t > 0 stands for the step-size at the t-th iteration, and \u03bb > 0 works as the regularization strength hyperparameter that promotes sparsity. Besides, T\u03b7t\u00b7\u03bb(\u00b7) in the above expression stands for the element-wise broadcast of the following soft-thresholding function:\nT\u03be(x) :=    x\u2212 \u03be, x > \u03be 0, \u2212\u03be < x \u2264 \u03be x+ \u03be, x \u2264 \u2212\u03be\n(11)\nwith \u03be = \u03b7t \u00b7 \u03bb being the threshold. In practice, the true gradient\u2207gL0 in (10) is approximated by its mini-batch stochastic counterpart.\nPost-pruning. When training is completed, we further prune the SoRA weights to drop the zeroedout ranks and reduce the module back to the LoRA form. To be specific, for the k-th SoRA module, let\nI(k) = { i \u2208 [1 : rmax] | g(k)i = 0 } (12)\nbe the index of zero entry in the k-th gating vector g(k). We drop the I(k)-th rows of down-projection W\n(k) d to obtain W\u0303 (k) d , the I(k)-th columns of upprojection W(k)u to obtain W\u0303 (k) u , as well as the I(k)-th entry of gate g(k) to obtain g\u0303(k). In this way, during inference time the k-th SoRA module will proceed as a usual LoRA module of rank rmax \u2212 |I(k)| with down-projection matrix W\u0303(k)d and upprojection matrix W\u0303(k)u \u00b7 diag(g\u0303(k))."
        },
        {
            "heading": "3.2 Interpretation and Comparison",
            "text": "Theoretical interpretation. The update rule (10) is in fact an application of the proximal gradient method for \u21131 loss (Chambolle et al., 1998; Beck and Teboulle, 2009). This follows immediately once we reformulate (10) equivalently as\ngt+1 \u2190 argmin g \u03b7t \u00b7 \u03bb\u2225g\u22251\n+ 1\n2 \u2225g \u2212 (gt \u2212 \u03b7t\u2207L0(gt))\u222522. (13)\nThe above equation (13) is exactly the proximal gradient update of the \u21131 regularized loss function\nL(\u2206) := L0(\u2206) + \u03bb K\u2211\nk=1\n\u2225g(k)\u22251, (14)\nwhere g(k) denotes the gate of the k-th SoRA module. This sparsity-promoting strategy dates back to LASSO estimator (Tibshirani, 1996) and compressed sensing (Candes et al., 2006), and is also adopted by many works within the realm of deep learning (Wen et al., 2016; Scardapane et al., 2017).\nComparision with AdaLoRA. Inspired alike by SVD decomposition, our approach SoRA differs from the preceding work AdaLoRA (Zhang et al., 2023) in the following sense. First, we do not apply the orthogonality regularization (5) used in AdaLoRA. The reason is that for rank selection purposes, sparsifying the gate g will be sufficient. Sticking to the original requirements of SVD can result in additional computation expenditure. Second, the moving averaged importance score in AdaLoRA works as an approximation to the change in loss when the corresponding entry is zeroed out, which is regarded as a heuristic measurement of parameter \"sensitivity\". However, a model\u2019s temporal sensitivity to a certain parameter cannot imply that the parameter should be retained, since there is no rigorous theory for doing so. By contrast, our rank selection based on soft-thresholding operation (10) proceeds in a much cleaner form and is soundly justified by the theory of proximal gradient iteration. As is explained earlier this section, the updating rule of SoRA module exactly follows the first principle of interpolation-complexity trade-off by minimizing a regularized loss objective (14).\nBeyond the formal simplicity and theoretical clearness is SoRA\u2019s superior experimental performance achieved with fewer parameters in less wallclock time, which will be presented in Section 4."
        },
        {
            "heading": "3.3 Scheduling \u03be to Explore Memorization and Generalization",
            "text": "We dub the threshold \u03be as a sparsity indicator. As the name implies, this parameter could directly determine the sparsity of SoRA in the training process. It can be set as a constant to heuristically control the sparsity according to the budget of parameters and expected performance. When dynamically changing \u03be in the adaptation process, SoRA serves as an effective tool to assess the memorization and generalization under a modelM and a dataset D. In other words, we can visually observe how many additional parameters are required to achieve a particular point of performance given the modelM and data D. We elaborate the fundamental idea as follows. The process starts by assigning a rel-\natively small value to \u03be. Consequently, the SoRA model is initially \"dense\" and is trained until convergence. Once this stage is achieved, we introduce a scheduler to incrementally increase the value of \u03be, thereby enhancing the model\u2019s sparsity. During this transition from a dense to a sparse model, it becomes possible to evaluate the model\u2019s memorization and generalization abilities by examining performance on the training and testing data respectively. The procedure is reported in Algorithm 1.\nThe process can be regarded as exploring the \u201ccompression loss\u201d in the scenario of model adaptation. Here, \u201ccompression loss\u201d refers to the reduction in model performance due to the increased sparsity, providing a measure of how well the model can retain its predictive power under constraints. Investigating this \u201ccompression loss\u201d is meaningful to understanding the behavior of model adaptation and can facilitate developing efficient, compact models that maintain high-performance levels.\nAlgorithm 1: Scheduling Algorithm of \u03be Input :M, \u03be0, \u03bemax, \u03b4\u03be,D Output :M\u2032 = {M0,M1, ...} \u03be \u2190 \u03be0; M\u2032 \u2190 \u2205; M = TrainUntilConvergence(M,D, \u03be); M\u2032.add(M); \u03be \u2190 \u03be + \u03be\u03bb; while \u03be \u2264 \u03bemax do\nfor epoch\u2190 1 to 5 do M = Update(M,D, \u03be); end M\u2032.add(M); \u03be \u2190 \u03be + \u03b4\u03be;\nend"
        },
        {
            "heading": "4 Experiments",
            "text": "Extensive experiments are carried out to assess the effectiveness of our approach comprehensively. Generally speaking, we explore two aspects in this section: (1) the performance and corresponding analysis as a normal parameter-efficient method; and (2) the investigation of memorization and generalization in virtue of the sparsity nature of SoRA."
        },
        {
            "heading": "4.1 Experimental Settings.",
            "text": "Baselines. Our baselines comprise full-parameter fine-tuning and other well-recognized parameterefficient methods, including Adapter (Houlsby\net al., 2019), BitFit (Zaken et al., 2021), LoRA (Hu et al., 2021) and AdaLoRA (Zhang et al., 2023). We omit the variants of the Adapter since we find that the performance between them is very close. We also do not include Prompt Tuning since we find that it takes considerably longer time for convergence and cannot yield non-trivial performance on our backbone models.\nDatasets For evaluation, we adaopt the GLUE benchmark (Wang et al.), including CoLA (Warstadt et al., 2019), SST-2 (Socher et al., 2013), MRPC (Dolan and Brockett, 2005), QQP (Wang et al.), STS-B (Wang et al.), MNLI (Williams et al., 2017), QNLI (Rajpurkar et al., 2016) and RTE (Dagan et al., 2005; Haim et al., 2006; Giampiccolo et al., 2007; Bentivogli et al., 2009). We mainly use DeBERTaV3-base (He et al., 2021) as the backbone model. Additionally, we also use RoBERTa-large (Liu et al., 2019) for analysis. Other experimental details are described in Appendix A."
        },
        {
            "heading": "4.2 Results",
            "text": "We first conduct an evaluation on GLUE benchmark, a widely recognized benchmark for natural language understanding. The experimental performance of SoRA, as well as other baseline methodologies, is recorded in Table 1. We reproduce these methods in our infrastructure and present the average results drawn from 5 random seeds. Our findings indicate that both AdaLoRA and SoRA consistently outperform the initial LoRA baseline. This underlines the validity of adaptive rank as a potent solution for enhanced model adaptation. Most notably, SoRA outshines all other baselines, particularly LoRA and AdaLoRA, despite utilizing fewer parameters. This lends credence to the argument that our proximal gradient method may constitute a more efficacious and essential approach to achieving adaptive rank. For instance, on the MRPC,\nSoRA achieved an accuracy of 91.98%, surpassing AdaLoRA by 1.76%. On average, SoRA surpassed LoRA and AdaLoRA on the GLUE benchmark by 0.98% and 0.52%, respectively, using 31.5% and 28.3% fewer parameters. To take a closer look at the effectiveness of adaptive rank, we conduct an experiment to compare LoRA and SoRA with different ranks in Table 2. The results affirm that SoRA\u2019s superiority is consistent across different budgets of parameters, that is, SoRA could outperform the LoRA baseline in all settings while utilizing over 30% fewer parameters."
        },
        {
            "heading": "4.3 Sparsifying Scheduler",
            "text": "We apply the sparsifying scheduler introduced in Section 3.3 by enlarging the sparse indicator \u03be (starting from 1e-4) of SoRA progressively in the adaptation process. As illustrated in Figure 2, we plot the memorization and generalization curve of RoBERTa-large (Liu et al., 2019) on MRPC, RTE, STS-B, CoLA, QNLI, and SST-2, where the memorization is gauged by the performance on the training set and the generalization is measured by the performance on the validation set. Intriguingly, we observe a robust \u201ccompression performance\" across almost all the datasets. Among these, SST-2 emerges as the most \"compressible\" task, where the model sustains over 99% performance even when restricted to 47,104 non-zero parameters. Remarkably, a mere 4,096 parameters can still conserve above 90% memorization and generalization capabilities. As the sparsifying process proceeds, the model encounters an \u201cinflection point\u201d on different data, after which the performance significantly plummets. This consistent phenomenon suggests that there exist some critical parameters that underpin the performance and are worth further investigation. Insight gleaned from the graph also indicates varying degrees of adaptation difficulty for the model across different datasets. For example, certain datasets, like CoLA, prompt an earlier\nand more pronounced decline in performance compared to others. Another finding is that the trend of memorization and generalization is consistent in the sparsifying procedure, which is aligned with intuition. Our observations also indicate a tendency for the parameters of intermediate and deep layers to maintain their density, while those of the shallow layers show a higher propensity towards sparsity."
        },
        {
            "heading": "4.4 Rank Analysis",
            "text": "An intuitive statement is that a single model suffers from varying extents of difficulty when being adapted to different downstream datasets. Concurrently, it is evident that not all parameters within the model carry equal importance\u2014some are more critical to performance than others. In this section, we visualize the final ranks after the training process\nconverges with SoRA on four datasets in Figure 3. Quite obviously, the trained parameter matrices on QQP are exceedingly dense and others do not exhibit such density, which echos the existence of different levels of difficulties. This phenomenon also suggests that leveraging the performance and the parameter budget does not have an invariable constant law, but needs specific considerations in different situations."
        },
        {
            "heading": "4.5 Applying SoRA to Different Weights",
            "text": "In our experiments in Table 1, we utilize LoRA, AdaLoRA, and SoRA on all weight matrices to enhance performance. It should be noted that the performance may fluctuate when parameterefficient fine-tuning is applied to various positions within the model, as evidenced by previous\nresearch (Zaken et al., 2021; Hu et al., 2022; Zhang et al., 2023). We carry out such ablation experiments with SoRA on three datasets to investigate the impact. Although SoRA is not a budget-oriented method, we adjust \u03bb to approximately equate the retained non-zero parameters. As reported in Table 3, in most cases, the application of SoRA to all weight matrices resulted in a considerable improvement in performance compared to the application of merely one or several types of weights, which suggest that uniformly applying SoRA to all weight matrices can serve as a beneficial strategy. And merely applying SoRA to WQ,K will experience considerable performance drop, which is aligned with LoRA."
        },
        {
            "heading": "4.6 Efficiency Analysis",
            "text": "We elaborate that SoRA is a theoretically clear and computation-efficient method in Section 3.2. To evaluate this, we measure the efficiency of SoRA and AdaLora in this section. We compute the clock time of average epoch of AdaLoRA and SoRA on six datasets with identical compute infrastructure\nand batch size. As shown in Table 4, SoRA takes about 30% less training time than AdaLoRA. In certain instances, such as the CoLA, QNLI, and RTE datasets, SoRA exhibits a significant edge in efficiency over its counterpart. Conversely, while SoRA consistently outpaces AdaLoRA on other datasets, the margin is not as wide. This discrepancy could be attributable to the different rank distributions of AdaLoRA and SoRA under varying tasks. Such distributions exert influence on the calculation of regularization in AdaLoRA."
        },
        {
            "heading": "5 Conclusion",
            "text": "Our work presents Sparse Low-Rank Adaptation (SoRA), an innovative method for parameterefficient fine-tuning large pre-trained language models. Upon the hypothesis that the adaptation process could be intrinsically sparse, we offer a dynamic alternative rank by introducing an optimizable gate with a proximal gradient method to\nregulate sparsity, thereby expanding the optimization space while enhancing parameter efficiency. The method is simple and theoretically supported with promising performance across various tasks. Utilizing SoRA as a tool, we propose a sparsifying scheduler to analyze the correlation between parameters and memorization and generalization.\nLimitations\nDespite the encouraging results demonstrated by SoRA, there are certain limitations in our current study that are worth acknowledging. This paper only evaluates the effectiveness of SoRA on traditional natural language processing tasks. However, recent studies demonstrate that parameterefficient methods could be applied to cross-modal or instruction-tuning scenarios. In those cases, how the sparsity of SoRA is displayed is still unknown and worth investigating. Our sparsifying scheduler could provide insights on the adaptation process of language models, but it is still challenging to rigorously explain the procedure and more efficiently to assess the difficulty of an adaptation process."
        },
        {
            "heading": "Acknowledgements",
            "text": "This work is supported by the National Key R&D Program of China (No. 2022ZD0119101), National Natural Science Foundation of China (No. 62236004), the Young Elite Scientists Sponsorship Program by CAST, and Institute Guo Qiang at Tsinghua University."
        },
        {
            "heading": "A Experimental Details",
            "text": "A.1 Datasets The GLUE benchmark, consisting of CoLA (Warstadt et al., 2019), SST-2 (Socher et al., 2013), MRPC (Dolan and Brockett, 2005), QQP (Wang et al.), STS-B (Wang et al.), MNLI (Williams et al., 2017), QNLI (Rajpurkar et al., 2016) and RTE (Dagan et al., 2005; Haim et al., 2006; Giampiccolo et al., 2007; Bentivogli et al., 2009), is used for natural language understanding. The details and the evaluation metric are reported in Table 5. We source each dataset from Huggingface Datasets (Lhoest et al., 2021) and utilize the full dataset for our experiments. For almost all experiments, we run 5 times using different random seeds and report the average results in order to ensure statistical significance.\nA.2 Implementation Details Regarding hyper-parameters, we set the learning rate to 8e-4. Based on the size and training convergence speed of the datasets, we set the number of epochs for CoLA, MRPC, and STS-B to 20, and the number of epochs for the remaining tasks to 10. As for RTE, we reference the settings of Friedman et al. 2021, which entail a learning rate of 1.2e-3 and an epoch count of 50. We set \u03bb to 0.1 in all our experiments, and select \u03be with a grid search in {1e-5, 5e-5, 1e-4}. When dealing with MRPC, RTE, and STS-B datasets, a common trick in certain studies is that using the best model checkpoint on the MNLI dataset could boost the performance. In our experiments, we do not use this strategy and instead opt for standard initializations across all models.\nThe Huggingface Transformers (Wolf et al., 2020) and PyTorch (Paszke et al., 2019) are utilized for all the experiments. We use NVIDIA GeForce RTX 3090 (maximum GPU memory=24268MB) and the application of SoRA with a batch size of 8 occupies 6110MB GPU memory on average.\nA.3 Optimization of Hyperparameters In this section, we delve into the optimization of hyperparameters. The results of different rmax are proved in Table 2 and we supplement the results of two other important hyperparameters, \u03be and \u03b7 in the Table 6 and Table 7. The performance of SoRA is highly stable with respect to different choices of \u03be and \u03b7. And for each fixed \u03be and \u03b7, the variance of performance is rather low. In general, we suggest setting \u03be to 1e-4 level and \u03b7 around 1e-1\u223c1e-3.\nA.4 Results with Standard Deviations The test results in Table 1 are shown in Table 8, and results in Table 2 are shown in Table 9."
        }
    ],
    "title": "Sparse Low-rank Adaptation of Pre-trained Language Models",
    "year": 2023
}