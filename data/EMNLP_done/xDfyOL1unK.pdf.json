{
    "abstractText": "We present NOVACOMET, an open commonsense knowledge model, that combines the best aspects of knowledge models and general task models. Compared to previous knowledge models, NOVACOMET allows open-format relations enabling direct application to reasoning tasks; compared to general task models like Flan-T5, NOVACOMET explicitly centers knowledge, enabling superior performance for commonsense reasoning. NOVACOMET leverages the knowledge of opaque proprietary models to create an open knowledge pipeline. First, knowledge is symbolically distilled into NOVATOMIC, a publiclyreleased1 discrete knowledge graph which can be audited, critiqued, and filtered. Next, we train NOVACOMET on NOVATOMIC by finetuning an open-source pretrained model. NOVACOMET uses an open-format training objective, replacing the fixed relation sets of past knowledge models, enabling arbitrary structures within the data to serve as inputs or outputs. The resulting generation model, optionally augmented with human annotation, matches or exceeds comparable open task models like FlanT5 on a range of commonsense generation tasks. NOVACOMET serves as a counterexample to the contemporary focus on instruction tuning only, demonstrating a distinct advantage to explicitly modeling commonsense knowledge as well.",
    "authors": [
        {
            "affiliations": [],
            "name": "Peter West"
        },
        {
            "affiliations": [],
            "name": "Ronan Le Bras"
        },
        {
            "affiliations": [],
            "name": "Taylor Sorensen"
        },
        {
            "affiliations": [],
            "name": "Bill Yuchen Lin"
        },
        {
            "affiliations": [],
            "name": "Liwei Jiang"
        },
        {
            "affiliations": [],
            "name": "Ximing Lu"
        },
        {
            "affiliations": [],
            "name": "Khyathi Chandu"
        },
        {
            "affiliations": [],
            "name": "Jack Hessel"
        },
        {
            "affiliations": [],
            "name": "Ashutosh Baheti"
        },
        {
            "affiliations": [],
            "name": "Chandra Bhagavatula"
        },
        {
            "affiliations": [],
            "name": "Yejin Choi"
        },
        {
            "affiliations": [],
            "name": "\u2020\u2021 \u2020Paul"
        },
        {
            "affiliations": [],
            "name": "G. Allen"
        }
    ],
    "id": "SP:f2fa4b3d9b201f175b0773913a2b57c630856424",
    "references": [
        {
            "authors": [
                "Chandra Bhagavatula",
                "Jena D. Hwang",
                "Doug Downey",
                "Ronan Le Bras",
                "Ximing Lu",
                "Keisuke Sakaguchi",
                "Swabha Swayamdipta",
                "Peter West",
                "Yejin Choi."
            ],
            "title": "I2D2: Inductive knowledge distillation with NeuroLogic and self-imitation",
            "venue": "Proceedings of the",
            "year": 2023
        },
        {
            "authors": [
                "Chandra Bhagavatula",
                "Ronan Le Bras",
                "Chaitanya Malaviya",
                "Keisuke Sakaguchi",
                "Ari Holtzman",
                "Hannah Rashkin",
                "Doug Downey",
                "Scott Yih",
                "Yejin Choi."
            ],
            "title": "Abductive commonsense reasoning",
            "venue": "ICLR.",
            "year": 2019
        },
        {
            "authors": [
                "Ning Bian",
                "Xianpei Han",
                "Le Sun",
                "Hongyu Lin",
                "Yaojie Lu",
                "Ben He."
            ],
            "title": "Chatgpt is a knowledgeable but inexperienced solver: An investigation of commonsense problem in large language models",
            "venue": "ArXiv, abs/2303.16421.",
            "year": 2023
        },
        {
            "authors": [
                "Yonatan Bisk",
                "Rowan Zellers",
                "Ronan Le Bras",
                "Jianfeng Gao",
                "Yejin Choi."
            ],
            "title": "PIQA: Reasoning about physical commonsense in natural language",
            "venue": "AAAI Conference on Artificial Intelligence.",
            "year": 2019
        },
        {
            "authors": [
                "Antoine Bosselut",
                "Hannah Rashkin",
                "Maarten Sap",
                "Chaitanya Malaviya",
                "Asli Celikyilmaz",
                "Yejin Choi."
            ],
            "title": "Comet: Commonsense transformers for automatic knowledge graph construction",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Christian Buck",
                "Kenneth Heafield",
                "Bas Van Ooyen."
            ],
            "title": "N-gram counts and language models from the common crawl",
            "venue": "LREC, volume 2, page 4. Citeseer.",
            "year": 2014
        },
        {
            "authors": [
                "Michael Chen",
                "Mike D\u2019Arcy",
                "Alisa Liu",
                "Jared Fernandez",
                "Doug Downey"
            ],
            "title": "Codah: An adversarially-authored question answering dataset for common sense",
            "venue": "In Proceedings of the 3rd Workshop on Evaluating Vector Space Representations",
            "year": 2019
        },
        {
            "authors": [
                "Wei-Lin Chiang",
                "Zhuohan Li",
                "Zi Lin",
                "Ying Sheng",
                "Zhanghao Wu",
                "Hao Zhang",
                "Lianmin Zheng",
                "Siyuan Zhuang",
                "Yonghao Zhuang",
                "Joseph E. Gonzalez",
                "Ion Stoica",
                "Eric P. Xing"
            ],
            "title": "Vicuna: An opensource chatbot impressing gpt-4 with 90%* chatgpt",
            "year": 2023
        },
        {
            "authors": [
                "Meier-Hellstern",
                "Douglas Eck",
                "Jeff Dean",
                "Slav Petrov",
                "Noah Fiedel."
            ],
            "title": "Palm: Scaling language modeling with pathways",
            "venue": "ArXiv, abs/2204.02311.",
            "year": 2022
        },
        {
            "authors": [
                "Narang",
                "Gaurav Mishra",
                "Adams Wei Yu",
                "Vincent Zhao",
                "Yanping Huang",
                "Andrew M. Dai",
                "Hongkun Yu",
                "Slav Petrov",
                "Ed Chi",
                "Jeff Dean",
                "Jacob Devlin",
                "Adam Roberts",
                "Denny Zhou",
                "Quoc Le",
                "Jason Wei"
            ],
            "title": "Scaling instruction-finetuned language",
            "year": 2022
        },
        {
            "authors": [
                "Joe Davison",
                "Joshua Feldman",
                "Alexander M. Rush."
            ],
            "title": "Commonsense knowledge mining from pretrained models",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference",
            "year": 2019
        },
        {
            "authors": [
                "Tim Dettmers",
                "Artidoro Pagnoni",
                "Ari Holtzman",
                "Luke Zettlemoyer."
            ],
            "title": "Qlora: Efficient finetuning of quantized llms",
            "venue": "arXiv preprint arXiv:2305.14314.",
            "year": 2023
        },
        {
            "authors": [
                "Bhuwan Dhingra",
                "Jeremy R. Cole",
                "Julian Martin Eisenschlos",
                "Daniel Gillick",
                "Jacob Eisenstein",
                "William W. Cohen."
            ],
            "title": "Time-aware language models as temporal knowledge bases",
            "venue": "Trans. Assoc. Comput. Linguistics, 10:257\u2013273.",
            "year": 2022
        },
        {
            "authors": [
                "Joseph L Fleiss."
            ],
            "title": "Measuring nominal scale agreement among many raters",
            "venue": "Psychological bulletin, 76(5):378.",
            "year": 1971
        },
        {
            "authors": [
                "Phillip Howard",
                "Junlin Wang",
                "Vasudev Lal",
                "Gadi Singer",
                "Yejin Choi",
                "Swabha Swayamdipta."
            ],
            "title": "Neurocomparatives: Neuro-symbolic distillation of comparative knowledge",
            "venue": "ArXiv, abs/2305.04978.",
            "year": 2023
        },
        {
            "authors": [
                "Jena D. Hwang",
                "Chandra Bhagavatula",
                "Ronan Le Bras",
                "Jeff Da",
                "Keisuke Sakaguchi",
                "Antoine Bosselut",
                "Yejin Choi."
            ],
            "title": "Comet-atomic 2020: On symbolic and neural commonsense knowledge graphs",
            "venue": "AAAI Conference on Artificial Intelligence.",
            "year": 2020
        },
        {
            "authors": [
                "Jena D Hwang",
                "Chandra Bhagavatula",
                "Ronan Le Bras",
                "Jeff Da",
                "Keisuke Sakaguchi",
                "Antoine Bosselut",
                "Yejin Choi."
            ],
            "title": "comet-) atomic 2020: On symbolic and neural commonsense knowledge graphs",
            "venue": "Proceedings of the AAAI Conference on Artificial",
            "year": 2021
        },
        {
            "authors": [
                "Jaehun Jung",
                "Peter West",
                "Liwei Jiang",
                "Faeze Brahman",
                "Ximing Lu",
                "Jillian Fisher",
                "Taylor Sorensen",
                "Yejin Choi."
            ],
            "title": "Impossible distillation: from low-quality model to high-quality dataset & model for summarization and paraphrasing",
            "venue": "ArXiv, abs/2305.16635.",
            "year": 2023
        },
        {
            "authors": [
                "Hyunwoo Kim",
                "Jack Hessel",
                "Liwei Jiang",
                "Ximing Lu",
                "Youngjae Yu",
                "Pei Zhou",
                "Ronan Le Bras",
                "Malihe Alikhani",
                "Gunhee Kim",
                "Maarten Sap"
            ],
            "title": "SODA: Million-scale dialogue distillation with social commonsense contextualization",
            "year": 2023
        },
        {
            "authors": [
                "Yash Kumar Lal",
                "Nathanael Chambers",
                "Raymond Mooney",
                "Niranjan Balasubramanian."
            ],
            "title": "TellMeWhy: A dataset for answering why-questions in narratives",
            "venue": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages",
            "year": 2021
        },
        {
            "authors": [
                "J Richard Landis",
                "Gary G Koch."
            ],
            "title": "The measurement of observer agreement for categorical data",
            "venue": "biometrics, pages 159\u2013174.",
            "year": 1977
        },
        {
            "authors": [
                "Jens Lehmann",
                "Robert Isele",
                "Max Jakob",
                "Anja Jentzsch",
                "D. Kontokostas",
                "Pablo N. Mendes",
                "Sebastian Hellmann",
                "M. Morsey",
                "Patrick van Kleef",
                "S. Auer",
                "C. Bizer."
            ],
            "title": "Dbpedia - a large-scale, multilingual knowledge base extracted from wikipedia",
            "venue": "Semantic",
            "year": 2015
        },
        {
            "authors": [
                "Zhongyang Li",
                "Xiao Ding",
                "Ting Liu",
                "J. Edward Hu",
                "Benjamin Van Durme."
            ],
            "title": "Guided generation of cause and effect",
            "venue": "Proceedings of the TwentyNinth International Joint Conference on Artificial Intelligence, IJCAI-20.",
            "year": 2020
        },
        {
            "authors": [
                "Bill Yuchen Lin",
                "Ziyi Wu",
                "Yichi Yang",
                "Dong-Ho Lee",
                "Xiang Ren."
            ],
            "title": "RiddleSense: Reasoning about riddle questions featuring linguistic creativity and commonsense knowledge",
            "venue": "Findings of the Association for Computational Linguistics: ACL-",
            "year": 2021
        },
        {
            "authors": [
                "Alisa Liu",
                "Swabha Swayamdipta",
                "Noah A. Smith",
                "Yejin Choi."
            ],
            "title": "WANLI: Worker and ai collaboration for natural language inference dataset creation",
            "venue": "Conference on Empirical Methods in Natural Language Processing.",
            "year": 2022
        },
        {
            "authors": [
                "Jiacheng Liu",
                "Alisa Liu",
                "Ximing Lu",
                "Sean Welleck",
                "Peter West",
                "Ronan Le Bras",
                "Yejin Choi",
                "Hannaneh Hajishirzi."
            ],
            "title": "Generated knowledge prompting for commonsense reasoning",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Compu-",
            "year": 2022
        },
        {
            "authors": [
                "Jiacheng Liu",
                "Wenya Wang",
                "Dianzhuo Wang",
                "Noah A. Smith",
                "Yejin Choi",
                "Hanna Hajishirzi."
            ],
            "title": "Vera: A general-purpose plausibility estimation model for commonsense statements",
            "venue": "ArXiv, abs/2305.03695.",
            "year": 2023
        },
        {
            "authors": [
                "Ximing Lu",
                "Sean Welleck",
                "Jack Hessel",
                "Liwei Jiang",
                "Lianhui Qin",
                "Peter West",
                "Prithviraj Ammanabrolu",
                "Yejin Choi."
            ],
            "title": "QUARK: Controllable text generation with reinforced unlearning",
            "venue": "Advances in Neural Information Processing Systems.",
            "year": 2022
        },
        {
            "authors": [
                "Nasrin Mostafazadeh",
                "Nathanael Chambers",
                "Xiaodong He",
                "Devi Parikh",
                "Dhruv Batra",
                "Lucy Vanderwende",
                "Pushmeet Kohli",
                "James Allen."
            ],
            "title": "A corpus and cloze evaluation for deeper understanding of commonsense stories",
            "venue": "Proceedings of the 2016",
            "year": 2016
        },
        {
            "authors": [
                "Rahul Nadkarni",
                "David Wadden",
                "Iz Beltagy",
                "Noah A. Smith",
                "Hannaneh Hajishirzi",
                "Tom Hope."
            ],
            "title": "Scientific language models for biomedical knowledge base completion: An empirical study",
            "venue": "3rd Conference on Automated Knowledge Base Construction,",
            "year": 2021
        },
        {
            "authors": [
                "OpenAI."
            ],
            "title": "Gpt-4 technical report",
            "venue": "ArXiv, abs/2303.08774.",
            "year": 2023
        },
        {
            "authors": [
                "ter Welinder",
                "Paul Francis Christiano",
                "Jan Leike",
                "Ryan J. Lowe"
            ],
            "title": "Training language models to follow instructions with human feedback. ArXiv, abs/2203.02155",
            "year": 2022
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th annual meeting on association for computational linguistics, pages 311\u2013318. Association for",
            "year": 2002
        },
        {
            "authors": [
                "Fabio Petroni",
                "Tim Rockt\u00e4schel",
                "Patrick S.H. Lewis",
                "Anton Bakhtin",
                "Yuxiang Wu",
                "Alexander H. Miller",
                "Sebastian Riedel"
            ],
            "title": "Language models as knowledge bases? CoRR, abs/1909.01066",
            "year": 2019
        },
        {
            "authors": [
                "Raul Puri",
                "Bryan Catanzaro."
            ],
            "title": "Zero-shot text classification with generative language models",
            "venue": "CoRR, abs/1912.10165.",
            "year": 2019
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam M. Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J. Liu."
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "ArXiv, abs/1910.10683.",
            "year": 2019
        },
        {
            "authors": [
                "Keisuke Sakaguchi",
                "Ronan Le Bras",
                "Chandra Bhagavatula",
                "Yejin Choi."
            ],
            "title": "Winogrande: An adversarial winograd schema challenge at scale",
            "venue": "AAAI Conference on Artificial Intelligence.",
            "year": 2019
        },
        {
            "authors": [
                "drea Santilli",
                "Thibault F\u00e9vry",
                "Jason Alan Fries",
                "Ryan Teehan",
                "Stella Rose Biderman",
                "Leo Gao",
                "Tali Bers",
                "Thomas Wolf",
                "Alexander M. Rush"
            ],
            "title": "Multitask prompted training enables zero-shot task generalization. ArXiv, abs/2110.08207",
            "year": 2021
        },
        {
            "authors": [
                "Sebastin Santy",
                "Jenny T Liang",
                "Ronan Le Bras",
                "Katharina Reinecke",
                "Maarten Sap."
            ],
            "title": "NLPositionality: Characterizing design biases of datasets and models",
            "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics,",
            "year": 2023
        },
        {
            "authors": [
                "Maarten Sap",
                "Hannah Rashkin",
                "Derek Chen",
                "Ronan Le Bras",
                "Yejin Choi."
            ],
            "title": "Social IQA: Commonsense reasoning about social interactions",
            "venue": "Conference on Empirical Methods in Natural Language Processing.",
            "year": 2019
        },
        {
            "authors": [
                "Melanie Sclar",
                "Peter West",
                "Sachin Kumar",
                "Yulia Tsvetkov",
                "Yejin Choi."
            ],
            "title": "Referee: Referencefree sentence summarization with sharper controllability through symbolic knowledge distillation",
            "venue": "arXiv preprint arXiv:2210.13800.",
            "year": 2022
        },
        {
            "authors": [
                "Taylor Shin",
                "Yasaman Razeghi",
                "Robert L. Logan IV",
                "Eric Wallace",
                "Sameer Singh."
            ],
            "title": "Autoprompt: Eliciting knowledge from language models with automatically generated prompts",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural",
            "year": 2020
        },
        {
            "authors": [
                "Oyvind Tafjord",
                "Peter Clark."
            ],
            "title": "Generalpurpose question-answering with macaw",
            "venue": "ArXiv, abs/2109.02593.",
            "year": 2021
        },
        {
            "authors": [
                "Alon Talmor",
                "Jonathan Herzig",
                "Nicholas Lourie",
                "Jonathan Berant."
            ],
            "title": "CommonsenseQA: A question answering challenge targeting commonsense knowledge",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Trieu H. Trinh",
                "Quoc V. Le."
            ],
            "title": "A simple method for commonsense reasoning",
            "venue": "CoRR, abs/1806.02847.",
            "year": 2018
        },
        {
            "authors": [
                "Peter West",
                "Chandra Bhagavatula",
                "Jack Hessel",
                "Jena Hwang",
                "Liwei Jiang",
                "Ronan Le Bras",
                "Ximing Lu",
                "Sean Welleck",
                "Yejin Choi."
            ],
            "title": "Symbolic knowledge distillation: from general language models to commonsense models",
            "venue": "Proceedings of the",
            "year": 2022
        },
        {
            "authors": [
                "Peter West",
                "Chandra Bhagavatula",
                "Jack Hessel",
                "Jena D. Hwang",
                "Liwei Jiang",
                "Ronan Le Bras",
                "Ximing Lu",
                "Sean Welleck",
                "Yejin Choi."
            ],
            "title": "Symbolic Knowledge Distillation: from general language models to commonsense models",
            "venue": "North American",
            "year": 2021
        },
        {
            "authors": [
                "Canwen Xu",
                "Daya Guo",
                "Nan Duan",
                "Julian McAuley."
            ],
            "title": "Baize: An open-source chat model with parameter-efficient tuning on self-chat data",
            "venue": "ArXiv, abs/2304.01196.",
            "year": 2023
        },
        {
            "authors": [
                "Rowan Zellers",
                "Ari Holtzman",
                "Yonatan Bisk",
                "Ali Farhadi",
                "Yejin Choi"
            ],
            "title": "HellaSwag: Can a machine really finish your sentence? In Annual Meeting of the Association for Computational Linguistics",
            "year": 2019
        },
        {
            "authors": [
                "Hongming Zhang",
                "Daniel Khashabi",
                "Y. Song",
                "D. Roth."
            ],
            "title": "TransOMCS: From linguistic graphs to commonsense knowledge",
            "venue": "IJCAI.",
            "year": 2020
        },
        {
            "authors": [
                "Tianyi Zhang",
                "V. Kishore",
                "Felix Wu",
                "Kilian Q. Weinberger",
                "Yoav Artzi."
            ],
            "title": "Bertscore: Evaluating text generation with bert",
            "venue": "ArXiv, abs/1904.09675.",
            "year": 2020
        },
        {
            "authors": [
                "Pei Zhou",
                "Hyundong Justin Cho",
                "Pegah Jandaghi",
                "DongHo Lee",
                "Bill Yuchen Lin",
                "Jay Pujara",
                "Xiang Ren."
            ],
            "title": "Reflect, not reflex: Inference-based common ground improves dialogue response quality",
            "venue": "Conference on Empirical Methods in Natural Language",
            "year": 2022
        }
    ],
    "sections": [
        {
            "text": "NOVACOMET leverages the knowledge of opaque proprietary models to create an open knowledge pipeline. First, knowledge is symbolically distilled into NOVATOMIC, a publiclyreleased1 discrete knowledge graph which can be audited, critiqued, and filtered. Next, we train NOVACOMET on NOVATOMIC by finetuning an open-source pretrained model. NOVACOMET uses an open-format training objective, replacing the fixed relation sets of past knowledge models, enabling arbitrary structures within the data to serve as inputs or outputs.\nThe resulting generation model, optionally augmented with human annotation, matches or exceeds comparable open task models like FlanT5 on a range of commonsense generation tasks. NOVACOMET serves as a counterexample to the contemporary focus on instruction tuning only, demonstrating a distinct advantage to explicitly modeling commonsense knowledge as well."
        },
        {
            "heading": "1 Introduction",
            "text": "We present NOVACOMET, an open commonsense knowledge model combining the advantages of both knowledge models and general task models. NOVACOMET models commonsense knowledge with an open format, allowing it to be applied to general reasoning tasks in contrast to previous knowledge models. Compared to simply training\n1Our resources are available at novacomet.dev\nCaption: Knowledge is distilled from strong LLMs such as gpt-3 turbo, which allows auditable transfer of knowledge that prevents issues like data contamination (CITE) that may plague opaque proprietary models. The final trained model learns to fill in any part of the knowledge \u2014 beyond simply answering a query[orange], NovaCOMET can e.g. predict what\ncontext[green] would make a query[orange] + inference[purple] likely.\nmodels to be open task solvers (e.g. instruction tuning) we find that explicitly modeling knowledge in NOVACOMET also provides a distinct advantage, with NOVACOMET showing similar or superior performance to comparable open task models on a range of commonsense reasoning benchmarks.\nFor NOVACOMET, we leverage opaque, proprietary models like ChatGPT or GPT-4 (Ouyang et al., 2022; OpenAI, 2023) as the knowledge source in an open commonsense pipeline (Figure 1). Such models have demonstrated remarkable commonsense ability (Bubeck et al., 2023; Bian et al., 2023) yet, closed and opaque, their direct usefulness for studying commonsense is limited. Without information about training or direct access to the model, it is impossible to study where reported gains come from\u2014e.g. the extent of test set contamination with benchmarks.\nIn our work, we use these models first to gener-\nate an open knowledge base (NOVATOMIC, \u00a72.1), which can be analyzed, improved, and verified against test set contamination. Next, we train an open commonsense model (NOVACOMET, \u00a72.3) on this knowledge: the underlying data and code will be released along with the model for the study of commonsense. This allows future testing of NOVACOMET (and of other models based on NOVATOMIC) to analyze the training set\u2014essentially allowing us to distill information from a base LLM into an auditable format.\nIn training NOVACOMET, we also use an open format: compared to previous knowledge models which use a fixed relation set and training order (head + relation\u2192 tail) we use natural language queries as relations, and allow masked generation of all aspects of the data. This allows our model to be used in a wide range of general reasoning tasks, thus addressing a significant limitation of prior knowledge models that are limited to downstream applications capable of effectively leveraging their restricted set of relations. Enabling an open format also allows the knowledge generation to focus on pertinent aspects of the context, rather than forcing the generation of inferences for arbitrary, potentially irrelevant relations.\nFollowing past work on symbolic knowledge distillation (West et al., 2022), we also use NOVATOMIC as the basis for training a plausibility model with human annotations (\u00a72.2), and study how this can improve NOVACOMET (\u00a72.3).\nWe test NOVACOMET on a range of commonsense generation tasks, and find that it consistently outperforms general task models of comparable size, such as Flan-T5xxl (Chung et al., 2022a) and T0 on commonsense tasks like abductive infilling and explanation generation. Furthermore, we assess the ability of our plausibility model to handle general commonsense QA tasks and observe that it achieves comparable or superior discriminative performance on a range of tasks. NOVACOMET will serve as an open resource for studying commonsense, and an example of the advantage of explicitly modeling commonsense knowledge in contrast to general task modeling alone."
        },
        {
            "heading": "2 NOVACOMET: open commonsense models",
            "text": "NOVACOMET is a large-scale, open commonsense model that can handle both explicit knowledge generation, and tasks that require common-\nsense reasoning. NOVACOMET is trained with symbolic knowledge distillation (West et al., 2021) by combining the commonsense data generated by large language models (\u00a72.1) with high-quality annotations of knowledge plausibility (\u00a72.2). We experiment with multiple methods for combining generated data with plausibility information (indicating how likely a given knowledge is) to train the final model, NOVACOMET (\u00a72.3)."
        },
        {
            "heading": "2.1 Generating Open Commonsense Data",
            "text": "Following symbolic knowledge distillation (West et al., 2021), we distill large quantities of highquality knowledge from very large, general foundation models (\u00a72.1.1) \u2013 we call the resulting dataset NOVATOMIC. One major difference from previous knowledge graphs is that we allow an open relation set, in the form of queries rather than fixed relation tokens. While commonsense knowledge often takes a head, relation, tail format with a fixed set of discrete relations (e.g. X buys a lottery ticket, xWant, to win.), we propose a context, query, inference (CQI) format with natural language queries serving as open relations. We also analyze unique properties of this distilled knowledge in \u00a72.1.2."
        },
        {
            "heading": "2.1.1 Data Generation",
            "text": "We outline the generation process below, which consists of (1) generating contexts and (2) generating queries/inferences, resulting in our new knowledge base, NOVATOMIC.\nContext Generation. First, we have experts generate 21 varied prompts to steer models to generate events or situations that require commonsense knowledge to fully understand (see B.1 for all prompts used). As variations in prompt wording influence the model\u2019s output, we use many different prompts to enhance both diversity and coverage of the generated outputs. Half of the time, we generate contexts in a zero-shot manner, while for the other half, we do one-shot generation with one example drawn from ATOMIC10X (West et al., 2022). In order to reduce generation cost, we generate 20 situations per prompt (batched generation).\nWe generate the contexts using GPT-3 (Brown et al., 2020) variant text-davinci-003 (Ouyang et al., 2022) for a total cost of USD $39.56. We set top_p=0.99 and presence_penalty=0.3, lowering the logit values for tokens that have already\noccurred to promote diversity within each batch. Finally, to allow NOVACOMET to see some diversity of names, we also randomly swap all entities (names or \"PersonX/Y/Z\") for a name drawn from the 2021 public US social security application name registry2 with probability 0.5.\nQuery/Inference Generation. As no other resource currently has examples of high-quality commonsense inferences in our proposed open format, we develop a set of few-shot examples of 10 contexts (either handwritten or selected from ATOMIC10X or from ROCStories (Mostafazadeh et al., 2016)) with 10 handwritten commonsense query/inference pairs for each (see Appendix B.2 for more details). These query/inference pairs cover a broad swathe of knowledge, including consequences, explanations, reactions, attributes, counterfactuals, etc.\nFor each context in NOVATOMIC generated in the previous step, we randomly select and permute n \u223c Uniform(1, 10) of the few-shot examples to provide in context after the instructions and then task the model with generating 10 query/inference pairs for the new context. The rationale for this random selection and permutation of the few-shot examples is to mitigate the potential overfitting to a specific ordering or selection or ordering of handwritten examples. To try to support the use case where a desired commonsense query is not known in advance, e.g. when a user simply want general knowledge for a given context, we also generated half of the commonsense hypotheses without generating a query first (prompt in B.2). At training time (\u00a72.3), we input a NULL value for the query field. We generated all query/inference pairs using default decoding arguments with gpt-3.5-turbo-0301 for a total cost of USD $337.16."
        },
        {
            "heading": "2.1.2 Analysis",
            "text": "Comparison to Previous CSKGs. Table 1 shows the comparisons of NOVATOMIC to existing CSKGs, ATOMIC2020 (Hwang et al., 2020) and ATOMIC10X (West et al., 2022) in dataset statistics and lexical diversity measures. NOVATOMIC contains more diverse unique premises (heads) and hypotheses (tails) as indicated by the higher number and/or percentage of these data entries. NOVATOMIC also has higher lexical variations, as re-\n2https://catalog.data.gov/dataset/baby-names-fromsocial-security-card-applications-national-data\nflected by the significantly more diverse 3-grams. In particular, as NOVATOMIC breaks out from fixed relation types with open questions to connect premise and hypothesis, it contains much more diverse and flexible sets of relations denoted by natural language questions.\nIt is also of note that, based on estimates from (West et al., 2022), the total cost of ATOMIC2020 and ATOMIC10X were approximately USD $40,000 and USD $6,000 respectively, whereas the cost for NOVATOMIC is approximately $400. Though the size of NOVATOMIC is somewhat smaller, the unit cost per example is also significantly lower.\nAnalysis of Question Types. To delve into what relations are encoded in NOVATOMIC with open questions, we conduct an analysis of question types. Figure 2 shows the top 10 most common question prefixes, including open-ended question types, such as what and how, and binary yes/no question types, such as is and will. By grouping WHquestions together (i.e., how, what, why, who, where, when, whose, which), we obtain 81.1% of open-ended questions and 18.9% of binary yes/no questions, indicating a diverse and flexible relation space the large portion of free-form questions represent, as shown in Figure 2(b). Table 2 shows some\nof the most common questions in the dataset. The most common questions are not context-specific (asking about time, weather, or location), although we find that many of the queries do condition specifically on context."
        },
        {
            "heading": "2.2 Plausibility Annotation",
            "text": "Next, we collect annotations of CQI data plausibility. Broadly, this follows West et al. (2022); Howard et al. (2023) in combining generated data with an automatic critic to maximize the quality of a final trained model. In this case, however, we explore multiple ways to incorporate annotations of plausibility into the final model NOVACOMET (\u00a72.3.2).\nOur primary means of collecting annotations of plausibility is through Amazon Mechanical Turk. We use a similar annotation template to (Hwang et al., 2020) (see Appendix C), asking annotators to decide if knowledge is always/often, sometimes/likely, farfetched/never true, or invalid (giving these annotations a score of 3, 2, 1, 0 respectively). We consider any knowledge scored 3 or 2 to be plausible.\nIn practice, we collect 20k annotations, with 1\nannotator per example. For underlying data, we use 16k examples from NOVATOMIC, as well as 2k examples each from ATOMIC10X and ATOMIC2020 to increase diversity of annotated knowledge style. While these knowledge graphs have fixed relation sets, we use sample natural language queries to replace the discrete relations (e.g. xNeed \u2192 What did PersonX need?).\nWe conduct a human agreement study on a segment of 200 examples for which we elicit 3 annotations each, finding Fleiss \u03ba (Fleiss, 1971) of 0.317 indicating fair agreement (Landis and Koch, 1977)."
        },
        {
            "heading": "2.3 Training NOVACOMET",
            "text": ""
        },
        {
            "heading": "2.3.1 Commonsense field masking",
            "text": "Previous knowledge models tend to use a standard head,relation \u2192 tail format in training, generating some inference given the situation/concept, and one of a set of possible commonsense relations to guide generation.\nThe goal of NOVACOMET is maximum flexibility in handling commonsense knowledge and tasks, meaning we would like to generate any of these fields from any others. For example, we may want to generate a likely query that connects the context and inference; or, a context under which the query and inference are correct. To this end, we propose commonsense field masking, wherein we randomly sample subspans of fields to be masked for prediction, e.g.\nInput: Context: Consider the list of MASKC shows. Query: What is the MASKQ show? Inference: Hamilton Target: MASKC = Broadway MASKQ = most popular\nThe process of masking follows two steps. First, the set of which fields (CQI) will be masked is uniformly selected from all options in which at least one field is masked. Second, for each field, we randomly (with p=0.5) decide whether to mask the entire field, or a subspan. Finally, for those fields where a subspan is masked, we uniformly select the mask length, and which subspan of the given length to mask.\nIn effect, this gives the final model maximal flexibility at inference time. Users can mask any field, either the full span or infill a subspan as needed, allowing for use cases besides simply generating a full inference as in previous commonsense models.\nWe explore how this can be especially useful in \u00a73.2."
        },
        {
            "heading": "2.3.2 NOVACOMET Versions",
            "text": "We consider a variety of methods to use the generation and critique data described above for training.\nGeneration-only Model First, we consider the simplest option for producing a commonsense generation model: training directly on NOVATOMIC. NOVACOMETbase is trained only on generation data from \u00a72.1 with the commonsense masking objective (\u00a72.3.1). Plausibility is not used in this model.\nCritic-only Model Second, we train a standalone plausibility critic model, NOVACOMETcrit. This is trained to generate a plausibility score from a complete CQI (context, query, inference) knowledge triple, on the annotation set from \u00a72.2. In effect, it returns a probability that a given CQI is plausible.\nFiltered Generation Model Following West et al. (2022), we use a simple filtering-based technique for improving generation with plausibility scores. Using NOVACOMETcrit, we calculate the probability of being plausible for all examples in NOVATOMIC, and filter to only those points that meet a minimum probability. We focus on one threshold in particular, 0.99, indicating that NOVACOMETcrit gives at least 0.99 probability to the given CQI being plausible. We call the resulting model NOVACOMETfilter\u22120.99, and the resulting filtered training set retains over 50% of its original size, indicating NOVATOMIC is already high quality.\nQuantized Reward Conditioning Inspired by quantized reward conditioning in (Lu et al., 2022), we also consider more closely unifying the critical and generation data. We consider a light-weight, one-step approach (as opposed to full reinforcement learning in Lu et al. 2022) in which we annotate NOVATOMIC with NOVACOMETcrit, then train a masked-prediction model that includes plausibility as a conditioning variable for predicting CQI. For annotation with NOVACOMETcrit, we greedily decode plausibility, and train a rewardconditional model NOVACOMETrc. When decoding with NOVACOMETrc, we condition on either of the \u201cplausible\u201d labels (2 or 3) from \u00a72.2."
        },
        {
            "heading": "2.3.3 Model Training",
            "text": "We use the T5X codebase (Roberts et al., 2022) to train NOVACOMET, using the base T5 1.1 xxl (\u223c11B parameters) checkpoint to initialize all of our experiments. We train all models on v3-128 TPU pods, using a batch size of 128 and a learning rate of 1e-5. For generation models, we train for a fixed 100k training steps, ensuring that loss does not converge or begin increasing. For models that include plausibility prediction as an objective, we stop training when evaluation loss for plausibility converges, which is often significantly before 100k training steps."
        },
        {
            "heading": "3 Experiments",
            "text": ""
        },
        {
            "heading": "3.1 Evaluating Plausibility",
            "text": "We begin by evaluating the performance of our plausibility model NOVACOMETcritic. Particularly, we aim to understand the ability of this model to provide a useful, absolute plausibility score. We compare the accuracy of our plausibility scores on discriminative commonsense benchmarks to judge its effectiveness."
        },
        {
            "heading": "3.1.1 Datasets",
            "text": "We consider a range of standard discriminative commonsense benchmarks: HellaSwag (HS) (Zellers et al., 2019) for generation recognition; \u03b1NLI (Bhagavatula et al., 2019) for abductive reasoning; WinoGrande (WG) (Sakaguchi et al., 2019) for pronoun resolution; Commonsense QA (CSQA) (Talmor et al., 2019) and CODAH (Chen et al., 2019) for general commonsense question answering; Social IQA (SIQA) (Sap et al., 2019) for social commonsense; RiddleSense (RS) (Lin et al., 2021) for riddle answering; and Physical IQA (PIQA) (Bisk et al., 2019) for physical commonsense. Together, these allow us to judge the ability of models to assess the correctness/plausibility of commonsense."
        },
        {
            "heading": "3.1.2 Models and Baselines",
            "text": "As baselines, we primarily consider popular language models in a roughly similar range of parameter sizes. We include basic language model LLaMA (Touvron et al., 2023) and PaLM (Chowdhery et al., 2022) (citing performance directly for both); and language models with general task tuning such as QA for Macaw (Tafjord and Clark, 2021) or instruction tuning for Flan-T5xxl (Chung et al., 2022b) and T0 (Sanh et al., 2021). We create\nstandard-format prompts that depend on the model. When possible, models are given answer choices as input. This is an advantage over plausibility models like NOVACOMETcrit which are designed to judge answers in isolation, but we include this to maximize baseline quality. To score options of baselines, we use negative-log-likelihood, as it was found by us to be best out of a range of options. We cite results for an alternative formatting for prompting FLAN from (Liu et al., 2023) which automatically reformats commonsense questions as statements, then judges plausibility as the likelihood of answering \u201cyes\u201d or \u201cno\u201d to whether the statement is plausible. We note that, while this method performs well, it will not generally apply to Context-Query-Inference (CQI) formatted data, as not all CQI examples can be naturally reformatted into short statements, but we include this baseline for completeness. We also cite results on GPT-3.5, ChatGPT, and GPT-4 from the same paper.\nWe compare baselines to NOVACOMETcrit described in \u00a72.3. For this models, we score options based on the probability of predicting 2 or 3 for plausibility (sometimes/likely or always/often true), renormalized against the probability of predicting 1 or 0 (rarely or never true, or invalid)."
        },
        {
            "heading": "3.1.3 Results and Discussion",
            "text": "Model scores on various tasks requiring commonsense knowledge can be seen in Table 3. While various models are better at different tasks, NOVACOMETcrit is tied for most combined 1st + 2nd place results (5). Note that the other tied system, Flan-T5 (statements) requires automatically transforming each problem into a yes or no question; a transformation that is not generally applicable to the kinds of Context-Query-Inference style problems we would like to solve when deriving commonsense information from a model.\nLooking at cases where NOVACOMETcrit fails to get the highest accuracy, it is perhaps unsurprising that PaLM 540B and 62B outperform all other models on HellaSwag, which requires predicting the most likely continuation of a scene description, a task especially well suited to a raw language model. Furthermore, with Physical IQA (PIQA), the focus is on physical commonsense, a subcategory that our base generator seemed to produce less naturally on inspection.\nWe also note that many baselines (e.g. Macaw, T0) assume access to all answer choices. For our use case (judging knowledge within NOVATOMIC\nto improve the overall dataset) we are judging examples in isolation with no clear contrastive examples. The competitive performance of NOVACOMETcrit here, despite such disadvantages, further validates it for this use case."
        },
        {
            "heading": "3.2 Evaluating Generation",
            "text": "The central goal of NOVACOMET is in generating commonsense knowledge, and carrying out commonsense reasoning. In this section, we test the ability of various versions of NOVACOMET described in \u00a72.3 to do this. Note that we primarily use human evaluation for model generations, following a similar setup to \u00a72.2 with annotation templates available in Appendix C."
        },
        {
            "heading": "3.2.1 Datasets",
            "text": "First, we test the ability of models to generate commonsense knowledge in the format of previous knowledge models. Particularly, we take a sample of ATOMIC2020 (Hwang et al., 2020) commonsense prompts (head + relation), testing the ability of models to generate a valid tail. Results are included in Table 4.\nNext, we test on various downstream benchmarks requiring generative commonsense reasoning. First, we test abductive natural language generation (\u03b1NLG) (Bhagavatula et al., 2019), wherein models must abductively fill in the gap in a story between two observations. We also consider two question-answering datasets that require commonsense reasoning: TellMeWhy (Lal et al., 2021) in which models explain events, and Reflect (Zhou et al., 2022) in which models generate ATOMICstyle inferences for dialogues. We report results for all downstream reasoning benchmarks in Table 3. We use a custom annotation template for \u03b1NLG, and otherwise use the base CQI template from our annotation in \u00a72.2."
        },
        {
            "heading": "3.2.2 Baselines and Models",
            "text": "For baselines, we include all of the models described in \u00a73.1 as well as T5xxl (\u223c11B parameters) finetuned for language modeling (T5-LM) (Raffel et al., 2019). We use straightforward prompts to describe each task and generate directly.\nDifferent datasets can demonstrate unique ways to use the commonsense masking of NOVACOMET for generation. For example, for \u03b1NLG, we mask between the beginning (o1) and ending (o2) events to form a natural sequence:\nInput: Context: <o1> MASKC Query: What happens next? Inference: <o2>\nTo predict a hypothesis h that fits between o1 and o2. We found this resulted in much higher quality generations than encoding o1, o2 as context and predicting h as inference.\nFor other datasets (Reflect, TellMeWhy, ATOMIC2020), we can encode examples simply by giving context and query, then predicting the\ninference. For all models, we use greedy decoding."
        },
        {
            "heading": "3.2.3 Results and Discussion",
            "text": "All generation results use human evaluation, presented in Table 4. Note that human evaluation templates are included in the Appendix. We evaluate 100 examples for each system and dataset. For Reflect, TellMeWhy, and ATOMIC2020, we use the same template as \u00a72.2. For \u03b1NLG we use a template measuring coherence between the generated infill and either or both hypotheses, as well as overall quality. All scores in Table 4 are normalized to\na range between 0 and 1. Note that NOVACOMET models win across the board. Particularly effective is the filtered model NOVACOMETfilter\u22120.99, but so are the reward conditional models, and NOVACOMETrc(2) in particular, conditioned on \u201c2\u201d (likely/sometimes true) rather than \u201c3\u201d (always/often true). It is possible that answers that are always true are somewhat less creative or preferable to humans.\nIn general, the NOVACOMET models that use plausibility information outperform the basic NOVACOMETbase, other than on the TellMeWhy dataset. This demonstrates a particular advantage of distilling discrete data \u2013 it can be annotated, and those annotations can improve downstream performance.\nOverall, superior performance of NOVACOMET suggests that explicitly modeling knowledge can provide an advantage, at least considering tasks that explicitly require commonsense knowledge and reasoning."
        },
        {
            "heading": "4 Related Work",
            "text": "Knowledge Generation Pretrained language models demonstrated the ability to carry implicit knowledge (Petroni et al., 2019; Dhingra et al., 2022). These large language models are prompted for generating new knowledge to perform downstream tasks such as text classification (Shin et al., 2020; Puri and Catanzaro, 2019), commonsense reasoning (Liu et al., 2022b; Trinh and Le, 2018; Davison et al., 2019). We take inspiration from commonsense LMs, designed for query commonsense knowledge, such as COMET (Bosselut et al., 2019) and COMET-2020 (Hwang et al., 2021). Domain specific LMs are also used for knowledge graph completion in specialized domains like biomedicine (Nadkarni et al., 2021). Liu et al. (2022a) use dataset cartography to prime the model with challenging examples and enable it to generate more examples with such patterns.\nKnowledge Distillation As the process of manually creating datasets can be costly and complex, prior studies have explored the realm of automated data generation. These prior works mainly focused on extractive approaches, e.g. syntactic parsing (Zhang et al., 2020a) or pattern matching (Li et al., 2020) from unstructured text (Lehmann et al., 2015; Buck et al., 2014).\nWest et al. (2021) proposed filtering out low quality data using a critic model for symbolic knowl-\nedge distillation from larger models. Following this, several works effectively improved upon this for iterative distillation (Sclar et al., 2022; Bhagavatula et al., 2023), self-chat with feedback and conversations with ChatGPT (Xu et al., 2023; Geng et al., 2023; Chiang et al., 2023). SODA (Kim et al., 2023) contextualized social commonsense knowledge from a knowledge graph to distill dialogues from InstructGPT. Sclar et al. (2022) established filters based on length, fidelity, and information bottleneck for distilling reference-free summarization determining the effectiveness of designing filters for selecting data for the following iteration. Recently, (Jung et al., 2023) proposed a framework to learn a high-quality model from a low-quality teacher model to distill a good dataset by summarizing and paraphrasing."
        },
        {
            "heading": "5 Conclusions",
            "text": "Overall, we introduce NOVACOMET, an open commonsense foundation model. NOVACOMET takes advantage of closed proprietary models, resulting in an open pipeline and resources that are publicly available. NOVACOMET is trained on data generated from these closed proprietary models and augmented with human annotations, resulting in both a high-quality plausibility model and improved generative model. NOVACOMET surpasses other general models of similar size at a range of commonsense knowledge-intensive tasks, demonstrating the existing need for explicit knowledge modeling, even as task-focused methods like instruction tuning grow in popularity.\nLimitations\nFirst, we recognize that our line of research requires extensive resources and funding, limiting the broad adoption of our methodology as it is presented. Particularly, our work relies on both massive generation from proprietary language models (GPT-3 turbo) and extensive use of TPU resources. Our hope is that these barriers will only be lowered as proprietary LMs become cheaper and LMs become increasingly efficient to tune and do inference on (Dettmers et al., 2023), lowering the barrier for techniques such as ours.\nSecond of all, we recognize that, while we have attempted to test the query-ability of commonsense knowledge via automatic and human evaluations on a number of different tasks [FIX ME]RL. However, current tasks are largely biased towards both\ncertain topics and tends to implicitly define ground truth from certain, fixed perspectives rather than acknowledging the underlying diversity of human perspectives (Santy et al., 2023). This limits our ability to assess whether our models capture genuine human agreement\u2014or only the agreement of a certain portion of the population\u2014something which we hope future work will investigate.\nEthics Statement\nAkin to all other machine learning approaches, our model could inadvertently exhibit biases. We acknowledge that the open format relations gathered from proprietary models may not be representative of all cultures, and thereby these perpetuate the biases that these proprietary large models possess. While generating commonsense knowledge, LLMs may result in unanticipated commonsense inferences, including those that are biased and escape our critic model. Consequently, incorporating these inferences during training can further amplify such biases. We are committed to understanding such biases and improving our critic model. However, our model\u2019s central tenet is knowledge, which contrasts with existing public models of similar size and architecture, thereby regulating the toxicity of the model. We ensured that the crowd workers involved in our project were compensated at a rate that met or exceeded the minimum wage requirement, recognizing the value of their contributions to building our model. Comparable to all open models, our model is susceptible to malicious use and it is our collective responsibility to thrust safe open usage. We acutely understand the ethical implications associated with our proposed method and are dedicated to resolving them, aiming to ensure the responsible adaptation of our approach in the community."
        },
        {
            "heading": "A Manual Cluster Analysis of Queries",
            "text": "To understand the contents of NOVATOMIC, we analyze the top 100 surface form queries by total count in NOVATOMIC. We cluster these queries by hand into semantically related/equivalent groups, and then further take the top 10 of these groups, displayed in the main paper text. In Table 5, we include all queries in the the top 10 clusters along with with counts and total counts per cluster.\nA.1 Automatic Evaluation of Generation\nWe also include automatic evaluation with 2 metrics in Table 6. We find these values show a much less distinct spread, with no model taking a clear lead over others. The seemingly lower information and general unreliability of automatic metrics was a motivation in mainly considering human evaluation."
        },
        {
            "heading": "B Data Generation",
            "text": "B.1 Context Generation Prompts\nBelow are the 21 prompts used for doing context generation (delimited with \u201d\u2019)\nGenerate 20 events.\n1. Event:\n''' Generate 20 common events.\n1. Event: ''' Generate 20 everyday events.\n1. Event: ''' Generate 20 events that happen often.\n1. Event: ''' Generate 20 events that happen sometimes\n.\n1. Event: ''' Generate 20 events that include a person\nor people.\n1. Event: '''\nGenerate 20 everyday events about PersonX (one per line). It may also involve other entities, such as PersonY.\n1. Event: ''' Generate 20 situations.\n1. Situation: ''' Generate 20 common situations.\n1. Situation: ''' Generate 20 everyday situations.\n1. Situation: ''' Generate 20 situations that happen often\n.\n1. Situation: ''' Generate 20 situations that happen\nsometimes.\n1. Situation: ''' Generate 20 situations that include a\nperson or people.\n1. Situation: ''' Generate 20 everyday situations about\nPersonX (one per line). It may also involve other entities, such as PersonY.\n1. Situation: ''' Generate 20 situations. They should be\ncomplex and include multiple parts. (One per line)\n1. Situation: ''' Generate 20 common situations. They\nshould be complex and include multiple parts. (One per line)\n1. Situation: ''' Generate 20 everyday situations. They\nshould be complex and include multiple parts. (One per line)\n1. Situation: ''' Generate 20 situations that happen often\n. They should be complex and include multiple parts. (One per line)\n1. Situation: ''' Generate 20 situations that happen\nsometimes. They should be complex and include multiple parts. (One per line)\n1. Situation: ''' Generate 20 situations that include a\nperson or people. They should be complex and include multiple parts. (One per line)\n1. Situation: ''' Generate 20 everyday situations about\nPersonX (one per line). It may also involve other entities, such as PersonY. They should be complex and include multiple parts. (One per line)\n1. Situation:\nB.2 Relation Generation Prompts\nBelow are the prompts for generating relations. To promote diversity, the number of examples were randomly selected from Uniform(1,10) and were shuffled. Some contexts come from ROCStories (Mostafazadeh et al., 2016) and (West et al., 2022), while others are handwritten. All questions and inferences are hand-written. When prompting \u2018gpt3.5-turbo\u2018, we provide the instructions \"Given a situation... answer\" as the system message, the Context as a user message, and the ten generated queries/inferences as the system response.\nB.3 With queries\nGiven a situation, ask and answer ten (10) relevant questions that require commonsense or a world model. Some\nexamples may include potential consequences, explanations, prerequisites or reactions, attributes, or counterfactuals. The commonsense facts may be about actors, actions, events, or ideas in the passage. The examples should be high-quality and things that are\ntrue. Please give a plausible answer at all times instead of just saying that it depends. Only ask questions that will have a relevant,\ncommonsense answer.\nAlisa and her family lived in Florida. They heard a hurricane was coming. They decided to evacuate to a relative's house. They arrived and learned from the news that it was a terrible storm.\n1. What will happen now? They will wait out the storm.\n2. How does Alisa feel? She is probably relieved to be out of the hurricane' s path.\n3. What would have happened if Alisa and her family had not evacuated? They\nwould have been in the storm. 4. Why did they decide to evacuate to a\nrelative's house? They wanted to be in a safe place.\n5. Alisa's family is what? Responsible\n6. What might have prevented them from fleeing? If they had not heard about the hurricane, or if they had no\nway to get to a relative's house. 7. They would not have fled if they were\nnot what? Cautious 8. Where does their relative live?\nSomewhere safe from the hurricane. 9. Should they have fled even if the\nstorm hadn't been bad? Yes, because they might have not been able to leave if the hurricane got worse.\n10. How could you describe their relative? Kind\nA robber steals from a bank. 1. What are some potential characters in\nthe situation? Robber, bank teller/ worker, customers\n2. Tell me something about the robber? The robber is probably armed\n3. What does the robber have? The robber probably has a getaway car\n4. What does the bank teller feel? The bank teller is probably scared\n5. What might happen to the robber? The robber could go to jail\n6. What does the bank have? The bank might have a security system\n7. Before this, did the robber do anything? The robber probably planned this in advance\n8. As a consequence, what will happen? After, the robber will have the money\n9. What happens before this? The robber tells the bank teller to give them the money\n10. How much money does the robber get? A lot of money\nThe woman enters the elevator 1. What did the woman have to do before?\nThe woman had to press the button for the elevator to come to her floor\n2. What is the woman's goal? The woman wants to go to a different floor\n3. What will the woman do next? The woman will press the button for the floor she wants to go to\n4. What could hinder this situation? The woman wants to take the stairs to\nbe healthy 5. Is she alone? She may or may not be\nalone, since there could be other people in the elevator.\n6. What does the woman see in the elevator? Buttons to different floors\n7. What does the woman feel? The woman could feel impatient at having to wait for an elevator\n8. As a consequence, what will happen? The woman will arrive at her desired floor\n9. What could prevent this from happening? The elevator is out of service\n10. Where are elevators located? Multistory buildings\nEmma has a big exam tomorrow. She got so stressed, she pulled an all-nighter. She went into class the next day,\nweary as can be. Her teacher stated that the test is postponed for next week.\n1. How does Emma feel about this? Emma is probably relieved\n2. Why might Emma be frustrated? Emma could be frustrated because she stayed up all night studying for nothing\n3. What is the consequence of the situation? Emma will have more time to study\n4. What is the prerequisite for this situation? Emma needed to have a big exam\n5. Tell me what Emma will do next. Emma will probably go home and sleep.\n6. What did Emma do before this? Emma was studying for her exam\n7. Why did the teacher postpone the exam ? The teacher may have postponed the exam because not everyone was ready.\n8. What is an attribute of Emma? Emma is a procrastinator.\n9. What is an attribute of Emma's teacher? flexible\n10. What is the counterfactual of the situation? If Emma didn't have a big exam, she wouldn't have pulled an\nall-nighter.\nKaren was assigned a roommate her first year of college. Her roommate asked her to go to a nearby city for a concert. Karen agreed happily. The show was absolutely exhilarating.\n1. What's something we can infer about Karen? Karen likes music\n2. What will happen because of this? Karen and her roommate will be better friends\n3. How might this have been prevented? If Karen's roommate was shy, she might not have asked Karen to go to a concert\n4. How old is Karen? Young adult 5. Why did Karen agree happily? Karen\nwanted to get to know her roommate better, make friends, and enjoy a concert\n6. How did Karen and her roommate get to the concert? By car or public\ntransportation 7. What's a potential consequence of\nthis situation? Karen might have fun and meet new people\n8. How does Karen feel? Karen is pleased 9. What does Karen's roommate think of\nher? The roommate thinks Karen is cool\n10. When is the concert? The concert is likely at night\nIvette misplaced her phone at her grandparents.\n1. What did Ivette do before this? Ivette was at her grandparents\n2. How does Ivette feel? Ivette feels frustrated\n3. What will Ivette do next? Ivette will look for her phone\n4. What could hinder this situation? If Ivette was more careful\n5. Ivette is what? Young 6. What would make this situation harder\nfor Ivette? Her phone is turned off.\n7. Where might her phone be? Ivette's phone could be in the house, outside , or in the car.\n8. Did Ivette mean to lose her phone? No 9. What is a consequence of the\nsituation? Ivette will have to buy a new phone\n10. What would remedy the situation? Finding Ivette's phone\nPersonX takes PersonY back to the hospital\n1. Why did PersonX take PersonY back to the hospital? PersonY was not feeling well\n2. What happened before this? PersonY was discharged from the hospital\n3. What is PersonX and PersonY's relationship to eachother? They are either friends or family.\n4. What would make this hard? PersonX doesn't have a car.\n5. Next, what will happen? PersonY will receive medical care.\n6. What happened before? PersonY asked PersonX to take them to the hospital.\n7. What is PersonX? PersonX is kind 8. What is PersonY? PersonY is sick 9. Where are they? They are in a car 10. What is a result? PersonY will get\nbetter\nMila and her family lived in Florida. They heard a hurricane was coming. They decided to evacuate to a relative's house. They arrived and learned from the news that it was a terrible storm.\n1. What will happen now? They will wait out the storm.\n2. How does Mila feel? She is probably relieved to be out of the hurricane' s path.\n3. What would have happened if Mila and her family had not evacuated? They would have been in the storm.\n4. Why did they decide to evacuate to a relative's house? They wanted to be in a safe place.\n5. Mila's family is what? Responsible\n6. What might have prevented them from fleeing? If they had not heard about the hurricane, or if they had no\nway to get to a relative's house. 7. They would not have fled if they were\nnot what? Cautious 8. Where does their relative live?\nSomewhere safe from the hurricane. 9. Should they have fled even if the\nstorm hadn't been bad? Yes, because they might have not been able to leave if the hurricane got worse.\n10. How could you describe their relative? Kind\nAlegra coyly smiled at the boy as he walked in.\n1. Why did Alegra smile at the boy? Alegra was interested in him.\n2. What will the boy do? The boy will notice Alegra.\n3. What is Alegra's relationship to the boy? They are strangers.\n4. What will happen if Alegra keeps smiling at the boy? The boy might talk to her.\n5. If the boy doesn't talk to her, how will Alegra feel? Alegra will feel awkward.\n6. What is the difference between a coy smile and a regular smile? A coy smile is more flirtatious.\n7. How could Alegra be described? Confident\n8. Where is this probably located? In a public place\n9. Alegra is probably what age? A teenager or young adult\n10. What would prevent this from happening? Alegra is scared to put herself out there\nPersonX crosses the road 1. What is PersonX? A pedestrian 2. What could prevent this from\nhappening? This could be prevented if there was no crosswalk.\n3. What is a prerequisite for this event ? A prerequisite for this event is that PersonX wants to cross the road.\n4. What is something that could happen? PersonX gets hit by a car\n5. If this didn't happen, what would happen? If this didn't happen, PersonX would not get to where they need to go.\n6. What actors might be in this situation? PersonX, drivers, other pedestrians\n7. What might PersonX be thinking? PersonX might be thinking that they need to get to the other side of the road.\n8. What could be true to make PersonX reckless? PersonX crosses when there are lots of cars and no crosswalk\n9. What could be true to make PersonX cautious? PersonX waits carefully for the walk signal and looks both ways.\n10. What do people do before crossing the road? People might look both ways to check for cars.\nHonor decides whether to bike or walk to school.\n1. In what situation would Honor choose to walk to school? It is raining outside.\n2. What is Honor? a student 3. How could Honor be described? Unsure 4. What would make this improbable?\nHonor lives very far away from the school.\n5. Why might Honor choose to bike over walk? It is faster.\n6. What will happen if Honor can't make up his mind? Honor will be late for school.\n7. What is a possible reason for why Honor can't decide? He is feeling lazier today.\n8. Either way, Honor will what? Get exercise\n9. What is the difference between biking and walking? Biking is faster but\nrequires more effort. 10. What is the weather? It might be\nsunny.\nB.4 Without queries\nList ten (10) commonsense facts about each situation. Some examples may include potential consequences, explanations, prerequisites or reactions. The commonsense facts may be about actors, actions, events,\nor ideas in the passage. The outputs could also include counterfactuals\nor things that could hinder the event from happening. The examples should be high-quality and things that are true.\nPersonX crosses the road 1. PersonX is probably going to the\nother side 2. Cars are on the road 3. Before this can happen, PersonX looks\nboth ways to make sure it's safe 4. PersonX probably has a destination 5. PersonX is probably walking 6. This wouldn't happen if there wasn't\na crosswalk 7. After, PersonX will be on the other\nside 8. If PersonX is jaywalking, they might\nget hit by a car 9. PersonX might use a crosswalk signal 10. This couldn't happen if the person\nwasn't near a road\nA robber steals from a bank. 1. The robber is probably armed 2. The robber probably has a getaway car 3. The bank teller is probably scared 4. This is illegal 5. The robber could go to jail 6. The bank might have a security system 7. The robber probably planned this in\nadvance 8. After, the robber will have the money 9. Before this happens, the robber tells\nthe bank teller to give them the money\n10. The robber might wear a mask\nAddilyn and her family lived in Florida. They heard a hurricane was coming.\nThey decided to evacuate to a relative's house. They arrived and learned from the news that it was a\nterrible storm. 1. They may have left valuables behind 2. They may come back to a destroyed\nhouse 3. They were smart to evacuate 4. If they didn't evacuate, they might\nhave died 5. The hurricane was very bad 6. Now, they will wait out the storm 7. They went to their relatives house\nbecause they wanted to be in a safe place\n8. They wouldn't have fled if they had not heard about the hurricane\n9. The relative lives somewhere safe from the hurricane\n10. Their relative is kind for letting them stay over\nFatima was assigned a roommate her first year of college. Her roommate asked her to go to a nearby city for a\nconcert. Fatima agreed happily. The show was absolutely exhilarating.\n1. Fatima has a roommate 2. Fatima likes music 3. As a result, Fatima and her roommate\nwill be better friends 4. Fatima enjoyed the concert 5. In the future, Fatima may want to go\nto more concerts 6. Fatima may be more likely to spend\ntime with her roommate 7. Fatima's roommate is considerate 8. Fatima's roommate is probably also a\nstudent 9. The roommate thinks that Fatima is\ncool 10. They got to the concert using a car\nor public transportation\nLoretta misplaced her phone at her grandparents.\n1. As a result, Loretta may be stressed. 2. Loretta may have to buy a new phone. 3. This event may have ruined Loretta's\nweekend. 4. This wouldn't happen if Loretta was\nmore careful. 5.. Now, Loretta will probably look for\nher phone.\n6. It will be expensive to replace her phone if it is lost.\n7. Loretta is young. 8. This situation would be worse if\nLoretta's phone was turned off. 9. Things could be better if Loretta\nfinds her phone 10. Loretta did not mean to lose her\nphone\nSAN FRANCISCO - Charlotte's husband, Maxwell, was violently assaulted by a man who broke into the couple's home in San Francisco early Friday morning, the police said. The authorities identified the suspect as Lozen, 42, and said they were investigating a possible motive.\n1. Lozen could be mentally ill 2. Maxwell was likely asleep when the\nattack happened 3. Lozen is either in custody or being\nsearched for by the police 4. The breaking and entering was likely\nplanned 5. Charlotte was probably not attacked 6. This would have been a frightening\nexperience for Charlotte and Maxwell 7. If Lozen is caught, he will likely go\nto jail 8. Lozen's motive might have been\npersonal 9. This wouldn't have happened if Lozen\nwere not violent 10. Home invasions are usually\npremeditated\nThe woman enters the elevator 1. Before, the woman pushed the button\nfor the elevator 2. The woman is going to a different\nfloor 3. After, the woman will push the button\nfor her floor 4. Then, she will press the button for\nher desired floor 5. First, the woman will wait for other\npeople to walk out of the elevator 6. The woman might have been impatient\nif she had to wait for a long time 7. This couldn't happen if the elevator\nwere out of service 8. The woman would not have done this if\nshe wanted to take the stairs to be healthy\n9. The woman may have been in a hurry 10. She is in a multi-story building\nPersonX takes PersonY back to the hospital.\n1. PersonY has been to the hospital before\n2. The goal of PersonX was to help PersonY\n3. Before this can happen, PersonY must ask PersonX to take them to the hospital\n4. PersonY hopes to get medical care 5. PersonY may have been injured before\nthis 6. This couldn't happen if PersonX does\nnot have a car 7. PersonY is sick in some way 8. Going to the hospital may be\nexpensive 9. This probably wouldn't happen if\nPersonY wasn't sick 10. PersonX cares about PersonY\nMichaela has a big exam tomorrow. She got so stressed, she pulled an allnighter. She went into class the next day, weary as can be. Her teacher stated that the test is postponed for next week.\n1. Michaela is relieved that she doesn't have to take the test today\n2. Michaela is sad because she worked hard to prepare and in the end didn' t have to\n3. When Michaela stayed up all night she was studying\n4. The teacher probably postponed the exam because not everyone was ready.\n5. Next week, Michaela will have to study again\n6. Michaela may do better on the exam next week because she will have more time to prepare\n7. If the exam was today, Michaela would have done poorly\n8. The test is in a subject that\nMichaela is struggling in 9. Michaela is a procrastinator 10. If Michaela hadn't stayed up all\nnight, she would not be tired\nKeanu decides whether to bike or walk to school.\n1. Keanu might not choose to bike if it' s raining outside\n2. Keanu is a student 3. They are unsure 4. If Keanu doesn't make up their mind,\nKeanu will be late for school 5. This is because Keanu is feeling lazy\ntoday 6. Either way, Keanu will get exercise 7. Biking is faster than walking but\nrequires more effort 8. This wouldn't happen if Keanu were\nmore decisive 9. This would be hard if Keanu lived\nvery far away from the school 10. Keanu might choose to bike if it's a\nnice day outside\nC MTurk Templates"
        }
    ],
    "title": "NovaCOMET: Open Commonsense Foundation Models with Symbolic Knowledge Distillation",
    "year": 2023
}