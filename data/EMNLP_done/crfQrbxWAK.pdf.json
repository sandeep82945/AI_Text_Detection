{
    "abstractText": "Conventional Knowledge Graph Construction (KGC) approaches typically follow the static information extraction paradigm with a closed set of pre-defined schema. As a result, such approaches fall short when applied to dynamic scenarios or domains, whereas a new type of knowledge emerges. This necessitates a system that can handle evolving schema automatically to extract information for KGC. To address this need, we propose a new task called schema-adaptable KGC, which aims to continually extract entity, relation, and event based on a dynamically changing schema graph without re-training. We first split and convert existing datasets based on three principles to build a benchmark, i.e., horizontal schema expansion, vertical schema expansion, and hybrid schema expansion; then investigate the schemaadaptable performance of several well-known approaches such as Text2Event, TANL, UIE and GPT-3.5. We further propose a simple yet effective baseline dubbed ADAKGC, which contains schema-enriched prefix instructor and schema-conditioned dynamic decoding to better handle evolving schema. Comprehensive experimental results illustrate that ADAKGC can outperform baselines but still have room for improvement. We hope the proposed work can deliver benefits to the community1.",
    "authors": [
        {
            "affiliations": [],
            "name": "Hongbin Ye"
        },
        {
            "affiliations": [],
            "name": "Honghao Gui"
        },
        {
            "affiliations": [],
            "name": "Xin Xu"
        },
        {
            "affiliations": [],
            "name": "Xi Chen"
        },
        {
            "affiliations": [],
            "name": "Huajun Chen"
        },
        {
            "affiliations": [],
            "name": "Ningyu Zhang"
        }
    ],
    "id": "SP:ff04b014e4f3c89a76affb4dcc357e54b1a34471",
    "references": [
        {
            "authors": [
                "Rahaf Aljundi",
                "Francesca Babiloni",
                "Mohamed Elhoseiny",
                "Marcus Rohrbach",
                "Tinne Tuytelaars."
            ],
            "title": "Memory aware synapses: Learning what (not) to forget",
            "venue": "Computer Vision - ECCV 2018 - 15th European Conference, Munich, Germany, September",
            "year": 2018
        },
        {
            "authors": [
                "Collin F. Baker",
                "Hiroaki Sato."
            ],
            "title": "The framenet data and software",
            "venue": "ACL 2003, 41st Annual Meeting of the Association for Computational Linguistics, Companion Volume to the Proceedings, 7-12 July 2003, Sapporo Convention Center, Sapporo, Japan,",
            "year": 2003
        },
        {
            "authors": [
                "Pengfei Cao",
                "Yubo Chen",
                "Jun Zhao",
                "Taifeng Wang."
            ],
            "title": "Incremental event detection via knowledge consolidation networks",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November",
            "year": 2020
        },
        {
            "authors": [
                "Xiang Chen",
                "Lei Li",
                "Ningyu Zhang",
                "Chuanqi Tan",
                "Fei Huang",
                "Luo Si",
                "Huajun Chen."
            ],
            "title": "Relation extraction as open-book examination: Retrievalenhanced prompt tuning",
            "venue": "SIGIR \u201922: The 45th International ACM SIGIR Conference on Research",
            "year": 2022
        },
        {
            "authors": [
                "Huajun Chen"
            ],
            "title": "2022b. Knowprompt: Knowledge",
            "year": 2022
        },
        {
            "authors": [
                "Martha Palmer"
            ],
            "title": "A large-scale classification",
            "year": 2008
        },
        {
            "authors": [
                "Minqian Liu",
                "Shiyu Chang",
                "Lifu Huang."
            ],
            "title": "Incremental prompting: Episodic memory prompt for lifelong event detection",
            "venue": "CoRR, abs/2204.07275.",
            "year": 2022
        },
        {
            "authors": [
                "David Lopez-Paz",
                "Marc\u2019Aurelio Ranzato"
            ],
            "title": "Gradient episodic memory for continual learning",
            "venue": "In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems",
            "year": 2017
        },
        {
            "authors": [
                "Jie Lou",
                "Yaojie Lu",
                "Dai Dai",
                "Wei Jia",
                "Hongyu Lin",
                "Xianpei Han",
                "Le Sun",
                "Hua Wu."
            ],
            "title": "Universal information extraction as unified semantic matching",
            "venue": "CoRR, abs/2301.03282.",
            "year": 2023
        },
        {
            "authors": [
                "Yaojie Lu",
                "Hongyu Lin",
                "Jin Xu",
                "Xianpei Han",
                "Jialong Tang",
                "Annan Li",
                "Le Sun",
                "Meng Liao",
                "Shaoyi Chen."
            ],
            "title": "Text2event: Controllable sequence-tostructure generation for end-to-end event extraction",
            "venue": "Proceedings of the 59th Annual Meeting of the",
            "year": 2021
        },
        {
            "authors": [
                "Yaojie Lu",
                "Qing Liu",
                "Dai Dai",
                "Xinyan Xiao",
                "Hongyu Lin",
                "Xianpei Han",
                "Le Sun",
                "Hua Wu."
            ],
            "title": "Unified structure generation for universal information extraction",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics",
            "year": 2022
        },
        {
            "authors": [
                "Arun Mallya",
                "Svetlana Lazebnik."
            ],
            "title": "Packnet: Adding multiple tasks to a single network by iterative pruning",
            "venue": "2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018, pages 7765\u2013",
            "year": 2018
        },
        {
            "authors": [
                "Natawut Monaikul",
                "Giuseppe Castellucci",
                "Simone Filice",
                "Oleg Rokhlenko."
            ],
            "title": "Continual learning for named entity recognition",
            "venue": "Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications",
            "year": 2021
        },
        {
            "authors": [
                "Ii. I Ntroduction"
            ],
            "title": "The ace 2005 ( ace 05 ) evaluation plan evaluation of the detection and recognition of ace entities",
            "year": 2005
        },
        {
            "authors": [
                "der",
                "Paul F. Christiano",
                "Jan Leike",
                "Ryan Lowe"
            ],
            "title": "Training language models to follow instructions with human feedback",
            "venue": "NeurIPS",
            "year": 2022
        },
        {
            "authors": [
                "Martha Palmer",
                "Paul R. Kingsbury",
                "Daniel Gildea."
            ],
            "title": "The proposition bank: An annotated corpus of semantic roles",
            "venue": "Comput. Linguistics, 31(1):71\u2013106.",
            "year": 2005
        },
        {
            "authors": [
                "Giovanni Paolini",
                "Ben Athiwaratkun",
                "Jason Krone",
                "Jie Ma",
                "Alessandro Achille",
                "Rishita Anubhai",
                "C\u00edcero Nogueira dos Santos",
                "Bing Xiang",
                "Stefano Soatto."
            ],
            "title": "Structured prediction as translation between augmented natural languages",
            "venue": "9th",
            "year": 2021
        },
        {
            "authors": [
                "Adam Paszke",
                "Sam Gross",
                "Soumith Chintala",
                "Gregory Chanan",
                "Edward Yang",
                "Zachary DeVito",
                "Zeming Lin",
                "Alban Desmaison",
                "Luca Antiga",
                "Adam Lerer"
            ],
            "title": "Automatic differentiation in pytorch",
            "year": 2017
        },
        {
            "authors": [
                "Sameer S. Pradhan",
                "Eduard H. Hovy",
                "Mitchell P. Marcus",
                "Martha Palmer",
                "Lance A. Ramshaw",
                "Ralph M. Weischedel."
            ],
            "title": "Ontonotes: A unified relational semantic representation",
            "venue": "Proceedings of the First IEEE International Conference on Se-",
            "year": 2007
        },
        {
            "authors": [
                "Shuofei Qiao",
                "Yixin Ou",
                "Ningyu Zhang",
                "Xiang Chen",
                "Yunzhi Yao",
                "Shumin Deng",
                "Chuanqi Tan",
                "Fei Huang",
                "Huajun Chen."
            ],
            "title": "Reasoning with language model prompting: A survey",
            "venue": "ACL. The Association for Computational Linguistics.",
            "year": 2023
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J. Liu."
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "J. Mach. Learn. Res., 21:140:1\u2013140:67.",
            "year": 2020
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J. Liu."
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "Journal of Machine Learning Research,",
            "year": 2020
        },
        {
            "authors": [
                "Alan Ramponi",
                "Rob van der Goot",
                "Rosario Lombardo",
                "Barbara Plank."
            ],
            "title": "Biomedical event extraction as sequence labeling",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November",
            "year": 2020
        },
        {
            "authors": [
                "Sebastian Riedel",
                "Limin Yao",
                "Andrew McCallum."
            ],
            "title": "Modeling relations and their mentions without labeled text",
            "venue": "Machine Learning and Knowledge Discovery in Databases, European Conference,",
            "year": 2010
        },
        {
            "authors": [
                "Sebastian Riedel",
                "Limin Yao",
                "Andrew McCallum."
            ],
            "title": "Modeling relations and their mentions without labeled text",
            "venue": "Machine Learning and Knowledge Discovery in Databases, pages 148\u2013163, Berlin, Heidelberg. Springer Berlin Heidelberg.",
            "year": 2010
        },
        {
            "authors": [
                "Apoorv Saxena",
                "Aditay Tripathi",
                "Partha P. Talukdar."
            ],
            "title": "Improving multi-hop question answering over knowledge graphs using knowledge base embeddings",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL",
            "year": 2020
        },
        {
            "authors": [
                "Timo Schick",
                "Hinrich Sch\u00fctze."
            ],
            "title": "Exploiting cloze-questions for few-shot text classification and natural language inference",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Vol-",
            "year": 2021
        },
        {
            "authors": [
                "Chao Shang",
                "Guangtao Wang",
                "Peng Qi",
                "Jing Huang."
            ],
            "title": "Improving time sensitivity for question answering over temporal knowledge graphs",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
            "year": 2022
        },
        {
            "authors": [
                "Hangjie Shen",
                "Shenggen Ju",
                "Jieping Sun",
                "Run Chen",
                "Yuezhong Liu."
            ],
            "title": "Efficient lifelong relation extraction with dynamic regularization",
            "venue": "Natural Language Processing and Chinese Computing - 9th CCF International Conference, NLPCC 2020, Zhengzhou,",
            "year": 2020
        },
        {
            "authors": [
                "Hanul Shin",
                "Jung Kwon Lee",
                "Jaehong Kim",
                "Jiwon Kim."
            ],
            "title": "Continual learning with deep generative replay",
            "venue": "Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9,",
            "year": 2017
        },
        {
            "authors": [
                "Sebastian Thrun."
            ],
            "title": "Lifelong learning algorithms",
            "venue": "Sebastian Thrun and Lorien Y. Pratt, editors, Learning to Learn, pages 181\u2013209. Springer.",
            "year": 1998
        },
        {
            "authors": [
                "Hong Wang",
                "Wenhan Xiong",
                "Mo Yu",
                "Xiaoxiao Guo",
                "Shiyu Chang",
                "William Yang Wang."
            ],
            "title": "Sentence embedding alignment for lifelong relation extraction",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Rui Wang",
                "Tong Yu",
                "Handong Zhao",
                "Sungchul Kim",
                "Subrata Mitra",
                "Ruiyi Zhang",
                "Ricardo Henao."
            ],
            "title": "Few-shot class-incremental learning for named entity recognition",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Com-",
            "year": 2022
        },
        {
            "authors": [
                "Xin Wang",
                "Minlong Peng",
                "Mingming Sun",
                "Ping Li."
            ],
            "title": "Oie@oia: an adaptable and efficient open information extraction framework",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
            "year": 2022
        },
        {
            "authors": [
                "Xinyu Wang",
                "Yong Jiang",
                "Nguyen Bach",
                "Tao Wang",
                "Zhongqiang Huang",
                "Fei Huang",
                "Kewei Tu."
            ],
            "title": "Automated concatenation of embeddings for structured prediction",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Lin-",
            "year": 2021
        },
        {
            "authors": [
                "Yunzhi Yao",
                "Shengyu Mao",
                "Xiang Chen",
                "Ningyu Zhang",
                "Shumin Deng",
                "Huajun Chen."
            ],
            "title": "Schema-aware reference as prompt improves dataefficient relational triple and event extraction",
            "venue": "CoRR, abs/2210.10709.",
            "year": 2022
        },
        {
            "authors": [
                "Michihiro Yasunaga",
                "Hongyu Ren",
                "Antoine Bosselut",
                "Percy Liang",
                "Jure Leskovec."
            ],
            "title": "QA-GNN: reasoning with language models and knowledge graphs for question answering",
            "venue": "Proceedings of the 2021 Conference of the North American Chap-",
            "year": 2021
        },
        {
            "authors": [
                "Hongbin Ye",
                "Ningyu Zhang",
                "Shumin Deng",
                "Mosha Chen",
                "Chuanqi Tan",
                "Fei Huang",
                "Huajun Chen."
            ],
            "title": "Contrastive triple extraction with generative transformer",
            "venue": "Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third",
            "year": 2021
        },
        {
            "authors": [
                "Jaehong Yoon",
                "Eunho Yang",
                "Jeongtae Lee",
                "Sung Ju Hwang."
            ],
            "title": "Lifelong learning with dynamically expandable networks",
            "venue": "6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Confer-",
            "year": 2018
        },
        {
            "authors": [
                "Pengfei Yu",
                "Heng Ji",
                "Prem Natarajan."
            ],
            "title": "Lifelong event detection with knowledge transfer",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Repub-",
            "year": 2021
        },
        {
            "authors": [
                "Friedemann Zenke",
                "Ben Poole",
                "Surya Ganguli."
            ],
            "title": "Continual learning through synaptic intelligence",
            "venue": "Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, volume 70 of",
            "year": 2017
        },
        {
            "authors": [
                "Junlang Zhan",
                "Hai Zhao."
            ],
            "title": "Span model for open information extraction on accurate corpus",
            "venue": "The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI",
            "year": 2020
        },
        {
            "authors": [
                "Jing Zhang",
                "Xiaokang Zhang",
                "Jifan Yu",
                "Jian Tang",
                "Jie Tang",
                "Cuiping Li",
                "Hong Chen."
            ],
            "title": "Subgraph retrieval enhanced model for multi-hop knowledge base question answering",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational",
            "year": 2022
        },
        {
            "authors": [
                "Minhao Zhang",
                "Ruoyu Zhang",
                "Yanzeng Li",
                "Lei Zou."
            ],
            "title": "Crake: Causal-enhanced table-filler for question answering over large scale knowledge base",
            "venue": "Findings of the Association for Computational Linguistics: NAACL 2022, Seattle, WA, United States,",
            "year": 2022
        },
        {
            "authors": [
                "Ningyu Zhang",
                "Shumin Deng",
                "Zhanlin Sun",
                "Jiaoyan Chen",
                "Wei Zhang",
                "Huajun Chen."
            ],
            "title": "Relation adversarial network for low resource knowledge graph completion",
            "venue": "WWW \u201920: The Web Conference 2020, Taipei, Taiwan, April 20-24, 2020, pages",
            "year": 2020
        },
        {
            "authors": [
                "Ningyu Zhang",
                "Xin Xie",
                "Xiang Chen",
                "Shumin Deng",
                "Hongbin Ye",
                "Huajun Chen"
            ],
            "title": "Knowledge collaborative fine-tuning for low-resource knowledge",
            "year": 2022
        },
        {
            "authors": [
                "Xikun Zhang",
                "Antoine Bosselut",
                "Michihiro Yasunaga",
                "Hongyu Ren",
                "Percy Liang",
                "Christopher D. Manning",
                "Jure Leskovec."
            ],
            "title": "Greaselm: Graph reasoning enhanced language models for question answering",
            "venue": "ArXiv, abs/2201.08860.",
            "year": 2022
        },
        {
            "authors": [
                "Hengyi Zheng",
                "Rui Wen",
                "Xi Chen",
                "Yifan Yang",
                "Yunyan Zhang",
                "Ziheng Zhang",
                "Ningyu Zhang",
                "Bin Qin",
                "Xu Ming",
                "Yefeng Zheng."
            ],
            "title": "PRGC: potential relation and global correspondence based joint relational triple extraction",
            "venue": "Proceedings of the 59th",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Knowledge Graph Construction (KGC), typically through information extraction, has enjoyed widespread empirical success and can provide backend support for various NLP tasks, such as question answering (Saxena et al., 2020; Shang et al., 2022; Zhang et al., 2022a), commonsense reasoning (Yasunaga et al., 2021; Zhang et al., 2022d) etc. Traditional KGC tasks, including named entity recognition (NER) (Liu et al., 2021; Wang et al., 2021),\n\u2217 Corresponding author. 1Code and datasets available at https://github.com/\nzjunlp/AdaKGC.\nrelation extraction (RE) (Chen et al., 2022a; Zheng et al., 2021; Yao et al., 2022) and event extraction (EE) (Huang et al., 2018; Liu et al., 2020; Lu et al., 2021; Lou et al., 2023) are \u201creactive\u201d, relying on static pre-defined schema from end-users. However, as shown in Figure 1, the schema may evolve along with scenario adaptation, making previous models challenging to utilize without re-training.\nNote that existing information extraction systems can only handle a fixed number of classes by pre-defined schema and performing once-and-forall training on a fixed framework. It is desirable to respond to changes (e.g., evolving schema) to existing KGs, making the system act more \u201cproactively\u201d like humans who can handle flexible knowledge updates. Early, several approaches introduce incremental learning (Cao et al., 2020; Wang et al., 2019; Shen et al., 2020; Cui et al., 2021b) to learn new classes continually. In this case, the extraction system learns from the class incremental data stream but usually suffers significant performance degradation on the old class when adapting to the new class. Stated differently, previous studies put emphasis on struggling against catastrophic forgetting (Thrun, 1998). However, for the schemaevolving scenarios, the dynamic generalizability of extraction models plays a vital role and needs to be\ninspected from an ontology evolution perspective. Therefore, we propose a novel KGC task dubbed schema-adaptable KGC, where the models are required to have the ability to represent and adapt to complement knowledge extraction. We first construct datasets according to three principles of evolutionary schema directions (Horizontal Schema Expansion, Vertical Schema Expansion, and Hybrid Schema Expansion) on three tasks of NER, RE2, and EE. Through empirical analysis, we notice that approaches of Text2Event (Lu et al., 2021), TANL (Paolini et al., 2021), UIE (Lu et al., 2022), and GPT-3.5(Ouyang et al., 2022) cannot effectively extract the information given complex evolving schema. We argue that the major issues lie in the following: 1) How to learn dynamic and generalizable schema representations as conditions for extraction; 2) How to precisely extract new instances constrained with newly updated schema.\nTo this end, we propose a simple baseline dubbed ADAKGC, which introduces Schemaenriched Prefix Instructors (SPI) to represent and transfer the learnable schema-specific knowledge. At each iteration stage, we linearly convert from the current schema graph to learnable prompts, initialized with the ontology name and connected to taskspecific prefixes. To encourage the decoder to understand the dynamic schema, we utilize a Schemaconditioned Dynamic Decoding (SDD) strategy that constructs a decoding path of schema-specific vocabulary to the output space. When the schema changes, we dynamically construct a new trie-tree to adjust the output space. Note that ADAKGC is model agnostic and can handle a variety of challenging schema evolution scenarios. We summarize the contribution of this work as:\n\u2022 We introduce a new task of the schemaadaptable KGC to meet the schema evolution requirements, which is a new branch that has not been well-explored to the best of our knowledge.\n\u2022 We propose a new baseline ADAKGC, which includes schema-enriched prefix instructors and schema-conditioned dynamic decoding strategy, and experimentally demonstrate the adaptability.\n\u2022 We release the schema-adaptable KGC benchmark, which imposes new challenges and\n2We regard RE as relational triple extraction in this paper.\npresents new research opportunities for the NLP community."
        },
        {
            "heading": "2 Problem Statement and Overview",
            "text": ""
        },
        {
            "heading": "2.1 Background of KGC",
            "text": "KGC has been a promising research challenge (Lu et al., 2022; Zhang et al., 2022b), and existing benchmarks utilize a well-defined schema for directing knowledge graph construction, focusing on generating domain-specific knowledge graphs or aggregating heterogeneous structured databases. For example, FEW-NERD (Ding et al., 2021) consists of coarse-grained and fine-grained entity type definitions to locate and classify named entities from unstructured natural language. NYT (Riedel et al., 2010a) extracts relational triple instances specifically from textual data sources according to a specific taxonomy structure. ACE2005 (Ntroduction) identifies triggers and event types based on context, and each has its own event arguments, described in a slot-filling way. In addition, TAC-KBP (Ellis et al., 2014) is designed to leverage existing generic domain structured data sources and extend entity links employing descriptive text as additional information. OAEI (Euzenat et al., 2011) creates an integrated ontology based on an alignment between two or more existing ontologies or knowledge graphs. In this paper, we focus on the work of extracting knowledge instances from unstructured text, which is regarded as the schema-constraint prediction (structure prediction) task."
        },
        {
            "heading": "2.2 Definition of Schema-adaptable KGC",
            "text": "In the real world, the KGC system extracts structured knowledge from unstructured text and normalizes it to the instance graph according to a frequently adjusted schema. Given a set of schema graphs S = {s1, s2, ..., sn}, the task of schemaadaptable KGC is to generate a set of schemaconstraint instances G = {g1, g2, ..., gn} for each iteration. Suppose there is a model M\u03b8 = LM(D1train|S1) trained on the initial training set, after which labeled data for updated schema are not available. A schema-adaptable data stream{ D(1),D(2), . . . ,D(N) } is provided to evaluate the adaptability of model for the dynamic updates of schema. Each D(k) contains dev/test data( Dkdev,Dktest ) and schema graph sk. Note that the model will not be re-trained but hope to pick up on the ability of information extraction with evolving schema. The challenge is that the model is"
        },
        {
            "heading": "Input Text:",
            "text": "expected to perform well in each iteration of the test set Dktest, which contains the golden instances changed for the updated schema."
        },
        {
            "heading": "2.3 Dataset Construction Process",
            "text": "As shown in Figure 2, we design three principles regarding different types of schema evolution and apply Algorithm 1 to build the dataset for evaluation: (1) Horizontal Schema Expansion requires the schema to add new class nodes of the same level, which can be considered a form of classincremental learning without new classe instances as training data. Based on the generalization effect on the neighboring new classes, we can assess the transfer capabilities of the schema feature. (2) Vertical Schema Expansion requires the schema to add subclasses of father classes. Based on the generalization effect on subclasses, we can assess the inheritance and derivation capabilities of the schema feature. (3) Hybrid Schema Expansion requires the schema to randomly expands nodes horizontally or vertically at each iteration, which summarizes schema graphs and represents their potential co-evolutionary pattern. More details are in Appendix A.1, besides the above structural extensions, we further explore analogous node replacement from the perspective of semantics."
        },
        {
            "heading": "2.4 Schema-adaptable KGC Benchmark",
            "text": "There are two challenges for schema-adaptable KGC. Firstly, since the schema is updated in each iteration, the schema evolution information needs to be dynamically injected into the model. Secondly, since the output target of KGC is often demandspecific, the extraction results should be adaptively\nAlgorithm 1 Dataset Construction Process. Input: iteration N , raw schema Sraw, and raw dataset {Drawtrain,Drawdev ,Drawtest } Output: Schema SN ,{DNtrain,DNdev,DNtest}\n1: Randomly initialize ninit nodes in Sraw as S1 2: Pick out the instance associated with schema\nS as D(1) = {D1train,D1dev,D1test} 3: for iteration i = 2, . . . , n do 4: Horizontal Schema Expansion: Compute \u03d5neighbor(W\u20d7c, W\u20d7s) for candidate schema S 5: Vertical Schma Expansion: Select niter\nsub node whose father node belongs to S and update\n6: Hybrid Schema Expansion: Combine extension Steps 4 and 5 7: Ouput iteration i dataset schema Si = S, instance D(i) = {Didev,Ditest} 8: end for\nadjusted according to the schema. We detail several vanilla baselines as follows and introduce the proposed ADAKGC in \u00a73.\nVanilla Baselines: Schema-adaptable KGC can be thought of as a structured prediction language task that transfers information between class nodes through the generalizability of the structure. TANL (Paolini et al., 2021) introduces an augmented natural language translation task from which information related to the schema can be implicitly extracted. TEXT2EVENT (Lu et al., 2021) is a unified sequence-to-structure architecture for event extraction with a constrained decoding algorithm for event schema knowledge injection during in-\nference. UIE (Lu et al., 2022) is a unified text-tostructure generation framework that enables unified modeling of different IE tasks and adaptively generates target sequences by a schema-based prompting mechanism. GPT-3 (Brown et al., 2020), a largescale language model (LLM), can serve as a baseline for schema-adaptable KGC. Although current works focusing on structured extraction can achieve excellent performance with static types of knowledge, they are typically unaware of schema evolution. To clarify this issue, we introduce a simple yet effective baseline dubbed schema-ADAptive Knowledge Graph Construction ADAKGC."
        },
        {
            "heading": "3 The Proposed Baseline: ADAKGC",
            "text": ""
        },
        {
            "heading": "3.1 Overview",
            "text": "As shown in Figure 3, ADAKGC utilizes a pretrained encoder-decoder language model (LM) T5 (Raffel et al., 2020a) as the basic architecture for the schema-adaptable KGC task. Specifically, let encoder input Xen = [S;X] be the concatenation of schema S and input X . In the decoding process, the LM calculates the conditioned probability of generating a new token yt given the previous token y<t:\np(Yde | Xen) = |Y |\u220f t=1 p (yt | y<t, S,X) (1)\nWe initialize the model using the pre-trained parameter \u03b8. Here, p\u03b8 is a trainable language model distribution. In the k-th iteration, we perform a gradient update on the following log-likelihood objective:\nmax \u03b8\nlog p\u03b8(y | x; sk)\n= max \u03b8 \u2211 t\u2208Yindex log p\u03b8(ht | h<t) (2)\nwhere ht is the activation vector at decoding time step t. ht = [ h (1) t ; \u00b7 \u00b7 \u00b7 ;h (m) t ] is a concatenation of all activation layers, and h(j)t is the activation vector of the j-th layer at time step t."
        },
        {
            "heading": "3.2 Schema-enriched Prefix Instructor",
            "text": "Inspired by prefix-tuning (Li and Liang, 2021), we use task-specific prefix instructors to indicate task information, which are pairs of transformeractivated differentiable sequences {sien, side}, each containing p consecutive D-dim vectors for encoder and decoder. Since using a discrete natural language task instruction in the context (e.g., \"The schema used for the task is:\") may guide the LM to produce a sub-optimal generated sequence, we optimize the instructions as a continuous soft prompt, propagating upward to all transformer activation layers and rightward to subsequent tokens.\nDue to schema changes with iterations, we present schema-specific prefix instructors to instruct the encoding process. Specifically, we formalize the schema graph as linearized text. Assume given the constrained schema of RE task sk = {(h1, r1, t1), ...(hn, rn, tn)} and tpci = (hi, ri, ti) denotes the i-th triple prefix constraint. By concatenating these schema prefix constraints initialized by word embedding, spc can be dynamically adjusted as the schema evolves, and added padding tokens to be a fixed length when instructing the LM:\nspc = Concat (tpc1, . . . , tpcn, PAD) (3)\nThus, the schema-enriched prefix instructor provides a two-part prefix combination Z = {sien, spcc; side}, where \";\" separates the respective prefix instructors for encoder and decoder. We recursively activate the decoder transformer activation vector ht, which is the connection of all layers, at time step t in the LM.\nht = { sit, if t \u2264 p LM(yt, h<t | S,X) , otherwise (4)\nThe training parameters of our model contain the LM parameters \u03b8, the encoder-decoder task-specific prefix instructor{sien, side}, and the schema-specific constraint instructor spc. For stable optimization, we follow Li and Liang (2021) to reparameterize the matrix M\u03d5[t, :] = MLP\u03d5(M \u2032 \u03d5[t, :]) with a smaller matrix M \u2032 \u03d5 consisting of a large feedforward neural network MLP\u03d5, which can alleviate the optimization instability caused by directly updating the prefix parameters and is applied to {sien, side; spc}. We train the parameters of the model in the following steps: (1) First, freeze other parameters, fine-tune the prefix instructor {sien, side} to learn task-specific prompts; (2) Secondly, freeze {sien, side}, optimize the schema-specific instructor spc for the given schema graph; (3) Finally, we unfreeze the LM parameter \u03b8 and collaboratively optimize all parameters to capture the association between the prefix instructor and model parameters."
        },
        {
            "heading": "3.3 Schema-conditioned Dynamic Decoding",
            "text": "Previous works leverage a greedy decoding algorithm to generate linearized instance predictions token by token for the hidden sequence ht, which selects the token with the highest prediction probability p (yt | y<t, S,X) at each vanilla decoding step t. Unfortunately, when the schema changes, this decoding algorithm does not guarantee the generated instances are consistent with the latest schema. In other words, it may result in out-of-date or invalid types being generated due to the lack of labeled data fine-tuning the model to adapt the probability distribution to the current schema constraints. In addition, the greedy decoding algorithm neglects useful schema knowledge that can effectively guide the decoding process.\nIn the schema-conditioned decoding process, we apply a trie-based decoding mechanism that dynamically constructs a trie-tree by leveraging the latest schema. An intuitive interpretation is that the schema contains rich semantic information (e.g., instance types) and structural information (e.g., relational edges between instance types) so that the decoding process can be constrained to ensure that the generated token is valid. Specifically, we constrain the model to generate the type tokens consistently with the existing schema at the type location. We pursue the LM output to be a sequence of RE following pattern and optimized using the standard seq2seq objective function:\n[bos] . . . T (n)h , E (n) h ,R (n), T (n)t , E (n) t . . . [eos]\nwhere E(n)h , T (n) h , E (n) t , E (n) h refer to the n-th generated head entity, tail entity, and their respective types while R(n) refer to relation."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Experimental Settings",
            "text": "Datasets. We conduct experiments on KGC tasks, including NER, RE and EE. The used datasets includes FEW-NERD (Ding et al., 2021), NYT (Riedel et al., 2010b) and ACE2005 (Walker et al., 2006). In our work, we need to construct schema as well as golden validation/test sets dynamically. For each dataset, we build three types of evaluation settings based on \u00a72.3. Therefore for original datasets, we use a certain proportion of the schema as initialization to conduct schema expansion regarding three schema evolution categories in Appendix A.1. Evaluation. We use span-based Micro-F1 as the primary metric. Rel-S means that the relation is correct if the relation type is correct and the string and entity types of the related entity mentions are correct. For each iteration experiment, we report the average performance over 3 random seeds. UIE is implemented without pre-training by directly using T5-v1.1-base as the backbone for a fair comparison. More details are in Appendix A.2."
        },
        {
            "heading": "4.2 Main Results",
            "text": "We report empirical results regarding horizontal schema expansion, vertical schema expansion and hybrid schema expansion settings to compare our proposed methods with the baselines. The performance over all iterations during the whole schemaadaptable KGC process is presented in Table 1-3. From the results, we can observe that:\nSchema adaptive generalization challenge. On all three expansion categories, the model performances tend to decrease as the iterations increase. TANL achieves lower performance which employs an augmented language and implicitly trains the model to learn schema information. TEXT2EVENT utilizes schema as constraint information on the decoding side and outperforms other models in some iterations. Although ADAKGC and UIE obtain optimal or suboptimal performance, the performance of iteration 1 and iteration 7 has a significant drop. We believe that the implicit schema evolution rules can help future work to develop adaptive generalization capabilities for schema-adaptable KGC.\nSchema-enhanced modules boost the performances. Compared to other models, ADAKGC is improved with schema-enhanced modules on both the encoder and decoder, which allows it to achieve the best performance in most settings. On the ACE2005 hybrid schema expansion dataset,\nADAKGC improves 0.71% on trigger extraction and 3.65% on event argument extraction, indicating that ADAKGC can capture schema-specific information under evolutionary schema. LLMs can understand schema adaption patterns better. To explore the performance of LLMs (Qiao et al., 2023) on the proposed tasks, we per-\nform comparative experiments with GPT-3.5 on NYT. Since we cannot utilize all training instances, we report in-context learning performance given 20-shot demonstrations as shown in Appendix A.5. From Figure 4, we notice that GPT-3.5 is capable of producing instances that conform to the dynamically changing schema but still yield low performance due to the low-shot issue. Likewise, we sample several cases and use ChatGPT3 to evaluate schema-adaptable KGC (See Figure 7 and 8 in Appendix A.6), which surprisingly demonstrates stable generalization ability with evolving schema. These findings indicate a promising future work of schema-adaptable KGC to develop alignment prompts with LLMs."
        },
        {
            "heading": "4.3 Ablation Study on ADAKGC",
            "text": "To prove the effects of the schema-enriched prefix instructor and schema-conditioned dynamic decod-\n3https://openai.com/blog/chatgpt/\ning, we conduct the ablation study, and the results are shown in Figure 5. From two evolutionary categories, we observe that: (1) Both schema-enriched prefix instructor and schema-conditioned dynamic decoding can help the schema-adaptable learning process; (2) Efficiently encoding schema evolution information is more important, which achieves improvements of 0.77% on horizontal schema expansion and 0.36% on vertical schema expansion."
        },
        {
            "heading": "4.4 Case Study",
            "text": "As shown in Figure 6, we randomly select 8 types and observe that: (1) The types that appear in the initial schema mostly degrade performance, indicating that the model causes slight confusion as the schema expands. (2) Due to the structural inheritance relationship in the vertical expansion of the schema, our model can effectively transfer the labels of the father node to the child nodes when new child nodes are added.\nTo further analyze the drawbacks of our model\nand promote future works of schema-adaptable KGC, we count incorrect instances and classify them into five categories below, as shown in Table 4: (1) Weak Transfer. Despite schema expansion, the model is prevented from updating labels by old model parameters. (2) Inheritance Deficiency. The label is not inherited in time when subdividing the father node. (3) Relevance Neglect. The lack of ontology relevance leads to the absence of correlated event extraction. (4) Class Imbalance. Models suffering from unbalanced class learning problems tend to depend on similarly in-context sentences to judge high-frequency labels. (5) Potential Annotation. Some example outputs suggest potential errors or omitted annotation."
        },
        {
            "heading": "5 Related Work",
            "text": ""
        },
        {
            "heading": "5.1 Knowledge Graph Construction",
            "text": "Automatic construction of knowledge graphs from textual or structured data has attracted extensive research in recent years, including tasks such as NER (Paolini et al., 2021; Cui et al., 2021a), RE (Lin et al., 2020; Joshi et al., 2020; Ye et al., 2021), EE (Ramponi et al., 2020; Liu et al., 2020; Lu et al., 2021), etc. In contrast to closed-domain knowledge extraction, open knowledge extraction (Kolluru et al., 2020; Zhan and Zhao, 2020; Kotnis et al., 2022; Wang et al., 2022b) is oriented toward the absence of schema constraints and can quickly generate extensive and meaningful knowledge. However, the ignoring of schema introduces uncertainty and ambiguity in output control, and we believe that a clear setting can be chosen to track the realignment of instances. Besides, KGC in low-resource scenarios (Huang et al., 2018; Zhang et al., 2020; Schick and Sch\u00fctze, 2021; Chen et al., 2022b; Ye et al., 2022; Zhang et al., 2022c) requires the model to predict new instances with only lim-\nited training instances available. As opposed to this instance-driven KGC approach, we argue that the schema-driven approach can leverage evolutionary instructions provided with richer ontological associations, resulting in new challenges and research opportunities."
        },
        {
            "heading": "5.2 Lifelong Learning",
            "text": "Lifelong learning is aimed at training new classes online without catastrophic forgetting. Generally, lifelong learning mainly falls into four categories: regularization-based (Kirkpatrick et al., 2017; Zenke et al., 2017; Aljundi et al., 2018), replay-based (Lopez-Paz and Ranzato, 2017; Shin et al., 2017), architecture-based (Mallya and Lazebnik, 2018; Yoon et al., 2018) and knowledge distillation (Chuang et al., 2020; Cao et al., 2020). To study class-incremental learning, Monaikul et al. (2021) builds a unified NER classifier for all the classes encountered over time, while Wang et al. (2022a) develops a framework to reconstruct synthetic training data of the old classes. Recently, (Wang et al., 2019) proposes a lifelong RE method that employs an explicit alignment model to overcome forgetting, while (Shen et al., 2020) presents a self-adaptive dynamic regularization method. To address class incremental learning in event detection (Cao et al., 2020), Yu et al. (2021) takes advantage of rich correlations among ontology types, and Liu et al. (2022) adopts continuous prompts to learn event-specific representation for prediction. Compared with previous work that focused only on class increments, we discuss three principles of schema expansion from the potential demand for schema adaptation."
        },
        {
            "heading": "6 Conclusion",
            "text": "This paper introduces a new task of schemaadaptable KGC with benchmark datasets and a new baseline ADAKGC. We illustrate the task difficulties with previous baselines on three principles of schema expansion patterns (horizontal, vertical, hybrid) and demonstrate the effectiveness of the proposed ADAKGC."
        },
        {
            "heading": "Acknowledgment",
            "text": "We would like to express gratitude to the anonymous reviewers for their kind comments. This work was supported by the National Natural Science Foundation of China (No.62206246), Zhejiang Provincial Natural Science Foundation of China (No. LGG22F030011), Ningbo Natural Science Foundation (2021J190), Yongjiang Talent Introduction Programme (2021A-156-G), CCFBaidu Open Fund, and Information Technology Center and State Key Lab of CAD&CG, Zhejiang University."
        },
        {
            "heading": "Limitations",
            "text": "The proposed work still contains several limitations, as follows:\nDatasets: Note that several datasets, such as ACE2005, cannot be released due to LICENCE issues; we release the code to build the datasets and provide all the pre-processed publicly available datasets (e.g., Few-NERD, NYT) We use several existing datasets to construct schema-adaptable benchmarks; however, previous datasets may have limited schema structures (the schema pattern in some datasets is very simple). We plan to build more datasets via crowdsourcing for comprehensive evaluation. In addition, we will continue to promote the construction of multimodal schema adaptive graphs, which leverage the dynamic evolution of schema to integrate visual and textual knowledge into a self-learning graph extraction system.\nBaselines and Proposed ADAKGC: Note that the proposed one, although better than previous approaches, including Text2Event (Lu et al., 2021), TANL (Paolini et al., 2021), UIE (Lu et al., 2022), still suffers from poor generalization ability. However, we notice a very stable performance with LLM (though deficient performance), indicating a new promising solution for schema-adatable KGC."
        },
        {
            "heading": "Ethical Considerations",
            "text": "Intended use. The dataset and model in this paper are indented to be used for exploratory analysis of schema-adaptable KGC.\nBiases. We collect data from existing datasets (e.g., Few-NERD: CC BY-SA 4.0 license.), which may contain some data with offensive language or discriminatory."
        },
        {
            "heading": "A Appendix",
            "text": "This section describes the details of experiments, including dataset construction and evaluation on downstream tasks."
        },
        {
            "heading": "A.1 Dataset Construction",
            "text": ""
        },
        {
            "heading": "A.1.1 Construction Process",
            "text": "In each task, we execute three schema evolution strategies. The raw dataset statistics are shown in Table 5, where it can be seen that they have a two-level schema structure, leaving the research of a more hierarchical schema structure for future work. As shown in Algorithm 2-4, we describe in detail the specific construction process of horizontal schema extension, vertical schema extension and hybrid schema extension.\nIn particular, we also release additional datasets from a semantic substitution perspective. As shown in Algorithm 5, analogous schema expansion requires schema replacement for semantically similar new nodes. Based on the performance of the old class transfer to the new semantic class, we can evaluate the semantic invariance capability.\nHorizontal Schema Expansion. Neighboring nodes of the specified type that have high-level\nsimilarity values in the same framework are also adjacent when projected into the semantic space (Huang et al., 2018). Existing research efforts have developed many rich libraries of ontologies (e.g.FrameNet (Baker and Sato, 2003), VerbNet (Kipper et al., 2008), Propbank (Palmer et al., 2005), and OntoNotes (Pradhan et al., 2007)), where each ontology type is associated with a set of pre-defined neighboring ontologies. (1) Searching the ontology library to retrieve candidate nodes Wf associated with target nodes Ws at the same hierarchy. (2) The similarity metric is obtained by calculating the cosine vector similarity of all candidate nodes Wf to the target node Ws (Eq. 5). (3) Selecting the appropriate threshold of node pairs to confirm the sorted addition of horizontal nodes. (4) Updating the schema with horizontal nodes and adding the golden validation set and test set in the dataset.\n\u03d5Sim(W\u20d7f , W\u20d7s) =\n\u2211|Ws| i=1 wi \u00b7 wf\n\u2225W\u20d7f\u22252 \u00b7 \u2225W\u20d7s\u22252 (5)\nVertical Schema Expansion. Structural similarity needs to be exploited when adding schema hierarchy nodes as new classes. (1) For search convenience, we link the hypernym ontology under a root node so that the schema forms a tree structure. (2) Starting at the root node, we utilize a child selection strategy by recursively applying through the tree until reaching the deepest node. A node could be expandable when it represents a non-terminal state or has hyponyms in semantics (e.g., location->country). (3) According to the available hyponyms, one (or more) child nodes are added to expand the current schema tree. (4) Updating the schema with vertical nodes and adding the golden validation set and test set in the dataset. Hybrid Schema Expansion. It is necessary to hybrid horizontal and vertical expansion to form a comprehensive structural topology, which is more consistent with real scenarios. (1) Setting the threshold \u03b1 for random selection. (2) Executing horizontal expansion iteration below the threshold \u03b1, or vertical node expansion above the threshold \u03b1. Note that when the father node of added nodes does not exist, we also add the father node to maintain the schema hierarchy. (3) Updating the schema with the corresponding nodes and adding the golden validation set and test set in the dataset. Analogous Schema Expansion. To detect the semantic node sensitivity of the schema, we randomly\nreplace similar semantic expressions for the nodes. (1) Random selection of candidate nodes to obtain word expressions WC . (2) Candidate nodes are created by pairing WC with all words in the corpus word list WL. The consistency between individual words is calculated by the normalized point-bypoint mutual information (NPMI) of wi and wj (Eq. 6), where adding smooth \u03f5 and \u03b3 controls for log p (wi, wj) weights for higher NPMI values (Eq. 7). (3) Adopting candidate nodes that exceed the threshold to replace the schema and updating the golden validation set and test set in the dataset.\nv\u20d7(W ) =  \u2211 wi\u2208WC NMPI (wi, wj) \u03b3  j=1,...,|WL|\n(6)\nNMPI (wi, wj) \u03b3 =  log p(wi,wj)+\u03f5p(wi)\u00b7p(wj) \u2212 log p (wi, wj) + \u03f5 \u03b3 (7)"
        },
        {
            "heading": "A.1.2 Schema-adaptable Datasets Statistic",
            "text": "We set the number N of total iterations, and initialize the original number of schema nodes. We show the statistics of schema-adaptable datasets for each task in Table 6."
        },
        {
            "heading": "A.2 Evaluation",
            "text": "We use span-based Micro-F1 as the major metric to evaluate the model and adopt the same evaluation metrics as previous work:\n* Named Entity Recognition: an entity mention is correct if its strings and type match a reference entity.\n* Relation Strict: a relation is correct if its relation type is correct and the string and entity types of the related entity mentions are correct.\n* Event Trigger: an event trigger is correct if its strings and event type match a reference trigger.\n* Event Argument: an event argument is correct if its strings, role type, and event type match a reference argument mentioned."
        },
        {
            "heading": "A.3 Hyper-parameters",
            "text": "We adopt T5-v1.1-base (Raffel et al., 2020b), which has 12 layers of the encoder, 12 layers of the decoder, 768 hidden units, and 12 attention heads as the backbone. Specifically, we utilize Pytorch (Paszke et al., 2017) to conduct experiments with batch size 16 on one NVIDIA 3090 GPU. We detail the hyper-parameters for each dataset as follows:\nNERD. The hyper-parameter search space is:\n\u2022 epoch: 15\n\u2022 batch size: 16\n\u2022 accumulate: 1\n\u2022 learning rate: [1e-4, 3e-4, 5e-4]\n\u2022 warmup rate: 0.06\nNYT. The hyper-parameter search space is:\n\u2022 epoch: 20\n\u2022 batch size: 16\n\u2022 accumulate: 1\n\u2022 learning rate: [1e-4, 3e-4, 5e-4]\n\u2022 warmup rate: 0.06\nACE2005. The hyper-parameter search space is:\n\u2022 epoch: 30\n\u2022 batch size: 16\n\u2022 accumulate: 1\n\u2022 learning rate: [1e-4, 3e-4, 5e-4]\n\u2022 warmup rate: 0.06"
        },
        {
            "heading": "A.4 Analogous Schema Expansion Experiment",
            "text": "As shown in Figure 7, our ADAKGC also has powerful semantic transplantation capabilities, which achieves competitive performance with baselines. With the schema-enriched prefix instructor, ADAKGC achieves an improvement of 7.70% on average over TEXT2EVENT on the event trigger extraction task and 4.87% on the event argument extraction task. This verifies the proposed schemaenriched prefix instructor and decoding modules can learn general schema-adaptable ability even the schema evolution knowledge is rarely in the pretraining stage. Note that TANL achieves the best performance on the NYT dataset, indicating that language models have the ability to learn schema semantic transfer implicitly as an augmented natural language prediction task. Therefore we believe that in addition to the schema structure perception modules, semantic robustness modules for analogous node expansion scenarios are also essential."
        },
        {
            "heading": "A.5 GPT-3.5 Experiment Details",
            "text": "GPT-3.5 is a large autoregressive language model with 175 billion parameters. To explore the performance of GPT-3.5 on the schema-adaptive KGC task, we follow the input format of few-shot learning using OpenAI API4. As shown in Table 12, we utilize a fixed manual template to generate a contextual window suitable for the model, including natural language task descriptions (text in blue), linearized schemas (text in purple), 20 examples in the model\u2019s context, and task prompts (text in red)."
        },
        {
            "heading": "A.6 ChatGPT Results",
            "text": "ChatGPT5 trains an initial model using supervised fine-tuning and further utilizes reinforcement learning systems to rank by quality for human feedback rewards. We handle Schema-adaptable KGC tasks\n4https://platform.openai.com/docs/models/ gpt-3-5\n5https://chat.openai.com/chat\nAlgorithm 2 The construction process of horizontal schema expansion.\n1: Set sampling seed \u03b8, total iteration N , raw schema Sraw, and raw dataset {Drawtrain, Drawdev , Drawtest } 2: Initialize blank schema S, blank dataset {Dtrain, Ddev, Dtest} and initial node number ninit, node number niter per iteration 3: Randomly select ninit nodes in Sraw, S = S \u222a init node, S1 = S,Sraw = Sraw \u2212 S 4: Pick out the instance associated with S, {D1train, D1dev, D1test} = {Dtrain, Ddev, Dtest} 5: for iteration N do 6: Calculate \u03d5Sim(W\u20d7f , W\u20d7s) = \u2211|Ws| i=1 wi\u00b7wf\n\u2225W\u20d7f\u22252\u00b7\u2225W\u20d7s\u22252 for node between Sraw and S\n7: Pick out top niter schema node, S = S \u222a Sraw[: niter], Sraw = Sraw \u2212 Sraw[: niter] 8: Iteration i dataset Si = S,{Didev, Ditest} = {Ddev, Dtest} 9: end for\nby asking questions to the chatbot in a conversational mode. First, we present the task description and the 20 demonstrations as shown in Figure 7. Then we give a paragraph text to test whether the chatbot can extract the corresponding triples based on the same schema as the demonstration examples comply with. From Figure 8 we can find that some of the facts are well extracted, indicating that ChatGPT can understand the task and perform extraction consistent with the schema. Finally, we add three new nodes \u201cprofession\u201d \u201cplace founded\u201d \"founders\" to the previous schema under a horizontal schema expansion iteration. Output results in Figure 8 show that ChatGPT not only adapts the output to the updated schema but also deduces reasonable facts by a chain-of-thought approach.\nAlgorithm 3 The construction process of vertical schema expansion.\n1: Set sampling seed \u03b8, total iteration N , raw schema Sraw, and raw dataset {Drawtrain, Drawdev , Drawtest } 2: Initialize blank schema S, blank dataset {Dtrain, Ddev, Dtest} and initial node number ninit, node number niter per iteration 3: for major node in Sraw do 4: S = S\u222a major node 5: end for 6: Randomly select ninit nodes in Sraw, S = S \u222a\ninit node, S1 = S,Sraw = Sraw \u2212 S 7: Pick out the instance associated\nwith S, {D1train, D1dev, D1test} = {Dtrain, Ddev, Dtest} 8: for iteration N do 9: Randomly select niter sub node, whose par-\nent belongs to S 10: S = S \u222a Sraw[: niter], Sraw = Sraw \u2212 Sraw[: niter] 11: Iteration i dataset Si = S,{Didev, Ditest} = {Ddev, Dtest} 12: end for\nAlgorithm 4 The construction process of hybrid schema expansion.\n1: Set sampling seed \u03b8, hybrid ratio \u03b1,total iteration N , raw schema Sraw, and raw dataset {Drawtrain, Drawdev , Drawtest } 2: Initialize blank schema S, blank dataset {Dtrain, Ddev, Dtest} and initial node number ninit, node number niter per iteration 3: Randomly select ninit nodes in Sraw, S = S \u222a init node, S1 = S,Sraw = Sraw \u2212 S 4: Pick out the instance associated with S, {D1train, D1dev, D1test} = {Dtrain, Ddev, Dtest} 5: for iteration N do 6: if random(0,1)< \u03b1 then 7: Calculate \u03d5Sim(W\u20d7f , W\u20d7s)= \u2211|Ws| i=1 wi\u00b7wf\n\u2225W\u20d7f\u22252\u00b7\u2225W\u20d7s\u22252 for node between Sraw and S\n8: Pick out top niter schema node, S = S \u222a Sraw[: niter], Sraw = Sraw \u2212 Sraw[: niter]\n9: else 10: Randomly select niter sub node, whose parent belongs to S 11: S = S \u222a Sraw[: niter], Sraw = Sraw \u2212 Sraw[: niter] 12: end if 13: Iteration i dataset Si = S,{Didev, Ditest} = {Ddev, Dtest} 14: end for\nAlgorithm 5 The construction process of analogous schema expansion.\n1: Set sampling seed \u03b8, total iteration N , raw schema Sraw, and raw dataset {Drawtrain, Drawdev , Drawtest } 2: Initialize blank schema S, blank dataset {Dtrain, Ddev, Dtest} and node number niter per iteration 3: Initialize S = Sraw, S1 = S, {Dtrain, Ddev, Dtest}={Drawtrain, Drawdev , Drawtest } 4: Pick out the instance associated with S, {D1train, D1dev, D1test} = {Dtrain, Ddev, Dtest} 5: for iteration N do 6: Randomly select niter schema\nnode in S, calculate v\u20d7(W ) ={\u2211 wr\u2208W NMPI (wr, wj) \u03b3} j=1,...,|WL| for each node, create candidate nodes by pairing Wr with all words WL in the corpus word list\n7: Replace S[: niter] with candidate nodes with analogous semantics 8: Iteration i dataset Si = S,{Didev, Ditest} = {Ddev, Dtest} 9: end for\nInput: The Belgrade district court said that Markovic will be tried along with 10 other Milosevic-era officials who face similar charges of \u2018inappropriate use of state property\u2019 that carry a sentence of up to five years in jail. Labels\nIteration 1 schema: \"attack\", \"start position\", \"transfer ownership\", \"be born\", \"sentence\", \"die\", \"arrest jail\", \"transport\", \"elect\", \"phone write\", \"end organization\", \"sue\", \"acquit\", \"marry\", \"extradite\" Sentence[sentence]\nIteration 2 schema: \"attack\", \"start position\", \"transfer ownership\", \"be born\", \"sentence\", \"die\", \"arrest jail\", \"transport\", \"elect\", \"injure\", \"phone write\", \"fine\", \"convict\", \"end organization\", \"sue\", \"acquit\", \"marry\", \"extradite\" Sentence[sentence]\nIteration 3 schema: \"attack\", \"start position\", \"transfer money\", \"transfer ownership\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"arrest jail\", \"transport\", \"elect\", \"injure\", \"phone write\", \"fine\", \"convict\", \"end organization\", \"sue\", \"acquit\", \"execute\", \"marry\", \"extradite\" Sentence[sentence]\nIteration 4 schema: \"end position\", \"attack\", \"start position\", \"transfer money\", \"transfer ownership\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"arrest jail\", \"transport\", \"elect\", \"start organization\", \"injure\", \"phone write\", \"fine\", \"convict\", \"end organization\", \"sue\", \"acquit\", \"execute\", \"marry\", \"extradite\", \"pardon\" Sentence[sentence]\nIteration 5 schema: \"end position\", \"attack\", \"start position\", \"transfer money\", \"transfer ownership\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"arrest jail\", \"transport\", \"elect\", \"start organization\", \"injure\", \"phone write\", \"declare bankruptcy\", \"trial hearing\", \"fine\", \"convict\", \"end organization\", \"sue\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Sentence[sentence] Trial hearing[tried]\nIteration 6 schema: \"end position\", \"attack\", \"start position\", \"charge indict\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"arrest jail\", \"transport\", \"elect\", \"start organization\", \"injure\", \"phone write\", \"merge organization\", \"declare bankruptcy\", \"trial hearing\", \"fine\", \"convict\", \"end organization\", \"sue\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Sentence[sentence] Trial hearing[tried] ChargeIndict[charges]\nIteration 7 schema: \"end position\", \"attack\", \"start position\", \"nominate\", \"charge indict\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"arrest jail\", \"transport\", \"elect\", \"start organization\", \"meet\", \"injure\", \"phone write\", \"merge organization\", \"declare bankruptcy\", \"trial hearing\", \"fine\", \"convict\", \"end organization\", \"sue\", \"divorce\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Sentence[sentence] Trial hearing[tried] ChargeIndict[charges]\nTable 8: Adaptive evolution of horizontal schema expansion on ACE2005 dataset.\nInput: Kelly, the US assistant secretary for East Asia and Pacific Affairs, arrived in Seoul from Beijing Friday to brief Yoon, the foreign minister. Labels\nIteration 1 schema: \"personnel\", \"attack\", \"justice\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"transport\", \"business\", \"contact\", \"life\", \"fine\", \"sue\", \"execute\", \"marry\", \"extradite\", \"pardon\" Transport[arrived] Contact[brief]\nIteration 2 schema: \"personnel\", \"attack\", \"justice\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"transport\",\"business\", \"meet\", \"life\", \"contact\", \"fine\", \"sue\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Transport[arrived] Meet[brief]\nIteration 3 schema: \"personnel\", \"attack\", \"justice\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"transport\", \"start organization\", \"meet\", \"life\", \"contact\",\"merge organization\", \"business\", \"trial hearing\", \"fine\", \"sue\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Transport[arrived] Meet[brief]\nIteration 4 schema: \"personnel\", \"attack\", \"justice\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"transport\", \"start organization\", \"meet\", \"life\", \"phone write\", \"merge organization\", \"declare bankruptcy\", \"trial hearing\", \"fine\", \"end organization\", \"sue\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Transport[arrived] Meet[brief]\nIteration 5 schema: \"personnel\", \"attack\", \"charge indict\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"arrest jail\", \"transport\", \"start organization\", \"meet\", \"life\", \"phone write\", \"merge organization\", \"declare bankruptcy\", \"trial hearing\", \"fine\", \"convict\", \"end organization\", \"sue\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Transport[arrived] Meet[brief]\nIteration 6 schema: \"end position\", \"attack\", \"personnel\", \"charge indict\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"arrest jail\", \"transport\", \"start organization\", \"meet\", \"injure\", \"phone write\", \"merge organization\", \"declare bankruptcy\", \"trial hearing\", \"fine\", \"convict\", \"end organization\", \"sue\", \"divorce\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Transport[arrived] Meet[brief]\nIteration 7 schema: \"end position\", \"attack\", \"start position\", \"nominate\", \"charge indict\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"arrest jail\", \"transport\", \"elect\", \"start organization\", \"meet\", \"injure\", \"phone write\", \"merge organization\", \"declare bankruptcy\", \"trial hearing\", \"fine\", \"convict\", \"end organization\", \"sue\", \"divorce\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Transport[arrived] Meet[brief]\nTable 9: Adaptive evolution of vertical schema expansion on ACE2005 dataset. Underlined classes refer to major classes, which will be covered by refined sub classes.\nInput: The charismatic leader of Turkey\u2019s governing party was named prime minister Tuesday, a step that probably boosts chances that the United States will get permission to deploy troops in the country along Iraq\u2019s northern border. Labels\nIteration 1 schema: \"attack\", \"justice\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"transport\", \"life\", \"fine\", \"sue\", \"execute\", \"marry\", \"extradite\", \"pardon\" Transport[deploy]\nIteration 2 schema: \"attack\", \"justice\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"transport\", \"meet\", \"life\", \"contact\", \"fine\", \"sue\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Transport[deploy]\nIteration 3 schema: \"attack\", \"justice\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"transport\", \"start organization\", \"meet\", \"life\", \"contact\", \"merge organization\", \"business\", \"trial hearing\", \"fine\", \"sue\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Transport[deploy]\nIteration 4 schema: \"attack\", \"justice\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"transport\", \"start organization\", \"meet\", \"life\", \"phone write\", \"merge organization\", \"declare bankruptcy\", \"trial hearing\", \"fine\", \"end organization\", \"sue\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Transport[deploy]\nIteration 5 schema: \"attack\", \"charge indict\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"arrest jail\", \"transport\", \"start organization\", \"meet\", \"life\", \"phone write\", \"merge organization\", \"declare bankruptcy\", \"trial hearing\", \"fine\", \"convict\", \"end organization\", \"sue\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Transport[deploy]\nIteration 6 schema: \"end position\", \"attack\", \"personnel\", \"charge indict\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"arrest jail\", \"transport\", \"start organization\", \"meet\", \"injure\", \"phone write\", \"merge organization\", \"declare bankruptcy\", \"trial hearing\", \"fine\", \"convict\", \"end organization\", \"sue\", \"divorce\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Transport[deploy] Personnel[named]\nIteration 7 schema: \"end position\", \"attack\", \"start position\", \"nominate\", \"charge indict\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"arrest jail\", \"transport\", \"elect\", \"start organization\", \"meet\", \"injure\", \"phone write\", \"merge organization\", \"declare bankruptcy\", \"trial hearing\", \"fine\", \"convict\", \"end organization\", \"sue\", \"divorce\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Transport[deploy] Elect[named]\nTable 10: Adaptive evolution of hybrid schema expansion on ACE2005 dataset. Underlined classes refer to father classes, which occurs when directly adding sub classes that corresponding major class not exists.\nInput: Webb also said details of the breakdowns of the Welches\u2019 previous marriages were likely to come up , and cited reports of alleged extramarital affairs by both. Labels\nIteration 1 schema: \"end position\", \"attack\", \"start position\", \"nominate\", \"charge indict\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"arrest jail\", \"transport\", \"elect\", \"start organization\", \"meet\", \"injure\", \"phone write\", \"merge organization\", \"declare bankruptcy\", \"trial hearing\", \"fine\", \"convict\", \"end organization\", \"sue\", \"divorce\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Divorce[breakdowns] Marry[marriages]\nIteration 2 schema: \"end position\", \"attack\", \"begin\", \"nominate\", \"charge indict\", \"transfer money\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"arrest jail\", \"carry\", \"elect\", \"start organization\", \"meet\", \"injure\", \"phone write\", \"merge organization\", \"declare bankruptcy\", \"trial hearing\", \"fine\", \"convict\", \"end organization\", \"sue\", \"separate\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Separate[breakdowns] Marry[marriages]\nIteration 3 schema: \"end\", \"attack\", \"begin\", \"nominate\", \"prosecute\", \"remittance\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"die\", \"demonstrate\", \"arrest jail\", \"carry\", \"elect\", \"start organization\", \"meet\", \"injure\", \"phone write\", \"merge organization\", \"declare bankruptcy\", \"trial hearing\", \"fine\", \"convict\", \"end organization\", \"sue\", \"separate\", \"acquit\", \"appeal\", \"execute\", \"marry\", \"extradite\", \"pardon\" Separate[breakdowns] Marry[marriages]\nIteration 4 schema: \"end\", \"attack\", \"begin\", \"nominate\", \"prosecute\", \"remittance\", \"transfer ownership\", \"release parole\", \"be born\", \"sentence\", \"pass away\", \"demonstrate\", \"arrest jail\", \"carry\", \"elect\", \"start organization\", \"meet\", \"injure\", \"phone write\", \"merge organization\", \"declare bankruptcy\", \"attend the trial\", \"fine\", \"convict\", \"end organization\", \"sue\", \"separate\", \"acquit\", \"appeal\", \"perform\", \"marry\", \"extradite\", \"pardon\" Separate[breakdowns] Marry[marriages]\nIteration 5 schema: \"end\", \"attack\", \"begin\", \"nominate\", \"prosecute\", \"remittance\", \"transfer ownership\", \"release parole\", \"be born\", \"condemn\", \"pass away\", \"demonstrate\", \"arrest jail\", \"carry\", \"elect\", \"start organization\", \"encounter\", \"injure\", \"phone write\", \"merge organization\", \"go out of business\", \"attend the trial\", \"fine\", \"convict\", \"end organization\", \"sue\", \"separate\", \"acquit\", \"appeal\", \"perform\", \"marry\", \"extradite\", \"pardon\" Separate[breakdowns] Marry[marriages]\nIteration 6 schema: \"end\", \"attack\", \"begin\", \"nominate\", \"prosecute\", \"remittance\", \"giveaway\", \"release parole\", \"be born\", \"condemn\", \"pass away\", \"parade\", \"arrest jail\", \"carry\", \"vote\", \"start organization\", \"encounter\", \"injure\", \"phone write\", \"merge organization\", \"go out of business\", \"attend the trial\", \"fine\", \"convict\", \"end organization\", \"sue\", \"separate\", \"acquit\", \"appeal\", \"perform\", \"marry\", \"extradite\", \"pardon\" Separate[breakdowns] Marry[marriages]\nIteration 7 schema: \"end\", \"attack\", \"begin\", \"nominate\", \"prosecute\", \"remittance\", \"giveaway\", \"release parole\", \"be born\", \"condemn\", \"pass away\", \"parade\", \"arrest jail\", \"carry\", \"vote\", \"start organization\", \"encounter\", \"hurt\", \"communication\", \"merge organization\", \"go out of business\", \"attend the trial\", \"fine\", \"convict\", \"end organization\", \"sue\", \"separate\", \"acquit\", \"appeal\", \"perform\", \"wed\", \"extradite\", \"pardon\" Separate[breakdowns] Wed[marriages]\nTable 11: Adaptive evolution of analogous schema expansion on ACE2005 dataset.\nGPT-3.5 Input Example:\nThere are some relation extraction samples, relation must be taken from schema, head entity and tail entity must be taken from context. Relation, head entity and tail entity may have multiple. schema: [\"people\", \"country\", \"religion\", \"major shareholder of\", \"industry\", \"contains\", \"brith place\", \"location\", \"nationality\", \"advisors\", \"neighborhood of\", \"place lived\", \"capital\", \"geographic distribution\", \"teams\", \"major shareholders\", \"place of death\", \"children\", \"company\", \"profession\", \"place founded\", \"founders\"] Context: In Queens, North Shore Towers, near the Nassau border, supplanted a golf course, and housing replaced a gravel quarry in Douglaston. The relation involved in the above sentence are: 1. The head entity is Douglaston, relation is neighborhood of, tail entity is Queens; 2. The head entity is Queens, relation is contains, tail entity is Douglaston. Context: Martin, the district attorney for Lehigh County in Pennsylvania, said that after his office\u2019s review of the records, he was satisfied with Mr. Cullen\u2019s denials. The relation involved in the above sentence are: 1. The head entity is Pennsylvania, relation is contains, tail entity is Lehigh County. Context: Mr.Brown has demeaned Mr.Bush as \"a cheerleader,\" declared that Homeland Security Secretary Michael Chertoff did not know \"the first thing about running a disaster,\" and called critics like Representative Gene Taylor, Democrat of Mississippi, \"a little twerp\" and Senator Norm Coleman, Republican of Minnesota, an unprintable vulgarity (both in Playboy). The relation involved in the above sentence are: 1. The head entity is Gene Taylor, relation is place lived, tail entity is Mississippi. ... Do you understand how to do relation extraction based on schema? Now it\u2019s your turn to do relation extraction. schema: [\"people\", \"country\", \"religion\", \"major shareholder of\", \"industry\", \"contains\", \"birth place\", \"location\", \"nationality\", \"advisors\", \"neighborhood of\", \"place lived\", \"capital\", \"geographic distribution\", \"teams\", \"major shareholders\", \"place of death\", \"children\", \"company\", \"profession\", \"place founded\", \"founders\"] Context: But that spasm of irritation by a master intimidator was minor compared with what Bobby Fischer, the erratic former world chess champion, dished out in March at a news conference in Reykjavik, Iceland. The relation involved in the above sentence are:"
        }
    ],
    "title": "Schema-adaptable Knowledge Graph Construction",
    "year": 2023
}