{
    "abstractText": "We address an important gap in detecting political bias in news articles. Previous works that perform document classification can be influenced by the writing style of each news outlet, leading to overfitting and limited generalizability. Our approach overcomes this limitation by considering both the sentence-level semantics and the document-level rhetorical structure, resulting in a more robust and style-agnostic approach to detecting political bias in news articles. We introduce a novel multi-head hierarchical attention model that effectively encodes the structure of long documents through a diverse ensemble of attention heads. While journalism follows a formalized rhetorical structure, the writing style may vary by news outlet. We demonstrate that our method overcomes this domain dependency and outperforms previous approaches for robustness and accuracy. Further analysis and human evaluation demonstrate the ability of our model to capture common discourse structures in journalism.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Jiwoo Hong"
        },
        {
            "affiliations": [],
            "name": "Yejin Cho"
        },
        {
            "affiliations": [],
            "name": "Jaemin Jung"
        },
        {
            "affiliations": [],
            "name": "Jiyoung Han"
        },
        {
            "affiliations": [],
            "name": "James Thorne"
        }
    ],
    "id": "SP:3d4067591bd35e896477db9a702fb7e2d3350784",
    "references": [
        {
            "authors": [
                "Hunt Allcott",
                "Levi Boxell",
                "Jacob Conway",
                "Matthew Gentzkow",
                "Michael Thaler",
                "David Yang."
            ],
            "title": "Polarization and public health: Partisan differences in social distancing during the coronavirus pandemic",
            "venue": "Journal of Public Economics, 191:104254.",
            "year": 2020
        },
        {
            "authors": [
                "Leila Arras",
                "Franziska Horn",
                "Gr\u00e9goire Montavon",
                "KlausRobert M\u00fcller",
                "Wojciech Samek."
            ],
            "title": "what is relevant in a text document?\": An interpretable machine learning approach",
            "venue": "PloS one, 12(8):e0181142.",
            "year": 2017
        },
        {
            "authors": [
                "Sebastian Bach",
                "Alexander Binder",
                "Gr\u00e9goire Montavon",
                "Frederick Klauschen",
                "Klaus-Robert M\u00fcller",
                "Wojciech Samek."
            ],
            "title": "On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation",
            "venue": "PLOS ONE, 10(7):1\u201346.",
            "year": 2015
        },
        {
            "authors": [
                "Ramy Baly",
                "Giovanni Da San Martino",
                "James Glass",
                "Preslav Nakov."
            ],
            "title": "We can detect your bias: Predicting the political ideology of news articles",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
            "year": 2020
        },
        {
            "authors": [
                "Kevin G Barnhurst",
                "Diana Mutz."
            ],
            "title": "American journalism and the decline in event-centered reporting",
            "venue": "Journal of Communication, 47(4):27\u201353.",
            "year": 1997
        },
        {
            "authors": [
                "Aria Bendix."
            ],
            "title": "Covid death rates are higher among republicans than democrats, mounting evidence shows",
            "venue": "NBC News.",
            "year": 2022
        },
        {
            "authors": [
                "Yochai Benkler",
                "Robert Faris",
                "Hal Roberts."
            ],
            "title": "Network propaganda: Manipulation, disinformation, and radicalization in American politics",
            "venue": "Oxford University Press.",
            "year": 2018
        },
        {
            "authors": [
                "Alexander Binder",
                "Gr\u00e9goire Montavon",
                "Sebastian Bach",
                "Klaus-Robert M\u00fcller",
                "Wojciech Samek."
            ],
            "title": "Layer-wise relevance propagation for neural networks with local renormalization layers",
            "venue": "CoRR, abs/1604.00825.",
            "year": 2016
        },
        {
            "authors": [
                "Ceren Budak",
                "Sharad Goel",
                "Justin M. Rao."
            ],
            "title": "Fair and Balanced? Quantifying Media Bias through Crowdsourced Content Analysis",
            "venue": "Public Opinion Quarterly, 80(S1):250\u2013271.",
            "year": 2016
        },
        {
            "authors": [
                "Wei-Fan Chen",
                "Khalid Al Khatib",
                "Henning Wachsmuth",
                "Benno Stein"
            ],
            "title": "Analyzing political bias",
            "year": 2020
        },
        {
            "authors": [
                "J. Clinton",
                "J. Cohen",
                "J. Lapinski",
                "M. Trussler."
            ],
            "title": "Partisan pandemic: How partisanship and public health concerns affect individuals&#x2019; social mobility during covid-19",
            "venue": "Science Advances, 7(2):eabd7204.",
            "year": 2021
        },
        {
            "authors": [
                "Nicholas T. Davis",
                "Johanna L. Dunaway."
            ],
            "title": "Party Polarization, Media Choice, and Mass PartisanIdeological Sorting",
            "venue": "Public Opinion Quarterly, 80(S1):272\u2013297.",
            "year": 2016
        },
        {
            "authors": [
                "Stefano DellaVigna",
                "Ethan Kaplan."
            ],
            "title": "The Fox News Effect: Media Bias and Voting",
            "venue": "The Quarterly Journal of Economics, 122(3):1187\u20131234.",
            "year": 2007
        },
        {
            "authors": [
                "Nicolas Devatine",
                "Philippe Muller",
                "Chlo\u00e9 Braud."
            ],
            "title": "Predicting political orientation in news with latent discourse structure to improve bias understanding",
            "venue": "Proceedings of the 3rd Workshop on Computational Approaches to Discourse, pages 77\u201385,",
            "year": 2022
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Elizabeth Dubois",
                "Grant Blank."
            ],
            "title": "The echo chamber is overstated: the moderating effect of political interest and diverse media",
            "venue": "Information, Communication & Society, 21(5):729\u2013745.",
            "year": 2018
        },
        {
            "authors": [
                "Lisa Fan",
                "Marshall White",
                "Eva Sharma",
                "Ruisi Su",
                "Prafulla Kumar Choubey",
                "Ruihong Huang",
                "Lu Wang."
            ],
            "title": "In plain sight: Media bias through the lens of factual reporting",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Pro-",
            "year": 2019
        },
        {
            "authors": [
                "Lauren Feldman",
                "Edward W. Maibach",
                "Connie RoserRenouf",
                "Anthony Leiserowitz."
            ],
            "title": "Climate on cable: The nature and impact of global warming coverage on fox news, cnn, and msnbc",
            "venue": "The International Journal of Press/Politics, 17(1):3\u201331.",
            "year": 2012
        },
        {
            "authors": [
                "Shangbin Feng",
                "Zilong Chen",
                "Wenqian Zhang",
                "Qingyao Li",
                "Qinghua Zheng",
                "Xiaojun Chang",
                "Minnan Luo"
            ],
            "title": "Kgap: Knowledge graph augmented political perspective detection in news media",
            "year": 2022
        },
        {
            "authors": [
                "Seth Flaxman",
                "Sharad Goel",
                "Justin M. Rao."
            ],
            "title": "Filter Bubbles, Echo Chambers, and Online News Consumption",
            "venue": "Public Opinion Quarterly, 80(S1):298\u2013320.",
            "year": 2016
        },
        {
            "authors": [
                "Rama Rohit Reddy Gangula",
                "Suma Reddy Duggenpudi",
                "Radhika Mamidi."
            ],
            "title": "Detecting political bias in news articles using headline attention",
            "venue": "Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP,",
            "year": 2019
        },
        {
            "authors": [
                "Matthew Gentzkow",
                "Jesse M. Shapiro"
            ],
            "title": "What drives media slant? evidence from u.s. daily newspapers",
            "year": 2010
        },
        {
            "authors": [
                "Matthew Gentzkow",
                "Jesse M. Shapiro."
            ],
            "title": "Ideological Segregation Online and Offline ",
            "venue": "The Quarterly Journal of Economics, 126(4):1799\u20131839.",
            "year": 2011
        },
        {
            "authors": [
                "John Gramlich"
            ],
            "title": "Q&a: How pew research center evaluated americans\u2019 trust in 30 news sources [online",
            "year": 2020
        },
        {
            "authors": [
                "Sooji Han",
                "Rui Mao",
                "Erik Cambria."
            ],
            "title": "Hierarchical attention network for explainable depression detection on Twitter aided by metaphor concept mappings",
            "venue": "Proceedings of the 29th International Conference on Computational Linguistics, pages 94\u2013104,",
            "year": 2022
        },
        {
            "authors": [
                "Sepp Hochreiter",
                "J\u00fcrgen Schmidhuber."
            ],
            "title": "Long short-term memory",
            "venue": "Neural computation, 9(8):1735\u2013 1780.",
            "year": 1997
        },
        {
            "authors": [
                "Shanto Iyengar",
                "Kyu S Hahn."
            ],
            "title": "Red Media, Blue Media: Evidence of Ideological Selectivity in Media Use",
            "venue": "Journal of Communication, 59(1):19\u201339.",
            "year": 2009
        },
        {
            "authors": [
                "Mark Jurkowitz",
                "Amy Mitchell"
            ],
            "title": "About one-fifth of democrats and republicans get political news in a kind of media bubble [online",
            "year": 2020
        },
        {
            "authors": [
                "Hamid Karimi",
                "Jiliang Tang."
            ],
            "title": "Learning hierarchical discourse-level structure for fake news detection",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-",
            "year": 2019
        },
        {
            "authors": [
                "Johannes Kiesel",
                "Maria Mestre",
                "Rishabh Shukla",
                "Emmanuel Vincent",
                "Payam Adineh",
                "David Corney",
                "Benno Stein",
                "Martin Potthast."
            ],
            "title": "SemEval2019 task 4: Hyperpartisan news detection",
            "venue": "Proceedings of the 13th International Workshop on",
            "year": 2019
        },
        {
            "authors": [
                "Eunji Kim",
                "Yphtach Lelkes",
                "Joshua McCrain."
            ],
            "title": "Measuring dynamic media bias",
            "venue": "Proceedings of the National Academy of Sciences, 119(32):e2202197119.",
            "year": 2022
        },
        {
            "authors": [
                "William Yang Wang"
            ],
            "title": "Multi-view models for",
            "year": 2018
        },
        {
            "authors": [
                "Ramesh Nallapati",
                "Bowen Zhou",
                "Cicero dos Santos",
                "\u00c7a\u011flar Gu\u0307l\u00e7ehre",
                "Bing Xiang"
            ],
            "title": "Abstractive text summarization using sequence-to-sequence RNNs and beyond",
            "venue": "In Proceedings of the 20th SIGNLL Conference on Computational Natural Lan-",
            "year": 2016
        },
        {
            "authors": [
                "Woo-Jeoung Nam",
                "Jaesik Choi",
                "Seong-Whan Lee."
            ],
            "title": "Relative attributing propagation: Interpreting the comparative contributions of individual units in deep neural networks",
            "venue": "CoRR, abs/1904.00605.",
            "year": 2019
        },
        {
            "authors": [
                "T.E. Patterson."
            ],
            "title": "Out of Order: An incisive and boldly original critique of the news media\u2019s domination of America\u2019s political process",
            "venue": "Politics: Media studies. Knopf Doubleday Publishing Group.",
            "year": 1994
        },
        {
            "authors": [
                "Horst P\u00f6ttker"
            ],
            "title": "News and its communicative quality: the inverted pyramid\u2014when and why did it appear",
            "venue": "Journalism Studies,",
            "year": 2003
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych."
            ],
            "title": "SentenceBERT: Sentence embeddings using Siamese BERTnetworks",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natu-",
            "year": 2019
        },
        {
            "authors": [
                "Peter J. Rousseeuw."
            ],
            "title": "Silhouettes: A graphical aid to the interpretation and validation of cluster analysis",
            "venue": "Journal of Computational and Applied Mathematics, 20:53\u201365.",
            "year": 1987
        },
        {
            "authors": [
                "Susana Salgado",
                "Jesper Str\u00f6mb\u00e4ck."
            ],
            "title": "Interpretive journalism: A review of concepts, operationalizations and key findings",
            "venue": "Journalism, 13(2):144\u2013161.",
            "year": 2012
        },
        {
            "authors": [
                "Michael Schudson."
            ],
            "title": "The politics of narrative form: The emergence of news conventions in print and television",
            "venue": "Daedalus, 111(4):97\u2013112.",
            "year": 1982
        },
        {
            "authors": [
                "S.S. Shapiro",
                "M.B. Wilk."
            ],
            "title": "An analysis of variance test for normality (complete samples)",
            "venue": "Biometrika, 52(3-4):591\u2013611.",
            "year": 1965
        },
        {
            "authors": [
                "Shirong Shen",
                "Guilin Qi",
                "Zhen Li",
                "Sheng Bi",
                "Lusheng Wang."
            ],
            "title": "Hierarchical Chinese legal event extraction via pedal attention mechanism",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 100\u2013113,",
            "year": 2020
        },
        {
            "authors": [
                "Leslie N. Smith."
            ],
            "title": "No more pesky learning rate guessing games",
            "venue": "CoRR, abs/1506.01186.",
            "year": 2015
        },
        {
            "authors": [
                "Timo Spinde",
                "Manuel Plank",
                "Jan-David Krieger",
                "Terry Ruas",
                "Bela Gipp",
                "Akiko Aizawa."
            ],
            "title": "Neural media bias detection using distant supervision with BABE - bias annotations by experts",
            "venue": "Findings of the Association for Computational Linguis-",
            "year": 2021
        },
        {
            "authors": [
                "Paolo Tormene",
                "Toni Giorgino",
                "Silvana Quaglini",
                "Mario Stefanelli."
            ],
            "title": "Matching incomplete time series with dynamic time warping: An algorithm and an application to post-stroke rehabilitation",
            "venue": "Artificial Intelligence in Medicine, 45(1):11\u201334.",
            "year": 2008
        },
        {
            "authors": [
                "Teun A Van Dijk."
            ],
            "title": "Structures of news in the press",
            "venue": "Discourse and communication: New approaches to the analysis of mass media discourse and communication, 10:69.",
            "year": 1985
        },
        {
            "authors": [
                "Teun A Van Dijk."
            ],
            "title": "News, discourse, and ideology",
            "venue": "The handbook of journalism studies, pages 211\u2013 224. Routledge.",
            "year": 2009
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141 ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc.",
            "year": 2017
        },
        {
            "authors": [
                "Chenguang Wang",
                "Mu Li",
                "Alexander J. Smola"
            ],
            "title": "Language models with transformers",
            "year": 2019
        },
        {
            "authors": [
                "Thomas Wolf",
                "Lysandre Debut",
                "Victor Sanh",
                "Julien Chaumond",
                "Clement Delangue",
                "Anthony Moi",
                "Pierric Cistac",
                "Tim Rault",
                "R\u00e9mi Louf",
                "Morgan Funtowicz",
                "Jamie Brew."
            ],
            "title": "Huggingface\u2019s transformers: State-of-the-art natural language processing",
            "venue": "CoRR,",
            "year": 2019
        },
        {
            "authors": [
                "Zichao Yang",
                "Diyi Yang",
                "Chris Dyer",
                "Xiaodong He",
                "Alex Smola",
                "Eduard Hovy."
            ],
            "title": "Hierarchical attention networks for document classification",
            "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-",
            "year": 2016
        },
        {
            "authors": [
                "Muhan Zhang",
                "Christopher R. King",
                "Michael S. Avidan",
                "Yixin Chen."
            ],
            "title": "Hierarchical attention propagation for healthcare representation learning",
            "venue": "Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining.",
            "year": 2020
        },
        {
            "authors": [
                "Tianyi Zhang",
                "Varsha Kishore",
                "Felix Wu",
                "Kilian Q. Weinberger",
                "Yoav Artzi."
            ],
            "title": "Bertscore: Evaluating text generation with BERT",
            "venue": "CoRR, abs/1904.09675.",
            "year": 2019
        },
        {
            "authors": [
                "Wenqian Zhang",
                "Shangbin Feng",
                "Zilong Chen",
                "Zhenyu Lei",
                "Jundong Li",
                "Minnan Luo."
            ],
            "title": "KCD: Knowledge walks and textual cues enhanced political perspective detection in news media",
            "venue": "Proceedings of the 2022 Conference of the North American Chap-",
            "year": 2022
        },
        {
            "authors": [
                "the complaints tend to overlook the fact that the overall security budget has more than doubled since fiscal"
            ],
            "title": "For that year, the budget was $640 million",
            "venue": "It steadily climbed to $1.6 billion in fiscal 2010. It dipped to $1.5 billion the following year and roughly $1.35 billion in fiscal 2012 \u2013 still far more than it was a decade ago. Slightly more has been requested for fiscal 2013. It\u2019s difficult to tell how much was specifically allocated for Benghazi. Tripoli was the only post mentioned in",
            "year": 2004
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "One of the primary reasons people consume news is for social cognition: to stay informed about events and developments and make informed decisions. To fulfill this purpose, news outlets must provide citizens with information from diverse sources and perspectives. The Pew Research Center (Mitchell et al., 2018) reports that the majority of American respondents (78%) indicated that news organizations should refrain from showing favoritism towards any political party in their reporting. However, more than half of the respondents (52%) expressed dissatisfaction with the media\u2019s ability to report on political issues fairly and unbiasedly.\nExtensive research has revealed that partisan bias exists in various social issues, such as the 2016 US presidential election (Benkler et al., 2018), the\n1Our code is available at: https://github.com/ xfactlab/emnlp2023-Document-Hierarchy\nIraq war (Luther and Miller, 2005), and climate change (Feldman et al., 2012). This disparity in media coverage has significant impacts on shaping people\u2019s perceptions of the issue (Levendusky, 2013) and their voting behavior (DellaVigna and Kaplan, 2007). Even the COVID-19 pandemic, a global health crisis, has been covered differently across the conservative and liberal political spectrum (Motta et al., 2020). Consequently, Americans have displayed a deep partisan divide, with Republicans showing less concern about personal COVID-19 risks and the severity of the pandemic than Democrats (Allcott et al., 2020). This led to Republicans being less willing to adhere to stay-athome orders and engage in social distancing (Clinton et al., 2021), resulting in higher COVID-19 mortality rates among this group (Bendix, 2022).\nThe role of news media in shaping public discourse and perceptions of social issues cannot be overstated. The media plays a crucial role in disseminating information, framing issues, and setting the agenda for public debate, ultimately leading to public policy-making. Mapping the political landscape of news media is an important task. It helps news consumers evaluate the credibility of the news\nthey are exposed to and more easily interpret and contextualize the information at hand. Moreover, news consumers who are aware of news outlets\u2019 political leanings can seek out other viewpoints to balance their understanding of an issue. This is particularly important in a society where media outlets are increasingly polarized along parties (Jurkowitz and Mitchell, 2020; Mitchell and Jurkowitz, 2021). It is more crucial than ever for news consumers to be discerning and critical in their news media consumption. However, previous works mainly focus on a document-level classification, making it challenging to assess why an article is biased.\nTo validate the necessity of discourse structural analysis in this task, we analyze the drawbacks of political bias classifiers that disregard the discourse structure by questioning their credibility. We formulate this issue as a domain dependency problem: instability of the model to which news articles model is trained or tested on. And we propose an approach for biased context detection in news articles which uses a multi-head attention mechanism to propagate document-level labels to prominent subsets of sentences, which helps make the model more reliable and explainable, illustrated in Figure 1 and Appendix G.\nOur paper offers four contributions: (1) we address the problem of domain dependencies in the political bias detection task, which is an essential but understudied task; (2) we propose a new approach for biased context detection in news articles based on multi-head attention and a hierarchical model; (3) we evaluate the effectiveness of understanding the special discourse structure in the journalism domain in comparison to the syntactic hierarchy; and (4) we analyze the structures our model captures with respect to journalistic writing styles."
        },
        {
            "heading": "2 Background",
            "text": "Measuring bias There have been continuous efforts to determine the political bias of news outlets, with two main approaches: audience-based and content-based analyses. Audience-based methods assume that a news outlet\u2019s political stance can be inferred from the political preferences of its primary audience (Gramlich, 2020). This is because news outlets are expected to cater to the inclinations of their users to retain their viewership or readership. Studies have shown that partisans tend to choose news from politically congruent outlets (Davis and Dunaway, 2016; Iyengar and\nHahn, 2009). However, recent web tracking technologies have revealed that a significant amount of traffic crosses ideological lines (Dubois and Blank, 2018; Flaxman et al., 2016; Gentzkow and Shapiro, 2011) This conflicting evidence suggests the audience makeup of a news outlet may no longer be stable in a highly competitive media environment.\nContent-based methods typically rely on student coders (Feldman et al., 2012; Luther and Miller, 2005) or workers from crowdsourcing platforms (Budak et al., 2016) to measure progressive/conservative media bias. The introduction of computer-assisted content analysis techniques allows researchers to compare the linguistic patterns adopted by partisan media on a large scale (Gentzkow and Shapiro, 2010; Luther and Miller, 2005). Nonetheless, these methods are generally confined to specific news topics, such as the federal tax on inherited assets (Gentzkow and Shapiro, 2010), and may not be generalizable to other news topics or entire news channels. Recently, facial recognition algorithms have been used to quantify the visibility of politicians in broadcast news programs (Kim et al., 2022). This technique detects whether a program displays a liberal or conservative bias if it features more actors from the left (or right) for a longer duration. However, it is restricted to analyzing news visuals only and cannot be applied to other types of news content.\nStructural Properties The writing style in the journalism domain plays a crucial role in shaping public discourse and perceptions of social issues. Sentences in the articles have unique roles according to their position in the article (Van Dijk, 1985), typically following an inverted pyramid structure (P\u00f6ttker, 2003). Structural analysis for detecting political bias in news articles (Van Dijk, 2009; Gangula et al., 2019) has shown that analysis of how information is presented can be used to determine the political bias of the author or news outlet. Therefore, specialized structural analysis of journalism is important in developing NLP-based approaches for political bias detection."
        },
        {
            "heading": "3 Related Works",
            "text": "Detecting political ideologies and biases There are two common approaches in the content-based political bias detection task in NLP: either articlelevel (Kulkarni et al., 2018; Baly et al., 2020; Liu et al., 2022), sentence-level (Chen et al., 2020; Fan et al., 2019; Spinde et al., 2021; Lei et al.,\n2022). For sentence-level bias detection, previous work has centered around labeling additional data: Spinde et al. (2021) developed a process for labeling data at a sentence-level with binary labels and Fan et al. (2019) defined informational bias and lexical bias while providing sentence-level and word-level bias labels for news articles. With these datasets, Lei et al. (2022) used discourse structures that inform the model about the role of a sentence to detect sentence-level bias.\nResearch in article-level bias centers around using external information (Baly et al., 2020; Zhang et al., 2022; Feng et al., 2022). For example, Baly et al. (2020) incorporate additional external information such as Twitter bios and Wikipedia pages related to each news outlet, and Zhang et al. (2022) and Feng et al. (2022) implemented a knowledge graph of external facts to enhance the political bias detection performance. In related works, contrastive learning with additional data preprocessing (e.g. curating article triplets) has also helped build robust models learning from annotations of left, centrist, and right viewpoints on the same event (Kim and Johnson, 2022; Liu et al., 2022).\nHierarchical attention Hierarchical attention (Yang et al., 2016) allows a model to encode longer texts by combining independently encoded sentences or phrases (Shen et al., 2020; Zhang et al., 2020; Han et al., 2022; Kulkarni et al., 2018; Karimi and Tang, 2019; Devatine et al., 2022). In the legal domain, Shen et al. (2020) hierarchically formulated legal events and arguments for legal event extraction. In the medical domain, Zhang et al. (2020) used hierarchical attention in medical ontology to embed medical terminologies with respect to both low- and high-level concepts.\nFor journalism, Karimi and Tang (2019) utilized hierarchical attention for building discourse\nstructure trees on fake news detection tasks. Also, for political ideology classification, Kulkarni et al. (2018) proposed a multi-view model that hierarchically encodes the article with word-level and sentence-level embeddings. Devatine et al. (2022) also hierarchically encoded the article and applied adversarial adaptation for political bias classification. While hierarchical features have been used for document-level classification, we propose propagating relevance through the document hierarchy.\nRelevance Propagation Relevance propagation methods are widely used in many domains to improve the explainability of black box models (Nam et al., 2019; Binder et al., 2016; Bach et al., 2015). Specifically for NLP, Arras et al. (2017) propagate model weights to highlight relevant tokens for predictions. Our method widens the range of relevance propagation in NLP by considering sentence-level relevance in document understanding.\nArticle-level political bias datasets For articlelevel bias detection, many previous works published labeled datasets with news articles collected from Allsides.com (Kiesel et al., 2019; Baly et al., 2020; Chen et al., 2020; Liu et al., 2022). Models will likely memorize aspects irrelevant to political bias when predicting the label. Publisher (Kiesel et al., 2019), news outlet (Baly et al., 2020), and topic (Chen et al., 2020) have shown confounding effects. While Baly et al. (2020) reported this discrepancy between seen news outlets for training and unseen news outlets during testing, they did not analyze the cause of this problem."
        },
        {
            "heading": "4 Model Architecture",
            "text": "We have three modeling objectives: (1) to induce sentence-level information from a document-level label, (2) to understand the discourse structure of the news article, and (3) to reduce the effect of\nspurious correlation between the media outlet and the bias label. It is critical to model the complex relation between sentences in the news article when predicting its political ideology, to this end, we apply hierarchical modeling to propagate document information to sentences.\nWe propose a bias prediction model that uses a two-layer tree with sentence-level embeddings to better understand the news article\u2019s semantics and discourse structure. Our pipeline consists of three key stages that can be jointly trained as a single unified model: semantic analysis, sentence type detection, and context clustering. Each component is described in detail in the following sections, and the model architecture is illustrated in Figure 2."
        },
        {
            "heading": "4.1 Semantic Understanding",
            "text": "The first stage of the model builds a representation vector for each sentence comprising the semantics, positional information, and discourse relation.\nSemantics A news article contains a headline S0 and a sequence of many sentences: (S1, ..., Sn). The semantics of each sentence is independently captured by using a large language model to generate a sentence embedding si = SBERT (Si), i \u2208 {0, . . . , n}. We use S-BERT (Reimers and Gurevych, 2019), as it is trained specifically to represent the semantic similarity between sentences.\nPosition The positional information captures the role of a sentence with respect to its location in the article. We chose to add the positional information to the sentence embedding through BiLSTM (Hochreiter and Schmidhuber, 1997) over encoded sentences. As the sentences in the news articles have intricate relationships more than a simple sequential relationship, we chose to use BiLSTM instead of positional encoding as we desire a conditional representation that cannot be achieved with positional encoding alone (Wang et al., 2019).\nhi =[ \u2212\u2212\u2212\u2212\u2192 LSTM(si, s0:i\u22121); \u2190\u2212\u2212\u2212\u2212 LSTM(si, sn:i+1)] (1)\nDiscourse To capture the discourse relation between multiple sentences in different viewpoints, we apply multi-head attention (Vaswani et al., 2017) over the BiLSTM encodings: H = [h0, . . . ,hn]. Each attention head, H\u0304k = Attn(QW\n(Q) k ,KW (K) k , V W (V ) k ), independently\nmodels the relationships between all document sentences and headline with scaled dot product attention. We set Q = K = V = H . In contrast to the\nmulti-head attention mechanism of the transformer, we do not concatenate the results. We instead perform the sentence type detection independently for each of the N attention heads to propagate the political bias distribution to the independently captured N different main contexts."
        },
        {
            "heading": "4.2 Multi-Head Sentence Type Detection",
            "text": "This step is computed independently for each attention head H\u0304k. For simplicity, we omit the subscript defining the head k. We use the attended representation to predict the importance of each of the sentences in the article with respect to the headline. Each sentence is assigned one of two roles: main or supporting. We compute these roles by comparing dot product similarity between the sentences h\u0304i and the headline h\u03040. Supporting sentences are assigned Psupp(Si|S0) = 1\u2212 Pmain(Si|S0).\nPmain(Si|S0) = \u03b1i = exp h\u0304Ti h\u03040\u2211n\ni\u2032=1 exp h\u0304 T i\u2032 h\u03040\n(2)\nWe created weighted embeddings of sentences so that the sentences which are likely to be main sentences have high norms. These weighted embeddings undergo further encoding with a single feed-forward layer with GELU unit: ui = Gelu(FFN(\u03b1ih\u0304i)). Similarly, we make encodings for sentences from the SUPPORTING perspective: vi = Gelu(FFN((1 \u2212 \u03b1i)h\u0304i)). Note that the headline acts as a main sentence with \u03b10 = 1."
        },
        {
            "heading": "4.3 Context Cluster Embedding",
            "text": "The generated perspective vectors are used for each attention head to predict the hierarchical relation between the main and supporting sentences. We use the dot product similarity to capture this discourse dependency. The dependency scorer (Figure 2) returns the proportion of focus between the main sentence Si and the supporting sentence Sj :\nPdep(Sj |Si) = expvTj ui\u2211n\nj\u2032=1 expvj\u2032ui , i \u0338= j (3)\nContext cluster embeddings are created by summing the main sentence representation u(m)i with the weighted sum of the supporting sentence representations. We weight this sum by the dependency score so that unrelated sentences contribute less to the context cluster embedding.\nci = ui + n\u2211\nj=1,j \u0338=i Pdep(Sj |Si) \u00b7 vj (4)\nFor each attention head, we create a single embedding by summing each of the context cluster embeddings c\u0304 = LayerNorm( \u2211 i ci). We apply LayerNorm (Ba et al., 2016) to mitigate the effect of having multiple depending sentences. We then predict the distribution of bias label for the news article distribution with a linear classifier over this head\u2019s embedding: y\u0302k = softmax(FFN(c\u0304)). During training, we treat each attention head as a component in a mixture model, averaging the class probabilities to predict the bias: y\u0302 = 1N \u2211N k=1 y\u0302k. At test time, we propagate the document-level label to a single main sentence and corresponding supporting sentences (i.e. context clusters) for each head according to argmax\ni Pmain(Si|S0)."
        },
        {
            "heading": "5 Experimental Settings",
            "text": ""
        },
        {
            "heading": "5.1 Datasets",
            "text": "We train and evaluate the model on the media bias detection dataset from Baly et al. (2020). Unlike Baly et al. (2020), we build two test sets to test the performance gap upon two test sets rather than pursuing the higher accuracy in a single test set. We use the media-based split to evaluate the generalization between news outlets to which the model is trained and tested with two modifications:2\nFirst, we deleted 425 news outlets with less than 50 articles to ensure that the model is not memorizing the writing style of certain mediums. For the remaining mediums, we merged news outlets from the same company, such as \"CNN\" and \"CNN (Web News)\" to prevent overlapping between the train set and the others.\nSecond, we made a balanced dataset with respect to both data size and news outlets. We selected four\n2Because the dataset reported in the paper significantly differs from the published files, we re-balance the data ourselves.\nnews outlets for each class to make our test sets. As the number of articles varied by news outlets, we selected 50 and 60 articles from each news outlet for Test Set 1 and 2, respectively. We sampled 7,300 articles from each side regardless of the news outlets to preserve the train data size for the train set. Dataset statistics and the list of news outlets for each set are provided in Table 1 and Appendix C."
        },
        {
            "heading": "5.2 Baseline",
            "text": "To compare against our hierarchical model, we also fine-tuned BERT (Devlin et al., 2019) model using the HuggingFace bert-base-uncased implementation (Wolf et al., 2019). We use a single classification layer over the CLS token from the final hidden layer. Since news articles are lengthy documents, the articles were truncated by 512 tokens."
        },
        {
            "heading": "6 Experiments",
            "text": "We compare our model against a BERT baseline classifier for the news article classification task with experiments to (1) compare our model against the BERT baseline, which is representative of previous work; (2) compare the accuracy of the model on two disjoint test sets (3) evaluate sensitivity to the content of training data and (4) evaluate sensitivity to the number of training data. In all experiments, we report AUROC and macro F1 scores. The hyperparameters for training are in Appendix A.\nComparison against baseline We compare against a BERT classifier, which performs on par with the model from (Baly et al., 2020). For both the baseline and our model, we train 20 versions of the model with different random seeds. We report the average and standard deviation of the results for each model, respectively.\nSensitivity to test data We evaluate whether the models depend on the news articles they are tested on. We use the two test sets, which were pairwise disjoint by a news outlet (i.e. a news outlet from\nin Test Set 1 does not have any articles in Test Set 2). If the model is robust to the writing style of the news outlets in evaluation, the distribution of the tested result will be invariant between test sets. We apply a two-sided t-test over AUROC and also report divergence (JSD) between the distributions.\nSensitivity to training data We study if the models depend on the news articles they are trained on. We compute the learning curve by training the model on increasing subsets of data from (N=1000,5000,10000,Full). For each sample size, we report the variance based on training on 20 different subsets of the training data. We first apply the Shapiro-Wilk test (Shapiro and Wilk, 1965) to validate whether the AUROC distribution of each model on the test set is normal. Then, we conducted the F-test and checked the variance ratio to validate which model was more sensitive to the training data. We report JSD to quantify the discrepancy between the results in the two test sets for both the BERT baseline and our model.\nLearning Curve We trained the model to the random subsets of 1,000, 5,000, and 10,000 articles and the full train set (21,900 articles) for the experiments studying sensitivity to training data."
        },
        {
            "heading": "7 Result",
            "text": "We report Macro F1 and AUROC for the documentlevel bias prediction task in Table 2. Our results\nindicate that our approach (1) outperforms a conventional LM-based classifier, (2) is resilient to domain shift between train and test (3) uncovers structural properties which follow the general practice and theoretical background in journalism."
        },
        {
            "heading": "7.1 Comparison against baseline",
            "text": "To compare the data efficiency of the BERT baseline and our model, we evaluate model accuracy with varying numbers of training data in Table 2. For Test Set 1, our model outperformed BERT for both AUROC and macro F1 score in every data size setting. For Test Set 2, our model outperformed BERT in the subsets of 10,000 articles and the full train set but not in the subsets of 1,000 articles and 5,000 articles. BERT outperformed when the models were trained to the small subsets and tested on Test Set 2. Otherwise, our model outperformed BERT in any setting. The highest AUROC of our model on both test sets was 0.6733 and 0.7071, outperforming BERT (AUROC of 0.6384 and 0.6977).\nWe further explored the reason why BERT outperformed in two specific cases with the model\u2019s sensitivity to test data in the following subsection."
        },
        {
            "heading": "7.2 Sensitivity to test data",
            "text": "To measure the discrepancy of each model\u2019s results from Test Sets 1 and 2, we used the two-sided ttest and JSD. The null hypothesis and alternative hypothesis for the t-test are listed in Appendix B.1. Except for our model trained with the subsets of\n5,000 articles, it was evident to reject H0. This means that both models have discrepancies in AUROC from Test Set 1 and Test Set 2. However, BERT always had a higher discrepancy measured by JSD. This indicated that BERT always showed distant results in Test Set 1 and Test Set 2 in every case. This provides evidence that our model is more robust to test data than BERT (further reported in Figure 3 and Table 2)."
        },
        {
            "heading": "7.3 Sensitivity to training data",
            "text": "To compare the variance of AUROC, we used the F-test. The null hypothesis H0, alternative hypothesis H1, and the ratio of variance f0 are listed in Appendix B.2. For both models, the AUROC variance in Test Set 1 and Test Set 2 tends to decrease as the subset size increases. In all but 1 case, the variance of BERT was consistently higher than our model. Evaluating on Test Set 1, f0 was always higher than F0.05,19,19, so it was evident to reject H0 in every case. Evaluating Test Set 2, f0 linearly increased as the size of the subset increased. However, for 1,000 training data, we could not reject H0. This shows that our model is more invariant to the data it was trained on than the BERT classifier."
        },
        {
            "heading": "8 Structural Analysis",
            "text": "In this section, we analyze the structural properties of news articles using the main sentences identified by the model. To do so, we collect the predicted main sentences and assess if they capture the formalized discourse structures commonly used in journalism. By validating from summarization and structure, we ensure the reliability of using multiple attention heads as an explanation mechanism.\nWe use the BASIL dataset, which contains sentence-level annotations for two types of biases (Fan et al., 2019): lexical and informational bias.\nLexical bias refers to the bias from the word choice of the journalist, such as using polarized words (e.g. Donald Trump is investing more in conspiracy theories about President Obama\u2019s birth certificate as he explores his bid for the presidency.) Informational bias refers to the biased elaboration of certain events or facts, which includes using selective quotations to strengthen their viewpoint. (e.g. The Arizona group said the call from Mr. Trump on Wednesday came unexpectedly, and the group had spent much of the day Thursday scurrying to make travel arrangements to New York.)"
        },
        {
            "heading": "8.1 Main Sentences as Extractive Summary",
            "text": "We conducted machine and human evaluations to assess whether the main sentences identified by the model were informative. Our working assumption is that the concatenation of main sentences from our model acts as an extractive summary.\nMachine Evaluation We used BART-large (Lewis et al., 2019) pretrained on CNN/Daily Mail dataset (Nallapati et al., 2016) to generate the summaries. We report BERTScore (Zhang et al., 2019) between abstractive summarizer and our model as an extractive summarizer in Table 3.\nHuman Evaluation To evaluate whether the main sentences selected by the model were informative, two annotators (\u03ba = 0.43) recorded preference of summary from either 1) the lead, 2) randomly selected sentences, 3) main sentences from our model. Without knowing the system, annotators were instructed to select which summary best explains the concept and biased contents of twenty news articles sampled from BASIL. Annotators select our model\u2019s main sentences in 75% of cases. Detailed instructions are provided in Appendix D."
        },
        {
            "heading": "8.2 Structure of documents",
            "text": "To assess whether the main sentences identified by our model capture the structural properties of news articles, we cluster articles from the BASIL dataset with respect to their distribution of contexts using K-Means. For the distance metric, we use Dynamic Time Warping (Tormene et al., 2008, DTW), which captures the temporal elements without a dependency on the document length. The BASIL dataset consists of 100 political news stories, each comprising three articles about the same main events, sourced from the New York Times, Fox News, and the Huffington Post. Articles containing less than 200 words or exceeding 1,000 words and op-eds were excluded from the dataset.\nOur analysis of the BASIL dataset, including political news longer than 200 words, identified three distinct clusters that differ in narrative structure. Clusters 1 and 2 are characterized as straight news, while cluster 3 is classified as interpretive news. The main sentence locations and statistics are listed in Table 4 and visualized in Figure 4. Sample articles are provided in Appendix F. Furthermore, we validate the clustering results in Appendix E."
        },
        {
            "heading": "8.2.1 Cluster 1 - Straight News with the Inverted Pyramid Structure",
            "text": "Our classifier identified that the main sentences in cluster 1 were located in the first quarter of the article, indicating the use of the inverted pyramid structure (Missouri Group, 2013). In this structure, the lead paragraph contains the core information of the news story, while subsequent paragraphs are arranged in decreasing order of importance (Van Dijk, 1985). By presenting the essential details at the beginning, readers can rapidly comprehend the main points of the article, resulting in a shorter article (P\u00f6ttker, 2003). These characteristics of straight news using the inverted pyramid structure are reflected in the lower article length and fewer biased sentences, which is shown in Table 4."
        },
        {
            "heading": "8.2.2 Cluster 2 - Straight News Beyond the Inverted Pyramid",
            "text": "Cluster 2 comprises news articles that are of similar length to those in cluster 1 and account for 4.3% of the whole dataset. Unlike cluster 1, which follows the inverted pyramid structure, the articles in cluster 2 present the main information at the beginning and in the article\u2019s first and second quarters. This structure still employs the inverted pyramid narrative but incorporates a distinct feature \u2013 bridge sentences. These sentences connect anecdotes or examples to the news story\u2019s broader theme and help tie seemingly unrelated information together, leading toward a cohesive narrative thread. Interestingly, articles in cluster 2 exhibit the least amount of lexical and informational bias."
        },
        {
            "heading": "8.2.3 Cluster 3 - Interpretive News",
            "text": "Cluster 3 is distinguished by main sentences that are typically located in the first and third quarters of\nthe article, with the latter sentences often reflecting the reporter\u2019s interpretation of the event (Van Dijk, 1985). This type of reporting aligns with the trend toward Interpretive news, which seeks to uncover the meaning of news beyond the facts and statements of sources (Schudson, 1982; Patterson, 1994; Salgado and Str\u00f6mb\u00e4ck, 2012). As a result, interpretive news tends to be longer than straight news and often includes analysis and commentary alongside the reporting of events (Barnhurst and Mutz, 1997). Our findings are consistent with the observations made by Chen et al. (2020), who found that any political bias in news stories, if present, tends to appear in the later part of the article."
        },
        {
            "heading": "9 Conclusions",
            "text": "Our multi-head attention model leverages sentencelevel information to capture the narrative structure. Our model outperforms conventional documentlevel classifiers by mitigating the domain dependency constraints of traditional classifiers and generating more robust and precise document-level representations. We validated our model\u2019s effectiveness in capturing journalism\u2019s rhetorical structures and writing styles.\nLimitations\nWhile news plays a vital role in every country and language, our method only applies to English news articles. Although the dataset contains articles from some international news outlets (e.g. Al Jazeera), most news outlets are from Western countries. As political bias in news articles closely relates to cultural background, we would like to expand our work to journalism in non-English languages or based in other non-western contexts.\nOur work is limited by the types of biases captured in the dataset. There are many approaches to bias, and the datasets available only reflect a limited range of discretized political bias. Future work from the community could focus on introducing better datasets and resources for modeling the many dimensions and nuances of bias."
        },
        {
            "heading": "Acknowledgements",
            "text": "Jiyoung Han and James Thorne are the corresponding authors. This work was supported by the Institute of Information and Communications Technology Planning & Evaluation (IITP) grant funded by the Korean government (MSIT; Grant No. 2019- 0-00075, Artificial Intelligence Graduate School\nProgram(KAIST)), Artificial Intelligence Industrial Convergence Cluster Development project funded by the Ministry of Science and ICT(MSIT, Korea) & Gwangju Metropolitan City, and by the National Research Foundation of Korea (NRF) grant funded by MSIT (Grant No. RS-2023-00252535)."
        },
        {
            "heading": "A Hyperparameters",
            "text": "For our model, we used AdamW as an optimizer with a weight decay of 1e-05 for both models. Both models were trained for 25 epochs. For BERT, we used a constant learning rate of 2e-05. For our model, we used a two-layered BiLSTM with size of 512. There parameters of the S-BERT sentence encoder were frozen and not updated during training. The number of attention head was fixed to 8. And we used a 1 cycle learning rate scheduler (Smith, 2015) with a maximum learning rate of 5e-05. The maximum learning rate was reached after 10 percent of the training was finished. We used a single Nvidia RTX A6000 to train the model: BERT took 9 minutes, and our model took 22 minutes per epoch for training with the full data. Hyperparameters were selected optimizing our model for the original dataset from (Baly et al., 2020) and then applied to our augmented datasets without modification."
        },
        {
            "heading": "B Hypothesis Tests",
            "text": "This section introduces the null hypothesis H0, alternative hypothesis H1, and ratio of variance f0 used in Section 7.2 and Section 7.3 to compare the robustness of baseline and our model.\nB.1 Sensitivity to test data H0 : \u00b5Set1 = \u00b5Set2 H1 : \u00b5Set1 \u0338= \u00b5Set2\n(5)\nB.2 Sensitivity to training data H0 : \u03c3 2 BERT = \u03c3 2 Ours\nH1 : \u03c3 2 BERT > \u03c3 2 Ours\n(6)\nf0 = S2BERT S2Ours\n(7)"
        },
        {
            "heading": "C List of News Outlets in Dataset",
            "text": ""
        },
        {
            "heading": "D Human Evaluation Template",
            "text": "We hired two annotators who are not experts in journalism to select the option that best follows the instructions given in Table 6. The three options were given to the annotator in a randomized order: 1) the lead of the news article, 2) set of randomly selected sentences, 3) the main sentences selected by our model. For the set of randomly selected articles, we first calculated the mean and variance of the main sentences selected by our model. Then we sampled twenty random numbers from the normal distribution with calculated mean and variance, which is used as a number of sentences to be randomly selected. After both annotations were finished, the authors measured Cohen\u2019s \u03ba and F1 scores after counting the common and uncommon annotations.\nE Validity of Clustering Results\nWe report the Silhouette score (Rousseeuw, 1987) and the additional results with changing the number of clusters. Also, we analyze the validity of Cluster 1 in Section 8.\n1. Silhouette Score: With the three clusters reported in Table 4, the Silhouette score was 0.8988. And the score consistently decreased as we increase the number of clusters.\n2. Increasing Number of Clusters: By clustering the news articles into three, four, and five clusters, the biggest cluster had 92% of items in K = 3, 91.33% in K = 4, and 88% in K = 5.\n3. Clustering within Cluster 1: By re-clustering the news articles in Cluster 1 into minimum two to maximum five clusters, the biggest cluster had 97.6% of items in K = 2, 90.9% in K = 3, 87.3% in K = 4, and 86.2% in K = 5."
        },
        {
            "heading": "F Sample News Articles from Each Cluster",
            "text": "We sampled two articles from each cluster and show their contents. The main sentences identified by the model are italicized bold sentences. The news outlet is mentioned in the bracket next to the headline. We report BERTScore (Zhang et al., 2019) between the set of selected main sentences and a summary from a BART model (Lewis et al., 2019) pre-trained on the CNN/Daily Mail dataset (Nallapati et al., 2016).\nF.1 Cluster 1 - Inverted Pyramid Structure\nHeadline Texas Rep. Blake Farenthold resigns from Congress (Fox News) Body U.S. Representative Blake Farenthold resigned from Congress on Friday, following multiple\nallegations of sexual harassment, misconduct and inappropriate behavior. Farenthold, R-Texas, had previously announced that he would not seek re-election in the 2018 midterm election, when reports of sexual misconduct first surfaced. \u201cWhile I planned on serving out the remainder of my term in Congress, I know in my heart it\u2019s time for me to move along and look for new ways to serve,\u201d Farenthold said in a statement Friday evening, noting he sent a letter to Texas Gov. Greg Abbott to tell him about his resignation, effective at 5 p.m. \u201cIt\u2019s been an honor and privilege to serve the constituents of Texas\u2019 27th Congressional District. I would like to thank my staff both in Washington and Texas for all of their hard work on behalf of our constituents. I would also like to thank my family for their unwavering support and most importantly the people that elected me,\u201d Farenthold said. \u201cLeaving my service in the House, I\u2019m able to look back at the entirety of my career in public office and say that it was well worthwhile.\u201d Farenthold was sued by his former aide, Lauren Greene, in 2014, alleging a hostile work environment, gender discrimination and retaliation. Among other things, Greene claimed Farenthold asked her for a threesome. She sued him and was paid $84,000 from a public fund on behalf of Farenthold for a sexual harassment claim. Farenthold pledged to repay the $84,000 in taxpayer money spent to settle the claim. Farenthold\u2019s former communications director, Michael Rekola, also described in detail the congressman\u2019s alleged abusive behavior toward staff members, which ranged from making sexually graphic jokes to verbally abusing his aides. Other staffers accused Farenthold of routinely commenting on the size of women\u2019s breasts and making jokes about being on \u201credhead patrol\u201d because he was attracted to women with red hair.\nBERTScore 0.9337\nTable 7: Example of an inverted pyramid structure article from cluster 1.\nF.2 Cluster 2 - Straight Reporting\nHeadline Republicans challenge Clinton claims on budget cuts, Benghazi cable (Fox News) Body Republicans are challenging a host of statements made by Secretary of State Hillary Clinton\nand Democratic allies during Wednesday\u2019s heated Libya testimony \u2013 claiming that complaints about a lack of funding are bogus and questioning the secretary\u2019s insistence she never saw urgent cables warning about the danger of an attack. The questions come as the Senate Foreign Relations Committee begins its confirmation hearing for Sen. John Kerry, D-Mass., who was tapped to replace Clinton at the department. One issue that may come up is the department\u2019s funding. Assertions that State Department posts are left vulnerable because Congress has decided not to fully fund security requests pervaded Wednesday\u2019s hearings. \"Shame on the House for ... failing to adequately fund the administration\u2019s request,\" Rep. Gregory Meeks, D-N.Y., said Democratic New York Rep. Eliot Engel repeatedly said Congress had \"slashed\" diplomatic security requests. Clinton, in turn, affirmed their claims, saying budget issues are a \"bipartisan problem.\" Budget numbers, though, actually show the overall diplomatic security budget has ballooned over the past decade. Democrats point to modest decreases in funding in recent years, and the fact that Congress has approved less than was requested. But Congress often scales back the administration\u2019s requests, and not just for the State Department. And the complaints tend to overlook the fact that the overall security budget has more than doubled since fiscal 2004. For that year, the budget was $640 million. It steadily climbed to $1.6 billion in fiscal 2010. It dipped to $1.5 billion the following year and roughly $1.35 billion in fiscal 2012 \u2013 still far more than it was a decade ago. Slightly more has been requested for fiscal 2013. It\u2019s difficult to tell how much was specifically allocated for Benghazi. Tripoli was the only post mentioned in the department\u2019s fiscal 2013 request \u2013 funding for that location did slip, from $11.5 million in fiscal 2011 to $10.1 million the following year. Slightly more has been requested for fiscal 2013. Still, then-Deputy Assistant Secretary for Diplomatic Security Charlene Lamb testified in October that the size of the attack \u2013 and not the money \u2013 was the issue. Asked if there was any budget consideration that led her not to increase the security force, she said: \"No.\" She added: \"This was an unprecedented attack in size.\" Asked again about budget issues, Lamb said: \"Sir, if it\u2019s a volatile situation, we will move assets to cover that.\" Asked Wednesday about Lamb\u2019s testimony, Clinton noted that the review board that examined the Libya attack found budget issues have played a role. \"That\u2019s why you have an independent group like an (Accountability Review Board); that\u2019s why it was created to look at everything,\" Clinton said. But Rep. Dana Rohrabacher, R-Calif., said \"any suggestion that this is a budget issue is off base, or political.\" Other lawmakers further complained that the State Department has spent millions on lower-priority projects that could have been spent on security. Another pivotal issue Wednesday dealt with an Aug. 16 cable. That cable summarized an emergency meeting the day before by the U.S. Mission in Benghazi and warned the consulate could not defend against a \"coordinated attack.\" That cable is seen as one of the vital warnings sent out of Libya in the months leading up to the attack. But, to the dismay of lawmakers, Clinton repeatedly said she never saw it. \"That cable did not come to my attention. I have made it very clear that the security cables did not come to my attention or above the assistant secretary level,\" Clinton said. \"I\u2019m not aware of anyone within my office, within the secretary\u2019s office, having seen the cable.\" Rep. Michael McCaul, R-Texas, said \"somebody within your office should have seen this cable.\" \"An emergency meeting was held and a cable sent out on Aug. 16 by the ambassador himself, warning of what could happen. And this meant this cable went unnoticed by your office. That\u2019s the bottom line,\" he said. Clinton said it was \"very disappointing\" that \"inadequacies\" were found in the \"responsiveness of our team here in Washington,\" and said \"it\u2019s something we\u2019re fixing and intend to put into place protocols and systems to make sure it doesn\u2019t happen again.\" The secretary tried to explain that \"1.43 million cables\" come through the department every year. They are addressed to her but in many cases do not go to her. Rather, they go through \"the bureaucracy.\" Republicans argue the Aug. 16 cable was rather high priority. As Sen. Rand Paul, R-Ky., put it, \"Libya has to have been one of the hottest of hot spots around the world.\" He claimed that not knowing about their security requests \"really, I think, cost these people their lives.\" \"Had I been president at the time, and I found that you did not read the cables from Benghazi, you did not read the cables from Ambassador Stevens, I would have relieved you of your post. I think it\u2019s inexcusable,\" Paul said.\nBERTScore 0.8849\nTable 9: Example of straight reporting article from cluster 2.\nF.3 Cluster 3 - Interpretive Reporting\nHeadline Supreme Court Questions Claims in Sex Bias Suit Against Wal-Mart (Fox News) Body A pending class action lawsuit against Wal-Mart that would be the largest of its kind in U.S.\nhistory may soon be dismissed, considering the tenor of oral arguments before the Supreme Court Tuesday. Although she may ultimately side with the plaintiffs, even Justice Ruth Bader Ginsburg, an ardent defender of women\u2019s rights, expressed some concerns about the particulars of the sex discrimination lawsuit that covers 1.5 million women and could cost the world\u2019s largest retailer billions of dollars. The key vote for a Wal-Mart victory could belong to Justice Anthony Kennedy, who said he was troubled by what he called an inconsistency in the women\u2019s lawsuit. \"Number one, you said this is a culture where Arkansas knows, the headquarters knows, everything that\u2019s going on,\" Kennedy told lawyer Joseph Sellers who represents the women. \"Then in the next breath, you say, well, now these (local) supervisors have too much discretion.\" The lawsuit alleges that the company\u2019s corporate culture, described in court Tuesday as the \"Wal-Mart Way,\" fosters the advancement of male workers over their female counterparts. It also claims that despite a company policy expressly prohibiting discrimination, local store managers are given too much flexibility in determining salary hikes and job promotions that invariably favor men over women. This dual argument that confounded Justice Kennedy also drew the ire of Justice Antonin Scalia who said he was whipsawed by the claims. \"If somebody tells you how to exercise discretion, you don\u2019t have discretion,\" he said. Chief Justice John Roberts also offered his doubts about the merits of lawsuit, suggesting that any discriminatory acts at Wal-Mart are no worse than anywhere else. \"Is it true that Wal-Mart\u2019s pay disparity across the company was less than the national average?\" he asked. Sellers said that wasn\u2019t a fair comparison because Wal-Mart has an obligation under federal law to make sure its managers do not discriminate. The case started a decade ago when Wal-Mart worker Betty Dukes said the management at her Pittsburg, Calif., store was bypassing her for promotions. \"I could see the men going forth and the women in the store stayed in the basic positions they were always in,\" Dukes once told an interviewer. Her discrimination claims were folded into a class action lawsuit covering all current female Wal-Mart employees and any who worked for the company going back to late 1998. Two lower courts said the case could move toward trial. Wal-Mart\u2019s appeal is asking the Supreme Court to stop the case from ever getting to a trial judge. On Tuesday, Dukes walked out of the courthouse full of confidence and poise saying she feels no anger toward her bosses or anyone else. \"Wal-Mart may be a big company and that is no doubt. But they are not big enough where they can\u2019t be challenged in a court of law. If you do wrong, then you should be held accountable. From the least of us to the greatest of us.\" Dukes\u2019s case has drawn the attention of the larger business community who fear that if the justices allow the case to proceed, it will open the doors to more class action lawsuits. The U.S. Chamber of Commerce and major corporations including Bank of America, General Electric and Microsoft submitted briefs in the case supporting Wal-Mart. Much of the hour-long argument delved into the tedious details of class action law and if the Wal-Mart women could properly certify their claims into a single case. Wal-Mart lawyer Theodore Boutrous argued that every member of the class couldn\u2019t possibly meet a standard of commonality to justify the lawsuit. \"Our expert\u2019s report and testimony showed that at 90 percent of the stores, there was no pay disparity,\" Boutrous told the court. \"And that\u2019s the kind of \u2013 and even putting that aside, the plaintiffs needed to come forward with something that showed that there was this miraculous recurrence at every decision across every store of stereotyping, and the evidence simply doesn\u2019t show that.\" Another technical concern that appears to work against the women covers the different types of remedies they are seeking. In addition to the punitive damages they want an injunction that would force Wal-Mart to adopt more stringent anti-discrimination policies. But those two remedies require different standards for class certification and Justice Ruth Bader Ginsburg said it was \"a very serious problem\" in the case to try and sue for punitive damages after only obtaining certification under the lower threshold required for the injunction. It\u2019s possible that instead of an outright victory for Wal-Mart, the justices could issue a split decision of sorts and allow only the injunction part of the lawsuit to move forward. That potential ruling would get Wal-Mart off the hook for any financial damages.\nBERTScore 0.8650\nTable 11: Example of interpretive reporting article from cluster 3.\n* This sample article is divided into three pages.\nHeadline Trump Declares a National Emergency, and Provokes a Constitutional Clash (New York Times) Body(Cont.) WASHINGTON \u2014 President Trump declared a national emergency on the border with Mexico\non Friday in order to access billions of dollars that Congress refused to give him to build a wall there, transforming a highly charged policy dispute into a confrontation over the separation of powers outlined in the Constitution. Trying to regain momentum after losing a grinding two-month battle with lawmakers over funding the wall, Mr. Trump asserted that the flow of drugs, criminals and illegal immigrants from Mexico constituted a profound threat to national security that justified unilateral action. \u201cWe\u2019re going to confront the national security crisis on our southern border, and we\u2019re going to do it one way or the other,\u201d he said in a televised statement in the Rose Garden barely 13 hours after Congress passed a spending measure without the money he had sought. \u201cIt\u2019s an invasion,\u201d he added. \u201cWe have an invasion of drugs and criminals coming into our country.\u201d But with illegal border crossings already down and critics accusing him of manufacturing a crisis, he may have undercut his own argument that the border situation was so urgent that it required emergency action. \u201cI didn\u2019t need to do this, but I\u2019d rather do it much faster,\u201d he said. \u201cI just want to get it done faster, that\u2019s all.\u201d The president\u2019s decision incited instant condemnation from Democrats, who called it an unconstitutional abuse of his authority and vowed to try to overturn it with the support of Republicans who also objected to the move. \u201cThis is plainly a power grab by a disappointed president, who has gone outside the bounds of the law to try to get what he failed to achieve in the constitutional legislative process,\u201d Speaker Nancy Pelosi of California and Senator Chuck Schumer of New York, the Democratic leader, said in a joint statement. Mr. Trump\u2019s announcement came during a freewheeling, 50-minute appearance in which he ping-ponged from topic to topic, touching on the economy, China trade talks and his coming summit meeting with North Korea\u2019s leader, Kim Jong-un. The president again suggested that he should win the Nobel Peace Prize, and he reviewed which conservative commentators had been supportive of him, while dismissing Ann Coulter, who has not. Sounding alternately defensive and aggrieved, Mr. Trump explained his failure to secure wall funding during his first two years in office when Republicans controlled both houses of Congress by saying, \u201cI was a little new to the job.\u201d He blamed \u201ccertain people, a particular one, for not having pushed this faster,\u201d a clear reference to former Speaker Paul D. Ryan of Wisconsin, a Republican. Mr. Trump\u2019s assertions were replete with misinformation and, when challenged by reporters, he refused to accept statistics produced by his own government that conflicted with his narrative. \u201cThe numbers that you gave are wrong,\u201d he told one reporter. \u201cIt\u2019s a fake question.\u201d On point after point, the president insisted that he would be proved correct. \u201cPeople said, \u2018Trump is crazy,\u2019\u201d he said at one point, discussing his outreach to Mr. Kim. \u201cAnd you know what it ended up being? A very good relationship.\u201d Mr. Trump acknowledged that his declaration of a national emergency would be litigated in the courts and even predicted a rough road for his side. \u201cLook, I expect to be sued,\u201d he said, launching into a mocking riff about how he anticipated lower court rulings against him. \u201cAnd we\u2019ll win in the Supreme Court,\u201d he predicted. Indeed, Public Citizen, an advocacy group, filed suit by the end of the day on behalf of three Texas landowners whose property might be taken for a barrier. California and New York likewise announced that they will sue over what Gov. Gavin Newsom of California called the president\u2019s \u201cvanity project,\u201d and a roster of other groups lined up to do the same. \u201cFortunately, Donald Trump is not the last word,\u201d said Mr. Newsom, a Democrat. \u201cThe courts will be the last word.\u201d Among those predicting a flurry of judicial decisions against Mr. Trump was George T. Conway III, a conservative lawyer and the husband of Kellyanne Conway, the president\u2019s counselor. \u201cIf he knows he is going to lose,\u201d Mr. Conway, a vocal critic of Mr. Trump, wrote on Twitter, \u201cthen he knows he is violating the Constitution and laws he has sworn to uphold.\u201d The House Judiciary Committee announced Friday that it would investigate the president\u2019s emergency claim, while House Democrats plan to introduce legislation to block it. That measure could pass both houses of Congress if it wins the votes of the half-dozen Republican senators who have criticized the declaration, forcing Mr. Trump to issue the first veto of his presidency. The emergency declaration, according to White House officials, enables the president to divert $3.6 billion from military construction projects to the wall. (Continued)\nBody(Cont.) Mr. Trump will also use more traditional presidential discretion to tap $2.5 billion from counternarcotics programs and $600 million from a Treasury Department asset forfeiture fund. Combined with $1.375 billion authorized for fencing in the spending package passed on Thursday night, Mr. Trump would have about $8 billion in all for barriers, significantly more than the $5.7 billion he unsuccessfully demanded from Congress. The president opted not to tap hurricane relief money from Texas or Puerto Rico, an idea that had generated angry complaints from Republicans. But he expressed no concern that diverting military construction money would delay projects benefiting the troops like base housing, schools and gyms. \u201cIt didn\u2019t sound too important to me,\u201d he said. Neither the White House nor the Pentagon had yet identified which projects may be shelved as a result, but Pentagon lawyers and other officials planned to work over the weekend to identify which construction funds would be diverted. The declaration also provided that land may be transferred to the Defense Department from other federal agencies or from privately purchased or condemned land. The next step would be to secure those lands, where the Pentagon would erect barriers. The declaration gives Patrick Shanahan, the acting defense secretary, broad latitude to carry out this process. Most Americans oppose Mr. Trump\u2019s emergency declaration, according to polls. One released this week by Fox News found 56 percent against it, including 20 percent of Republicans. Mr. Trump\u2019s desire for approval by Fox and other conservative news outlets was on display when he identified various pundits as supporters, naming Sean Hannity, Laura Ingraham, Tucker Carlson and Rush Limbaugh, although he insisted that \u201cthey don\u2019t decide policy.\u201d But Ms. Coulter, who has viscerally attacked Mr. Trump for caving on the wall, has clearly gotten under his skin. \u201cI don\u2019t know her,\u201d he said before quickly correcting himself. \u201cI hardly know her. I haven\u2019t spoken to her in way over a year.\u201d He noted, though, that she was an early predictor of his election victory. \u201cSo I like her, but she\u2019s off the reservation,\u201d he said. \u201cBut anybody that knows her understands that.\u201d Ms. Coulter fired back shortly afterward. \u201cThe only national emergency is that our president is an idiot,\u201d she said on KABC radio in Los Angeles. White House officials rejected criticism from across the ideological spectrum that Mr. Trump was creating a precedent that future presidents could use to ignore the will of Congress. Republicans have expressed concern that a Democratic commander in chief could cite Mr. Trump\u2019s move to declare a national emergency over gun violence or climate change without legislation from Congress. \u201cIt actually creates zero precedent,\u201d Mick Mulvaney, the acting White House chief of staff, told reporters. \u201cThis is authority given to the president in law already. It\u2019s not as if he just didn\u2019t get what he wanted so he\u2019s waving a magic wand and taking a bunch of money.\u201d Presidents have declared national emergencies under a 1970s-era law about five dozen times, and 31 of those prior emergencies remain active. But most of them dealt with foreign crises and involved freezing property, blocking trade or exports or taking other actions against national adversaries, not redirecting money without explicit congressional authorization. White House officials cited only two times that such emergency declarations were used by presidents to spend money without legislative approval \u2014 once by President George Bush in 1990 during the run-up to the Persian Gulf war, and again by his son, President George W. Bush, in 2001 after the terrorist attacks in New York, Washington and Pennsylvania. In both of those cases, the presidents were responding to new events \u2014 the Iraqi invasion of Kuwait and Al Qaeda\u2019s assault on the United States \u2014 and were moving military funds around for a military purposes. Neither was taking action specifically rejected by Congress. In Mr. Trump\u2019s case, he is defining a longstanding problem at the border as an emergency even though border apprehensions have actually fallen in recent years, to 400,000 in the last fiscal year from a peak of 1.6 million in the 2000 fiscal year. And unlike either of the Bushes, he is taking action after failing to persuade lawmakers to go along with his plans through the regular appropriations process. The spending package passed Thursday by Congress included none of the $5.7 billion that Mr. Trump demanded for 234 miles of steel wall. Instead, it provided $1.375 billion for about 55 miles of fencing. Mr. Trump signed the package into law on Friday anyway to avoid a second government shutdown after the impasse over border wall funding closed the doors of many federal agencies for 35 days and left 800,000 workers without pay. For weeks, Republicans led by Senator Mitch McConnell of Kentucky urged Mr. Trump not to declare a national emergency, but the president opted to go ahead anyway to find a way out of the political corner he had put himself in with the failed effort to force Congress to finance the wall. Mr. McConnell privately told the president that he would support the move despite his own reservations, but warned Mr. Trump that he had about two weeks to win over critical Republicans to avoid having Congress vote to reject the declaration. Mr. Trump was among those Republicans who criticized President Barack Obama for using his executive authority to spare millions of illegal immigrants from deportation after failing to persuade Congress to do so. (Continued)"
        },
        {
            "heading": "G Example Model Output",
            "text": ""
        }
    ],
    "title": "Disentangling Structure and Style: Political Bias Detection in News by Inducing Document Hierarchy",
    "year": 2023
}