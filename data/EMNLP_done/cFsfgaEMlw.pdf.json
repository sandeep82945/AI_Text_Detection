{
    "abstractText": "We introduce an encoding for syntactic parsing as sequence labeling that can represent any projective dependency tree as a sequence of 4-bit labels, one per word. The bits in each word\u2019s label represent (1) whether it is a right or left dependent, (2) whether it is the outermost (left/right) dependent of its parent, (3) whether it has any left children and (4) whether it has any right children. We show that this provides an injective mapping from trees to labels that can be encoded and decoded in linear time. We then define a 7-bit extension that represents an extra plane of arcs, extending the coverage to almost full non-projectivity (over 99.9% empirical arc coverage). Results on a set of diverse treebanks show that our 7-bit encoding obtains substantial accuracy gains over the previously best-performing sequence labeling encodings.",
    "authors": [
        {
            "affiliations": [],
            "name": "Carlos G\u00f3mez-Rodr\u00edguez"
        },
        {
            "affiliations": [],
            "name": "Diego Roca"
        },
        {
            "affiliations": [],
            "name": "David Vilares"
        }
    ],
    "id": "SP:0e3faadc796309131a9b4bae8faaeee7777eec3f",
    "references": [
        {
            "authors": [
                "Rodr\u00edguez"
            ],
            "title": "The fragility of multi-treebank",
            "year": 2022
        },
        {
            "authors": [
                "Afra Amini",
                "Ryan Cotterell."
            ],
            "title": "On parsing as tagging",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 8884\u20138900, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.",
            "year": 2022
        },
        {
            "authors": [
                "Afra Amini",
                "Tianyu Liu",
                "Ryan Cotterell."
            ],
            "title": "Hexatagging: Projective dependency parsing as tagging",
            "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 1453\u20131464, Toronto, Canada.",
            "year": 2023
        },
        {
            "authors": [
                "Mark Anderson",
                "Mathieu Dehouck",
                "Carlos G\u00f3mezRodr\u00edguez."
            ],
            "title": "A falta de pan, buenas son tortas: The efficacy of predicted UPOS tags for low resource UD parsing",
            "venue": "Proceedings of the 17th International Conference on Parsing Technologies and the IWPT",
            "year": 2021
        },
        {
            "authors": [
                "Mark Anderson",
                "Carlos G\u00f3mez-Rodr\u00edguez."
            ],
            "title": "Distilling neural networks for greener and faster dependency parsing",
            "venue": "Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced",
            "year": 2020
        },
        {
            "authors": [
                "Mark Anderson",
                "Carlos G\u00f3mez-Rodr\u00edguez."
            ],
            "title": "A modest Pareto optimisation analysis of dependency parsers in 2021",
            "venue": "Proceedings of the 17th International Conference on Parsing Technologies and the IWPT 2021 Shared Task on Parsing into Enhanced",
            "year": 2021
        },
        {
            "authors": [
                "Alexis Conneau",
                "Kartikay Khandelwal",
                "Naman Goyal",
                "Vishrav Chaudhary",
                "Guillaume Wenzek",
                "Francisco Guzm\u00e1n",
                "Edouard Grave",
                "Myle Ott",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Unsupervised cross-lingual representation learning at scale",
            "venue": "Pro-",
            "year": 2020
        },
        {
            "authors": [
                "Timothy Dozat",
                "Peng Qi",
                "Christopher D. Manning."
            ],
            "title": "Stanford\u2019s graph-based neural dependency parser at the CoNLL 2017 shared task",
            "venue": "Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,",
            "year": 2017
        },
        {
            "authors": [
                "Carlos G\u00f3mez-Rodr\u00edguez",
                "Joakim Nivre."
            ],
            "title": "A transition-based parser for 2-planar dependency structures",
            "venue": "Proceedings of the 48th Annual Meeting of",
            "year": 2010
        },
        {
            "authors": [
                "Carlos G\u00f3mez-Rodr\u00edguez",
                "Joakim Nivre."
            ],
            "title": "Divisible transition systems and multiplanar dependency parsing",
            "venue": "Computational Linguistics, 39(4):799\u2013845.",
            "year": 2013
        },
        {
            "authors": [
                "Carlos G\u00f3mez-Rodr\u00edguez",
                "Michalina Strzyz",
                "David Vilares."
            ],
            "title": "A unifying theory of transition-based and sequence labeling parsing",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 3776\u20133793, Barcelona, Spain (On-",
            "year": 2020
        },
        {
            "authors": [
                "Carlos G\u00f3mez-Rodr\u00edguez",
                "David Vilares."
            ],
            "title": "Constituent parsing as sequence labeling",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1314\u20131324, Brussels, Belgium. Association for Computational",
            "year": 2018
        },
        {
            "authors": [
                "Nikita Kitaev",
                "Dan Klein."
            ],
            "title": "Tetra-tagging: Word-synchronous parsing with linear-time inference",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6255\u2013 6261, Online. Association for Computational Lin-",
            "year": 2020
        },
        {
            "authors": [
                "Oph\u00e9lie Lacroix."
            ],
            "title": "Dependency parsing as sequence labeling with head-based encoding and multitask learning",
            "venue": "Proceedings of the Fifth International Conference on Dependency Linguistics (Depling, SyntaxFest 2019), pages 136\u2013143, Paris,",
            "year": 2019
        },
        {
            "authors": [
                "Alberto Mu\u00f1oz-Ortiz",
                "Michalina Strzyz",
                "David Vilares."
            ],
            "title": "Not all linearizations are equally datahungry in sequence labeling parsing",
            "venue": "Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP",
            "year": 2021
        },
        {
            "authors": [
                "Michalina Strzyz",
                "David Vilares",
                "Carlos G\u00f3mezRodr\u00edguez."
            ],
            "title": "Viable dependency parsing as sequence labeling",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
            "year": 2019
        },
        {
            "authors": [
                "Michalina Strzyz",
                "David Vilares",
                "Carlos G\u00f3mezRodr\u00edguez."
            ],
            "title": "Bracketing encodings for 2-planar dependency parsing",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 2472\u20132484, Barcelona, Spain (Online). Inter-",
            "year": 2020
        },
        {
            "authors": [
                "Rob van der Goot",
                "Ahmet \u00dcst\u00fcn",
                "Alan Ramponi",
                "Ibrahim Sharaf",
                "Barbara Plank."
            ],
            "title": "Massive choice, ample tasks (MaChAmp): A toolkit for multitask learning in NLP",
            "venue": "Proceedings of the 16th",
            "year": 2021
        },
        {
            "authors": [
                "Yufei Wang",
                "Mark Johnson",
                "Stephen Wan",
                "Yifang Sun",
                "Wei Wang."
            ],
            "title": "How to best use syntax in semantic role labelling",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5338\u20135343, Florence, Italy. Asso-",
            "year": 2019
        },
        {
            "authors": [
                "Anssi Yli-Jyr\u00e4."
            ],
            "title": "Bounded-depth high-coverage search space for noncrossing parses",
            "venue": "Proceedings of the 13th International Conference on Finite State Methods and Natural Language Processing (FSMNLP 2017), pages 30\u201340, Ume\u00e5, Sweden. As-",
            "year": 2017
        },
        {
            "authors": [
                "Anssi Mikael Yli-Jyr\u00e4."
            ],
            "title": "Multiplanarity \u2013 a model for dependency structures in treebanks",
            "venue": "TLT 2003. Proceedings of the Second Workshop on Treebanks and Linguistic Theories, volume 9 of Mathematical Modelling in Physics, Engineering and Cognitive",
            "year": 2003
        },
        {
            "authors": [
                "Anssi Mikael Yli-Jyr\u00e4."
            ],
            "title": "How to embed noncrossing trees in universal dependencies treebanks in a low-complexity regular language",
            "venue": "Journal of Language Modelling, 7(2):177\u2013232.",
            "year": 2019
        },
        {
            "authors": [
                "structures). E Hexatagging Amini"
            ],
            "title": "2023) use an intermediate representation, called binary head trees, that acts as a proxy between dependency trees and hexatags",
            "year": 2023
        },
        {
            "authors": [
                "G\u00f3mez-Rodr\u00edguez"
            ],
            "title": "G Non-Surjectivity in Decoding As mentioned in the main text, all encodings explored in this paper are non-surjective, meaning that there are label sequences",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Approaches that cast parsing as sequence labeling have gathered interest as they are simple, fast (Anderson and G\u00f3mez-Rodr\u00edguez, 2021), highly parallelizable (Amini and Cotterell, 2022) and produce outputs that are easy to feed to other tasks (Wang et al., 2019). Their main ingredient are the encodings that map trees into sequences of one discrete label per word. Thus, various such encodings have been proposed both for constituency (G\u00f3mezRodr\u00edguez and Vilares, 2018; Amini and Cotterell, 2022) and dependency parsing (Strzyz et al., 2019; Lacroix, 2019; G\u00f3mez-Rodr\u00edguez et al., 2020).\nMost such encodings have an unbounded label set, whose cardinality grows with sentence length. An exception for constituent parsing is tetratagging (Kitaev and Klein, 2020). For dependency parsing, to our knowledge, no bounded encodings were known. Simultaneously to this work, Amini et al. (2023) have just proposed one: hexatagging, where projective dependency trees are represented by tagging each word with one of a set of 8 tags.1\n1The \u201chexa\u201d in the name comes from a set of six atoms\nContribution We present a bounded sequencelabeling encoding that represents any projective dependency tree with 4 bits (i.e., 16 distinct labels) per word. While this requires one more bit than hexatagging, it is arguably more straightforward, as the bits directly reflect properties of each node in the dependency tree without an intermediate constituent structure, as hexatagging requires. Also, it has a clear relation to existing bracketing encodings, and has a straightforward non-projective extension using 7 bits with almost full non-projective coverage. Empirical results show that our encoding provides more accurate parsers than the existing unbounded bracketing encodings, which had the best previous results among sequence-labeling encodings, although it underperforms hexatagging."
        },
        {
            "heading": "2 Projective Encoding",
            "text": "Let Tn be a set of unlabeled dependency trees2 for sentences of length n. A sequence-labeling encoding defines a function \u03a6n : Tn \u2192 Ln, for a label set L. Thus, each tree for a sentence w1 . . . wn is encoded as a sequence of labels, l1 . . . ln, that assigns a label li \u2208 L to each word wi.\nWe define the 4-bit projective encoding as an encoding where Tn is the set of projective depen-\nused to define the labels. However, the label for each word is composed of two such atoms (one from a set of two, and other from a set of four) so there are eight possible labels per word.\n2For simplicity, we ignore dependency labels in definitions. In the implementation, they are added as a separate component to the label of each word, following common practice.\ndency trees, and we assign to each word wi a label li = b0b1b2b3, such that bj is a boolean as follows:\n\u2022 b0 is true if wi is a right dependent, and false if it is a left dependent. Root nodes are considered right dependents for this purpose (i.e., we assume that they are linked as dependents of a dummy root node w0 located to the left).\n\u2022 b1 is true iff wi is the outermost right (or left) dependent of its parent node.\n\u2022 b2 (respectively, b3) is true iff wi has one or more left (right) dependents.\nAll combinations of the four bits are possible, so we have 16 possible labels.\nFor easier visualization and comparison to existing bracketing encodings, we will represent the values of b0 as > (right dependent) or < (left dependent), b1 as * (true) or blank (false), and b2 and b3 respectively as \\ and / (true) or blank (false). We will use these representations with set notation to make claims about a label\u2019s bits, e.g. >* \u2208 l means that label l has b0 = 1, b1 = 1. Figure 1 shows a sample tree encoded with this method.\nWe will now show how to encode and decode trees, and prove that the encoding is a total, injective map from projective trees to label sequences.\nEncoding and Totality Encoding a tree is trivial: one just needs to traverse each word and apply the definition of each bit to obtain the label. This also means that our encoding from trees to labels is a total function, as the labels are well defined for any dependency tree (and thus, for any projective tree).\nDecoding and Injectivity Assuming a wellformed sequence of labels, we can decode it to a tree. We can partition the arcs of any tree t \u2208 Tn into a subset of left arcs, tl, and a subset of right arcs, tr. We will decode these subsets separately. Algorithm 1 shows how to obtain the arcs of tr.\nThe idea of the algorithm is as follows: we read labels from left to right. When we find a label containing /, we know that the corresponding node will be a source of one or more right arcs. We push it into the stack. When we find a label with >, we know that its node is the target of a right arc, so we link it to the / on top of the stack. Additionally, if the label contains *, the node is a rightmost sibling, so we pop the stack because no more arcs will be\nAlgorithm 1 To decode right arcs in the 4-bit encoding. 1: function DECODERIGHTARCS(l1..ln) 2: s\u2190 empty stack 3: a\u2190 empty set of arcs 4: s.push(0) \u25b7 corresponding to dummy root 5: for i\u2190 1 to n do 6: if >\u2208 li then 7: a.addArc( s.peek() \u2192 i) 8: if \u2217 \u2208 li then 9: s.pop() 10: end if 11: end if 12: if / \u2208 li then 13: s.push(i) 14: end if 15: end for 16: return a 17: end function\ncreated from the same head. Otherwise, we do not pop as we expect more arcs from the same origin.3\nIntuitively, this lets us generate all the possible non-crossing combinations of right arcs: the stack enforces projectivity (to cover a / label with a dependency we need to remove it from the stack, so crossing arcs from inside the covering dependency to its right are not allowed), and the distinction between > with and without * allows us to link a new node to any of the previous, non-covered nodes.\nTo decode left arcs, we use a symmetric algorithm DecodeLeftArcs (not shown as it is analogous), which traverses the labels from right to left, operating on the elements \\ and < rather than / and >; with the difference that the stack is not initialized with the dummy root node (as the arc originating in it is a right arc). By the same reasoning as above, this algorithm can obtain all the possible non-crossing configurations of left arcs, and hence the mapping is injective. The decoding is trivially linear-time with respect to sequence length.\nA sketch of an injectivity proof can be based on showing that the set of right arcs generated by Algorithm 1 (and the analogous for left arcs) is the only possible one that meets the conditions of the labels and does not have crossing arcs (hence, we cannot have two projective trees with the same encoding). To prove this, we can show that at each iteration, the arc added by line 7 of Algorithm 1 is the only possible alternative that can lead to a legal projective tree (i.e., that s.peek() is the only possible parent of node i). This is true because (1)\n3Note that, thus, the interpretation of the symbols / and > is similar to that of the same symbols in the unbounded bracketing encoding by (Strzyz et al., 2019), but here the / symbol is acting as a \u201csuperbracket\u201d that matches several opposing brackets (Yli-Jyr\u00e4, 2017; Yli-Jyr\u00e4, 2019)\nif we choose a parent to the left of s.peek(), then we cover s.peek() with a dependency, while it has not yet found all of its right dependents (as otherwise it would have been popped from the stack), so a crossing arc will be generated later; (2) if we choose a parent to the right of s.peek() and to the left of i, its label must contain / (otherwise, by definition, it could not have right dependents) and not be on the stack (as the stack is always ordered from left to right), so it must have been removed from the stack due to finding all its right dependents, and adding one more would violate the conditions of the encoding; and finally (3) a parent to the right of i cannot be chosen as the algorithm is only considering right arcs. Together with the analogous proof for the symmetric algorithm, we show injectivity.\nCoverage While we have defined and proved this encoding for projective trees,4 its coverage is actually larger: it can encode any dependency forest (i.e., does not require connectedness) such that arcs in the same direction do not cross (i.e., it can handle some non-projective structures where arcs only cross in opposite directions, as the process of encoding and decoding left and right arcs is independent). This is just like in the unbounded bracketing encodings of (Strzyz et al., 2019), but this extra coverage is not very large in practice, and we will define a better non-projective extension later.\nNon-surjectivity Just like other sequencelabeling encodings (Strzyz et al., 2019; Lacroix, 2019; Strzyz et al., 2020, inter alia), ours is not surjective: not every label sequence corresponds to a valid tree, so heuristics are needed to fix cases where the sequence labeling component generates an invalid sequence. This can happen regardless of whether we only consider a tree to be valid if it is projective, or we accept the extra coverage mentioned above. For example, a sequence where the last word is marked as a left child (<) is invalid in either case. Trying to decode invalid label sequences will result in trying to pop an empty stack or leaving material in the stack after finishing Algorithm 1 or its symmetric. In practice, we can\n4If we did not consider a dummy root, we would be able to cover planar trees, rather than just projective trees (as in the bracketing of (Strzyz et al., 2019)), but this would require an extra label for the sentence\u2019s syntactic root. Instead, we use a dummy root on the left and explicitly encode the arc from it to the syntactic root, which is thus labeled as a right child instead of using an extra label. This simplifies the encoding, and the practical difference between the coverage of projectivity and planarity is small (G\u00f3mez-Rodr\u00edguez and Nivre, 2013).\nskip dependency creation when the stack is empty, ignore material left in the stack after decoding, break cycles and (if we require connectedness) attach any unconnected nodes to a neighbor."
        },
        {
            "heading": "3 Non-Projective Encoding",
            "text": "For a wider coverage of non-projective dependency trees (including the overwhelming majority of trees found in treebanks), we use the same technique as defined for unbounded brackets in (Strzyz et al., 2020): we partition dependency trees into two subsets (planes) of arcs (details in Appendix D), and this lets us define a 7-bit non-projective encoding by assigning each word wi a label li = (b0 . . . b6), where:\n\u2022 b0b1 can take values <0 (wi is a left dependent in the first plane), >0 (right dependent in the 1st plane), <1 or >1 (same for the 2nd plane).\n\u2022 b2 is true iff wi is the outermost right (or left) dependent of its parent (regardless of plane). We represent it as * if true or blank if false.\n\u2022 b3 (respectively, b4) is true iff wi has one or more left (right) dependents in the first plane. We denote it as \\0 (/0) if true, blank if false.\n\u2022 b5 and b6 are analogous to b3 and b4, but in the second plane, represented as \\1 or /1.\nEvery 7-bit combination is possible, leading to 128 distinct labels. Figure 2 shows an example of a non-projective tree represented with this encoding.\nThe encoding is able to cover every possible dependency tree whose arc set can be partitioned into two subsets (planes), such that arcs with the same direction and plane do not cross.\nThis immediately follows from defining the decoding with a set of four algorithms, two for decoding left and right arcs on the first plane (defined as Algorithm 1 and its symmetric, but considering only the symbols making reference to arcs in the first plane) and other two identical decoding passes for the second plane. With this, injectivity\nis shown in the same way as for the 4-bit encoding. Decoding is still linear-time.\nNote that the set of trees covered by the encoding, described above, is a variant of the set of 2-Planar trees (Yli-Jyr\u00e4, 2003; G\u00f3mez-Rodr\u00edguez and Nivre, 2010), which are trees that can be split into two planes such that arcs within the same plane do not cross, regardless of direction. Compared to 2- Planar trees, and just like the encodings in (Strzyz et al., 2020), our set is extended as it allows arcs with opposite directions to cross within the same plane. However, it also loses some trees because the dummy root arc is also counted when restricting crossings, whereas in 2-Planar trees it is ignored."
        },
        {
            "heading": "4 Experiments",
            "text": "We compare our 4-bit and 7-bit encodings to their unbounded analogs, the bracketing (Strzyz et al., 2019) and 2-planar bracketing encodings (Strzyz et al., 2020) which overall are the best performing in previous work (Mu\u00f1oz-Ortiz et al., 2021). We use MaChAmp (van der Goot et al., 2021) as a sequence labeling library, with default hyperparameters (Appendix B). We use XLM-RoBERTa (Conneau et al., 2020) followed by two separate onelayered feed-forward networks, one for syntactic labels and another for dependency types. We evaluate on the Penn Treebank Stanford Dependencies 3.3.0 conversion and on UD 2.9: a set of 9 linguistically-diverse treebanks taken from (Anderson and G\u00f3mez-Rodr\u00edguez, 2020), and a lowresource set of 7 (Anderson et al., 2021). We consider multiple subsets of treebanks as a single subset could be fragile (Alonso-Alonso et al., 2022).\nTable 1 compares the compactness of the encodings by showing the number of unique syntactic labels needed to encode the (unlabeled) trees in the training set (i.e. the label set of the first task). The new encodings yield clearly smaller label set sizes,\nas predicted in theory. In particular, the 4-bit encoding always uses its 16 distinct labels. The 7-bit encoding only needs its theoretical maximum of 128 labels for the Ancient Greek treebank (the most non-projective one). On average, it uses around a third as many labels as the 2-planar bracketing encoding, and half as many as the basic bracketing. Regarding coverage, the 7-bit encoding covers over 99.9% of arcs, like the 2-planar bracketing. The 4-bit encoding has lower coverage than basic brackets: both cover all projective trees, but they differ on coverage of non-projectivity (see Appendix C for an explanation of the reasons). More detailed data (e.g. coverage and label set size for low-resource treebanks) is in Appendix A.\nTable 2 shows the models\u2019 performance in terms of LAS. The 4-bit encoding has mixed performance, excelling in highly projective treebanks like the PTB or Hebrew-HTB, but falling behind in non-projective ones like Ancient Greek, which is consistent with the lower non-projective coverage. The 7-bit encoding, however, does not exhibit this problem (given the almost total arc coverage mentioned above) and it outperforms both baselines for every treebank: the basic bracketing by 1.16 and the 2-planar one by 1.96 LAS points on average.5\nIf we focus on low-resource corpora (Table 3), label set sparsity is especially relevant so compact-\n5In our setup, the basic bracketing encoding baseline beats the 2-planar baseline on average, contrary to the results in the papers that introduced them (cf. (Strzyz et al., 2020)). This likely owes to the architecture used: they used BiLSTMs, whereas we perform our experiments on a more competitive architecture with XLM-RoBERTa.\nness further boosts accuracy. The new encodings obtain large improvements, the 7-bit one surpassing the best baseline by over 3 average LAS points."
        },
        {
            "heading": "4.1 Additional results: splitting bits and external parsers",
            "text": "We perform additional experiments to test implementation variants of our encodings, as well as to put our results into context with respect to nonsequence-labeling parsers and simultaneous work. In the previous tables, both for the 4-bit and 7-bit experiments, all bits were predicted as a single, atomic task. We contrast this with a multi-task version where we split certain groups of bits to be predicted separately. We only explore a preliminary division of bits. For the 4-bit encoding, instead of predicting a label of the form b0b1b2b3, the model predicts two labels of the form b0b1 and b2b3, respectively. We call this method 4-bit-s. For the 7-bit encoding, we decided to predict the bits corresponding to each plane as a separate task, i.e., b0b2b3b4 and b1b5b6. We call this method 7-bit-s. We acknowledge that other divisions could be better. However, this falls outside the scope of this paper.\nWe additionally compare our results with other relevant models. As mentioned earlier, alongside this work, Amini et al. (2023) introduced a parsingas-tagging method called hexatagging. In what follows, we abbreviate this method as 6tg. We implement 6tg under the same framework as our encodings for homogeneous comparison, and we predict these hexatags through two separate linear layers, one to predict the arc representation and another for the dependency type. We also consider a split version, 6tg-s, where the two components of the arc representation are predicted separately. For a better understanding of their method, we refer the reader to Amini et al. and Appendix E. Finally, we include a comparison against the biaffine graphbased parser by Dozat et al. (2017). For this, we trained the implementation in SuPar6 using xlmroberta-large as the encoder, which is often taken as a strong upper bound baseline.\nTable 4 compares the performance of external parsers with our bit encodings. First, the results show that the choice of whether to split labels into components or not has a considerable influence, both for 6tg (where splitting is harmful across the board) and for our encodings (where it is mostly\n6https://github.com/yzhangcs/parser\nbeneficial, perhaps because the structure of the encoding in bits with independent meanings naturally lends itself to multi-task learning). Second, on average, the best (multi-task) version of our 7-bit encoding is about 1.7 points behind the 6tg and 1.2 behind biaffine state-of-the-art parsers in terms of LAS. However, the difference between versions with and without multi-task learning suggests that there might be room for improvement by investigating different splitting techniques. Additionally, in Appendix F, Table 14 compares the processing speeds of these parsers (on a single CPU). In Appendix G, Tables 15 and 16 show how often heuristics are applied in decoding.\nFinally, Table 5 shows the external comparison on the low-resource treebanks, where our encodings lag further behind biaffine and especially 6tg, which surpasses 7-bit-s by over 5 points."
        },
        {
            "heading": "5 Conclusion",
            "text": "We have presented two new bracketing encodings for dependency parsing as sequence labeling, which use a bounded number of labels. The 4-bit encoding, designed for projective trees, excels in projective treebanks and low-resource setups. The 7-bit encoding, designed to accommodate non-projectivity, clearly outperforms the best prior sequence-labeling encodings across a diverse set of treebanks. The source code is available at https://github.com/Polifack/ CoDeLin/releases/tag/1.25.\nLimitations\nIn our experiments, we do not perform any hyperparameter optimization or other task-specific tweaks to try to bring the raw accuracy figures as close as possible to state of the art. This is for several reasons: (1) limited resources, (2) the paper having a mainly theoretical focus, with the experiments serving to demonstrate that our encodings are useful when compared to alternatives (the baselines) rather than chasing state-of-the-art accuracy, and (3) because we believe that one of the primary advantages of parsing as sequence labeling is its ease of use for practitioners, as one can perform parsing with any off-the-shelf sequence labeling library, and our results directly reflect this kind of usage. We note that, even under such a setup, raw accuracies are remarkably good.\nEthics Statement\nThis is a primarily theoretical paper that presents new encodings for the well-known task of dependency parsing. We conduct experiments with the sole purpose of evaluating the new encodings, and we use publicly-available standard datasets that have long been in wide use among the NLP community. Hence, we do not think this paper raises any ethical concern."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work has received funding by the European Research Council (ERC), under the Horizon Europe research and innovation programme (SALSA, grant agreement No 101100615), ERDF/MICINN-AEI (SCANNER-UDC, PID2020113230RB-C21), Xunta de Galicia (ED431C 2020/11), Grant GAP (PID2022-139308OA-I00) funded by MCIN/AEI/10.13039/501100011033/ and by ERDF \u201cA way of making Europe\u201d, and Centro de Investigaci\u00f3n de Galicia \u201cCITIC\u201d, funded by the Xunta de Galicia through the collaboration agreement between the Conseller\u00eda de Cultura, Educaci\u00f3n, Formaci\u00f3n Profesional e Universidades and the Galician universities for the reinforcement of the research centres of the Galician University System (CIGUS)."
        },
        {
            "heading": "A Further Data",
            "text": "Tables 6 and 7 show treebank statistics for the general and low-resource set of treebanks, respectively.\nTable 8 shows the number of labels and the arc coverage of each considered encoding for the lowresource treebank set of Anderson et al. (2021), in the same notation as in Table 1. As can be seen in the table, the trends are analogous to those for the other treebanks (Table 1 in the main text).\nTables 9 and 10 show the coverage of the encodings in terms of full trees, rather than arcs (i.e., what percentage of the dependency trees in each treebank can be fully encoded and decoded back by each of the encodings).\nTables 11 and 12 show the total number of labels needed to encode the training set for each encoding and treebank, when considering full labels (i.e., the number of combinations of syntactic labels and dependency type labels). This can be relevant for implementations that generate such combinations as atomic labels (in our implementation, label components are generated separately instead)."
        },
        {
            "heading": "B Hyperparameters",
            "text": "We did not perform hyperparameter search, but just used MaChAmp\u2019s defaults, which can be seen in Table 13."
        },
        {
            "heading": "C Coverage Differences",
            "text": "It is worth noting that, while the 7-bit encoding has exactly the same coverage as the 2-planar bracketing encoding (see Tables 1, 8, 9, 10); the 4-bit encoding has less coverage than the basic bracketing. As mentioned in the main text, both have full coverage of projective trees, but there are subtle differences in how they behave when they are applied to non-projective trees. We did not enumerate all of these differences in detail for space reasons. In particular, they are the following:\n\u2022 Contrary to basic bracketing, the 4-bit encoding needs to encode the arc originating from the dummy root explicitly. This means that it cannot encode non-projective, but planar trees where the dummy root arc crosses a right arc (or equivalently, the syntactic root is covered by a right arc).\n\u2022 In the basic bracketing, a dependency involving words wi and wj (i < j) is not encoded in the labels of wi and wj , but in the labels of wi+1 and wj (see (Strzyz et al., 2019)), as a technique to alleviate sparsity (in the particular case of that encoding, it guarantees that the worst-case number of labels is linear, rather than quadratic, with respect to sentence length). In the 2-planar, 4- and 7-bit encodings, this is unneeded so dependencies are encoded directly in the labels of the intervening words.\n\u2022 Contrary to basic bracketing, in the 4-bit encoding a single / or \\ element is shared by several arcs. Thus, if an arc cannot be successfully encoded due to unsupported nonprojectivity, the problem can propagate to sibling dependencies. In other words, due to being more compact, the 4-bit encoding has less redundancy than basic bracketing."
        },
        {
            "heading": "D Plane Assignment",
            "text": "The 2-planar and 7-bit encodings need a strategy to partition trees into two planes. We used the second-plane-averse strategy based on restriction propagation on the crossings graph (Strzyz et al., 2020). It can be summarized as follows:\n1. The crossings graph is defined as an undirected graph where each node corresponds to an arc in the dependency tree, and there is an edge between nodes a and b if arc a crosses arc b in the dependency tree.\n2. Initially, both planes are marked as allowed for every arc in the dependency tree.\n3. The arcs are visited in the order of their right endpoint, moving from left to right. Priority is given to shorter arcs if they have a common right endpoint. Once sorted, we iterate through the arcs.\n4. Whenever we assign an arc a to a given plane p, we immediately propagate restrictions in\nthe following way: we forbid plane p for the arcs that cross a (its neighbors in the crossings graph), we forbid the other plane (p\u2032) for the neighbors of its neighbors, plane p for the neighbors of those, and so on.\n5. Plane assignment is made by traversing arcs. For each new arc a, we look at the restrictions and assign it to the first plane if allowed, otherwise to the second plane if allowed, and finally to no plane if none is allowed (for non2-planar structures)."
        },
        {
            "heading": "E Hexatagging",
            "text": "Amini et al. (2023) use an intermediate representation, called binary head trees, that acts as a proxy between dependency trees and hexatags. These trees have a structure akin to binary constituent trees in order to apply the tetra-tagging encoding (Kitaev and Klein, 2020). In addition, non-terminal intermediate nodes are labeled with \u2018L\u2019 or \u2018R\u2019 based on whether the head of the constituent is on its left or right subtree. We direct the reader to the paper for specifics. However, a mapping between projective dependency trees and this structure can be achieved by starting at the sentence\u2019s root and conducting a depth-first traversal of the tree. The arc representation components for each hexatag encode: (i) the original label corresponding to the tetratag, and (ii) the value of the non-terminal symbol in the binary head tree."
        },
        {
            "heading": "F Speed comparison",
            "text": "Table 14 compares the speed of the models over an execution on a single CPU.7 It is important to note that while SuPar is an optimized parser, in this context, we used MaChAmp as a general sequence labeling framework without specific optimization for speed. With a more optimized model, practical processing speeds in the range of 100 sentences per second on CPU or 1000 on a consumer-grade GPU should be achievable (cf. the figures for sequencelabeling parsing implementations in (Anderson and G\u00f3mez-Rodr\u00edguez, 2021))."
        },
        {
            "heading": "G Non-Surjectivity in Decoding",
            "text": "As mentioned in the main text, all encodings explored in this paper are non-surjective, meaning that there are label sequences that do not correspond to a valid tree. In these cases, the labels\n7Intel(R) Core(TM) i9-10920X CPU @ 3.50GHz.\nare decoded using simple heuristics (e.g. skipping dependency creation if the stack is empty, ignoring material remaining in the stack after decoding, attaching unconnected nodes and breaking cycles). Table 15 shows data about the number of trees in the test set such that the labels output by the tagger do not directly correspond to a valid tree, and at least one of these heuristics has to be applied. Table 16 shows the same information in terms of the percentage of dependency arcs that are affected by said heuristics."
        }
    ],
    "title": "4 and 7-bit Labeling for Projective and Non-Projective Dependency Trees",
    "year": 2023
}