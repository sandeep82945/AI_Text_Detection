{
    "abstractText": "Given a textual passage and an answer, humans are able to ask questions with various expressions, but this ability is still challenging for most question generation (QG) systems. Existing solutions mainly focus on the internal knowledge within the given passage or the semantic word space for diverse content planning. These methods, however, have not considered the potential of external knowledge for expression diversity. To bridge this gap, we propose RAST, a framework for Retrieval-Augmented Style Transfer, where the objective is to utilize the style of diverse templates for question generation. For training RAST, we develop a novel Reinforcement Learning (RL) based approach that maximizes a weighted combination of diversity reward and consistency reward. Here, the consistency reward is computed by a Question-Answering (QA) model, whereas the diversity reward measures how much the final output mimics the retrieved template. Experimental results show that our method outperforms previous diversity-driven baselines on diversity while being comparable in terms of consistency scores. Our code is available at https://github.com/gouqi666/RAST.",
    "authors": [
        {
            "affiliations": [],
            "name": "Qi Gou"
        },
        {
            "affiliations": [],
            "name": "Zehua Xia"
        },
        {
            "affiliations": [],
            "name": "Bowen Yu"
        },
        {
            "affiliations": [],
            "name": "Haiyang Yu"
        },
        {
            "affiliations": [],
            "name": "Fei Huang"
        },
        {
            "affiliations": [],
            "name": "Yongbin Li"
        },
        {
            "affiliations": [],
            "name": "Cam-Tu Nguyen"
        }
    ],
    "id": "SP:bbf246ddee8fe8b797d2b4582e8f513198b7e208",
    "references": [
        {
            "authors": [
                "Chris Alberti",
                "Daniel Andor",
                "Emily Pitler",
                "Jacob Devlin",
                "Michael Collins."
            ],
            "title": "Synthetic QA corpora generation with roundtrip consistency",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics.",
            "year": 2019
        },
        {
            "authors": [
                "Deng Cai",
                "Yan Wang",
                "Wei Bi",
                "Zhaopeng Tu",
                "Xiaojiang Liu",
                "Wai Lam",
                "Shuming Shi."
            ],
            "title": "Skeletonto-response: Dialogue generation guided by retrieval memory",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Deng Cai",
                "Yan Wang",
                "Wei Bi",
                "Zhaopeng Tu",
                "Xiaojiang Liu",
                "Shuming Shi."
            ],
            "title": "Retrievalguided dialogue response generation via a matchingto-generation framework",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natu-",
            "year": 2019
        },
        {
            "authors": [
                "Shuyang Cao",
                "Lu Wang."
            ],
            "title": "Controllable openended question generation with a new question type ontology",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natu-",
            "year": 2021
        },
        {
            "authors": [
                "Hao Chen",
                "Rui Xia",
                "Jianfei Yu."
            ],
            "title": "Reinforced counterfactual data augmentation for dual sentiment classification",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 269\u2013278, Online and Punta Cana,",
            "year": 2021
        },
        {
            "authors": [
                "Yu Chen",
                "Lingfei Wu",
                "Mohammed J. Zaki."
            ],
            "title": "Reinforcement learning based graph-to-sequence model for natural question generation",
            "venue": "Proceedings of the 8th International Conference on Learning Representations.",
            "year": 2020
        },
        {
            "authors": [
                "Jaemin Cho",
                "Minjoon Seo",
                "Hannaneh Hajishirzi."
            ],
            "title": "Mixture content selection for diverse sequence generation",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on",
            "year": 2019
        },
        {
            "authors": [
                "Shaobo Cui",
                "Xintong Bao",
                "Xinxing Zu",
                "Yangyang Guo",
                "Zhongzhou Zhao",
                "Ji Zhang",
                "Haiqing Chen"
            ],
            "title": "Onestop qamaker: Extract question-answer pairs from text in a one-stop approach",
            "year": 2021
        },
        {
            "authors": [
                "Arthur Deschamps",
                "Sujatha Das Gollapalli",
                "See Kiong Ng."
            ],
            "title": "On generating fact-infused question variations",
            "venue": "Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021).",
            "year": 2021
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "NAACL-HLT (1).",
            "year": 2019
        },
        {
            "authors": [
                "Li Dong",
                "Nan Yang",
                "Wenhui Wang",
                "Furu Wei",
                "Xiaodong Liu",
                "Yu Wang",
                "Jianfeng Gao",
                "Ming Zhou",
                "Hsiao-Wuen Hon"
            ],
            "title": "Unified language model pre-training for natural language understanding and generation",
            "year": 2019
        },
        {
            "authors": [
                "Xinya Du",
                "Junru Shao",
                "Claire Cardie."
            ],
            "title": "Learning to ask: Neural question generation for reading comprehension",
            "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1342\u20131352.",
            "year": 2017
        },
        {
            "authors": [
                "Anthony Fader",
                "Luke Zettlemoyer",
                "Oren Etzioni."
            ],
            "title": "Paraphrase-driven learning for open question answering",
            "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1608\u20131618.",
            "year": 2013
        },
        {
            "authors": [
                "Angela Fan",
                "Mike Lewis",
                "Yann Dauphin."
            ],
            "title": "Hierarchical neural story generation",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 889\u2013898, Melbourne, Australia. Association",
            "year": 2018
        },
        {
            "authors": [
                "Zhihao Fan",
                "Zhongyu Wei",
                "Siyuan Wang",
                "Yang Liu",
                "Xuan-Jing Huang."
            ],
            "title": "A reinforcement learning framework for natural question generation using bi-discriminators",
            "venue": "Proceedings of the 27th International Conference on Computational Linguistics.",
            "year": 2018
        },
        {
            "authors": [
                "Song Feng",
                "Siva Sankalp Patel",
                "Hui Wan",
                "Sachindra Joshi."
            ],
            "title": "MultiDoc2Dial: Modeling dialogues grounded in multiple documents",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 6162\u20136176, Online",
            "year": 2021
        },
        {
            "authors": [
                "Song Feng",
                "Hui Wan",
                "Chulaka Gunasekara",
                "Siva Patel",
                "Sachindra Joshi",
                "Luis Lastras."
            ],
            "title": "doc2dial: A goal-oriented document-grounded dialogue dataset",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
            "year": 2020
        },
        {
            "authors": [
                "Haomin Fu",
                "Yeqin Zhang",
                "Haiyang Yu",
                "Jian Sun",
                "Fei Huang",
                "Luo Si",
                "Yongbin Li",
                "Cam-Tu Nguyen."
            ],
            "title": "Doc2bot: Accessing heterogeneous documents via conversational bots",
            "venue": "arXiv preprint arXiv:2210.11060.",
            "year": 2022
        },
        {
            "authors": [
                "Yingxue Fu."
            ],
            "title": "Towards unification of discourse annotation frameworks",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, pages 132\u2013 142, Dublin, Ireland. Association for Computational",
            "year": 2022
        },
        {
            "authors": [
                "Michael Glass",
                "Gaetano Rossiello",
                "Md Faisal Mahbub Chowdhury",
                "Ankita Naik",
                "Pengshan Cai",
                "Alfio Gliozzo."
            ],
            "title": "Re2G: Retrieve, rerank, generate",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computa-",
            "year": 2022
        },
        {
            "authors": [
                "Qi Gou",
                "Zehua Xia",
                "Wenzhe Du."
            ],
            "title": "Crosslingual data augmentation for document-grounded dialog systems in low resource languages",
            "venue": "Proceedings of the Third DialDoc Workshop on Documentgrounded Dialogue and Conversational Question An-",
            "year": 2023
        },
        {
            "authors": [
                "Tanya Goyal",
                "Greg Durrett."
            ],
            "title": "Neural syntactic preordering for controlled paraphrase generation",
            "venue": "arXiv preprint arXiv:2005.02013.",
            "year": 2020
        },
        {
            "authors": [
                "Junxian He",
                "Taylor Berg-Kirkpatrick",
                "Graham Neubig."
            ],
            "title": "Learning sparse prototypes for text generation",
            "venue": "Advances in Neural Information Processing Systems, 33:14724\u201314735.",
            "year": 2020
        },
        {
            "authors": [
                "Ari Holtzman",
                "Jan Buys",
                "Li Du",
                "Maxwell Forbes",
                "Yejin Choi."
            ],
            "title": "The curious case of neural text degeneration",
            "venue": "arXiv preprint arXiv:1904.09751.",
            "year": 2019
        },
        {
            "authors": [
                "Tom Hosking",
                "Sebastian Riedel."
            ],
            "title": "Evaluating rewards for question generation models",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1",
            "year": 2019
        },
        {
            "authors": [
                "Tom Hosking",
                "Hao Tang",
                "Mirella Lapata."
            ],
            "title": "Hierarchical sketch induction for paraphrase generation",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2489\u20132501, Dublin, Ireland.",
            "year": 2022
        },
        {
            "authors": [
                "Nabil Hossain",
                "Marjan Ghazvininejad",
                "Luke Zettlemoyer."
            ],
            "title": "Simple and effective retrieve-editrerank text generation",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2532\u20132538, Online. Association",
            "year": 2020
        },
        {
            "authors": [
                "Zhiqiang Hu",
                "Roy Ka-Wei Lee",
                "Charu C Aggarwal",
                "Aston Zhang."
            ],
            "title": "Text style transfer: A review and experimental evaluation",
            "venue": "ACM SIGKDD Explorations Newsletter, 24(1):14\u201345.",
            "year": 2022
        },
        {
            "authors": [
                "Vladimir Karpukhin",
                "Barlas Oguz",
                "Sewon Min",
                "Patrick Lewis",
                "Ledell Wu",
                "Sergey Edunov",
                "Danqi Chen",
                "Wen-tau Yih."
            ],
            "title": "Dense passage retrieval for opendomain question answering",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural",
            "year": 2020
        },
        {
            "authors": [
                "Vishwajeet Kumar",
                "Nitish Joshi",
                "Arijit Mukherjee",
                "Ganesh Ramakrishnan",
                "Preethi Jyothi."
            ],
            "title": "Cross-lingual training for automatic question generation",
            "venue": "arXiv preprint arXiv:1906.02525.",
            "year": 2019
        },
        {
            "authors": [
                "H. Kunichika",
                "T. Katayama",
                "T. Hirashima",
                "A. Takeuchi."
            ],
            "title": "Automated question generation methods for intelligent english learning systems and its evaluation",
            "venue": "proc of icce.",
            "year": 2004
        },
        {
            "authors": [
                "Patrick Lewis",
                "Ethan Perez",
                "Aleksandra Piktus",
                "Fabio Petroni",
                "Vladimir Karpukhin",
                "Naman Goyal",
                "Heinrich K\u00fcttler",
                "Mike Lewis",
                "Wen-tau Yih",
                "Tim Rockt\u00e4schel"
            ],
            "title": "Retrieval-augmented generation for knowledge-intensive nlp tasks",
            "year": 2020
        },
        {
            "authors": [
                "Juncen Li",
                "Robin Jia",
                "He He",
                "Percy Liang."
            ],
            "title": "Delete, retrieve, generate: a simple approach to sentiment and style transfer",
            "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human",
            "year": 2018
        },
        {
            "authors": [
                "Bang Liu",
                "Mingjun Zhao",
                "Di Niu",
                "Kunfeng Lai",
                "Yancheng He",
                "Haojie Wei",
                "Yu Xu."
            ],
            "title": "Learning to generate questions by learningwhat not to generate",
            "venue": "The World Wide Web Conference, WWW 2019, San Francisco, CA, USA, May 13-17, 2019.",
            "year": 2019
        },
        {
            "authors": [
                "Dayiheng Liu",
                "Yeyun Gong",
                "Jie Fu",
                "Yu Yan",
                "Jiusheng Chen",
                "Jiancheng Lv",
                "Nan Duan",
                "Ming Zhou."
            ],
            "title": "Tell me how to ask again: Question data augmentation with controllable rewriting in continuous space",
            "venue": "Proceedings of the 2020 Conference on",
            "year": 2020
        },
        {
            "authors": [
                "Ruibo Liu",
                "Guoqing Zheng",
                "Shashank Gupta",
                "Radhika Gaonkar",
                "Chongyang Gao",
                "Soroush Vosoughi",
                "Milad Shokouhi",
                "Ahmed H. Awadallah."
            ],
            "title": "Knowledge infused decoding",
            "venue": "International Conference on Learning Representations (ICLR).",
            "year": 2022
        },
        {
            "authors": [
                "Chenyang Lyu",
                "Lifeng Shang",
                "Yvette Graham",
                "Jennifer Foster",
                "Xin Jiang",
                "Qun Liu."
            ],
            "title": "Improving unsupervised question answering via summarizationinformed question generation",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural",
            "year": 2021
        },
        {
            "authors": [
                "Ali Montazeralghaem",
                "James Allan."
            ],
            "title": "Learning relevant questions for conversational product search using deep reinforcement learning",
            "venue": "Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining, WSDM \u201922.",
            "year": 2022
        },
        {
            "authors": [
                "J. Mostow",
                "C. Wei."
            ],
            "title": "Generating instruction automatically for the reading strategy of selfquestioning",
            "venue": "Conference on Artificial Intelligence in Education: Building Learning Systems That Care: from Knowledge Representation to Affective Mod-",
            "year": 2009
        },
        {
            "authors": [
                "Shashi Narayan",
                "Gon\u00e7alo Sim\u00f5es",
                "Yao Zhao",
                "Joshua Maynez",
                "Dipanjan Das",
                "Michael Collins",
                "Mirella Lapata."
            ],
            "title": "A well-composed text is half done! composition sampling for diverse conditional generation",
            "venue": "Proceedings of the 60th Annual Meeting of",
            "year": 2022
        },
        {
            "authors": [
                "Shashi Narayan",
                "Gon\u00e7alo Sim\u00f5es",
                "Yao Zhao",
                "Joshua Maynez",
                "Dipanjan Das",
                "Michael Collins",
                "Mirella Lapata."
            ],
            "title": "A well-composed text is half done! composition sampling for diverse conditional generation",
            "venue": "Proceedings of the 60th Annual Meeting of",
            "year": 2022
        },
        {
            "authors": [
                "Weizhen Qi",
                "Yu Yan",
                "Yeyun Gong",
                "Dayiheng Liu",
                "Nan Duan",
                "Jiusheng Chen",
                "Ruofei Zhang",
                "Ming Zhou."
            ],
            "title": "Prophetnet: Predicting future n-gram for sequence-to-sequencepre-training",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP",
            "year": 2020
        },
        {
            "authors": [
                "Fanyi Qu",
                "Xin Jia",
                "Yunfang Wu."
            ],
            "title": "Asking questions like educational experts: Automatically generating question-answer pairs on real-world examination data",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing.",
            "year": 2021
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J Liu"
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "J. Mach. Learn. Res.,",
            "year": 2020
        },
        {
            "authors": [
                "Pranav Rajpurkar",
                "Jian Zhang",
                "Konstantin Lopyrev",
                "Percy Liang."
            ],
            "title": "Squad: 100,000+ questions for machine comprehension of text",
            "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2383\u20132392.",
            "year": 2016
        },
        {
            "authors": [
                "Steven J Rennie",
                "Etienne Marcheret",
                "Youssef Mroueh",
                "Jerret Ross",
                "Vaibhava Goel."
            ],
            "title": "Self-critical sequence training for image captioning",
            "venue": "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 7008\u20137024.",
            "year": 2017
        },
        {
            "authors": [
                "John Schulman",
                "Filip Wolski",
                "Prafulla Dhariwal",
                "Alec Radford",
                "Oleg Klimov."
            ],
            "title": "Proximal policy optimization algorithms",
            "venue": "arXiv preprint arXiv:1707.06347.",
            "year": 2017
        },
        {
            "authors": [
                "Siamak Shakeri",
                "Cicero dos Santos",
                "Henghui Zhu",
                "Patrick Ng",
                "Feng Nan",
                "Zhiguo Wang",
                "Ramesh Nallapati",
                "Bing Xiang."
            ],
            "title": "End-to-end synthetic data generation for domain adaptation of question answering systems",
            "venue": "Proceedings of the 2020 Con-",
            "year": 2020
        },
        {
            "authors": [
                "Tianxiao Shen",
                "Myle Ott",
                "Michael Auli",
                "Marc\u2019Aurelio Ranzato"
            ],
            "title": "Mixture models for diverse machine translation: Tricks of the trade",
            "venue": "In Proceedings of the 36th International Conference on Machine Learning,",
            "year": 2019
        },
        {
            "authors": [
                "Anshumali Shrivastava",
                "Ping Li."
            ],
            "title": "Asymmetric lsh (alsh) for sublinear time maximum inner product search (mips)",
            "venue": "Advances in neural information processing systems, 27.",
            "year": 2014
        },
        {
            "authors": [
                "Kurt Shuster",
                "Spencer Poff",
                "Moya Chen",
                "Douwe Kiela",
                "Jason Weston."
            ],
            "title": "Retrieval augmentation reduces hallucination in conversation",
            "venue": "Findings of the Association for Computational Linguistics.",
            "year": 2021
        },
        {
            "authors": [
                "Linfeng Song",
                "Zhiguo Wang",
                "Wael Hamza",
                "Yue Zhang",
                "Daniel Gildea."
            ],
            "title": "Leveraging context information for natural question generation",
            "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Lin-",
            "year": 2018
        },
        {
            "authors": [
                "Yiping Song",
                "Cheng-Te Li",
                "Jian-Yun Nie",
                "Ming Zhang",
                "Dongyan Zhao",
                "Rui Yan."
            ],
            "title": "An ensemble of retrieval-based and generation-based humancomputer conversation systems",
            "venue": "Proceedings of the Twenty-Seventh International Joint Conference",
            "year": 2018
        },
        {
            "authors": [
                "Md Arafat Sultan",
                "Shubham Chandel",
                "Ram\u00f3n Fernandez Astudillo",
                "Vittorio Castelli."
            ],
            "title": "On the importance of diversity in question generation for qa",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.",
            "year": 2020
        },
        {
            "authors": [
                "Adam Trischler",
                "Tong Wang",
                "Xingdi Yuan",
                "Justin Harris",
                "Alessandro Sordoni",
                "Philip Bachman",
                "Kaheer Suleman."
            ],
            "title": "Newsqa: A machine comprehension dataset",
            "venue": "Proceedings of the 2nd Workshop on Representation Learning for NLP, pages 191\u2013200.",
            "year": 2017
        },
        {
            "authors": [
                "Liuyin Wang",
                "Zihan Xu",
                "Zibo Lin",
                "Haitao Zheng",
                "Ying Shen."
            ],
            "title": "Answer-driven deep question generation based on reinforcement learning",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 5159\u20135170, Barcelona,",
            "year": 2020
        },
        {
            "authors": [
                "Zhen Wang",
                "Siwei Rao",
                "Jie Zhang",
                "Zhen Qin",
                "Guangjian Tian",
                "Jun Wang."
            ],
            "title": "Diversify question generation with continuous content selectors and question type modeling",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages",
            "year": 2020
        },
        {
            "authors": [
                "Zhiguo Wang",
                "Wael Hamza",
                "Radu Florian."
            ],
            "title": "Bilateral multi-perspective matching for natural language sentences",
            "venue": "arXiv preprint arXiv:1702.03814.",
            "year": 2017
        },
        {
            "authors": [
                "R.J. Williams."
            ],
            "title": "Simple statistical gradientfollowing algorithms for connectionist reinforcement learning",
            "venue": "Machine Learning, 8(3-4):229\u2013256.",
            "year": 1992
        },
        {
            "authors": [
                "Qingyang Wu",
                "Song Feng",
                "Derek Chen",
                "Sachindra Joshi",
                "Luis Lastras",
                "Zhou Yu."
            ],
            "title": "DG2: Data augmentation through document grounded dialogue generation",
            "venue": "Proceedings of the 23rd Annual Meeting of the Special Interest Group on Discourse and Dia-",
            "year": 2022
        },
        {
            "authors": [
                "Yu Wu",
                "Furu Wei",
                "Shaohan Huang",
                "Yunli Wang",
                "Zhoujun Li",
                "Ming Zhou."
            ],
            "title": "Response generation by context-aware prototype editing",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 33.",
            "year": 2019
        },
        {
            "authors": [
                "Jingjing Xu",
                "Xu Sun",
                "Qi Zeng",
                "Xiaodong Zhang",
                "Xuancheng Ren",
                "Houfeng Wang",
                "Wenjie Li."
            ],
            "title": "Unpaired sentiment-to-sentiment translation: A cycled reinforcement learning approach",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for",
            "year": 2018
        },
        {
            "authors": [
                "Bingsheng Yao",
                "Dakuo Wang",
                "Tongshuang Wu",
                "Zheng Zhang",
                "Toby Li",
                "Mo Yu",
                "Ying Xu."
            ],
            "title": "It is AI\u2019s turn to ask humans a question: Questionanswer pair generation for children\u2019s story books",
            "venue": "Proceedings of the 60th Annual Meeting of the",
            "year": 2022
        },
        {
            "authors": [
                "Xingdi Yuan",
                "Tong Wang",
                "Caglar Gulcehre",
                "Alessandro Sordoni",
                "Philip Bachman",
                "Saizheng Zhang",
                "Sandeep Subramanian",
                "Adam Trischler."
            ],
            "title": "Machine comprehension by text-to-text neural question generation",
            "venue": "Proceedings of the 2nd Workshop on Repre-",
            "year": 2017
        },
        {
            "authors": [
                "Shiyue Zhang",
                "Mohit Bansal."
            ],
            "title": "Addressing semantic drift in question generation for semisupervised question answering",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
            "year": 2019
        },
        {
            "authors": [
                "Yeqin Zhang",
                "Haomin Fu",
                "Cheng Fu",
                "Haiyang Yu",
                "Yongbin Li",
                "Cam-Tu Nguyen."
            ],
            "title": "Coarse-to-fine knowledge selection for document grounded dialogs",
            "venue": "ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing",
            "year": 2023
        },
        {
            "authors": [
                "Yizhe Zhang",
                "Siqi Sun",
                "Xiang Gao",
                "Yuwei Fang",
                "Chris Brockett",
                "Michel Galley",
                "Jianfeng Gao",
                "Bill Dolan."
            ],
            "title": "Retgen: A joint framework for retrieval and grounded text generation modeling",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence.",
            "year": 2022
        },
        {
            "authors": [
                "Yao Zhao",
                "Xiaochuan Ni",
                "Yuanyuan Ding",
                "Qifa Ke."
            ],
            "title": "Paragraph-level neural question generation with maxout pointer and gated self-attention networks",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing.",
            "year": 2018
        },
        {
            "authors": [
                "Qingyu Zhou",
                "Nan Yang",
                "Furu Wei",
                "Chuanqi Tan",
                "Hangbo Bao",
                "Ming Zhou."
            ],
            "title": "Neural question generation from text: A preliminary study",
            "venue": "National CCF Conference on Natural Language Processing and Chinese Computing. Springer.",
            "year": 2017
        },
        {
            "authors": [
                "Peide Zhu",
                "Claudia Hauff."
            ],
            "title": "Evaluating bertbased rewards for question generation with reinforcement learning",
            "venue": "Proceedings of the 2021 ACM SIGIR International Conference on Theory of Information Retrieval, ICTIR \u201921.",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Question Generation (QG) aims to generate questions from a given answer and a grounding paragraph. As a dual task of Question Answering (QA), QG can potentially be used for the automatic construction of QA datasets, thereby improving QA with little annotation effort (Shakeri et al., 2020; Alberti et al., 2019; Cui et al., 2021). Furthermore, QG can be utilized for educational purposes (Yao et al., 2022; Qu et al., 2021), dialog systems (Wu et al., 2022), and conversational recommendation systems (Montazeralghaem and Allan, 2022).\nQG systems are typically known to suffer from two major issues, namely inconsistency and lack\n\u2217Corresponding authors.\nof diversity. The former indicates that QG systems may yield context-irrelevant or answer-irrelevant questions (Zhang and Bansal, 2019; Zhao et al., 2018; Liu et al., 2019; Song et al., 2018a). The latter is because QG systems may fail to capture the one-to-many nature of QG tasks; that is, many questions can be asked given the same pair of context and answer. Existing solutions mainly exploit the internal knowledge within the context (Narayan et al., 2022a; Wang et al., 2020b), the language model (Fan et al., 2018a; Holtzman et al., 2019), or the semantic word space (Shen et al., 2019; Cho et al., 2019) for diverse content planning. Unfortunately, since these methods rely on obscure factors such as the black-box language model or the latent variable, they are not as controllable as exploiting external question templates (Figure 1).\nIn this paper, we aim to improve generation diversity by looking for expression variations in an external set of question templates. Figure 1 shows several questions that can be generated with a number of retrieved templates for a given source context.\nAlthough external information has been exploited for QG (Cao and Wang, 2021; Deschamps et al., 2021), prior methods depend on manually crafted set of type-dependent templates (Cao and Wang, 2021) or paraphrasing samples (Deschamps et al., 2021). In contrast, we neither require the annotation of question types and the relevant templates (unlike Cao and Wang (2021)) nor assume that question rewriting samples are accessible (unlike Deschamps et al. (2021)).\nOur framework contains three main components: (1) a vanilla generator for initial template planning; (2) a style retriever, which filters related style templates given the initial one; and (3) a style-based generator, which robustly combines a style template and the internal context to generate the final question. Training such a model, however, is nontrivial due to two issues: 1) diversity should not come with the cost of consistency; 2) the lack of template-based question rewriting samples. We address these issues with Reinforcement Learning (RL), which directly maximizes a balanced combination of consistency and diversity rewards. Here, the consistency metric is computed by a QuestionAnswering (QA) model, whereas the diversity metric measures how much the final output mimics the retrieved template. Unlike the standard maximum likelihood approach, we do not need tokenby-token supervised signals for training with RL, thus relaxing the need for question rewriting samples. Our approach is inspired by the retrieval-andedit methods (Cai et al., 2019a,b), but focuses on the unexplored problem of balancing diversity and consistency by using RL.\nAll in all, our main contributions are three-fold:\n1. We propose RAST, a framework for RetrievalAugmented Style Transfer, which retrieves question style templates from an external set and utilizes them to generate questions with diverse expressions.\n2. We propose a novel RL-based method to jointly train the retriever and the style-based generator in RAST. Our method is potentially adaptable for other retrieval-augmented tasks such as document-grounded dialog systems (Feng et al., 2020; Fu, 2022).\n3. Experimental results on NewsQA (Trischler et al., 2017) and two splits of SQuAD datasets (Zhou et al., 2017; Du et al., 2017) show that\nRAST achieves superior performance on diversity whereas being comparable in terms of consistency."
        },
        {
            "heading": "2 Related Work",
            "text": "Question Generation Early attempts on QG are rule-based (Kunichika et al., 2004; Mostow and Wei, 2009), which are inflexible and laborintensive. In addition, such methods are not able to generate questions from a larger context. Sequenceto-sequence-based methods (Du et al., 2017; Kumar et al., 2019) are able to overcome such issues, leading to better results. Recently, supervised finetuning pre-trained language models (PLM) have shown to achieve significant improvement (Dong et al., 2019; Qi et al., 2020). These systems, however, mostly focus on consistency, whereas diversity is also essential for downstream tasks such as QA. Prior attempts at diversity can be divided into two main categories, those that make use of internal knowledge such as content selection (Cho et al., 2019; Shen et al., 2019; Wang et al., 2020b) and improved decoding (Fan et al., 2018a; Narayan et al., 2022a), and those that exploit external patterns (Deschamps et al., 2021; Cao and Wang, 2021). Our work falls into the latter category but attempts to do so without samples for question rewriting.\nRetrieval-Augmented Generation There has been a growing interest in integrating (external) knowledge from a retrieval model into a parametric language model for text generation. Wu et al. (2019) propose a retrieve-then-edit paradigm, where an editor is trained to modify a retrieval result to produce a more consistent response. Cai et al. (2019a,b) exploit skeletons to diversify text generation outputs, where a skeleton is obtained by masking query-specific information in the text. The retrieval-augmented generation approach has also been used for task-oriented dialogs (Feng et al., 2020, 2021; Shuster et al., 2021; Fu et al., 2022; Gou et al., 2023; Zhang et al., 2023). These studies, however, either exploit surface matching methods (e.g. tf.idf) (Song et al., 2018b; Cai et al., 2019a,b; Wu et al., 2019) or separately train the retrieval with relevant labels (Shuster et al., 2021; Feng et al., 2020, 2021; Fu et al., 2022). The retriever, therefore, might not be optimal for generation.\nSeveral studies have jointly trained the retriever and the generation model (Lewis et al., 2020; Hossain et al., 2020; Glass et al., 2022) , but they have mostly focused on consistency, not diversity.\nReinforcement Learning for Generation Reinforcement learning (RL) has been used for text generation to mitigate the exposure bias issue associated with the standard Supervised Learning (SL) approach. Here, the exposure bias refers to the fact that generation during inference relies on predicted tokens instead of ground-truth tokens as in training. Furthermore, instead of optimizing proxy losses as in SL approach, RL directly optimizes the quality of interest via RL rewards, thus bridging the evaluation gap between training and testing. Researchers have proposed various RL rewards for QG, including answerability (for question generation) (Liu et al., 2020), BLEU-4 and Word Mover Distance (WMD) (Wang et al., 2020a; Chen et al., 2020), naturalness (Fan et al., 2018b), consistency using a Question Paraphrase Probability (QPP), and a Question Answering Probability (QAP) (Zhang and Bansal, 2019; Hosking and Riedel, 2019; Yuan et al., 2017). Previous methods have primarily focused on evaluating the consistency of generated questions, while we seek to evaluate both consistency and diversity. Here, the diversity is achieved by training a retrieval model for a retrieval-augmented generation.\nOur work is closely related to RetGen (Zhang et al., 2022). This method, however, differs from ours in several ways: 1) only the retrieval model is optimized using RL in RetGen, whereas both the retrieval and the generation model are updated end-to-end via our RL framework; 2) it uses the likelihood of ground truth generation outputs as returns to update the retriever while we combine consistency and diversity rewards.\nText Style Transfer Our objective of question style transfer bears some resemblance to text style transfer studies (Li et al., 2018; Xu et al., 2018; Hu et al., 2022). The main difference is that we do not have predefined style labels, whereas most studies in the style transfer literature rely on given labels such as positive/negative or formal/informal.\nParaphrase Generation Paraphrasing involves transforming a natural language sentence into a new sentence with the same semantic meaning but a different syntactic or lexical surface form. Although diversity can be obtained by paraphrasing generated questions, our setting is different from (He et al., 2020; Goyal and Durrett, 2020; Hosking et al., 2022). Specifically, question paraphrase datasets, such as (Fader et al., 2013; Wang et al.,\n2017), do not associate context with each pair of (sentence, paraphrased sample). As such, paraphrasing in these datasets can only focus on different word choice or syntactic modification of an input question. In contrast, our consistency reward allows generating questions as long as the answer is the same with the input question given the context. In other words, our method also pays attention to different clues of the context for QG diversity."
        },
        {
            "heading": "3 Methodology",
            "text": ""
        },
        {
            "heading": "3.1 Overview",
            "text": "QG aims to generate question y given a paragraph c and answer a, which we combine to form the context x = {c, a} for convenience. To indicate the position of the answer a in x, we wrap it in a special tag <HL>. Previous works such as (Narayan et al., 2022a) model p(y|x) for QG, i.e they rely on the internal knowledge of the context or the language model for diversity. Instead, we model our diverse QG as follows:\np(y|x,Z) = Ez0,z\u2208Z[p(z0|x)\u00d7 p(z|z0)p(y|z, x)] = vanilla QG\u00d7 RAST\nwhere Z denotes the external corpus of question style templates, and z0 indicates the initial question template that can be predicted based on the context x. The intuition is that we choose the style templates from the external knowledge (z \u2208 top \u2212 k from Z) that are close but not the same as z0, and utilize them to generate questions with diverse styles. During training, for a given context x, we extract z0 from the ground truth question y by masking context-sensitive information. During inference, as we do not know the ground truth question, we rely on a vanilla question generation p(y|x) (vanilla QG) to generate the best y0 from which we extract the initial template z0. In other words, we approximate p(z0|x) = 1 for z0 being the ground truth z0 during training and the greedy z0 of the vanilla QG during inference.\nThe general architecture of our framework is demonstrated in Figure 2, which contains a vanilla QG and a Retrieval-Augmented Style Transfer model (RAST model). It is noteworthy that although we apply a base T5 model (Raffel et al., 2020), many generation methods can be applied for vanilla QG to improve content diversity (Narayan et al., 2022a; Wang et al., 2020b), and the diversity\nof RAST subsequently. The vanilla QG is trained using the standard maximum likelihood method, which we skip here for brevity. In the following, we detail our RAST model and how to train the model without samples for rewriting questions based on alternative styles (z)."
        },
        {
            "heading": "3.2 Question Style Templates",
            "text": "To achieve style diversity in RAST, we use a set of question style templates which are constructed automatically through two steps - masking and duplication removal. Firstly, we leverage training data as our collected question corpus, allowing crosssample reference for diverse question styles. The question templates are then obtained from the collected questions by masking context-sensitive information, making such patterns generalizable across contexts. Specifically, for each question, we keep stop and interrogative words, but replace entities (NER), noun phrases (NP), and context tokens with \u201c[MASK]\u201d. Here, NER and NP are detected using Spacy1. Finally, near-duplicate templates are removed by measuring pairwise Jaccard similarities."
        },
        {
            "heading": "3.3 Retrieval-Augmented Style Transfer",
            "text": "Style Retrieval Model We apply Dense Passage Retrieval (DPR) (Karpukhin et al., 2020) as the style retrieval model. Specifically, query and sample styles are encoded as the following:\nq(z) = BERT1(z) (1)\nq(z0) = BERT2(z0) (2) p\u03d5(z|z0) \u221d exp[q(z)T q(z0)] (3) 1https://spacy.io/usage/linguistic-features\nwhere BERT-based encoders (Devlin et al., 2019) are used to convert question templates into dense embedding vectors for style retrieval. Sub-linear time search can be achieved with a Maximum Inner Product Search (MIPS) (Shrivastava and Li, 2014). Note that parameters of two encoders (2 BERT) constitute the parameter set \u03d5 of the style retrieval.\nStyle Transfer Model We use T5 (Raffel et al., 2020) as our style transfer model p\u03b8(y|z, x), which generates questions auto-regressively based on a chosen style z and the context x:\np\u03b8(y|x, z) = T\u220f i=1 p\u03b8(yt|x, z, y1:t\u22121) (4)\nwhere T indicates the question length, and \u03b8 denotes T5 model parameters."
        },
        {
            "heading": "4 Two Stage Training",
            "text": "We train RAST using RL to avoid the exposure bias and the evaluation discrepancy between training and testing, which are often associated with supervised learning objectives (Chen et al., 2021). To accelerate the convergence of RL-based training, we first use supervised learning to initialize the style transfer model, resulting in a two-stage training procedure described in the following."
        },
        {
            "heading": "4.1 Supervised Learning",
            "text": "The style transfer model p\u03b8(y|x, z) can theoretically be initialized by the model trained on {(x, y0, z0)}, where y0 is the ground truth question with the associated template z0. Unfortunately, doing so results in an over-fitting model that is not\nadaptable to training with noisy templates in the RL training phase. To overcome this issue, we actively corrupt z0 to obtain a noisy template z\u03030 using several mechanisms, including (1) replacing [MASK] by a random entity; (2) adding some nouns; (3) deleting [MASK]; and (4) randomly choosing another template. Let y\u0302 denote the predicted sequence given the input x and the corrupted template z\u03030, the model is then trained with cross-entropy loss:\nLCE\u03b8 = \u2212 \u2211 i yi log p(y\u0302i|x, z\u03030) (5)\nwhere yi, y\u0302i denote the ground truth label and the predicted one at the time step i."
        },
        {
            "heading": "4.2 Reinforcement Learning",
            "text": ""
        },
        {
            "heading": "4.2.1 RL for Style Retrieval and Transfer",
            "text": "Our style retrieval and transfer problem are cast as a RL problem. Our model (RAST) introduced above can be viewed as an \u201cagent\u201d that interacts with an external \u201cenvironment\u201d of words and question templates. The parameters of the retrieval model (\u03d5) and the transfer model (\u03b8) define a combined policy that results in an \u201caction\u201d that is the selection of one style or the prediction of the next word. For simplicity, we assume that the style is chosen at the beginning of the sequence generation and kept unchanged throughout the generation process. Upon generating the end-of-sequence (EOS) token, the agent observes a \u201creward\u201d r, which is detailed in Section 4.2.2. The goal of training is to minimize the negative expected reward:\nLRL(\u03b8, \u03d5) = \u2212Eys\u223cp\u03b8,zs\u223cp\u03d5 [r(y s, zs)] (6)\nwhere ys = (ys1, ..., y s T ) and y s t is the word sampled from the style transfer model p\u03b8 at the time step t; zs is the template sampled from the style retrieval model p\u03d5. Here, ys and zs are sampled according to the algorithm described in Section 4.2.3.\nIn order to compute the gradient \u2207LRL(\u03b8, \u03d5), we use REINFORCE method (Williams, 1992), which calculates a non-differential reward:\n\u2207LRL = \u2212Eys,zs [r(ys, zs)\u2207 log p\u03b8,\u03d5] = \u2212Eys,zs [r(ys, zs)\u2207 log p\u03d5(zs|z0)\u2212\nEys,zs [(r(ys, zs))\u2207 log p\u03b8(ys|x, zs)] = \u2207LRL\u03b8 +\u2207LRL\u03d5 (7)\nwhere p\u03b8,\u03d5 indicates p\u03b8,\u03d5(ys, zs|x, z0), which can be decomposed into the product of the style transfer model p\u03b8(ys|x, zs) and the style retrieval model\np\u03d5(z s|z0). This subsequently decouples the gradients of the style transfer model\u2207LRL\u03b8 and the style retrieval model\u2207LRL\u03d5 .\nRL with a Baseline and KL Divergence In order to reduce the variance of reinforcement learning for sequence generation, we modify the reward for the style transfer by referencing a baseline b using the Self-critical sequence training (SCST) method (Rennie et al., 2017). Here, we use the reward of the greedy output of the style transfer model as the baseline, hence obtaining:\n\u2207LRL\u03b8 = \u2212Eys,zs [(r(ys, zs)\u2212 b)\u2207 log p\u03b8] (8)\nKL divergence is additionally used to avoid the updated policy (p\u2217\u03b8) drifting too far away from the original one (p\u03b8) (Liu et al., 2022; Schulman et al., 2017). The total gradient function for the style transfer model, therefore, is:\n\u2207LRL\u03d5,\u03b8 = \u2212Eys,zs [r(ys, zs)\u2207 log p\u03d5] \u2212Eys,zs [(r(ys, zs)\u2212 b)\u2207 log p\u03b8] +\u03b2\u2207KL(p\u03b8||p\u2217\u03b8) (9)"
        },
        {
            "heading": "4.2.2 Reward Model",
            "text": "Consistency Reward encourages the model to generate context-relevant and answer-relevant questions. Various strategies for consistency rewards can be used such as answerability (Liu et al., 2020), BLEU-4 and Word Mover Distance (WMD) (Wang et al., 2020a; Chen et al., 2020), naturalness (Fan et al., 2018b). In this paper, inspired by (Zhu and Hauff, 2021), we apply a Question Answer (QA) loss-based metric as our consistency reward. There are two reasons for QA-based metrics to be a good approximation for QG consistency: 1) QA is the dual task of QG; 2) the performance of QA systems, e.g., on SQuAD, has come close to human performance. Unlike (Zhu and Hauff, 2021), which uses an extractive QA model, we utilize a generative QA model based on T5 (Raffel et al., 2020). The reward is then measured as follows:\nLqa = \u2212 1\nTa Ta\u2211 i=1 log p(ai|c, ys, a<i) (10) rcons(y s, zs) = exp(\u2212Lqa) (11)\nwhere Ta indicates the answer length, and ys is a sampled question from p\u03b8(y|z, x).\nAlgorithm 1: Diversity driven Sampling input :The combination of paragraph and\nanswer, x = {c, a}; the list of templates retrieved from Z based on z0, S; the generation sampling probability, p; and k.\noutput :k sampled questions and styles 1 clusters\u2190 cluster S into k clusters based\non Jaccard similarity; 2 QZs \u2190 empty set ; 3 for i\u2190 1 to k do 4 if training then 5 zs \u2190 randomly choose a style from clusters[i]; 6 else 7 zs \u2190 select top style based on\np\u03d5(z s|z0);\n8 Sample ys from p\u03b8(y|x, zs) using nucleus sampling with probability p;\n9 Add {zs, ys} to QZs; 10 return QZs\nDiversity Reward promotes the generation of questions that are close to retrieved templates. For simplicity, we use Jaccard Similarity as our diversity reward as follows:\nrdivs(y s, zs) =\nzs \u2229 ys zs \u222a ys (12)\nTotal Reward tries to trade off between consistency and diversity. It is obtained by combining the two rewards with a diverse coefficient \u03bb \u2208 [0, 1] :\nr(ys, rs) = rcons + \u03bbrdivs (13)\nFor the style transfer model, it is intuitive to see how this reward helps balance consistency and diversity. As for the style retriever, since the reward includes the consistency metric, we can assign higher scores to templates that can be used to generate various questions as long as the answer is a. By doing so, the style retrieval can go beyond surface matching and assign higher scores to templates of different styles."
        },
        {
            "heading": "4.2.3 Diversity-driven Sampling",
            "text": "One issue with training an RL model is that the model may degenerate to a locally optimal one, during which the retrieval puts all the probability mass on a small number of templates very close to z0 according to surface matching, ignoring all\nthe other templates. To overcome this, we propose a diversity-driven sampling procedure as in Algorithm 1. During training, we first cluster retrieved templates to group those close to each other according to surface matching (Jaccard similarity), then sample a template randomly from each cluster. By doing so, RL can have better exploration for various styles, thus avoiding the local optimal. During inference, however, we select the top template based on the retrieval scores from the well-trained retrieval model."
        },
        {
            "heading": "5 Experiments",
            "text": ""
        },
        {
            "heading": "5.1 Experiment Settings",
            "text": "Datasets We conduct experiments on two public datasets, SQuAD (Rajpurkar et al., 2016) and NewsQA (Trischler et al., 2017). As for SQuAD, since the test set is not accessible, we use the splits of (Zhou et al., 2017)2 and (Du et al., 2017) instead. Table 1 provides the statistics of these datasets.\nEvaluation Following (Wang et al., 2020b; Narayan et al., 2022b), we adopt several metrics to evaluate diversity and consistency: 1) Top-1 BLEU measures BLEU of the best generated output; 2) Oracle BLEU reflects the overall consistency by comparing the best hypothesis among top-N outputs with the target question. 3) Pairwise BLEU (or Self BLEU) measures the diversity by averaging sentence-level metrics of pairs within top N. A lower value of pairwise BLEU indicates a higher level of diversity. 4) Overall BLEU measures the overall performance, which can be calculated by Top-1 \u00d7 Oracle \u00f7 Pairwise. Note that all the mentioned BLEU indicate BLEU-4."
        },
        {
            "heading": "5.2 Baselines",
            "text": "We compare our method with recent diverse-driven QG methods, which include those based on content\n2https://res.qyzhou.me/redistribute.zip\nplanning and those based on sampling.\nContent Planning-based Methods Mixture Decoder (Shen et al., 2019) models a mixture of experts (MoE), where a latent variable drawn from MoE is used to control the generation and produce a diverse set of hypotheses. Mixture Selector (Cho et al., 2019) focuses on different parts of the context by modeling a binary variable for token selection. CVAE (Wang et al., 2020b) also selects tokens from the context, but uses a continuous latent variable instead of a binary variable like Mixture-Selector.\nSampling-based Methods Nucleus Sampling (Holtzman et al., 2019) samples tokens from a truncated distribution, where the unreliable tail of 1\u2212p probability mass is cropped. Composition Sampling (Narayan et al., 2022a) uses nucleus sampling to obtain diverse entity chains, then utilizes beam search to generate the most-likely output."
        },
        {
            "heading": "5.3 Implementation Details",
            "text": "We use the pre-trained DPR (Karpukhin et al., 2020) to initialize the retrieval encoders. Pretrained T5-base 3 is used for vanilla QG and the style transfer model. During inference, the template of the vanilla QG is used as a query to retrieve N \u2212 1 more templates. The obtained templates are then used to generate N (N=5) questions for evaluation. We use SacreBLEU 4 to calculate BLEU.\n3https://huggingface.co/t5-base 4https://github.com/mjpost/sacrebleu\nMore details can be found in Appendix A. We conduct experiments with Nucleus-T5 by ourself using Transformers5. In addition, the results of Composition Sampling are reevaluated, whereas those of other baselines are from (Shen et al., 2019; Cho et al., 2019; Wang et al., 2020b)."
        },
        {
            "heading": "5.4 Results and Analysis",
            "text": "Table 2 summarizes our experimental results, for which detailed analysis are given in the following.\nAmong diverse-promoting baselines, NucleusT5 promotes diversity with the cost of Top-1 BLEU being dropped significantly. CVAE and Composition are better at balancing between consistency and diversity, resulting in high overall scores. For example, in comparison with Nucleus-T5 on SQuAD /2, Composition is more consistent (better Top-1 and Oracle-BLEU), despite of being less diverse (lower Pairwise-BLEU). Our result is in line with (Narayan et al., 2022b).\nCompared to the previous methods, RAST achieve the best diversity score (the lowest Pairwise-BLEU) on SQuAD/1 and NewsQA, and the second-best on SQuAD/2. Particularly, our method outperforms strong baselines (Composition Sampling and CVAE) by a large margin in terms of diversity, whereas being comparable on consistency scores. Specifically, on NewsQA and\n5https://github.com/huggingface/transformers\nSQuAD/1, RAST is better than CVAE on both Top1 and Oracle-BLEU. On SQuAD/1 and SQuAD/2, RAST is better than Composition on Top-1 whereas being comparable on Oracle-BLEU. Regarding the overall score, RAST obtains the superior results on three datasets, showing that its capability in balancing between diversity and consistency."
        },
        {
            "heading": "5.5 Ablation Study",
            "text": "We study the impact of different components of RAST on SQuAD/1 (Zhou et al., 2017), where the results are given in Figure 3 and Table 3.\nDiverse Coefficient Figure 3 shows how diversity and consistency change when increasing \u03bb. Besides Oracle-BLEU, we also use Exact Match (EM) and F1 (two QA metrics) to measure consistency (Sultan et al., 2020; Lyu et al., 2021). Here, the QA metrics are calculated by averaging EM and F1 scores of the answers, which are generated by the QA model for top-N evaluation questions.\nAs observable from Figure 3, increasing \u03bb leads to higher diversity (lower pairwise-BLEU), but lower consistency (lower Oracle and QA metrics). This is the result that we expect. The rate of increase in diversity, however, is much higher than the rate of decrease in the consistency metrics. Specifically, when \u03bb changes from 0.05 to 0.25, pairwise-BLEU drops 39.52 points (from 74.7 to 35.18), whereas F1 only drops 6.96 points (from 85.16 to 78.2), showing that our method is able to maintain consistency within a reasonable range while promoting diversity significantly.\nFreeze DPR To study the impact of joint RL training on the retrieval and generation models, we\ncompare the performance of RAST and RAST (w/o e2e). As observable from Table 3, overall BLEU is improved with end2end training, showing that the retrieval model is better optimized for balancing between diversity and consistency.\nDiversity-driven Sampling We measure the impact of the clustering step in diversity-driven sampling (Algorithm 1) by comparing RAST and RAST (w/o cluster) in Table 3. Here, during training, RAST (w/o cluster) samples templates based solely on the retrieval scores. It is observable that clustering allows us to better train RAST, and thus results in better performance across all metrics.\nRetrieval Query The last row of Table 3 shows the performance of RAST when we use the best question y0 of the vanilla QG (RAST w/ question) instead of the question template z0 for querying external templates. As we can see, using masked questions (RAST) leads to higher diversity than the alternative. This is intuitive given the fact that masking context-sensitive information can make templates more generalizable across contexts."
        },
        {
            "heading": "5.6 Human Evaluation",
            "text": "We followed (Wang et al., 2020b) to evaluate the consistency and diversity of RAST and Nucleus sample6 on 50 samples of SQuAD /1. Here, the consistency metric ranges from 0 to 5, measuring the proportion of the generated questions being answerable based on the given context (without\n6This is because the source code of the other baselines is not publicly available\nany hallucinations on the named entity or intent errors). On the other hand, the diversity metric calculates the number of distinct questions among the consistent ones, which means the diversity score ranges from 1 to the consistency score. Specifically, each sample has been checked by three annotators. The results in Table 4 indicate that RAST less suffers from hallucination, whereas being more diverse. We also provide our inter-annotator agreement score in Table 5, which indicate moderate to substantial agreement among our annotators."
        },
        {
            "heading": "5.7 Case Analysis",
            "text": "To better analyze the performance of RAST, we provide a case study in Figure 4. As shown in this case, RAST obtains its diversity by retrieving different templates. Notably, the third output replaces \u201cthat\u201d in the template with \u201cwhich,\u201d demonstrating that our model does not simply copy syntactic words from the template. Interesting, the diversity also results from selecting different clues from the context that are suitable for the retrieved templates, such as \u201cHobson,\u201d \u201crace,\u201d \u201cbest,\u201d and \u201cthe development of the earth.\u201d Please refer to Appendix B for more cases."
        },
        {
            "heading": "6 Conclusion",
            "text": "This paper proposes RAST, a framework that exploits question templates from an external corpus to improve expression diversity in QG systems. Compared to previous methods, that exploit internal knowledge of language models for diversity, RAST provides a more flexible and interpretative way to control the generation outputs. To train RAST without question rewriting samples, we develop a novel RL based method, where we directly optimize the combination of the consistency and diversity rewards. In addition, we provide two stage training and diversity-driven sampling, which help better train our RL-based model. Experiment results show that RAST outperforms strong baselines in terms of diversity whereas being comparable on consistency scores. For future studies, we aim at further improvement by developing efficient training with a small number of paraphasing samples.\nLimitations\nOur study currently suffers from several limitations: (1) QG evaluation is challenging due to oneto-many nature of the task. The best evaluation should be human evaluation. Unfortunately, this is not possible since we do not have access to source code of many previous studies. Although the outputs of Composition Sampling are available, they only come with the paired gold questions. Since the data was shuffled, we do not know the corresponding passages for human evaluation. As an alternative, we have tried to cover as many metrics as possibles, including all of the metrics used in previous baselines and QA-based metrics. (2) Training a RL-based method like RAST is typically more difficult and time consuming. This is because RL requires many rounds of sampling to converge. Our two-stage training is helpful, but there is still more room for improvement. (3) Our model is limited by the maximum context length like most of the Transformer-based methods.\nEthics Statement\nThis paper uses opensource datasets to construct the external style corpus. One concern is that model can learn to mimic target properties in the training data that are not desirable. Another concern is that our work might involve the same biases and toxic behaviors in the pre-trained models."
        },
        {
            "heading": "A Technical Details",
            "text": "A.1 Implementation Details Our model is implemented with Pytorch 1.8.1 and Transformers 4.23.1. For three datasets, we set max length of input as 128/512/1250 for SQuAD split1, SQuAD split2, and NewsQA respectively.\nDuring inference, the template of the vanilla QG (z0) is used as a query to achieve N \u2212 1 more templates, which are then combined with z0 to generate N questions for top-N evaluation (N=5). The z0, however, is not actually be used for generating questions with the style transfer model, instead we replace it with an empty string. In other words, the input the style transfer model contain only context. This is done so that we do not take the advantage of the vanilla QG into account.\nA.1.1 Hyperparameters During SL, we fine-tune the baselines for 5 epochs with learning rate of 5e-4 and 5 epochs. We set the sampling parameters with top-p of 0.9 and top-k of 30. Warmup-ratio and weight-decay are set as 0.1 for all three datasets. We set batch size as 64/32/6 for SQuAD/1, /2, and NewsQA, respectively.\nFor RL, we train RAST with 7 epochs and warmup-ratio of 0.2. The number of retrieval is set as 100 at training and 500 at evaluation. We choose 5 style templates for style transfer model at evaluation since we should calculate Oracle BLEU(K=5) with baselines for fair comparison. The final model is the one with the highest Oracle BLEU on development set. Please refer to Table 6 for more information.\nB Samples of Generation Results"
        }
    ],
    "title": "Diversify Question Generation with Retrieval-Augmented Style Transfer",
    "year": 2023
}