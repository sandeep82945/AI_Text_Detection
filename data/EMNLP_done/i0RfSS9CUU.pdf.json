{
    "abstractText": "The remarkable advancements in large language models (LLMs) have significantly enhanced predictive performance in few-shot learning settings. By using only a small number of labeled examples, referred to as demonstrations, LLMs can effectively perform the task at hand through in-context learning. However, the process of selecting demonstrations for maximizing performance has received limited attention in prior work. This paper addresses the issue of identifying the most informative demonstrations for few-shot learning by approaching it as a pool-based Active Learning (AL) problem over a single iteration. We compare standard AL algorithms based on uncertainty, diversity, and similarity, and consistently observe that the latter outperforms all other methods, including random sampling. Our extensive experimentation involving a diverse range of GPT and OPT models across 24 classification and multi-choice tasks, coupled with thorough analysis, unambiguously demonstrates the importance of using demonstrations that are semantically similar to the domain of the test examples. In fact, we show higher average classification performance using \u201csimilar\u201d demonstrations with GPT-2 (124M) than random demonstrations with GPT-Neox (20B). Notably, while diversity sampling shows promise, uncertainty sampling, despite its success in conventional supervised learning AL scenarios, performs poorly in in-context learning.",
    "authors": [
        {
            "affiliations": [],
            "name": "Katerina Margatina"
        },
        {
            "affiliations": [],
            "name": "Timo Schick"
        },
        {
            "affiliations": [],
            "name": "Nikolaos Aletras"
        },
        {
            "affiliations": [],
            "name": "Jane Dwivedi-Yu"
        }
    ],
    "id": "SP:6687b5d01237583c5de84598f44bf8dd694f84e0",
    "references": [
        {
            "authors": [
                "Sweta Agrawal",
                "Chunting Zhou",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Marjan Ghazvininejad"
            ],
            "title": "Incontext examples selection for machine translation",
            "year": 2022
        },
        {
            "authors": [
                "Ekin Aky\u00fcrek",
                "Dale Schuurmans",
                "Jacob Andreas",
                "Tengyu Ma",
                "Denny Zhou."
            ],
            "title": "What learning algorithm is in-context learning? investigations with linear models",
            "venue": "ArXiv, abs/2211.15661.",
            "year": 2022
        },
        {
            "authors": [
                "Francesco Barbieri",
                "Jose Camacho-Collados",
                "Luis Espinosa Anke",
                "Leonardo Neves."
            ],
            "title": "Tweeteval: Unified benchmark and comparative evaluation for tweet classification",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages",
            "year": 2020
        },
        {
            "authors": [
                "Samuel Weinbach."
            ],
            "title": "GPT-NeoX-20B: An opensource autoregressive language model",
            "venue": "Proceedings of BigScience Episode #5 \u2013 Workshop on Challenges & Perspectives in Creating Large Language Models, pages 95\u2013136, virtual+Dublin. Association",
            "year": 2022
        },
        {
            "authors": [
                "Zal\u00e1n Bod\u00f3",
                "Zsolt Minier",
                "Lehel Csat\u00f3."
            ],
            "title": "Active learning with clustering",
            "venue": "Proceedings of the Active Learning and Experimental Design workshop",
            "year": 2011
        },
        {
            "authors": [
                "Klaus Brinker."
            ],
            "title": "Incorporating diversity in active learning with support vector machines",
            "venue": "Proceedings of the International Conference on Machine Learning, pages 59\u201366.",
            "year": 2003
        },
        {
            "authors": [
                "Michael Chen",
                "Mike D\u2019Arcy",
                "Alisa Liu",
                "Jared Fernandez",
                "Doug Downey"
            ],
            "title": "CODAH: An adversarially-authored question answering dataset for common sense",
            "venue": "In Proceedings of the 3rd Workshop on Evaluating Vector Space Representations",
            "year": 2019
        },
        {
            "authors": [
                "Meier-Hellstern",
                "Douglas Eck",
                "Jeff Dean",
                "Slav Petrov",
                "Noah Fiedel"
            ],
            "title": "2022. Palm: Scaling language modeling with pathways",
            "year": 2022
        },
        {
            "authors": [
                "Petrov",
                "Ed H. Chi",
                "Jeff Dean",
                "Jacob Devlin",
                "Adam Roberts",
                "Denny Zhou",
                "Quoc V. Le",
                "Jason Wei"
            ],
            "title": "Scaling instruction-finetuned language models",
            "year": 2022
        },
        {
            "authors": [
                "Peter Clark",
                "Isaac Cowhey",
                "Oren Etzioni",
                "Tushar Khot",
                "Ashish Sabharwal",
                "Carissa Schoenick",
                "Oyvind Tafjord."
            ],
            "title": "Think you have solved question answering? try arc, the ai2 reasoning challenge",
            "venue": "arXiv preprint arXiv:1803.05457.",
            "year": 2018
        },
        {
            "authors": [
                "David A. Cohn",
                "Zoubin Ghahramani",
                "Michael I. Jordan."
            ],
            "title": "Active learning with statistical models",
            "venue": "Journal of Artificial Intelligence Research, 4(1):129\u2013145.",
            "year": 1996
        },
        {
            "authors": [
                "Ona de Gibert",
                "Naiara P\u00e9rez",
                "Aitor Garc\u00eda-Pablos",
                "Montse Cuadros."
            ],
            "title": "Hate speech dataset from a white supremacy forum",
            "venue": "Proceedings of the 2nd Workshop on Abusive Language Online (ALW2), pages 11\u201320.",
            "year": 2018
        },
        {
            "authors": [
                "Marie-Catherine de Marneffe",
                "Mandy Simons",
                "Judith Tonhauser"
            ],
            "title": "The commitmentbank: Investigating projection in naturally occurring discourse",
            "year": 2019
        },
        {
            "authors": [
                "Mostafa Dehghani",
                "Yi Tay",
                "Alexey A. Gritsenko",
                "Zhe Zhao",
                "Neil Houlsby",
                "Fernando Diaz",
                "Donald Metzler",
                "Oriol Vinyals"
            ],
            "title": "The benchmark lottery",
            "year": 2021
        },
        {
            "authors": [
                "Shizhe Diao",
                "Pengcheng Wang",
                "Yong Lin",
                "Tong Zhang"
            ],
            "title": "Active prompting with chain-ofthought for large language models",
            "year": 2023
        },
        {
            "authors": [
                "Thomas Diggelmann",
                "Jordan Boyd-Graber",
                "Jannis Bulian",
                "Massimiliano Ciaramita",
                "Markus Leippold"
            ],
            "title": "Climate-fever: A dataset for verification of real-world climate claims",
            "year": 2020
        },
        {
            "authors": [
                "William B Dolan",
                "Chris Brockett."
            ],
            "title": "Automatically constructing a corpus of sentential paraphrases",
            "venue": "Proceedings of the Third International Workshop on Paraphrasing (IWP2005).",
            "year": 2005
        },
        {
            "authors": [
                "Qingxiu Dong",
                "Lei Li",
                "Damai Dai",
                "Ce Zheng",
                "Zhiyong Wu",
                "Baobao Chang",
                "Xu Sun",
                "Jingjing Xu",
                "Zhifang Sui."
            ],
            "title": "A survey for in-context learning",
            "venue": "ArXiv, abs/2301.00234.",
            "year": 2022
        },
        {
            "authors": [
                "Liat Ein-Dor",
                "Alon Halfon",
                "Ariel Gera",
                "Eyal Shnarch",
                "Lena Dankin",
                "Leshem Choshen",
                "Marina Danilevsky",
                "Ranit Aharonov",
                "Yoav Katz",
                "Noam Slonim."
            ],
            "title": "Active Learning for BERT: An Empirical Study",
            "venue": "Proceedings of the 2020 Conference on Empirical",
            "year": 2020
        },
        {
            "authors": [
                "Yarin Gal",
                "Riashat Islam",
                "Zoubin Ghahramani."
            ],
            "title": "Deep Bayesian active learning with image data",
            "venue": "Proceedings of the 34th International Conference",
            "year": 2017
        },
        {
            "authors": [
                "Xavier Garc\u00eda",
                "Yamini Bansal",
                "Colin Cherry",
                "George F. Foster",
                "Maxim Krikun",
                "Fan Feng",
                "Melvin Johnson",
                "Orhan Firat"
            ],
            "title": "The unreasonable effectiveness of few-shot learning for machine translation",
            "year": 2023
        },
        {
            "authors": [
                "Shivam Garg",
                "Dimitris Tsipras",
                "Percy Liang",
                "Gregory Valiant."
            ],
            "title": "What can transformers learn in-context? a case study of simple function classes",
            "venue": "ArXiv, abs/2208.01066.",
            "year": 2022
        },
        {
            "authors": [
                "Hila Gonen",
                "Srini Iyer",
                "Terra Blevins",
                "Noah A. Smith",
                "Luke Zettlemoyer."
            ],
            "title": "Demystifying prompts in language models via perplexity estimation",
            "venue": "ArXiv, abs/2212.04037.",
            "year": 2022
        },
        {
            "authors": [
                "Andrew Gordon",
                "Zornitsa Kozareva",
                "Melissa Roemmele."
            ],
            "title": "SemEval-2012 task 7: Choice of plausible alternatives: An evaluation of commonsense causal reasoning",
            "venue": "*SEM 2012: The First Joint Conference on Lexical and Computational Seman-",
            "year": 2012
        },
        {
            "authors": [
                "Joel Jang",
                "Seonghyeon Ye",
                "Minjoon Seo."
            ],
            "title": "Can large language models truly understand prompts? a case study with negated prompts",
            "venue": "ArXiv, abs/2209.12711.",
            "year": 2022
        },
        {
            "authors": [
                "Tushar Khot",
                "Peter Clark",
                "Michal Guerquin",
                "Peter Jansen",
                "Ashish Sabharwal."
            ],
            "title": "Qasc: A dataset for question answering via sentence composition",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 8082\u20138090.",
            "year": 2020
        },
        {
            "authors": [
                "Hyuhng Joon Kim",
                "Hyunsoo Cho",
                "Junyeob Kim",
                "Taeuk Kim",
                "Kang Min Yoo",
                "Sang goo Lee."
            ],
            "title": "Self-generated in-context learning: Leveraging autoregressive language models as a demonstration generator",
            "venue": "ArXiv, abs/2206.08082.",
            "year": 2022
        },
        {
            "authors": [
                "Andreas Kirsch",
                "Tom Rainforth",
                "Yarin Gal"
            ],
            "title": "Test distribution-aware active learning: A principled approach against distribution shift and outliers",
            "year": 2021
        },
        {
            "authors": [
                "Rafal Kocielnik",
                "Sara Kangaslahti",
                "Shrimai Prabhumoye",
                "M Hari",
                "R. Michael Alvarez",
                "Anima Anandkumar."
            ],
            "title": "Can you label less by using out-of-domain data? active & transfer learning with few-shot instructions",
            "venue": "ArXiv, abs/2211.11798.",
            "year": 2022
        },
        {
            "authors": [
                "Abdullatif K\u00f6ksal",
                "Timo Schick",
                "Hinrich Schutze."
            ],
            "title": "Meal: Stable and active learning for few-shot prompting",
            "venue": "ArXiv, abs/2211.08358.",
            "year": 2022
        },
        {
            "authors": [
                "Hector Levesque",
                "Ernest Davis",
                "Leora Morgenstern."
            ],
            "title": "The winograd schema challenge",
            "venue": "Thirteenth international conference on the principles of knowledge representation and reasoning.",
            "year": 2012
        },
        {
            "authors": [
                "Itay Levy",
                "Ben Bogin",
                "Jonathan Berant"
            ],
            "title": "Diverse demonstrations improve in-context compositional generalization",
            "year": 2022
        },
        {
            "authors": [
                "David D. Lewis",
                "William A. Gale."
            ],
            "title": "A sequential algorithm for training text classifiers",
            "venue": "In Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.",
            "year": 1994
        },
        {
            "authors": [
                "Jiachang Liu",
                "Dinghan Shen",
                "Yizhe Zhang",
                "Bill Dolan",
                "Lawrence Carin",
                "Weizhu Chen"
            ],
            "title": "What makes good in-context examples for GPT-3",
            "venue": "In Proceedings of Deep Learning Inside Out (DeeLIO",
            "year": 2022
        },
        {
            "authors": [
                "S. Longpre",
                "Julia Reisler",
                "Edward Greg Huang",
                "Yi Lu",
                "Andrew J. Frank",
                "Nikhil Ramesh",
                "Chris DuBois."
            ],
            "title": "Active learning over multiple domains in natural language tasks",
            "venue": "ArXiv, abs/2202.00254.",
            "year": 2022
        },
        {
            "authors": [
                "Yao Lu",
                "Max Bartolo",
                "Alastair Moore",
                "Sebastian Riedel",
                "Pontus Stenetorp."
            ],
            "title": "Fantastically ordered prompts and where to find them: Overcoming fewshot prompt order sensitivity",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Compu-",
            "year": 2022
        },
        {
            "authors": [
                "Aman Madaan",
                "Amir Yazdanbakhsh."
            ],
            "title": "Text and patterns: For effective chain of thought, it takes two to tango",
            "venue": "ArXiv, abs/2209.07686.",
            "year": 2022
        },
        {
            "authors": [
                "Katerina Margatina",
                "Nikolaos Aletras."
            ],
            "title": "On the limitations of simulating active learning",
            "venue": "Findings of the Association for Computational Linguistics: ACL 2023, pages 4402\u20134419.",
            "year": 2023
        },
        {
            "authors": [
                "Katerina Margatina",
                "Loic Barrault",
                "Nikolaos Aletras."
            ],
            "title": "On the importance of effectively adapting pretrained language models for active learning",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2:",
            "year": 2022
        },
        {
            "authors": [
                "Katerina Margatina",
                "Giorgos Vernikos",
                "Lo\u00efc Barrault",
                "Nikolaos Aletras."
            ],
            "title": "Active learning by acquiring contrastive examples",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 650\u2013663, Online and",
            "year": 2021
        },
        {
            "authors": [
                "Clara H. McCreery",
                "Namit Katariya",
                "Anitha Kannan",
                "Manish Chablani",
                "Xavier Amatriain"
            ],
            "title": "Effective transfer learning for identifying similar questions: Matching user questions to covid-19 faqs",
            "year": 2020
        },
        {
            "authors": [
                "Sewon Min",
                "Xinxi Lyu",
                "Ari Holtzman",
                "Mikel Artetxe",
                "Mike Lewis",
                "Hannaneh Hajishirzi",
                "Luke Zettlemoyer"
            ],
            "title": "Rethinking the role of demonstrations: What makes in-context learning work",
            "year": 2022
        },
        {
            "authors": [
                "Shervin Minaee",
                "Nal Kalchbrenner",
                "Erik Cambria",
                "Narjes Nikzad",
                "Meysam Chenaghlu",
                "Jianfeng Gao."
            ],
            "title": "Deep learning\u2013based text classification: a comprehensive review",
            "venue": "ACM computing surveys (CSUR), 54(3):1\u201340.",
            "year": 2021
        },
        {
            "authors": [
                "Akiva Miura",
                "Graham Neubig",
                "Michael Paul",
                "Satoshi Nakamura."
            ],
            "title": "Selecting syntactic, nonredundant segments in active learning for machine translation",
            "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association",
            "year": 2016
        },
        {
            "authors": [
                "Ioannis Mollas",
                "Zoe Chrysopoulou",
                "Stamatis Karlos",
                "Grigorios Tsoumakas."
            ],
            "title": "ETHOS: a multilabel hate speech detection dataset",
            "venue": "Complex Intelligent Systems, 8(6):4663\u20134678.",
            "year": 2022
        },
        {
            "authors": [
                "Paul Christiano",
                "Jan Leike",
                "Ryan Lowe"
            ],
            "title": "Training language models to follow instructions with human feedback",
            "year": 2022
        },
        {
            "authors": [
                "Jane Pan",
                "Tianyu Gao",
                "Howard Chen",
                "Danqi Chen"
            ],
            "title": "What in-context learning \"learns\" in-context: Disentangling task recognition and task learning",
            "year": 2023
        },
        {
            "authors": [
                "Alec Radford",
                "Jeff Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "year": 2019
        },
        {
            "authors": [
                "Lukas Rauch",
                "Matthias A\u00dfenmacher",
                "Denis Huseljic",
                "Moritz Wirth",
                "Bernd Bischl",
                "Bernhard Sick"
            ],
            "title": "Activeglae: A benchmark for deep active learning with transformers",
            "year": 2023
        },
        {
            "authors": [
                "Yasaman Razeghi",
                "Robert L Logan IV",
                "Matt Gardner",
                "Sameer Singh."
            ],
            "title": "Impact of pretraining term frequencies on few-shot numerical reasoning",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022, pages 840\u2013854, Abu Dhabi,",
            "year": 2022
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych."
            ],
            "title": "SentenceBERT: Sentence embeddings using Siamese BERTnetworks",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natu-",
            "year": 2019
        },
        {
            "authors": [
                "Laria Reynolds",
                "Kyle McDonell."
            ],
            "title": "Prompt programming for large language models: Beyond the few-shot paradigm",
            "venue": "Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems, CHI EA \u201921, New York, NY, USA.",
            "year": 2021
        },
        {
            "authors": [
                "Ohad Rubin",
                "Jonathan Herzig",
                "Jonathan Berant."
            ],
            "title": "Learning to retrieve prompts for in-context learning",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-",
            "year": 2022
        },
        {
            "authors": [
                "Rylan Schaeffer",
                "Brando Miranda",
                "Sanmi Koyejo"
            ],
            "title": "Are emergent abilities of large language models a mirage",
            "year": 2023
        },
        {
            "authors": [
                "Timo Schick",
                "Hinrich Sch\u00fctze."
            ],
            "title": "Exploiting cloze-questions for few-shot text classification and natural language inference",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,",
            "year": 2021
        },
        {
            "authors": [
                "Timo Schick",
                "Hinrich Sch\u00fctze."
            ],
            "title": "It\u2019s not just size that matters: Small language models are also fewshot learners",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
            "year": 2021
        },
        {
            "authors": [
                "Christopher Schr\u00f6der",
                "Lydia M\u00fcller",
                "Andreas Niekler",
                "Martin Potthast."
            ],
            "title": "Small-text: Active learning for text classification in python",
            "venue": "Proceedings of the 17th Conference of the European Chapter of",
            "year": 2023
        },
        {
            "authors": [
                "Ozan Sener",
                "Silvio Savarese."
            ],
            "title": "Active learning for convolutional neural networks: A core-set approach",
            "venue": "International Conference on Learning Representations.",
            "year": 2018
        },
        {
            "authors": [
                "Burr Settles."
            ],
            "title": "Active learning literature survey",
            "venue": "Computer Sciences Technical Report 1648, University of Wisconsin\u2013Madison.",
            "year": 2009
        },
        {
            "authors": [
                "Yanyao Shen",
                "Hyokun Yun",
                "Zachary Lipton",
                "Yakov Kronrod",
                "Animashree Anandkumar."
            ],
            "title": "Deep active learning for named entity recognition",
            "venue": "Proceedings of the Workshop on Representation Learning for NLP, pages 252\u2013256.",
            "year": 2017
        },
        {
            "authors": [
                "Emily Sheng",
                "David C Uthus."
            ],
            "title": "Investigating societal biases in a poetry composition system",
            "venue": "Proceedings of the Second Workshop on Gender Bias in Natural Language Processing, pages 93\u2013106.",
            "year": 2020
        },
        {
            "authors": [
                "Weijia Shi",
                "Xiaochuang Han",
                "Hila Gonen",
                "Ari Holtzman",
                "Yulia Tsvetkov",
                "Luke Zettlemoyer"
            ],
            "title": "Toward human readable prompt tuning: Kubrick\u2019s the shining is a good movie, and a good prompt too? ArXiv, abs/2212.10539",
            "year": 2022
        },
        {
            "authors": [
                "Ard Snijders",
                "Douwe Kiela",
                "Katerina Margatina."
            ],
            "title": "Investigating multi-source active learning for natural language inference",
            "venue": "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 2187\u2013",
            "year": 2023
        },
        {
            "authors": [
                "Taylor Sorensen",
                "Joshua Robinson",
                "Christopher Rytting",
                "Alexander Shaw",
                "Kyle Rogers",
                "Alexia Delorey",
                "Mahmoud Khalil",
                "Nancy Fulda",
                "David Wingate."
            ],
            "title": "An information-theoretic approach to prompt engineering without ground truth labels",
            "venue": "Proceed-",
            "year": 2022
        },
        {
            "authors": [
                "Wang",
                "Ziyi Wu"
            ],
            "title": "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models",
            "year": 2022
        },
        {
            "authors": [
                "Oyvind Tafjord",
                "Peter Clark",
                "Matt Gardner",
                "Wen-tau Yih",
                "Ashish Sabharwal."
            ],
            "title": "Quarel: A dataset and models for answering questions about qualitative relationships",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 7063\u2013",
            "year": 2019
        },
        {
            "authors": [
                "Oyvind Tafjord",
                "Matt Gardner",
                "Kevin Lin",
                "Peter Clark."
            ],
            "title": "Quartz: An open-domain dataset of qualitative relationship questions",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
            "year": 2019
        },
        {
            "authors": [
                "Alex Tamkin",
                "Dat Pham Nguyen",
                "Salil Deshpande",
                "Jesse Mu",
                "Noah Goodman."
            ],
            "title": "Active learning helps pretrained models learn the intended task",
            "venue": "Advances in Neural Information Processing Systems.",
            "year": 2022
        },
        {
            "authors": [
                "Simone Tedeschi",
                "Johan Bos",
                "Thierry Declerck",
                "Jan Hajic",
                "Daniel Hershcovich",
                "Eduard H. Hovy",
                "Alexander Koller",
                "Simon Krek",
                "Steven Schockaert",
                "Rico Sennrich",
                "Ekaterina Shutova",
                "Roberto Navigli"
            ],
            "title": "What\u2019s the meaning of superhuman performance",
            "year": 2023
        },
        {
            "authors": [
                "Jesse Dodge",
                "Emma Strubell",
                "Niranjan Balasubramanian",
                "Leon Derczynski",
                "Iryna Gurevych",
                "Roy Schwartz."
            ],
            "title": "Efficient Methods for Natural Language Processing: A Survey",
            "venue": "Transactions of the Association for Computational Linguistics, 11:826\u2013",
            "year": 2023
        },
        {
            "authors": [
                "Alex Wang",
                "Amanpreet Singh",
                "Julian Michael",
                "Felix Hill",
                "Omer Levy",
                "Samuel R Bowman."
            ],
            "title": "Glue: A multi-task benchmark and analysis platform for natural language understanding",
            "venue": "International Conference on Learning Representations.",
            "year": 2019
        },
        {
            "authors": [
                "Boshi Wang",
                "Sewon Min",
                "Xiang Deng",
                "Jiaming Shen",
                "You Wu",
                "Luke Zettlemoyer",
                "Huan Sun."
            ],
            "title": "Towards understanding chain-of-thought prompting: An empirical study of what matters",
            "venue": "ArXiv, abs/2212.10001.",
            "year": 2022
        },
        {
            "authors": [
                "Albert Webson",
                "Ellie Pavlick"
            ],
            "title": "Do promptbased models really understand the meaning of their prompts",
            "venue": "In Proceedings of the 2022 Conference",
            "year": 2022
        },
        {
            "authors": [
                "Jason Wei",
                "Xuezhi Wang",
                "Dale Schuurmans",
                "Maarten Bosma",
                "Brian Ichter",
                "Fei Xia",
                "Ed Chi",
                "Quoc Le",
                "Denny Zhou"
            ],
            "title": "2023a. Chain-of-thought prompting elicits reasoning in large language models",
            "year": 2023
        },
        {
            "authors": [
                "Jerry Wei",
                "Jason Wei",
                "Yi Tay",
                "Dustin Tran",
                "Albert Webson",
                "Yifeng Lu",
                "Xinyun Chen",
                "Hanxiao Liu",
                "Da Huang",
                "Denny Zhou",
                "Tengyu Ma"
            ],
            "title": "2023b. Larger language models do in-context learning differently",
            "year": 2023
        },
        {
            "authors": [
                "Qiang Wei",
                "Yukun Chen",
                "Mandana Salimi",
                "Joshua C Denny",
                "Qiaozhu Mei",
                "Thomas A Lasko",
                "Qingxia Chen",
                "Stephen Wu",
                "Amy Franklin",
                "Trevor Cohen",
                "Hua Xu."
            ],
            "title": "Cost-aware active learning for named entity recognition in clinical text",
            "venue": "Journal",
            "year": 2019
        },
        {
            "authors": [
                "Zhiyong Wu",
                "Yaoxiang Wang",
                "Jiacheng Ye",
                "Lingpeng Kong."
            ],
            "title": "Self-adaptive in-context learning",
            "venue": "ArXiv, abs/2212.10375.",
            "year": 2022
        },
        {
            "authors": [
                "Sang Michael Xie",
                "Aditi Raghunathan",
                "Percy Liang",
                "Tengyu Ma."
            ],
            "title": "An explanation of in-context learning as implicit bayesian inference",
            "venue": "International Conference on Learning Representations.",
            "year": 2022
        },
        {
            "authors": [
                "Canwen Xu",
                "Yichong Xu",
                "Shuohang Wang",
                "Yang Liu",
                "Chenguang Zhu",
                "Julian McAuley"
            ],
            "title": "Small models are valuable plug-ins for large language models",
            "year": 2023
        },
        {
            "authors": [
                "Sohee Yang",
                "Jonghyeon Kim",
                "Joel Jang",
                "Seonghyeon Ye",
                "Hyunji Lee",
                "Minjoon Seo"
            ],
            "title": "Improving probability-based prompt selection through unified evaluation and analysis",
            "year": 2023
        },
        {
            "authors": [
                "Jiacheng Ye",
                "Zhiyong Wu",
                "Jiangtao Feng",
                "Tao Yu",
                "Lingpeng Kong"
            ],
            "title": "Compositional exemplars for in-context learning",
            "year": 2023
        },
        {
            "authors": [
                "Qinyuan Ye",
                "Bill Yuchen Lin",
                "Xiang Ren."
            ],
            "title": "CrossFit: A few-shot learning challenge for crosstask generalization in NLP",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7163\u20137189, Online and",
            "year": 2021
        },
        {
            "authors": [
                "Xi Ye",
                "Srinivasan Iyer",
                "Asli Celikyilmaz",
                "Ves Stoyanov",
                "Greg Durrett",
                "Ramakanth Pasunuru."
            ],
            "title": "Complementary explanations for effective in-context learning",
            "venue": "Findings of the Conference of the Association for Computational Linguistics.",
            "year": 2023
        },
        {
            "authors": [
                "Kang Min Yoo",
                "Junyeob Kim",
                "Hyuhng Joon Kim",
                "Hyunsoo Cho",
                "Hwiyeol Jo",
                "Sang-Woo Lee",
                "Sang-goo Lee",
                "Taeuk Kim"
            ],
            "title": "Ground-truth labels matter: A deeper look into input-label demonstrations",
            "year": 2022
        },
        {
            "authors": [
                "W. Yu",
                "Dan Iter",
                "Shuohang Wang",
                "Yichong Xu",
                "Mingxuan Ju",
                "Soumya Sanyal",
                "Chenguang Zhu",
                "Michael Zeng",
                "Meng Jiang."
            ],
            "title": "Generate rather than retrieve: Large language models are strong context generators",
            "venue": "ArXiv, abs/2209.10063.",
            "year": 2022
        },
        {
            "authors": [
                "Wang",
                "Luke Zettlemoyer"
            ],
            "title": "2022a. Opt: Open pre-trained transformer language models",
            "year": 2022
        },
        {
            "authors": [
                "Yiming Zhang",
                "Shi Feng",
                "Chenhao Tan."
            ],
            "title": "Active example selection for in-context learning",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 9134\u2013 9148, Abu Dhabi, United Arab Emirates. Association",
            "year": 2022
        },
        {
            "authors": [
                "Zhisong Zhang",
                "Emma Strubell",
                "Eduard Hovy."
            ],
            "title": "A survey of active learning for natural language processing",
            "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing.",
            "year": 2022
        },
        {
            "authors": [
                "Tony Zhao",
                "Eric Wallace",
                "Shi Feng",
                "Dan Klein",
                "Sameer Singh."
            ],
            "title": "Calibrate before use: Improving few-shot performance of language models",
            "venue": "ICML, abs/2102.09690.",
            "year": 2021
        },
        {
            "authors": [
                "Yuekai Zhao",
                "Haoran Zhang",
                "Shuchang Zhou",
                "Zhihua Zhang."
            ],
            "title": "Active learning approaches to enhancing neural machine translation",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1796\u20131806, Online. Association",
            "year": 2020
        },
        {
            "authors": [
                "ethos-national_origin (Mollas"
            ],
            "title": "2022), ethosrace (Mollas et al., 2022), ethos-religion (Mollas et al., 2022), tweet_eval-stance_atheism (Barbieri et al., 2020), tweet_eval-stance_feminist (Barbieri et al., 2020) and quarel (Tafjord",
            "year": 2019
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "The field of Natural Language Processing (NLP) has recently witnessed a remarkable paradigm shift with the emergence of in-context learning with large language models (LLMs), also referred to as few-shot learning (Brown et al., 2020). Traditionally, NLP systems heavily relied on supervised learning approaches, where large amounts of labeled training data were necessary to achieve high\n\u2217 Work done during an internship at FAIR, Meta.\npredictive performance. However, in-context learning has changed this status-quo by enabling LLMs to learn from limited, context-specific examples and adapt to new tasks and domains with remarkable proficiency (Zhao et al., 2021; Chowdhery et al., 2022; Garc\u00eda et al., 2023; Wei et al., 2023b; Touvron et al., 2023; Bubeck et al., 2023). Unlike more traditional approaches, which require extensive retraining or fine-tuning for every new task, in-context learning empowers LLMs to generalize from a few examples that are fed to the model through prompting to learn a new task at hand, without any weight updates.\nThe data efficiency of few-shot in-context learning of LLMs is indeed remarkable with only a small number of demonstrations.1 Still, such demonstrations constitute labeled data examples, raising two key questions: (1) When faced with tasks where there is only unlabeled data available, how can we select the most appropriate samples to label and then use as in-context demonstrations? (2) When we have labeled data for a given task, how can\n1We use the terms in-context examples, few-shot examples, demonstrations, descriptors and exemplars interchangeably throughout the paper.\nwe efficiently identify the most informative combination of demonstrations for in-context learning? Answering these questions is essential to ensure effective and efficient few-shot learning using LLMs.\nA growing line of work has investigated how incontext learning works (Reynolds and McDonell, 2021; Razeghi et al., 2022; Xie et al., 2022; Ye et al., 2023b), which demonstrations to use (Liu et al., 2022; Zhang et al., 2022b; Wu et al., 2022; Kim et al., 2022), how to form the prompt (Zhao et al., 2021; Lu et al., 2022; Yang et al., 2023) and whether ground truth labels matter (Webson and Pavlick, 2022; Min et al., 2022; Yoo et al., 2022; Wang et al., 2022; Wei et al., 2023b). Still, to the best of our knowledge, no prior work has explored the problem of in-context demonstration selection explicitly through the lens of active learning (AL).\nBased on the core principle that not all data points are equally useful, AL (Cohn et al., 1996; Settles, 2009) aims to identify the most informative instances from a pool of unlabeled data for annotation. Iterating through model training, data acquisition and human annotation, the goal is to achieve data efficiency. A data-efficient AL algorithm ensures that a model achieves satisfactory performance on a withheld test set by selecting only a small fraction of the unlabeled data for annotation that typically is better than randomly selecting and annotating data of equal size.\nIn this paper, our main aim is to redefine the concept of data efficiency within the framework of in-context learning inspired by conventional active learning settings. For this purpose, we assume that given a pool of labeled or unlabeled data, the objective is to identify a set of k examples that will serve as demonstrations to an LLM, resulting in optimal performance on a held-out test set. Given this formulation of data efficiency, we explore the effectiveness of the most prevalent AL approaches based on uncertainty (Lewis and Gale, 1994; Cohn et al., 1996; Gal et al., 2017), diversity (Brinker, 2003; Bod\u00f3 et al., 2011; Sener and Savarese, 2018) and similarity (Margatina et al., 2021; Kirsch et al., 2021; Liu et al., 2022), as demonstration selection methods for in-context learning (Figure 1).\nOur key contributions are as follows:\n\u2022 We formulate the selection of in-context examples as a single iteration AL problem and explore the effectiveness of four standard approaches: uncertainty, diversity, similarity and random sampling.\n\u2022 We evaluate 15 models, between 125M and 30B parameters, from the GPT (Radford et al., 2019; Brown et al., 2020; Black et al., 2022) and OPT (Zhang et al., 2022a) families in 15 classification and 9 multi-choice tasks, using different AL sampling techniques to select demonstrations for few-shot learning.\n\u2022 We demonstrate that while diversity and uncertainty sampling perform slightly better than random sampling, choosing in-context examples that are semantically similar to the input test examples outperforms consistently all other methods by a large margin across model families and sizes in all tasks.\n\u2022 We show that while uncertainty sampling is one of the strongest AL approaches in supervised learning, this does not generalize to incontext learning, where interestingly it underperforms. Our analysis, however, shows that larger models might perform better with uncertain demonstrations, hinting that uncertainty might be an emerging LLM ability."
        },
        {
            "heading": "2 Active In-context Learning",
            "text": ""
        },
        {
            "heading": "2.1 Problem Formulation",
            "text": "To build our in-context learning framework with actively acquired demonstrations, depicted in Figure 2, we borrow the formulation from the standard pool-based active learning paradigm. We consider an AL setting where we have a large pool of unlabeled data from which we want to sample a batch of k data points using a data acquisition algorithm. We assume that these k are subsequently labeled by humans (Figure 2, top). Instead of following the standard approach that involves multiple iterations of data selection and model training, we only perform a single iteration (Longpre et al., 2022), since we do not train or perform any model-in-the-loop updates. We use the acquired set of k examples as demonstrations for in-context learning with an LLM (i.e., as part of the prompt). We assume the existing datasets as the pool from which to select these k examples. The goal is to find the most informative examples from the pool, which are expected to yield improved performance on the test set when employed as a few-shot prompt, compared to demonstrations randomly sampled from the same pool. The resulting prompt consists of the concatenation of the k acquired examples (text\ninputs and labels with standard verbalizers), alongside the test example, repeated for all data instances in the test set (Figure 2, bottom)."
        },
        {
            "heading": "2.2 Few-shot Data Acquisition Algorithms",
            "text": "We build few-shot data acquisition algorithms inspired by the most prevalent AL algorithmic families that are uncertainty sampling, diversity sampling and similarity (also known as testaware sampling) (Zhang et al., 2022c). We acknowledge that there are more elaborate demonstration selection methods for in-context learning that are not considered in our experiments, such as Q-learning (Zhang et al., 2022b), Self Adaptive (Wu et al., 2022), SG-ICL (Kim et al., 2022), MI (Sorensen et al., 2022), inter alia. These methods fall beyond the scope of our analysis, as our objective is to gain insights into AL principles for in-context learning, rather than benchmarking all available demonstration sampling algorithms. Additionally, there are techniques, complementary to the aforementioned few-shot data selection methods, such as calibration (Zhao et al., 2021) and prompt re-ordering (Lu et al., 2022), which can further enhance few-shot learning performance, while also being out of the scope of our work.\nRandom The overarching objective of any data selection method, like AL algorithms, is to identify data points that, however used, yield superior models compared to randomly sampled data from the same pool which we consider as a baseline method.\nDiversity The first data selection method that we use as a representative for the diversity family of methods is a simple clustering technique, similar\nto Yu et al. (2022). Specifically, we first encode all data points in the pool of unlabeled data with Sentence-BERT (Reimers and Gurevych, 2019) embeddings and then we perform k-means clustering.2 We choose the number of clusters to be k and select one data point from each cluster. The underlying principle of this approach is that leveraging a diverse set of in-context examples can offer greater advantages compared to random sampling. This selection strategy ensures that the chosen demonstrations are likely to encompass a broad range of information, enhancing the overall effectiveness of the learning process.\nUncertainty The second approach is an uncertainty-based sampling algorithm that is based on SPELL, proposed by Gonen et al. (2022). Since we use an off-the-shelf LLM that does not have a fine-tuned classification layer, we cannot compute the model probabilities associated with each class (for a classification or multi-choice task). This essentially means that we cannot use standard AL uncertainty baselines such as maximum entropy or least confidence. Instead, we can use the loss, i.e., perplexity, of the LLM to score each candidate example from the pool. Gonen et al. (2022) define perplexity of the prompt as the perplexity of the full prompt sequence, including the input itself, and without the label, averaged over 1, 000 examples. Our approach is different since we want to evaluate the perplexity of each in-context example individually. We also do not do the averaging over a thousand examples as we wanted to make the method more general, without\n2We use the implementation from https://www.sbert. net/examples/applications/clustering/.\nthe need to assume access to that many examples. The underlying principle guiding this approach is the belief that a high perplexity set of in-context examples can yield greater advantages compared to randomly sampling from the dataset (or at least for data efficiency in a supervised learning setting this is proven to enhance the learning process).\nSimilarity Finally, the third AL algorithm we consider is based on KATE a kNN-augmented incontext example selection method proposed by Liu et al. (2022). This method retrieves examples from the pool that are semantically-similar to a test query sample. We use Sentence-BERT (Reimers and Gurevych, 2019) representations of both the pool and the test set to find the k-nearest neighbours. The rationale behind this approach is that the most similar demonstrations to the test example will best help the model answer the query. We have to highlight, however, that by definition each test example will have a different prompt, as the k most similar demonstrations will be different. This is a crucial limitation of this approach compared to the others, as it assumes that we are able to acquire labels for any in-context example selected from the pool."
        },
        {
            "heading": "3 Experimental Setup",
            "text": "Models We evaluate 15 LLMs in total, 8 models from the GPT (Radford et al., 2019; Brown et al., 2020; Black et al., 2022) and 7 from the OPT (Zhang et al., 2022a) family. We choose our models to span from a few million to tens of billions parameters, as we want to study how the model size affects the effectiveness of in-context example selection methods. All models considered in this work are publicly available.\nTasks & Datasets Following Min et al. (2022), we evaluate all LLMs in 15 classification and 9 multi-choice tasks taken from the Crossfit (Ye et al., 2021) benchmark. We provide details for all tasks and datasets considered in the Appendix A.1.\nIn-context Learning Prompting Unless specified otherwise, we sample k=16 demonstrations, i.e., labeled data, from the pool with each AL method. After collecting the k input-label pairs, we concatenate them all together with the test example that we want to make a prediction for to form the LLM prompt (Figure 2). Our implementation, including prompt verbalizers, is based on those by Min et al. (2022) and Yoo et al. (2022)."
        },
        {
            "heading": "4 Results",
            "text": "Figure 3 shows the results on few-shot incontext learning across all data acquisition methods (random, diversity, uncertainty and similarity), model families (GPT and OPT) and tasks (classification and multi-choice question answering).3 Overall, we observe the anticipated trend of performance enhancement with increasing scale, particularly notable in the multi-choice tasks for both OPT and GPT models.\nStill, the most remarkable finding is the substantial performance improvement achieved by selecting similar in-context examples for few-shot learning, particularly in classification tasks. This observation aligns with the findings reported by Liu et al. (2022), who demonstrated similar patterns in sentiment analysis tasks with GPT-3. Our results indicate that the selection of appropriate demonstrations can hold greater significance than the number of model parameters, at least within the scope of the models evaluated in this study. In multi-choice tasks, similarity is also the top-performing acquisition method, while the other three approaches exhibit closely competitive performance.\nThe data selection method based on diversity is consistently the second best approach after similarity (with very few exceptions in the multichoice tasks for OPT models). Even though it is not the top performing method, we can consider that consistently outperforming random sampling is a strong signal that diversity in the demonstrations is a characteristic of effective demonstrations. Levy et al. (2022) explore the setting of compositional generalization, where models are tested on outputs with structures that are absent from the training set and thus selecting similar demonstrations is insufficient. They show that combining diverse demonstrations with in-context learning substantially improves performance for the task of compositional generalization semantic parsing.\nRemarkably, uncertainty sampling, typically regarded as one of the best approaches for traditional supervised AL (Shen et al., 2017; Margatina et al., 2022; Schr\u00f6der et al., 2023), exhibits the lowest performance. This finding contradicts the conventional AL principles that suggest selecting a few highly uncertain labeled data points for data efficiency. Similar to our findings, Gonen et al. (2022) explore the performance variabilty of dif-\n3We provide the results per dataset and model in the Appendix A.2, including the majority vote baseline.\nferent prompts (consisting of randomly sampled demonstrations) for in-context learning using uncertainty, and find that the lower the perplexity of the prompt is, the better the prompt is able to perform the task. Still, in a later analysis we show that larger models might be able to handle high uncertain prompts better than the smaller ones (\u00a75.4)."
        },
        {
            "heading": "5 Analysis",
            "text": ""
        },
        {
            "heading": "5.1 Effect of Model Size",
            "text": "In order to gain some intuition on the effect of scale, we group together GPT and OPT models with similar number of parameters. We provide the results in Figure 4. Even after aggregating the results from both model families, we do not see any specific pattern as the model parameters increase. We wanted to explore whether the largest models of our collection would behave differently under the varying in-context learning settings, thus perhaps attributing such a behaviour to potential emergent abilities of the bigger LLMs, but we observe the same patterns (in terms of ranking between the considered data selection methods). We believe that this is an interesting avenue of future research,\nespecially as models grow and, most likely, will continue to grow exponentially in terms of model parameters. Our findings show that the in-context learning ability of models from a few millions to a few billions of parameters follows similar patterns. However, this might not be the case when studying even larger models, as primary results hint (Rae et al., 2022; Wei et al., 2023b; Chowdhery et al., 2022; Touvron et al., 2023)."
        },
        {
            "heading": "5.2 Ground Truth Demonstrations",
            "text": "We next delve into the debate of whether ground truth demonstrations, i.e., providing the correct label to the in-context examples, is crucial for high performing in-context learning. Various findings have shown mixed results for randomly sampled data, which essentially means that the benefit of ground truth labels depends on the label space or the distribution of inputs specified by the demonstrations (Min et al., 2022; Yoo et al., 2022). In our analysis, we differentiate from prior work by exploring the importance of ground truth demonstrations in the case of leveraging similar in-context examples (\u00a72.2). The rationale is that if the find-\nings of Min et al. (2022) ubiquitously hold, then the performance should only marginally drop if we replace ground truth labels with random ones. If the high performance of the similarity acquisition method can be retained, we would be able to construct an efficient and effective in-context selection algorithm that would be agnostic to correct labels. However, we find that this is not the case. We show in Figure 5 that for almost all datasets considered in this part of analysis, the performance with random labels drops significantly as expected. There are cases where replacing the original labels with random ones as in Min et al. (2022) retains the same performance (e.g., in the glue-rte dataset), but this is certainly a finding that does not generalize overall. In summary, we find that ground truth demonstrations are crucial for high performing, robust in-context learning (Yoo et al., 2022)."
        },
        {
            "heading": "5.3 Most vs. Least Similar Demonstrations",
            "text": "To investigate the striking effectiveness of the similarity-based acquisition strategy, we conduct additional experiments where we invert the approach\nand choose the least similar examples from the pool to form the prompt. This investigation aims to ascertain whether the remarkable performance gains can be attributed solely to the semantic similarity between the demonstrations and the test input. The results depicted in Figure 6 substantiate our hypothesis, demonstrating a significant performance drop when employing opposite examples from the pool as in-context exemplars. While this pattern is particularly pronounced in the classification tasks, it consistently emerges across different model sizes and task types. Hence, we can assert that maximizing semantic similarity between the demonstations and the input test sample is an unequivocally vital attribute for achieving successful in-context learning outcomes with LLMs. Future endeavors in the field of building effective in-context learning frameworks should incorporate this principle to enable data-efficient algorithms that can fully harness the potential of LLMs."
        },
        {
            "heading": "5.4 Most vs. Least Uncertain Demonstrations",
            "text": "Along these lines, we also opt to examine the duality between selecting the most or the least uncertain in-context examples from the pool. We show the results of these experiments for the GPT models in Figure 7. Interestingly, we observe that while the smaller language models (gpt2, gpt2-medium, gpt-large) perform better with the least uncertain prompts, the larger models seem to start benefiting from the demonstrations with high uncertainty. This is particularly clear in the largest model of our collection, GPT-Neox (20B parameters). This interesting finding shows that even larger models will most likely perform better with high entropy incontext examples, similar to their supervised learn-\ning counterparts. Such findings open a plethora of research questions regarding understanding how incontext learning works (Reynolds and McDonell, 2021; Razeghi et al., 2022; Xie et al., 2022; Min et al., 2022), how AL and data acquisition methods reshape with larger language models or whether we can properly investigate potential emergent abilities of LLMs acquired by model scaling (Wei et al., 2022; Schaeffer et al., 2023)."
        },
        {
            "heading": "5.5 Evaluation with Different Metrics",
            "text": "Finally, we want to provide a clear overview of our experiments and summary of our findings, while making some clarifications regarding how we evaluate and compare different approaches to in-context learning. Figure 8 shows the results for in-context learning with random sampling, three data selection techniques inspired by AL (\u00a72.2), namely diversity, uncertainty and similarity, and a zero-shot baseline where no labeled examples are included in the prompt (no_demo). We show that incontext learning with k=16 demonstrations consistently outperform zero-shot learning for an average of 15 classification tasks for gpt2-large, gpt-j and gpt-neox. Next, we observe that the best performing in-context example selection method is by a clear margin similarity, followed by diversity. This finding corroborates the original hypothesis of AL that, indeed, not all data is equal and there exist more informative data subsets\nin the pool that can be used as in-context exemplars. We can see that the uncertainty baseline, which is usually top performing in supervised AL, generally underperforms in the few-shot setting. Still, there is some evidence that this could change with even larger and better models (\u00a75.4). Finally, delving into the debate on whether ground truth labels matter or not (Min et al., 2022; Yoo et al., 2022), we show that replacing original with random incontext labels hurt significantly the performance of similarity, the best data selection method (\u00a75.2).\nWe further emphasize the significance of employing a meticulous evaluation framework, particularly in the selection of appropriate metrics. In Figure 8, we illustrate the same classification experiments, but with the F1 score plotted on the left and accuracy on the right. The use of F1, the conventional metric for classification tasks, reveals a distinct ranking among the various AL methods, with similarity exhibiting the best performance, followed by diversity. Conversely, when employing accuracy to compare the methods, diversity emerges as the top approach, followed by similarity and random selection. This disparity highlights the potential for misconceptions or obscured findings, underscoring the need for caution when evaluating and comparing different methods across various models within the in-context learning framework (Dehghani et al., 2021; Min et al., 2022; Yoo et al., 2022; Tedeschi et al., 2023)."
        },
        {
            "heading": "6 Related Work",
            "text": ""
        },
        {
            "heading": "6.1 Understanding In-Context Learning",
            "text": "Few-shot in-context learning with LLMs has garnered significant attention in recent NLP research. Simply concatenating a few labeled examples to form the prompt for the LLM results in high performance gains, even outperforming fine-tuned models (Brown et al., 2020; Chung et al., 2022; Ouyang et al., 2022; Dong et al., 2022). This has naturally lead to study its effectiveness with multiple fewshot learning benchmarks such as Crossfit (Ye et al., 2021) and BigBench (Srivastava et al., 2022).\nAnother active area of research is on understanding how in-context learning works (Xie et al., 2022; Garg et al., 2022; Aky\u00fcrek et al., 2022; Xie et al., 2022; Pan et al., 2023), and what are its strengths and limitations (Webson and Pavlick, 2022; Jang et al., 2022; Levy et al., 2022; Shi et al., 2022; Agrawal et al., 2022; Wei et al., 2023b; Ye et al., 2023b). Previous work has explored the effec-\ntiveness of the chain-of-thought prompting technique (Wei et al., 2023a; Wang et al., 2022; Madaan and Yazdanbakhsh, 2022), while other studies try to determine the importance of in-context ground truth labels, with Min et al. (2022) showing that random labels do not hurt performance considerably and Yoo et al. (2022) providing a rebuttal. Wei et al. (2023b) explain that model size plays an role in the effect of ground truth labels, showing that small LMs ignore flipped labels, while LLMs can override semantic priors learned during pretraining. Interestingly, Razeghi et al. (2022) demonstrates that in-context learning performance is highly correlated with the prevalence of each instance in the pretraining corpus, showing that models are more accurate on few-shot numerical reasoning on instances whose terms are more frequent."
        },
        {
            "heading": "6.2 Selecting Informative Demonstrations",
            "text": "Typically, work on evaluating LLMs in few-shot settings commonly uses randomly sampled examples to compose the in-context prompt (Brown et al., 2020; Zhang et al., 2022a; Chowdhery et al., 2022; Chung et al., 2022; Touvron et al., 2023). Nonetheless, it has been demonstrated that the effectiveness of few-shot performance significantly depends on the selection of in-context examples (Kocielnik et al., 2022; Ye et al., 2023a; Diao et al., 2023; Xu et al., 2023). Consequently, there is ongoing research on generating or selecting the most informative demonstrations, aiming to maximize the downstream few-shot performance.\nSome approaches are based on a retrieval component that sources the most relevant examples from a pool. The prompt retriever can be trainable (Rubin et al., 2022) or based on pretrained embeddings (Liu et al., 2022; Agrawal et al., 2022). Gonen et al. (2022) use uncertainty to evaluate the use-\nfulness of in-context examples and find that the best performing prompts have low perplexity. Zhang et al. (2022b) formulate example selection for incontext learning as a sequential decision problem and show modest performance improvements by acquiring data with their proposed method based on reinforcement learning. Other previous work, instead of focusing on the part of acquiring data for in-context learning, show that demonstration ordering (Lu et al., 2022) and model calibration (Zhao et al., 2021) are additional properties that influence the few-shot learning performance."
        },
        {
            "heading": "6.3 Active Learning for NLP",
            "text": "AL has been extensively studied in various NLP tasks, including machine translation (Miura et al., 2016; Zhao et al., 2020), natural language inference (Snijders et al., 2023), named entity recognition (Shen et al., 2017; Wei et al., 2019), and text classification (Ein-Dor et al., 2020; Margatina et al., 2022; Schr\u00f6der et al., 2023), among others.\nStill, its importance and potential value is on the rise (Zhang et al., 2022c; Rauch et al., 2023), as the current language model pretraining paradigm continues to advance the state-of-the-art (Tamkin et al., 2022). Given the fundamental premise that\u201cnot all data is equal\u201d it is reasonable to expect researchers to actively seek the \u201cmost informative\u201d data for pretraining or adapting their large language models (LLMs), as well as identifying the most valuable in-context examples for few-shot learning scenarios. Previous work has explored AL for promptbased finetuning (K\u00f6ksal et al., 2022), proposing a method based in inter-prompt uncertainty sampling with diversity coupled with the PET architecture (Schick and Sch\u00fctze, 2021a,b) that outperforms all AL baselines."
        },
        {
            "heading": "7 Conclusion",
            "text": "In this study, we have examined the selection of demonstrations, i.e., labeled data that provide examples of solving a task, for in-context learning with LLMs. We formulated the selection process as a single iteration active learning problem and evaluated four standard approaches: uncertainty, diversity, similarity, and random sampling. Our evaluation involved 15 models of varying size from the GPT and OPT families, encompassing 15 classification tasks and 9 multi-choice tasks. Through extensive experimentation, we have demonstrated that selecting demonstrations that are semantically similar to the test input examples consistently outperforms all other methods by a significant margin across all model families, sizes, and tasks. This corroborates findings of several previous and concurrent studies that explore the properties of \u201cgood\u201d in-context examples (Liu et al., 2022; Shi et al., 2022). Interestingly, our findings reveal that uncertainty sampling, although effective in supervised learning, underperforms in the in-context learning paradigm. This highlights the importance of our work in exploring the principles of active learning in the context of few-shot learning."
        },
        {
            "heading": "Acknowledgements",
            "text": "We would like to thank the anonymous reviewers for their suggestions to improve our work. We also thank Louis Martin, Patrick Lewis, Fabio Petroni and other members of FAIR for their constructive feedback on previous versions of the paper.\nLimitations\nTasks & Datasets We acknowledge that even though we experimented with a well established benchmark, the Crossfit (Ye et al., 2021) benchmark consisting of 15 classification and 9 multi-choice question answering datasets (Appendix A.1), it might still not be sufficient to ensure that our findings will generalize to any NLP classification or multi-choice application of in-context learning.\nLanguage We also acknowledge that all the datasets and models considered in this work are based on the English language alone. This limits generalizability of our findings to other languages.\nModel scale We investigated in-context learning with actively acquired demonstrations with 15 GPT\nand OPT models that span 125M to 30B parameters. Even though our experimentation is thorough, our findings might not generalize to larger or smaller transformer-based models, or models based in a different architecture.\nActive learning considerations We explicitly note in the paper that we do a single active learning iteration, which is different than the common AL loop that consists of multiple iterations. As we explained, because the model-in-the-loop (the LLM) is not updated (no fine-tuning) with new data, performing multiple iterations does not make sense in this context (Figure 2). Still, it would be interesting for future work to explore how we can perform multiple AL iterations while constructing the prompt (i.e., acquiring the demonstrations). The upper bound would be to try all the combinations of a set of labeled data and find the best performing prompt. However, doing this with unlabeled data, in an efficient way, is far from trivial. We refer to Zhang et al. (2022c); Treviso et al. (2023); Margatina and Aletras (2023) for in-depth suggestions for future work in this area."
        },
        {
            "heading": "A Experimental Details",
            "text": "A.1 Tasks & Datasets Following Min et al. (2022), we evaluate our models in 15 classification and 9 multi-choice tasks taken from the Crossfit (Ye et al., 2021) benchmark. Specifically the tasks we evaluate are poem_sentiment (Sheng and Uthus, 2020), gluewnli (Wang et al., 2019; Levesque et al., 2012), climate_fever (Diggelmann et al., 2020), gluerte (Wang et al., 2019), superglue-cb (de Marneffe et al., 2019), sick (Minaee et al., 2021), medical_questions_pairs (McCreery et al., 2020), gluemrpc (Wang et al., 2019; Dolan and Brockett, 2005), hate_speech18 (de Gibert et al., 2018), ethos-national_origin (Mollas et al., 2022), ethosrace (Mollas et al., 2022), ethos-religion (Mollas et al., 2022), tweet_eval-stance_atheism (Barbieri et al., 2020), tweet_eval-stance_feminist (Barbieri et al., 2020) and quarel (Tafjord et al., 2019a), openbookqa,qasc (Khot et al., 2020), commonsense_qa, ai2_arc (Clark et al., 2018), codah (Chen et al., 2019), superglue-copa (Gordon et al., 2012), quartz-with_knowledge (Tafjord et al., 2019b), quartz-no_knowledge (Tafjord et al., 2019b), for classification and multi-choice respectively.\nA.2 Full results We provide below the full set of results, for each dataset, model and active learning acquisition strategy considered. The dashed line depicts the majority vote baseline.\nA.3 Model Family We provide the results on few-shot learning with k=16 demonstrations per prompt per model family and task type in Figure 9. We observe the same patterns for both GPT and OPT models."
        }
    ],
    "title": "Active Learning Principles for In-Context Learning with Large Language Models",
    "year": 2023
}