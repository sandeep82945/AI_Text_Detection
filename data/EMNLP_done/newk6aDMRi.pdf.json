{
    "abstractText": "One of the challenges in language teaching is how best to organize rules regarding syntax, semantics, or phonology in a meaningful manner. This not only requires content creators to have pedagogical skills, but also have that language\u2019s deep understanding. While comprehensive materials to develop such curricula are available in English and some broadly spoken languages, for many other languages, teachers need to manually create them in response to their students\u2019 needs. This is challenging because i) it requires that such experts be accessible and have the necessary resources, and ii) describing all the intricacies of a language is time-consuming and prone to omission. In this work, we aim to facilitate this process by automatically discovering and visualizing grammar descriptions. We extract descriptions from a natural text corpus that answer questions about morphosyntax (learning of word order, agreement, case marking, or word formation) and semantics (learning of vocabulary). We apply this method for teaching two Indian languages, Kannada and Marathi, which, unlike English, do not have well-developed resources for second language learning. To assess the perceived utility of the extracted material, we enlist the help of language educators from schools in North America to perform a manual evaluation, who find the materials have potential to be used for their lesson preparation and learner evaluation.",
    "authors": [
        {
            "affiliations": [],
            "name": "Aditi Chaudhary"
        },
        {
            "affiliations": [],
            "name": "Arun Sampath"
        },
        {
            "affiliations": [],
            "name": "Ashwin Sheshadri"
        },
        {
            "affiliations": [],
            "name": "Antonios Anastasopoulos"
        },
        {
            "affiliations": [],
            "name": "Graham Neubig"
        }
    ],
    "id": "SP:5350c4f87a1af409d810afb9768af6682c477706",
    "references": [
        {
            "authors": [
                "Cristian Ahumada",
                "Claudio Gutierrez",
                "Antonios Anastasopoulos."
            ],
            "title": "Educational tools for mapuzugun",
            "venue": "Proceedings of the 17th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2022), pages 183\u2013196, Seattle, Wash-",
            "year": 2022
        },
        {
            "authors": [
                "Irshad Ahmad Bhat",
                "Vandan Mujadia",
                "Aniruddha Tammewar",
                "Riyaz Ahmad Bhat",
                "Manish Shrivastava."
            ],
            "title": "Iiit-h system submission for fire2014 shared task on transliterated search",
            "venue": "Proceedings of the Forum for Information Retrieval Evaluation, FIRE",
            "year": 2015
        },
        {
            "authors": [
                "Riyaz Ahmad Bhat",
                "Rajesh Bhatt",
                "Annahita Farudi",
                "Prescott Klassen",
                "Bhuvana Narasimhan",
                "Martha Palmer",
                "Owen Rambow",
                "Dipti Misra Sharma",
                "Ashwini Vaidya",
                "Sri Ramagurumurthy Vishnu"
            ],
            "title": "The hindi/urdu treebank project",
            "year": 2017
        },
        {
            "authors": [
                "Aditi Chaudhary",
                "Zaid Sheikh",
                "David R Mortensen",
                "Antonios Anastasopoulos",
                "Graham Neubig."
            ],
            "title": "Autolex: An automatic framework for linguistic exploration",
            "venue": "arXiv preprint arXiv:2203.13901.",
            "year": 2022
        },
        {
            "authors": [
                "Aditi Chaudhary",
                "Kayo Yin",
                "Antonios Anastasopoulos",
                "Graham Neubig."
            ],
            "title": "When is wall a pared and when a muro?: Extracting rules governing lexical selection",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Process-",
            "year": 2021
        },
        {
            "authors": [
                "T Cobb."
            ],
            "title": "Web compleat lexical tutor/vocabulary profile",
            "venue": "Retrieved on September, 4:2011.",
            "year": 2002
        },
        {
            "authors": [
                "Niladri Sekhar Dash."
            ],
            "title": "Corpus linguistics: An introduction",
            "venue": "Pearson Education India.",
            "year": 2008
        },
        {
            "authors": [
                "Mark Davies"
            ],
            "title": "The corpus of contemporary american english (coca): 560 million words, 1990-present",
            "year": 2008
        },
        {
            "authors": [
                "Gina Doggett."
            ],
            "title": "Eight approaches to language teaching",
            "venue": "ERIC.",
            "year": 1986
        },
        {
            "authors": [
                "Zi-Yi Dou",
                "Graham Neubig."
            ],
            "title": "Word alignment by fine-tuning embeddings on parallel corpora",
            "venue": "arXiv preprint arXiv:2101.08231.",
            "year": 2021
        },
        {
            "authors": [
                "Pedregosa Fabian."
            ],
            "title": "Scikit-learn: Machine learning in python",
            "venue": "Journal of machine learning research 12, page 2825.",
            "year": 2011
        },
        {
            "authors": [
                "Keith S Folse."
            ],
            "title": "Myths about teaching and learning second language vocabulary: What recent research says",
            "venue": "TESL reporter, 37:13\u201313.",
            "year": 2004
        },
        {
            "authors": [
                "Peter JM Groot."
            ],
            "title": "Computer assisted second language vocabulary acquisition",
            "venue": "Language learning & technology, 4(1):56\u201376.",
            "year": 2000
        },
        {
            "authors": [
                "Joseph Marvin Imperial",
                "Lloyd Lois Antonie Reyes",
                "Michael Antonio Ibanez",
                "Ranz Sapinit",
                "Mohammed Hussien."
            ],
            "title": "A baseline readability model for Cebuano",
            "venue": "Proceedings of the 17th Workshop on Innovative Use of NLP for Building",
            "year": 2022
        },
        {
            "authors": [
                "Keith Johnson",
                "Christopher Brumfit."
            ],
            "title": "The communicative approach to language teaching",
            "venue": "Oxford University Press.",
            "year": 1979
        },
        {
            "authors": [
                "Anisia Katinskaia",
                "Javad Nouri",
                "Roman Yangarber."
            ],
            "title": "Revita: a system for language learning and supporting endangered languages",
            "venue": "Proceedings of the joint workshop on NLP for Computer Assisted Language Learning and NLP for Language Acquisition,",
            "year": 2017
        },
        {
            "authors": [
                "Julia Kreutzer",
                "Isaac Caswell",
                "Lisa Wang",
                "Ahsan Wahab",
                "Daan van Esch",
                "Nasanbayar Ulzii-Orshikh",
                "Allahsera Tapo",
                "Nishant Subramani",
                "Artem Sokolov",
                "Claytone Sikasote"
            ],
            "title": "Quality at a glance: An audit of web-crawled multilingual datasets",
            "year": 2021
        },
        {
            "authors": [
                "Cathy Li",
                "Farah Lalani."
            ],
            "title": "The covid-19 pandemic has changed education forever",
            "venue": "World economic forum, volume 29. The rise of online learning during the COVID-19 pandemic| World Economic . . . .",
            "year": 2020
        },
        {
            "authors": [
                "T\u00e4ckstr\u00f6m",
                "Claudia Bedini",
                "N\u00faria Bertomeu Castell\u00f3",
                "Jungmee Lee."
            ],
            "title": "Universal Dependency annotation for multilingual parsing",
            "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),",
            "year": 2013
        },
        {
            "authors": [
                "George A Miller."
            ],
            "title": "Wordnet: a lexical database for english",
            "venue": "Communications of the ACM, 38(11):39\u201341.",
            "year": 1995
        },
        {
            "authors": [
                "John Munby."
            ],
            "title": "Communicative syllabus design: A sociolinguistic model for designing the content of purpose-specific language programmes",
            "venue": "Cambridge university press.",
            "year": 1981
        },
        {
            "authors": [
                "ISP Nation."
            ],
            "title": "Teaching and learning vocabulary",
            "venue": "Handbook of research in second language teaching and learning, pages 605\u2013620. Routledge.",
            "year": 2005
        },
        {
            "authors": [
                "OpenAI."
            ],
            "title": "GPT-4 technical report",
            "venue": "CoRR, abs/2303.08774.",
            "year": 2023
        },
        {
            "authors": [
                "Tommaso Pasini",
                "Alessandro Raganato",
                "Roberto Navigli."
            ],
            "title": "XL-WSD: An extra-large and crosslingual evaluation framework for word sense disambiguation",
            "venue": "Proc. of AAAI.",
            "year": 2021
        },
        {
            "authors": [
                "J. Ross Quinlan."
            ],
            "title": "Induction of decision trees",
            "venue": "Machine learning, 1(1):81\u2013106.",
            "year": 1986
        },
        {
            "authors": [
                "Jack C Richards",
                "David Singleton",
                "Michael H Long."
            ],
            "title": "Exploring the second language mental lexicon",
            "venue": "Cambridge University Press.",
            "year": 1999
        },
        {
            "authors": [
                "Tatyana Ruzsics",
                "Olga Sozinova",
                "Ximena GutierrezVasques",
                "Tanja Samardzic."
            ],
            "title": "Interpretability for morphological inflection: from character-level predictions to subword-level rules",
            "venue": "Proceedings of the 16th Conference of the European Chapter of",
            "year": 2021
        },
        {
            "authors": [
                "Ali Fuad Selvi",
                "Ali Shehadeh."
            ],
            "title": "Approaches and Methods in English for Speakers of Other Languages & Non-native English-speaking Teachers (NNESTs)",
            "venue": "Wiley-Blackwell.",
            "year": 2018
        },
        {
            "authors": [
                "Philip D Smith Jr."
            ],
            "title": "Second Language Teaching: A Communicative Strategy",
            "venue": "The Foreign & Second Language Educator Series. ERIC.",
            "year": 1981
        },
        {
            "authors": [
                "Juhi Tandon",
                "Himani Chaudhry",
                "Riyaz Ahmad Bhat",
                "Dipti Sharma."
            ],
            "title": "Conversion from paninian karakas to Universal Dependencies for Hindi dependency treebank",
            "venue": "Proceedings of the 10th Linguistic Annotation Workshop held in conjunction with ACL",
            "year": 2016
        },
        {
            "authors": [
                "Thiemo Wambsganss",
                "Andrew Caines",
                "Paula Buttery."
            ],
            "title": "ALEN app: Argumentative writing support to foster English language learning",
            "venue": "Proceedings of the 17th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2022),",
            "year": 2022
        },
        {
            "authors": [
                "Zarah Weiss",
                "Detmar Meurers"
            ],
            "title": "Assessing sentence readability for German language learners with broad linguistic modeling or readability formulas: When do linguistic insights make a difference",
            "venue": "In Proceedings of the 17th Workshop on Innovative",
            "year": 2022
        },
        {
            "authors": [
                "Hyunsook Yoon."
            ],
            "title": "An investigation of students\u2019 experiences with corpus technology in second language academic writing",
            "venue": "Ph.D. thesis, The Ohio State University.",
            "year": 2005
        },
        {
            "authors": [
                "Bowei Zou",
                "Pengfei Li",
                "Liangming Pan",
                "Ai Ti Aw."
            ],
            "title": "Automatic true/false question generation for educational purpose",
            "venue": "Proceedings of the 17th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2022), pages 61\u201370,",
            "year": 2022
        },
        {
            "authors": [
                "Tandon"
            ],
            "title": "2016) to convert between the two formats to obtain POS tags, lemmatization and morphological analysis",
            "venue": "UD annotation scheme (McDonald et al.,",
            "year": 2013
        },
        {
            "authors": [
                "Chaudhary"
            ],
            "title": "2021) and learn interpretable models such as decision tree (Quinlan",
            "year": 1986
        },
        {
            "authors": [
                "Chaudhary"
            ],
            "title": "Perception Survey In Table 3 we present the questions posed to the teachers for assessing the extracted learning material. Consent of all subjects",
            "year": 2021
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Recently, computer-assisted learning systems have gained tremendous popularity, especially during the COVID-19 pandemic when in-person instruction was not possible, leading to the need for userfriendly and accessible learning resources (Li and Lalani, 2020). Because these materials are curated by subject experts, this makes curriculum design a challenging process, especially for languages where experts or resources are inaccessible.\n\u2217Currently works at Google Research\nIn the language learning context this entails designing materials for different learning levels, covering different grammar points, finding relevant examples, and even creating evaluation exercises. For second language (L2) learning, it is not straightforward to reuse existing curricula even in the same language, as the requirements of L2 learners could be vastly different from the traditional first language (L1) setting (Munby, 1981). Given that only a handful of languages, in particular English, have a plethora of resources for L2 learning, but for most of the world\u2019s 4000+ written languages (Eberhard et al., 2022), it is a struggle to find even a sufficiently large and good quality text corpus (Kreutzer et al., 2021), let alone teaching material. In this paper, we explore to what extent can a combination of NLP techniques and corpus linguistics assist language education for languages with limited teaching as well as text resources?\nWith technology advancements, teachers have used corpus-based methods (Yoon, 2005) to analyze large text corpora and find patterns such as collocations and relevant examples of language use, (Davies, 2008; Cobb, 2002), to supplement their vocabulary teaching. Now, with advances in NLP, we can extract instructional material for more complex use cases. For instance, the popular tasks of Part-of-Speech (POS) tagging and dependency parsing do answer questions about some local aspects of the language such as \u2018what is the function of words or their relations\u2019. AutoLEX (Chaudhary et al., 2022) uses this local analysis for extracting answers to linguistic questions in both humanand machine-readable format. Given a question (e.g. \u201chow are objects ordered with respect to verbs in English\u201d), AutoLEX formalizes it into an NLP task and learns an algorithm which extracts not only the common patterns (e.g. \u201cobject is before/after the verb\u201d) but also the conditions which trigger each of them (e.g. \u201cobjects come after verbs except for interrogatives\u201d).\nIn this paper, we take a step further by examining the utility of such extracted descriptions for language education. We collaborate with in-service teachers, where we tailor automatically extracted grammar points to their teaching objectives. The process starts with identifying \u201cteachable grammar points\u201d which are individual syntactic or semantic concepts that can be taught to a learner. For example, with respect to word order, a teachable grammar point could be understanding \u201chow subjects are positioned with respect to verbs\u201d. We apply AutoLEX to extract human-readable explanations directly from the text corpora of the language of interest. Finally, we present the extracted materials to in-service teachers to evaluate the utility in their teaching process. Figure 1 outlines this collaborative design. To our knowledge, use of such automatically extracted insights have not been explored for language teaching (see section 7 for related work). We summarize our contributions below \u2013\n\u2022 We explore how NLP methods can play a role in language pedagogy, especially for languages which lack resources. This entails designing teaching points by including real users (teachers in our case) in a collaborative design process and further evaluating its its practical utility with a large human study.\n\u2022 We automatically extract leaning materials for Kannada and Marathi, two Indian languages, and present them through an online interface1\nand release the code/data publicly.2\n1https://www.autolex.co 2https://github.com/reviewfornlp/\n\u2022 We conduct a survey with 17 in-service teachers to understand their perception of the extracted materials \u2013 85% Kannada teachers and 40% Marathi teachers note that they will likely use this material for lesson preparation, and for providing additional material to students for self-exploration."
        },
        {
            "heading": "2 Why Marathi and Kannada?",
            "text": "Although these languages are spoken primarily in India, a small but significant populace of speakers has emigrated, resulting in a demand to maintain language skills within this diaspora. We identified schools in North America that teach these languages to English speakers including children and adults, with their primary objective to a) preserve and promote the language and culture and, b) help speakers communicate with their community. While there are existing textbooks, they cannot be used as-is, as they are based on more traditional L1 teaching (Selvi and Shehadeh, 2018), where the language is taught from the ground up, from introducing the alphabet, its pronunciation and writing, to each subsequent grammar point. Teachers have instead adapted the existing material and continue to design new material to suit the L2 speakers\u2019 needs. Additionally, in comparison to English, both these languages have far fewer L2 learning resources. Both Marathi and Kannada are not part of any popular tools (e.g. Duolingo3 or Rosetta Stone (Stone, 2010)). For Marathi, there is an online learning tool Barakhadi4 which, however, is not\nteacher-perception 3https://www.duolingo.com/ 4https://barakhadi.com/\nfree of cost. Therefore, these languages are underresourced with respect to pedagogical resources, and will likely benefit from this exercise."
        },
        {
            "heading": "3 Proposed Work",
            "text": "Although language education has been widely studied in literature, there is no one \u2018right\u2019 method of teaching. Since our focus is to create pedagogical content to assist teachers in their process, we conduct a pilot study and collaborative design with two Kannada teachers who are deeply involved in the curriculum designing. We first identify some \u201cteachable grammar points\u201d which, as defined above, are points that can be taught to a learner and are typically included in a learning curriculum. Next, following AutoLEX, we formulate each grammar point into an NLP task and extract human-readable descriptions, as shown below."
        },
        {
            "heading": "3.1 Identify Teachable Grammar Points",
            "text": "As a first step towards the curriculum design scenario, we performed an inventory of the aspects taught in existing teaching materials. We manually inspected three of the eight Kannada textbooks shared by the curriculum designers, which are organized by increasing learning complexity, and identified grammar aspects such as identification of word categories (e.g. nouns, verbs, etc.), vocabulary, and suffixes. In Table 1, we show examples of the teachable grammar points that we attempt to extract, which we group under five grammar aspects namely General Information, Vocabulary, Word Order, Suffix Usage and Agreement. We only cover the above subset out of all grammar aspects described in the textbooks because they satisfied two desiderata: a) the Kannada teachers identified these to be widely studied and important in their curriculum and b) the underlying linguistic questions can be formulated into an NLP task thereby allowing us to extract descriptions."
        },
        {
            "heading": "3.2 Extract Learning Material",
            "text": "As noted above, we build on AutoLEX (Chaudhary et al., 2022) to extract learning material. AutoLEX takes as input a raw text corpus, comprising of sentences in the language of interest, and produces human- and machine-readable explanations of different linguistic behaviors, following a four step process. The first step is formulating a linguistic question into an NLP task. For example, given a question \u201chow are objects ordered with respect\nto verbs in English\u201d, it is formalized it into an NLP task \u201cpredict whether the object comes before or after the verb\u201d. The second step is to learn a model for this prediction task, for which training data is constructed by identifying and extracting features from the text corpora that are known to govern the said phenomenon (e.g. POS tagging and dependency parsing). Next, AutoLEX learn an algorithm which extracts not only the common patterns (e.g. \u201cobject is before/after the verb\u201d) but also the conditions which trigger each of them (e.g. \u201cobjects come after verbs except for interrogatives\u201d). Importantly, for each pattern, illustrative examples with examples of exceptions are extracted from the corpora. Finally, the extracted conditions are visualized with illustrative examples through an online interface. We adapt the above process to extract descriptions for all the teachable grammar points defined in Table 1. Of those, AutoLEX already outlines the process for agreement and word order and for the others we adapt the process as shown below.\nWord Order and Agreement Both Marathi and Kannada are morphologically rich, with highly inflected words for gender, person, number; morphological agreement between words is also frequently observed. Both languages predominantly follow SOV word order, but because syntactic roles are often expressed through morphology, there are often deviations from this order. Therefore, learners must understand both the rules of word order and agreement to produce grammatically correct language. In AutoLEX, word order and agreement grammar points are extracted by formulating questions, as shown in Table 1, and learning a model to answer each question. As outlined above, to train these models, we must first identify the relevant elements (e.g. for word order, subjects, and verbs) to construct the training data. To do so, the corpus of that language must be syntactically annotated with POS tags, morphological analyses, lemmas, and dependency parses. Next, to discover when the subject is before or after, AutoLEX extracts syntactic and lexical signals from other words in that sentence and uses them to train a classifier. To obtain interpretable patterns, we use decision trees (Quinlan, 1986), similar to AutoLEX, which extract \u201cif X then Y\u201d style patterns that can, if presented appropriately, be interpreted by teachers or learners. Example word order patterns extracted from this model for Marathi are shown in Figure 1. While AutoLEX uses English as the meta-language to present ex-\ntracted descriptions, we use a combination of L1 (English) and L2. This is in alignment with methods such as Grammar-Translation (Doggett, 1986) that encourage learning using both L1 and L2.\nSuffix Usage Along with understanding sentence structure, it is equally important to understand how inflection works at the word level. The first step is to identify the common suffixes for each word type (e.g. nouns) and then ask \u201cwhich suffix to use when\u201d. For that, we need to identify the POS tags and produce a morphological analysis for each word, like we did above. To identify the suffix, we train a model that takes as input a word with its morphological analysis (e.g. \u2018deshaala,N,Acc,Masc,Sing\u2019) and outputs the decomposition (e.g. \u2018desh + laa\u2019). Next, a classification model is trained for each such suffix (e.g. \u2018-laa\u2019) to extract the conditions under which one suffix is typically used over another (Figure 2).\nVocabulary Vocabulary is probably one of the most important components of language learning (Folse, 2004). There are several debates on the best strategy for teaching vocabulary; we follow prior literature (Groot, 2000; Nation, 2005; Richards et al., 1999), which use a mixture of definitions with examples of word usage in context. Specifically, we organize the material around three questions, as shown in Table 1. There are some categories of words where the same L1 (English) word can have multiple L2 translations, with fine-grained semantic subdivisions (e.g. \u2018bhaat\u2019 and \u2018tandul\u2019 both refer to \u2018rice\u2019 in Marathi, but the latter refers to raw rice and the former refers to cooked rice). Chaudhary et al. (2021) propose a method for identifying such word pairs, along with explanations on their usage, using parallel sentences between English and the L2. Each pair of sentence translations is first run through an automatic word aligner (Dou and Neubig, 2021), which extracts word-byword translations, producing a list of English words with their corresponding L2 translations. On top of this initial list, filtration steps are applied to extract those word pairs that show fine-grained divergences. Training data is then constructed to solve the task of lexical selection, i.e. for a given L1 word (e.g. \u2018rice\u2019) in which contexts to use one L2 word over another (e.g. \u2018bhaat\u2019 vs \u2018tandul\u2019). Because most of our learners have English as their L1, we extract signals from both the L1 and L2 corpora to train the classifier and thereby derive style patterns which contain both L1 and L2. Communicative Approach (Johnson and Brumfit, 1979) focuses on teaching through functions (e.g. selfintroduction, identification of relationships, etc.) over grammar forms; therefore, we also organize vocabulary around popular categories. We run a word-sense disambiguation (WSD) model (Pasini et al., 2021) on English sentences, which helps us to identify the word sense for each word in context (e.g. \u2018bank.n.02\u2019 refers to a financial institution while \u2018bank.n.01\u2019 refers to a river edge). Given the hierarchy of word senses expressed in WordNet (Miller, 1995), we can traverse the ancestors of each sense to find whether it belongs to any of the pre-defined categories (e.g. food, relationships, animals, fruits, colors, time, verbs, body parts, vehicle, elements, furniture, clothing). Example Marathi words extracted are shown in Figure 4. We also identify popular adjectives, their synonyms,\nand antonyms, also extracted from WordNet, and present them in a similar format (Figure 5).5 For each word, we also present accompanying examples that illustrate its usage in context, along with its English translations. For the benefit of users who are not familiar with the script of L2 languages, we automatically transliterate into Roman script using Bhat et al. (2015).\nGeneral Information In addition to answering these morpho-syntax and semantic questions, we also present salient morphology properties at the language level. Specifically, from the syntactically parsed corpus of the target language, we hope to answer basic questions such as \u201cwhat morphological properties (e.g. gender, person, number, tense, case) does this language have\u201d, as shown in Table 1. These questions were inspired from the Kannada textbooks shared by experts, which introduces the learner to basic syntax and morphology. Understanding syntax patterns are crucial, especially for Kannada and Marathi, which show significant variations in inflection. Through the previous vocabulary section, learners can learn the L2 words for action verbs, and through this section, they can learn how to use those verbs for different genders, tenses, etc. For each question, we organize the information by frequency, a common practice in language teaching where textbooks often comprise of frequently used examples (Dash, 2008).\nAlong with relevant content, the format in which the material is presented is equally important. Smith Jr (1981) outline four steps involved in language teaching: presentation, explanation, repetition of material until it is learned, and transfer of materials in different contexts, which have no fixed order. For example, some teachers prefer the presentation of content (e.g. reading material, examples, etc.) first followed by explanation (e.g. grammar rules), while Smith Jr (1981) discuss that, for above-average learners, explanation followed by presentation may be preferable. In our design, we extract and present both (i.e. rules and examples) without any specific ordering, allowing educators to decide based on their requirements. By providing illustrative examples from the underlying text at each step, we hope to address the transfer step, where learners are exposed to real language .\n5First, we automatically identify frequent cross-lingual word pairs from our corpus. Next, we identify the adjectives using POS tagging and use WordNet to extract the antonyms/synonyms of their English counterparts."
        },
        {
            "heading": "4 Automatic Evaluation",
            "text": "Since our objective is to evaluate whether such automatically derived linguistic insights can be useful for language pedagogy, we first conduct a pilot study to evaluate quality and properties of the extracted materials (section 5). Next, we conduct a study with several in-service teachers, both in Kannada and Marathi, to evaluate relevance, usability, and presentation of the extracted materials (section 6). In addition to human evaluation, we follow Chaudhary et al. (2022) to automatically evaluate the quality of extracted descriptions. This provides a quick sanity check on whether our trained models are able to learn the said linguistic phenomena.\nWord order and Agreement Chaudhary et al. (2022) automatically evaluate the learnt model by measuring the accuracy on held-out sentences. For example, for subject-verb model, the gold label is the observed word order which can be determined from the POS and dependency parses (i.e. whether the subject is \u2018before\u2018 or \u2018after\u2019 the verb), which is then compared with the model prediction to compute the accuracy. This model is compared with a baseline that assigns the most frequent observed pattern in the training data as model prediction.\nSuffix Usage We use a similar most-frequent baseline where the most frequent suffix pattern is used as model prediction for the baseline accuracy, where the observed suffix is the gold label.\nVocabulary We follow the accuracy computation from Chaudhary et al. (2021) to evaluate the model used for extracting semantic subdivisions \u2013 for each sentence the model prediction is compared with the gold label which is the observed L2 word for the L1 word. The baseline uses the most frequently observed L2 word translation for the given L1 word and is compared with the gold label to compute the baseline accuracy."
        },
        {
            "heading": "4.1 Setup",
            "text": "Data Since our goal is to create teaching material for learners having English as L1, we use the parallel corpus of Kannada-English and Marathi-English from SAMANANTAR (Ramesh et al., 2022) comprising of 4 million sentences, as our starting point. This covers text from a variety of domains such as news, Wikipedia, talks, religious text, movies.\nModel As mentioned in section 3, the first step in the extraction of materials is to parse sentences for POS tags, morphological analysis and dependency parsing. To obtain this analysis for our corpus,\nwe use UDIFY (Kondratyuk and Straka, 2019) that jointly predicts POS tags, lemma, morphology and dependency tree over raw sentences. However, UDIFY requires training data in the UD annotation scheme (McDonald et al., 2013). Kannada has no UD treebank available and for Marathi the treebank is extremely low-resourced covering only 300 sentences. Therefore, we train our own parser as outlined in subsection A.1. To learn models for extracting descriptions, we follow the same modeling setup as Chaudhary et al. (2021) and Chaudhary et al. (2022) and use decision trees (Quinlan, 1986) to extract the patterns, explanations and accompanying examples (subsection A.2). For suffix usage, we additionally train a morphology decomposition model (Ruzsics et al., 2021) which breaks a word into its lemma and suffixes, over which we learn a classification model."
        },
        {
            "heading": "4.2 Results",
            "text": "In Table 5 we report results for word order, suffix usage and agreement. We can see that in most cases, the rules extracted by the model outperform the respective baselines, suggesting that the model is able to extract decent first-pass rules, with 98% avg. accuracy for Kannada word order, 48% for agreement, 85% for suffix usage, 68% for vocabulary, 98% for Marathi word order, 61% for agreement, 85% for suffix usage and 70% for vocabulary.6"
        },
        {
            "heading": "5 Human Quality Evaluation",
            "text": "We conduct a limited study for a sanity check with two Kannada teachers.\nVocabulary We present both experts with an automatically generated list of 100 English-Kannada word pairs, where one English word has multiple translations showing fine-grained semantic subdivisions. Both experts found 80% of the word pairs to be valid, according to the criterion that they show different usages. For example, for \u2018doctor\u2019, the model discovered four unique translations, namely \u2018vaidya, vaidyaro, daktor, vaidyaru\u2019 in Kannada which the expert found interesting for teaching as they demonstrated fine-grained divergences, both semantically and syntactically. For instance, \u2018vadiya\u2019 is the direct translation of \u2018doctor\u2019, whereas \u2018daktor\u2019 is the English word used\n6Because there tends to be strong agreement in these languages, there is a class imbalance which probably led to the low performance of the agreement classifier.\nas-is, \u2018vaidyaro\u2019 is the plural form and \u2018vaidayaru\u2019 is a formal way of saying a doctor.\nWord Order For word order, experts evaluate the rules for subject-verb and object-verb order. For subject-verb, seven grammar rules explaining the different word order patterns were extracted (4 explaining when the subject can occur both before and after the verb, 2 rules informing when subjects occur after, and 1 showing the default order of \u201cbefore\u201d). Of the seven rules, experts found four to be valid patterns. For object-verb word order, of the six rules extracted by the model, experts marked that 2 rules precisely captured the patterns, while one rule was too fine-grained. Interestingly, in addition to correctly identifying the dominant order, all the rules which were deemed valid showed non-dominant patterns. The rules marked as invalid were invalid because the syntactic parser that generated the underlying syntactic analyses incorrectly identified the subjects/objects. Such errors are expected given that there is not sufficient quantity/quality of expertly annotated Kannada syntactic analyses available to train a high-quality parser. However, we would argue that these results are still encouraging because i) despite imperfect syntactic analysis, the proposed method was able to extract several interesting counter-examples to the dominant word order, and ii) further improvements in the underlying parsers for low-resource languages may be expected through active research.\nSuffix Usage We extract different suffixes used for each word type (e.g. nouns, adjectives, etc.) but in the interest of time asked experts to evaluate only the suffixes extracted for nouns and verbs. Of the 18 noun suffixes, 7 were marked as valid, 2 suffixes were not suffixes in traditional terms but arise due to \u201csandhi\u201d i.e. transformation in the characters at morpheme boundaries. Similarly, for verb suffixes, 53% (7/13) were marked as valid. Experts mentioned that understanding suffix usage is particularly important in Kannada, as it is an agglutinative language with different affixes for different grammar categories."
        },
        {
            "heading": "6 Teacher Perception Study",
            "text": "For Kannada, we work with teachers from the Kannada Academy7 (KA), which is one of the largest organizations of free Kannada teaching schools in the world and recruit 12 volunteer teachers. For\n7https://www.kannadaacademy.com/\nMarathi, there is no central organization as for Kannada, but there are many independent schools in North America. We reached out to Marathi Vidyalay8 in New Jersey, that teaches learners in the age group of 6-15, and Shala in Pittsburgh9. Marathi Vidyalay is a small school consisting of seven volunteer teachers, of whom four agreed to participate, while Shala has one teacher. All participants are volunteer teachers; teaching is not their primary profession. Since we extract learning materials automatically from publicly available corpora which may contain material which is ageinappropriate, we purposefully chose to share these materials with the teachers who we feel are best suited to decide how to use them.\nPerception Survey To answer the research question of whether materials are practically usable and, if so, with regard to what aspects, we analyze the Kannada and Marathi teachers\u2019 perception regarding relevance, utility and presentation of the materials. First, a 30\u201360 minute meeting is conducted for the teachers, in which we introduce the tool, the different grammar points covered in it, and how to navigate the online interface. Teachers have one week to explore the materials. Finally, all teachers receive a questionnaire Table 3 that requires them to assess the relevance, utility and presentation.10"
        },
        {
            "heading": "6.1 Kannada Results and Discussion",
            "text": "We report individual results in Table 2. 12 teachers with varying levels of teaching experience participated in this study.11 All teachers have used some online tools, but mostly for creating assignments for the learners (e.g. Google Classroom, Kahoot12, Quizlet13), or conducting classes (e.g. Zoom). However, none had used immersive online tools similar to our tool.\nRelevance We see that teachers, on average, find 45\u201360% of material presented as relevant to their\n8https://marathivishwa.org/marathi-shala/ 9https://www.mmpgh.org/MarathiShala.shtml\n10Although we conducted a manual evaluation of a subset of extracted materials in section 5, we did not remove those items that were marked as incorrect by the experts as we wanted to understand how the materials, as directly obtained automatically without significant human intervention, are perceived when presented as-is. This is close to the real world setting where human evaluation of each grammar point is not feasible.\n11Four teachers had less than three years of experience, four teachers between 3-10 years, and the remaining had 10+ years of experience. Four teachers teach only beginners, while others have experience teaching higher levels as well.\n12https://kahoot.com/ 13https://quizlet.com/\nexisting curriculum. This is notable given that the underlying corpus is not specifically curated for language teaching and contains rather formal language. All teachers noted that especially for beginners they prefer starting with simpler and more conversational language style, but 5 teachers explicitly mentioned that for advanced learners this would be very helpful. In fact, one of the teachers having 3+ years of experience teaching intermediate to advanced learners explicitly mentioned that\u2013\n\u201cThe examples are well written, however, for beginners and intermediates, this might be too detailed. The corpus could be from a wider data source. The use of legal terms is less commonly used in day-to-day life. Advanced learners will certainly benefit from this.\u201d\nUtility We find that for all grammar concepts, most teachers (nearly 80%) expressed that they were likely to use the materials for lesson preparation. The per-grammar category results are in Table 2. In fact, one teacher who used our materials to teach suffix usage to an adult learner said\u2013\n\u201cI used this tool to teach an American adult who takes private lessons and found it helpful in addressing her grammar questions. I liked how it was clearly segregated i.e. the suffixes for nouns vs proper-nouns and how it is different from one another. It is definitely great tool to refer for adults but again the vocabulary is perfect to improve written skills than the spoken language\u201d.\nSome teachers also mentioned that they could present the material to students for self-exploration, and about 70% teachers noted that it would be especially helpful for vocabulary learning. When asked what aspects of the presented material they would consider using, all teachers said that they would use the illustrative examples for all sections except for the word order and agreement sections. For agreement and word order sections, although they liked the general concepts presented in the material (for example, the non-dominant patterns shown under each section), 88% of the teachers felt that the material covered advanced topics outside the current scope. Although the quality evaluation of the rules was not part of this study, teachers noted that if the accuracy of the rules, particularly for\nsuffix usage, could be further improved, they could foresee this tool being used in classroom teaching, as suffixes are essential in Kannada.\nPresentation In terms of presentation of the materials, all teachers found them easy to navigate through, although it took some getting used to. This is expected given that the teachers spent only a few hours (5-6) over the course of a week exploring all materials. 8 teachers noted that for a new user the materials could be overwhelming to navigate but for instance, the two Kannada experts, who also participated in the quality study, have had weeks of exposure to the tool and therefore rated it very easy to navigate. We also find that these results vary for different grammar categories covered, for example, for the Vocabulary section, generally the materials presented were \u2018somewhat-easy\u2019 to \u2018easy\u2019 to navigate, while for the Agreement section, 18.2% teachers found the materials difficult to navigate. One of the reasons could be the meta-language used to describe the materials, for instance for Agreement the rules consisted of formal linguistic jargon (for example, most teachers were unfamiliar with the term \u2018lemma\u2019 or the different POS tags)14."
        },
        {
            "heading": "6.2 Marathi Results and Discussion",
            "text": "For Marathi, five teachers participated in the study, all of whom teach at the beginner level with a few intermediate learners.\nRelevance Teachers find only 10\u201315% of the materials as relevant to their existing curriculum. This\n14For reference, we had created a documentation for the teachers in the study, which provides definition of these formal terms along with examples, but it is hard to determine whether the teachers consulted them frequently while evaluating.\nis much less than what the Kannada teachers reported, probably because the Marathi schools\u2019 primary focus is teaching beginners. For beginners, teachers begin by introducing the alphabet, simple vocabulary, and sentences. In our tool, currently we do not curate the material according to learner age/experience, and we have extracted the learning materials from a public corpus which comprises of news articles that are not beginner-oriented.\nUtility Unlike in the Kannada findings, where 85% teachers said that were \u2018likely to use\u2019 the materials, for Marathi, 60% teachers said \u2018not likely to use\u2019. The main reason being that the Marathi teachers mainly teach beginner levels and found the materials more suited for advanced learners. The teachers who marked that were \u2018likely to use\u2019 noted that they would use them for lesson preparation. 50% of those also said that they could provide the materials to advanced students for self-exploration, to encourage them to explore the materials and ask questions. Similarly to the Kannada study, two teachers found the illustrative examples to be of the most utility, as they demonstrate a variety of usage. However, they did note that because the underlying corpus was too restricted in genre, they would benefit more from applying this tool to their curated set of stories, which are age-appropriate.\nPresentation 88% of the teachers found the materials \u2018somewhat easy\u2019 to navigate and similar to the Kannada teachers, mentioned that it did require some time to understand the format. The teachers also said that currently the material is too content heavy and not visually engaging, if the presentation could be improved along those aspects, it would\nmake the tool more inviting."
        },
        {
            "heading": "7 Related Work",
            "text": "Below, we discuss some relevant literature for language learning.\nAutomatic Assessment Automatically assessing a learner\u2019s progress is perhaps the most popular NLP application explored in the past. For instance, Zou et al. (2022) automatically generate true/false question to assess an English learner\u2019s reading comprehension. Wambsganss et al. (2022) provide feedback on erroneous argument structures to help improve an English learner\u2019s essay writing skills. While most work has been for English, some works have developed assessment tools for other languages, for example, Weiss and Meurers (2022) assess sentence readability for German L2 learners, Imperial et al. (2022) build the first readability model for Cebuano which assesses the readability level of children\u2019s books. Similar to us, they also use interpretable models (e.g. SVM, RandomForests) trained using linguistic features extracted from a text corpora. However, their focus is on classifying the content into three learner levels, while our focus is towards extracting teaching content from the corpus.\nEducational Tools Over the years there has been a surge in language learning tools such as Rosetta Stone (Stone, 2010), Duolingo15, LingQ16, LearnALanguage17, Omniglot18. Most of these tools have learning content manually curated with the help of subject matter experts, which, however, makes it difficult to extend them to numerous languages. Recently, NLP tools have been used to develop resources for low-resource languages, for instance, Ahumada et al. (2022) use a combination of linguistic resources (e.g. grammars), NLP tools (e.g.- morphological analyzers) and community resources (e.g. dictionaries) to build learning tools for the indigenous language Mapuzugun. Specifically, they design an orthography recognizer which identifies which of the three alphabets the input text is in, converts across orthographies if required, performs word segmentation and analysis and maps to them user-readable phrases/words. These are presented to Mapuzugun students which\n15https://www.duolingo.com/ 16https://www.lingq.com/en/grammar-resource/ 17https://www.learnalanguage.com/ 18https://www.omniglot.com/\nreveal promising results. Revita (Katinskaia et al., 2017) automatically create exercises for several endangered languages within the Russian Federation. Specifically, they use morphological analyzers to construct cloze-test questions which requires readers to provide the correct surface form of the missing word in a text\nLLMs for Learning With the advent of Large Language Models (LLMs), many research and commercial applications are exploring their use for language learning, especially for retrieving examples of word collocations or creative writing samples. For example, DuoLingo Max19 use GPT-4 (OpenAI, 2023) for conversation practice across different scenarios (e.g. going on a vacation versus ordering in a restaurant), which is a useful feature for learning real-world language use. However, this feature is only available for learning high-resource languages of French and Spanish for English speakers. As more languages are added to LLMs, such automatic features can be leveraged across languages and speakers. Additionally, our main focus is to extract interpretable patterns for understanding complex grammatical aspects, which currently is not straightforward to extract from LLMs."
        },
        {
            "heading": "8 Next Steps",
            "text": "In this work, we have explored one combination of NLP techniques and corpus linguistics to assist in language education. The perception study shows that teachers do find the selected grammar points relevant and interesting, which highlights the importance of a collaborative design; however, all note that the content is more suitable for advanced learners. Although in the current state, the materials cannot be used as-is but the teachers find this overall effort very promising, as this tool can be applied to a corpus of their choice, which is more suited for the learning requirements. Among the different features, teachers find the illustrative examples to be most useful, especially for understanding the non-dominant linguistic behaviors or exceptions to general rules. Additionally, the tool has the capability to extract numerous example usages which the teachers noted as a big plus, as it can provide a starting point for them to build upon rather than them having to find examples manually.\n19"
        },
        {
            "heading": "9 Limitations",
            "text": "Currently, a major limitation of the tool, as noted by the teachers, is that the content is not organized by learner age/experience. A next step would be to invite teachers to organize the content by each level, taking the learner incrementally through the complexities of language. For beginner learners, language properties are built through engaging stories with little use of formal grammar terms. Therefore, using simpler meta-language to explain the grammar points and including engaging content would be a worthwhile addition. Even for the teachers, the materials took some time getting used to, especially the formal linguistic terms, therefore, in addition to simplifying the language, educating the teachers in the tool format will also be necessary for effective learning. We hope that our work drives more such practical research in language education where we consult the real users (teachers in our work) to better understand what they need and work with them in collaboration."
        },
        {
            "heading": "10 Ethical Considerations",
            "text": "We acknowledge that there are several ethical considerations to keep in mind while creating content or tools that will be directly used by human learners. Since currently we use public corpora to extract the learning materials, they may contain unwanted bias or age-inappropriate language or even culturallyinsensitive materials. That is why we work in close collaboration with the respective educators in this work."
        },
        {
            "heading": "Acknowledgements",
            "text": "We are grateful to Charles Perfetti and Lin Chen from the University of Pittsburgh, for the illuminating discussions on L2 acquisition. We thank all teachers, without whom this work would not have been possible or meaningful. Specifically, we are grateful to Kannada Academy teachers\u2013 Arun Sampath, Ashwin Sheshadri, Manasa Kashi, Mukta Hendi, Sunita Sundaresh, Aravind Gangaiah, Shashi Basavaraju, Madhu Rangappagowda, Gayathri Hebbar, Shruthi A, Naina Sharma, Gowri Gudi and P Tantry. We are also grateful to the Marathi Vidyalay, New Jersey teachers\u2013 Sudhir Ambekar, Aparna Potdar, Sujata Kulkarni, Varsha Joshi and Archana Kakirde and the Marathi Shala teacher from Pittsburgh\u2013 Pranati Talnikar. We also thank Sunanda Tumne, Komal Chaukkar, and Sona\nBhide of the Bruhan Maharashtra Mandal (BMM) Shala for providing initial feedback on the interface. We also thank Pruthwik Mishra and Dipti Misra from IIIT-Hyderabad for sharing the Marathi and Kannada treebanks for training the parser. This work is sponsored by the Waibel Presidential Fellowship and the National Science Foundation under grants 1761548, 2125466 and 2109578 . This research was performed under protocol number 2018- 00000208 approved by the Carnegie Mellon University Institutional Review Board. Antonios Anastasopoulos is supported by NSF grant IIS-2327143."
        },
        {
            "heading": "A Appendix",
            "text": "A.1 Learning a Parser for Marathi and Kannada\nAs mentioned in the main text, we train our own parser for both Marathi and Kannada to get the POS tags, dependency parses and lemmas. To train a parser for Marathi and Kannada, we use the training data collected by IIIT-Hyderabad20, which is annotated in the Paninian Grammar Framework (Bhat et al., 2017). However, UDIFY requires training data in the UD annotation scheme (McDonald et al., 2013), so we follow Tandon et al. (2016) to convert between the two formats to obtain POS tags, lemmatization and morphological analysis. However, this converted data does not have dependency information. To obtain dependency data, we train UDIFY in a related language (Hindi) and apply it directly to the converted data above.21 We then train a new model on this converted data and augment it with the Hindi data, and apply the resulting model on the 4 million Marathi and Kannada raw sentences. The performance of the resulting parser is seen in Table 4.\nA.2 Model for Extracting Learning Material\nTo extract descriptions in human-readable format, we follow Chaudhary et al. (2022) and Chaudhary et al. (2021) and learn interpretable models such as decision tree (Quinlan, 1986) and SVM as they are conducive to interpretation.\nFor the grammar aspects of Agreement and Word order, we use XGBOOST to learn a decision tree for each language and setting separately, with the following hyperparameters: learning-rate:0.1, n-estimators:1, subsample:0.8, colsample-bytree:0.8, objective: multi:softprob. We perform a grid-search over two criterion, namely, gini and entropy and depths ranging from 3\u201320, and select the best performing tree based on the validation set. However, to keep the rules concise, we limit the tree max-depth to 10 and as find that balances the model performance while keeping the number of rules we derive from the trees also concise. We use the standard train/dev/test splits as provided\n20https://ltrc.iiit.ac.in/showfile.php? filename=downloads/kolhi/\n21Hindi and Marathi both belong to the same IndoAryan language family and share vocabulary, grammar and even script. Although Kannada belongs to the Dravidian language family, it is still related to Hindi via Sanskrit on which all (Hindi, Marathi and Kannada) are based on.\nwith the original treebanks and report all results in Table 5 The running time of the model is approximately 2-5 mins.\nAfter learning a decision tree, we extract rules from each leaf. However, given that there could be spurious correlations that led to a leaf, simply using the majority label of a leaf as the grammar rule would be incorrect. Therefore, we apply a statistical threshold, as outlined in (Chaudhary et al., 2022) to re-label each leaf. We design two hypothesis, a null hypothesis H0 and a hypothesis to be tested H1, upon which we apply the the chi-squared goodness of fit test where we compute the expected probability distribution for H0 considering a uniform distribution. Below, we define the H0 and H1 for the grammar aspects:\nMorphological Agreement : The task is formulated as \u2013 given a head (e.g. a verb) and dependent (e.g. a noun) in a syntactic relation, when is the agreement for a morphological attribute (e.g. gender) required. This is formulated as a binary classification task, where label is 1 if the values of the head and dependent for the morphological attribute match (e.g. gender = feminine) and 0 otherwise. To extract rules for agreement, we consider those leaves where the majority label is 1. However, simply relying on the majority label could be misleading, as it might be an artifact of any spurious correlations in the training data, we apply the statistical threshold to filter such leaves. Particularly, the null hypothesis H0 states that each leaf denotes chance-agreement i.e. any observed agreement, say for gender between the dependent and its head, is not required rather is purely an artifact of the dataset, while H1 states that the leaf being considered denotes required-agreement. If the observed example distribution under a leaf is deemed to be statistically significant when compared to an expected empirical distribution (computed over the training data), we can reject H0 and accept H1.\nWord Order The task is formulated as \u2013 given a head (e.g. verb) and its dependent (e.g. subject nouns), when is the head before or after its dependent. Similar to above, we design H0 as both the labels i.e. before and after are equally likely, and H1 that the leaf takes the label dominant under that leaf. Leaves that pass the statistical threshold are assigned the dominant label and syntactic/lexical/morphological features that lead up to the leaf form the rule.\nFor extracting rules for suffix usage and word usage, we follow Chaudhary et al. (2021) and use a SVM classifier. The respective tasks are formulated as follows:\nSuffix Usage The task is formulated as \u2013 given a suffix (e.g. -laa) determine the conditions under which this suffix is observed.\nWord Usage The task is formulated as \u2013 given different target language word translations (e.g. \u2018bhaat\u2019 vs \u2018tandul\u2019 for rice) , determine the conditions under which a particular translation is used.\nBoth these tasks are formulated as multi-class classification tasks, and since Chaudhary et al. (2021) find SVMs to outperform decision trees, we follow their same setup. Specifically, we use the LinearSVM model from sklearn (Fabian, 2011) and perform a grid search over the hyperparameters: C = [0.001, 0.01], class weight =[\u2019balanced\u2019, None]. We select top-20 features for each word to extract the rules. Furthermore, all rules are formatted using human-readable templates, as shown in Table 2 of Chaudhary et al. (2021).\nA.3 Perception Survey In Table 3 we present the questions posed to the teachers for assessing the extracted learning material. Consent of all subjects was collected before the study, questions regarding personal information such as name, age, gender, were made optional and all results have been aggregated and presented without revealing individual details."
        }
    ],
    "title": "Teacher Perception of Automatically Extracted Grammar Concepts for L2 Language Learning",
    "year": 2023
}