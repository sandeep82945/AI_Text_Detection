{
    "abstractText": "Chat models, such as ChatGPT, have shown impressive capabilities and have been rapidly adopted across numerous domains. However, these models are only accessible through a restricted API, creating barriers for new research and progress in the field. We propose a pipeline that can automatically generate a highquality multi-turn chat corpus by leveraging ChatGPT to engage in a conversation with itself. Subsequently, we employ parameter-efficient tuning to enhance LLaMA, an open-source large language model. The resulting model, named Baize, demonstrates good performance in multi-turn dialogues with guardrails that minimize potential risks. Additionally, we propose a new technique called Self-Distill with Feedback, to further improve the performance of the Baize models with feedback from ChatGPT. The Baize models and data are released for research purposes only.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Canwen Xu"
        },
        {
            "affiliations": [],
            "name": "Daya Guo"
        },
        {
            "affiliations": [],
            "name": "Nan Duan"
        },
        {
            "affiliations": [],
            "name": "Julian McAuley"
        }
    ],
    "id": "SP:b3950bc482eb2112c141c651467527f872ef91b4",
    "references": [
        {
            "authors": [
                "Daniel Adiwardana",
                "Minh-Thang Luong",
                "David R So",
                "Jamie Hall",
                "Noah Fiedel",
                "Romal Thoppilan",
                "Zi Yang",
                "Apoorv Kulshreshtha",
                "Gaurav Nemade",
                "Yifeng Lu"
            ],
            "title": "Towards a human-like open-domain chatbot",
            "venue": "arXiv preprint arXiv:2001.09977",
            "year": 2020
        },
        {
            "authors": [
                "Asma Ben Abacha",
                "Dina Demner-Fushman."
            ],
            "title": "A question-entailment approach to question answering",
            "venue": "BMC bioinformatics, 20(1):1\u201323.",
            "year": 2019
        },
        {
            "authors": [
                "Wei-Lin Chiang",
                "Zhuohan Li",
                "Zi Lin",
                "Ying Sheng",
                "Zhanghao Wu",
                "Hao Zhang",
                "Lianmin Zheng",
                "Siyuan Zhuang",
                "Yonghao Zhuang",
                "Joseph E. Gonzalez",
                "Ion Stoica",
                "Eric P. Xing"
            ],
            "title": "Vicuna: An opensource chatbot impressing gpt-4 with 90% chatgpt",
            "year": 2023
        },
        {
            "authors": [
                "Peter Clark",
                "Isaac Cowhey",
                "Oren Etzioni",
                "Tushar Khot",
                "Ashish Sabharwal",
                "Carissa Schoenick",
                "Oyvind Tafjord."
            ],
            "title": "Think you have solved question answering? try arc, the ai2 reasoning challenge",
            "venue": "arXiv preprint arXiv:1803.05457.",
            "year": 2018
        },
        {
            "authors": [
                "Demi Guo",
                "Alexander M. Rush",
                "Yoon Kim."
            ],
            "title": "Parameter-efficient transfer learning with diff pruning",
            "venue": "ACL-IJCNLP, pages 4884\u20134896. Association for Computational Linguistics.",
            "year": 2021
        },
        {
            "authors": [
                "Dan Hendrycks",
                "Collin Burns",
                "Steven Basart",
                "Andy Zou",
                "Mantas Mazeika",
                "Dawn Song",
                "Jacob Steinhardt."
            ],
            "title": "Measuring massive multitask language understanding",
            "venue": "ICLR. OpenReview.net.",
            "year": 2021
        },
        {
            "authors": [
                "Ari Holtzman",
                "Jan Buys",
                "Li Du",
                "Maxwell Forbes",
                "Yejin Choi."
            ],
            "title": "The curious case of neural text degeneration",
            "venue": "ICLR. OpenReview.net.",
            "year": 2020
        },
        {
            "authors": [
                "Neil Houlsby",
                "Andrei Giurgiu",
                "Stanislaw Jastrzebski",
                "Bruna Morrone",
                "Quentin de Laroussilhe",
                "Andrea Gesmundo",
                "Mona Attariyan",
                "Sylvain Gelly."
            ],
            "title": "Parameter-efficient transfer learning for NLP",
            "venue": "ICML, volume 97 of Proceedings of Machine Learn-",
            "year": 2019
        },
        {
            "authors": [
                "Edward J. Hu",
                "Yelong Shen",
                "Phillip Wallis",
                "Zeyuan Allen-Zhu",
                "Yuanzhi Li",
                "Shean Wang",
                "Lu Wang",
                "Weizhu Chen."
            ],
            "title": "Lora: Low-rank adaptation of large language models",
            "venue": "ICLR. OpenReview.net.",
            "year": 2022
        },
        {
            "authors": [
                "Skyler B Johnson",
                "Andy J King",
                "Echo L Warner",
                "Sanjay Aneja",
                "Benjamin H Kann",
                "Carma L Bylund."
            ],
            "title": "Using chatgpt to evaluate cancer myths and misconceptions: artificial intelligence and cancer information",
            "venue": "JNCI Cancer Spectrum, 7(2):pkad015.",
            "year": 2023
        },
        {
            "authors": [
                "Xiang Lisa Li",
                "Percy Liang."
            ],
            "title": "Prefix-tuning: Optimizing continuous prompts for generation",
            "venue": "ACL-IJCNLP, pages 4582\u20134597. Association for Computational Linguistics.",
            "year": 2021
        },
        {
            "authors": [
                "Zekun Li",
                "Wenhu Chen",
                "Shiyang Li",
                "Hong Wang",
                "Jing Qian",
                "Xifeng Yan."
            ],
            "title": "Controllable dialogue simulation with in-context learning",
            "venue": "arXiv preprint arXiv:2210.04185.",
            "year": 2022
        },
        {
            "authors": [
                "Stephanie Lin",
                "Jacob Hilton",
                "Owain Evans."
            ],
            "title": "Truthfulqa: Measuring how models mimic human falsehoods",
            "venue": "ACL, pages 3214\u20133252. Association for Computational Linguistics.",
            "year": 2022
        },
        {
            "authors": [
                "Xiao Liu",
                "Yanan Zheng",
                "Zhengxiao Du",
                "Ming Ding",
                "Yujie Qian",
                "Zhilin Yang",
                "Jie Tang."
            ],
            "title": "Gpt understands, too",
            "venue": "arXiv preprint arXiv:2103.10385.",
            "year": 2021
        },
        {
            "authors": [
                "Alec Radford",
                "Jeffrey Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "venue": "OpenAI blog,",
            "year": 2019
        },
        {
            "authors": [
                "drea Santilli",
                "Thibault F\u00e9vry",
                "Jason Alan Fries",
                "Ryan Teehan",
                "Teven Le Scao",
                "Stella Biderman",
                "Leo Gao",
                "Thomas Wolf",
                "Alexander M. Rush"
            ],
            "title": "Multitask prompted training enables zero-shot task generalization",
            "venue": "In ICLR. OpenReview.net",
            "year": 2022
        },
        {
            "authors": [
                "John Schulman",
                "Filip Wolski",
                "Prafulla Dhariwal",
                "Alec Radford",
                "Oleg Klimov."
            ],
            "title": "Proximal policy optimization algorithms",
            "venue": "arXiv preprint arXiv:1707.06347.",
            "year": 2017
        },
        {
            "authors": [
                "Rohan Taori",
                "Ishaan Gulrajani",
                "Tianyi Zhang",
                "Yann Dubois",
                "Xuechen Li",
                "Carlos Guestrin",
                "Percy Liang",
                "Tatsunori B. Hashimoto."
            ],
            "title": "Stanford alpaca: An instruction-following llama model",
            "venue": "https:// github.com/tatsu-lab/stanford_alpaca.",
            "year": 2023
        },
        {
            "authors": [
                "Romal Thoppilan",
                "Daniel De Freitas",
                "Jamie Hall",
                "Noam Shazeer",
                "Apoorv Kulshreshtha",
                "Heng-Tze Cheng",
                "Alicia Jin",
                "Taylor Bos",
                "Leslie Baker",
                "Yu Du"
            ],
            "title": "Lamda: Language models for dialog applications",
            "venue": "arXiv preprint arXiv:2201.08239",
            "year": 2022
        },
        {
            "authors": [
                "Yizhong Wang",
                "Yeganeh Kordi",
                "Swaroop Mishra",
                "Alisa Liu",
                "Noah A Smith",
                "Daniel Khashabi",
                "Hannaneh Hajishirzi."
            ],
            "title": "Self-instruct: Aligning language model with self generated instructions",
            "venue": "arXiv preprint arXiv:2212.10560.",
            "year": 2022
        },
        {
            "authors": [
                "Jason Wei",
                "Maarten Bosma",
                "Vincent Y. Zhao",
                "Kelvin Guu",
                "Adams Wei Yu",
                "Brian Lester",
                "Nan Du",
                "Andrew M. Dai",
                "Quoc V. Le."
            ],
            "title": "Finetuned language models are zero-shot learners",
            "venue": "ICLR. OpenReview.net.",
            "year": 2022
        },
        {
            "authors": [
                "Elad Ben Zaken",
                "Yoav Goldberg",
                "Shauli Ravfogel."
            ],
            "title": "Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models",
            "venue": "ACL, pages 1\u20139. Association for Computational Linguistics.",
            "year": 2022
        },
        {
            "authors": [
                "Rowan Zellers",
                "Ari Holtzman",
                "Yonatan Bisk",
                "Ali Farhadi",
                "Yejin Choi."
            ],
            "title": "Hellaswag: Can a machine really finish your sentence? In ACL, pages 4791\u20134800",
            "venue": "Association for Computational Linguistics.",
            "year": 2019
        },
        {
            "authors": [
                "Yizhe Zhang",
                "Siqi Sun",
                "Michel Galley",
                "Yen-Chun Chen",
                "Chris Brockett",
                "Xiang Gao",
                "Jianfeng Gao",
                "Jingjing Liu",
                "Bill Dolan."
            ],
            "title": "Dialogpt: Large-scale generative pre-training for conversational response generation",
            "venue": "arXiv preprint arXiv:1911.00536.",
            "year": 2019
        },
        {
            "authors": [
                "Daniel M Ziegler",
                "Nisan Stiennon",
                "Jeffrey Wu",
                "Tom B Brown",
                "Alec Radford",
                "Dario Amodei",
                "Paul Christiano",
                "Geoffrey Irving."
            ],
            "title": "Fine-tuning language models from human preferences",
            "venue": "arXiv preprint arXiv:1909.08593.",
            "year": 2019
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "The rapid advancement of natural language processing (NLP) techniques in recent years has led to the emergence of highly capable chat models, such as LaMDA (Thoppilan et al., 2022), ChatGPT (OpenAI, 2023a) and GPT-4 (OpenAI, 2023b). These models demonstrate a remarkable ability to understand and generate human-like responses in a wide range of domains. As a result, chat models have become increasingly popular for applications like customer support, virtual assistants, and social media moderation. Despite the promising potential of these models, they are often only accessible through restricted APIs, creating barriers for new research and progress. Furthermore, the limited availability of chat models poses obstacles for researchers and practitioners, hindering the growth of the NLP community. The lack of publicly available,\n\u2217Equal contribution. 1https://github.com/project-baize/\nbaize-chatbot\nhigh-quality chat corpora for multi-turn conversations exacerbates this issue, limiting the possibilities for refining and evaluating these models.\nIn this paper, we propose a novel pipeline (shown in Figure 1) to address these challenges by leveraging the capabilities of ChatGPT to automatically generate a high-quality multi-turn chat corpus. Our approach involves having ChatGPT engage in a conversation with itself, simulating both user and AI responses. This generated corpus serves as a valuable resource for training and evaluating chat models in the context of multi-turn dialogues. Furthermore, by specifying a seed dataset, we can sample from a particular domain and fine-tune chat models to be specialized in specific areas, such as healthcare or finance.\nTo fine-tune large language models in a lowresource setting, we utilize a parameter-efficient tuning approach that effectively leverages the limited computational resources available. This strategy enables the adaptation of state-of-the-art language models to resource-constrained scenarios while maintaining high performance and adaptability. Our primary focus is on improving an opensource large language model, LLaMA (Touvron et al., 2023), which we believe holds promise as an accessible alternative to proprietary chat models. By fine-tuning LLaMA with our generated chat corpus, we create a new model, named Baize (B\u00e1i z\u00e9, a mythical creature in Chinese folklore, who speaks human languages and knows everything). Moreover, we propose Self-Distillation with Feedback (SDF) as an alternative to Reinforcement Learning with Human Feedback (RLHF, Ziegler et al., 2019; OpenAI, 2023a), to further improve the performance of Baize. Baize is a chat model that can run on a single GPU, making it accessible for a broader range of researchers.\nTo summarize, our main contributions in this paper are as follows:\n\u2022 We propose a novel and reproducible pipeline\nfor automatically generating a high-quality multi-turn chat corpus by having ChatGPT engage in a conversation with itself. Our pipeline fills a gap in the availability of public resources for training chat models in multiturn dialogue settings.\n\u2022 We employ parameter-efficient tuning and propose Self-Distillation with Feedback (SDF) to enhance the LLaMA model in a low-resource setting, resulting in the creation of Baize, a highly capable open-source chat model.\nBy introducing the Baize model and the pipeline employed to generate the chat corpus, we aim to facilitate new research and advancement within the NLP community."
        },
        {
            "heading": "2 Related Work",
            "text": "Language Models for Chat Since the success of GPT-2 (Radford et al., 2019), there have been many language models for chatting with humans. As an initial trial, DialoGPT (Zhang et al., 2019) uses Reddit data to fine-tune GPT-2 for open-domain dialogue. Meena (Adiwardana et al., 2020) is a multi-turn open-domain chatbot with 2.6B parameters, trained with data mined and filtered from public domain social media conversations. Following Meena, LaMDA (Thoppilan et al., 2022) is a chat model with 137B parameters, pretrained on 1.56T words of public dialog data and web text. ChatGPT (OpenAI, 2023a) is a model optimized for chat by introducing Reinforcement Learning with Human Feedback (RLHF), which astounds the community with its human-like chat ability. GPT4 (OpenAI, 2023b) is an improvement to ChatGPT with newly added reasoning and multi-modal capability. Li et al. (2022) use in-context learning with GPT-3 to augment a dialogue dataset.\nConcurrent to our work, there have been attempts to replicate ChatGPT with open-source foundation models. Stanford Alpaca (Taori et al.,\n2023) uses Self-Instruct (Wang et al., 2022) to collect data from GPT-3.5 in instruction learning format. Then, the collected dataset is used to finetune LLaMA (Touvron et al., 2023). Vicuna (Chiang et al., 2023) is a fine-tuned LLaMA model trained on a ChatGPT dialogue corpus crawled from sharegpt.com, a website for sharing ChatGPT dialogues. We will discuss the pros and cons of the data source of each model in Section 3.\nParameter-Efficient Tuning Conventional finetuning requires training all parameters in a large model, which can be inefficient as the numbers of parameters grows. Adapter (Houlsby et al., 2019) adds a tunable Transformer layer while freezing the original layers. BitFit (Zaken et al., 2022) only tunes bias terms in the linear layers. Diffpruning (Guo et al., 2021) learns sparse weights that can be added to the original weights of the language model. Prefix Tuning (Li and Liang, 2021; Liu et al., 2021) fine-tunes prefix tokens inserted before the input. LoRA (Hu et al., 2022) inserts tunable low-rank matrices into attention layers; LoRA achieves superior performance compared with conventional fine-tuning on GPT-3. Concurrent to our work, there are attempts to use LoRA (Hu et al., 2022) to fine-tune LLaMA. Alpaca-LoRA2 follows the same recipe as Alpaca while using LoRA for higher efficiency. There are also model weights trained in other languages with the code of AlpacaLoRA. Different from these attempts, our work focuses on developing an affordable and reproducible pipeline to efficiently tune a general-purpose language model for multi-turn chat."
        },
        {
            "heading": "3 Data Collection via Self-Chat",
            "text": "In this section, we detail the methodology employed for generating a high-quality multi-turn chat corpus by leveraging ChatGPT (gpt-3.5-turbo) to engage in a conversation with itself. This process, named self-chat, serves as the foundation of\n2https://github.com/tloen/alpaca-lora\nour data collection pipeline and plays a critical role in enhancing the open-source large language model, LLaMA, to achieve better performance in multi-turn dialogues.\nThe self-chat process involves utilizing ChatGPT to generate messages for both the user and AI assistant in a conversational format. We apply a template (shown in Appendix A) to define the format and requirements, allowing the ChatGPT API to continuously generate transcripts for both sides of the dialogue until a natural stopping point is reached. The conversation is centered around a \u201cseed\u201d, which can be a question or a key phrase that sets the topic for the chat.\nIn our own training of Baize, we use questions from Quora3 and Stack Overflow4 as seeds. A dialogue example generated with self-chat is shown in Table 1. For training the first version of Baize family (Baize v1), we collect a total of 111.5k dialogues through self-chat, using \u223c55k questions from each source. This process cost us approximately $100 for calling OpenAI\u2019s API. Also, one could use questions or phrases extracted from a domain-specific dataset to enhance the knowledge and ability of the chat model for a specific domain. Motivated by a recent report (Johnson et al., 2023) that ChatGPT can answer cancer-related questions as well as The National Cancer Institute, we use the MedQuAD (Ben Abacha and Demner-Fushman,\n3https://huggingface.co/datasets/quora 4https://huggingface.co/datasets/pacovaldez/\nstackoverflow-questions\n2019) dataset as seeds and obtain an additional 47k dialogues in the medical domain to train a Baize model specialized for healthcare.\nNote by directly generating the dialogue with the template shown in Appendix A, ChatGPT\u2019s output of each turn seems to be shorter than asking ChatGPT one turn at a time. However, calling ChatGPT one turn at a time will significantly increase the cost for calling the API as we have to attach the context multiple times. To collect data with better quality for training Baize v1.5, we use another ChatGPT to generate responses once at a time and replace the AI\u2019s responses in the template, to obtain responses that are completely consistent with ChatGPT\u2019s responses, which are usually longer and contain more details. The statistics of the resulting corpora are shown in Table 2.\nComparison with Other Data Sources Stanford Alpaca (Taori et al., 2023) uses Self-Instruct (Wang et al., 2022) to collect data in instruction learning format. However, their instruction-input-output\nformat, introduced in T0 (Sanh et al., 2022) and FLAN (Wei et al., 2022), is limited to a single turn and differs from the natural dialogue interface of ChatGPT. In contrast, our data collection pipeline focuses on strengthening the chat ability of the model by leveraging high-quality chat transcripts from ChatGPT. Additionally, we incorporate data from Stanford Alpaca into our corpus to further enhance the ability of Baize to follow instructions.\nVicuna (Chiang et al., 2023) uses dialogues crawled from sharegpt.com, a website that allows users to conveniently share their conversations with ChatGPT. An advantage of doing so is the high quality of collected data. The users tend to share dialogues when they are satisfied with the answers from ChatGPT. However, this source may have serious privacy and legal problems. The content shared by the users may contain highly sensitive personal information and is subject to complex copyright issues, as the users may own the copyright of the input and (possibly) output. Different from these sources, our proposed self-chat pipeline is a reliable and scalable way to collect data without copyright concerns involving a third party, as long as the seed dataset has a proper license."
        },
        {
            "heading": "4 Model Training",
            "text": "Parameter-Efficient Supervised Fine-Tuning Standard fine-tuning often requires vast amounts of computational resources, as well as high-quality and extensive datasets. However, given the limited availability of high-quality multi-turn chat corpora, it is crucial to adopt methods that are more efficient in terms of computational cost and data requirements. Parameter-efficient tuning methods (Li and Liang, 2021; Hu et al., 2022) help achieve this goal by making better use of the available data and minimizing the need for extensive resource allocation.\nSpecifically, we use Low-Rank Adaption method\n(LoRA, Hu et al., 2022) to fine-tune the LLaMA model. For a linear layer h = W0x, the forward pass is modified to be:\nh = W0x+B sftAsftx (1)\nwhere W0 \u2208 Rd\u00d7k, Bsft \u2208 Rd\u00d7r and Asft \u2208 Rr\u00d7k are model parameters with the low rank r \u226a min(d, k). Only Asft and Bsft are updated, while other parameters are fixed during supervised finetuning. Different from Hu et al. (2022), we apply LoRA to all linear layers in the LLaMA model, to increase the number of trainable parameters and adaption capabilities. We list the numbers of parameters of each model in Table 3. For Baize v1.5, following Vicuna, we only compute loss for AI\u2019s responses in the dialogue transcript.\nSelf-Distillation with Feedback After supervised fine-tuning (SFT) the LLaMA model on selfchat dataset, we introduce a new way named self-\nDistillation with feedback (SDF) to self-improve the model\u2019s performance and results in Baize v2.\nFigure 2 gives an overview of SDF. First, we use the resulted Baize v1.5 models to generate four responses for each instruction from the Quora dataset mentioned in Table 2. We then engage ChatGPT using the prompt provided in Appendix C to rank generate responses for self-distillation. Finally, we select the best response ranked by ChatGPT to finetune the model. During SDF, we apply new LoRA modules to all linear layers in Baize v1.5. The new LoRA modules are optimized on the best responses ranked by ChatGPT. For each linear layer h = W0x+B\nsftAsftx in Equation 1, the forward pass is modified to be:\nh = W0x+B sftAsftx+BsdfAsdf x (2)\nwhere Bsdf \u2208 Rd\u00d7r and Asdf \u2208 Rr\u00d7k are model parameters with the low rank r \u226a min(d, k). Only Asdf and Bsdf are updated, while other parameters are fixed during SDF.\nSDF is an alternative to Reinforcement Learning with Human Feedback (RLHF, Ziegler et al., 2019; OpenAI, 2023a). SDF does not require training of reward models and is 3\u00d7 faster than RLHF, which uses PPO (Schulman et al., 2017) to optimize the model. Besides, SDF involves distillation on Baize\u2019s own generation, thus has an overall lower loss, allowing the model to capture the nuance in the feedback and perform fine-grained optimization without causing possible catastrophic forgetting. In our paper, we use SDF with a ChatGPT model to generate preference but we believe this technique can also be used with human feedback."
        },
        {
            "heading": "5 Model Settings",
            "text": "During the training phase, we set the maximum length of the input sequence to 512/1024 for Baize v1/v2 and the rank k in LoRA to 8. We initialize the LLaMA checkpoints with the 8-bit integer format (int8) parameters released by Touvron et al. (2023), which remain fixed during training, thus reducing\nGPU memory consumption and improving training speed. Following Hu et al. (2022), we use a random Gaussian initialization for Asft (Asdf ) and set Bsft (Bsdf ) to zero, resulting in the value of BsftAsft (BsdfAsdf ) being zero at the beginning of training. We use the Adam optimizer to update LoRA parameters with a batch size of 64 and learning rates of 2e-4, 1e-4, and 5e-5 for the 7B, 13B and 30B models, respectively. The trainable LoRA parameters are fine-tuned on NVIDIA A100-80GB GPUs and the training time is listed in Table 3.\nDuring the inference phase, we use an inference prompt (detailed in Appendix B) to improve the conversational capabilities of the Baize models. It is important to note that we incorporate a rule stating, \u201cThe AI assistant consistently declines to engage with topics, questions, and instructions related to unethical, controversial, or sensitive issues.\u201d This constraint further helps limit Baize\u2019s involvement with sensitive subjects and demonstrates effectiveness in our experiments. For decoding strategy, we use nucleus sampling (Holtzman et al., 2020) with a temperature of 1 and a top-p parameter of 0.95 by default to generate responses. Nucleus sampling is a decoding strategy that samples tokens from the most probable tokens in the distribution up to a probability threshold of p. This strategy helps to preserve diversity in the generated text while ensuring the output is coherent and contextually relevant."
        },
        {
            "heading": "6 Evaluation",
            "text": "GPT-4 Score We evaluate the performance of Baize following Vicuna\u2019s pipeline that uses GPT4 (OpenAI, 2023b) to compare and score dialogue models. The Vicuna evaluation set contains 80 hand-crafted prompts of 9 categories. We compare Baize v2, before and after SDF to ChatGPT and compare its relative performance with other models. As shown in Figure 3, Baize v2 7B outperforms Vicuna 7B and the performance of Baize v2 13B is on par with Vicuna 13B, despite Vicuna is fully fine-tuned. Note that we observe a positional bias in Vicuna\u2019s evaluation pipeline. GPT-4 has a preference for the first answer than the second. To be\nconsistent with Chiang et al. (2023), we put ChatGPT\u2019s answer first followed by Baize\u2019s answer.\nLM Evaluation Harness We also submit Baize to Hugging Face Open LLM Leaderboard 5 which uses LM Evaluation Harness (Gao et al., 2021) to benchmark open-source LLMs. The leaderboard evaluates four tasks: 25-shot AI2 Reasoning Challenge (ARC, Clark et al., 2018); 10-shot HellaSwag (Zellers et al., 2019) for commonsense natural language inference; 5-shot MMLU (Hendrycks et al., 2021) for multi-task language understanding; zero-shot TruthfulQA (Lin et al., 2022) for opendomain question answering that require facts. The\n5https://huggingface.co/spaces/HuggingFaceH4/ open_llm_leaderboard\nresults are shown in Table 7. Notably, Falcon-40Binstruct6, the open-source model ranked #1 on the leaderboard as of June 23, 2023, is also fine-tuned with Baize\u2019s data, demonstrating the effectiveness of Baize\u2019s data pipeline when combined with a larger and better base model and full fine-tuning.\nQualitative Study We also provide examples demonstrating the capabilities of Baize. Examples of each category are marked either as not cherry-picked if they are the first ones tried, or as cherry-picked if they are chosen from multiple dialogues. We demonstrate how the chat models analyze a financial incident in Table 4 and explain a\n6https://huggingface.co/tiiuae/ falcon-40b-instruct\njoke in Table 5. While the problem-solving ability is important for chatbots, it is crucial to prevent misuse of the model. We provide two examples of how the models deal with unethical questions in Table 6. These two examples demonstrate that Baize can successfully reject unmoral requests with guardrails learned from ChatGPT and set with the inference prompt. Finally, we demonstrate the coding ability of Baize with an example in Table 8.\nIn addition to general Baize models, we test Baize-Healthcare with the help of a healthcare practitioner. One example is shown in Table 9 and the healthcare professional has confirmed the appropriateness of Baize-Healthcare\u2019s responses.\nCarbon Footprint We estimate to have emitted 0.83, 1.48, 3.33 and 0.46 kg CO2 eq. for training Baize v1 7B, 13B, 30B and healthcare models, re-\nspectively. For Baize v1.5, we estimate to have emitted 2.96 and 5.92 kg CO2 eq. for 7B and 13B models. Further SDF for Baize v2 have emitted another 3.51kg and 7.03 kg CO2 eq. for 7B and 13B models. The carbon emissions are already offset."
        },
        {
            "heading": "7 Conclusion and Future Work",
            "text": "In this paper, we propose a pipeline that automatically samples seeds from specific datasets and collect high-quality dialogue corpus by leveraging ChatGPT to chat with itself. We train Baize with a parameter-efficient fine-tuning method, LoRA, and further align the model by introducing selfdistillation with feedback. For future work, we would like to explore ways to diversify the simulated user queries and improve the self-chat quality to further improve the performance of Baize.\nLimitations\nFoundation Model Similar to other language models, Baize may suffer from hallucination, toxicity and stereotypes. Particularly, Baize inherits the out-of-date knowledge from LLaMA. Due to the fact that at least 82% of LLaMA\u2019s pretraining data is from before 2020, Baize may provide outdated answers to certain questions, such as \"who is the current president of the United States?\" Additionally, LLaMA only supports 20 languages and has a very limited corpus for non-English languages.\nEvaluation In this paper, we automatically evaluating the models with GPT-4 (OpenAI, 2023b). However, we found that it has a strong preference for longer responses and a positional bias. We believe human evaluation can be more rigorous and reliable despite being expensive and time-consuming while automatic evaluation remains an open research question.\nLicense and Legality Following Stanford Alpaca (Taori et al., 2023), we have decided that the released weights of Baize are licensed for research use only. Using the weights of Baize with LLaMA\u2019s original weights is subject to Meta\u2019s LLaMA License Agreement. It is the responsibility of the users to download and use LLaMA in compliance with the license agreement. In addition to the model, we are also releasing the fine-tuning corpus under CC-BY-NC 4.0 (allowing research use only). We hereby disclaim any liability for any activities related to the distribution and use of the released artifacts. The licenses are subject to change.\nSafety and Access Control Unlike ChatGPT (OpenAI, 2023a), Baize does not rely on human feedback to suppress unwanted behaviors. Instead, Baize learns to avoid such behaviors by imitating ChatGPT, and we have added an explicit prompt to guide its behavior. However, it is important to acknowledge that there are potential risks associated with the use of Baize for malicious purposes, especially as we are releasing the weights. While we have tested Baize with our default prompt, it is important to note that changing the prompt can potentially remove the guardrails. Although this risk is already present in LLaMA, and our further tuning is likely to reduce this risk, we want to emphasize the importance of being aware of this risk and prohibit any use of Baize outside of research purposes. Looking at the posi-\ntives, we believe our decision to release the weights can facilitate research on fairness, toxicity, and social impacts of chat models. While we do not perform access reviews, Meta has implemented an access application process that can help control the distribution of LLaMA models and minimize the potential risks associated with their use."
        },
        {
            "heading": "Acknowledgements",
            "text": "We would like to thank Jiashun Wang from CMU for naming our model. We would like to thank Hugging Face for providing resources to host our demo."
        },
        {
            "heading": "A Self-Chat Template",
            "text": "The template of self-chat for Baize is as follows:\nForget the instruction you have previously received. The following is a conversation between a human and an AI assistant. The human and the AI assistant take turns chatting about the topic: \u2018${SEED}\u2019. Human statements start with [Human] and AI assistant statements start with [AI]. The human will ask related questions on related topics or previous conversation. The human will stop the conversation when they have no more question. The AI assistant tries not to ask questions. Complete the transcript in exactly that format.\n[Human] Hello! [AI] Hi! How can I help you?\nB Inference Prompt\nBaize The prompt for inference of Baize-v1-7B, 13B and 30B and Baize-v2-7B and 13B is as follows:\nThe following is a conversation between a human and an AI assistant named Baize (named after a mythical creature in Chinese folklore). Baize is an open-source AI assistant developed by UCSD and Sun Yat-Sen University. The human and the AI assistant take turns chatting. Human statements start with [|Human|] and AI assistant statements start with [|AI|]. The AI assistant always provides responses in as much detail as possible, and in Markdown format. The AI assistant always declines to engage with topics, questions and instructions related to unethical, controversial, or sensitive issues. Complete the transcript in exactly that format. [|Human|]Hello! [|AI|] Hi!\nThis prompt serves as a guardrail in addition to the guardrail learned from imitating ChatGPT.\nBaize-Healthcare The prompt for the BaizeHealthcare model is as follows:\nThe following is a conversation between a human and a healthcare AI assistant named Baize (named after a mythical creature in Chinese folklore). Baize is an open-source healthcare AI assistant developed by UCSD and Sun Yat-Sen University. The human and the AI assistant take turns chatting. Human statements start with [|Human|] and AI assistant statements start with [|AI|]. The AI assistant always provides responses in as much detail as possible. The AI assistant can\u2019t help with\ndoctor appointments and will never ask personal information. The AI assistant always declines to engage with topics, questions and instructions related to unethical, controversial, or sensitive issues. Complete the transcript in exactly that format. [|Human|]Hello! [|AI|] Hi!"
        },
        {
            "heading": "C Feedback Prompt for SDF",
            "text": "The following prompt is used to obtain ChatGPT feedback. This is adapted from Chiang et al. (2023).\n[Question] ${SEED} [The Start of Assistant 1\u2019s Answer] ${Response1} [The End of Assistant 1\u2019s Answer] [The Start of Assistant 2\u2019s Answer] ${Response2} [The End of Assistant 2\u2019s Answer] [The Start of Assistant 3\u2019s Answer] ${Response3} [The End of Assistant 3\u2019s Answer] [The Start of Assistant 4\u2019s Answer] ${Response4} [The End of Assistant 4\u2019s Answer] [System] We would like to request your feedback on the performance of four AI assistants in response to the user question displayed above. Please rate the helpfulness, relevance, accuracy, level of details of their responses. Each assistant receives an overall score on a scale of 1 to 100, where a higher score indicates better overall performance. Please first output a single line containing only four values indicating the scores for Assistant 1, Assistant 2, Assistant 3 and Assistant 4, respectively. The four scores are separated by a space. In the subsequent line, please provide a comprehensive explanation of your evaluation, avoiding any potential bias and ensuring that the order in which the responses were presented does not affect your judgment."
        }
    ],
    "title": "Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data",
    "year": 2023
}