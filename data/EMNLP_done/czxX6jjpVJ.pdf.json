{
    "abstractText": "Shortcut reasoning is an irrational process of inference, which degrades the robustness of an NLP model. While a number of previous work has tackled the identification of shortcut reasoning, there are still two major limitations: (i) a method for quantifying the severity of the discovered shortcut reasoning is not provided; (ii) certain types of shortcut reasoning may be missed. To address these issues, we propose a novel method for identifying shortcut reasoning. The proposed method quantifies the severity of the shortcut reasoning by leveraging out-of-distribution data and does not make any assumptions about the type of tokens triggering the shortcut reasoning. Our experiments on Natural Language Inference and Sentiment Analysis demonstrate that our framework successfully discovers known and unknown shortcut reasoning in the previous work.1",
    "authors": [
        {
            "affiliations": [],
            "name": "Daichi Haraguchi"
        },
        {
            "affiliations": [],
            "name": "Kiyoaki Shirai"
        },
        {
            "affiliations": [],
            "name": "Naoya Inoue"
        },
        {
            "affiliations": [],
            "name": "Natthawut Kertkeidkachorn"
        }
    ],
    "id": "SP:f784ae71a1125e3f979229ed270f1e2f33125d90",
    "references": [
        {
            "authors": [
                "Francesco Barbieri",
                "Jose Camacho-Collados",
                "Luis Espinosa Anke",
                "Leonardo Neves."
            ],
            "title": "TweetEval: Unified benchmark and comparative evaluation for tweet classification",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages",
            "year": 2020
        },
        {
            "authors": [
                "Robert Geirhos",
                "J\u00f6rn-Henrik Jacobsen",
                "Claudio Michaelis",
                "Richard Zemel",
                "Wieland Brendel",
                "Matthias Bethge",
                "Felix A. Wichmann."
            ],
            "title": "Shortcut learning in deep neural networks",
            "venue": "Nature Machine Intelligence, page 665\u2013673.",
            "year": 2020
        },
        {
            "authors": [
                "Suchin Gururangan",
                "Swabha Swayamdipta",
                "Omer Levy",
                "Roy Schwartz",
                "Samuel Bowman",
                "Noah A. Smith."
            ],
            "title": "Annotation artifacts in natural language inference data",
            "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for",
            "year": 2018
        },
        {
            "authors": [
                "Xiaochuang Han",
                "Byron C. Wallace",
                "Yulia Tsvetkov."
            ],
            "title": "Explaining black box predictions and unveiling data artifacts through influence functions",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5553\u2013",
            "year": 2020
        },
        {
            "authors": [
                "Xanh Ho",
                "Johannes Mario Meissner",
                "Saku Sugawara",
                "Akiko Aizawa."
            ],
            "title": "A survey on measuring and mitigating reasoning shortcuts in machine reading comprehension",
            "venue": "Computing Research Repository, arXiv:2209.01824.",
            "year": 2022
        },
        {
            "authors": [
                "Nitish Joshi",
                "Xiang Pan",
                "He He."
            ],
            "title": "Are all spurious features in natural language alike? an analysis through a causal lens",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 9804\u20139817, Abu",
            "year": 2022
        },
        {
            "authors": [
                "Phillip Keung",
                "Yichao Lu",
                "Gy\u00f6rgy Szarvas",
                "Noah A. Smith."
            ],
            "title": "The multilingual Amazon reviews corpus",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4563\u20134568, Online. Association for",
            "year": 2020
        },
        {
            "authors": [
                "Pang Wei Koh",
                "Percy Liang."
            ],
            "title": "Understanding black-box predictions via influence functions",
            "venue": "Proceedings of the 34th International Conference on Machine Learning, page 1885\u20131894.",
            "year": 2017
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "Computing Research Repository,",
            "year": 2019
        },
        {
            "authors": [
                "Tom McCoy",
                "Ellie Pavlick",
                "Tal Linzen."
            ],
            "title": "Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3428\u20133448, Florence,",
            "year": 2019
        },
        {
            "authors": [
                "Yixin Nie",
                "Adina Williams",
                "Emily Dinan",
                "Mohit Bansal",
                "Jason Weston",
                "Douwe Kiela."
            ],
            "title": "Adversarial NLI: A new benchmark for natural language understanding",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
            "year": 2020
        },
        {
            "authors": [
                "Pouya Pezeshkpour",
                "Sarthak Jain",
                "Sameer Singh",
                "Byron Wallace."
            ],
            "title": "Combining feature and instance attribution to detect artifacts",
            "venue": "Findings of the Association for Computational Linguistics: ACL 2022, pages 1934\u20131946, Dublin, Ireland. Association",
            "year": 2022
        },
        {
            "authors": [
                "Adam Poliak",
                "Jason Naradowsky",
                "Aparajita Haldar",
                "Rachel Rudinger",
                "Benjamin Van Durme."
            ],
            "title": "Hypothesis only baselines in natural language inference",
            "venue": "Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics, pages",
            "year": 2018
        },
        {
            "authors": [
                "Marco Tulio Ribeiro",
                "Tongshuang Wu",
                "Carlos Guestrin",
                "Sameer Singh."
            ],
            "title": "Beyond accuracy: Behavioral testing of NLP models with CheckList",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4902\u2013",
            "year": 2020
        },
        {
            "authors": [
                "Viktor Schlegel",
                "Goran Nenadic",
                "Riza BatistaNavarro."
            ],
            "title": "Beyond leaderboards: A survey of methods for revealing weaknesses in natural language inference data and models",
            "venue": "Computing Research Repository, arXiv:2005.14709.",
            "year": 2020
        },
        {
            "authors": [
                "Mukund Sundararajan",
                "Ankur Taly",
                "Qiqi Yan."
            ],
            "title": "Axiomatic attribution for deep networks",
            "venue": "Proceedings of the 34th International Conference on Machine Learning, page 3319\u20133328.",
            "year": 2017
        },
        {
            "authors": [
                "Tianlu Wang",
                "Rohit Sridhar",
                "Diyi Yang",
                "Xuezhi Wang."
            ],
            "title": "Identifying and mitigating spurious correlations for improving robustness in NLP models",
            "venue": "Findings of the Association for Computational",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "While Transformer-based large language models have remarkably improved various NLP tasks, the issue of shortcut reasoning has been identified as a severe problem (Schlegel et al., 2020; Wang et al., 2022b; Ho et al., 2022). Shortcut reasoning usually refers to the irrational inference of a model, which is derived from spurious correlations in the training data (Gururangan et al., 2018; Poliak et al., 2018; McCoy et al., 2019). For example, sentiment analysis models could learn to classify any sentences containing the word Spielberg into POSITIVE, given a training dataset with many positive movie reviews containing Spielberg (e.g., Spielberg is a great director!).\nShortcut reasoning makes models brittle against Out of Distribution (OOD) data (i.e., data from a different distribution from the training data) compared to Independent and Identically Distributed\n1Our code is available at https://github.com/ homoscribens/shortcut_reasoning.git\n(IID) data (i.e., data from an identical distribution as the training data) (Geirhos et al., 2020). In the aforementioned example, the reasoning for movie reviews would not be valid for OOD data (e.g., news articles) because the sentiment of news articles containing Spielberg could be arbitrary.\nAlthough many studies have explored the detection of spurious correlations or shortcut reasoning (Ribeiro et al., 2020; Pezeshkpour et al., 2022; Han et al., 2020), several challenges persist. Wang et al. (2022a) propose a state-of-the-art method for discovering shortcut reasoning, which implements an automated framework to discover shortcuts without predefining shortcut templates. Still, their approach suffers from two major limitations.\nFirstly, their framework lacks a method for quantifying the severity of the discovered shortcut reasoning on OOD data. Even if the shortcuts are identified, we do not have to necessarily be concerned about them as long as they have little negative impact on the model\u2019s robustness. Secondly, their approach assumes that genuine tokens, useful tokens for predicting labels across different datasets (e.g., \u201cgood\u201d, \u201cbad\u201d), do not lead to shortcut reasoning. While this assumption seems reasonable, Joshi et al. (2022) argue that such tokens are still prevalent among spurious correlations. This is because such tokens are indeed necessary to predict the label, but these tokens alone may not provide sufficient information to accurately predict labels. For example, a genuine token \u201cgood\u201d in a sentence This movie is not good can be spurious, since \u201cgood\u201d is a necessary but insufficient token for determining its sentiment label. Therefore, genuine tokens can not be ignored when identifying shortcut reasoning.\nTo address these problems, we propose a new method for discovering shortcut reasoning. Our contributions can be summarized as follows:\n\u2022 We present an automated method for identifying shortcut reasoning.\n\u2022 By applying the less subjective definition of shortcut reasoning (Geirhos et al., 2020), our method does not require laborious human evaluation for detected shortcuts.\n\u2022 Our method quantifies the severity of shortcut reasoning by leveraging OOD data and does not make any assumptions about the type of tokens triggering the shortcut reasoning.\n\u2022 We demonstrate that our method successfully discovers previously unknown shortcut reasoning as well as ones reported in previous research."
        },
        {
            "heading": "2 Discovering Shortcut Reasoning",
            "text": "Fig. 1 shows the overall procedure of the proposed method. Given (i) a target model f , (ii) IID data DIID, and (iii) OOD data DOOD as inputs, shortcut reasoning is extracted as an output. The procedure consists of the following three steps.\nStep 1 extracts inference patterns, an abstract representation that characterizes the inferential process of a given model (\u00a72.1). To extract inference patterns, we use input reduction, an algorithm that automatically derives the inference patterns (\u00a72.2). Step 2 estimates the generality of the extracted inference patterns. Generality is a measure of the strength of an inference pattern, indicating its degree of regularity (\u00a72.3). Step 3 identifies shortcut reasoning. We automatically determine whether an inference pattern exhibits shortcut reasoning without human intervention, comparing the effectiveness of inference patterns in DIID with that in DOOD and leveraging the estimated generality as a proxy for the severity of the identified shortcut reasoning (\u00a72.4)."
        },
        {
            "heading": "2.1 Inference Pattern",
            "text": "An inference pattern is a crucial pattern that activates a label during a model\u2019s inference process. Given a target model f , we formally define an inference pattern p as follows:\np def = t f\u2192 l, (1)\nwhere t denotes a trigger that induces a certain label, and l is the induced label.\nPezeshkpour et al. (2022) classified spurious correlations into two types: (i) granular features, namely discrete units such as an individual token \u201cSpielberg\u201d, and (ii) abstract features, namely highlevel patterns such as lexical overlap.\nThis paper focuses on granular features and leaves the detection of shortcut reasoning with abstract features for future work. We thus adopt the following definition as an inference pattern:\np def = w f\u2192 l, (2)\nwhere w is a sequence of tokens [w1, w2, \u00b7 \u00b7 \u00b7 , wn]. Although we limit ourselves to granular features, this definition still enables us to detect shortcut reasoning with a variety of forms, such as combinations of tokens as well as a single token. For example, a sentiment analysis model f may have inference patterns such as [\u201cnot\u201d, \u201cbad\u201d]\u2192 NEUTRAL or [\u201cSpielberg\u201d] \u2192 POSITIVE (possibly shortcut reasoning)."
        },
        {
            "heading": "2.2 Extracting Inference Patterns",
            "text": "Given a target model f and an IID dataset DIID = {(xi, yi)}Ni=1, we extract a set C of inference patterns by applying input reduction (IR) to each input xi.\nIR gradually reduces the number of tokens in xi by masking each token one by one, incrementally increasing the number of masked tokens after each step. In each step, IR feeds the masked xi into f , and obtains a predicted label y\u0302i. IR stops when the predicted label y\u0302i flips. As the final step, IR extracts a sequence wi of unmasked tokens in xi and y\u0302i that is the last predicted label before the prediction flips as an inference pattern, namely wi f\u2192 y\u0302i.\nTo prioritize which tokens should be masked, we employ Integrated Gradient (Sundararajan et al., 2017), which computes the importance of each token for prediction. IR sorts the tokens in xi according to their IG score and then incrementally applies masks to the tokens in ascending order of their rank in the sorted sequence. For each mask applied, IR leaves the corresponding token masked and proceeds to the next token in the sequence.\nFig. 2 shows an example of the extracting process by IR. The tokens are replaced with [MASK] in the ascending order of the IG scores (values in orange in the figure). When the predicted label is flipped from NEGATIVE to POSITIVE, the remained tokens at the previous step and NEGATIVE label are extracted as the inference pattern [\u201cdon\u2019t\u201d, \u201clike\u201d] \u2192 NEGATIVE. See Appendix A for the pseudocode of IR.\nThe IR-based extraction algorithm ensures that the trigger wi of the extracted inference patterns is concise and not redundant."
        },
        {
            "heading": "2.3 Calculating Generality",
            "text": "In order to verify the validity of an inference pattern in C as a universal pattern, we assess its generality on DOOD. This measurement determines the degree to which the pattern exhibits regularity in the OOD dataset.\nTo estimate the generality of inference pattern\npi = wi \u2192 li \u2208 C, we collect a set EOOD(wi) of examples from DOOD such that the input contains wi. For example, given pi = [\u201cSpielberg\u201d] \u2192 POSITIVE, EOOD(wi) may contain sentences such as I grew up with Steven Spielberg\u2019s films. His films are always great!! and Spielberg is overrated. We then estimate the generality g of the inference pattern pi as follows:\ng(pi) def =\n\u2211 x\u2032\u2208EOOD(wi) 1 [f(x \u2032) = li]\n|EOOD(wi)| \u00d7100. (3)\nIntuitively, g(pi) explains how much the inference pattern is dominant on the OOD dataset."
        },
        {
            "heading": "2.4 Identifying Shortcut Reasoning",
            "text": "In this section, we define shortcut reasoning and describe the method for its detection. According to Geirhos et al. (2020), shortcut reasoning satisfies both of the following conditions: (i) performs well on DIID, and (ii) underperforms on DOOD.\nWe apply these conditions to inference patterns. Given pi = wi \u2192 li extracted from DIID by IR, the condition (i) is satisfied when pi works well on DIID. In other words, when the model performs well on IID examples that contain wi (i.e., EIID(wi)). Thus, we evaluate the performance of each inference pattern using EIID(wi). Specifically, we define a new metric iid_acci, which computes\u2211\nx\u2208EIID(wi) 1 [f(x) = li \u2227 li = yi]\u2211 x\u2208EIID(wi) 1 [f(x) = li] \u00d7 100. (4)\nThis metric counts the right prediction for inputs that contain trigger (wi).\nThe condition (ii) is satisfied when pi does not deliver accurate results on DOOD, i.e., when the model operates poorly on OOD inputs that contain wi (i.e., EOOD(wi)). As a metric to evaluate how much the pi underperforms over E(wi), we define \u2206 as follows:\n\u2206i def = F1(EOOD(wi), f)\u2212 F1(DOOD, f). (5)\nThis metric compares the F1 score on EOOD(wi) to that on DOOD, employed as a baseline for comparison.\nTo sum up, shortcut reasoning is defined as p\u0303i = wi \u2192 li such that g(pi) is sufficiently large, iid_acc is large enough and \u2206i is small enough. The set P\u0303 of shortcut reasoning is defined as\n{pi\u2208C | g(pi)>\u03bb1, iid_acci>\u03bb2,\u2206i<\u03bb3}. (6)\n\u03bb1, \u03bb2, and \u03bb3 are the pre-defined thresholds. Note that \u03bb2 and \u03bb3 have to be an above-chance score and less than 0 at least, respectively. This definition enables us to automatically identify shortcut reasoning that has a substantial impact on OOD, unlike previous studies (Pezeshkpour et al., 2022; Wang et al., 2022a)."
        },
        {
            "heading": "3 Experiments",
            "text": ""
        },
        {
            "heading": "3.1 Setup",
            "text": "One straightforward approach for assessing our method is to annotate NLP models with their ground-truth shortcut reasoning. However, recent NLP models are known to be hard to interpret, which makes it difficult to create such a reference dataset. We thus resort to existing datasets for Natural Language Inference (NLI) and Sentiment Analysis (SA) that have been shown to contain spurious features and check if our inference patterns can reveal such features (and unknown ones). Datasets For NLI, we adopt MNLI (Williams et al., 2018) as DIID and ANLI (Nie et al., 2020) as DOOD. ANLI is an NLI dataset based on MNLI, but adversarially redesigned, which makes it harder to answer. For SA, we apply Sentiment subset in Tweeteval (Barbieri et al., 2020) as DIID and MARC (Multilingual Amazon Reviews Corpus) (Keung et al., 2020) as DOOD. For all OOD datasets, we use training split of each. See Appendix B.1 for the dataset details. Note that all the datasets are trinary classifications, so the chance accuracy is 0.33. Models We apply our method to RoBERTa (Liu et al., 2019) fine-tuned with the DIID mentioned above, available at Hugging Face Hub. See Appendix B.2 for the details. Configuration The inference patterns of a model are obtained by learning training data. Thus, aside from test (or validation) sets, we extract C from the training set of DIID, expecting to better simulate the model\u2019s reasoning process. In addition, we randomly choose 1,000 examples as input to IR considering its runtime. We set hyperparameters \u03bb1 = 50, \u03bb2 = 70 and \u03bb3 = \u22120.05. To reliably obtain g(pi), we filter out pi with |EOOD(wi)| < 100 from C."
        },
        {
            "heading": "3.2 Results",
            "text": "We show samples of the results in Table 1. We selected representative p\u0303, which have large g, iid_acc, and |\u2206|. The column train/test denotes whether\nshortcut reasoning is discovered in the training or the test split of IID dataset (i.e., input for IR).\nNLI For OOD data, the model performed 77.8 of F1(DOOD, f). \u201c/s\u201d denotes a separation token between premise and hypothesis. For OOD data, the model performed 77.8 of F1(DOOD, f). We observed that most of t identified as shortcut reasoning belonged to the hypothesis, while only a small proportion was present in the premises. This observation suggests that the model heavily relies on the hypothesis to predict labels, corroborating the findings of Poliak et al. (2018). Furthermore, we found that negation representation in t, such as \u201cnot\u201d or \u201cnever\u201d, often led the model to predict CONTRADICTION. This phenomenon manifests itself even when the gold label indicates otherwise, as indicated by the values of \u2206 at the first and fourth p\u0303 in the Table 1. This finding aligns with the results reported by Gururangan et al. (2018). With this observed consistency with previous work, our method seems to be effective at accurately identifying shortcuts.\nSA The model showed 60.3 points at F1(DOOD, f). We found that sentiment words, such as \u201cworst\u201d or \u201cExcellent\u201d, emerged in almost all t that were classified as shortcut reasoning. Further analysis showed that reviews with neutral labels in MARC frequently contained both positive and negative sentiments (e.g., I hate the wrapping, but it works pretty well.). Considering a sufficient number of p with small \u2206 are annotated with neutral label for the original input, we estimate that the model relies on one among multiple sentiments in the input and ignores the rest. Therefore, it is possible to say that these inference patterns are shortcuts, whose t are necessary but insufficient.\nTrain/Test No significant difference was observed between the train and test experiments. Although the extracted shortcut reasoning from the experiments differed, they were essentially similar in terms of their characteristics (such as negations in NLI or sentiment words in SA).\nUnknown Shortcut Reasoning In the NLI experiment, it is interesting to note that we revealed several previously unknown shortcut reasoning, such as [\u201csoon\u201d]\u2192 NEUTRAL and [\u201cis\u201d, \u201calways\u201d] \u2192 NEUTRAL. Both have sufficiently small \u2206, and large iid_acc and g to be considered as p\u0303."
        },
        {
            "heading": "4 Related work",
            "text": "Numerous studies have tackled the problem of detecting spurious correlations or shortcut reasoning (Ribeiro et al., 2020; Han et al., 2020). One major limitation of earlier studies is that they predefine a specific format or structure for the shortcuts (e.g., a single token or a predefined set of tokens). This can hinder the discovery of new and unexplored shortcuts, which may be manifested in diverse forms.\nRecently, Pezeshkpour et al. (2022) address this problem by combining multiple interpretability techniques, such as influence function (Koh and Liang, 2017) and feature attribution methods (e.g., Integrated Gradient). However, they rely on human assessment to identify shortcut reasoning, which can result in misjudgment between rational and irrational reasoning. Besides, human evaluation is laborious and time-consuming.\nWang et al. (2022a) solve this issue by automatically identifying genuine tokens, important tokens that appear across different datasets, and spurious tokens, important tokens that appear only in an indomain dataset. Still, as discussed in \u00a71, there is a major limitation with their approach in that they fail to consider the influence of the identified shortcut reasoning on OOD data. Our work attempts to address this issue by estimating the generality of inference patterns. Besides, our definition of shortcut reasoning aligns well with more practical scenarios. While they rely on a subjective definition of shortcut reasoning (i.e., whether reasoning is irrational from humans\u2019 point of view), our work targets shortcut reasoning that performs well on IID but underperforms on OOD (Geirhos et al., 2020), namely the one that clearly hurts the robustness of NLP models by definition."
        },
        {
            "heading": "5 Conclusion",
            "text": "We introduced a method to automatically discover shortcut reasoning. With minimal predefinition, our method successfully identified known and previously unknown examples of shortcut reasoning. For future research, we plan to adapt our method to large language models and other tasks such as machine reading comprehension. Overall, we hope that our study provides a promising approach towards understanding the behavior of deep learning models and improving their trustworthiness."
        },
        {
            "heading": "6 Limitations",
            "text": "Firstly, we have yet to develop an evaluation process to validate the discovered shortcut reasoning. Even though we indicate the metrics or measurement of shortcut reasoning, knowing the actual reasoning process is impossible if we use black box models. Unfortunately, this problem would require significant effort to be solved.\nSecondly, as our method is not compatible with abstract inference patterns, it cannot cover all kinds of shortcut reasoning other than the granular one.\nThirdly, preparing two datasets, i.e., IID and OOD, is challenging for low-resource languages or some tasks. This problem limits the further studies or application of this method. Fortunately, now that we can access large language models that have surprising linguistic capabilities and are well-aligned with the user\u2019s instruction. The generated examples by LLMs have a certain distribution which can be treated as OOD for target models, or we can prompt them to generate examples with specific distribution.\nThe fourth limitation is about IR. If the prediction for the masked input does not flip during the\nreduction, then we alternatively output the last token left in the input. Therefore, in some cases, we cannot guarantee that the extracted inference pattern is genuine.\nFinally, input reduction can be utilized only when a MASK token is available on the input model."
        },
        {
            "heading": "A Details of Input Reduction",
            "text": "Algorithm 1 Pseudo-code of Input reduction 1: function INPUT_REDUCTION_IG(D) 2: for all (x, y) \u2208 D do 3: y\u0302 \u2190 f(x) ; x\u2032 \u2190 x ; y\u0302\u2032 \u2190 y\u0302 4: while y\u0302 = y\u0302\u2032 do 5: x\u2032prev \u2190 x\u2032 ; y\u0302\u2032prev \u2190 f(x\u2032prev) 6: x\u2032 \u2190 IG_mask(x\u2032) 7: y\u0302\u2032 \u2190 f(x\u2032) 8: if all tokens in x\u2032 are mask then 9: break\n10: end if 11: end while 12: C \u2190 C \u222a {p = (x\u2032prev, y\u0302\u2032prev)} 13: end for 14: return C 15: end function"
        },
        {
            "heading": "B Experimental setup",
            "text": "B.1 Dataset detail\nDataset train validation test\nNLI MNLI (matched) 392,702 9,815 9,796 ANLI (round3) 100,459 1,200 1,200\nSA Tweeteval (sentiment) 45,615 2,000 12,284 MARC (en) 200,000 5,000 5,000\nB.2 Models detail\nTask Model\nNLI roberta-large-mnli SA cardiffnlp/twitter-roberta-base-sentiment"
        }
    ],
    "title": "Discovering Highly Influential Shortcut Reasoning: An Automated Template-Free Approach",
    "year": 2023
}