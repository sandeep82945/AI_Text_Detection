{
    "abstractText": "Text simplification has emerged as an increasingly useful application of AI for bridging the communication gap in specialized fields such as medicine, where the lexicon is often dominated by technical jargon and complex constructs. Despite notable progress, methods in medical simplification sometimes result in the generated text having lower quality and diversity. In this work, we explore ways to further improve the readability of text simplification in the medical domain. We propose (1) a new unlikelihood loss that encourages generation of simpler terms and (2) a reranked beam search decoding method that optimizes for simplicity, which achieve better performance on readability metrics on three datasets. This study\u2019s findings offer promising avenues for improving text simplification in the medical field.",
    "authors": [
        {
            "affiliations": [],
            "name": "Lorenzo Flores"
        },
        {
            "affiliations": [],
            "name": "Heyuan Huang"
        },
        {
            "affiliations": [],
            "name": "Kejian Shi"
        },
        {
            "affiliations": [],
            "name": "Sophie Chheang"
        },
        {
            "affiliations": [],
            "name": "Arman Cohan"
        }
    ],
    "id": "SP:55277bad9d31b9c3cd48f812e841f37655ab2c06",
    "references": [
        {
            "authors": [
                "Emil Abrahamsson",
                "Timothy Forni",
                "Maria Skeppstedt",
                "Maria Kvist"
            ],
            "title": "Medical text simplification using synonym replacement: Adapting assessment",
            "year": 2014
        },
        {
            "authors": [
                "Griffin Adams",
                "Han-Chin Shing",
                "Qing Sun",
                "Christopher Winestock",
                "Kathleen McKeown",
                "No\u00e9mie Elhadad."
            ],
            "title": "Learning to revise references for faithful summarization",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022,",
            "year": 2022
        },
        {
            "authors": [
                "Fernando Alva-Manchego",
                "Louis Martin",
                "Carolina Scarton",
                "Lucia Specia."
            ],
            "title": "EASSE: Easier automatic sentence simplification evaluation",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th Inter-",
            "year": 2019
        },
        {
            "authors": [
                "Tal August",
                "Lucy Lu Wang",
                "Jonathan Bragg",
                "Marti A. Hearst",
                "Andrew Head",
                "Kyle Lo."
            ],
            "title": "Paper plain: Making medical research papers approachable to healthcare consumers with natural language processing",
            "venue": "ACM Transactions on Computer-Human",
            "year": 2022
        },
        {
            "authors": [
                "Chandrayee Basu",
                "Rosni Vasu",
                "Michihiro Yasunaga",
                "Qiang Yang."
            ],
            "title": "Med-easi: Finely annotated dataset and models for controllable simplification of medical texts",
            "venue": "ArXiv, abs/2302.09155.",
            "year": 2023
        },
        {
            "authors": [
                "Olivier Bodenreider."
            ],
            "title": "The unified medical language system (umls): Integrating biomedical terminology",
            "venue": "Nucleic acids research, 32:D267\u201370.",
            "year": 2004
        },
        {
            "authors": [
                "Yixin Cao",
                "Ruihao Shui",
                "Liangming Pan",
                "Min-Yen Kan",
                "Zhiyuan Liu",
                "Tat-Seng Chua."
            ],
            "title": "Expertise style transfer: A new task towards better communication between experts and laymen",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for",
            "year": 2020
        },
        {
            "authors": [
                "R\u00e9mi Cardon",
                "Natalia Grabar."
            ],
            "title": "Parallel sentence retrieval from comparable corpora for biomedical text simplification",
            "venue": "Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019), pages 168\u2013177,",
            "year": 2019
        },
        {
            "authors": [
                "R\u00e9mi Cardon",
                "Natalia Grabar."
            ],
            "title": "French biomedical text simplification: When small and precise helps",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 710\u2013716, Barcelona, Spain (Online). International Committee",
            "year": 2020
        },
        {
            "authors": [
                "John Carroll",
                "Guido Minnen",
                "Yvonne Canning",
                "Siobhan Devlin",
                "John Tait"
            ],
            "title": "Practical simplification of english newspaper text to assist aphasic readers",
            "year": 1998
        },
        {
            "authors": [
                "Ashwin Devaraj",
                "Iain Marshall",
                "Byron Wallace",
                "Junyi Jessy Li."
            ],
            "title": "Paragraph-level simplification of medical texts",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human",
            "year": 2021
        },
        {
            "authors": [
                "Joseph L. Fleiss."
            ],
            "title": "Measuring nominal scale agreement among many raters",
            "venue": "Psychological Bulletin, 76:378\u2013382.",
            "year": 1971
        },
        {
            "authors": [
                "Tanya Goyal",
                "Junyi Jessy Li",
                "Greg Durrett"
            ],
            "title": "News summarization and evaluation in the era of gpt-3",
            "year": 2023
        },
        {
            "authors": [
                "Gintar\u0117 Grigonyte",
                "Maria Kvist",
                "Sumithra Velupillai",
                "Mats Wir\u00e9n."
            ],
            "title": "Improving readability of Swedish electronic health records through lexical simplification: First results",
            "venue": "Proceedings of the 3rd Workshop on Predicting and Improving Text",
            "year": 2014
        },
        {
            "authors": [
                "James Hargreaves",
                "Andreas Vlachos",
                "Guy Emerson."
            ],
            "title": "Incremental beam manipulation for natural language generation",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages",
            "year": 2021
        },
        {
            "authors": [
                "Matthew Honnibal",
                "Ines Montani."
            ],
            "title": "spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing",
            "venue": "To appear.",
            "year": 2017
        },
        {
            "authors": [
                "Mengting Hu",
                "Yinhao Bai",
                "Yike Wu",
                "Zhen Zhang",
                "Liqi Zhang",
                "Hang Gao",
                "Shiwan Zhao",
                "Minlie Huang"
            ],
            "title": "Uncertainty-aware unlikelihood learning improves generative aspect sentiment quad prediction",
            "year": 2023
        },
        {
            "authors": [
                "Sebastian Joseph",
                "Kathryn Kazanas",
                "Keziah Reina",
                "Vishnesh J. Ramanathan",
                "Wei Xu",
                "Byron C. Wallace",
                "Junyi Jessy Li"
            ],
            "title": "Multilingual simplification of medical texts",
            "year": 2023
        },
        {
            "authors": [
                "Sebastian Valiaparampil Joseph",
                "Kathryn Kazanas",
                "Keziah Reina",
                "Vishnesh J. Ramanathan",
                "Wei Xu",
                "Byron Wallace",
                "Junyi Jessy Li."
            ],
            "title": "Multilingual simplification of medical texts",
            "venue": "ArXiv, abs/2305.12532.",
            "year": 2023
        },
        {
            "authors": [
                "J. Peter Kincaid",
                "Robert P. Fishburne",
                "Richard L. Rogers",
                "Brad S. Chissom"
            ],
            "title": "Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel",
            "year": 1975
        },
        {
            "authors": [
                "Reno Kriz",
                "Jo\u00e3o Sedoc",
                "Marianna Apidianaki",
                "Carolina Zheng",
                "Gaurav Kumar",
                "Eleni Miltsakaki",
                "Chris Callison-Burch."
            ],
            "title": "Complexity-weighted loss and diverse reranking for sentence simplification",
            "venue": "Proceedings of the 2019 Conference of the North",
            "year": 2019
        },
        {
            "authors": [
                "Philippe Laban",
                "Jesse Vig",
                "Wojciech Kryscinski",
                "Shafiq R. Joty",
                "Caiming Xiong",
                "Chien-Sheng Wu."
            ],
            "title": "Swipe: A dataset for document-level simplification of wikipedia pages",
            "venue": "ArXiv, abs/2305.19204.",
            "year": 2023
        },
        {
            "authors": [
                "Evgeny Lagutin",
                "Daniil Gavrilov",
                "Pavel Kalaidin."
            ],
            "title": "Implicit unlikelihood training: Improving neural text generation with reinforcement learning",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Lin-",
            "year": 2021
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdelrahman Mohamed",
                "Omer Levy",
                "Veselin Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "BART: Denoising sequence-to-sequence pre-training for natural language",
            "year": 2020
        },
        {
            "authors": [
                "Margaret Li",
                "Stephen Roller",
                "Ilia Kulikov",
                "Sean Welleck",
                "Y-Lan Boureau",
                "Kyunghyun Cho",
                "Jason Weston."
            ],
            "title": "Don\u2019t say that! making inconsistent dialogue unlikely with unlikelihood training",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for",
            "year": 2020
        },
        {
            "authors": [
                "Wei Li",
                "Wenhao Wu",
                "Moye Chen",
                "Jiachen Liu",
                "Xinyan Xiao",
                "Hua Wu"
            ],
            "title": "Faithfulness in natural language generation: A systematic survey of analysis, evaluation and optimization methods",
            "year": 2022
        },
        {
            "authors": [
                "Chin-Yew Lin."
            ],
            "title": "ROUGE: A package for automatic evaluation of summaries",
            "venue": "Text Summarization Branches Out, pages 74\u201381, Barcelona, Spain. Association for Computational Linguistics.",
            "year": 2004
        },
        {
            "authors": [
                "Yang Liu",
                "Dan Iter",
                "Yichong Xu",
                "Shuohang Wang",
                "Ruochen Xu",
                "Chenguang Zhu"
            ],
            "title": "G-eval: Nlg evaluation using gpt-4 with better human alignment",
            "year": 2023
        },
        {
            "authors": [
                "Leonardo Campillos Llanos",
                "Dhouha Bouamor",
                "Pierre Zweigenbaum",
                "Sophie Rosset."
            ],
            "title": "Managing linguistic and terminological variation in a medical dialogue system",
            "venue": "Proceedings of the Tenth International Conference on Language Resources and",
            "year": 2016
        },
        {
            "authors": [
                "Junru Lu",
                "Jiazheng Li",
                "Byron Wallace",
                "Yulan He",
                "Gabriele Pergola."
            ],
            "title": "NapSS: Paragraph-level medical text simplification via narrative prompting and sentence-matching summarization",
            "venue": "Findings of the Association for Computational Linguistics:",
            "year": 2023
        },
        {
            "authors": [
                "Louis Martin",
                "Angela Fan",
                "\u00c9ric de la Clergerie",
                "Antoine Bordes",
                "Beno\u00eet Sagot."
            ],
            "title": "MUSS: Multilingual unsupervised sentence simplification by mining paraphrases",
            "venue": "Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages",
            "year": 2022
        },
        {
            "authors": [
                "Linyong Nan",
                "Lorenzo Jaime Flores",
                "Yilun Zhao",
                "Yixin Liu",
                "Luke Benson",
                "Weijin Zou",
                "Dragomir Radev."
            ],
            "title": "R2D2: Robust data-to-text with replacement detection",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2022
        },
        {
            "authors": [
                "Mark Neumann",
                "Daniel King",
                "Iz Beltagy",
                "Waleed Ammar."
            ],
            "title": "ScispaCy: Fast and robust models for biomedical natural language processing",
            "venue": "Proceedings of the 18th BioNLP Workshop and Shared Task, pages 319\u2013327, Florence, Italy. Association for",
            "year": 2019
        },
        {
            "authors": [
                "OpenAI."
            ],
            "title": "Gpt-4 technical report",
            "venue": "ArXiv, abs/2303.08774.",
            "year": 2023
        },
        {
            "authors": [
                "Constantin Or\u0103san",
                "Richard Evans",
                "Ruslan Mitkov."
            ],
            "title": "Intelligent Text Processing to Help Readers with Autism, pages 713\u2013740",
            "venue": "Springer International Publishing, Cham.",
            "year": 2018
        },
        {
            "authors": [
                "Rebecca Passonneau."
            ],
            "title": "Measuring agreement on set-valued items (MASI) for semantic and pragmatic annotation",
            "venue": "Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC\u201906), Genoa, Italy. European Language Re-",
            "year": 2006
        },
        {
            "authors": [
                "Atharva Phatak",
                "David W. Savage",
                "Robert Ohle",
                "Jonathan Smith",
                "Vijay K. Mago."
            ],
            "title": "Medical text simplification using reinforcement learning (teslea): Deep learning\u2013based text simplification approach",
            "venue": "JMIR Medical Informatics, 10.",
            "year": 2022
        },
        {
            "authors": [
                "Horacio Saggion",
                "Sanja \u0160tajner",
                "Stefan Bott",
                "Simon Mille",
                "Luz Rello",
                "Biljana Drndarevic."
            ],
            "title": "Making it simplext: Implementation and evaluation of a text simplification system for spanish",
            "venue": "ACM Trans. Access. Comput., 6(4).",
            "year": 2015
        },
        {
            "authors": [
                "Thomas Scialom",
                "Louis Martin",
                "Jacopo Staiano",
                "\u00c9ric Villemonte de la Clergerie",
                "Beno\u00eet Sagot"
            ],
            "title": "Rethinking automatic evaluation in sentence simplification",
            "year": 2021
        },
        {
            "authors": [
                "Matthew Shardlow",
                "Fernando Alva-Manchego."
            ],
            "title": "Simple TICO-19: A dataset for joint translation and simplification of COVID-19 texts",
            "venue": "Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 3093\u20133102, Marseille, France. Eu-",
            "year": 2022
        },
        {
            "authors": [
                "Weijia Shi",
                "Xiaochuang Han",
                "Mike Lewis",
                "Yulia Tsvetkov",
                "Luke Zettlemoyer",
                "Scott Wen tau Yih"
            ],
            "title": "Trusting your evidence: Hallucinate less with context-aware decoding",
            "year": 2023
        },
        {
            "authors": [
                "E A Smith",
                "R. Senter."
            ],
            "title": "Automated readability index",
            "venue": "AMRL-TR. Aerospace Medical Research Laboratories, pages 1\u201314.",
            "year": 1967
        },
        {
            "authors": [
                "Lucia Specia",
                "Gustavo Paetzold."
            ],
            "title": "Lexical simplification with neural ranking",
            "venue": "Conference of the European Chapter of the Association for Computational Linguistics.",
            "year": 2017
        },
        {
            "authors": [
                "Arvind Krishna Sridhar",
                "Erik Visser"
            ],
            "title": "Improved beam search for hallucination mitigation in abstractive summarization",
            "year": 2022
        },
        {
            "authors": [
                "Neha Srikanth",
                "Junyi Jessy Li."
            ],
            "title": "Elaborative simplification: Content addition and explanation generation in text simplification",
            "venue": "Findings.",
            "year": 2020
        },
        {
            "authors": [
                "Sanja Stajner."
            ],
            "title": "Automatic text simplification for social good: Progress and challenges",
            "venue": "Findings of the Association for Computational Linguistics: ACLIJCNLP 2021, pages 2637\u20132652, Online. Association for Computational Linguistics.",
            "year": 2021
        },
        {
            "authors": [
                "Elior Sulem",
                "Omri Abend",
                "Ari Rappoport."
            ],
            "title": "Semantic structural evaluation for text simplification",
            "venue": "North American Chapter of the Association for Computational Linguistics.",
            "year": 2018
        },
        {
            "authors": [
                "Renliang Sun",
                "Hanqi Jin",
                "Xiaojun Wan."
            ],
            "title": "Document-level text simplification: Dataset, criteria and baseline",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7997\u20138013, Online and Punta Cana,",
            "year": 2021
        },
        {
            "authors": [
                "Renliang Sun",
                "Zhixian Yang",
                "Xiaojun Wan."
            ],
            "title": "Exploiting summarization data to help text simplification",
            "venue": "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 39\u201351, Dubrovnik, Croatia.",
            "year": 2023
        },
        {
            "authors": [
                "Jan Trienes",
                "J\u00f6rg Schl\u00f6tterer",
                "Hans-Ulrich Schildhaus",
                "Christin Seifert."
            ],
            "title": "Patient-friendly clinical notes: Towards a new text simplification dataset",
            "venue": "Proceedings of the Workshop on Text Simplification, Accessibility, and Readability (TSAR-2022), pages",
            "year": 2022
        },
        {
            "authors": [
                "Laurens van den Bercken",
                "Robert-Jan Sips",
                "Christoph Lofi."
            ],
            "title": "Evaluating neural text simplification in the medical domain",
            "venue": "The World Wide Web Conference, WWW \u201919, page 3286\u20133292, New York, NY, USA. Association for Computing Machin-",
            "year": 2019
        },
        {
            "authors": [
                "Sean Welleck",
                "Ilia Kulikov",
                "Stephen Roller",
                "Emily Dinan",
                "Kyunghyun Cho",
                "Jason Weston."
            ],
            "title": "Neural text generation with unlikelihood training",
            "venue": "International Conference on Learning Representations.",
            "year": 2020
        },
        {
            "authors": [
                "Teven Le Scao",
                "Sylvain Gugger",
                "Mariama Drame",
                "Quentin Lhoest",
                "Alexander M. Rush"
            ],
            "title": "Huggingface\u2019s transformers: State-of-the-art natural language processing",
            "year": 2020
        },
        {
            "authors": [
                "Yuxiang Wu",
                "Matt Gardner",
                "Pontus Stenetorp",
                "Pradeep Dasigi."
            ],
            "title": "Generating data to mitigate spurious correlations in natural language inference datasets",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics",
            "year": 2022
        },
        {
            "authors": [
                "Wei Xu",
                "Chris Callison-Burch",
                "Courtney Napoles."
            ],
            "title": "Problems in current text simplification research: New data can help",
            "venue": "Transactions of the Association for Computational Linguistics, 3:283\u2013297.",
            "year": 2015
        },
        {
            "authors": [
                "Wei Xu",
                "Courtney Napoles",
                "Ellie Pavlick",
                "Quanze Chen",
                "Chris Callison-Burch."
            ],
            "title": "Optimizing statistical machine translation for text simplification",
            "venue": "Transactions of the Association for Computational Linguistics, 4:401\u2013415.",
            "year": 2016
        },
        {
            "authors": [
                "Ziyu Yang",
                "Santhosh Cherian",
                "Slobodan Vucetic."
            ],
            "title": "Data augmentation for radiology report simplification",
            "venue": "Findings of the Association for Computational Linguistics: EACL 2023, pages 1922\u20131932, Dubrovnik, Croatia. Association for Computational",
            "year": 2023
        },
        {
            "authors": [
                "Tianyi Zhang",
                "Varsha Kishore",
                "Felix Wu",
                "Kilian Q. Weinberger",
                "Yoav Artzi."
            ],
            "title": "Bertscore: Evaluating text generation with bert",
            "venue": "International Conference on Learning Representations.",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "In recent years, text simplification has become an increasingly useful application of AI (Stajner, 2021) particularly in healthcare (Carroll et al., 1998; Saggion et al., 2015; Ora\u0306san et al., 2018), where text can be technical and difficult to understand. By automating this process, we can help healthcare professionals explain key medical texts (e.g. doctor\u2019s reports, findings) to patients. Previous work in text simplification in medical domain has explored use of pretrained language models (Devaraj et al., 2021; Sun et al., 2023; Martin et al., 2022; Trienes et al., 2022; Basu et al., 2023; Joseph et al., 2023b; Lu et al., 2023), reinforcement learning (Phatak et al., 2022), and zero-shot prompting (August et al., 2022; Joseph et al., 2023b). Despite this progress, simplification sometimes results in the generated text having lower quality and diversity (Devaraj et al., 2021; Phatak et al., 2022). Further as we find some simplification models copy sentences from the source, and thus remain do not sufficiently improve the readability (See Appendix B).\nIn this work, we seek to further improve medical text simplification. We first propose a new unlikelihood loss that penalizes words in proportion to their reading level using a well-established readability index. Second, we propose a modified beam search method at decoding time to rerank intermediate candidates based on their readability. Despite simplicity, our methods improve readability based on automated metrics (up to 2.43 points on FleschKincaid) and human evaluation, while maintaining similar performance in terms of factual consistency and overall simplification.\nWe make the following contributions: (1) We propose a new form of unlikelihood loss based on well-established readability index to improve medical text simplification (2) We propose a decoding strategy that optimizes for readability in medical text simplification (3) We provide evaluation results for previous state-of-the-art on three datasets in terms of readability and factual consistency. We make our code publicly available at https://github.com/ljyflores/ simplification-project.\nRelated Work Text simplification research primarily focuses on sentence-level (Xu et al., 2015; Specia and Paetzold, 2017; Sulem et al., 2018; Srikanth and Li, 2020; Shardlow and AlvaManchego, 2022), with some attempts at paragraph or document-level datasets (Sun et al., 2021; Laban et al., 2023). Most datasets have been sourced from accessible Wikipedia or News articles, which are already quite accessible. However, the medical field, laden with technical jargon, can greatly benefit from simplification. Initial methods in medical text simplification employed lexical and syntactic techniques (Llanos et al., 2016; Abrahamsson et al., 2014), while recent work includes finetuning language models like BART (Devaraj et al., 2021; Lewis et al., 2020) and a two-stage summarizethen-simplify approach (Lu et al., 2023). Medical\nsimplification has also expanded to multilingual settings (Joseph et al., 2023b).\nIn this work, following Devaraj et al. (2021) we use unlikelihood (UL) training (Welleck et al., 2020) to encourage the generation of simplified terminology. This strategy has been used in other domains to penalize inaccuracy (Hu et al., 2023; Nan et al., 2022), complexity (Devaraj et al., 2021; Lu et al., 2023), and redundancy (Lagutin et al., 2021; Li et al., 2020) in text generation. Unlike Devaraj et al. (2021), our work adapts UL to optimize for both readability and factual consistency. To improve simplification, we also intervene at the decoding stage. Previous work uses modified decoding methods to address factual inconsistency (Shi et al., 2023; King et al., 2022; Sridhar and Visser, 2022), or optimize fluency and diversity in text generation (Kriz et al., 2019; Hargreaves et al., 2021). Our work extends this by optimizing the decoder for readability in medical text simplification."
        },
        {
            "heading": "2 Methods",
            "text": "We propose two simple but effective approaches for improving medical text simplification, one during the training phase, and the other during decoding. Specifically, we propose a modified Unlikelihood Loss (Welleck et al., 2020) to incorporate readability index and encourage the model to favor the generation of simpler words. Then, we introduce a decoding approach that evaluates and re-ranks the candidate beams by considering both readability and factuality. We detail these approaches below:"
        },
        {
            "heading": "2.1 Unlikelihood Loss for Simplification",
            "text": "Unlikelihood loss (UL) (Welleck et al., 2020) is a training objective that forces unlikely generations to be assigned lower probability by the model (See Figure 1).\nReadability UL Following prior work (Devaraj et al., 2021) we can use this loss to force the model to assign a lower probability to complex words. Unlike Devaraj et al. (2021), we use the Flesch-Kincaid (FK) readability score (Kincaid et al., 1975) instead of model-predicted scores. The Flesch-Kincaid readability score is a numerical indicator that assesses the complexity of a text by estimating the US grade level needed for comprehension. Because FK considers syllable count and average phrase length, it serves as a good proxy metric even for incomplete sentences, by prioritiz-\ning text with shorter words and shorter phrases. We incorporate this score as follows: At generation step t, we identify the word v in the vocabulary with the largest output probability; this is the word which the model is most likely to output at step t. We compute the token-level UL for v by taking the product of the word\u2019s Flesch-Kincaid score and its standard UL term log(1\u2212 p(v|y\u0302<t). The total UL (ULR) is the sum of the token-level penalties.\nULR = \u2212 |y\u0302|\u2211 t=1 V\u2211 v=1 1v,tFKv log(1\u2212 p(v|y\u0302<t))\nwhere 1v,t indicates whether word v has the largest output probability in the vocabulary at step t, and FKv is the Flesch-Kincaid score of word v.\nConsistency UL As we discuss in \u00a74, we find that ULR alone leads to hallucinations, hence we also penalize the model for generating unsupported words in some set e using an additional factual consistency UL (ULC).\nULC = \u2212 |y\u0302|\u2211 t=1 V\u2211 v=1 1v,t1v,e log(1\u2212 p(v|y\u0302<t))\nwhere 1v,e is an indicator for whether the word v is in the set of hallucinated words e.\nWe determine the set e as follows: we identify the sequence which the model is most likely to generate, by finding the tokens with the highest logits at each generation step. Then, we then filter this set to the tokens which do not exist in either the input text nor label. At this point, the set contains all words which the model is likely to generate, but are not present in the input/label. Hence, it may contain words which are factually or grammatically correct, but don\u2019t match the gold summary. We\u2019d like to penalize only the tokens which we are sure are factually incorrect, hence we filter this set down to just entities using Spacy en_core_web_lg NER models (Honnibal and Montani, 2017), which results in the entity set e.\nOverall Loss The overall loss is a weighted sum of the negative log-likelihood (LNLL) and UL, where \u03bbR and \u03bbC are constants.\nL = LNLL + \u03bbRULR + \u03bbCULC"
        },
        {
            "heading": "2.2 Decoding for Simplification",
            "text": "Our proposed decoding strategy reranks candidate beams by their current readability and factual consistency scores, and retains the top n beams as the candidates for the next token (See Figure 2).\nReadability Score We optimize candidates\u2019 readability during decoding using Flesch-Kincaid (FK) Grade Level scores. FK represents the readability of a text measured by US grade level; hence, lower scores are more readable (Kincaid et al., 1975). These typically range from 0 to 18, but can extend past this range in practice. We compute FK of candidate beams and cap it from 4 to 20, as we find that qualitatively, beams with scores below 4 as equally simple, and above 20 as equally complex. Then, we normalize the score rF (s) from 0 to 1, such that 0 is least readable, and 1 is most readable.\nConsistency Score Like in UL training, we find that optimizing solely for readability in decoding may introduce hallucinations; hence we balance readability with consistency, as measured by BERTScore (Zhang et al., 2020). We find that beams with scores below 0.60 to have equally poor factuality, hence we cap the score rB(s) between 0.60 and 1.00 and normalize it.\nComposite Score We compute a composite score r(s) using an F1-like metric. Note that the score is merely used to rerank the candidates.\nrF (s) =  1, fF (s) < 4 20\u2212fF (s)\n20\u22124 , 4 \u2264 fF (s) \u2264 20 0, fF (s) > 20  rB(s) = { fB(s)\u22120.60\n0.40 , fB(s) \u2265 0.60 0, fB(s) < 0.60\n}\nr(s) =\n( 2rF (s)rB(s)\nrF (s) + rB(s)\n)2\nRanking Every k Steps Computing metrics at each generation step can be inefficient, and the meaning or readability of the beam might not change after adding just one word. Hence, we reduce the frequency with which we perform the reranking to intervals of k (See Appendix E).\nHallucination Heuristic We implement a heuristic to remove beams with unsupported entities. We identify entities with the Spacy en_core_web_lg NER model (Honnibal and Montani, 2017), check if the entities appear in the source, and set the beam\u2019s score as zero if any of the entities are not."
        },
        {
            "heading": "3 Experiments",
            "text": "Datasets We run our experiments on three datasets: Cochrane (Devaraj et al., 2021) consists of 4,459 pairs of abstracts from the Cochrane Database of Systematic Reviews and their corresponding summaries written by domain experts. MedEasi (Basu et al., 2023) consists of 1,697 pairs of human-annotated sentences sourced from the Merck Manuals (Cao et al., 2020) and SimpWiki (van den Bercken et al., 2019). Finally, the Radiology Reports Dataset 1 consists of 2,269 radiology reports collected from a large urban hospital and simplified by medical residents and doctors.\nBaselines We compare against a BART-XSum (Lewis et al., 2020) model which we further finetune on our datasets, and state-of-the-art models by Lu et al. (2023); Devaraj et al. (2021), all of which we fine-tune on each of the three datasets; we chose BART-XSum to align it with previous work, in order to provide an apples-to-apples comparison and isolate the impact of our methods. We also compare with state-of-the-art large language model GPT-4-0314 (OpenAI, 2023)2.\nEvaluation Metrics We evaluate the readability, consistency, and overall performance as follows:\n1Internal dataset 2We set the system\u2019s role as \u201cYou are a helpful assistant\nthat simplifies text\u201d, and the prompt as \u201cSimplify this text:\u201d.\nFor readability, we use the standard FK (Kincaid et al., 1975) and ARI scores (Smith and Senter, 1967), which use the average word and sentence length to estimate the complexity of texts.\nFor factual consistency, we use BERTScore (Zhang et al., 2020) and GPT-Eval (Liu et al., 2023) (See Appendix D), as these correlated well with human judgement (Scialom et al., 2021; Li et al., 2022; Liu et al., 2023). For GPT-Eval, we evaluate 50 summaries, and report the fraction of samples in which a factual inconsistency was found.\nWe additionally use SARI (Xu et al., 2016), an edit-based metric for text simplification, and ROUGE-LSum (Lin, 2004) for overall fluency."
        },
        {
            "heading": "4 Results",
            "text": "We fine-tune a BART model using our methods and present the results in Table 1; see Appendix A for implementation details."
        },
        {
            "heading": "Effect of Unlikelihood Loss and Decoding On",
            "text": "Cochrane and Radiology, our proposed methods achieve better readability scores in terms of FK and ARI. In particular, combining unlikelihood loss with the decoding strategy achieves a 2.43/1.74 point improvement in FK/ARI upon the next best model for Cochrane, and a 0.12/0.17 point improvement for Radiology. Note that in the radiology dataset, the sentences are typically short, resulting in a lower (better) baseline readability score. See sample comparison of outputs in Appendix B.\nOn MedEasi, our methods slightly underperform NapSS (Lu et al., 2023). We find that it sometimes generates phrases instead of full sentences, which lowers FK/ARI, since these scores depend on sentence length. In contrast, our models generate complete sentences, which improve fluency at the cost of worse (i.e. higher) FK/ARI scores.\nOur methods generally improve over the prior SOTA in terms of SARI and BERTScore, however, interestingly on the radiology dataset all methods underperform a fine-tuned BART model.\nWe observe that using UL or the decoder indi-\nvidually results in fewer hallucinations than both BART-UL (Devaraj et al., 2021) and NapSS (Lu et al., 2023) on Radiology, and against NapSS on MedEasi. When the baseline models perform well, we find that it is because they tend to copy information from the input, and hence are less prone to hallucinations. In contrast, our strategies force the model to use simpler words and not copy the input, but may introduce inconsistencies with the source. We confirmed this with an experiment: we compute the % 4-gram overlap of the model written summaries with the source, and observe that large portions of previous works\u2019 output is copied from the text, whereas output in our models are not (See Table 3).\nNote that some of the identified hallucination errors are relatively minor as we find GPT-Eval to be very strict. For example the phrase \u201c26 selftreatments of 26 Chinese herbal medicine prescriptions\u201d is found to be factually inconsistent with the source having the phrase \u201c26 self concocted Chinese herbal compound prescriptions\u201d by GPT-Eval (see Table 11 for full example).\nHuman Evaluation We conduct a human evaluation study to further investigate the results (See Table 2). We observe that our proposed UL and decoder improves readability over a fine-tuned BARTXSum model 43% and 27% of the time, whereas the previous SOTA NapSS (Lu et al., 2023) only demonstrated clear benefits 3% of the time. However, GPT-4 achieves the best performance, mainly because it is trained on human preference data and omits minor details, only keeping the main summary. In contrast, our models and previous SOTA tend to retain these minor details from the source, which human evaluators may find irrelevant.\nWe note that the low interrater agreeability aligns with the ranges reported in previous work (Goyal et al., 2023), which reflects the subjective nature of human preference, given that simplicity and readability varies based on one\u2019s technical background and style preferences. While such variability is\nhard to avoid, the average proportions suggest that overall, our methods significantly improved upon previous SOTA (NAPSS).\nEffect of Individual Unlikelihood Losses We test using ULR and ULC separately (See Table 4). ULR alone results in good readability but poor factual consistency, and vice versa for ULC , justifying the need for both losses to be used in conjunction."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this paper, we propose methods to improve simplicity in medical text simplification; this improves the readability of generated summaries, and achieves comparable BERTScore and SARI scores. However, hallucination remains a challenge."
        },
        {
            "heading": "Model % 4-Gram Overlap",
            "text": ""
        },
        {
            "heading": "Model FK \u2193 BScr \u2191 GPT \u2193 SARI \u2191",
            "text": "We explored augmenting the data with external knowledge (See Appendix C.2), but found no benefit. This may be because the sources and labels in the training data contains inconsistencies (Lu et al., 2023), which require further preprocessing. Addressing such hallucinations to generate more robust summaries is a critical future direction in medical text summarization, which we aim to explore further."
        },
        {
            "heading": "Limitations",
            "text": "One limitation of our work is the persistence of hallucinations in the output. Previous literature has shown that this often originates from inconsistencies between the source and text data. For example, a number of training labels in the Cochrane dataset (Devaraj et al., 2021) contain the phrase, \u201cThe evidence is up to date as of X\u201d, despite no mention of a date in the source (Lu et al., 2023). To this end, future work can adapt strategies from literature in summarization, which have shown that preprocessing (Adams et al., 2022; Wu et al., 2022) and augmenting (Yang et al., 2023) the data can mitigate such hallucinations.\nAnother limitation is our paper examines medical text simplification very broadly, whereas there may be expert knowledge needed to improve specific tasks. Hence, future work can analyze such methods on a more niche set of datasets (e.g. medical literature, patient reports, health-related news). Such work can be extended to other languages, for which multiple medical text simplification datasets have been developed (Trienes et al., 2022; Grigonyte et al., 2014; Cardon and Grabar, 2019, 2020; Joseph et al., 2023a).\nFinally, we note that our inter-annotator agreement on the task of readability is particularly low; this reflects both how human preferences are diverse and how the task is highly subjective, as has been shown in other domains (Goyal et al., 2023). Moreover, readability not only differs by person, but also by domain and task. Future work can define domain-specific criteria, and recruit participants from the exact target populations which the text is meant to be simplified for."
        },
        {
            "heading": "Ethics Statement",
            "text": "We use publicly available datasets and make our preprocessing and training scripts available. As mentioned in the limitations section, both our methods and previous methods still exhibit varying degrees of hallucination, and have yet to undergo domain-specific examination. Hence, we do not recommend these models be applied in a practical setting at the moment."
        },
        {
            "heading": "Proc. of AAAI-98 Workshop on Integrating Artificial",
            "text": "Intelligence and Assistive Technology.\nAshwin Devaraj, Iain Marshall, Byron Wallace, and Junyi Jessy Li. 2021. Paragraph-level simplification of medical texts. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 4972\u20134984, Online. Association for Computational Linguistics.\nJoseph L. Fleiss. 1971. Measuring nominal scale agreement among many raters. Psychological Bulletin, 76:378\u2013382.\nTanya Goyal, Junyi Jessy Li, and Greg Durrett. 2023. News summarization and evaluation in the era of gpt-3.\nGintare\u0307 Grigonyte, Maria Kvist, Sumithra Velupillai, and Mats Wir\u00e9n. 2014. Improving readability of Swedish electronic health records through lexical simplification: First results. In Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR), pages 74\u201383, Gothenburg, Sweden. Association for Computational Linguistics.\nJames Hargreaves, Andreas Vlachos, and Guy Emerson. 2021. Incremental beam manipulation for natural language generation. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 2563\u20132574, Online. Association for Computational Linguistics.\nMatthew Honnibal and Ines Montani. 2017. spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing. To appear.\nMengting Hu, Yinhao Bai, Yike Wu, Zhen Zhang, Liqi Zhang, Hang Gao, Shiwan Zhao, and Minlie Huang. 2023. Uncertainty-aware unlikelihood learning improves generative aspect sentiment quad prediction.\nSebastian Joseph, Kathryn Kazanas, Keziah Reina, Vishnesh J. Ramanathan, Wei Xu, Byron C. Wallace, and Junyi Jessy Li. 2023a. Multilingual simplification of medical texts.\nSebastian Valiaparampil Joseph, Kathryn Kazanas, Keziah Reina, Vishnesh J. Ramanathan, Wei Xu, Byron Wallace, and Junyi Jessy Li. 2023b. Multilingual simplification of medical texts. ArXiv, abs/2305.12532.\nJ. Peter Kincaid, Robert P. Fishburne, Richard L. Rogers, and Brad S. Chissom. 1975. Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel.\nDaniel King, Zejiang Shen, Nishant Subramani, Daniel S. Weld, Iz Beltagy, and Doug Downey. 2022.\nDon\u2019t say what you don\u2019t know: Improving the consistency of abstractive summarization by constraining beam search. In Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM), pages 555\u2013571, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.\nReno Kriz, Jo\u00e3o Sedoc, Marianna Apidianaki, Carolina Zheng, Gaurav Kumar, Eleni Miltsakaki, and Chris Callison-Burch. 2019. Complexity-weighted loss and diverse reranking for sentence simplification. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 3137\u20133147, Minneapolis, Minnesota. Association for Computational Linguistics.\nPhilippe Laban, Jesse Vig, Wojciech Kryscinski, Shafiq R. Joty, Caiming Xiong, and Chien-Sheng Wu. 2023. Swipe: A dataset for document-level simplification of wikipedia pages. ArXiv, abs/2305.19204.\nEvgeny Lagutin, Daniil Gavrilov, and Pavel Kalaidin. 2021. Implicit unlikelihood training: Improving neural text generation with reinforcement learning. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 1432\u20131441, Online. Association for Computational Linguistics.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7871\u20137880, Online. Association for Computational Linguistics.\nMargaret Li, Stephen Roller, Ilia Kulikov, Sean Welleck, Y-Lan Boureau, Kyunghyun Cho, and Jason Weston. 2020. Don\u2019t say that! making inconsistent dialogue unlikely with unlikelihood training. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4715\u20134728, Online. Association for Computational Linguistics.\nWei Li, Wenhao Wu, Moye Chen, Jiachen Liu, Xinyan Xiao, and Hua Wu. 2022. Faithfulness in natural language generation: A systematic survey of analysis, evaluation and optimization methods.\nChin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. In Text Summarization Branches Out, pages 74\u201381, Barcelona, Spain. Association for Computational Linguistics.\nYang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu. 2023. G-eval: Nlg evaluation using gpt-4 with better human alignment.\nLeonardo Campillos Llanos, Dhouha Bouamor, Pierre Zweigenbaum, and Sophie Rosset. 2016. Managing linguistic and terminological variation in a medical dialogue system. In Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC\u201916), pages 3167\u20133173, Portoro\u017e, Slovenia. European Language Resources Association (ELRA).\nJunru Lu, Jiazheng Li, Byron Wallace, Yulan He, and Gabriele Pergola. 2023. NapSS: Paragraph-level medical text simplification via narrative prompting and sentence-matching summarization. In Findings of the Association for Computational Linguistics: EACL 2023, pages 1079\u20131091, Dubrovnik, Croatia. Association for Computational Linguistics.\nLouis Martin, Angela Fan, \u00c9ric de la Clergerie, Antoine Bordes, and Beno\u00eet Sagot. 2022. MUSS: Multilingual unsupervised sentence simplification by mining paraphrases. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 1651\u20131664, Marseille, France. European Language Resources Association.\nLinyong Nan, Lorenzo Jaime Flores, Yilun Zhao, Yixin Liu, Luke Benson, Weijin Zou, and Dragomir Radev. 2022. R2D2: Robust data-to-text with replacement detection. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 6903\u20136917, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.\nMark Neumann, Daniel King, Iz Beltagy, and Waleed Ammar. 2019. ScispaCy: Fast and robust models for biomedical natural language processing. In Proceedings of the 18th BioNLP Workshop and Shared Task, pages 319\u2013327, Florence, Italy. Association for Computational Linguistics.\nOpenAI. 2023. Gpt-4 technical report. ArXiv, abs/2303.08774.\nConstantin Ora\u0306san, Richard Evans, and Ruslan Mitkov. 2018. Intelligent Text Processing to Help Readers with Autism, pages 713\u2013740. Springer International Publishing, Cham.\nRebecca Passonneau. 2006. Measuring agreement on set-valued items (MASI) for semantic and pragmatic annotation. In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC\u201906), Genoa, Italy. European Language Resources Association (ELRA).\nAtharva Phatak, David W. Savage, Robert Ohle, Jonathan Smith, and Vijay K. Mago. 2022. Medical text simplification using reinforcement learning (teslea): Deep learning\u2013based text simplification approach. JMIR Medical Informatics, 10.\nHoracio Saggion, Sanja \u0160tajner, Stefan Bott, Simon Mille, Luz Rello, and Biljana Drndarevic. 2015. Making it simplext: Implementation and evaluation of a text simplification system for spanish. ACM Trans. Access. Comput., 6(4).\nThomas Scialom, Louis Martin, Jacopo Staiano, \u00c9ric Villemonte de la Clergerie, and Beno\u00eet Sagot. 2021. Rethinking automatic evaluation in sentence simplification.\nMatthew Shardlow and Fernando Alva-Manchego. 2022. Simple TICO-19: A dataset for joint translation and simplification of COVID-19 texts. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 3093\u20133102, Marseille, France. European Language Resources Association.\nWeijia Shi, Xiaochuang Han, Mike Lewis, Yulia Tsvetkov, Luke Zettlemoyer, and Scott Wen tau Yih. 2023. Trusting your evidence: Hallucinate less with context-aware decoding.\nE A Smith and R. Senter. 1967. Automated readability index. AMRL-TR. Aerospace Medical Research Laboratories, pages 1\u201314.\nLucia Specia and Gustavo Paetzold. 2017. Lexical simplification with neural ranking. In Conference of the European Chapter of the Association for Computational Linguistics.\nArvind Krishna Sridhar and Erik Visser. 2022. Improved beam search for hallucination mitigation in abstractive summarization.\nNeha Srikanth and Junyi Jessy Li. 2020. Elaborative simplification: Content addition and explanation generation in text simplification. In Findings.\nSanja Stajner. 2021. Automatic text simplification for social good: Progress and challenges. In Findings of the Association for Computational Linguistics: ACLIJCNLP 2021, pages 2637\u20132652, Online. Association for Computational Linguistics.\nElior Sulem, Omri Abend, and Ari Rappoport. 2018. Semantic structural evaluation for text simplification. In North American Chapter of the Association for Computational Linguistics.\nRenliang Sun, Hanqi Jin, and Xiaojun Wan. 2021. Document-level text simplification: Dataset, criteria and baseline. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7997\u20138013, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.\nRenliang Sun, Zhixian Yang, and Xiaojun Wan. 2023. Exploiting summarization data to help text simplification. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 39\u201351, Dubrovnik, Croatia. Association for Computational Linguistics.\nJan Trienes, J\u00f6rg Schl\u00f6tterer, Hans-Ulrich Schildhaus, and Christin Seifert. 2022. Patient-friendly clinical notes: Towards a new text simplification dataset. In Proceedings of the Workshop on Text Simplification, Accessibility, and Readability (TSAR-2022), pages 19\u201327, Abu Dhabi, United Arab Emirates (Virtual). Association for Computational Linguistics.\nLaurens van den Bercken, Robert-Jan Sips, and Christoph Lofi. 2019. Evaluating neural text simplification in the medical domain. In The World Wide Web Conference, WWW \u201919, page 3286\u20133292, New York, NY, USA. Association for Computing Machinery.\nSean Welleck, Ilia Kulikov, Stephen Roller, Emily Dinan, Kyunghyun Cho, and Jason Weston. 2020. Neural text generation with unlikelihood training. In International Conference on Learning Representations.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. 2020. Huggingface\u2019s transformers: State-of-the-art natural language processing.\nYuxiang Wu, Matt Gardner, Pontus Stenetorp, and Pradeep Dasigi. 2022. Generating data to mitigate spurious correlations in natural language inference datasets. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2660\u20132676, Dublin, Ireland. Association for Computational Linguistics.\nWei Xu, Chris Callison-Burch, and Courtney Napoles. 2015. Problems in current text simplification research: New data can help. Transactions of the Association for Computational Linguistics, 3:283\u2013297.\nWei Xu, Courtney Napoles, Ellie Pavlick, Quanze Chen, and Chris Callison-Burch. 2016. Optimizing statistical machine translation for text simplification. Transactions of the Association for Computational Linguistics, 4:401\u2013415.\nZiyu Yang, Santhosh Cherian, and Slobodan Vucetic. 2023. Data augmentation for radiology report simplification. In Findings of the Association for Computational Linguistics: EACL 2023, pages 1922\u20131932, Dubrovnik, Croatia. Association for Computational Linguistics.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020. Bertscore: Evaluating text generation with bert. In International Conference on Learning Representations.\nA Implementation Details\nWe train a baseline BART-XSum model (Lewis et al., 2020) on Cochrane, MedEasi, and the Radiology Dataset. We implement the unlikelihood loss and modified decoder using the Transformers library (Wolf et al., 2020); we report the hyperparameters in Table 5. We run our experiments using NVIDIA-RTX 6000 GPUs."
        },
        {
            "heading": "B Example Output",
            "text": "Tables 6, 7, and 8 show comparisons of outputs from the previous SOTA vs our model. We clearly observe the benefits of our methods; the writing is much simpler, and complex phrases such as \u201casthma exacerbation\u201d and \u201cemergency department presentation\u201d have been replaced by \u201casthma attack\u201d and \u201ccoming to the emergency department\u201d. Table 8 shows an instance wherein the writing is much simpler, but the model tends to retain much more information about the source and explain other concepts (in italics); this may come across as redundant to some evaluators, which explains the results in the human evaluation portion, when compared to models like GPT-4."
        },
        {
            "heading": "C Other Experiments",
            "text": "C.1 Varying Candidate Set e\nKindly refer to Table 10 for a comparison of performance when we exclude only words in the input (ULI ), the label (ULL), or both (ULIL)."
        },
        {
            "heading": "C.2 External Knowledge Augmentation",
            "text": "We identify complex terms using SciSpacy (Neumann et al., 2019), obtain their meanings from UMLS (Bodenreider, 2004), and insert these meanings in the sentence. An example is provided in Table 9. Kindly refer to Table 10 for a comparison of performance with and without external knowledge (EK)."
        },
        {
            "heading": "D GPT-Eval Implementation",
            "text": "We follow Liu et al. (2023) to implement GPTEval for factual consistency with GPT-4, as this was found to correlate best with human judgment. We use the gpt-4-0314 version, with n, topp , and temperature set to 1. We set the system role as \u201cYour task is to rate the summary on one metric.\u201d For the user input, we input the following:\nModel Example\nInput A total of 38 studies involving 7843 children were included. Following educational intervention delivered to children, their parents or both, there was a significantly reduced risk of subsequent emergency department visits (RR 0.73, 95% CI 0.65 to 0.81, N = 3008) and hospital admissions (RR 0.79, 95% CI 0.69 to 0.92, N = 4019) compared with control. There were also fewer unscheduled doctor visits (RR 0.68, 95% CI 0.57 to 0.81, N = 1009). Very few data were available for other outcomes (FEV1, PEF, rescue medication use, quality of life or symptoms) and there was no statistically significant difference between education and control. Asthma education aimed at children and their carers who present to the emergency department for acute exacerbations can result in lower risk of future emergency department presentation and hospital admission. There remains uncertainty as to the longterm effect of education on other markers of asthma morbidity such as quality of life, symptoms and lung function. It remains unclear as to what type, duration and intensity of educational packages are the most effective in reducing acute care utilisation.\nNAPSS A total of 38 studies involving 7843 children were included in this review. Asthma education aimed at children and their carers who present to the emergency department for acute exacerbations can result in lower risk of future emergency department presentation and hospital admission. There were also fewer unscheduled doctor visits. Very few data were available for textbfother outcomes (FEV1, PEF, rescue medication use, quality of life or symptoms) and there was no statistically significant difference between education and control. It remains unclear as to what type, duration and intensity of educational packages are the most effective in reducing acute care utilisation. There remains uncertainty as to the long-term effect of education on other markers of asthma morbidity, symptoms and lung function.\nBARTUL\nThis review of 38 studies involving 7843 children found that asthma education aimed at children and their carers who present to the emergency department for acute exacerbations can result in lower risk of future emergency department presentation and hospital admission. There were also fewer unscheduled doctor visits. Very few data were available on other markers of asthma morbidity such as quality of life, symptoms and lung function. It remains unclear as to what type, duration and intensity of educational packages are the most effective in reducing acute care utilisation.\nModel Example\nInput Five trials of MSP/RESA vaccine with 217 participants were included; all five reported on safety, and two on efficacy. No severe or systemic adverse effects were reported at doses of 13 to 15 5g of each antigen (39 to 45 5g total). One small efficacy trial with 17 non-immune participants with blood-stage parasites showed no reduction or delay in parasite growth rates after artificial challenge. In the second efficacy trial in 120 children aged five to nine years in Papua New Guinea, episodes of clinical malaria were not reduced, but MSP/RESA significantly reduced parasite density only in children who had not been pretreated with an antimalarial drug (sulfadoxine-pyrimethamine). Infections with the 3D7 parasite subtype of MSP2 (the variant included in the vaccine) were reduced (RR 0.38, 95% CI 0.26 to 0.57; 719 participants) while those with the other main subtype, FC27, were not (720 participants). The MSP/RESA (Combination B) vaccine shows promise as a way to reduce the severity of malaria episodes, but the effect of the vaccine is MSP2 variant-specific. Pretreatment for malaria during a vaccine trial makes the results difficult to interpret, particularly with the relatively small sample sizes of early trials. The results show that blood-stage vaccines may play a role and merit further development.\nNAPSS Five trials of MSP/RESA vaccine with 217 participants were included; all five reported on safety, and two on efficacy. No severe or systemic adverse effects were reported at doses of 13 to 15 \u00b5g of each antigen (39 to 45 \u00b5g total). One small efficacy trial with 17 non-immune participants with blood-stage parasites showed no reduction or delay in parasite growth rates after artificial challenge. In the second efficacy trial in 120 children aged five to nine years in Papua New Guinea, episodes of clinical malaria were not reduced, but the vaccine significantly reduced parasite density only in children who had not been pretreated with an antimalarial drug (sulfadoxinepyrimethamine). Infections with the 3D7 parasite subtype (the variant included in the vaccine) were reduced (RR 0.38, 95% CI 0.26 to 0.57; 719 participants) while those with the other main subtype, FC27, were not (720 participants). The effect of the vaccine is MSP2 variant-specific. Pretreatment for malaria during a vaccine trial makes the results difficult to interpret, particularly with the relatively small sample sizes of early trials.\nBARTUL\nThis review of five trials found that the MSP/RESA (Combination B) vaccine shows promise as a way to reduce the severity of malaria episodes, but the effect of the vaccine is MSP2 variant-specific. The results show that blood-stage vaccines may play a role and merit further development.\nModel Example\nInput Four studies, involving 125 participants, were included. Three studies evaluated the effects of pulsed electromagnetic fields and one study, capacitive coupled electric fields. Participants with delayed union and non-union of the long bones were included, but most data related to non-union of the tibia. Although all studies were blinded randomised placebo-controlled trials, each study had limitations. ... The overall pooled effect size was small and not statistically significant (risk ratio 1.96; 95% confidence interval 0.86 to 4.48; 4 trials). There was substantial clinical and statistical heterogeneity in this pooled analysis (I2 = 58%). A sensitivity analysis conducted to determine the effect of multiple follow-up time-points on the heterogeneity amongst the studies showed that the effect size remained nonsignificant at 24 weeks (risk ratio 1.61; 95% confidence interval 0.74 to 3.54; 3 trials), with similar heterogeneity (I2 = 57%). There was no reduction in pain found in two trials. ... More definitive conclusions on treatment effect await further well-conducted randomised controlled trials.\",\nNAPSS Four studies, involving 125 participants, were included in this review. Three studies evaluated the effects of pulsed electromagnetic fields and one study, capacitive coupled electric fields. Participants with delayed union of the long bones were included, but most data related to non-union of the tibia. Although all studies were blinded randomised placebo-controlled trials, each study had limitations. The primary measure of the clinical effectiveness of electromagnetic field stimulation was the proportion of participants whose fractures had united at a fixed time point. The overall pooled effect size was small and not statistically significant (risk ratio 1.96; 95% confidence interval 0.86 to 4.48; 4 trials). There was substantial clinical and statistical heterogeneity in this pooled analysis (I2 = 58%). A sensitivity analysis conducted to determine the effect of multiple follow-up time-points on the heterogeneity amongst the studies showed that the effect size remained non-significant at 24 weeks. There was no reduction in pain found in two trials.... No study reported functional outcome measures. One trial reported two minor complications resulting from treatment. More definitive conclusions on treatment effect await further well-conducted randomised controlled trials.\nBARTUL\nThis review of four studies, involving 125 participants, found that electromagnetic field stimulation may offer some benefit in the treatment of delayed union of long bone fractures, but it is inconclusive. More definitive conclusions on treatment effect await further well-conducted randomised controlled trials."
        },
        {
            "heading": "Human Evaluation of Text Summarization",
            "text": "Systems: Factual Consistency: Does the summary have untruthful or misleading facts that are not supported by the source text? Source Text: document Summary: summary Does the summary contain factual inconsistencies? Answer:\nWe additionally prompt GPT to explain why it labeled a summary as being factually inconsistent by adding \u201cWhy: \u201d after the last line. A sample output is shown in Table 11."
        },
        {
            "heading": "E Results by Varying k",
            "text": "We reduce the frequency with which we rerank beams, and find that this reduces inference time without large tradeoffs in performance. This was\nsurprising, as we thought reranking less frequently would lead the model to fail to find an \u201coptimal\u201d candidate (See Table 12)."
        },
        {
            "heading": "5 20.24 9.82 0.867 40.74 42.60",
            "text": ""
        }
    ],
    "title": "Medical Text Simplification: Optimizing for Readability with Unlikelihood Training and Reranked Beam Search Decoding",
    "year": 2023
}