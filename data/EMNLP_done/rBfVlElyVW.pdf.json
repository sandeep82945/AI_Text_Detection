{
    "abstractText": "Humans possess a remarkable ability to assign novel interpretations to linguistic expressions, enabling them to learn new words and understand community-specific connotations. However, Large Language Models (LLMs) have a knowledge cutoff and are costly to finetune repeatedly. Therefore, it is crucial for LLMs to learn novel interpretations in-context. In this paper, we systematically analyse the ability of LLMs to acquire novel interpretations using incontext learning. To facilitate our study, we introduce MAGNIFICO, an evaluation suite implemented within a text-to-SQL semantic parsing framework that incorporates diverse tokens and prompt settings to simulate real-world complexity. Experimental results on MAGNIFICO demonstrate that LLMs exhibit a surprisingly robust capacity for comprehending novel interpretations from natural language descriptions as well as from discussions within long conversations. Nevertheless, our findings also highlight the need for further improvements, particularly when interpreting unfamiliar words or when composing multiple novel interpretations simultaneously in the same example. Additionally, our analysis uncovers the semantic predispositions in LLMs and reveals the impact of recency bias for information presented in long contexts.",
    "authors": [
        {
            "affiliations": [],
            "name": "Arkil Patel"
        },
        {
            "affiliations": [],
            "name": "Satwik Bhattamishra"
        },
        {
            "affiliations": [],
            "name": "Siva Reddy"
        },
        {
            "affiliations": [],
            "name": "Dzmitry Bahdanau"
        }
    ],
    "id": "SP:afa11c690768ed915b053d4beaecef05c2a16c31",
    "references": [
        {
            "authors": [
                "Ekin Akyurek",
                "Jacob Andreas."
            ],
            "title": "Lexicon learning for few shot sequence modeling",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
            "year": 2021
        },
        {
            "authors": [
                "Shengnan An",
                "Zeqi Lin",
                "Qiang Fu",
                "Bei Chen",
                "Nanning Zheng",
                "Jian-Guang Lou",
                "Dongmei Zhang"
            ],
            "title": "How do in-context examples affect compositional generalization",
            "venue": "In Proceedings of the 61st Annual Meeting of the Association",
            "year": 2023
        },
        {
            "authors": [
                "Jacob Andreas."
            ],
            "title": "Good-enough compositional data augmentation",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7556\u20137566, Online. Association for Computational Linguistics.",
            "year": 2020
        },
        {
            "authors": [
                "Dzmitry Bahdanau",
                "Kyunghyun Cho",
                "Yoshua Bengio."
            ],
            "title": "Neural machine translation by jointly learning to align and translate",
            "venue": "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference",
            "year": 2015
        },
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are few-shot learners. Advances in neural information processing",
            "year": 2020
        },
        {
            "authors": [
                "Paco Calvo",
                "John Symons."
            ],
            "title": "The architecture of cognition: Rethinking Fodor and Pylyshyn\u2019s systematicity challenge",
            "venue": "MIT Press.",
            "year": 2014
        },
        {
            "authors": [
                "Greg Brockman"
            ],
            "title": "Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374",
            "year": 2021
        },
        {
            "authors": [
                "Xinyun Chen",
                "Chen Liang",
                "Adams Wei Yu",
                "Dawn Song",
                "Denny Zhou."
            ],
            "title": "Compositional generalization via neural-symbolic stack machines",
            "venue": "Advances in Neural Information Processing Systems, volume 33, pages 1690\u20131701. Curran Associates,",
            "year": 2020
        },
        {
            "authors": [
                "Maxime Chevalier-Boisvert",
                "Dzmitry Bahdanau",
                "Salem Lahlou",
                "Lucas Willems",
                "Chitwan Saharia",
                "Thien Huu Nguyen",
                "Yoshua Bengio."
            ],
            "title": "BabyAI: First steps towards grounded language learning with a human in the loop",
            "venue": "International Conference on",
            "year": 2019
        },
        {
            "authors": [
                "Henry Conklin",
                "Bailin Wang",
                "Kenny Smith",
                "Ivan Titov."
            ],
            "title": "Meta-learning to compositionally generalize",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natu-",
            "year": 2021
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Longxu Dou",
                "Yan Gao",
                "Xuqi Liu",
                "Mingyang Pan",
                "Dingzirui Wang",
                "Wanxiang Che",
                "Dechen Zhan",
                "MinYen Kan",
                "Jian-Guang Lou."
            ],
            "title": "Towards knowledge-intensive text-to-SQL semantic parsing with formulaic knowledge",
            "venue": "Proceedings of the",
            "year": 2022
        },
        {
            "authors": [
                "Andrew Drozdov",
                "Nathanael Sch\u00e4rli",
                "Ekin Aky\u00fcrek",
                "Nathan Scales",
                "Xinying Song",
                "Xinyun Chen",
                "Olivier Bousquet",
                "Denny Zhou."
            ],
            "title": "Compositional semantic parsing with large language models",
            "venue": "The Eleventh International Conference on Learning",
            "year": 2023
        },
        {
            "authors": [
                "Julian Martin Eisenschlos",
                "Jeremy R. Cole",
                "Fangyu Liu",
                "William W. Cohen."
            ],
            "title": "WinoDict: Probing language models for in-context word acquisition",
            "venue": "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Lin-",
            "year": 2023
        },
        {
            "authors": [
                "Jerry A Fodor",
                "Ernest Lepore."
            ],
            "title": "The compositionality papers",
            "venue": "Oxford University Press.",
            "year": 2002
        },
        {
            "authors": [
                "Jerry A Fodor",
                "Zenon W Pylyshyn."
            ],
            "title": "Connectionism and cognitive architecture: A critical analysis",
            "venue": "Cognition, 28(1-2):3\u201371.",
            "year": 1988
        },
        {
            "authors": [
                "Jonathan Gordon",
                "David Lopez-Paz",
                "Marco Baroni",
                "Diane Bouchacourt."
            ],
            "title": "Permutation equivariant models for compositional generalization in language",
            "venue": "International Conference on Learning Representations.",
            "year": 2020
        },
        {
            "authors": [
                "Demi Guo",
                "Yoon Kim",
                "Alexander Rush."
            ],
            "title": "Sequence-level mixed sample data augmentation",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5547\u20135552, Online. Association for Computa-",
            "year": 2020
        },
        {
            "authors": [
                "Robert F Hadley."
            ],
            "title": "Systematicity in connectionist language learning",
            "venue": "Mind & Language, 9(3):247\u2013272.",
            "year": 1994
        },
        {
            "authors": [
                "Coleman Haley."
            ],
            "title": "This is a BERT",
            "venue": "now there are several of them. can they generalize to novel words? In Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 333\u2013341, Online. Association for Com-",
            "year": 2020
        },
        {
            "authors": [
                "Aur\u00e9lie Herbelot",
                "Eva Maria Vecchi."
            ],
            "title": "Many speakers, many worlds",
            "venue": "Linguistic Issues in Language Technology, 13.",
            "year": 2016
        },
        {
            "authors": [
                "Felix Hill",
                "Olivier Tieleman",
                "Tamara von Glehn",
                "Nathaniel Wong",
                "Hamza Merzic",
                "Stephen Clark."
            ],
            "title": "Grounded language learning fast and slow",
            "venue": "International Conference on Learning Representations.",
            "year": 2021
        },
        {
            "authors": [
                "Najoung Kim",
                "Tal Linzen."
            ],
            "title": "COGS: A compositional generalization challenge based on semantic interpretation",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 9087\u20139105, Online. As-",
            "year": 2020
        },
        {
            "authors": [
                "Brenden Lake",
                "Marco Baroni."
            ],
            "title": "Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks",
            "venue": "Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Ma-",
            "year": 2018
        },
        {
            "authors": [
                "Brenden M Lake."
            ],
            "title": "Compositional generalization through meta sequence-to-sequence learning",
            "venue": "Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.",
            "year": 2019
        },
        {
            "authors": [
                "Andrew K Lampinen",
                "James L McClelland."
            ],
            "title": "One-shot and few-shot learning of word embeddings",
            "venue": "arXiv preprint arXiv:1710.10280.",
            "year": 2017
        },
        {
            "authors": [
                "Chia-Hsuan Lee",
                "Oleksandr Polozov",
                "Matthew Richardson."
            ],
            "title": "KaggleDBQA: Realistic evaluation of text-to-SQL parsers",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint",
            "year": 2021
        },
        {
            "authors": [
                "Jinyang Li",
                "Binyuan Hui",
                "Ge Qu",
                "Binhua Li",
                "Jiaxi Yang",
                "Bowen Li",
                "Bailin Wang",
                "Bowen Qin",
                "Rongyu Cao",
                "Ruiying Geng"
            ],
            "title": "2023a. Can llm already serve as a database interface? a big bench for largescale database grounded text-to-sqls",
            "year": 2023
        },
        {
            "authors": [
                "Sean Hughes",
                "Thomas Wolf",
                "Arjun Guha",
                "Leandro von Werra",
                "Harm de Vries"
            ],
            "title": "2023b. Starcoder: may the source be with you",
            "year": 2023
        },
        {
            "authors": [
                "Yuanpeng Li",
                "Liang Zhao",
                "Jianyu Wang",
                "Joel Hestness."
            ],
            "title": "Compositional generalization for primitive substitutions",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference",
            "year": 2019
        },
        {
            "authors": [
                "Dongmei Zhang"
            ],
            "title": "Learning algebraic recombination for compositional generalization",
            "year": 2021
        },
        {
            "authors": [
                "Qian Liu",
                "Shengnan An",
                "Jian-Guang Lou",
                "Bei Chen",
                "Zeqi Lin",
                "Yan Gao",
                "Bin Zhou",
                "Nanning Zheng",
                "Dongmei Zhang."
            ],
            "title": "Compositional generalization by learning analytical expressions",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Gary F Marcus."
            ],
            "title": "The algebraic mind: Integrating connectionism and cognitive science",
            "venue": "MIT press.",
            "year": 2003
        },
        {
            "authors": [
                "Paul Christiano",
                "Jan Leike",
                "Ryan Lowe"
            ],
            "title": "Training language models to follow instructions with human feedback",
            "year": 2022
        },
        {
            "authors": [
                "jani",
                "Sasank Chilamkurthy",
                "Benoit Steiner",
                "Lu Fang",
                "Junjie Bai",
                "Soumith Chintala"
            ],
            "title": "Pytorch: An imperative style, high-performance deep learning library",
            "venue": "In Advances in Neural Information Processing Systems,",
            "year": 2019
        },
        {
            "authors": [
                "Arkil Patel",
                "Satwik Bhattamishra",
                "Phil Blunsom",
                "Navin Goyal."
            ],
            "title": "Revisiting the compositional generalization abilities of neural sequence models",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume",
            "year": 2022
        },
        {
            "authors": [
                "Ngoc-Quan Pham",
                "Jan Niehues",
                "Alex Waibel."
            ],
            "title": "Towards one-shot learning for rare-word translation with external experts",
            "venue": "arXiv preprint arXiv:1809.03182.",
            "year": 2018
        },
        {
            "authors": [
                "Nitarshan Rajkumar",
                "Raymond Li",
                "Dzmitry Bahdanau"
            ],
            "title": "Evaluating the text-to-sql capabilities of large language models",
            "year": 2022
        },
        {
            "authors": [
                "Timo Schick",
                "Hinrich Sch\u00fctze."
            ],
            "title": "Learning semantic representations for novel words: Leveraging both form and context",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 6965\u20136973.",
            "year": 2019
        },
        {
            "authors": [
                "Ankur Sikarwar",
                "Arkil Patel",
                "Navin Goyal."
            ],
            "title": "When can transformers ground and compose: Insights from compositional generalization benchmarks",
            "venue": "Proceedings of the 2022 Conference on",
            "year": 2022
        },
        {
            "authors": [
                "Rohan Taori",
                "Ishaan Gulrajani",
                "Tianyi Zhang",
                "Yann Dubois",
                "Xuechen Li",
                "Carlos Guestrin",
                "Percy Liang",
                "Tatsunori B Hashimoto."
            ],
            "title": "Alpaca: A strong, replicable instruction-following model",
            "venue": "Stanford Center for Research on Foundation Models.",
            "year": 2023
        },
        {
            "authors": [
                "Tristan Thrush",
                "Ethan Wilcox",
                "Roger Levy."
            ],
            "title": "Investigating novel verb learning in BERT: Selectional preference classes and alternation-based syntactic generalization",
            "venue": "Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpret-",
            "year": 2020
        },
        {
            "authors": [
                "driguez",
                "Robert Stojnic",
                "Sergey Edunov",
                "Thomas Scialom"
            ],
            "title": "2023b. Llama 2: Open foundation and fine-tuned chat models",
            "year": 2023
        },
        {
            "authors": [
                "Maria Tsimpoukelli",
                "Jacob Menick",
                "Serkan Cabi",
                "S.M. Ali Eslami",
                "Oriol Vinyals",
                "Felix Hill."
            ],
            "title": "Multimodal few-shot learning with frozen language models",
            "venue": "Advances in Neural Information Processing Systems.",
            "year": 2021
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems, 30.",
            "year": 2017
        },
        {
            "authors": [
                "Su Wang",
                "Stephen Roller",
                "Katrin Erk"
            ],
            "title": "Distributional modeling on a diet: One-shot word learning from text",
            "year": 2017
        },
        {
            "authors": [
                "Yizhong Wang",
                "Yeganeh Kordi",
                "Swaroop Mishra",
                "Alisa Liu",
                "Noah A. Smith",
                "Daniel Khashabi",
                "Hannaneh Hajishirzi"
            ],
            "title": "Self-instruct: Aligning language models with self-generated instructions",
            "year": 2023
        },
        {
            "authors": [
                "Teven Le Scao",
                "Sylvain Gugger",
                "Mariama Drame",
                "Quentin Lhoest",
                "Alexander Rush."
            ],
            "title": "Transformers: State-of-the-art natural language processing",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System",
            "year": 2020
        },
        {
            "authors": [
                "Hitomi Yanaka",
                "Koji Mineshima",
                "Kentaro Inui."
            ],
            "title": "SyGNS: A systematic generalization testbed based on natural language semantics",
            "venue": "Findings of the Association for Computational Linguistics: ACLIJCNLP 2021, pages 103\u2013119, Online. Association",
            "year": 2021
        },
        {
            "authors": [
                "Tao Yu",
                "Chien-Sheng Wu",
                "Xi Victoria Lin",
                "bailin wang",
                "Yi Chern Tan",
                "Xinyi Yang",
                "Dragomir Radev",
                "richard socher",
                "Caiming Xiong"
            ],
            "title": "Gra{pp}a: Grammar-augmented pre-training for table semantic parsing",
            "venue": "In International Conference on Learning",
            "year": 2021
        },
        {
            "authors": [
                "Tao Yu",
                "Rui Zhang",
                "Kai Yang",
                "Michihiro Yasunaga",
                "Dongxu Wang",
                "Zifan Li",
                "James Ma",
                "Irene Li",
                "Qingning Yao",
                "Shanelle Roman",
                "Zilin Zhang",
                "Dragomir Radev"
            ],
            "title": "Spider: A large-scale human-labeled dataset for complex and cross-domain semantic pars",
            "year": 2018
        },
        {
            "authors": [
                "Chen Zhao",
                "Yu Su",
                "Adam Pauls",
                "Emmanouil Antonios Platanios."
            ],
            "title": "Bridging the generalization gap in text-to-SQL parsing with schema expansion",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume",
            "year": 2022
        },
        {
            "authors": [
                "Ruiqi Zhong",
                "Tao Yu",
                "Dan Klein."
            ],
            "title": "Semantic evaluation for text-to-SQL with distilled test suites",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 396\u2013411, Online. Association for Computa-",
            "year": 2020
        },
        {
            "authors": [
                "Lazaridou"
            ],
            "title": "2021) analyse the temporal generalization capabilities of LLMs and showed that the perplexity increases when modelling text containing new words. There is also some related work in the domain of grounded language learning",
            "year": 2021
        },
        {
            "authors": [
                "Chevalier-Boisvert"
            ],
            "title": "2019) focus on learning a synthetic language which is a subset of English. However, they do not carry out any systematic evaluation focused on word learning",
            "venue": "Hill et al",
            "year": 2021
        },
        {
            "authors": [
                "Tsimpoukelli"
            ],
            "title": "2021) focus on using frozen pretrained models for learning words that only act as names of objects in images. We wish to study word learning",
            "year": 2021
        },
        {
            "authors": [
                "Lake",
                "Baroni"
            ],
            "title": "2018) investigated the compositional generalization abilities of contemporary neural sequence models such as RNNs and LSTMs based on their performance on a synthetic benchmark called \u2018SCAN",
            "year": 2018
        },
        {
            "authors": [
                "Liu"
            ],
            "title": "2021). However, most of these approaches are task-specific and cannot be generally applied for language processing. Moreover, LLMs achieve a very high level of performance on compositional generalization benchmarks",
            "year": 2021
        },
        {
            "authors": [
                "JP"
            ],
            "title": "Using valid SQLite, answer the following question with the corresponding SQL query: what is all the information about overpaid employees hired before April",
            "year": 1995
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Humans can assign new interpretations to words or phrases in a language and consequently use them compositionally in utterances. For instance, the word \u2018zoom\u2019 is increasingly used to refer to a virtual calling service in the context of the COVID-19 pandemic. Similarly, as our society progresses, new words such as \u2018binge-watching\u2019 and \u2018selfie\u2019 keep getting coined frequently and become a part of our daily usage. Moreover, in regular conversations, people might assign custom interpretations to words or phrases (e.g., see the interpretation of \u2018underpaid\u2019 in Figure 2). The question of whether\nlanguage models are similarly capable of assigning novel interpretations to words and phrases is therefore interesting and requires investigation.\nThe task of learning novel interpretations has predominantly been studied from the perspective of finetuning a model, particularly the word embeddings, to acquire novel words during training (Lampinen and McClelland, 2017; Pham et al., 2018; Schick and Sch\u00fctze, 2019). Prior studies on compositional generalization (Lake and Baroni, 2018; Kim and Linzen, 2020) also attempt to evaluate novel word learning using specially crafted train-test splits in which certain combinations of words are systematically held out from the test set. In recent years, however, contemporary Large Language Models (LLMs) have brought about a paradigm shift away from the classical train-test setup with their incredible capacity to learn new tasks in-context (Brown et al., 2020). With this study, we seek to understand how well can LLMs acquire novel interpretations in-context. Compared to previous setups, in-context learning (ICL) is also more practical since it is difficult to train models every time a new interpretation is encountered.\nIn this work, we systematically analyse the ability of LLMs to in-context learn novel interpretations. We summarize our contributions below.\nEvaluation Suite. To facilitate our analysis, we create an evaluation suite, MAGNIFICO: Measuring Adaptability and Generalization to Novel Interpretations For In-Context Learning. Each example in MAGNIFICO is a text-to-SQL semantic parsing problem that requires models to understand one or more novel interpretations used in the input text to generate the correct SQL query. To simulate real-world diversity and complexity, we experiment with different ways of introducing new interpretations to the model (see Figure 2).\nCapabilities of LLMs. We extensively experiment with 11 LLMs to understand their ability for learning novel interpretations in-context. Experiments on MAGNIFICO reveal that LLMs show a high degree of capability in learning novel interpretations even from a brief natural language description of the interpretation or from a longform conversation. For larger LMs, learning from a description is competitive to providing explicit few-shot examples.\nChallenges for LLMs. We find that LLMs severely fail at learning multiple novel interpretations simultaneously. Moreover, we observed that LLMs find it more challenging to learn interpretations for unfamiliar words. Our analysis also shows that LLMs have a recency bias and might\nfind it difficult to learn interpretations presented earlier in the context."
        },
        {
            "heading": "2 Related Work",
            "text": "Word Learning. Previous works (Wang et al., 2017; Herbelot and Vecchi, 2016; Lampinen and McClelland, 2017; Pham et al., 2018; Schick and Sch\u00fctze, 2019) have developed task- or modelspecific approaches for learning the embeddings of novel words. However, these methods cannot be applied in diverse scenarios with contemporary Large Language Models (LLMs). In this work, we take a more practical approach by evaluating how well do LLMs understand novel interpretations of words and phrases in-context on top of a grounded NLP task, text-to-SQL semantic parsing.\nThere are a limited number of works that analyse the novel word learning abilities of LLMs. Haley (2020) and Thrush et al. (2020) analysed novel word learning with BERT (Devlin et al., 2019) using synthetic tests. However, it is unclear how their findings relate to autoregressive LLMs. Brown et al. (2020) qualitatively tested GPT-3\u2019s ability to use a novel word in a sentence after seeing its definition. Eisenschlos et al. (2023) analyse the in-context word learning abilities of LLMs using a synthetic co-reference resolution task. In this paper, however, we work on a more practical task and take a broader view of the problem by studying the acquisition of novel interpretations, which can arise even from\nexisting words and phrases in the vocabulary. We also study compositional generalization of multiple novel interpretations simultaneously.\nCompositional Generalization. Recent works (Lake and Baroni, 2018; Kim and Linzen, 2020; Keysers et al., 2020) proposed benchmarks with a systematic difference between the train and test sets: novel combinations of certain words are held out from the train set. However, such evaluation setups are susceptible to fairness issues (Sikarwar et al., 2022) arising from the dependence on a train set. Moreover, model-independent factors in the train set can influence generalization performance (Patel et al., 2022). Our evaluation framework is set within the paradigm of in-context learning (ICL), which does not require the creation of an explicit train set. Note that even in ICL settings, LLMs have saturated existing compositional generalization benchmarks (Drozdov et al., 2023). More recently, An et al. (2023) proposed a new benchmark, COFE, for in-context compositional generalization. However, their focus was on understanding the factors affecting better selection of in-context examples for compositional generalization. Moreover, the examples in COFE are based on another synthetic benchmark, while we focus on more realistic settings using a grounded text-to-SQL task.\nKnowledge-intensive text-to-SQL. Works on knowledge-intensive text-to-SQL (Li et al., 2023a; Lee et al., 2021; Zhao et al., 2022; Dou et al., 2022) have some similarities with our work in that they assign schema-specific external knowledge to words or phrases in the input query. However, our interpretations are much more dynamic and do not have pre-defined formal definitions. Moreover, the focus of these works is on domain generalization for text-to-SQL semantic parsing. We only use text-to-SQL as a testbed since it allows us to more formally ground meanings of interpretations and has real-world applicability."
        },
        {
            "heading": "3 MAGNIFICO",
            "text": "We choose the text-to-SQL task to test LLMs\u2019 ability to handle novel interpretations because of its relevance to real-world applications. Moreover, contemporary LLMs already achieve good zero/fewshot in-context performance on the task. We create MAGNIFICO by modifying and re-tasking examples from an existing text-to-SQL benchmark, Spider (Yu et al., 2018). Below, we describe the procedure in detail."
        },
        {
            "heading": "3.1 Novel Interpretations",
            "text": "We define a set of 24 interpretations that are either already being used or can be introduced in the examples of Spider:\n\u22c6 Basic operations: Standard column operations frequently used in SQL queries.\n\u22c6 Subquery-based operations: Complex operations using nested subqueries.\n\u22c6 Value-based filtering: Particular subset of values for specific columns.\n\u22c6 Column operations: Operations performed over specific columns.\nTable 1 provides examples of some of the interpretations that we defined. We will refer to the word or phrase used to denote the novel interpretation on the source side of the example as its form. We defined 18 interpretations denoted by a single word form and 6 interpretations denoted by a phrase form (see Figure 3 for an illustration). The full list of all interpretations can be found in Tables 4 and 5 in the Appendix. For the 18 interpretations denoted by a single word, we experiment with three types of forms that vary in their pre-existing semantic meaning: (1) plausible forms are words that can\nreasonably be expected to represent the novel interpretation in realistic scenarios, (2) foreign forms are novel words without any pre-defined meaning that are generated using a random permutation of English characters, and (3) adversarial forms are words with an existing meaning that is contrary to the intent expressed by the novel interpretation. Figure 1 illustrates the three types of forms in an example from MAGNIFICO."
        },
        {
            "heading": "3.2 Generating Data",
            "text": "We create MAGNIFICO examples by modifying examples in the Spider dataset such that understanding a novel interpretation1 used in the input is necessary to successfully generate the corresponding SQL query. We will refer to the original examples from Spider as seed examples. For each interpretation, we generate data using one or more of the following methods:\n(1) Regex-based pattern matching. Some interpretations such as \u2018the minimum value\u2019 (see Table 1) already have examples existing in Spider. For such interpretations, we find the relevant seed examples using regex-based pattern matching, either on the source side by conditioning on the presence of certain keywords such as minimum or lowest or on the target side by conditioning on operations such as min(). We then modify the seed examples to include the form of the interpretation in the input and inculcate the corresponding logic in the target SQL query using specific rules, if required. An illustration of this process is shown in Figure 4.\n(2) LLM-assisted constrained paraphrasing. For many interpretations, it is not possible to manually devise rules for modifying the natural language\n1We experiment with different types of prompt contexts for explaining the novel interpretation, detailed in \u00a74."
        },
        {
            "heading": "Example from Spider",
            "text": ""
        },
        {
            "heading": "Example in MAGNIFICo",
            "text": "queries of the seed example to include the corresponding form in a suitable manner. In such cases, we prompt GPT-4 (OpenAI, 2023) with the query of the seed example and instruct it to paraphrase the query so as to include the form of the novel interpretation. We then manually examine the modelgenerated paraphrase for grammatical correctness and consistency of intended meaning. Similar to the previous method, we modify the target SQL query using hand-crafted rules, if required.\n(3) Synchronous Context-Free Grammar. For many interpretations, there are either none or very few examples already existing in Spider. It is also difficult to find such examples automatically based on regex patterns. In such cases, if we have obtained a limited number of examples from Spider, we extract an SCFG representing those examples by abstracting away specific column and table names and data values similar to the method used by Yu et al. (2021). If there are not enough examples in Spider, we define an SCFG ourselves that represents the interpretation. We then automatically generate examples from the SCFG by filling it with randomly sampled column and table names and values from the set of databases in Spider. We only keep the examples for which the generated SQL query correctly executes and does not give a NULL output. An illustration of this process is provided in Figure 5.\nMultiple novel interpretations in same example. From the data created using the procedures above, we select pairs of examples that have different novel interpretations but use the same database schema. We devise a set of rules using which, given such a pair, we can automatically create a new example that requires understanding both novel interpretations (one from each of the examples in the pair) simultaneously. Figure 3 illustrates such an example. We created a\ntotal of 376 such examples spanning 24 unique combinations of interpretations. We manually reviewed each example to ensure correctness.\nGenerating Conversations. We generate long-form dialogues for a subset of examples in MAGNIFICO. For each database schema used in these examples, we prompt GPT-42 to generate a long conversation between two users of that database. We instruct GPT-4 to introduce the corresponding novel interpretation and its description in a manner that makes it blend naturally into the flow of the conversation at the beginning. We generated a total of 125 unique dialogues, each at least 2000 tokens long. We manually reviewed all generated dialogues to ensure correctness.\nBase Examples. We are only interested in measuring the ability of models to generalize to novel interpretations and not how well they perform on the text-to-SQL semantic parsing task. Hence, for every example in MAGNIFICO with a novel interpretation, we also maintain an example that does not include any novel interpretation form and instead directly states the interpretation as part of the input query. These examples serve as a comparative reference point for our evaluation. We refer to these examples as base examples and measure the performance of all models across all\n2Prompt provided in Figure 19 in the Appendix.\nprompt types on them. An illustration of a base example is shown in Figure 1.\nSummary. Overall, we created 1523 unique examples across 24 interpretations. The forms of interpretations in these examples can be automatically replaced to generate more data at scale. Dataset statistics for MAGNIFICO are provided in Table 2. Additional details on creating MAGNIFICO are provided in Appendix B. Note that each example in MAGNIFICO was manually reviewed by at least one of the authors to ensure correctness."
        },
        {
            "heading": "4 Experimental Setup",
            "text": "In this section, we will discuss the setup for our experiments on MAGNIFICO.3\nModels. We experiment with OpenAI GPT-3.5-Turbo (v0301) (Brown et al., 2020; Ouyang et al., 2022), StarCoder (Li et al., 2023b), LLaMA-7B,13B,30B (Touvron et al., 2023a), Alpaca-7B (Taori et al., 2023), MPT-7B4, MPT-7B-Instruct, RedPajama-7B5, RedPajama-7B-Instruct, and RWKV-14B (Bo, 2021). We additionally experimented with GPT-4 (OpenAI, 2023) and LLaMA-2 (Touvron et al., 2023b), results for which are provided in Appendix C.4. For all models, we decode greedily for a maximum of 128 tokens. To take stock of the basic text-to-SQL semantic parsing capabilities of these models, we show their execution accuracies over the base examples in MAGNIFICO averaged over all interpretations in Figure 6. Some of the results for RWKV-14B and the RedPajama-7B models can be found in Appendix C.\nPrompt. All our experiments are in the in-context learning experimental setup. Our prompt structure\n3We make our code and data available at https://github.com/McGill-NLP/MAGNIFICo.\n4https://www.mosaicml.com/blog/mpt-7b 5https://www.together.xyz/blog/redpajama-models-v1\nlargely follows the Create Table + Select 3 prompt format from Rajkumar et al. (2022) which resulted in the best performance on Spider with OpenAI Codex (Chen et al., 2021). This format provides the CREATE TABLE commands for each table in the schema and displays the values for the top three rows for each table. We experiment with three different prompt settings: (1) \u2018Direct\u2019 is exactly the zero-shot Create Table + Select 3 setting which includes no information about how to interpret the form of the novel interpretation, (2) \u2018Description\u2019 additionally includes a brief, one-line natural language description of the novel interpretation(s), and (3) \u2018Few-shot\u2019 includes 5 input-output examples6 of the novel interpretation instead of the description. We hold out 5 examples for each interpretation from the test sets to maintain consistency in testing across various experimental settings. For experiments with a dialogue in the context, the dialogue is prepended to the Create Table + Select 3 prompt. Examples for each type of prompt are provided in Appendix E.\nMetric. We use a metric called Relative Performance to measure the generalization ability of models towards acquiring novel interpretations. Our metric provides a measure that is relative to the performance of the model on the corresponding base examples:\nRelative Performance = min ( EXNI\nEXbase , 1\n) \u00d7 100\nwhere EXNI is the execution accuracy7 on the examples with novel interpretations from MAGNIFICO and EXbase is the execution accuracy on\n6For multiple novel interpretations in the same example, we include 3 support examples for each novel interpretation.\n7Measure of equivalence between output obtained from executing the generated SQL query and the ground truth output.\nthe corresponding base examples.8 Hence, the higher the Relative Performance, the lower the model\u2019s drop in performance on examples with novel interpretation(s) (relative to base examples), and consequently, the higher its ability to learn novel interpretations."
        },
        {
            "heading": "5 Results and Discussion",
            "text": ""
        },
        {
            "heading": "5.1 Impact of Description and Few-shot Examples",
            "text": "Question: How well can LLMs learn novel interpretations when the interpretation is simply described in an English sentence? And how does it compare against the case when we provide few-shot examples of usage of that interpretation?\nWe compare providing a natural language description of the novel interpretation (\u2018Description\u2019 prompt type) against providing examples of usage of the novel interpretation (\u2018Few-shot\u2019 prompt type). Figure 7 provides the results when the form used to represent the novel interpretation is a plausible English word. The results for foreign and adversarial forms can be found in Figures 16 and 17 in the Appendix.\nMost LLMs exhibit a surprisingly high capability to understand and generalize to novel interpretations from simply the natural language descriptions. This capability seems to increase with model size as GPT-3.5-Turbo and LLaMA-30B outperform all other models while the smallest model, LLaMA-7B, struggles to generalize from just the description. It is also interesting to see the benefit of instruction finetuning (Wang et al., 2023) in learning novel interpretations in-context just from natural language descriptions: the instruction-finetuned models outperform their corresponding base models, often by\n8We only consider interpretations for which the execution accuracy on base examples is at least 5%.\nlarge margins. All models generalize well when a few examples of usage of the novel interpretation are provided."
        },
        {
            "heading": "5.2 Impact of Pre-existing Semantic Interpretation",
            "text": "Question: How much does the existing semantic interpretation of the form denoting the novel interpretation influence the generalization capability of LLMs?\nAs mentioned in \u00a73.1, we experiment with three types of form. We plot the relative performance averaged over the \u2018Description\u2019 and \u2018Few-shot\u2019 prompt types9 in Figure 8.\nWe see a trend of decrease in generalization ability when the pre-existing semantic interpretation of the form steers farther from the intended meaning of the novel interpretation. This shows that LLMs have strong semantic priors that may require targeted approaches to be overcome. Moreover, the fact that LLMs can easily understand novel interpretations when presented in a familiar form (as opposed to completely foreign words) is an interesting finding for potential applications requiring acquisition of novel interpretations in the wild (e.g., conversational agents)."
        },
        {
            "heading": "5.3 Acquiring Novel Interpretations From Long Form Dialogue",
            "text": "We envision a real-life scenario requiring compositional generalization: acquiring novel interpretations introduced in a long form conversation. This may arise in situations such as having a conversation with an AI personal assistant or when we want to condition the outputs of an AI system based\n9We average over the prompt types to improve readability of the figure. The complete figure can be seen in Figure 18 in the Appendix.\non a dialogue history between multiple users. An example is provided in Figure 2. Question: How well can LLMs learn a novel interpretation from its description mentioned briefly within a long-form dialogue?\nWe select 8 interpretations, covering a total of 583 examples from MAGNIFICO, encompassing all four categories. We generate long conversation contexts for each of these examples as described in \u00a73.2. An example of the prompt structure is provided in Figure 22. We experiment with StarCoder and GPT-3.5-Turbo since they are capable of processing more than 2000 tokens of text in-context. The results are provided in Table 3. For ease of comparison, we also state the results with the \u2018Description\u2019 prompt-type for the 8 interpretations considered.\nFor both models, using a foreign form to represent the novel interpretation does not result in much performance difference when the description of the novel interpretation is blended inside a long form dialogue instead of directly stating it. However, when the form is a plausible english word, we see a clear decrease in generalization ability for both models. The decrease is much more significant for StarCoder compared to GPT-3.5-Turbo. This indicates that LLMs may find it difficult to associate a case-specific interpretation with tokens that they are already familiar with when used in long conversations. It is possible that the models do not pay much attention to that aspect of the conversation as it might seem more \u2018normal\u2019 compared to the case where a foreign form is used."
        },
        {
            "heading": "5.4 Impact of Position of Description in Context Window",
            "text": "Question: How sensitive are LLMs to the location in the context window that the novel interpretation is described in?\nWe experiment with placing the description at the beginning, middle, or the end of the prompt\nwhen using the \u2018Description\u2019 prompt type. We also experiment with the \u2018Dialogue\u2019 setting by placing the turns of conversation describing the novel interpretation at the beginning, middle, or the end of the dialogue. The results for both experiments are provided in Figure 9. Note that we measure performance relative to the performance when the novel interpretation is described in the end so as to better characterize recency bias.\nWe observe a clear trend of recency bias in both LLMs, where the generalization increases when the interpretation is described nearer to the end of the context window. StarCoder suffers much more variation in performance compared to GPT-3.5-Turbo. The difference in performance between start and end positions for GPT-3.5-Turbo, while comparatively small, is still significant enough to indicate a stronger preference for information presented later in the context."
        },
        {
            "heading": "5.5 Composing Multiple Novel Interpretations",
            "text": "Question: Are LLMs able to simultaneously learn multiple novel interpretations used compositionally in the same example?\nWe evaluate models on a total of 376 examples that require simultaneously understanding two novel interpretations (see Figure 3 for an example). The results for all models across all three types of form of interpretations using the \u2018Description\u2019 and\n\u2018Few-shot\u2019 prompt types are provided in Figure 10. We notice that all models struggle at learning multiple novel interpretations in the same example compared to learning just one novel interpretation. GPT-3.5-Turbo is the best performing model, significantly outperforming StarCoder while the rest of the models show nearly trivial performance. The difference in performance between \u2018description\u2019 and \u2018few-shot\u2019 prompt types for foreign form suggests that models have a comparatively harder time composing interpretations when they are presented individually in separate examples in the prompt."
        },
        {
            "heading": "5.6 Learning Novel Interpretations of Phrases",
            "text": "Question: Are LLMs able to learn novel interpretations when they are denoted by more than a single word?\nWe defined 6 interpretations denoted by phrases of plausible English words in MAGNIFICO, amounting to a total of 279 examples (see Figure 3 for an example). The results of evaluation over these examples are provided in Figure 11.\nWe notice that LLaMA, StarCoder, and GPT-3.5-Turbo models show a surprisingly high ability to learn the novel interpretation from just the description. It is even more surprising to see both MPT-7B models struggle since they comparatively excelled for single-word form interpretations (see Figure 7). This shows that the task of learning novel interpretations denoted by multiword phrases is not simply an extension of learning single-word form interpretations, but a separate task that presents its own set of challenges. Lastly, it is interesting to see that contrary to expectations, StarCoder outperforms GPT-3.5-Turbo in both prompt settings."
        },
        {
            "heading": "6 Final Remarks",
            "text": "We studied the ability of LLMs to interpret new words and phrases in-context using their description or a few demonstrations. We also extended this study to a realistic scenario: understanding userdefined interpretations from long form dialogue.\nOur results indicate that current LLMs can, to an extent, acquire novel interpretations from diverse forms of context. However, interpreting unfamiliar words or multiple novel words simultaneously still poses a significant challenge for existing LLMs. These tasks can serve as a measure to evaluate the compositional generalization abilities of future LLMs in practical settings.\nIt is interesting to note that instruction finetuning leads to significant improvements in learning from descriptions across three different LLM families. Considering that instruction fine-tuning doesn\u2019t involve acquiring novel semantics, it could be useful to understand why it has this impact.\nIn the past few years, several works (Lake and Baroni, 2018; Kim and Linzen, 2020) showed that sequence models were limited in their ability to generalize to novel words on semantic parsing tasks based on a few examples in the training set. Many specialised methods and approaches (Liu et al., 2021; Chen et al., 2020) were designed to address this problem. It is therefore fascinating to see that contemporary general LLMs are able to generalize to novel words from not only processing a few examples in-context, but also from natural language descriptions and conversations. While a large part of the compositional generalization challenge still remains unsolved, we feel it is important to highlight this paradigm shift. We hope our work paves the way for further studies of practical setups that require LLMs to generalize compositionally."
        },
        {
            "heading": "Acknowledgments",
            "text": "We would like to thank Navin Goyal for initial discussions related to the idea behind this work. We also thank the anonymous reviewers, and our colleagues at Mila and McGill University for helpful discussions and for providing valuable feedback. Arkil is also supported by the Canada Graduate Scholarship \u2013 Master\u2019s (CGS-M) funded by the Natural Sciences and Engineering Research Council of Canada (NSERC)."
        },
        {
            "heading": "Limitations",
            "text": "We created our evaluation suite MAGNIFICO over a single task, text-to-SQL semantic parsing. While semantic parsing is a fundamental task in language processing with general applicability, it would be useful to verify the findings across other tasks and domains. In the future, we aim to incorporate more tasks from diverse domains such as classification to better support our claims.\nThe execution accuracies over base examples in MAGNIFICO are low for smaller models. This results in a higher variance in the results of small models. While we enforce a threshold of minimum 5% accuracy on the base examples for each interpretation to be included in the results, in the future, we shall also include experiments over a task that is more easily solvable by smaller models.\nThe number of data points for some of our experimental settings (such as multiple novel interpretations) is not large. However, note that our study was exploratory in nature and our main focus was on analysing the in-context learning abilities of LLMs for acquiring novel interpretations rather than proposing a general benchmark for evaluating LLMs. Our findings revealed that LLMs face more difficulty when there are multiple novel interpretations in the same example. This motivates us to look more closely at this particular setting in the future and potentially create a challenging benchmark."
        },
        {
            "heading": "Ethics Statement",
            "text": "We have extensively discussed the limitations of our work in the previous section. We use an existing dataset, Spider (Yu et al., 2018), which is publicly available and commonly used in NLP research. We generate additional data by modifying the examples in Spider in a rule-based manner. Since we focus on a text-to-SQL semantic parsing task, there\nare minimal risks and biases associated with our data and we believe that it does not require ethical consideration. We also employed Large Language Models to automatically generate data, and each example of the generated data went through manual verification, ensuring that it does not pose any significant risk. We have discussed the experimental details in Appendix A. The research presented in this paper focuses on analysing the in-context learning abilities of LLMs targeted towards interpreting novel interpretations and we believe that our work does not raise any ethical concerns."
        },
        {
            "heading": "B Additional Information on MAGNIFICO",
            "text": "We provide examples for each of the 18 singleword form and 6 phrase form interpretations in MAGNIFICO in Table 4 and Table 5 respectively."
        },
        {
            "heading": "B.1 Populating Tables with Edge Cases",
            "text": "The metric for evaluating the generated SQL queries in text2SQL benchmarks is execution accuracy, which compares the output of the execution of the generated query with the ground truth. Since we are introducing new interpretations in existing databases, it is possible that the output of the corresponding SQL query is trivial, like printing all values in the Table. Apart from this, it is possible that an incorrect SQL query leads to the groundtruth output because there are no edge case values present in the Table. To handle such cases, we automatically populate the tables by inserting new values that act as edge cases (Zhong et al., 2020)."
        },
        {
            "heading": "C Additional Experimental Results",
            "text": ""
        },
        {
            "heading": "C.1 Performance on Base Examples",
            "text": "The performance of models on base examples in MAGNIFICO can be seen in Figure 12. We found the base text-to-SQL performance of RWKV-14B to be extremely low and hence do not experiment with it in other settings.\nC.2 Impact of Description and Few-Shot Examples\nFigure 7, Figure 16 and Figure 17 illustrate the impact of providing description and few-shot examples of the novel interpretation when the novel interpretation is represented by a plausible, foreign or an adversarial form respectively for all models.\n10https://platform.openai.com/\nC.3 Impact of Pre-existing Semantic Interpretation\nFigure 18 provides the results for all models across all experimental settings."
        },
        {
            "heading": "C.4 Results for LLaMA-2 and GPT-4",
            "text": "The performance of LLaMA-2 and GPT-4 models on base examples in MAGNIFICO can be seen in Figure Figure 13. Their performance across all experimental settings can be seen in Figure 14."
        },
        {
            "heading": "D Additional Related Works",
            "text": ""
        },
        {
            "heading": "Word Acquisition",
            "text": "Lazaridou et al. (2021) analyse the temporal generalization capabilities of LLMs and showed that the perplexity increases when modelling text containing new words. There is also some related work in the domain of grounded language learning. Chevalier-Boisvert et al. (2019) focus on learning a synthetic language which is a subset of English. However, they do not carry out any systematic evaluation focused on word learning. Hill et al. (2021) propose an approach for fast-mapping, i.e.,\nthe ability to bind a novel non-sense word to an object in their RL framework. However, their framework and approach are specifically designed to cater to word learning, while we wish to evaluate the word learning abilities of general NLP models across various NLP tasks. Tsimpoukelli et al. (2021) focus on using frozen pretrained models for learning words that only act as names of objects in images. We wish to study word learning at a broader level, by considering more complex types of words and interpretations."
        },
        {
            "heading": "Compositional Generalization",
            "text": "Many works in the past (Fodor and Pylyshyn, 1988; Hadley, 1994; Fodor and Lepore, 2002; Marcus, 2003; Calvo and Symons, 2014) have argued that artificial neural networks are incapable of exhibiting systematic compositionality. However, recent successes of neural models (Bahdanau et al., 2015; Vaswani et al., 2017; Devlin et al., 2019) across various NLP tasks have revived this debate with a focus on investigating the presence and extent of compositional biases in models.\nLake and Baroni (2018) investigated the compositional generalization abilities of contemporary neural sequence models such as RNNs and LSTMs based on their performance on a synthetic benchmark called \u2018SCAN\u2019. Their conclusions were consistent with past work in that they found neural sequence models generalize poorly when tested on systematically held-out novel combinations of words and phrases. Follow-up work by Kim and Linzen (2020) reached similar conclusions using their semantic parsing benchmark, \u2018COGS\u2019.\nWhile novel word learning has not been explicitly studied in previous compositional generalization literature, some of the experiments carried out by Lake and Baroni (2018) and Kim and Linzen (2020) do implicitly assess the abilities of models to one-shot acquire a novel word. However, the words used in these experiments are of a primitive nature and have a context-independent direct mapping in the output space (for e.g., in SCAN, models simply need to learn to map the input word \u2018jump\u2019 to its corresponding output token \u2018JUMP\u2019). In our work, we broaden the scope to also understand how well models acquire more functional words, i.e., words that act over other words in a context-dependent manner to generate the output (for e.g., consider the interpretation \u2018most-frequent\u2019 represented by the form prevalant in Table 1. The output looks\nvery different for inputs like, \u2018Find the prevalant age of students\u2019 or, \u2018What is the number of students that do not have the prevalant last name?\u2019).\nThere have been many compositional generalization benchmarks proposed in recent years (Keysers et al., 2020; Yanaka et al., 2021), almost all of them illustrating deficiencies of neural models at generalizing compositionally. Many approaches have also been proposed to solve compositional generalization benchmarks (Li et al., 2019; Lake, 2019; Gordon et al., 2020; Chen et al., 2020; Andreas, 2020; Liu et al., 2020; Guo et al., 2020; Akyurek and Andreas, 2021; Conklin et al., 2021; Liu et al., 2021). However, most of these approaches are task-specific and cannot be generally applied for language processing. Moreover, LLMs achieve a very high level of performance on compositional generalization benchmarks based on just a few examples in-context (Drozdov et al., 2023). In this work, we seek to analyse the compositional generalization capabilities of LLMs more realistically, by grounding our evaluation to possible use case scenarios, for e.g. generating SQL queries for user inputs that require understanding novel interpretations from a long conversation context."
        },
        {
            "heading": "E Example Prompts",
            "text": "Figure 19 shows an example of a prompt used to generate a long form dialogue using GPT-4. Figures 20, 21, and 22 show examples for the \u2018Description\u2019, \u2018Few-shot\u2019, and \u2018Dialogue\u2019 prompt types respectively."
        },
        {
            "heading": "INTERPRETATION EXAMPLES",
            "text": ""
        },
        {
            "heading": "System Prompt:",
            "text": "You are DialogueGPT - a tool to generate realistic long-form multi-turn dialogues based on the situation provided."
        },
        {
            "heading": "User Prompt:",
            "text": "You are given a database schema. Examples of the data in each of the tables is provided:\nCREATE TABLE IF NOT EXISTS `departments` ( `DEPARTMENT_ID` decimal(4,0) NOT NULL DEFAULT '0', `DEPARTMENT_NAME` varchar(30) NOT NULL, `MANAGER_ID` decimal(6,0) DEFAULT NULL, `LOCATION_ID` decimal(4,0) DEFAULT NULL, PRIMARY KEY (`DEPARTMENT_ID`) ) /* 3 example rows: SELECT * FROM `departments` LIMIT 3; DEPARTMENT_ID DEPARTMENT_NAME MANAGER_ID LOCATION_ID 10 Administration 200 1700 20 Marketing 201 1800 30 Purchasing 114 1700 */ . . . /* CREATE TABLE IF NOT EXISTS `jobs` ( `JOB_ID` varchar(10) NOT NULL DEFAULT '', `JOB_TITLE` varchar(35) NOT NULL, `MIN_SALARY` decimal(6,0) DEFAULT NULL, `MAX_SALARY` decimal(6,0) DEFAULT NULL, PRIMARY KEY (`JOB_ID`) ) /* 3 example rows: SELECT * FROM `jobs` LIMIT 3; JOB_ID JOB_TITLE MIN_SALARY MAX_SALARY AD_PRES President 20000 40000 AD_VP Administration Vice President 15000 30000 AD_ASST Administration Assistant 3000 6000 */\nGenerate a 20-turn dialogue between two users of this database. Somewhere near the start of the conversation, user1 says that based on the schema, some people are overpaid. In response to user2 asking what user1 means when they say someone is overpaid, user1 will casually mention that according to them, anyone that earns a salary more than 30,000 is overpaid. The rest of the conversation should make no mention of overpaid. The conversation should not include SQL queries.\nFigure 19: Prompt used for generating long form dialogues using GPT-4.\nCREATE TABLE IF NOT EXISTS `departments` ( `DEPARTMENT_ID` decimal(4,0) NOT NULL DEFAULT '0', `DEPARTMENT_NAME` varchar(30) NOT NULL, `MANAGER_ID` decimal(6,0) DEFAULT NULL, `LOCATION_ID` decimal(4,0) DEFAULT NULL, PRIMARY KEY (`DEPARTMENT_ID`) ) /* 3 example rows: SELECT * FROM `departments` LIMIT 3; DEPARTMENT_ID DEPARTMENT_NAME MANAGER_ID LOCATION_ID 10 Administration 200 1700 20 Marketing 201 1800 30 Purchasing 114 1700 */ . . . /* CREATE TABLE IF NOT EXISTS `jobs` ( `JOB_ID` varchar(10) NOT NULL DEFAULT '', `JOB_TITLE` varchar(35) NOT NULL, `MIN_SALARY` decimal(6,0) DEFAULT NULL, `MAX_SALARY` decimal(6,0) DEFAULT NULL, PRIMARY KEY (`JOB_ID`) ) /* 3 example rows: SELECT * FROM `jobs` LIMIT 3; JOB_ID JOB_TITLE MIN_SALARY MAX_SALARY AD_PRES President 20000 40000 AD_VP Administration Vice President 15000 30000 AD_ASST Administration Assistant 3000 6000 */\n-- Using valid SQLite, answer the following questions for the tables provided above.\n-- The word \u2019overpay\u2019 refers to those with salary more than 30000.\n-- what is all the information about overpaid employees hired before April 2, 1995? SELECT\nFigure 20: Example prompt for Create Table + Select 3 where the prompt contains a description of the novel interpretation.\nCREATE TABLE IF NOT EXISTS `regions` ( `REGION_ID` decimal(5,0) NOT NULL, `REGION_NAME` varchar(25) DEFAULT NULL, PRIMARY KEY (`REGION_ID`) ) /* . . .\ncreate table prereq (course_id varchar(8), prereq_id varchar(8), primary key (course_id, prereq_id), foreign key (course_id) references course (course_id)\non delete cascade, foreign key (prereq_id) references course (course_id) )\n/* 3 example rows: SELECT * FROM prereq LIMIT 3; course_id prereq_id 376 130 760 169 403 345 */\n-- Using valid SQLite, answer the following questions for the tables provided above.\n-- on what dates were overpaid employees without the letter m in their first names hired? select hire_date from employees where salary > 30000 and first_name not like '%m%'\n-- give the distinct department ids of departments in which a manager is in charge of one or more overpaid employees? select distinct department_id from employees where salary > 30000 group by department_id , manager_id having count(employee_id) >= 1\n-- find the names of all overpaid instructors in comp. sci. department . select name from instructor where dept_name = 'Comp. Sci.' and salary > 30000\n-- what is all the information about overpaid employees hired before April 2, 1995? SELECT\nFigure 21: Example prompt with few-shot examples for the novel interpretation represented by the plausible form \u2018overpaid\u2019 followed by the query input.\nUser1: Hey, I've been working with this database schema and I wanted to discuss some of the tables and their relationships.\nUser2: Sure, I'm familiar with the schema. What do you want to know?\nUser1: I noticed there's a table for employees with a salary column. Which employees would you consider to be overpaid ?\nUser2: Well, that's subjective and depends on various factors. But for the sake of this conversation, let's say anyone earning a salary more than 30,000 is\noverpaid. What do you want to discuss in relation to the schema? ... /* conversation containing 2000 words */ ...\nUser2: The benefits_enrollment table has a foreign key EMPLOYEE_ID, indicating which employee the benefit enrollment is associated with. It also has columns for the benefit name, enrollment date, and status.\nUser1: Suppose you are given the following schema:\nCREATE TABLE IF NOT EXISTS `regions` ( `REGION_ID` decimal(5,0) NOT NULL, `REGION_NAME` varchar(25) DEFAULT NULL, PRIMARY KEY (`REGION_ID`) ) /* 3 example rows: SELECT * FROM `regions` LIMIT 3; REGION_ID REGION_NAME 1 Europe\\r 2 Americas\\r 3 Asia\\r */ . . . /* 3 example rows: SELECT * FROM `locations` LIMIT 3; LOCATION_ID STREET_ADDRESS POSTAL_CODE CITY STATE_PROVINCE COUNTRY_ID 1000 1297 Via Cola di Rie 989 Roma IT 1100 93091 Calle della Testa 10934 Venice IT 1200 2017 Shinjuku-ku 1689 Tokyo Tokyo Prefecture JP */\nUsing valid SQLite, answer the following question with the corresponding SQL query: what is all the information about overpaid employees hired before April 2, 1995?\nUser2: SELECT\nFigure 22: Example prompt which involves a long form dialogue containing the description of the novel interpretation. Note that the truncated section of the dialogue has over 2000 words."
        }
    ],
    "title": "MAGNIFICO: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations",
    "year": 2023
}