{
    "abstractText": "Due to its growing impact on public opinion, hate speech on social media has garnered increased attention. While automated methods for identifying hate speech have been presented in the past, they have mostly been limited to analyzing textual content. The interpretability of such models has received very little attention, despite the social and legal consequences of erroneous predictions. In this work, we present a novel problem of Distress Identification and Cause Extraction (DICE) from multimodal online posts. We develop a multi-task deep framework for the simultaneous detection of distress content and identify connected causal phrases from the text using emotional information. The emotional information is incorporated into the training process using a zero-shot strategy, and a novel mechanism is devised to fuse the features from the multimodal inputs. Furthermore, we introduce the first-ofits-kind Distress and Cause annotated Multimodal (DCaM) dataset of 20,764 social media posts. We thoroughly evaluate our proposed method by comparing it to several existing benchmarks. Empirical assessment and comprehensive qualitative analysis demonstrate that our proposed method works well on distress detection and cause extraction tasks, improving F1 and ROS scores by 1.95% and 3%, respectively, relative to the best-performing baseline. The code and the dataset can be accessed from the following link: https://www.iitp. ac.in/~ai-nlp-ml/resources.html#DICE.",
    "authors": [
        {
            "affiliations": [],
            "name": "Gopendra Vikram Singh"
        },
        {
            "affiliations": [],
            "name": "Soumitra Ghosh"
        },
        {
            "affiliations": [],
            "name": "Atul Verma"
        },
        {
            "affiliations": [],
            "name": "Chetna Painkra"
        },
        {
            "affiliations": [],
            "name": "Asif Ekbal"
        }
    ],
    "id": "SP:d25fc27ce7ad63467a7d35f6ff506cb8620ce582",
    "references": [
        {
            "authors": [
                "Sai Saketh Aluru",
                "Binny Mathew",
                "Punyajoy Saha",
                "Animesh Mukherjee."
            ],
            "title": "Deep learning models for multilingual hate speech detection",
            "venue": "arXiv preprint arXiv:2004.06465.",
            "year": 2020
        },
        {
            "authors": [
                "David Balduzzi",
                "Marcus Frean",
                "Lennox Leary",
                "JP Lewis",
                "Kurt Wan-Duo Ma",
                "Brian McWilliams"
            ],
            "title": "The shattered gradients problem: If resnets are the answer, then what is the question",
            "venue": "In International Conference on Machine Learning,",
            "year": 2017
        },
        {
            "authors": [
                "Pete Burnap",
                "Matthew L Williams."
            ],
            "title": "Us and them: identifying cyber hate on twitter across multiple protected characteristics",
            "venue": "EPJ Data science, 5:1\u201315.",
            "year": 2016
        },
        {
            "authors": [
                "Rui Cao",
                "Roy Ka-Wei Lee",
                "Wen-Haw Chong",
                "Jing Jiang."
            ],
            "title": "Prompting for multimodal hateful meme classification",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 321\u2013332.",
            "year": 2022
        },
        {
            "authors": [
                "Despoina Chatzakou",
                "Nicolas Kourtellis",
                "Jeremy Blackburn",
                "Emiliano De Cristofaro",
                "Gianluca Stringhini",
                "Athena Vakali."
            ],
            "title": "Mean birds: Detecting aggression and bullying on twitter",
            "venue": "Proceedings of the 2017 ACM on web science conference, pages",
            "year": 2017
        },
        {
            "authors": [
                "Tao Chen",
                "Damian Borth",
                "Trevor Darrell",
                "ShihFu Chang"
            ],
            "title": "Deepsentibank: Visual sentiment",
            "year": 2014
        },
        {
            "authors": [
                "Thomas Davidson",
                "Dana Warmsley",
                "Michael Macy",
                "Ingmar Weber."
            ],
            "title": "Automated hate speech detection and the problem of offensive language",
            "venue": "Proceedings of the international AAAI conference on web and social media, pages 512\u2013515.",
            "year": 2017
        },
        {
            "authors": [
                "Jiankang Deng",
                "Jia Guo",
                "Niannan Xue",
                "Stefanos Zafeiriou."
            ],
            "title": "Arcface: Additive angular margin loss for deep face recognition",
            "venue": "Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 4690\u20134699.",
            "year": 2019
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "arXiv preprint arXiv:1810.04805.",
            "year": 2018
        },
        {
            "authors": [
                "Paul Ekman."
            ],
            "title": "An argument for basic emotions",
            "venue": "Cognition & emotion, 6(3-4):169\u2013200.",
            "year": 1992
        },
        {
            "authors": [
                "Mai ElSherief",
                "Vivek Kulkarni",
                "Dana Nguyen",
                "William Yang Wang",
                "Elizabeth Belding."
            ],
            "title": "Hate lingo: A target-based linguistic analysis of hate speech in social media",
            "venue": "Proceedings of the International AAAI Conference on Web and Social Media,",
            "year": 2018
        },
        {
            "authors": [
                "Elisabetta Fersini",
                "Francesca Gasparini",
                "Giulia Rizzi",
                "Aurora Saibene",
                "Berta Chulvi",
                "Paolo Rosso",
                "Alyssa Lees",
                "Jeffrey Sorensen."
            ],
            "title": "Semeval-2022 task 5: Multimedia automatic misogyny identification",
            "venue": "Proceedings of the 16th International Workshop",
            "year": 2022
        },
        {
            "authors": [
                "Paula Fortuna",
                "S\u00e9rgio Nunes."
            ],
            "title": "A survey on automatic detection of hate speech in text",
            "venue": "ACM Computing Surveys (CSUR), 51(4):1\u201330.",
            "year": 2018
        },
        {
            "authors": [
                "Antigoni Maria Founta",
                "Despoina Chatzakou",
                "Nicolas Kourtellis",
                "Jeremy Blackburn",
                "Athena Vakali",
                "Ilias Leontiadis."
            ],
            "title": "A unified deep learning architecture for abuse detection",
            "venue": "Proceedings of the 10th ACM conference on web science, pages 105\u2013",
            "year": 2019
        },
        {
            "authors": [
                "Antigoni Maria Founta",
                "Constantinos Djouvas",
                "Despoina Chatzakou",
                "Ilias Leontiadis",
                "Jeremy Blackburn",
                "Gianluca Stringhini",
                "Athena Vakali",
                "Michael Sirivianos",
                "Nicolas Kourtellis"
            ],
            "title": "Large scale crowdsourcing and characterization of twitter abusive",
            "year": 2018
        },
        {
            "authors": [
                "Shreyansh Gandhi",
                "Samrat Kokkula",
                "Abon Chaudhuri",
                "Alessandro Magnani",
                "Theban Stanley",
                "Behzad Ahmadi",
                "Venkatesh Kandaswamy",
                "Omer Ovenc",
                "Shie Mannor"
            ],
            "title": "Image matters: scalable detection of offensive and non-compliant content/logo",
            "year": 2019
        },
        {
            "authors": [
                "Soumitra Ghosh",
                "Asif Ekbal",
                "Pushpak Bhattacharyya."
            ],
            "title": "A multitask framework to detect depression, sentiment and multi-label emotion from suicide notes",
            "venue": "Cognitive Computation, 14(1):110\u2013 129.",
            "year": 2022
        },
        {
            "authors": [
                "Soumitra Ghosh",
                "Asif Ekbal",
                "Pushpak Bhattacharyya."
            ],
            "title": "A multitask framework to detect depression, sentiment and multi-label emotion from suicide notes",
            "venue": "Cogn. Comput., 14(1):110\u2013129.",
            "year": 2022
        },
        {
            "authors": [
                "Soumitra Ghosh",
                "Swarup Roy",
                "Asif Ekbal",
                "Pushpak Bhattacharyya."
            ],
            "title": "Cares: Cause recognition for emotion in suicide notes",
            "venue": "European Conference on Information Retrieval, pages 128\u2013136. Springer.",
            "year": 2022
        },
        {
            "authors": [
                "Lin Gui",
                "Dongyin Wu",
                "Ruifeng Xu",
                "Qin Lu",
                "Yu Zhou."
            ],
            "title": "Event-driven emotion cause extraction with corpus construction",
            "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1639\u20131649, Austin,",
            "year": 2016
        },
        {
            "authors": [
                "Xiaochuang Han",
                "Jacob Eisenstein."
            ],
            "title": "Unsupervised domain adaptation of contextualized embeddings for sequence labeling",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
            "year": 2019
        },
        {
            "authors": [
                "Devamanyu Hazarika",
                "Soujanya Poria",
                "Amir Zadeh",
                "Erik Cambria",
                "Louis-Philippe Morency",
                "Roger Zimmermann."
            ],
            "title": "Conversational memory network for emotion recognition in dyadic dialogue videos",
            "venue": "Proceedings of the 2018 Conference of the",
            "year": 2018
        },
        {
            "authors": [
                "Ming Shan Hee",
                "Roy Ka-Wei Lee",
                "Wen-Haw Chong."
            ],
            "title": "On explaining multimodal hateful meme detection models",
            "venue": "Proceedings of the ACM Web Conference 2022, pages 3651\u20133655.",
            "year": 2022
        },
        {
            "authors": [
                "Mandar Joshi",
                "Danqi Chen",
                "Yinhan Liu",
                "Daniel S. Weld",
                "Luke Zettlemoyer",
                "Omer Levy."
            ],
            "title": "SpanBERT: Improving pre-training by representing and predicting spans",
            "venue": "Transactions of the Association for Computational Linguistics, 8.",
            "year": 2020
        },
        {
            "authors": [
                "Md Karim",
                "Sumon Kanti Dey",
                "Tanhim Islam",
                "Bharathi Raja Chakravarthi"
            ],
            "title": "Multimodal hate speech detection from bengali memes and texts. arXiv preprint arXiv:2204.10196",
            "year": 2022
        },
        {
            "authors": [
                "Md Rezaul Karim",
                "Bharathi Raja Chakravarthi",
                "John P McCrae",
                "Michael Cochez."
            ],
            "title": "Classification benchmarks for under-resourced bengali language based on multichannel convolutional-lstm network",
            "venue": "2020 IEEE 7th International Conference on Data",
            "year": 2020
        },
        {
            "authors": [
                "Douwe Kiela",
                "Hamed Firooz",
                "Aravind Mohan",
                "Vedanuj Goswami",
                "Amanpreet Singh",
                "Pratik Ringshia",
                "Davide Testuggine."
            ],
            "title": "The hateful memes challenge: Detecting hate speech in multimodal memes",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2020
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Jimmy Ba."
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.",
            "year": 2015
        },
        {
            "authors": [
                "Tao Lei",
                "Regina Barzilay",
                "Tommi Jaakkola."
            ],
            "title": "Rationalizing neural predictions",
            "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 107\u2013117.",
            "year": 2016
        },
        {
            "authors": [
                "Liunian Harold Li",
                "Mark Yatskar",
                "Da Yin",
                "Cho-Jui Hsieh",
                "Kai-Wei Chang."
            ],
            "title": "Visualbert: A simple and performant baseline for vision and language",
            "venue": "arXiv preprint arXiv:1908.03557.",
            "year": 2019
        },
        {
            "authors": [
                "Bing Liu",
                "Ian Lane."
            ],
            "title": "Attention-based recurrent neural network models for joint intent detection and slot filling",
            "venue": "arXiv preprint arXiv:1609.01454.",
            "year": 2016
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized BERT pretraining approach",
            "venue": "CoRR, abs/1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Jiasen Lu",
                "Dhruv Batra",
                "Devi Parikh",
                "Stefan Lee."
            ],
            "title": "Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks",
            "venue": "Advances in neural information processing systems, 32.",
            "year": 2019
        },
        {
            "authors": [
                "Scott M Lundberg",
                "Su-In Lee."
            ],
            "title": "A unified approach to interpreting model predictions",
            "venue": "Advances in neural information processing systems, 30.",
            "year": 2017
        },
        {
            "authors": [
                "Binny Mathew",
                "Punyajoy Saha",
                "Hardik Tharad",
                "Subham Rajgaria",
                "Prajwal Singhania",
                "Suman Kalyan Maity",
                "Pawan Goyal",
                "Animesh Mukherjee."
            ],
            "title": "Thou shalt not hate: Countering online hate speech",
            "venue": "Proceedings of the international AAAI conference on",
            "year": 2019
        },
        {
            "authors": [
                "Binny Mathew",
                "Punyajoy Saha",
                "Seid Muhie Yimam",
                "Chris Biemann",
                "Pawan Goyal",
                "Animesh Mukherjee."
            ],
            "title": "Hatexplain: A benchmark dataset for explainable hate speech detection",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, pages",
            "year": 2021
        },
        {
            "authors": [
                "Susan McGregor"
            ],
            "title": "Predictive embeddings for hate speech detection on twitter",
            "venue": "EMNLP 2018,",
            "year": 2018
        },
        {
            "authors": [
                "Nedjma Ousidhoum",
                "Zizheng Lin",
                "Hongming Zhang",
                "Yangqiu Song",
                "Dit-Yan Yeung."
            ],
            "title": "Multilingual and multi-aspect hate speech analysis",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th",
            "year": 2019
        },
        {
            "authors": [
                "Soujanya Poria",
                "Navonil Majumder",
                "Devamanyu Hazarika",
                "Deepanway Ghosal",
                "Rishabh Bhardwaj",
                "Samson Yu Bai Jian",
                "Pengfei Hong",
                "Romila Ghosh",
                "Abhinaba Roy",
                "Niyati Chhaya"
            ],
            "title": "Recognizing emotion cause in conversations",
            "year": 2021
        },
        {
            "authors": [
                "Jing Qian",
                "Mai ElSherief",
                "Elizabeth Belding",
                "William Yang Wang."
            ],
            "title": "Hierarchical cvae for fine-grained hate speech classification",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3550\u20133559.",
            "year": 2018
        },
        {
            "authors": [
                "Aneri Rana",
                "Sonali Jha."
            ],
            "title": "Emotion based hate speech detection using multimodal learning",
            "venue": "arXiv preprint arXiv:2202.06218.",
            "year": 2022
        },
        {
            "authors": [
                "Tharindu Ranasinghe",
                "Marcos Zampieri",
                "Hansi Hettiarachchi."
            ],
            "title": "Brums at hasoc 2019: Deep learning models for multilingual hate speech and offensive language identification",
            "venue": "FIRE (working notes), pages 199\u2013207.",
            "year": 2019
        },
        {
            "authors": [
                "Manoel Horta Ribeiro",
                "Pedro H Calais",
                "Yuri A Santos",
                "Virg\u00edlio AF Almeida",
                "Wagner Meira Jr."
            ],
            "title": "Characterizing and detecting hateful users on twitter",
            "venue": "Twelfth international AAAI conference on web and social media.",
            "year": 2018
        },
        {
            "authors": [
                "Manuela Sanguinetti",
                "Fabio Poletto",
                "Cristina Bosco",
                "Viviana Patti",
                "Marco Stranisci."
            ],
            "title": "An italian twitter corpus of hate speech against immigrants",
            "venue": "Proceedings of the eleventh international conference on language resources and evaluation (LREC 2018).",
            "year": 2018
        },
        {
            "authors": [
                "Gopendra Vikram Singh",
                "Mauajama Firdaus",
                "Shruti Mishra",
                "Asif Ekbal"
            ],
            "title": "Knowing what to say: Towards knowledge grounded code-mixed response generation for open-domain conversations",
            "venue": "Knowledge-Based Systems,",
            "year": 2022
        },
        {
            "authors": [
                "Ran Song",
                "Shizhu He",
                "Suncong Zheng",
                "Shengxiang Gao",
                "Kang Liu",
                "Jun Zhao",
                "Zhengtao Yu."
            ],
            "title": "Ontology-guided and text-enhanced representation for knowledge graph zero-shot relational learning",
            "venue": "ICLR 2022 Workshop on Deep Learning on Graphs",
            "year": 2022
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems, 30.",
            "year": 2017
        },
        {
            "authors": [
                "Zeerak Waseem",
                "Dirk Hovy."
            ],
            "title": "Hateful symbols or hateful people? predictive features for hate speech detection on twitter",
            "venue": "Proceedings of the NAACL student research workshop, pages 88\u201393.",
            "year": 2016
        },
        {
            "authors": [
                "Ainur Yessenalina",
                "Yejin Choi",
                "Claire Cardie."
            ],
            "title": "Automatically generating annotator rationales to improve sentiment classification",
            "venue": "Proceedings of the ACL 2010 Conference Short Papers, pages 336\u2013341.",
            "year": 2010
        },
        {
            "authors": [
                "Omar Zaidan",
                "Jason Eisner",
                "Christine Piatko."
            ],
            "title": "Using \u201cannotator rationales\u201d to improve machine learning for text categorization",
            "venue": "Human language technologies 2007: The conference of the North American chapter of the association for computa-",
            "year": 2007
        },
        {
            "authors": [
                "Savvas Zannettou",
                "Barry Bradlyn",
                "Emiliano De Cristofaro",
                "Haewoon Kwak",
                "Michael Sirivianos",
                "Gianluca Stringini",
                "Jeremy Blackburn."
            ],
            "title": "What is gab: A bastion of free speech or an alt-right echo chamber",
            "venue": "Companion Proceedings of the The Web Confer-",
            "year": 2018
        },
        {
            "authors": [
                "Ziqi Zhang",
                "David Robinson",
                "Jonathan Tepper."
            ],
            "title": "Detecting hate speech on twitter using a convolution-gru based deep neural network",
            "venue": "European semantic web conference, pages 745\u2013760. Springer.",
            "year": 2018
        }
    ],
    "sections": [
        {
            "text": "Due to its growing impact on public opinion, hate speech on social media has garnered increased attention. While automated methods for identifying hate speech have been presented in the past, they have mostly been limited to analyzing textual content. The interpretability of such models has received very little attention, despite the social and legal consequences of erroneous predictions. In this work, we present a novel problem of Distress Identification and Cause Extraction (DICE) from multimodal online posts. We develop a multi-task deep framework for the simultaneous detection of distress content and identify connected causal phrases from the text using emotional information. The emotional information is incorporated into the training process using a zero-shot strategy, and a novel mechanism is devised to fuse the features from the multimodal inputs. Furthermore, we introduce the first-ofits-kind Distress and Cause annotated Multimodal (DCaM) dataset of 20,764 social media posts. We thoroughly evaluate our proposed method by comparing it to several existing benchmarks. Empirical assessment and comprehensive qualitative analysis demonstrate that our proposed method works well on distress detection and cause extraction tasks, improving F1 and ROS scores by 1.95% and 3%, respectively, relative to the best-performing baseline. The code and the dataset can be accessed from the following link: https://www.iitp. ac.in/~ai-nlp-ml/resources.html#DICE."
        },
        {
            "heading": "1 Introduction",
            "text": "The exponential expansion of microblogging sites and social media not only empowers free expression and individual voices, but also allows individuals to exhibit anti-social conduct (ElSherief et al., 2018), such as cyberbullying, online rumours, and\n[*] These authors contributed equally to this work and are the joint first authors.\nspreading hate remarks (Ribeiro et al., 2018). Abusive speech based on race, religion, and sexual orientation is becoming more common (Karim et al., 2020). Automatic identification of hate speech and raising public awareness are critical tasks (Karim et al., 2020). Manually evaluating and validating a large volume of web information, on the other hand, is time-consuming and labor-intensive.\nModern language models excel over traditional machine learning and neural network-based approaches but lack transparency in output transformation, posing limitations in domains, such as the military, medical research, and internet content monitoring. Robust models for monitoring distressed content online require multimodal inputs. In our \"DCaM\" dataset, Figure 1 highlights the significance of multimodality and span annotations in comprehending distress content. While both posts are labeled as \"distressed,\" the first post may not offer sufficient information based on textual content alone. However, the second post, with both picture and text, provides clarity, and the span annotation aids in analyzing the manifestation of distress.\nThis necessitates a shift in viewpoint away from performance-based models and toward interpretable models. We address model explainability by jointly learning the target classification of a multimodal social media post as Distressed or Non-\ndistressed and extracting the reasons for the classification decision (for the Distressed class) from the textual input. The prime focus of this study is to comprehend the causes associated with any form of offensive content (hate, offensive, abusive, etc.). We club all the connotations of offensive content under the category distressed.\nThe main contributions are summarized below:\n1. We propose the novel task of Unified Distress Identification and Cause Extraction (DICE) from multimodal online posts.\n2. We develop a multi-task deep framework for the simultaneous detection of distress content and identify connected causal phrases from the text using emotional information.\n3. We devise a zero-shot strategy to dynamically incorporate emotional information into training and propose a novel fusion mechanism to infuse the features of multimodal inputs.\n4. The first Distress and Cause annotated Multimodal (DCaM) corpus is created consisting over 20,764 social media posts.\n5. Resources are open-sourced to aid research.\nThe rest of the paper is organized as follows. Section 2 summarises some previous works in this area. We discuss the dataset preparation in Section 3. Section 4 addresses our proposed methodology in depth, followed by the results and analysis in Section 5. Finally, we conclude our discussion in Section 6 and define the scope of future work."
        },
        {
            "heading": "2 Related Work",
            "text": "Several approaches have been suggested to identify online hate speech (Burnap and Williams, 2016; Zhang et al., 2018; Qian et al., 2018). The current interest in hate speech research has led to the availability of datasets in several languages (Sanguinetti et al., 2018; Ousidhoum et al., 2019) and different computational ways to counteract online hate (Mathew et al., 2019; Aluru et al., 2020). Text-, user-, and network-based traits and characteristics that identify bullies have been extracted in (Chatzakou et al., 2017). Deep learning Lundberg and Lee (2017); Founta et al. (2019) has been used extensively to identify hate speech keyword identification, sexism, bullying, trolling, and racism.\nRecent research on identifying hate speech has made use of deep learning techniques, including neural networks (Han and Eisenstein, 2019) and\nword embedding techniques (McKeown and McGregor, 2018). Recent models based on Transformers (Vaswani et al., 2017) have had extraordinary success. Since this is essentially a classification problem, BERT (Bidirectional Encoder Representations from Transformers) (Devlin et al., 2018) has found widespread use in the field of hate speech identification. Ranasinghe et al. (2019) showed that a BERT-based model performed better than models based on recurrent neural networks (RNNs). Zaidan et al. (2007) first proposed the use of rationales, where human annotators highlight text that supports their classification decision. This work was enhanced by Yessenalina et al. (2010) to provide self-generating rationales. An encodergenerator system for quality rationales without annotations was presented in Lei et al. (2016). Mathew et al. (2021) used dataset rationales to fine-tune BERT to address bias and explainability.\nRecent research has shifted towards accommodating multimodal content, with a focus on detecting hate speech and objectionable material in various media. Gandhi et al. (2019) developed a computer vision-based technique for identifying offensive and non-offensive images in large datasets. Kiela et al. (2020) introduced a novel challenge for multimodal hate speech detection in Facebook memes. Rana and Jha (2022) employed the Hate Speech Recognition Video Dataset to identify emotion-based hate speech in a multimodal context. Karim et al. (2022) presented a dataset for detecting hate speech in Bengali memes and text. Fersini et al. (2022) discussed SemEval-2022 Task 5, focusing on identifying misogynous memes through text and images, including sub-tasks for recognizing misogynous content and categorizing types of misogyny. Hee et al. (2022) investigated multimodal hateful meme detection models and their ability to capture derogatory references in both images and text. Additionally, Cao et al. (2022) introduced PromptHate, a model that leverages pretrained language models with specific prompts and examples for hateful meme classification.\nEven though multimodal studies on offensive content have gotten a lot of attention, this study is the first to look at how to find distressed content on social media and figure out what caused it. Additionally, this work presents the first Distress and Cause annotated Multimodal (DCaM) corpus of social media posts to the research community."
        },
        {
            "heading": "3 Dataset",
            "text": "We discuss the data collection and annotation details in the following subsections."
        },
        {
            "heading": "3.1 Data Collection",
            "text": "We collect our dataset from sources where previous studies (Davidson et al., 2017; Zannettou et al., 2018; Mathew et al., 2021) on hate speech have been conducted: Twitter and Gab1. The data was scraped from the top 5 trending topics on Twitter using selenium2 to reduce the effects of sample bias. As for Twitter, we selected the top 10 percent of all collected tweets between October 2022 and December 2022. Using the textual mode of scraped tweets, we generated a list of the most frequent words, which we then used as tags to gather the posts from Gab. Please refer to Appendix Section A.1 for details on data collection from Gab, including keywords used for the DCaM dataset (see Table 8). To compile this data, we scoured Gab for posts between November and December 2022. Posts that have been deleted and reposted are not considered. We also remove links from posts to ensure that annotators can access all relevant information. A number of distress datasets are compared in Table 1."
        },
        {
            "heading": "3.2 Data Annotation",
            "text": "To ensure the dataset consists of only English posts, we used the TextBlob library for language detection and included only those identified as English. Additionally, non-English posts were flagged and excluded during annotation. Annotators were informed about the presence of hate or offensive content beforehand. Annotation guidelines3 from Poria et al. (2021); Ghosh et al. (2022c) were provided to assist annotators in understanding the classification and span annotation tasks. Each post was annotated\n1https://twitter.com/, https://gab.com/ 2https://pypi.org/project/selenium/ 3The annotation guidelines are discussed in Section A.2 of\nthe Appendix\nby five annotators4 (DI task), and then majority voting was applied to decide the final label.\nThere are two kinds of annotations in our dataset. First, whether the post is Distressed or Nondistressed post. Second, if the text is considered as Distressed by majority of the annotators, we ask the annotators to highlight parts of the text that include terms that might be a plausible basis for the provided annotation. These span annotations help us to delve further into the manifestations of hatred or offensive speech.\nFor the Distressed Identification task, the Krippendorff\u2019s \u03b1 for the inter-annotator agreement is 0.66 which is much higher than other hate speech\n42 Ph.D. Linguistics degree holders, 2 Ph.D. students, and 1 Undergraduate student from the Computer Science discipline\ndatasets (Ousidhoum et al., 2019; Mathew et al., 2021). Following the work in (Poria et al., 2021; Ghosh et al., 2022c), we marked at most 3 causal spans for a distressed post in the dataset. The final causal span is marked using the span-level aggregation approach detailed in (Gui et al., 2016). We use the macro-F1 measure to assess inter-rater agreement based on previous work on span extraction (Poria et al., 2021; Ghosh et al., 2022c), and achieve an F1-score of 0.73, suggesting that the annotations are of high quality. Table 2 contains further information about the dataset obtained. Figure 2 shows samples of our dataset. The average number of tokens highlighted per distressed post is 8.55, and the average token per post is 25.43."
        },
        {
            "heading": "4 Methodology",
            "text": "In this section, we illustrate our proposed DICE framework, which is a multitask system for Depression Identification and Cause Extraction from multimodal social media posts. The system employs a zero-shot strategy to dynamically incorporate emotional information into training and presents a novel fusion mechanism to infuse the features from the multimodal inputs. The overall architecture of the proposed method is shown in Figure 3a."
        },
        {
            "heading": "4.1 Problem Formulation",
            "text": "Given a post P = [s1, \u00b7 \u00b7 \u00b7 si \u00b7 \u00b7 \u00b7 , sp] composed of a sequence of sentences (s), and each utterance can be further decomposed into a sequence of words. p indicates the number of sentences in the post. The objective is to determine if the post is distressed or not (0 or 1) and to extract every plausible causal span that supports the prediction.\n4.2 Proposed DICE Framework\nTextual Encoder. Our textual encoder uses BERT followed by an ontology-based word graph. BERT extracts local information from a text. Ontology is the backbone of knowledge graphs (KGs) (Song et al., 2022), which give meta-data descriptions to guide the creation and completion of knowledge graphs. Additionally, relation descriptions contain semantic information that can be used to represent relations. During Graph Neural Network (GNN) message transmission, we embed text within ontology nodes. First, all the nodes are embedded using node embedding and text embedding as follows:\nho = hoWEo and ht = N\u2211\nn=1\nxiWEt (1)\nwhere WEt is word text embedding (BERT), WEo is graph embedding, xi depicts a node (representing a word). ho is a concept in ontology. Figure 3b illustrates the interaction between the vocab graph and BERT embedding to establish relationships. Our method enriches the text-embedding and graph-embedding space, enabling the identification of previously unseen relationships between graph embeddings of the head and tail.\nra = N\u2211 n=1 g(h) (2)\nwhere, ra is aggregate relationship, g(*) is aggregate function, and N is neighboring nodes for the missing node.\nImage Encoder. We use ResNet5 to capture facial expressions and visual surroundings for rich emotional indicators from the image in the input post. We separated the embedding dimensions and image data into groups to simplify the problem and make better use of the complete embedding space. Each learner will create a unique distance metric using just a subspace of the original embedding space and a portion of the training data. By segmenting the network\u2019s embedding layer into D consecutive slices, we are able to isolate D unique learners inside the embedding space. After learner solutions converge, we aggregate them to obtain the whole embedding space. The merging is accomplished by recombining the slices of the embedding layer that correspond to the D learners. To ensure uniformity in the embeddings produced by various learners, we then perform fine-grained tuning across the entire dataset. The merged embeddings may be hampered by the gradients, which resemble white noise and would hinder training performance. This is called the \"shattered gradients problem\". To address this, residual weights (Balduzzi et al., 2017) provide the gradients with some spatial structure, which aids in training, as shown in Figure 3b.\nInter-modal Fusion (IMF). The IMF module exchanges information and aligns entities across modalities (text and image) to learn joint intermodality representations. Figure 4 illustrates the mechanism of inter-modal fusion.\nText infused visual features (and vice-versa). We use an external word embedding model to build high-level representations (Ti\u2019) for an image-text\n5https://github.com/josharnoldjosh/ ResNet-Extract-Image-Feature-Pytorch-Python\npair consisting of Ii and Ti. Cross attention is employed to combine the textual and visual features to create the Text infused visual features (TV ). Taking into account the spatial properties of the channel-wise features, the query vectors (Q) are generated by convolution with N*kernels on each channel of Ii and then averaging (avg pooling) the feature maps as illustrated in Figure 4. Similarly, we construct the Visual infused textual features (VT ) by exchanging Ii and Ti. In particular, the key vectors (K) are produced by convolution with N*kernels on each channel of Ii\u2019 and then averaging (average pooling) the feature maps.\nCross-Attention. First, we take the query vector from one modality (say image, I) and the key/value pair from the other (say text, T). To examine how text affects the image vector, we feed the query (Iq) and textual key/value to self-attention (selfAtt(.)).\nIq = Query(I)\nTk, Tv = Key(T ), V alue(T )\nSTA = selfAtt(Tk, Tv, Iq)\n(3)\nWe filter noise from the output of the self-attention using the forget gate (\u03c3) and concatenate it with the linear layer\u2019s residual (c.f. Figure 4).\nGTI = Concat(linear(STI), \u03c3(linear(STI))) (4)\nFinally, we pass the representations of all the modalities (i.e., text, and image) through another self-attention to know how much the image vector will be impacted by text [CrossT I = SA(GTI , Iq)] Please note that bolded I in CrossT I represents the impacted modality (i.e., I). Similarly, we compute CrossIT and concatenate all of them to obtain the cross-attentive multimodal features.\nFinal Fusion. Although, the TV and VT can independently conduct image-text multimodal recognition, to further enhance the model\u2019s performance, we apply self-attention to fuse the two aforementioned feature vectors.\nClass Penalty. The inter-modal fusion unit receives a class penalty value to help the model understand the link between a unified distress label and the input post. This improves the prediction of start and end tokens. The equations below origi-\nnally represent softmax and sigmoid:\nL = \u2212 1 bs bs\u2211 i=1 log expWli+bi\u2211N j=1 exp Wlj+bj (5)\nL = \u2212 1 bs bs\u2211 i=1\n1\nexpWli+bi (6)\nWhere, li \u2208 Rd is the feature of ith sample; bs is batch size; bi and bj denote the bias; and W \u2208 Rd\u2217n denotes the weight matrix. Information extraction tasks are notoriously difficult to find the decision boundary for the start and end markers of a span, and a basic softmax/sigmoid classifier cannot manage this distinction. Some samples may be misclassified due to the classification boundary\u2019s ambiguity. This may require a faster convergence rate. We use the Insightface loss technique (Deng et al., 2019) to normalize the feature li and weight matrices. W to assess feature similarity based on the angle difference by which it maps the vector more closely. To converge the feature, it adds a penalty value x to the angle.\nLu1 = \u2212 1\nbs bs\u2211 i=1 log expa(cos(\u03b8+x))\nexpa(cos(\u03b8+x))+ N\u2211 j=1 expa(cos(\u03b8))\n(7)\nLu2 = \u2212 1\nbs bs\u2211 i=1\n1\nexpa(cos(\u03b8+x))+expa(cos(\u03b8))\n(8)\nwhere Lu1 and Lu2 is updated loss functions for softmax and sigmoid, respectively, \u03b8 denotes the angle between weight W and feature l and a denotes the amplifier function.\nEmotion Features. We consider Ekman\u2019s (Ekman, 1992) emotion classes and initialize them with the BERT (Devlin et al., 2018) vectors to represent their semantic features.\nReconstruction Loss. An auto-encoder reconstructs adjective-noun pair (ANP) features6 and produces latent features while maintaining emotion information in the learned latent space to match label and ANP feature structures. By optimizing the following loss function, the auto-encoder input (A) and output (A\u0302) must be sufficiently close to identify its parameters.\nLre = ||A\u0302(IMF (a, t))\u2212A(IMF (a, t))|| 2\n2\nAlso, optimizing this loss results in lowerdimensional input features and high-accuracy feature reconstruction.\nAdversarial loss. Our objective is to maintain the discriminative capacity of the combined fea-\n6To begin, we employ mid-level semantic representations of ANP features for the creation of an intermediary latent space. When provided with a training image, we opt for the application of the pre-trained ANP detector, DeepSentiBank (Chen et al., 2014) , to extract the ANP feature . To establish a proficient latent space conducive to a concise representation of the original affective features , we embrace the utilization of an auto-encoder model.\nture of the text and visual i.e.A(IMF (a, t)), and combine it with the rich emotional structural data contained in feature \u03d5(lemo). This is accomplished by using an adversarial restriction that seeks to trick a discriminator network D such that the output A(IMF (a, t)) features are as comparable as the ANP features:\nLadv = Ey(logD(h(y))\u2212 Ey(logD(\u03b8(y))\nWhere \u03b8(y) defines the combined feature of text and image i.e. MF (a,t); and h(y) defines the latent feature space. The generator network (autoencoder) minimizes this loss to learn how to generate emotionally rich labels that closely match the ANP features, ensuring accurate label generation.\nZero-shot loss. Suppose \u03b8(x) defines the combined feature of text and image i.e. MF(a,t), and \u03d5lemo) defines the semantic feature of the label. The objective here is to reduce the distance between these two using the following function:\nLzl = ||\u03b8(MF (x)\u2212 \u03d5lemo)||22\nThe zero-shot loss enhances the generation of accurate and emotionally rich labels by aligning the combined feature of text and image with the semantic feature of the emotion classes.\nJoint Loss. The model is trained using a unified loss function defined below:\nLjoint = Ladv + Lzl + Lre\nEmotion Label Prediction. For a given post (text+image), our model will classify the labels using a simple nearest neighbour (NN) search. Let us suppose that the post and labels are fed into the embeddings to obtain \u03b8(MF (a, t)) and \u03d5(lemo).\n||\u03b8(MF (a, t))\u2212 \u03d5(lemo)||22"
        },
        {
            "heading": "4.2.1 Calculation of Final Loss",
            "text": "As illustrated in equation 9, the model is trained using a unified loss function. For both the DI and\nCE tasks, we employ binary cross-entropy loss.\nL = \u2211 \u03c9 W\u03c9L\u03c9 (9)\nHere, \u03c9 represents the two tasks, DI and CE. The weights (W\u03c9) are updated using back-propagation for specific losses for each task."
        },
        {
            "heading": "5 Experiments and Results",
            "text": "This section discusses the results and the analysis. Due to space constraints, we discuss the experimental setup in Section A.3 and the evaluation metrics in Section A.5.1 in the Appendix."
        },
        {
            "heading": "5.1 Baselines",
            "text": "Our framework combines distress identification and cause extraction into a single automated system, utilizing classification and span detection. Due to the lack of suitable multimodal baselines with similar objectives, existing automated systems were used for evaluation. We compare our proposed DICE approach and the presented DCaM dataset against various baselines, including BiRNN-Attn (Liu and Lane, 2016), CNN-GRU (Zhang et al., 2018), BiRNN-HateXplain (Mathew et al., 2021), BERT (Liu et al., 2019a), BERTHateXplain (Mathew et al., 2021), SpanBERT (Liu et al., 2019b), and CMSEKI (Ghosh et al., 2022b). To thoroughly evaluate our approach on multimodal inputs, we employed two widely-used multimodal baselines, ViLBERT CC (Lu et al., 2019) and Visual BERT COCO (Li et al., 2019), to assess the distress identification task in our dataset. We discuss the baselines briefly in Section A.4 of the Appendix."
        },
        {
            "heading": "5.2 Results and Analysis",
            "text": "Table 3 shows the results of the proposed DICE framework on the introduced DCaM dataset. Specifically, we show the modality-varying results\nin Table 3a. The bi-modal (Text+Image) configuration yields the best results, followed by the unimodal network. The textual modality outperforms the others when compared independently, as texts have less background noise than visual sources. For the similar tasks, our results are consistent with prior studies (Hazarika et al., 2018).\nHuman evaluation. A qualitative human review was conducted on 300 randomly selected posts from the test dataset to assess the model\u2019s identified causes. The assessment used three well-defined measurements (Singh et al., 2022), with scores ranging from 0 to 5 based on Fluency, Knowledge Consistency, and Informativeness7. Scores of 0 were given to the most incorrect responses, while the best responses received a score of 5. In Table 3b, it can be seen that, compared to the various baselines, the proposed framework has done well for all the manual evaluation measures. Our suggested approach results in a higher Knowledge Consistency score, ensuring that the extracted causal spans are consistent with annotated causal spans. The Informativeness and Fluency of our proposed framework is likewise of high quality. These results demonstrate our model\u2019s strong ability to understand offensive information and produce results comparable to human annotators.\nComparison with Existing Works. Table 4 demonstrates that CMSEKI is the best-performing baseline, which is not unexpected considering that it grasps the input information using commonsense knowledge from external knowledge sources. However, the DICE model beats CMSEKI on all measures, especially by 1.95% F1 for the DI task and 3 ROS points for the CE task. SpanBERT is the highest-performing baseline that does not employ\n7We discuss the definition of each metric in Appendix A.5.2\nany external information, outperforming other comparable systems. However, it falls short by 2.88% F1 for the DI task and 5 ROS points for the CE task when compared to our DICE framework. Furthermore, the DICE method managed to outperform the sophisticated state-of-the-art multimodal language models, ViL-BERT CC and Visual BERT COCO. The results analysis reveals that BERT, SpanBERT, and BERT-HateXplain exhibit notably lower performance in the task of cause extraction for offensive content. This observation underscores the inherent difficulty that even powerful language models face when it comes to discerning crucial aspects, such as identifying causes, within offensive content.\nAblation Study. To examine the importance of the different modules in DICE framework, we remove the constituent components, one at a time, and report the results in Table 5. Specifically, we conduct five ablation experiments: first, we replace the proposed Inter-modal fusion (IMF) mechanism by linear concatenation to fuse multimodal features ([T+I]-IMF). Next, we independently eval-\nuate the impact of one modality on the other by removing TV and VT one by one. We observe from Table 5 that removing the text-infused visual features (TV) has a more detrimental effect on the system\u2019s performance compared to removing the visual infused text features (VT). Next, we remove DeepSentiBank sahi kya h(DS) alongside IMF ([T+I]-IMF+DS), and, finally, we substitute the proposed IMF, DS and AE mechanism by linear concatenation to fuse multimodal features ([T+I]-IMF+DS+AE). We observe a notable fall in scores when either of these modules is removed from the DICE approach, especially when we remove the IMF+DS+AE module. This establishes that all components of the DICE model developed for multimodal data contribute to the success of the defined tasks in a zero-shot environment.\nTo investigate the significance of the loss functions in DICE, we remove them one by one and report the results in Table 7. In the first ablated model, we remove all three loss functions (i.e., Ladv, Lre, and Lal). We remove the Lre loss function in the second model and the Ladv adversarial function in the third. In the fourth model, we remove Ladv and Lre. When any of these losses is eliminated from DICE, we see a performance decline when compared to the proposed method. The performance drop is the largest (4.73%) when all three losses are eliminated. Clearly, loss functions play a crucial role in training the entire model end-to-end.\nQualitative Analysis. We thoroughly examined the predictions made by the different systems. Consider the examples in Table 6. The top row displays the tokens (or \u2018causes\u2019) that human annotators noted and that they consider representing the causes. for the post being Distressed. The next four rows show the extracted tokens from the various models. We observe that the proposed DICE model correctly categorizes the examples as distressed and also extracts good-quality causal spans. In the second example, we observe that although the SpanBERT model extracts a partial causal span correctly, it assigns the wrong label (Non-distressed). We also analyze the cases where the proposed model performs poorly. In the interest of space, we present the discussion in the Appendix (section A.6)."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this work, we present a novel problem of Distress Identification and Cause Extraction (DICE) from multimodal online posts. We develop a multitask, deep framework for detecting distress content and identifying associated causal phrases from text using emotional information. We devise a zero-shot strategy to dynamically incorporate emotional information into training and propose a novel fusion mechanism to infuse the features of multimodal inputs. Furthermore, we introduce the first Distress and Cause annotated Multimodal (DCaM) corpus, consisting of over 20,764 social media posts. We illustrate the effectiveness of our method by comparing it to several state-of-the-art baselines. When compared to human performance, the present stateof-the-art models perform poorly, which serves to emphasize the difficulty of the task at hand. We believe our work will advance multimodal reasoning and comprehension while also assisting in the resolution of a significant real-world problem."
        },
        {
            "heading": "Limitations and Future Scope",
            "text": "Due to the low prevalence of hate speech on social media (approximately 3% of messages are hateful), (Fortuna and Nunes, 2018)), we scrape posts by searching for hate words to increase the likelihood of encountering hate-offensive content. This may have invited some undesired sampling bias while constructing the dataset. Additionally, emoticons and other non-standard symbols like $ are often used in current online interactions. One potential research direction is to use these neglected visual features of text information to adapt to more realistic settings."
        },
        {
            "heading": "Ethical Consideration",
            "text": "We created our resource using publicly accessible social media postings. We adhered to the data use guidelines and did not infringe on any copyright problems. Our Institutional Review Board also reviewed and approved this research. We make the code and data accessible for research purposes through an appropriate data agreement mechanism."
        },
        {
            "heading": "A Appendix",
            "text": "We discuss the implementation details and present supporting details of the considered baselines and the human evaluation metrics. We also discuss a vivid qualitative analysis that compares our model\u2019s predictions with the best-performing baselines."
        },
        {
            "heading": "A.1 Word characteristics",
            "text": "We generate word clouds to graphically represent the word frequencies that appear more frequently in the Distressed and Non-distressed posts. The\nbigger the term in the visual, the more often it appeared in user descriptions. Figures 5 and 6 show the word clouds generated from the 100 most frequent words of each class. The difference in word choices for the distinct classes is evident from the figures. Table 8 shows some keywords used for crawling posts from Twitter and Gab to develop the DCaM dataset. Initially, we randomly crawled around 5000 posts each for a period of 1 week from both Twitter and Gab and performed topic modeling to fetch the trending topics. We randomly use a subset of these topics to crawl posts for our dataset. From the collected posts, we create a bag of frequently occurring hashtags and use the generated set to crawl further posts. We take care of nonrepetition in the collected posts by maintaining the post IDs. Lastly, to supplement the lack of offensive posts being crawled, we use the synonyms of the words \u2019hate\u2019, and \u2019offensive\u2019 and use them as tags (like for the word \u2019offensive\u2019 an example synonym could be \u2019insult\u2019 and gab URL that can be used: https://gab.com/tags/insult) to extract posts during data scraping."
        },
        {
            "heading": "A.2 Annotation Guidelines",
            "text": "Our annotation guidelines are rooted in the works of (Poria et al., 2021; Ghosh et al., 2022c). The annotators were instructed to identify the set of causal spans that accurately depict the reasons for a post being tagged as distressed given an input post with that label. The annotators annotated a post with the No_cause tag if the cause of the post was latent,\nthat is, if there was no stated causal span. Two human experts\u2014graduate students with adequate task knowledge\u2014annotated every post. We used the union of candidate spans from distinct annotators as the final causal span only when the size of their intersection was at least 50% of the size of the smallest candidate span. A third annotator was brought in if the final span could not be determined from the previous spans. This third annotator was similarly told to choose shorter spans over larger spans where they could adequately depict the reason without losing any information."
        },
        {
            "heading": "A.3 Experimental Setup",
            "text": "We use PyTorch8, a Python-based deep learning package, to develop our proposed model. We conduct experiments with the BERT import from the huggingface transformers 9 package. To establish the ideal value of the additive angle x, which affects performance, five values ranging from 0.1 to 0.5 were examined. The default value for x is 0.30. We set amplification value a as 64. All experiments are carried out on an NVIDIA GeForce RTX 2080 Ti GPU. We conducted a grid search across 200 epochs. We find empirically that our Embedding\n8https://pytorch.org/ 9https://huggingface.co/docs/transformers/\nindex\nsize is 812 bytes. We use Adam (Kingma and Ba, 2015) for optimization. The learning rate is 0.05, and the dropout is 0.5. The auto-latent encoder\u2019s dimension is fixed at 812. The discriminator D consists of two completely linked layers and a ReLU layer and accepts 812-D input features. Stochastic gradient descent has a learning rate of 1e-4 and a weight decay of 1e-3. with a momentum of 0.5. We perform 5 cross-validations of the DCaM dataset for training and testing purposes. We run our experiments for 200 epochs and report the averaged scores after 5 runs of the experiments to account for the non-determinism of Tensorflow GPU operations."
        },
        {
            "heading": "A.4 Baselines",
            "text": "We discuss the details of the considered baselines below. Similar to the DICE approach, to adapt the baselines to our multi-task scenario, we add a linear layer on top of the hidden-states output in the output layer of the CE task to calculate span start and end logits. The output layer for the CE task employs sigmoid activation, in which the threshold value is set at 0.4."
        },
        {
            "heading": "A.4.1 BiRNN-Attention",
            "text": "The only difference between this model and the BiRNN model is the addition of an attention layer (Liu and Lane, 2016) after the sequential layer. In order to further train the attention layer outputs, we calculate the cross entropy loss between the attention layer output and the ground truth attention.\nA.4.2 CNN-GRU Zhang et al. (2018) employed CNN-GRU to achieve state-of-the-art on several hate speech datasets. We add convolutional 1D filters of window sizes 2, 3, and 4, with 100 filters per size, to the existing architecture. We employ the GRU layer for the RNN component and max-pool the hidden layer output representation. This hidden layer is routed via a fully connected layer to yield prediction logits.\nA.4.3 BERT We fine-tune BERT (Liu et al., 2019a) by adding a fully connected layer, with the output corresponding to the CLS token in the input. Next, to add attention supervision, we try to match the attention values corresponding to the CLS token in the final layer to the ground truth attention. This is calculated using a cross-entropy between the atten-\ntion values and the ground truth attention vector, as detailed in (Mathew et al., 2021).\nA.4.4 ViL-BERT CC ViL-BERT CC (Lu et al., 2019) is a variant of the ViL-BERT model that has been pre-trained on the Conceptual Captions (CC) dataset. Conceptual Captions is a large-scale dataset containing imagecaption pairs sourced from the web. By leveraging the rich and diverse data in CC, ViL-BERT CC is designed to understand and generate captions for images, enabling tasks such as image captioning, visual question answering, and image retrieval.\nA.4.5 Visual BERT COCO Visual BERT COCO (Li et al., 2019) is a variant of the Visual BERT model that has been pre-trained on the Common Objects in Context (COCO) dataset. COCO is a widely used dataset for object detection, segmentation, and captioning tasks. By pre-training on COCO, Visual BERT COCO learns to encode visual features and understand the context of images, enabling tasks such as object recognition, image captioning, and visual question answering. Visual BERT COCO enhances the model\u2019s ability to analyze visual content and perform various vision-related tasks."
        },
        {
            "heading": "A.4.6 BiRNN-HateXplain and BERT-HateXplain",
            "text": "We fine-tune the models10 made available by Mathew et al. (2021) on our DCaM dataset by changing the output layers as described earlier to suit our task\u2019s objective."
        },
        {
            "heading": "A.4.7 SpanBERT",
            "text": "SpanBERT (Joshi et al., 2020) follows a different pre-training objective compared to traditional BERT system (e.g. predicting masked contiguous spans instead of tokens) and performs better on question-answering tasks. Following the work in (Ghosh et al., 2022c) where SpanBERT is used to solve a mix of classification and cause extraction tasks, we fine-tune the SpanBERT base model on our DCaM dataset to meet our objective."
        },
        {
            "heading": "A.4.8 Cascaded Multitask System with External Knowledge Infusion (CMSEKI)",
            "text": "We contrast the performance of our model with the state-of-the-art CMSEKI system presented in\n10https://github.com/punyajoy/HateXplain\n(Ghosh et al., 2022b). CMSEKI leverages commonsense knowledge in the learning process to address multiple tasks simultaneously."
        },
        {
            "heading": "A.5 Metric Definitions",
            "text": "The following metrics collectively provide a quantitative assessment of how well our model performs in the task of extracting causal spans for manifestations and determinants."
        },
        {
            "heading": "A.5.1 Evaluation Metrics",
            "text": "\u2022 Full Match (FM): This metric measures the\npercentage of predicted outputs that exactly match the ground truth outputs. In the context of span extraction, it would indicate the proportion of extracted causal spans that are completely correct.\n\u2022 Partial Match (PM): This metric evaluates the similarity between the predicted outputs and the ground truth outputs, but it allows for some degree of variation. It takes into account cases where only a portion of the prediction matches the ground truth. This can be useful when the extracted causal spans are almost correct but might have minor variations.\n\u2022 Hamming Distance (HD): Hamming Distance is a measure of the difference between two strings of equal length. It counts the number of positions at which the corresponding symbols in the two strings are different. In the context of causal extraction, it could represent the number of positions where the predicted and ground truth causal relationships differ.\n\u2022 Jaccard Similarity (JS): Jaccard Similarity is a measure of set similarity that calculates the ratio of the size of the intersection of two sets to the size of their union. In the context of causal extraction, it would assess the similarity between the sets of tokens (or other elements) in the predicted and ground truth sequences.\n\u2022 Ratcliff-Obershelp Similarity (ROS): The ROS is a sequence comparison metric that measures the similarity between two sequences by identifying the common substrings between them. It calculates a similarity score based on the length of the longest common subsequence between the sequences. This metric would quantify how much of the predicted causal spans match the ground truth causal spans in terms of shared subsequence patterns."
        },
        {
            "heading": "A.5.2 Human Evaluation-based Metrics",
            "text": "1. Fluency: This determines whether or not the\nextracted span is fluent and natural. Natural and regular answers get a score of 5, whereas inarticulate ones receive a 0.\n2. Knowledge consistency: This determines whether or not the produced answer has used the appropriate knowledge. If the model generates responses based on irrelevant information, it must get a score of 0, while the selection of pertinent knowledge must receive a score of 5.\n3. Informativeness: This metric is used to assess how informative the produced replies are. Here, a score of 0 means that the replies are uninformative, and a score of 5 means that they are."
        },
        {
            "heading": "A.6 Error Analysis",
            "text": "Although our proposed DICE framework performs well in the majority of the test cases, still there are certain scenarios where it fails to make the correct predictions. We show some sample predictions from the test set in Table 9. In the first two instances, our model is able to partially predict the causal spans; however, in the first example, it fails to categorize the post as Distressed. It is also to be noted that the model extracted span in the second example seems to be more appropriate than the actual annotation by the human annotator. The model rightfully ignores the irrelevant information \u2019Video shows\u2019 and focuses on the relevant action part of the post. This illustrates our model\u2019s strong ability to comprehend offensive reasoning among diverse test cases. In the third and fourth examples, our model fails to extract any relevant cause from the given input. Moreover, in the third example, the model wrongly categorizes the post as Nondistressed. This can be due to the lack of sufficient context that hindered our model\u2019s comprehension ability for the given input."
        }
    ],
    "title": "Standardizing Distress Analysis: Emotion-Driven Distress Identification and Cause Extraction (DICE) in Multimodal Online Posts",
    "year": 2023
}