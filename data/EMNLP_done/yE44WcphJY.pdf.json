{
    "abstractText": "Most of the recent work in leveraging Large Language Models (LLMs) such as GPT-3 for Machine Translation (MT) has focused on selecting the few-shot samples for prompting. In this work, we try to better understand the role of demonstration attributes for the in-context learning of translations through perturbations of high-quality, in-domain demonstrations. We find that asymmetric perturbation of the sourcetarget mappings yield vastly different results. We show that the perturbation of the source side has surprisingly little impact, while target perturbation can drastically reduce translation quality, suggesting that it is the output text distribution that provides the most important learning signal during in-context learning of translations. We propose a method named Zero-Shot-Context to add this signal automatically in Zero-Shot prompting. We demonstrate that it improves upon the zero-shot translation performance of GPT-3, even making it competitive with few-shot prompted translations.",
    "authors": [
        {
            "affiliations": [],
            "name": "Vikas Raunak"
        },
        {
            "affiliations": [],
            "name": "Hany Hassan Awadalla"
        },
        {
            "affiliations": [],
            "name": "Arul Menezes"
        }
    ],
    "id": "SP:bdcc810d810cea6d585f1dcae9e82b2fb005ab75",
    "references": [
        {
            "authors": [
                "Sweta Agrawal",
                "Chunting Zhou",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Marjan Ghazvininejad"
            ],
            "title": "Incontext examples selection for machine translation",
            "year": 2022
        },
        {
            "authors": [
                "Ekin Aky\u00fcrek",
                "Dale Schuurmans",
                "Jacob Andreas",
                "Tengyu Ma",
                "Denny Zhou"
            ],
            "title": "What learning algorithm is in-context learning? investigations with linear models",
            "year": 2022
        },
        {
            "authors": [
                "Rachel Bawden",
                "Fran\u00e7ois Yvon."
            ],
            "title": "Investigating the translation performance of a large multilingual language model: the case of BLOOM",
            "venue": "Proceedings of the 24th Annual Conference of the European Association for Machine Translation, pages 157\u2013170,",
            "year": 2023
        },
        {
            "authors": [
                "Aakanksha Chowdhery",
                "Sharan Narang",
                "Jacob Devlin",
                "Maarten Bosma",
                "Gaurav Mishra",
                "Adam Roberts",
                "Paul Barham",
                "Hyung Won Chung",
                "Charles Sutton",
                "Sebastian Gehrmann"
            ],
            "title": "Palm: Scaling language modeling with pathways",
            "year": 2022
        },
        {
            "authors": [
                "Damai Dai",
                "Yutao Sun",
                "Li Dong",
                "Yaru Hao",
                "Zhifang Sui",
                "Furu Wei."
            ],
            "title": "Why can gpt learn in-context? language models secretly perform gradient descent as meta optimizers",
            "venue": "arXiv preprint arXiv:2212.10559.",
            "year": 2022
        },
        {
            "authors": [
                "Marina Fomicheva",
                "Shuo Sun",
                "Lisa Yankovskaya",
                "Fr\u00e9d\u00e9ric Blain",
                "Francisco Guzm\u00e1n",
                "Mark Fishel",
                "Nikolaos Aletras",
                "Vishrav Chaudhary",
                "Lucia Specia."
            ],
            "title": "Unsupervised quality estimation for neural machine translation",
            "venue": "Transactions of the Association",
            "year": 2020
        },
        {
            "authors": [
                "Markus Freitag",
                "Ricardo Rei",
                "Nitika Mathur",
                "Chi-kiu Lo",
                "Craig Stewart",
                "Eleftherios Avramidis",
                "Tom Kocmi",
                "George Foster",
                "Alon Lavie",
                "Andr\u00e9 F.T. Martins"
            ],
            "title": "Results of WMT22 metrics shared task: Stop using BLEU \u2013 neural metrics are better and more",
            "year": 2022
        },
        {
            "authors": [
                "Xavier Garcia",
                "Yamini Bansal",
                "Colin Cherry",
                "George Foster",
                "Maxim Krikun",
                "Melvin Johnson",
                "Orhan Firat."
            ],
            "title": "The unreasonable effectiveness of fewshot learning for machine translation",
            "venue": "Proceedings of the 40th International Conference on Machine",
            "year": 2023
        },
        {
            "authors": [
                "Tanya Goyal",
                "Junyi Jessy Li",
                "Greg Durrett"
            ],
            "title": "News summarization and evaluation in the era of gpt-3",
            "year": 2022
        },
        {
            "authors": [
                "Amr Hendy",
                "Mohamed Abdelrehim",
                "Amr Sharaf",
                "Vikas Raunak",
                "Mohamed Gabr",
                "Hitokazu Matsushita",
                "Young Jin Kim",
                "Mohamed Afify",
                "Hany Hassan Awadalla"
            ],
            "title": "How good are gpt models at machine translation? a comprehensive evaluation",
            "year": 2023
        },
        {
            "authors": [
                "Armand Joulin",
                "Edouard Grave",
                "Piotr Bojanowski",
                "Tomas Mikolov."
            ],
            "title": "Bag of tricks for efficient text classification",
            "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Pa-",
            "year": 2017
        },
        {
            "authors": [
                "Takeshi Kojima",
                "Shixiang Shane Gu",
                "Machel Reid",
                "Yutaka Matsuo",
                "Yusuke Iwasawa"
            ],
            "title": "Large language models are zero-shot reasoners",
            "year": 2022
        },
        {
            "authors": [
                "Percy Liang",
                "Rishi Bommasani",
                "Tony Lee",
                "Dimitris Tsipras",
                "Dilara Soylu",
                "Michihiro Yasunaga",
                "Yian Zhang",
                "Deepak Narayanan",
                "Yuhuai Wu",
                "Ananya Kumar"
            ],
            "title": "Holistic evaluation of language models. arXiv preprint arXiv:2211.09110",
            "year": 2022
        },
        {
            "authors": [
                "moyer",
                "Zornitsa Kozareva",
                "Mona Diab",
                "Veselin Stoyanov",
                "Xian Li"
            ],
            "title": "Few-shot learning with multilingual generative language models",
            "venue": "In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2022
        },
        {
            "authors": [
                "Xi Victoria Lin",
                "Todor Mihaylov",
                "Mikel Artetxe",
                "Tianlu Wang",
                "Shuohui Chen",
                "Daniel Simig",
                "Myle Ott",
                "Naman Goyal",
                "Shruti Bhosale",
                "Jingfei Du"
            ],
            "title": "Few-shot learning with multilingual language models. arXiv preprint arXiv:2112.10668",
            "year": 2021
        },
        {
            "authors": [
                "Sewon Min",
                "Xinxi Lyu",
                "Ari Holtzman",
                "Mikel Artetxe",
                "Mike Lewis",
                "Hannaneh Hajishirzi",
                "Luke Zettlemoyer"
            ],
            "title": "Rethinking the role of demonstrations: What makes in-context learning work",
            "year": 2022
        },
        {
            "authors": [
                "Vikas Raunak",
                "Arul Menezes",
                "Matt Post",
                "Hany Hassan"
            ],
            "title": "Do GPTs produce less literal translations? In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume",
            "year": 2023
        },
        {
            "authors": [
                "Ricardo Rei",
                "Craig Stewart",
                "Ana C Farinha",
                "Alon Lavie."
            ],
            "title": "COMET: A neural framework for MT evaluation",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2685\u20132702, Online. Association",
            "year": 2020
        },
        {
            "authors": [
                "Ricardo Rei",
                "Marcos Treviso",
                "Nuno M. Guerreiro",
                "Chrysoula Zerva",
                "Ana C Farinha",
                "Christine Maroti",
                "Jos\u00e9 G.C. de Souza",
                "Taisiya Glushkova",
                "Duarte Alves",
                "Luisa Coheur",
                "Alon Lavie",
                "Andr\u00e9 F.T. Martins"
            ],
            "title": "CometKiwi: IST-unbabel 2022",
            "year": 2022
        },
        {
            "authors": [
                "Chau Tran",
                "Shruti Bhosale",
                "James Cross",
                "Philipp Koehn",
                "Sergey Edunov",
                "Angela Fan."
            ],
            "title": "Facebook AI\u2019s WMT21 news translation task submission",
            "venue": "Proceedings of the Sixth Conference on Machine Translation, pages 205\u2013215, Online. Association for",
            "year": 2021
        },
        {
            "authors": [
                "David Vilar",
                "Markus Freitag",
                "Colin Cherry",
                "Jiaming Luo",
                "Viresh Ratnakar",
                "George Foster"
            ],
            "title": "Prompting palm for translation: Assessing strategies and performance",
            "year": 2022
        },
        {
            "authors": [
                "Johannes von Oswald",
                "Eyvind Niklasson",
                "Ettore Randazzo",
                "Jo\u00e3o Sacramento",
                "Alexander Mordvintsev",
                "Andrey Zhmoginov",
                "Max Vladymyrov"
            ],
            "title": "2022. Transformers learn in-context by gradient descent",
            "year": 2022
        },
        {
            "authors": [
                "Sang Michael Xie",
                "Aditi Raghunathan",
                "Percy Liang",
                "Tengyu Ma"
            ],
            "title": "An explanation of in-context learning as implicit bayesian inference",
            "year": 2021
        },
        {
            "authors": [
                "Kang Min Yoo",
                "Junyeob Kim",
                "Hyuhng Joon Kim",
                "Hyunsoo Cho",
                "Hwiyeol Jo",
                "Sang-Woo Lee",
                "Sang-goo Lee",
                "Taeuk Kim."
            ],
            "title": "Ground-truth labels matter: A deeper look into input-label demonstrations",
            "venue": "arXiv.",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Recent work has put into question the importance of the correctness of demonstrations for prompting in Large Language Models (LLMs) (Min et al., 2022). One key conjecture is that the latent zeroshot capabilities of LLMs might be considerably higher than their observed zero-shot capabilities for a range of tasks (Min et al., 2022; Kojima et al., 2022). One way to elicit higher zero-shot performance is to qualify the role of demonstration attributes towards task performance and then simulate such in-context learning signals in a zero-shot manner. However, realizing this goal hinges on explicitly dissecting the role of various demonstration attributes (format, inputs, outputs, input-output mapping) towards task performance within fewshot in-context learning. In this work, we explore these questions for the task of Machine Translation (MT). Our line of inquiry is orthogonal to finding\nthe most useful samples for few shot learning, a topic that has received considerable attention for eliciting better translations from LLMs (Vilar et al., 2022; Agrawal et al., 2022). Our contributions are:\n1. We explore the role of demonstration attributes within in-context learning of translations in the GPT family of LLMs, through perturbations of the input-output (source-target) mappings. We show that the target text distribution is the most important factor in demonstrations, while the source text distribution provides an inconsequential learning signal.\n2. Based on our findings, we propose Zero-ShotContext prompting, which tries to automatically provide the learning signal corresponding to the target text distribution without any source-target examples. This greatly improves GPT-3\u2019s zero-shot performance, even making it competitive with few-shot prompting."
        },
        {
            "heading": "2 Related Work",
            "text": "Our work is related to two key themes, namely prompting LLMs for translation and analysis of in-context learning in LLMs. In this section, we situate our work within these two themes.\nLLM Prompting for MT: LLMs have achieved close to the state-of-the-art translation performance under few-shot prompting (Hendy et al., 2023; Lin et al., 2022). Most of the work for prompting in MT has focused on selecting the training or development instances to be used as examples during prompting. Vilar et al. (2022) experiment on PaLM (Chowdhery et al., 2022) and find that quality of examples is the most important factor in few-shot prompting performance. Agrawal et al. (2022) experiment with XGLM (Lin et al., 2021) and report that translation quality and the domain of the examples are consequential. Our work builds on these with a different aim, in that we do not explore selecting the examples, rather apply perturbations on\nGround Truth Shuffled Targets Jumbled Source Jumbled Target Reversed Target\nhigh-quality, in-domain examples to better qualify the role of certain demonstration attributes for in-context learning of translations.\nAnalyzing In-Context Learning: Theoretical and empirical investigation of in-context learning is an ongoing research endeavor (Xie et al., 2021; von Oswald et al., 2022; Aky\u00fcrek et al., 2022; Dai et al., 2022). Min et al. (2022) demonstrate that label correctness in demonstrations is of limited importance for open-set classification tasks, while Yoo et al. (2022) show that negated labels do matter. Our experiments differ from these works both on the choice of the task (translation, which has an exponential output space) as well as on the types of perturbations applied to the demonstrations."
        },
        {
            "heading": "3 The Role of Demonstration Attributes",
            "text": "To produce outputs for a specific task, LLMs are typically prompted with demonstrations (inputoutput examples pertaining to the specific task) appended with the test input. Similar to Min et al. (2022), we posit that there exist four aspects of demonstrations of the translation task that provide a learning signal: the input-output mapping, the input text distribution, the output text distribution and the format. In this section, we conduct an empirical investigation on how LLMs such as GPT3 leverage the demonstrations provided to them for the task of translation by perturbing the inputoutput (source-target) mappings provided during prompting. Through these experiments, we hope to compare the importance of three key demonstration attributes \u2013 the input text distribution, the output text distribution and their mapping for translation.\nModels: In this section, we mainly report results for text-davinci-002 1, one of the most capable LLM models publically accessible (Liang et al.,\n1LLMs: https://beta.openai.com/docs/models/\n2022). We also investigate the veracity of our observations with text-davinci-001 and text-curie-001, two prior LLM versions in the GPT family as well as the more recent text-davinci-003.\nDatasets: We experiment with the WMT\u201921 News Translation task datasets (Barrault et al., 2021), for the following four language pairs: English-German (En-De), German-English (DeEn), English-Russian (En-Ru) and Russian-English (Ru-En). On each of these datasets text-davinci002 achieves highly competitive performance with the WMT-21 winning NMT model (Tran et al., 2021), with eight demonstrations (k = 8 in kshot prompting). We list the full test set performance with text-davinci-002 and text-davinci-003 for k = 8 in Table 2, while the perturbation experiments are reported on 100 random samples from the test sets in each case.\nPrompt Details: Vilar et al. (2022) report than the choice of the format is inconsequential for fewshot prompting on the translation task. As such, we use the standard prompt used for MT in prior works, namely [Source]: ABC (\\n) [Target]: DEF, where Source (e.g., English) and Target (e.g., German) represent the language names. Further, we use highquality, in-domain sentence pairs sampled from the development set for few-shot prompting.\nEvaluation: To minimize reference-bias in evaluation, which has been shown to be detrimental in\nestimating the LLM output quality in related sequence transduction tasks (Goyal et al., 2022; Garcia et al., 2023; Raunak et al., 2023), we make use of a state-of-the-art Quality Estimation (Fomicheva et al., 2020) metric named COMET-QE (Rei et al., 2020) for quality evaluation. Further, one caveat of using the reference-free metric is that it allocates high scores to a translation if it is in the same language as the source sentence, i.e. it doesn\u2019t penalize copy errors in translation. To mitigate this evaluation shortcoming, we use a language-id classifier (Joulin et al., 2017) and set the translation to empty if the translation is produced in the same language as the source.\nExperiment 1: We apply four perturbations to the demonstrations used for prompting. Table 1 enumerates the four perturbations with abstract source-target sequences: Shuffled Targets (ST) randomizes the mappings between the source and targets in the prompt, Jumbled Source (JS) randomizes the position of the words in the source sentences, Jumbled Ref (JT) randomizes the positions of the words in the target sentences and Reversed Ref (RT) reverses the order of the words in the target sentence. Among these perturbations, ST impacts both the input and output spaces symmetrically, while the other perturbations (JS, JT and RT) perturb only one of the input/output spaces.\nResults: The results of applying these perturbations on En-De are presented in Figure 1, across different number of demonstrations (k = 1, 2, 4, 8). The results show that while ST and JT both significantly disrupt the source-target mappings in the demonstrations, they have greatly different impact.\nTranslation quality declines by a large value for JT, an effect that becomes larger with increasing k, e.g., for JT perturbation at k = 8, the translation quality is considerably worse. On the other hand, JS produces very little to no effect on the quality of translations. Further, owing to the nature of the perturbation ST becomes more disruptive at higher values of k, while yielding no impact for k = 1.\nExperiment 2: We repeat the same experiment as above (Experiment 1) with four different language pairs from WMT-21 and text-davinci-002.\nResults: The results are reported in Figure 2. We find that the trends are similar to the first experiment (Figure 1). Across the language pairs, JS and JT have asymmetric impact on translation quality, showing that in each case the critical learning signal arrives from the target text distribution, while the source text distribution is an inconsequential factor with respect to the output translation quality.\nExperiment 3: We repeat Experiment 2, by keeping the language pair fixed to En-De and varying the LLMs. We report results in Figure 3 for three other models from the GPT family, namely textcurie-001, text-davinci-002 and text-davinci-003.\nResults: We find that across different models, JS and JT have asymmetric impact on the translation quality, consistent with the prior two experiments.\nAnalysis: Compared to Min et al. (2022), wherein the randomization of the input-output mappings in the demonstrations leads to better performance than no demonstrations (zero-shot prompting) for open-set classification tasks, our results\nare quite different. We find that depending on the type of perturbation, in-context translation learning results can be vastly different even when all the perturbations break the correct input-output mapping. For some perturbations (e.g., JT and RT) the translation quality is much worse than zero-shot. To reconcile these results, we hypothesize that the difference arises from the increased complexity of the auto-regressive search in the case of translation, i.e., a clear specification of the output space in the demonstrations becomes much more critical to constrain the search space.\nFurther, the ST results in Figures 2 & 3 show that source-target mapping is also a critical demonstration attribute, a fact consistent with prior results emphasizing the importance of example quality (Vilar et al., 2022; Agrawal et al., 2022). However, we show that it is not the primary learning signal in incontext learning of translations and even therein the source word order matters for little, suggesting that only an approximation of the input text distribution is sufficient for effective in-context learning.\nGenerality of Our Findings: We also conduct experiments on gpt-3.5-turbo-instruct and gpt-3.5turbo-instruct-0914, two of the more recent LLMs in the GPT family. With gpt-3.5-turbo-instruct on En-De, no perturbation (None in the plots) obtains a COMET-QE score of 34.21, the JS perturbation a score of 35.20 and the JT perturbation obtains a score of 25.45. Similarly, with gpt-3.5-turboinstruct-0914 on En-De, no perturbation obtains a COMET-QE score of 33.64, the JS perturbation a score of 34.35 and the JT perturbation obtains a score of 24.42. This observed behavior is agnostic\nto the choice of the MT quality metric as well: with COMET-KIWI (the state-of-the-art QE metric in the WMT-22 Quality Estimation Shared Task (Rei et al., 2022)), no perturbation (None in the plots) with gpt-3.5-turbo-instruct obtains a score of 83.75, the JS perturbation a score of 83.94 and the JT perturbation obtains a score of 73.26. Similarly, with COMET-KIWI gpt-3.5-turbo-instruct-0914 obtains a score of 83.94, the JS perturbation a score of 83.85 and the JT perturbation obtains a score of 72.72. These results point to the robustness of our findings.\nImplications: Our findings suggest that the data representing the output space might be the most important attribute in demonstrations for in-context learning of translations. Besides suggesting an in-built robustness towards perturbations on the source side, this result points to interesting exploratory directions for data selection for prompting, e.g., that target-original data might be more useful as demonstration examples than sourceoriginal. We leave such questions to future work."
        },
        {
            "heading": "4 Zero-Shot-Context for Translation",
            "text": "Previously, we demonstrated that the most important demonstration attribute for in-context learning of translations is the output text distribution. In this section, we present a method of providing this learning signal in a zero-shot manner. Our experiment here represents an inverse of experiments in section 3, i.e., here we add a useful learning signal to zero-shot prompting, rather removing learning signals from few-shot prompting to gauge their importance. We present a method named \u2018Zero-ShotContext\u2019 and show that it greatly improves upon zero-shot performance for GPT-3, eliciting performance competitive even with few-shot prompting. Note that this method is one example of adding a particular signal in zero-shot prompting and that there could be multiple ways to add such a signal to bolster zero-shot performance including direct instruction finetuning on the translation task. However, we leave a thorough analysis of improving zero-shot translation performance by adding relevant signals from demonstrations to future work and focus only exploring on our key hypothesis.\nProposed Method: We propose a new zero-shot prompting method named Zero-Shot-Context (Figure 4), which auto-generates the output space specification learning signal from the LLM itself (the\nContext) and uses it to condition the translation.\nExperiment and Results: In Table 3 we compare Zero-Shot-Context with Zero-Shot prompting, as well as few-shot prompting (for k=1, 2, 4) with high-quality, in-domain examples sampled from the development set, on En-De WMT-21 test set with text-davinci-002. The results show that Zero-Shot-Context greatly improves upon ZeroShot translation quality as measured by COMETQE (CQE). Note that the gains are not visible in reference-based evaluation with BLEU and ChrF and limitations of these metrics have been pointed our in the literature (Freitag et al., 2022). Table 4 presents a comparison on the WMT-21 En-Ru test set.\nAblation on Zero-Shot Context: We consider the following experiment: we pick a random targetside sentence from the development set and replace\nthe Context-Generation step\u2019s output with the random target-side sentence. Ideally, an in-domain, high-quality target-side sentence should also be able to provide a learning signal regarding the output text distribution. We find that this is indeed the case, and simply replacing the context generation step with the random target-side sentence also improves upon zero-shot performance, achieving 36.10 COMET-QE score for WMT-21 En-De test set and 37.86 COMET-QE score for WMT-21 En-Ru. However, these scores are lower than ZeroShot-Context, suggesting that the contextual nature of Zero-Shot-Context is also important.\nFurther Analysis: Our findings indicate that the latent zero-shot GPT-3 performance for translations could indeed be higher than currently reported and that it is possible to leverage direct computation to improve LLM translation performance instead of manually retrieving or selecting examples. In particular, we showed that a simple addition of a signal pertaining to the output space improved the zero-shot performance of text-davinci-002, a useful step towards better zero-shot utilization of LLMs for translation. As pointed out in Bawden and Yvon (2023), generating zero-shot translations often suffers from outputs in the wrong language and we find that Zero-Shot-Context considerably alleviates this, leading to better performance. However, further rigorous analysis of this phenomenon across different LLMs is hindered by the fact that we do not have access to the training or the instruction finetuning dataset used for the underlying state-of-the-art LLMs."
        },
        {
            "heading": "5 Summary and Conclusions",
            "text": "We analyzed the relative importance of demonstration attributes as learning signals within few-shot in-context learning of translations in LLMs from the GPT family. We demonstrated that the critical learning signal arrives from the output text distribution, followed by the input-output mapping, while the input text distribution matters for little. We use this finding to propose Zero-Shot-Context, a method that tries to automatically generate the critical learning signal. Zero-Shot-Context greatly improves upon zero-shot translation quality in GPT3, further validating our findings. We hope that our work could serve as a useful contribution towards better understanding of in-context learning of translations in LLMs."
        },
        {
            "heading": "6 Limitations",
            "text": "Our work experiments with high-quality, indomain examples for few-shot prompting. It is conceivable that perturbations could have different impacts on examples with varying quality. Also, while our proposed zero-shot method does not consume any manual examples, it suffers from the limitation that it involves two passes over a LLM. While this is mitigated by the method presented as an ablation, we believe that simpler methods to add the relevant demonstration signal could be derived by pre-computing the singular target-side context once for the entire test set, a proposal we didn\u2019t investigate."
        }
    ],
    "title": "Dissecting In-Context Learning of Translations in GPTs",
    "year": 2023
}