{
    "abstractText": "Evaluating the factual consistency of automatically generated summaries is essential for the progress and adoption of reliable summarization systems. Despite recent advances, existing factuality evaluation models are not robust, being especially prone to entity and relation errors in new domains. We propose FACTKB\u2014a simple new approach to factuality evaluation that is generalizable across domains, in particular with respect to entities and relations. FACTKB is based on language models pretrained using facts extracted from external knowledge bases. We introduce three types of complementary factuality pretraining objectives based on entity-specific facts, facts extracted from auxiliary knowledge about entities, and facts constructed compositionally through knowledge base walks. The resulting factuality evaluation model achieves state-of-the-art performance on two in-domain news summarization benchmarks as well as on three outof-domain scientific literature datasets. Further analysis of FACTKB shows improved ability to detect erroneous entities and relations in summaries and is robust and easily generalizable across domains. Code and data are available at https://github.com/BunsenFeng/FactKB.",
    "authors": [
        {
            "affiliations": [],
            "name": "Shangbin Feng"
        },
        {
            "affiliations": [],
            "name": "Vidhisha Balachandran"
        },
        {
            "affiliations": [],
            "name": "Yuyang Bai"
        },
        {
            "affiliations": [],
            "name": "Yulia Tsvetkov"
        }
    ],
    "id": "SP:b3c25052752302a6737624ea46087a7dccb5e9f4",
    "references": [
        {
            "authors": [
                "Oshin Agarwal",
                "Heming Ge",
                "Siamak Shakeri",
                "Rami Al-Rfou."
            ],
            "title": "Knowledge graph based synthetic corpus generation for knowledge-enhanced language model pre-training",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Asso-",
            "year": 2021
        },
        {
            "authors": [
                "Roee Aharoni",
                "Shashi Narayan",
                "Joshua Maynez",
                "Jonathan Herzig",
                "Elizabeth Clark",
                "Mirella Lapata."
            ],
            "title": "Multilingual summarization with factual consistency evaluation",
            "venue": "Findings of the Association for Computational Linguistics: ACL 2023, pages",
            "year": 2023
        },
        {
            "authors": [
                "Alfonso Amayuelas",
                "Shuai Zhang",
                "Xi Susie Rao",
                "Ce Zhang."
            ],
            "title": "Neural methods for logical reasoning over knowledge graphs",
            "venue": "International Conference on Learning Representations.",
            "year": 2021
        },
        {
            "authors": [
                "Vidhisha Balachandran",
                "Hannaneh Hajishirzi",
                "William Cohen",
                "Yulia Tsvetkov."
            ],
            "title": "Correcting diverse factual errors in abstractive summarization via postediting and language model infilling",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in",
            "year": 2022
        },
        {
            "authors": [
                "Vidhisha Balachandran",
                "Artidoro Pagnoni",
                "Jay Yoon Lee",
                "Dheeraj Rajagopal",
                "Jaime Carbonell",
                "Yulia Tsvetkov."
            ],
            "title": "StructSum: Summarization via structured representations",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Associ-",
            "year": 2021
        },
        {
            "authors": [
                "Jacob Benesty",
                "Jingdong Chen",
                "Yiteng Huang",
                "Israel Cohen."
            ],
            "title": "Pearson correlation coefficient",
            "venue": "Noise reduction in speech processing, pages 1\u20134. Springer.",
            "year": 2009
        },
        {
            "authors": [
                "Abhik Bhattacharjee",
                "Tahmid Hasan",
                "Wasi Uddin Ahmad",
                "Yuan-Fang Li",
                "Yong-Bin Kang",
                "Rifat Shahriyar."
            ],
            "title": "CrossSum: Beyond English-centric cross-lingual summarization for 1,500+ language pairs",
            "venue": "Proceedings of the 61st Annual Meeting of",
            "year": 2023
        },
        {
            "authors": [
                "Steven Bird",
                "Ewan Klein",
                "Edward Loper."
            ],
            "title": "Natural language processing with Python: analyzing text with the natural language toolkit",
            "venue": "\" O\u2019Reilly Media, Inc.\".",
            "year": 2009
        },
        {
            "authors": [
                "Antoine Bordes",
                "Nicolas Usunier",
                "Alberto GarciaDuran",
                "Jason Weston",
                "Oksana Yakhnenko."
            ],
            "title": "Translating embeddings for modeling multirelational data",
            "venue": "Advances in neural information processing systems, 26.",
            "year": 2013
        },
        {
            "authors": [
                "Antoine Bosselut",
                "Ronan Le Bras",
                "Yejin Choi."
            ],
            "title": "Dynamic neuro-symbolic knowledge graph construction for zero-shot commonsense question answering",
            "venue": "Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI).",
            "year": 2021
        },
        {
            "authors": [
                "Isabel Cachola",
                "Kyle Lo",
                "Arman Cohan",
                "Daniel S Weld."
            ],
            "title": "Tldr: Extreme summarization of scientific documents",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 4766\u20134777.",
            "year": 2020
        },
        {
            "authors": [
                "Ziqiang Cao",
                "Furu Wei",
                "Wenjie Li",
                "Sujian Li."
            ],
            "title": "Faithful to the original: Fact aware neural abstractive summarization",
            "venue": "thirty-second AAAI conference on artificial intelligence.",
            "year": 2018
        },
        {
            "authors": [
                "Wenhu Chen",
                "Yu Su",
                "Xifeng Yan",
                "William Yang Wang."
            ],
            "title": "Kgpt: Knowledge-grounded pretraining for data-to-text generation",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8635\u2013",
            "year": 2020
        },
        {
            "authors": [
                "Xiuying Chen",
                "Guodong Long",
                "Chongyang Tao",
                "Mingzhe Li",
                "Xin Gao",
                "Chengqi Zhang",
                "Xiangliang Zhang."
            ],
            "title": "Improving the robustness of summarization systems with dual augmentation",
            "venue": "Proceedings of the 61st Annual Meeting of the As-",
            "year": 2023
        },
        {
            "authors": [
                "Yulong Chen",
                "Yang Liu",
                "Ruochen Xu",
                "Ziyi Yang",
                "Chenguang Zhu",
                "Michael Zeng",
                "Yue Zhang."
            ],
            "title": "UniSumm and SummZoo: Unified model and diverse benchmark for few-shot summarization",
            "venue": "Proceedings of the 61st Annual Meeting of the Association for",
            "year": 2023
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Com-",
            "year": 2019
        },
        {
            "authors": [
                "Pierre Dognin",
                "Inkit Padhi",
                "Igor Melnyk",
                "Payel Das."
            ],
            "title": "ReGen: Reinforcement learning for text and knowledge base generation using pretrained language models",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2021
        },
        {
            "authors": [
                "Hady Elsahar",
                "Matthias Gall\u00e9."
            ],
            "title": "To annotate or not? predicting performance drop under domain shift",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language",
            "year": 2019
        },
        {
            "authors": [
                "Matan Eyal",
                "Tal Baumel",
                "Michael Elhadad."
            ],
            "title": "Question answering as an automatic evaluation metric for news article summarization",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics:",
            "year": 2019
        },
        {
            "authors": [
                "Alexander Fabbri",
                "Chien-Sheng Wu",
                "Wenhao Liu",
                "Caiming Xiong."
            ],
            "title": "QAFactEval: Improved QAbased factual consistency evaluation for summarization",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Com-",
            "year": 2022
        },
        {
            "authors": [
                "Yair Feldman",
                "Ran El-Yaniv."
            ],
            "title": "Multi-hop paragraph retrieval for open-domain question answering",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2296\u2013 2309.",
            "year": 2019
        },
        {
            "authors": [
                "Shangbin Feng",
                "Zilong Chen",
                "Wenqian Zhang",
                "Qingyao Li",
                "Qinghua Zheng",
                "Xiaojun Chang",
                "Minnan Luo."
            ],
            "title": "Kgap: Knowledge graph augmented political perspective detection in news media",
            "venue": "arXiv preprint arXiv:2108.03861.",
            "year": 2021
        },
        {
            "authors": [
                "Shangbin Feng",
                "Zhaoxuan Tan",
                "Wenqian Zhang",
                "Zhenyu Lei",
                "Yulia Tsvetkov."
            ],
            "title": "KALM: Knowledgeaware integration of local, document, and global contexts for long document understanding",
            "venue": "Proceedings of ACL 2023, pages 2116\u20132138.",
            "year": 2023
        },
        {
            "authors": [
                "Yue Feng",
                "Zhen Han",
                "Mingming Sun",
                "Ping Li."
            ],
            "title": "Multi-hop open-domain question answering over structured and unstructured knowledge",
            "venue": "Findings of the Association for Computational Linguistics: NAACL 2022, pages 151\u2013156, Seattle, United States.",
            "year": 2022
        },
        {
            "authors": [
                "Joseph Fisher",
                "Arpit Mittal",
                "Dave Palfrey",
                "Christos Christodoulopoulos."
            ],
            "title": "Debiasing knowledge graph embeddings",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 7332\u20137345.",
            "year": 2020
        },
        {
            "authors": [
                "Nicolas Garneau",
                "Luc Lamontagne."
            ],
            "title": "Trainable ranking models to evaluate the semantic accuracy of data-to-text neural generator",
            "venue": "Proceedings of the 2nd Workshop on Evaluation and Comparison of NLP Systems, pages 51\u201361.",
            "year": 2021
        },
        {
            "authors": [
                "Tomas Goldsack",
                "Zhihao Zhang",
                "Chenghua Lin",
                "Carolina Scarton."
            ],
            "title": "Making science simple: Corpora for the lay summarisation of scientific literature",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing.",
            "year": 2022
        },
        {
            "authors": [
                "Tanya Goyal",
                "Greg Durrett."
            ],
            "title": "Evaluating factuality in generation with dependency-level entailment",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 3592\u20133603.",
            "year": 2020
        },
        {
            "authors": [
                "Tanya Goyal",
                "Greg Durrett."
            ],
            "title": "Annotating and modeling fine-grained factuality in summarization",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.",
            "year": 2021
        },
        {
            "authors": [
                "Suchin Gururangan",
                "Ana Marasovi\u0107",
                "Swabha Swayamdipta",
                "Kyle Lo",
                "Iz Beltagy",
                "Doug Downey",
                "Noah A Smith."
            ],
            "title": "Don\u2019t stop pretraining: Adapt language models to domains and tasks",
            "venue": "Proceedings of the 58th Annual Meeting of the",
            "year": 2020
        },
        {
            "authors": [
                "Charles R Harris",
                "K Jarrod Millman",
                "St\u00e9fan J Van Der Walt",
                "Ralf Gommers",
                "Pauli Virtanen",
                "David Cournapeau",
                "Eric Wieser",
                "Julian Taylor",
                "Sebastian Berg",
                "Nathaniel J Smith"
            ],
            "title": "Array programming with numpy",
            "year": 2020
        },
        {
            "authors": [
                "Pengcheng He",
                "Baolin Peng",
                "Song Wang",
                "Yang Liu",
                "Ruochen Xu",
                "Hany Hassan",
                "Yu Shi",
                "Chenguang Zhu",
                "Wayne Xiong",
                "Michael Zeng",
                "Jianfeng Gao",
                "Xuedong Huang"
            ],
            "title": "Z-code++: A pre-trained language model optimized for abstractive summariza",
            "year": 2023
        },
        {
            "authors": [
                "Ruifang He",
                "Liangliang Zhao",
                "Huanyu Liu."
            ],
            "title": "TWEETSUM: Event oriented social summarization dataset",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 5731\u20135736.",
            "year": 2020
        },
        {
            "authors": [
                "Yu-Jung Heo",
                "Eun-Sol Kim",
                "Woo Suk Choi",
                "Byoung-Tak Zhang."
            ],
            "title": "Hypergraph transformer: Weakly-supervised multi-hop reasoning for knowledge-based visual question answering",
            "venue": "Proceedings of the 60th Annual Meeting of the Associa-",
            "year": 2022
        },
        {
            "authors": [
                "Linmei Hu",
                "Tianchi Yang",
                "Luhao Zhang",
                "Wanjun Zhong",
                "Duyu Tang",
                "Chuan Shi",
                "Nan Duan",
                "Ming Zhou."
            ],
            "title": "Compare to the knowledge: Graph neural fake news detection with external knowledge",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for",
            "year": 2021
        },
        {
            "authors": [
                "Yong-Ho Jung",
                "Jun-Hyung Park",
                "Joon-Young Choi",
                "Mingyu Lee",
                "Junho Kim",
                "Kang-Min Kim",
                "SangKeun Lee."
            ],
            "title": "Learning from missing relations: Contrastive learning with commonsense knowledge graphs for commonsense inference",
            "venue": "Findings",
            "year": 2022
        },
        {
            "authors": [
                "Ambedkar Kanapala",
                "Sukomal Pal",
                "Rajendra Pamula."
            ],
            "title": "Text summarization from legal documents: a survey",
            "venue": "Artificial Intelligence Review, 51(3):371\u2013402.",
            "year": 2019
        },
        {
            "authors": [
                "Ryuji Kano",
                "Yasuhide Miura",
                "Motoki Taniguchi",
                "YanYing Chen",
                "Francine Chen",
                "Tomoko Ohkuma."
            ],
            "title": "Harnessing popularity in social media for extractive summarization of online conversations",
            "venue": "Proceedings of the 2018 Conference on Empir-",
            "year": 2018
        },
        {
            "authors": [
                "Yu Jin Kim",
                "Beong-woo Kwak",
                "Youngwook Kim",
                "Reinald Kim Amplayo",
                "Seung-won Hwang",
                "Jinyoung Yeo."
            ],
            "title": "Modularized transfer learning with multiple knowledge graphs for zero-shot commonsense reasoning",
            "venue": "Proceedings of the 2022 Con-",
            "year": 2022
        },
        {
            "authors": [
                "Wojciech Kry\u015bci\u0144ski",
                "Bryan McCann",
                "Caiming Xiong",
                "Richard Socher."
            ],
            "title": "Evaluating the factual consistency of abstractive text summarization",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
            "year": 2020
        },
        {
            "authors": [
                "Philippe Laban",
                "Tobias Schnabel",
                "Paul N. Bennett",
                "Marti A. Hearst."
            ],
            "title": "SummaC: Re-Visiting NLIbased Models for Inconsistency Detection in Summarization",
            "venue": "Transactions of the Association for Computational Linguistics, 10:163\u2013177.",
            "year": 2022
        },
        {
            "authors": [
                "Timoth\u00e9e Lacroix",
                "Guillaume Obozinski",
                "Nicolas Usunier."
            ],
            "title": "Tensor decompositions for temporal knowledge base completion",
            "venue": "International Conference on Learning Representations.",
            "year": 2019
        },
        {
            "authors": [
                "Egoitz Laparra",
                "Steven Bethard",
                "Timothy A Miller."
            ],
            "title": "Rethinking domain adaptation for machine learning over clinical language",
            "venue": "JAMIA open, 3(2):146\u2013150.",
            "year": 2020
        },
        {
            "authors": [
                "Guy Lev",
                "Michal Shmueli-Scheuer",
                "Jonathan Herzig",
                "Achiya Jerbi",
                "David Konopnicki"
            ],
            "title": "TalkSumm: A dataset and scalable annotation method",
            "year": 2019
        },
        {
            "authors": [
                "Chen Li",
                "Zhongyu Wei",
                "Yang Liu",
                "Yang Jin",
                "Fei Huang."
            ],
            "title": "Using relevant public posts to enhance news article summarization",
            "venue": "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages",
            "year": 2016
        },
        {
            "authors": [
                "Shaobo Li",
                "Xiaoguang Li",
                "Lifeng Shang",
                "Chengjie Sun",
                "Bingquan Liu",
                "Zhenzhou Ji",
                "Xin Jiang",
                "Qun Liu."
            ],
            "title": "Pre-training language models with deterministic factual knowledge",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Lan-",
            "year": 2022
        },
        {
            "authors": [
                "Paul Pu Liang",
                "Chiyu Wu",
                "Louis-Philippe Morency",
                "Ruslan Salakhutdinov."
            ],
            "title": "Towards understanding and mitigating social biases in language models",
            "venue": "International Conference on Machine Learning, pages 6565\u20136576. PMLR.",
            "year": 2021
        },
        {
            "authors": [
                "Jiacheng Liu",
                "Alisa Liu",
                "Ximing Lu",
                "Sean Welleck",
                "Peter West",
                "Ronan Le Bras",
                "Yejin Choi",
                "Hannaneh Hajishirzi."
            ],
            "title": "Generated knowledge prompting for commonsense reasoning",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Compu-",
            "year": 2022
        },
        {
            "authors": [
                "Xiao Liu",
                "Shiyu Zhao",
                "Kai Su",
                "Yukuo Cen",
                "Jiezhong Qiu",
                "Mengdi Zhang",
                "Wei Wu",
                "Yuxiao Dong",
                "Jie Tang."
            ],
            "title": "Mask and reason: Pre-training knowledge graph transformers for complex logical queries",
            "venue": "Proceedings of the 28th ACM SIGKDD Confer-",
            "year": 2022
        },
        {
            "authors": [
                "Yang Liu",
                "Mirella Lapata."
            ],
            "title": "Text summarization with pretrained encoders",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing",
            "year": 2019
        },
        {
            "authors": [
                "Yang Liu",
                "Chenguang Zhu",
                "Michael Zeng."
            ],
            "title": "End-to-end segmentation-based news summarization",
            "venue": "Findings of the Association for Computational Linguistics: ACL 2022, pages 544\u2013554.",
            "year": 2022
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Yixin Liu",
                "Budhaditya Deb",
                "Milagro Teruel",
                "Aaron Halfaker",
                "Dragomir Radev",
                "Ahmed Hassan Awadallah."
            ],
            "title": "On improving summarization factual consistency from natural language feedback",
            "venue": "Proceedings of the 61st Annual Meeting of the Associa-",
            "year": 2023
        },
        {
            "authors": [
                "Yixin Liu",
                "Alex Fabbri",
                "Pengfei Liu",
                "Yilun Zhao",
                "Linyong Nan",
                "Ruilin Han",
                "Simeng Han",
                "Shafiq Joty",
                "Chien-Sheng Wu",
                "Caiming Xiong",
                "Dragomir Radev"
            ],
            "title": "Revisiting the gold standard: Grounding summarization evaluation with robust human",
            "year": 2023
        },
        {
            "authors": [
                "Yongtai Liu",
                "Joshua Maynez",
                "Gon\u00e7alo Sim\u00f5es",
                "Shashi Narayan."
            ],
            "title": "Data augmentation for lowresource dialogue summarization",
            "venue": "Findings of the Association for Computational Linguistics: NAACL 2022, pages 703\u2013710.",
            "year": 2022
        },
        {
            "authors": [
                "Zheheng Luo",
                "Qianqian Xie",
                "Sophia Ananiadou."
            ],
            "title": "Chatgpt as a factual inconsistency evaluator for abstractive text summarization",
            "venue": "arXiv preprint arXiv:2303.15621.",
            "year": 2023
        },
        {
            "authors": [
                "Kaixin Ma",
                "Hao Cheng",
                "Xiaodong Liu",
                "Eric Nyberg",
                "Jianfeng Gao."
            ],
            "title": "Open domain question answering with a unified knowledge interface",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1:",
            "year": 2022
        },
        {
            "authors": [
                "Joshua Maynez",
                "Shashi Narayan",
                "Bernd Bohnet",
                "Ryan McDonald."
            ],
            "title": "On faithfulness and factuality in abstractive summarization",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1906\u20131919.",
            "year": 2020
        },
        {
            "authors": [
                "Ninareh Mehrabi",
                "Pei Zhou",
                "Fred Morstatter",
                "Jay Pujara",
                "Xiang Ren",
                "Aram Galstyan."
            ],
            "title": "Lawyers are dishonest? quantifying representational harms in commonsense knowledge resources",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in",
            "year": 2021
        },
        {
            "authors": [
                "Kevin Meng",
                "David Bau",
                "Alex J Andonian",
                "Yonatan Belinkov."
            ],
            "title": "Locating and editing factual associations in gpt",
            "venue": "Advances in Neural Information Processing Systems.",
            "year": 2022
        },
        {
            "authors": [
                "Sayantan Mitra",
                "Roshni Ramnani",
                "Shubhashis Sengupta."
            ],
            "title": "Constraint-based multi-hop question answering with knowledge graph",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Hu-",
            "year": 2022
        },
        {
            "authors": [
                "Leann Myers",
                "Maria J Sirois."
            ],
            "title": "Spearman correlation coefficients, differences between",
            "venue": "Encyclopedia of statistical sciences, 12.",
            "year": 2004
        },
        {
            "authors": [
                "Moin Nadeem",
                "Anna Bethke",
                "Siva Reddy."
            ],
            "title": "Stereoset: Measuring stereotypical bias in pretrained language models",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference",
            "year": 2021
        },
        {
            "authors": [
                "Feng Nan",
                "Cicero dos Santos",
                "Henghui Zhu",
                "Patrick Ng",
                "Kathleen Mckeown",
                "Ramesh Nallapati",
                "Dejiao Zhang",
                "Zhiguo Wang",
                "Andrew O Arnold",
                "Bing Xiang."
            ],
            "title": "Improving factual consistency of abstractive summarization via question answering",
            "venue": "In",
            "year": 2021
        },
        {
            "authors": [
                "Shashi Narayan",
                "Shay Cohen",
                "Maria Lapata."
            ],
            "title": "Don\u2019t give me the details, just the summary! topicaware convolutional neural networks for extreme summarization",
            "venue": "2018 Conference on Empirical Methods in Natural Language Processing, pages",
            "year": 2018
        },
        {
            "authors": [
                "Shashi Narayan",
                "Yao Zhao",
                "Joshua Maynez",
                "Gon\u00e7alo Sim\u00f5es",
                "Vitaly Nikolaev",
                "Ryan McDonald."
            ],
            "title": "Planning with learned entity prompts for abstractive summarization",
            "venue": "Transactions of the Association for Computational Linguistics, 9:1475\u20131492.",
            "year": 2021
        },
        {
            "authors": [
                "Barlas Oguz",
                "Xilun Chen",
                "Vladimir Karpukhin",
                "Stan Peshterliev",
                "Dmytro Okhonko",
                "Michael Schlichtkrull",
                "Sonal Gupta",
                "Yashar Mehdad",
                "Scott Yih"
            ],
            "title": "UniK-QA: Unified representations of structured and unstructured knowledge for open-domain question",
            "year": 2022
        },
        {
            "authors": [
                "Artidoro Pagnoni",
                "Vidhisha Balachandran",
                "Yulia Tsvetkov."
            ],
            "title": "Understanding factuality in abstractive summarization with frank: A benchmark for factuality metrics",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Associ-",
            "year": 2021
        },
        {
            "authors": [
                "Adam Paszke",
                "Sam Gross",
                "Francisco Massa",
                "Adam Lerer",
                "James Bradbury",
                "Gregory Chanan",
                "Trevor Killeen",
                "Zeming Lin",
                "Natalia Gimelshein",
                "Luca Antiga"
            ],
            "title": "Pytorch: An imperative style, high-performance deep learning library",
            "year": 2019
        },
        {
            "authors": [
                "F. Pedregosa",
                "G. Varoquaux",
                "A. Gramfort",
                "V. Michel",
                "B. Thirion",
                "O. Grisel",
                "M. Blondel",
                "P. Prettenhofer",
                "R. Weiss",
                "V. Dubourg",
                "J. Vanderplas",
                "A. Passos",
                "D. Cournapeau",
                "M. Brucher",
                "M. Perrot",
                "E. Duchesnay"
            ],
            "title": "Scikit-learn: Machine learning",
            "year": 2011
        },
        {
            "authors": [
                "Thomas Pellissier Tanon",
                "Gerhard Weikum",
                "Fabian Suchanek."
            ],
            "title": "Yago 4: A reason-able knowledge base",
            "venue": "European Semantic Web Conference, pages 583\u2013596. Springer.",
            "year": 2020
        },
        {
            "authors": [
                "Xutan Peng",
                "Yi Zheng",
                "Chenghua Lin",
                "Advaith Siddharthan."
            ],
            "title": "Summarising historical text in modern languages",
            "venue": "Proceedings of the 16th Conference of the European Chapter of the Association",
            "year": 2021
        },
        {
            "authors": [
                "Seth Polsley",
                "Pooja Jhunjhunwala",
                "Ruihong Huang."
            ],
            "title": "Casesummarizer: a system for automated summarization of legal texts",
            "venue": "Proceedings of COLING 2016, the 26th international conference on Computational Linguistics: System Demonstrations, pages",
            "year": 2016
        },
        {
            "authors": [
                "Ofir Press",
                "Muru Zhang",
                "Sewon Min",
                "Ludwig Schmidt",
                "Noah A Smith",
                "Mike Lewis."
            ],
            "title": "Measuring and narrowing the compositionality gap in language models",
            "venue": "arXiv preprint arXiv:2210.03350.",
            "year": 2022
        },
        {
            "authors": [
                "Vinay Venkatesh Ramasesh",
                "Aitor Lewkowycz",
                "Ethan Dyer."
            ],
            "title": "Effect of scale on catastrophic forgetting in neural networks",
            "venue": "International Conference on Learning Representations.",
            "year": 2021
        },
        {
            "authors": [
                "Leonardo F.R. Ribeiro",
                "Mengwen Liu",
                "Iryna Gurevych",
                "Markus Dreyer",
                "Mohit Bansal."
            ],
            "title": "FactGraph: Evaluating factuality in summarization with semantic graph representations",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the",
            "year": 2022
        },
        {
            "authors": [
                "Md Rashad Al Hasan Rony",
                "Ricardo Usbeck",
                "Jens Lehmann."
            ],
            "title": "DialoKG: Knowledge-structure aware task-oriented dialogue generation",
            "venue": "Findings of the Association for Computational Linguistics: NAACL 2022, pages 2557\u20132571, Seattle, United",
            "year": 2022
        },
        {
            "authors": [
                "Corby Rosset",
                "Chenyan Xiong",
                "Minh Hieu Phan",
                "Xia Song",
                "Paul Bennett",
                "Saurabh Tiwary."
            ],
            "title": "Knowledge-aware language model pretraining",
            "venue": "ArXiv, abs/2007.00655.",
            "year": 2020
        },
        {
            "authors": [
                "Sascha Rothe",
                "Joshua Maynez",
                "Shashi Narayan."
            ],
            "title": "A thorough evaluation of task-specific pretraining for summarization",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 140\u2013145.",
            "year": 2021
        },
        {
            "authors": [
                "Arkadiy Saakyan",
                "Tuhin Chakrabarty",
                "Smaranda Muresan."
            ],
            "title": "Covid-fact: Fact extraction and verification of real-world claims on covid-19 pandemic",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the",
            "year": 2021
        },
        {
            "authors": [
                "Mourad Sarrouti",
                "Asma Ben Abacha",
                "Yassine M\u2019rabet",
                "Dina Demner-Fushman"
            ],
            "title": "Evidence-based fact-checking of health-related claims",
            "venue": "In Findings of the Association for Computational Linguistics: EMNLP",
            "year": 2021
        },
        {
            "authors": [
                "Thomas Scialom",
                "Paul-Alexis Dray",
                "Sylvain Lamprier",
                "Benjamin Piwowarski",
                "Jacopo Staiano",
                "Alex Wang",
                "Patrick Gallinari."
            ],
            "title": "Questeval: Summarization asks for fact-based evaluation",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in",
            "year": 2021
        },
        {
            "authors": [
                "Omar Shaikh",
                "Hongxin Zhang",
                "William Held",
                "Michael Bernstein",
                "Diyi Yang."
            ],
            "title": "On second thought, let\u2019s not think step by step! bias and toxicity in zeroshot reasoning",
            "venue": "Proceedings of the 61st Annual Meeting of the Association for Computational Lin-",
            "year": 2023
        },
        {
            "authors": [
                "Siamak Shakeri",
                "Cicero dos Santos",
                "Henghui Zhu",
                "Patrick Ng",
                "Feng Nan",
                "Zhiguo Wang",
                "Ramesh Nallapati",
                "Bing Xiang."
            ],
            "title": "End-to-end synthetic data generation for domain adaptation of question answering systems",
            "venue": "Proceedings of the 2020 Con-",
            "year": 2020
        },
        {
            "authors": [
                "Robyn Speer",
                "Joshua Chin",
                "Catherine Havasi"
            ],
            "title": "Conceptnet 5.5: An open multilingual graph of general knowledge",
            "venue": "In Thirty-first AAAI conference on artificial intelligence",
            "year": 2017
        },
        {
            "authors": [
                "Shahbaz Syed",
                "Michael V\u00f6lske",
                "Nedim Lipka",
                "Benno Stein",
                "Hinrich Sch\u00fctze",
                "Martin Potthast."
            ],
            "title": "Towards summarization for social media - results of the TL;DR challenge",
            "venue": "Proceedings of the 12th International Conference on Natural Language Gen-",
            "year": 2019
        },
        {
            "authors": [
                "Masato Takatsuka",
                "Tetsunori Kobayashi",
                "Yoshihiko Hayashi."
            ],
            "title": "Phrase-level localization of inconsistency errors in summarization by weak supervision",
            "venue": "Proceedings of the 29th International Conference on Computational Linguistics, pages 6151\u20136164.",
            "year": 2022
        },
        {
            "authors": [
                "Yi Chern Tan",
                "L Elisa Celis."
            ],
            "title": "Assessing social and intersectional biases in contextualized word representations",
            "venue": "Advances in Neural Information Processing Systems, 32.",
            "year": 2019
        },
        {
            "authors": [
                "Liyan Tang",
                "Tanya Goyal",
                "Alex Fabbri",
                "Philippe Laban",
                "Jiacheng Xu",
                "Semih Yavuz",
                "Wojciech Kryscinski",
                "Justin Rousseau",
                "Greg Durrett."
            ],
            "title": "Understanding factual errors in summarization: Errors, summarizers, datasets, error detectors",
            "venue": "Proceed-",
            "year": 2023
        },
        {
            "authors": [
                "Xiangru Tang",
                "Arjun Nair",
                "Borui Wang",
                "Bingyao Wang",
                "Jai Desai",
                "Aaron Wade",
                "Haoran Li",
                "Asli Celikyilmaz",
                "Yashar Mehdad",
                "Dragomir Radev."
            ],
            "title": "CONFIT: Toward faithful dialogue summarization with linguistically-informed contrastive fine-tuning",
            "venue": "In",
            "year": 2022
        },
        {
            "authors": [
                "Prasetya Utama",
                "Joshua Bambrick",
                "Nafise Moosavi",
                "Iryna Gurevych."
            ],
            "title": "Falsesum: Generating document-level NLI examples for recognizing factual inconsistency in summarization",
            "venue": "Proceedings of the 2022 Conference of the North American Chap-",
            "year": 2022
        },
        {
            "authors": [
                "Shikhar Vashishth",
                "Soumya Sanyal",
                "Vikram Nitin",
                "Partha Talukdar."
            ],
            "title": "Composition-based multirelational graph convolutional networks",
            "venue": "International Conference on Learning Representations.",
            "year": 2019
        },
        {
            "authors": [
                "Ellen Voorhees",
                "Tasmeer Alam",
                "Steven Bedrick",
                "Dina Demner-Fushman",
                "William R Hersh",
                "Kyle Lo",
                "Kirk Roberts",
                "Ian Soboroff",
                "Lucy Lu Wang."
            ],
            "title": "Trec-covid: constructing a pandemic information retrieval test collection",
            "venue": "ACM SIGIR Forum, vol-",
            "year": 2021
        },
        {
            "authors": [
                "Denny Vrande\u010di\u0107",
                "Markus Kr\u00f6tzsch."
            ],
            "title": "Wikidata: a free collaborative knowledgebase",
            "venue": "Communications of the ACM, 57(10):78\u201385.",
            "year": 2014
        },
        {
            "authors": [
                "David Wadden",
                "Shanchuan Lin",
                "Kyle Lo",
                "Lucy Lu Wang",
                "Madeleine van Zuylen",
                "Arman Cohan",
                "Hannaneh Hajishirzi."
            ],
            "title": "Fact or fiction: Verifying scientific claims",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language",
            "year": 2020
        },
        {
            "authors": [
                "David Wadden",
                "Kyle Lo",
                "Lucy Lu Wang",
                "Arman Cohan",
                "Iz Beltagy",
                "Hannaneh Hajishirzi."
            ],
            "title": "MultiVerS: Improving scientific claim verification with weak supervision and full-document context",
            "venue": "Findings of the Association for Computational Linguistics:",
            "year": 2022
        },
        {
            "authors": [
                "Alex Wang",
                "Kyunghyun Cho",
                "Mike Lewis."
            ],
            "title": "Asking and answering questions to evaluate the factual consistency of summaries",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5008\u20135020.",
            "year": 2020
        },
        {
            "authors": [
                "Lucy Lu Wang",
                "Kyle Lo",
                "Yoganand Chandrasekhar",
                "Russell Reas",
                "Jiangjiang Yang",
                "Doug Burdick",
                "Darrin Eide",
                "Kathryn Funk",
                "Yannis Katsis",
                "Rodney Michael Kinney"
            ],
            "title": "2020b. Cord-19: The covid-19 open research dataset",
            "venue": "In Proceedings of the 1st Workshop",
            "year": 2020
        },
        {
            "authors": [
                "Wenya Wang",
                "Sinno Pan."
            ],
            "title": "Deep inductive logic reasoning for multi-hop reading comprehension",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4999\u20135009.",
            "year": 2022
        },
        {
            "authors": [
                "Xiaozhi Wang",
                "Tianyu Gao",
                "Zhaocheng Zhu",
                "Zhengyan Zhang",
                "Zhiyuan Liu",
                "Juanzi Li",
                "Jian Tang."
            ],
            "title": "Kepler: A unified model for knowledge embedding and pre-trained language representation",
            "venue": "Transactions of the Association for Computational Linguis-",
            "year": 2021
        },
        {
            "authors": [
                "Peter West",
                "Chandra Bhagavatula",
                "Jack Hessel",
                "Jena Hwang",
                "Liwei Jiang",
                "Ronan Le Bras",
                "Ximing Lu",
                "Sean Welleck",
                "Yejin Choi."
            ],
            "title": "Symbolic knowledge distillation: from general language models to commonsense models",
            "venue": "Proceedings of the",
            "year": 2022
        },
        {
            "authors": [
                "Thomas Wolf",
                "Lysandre Debut",
                "Victor Sanh",
                "Julien Chaumond",
                "Clement Delangue",
                "Anthony Moi",
                "Pierric Cistac",
                "Tim Rault",
                "R\u00e9mi Louf",
                "Morgan Funtowicz"
            ],
            "title": "Transformers: State-of-the-art natural language processing",
            "year": 2020
        },
        {
            "authors": [
                "Yuexiang Xie",
                "Fei Sun",
                "Yang Deng",
                "Yaliang Li",
                "Bolin Ding."
            ],
            "title": "Factual consistency evaluation for text summarization via counterfactual estimation",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, pages 100\u2013110.",
            "year": 2021
        },
        {
            "authors": [
                "Xinnuo Xu",
                "Ond\u0159ej Du\u0161ek",
                "Jingyi Li",
                "Verena Rieser",
                "Ioannis Konstas."
            ],
            "title": "Fact-based content weighting for evaluating abstractive summarisation",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5071\u20135081.",
            "year": 2020
        },
        {
            "authors": [
                "Michihiro Yasunaga",
                "Antoine Bosselut",
                "Hongyu Ren",
                "Xikun Zhang",
                "Christopher D Manning",
                "Percy S Liang",
                "Jure Leskovec."
            ],
            "title": "Deep bidirectional language-knowledge graph pretraining",
            "venue": "Advances in Neural Information Processing Systems, 35:37309\u2013",
            "year": 2022
        },
        {
            "authors": [
                "Michihiro Yasunaga",
                "Hongyu Ren",
                "Antoine Bosselut",
                "Percy Liang",
                "Jure Leskovec."
            ],
            "title": "Qa-gnn: Reasoning with language models and knowledge graphs for question answering",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the",
            "year": 2021
        },
        {
            "authors": [
                "Wenhao Yu",
                "Meng Jiang",
                "Zhiting Hu",
                "Qingyun Wang",
                "Heng Ji",
                "Nazneen Rajani."
            ],
            "title": "Knowledgeenriched natural language generation",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts,",
            "year": 2021
        },
        {
            "authors": [
                "Tianyi Zhang",
                "Varsha Kishore",
                "Felix Wu",
                "Kilian Q Weinberger",
                "Yoav Artzi."
            ],
            "title": "Bertscore: Evaluating text generation with bert",
            "venue": "International Conference on Learning Representations.",
            "year": 2019
        },
        {
            "authors": [
                "Wenqian Zhang",
                "Shangbin Feng",
                "Zilong Chen",
                "Zhenyu Lei",
                "Jundong Li",
                "Minnan Luo."
            ],
            "title": "KCD: Knowledge walks and textual cues enhanced political perspective detection in news media",
            "venue": "Proceedings of NAACL 2022, pages 4129\u20134140.",
            "year": 2022
        },
        {
            "authors": [
                "X Zhang",
                "A Bosselut",
                "M Yasunaga",
                "H Ren",
                "P Liang",
                "C Manning",
                "J Leskovec."
            ],
            "title": "Greaselm: Graph reasoning enhanced language models for question answering",
            "venue": "International Conference on Representation Learning (ICLR).",
            "year": 2022
        },
        {
            "authors": [
                "Ribeiro"
            ],
            "title": "Class Class Distribution Train/Dev/Test Split Proposed In FACTCOLLECT",
            "venue": "FRANK",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Generating factually accurate document summaries in addition to fluent and informative ones is critical to the adoption of summarization models (Krys\u0301cin\u0301ski et al., 2020; Goyal and Durrett, 2020). However, evaluating the factual consistency of summaries is still challenging, especially in specialized domains like scientific or legal (Cachola et al., 2020; Goldsack et al., 2022; Polsley et al., 2016; Kanapala et al., 2019). The key reason is that the majority of existing approaches employ neural classifiers trained on synthetic data constructed from a relatively small set of documents (Krys\u0301cin\u0301ski et al., 2020; Goyal and Durrett, 2020). These factuality\nclassifiers are thus not robust to ever-growing information, in which the distribution of entities, events, and their relations changes greatly across time and domains (Elsahar and Gall\u00e9, 2019; Laparra et al., 2020). Pagnoni et al. (2021) highlighted this limitation, finding that over 50% of factuality errors in the XSUM (Narayan et al., 2018) summarization dataset stem from semantic frame errors, namely entities, events, and relations between them, as illustrated in Figure 1.\nTo address these issues, we develop a new factuality evaluation model with improved factual knowledge representation, specifically focusing on entities and relations. Entity-oriented pretraining objectives have been shown to improve QA and reasoning tasks (Yasunaga et al., 2022; Liu et al., 2022b); we thus hypothesize that similar objectives can aid factuality evaluation in better detecting semantic frame errors in generated summaries.\nWe propose FACTKB, a novel factuality evaluation model built upon language models (LMs) augmented with factual knowledge (\u00a72). The LMs\nare pretrained with knowledge-focused objectives using text synthesized from external knowledge bases (KBs) which store high-quality facts about entities and relations. We propose three types of complementary pretraining strategies: (1) entity wiki, with a focus on improving entity understanding; (2) evidence extraction, with a focus on incorporating supporting evidence from surrounding context; and (3) knowledge walks, with a focus on augmenting compositional reasoning about entities. For factuality evaluation, we first pretrain a language model using these three entity-centric pretraining strategies, and then fine-tune the enhanced LM on a factual error detection dataset.\nWe evaluate FACTKB\u2019s correlation with human factuality judgments across three settings (\u00a73). In in-domain (news) summarization, FACTKB significantly outperforms baselines by 2\u20137 balanced accuracy (BACC) points on the FactCollect dataset (Ribeiro et al., 2022) and 10\u201312 correlation points on the FRANK benchmark (Pagnoni et al., 2021), particularly showing marked improvements in semantic frame errors. In out-of-domain experiments, FACTKB consistently outperforms existing approaches by 3\u20135 BACC points on three datasets in biomedical and scientific domains (Saakyan et al., 2021; Sarrouti et al., 2021; Wadden et al., 2020), demonstrating stronger generalizability to unseen documents in new domains. Further analysis shows that FACTKB is compatible with different LMs and KBs while presenting a lightweight and easy-to-use approach to factuality evaluation. Code, data, and trained factuality evaluation models are publicly available."
        },
        {
            "heading": "2 FACTKB Methodology",
            "text": "FACTKB aims to improve the robustness and generalizability of factuality evaluation by a simple factuality pretraining, which improves entity and relation representations in LMs. We first propose three pretraining strategies (\u00a72.1). We then describe the training process to (1) pretrain an LM using the proposed strategies and (2) fine-tune the factenhanced LM on a factuality error detection dataset, resulting in FACTKB (\u00a72.2). Figure 2 presents an overview of our approach."
        },
        {
            "heading": "2.1 Factuality Pretraining",
            "text": "Knowledge bases are rich reservoirs of facts about entities and relations (Vrandec\u030cic\u0301 and Kr\u00f6tzsch, 2014; Pellissier Tanon et al., 2020), and we explore the possibility of leveraging external KBs as \u201cfact teachers\u201d to enhance an LM\u2019s representation of entities and relations.\nLet KB = (E ,R,A, \u03f5, \u03c6), where E = {e1, . . . , eN } represents the entities in the KB, R = {r1, . . . , rM} denotes the relations in the KB, A denotes the adjacency matrix where aij = k indicates relation rk connecting entities ei and ej (ei, rk, ej) \u2208 KB, \u03f5(\u00b7) : E \u2192 str and \u03c6(\u00b7) : R \u2192 str map the entities and relations to their textual names. We propose three novel types of factuality pretraining strategies that leverage the KB.\nStrategy 1: Entity Wiki Entities in KBs often have multiple edges connecting them to other entities via relations, each representing a distinct but related fact about the entity. Inspired by the task of knowledge base completion (Bordes et al., 2013; Vashishth et al., 2019) to predict missing connec-\ntions in KBs based on available KB facts, we propose the entity wiki factuality pretraining, where an LM is pretrained with the task of predicting masked entities or relations in KB facts. Specifically, for each entity ei \u2208 E , we retrieve its one-hop neighborhood in the KB as Eei = {ej | \u2203 rk s.t. aij = k}. We then synthesize a sentence using entity ei and its connected one-hop facts:\ndi = concatej\u2208Eei [ \u03f5(ei)\u03c6(rk|aij = k)\u03f5(ej)[SEP] ] where concat denotes string concatenation and [SEP ] denotes the special token. Repeating this generation process for all e \u2208 E , we produce a corpus of entity facts as {di}|E|i=1 with the max size being the number of entities |E|. We use this entity wiki corpus to pretrain an LM for better factual reasoning by randomly masking entities and relations in it and training the LM to predict the mask given the surrounding facts about an entity. We randomly mask the corpora with probability p and pretrain LMs with the masked language modeling objective. We expect this objective to train LMs to infer facts from surrounding knowledge and penalize unsupported hallucinations about entities and relations.\nStrategy 2: Evidence Extraction The goal of this pretraining strategy is to enhance the model\u2019s ability to evaluate facts based on relevant evidence. We begin by randomly selecting a triple (ei, rk, ej) \u2208 KB and use the first paragraph of the Wikipedia description of ei as the auxiliary knowledge. We synthesize a sentence using the two as:\ndi = \u03f5(ei) \u03c6(rk) [MASK] Wikipedia(ei)\nwhere we mask out \u03f5(ej) and [MASK] denotes the special token, Wikipedia(\u00b7) : E \u2192 str maps entities to the first paragraph of their Wikipedia description. Repeating this process N times with randomly selected triples, we obtain a corpus of triples paired with auxiliary knowledge {di}Ni=1. The corpus size is bounded by all KB triples represented as\nthe L0 norm of the adjacency matrix ||A||0. We use this corpus for the evidence extraction factuality pretraining and train the LM to predict the mask by using relevant evidence in the auxiliary paragraph. Through this, we aim to augment FACTKB\u2019s ability to implicitly select evidence from the document to support its factuality evaluation.\nStrategy 3: Knowledge Walk Natural language documents often include compositional statements about entities and relations (Feldman and ElYaniv, 2019; Wang and Pan, 2022), but pretrained LMs struggle with such compositional reasoning (Press et al., 2022). To improve FACTKB\u2019s ability to understand multi-hop claims, we propose the knowledge walk factuality pretraining strategy. Specifically, we randomly select a starting entity e(0) and randomly select an entity e(1) from its direct neighborhood Ee(0) , resulting in a onehop triple {e(0), r(0,1), e(1)} where r(0,1) denotes the relation between e(0) and e(1). Now, from e(1), we randomly select an entity from it\u2019s direct neighborhood to take the next step. We repeat this process for K times, and obtain a Khop random walk of triples beginning at e(0): {e(0), r(0,1), e(1), \u00b7 \u00b7 \u00b7 , r(K\u22121, K), e(K)}. We then produce a sentence based on the K-hop walk:\ndi = \u03f5(e(0)) concat K\u22121 i=0 [ \u03c6(r(i,i+1)) \u03f5(e(i+1)) ] Repeating this K-hop walk N times with differ-\nent randomly selected starting entities, we obtain {di}Ni=1 as the corpus for the knowledge walk factuality pretraining, whose size is bounded by the number of all possible K-hop walks as |E|( ||A||0|E| )\nk. In this corpus, we randomly mask entities or relations in each group of facts with probability p and train an LM to predict the masked element using the compositional facts around it using the masked language model objective. Through this pretraining, we expect FACTKB to improve in compositional\nfact understanding about entities and relations appearing in the summary and the input document.\nWe briefly summarize the three factuality pretraining strategies and provide examples in Table 1."
        },
        {
            "heading": "2.2 FACTKB Training",
            "text": "We initialize FACTKB with encoder-based LMs and pretrain FACTKB separately with each of the three factuality pretraining corpora using the masked language modeling objective to study the effectiveness of each strategy. This results in factenhanced LMs with the ability to better represent facts, entities, and relations. Finally, we fine-tune FACTKB on human-annotated factual error detection datasets with the sequence classification setting, taking SUMMARY [SEP] DOCUMENT as input and produce FACTUAL or NON-FACTUAL labels. The [CLS] token is adopted for classification. As a result, we obtain FACTKB, our entailment-based factuality evaluation model that classifies machinegenerated summaries as factual or non-factual."
        },
        {
            "heading": "3 Data and Experiment Settings",
            "text": ""
        },
        {
            "heading": "3.1 Training",
            "text": "Data We use YAGO (Pellissier Tanon et al., 2020), an encyclopedic knowledge base based on Wikidata (Vrandec\u030cic\u0301 and Kr\u00f6tzsch, 2014), to construct the three types of factuality pretraining corpora, while we discuss FACTKB\u2019s compatibility with different KBs in Section 5.2. For finetuning, we use the FactCollect dataset (Ribeiro et al., 2022), a dataset for factual error detection that gathers human annotations from different sources (Wang et al., 2020a; Krys\u0301cin\u0301ski et al., 2020; Maynez et al.,\n2020; Pagnoni et al., 2021) and consolidates them into a single dataset. It mainly focuses on the news media domain, covering summaries and articles from CNN, Daily Mail, and BBC. FactCollect follows a binary classification setting where each (SUMMARY, ARTICLE) pair has a FACTUAL or NON-FACTUAL label. We present more details about the FactCollect dataset in Appendix C.\nSettings We use a ROBERTA-BASE (Liu et al., 2019) checkpoint and continue pretraining separately on each of the three factuality pretraining corpora. We discuss FACTKB\u2019s compatibility with different LM initializations in Section \u00a75.2. We assign corpus size parameter N = 1e5, masking probability p = 0.15, and knowledge walk length K = 5 in the experiments, while we discuss the effect of corpus size and knowledge walk length in Appendix 5.4. We use a learning rate of 2e\u2212 5 for pretraining, 1e\u2212 4 for fine-tuning, a batch size of 32, and the RAdam optimizer. Pretraining is conducted for 5 epochs and fine-tuning has 50 maximum epochs with early stopping. More hyperparameter settings are presented in Appendix 3.1.\nHyperparameters We propose to further pretrain LM checkpoints with three types of factuality pretraining and fine-tune on factuality evaluation datasets. We present hyperparameters for the pretraining and fine-tuning stage in Table 4. We mostly follow the hyperparameters in Gururangan et al. (2020) for the pretraining stage. The default hyperparameters on Huggingface Transformers are adopted if not included in Table 4."
        },
        {
            "heading": "3.2 Evaluation",
            "text": "To study the robustness of FACTKB, we perform both in-domain and out-of-domain evaluation.\nIn-Domain Evaluation Since most research and resources on summarization and factuality are in the news media domain, we leverage the FactCollect dataset (Ribeiro et al., 2022) and the FRANK benchmark (Pagnoni et al., 2021) for in-domain factuality evaluation. We evaluate FACTKB on the held-out test set of the FactCollect dataset. FRANK (Pagnoni et al., 2021) is a factuality evaluation benchmark with human judgments on the factual consistency of model-generated summaries collected across 9 summarization models along with human annotations on the category of factual errors. Following the FRANK benchmark guidelines, we use two correlation measures (Pearson (Benesty et al., 2009) and Spearman (Myers and Sirois, 2004)). We present more details about the FRANK benchmark in Appendix C. Following previous work (Ribeiro et al., 2022), we train FACTKB\non the FactCollect dataset without the FRANK subset for the FRANK evaluation.\nGeneralizable Factuality Evaluation Summarization systems are used in diverse domains in the real world, including but not limited to news media (Liu et al., 2022c; Eyal et al., 2019; Li et al., 2016), social media (Syed et al., 2019; Kano et al., 2018; He et al., 2020), and scientific literature (Cachola et al., 2020; Lev et al., 2019). Consequently, factuality metrics should also provide reliable factuality scores in the face of shifting domains. To study this, we perform an out-of-domain evaluation using unseen documents and summaries from the scientific domain. To establish a test bed for generalizable factuality evaluation, we make use of three datasets in the scientific literature domain:\n\u2022 CovidFact (Saakyan et al., 2021) collects claims from the r/COVID19 subreddit and verifies them against relevant scientific literature and Google search results, resulting in a binary classification setting that is similar to the FactCollect dataset.\n\u2022 HealthVer (Sarrouti et al., 2021) consists of claims sourced from TREC-COVID (Voorhees et al., 2021) and verified against the CORD-19 (Wang et al., 2020b) corpus. While HealthVer originally follows a three-way classification setting (SUPPORT, REFUTE, NOT ENOUGH INFORMATION), we remove the examples in the \"NOT ENOUGH INFORMATION\" category to evaluate models as they are trained on the binary classification setting (factual, non-factual).\n\u2022 SciFact (Wadden et al., 2020) includes claims sourced from citation sentences in biomedical literature and verified against the cited paper\u2019s abstract. While SciFact uses three-way classification that includes \"NOT ENOUGH INFORMATION\", we similarly remove them in this work.\nWe leverage the well-organized version of the three datasets in Wadden et al. (2022). 1 We train and validate FACTKB with the FactCollect dataset from the news domain and evaluate on the test set of these datasets for zero-shot transfer learning.\nBaselines We compare FACTKB with different types of existing factuality evaluation models: QAGS (Wang et al., 2020a), QUALS (Nan et al., 2021), DAE (Goyal and Durrett, 2020), FalseSum (Utama et al., 2022), SummaC (Laban et al., 2022), FactCC (Krys\u0301cin\u0301ski et al., 2020), and FactGraph (Ribeiro et al., 2022). Since training data is a key factor in factuality evaluation models and they are often used off-the-shelf, we include factuality evaluation measures trained on both synthetic data (QAGS, QUALS, DAE, SummaC, FalseSum, FactCC) and human-annotated data (RoBERTa, FalseSum+, FactCC+, FactGraph, FactGraph-edge). We follow the same train/dev/test dataset split and experiment settings so that the results are directly comparable. We present more details about the baselines in Appendix D."
        },
        {
            "heading": "4 Results",
            "text": "In-Domain Results We evaluate FACTKB and baselines on the FactCollect dataset using the en-\n1Dataset statistics are presented in Table 8.\ntire held-out test data, the CNN/DM subset and the XSUM (BBC) subset, and report balanced accuracy scores and micro F1 scores. We run each method five times with different random seeds and report the average performance as well as the standard deviation. Table 2 demonstrates that FACTKB significantly (*) outperforms all baseline factuality evaluation methods by 3.8 BACC points on average across the three dataset settings. This demonstrates that the introduction of KBs and factuality pretraining is beneficial for factuality evaluation. Among the three factuality pretraining strategies, all of them outperform baseline models, suggesting that FACTKB\u2019s general methodology is compatible with different types of KB utilization.\nHuman Correlation We evaluate FACTKB and baselines on the FRANK benchmark to study how well FACTKB correlates with human judgments. We use the official script 2 to report the Pearson (\u03c1) and Spearman (r) correlation and p-values. Results in Table 3 show that classification-based metrics (FactCC, FactGraph, and FACTKB) generally outperform QA-based metrics (QAGS and QUALS). FACTKB significantly advances the state-of-the-art on the FRANK benchmark, resulting in the improvement of 5-15 correlation points across multiple settings. Our results show that FACTKB is highly correlated with human judgments, making it a practical approach for evaluating the factual consistency of generated news summaries.\nOut-of-Domain Results We evaluate FACTKB and existing factuality evaluation models on out-of-\n2https://github.com/artidoro/frank\ndomain scientific literature datasets in a zero-shot manner. Results are presented in Table 5, which demonstrate that while existing factuality evaluation models previously achieve good performance in the in-domain setting, they exhibit severe performance drops on the three out-of-domain datasets, performing only slightly better than random factuality scores (RANDOM). This suggests that existing approaches are not generalizable to other domains, limiting their applicability. On the contrary, FACTKB significantly (*) outperforms existing factuality metrics by 4.1 BACC points on average across the three out-of-domain datasets. Our results suggest that the factuality pretraining strategies enable FACTKB to better represent facts (entities and relations) in a new domain, making the factuality evaluation model more robust to shifting domains."
        },
        {
            "heading": "5 Analysis and Discussion",
            "text": ""
        },
        {
            "heading": "5.1 Where did FACTKB Improve?",
            "text": "To better understand FACTKB\u2019s improvement over existing approaches, we leverage the factual error typology in the FRANK benchmark (Pagnoni et al.,\n2021) and examine FACTKB\u2019s performance on the three error categories: semantic frame, discourse, and content verifiability errors. Using the official script in the FRANK benchmark, we remove each category of errors and report changes in correlation scores. Higher variation indicates a greater influence on a model\u2019s ability to handle a certain type of error. Figure 4 demonstrates that FACTKB is significantly better at identifying semantic frame errors, which focus on entities and relations. This indicates that our KB-based factuality pretraining strategies successfully result in a better understanding of the facts regarding entities and relations. FACTKB also has good performance in other categories, resulting in a factuality evaluation model that captures diverse types of errors and advances the state-of-the-art across the board. We conduct further qualitative analysis in Appendix B."
        },
        {
            "heading": "5.2 KB and LM Compatibility",
            "text": "FACTKB uses pretrained LMs for initialization, leverages external KBs for factuality pretraining, and trains on factuality evaluation datasets to result in a factuality metric. Our general methodology to leverage knowledge bases as fact teachers for generalizable factuality evaluation could work with different LM and KB combinations. To study whether out approach works across different settings, we apply the FACTKB methodology to six different LMs (RoBERTa, Electra, BART, DeBERTa, ALBERT, and distilRoBERTa) and pretrain the LMs on factuality pretraining corpora constructed based on six different KBs (YAGO, Wikidata, ConceptNet, Atomic, KGAP, and UMLS). For each combination, we initialize a particular LM and pretrain it using the proposed three pretraining strategies based on a particular KB. For each setting, we evaluate the resulting model using the FactCollect dataset and report the BACC scores. We present the performance\nof different settings in Figure 3, which illustrates that regardless of which LM and KB, FACTKB generally results in improved factual error detection capabilities compared to the vanilla LM checkpoints without factuality pretraining. In addition, certain LMs (RoBERTa and DeBERTa) and KBs (YAGO, KGAP, and UMLS) are better than others, suggesting that the choice of the base LM and external KB warrants further research. Our results demonstrate that FACTKB is a general pretraining approach that can be applied to various LM-KB combinations to improve fact representations and develop better factuality evaluation models."
        },
        {
            "heading": "5.3 Simplicity Study",
            "text": "While existing factuality evaluation approaches require additional processing (such as computing the dependency structure (Goyal and Durrett, 2020) and AMR graphs (Ribeiro et al., 2022) or running multiple iterations of question generation (Fabbri et al., 2022)) in the face of new data, FACTKB requires no preprocessing and only uses a fine-tuned RoBERTa for sequence classification. We summarize the steps involved in using existing approaches and their performance on the FRANK benchmark in Table 6, which demonstrates that FACTKB not only has state-of-the-art performance but is also a lightweight and simple factuality evaluation model."
        },
        {
            "heading": "5.4 Parameter Analysis",
            "text": "Corpus size. For evidence extraction and knowledge walk, the pretraining corpus size N is controllable and governs the amount of information towards augmenting FACTKB\u2019s ability towards factual errors regarding entities and relations. While we adopted N = 1e5 in the main experiments,\nwe further explore the effect of factuality pretraining corpus size in Figure 5. It is illustrated that N = 1e4 or N = 1e5 are generally desirable settings, while factuality pretraining with too large Ns might be counterproductive. This could in part be attributed to catastrophic forgetting (Ramasesh et al., 2021), which warrants further research.\nPretraining epoch. FACTKB further pretrains LM checkpoints on the three factuality pretraining corpora, while the training epoch governs the intensity of such exercises. We adopted 5 epochs of continued pretraining in the main experiments, while we further explore the effect of pretraining epochs in Figure 5. it is demonstrated that 1 to 10 epochs are generally desirable while exercising too much might be counterproductive.\nKnowledge walk length. An important aspect of the knowledge walk factuality pretraining is the generated walk length K, which governs the degree of compositionality in the pretraining corpus. While we adopted K = 5 in the main experiments, we further explore the effect of K in Figure 5. It is illustrated that K = 5 performs best by providing a moderate amount of compositionality in the factuality pretraining corpora."
        },
        {
            "heading": "6 Related Work",
            "text": "Factuality Evaluation Recent advances in text summarization have presented models and systems that are capable of generating increasingly fluent, controllable, and informative summaries of documents (Liu and Lapata, 2019; Balachandran et al., 2021; Meng et al., 2022; Tang et al., 2022; Goldsack et al., 2022; Peng et al., 2021; Aharoni et al.,\n2023; Liu et al., 2022d; Rothe et al., 2021; Narayan et al., 2021; Bhattacharjee et al., 2023; Chen et al., 2023b; He et al., 2023; Liu et al., 2023b; Chen et al., 2023a). However, they suffer from hallucination and might not be factually faithful towards the source document (Cao et al., 2018; Pagnoni et al., 2021; Balachandran et al., 2022; Tang et al., 2023; Liu et al., 2023a; Luo et al., 2023), leading to increased research in factuality evaluation. QA-based approaches (Wang et al., 2020a; Nan et al., 2021; Scialom et al., 2021; Fabbri et al., 2022) attempt to generate and answer questions based on summaries and documents and judge the factuality by comparing answers. Later approaches are generally entailment-based (Krys\u0301cin\u0301ski et al., 2020; Goyal and Durrett, 2020, 2021; Laban et al., 2022; Ribeiro et al., 2022), proposing to classify (summary, document) pairs into FACTUAL or NON-FACTUAL labels. Among them, FactCC (Krys\u0301cin\u0301ski et al., 2020) is one of the first entailment-based metrics and is trained on synthetic data; DAE (Goyal and Durrett, 2020, 2021) proposes to leverage the dependency structure of summaries and documents; FactGraph (Ribeiro et al., 2022) builds abstract meaning representation graphs and adopts graph neural networks for joint representation learning along the textual content. In addition, hypothesis re-ranking (Garneau and Lamontagne, 2021), counterfactual estimation (Xie et al., 2021), NLI models (Utama et al., 2022), phrase-level localization (Takatsuka et al., 2022), and weighting facts in the source document (Xu et al., 2020) were also explored in factuality evaluation. Moving beyond a binary concept of factuality, FRANK (Pagnoni et al., 2021) promotes a fine-grained understanding of factuality and proposes a typology of factuality errors. Inspired by its analysis that semantic frame errors, errors regarding entities and relations, are a major source of factuality errors yet under-explored by existing factuality metrics, we propose FACTKB to leverage external KBs for factuality pretraining and help enforce better factuality towards entities and relations discussed in summaries and documents.\nKnowledge Bases in NLP Knowledge base is a standard format for structured knowledge representation. One application of KBs in NLP is to inject knowledge and augment LMs, where different approaches focused aspects such as pretraining (Chen et al., 2020; Agarwal et al., 2021; Rosset et al., 2020; Li et al., 2022), document graphs (Hu et al., 2021; Zhang et al., 2022a), KB structure (Yasunaga\net al., 2021; Zhang et al., 2022b), and long documents (Feng et al., 2023). KB-enhanced approaches also advanced numerous NLP tasks, ranging from question answering (Mitra et al., 2022; Bosselut et al., 2021; Oguz et al., 2022; Feng et al., 2022; Heo et al., 2022; Ma et al., 2022), text generation (Rony et al., 2022; Dognin et al., 2021; Yu et al., 2021), and commonsense reasoning (Kim et al., 2022; Jung et al., 2022; Amayuelas et al., 2021; Liu et al., 2022a). In this work, we tap into KBs\u2019 nature as high-quality reservoirs of factual information and construct factuality pretraining objectives to augment factuality evaluation."
        },
        {
            "heading": "7 Conclusion",
            "text": "We propose FACTKB, a simple and novel approach to factuality evaluation using language models pretrained on facts from external KBs to improve entity and relation representations. Specifically, we leverage KBs to construct three factuality pretraining objectives: entity wiki, evidence extraction, and knowledge walk. FACTKB pretrains an LM using the three objectives and fine-tunes the resulting model on factuality evaluation datasets. Extensive experiments demonstrate that FACTKB advances the state-of-the-art in both in-domain and out-ofdomain factuality evaluation, better correlates with human factuality annotations, and better detects semantic frame errors. FACTKB presents an easy-touse and generalizable factuality metric, facilitating research on factually-consistent summarization.\nLimitations\nLM and KB Selection While Section 5.2 offers empirical evidence that FACTKB is compatible with 6 language models and 6 external knowledge bases, it remains unclear upfront which LM and KB combination would be most desirable. While empirical performance could be a good guide, there are several unaddressed possibilities: For language models, it is possible to leverage an ensemble of FACTKBs seeded with different LM checkpoints and architectures. This might result in better factuality evaluation, but would also dramatically increase the computation costs when evaluating on new data. For knowledge bases, it is possible to leverage domain expertise and select an external knowledge base that would be most helpful for the domain adaptation of factuality evaluation. It is also possible to leverage a combination of existing knowledge bases for FACTKB\u2019s factuality pretraining, while the specific combination and how to apply different factuality pretraining to different KBs are hard to determine. All in all, FACTKB presents a general KB-enhanced factuality metric with numerous possibilities, while we leave some of these considerations to future work.\nFACTKB training is not end-to-end. FACTKB has a two-step training process: pretraining with KB-based factuality pretraining and fine-tuning on factuality evaluation datasets. This creates several limitations, among which is the difficulty of hyperparameter tuning. Appendix 3.1 presents the study of hyperparameters in the factuality pretraining stage, which demonstrates that FACTKB works best with a moderate but not excessive amount of factuality pretraining. This reliance on certain hyperparameter configurations is further complicated by more hyperparameter choices in the fine-tuning stage. While the current hyperparameter setting in Appendix 3.1 achieves state-of-the-art empirical performance, we acknowledge the difficulty in FACTKB hyperparameter tuning.\nOut-of-Domain Factuality Evaluation. An important focus of this work is out-of-domain factuality evaluation: Summarization systems face input documents from varying domains, which requires factuality metrics to also generalize to different document domains. Existing metrics struggle with semantic frame errors and such struggle is exacerbated by the domain shift of entities and relations, while FACTKB offers a stronger and more gener-\nalizable factuality metric. However, in this work, we mainly focused on the additional domain of scientific literature, while other potential domains remain underexplored such as social media (Syed et al., 2019; Kano et al., 2018; He et al., 2020). We leave it to future work the exploration of FACTKB and existing factuality metrics on more document domains that are present in summarization systems.\nTradeoff between Performance and Granularity Existing approaches (Krys\u0301cin\u0301ski et al., 2020; Takatsuka et al., 2022) struggle with semantic frame errors and involve heavy preprocessing, while they provide fine-grained analysis and specific localization of summarization errors. FACTKB achieves significantly better factuality evaluation results and is easier to use while lacking the ability of error localization. We argue that this tradeoff should be considered with the use case in mind: for LLM evaluation, it is better to have an accurate metric for benchmarking efforts and an efficient metric for handling large-scale LM generation. As a result, FACTKB provides a valuable tool for factuality evaluation and LLM research.\nEthics Statement\nLM and KB Bias FACTKB is initialized with pretrained language model checkpoints and leverages knowledge-base-based factuality pretraining. Consequently, FACTKB might pick up the biases of the adopted language models (Liang et al., 2021; Nadeem et al., 2021; Shaikh et al., 2023; Tan and Celis, 2019) and knowledge bases (Fisher et al., 2020; Mehrabi et al., 2021). As a result, FACTKB might leverage these biases in judging the factuality of summaries, further reinforcing the bias in text summarization systems. We leave it to future work on understanding and mitigating the bias of factuality metrics.\nMisuse Potential FACTKB leverages highquality and factual knowledge bases to generate factuality pretraining corpora and augment LM\u2019s ability to stay factual with respect to entities and relations discussed in the summary and document. On the contrary, if non-factual and misleading knowledge is leveraged for the three factuality pretraining strategies, it might jeopardize the factuality of FACTKB and make it insensitive to misinformation and falsehoods in summaries and documents. As a result, we encourage the responsible use of FACTKB and the factuality pretraining methodology."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank the reviewers, the area chair, members of Tsvetshop, and the UW NLP Group for their feedback. This research was supported by This research is supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via the HIATUS Program contract #2022-22072200004. This material is also funded by the DARPA Grant under Contract No. HR001120C0124. We also gratefully acknowledge support from NSF CAREER Grant No. IIS2142739 and the Alfred P. Sloan Foundation Fellowship. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein."
        },
        {
            "heading": "A Merging the three strategies",
            "text": "We also tried combining the three factuality pretraining strategies to obtain FACTKB-COMBINED. We evaluate it on the FactCollect dataset and present results in Table 7. It is demonstrated that FACTKB-COMBINED is not significantly better than using a single factuality pretraining strategy, while we will make all versions of FACTKB publicly available."
        },
        {
            "heading": "B Qualitative Analysis",
            "text": "We present examples of (summary, article) pairs and their factuality scores in Table 9 and 10, where FACTKB is significantly closer to human judgment than existing factuality metrics. It is demonstrated that while existing factuality metrics are insensitive to major errors in entities and relations, FACTKB is capable of identifying inconsistencies and enforcing strict factuality standards."
        },
        {
            "heading": "C Dataset Details",
            "text": "We present more details about the adopted datasets in Table 8. There might be minor differences in certain numbers with the original dataset as a result of data preprocessing. FRANK (Pagnoni et al., 2021) does not explicitly have binary labels such as {FACTUAL, NOT FACTUAL}. It also does not have a training set due to its nature as an evaluation benchmark. HealthVer (Sarrouti et al., 2021) and SciFact (Wadden et al., 2020) originally had NOT ENOUGH INFORMATION labels, while we removed such examples in the out-of-domain factuality evaluation to ensure their compatibility with FactCollect."
        },
        {
            "heading": "D Baseline Details",
            "text": "We present more details about baseline factuality metrics in the following:\n\u2022 BERTScore (Zhang et al., 2019) is a general metric for text generation evaluation based on pretrained BERT (Devlin et al., 2019).\n\u2022 QAGS (Wang et al., 2020a) is a QA-based factuality metric, asking questions about summaries and articles while examining whether the answers are consistent.\n\u2022 QUALS (Nan et al., 2021) is a QA-based factuality metric that uses QAGen (Shakeri et al., 2020) to generate both questions and answers from the summary.\n\u2022 DAE (Goyal and Durrett, 2020) leverages the dependency structure of the summary and article to design a factuality metric.\n\u2022 SummaC (Laban et al., 2022) proposes to revisit and repurpose NLI models for detecting factual inconsistencies in text summarization.\n\u2022 FalseSum (Utama et al., 2022) augments NLI training data with controllable text generation for better factuality evaluation.\n\u2022 FactCC (Krys\u0301cin\u0301ski et al., 2020) is an entailment-based factuality metric trained on synthetic data evaluating factuality with binary classification. FactCC+ is a variant of FactCC providing explanations. FactCC+ is an enhanced version trained with human-annotated data.\n\u2022 FactGraph (Ribeiro et al., 2022) is an entailment-based factuality metric based on jointly analyzing the textual content and AMR graphs of the summary and article. FactGraphadapters is an enhanced version with pretrained adapters for both the text and graph modules."
        },
        {
            "heading": "E LM and KB Details",
            "text": "In Section 5.2, we explored whether FACTKB is compatible with different language models and knowledge bases. For LMs, we used the ROBERTA-BASE, GOOGLE/ELECTRA-BASEDISCRIMINATOR, FACEBOOK/BART-BASE, ALBERT-BASE-V2, MICROSOFT/DEBERTA-V3BASE, DISTILROBERTA-BASE LM checkpoints on Huggingface Transformers. For the six KBs, we used their organized versions: YAGO15k at Lacroix et al. (2019), Wikidata5M at Wang et al. (2021), Atomic at West et al. (2022), ConceptNet at Zhang et al. (2022b), KGAP at Feng et al. (2021), and UMLS at Zhang et al. (2022b)."
        },
        {
            "heading": "F Statistical Significance Test Details",
            "text": "We use the student t-test for statistical significance analysis throughout the paper. Specifically, the t-test calculator for 2 independent means 3 was adopted for the calculations. We use (*) to denote statistical significance in Tables 2 and 5.\n3https://www.socscistatistics.com/tests/ studentttest/default2.aspx"
        },
        {
            "heading": "G Computational Resources",
            "text": "We used a GPU cluster with 16 NVIDIA A40 GPUs, 1988G memory, and 104 CPU cores for the experiments. Factuality pretraining with the default hyperparameters takes around 1.5 hours, while finetuning language models on the FactCollect dataset takes around 30 minutes."
        },
        {
            "heading": "H Scientific Artifacts",
            "text": "FACTKB would not be possible without many open-source scientific artifacts, including pytorch (Paszke et al., 2019), pytorch lightning (Falcon and The PyTorch Lightning team, 2019), transformers (Wolf et al., 2020), sklearn (Pedregosa et al., 2011), numpy (Harris et al., 2020), nltk (Bird et al., 2009), and the six adopted knowledge bases (Pellissier Tanon et al., 2020; Vrandec\u030cic\u0301 and Kr\u00f6tzsch, 2014; West et al., 2022; Speer et al., 2017; Feng et al., 2021; Zhang et al., 2022b). We commit to making our code and data publicly available upon acceptance to facilitate reproduction and further research."
        }
    ],
    "title": "FACTKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge",
    "year": 2023
}