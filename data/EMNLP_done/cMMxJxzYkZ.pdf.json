{
    "abstractText": "Empathetic dialogue is an indispensable part of building harmonious social relationships and contributes to the development of a helpful AI. Previous approaches are mainly based on fine small-scale language models. With the advent of ChatGPT, the application effect of large language models (LLMs) in this field has attracted great attention. This work empirically investigates the performance of LLMs in generating empathetic responses and proposes three improvement methods of semantically similar incontext learning, two-stage interactive generation, and combination with the knowledge base. Extensive experiments show that LLMs can significantly benefit from our proposed methods and is able to achieve state-of-the-art performance in both automatic and human evaluations. Additionally, we explore the possibility of GPT-4 simulating human evaluators.",
    "authors": [
        {
            "affiliations": [],
            "name": "Yushan Qian"
        },
        {
            "affiliations": [],
            "name": "Wei-Nan Zhang"
        },
        {
            "affiliations": [],
            "name": "Ting Liu"
        }
    ],
    "id": "SP:e321ae6948c6934102915b6e80cba0b297846d16",
    "references": [
        {
            "authors": [
                "Guanqun Bi",
                "Lei Shen",
                "Yanan Cao",
                "Meng Chen",
                "Yuqiang Xie",
                "Zheng Lin",
                "Xiaodong He."
            ],
            "title": "Diffusemp: A diffusion model-based framework with multi-grained control for empathetic response generation",
            "venue": "CoRR, abs/2306.01657.",
            "year": 2023
        },
        {
            "authors": [
                "Tom B. Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are fewshot learners",
            "year": 2020
        },
        {
            "authors": [
                "Hua Cai",
                "Xuli Shen",
                "Qing Xu",
                "Weilin Shen",
                "Xiaomei Wang",
                "Weifeng Ge",
                "Xiaoqing Zheng",
                "Xiangyang Xue."
            ],
            "title": "Improving empathetic dialogue generation by dynamically infusing commonsense knowledge",
            "venue": "CoRR, abs/2306.04657.",
            "year": 2023
        },
        {
            "authors": [
                "Yejin Choi"
            ],
            "title": "comet-) atomic 2020",
            "year": 2021
        },
        {
            "authors": [
                "Press. Sevgi Keskin"
            ],
            "title": "From what isn\u2019t empathy",
            "year": 2014
        },
        {
            "authors": [
                "Ho Lee"
            ],
            "title": "Emp-rft: Empathetic response",
            "year": 2022
        },
        {
            "authors": [
                "Young-Jun Lee",
                "Chae-Gyun Lim",
                "Ho-Jin Choi."
            ],
            "title": "Does GPT-3 generate empathetic dialogues? A novel in-context example selection method and automatic evaluation metric for empathetic dialogue generation",
            "venue": "Proceedings of the 29th International",
            "year": 2022
        },
        {
            "authors": [
                "Jiwei Li",
                "Michel Galley",
                "Chris Brockett",
                "Jianfeng Gao",
                "Bill Dolan."
            ],
            "title": "A diversity-promoting objective function for neural conversation models",
            "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-",
            "year": 2016
        },
        {
            "authors": [
                "Qintong Li",
                "Hongshen Chen",
                "Zhaochun Ren",
                "Pengjie Ren",
                "Zhaopeng Tu",
                "Zhumin Chen."
            ],
            "title": "Empdg: Multi-resolution interactive empathetic dialogue generation",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, COLING",
            "year": 2020
        },
        {
            "authors": [
                "Qintong Li",
                "Piji Li",
                "Zhaochun Ren",
                "Pengjie Ren",
                "Zhumin Chen"
            ],
            "title": "Knowledge bridging for empathetic dialogue generation",
            "year": 2022
        },
        {
            "authors": [
                "Zhaojiang Lin",
                "Andrea Madotto",
                "Jamin Shin",
                "Peng Xu",
                "Pascale Fung."
            ],
            "title": "Moel: Mixture of empathetic listeners",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference",
            "year": 2019
        },
        {
            "authors": [
                "Jiachang Liu",
                "Dinghan Shen",
                "Yizhe Zhang",
                "Bill Dolan",
                "Lawrence Carin",
                "Weizhu Chen"
            ],
            "title": "What makes good in-context examples for gpt-3? In Proceedings of Deep Learning Inside Out: The 3rd Workshop on Knowledge Extraction and Integration",
            "year": 2022
        },
        {
            "authors": [
                "Navonil Majumder",
                "Pengfei Hong",
                "Shanshan Peng",
                "Jiankun Lu",
                "Deepanway Ghosal",
                "Alexander F. Gelbukh",
                "Rada Mihalcea",
                "Soujanya Poria."
            ],
            "title": "MIME: mimicking emotions for empathetic response generation",
            "venue": "Proceedings of the 2020 Conference",
            "year": 2020
        },
        {
            "authors": [
                "OpenAI."
            ],
            "title": "GPT-4 technical report",
            "venue": "CoRR, abs/2303.08774.",
            "year": 2023
        },
        {
            "authors": [
                "der",
                "Paul F. Christiano",
                "Jan Leike",
                "Ryan Lowe"
            ],
            "title": "Training language models to follow instructions with human feedback",
            "venue": "NeurIPS",
            "year": 2022
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "WeiJing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, July 6-12, 2002, Philadelphia,",
            "year": 2002
        },
        {
            "authors": [
                "Yushan Qian",
                "Bo Wang",
                "Ting-En Lin",
                "Yinhe Zheng",
                "Ying Zhu",
                "Dongming Zhao",
                "Yuexian Hou",
                "Yuchuan Wu",
                "Yongbin Li."
            ],
            "title": "Empathetic response generation via emotion cause transition graph",
            "venue": "CoRR, abs/2302.11787.",
            "year": 2023
        },
        {
            "authors": [
                "Yushan Qian",
                "Bo Wang",
                "Shangzhao Ma",
                "Bin Wu",
                "Shuo Zhang",
                "Dongming Zhao",
                "Kun Huang",
                "Yuexian Hou."
            ],
            "title": "Think twice: A human-like two-stage conversational agent for emotional response generation",
            "venue": "Proceedings of the 2023 International Con-",
            "year": 2023
        },
        {
            "authors": [
                "Hannah Rashkin",
                "Eric Michael Smith",
                "Margaret Li",
                "Y-Lan Boureau."
            ],
            "title": "Towards empathetic opendomain conversation models: A new benchmark and dataset",
            "venue": "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL",
            "year": 2019
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych."
            ],
            "title": "Sentence-bert: Sentence embeddings using siamese bert-networks",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural",
            "year": 2019
        },
        {
            "authors": [
                "Stephen Roller",
                "Emily Dinan",
                "Naman Goyal",
                "Da Ju",
                "Mary Williamson",
                "Yinhan Liu",
                "Jing Xu",
                "Myle Ott",
                "Eric Michael Smith",
                "Y-Lan Boureau",
                "Jason Weston."
            ],
            "title": "Recipes for building an open-domain chatbot",
            "venue": "Proceedings of the 16th Conference of",
            "year": 2021
        },
        {
            "authors": [
                "Sahand Sabour",
                "Chujie Zheng",
                "Minlie Huang."
            ],
            "title": "CEM: commonsense-aware empathetic response generation",
            "venue": "Thirty-Sixth AAAI Conference on Artifi-",
            "year": 2022
        },
        {
            "authors": [
                "Ashish Sharma",
                "Adam S Miner",
                "David C Atkins",
                "Tim Althoff."
            ],
            "title": "A computational approach to understanding empathy expressed in text-based mental health support",
            "venue": "EMNLP.",
            "year": 2020
        },
        {
            "authors": [
                "Haoyu Song",
                "Yan Wang",
                "Weinan Zhang",
                "Xiaojiang Liu",
                "Ting Liu."
            ],
            "title": "Generate, delete and rewrite: A three-stage framework for improving persona consistency of dialogue generation",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Com-",
            "year": 2020
        },
        {
            "authors": [
                "Lanrui Wang",
                "Jiangnan Li",
                "Zheng Lin",
                "Fandong Meng",
                "Chenxu Yang",
                "Weiping Wang",
                "Jie Zhou."
            ],
            "title": "Empathetic dialogue generation via sensitive emotion recognition and sensible knowledge selection",
            "venue": "Findings of the Association for Computational",
            "year": 2022
        },
        {
            "authors": [
                "Jason Wei",
                "Xuezhi Wang",
                "Dale Schuurmans",
                "Maarten Bosma",
                "Brian Ichter",
                "Fei Xia",
                "Ed H. Chi",
                "Quoc V. Le",
                "Denny Zhou."
            ],
            "title": "Chain-of-thought prompting elicits reasoning in large language models",
            "venue": "NeurIPS.",
            "year": 2022
        },
        {
            "authors": [
                "Anuradha Welivita",
                "Pearl Pu."
            ],
            "title": "A taxonomy of empathetic response intents in human social conversations",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, COLING 2020, Barcelona, Spain (Online), December 8-13,",
            "year": 2020
        },
        {
            "authors": [
                "Anuradha Welivita",
                "Yubo Xie",
                "Pearl Pu."
            ],
            "title": "A large-scale dataset for empathetic response generation",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Domini-",
            "year": 2021
        },
        {
            "authors": [
                "Emmanuelle Zech",
                "Bernard Rim\u00e9."
            ],
            "title": "Is talking about an emotional experience helpful? effects on emotional recovery and perceived benefits",
            "venue": "Clinical Psychology & Psychotherapy, 12:270 \u2013 287.",
            "year": 2005
        },
        {
            "authors": [
                "Tianyi Zhang",
                "Varsha Kishore",
                "Felix Wu",
                "Kilian Q. Weinberger",
                "Yoav Artzi."
            ],
            "title": "Bertscore: Evaluating text generation with BERT",
            "venue": "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenRe-",
            "year": 2020
        },
        {
            "authors": [
                "Weixiang Zhao",
                "Yanyan Zhao",
                "Xin Lu",
                "Bing Qin."
            ],
            "title": "Don\u2019t lose yourself! empathetic response generation via explicit self-other awareness",
            "venue": "CoRR, abs/2210.03884.",
            "year": 2022
        },
        {
            "authors": [
                "Ming Zhong",
                "Yang Liu",
                "Da Yin",
                "Yuning Mao",
                "Yizhu Jiao",
                "Pengfei Liu",
                "Chenguang Zhu",
                "Heng Ji",
                "Jiawei Han."
            ],
            "title": "Towards a unified multidimensional evaluator for text generation",
            "venue": "Proceedings of the 2022 Conference on Empirical Meth-",
            "year": 2022
        },
        {
            "authors": [
                "Jinfeng Zhou",
                "Chujie Zheng",
                "Bo Wang",
                "Zheng Zhang",
                "Minlie Huang."
            ],
            "title": "CASE: aligning coarse-tofine cognition and affection for empathetic response generation",
            "venue": "CoRR, abs/2208.08845.",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Empathetic dialogue plays an essential role in building harmonious social relationships (Zech and Rim\u00e9, 2005). The task of empathetic response generation involves understanding the user\u2019s experiences and feelings, and generating appropriate responses (Keskin, 2014; Rashkin et al., 2019). Using dialogue systems to provide empathetic responses has advantages such as easy access and no time constraints (Sharma et al., 2020). Figure 1 shows an example of the empathetic dialogue from the benchmark dataset.\nMost previous researchers have established elaborately designed models based on reliable theoretical knowledge (Lin et al., 2019; Majumder et al., 2020; Li et al., 2020; Sabour et al., 2022; Li et al., 2022; Zhou et al., 2022). However, the basic models used are mostly small in scale. Recently, large language models (LLMs) (Brown et al., 2020; Chowdhery et al., 2022; Touvron et al., 2023) have\n\u2217 Corresponding author.\nbeen widely used in natural language processing (NLP) with superior performance. In particular, the emergence of ChatGPT has elicited substantial attention and interest in academia and industry, and it has demonstrated extraordinary performance in a variety of tasks, especially dialogue generation. These LLMs are trained on a large amount of corpora, encompassing a wealth of knowledge. In specific tasks, even without fine-tuning, outstanding performance can be achieved by adopting some gradient-free techniques (Brown et al., 2020; Wei et al., 2022) (e.g., in-context learning (ICL)). Therefore, it is necessary to empirically explore the performance of LLMs on specific domains, as the methods of solving problems may undergo significant changes. There have been some initial attempts (Roller et al., 2021; Lee et al., 2022) to apply LLMs to empathetic response generation. However, their approaches mainly focus on pre-training or fine-tuning on the training data, or simply exploring the capability of a single model.\nTo investigate the capability of LLMs in empathetic response generation, this work empirically studies the performance of LLMs on the empathetic dialogue benchmark dataset. We first compare LLMs in the zero-shot and few-shot ICL set-\ntings with a large number of baseline models. Surprisingly, the performance of the GPT-3.5 series of LLMs with in-context learning settings has comprehensively surpassed state-of-the-art models. This reveals that the paradigm shift brought by LLMs also applies to empathetic dialogue. Furthermore, based on the best performance LLM setting, we propose three possible methods to improve its performance. Specifically, improvement via semantically similar in-context learning, two-stage interactive generation, and combination with the knowledge base. Extensive automatic and human evaluation experiments show that LLMs can benefit from our proposed methods, which can generate more empathetic, coherent, and informative responses. In addition, although human evaluation is crucial in empathetic dialogue, its associated costs and time consumption are enormous. In view of the outstanding performance of LLMs on empathetic response generation, we attempt to use GPT-4 (OpenAI, 2023) to simulate human evaluators to evaluate the results. The Spearman and Kendall-Tau correlation results indicate that GPT-4 has the potential to be a substitute for human evaluators.\nOur contributions are summarized as follows: (1) To the best of our knowledge, it is the first comprehensive empirical investigation on the performance of LLMs represented by ChatGPT on empathetic dialogue.\n(2) We construct a unified prompt template for the empathetic response generation, and LLMs guided by the template achieve outstanding performance.\n(3) We propose three targeted improvement methods, and sufficient experiments demonstrate their effectiveness.\n(4) We explore the possibility of GPT-4 simulating human evaluators."
        },
        {
            "heading": "2 Related Work",
            "text": ""
        },
        {
            "heading": "2.1 Empathetic Response Generation",
            "text": "Empathy is a complex multi-dimensional structure in psychology and has rich forms in practice (Davis et al., 1980). At present, two main forms of modeling empathy are affective empathy and cognitive empathy (Davis, 1983). Affective empathy oriented methods include mixture of experts (Lin et al., 2019), emotion mimicry (Majumder et al., 2020), and multi-resolution user feedback (Li et al., 2020). Cognitive empathy oriented methods include emotion causes (Gao et al., 2021; Kim et al., 2021;\nQian et al., 2023a), empathetic intents (Welivita and Pu, 2020; Chen et al., 2022), external knowledge (Li et al., 2022; Sabour et al., 2022; Zhou et al., 2022; Cai et al., 2023). Besides, Wang et al. (2022) models the interaction between knowledge and emotion, Zhao et al. (2022) considers self-other awareness, Bi et al. (2023) and Kim et al. (2022) propose multi-grained and fine-grained levels, respectively. However, most of researchers design elaborate small-scale models and the application of LLMs represented by ChatGPT in the empathetic dialogue has not been fully empirically explored."
        },
        {
            "heading": "2.2 Large Language Models",
            "text": "Large language models (LLMs) such as GPT-3 (Brown et al., 2020), PaLM (Chowdhery et al., 2022), and LLaMA (Touvron et al., 2023) are pretrained on extensive and large amounts of data, and their tens or hundreds of billions of parameters contain a lot of knowledge. Recently, in combination with new training techniques such as reinforcement learning from human feedback (RLHF) and instruction tuning (Ouyang et al., 2022), the capabilities of LLMs have made a qualitative leap. For example, the emergence of ChatGPT has aroused great interest in academia and industry, demonstrating extraordinary capabilities in a variety of tasks. GPT-4 (OpenAI, 2023) has given some researchers a glimpse of the spark of artificial general intelligence (AGI) (Bubeck et al., 2023). The powerful in-context learning capabilities of LLMs have also led to a paradigm shift.\nThere are some preliminary attempts to apply LLMs to empathetic dialogue. Blenderbot (Roller et al., 2021) can properly demonstrate empathy through the introduction of the blended skill talk (BST) setup and the correct choice of generation strategies. However, the implementation of empathy is mainly through pre-training with high-quality data and does not utilize the emerging ICL capabilities of LLMs. Lee et al. (2022) explores the performance of GPT-3 to generate empathetic responses with prompt-based in-context learning capabilities. However, they only explore GPT-3, and the capabilities of LLMs have greatly improved with the emergence of new training technologies."
        },
        {
            "heading": "3 Methodology",
            "text": ""
        },
        {
            "heading": "3.1 Overview",
            "text": "Formally, the dialogue context is alternate utterances between the speaker and the listener, defined\nas C = {U1, U2, . . . , Un\u22121}, where Ui represents the i-th utterance and n denotes the number of utterances in a dialogue. Our goal is to play the role of the listener and generate the empathetic, coherent and informative response Y , which is Un.\nThe overview of our proposed methods is illustrated in Figure 2, which includes the devised unified template of empathetic response generation and three improvement methods. The left part describes the improvement via two-stage interactive generation, the middle part displays the components of the devised unified template and the improvement via semantically similar in-context learning, and the right part illustrates details of improvement via the knowledge base."
        },
        {
            "heading": "3.2 Preliminary Exploration",
            "text": "LLMs possess the ability of in-context learning (ICL) (Brown et al., 2020), by providing task instructions and some examples to LLMs, they can perform related tasks without fine-tuning. This capability significantly alleviates the demand for training data. We first investigate the performance of LLMs on zero-shot ICL and few-shot ICL in empathetic response generation. Since different prompts may affect performance, we strive to maintain a consistent style when designing prompts. The devised prompt template for empathetic dialogue consists of the following components:\nTask Definition + Guideline Instruction + Exemplars (optional) + Dialogue Context\nAmong them, Task definition is the researchers\u2019 standard definition of the task. Guideline Instruction is the instruction we expect the model to follow. Exemplars are complete instances of dialogs used to help models better understand the task. Dialogue Context is the historical dialogue between the speaker and the listener, and the last sentence is the speaker\u2019s utterance. Our goal is to let the dialogue system generate the next round of the listener\u2019s utterance. The example of the prompt template is listed in Appendix A.\nIn the preliminary experimental exploration, we perform three groups of settings.\n0-shot. This represents a straightforward approach to leverage LLMs for empathetic response generation, which means there are no Exemplars.\n1-shot. We randomly sample a complete dialogue from the training set as the Exemplar.\n5-shot. We randomly sample five complete dialogues from the training set as the Exemplars."
        },
        {
            "heading": "3.3 Advanced Exploration",
            "text": "In this section, we gradually introduce three methods to improve the performance of LLMs in generating empathetic responses."
        },
        {
            "heading": "3.3.1 Improvement via Semantically Similar In-Context Learning",
            "text": "As Liu et al. (2022) argues, a small amount of carefully selected data can greatly improve the performance of LLMs without a large amount of data. We reasonably speculate that in addition to the number of instances, the quality of the instances will\nalso have an impact on the model\u2019s performance. Therefore, when choosing in-context instances, we select a few instances from the training set whose dialogue context semantics are closest to those in the test set.\nSpecifically, we concatenate the dialogue context of each instance into a long sentence and use a sentence encoder to obtain its vector representation, which represents the semantics of each instance\u2019s dialogue context. For the sentence encoder, we adpot the \u201call-mpnet-base-v2\u201d version of sentencetransformers (Reimers and Gurevych, 2019).1 It maps sentences to a 768 dimensional dense vector space. The sentence embedding model was trained on very large sentence level datasets using a self-supervised contrastive learning objective. The similarity between semantics is measured by calculating the cosine similarity between the vector representations of two sentences:\nS = U1 \u2295 U2 \u2295 ...\u2295 Un\u22121, (1)\nEtrain = Encsen(Strain), (2)\nEtest = Encsen(Stest), (3)\nSim(Strain, Stest) = Etrain \u00b7 Etest |Etrain||Etest| , (4)\nwhere Etrain, Etest are the sentence encodings of the dialogue context in the training and test set, respectively. Sim() is used to calculate the similarity of two sentence vectors."
        },
        {
            "heading": "3.3.2 Improvement via Two-stage Interactive Generation",
            "text": "In the setting of the empathetic dialogue task, the dialogue system needs to infer what the speaker\u2019s emotion is and what the situation is that caused this emotion, so as to provide an appropriate response. Inspired by some pipeline methods in open-domain dialogue (Song et al., 2020; Qian et al., 2023b) and combining the characteristics of empathetic response generation, we can conduct the multi-turn interaction to let LLMs generate appropriate responses. Specifically, in the first stage, we let LLMs speculate on the user\u2019s emotional state and experienced situation. In the second stage, the inferred intermediate results are used as input to continue calling LLMs to obtain the final response. Formally, we can express it as:\nP (Y |T,G,C) = P (e, s|T,G,C)P (Y |e, s), (5) 1https://huggingface.co/sentence-transformers/all-mpnet-\nbase-v2\nwhere T , G, C are Task Definition, Guideline Instruction and Dialogue Context, respectively. e and s represent the inferred emotion and situation, respectively.\nThe prompts we designed in two stages are:\n[The first stage] \u201cDon\u2019t rush to reply yet, let\u2019s think step by step. Based on the existing dialogue, what may be the user\u2019s emotion, and according to his description, what may be the situation when he feels this way?\u201d\n[The second stage] \u201cNow combine your thoughts with the existing dialogue context and give your response.\u201d\nThe model\u2019s thought process during the intermediate step is a basis for generating the final response, enhancing the model\u2019s interpretability. At the same time, it also facilitates the analysis of the impact of different key factors (such as emotions and situations) on the final result. Moreover, clearer error analysis is possible when generating responses do not work well."
        },
        {
            "heading": "3.3.3 Improvement via Knowledge Base",
            "text": "Merely inferring the speaker\u2019s emotions and situation from the historical dialogue is insufficient. A direct evidence is that the response has almost no non-stopword overlapping with the dialogue history in the benchmark dataset (Li et al., 2022). Dialogue systems need more external knowledge to conduct empathetic dialogue. LLMs store a large amount of knowledge through weights, so when performing specific tasks, how to better stimulate the use of relevant knowledge is crucial for improving the effect. An alternative solution is to fine-tune LLMs for specific tasks, but this process usually requires expensive hardware, time, and training data. Inspired by recent work on empathetic dialogue (Sabour et al., 2022), we augment the dialogue context with the commonsense knowledge graph, dynamically utilize external information to stimulate the relevant knowledge encoded by LLMs, and thus generate more empathetic responses.\nSimilar to Sabour et al. (2022); Zhou et al. (2022), we adopt the commonsense knowledge base ATOMIC2020 (Hwang et al., 2021), which contains knowledge not readily available in pre-trained language models, and can generate accurate and representative knowledge for unseen entities and\nevents. The ATOMIC2020 knowledge base is in the form of event, relation type and inferred knowledge triples. We adopt the BART version of COMET (Hwang et al., 2021) trained on this knowledge base to generate commonsense inferences of five relations (xIntent, xNeed, xWant, xEffect, xReact) for dialogue contexts. We also design an algorithm to construct the suitable prompt, which can dynamically concatenate the corresponding commonsense inferences according to different dialogue contexts, enriching the input representation, so as to stimulate the relevant knowledge of LLMs more accurately and generate more appropriate responses:\nCSr = COMETBART(C, r), (6)\nCSkno = \u2295 R CSr, (7)\nC \u2032 = C + CSkno, (8)\nP (Y ) = P (Y |T,G,C \u2032), (9)\nwhere r represents the relation type, r \u2208 R, and R = {xIntent, xNeed, xWant, xEffect, xReact}. CSkno is the concatenated external knowledge."
        },
        {
            "heading": "4 Experimental Setup",
            "text": ""
        },
        {
            "heading": "4.1 Dataset",
            "text": "EMPATHETICDIALOGUES (Rashkin et al., 2019) is a large-scale benchmark dataset of multi-turn empathetic dialogue in English. Each dialogue in the dataset has an emotion label (32 types in total) and the situation corresponding to the emotion label. The speaker talks about their situation and the listener attempts to understand the speaker\u2019s feelings and reply appropriately."
        },
        {
            "heading": "4.2 Compared Models",
            "text": "We compare LLMs with the recent state-of-the-art models: (1) MoEL (Lin et al., 2019). (2) MIME (Majumder et al., 2020). (3) EmpDG (Li et al., 2020). (4) EC (Gao et al., 2021). (5) EmpHi (Chen et al., 2022). (6) KEMP (Li et al., 2022). (7) CEM (Sabour et al., 2022). (8) CASE (Zhou et al., 2022). (9) BlenderBot (Roller et al., 2021). The details of compared models are listed in Appendix B."
        },
        {
            "heading": "4.3 Evaluation Metrics",
            "text": "We follow previous related studies, conducting both automatic and human evaluations, and choose as many metrics as possible.\nAutomatic Evaluation We adopt Distinct-n (Dist-1/2) (Li et al., 2016), BERTscore (PBERT, RBERT, FBERT) (Zhang et al., 2020), BLEU-n (B2/4) (Papineni et al., 2002) as main automatic metrics for the performance of the response generation. Distinct-n measures the proportion of distinct ngrams of the response, which is used for diversity evaluation in open-domain dialogue. BERTScore leverages the pre-trained embeddings from BERT and matches words in candidate and reference sentences by cosine similarity. We employ matching precision, recall and F1 score. BLEU-n measures the similarity and relevance between the generated and golden responses. We don\u2019t employ Perplexity (PPL) because there are differences in the vocabulary of multiple models. Additionally, some baseline models perform emotion classification as a part of their training process, we also report the emotion prediction accuracy (Acc).\nHuman Evaluation In human evaluation, we randomly sample 100 dialogues from the testing dataset. Considering both the human labor cost and the reliability of the experiment, we select competitive models from the past year (including state-of-the-art) and BlenderBot as representative baselines. Given the dialogue context and these models\u2019 generated responses, we recruit three annotators (majority rule) to assign a score from 1 to 5 (1: not at all, 3: OK, 5: very good) to the generated responses based on the aspects of Empathy, Coherence, Informativity, and Fluency. The four aspects are 1) Empathy (Emp): whether the response shows an understanding of the user\u2019s feelings and experiences, and expresses appropriately; 2) Coherence (Coh): whether the response is coherent and relevant to the context; 3) Informativity (Inf): whether the response contains more valuable information; 4) Fluency (Flu): whether the response is readable. More details about the human evaluation can be found in Appendix C.\nFurthermore, we conduct another human A/B test to directly compare different models, taking into account the variation among different individuals. Following Sabour et al. (2022), we conduct the pairwise preference test based on aspects. Given the context, we pair the responses generated by two different methods and ask annotators to choose the better response based on the context and the above four aspects. If the difference is really not significant, a tie is allowed."
        },
        {
            "heading": "4.4 Implementation Details",
            "text": "We use OpenAI\u2019s GPT family 2 as our LLMs. More specifically, we use the model gpt-3.5-turbo provided in the OpenAI API, which is the base model of ChatGPT. We also test with GPT-3 davinci and another version of GPT-3.5 (text-davinci-003). we set temperature to 0 to make the outputs mostly deterministic in the experiment. We divide the dataset into training, validation, and testing set according to the original paper (Rashkin et al., 2019) with 8:1:1. For a fair comparison, the parameter settings of all SOTA models are consistent with those recommended in their initial paper or code."
        },
        {
            "heading": "5 Results and Analysis",
            "text": ""
        },
        {
            "heading": "5.1 Preliminary Exploration Results",
            "text": "Table 1 shows the automatic evaluation results between LLMs and baselines. LLMs significantly outperform existing SOTA baselines and achieve a significant improvement on all automatic metrics, especially diversity. For Dist-1/2, LLMs achieve 51.8%[=(2.96- 1.95)/1.95] and 92.7%[=(18.29-9.49)/9.49] im-\n2https://platform.openai.com/docs/models\nprovement, which demonstrates a significant advantage of LLMs in diverse language expression (mainly unigrams and bigrams). In terms of BERTScore and BERT, LLMs achieve the average improvement of 2.1%[=(2.6+1.6+2.1)/3] and 26.95%[=(18.6+35.3)/2], respectively. This highlights the power of LLMs\u2019 in-context learning capability that can be quickly applied to unseen specific tasks. In addition, we observe that the number of exemplars is positively correlated with diversity performance, which suggests the addition of examplars can influence the linguistic habits of LLMs.\nIn the human evaluation, we select ChatGPT (+ 5-shot), which leads in most automatic metrics, as the representative of LLMs. The human ratings and the human A/B test results are listed in Table 2 and Table 4, respectively. We observe ChatGPT also outperforms baselines by a large margin on all aspects, which further demonstrates the outstanding performance of LLMs in generating empathetic, coherent and informative responses. Additionally, we note that the scores of the baselines are lower than in previous studies. This is due to the superior performance of ChatGPT in empathetic dialogue, which relatively raises the standards. It can be corroborated by the fact that in over 70% of the cases in the A/B test that human annotators prefer responses generated by ChatGPT. For Fluency aspect, there is no significant difference between models, since the responses generated by existing models are already fluent. Therefore, we do not need to compare separately in the A/B test."
        },
        {
            "heading": "5.2 Advanced Exploration Results",
            "text": "Experimental results of the advanced exploration on LLMs are shown in Table 3 and the lower part of Table 4. Overall, the responses generated by the three improvement methods we proposed are more favorably received by human annotators in\nall aspects during the human A/B test, compared to the responses generated by the original ChatGPT. These results verify the effectiveness of the choice for in-context exemplars, two-stage interaction generation and enhancement of knowledge related to the context. In the automatic evaluation, the Similar ICL improvement method obtains the best performance, this is attributed to that most automatic metrics tend to favor responses that are closer to the ground truth. However, introducing more thoughts or more information could potentially deviate from the ground truth, even if it\u2019s an appropriate response that humans like. Besides, to verify whether the correct inferred emotion or situation has an impact on the generated responses, we conduct two variants experiments of two-stage interactive generation. By separately replacing the model\u2019s thinking outputs in the first stage with the truth emotion and situation, results show an enhancement in both BERTScore and BERT metrics. However, this causes a loss in diversity."
        },
        {
            "heading": "5.3 Case Study",
            "text": "The generated responses from five competitive baselines and our proposed methods of LLMs are listed in Table 5. It can be observed that most baselines understand the user\u2019s feeling, but only pro-\nvide simple comforting responses (\u201cwill be fine\u201d). Blenderbot generates the response with more information while it only supports the user\u2019s idea without giving reasons and suggestions. Compared with other baselines, our proposed methods fully understand the user\u2019s feeling and generates more empathetic, coherent, and informative responses.\nThen we analyze the performance of the improvement methods in this case. The method of semantically similar ICL provides additional suggestions to alleviate the user\u2019s sadness emotion (\u201cfocus on things that make you happy\u201d, \u201ctake your mind off \u201d) by learning from relevant instances. The method of two-stage interaction generation reflects inferred user\u2019s emotion and situation more specifically in the response. The method of combination with the knowledge base generates the relevant and empathetic response based on the commonsense inference (\u201ctalk to her\u201d) of [xwant]. More cases can be found in the Appendix D."
        },
        {
            "heading": "5.4 Analysis of LLM Simulating Human Evaluators",
            "text": "LLMs have shown outstanding performance in generating empathetic responses. Naturally, we wonder if it is possible to use LLMs to simulate human evaluators to evaluate the performance of other models. Compared to human evaluators, the latter has lower costs and shorter time consumption. Therefore, we adopt GPT-4 as the evaluator to conduct the A/B test under the same settings. Following Zhong et al. (2022), we use Spearman and\nKendall-Tau correlations to assess the performance of human evaluators and GPT-4. The results are shown in Table 6. We can observe that GPT-4 achieves the best correlation with human evaluators on the aspect of empathy. We observe that GPT-4 has fairly good results in Spearman and Kendalltau with human evaluators on all aspects (refer to Zhong et al. (2022)), and achieves the best correlation in the aspect of empathy. This indicates the potential of LLMs to simulate human evaluators."
        },
        {
            "heading": "6 Conclusion and Future Work",
            "text": "In this work, we empirically study the performance of LLMs on empathetic response generation and propose three improvement methods. Empirical automatic and human evaluation results show that LLMs significantly outperform state-of-the-art models, and verify the effectiveness of our proposed improvements of LLMs.\nIn the future, our work can contribute to deeper comprehension and the application of LLMs for empathetic dialogue, and provide some insights for similar tasks."
        },
        {
            "heading": "Acknowledgements",
            "text": "This work is supported by the National Key Research and Development Program (No. 2022YFF0902100) and National Natural Science Foundation of China (No. 62076081 and No. 61936010).\nLimitations\nThe main limitation of our work is the shortage of standard datasets in the task of empathetic response generation. Although there are efforts (Welivita et al., 2021) to construct relevant datasets, their quality and popularity are far inferior to EMPATHETICDIALOGUES. Another limitation is that empathy is a complex concept, and different personalities, backgrounds, and cultures may have different ways of expressing empathy. However, our work do not consider the above factors, and we will explore them in the future work.\nEthics Statement\nThe dataset we adopt in this paper is a publicly available corpus. The EmpatheticDialogues dataset is annotated by Amazon Mechanical Turk, and the dataset provider filters all personal information and unethical language. We belieive that this work complies with the ethical policy of EMNLP."
        },
        {
            "heading": "A Prompt Template",
            "text": "Table 7 shows the example of the prompt template."
        },
        {
            "heading": "B Comparable Models Details",
            "text": "The following are the models we compared in the experiments. We use the official codes and follow the implementations.\n(1) MoEL (Lin et al., 2019): A Transformerbased model that employs multiple emotion specific decoders to generate empathetic responses 3.\n(2) MIME (Majumder et al., 2020): A Transformer-based model that explicitly targets empathetic dialogue by leveraging polarity-based emotion clusters and emotion mimicry 4.\n(3) EmpDG (Li et al., 2020): An interactive adversarial model which exploits the user feedback, the coarse-grained dialogue-level, and fine-grained token-level emotions 5.\n(4) EC (Gao et al., 2021): Employing the identification of emotion causes of the context and gated mechanism to enhance the generation of empathetic responses. There are soft and hard gated mechanisms 6.\n(5) EmpHi (Chen et al., 2022): Employing a discrete latent variable to understand the distribution of potential empathetic intentions, and integrating\n3https://github.com/HLTCHKUST/MoEL 4https://github.com/declare-lab/MIME 5https://github.com/qtli/EmpDG 6https://github.com/A-Rain/EmpDialogue_RecEC\nimplicit and explicit intent representations to produce empathetic responses 7.\n(6) KEMP (Li et al., 2022): A model leverages external knowledge, including commonsense and emotional lexical knowledge, to explicitly understand and express emotions in empathetic dialogue generation 8.\n(7) CEM (Sabour et al., 2022): A new approach leverages commonsense knowledge, combining affective and cognitive aspects, to further enhance empathetic expressions in generated responses 9.\n(8) CASE (Zhou et al., 2022): Align users\u2019 cognition and affection at coarse-grained and finegrained levels through the commonsense cognitive graph and emotional concept graph 10.\n(9) BlenderBot (Roller et al., 2021): An opendomain chatbot with a number of skills. We adopt BlenderBot 90M, which was fine-tuned on the EMPATHETICDIALOGUES train dataset 11."
        },
        {
            "heading": "C Human Evaluation Details",
            "text": "For each case, we provide the annotators with the dialogue context and responses from compared models. The responses of compared models in each case are randomly disrupted, so the evaluators are not affected by the order of the models."
        },
        {
            "heading": "D Additional Case Study",
            "text": "Table 8 shows additional case study of generated responses from SOTA baselines and our proposed methods.\n7https://github.com/mattc95/EmpHi 8https://github.com/qtli/KEMP 9https://github.com/Sahandfer/CEM\n10https://github.com/jfzhouyoo/CASE 11https://parl.ai/projects/recipes"
        }
    ],
    "title": "Harnessing the Power of Large Language Models for Empathetic Response Generation: Empirical Investigations and Improvements",
    "year": 2023
}