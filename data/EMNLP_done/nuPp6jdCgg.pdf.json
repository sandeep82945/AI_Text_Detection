{
    "abstractText": "While recent studies have looked into the abilities of large language models in various benchmark tasks, few studies have looked into the controllability of large language models on generation tasks. We present a systematic and extensive analysis of the controllability of large language models on ten benchmarks, including a new simple yet challenging numerical planning benchmark with different granularities. After comparing large language models against state-of-the-start finetuned smaller models, we present a spectrum showing when large language models fall behind, are comparable, or exceed the ability of smaller models. We conclude that large language models struggle at meeting fine-grained hard constraints.",
    "authors": [
        {
            "affiliations": [],
            "name": "Jiao Sun"
        },
        {
            "affiliations": [],
            "name": "Yufei Tian"
        },
        {
            "affiliations": [],
            "name": "Wangchunshu Zhou"
        },
        {
            "affiliations": [],
            "name": "Nan Xu"
        },
        {
            "affiliations": [],
            "name": "Qian Hu"
        },
        {
            "affiliations": [],
            "name": "Rahul Gupta"
        },
        {
            "affiliations": [],
            "name": "John Wieting"
        },
        {
            "affiliations": [],
            "name": "Nanyun Peng"
        },
        {
            "affiliations": [],
            "name": "Xuezhe Ma"
        }
    ],
    "id": "SP:efb3378914013a121e85308d2d74be73f4d0d5a8",
    "references": [
        {
            "authors": [
                "Arshiya Aggarwal",
                "Jiao Sun",
                "Nanyun Peng."
            ],
            "title": "Towards robust NLG bias evaluation with syntactically-diverse prompts",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022, pages 6022\u20136032, Abu Dhabi, United Arab",
            "year": 2022
        },
        {
            "authors": [
                "Shourya Aggarwal",
                "Divyanshu Mandowara",
                "Vishwajeet Agrawal",
                "Dinesh Khandelwal",
                "Parag Singla",
                "Dinesh Garg."
            ],
            "title": "Explanations for CommonsenseQA: New Dataset and Models",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for",
            "year": 2021
        },
        {
            "authors": [
                "Kabir Ahuja",
                "Harshita Diddee",
                "Rishav Hada",
                "Millicent Ochieng",
                "Krithika Ramesh",
                "Prachi Jain",
                "Akshay Nambi",
                "Tanuja Ganu",
                "Sameer Segal",
                "Maxamed Axmed",
                "Kalika Bali",
                "Sunayana Sitaram"
            ],
            "title": "Mega: Multilingual evaluation of generative ai",
            "year": 2023
        },
        {
            "authors": [
                "David Alvarez-Melis",
                "T. Jaakkola."
            ],
            "title": "Towards robust interpretability with self-explaining neural networks",
            "venue": "NeurIPS.",
            "year": 2018
        },
        {
            "authors": [
                "Peter Anderson",
                "Basura Fernando",
                "Mark Johnson",
                "Stephen Gould."
            ],
            "title": "Guided open vocabulary image captioning with constrained beam search",
            "venue": "Proceedings of the 2017 Conference on Empirical",
            "year": 2017
        },
        {
            "authors": [
                "Mingda Chen",
                "Qingming Tang",
                "Sam Wiseman",
                "Kevin Gimpel."
            ],
            "title": "A multi-task approach for disentangling syntax and semantics in sentence representations",
            "venue": "pages 2453\u20132464, Minneapolis, Minnesota. Association for Computational Linguistics.",
            "year": 2019
        },
        {
            "authors": [
                "Wei-Lin Chiang",
                "Zhuohan Li",
                "Zi Lin",
                "Ying Sheng",
                "Zhanghao Wu",
                "Hao Zhang",
                "Lianmin Zheng",
                "Siyuan Zhuang",
                "Yonghao Zhuang",
                "Joseph E. Gonzalez",
                "Ion Stoica",
                "Eric P. Xing"
            ],
            "title": "Vicuna: An opensource chatbot impressing gpt-4 with 90%* chatgpt",
            "year": 2023
        },
        {
            "authors": [
                "Narang",
                "Gaurav Mishra",
                "Adams Yu",
                "Vincent Zhao",
                "Yanping Huang",
                "Andrew Dai",
                "Hongkun Yu",
                "Slav Petrov",
                "Ed H. Chi",
                "Jeff Dean",
                "Jacob Devlin",
                "Adam Roberts",
                "Denny Zhou",
                "Quoc V. Le",
                "Jason Wei"
            ],
            "title": "Scaling instruction-finetuned language",
            "year": 2022
        },
        {
            "authors": [
                "Hyung Won Chung",
                "Le Hou",
                "Shayne Longpre",
                "Barret Zoph",
                "Yi Tay",
                "William Fedus",
                "Eric Li",
                "Xuezhi Wang",
                "Mostafa Dehghani",
                "Siddhartha Brahma"
            ],
            "title": "Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416",
            "year": 2022
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
            "year": 2019
        },
        {
            "authors": [
                "Angela Fan",
                "Mike Lewis",
                "Yann Dauphin."
            ],
            "title": "Hierarchical neural story generation",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 889\u2013898, Melbourne, Australia. Association",
            "year": 2018
        },
        {
            "authors": [
                "Jun Gao",
                "Huan Zhao",
                "Changlong Yu",
                "Ruifeng Xu"
            ],
            "title": "Exploring the feasibility of chatgpt for event extraction",
            "year": 2023
        },
        {
            "authors": [
                "Silin Gao",
                "Yichi Zhang",
                "Zhijian Ou",
                "Zhou Yu."
            ],
            "title": "Paraphrase augmented task-oriented dialog generation",
            "venue": "ArXiv, abs/2004.07462.",
            "year": 2020
        },
        {
            "authors": [
                "Tianyu Gao",
                "Xingcheng Yao",
                "Danqi Chen."
            ],
            "title": "SimCSE: Simple contrastive learning of sentence embeddings",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 6894\u20136910, Online and Punta Cana, Do-",
            "year": 2021
        },
        {
            "authors": [
                "John Hewitt",
                "Christopher Manning",
                "Percy Liang."
            ],
            "title": "Truncation sampling as language model desmoothing",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022, pages 3414\u2013 3427, Abu Dhabi, United Arab Emirates. Association",
            "year": 2022
        },
        {
            "authors": [
                "Ari Holtzman",
                "Jan Buys",
                "Li Du",
                "Maxwell Forbes",
                "Yejin Choi"
            ],
            "title": "The curious case of neural text degeneration",
            "year": 2020
        },
        {
            "authors": [
                "Kuan-Hao Huang",
                "Kai-Wei Chang."
            ],
            "title": "Generating syntactically controlled paraphrases without using annotated parallel pairs",
            "venue": "ArXiv, abs/2101.10579.",
            "year": 2021
        },
        {
            "authors": [
                "Mohit Iyyer",
                "John Wieting",
                "Kevin Gimpel",
                "Luke Zettlemoyer."
            ],
            "title": "Adversarial example generation with syntactically controlled paraphrase networks",
            "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computa-",
            "year": 2018
        },
        {
            "authors": [
                "Wenxiang Jiao",
                "Wenxuan Wang",
                "Jen tse Huang",
                "Xing Wang",
                "Zhaopeng Tu"
            ],
            "title": "Is chatgpt a good translator? yes with gpt-4 as the engine",
            "year": 2023
        },
        {
            "authors": [
                "Wenxiang Jiao",
                "Wenxuan Wang",
                "Jen tse Huang",
                "Xing Wang",
                "Zhaopeng Tu"
            ],
            "title": "Is chatgpt a good translator? yes with gpt-4 as the engine",
            "year": 2023
        },
        {
            "authors": [
                "Phillip Keung",
                "Yichao Lu",
                "Gy\u00f6rgy Szarvas",
                "Noah A. Smith."
            ],
            "title": "The multilingual Amazon reviews corpus",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4563\u20134568, Online. Association for",
            "year": 2020
        },
        {
            "authors": [
                "Been Kim."
            ],
            "title": "Interactive and interpretable machine learning models for human machine collaboration",
            "venue": "Ph.D. thesis, Massachusetts Institute of Technology.",
            "year": 2015
        },
        {
            "authors": [
                "A. Kumar",
                "Kabir Ahuja",
                "Raghuram Vadapalli",
                "P. Talukdar."
            ],
            "title": "Syntax-guided controlled generation of paraphrases",
            "venue": "Transactions of the Association for Computational Linguistics, 8:330\u2013345.",
            "year": 2020
        },
        {
            "authors": [
                "Po-Nien Kung",
                "Nanyun Peng."
            ],
            "title": "Do models really learn to follow instructions? an empirical study of instruction tuning",
            "venue": "ACL 2023.",
            "year": 2023
        },
        {
            "authors": [
                "Md Tahmid Rahman Laskar",
                "M Saiful Bari",
                "Mizanur Rahman",
                "Md Amran Hossen Bhuiyan",
                "Shafiq R. Joty",
                "J. Huang"
            ],
            "title": "A systematic study and comprehensive evaluation of chatgpt on benchmark datasets",
            "year": 2023
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdel rahman Mohamed",
                "Omer Levy",
                "Veselin Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "Bart: Denoising sequence-to-sequence pre-training for natural language",
            "year": 2019
        },
        {
            "authors": [
                "Xiang Lisa Li",
                "Ari Holtzman",
                "Daniel Fried",
                "Percy Liang",
                "Jason Eisner",
                "Tatsunori Hashimoto",
                "Luke Zettlemoyer",
                "Mike Lewis."
            ],
            "title": "Contrastive decoding: Open-ended text generation as optimization",
            "venue": "arXiv preprint arXiv:2210.15097.",
            "year": 2022
        },
        {
            "authors": [
                "Xiang Lisa Li",
                "John Thickstun",
                "Ishaan Gulrajani",
                "Percy Liang",
                "Tatsunori Hashimoto."
            ],
            "title": "DiffusionLM improves controllable text generation",
            "venue": "Advances in Neural Information Processing Systems.",
            "year": 2022
        },
        {
            "authors": [
                "Bill Yuchen Lin",
                "Wangchunshu Zhou",
                "Ming Shen",
                "Pei Zhou",
                "Chandra Bhagavatula",
                "Yejin Choi",
                "Xiang Ren."
            ],
            "title": "CommonGen: A constrained text generation challenge for generative commonsense reasoning",
            "venue": "Findings of the Association for Computa-",
            "year": 2020
        },
        {
            "authors": [
                "Zachary C Lipton."
            ],
            "title": "The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery",
            "venue": "Queue, 16(3):31\u201357.",
            "year": 2018
        },
        {
            "authors": [
                "Ximing Lu",
                "Peter West",
                "Rowan Zellers",
                "Ronan Le Bras",
                "Chandra Bhagavatula",
                "Yejin Choi."
            ],
            "title": "NeuroLogic decoding: (un)supervised neural text generation with predicate logic constraints",
            "venue": "Proceedings of the 2021 Conference of the North American Chap-",
            "year": 2021
        },
        {
            "authors": [
                "Clara Meister",
                "Tiago Pimentel",
                "Gian Wiher",
                "Ryan Cotterell."
            ],
            "title": "Typical decoding for natural language generation",
            "venue": "arXiv preprint arXiv:2202.00666.",
            "year": 2022
        },
        {
            "authors": [
                "Tao Meng",
                "Sidi Lu",
                "Nanyun Peng",
                "Kai-Wei Chang."
            ],
            "title": "Controllable text generation with neurallydecomposed oracle",
            "venue": "Advances in Neural Information Processing Systems, volume 35, pages 28125\u2013 28139. Curran Associates, Inc.",
            "year": 2022
        },
        {
            "authors": [
                "Nasrin Mostafazadeh",
                "Nathanael Chambers",
                "Xiaodong He",
                "Devi Parikh",
                "Dhruv Batra",
                "Lucy Vanderwende",
                "Pushmeet Kohli",
                "James Allen."
            ],
            "title": "A corpus and cloze evaluation for deeper understanding of commonsense stories",
            "venue": "Proceedings of the 2016",
            "year": 2016
        },
        {
            "authors": [
                "Paul Christiano",
                "Jan Leike",
                "Ryan Lowe"
            ],
            "title": "Training language models to follow instructions with human feedback",
            "year": 2022
        },
        {
            "authors": [
                "Harchaoui."
            ],
            "title": "Mauve: Measuring the gap between neural text and human text using divergence frontiers",
            "venue": "Advances in Neural Information Processing Systems, 34:4816\u20134828.",
            "year": 2021
        },
        {
            "authors": [
                "Matt Post",
                "David Vilar."
            ],
            "title": "Fast lexically constrained decoding with dynamic beam allocation for neural machine translation",
            "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Hu-",
            "year": 2018
        },
        {
            "authors": [
                "Lihua Qian",
                "Lin Qiu",
                "Weinan Zhang",
                "Xin Jiang",
                "Yong Yu."
            ],
            "title": "Exploring diverse expressions for paraphrase generation",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
            "year": 2019
        },
        {
            "authors": [
                "Chengwei Qin",
                "Aston Zhang",
                "Zhuosheng Zhang",
                "Jiaao Chen",
                "Michihiro Yasunaga",
                "Diyi Yang"
            ],
            "title": "Is chatgpt a general-purpose natural language processing task solver",
            "year": 2023
        },
        {
            "authors": [
                "Lianhui Qin",
                "Sean Welleck",
                "Daniel Khashabi",
                "Yejin Choi."
            ],
            "title": "COLD decoding: Energy-based constrained text generation with langevin dynamics",
            "venue": "Advances in Neural Information Processing Systems.",
            "year": 2022
        },
        {
            "authors": [
                "Alec Radford",
                "Jeffrey Wu",
                "Rewon Child",
                "David Luan",
                "Dario Amodei",
                "Ilya Sutskever"
            ],
            "title": "Language models are unsupervised multitask learners",
            "venue": "OpenAI blog,",
            "year": 2019
        },
        {
            "authors": [
                "Nazneen Fatema Rajani",
                "Bryan McCann",
                "Caiming Xiong",
                "Richard Socher."
            ],
            "title": "Explain yourself! leveraging language models for commonsense reasoning",
            "venue": "Proceedings of the 2019 Conference of the Association for Computational Linguistics",
            "year": 2019
        },
        {
            "authors": [
                "Machel Reid",
                "Victor Zhong",
                "Suchin Gururangan",
                "Luke Zettlemoyer."
            ],
            "title": "M2D2: A massively multidomain language modeling dataset",
            "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 964\u2013975, Abu",
            "year": 2022
        },
        {
            "authors": [
                "Koustuv Sinha",
                "Jon Gauthier",
                "Aaron Mueller",
                "Kanishka Misra",
                "Keren Fuentes",
                "Roger Levy",
                "Adina Williams."
            ],
            "title": "Language model acceptability judgements are not always robust to context",
            "venue": "Proceedings of the 61st Annual Meeting of the Association for",
            "year": 2023
        },
        {
            "authors": [
                "Eric Michael Smith",
                "Diana Gonzalez-Rico",
                "Emily Dinan",
                "Y-Lan Boureau"
            ],
            "title": "Controlling style in generated dialogue",
            "year": 2020
        },
        {
            "authors": [
                "Yixuan Su",
                "Tian Lan",
                "Yan Wang",
                "Dani Yogatama",
                "Lingpeng Kong",
                "Nigel Collier."
            ],
            "title": "A contrastive framework for neural text generation",
            "venue": "arXiv preprint arXiv:2202.06417.",
            "year": 2022
        },
        {
            "authors": [
                "Yixuan Su",
                "Jialu Xu."
            ],
            "title": "An empirical study on contrastive search and contrastive decoding for open-ended text generation",
            "venue": "arXiv preprint arXiv:2211.10797.",
            "year": 2022
        },
        {
            "authors": [
                "Jiao Sun",
                "Xuezhe Ma",
                "Nanyun Peng."
            ],
            "title": "AESOP: Paraphrase generation with adaptive syntactic control",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5176\u20135189, Online and Punta Cana, Dominican Re-",
            "year": 2021
        },
        {
            "authors": [
                "Jiao Sun",
                "Swabha Swayamdipta",
                "Jonathan May",
                "Xuezhe Ma."
            ],
            "title": "Investigating the benefits of freeform rationales",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2022, pages 5867\u20135882, Abu Dhabi, United Arab Emirates. As-",
            "year": 2022
        },
        {
            "authors": [
                "Rohan Taori",
                "Ishaan Gulrajani",
                "Tianyi Zhang",
                "Yann Dubois",
                "Xuechen Li",
                "Carlos Guestrin",
                "Percy Liang",
                "Tatsunori B. Hashimoto."
            ],
            "title": "Stanford alpaca: An instruction-following llama model",
            "venue": "https:// github.com/tatsu-lab/stanford_alpaca.",
            "year": 2023
        },
        {
            "authors": [
                "Yufei Tian",
                "Anjali Narayan-Chen",
                "Shereen Oraby",
                "Alessandra Cervone",
                "Gunnar Sigurdsson",
                "Chenyang Tao",
                "Wenbo Zhao",
                "Tagyoung Chung",
                "Jing Huang",
                "Nanyun Peng."
            ],
            "title": "Unsupervised melody-to-lyrics generation",
            "venue": "Proceedings of the 61st Annual Meet-",
            "year": 2023
        },
        {
            "authors": [
                "Yufei Tian",
                "Nanyun Peng."
            ],
            "title": "Zero-shot sonnet generation with discourse-level planning and aesthetics features",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-",
            "year": 2022
        },
        {
            "authors": [
                "Hugo Touvron",
                "Thibaut Lavril",
                "Gautier Izacard",
                "Xavier Martinet",
                "Marie-Anne Lachaux",
                "Timoth\u00e9e Lacroix",
                "Baptiste Rozi\u00e8re",
                "Naman Goyal",
                "Eric Hambro",
                "Faisal Azhar"
            ],
            "title": "Llama: Open and efficient foundation language models",
            "year": 2023
        },
        {
            "authors": [
                "Jason Wei",
                "Xuezhi Wang",
                "Dale Schuurmans",
                "Maarten Bosma",
                "Ed H. Chi",
                "Quoc Le",
                "Denny Zhou."
            ],
            "title": "Chain of thought prompting elicits reasoning in large language models",
            "venue": "CoRR, abs/2201.11903.",
            "year": 2022
        },
        {
            "authors": [
                "Sean Welleck",
                "Ilia Kulikov",
                "Stephen Roller",
                "Emily Dinan",
                "Kyunghyun Cho",
                "Jason Weston."
            ],
            "title": "Neural text generation with unlikelihood training",
            "venue": "arXiv preprint arXiv:1908.04319.",
            "year": 2019
        },
        {
            "authors": [
                "John Wieting",
                "Kevin Gimpel."
            ],
            "title": "ParaNMT-50M: Pushing the limits of paraphrastic sentence embeddings with millions of machine translations",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long",
            "year": 2018
        },
        {
            "authors": [
                "Nan Xu",
                "Chunting Zhou",
                "Asli Celikyilmaz",
                "Xuezhe Ma"
            ],
            "title": "2023a. Look-back decoding for open-ended text generation",
            "year": 2023
        },
        {
            "authors": [
                "Nan Xu",
                "Chunting Zhou",
                "Asli Celikyilmaz",
                "Xuezhe Ma."
            ],
            "title": "Look-back decoding for open-ended text generation",
            "venue": "arXiv preprint arXiv:2305.13477.",
            "year": 2023
        },
        {
            "authors": [
                "Fan Yin",
                "Jesse Vig",
                "Philippe Laban",
                "Shafiq Joty",
                "Caiming Xiong",
                "Chien-Sheng Jason Wu."
            ],
            "title": "Did you read the instructions? rethinking the effectiveness of task definitions in instruction learning",
            "venue": "ACL 2023.",
            "year": 2023
        },
        {
            "authors": [
                "Hanqing Zhang",
                "Haolin Song",
                "Shaoyu Li",
                "Ming Zhou",
                "Dawei Song."
            ],
            "title": "A survey of controllable text generation using transformer-based pre-trained language models",
            "venue": "ArXiv, abs/2201.05337.",
            "year": 2022
        },
        {
            "authors": [
                "Hattie Zhou",
                "Azade Nova",
                "Hugo Larochelle",
                "Aaron Courville",
                "Behnam Neyshabur",
                "Hanie Sedghi"
            ],
            "title": "Teaching algorithmic reasoning via in-context learning",
            "year": 2022
        },
        {
            "authors": [
                "Wangchunshu Zhou",
                "Yuchen Eleanor Jiang",
                "Ethan Wilcox",
                "Ryan Cotterell",
                "Mrinmaya Sachan"
            ],
            "title": "Controlled text generation with natural language instructions",
            "year": 2023
        },
        {
            "authors": [
                "Cansen \u00c7a\u011flayan",
                "Murat Karakaya."
            ],
            "title": "Topiccontrolled text generation",
            "venue": "2021 6th International Conference on Computer Science and Engineering (UBMK), pages 533\u2013536.",
            "year": 2021
        },
        {
            "authors": [
                "Lu et al"
            ],
            "title": "Datasets. For topic constraints, we use a subset of the topics from the first hierarchy in the M2D2 dataset",
            "venue": "(Reid et al.,",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Text generation models should generate texts that meet controllable constraints as humans wish (Zhang et al., 2022). For example, one can avoid the blandness caused by repetitive patterns by controlling the syntax of generated sentences (Iyyer et al., 2018; Qian et al., 2019). In a customized dialogue system, one should be able to control the persona of the utterance (Smith et al., 2020). Previous works either finetune generation models such as BART (Lewis et al., 2019) on specific tasks for better controllability (e.g., controlled paraphrase generation (Sun et al., 2021)) or design constrained decoding strategies (e.g., look-back decoding strategy by Xu et al. (2023a)) for controlled generation.\nLarge Language Models (LLMs) have recently shown great potential in various generation tasks. For example, Jiao et al. (2023a) shows that ChatGPT with GPT-4 as an engine achieves commercial-level machine translation quality. Laskar et al. (2023) find that annotators prefer summaries generated from ChatGPT over state-of-the-art summarization models. However,\n\u2217The first four authors contribute equally.\nfew works investigate the controllability of large language models. Towards this end, we aim to study and understand the controllability of large language models to answer the question: Are large language models better than finetuned smaller models at controllability on generation tasks?.\nThe main contribution of this work is to conduct a comprehensive analysis of LLM\u2019s controllability on five tasks and ten generation benchmarks, including controlled story generation, controlled free-form generation with sentiment and topics, controlled paraphrase generation, and controlled rationale generation as in Figure 1. We further design a new simple yet challenging benchmark named Numerical Planning Benchmark (NPB), where the task is to satisfy numerical constraints from four granularities (word-, syllable-, sentenceand paragraph-level) and under different content controls (e.g., prefix and ending). For evaluation, we use automatic metrics, which are imperfect yet convenient and reproducible.1\n1https://github.com/sunjiao123sun/\nAfter an in-depth examination, we categorize LLM\u2019s controllability on a spectrum: from lagging behind and being on par with to surpassing smaller finetuned models. Our findings indicate that large language models have difficulties adhering to specific hard constraints, such as numerical planning.\nWe first introduce the numerical planning task and the associated evaluation as this is a new, intuitively simple, yet challenging task (\u00a72). For the rest, we rank them by the task difficulty indicated in Figure 1 from easy to hard: constrained content generation (\u00a73), story generation (\u00a74), rationale generation (\u00a75) and paraphrase generation (\u00a76)."
        },
        {
            "heading": "2 Numerical Planning",
            "text": "Can LLMs count from two to ten?\nTask Description. We introduce the Numerical Planning Benchmark (NPB) as an intuitive task that tests the basic numerical planning ability of LLMs. The high-level task descriptions can be found in Table 1. We are inspired by real-world scenarios such as creative writing. For example, writers may wish to generate sentences or poems with a specific structure, such as a fixed number of words or syllables in each line, aiming to adhere to particular forms (e.g., sonnets, where each line contains exactly 10 or 11 syllables (Tian and Peng, 2022)). Meanwhile, humans may also want full control over the start and end of each line for rhetorical purposes such as alliteration and rhyming. Inductively, we formulate our numerical planning benchmark from four different granularities: generating a piece of text that contains a predefined number of words, syllables, sentences, or paragraphs given a plausible pair of prefix (start) and suffix (ending) as constraints. The prefix is given to LLMs such that they are only queried to generate the continuations.\nEvaluation Metrics. We use success rate (SR) and mean squared error (MSE) as automatic evaluation metrics. As our control is two-fold, we separately calculate the success rates of 1) generating the continuation with the correct counts and 2) generating the continuation with the proper ending. We also calculate the MSE between our input numbers and output numbers.\nEvaluate with LLMs. We evaluate ChatGPT and Alpaca-7b on our NPB benchmark in zero-shot and few-shot settings. Each request used to query the LLMs corresponds to a real case in the datasets\nllm-controlgen\nof Romance Books and Reddit Short Stories.2 For word-level planning tasks (word and syllable count), we randomly select sentences from the above datasets. Then, we select the last word in each sentence as the suffix. Depending on how many additional words we query the LLMs to generate, we select the first few words in each sentence as the prefix (if we simply ask LLMs to generate freely without a prefix, the outputs lack diversity). Our prompt is written as Complete a sentence that starts with {prefix} using exactly {N} additional words (including the last word {last word}). The sentence must end with the word {last word}. Sentence: {prefix}, and LLMs will continue. In the few-shot setting, we provide the task description and three examples. For each example, we also provide explanations to help LLMs better understand our task. For example,\n##Prefix: This is a story about a young girl\u2019s ##Last word: town ##N: 5 ##Output: This is a story about a young girl\u2019s redemption in a small town. ##Explanation: We generated \u201credemption in a small town\u201d. It contains exactly 5 words and ends with the last word \u2018town\u2019.\nWe query the LLMs to generate outputs from N = 2 to N = 10 words. Each number N has 100 evaluation samples. For paragraph-level tasks, the prefix and suffix are the first and last sentences in the corresponding paragraphs. For all experi-\n2huggingface.co/datasets/AlekseyKorshuk/romancebooks, www.kaggle.com/datasets/trevordu/reddit-short-stories\nments, our decoding strategy is top p (p = 0.95) sampling with temperature T = 0.3 unless otherwise specified.\nResult. We report the model performance of LLMs and a fine-tuned GPT-2-large model on the task of word count planning in Table 2. Due to space limitations, we compile the results of the remaining tasks in Appendix A. First, it is clear LLMs are poor at numerical planning, although it is an extremely simple task for humans. Given its extremely poor performance, we consider Alpaca incapable of doing numerical planning. Secondly, LLMs learn to incorporate literal constraints, such as the last word, via few-shot in-context learning. Interestingly, few-shot in-context learning deteriorates the performance of numerical planning.\nUpon further inspection, we find that LLMs try to mimic the style or features (such as length) in the in-context examples and are, therefore, more likely to generate outputs with the wrong word counts once the input number N cannot be found in the examples. Our results resonate with Yin et al. (2023); Kung and Peng (2023); Sinha et al. (2023) that LMs do not truly understand task definitions via in-context learning.\nFigure 2 is a fine-grained visualization of the input and output numbers distribution by zero-shot ChatGPT. Specifically, we compare LLMs\u2019 numerical planning abilities with (e.g., complete sentence with \u201credemption in a small town\u201d using exactly 5 words, including the last word as \u201chappy\u201d) and without additional suffix constraint (e.g., complete sentence with \u201credemption in a small town\u201d using exactly 5 words). LLMs can generate more freely without suffix constraints to meet the numerical constraint. However, ChatGPT doesn\u2019t always translate to a higher success rate. We find out that only when N is small (i.e., 2 and 3), ChatGPT achieves a higher success rate if explicitly told the last word of the target sentence.\nFinally, we would like to point out a few behaviors. First, although the general trend is that LLMs\u2019 numerical planning ability drops as N increases, N = 3 is a clear exception (performs worse) among various experiments we repeated. Second, by checking the failure cases, we find that\nChatGPT always generates shorter continuations than required. Moreover, we see a sudden drop in model performances (from above \u223c0.6 to \u223c0.4) when the input number N increases from 5 to 6. We encourage future research to investigate these behaviors."
        },
        {
            "heading": "3 Content-Controlled Generation",
            "text": "Task Description. We consider three types of content constraints: topic, sentiment, and keyword. The detailed task definitions and dataset can be found in Appendix B.\nEvaluation Metrics. We use the success rate as the evaluation metric to measure how well LLMs can follow the content constraints. Specifically, we use GPT-3.5 (Ouyang et al., 2022) based topic/sentiment classifiers with in-context learning using five examples per category to evaluate whether the generated texts belong to the specified topic or sentiment class. We consider an LLM to succeed in one example if the predicted class of the generated text is identical to the input constraint. For a keyword-constrained generation, we use the keyword coverage metric that measures the percentage of input keywords included in generated texts.\nEvaluate with LLMs. For the content constrained generation with LLMs, we follow Zhou et al. (2023) and use natural language instructions to prompt LLMs. Specifically, we use a prompt template of \u201cWrite a sentence about {topic name}\u201d for topic-constrained generation, \u201cWrite an Amazon review with {level number} star about a random thing. The number of stars ranges from one to five. One star is the most negative, and five stars are the most positive\u201d for sentiment constraints, and \u201cWrite a sentence using the following keywords: {keywords}\u201d for keyword constraints.\nIn addition to zero-shot evaluation, we also evaluate LLMs in the in-context learning setting by appending the following demonstration template: \u201cBelow are some examples for the task: Input: {input 1}, Output: {output 1}; Input: {input 2}, Output: {output 2} ... \u201d. We use 5 in-context examples per class following the practice in Zhou et al. (2023).\nWe compare various LLMs including ChatGPT, LLaMA, Alpaca, Vicuna, and Falcon in our experiments. We also report the results of DiffusionLM (Li et al., 2022b) based on BERT-large (Devlin\net al., 2019) and task-specific classifiers as a competitive non-LLM baseline\nResults. The results are shown in Table 3. We find that Alpaca significantly outperforms LLaMA in the zero-shot setting. This is intuitive since natural language instruction of constraints resembles instruction tuning data. However, this performance gap is significantly reduced when in-context learning is used. We think this is because the role of instruction tuning is mainly to adapt an LLM to human-friendly prompt formats instead of increasing the LLM\u2019s capability. We also find that ChatGPT achieves competitive performance without in-context learning and outperforms DiffusionLM, a competitive supervised baseline, by a large margin. Moreover, the performance of ChatGPT can be further improved by adding in-context examples to the prompt. This suggests that LLMs\u2019 ability to follow content constraints expressed in natural language depends on three confounding factors: instruction tuning or supervised fine-tuning, in-context learning, and model capacity."
        },
        {
            "heading": "4 Story Generation",
            "text": "Task Description. Given the beginning text of a story, open-ended story generation aims to decode texts that are coherent with previous topics, and informative without undesired repetitions (Su et al., 2022; Su and Xu, 2022; Xu et al., 2023b). Despite the impressive success on generating fluent and accurate sentences for low-entropy tasks such as summarization or translation, large-scale language models (LLMs) still suffer from serious degeneration problems, such as undesired repetitions (Holtzman et al., 2020; Su et al., 2022) and"
        },
        {
            "heading": "LM Method rep-2\u2193 rep-3\u2193 rep-4\u2193 diversity\u2191 coherence\u2191 ROC",
            "text": "unnatural topic drifts (Li et al., 2022a), under openended settings.\nDatasets. We evaluate different generation methods on two popular benchmark story datasets: ROCStories and Writing Prompts. ROCStories (ROC) (Mostafazadeh et al., 2016) is a corpus comprising commonsense stories written by crowdsourced workers within 5 short sentences. Given the first sentence as a prefix, generation methods are required to produce four continuing sentences. Writing Prompts (WP) is a challenging task for inspiring continuations with abstract, high-level story prompts submitted by online users and continuations by others on Reddit (Fan et al., 2018). Following prior literature (Xu et al., 2023b), we utilize the first 32 tokens as the prefix and ask for continuation with 256 tokens. Since we prompt different language models or decoding algorithms without extra fine-tuning, we directly sample 1,000 development and 1,000 testing instances from both ROC and WP.\nBaselines. We evaluate the pre-trained LLM, GPT-2-XL (Radford et al., 2019), with both search (SimCTG (Su et al., 2022) and Look-back (Xu et al., 2023b)) and sampling decoding methods (Nucleus sampling (Holtzman et al., 2020), Typical decoding (Meister et al., 2022) and \u03b7-sampling (Hewitt et al., 2022)).\nEvaluation Metrics. Following open-ended story generation literature (Su et al., 2022; Li et al., 2022a; Xu et al., 2023b), we adopt the following automatic metrics to evaluate generation quality: 1) rep-n to measure sequence-level repetition according to the portion of duplicate n-grams (Welleck et al., 2019); 2) diversity to assess the overall model repetition by considering rep-n at different n-gram levels; 3) coherence measured as the cosine similarity between prefix and continuation embeddings represented by SimCSE (Gao et al., 2021). We do not report MAUVE (Pillutla et al., 2021) score due to the concern that MAUVE may not accurately reflect human preferences considering contradicted results between MAUVE and human evaluations observed in prior work (Su and Xu, 2022).\nEvaluate with LLMs. Chatbots that fine-tune LLMs on instructions are also evaluated: Vicuna7B (Chiang et al., 2023), Falcon-7B-Instruct (Almazrouei et al., 2023) and ChatGPT. 3 We prepend the following instruction before the story prefix as prompt: 1) ROC: \u201cPlease continue writing this story within 4 very short sentences: <prefix>\u201d, 2) WP: \u201cPlease continue writing this story within 256 words: <prefix>\u201d4.\nResults. As shown in Table 4, both Vicuna-7B and ChatGPT are able to continue writing more fluent and coherent stories on both ROC and WP compared with other decoding methods based on GPT2-XL. Falcon-7B-Instruct obtains consistently lower diversity than other baselines, while ChatGPT achieves more robust performance in terms of diversity and coherence on both datasets."
        },
        {
            "heading": "5 Rationale Generation",
            "text": "Task Description. Free-form rationales are known to aid model interpretability by providing additional world knowledge or commonsense reasoning steps (Kim, 2015; Lipton, 2018; AlvarezMelis and Jaakkola, 2018). Wei et al. (2022) show that rationales can improve large language models\u2019 ability to solve complex reasoning tasks. Extractive rationales in question-answering tasks are based on the input passage to extract related information to answer the question. Conversely, free-form rationales in the question-answering tasks are open-\n3https://chat.openai.com/ 4We adopt generation parameters for different LLMs suggested from their respective documents or APIs. We leave evaluation on more configurations in our repository: https: //github.com/sunjiao123sun/llm-controlgen.\nended and condition on purely the question and options. (Sun et al., 2022) studies how different the quality of rationales would impact rationales\u2019 utilities in terms of improving the model performance and claims that crowdsourced rationales are superior to generated rationales. Sun et al. (2022) finetunes T5-base for both rationale generation and question answering. With the power of LLMs, we want to revisit the problem and see whether the utility of generated rationales conditioned on the question and options has been improved.\nEvaluation. We follow previous works and use the performance gap before and after adding rationales in the input to measure the utility of rationales, written as acc(I+R\u2192O) - acc(I\u2192O), where I stands for question and options as input, R stands for rationales, and O stands for one of the options as output. For the backbone model for question answering, we use flanT5-XXL (Chung et al., 2022a) instead of T5-base as it can handle longer sequences and is better at reasoning.\nSun et al. (2022) shows that two factors are mainly affecting the utility of rationales. One is leakage, which means that the correct answer is explicitly written in the rationales, and one can choose the correct answer among all the options by rationales without knowing the questions. The other is background knowledge, which is the additional background knowledge or reasoning step that can help answer the question.\nDatasets. CoS-E (Rajani et al., 2019) and ECQA (Aggarwal et al., 2021) are the most popular free-form rationale datasets through crowdsourcing. ECQA builds on CoS-E and improves the quality of the CoS-E dataset from various aspects, including completeness, comprehensiveness, coherence, etc.\nThey share the same sets of questions and options. Based on the findings from Sun et al. (2022), both CoS-E and ECQA tend to leak the correct answer in the rationale, while ECQA rationales contain the background necessary to answer the questions. We conduct our analysis on question-answer pairs from the test set. Based on the evaluation acc(I+R\u2192O) - acc(I\u2192O), since we are evaluating on the same set of question-answer pairs, acc(I\u2192O) is always the same. Therefore, we only compare acc(I+R\u2192O) with different LLMs.\nEvaluate with LLMs. We prompt LLMs to provide background knowledge that can help answer the question and control whether to leak the correct options in rationales. We use ChatGPT as the example for illustration:\n\u2022 Leakage. We have ChatGPT take the role of A teacher who is trying to explain to students the rationale behind choosing the correct option for a multiple-choice question. Then prompt it with Question: {question} Options: {concatenated options} Explain the rationale behind choosing the correct option \u201c{correct answer}\u201d.\n\u2022 Non-leakage. The role of ChatGPT becomes A teacher who is trying to explain to students the rationale behind a multiple-choice question. However, you do not want to leak the correct answer directly. and prompt it with Question: {question} Options: {concatenated options} Explain the rationale behind choosing the correct answer. Do not mention the correct answer \u201c{correct answer}\u201d explicitly.\nWe highlight the difference between the two modes with underline. When prompting LLaMA and Alpaca, we remove the role description and only use the prompts. Through analysis, we aim to answer two questions: 1) Are LLM-generated rationales on par with crowdsourced rationales? 2) How much would leakage impact the utility of rationales?\nResult. Compared to T5, FlanT5 has better reasoning abilities (Chung et al., 2022b) and is more capable of understanding instructions. Therefore, we use FlanT5 instead of using T5 as the backbone model for question answering, which can theoretically examine the utility of rationales better ruling out the incapability of models. Simply given the question and the option strings, Table 5 shows that FlanT5-XXL has an accuracy of 0.87\n(while T5 in (Sun et al., 2022) scores 0.57 under the same setting). We then show the performance with crowdsourced rationales from both ECQA and CoS-E. With crowdsourced rationales from ECQA, the model almost solved the task and reached a performance of 0.99. With CoS-E rationales, the accuracy is 0.92. Our finding echoes with Sun et al. (2022) that ECQA rationales are better quality.\nWe then evaluate the utility of LLM-generated rationales under both the Leakage and Non-leakage scenarios. As the majority of crowdsourced rationales contain leakage (Sun et al., 2022), we consider it fair to compare LLM-generated rationales under the Leakage scenarios against crowdsourced rationales. We have two major findings:\n\u2022 ChatGPT generated rationales are on par with ECQA rationales from crowdsourcing.\n\u2022 We quantify the influence of leakage in measuring the utility of rationales: whether or not having leakage in rationales could result in an accuracy difference of at least 5%."
        },
        {
            "heading": "6 Controlled Paraphrase Generation",
            "text": "Task Description. Syntactically-controlled paraphrase generation can benefit a wide range of NLP applications such as dialogue generation (Gao et al., 2020), improving the robustness of models (Huang and Chang, 2021) or metrics (Aggarwal et al., 2022), and diversifying other generation tasks such as diverse question generation. Syntacticallycontrolled paraphrase generation is challenging because it requires satisfying two folds of control signals: semantic preservation and syntactic conformation. By definition of paraphrases, the generation should have exactly the same semantics as the input text. With syntax as part of the input, generated paraphrases should also conform with the indicated syntax. The input syntax can come from a variety of sources.\nDatasets. We evaluate on ParaNMT-small (Chen et al., 2019), derived from ParaNMT (Wieting and Gimpel, 2018), and QQP-Pos (Kumar et al., 2020). Our train/dev/test split follows previous works (Kumar et al., 2020; Sun et al., 2021). Each instance is a tuple of {source sentence, exemplar, ground-truth paraphrase}, where the exemplar shares the same syntax with the ground-truth paraphrase.\nEvaluation Metrics. We use two sets of evaluation metrics to evaluate the quality of generated paraphrases. We use lexical-overlapping-based scores to evaluate the semantic preservation and tree-edit distances to evaluate the syntactic conformation. For lexical-overlapping-based scores, the higher is better. For tree edit distance, the lower is better, indicating that the newly derived syntax matches more closely with the expected syntax. In this work, we prune the constituency parse trees at a level of 2 and only compare the high-level syntactic structure. TED-R means the tree edit distance between the candidate-generated sentence with the ground-truth paraphrase as the reference. TED-E compares the candidate sentence against the exemplar that only provides the syntax.\nEvaluate with LLMs. We provide three ways to prompt for the controlled paraphrase generation:\n\u2022 Direct. We prompt LLMs directly without specifying any constraints. The prompt is written as Paraphrase {source sentence}. Please only have the paraphrase in the response.\n\u2022 Control. Under this mode, we use the exemplar sentence for the syntactic control signal. The prompt is written as Paraphrase \u201c{source sentence}\u201d so that it uses the syntactic structure from\n\u201c{exemplar}\u201d; please only have the paraphrase in the response.\nWe observe that under the Control mode, the generated paraphrases would sometimes take the syntactic information from the exemplars and the semantic meaning from exemplar sentences. To solve this, we introduce the third mode Control with syntax explanation. We first extract the constituency parse structure from the exemplar sentence using Stanford CoreNLP, prune the parse tree at the height of two (i.e., parse at H2), and then ask ChatGPT to generate a natural language explanation of the pruned syntactic parse, which we refer to as syntax explanation. The generated syntax explanation will be part of the input.\n\u2022 Control with Syntax Explanation. The prompt is written as Paraphrase \u201c{source sentence}\" so that the sentence has a syntactic structure of\n\u201c{pruned syntax}\". {generated explanation for the syntax.} Please only have the generated paraphrase, not its parse, in the response.\nTable 7 shows examples of generated explanations for constituency parse trees pruned at height\ntwo by ChatGPT. We prompt ChatGPT from zero shots to five shots for our experiments, find that ChatGPT\u2019s performance peaks with five shots as expected, and compare the performance of fiveshot ChatGPT with AESOP (Sun et al., 2021). The backbone of AESOP is the BART-base model, a 140m-parameter model finetuned with specialized input and output format tailored for the controlled paraphrase generation task. To the best of our knowledge, AESOP remains the state-of-the-art paraphrase generation model on both ParaNMTsmall and QQPPos datasets.\nResult. Table 6 shows the performance comparison between five-shot ChatGPT and AESOP. We show that AESOP surpasses ChatGPT across all evaluation metrics for both semantic preservation metrics (lexical-overlapping based metrics including BLEU, ROUGE scores, and METEOR) and\nsyntactic conformation metrics (TED-R and TEDE at the height of two). In addition, we find that ChatGPT\u2019s performance is the best under the setting of Control, where we use exemplar sentences for control signals. Compared with the setting Control with syntax explanation, Table 6 shows that ChatGPT is good at mimicking syntactic structures from sentences instead of directly incorporating the syntactic parses. Besides ChatGPT, we also tried Alpaca (Taori et al., 2023) and LLaMA (Touvron et al., 2023) on the controlled paraphrase generation task. However, they repeat input sentences and struggle to generate meaningful content. Therefore, we do not include them here for comparison."
        },
        {
            "heading": "7 Related Works",
            "text": "LLM Evaluation. While the advancement of more potent large language models drives our work, our focus aligns more with recent studies evaluating LLMs\u2019 performance on academic NLP benchmarks. We roughly categorize these studies as either general or specific NLP tasks. For general NLP tasks, Qin et al. (2023) shows that ChatGPT performs well on many tasks involving reasoning capabilities but not on sequence tagging. Ahuja et al. (2023) evaluate LLMs on various multilingual NLP tasks. For specific tasks, Jiao et al. (2023b) shows that ChatGPT has achieved competitive performance on machine translation. Gao et al. (2023) uses ChatGPT for event extraction and shows that it only matches with around a half percent of specialized event extraction models. To the best of the authors\u2019 knowledge, we are the first to study the controllability of LLMs and the tasks in our work\nhave not been previously studied. Instead of having a single conclusion on if LLMs perform well at certain task, we provide a spectrum showcasing how LLMs\u2019 abilities vary according to different control granularities."
        },
        {
            "heading": "8 Discussion: Why and How",
            "text": "We believe that our work makes a substantial contribution to the field of benchmarking LLMs\u2019 controllabiltiy, especially considering the prevalence of LLMs these days. That being said, we do have a few hypotheses to investigate why LLMs fail at numerical planning and how we could potentially increase their controllability.\nTokenization. On one hand, tokenization indeed makes the task of numerical planning more challenging than without, by separating the generative process (i.e., subword-level generation) and the numerical planning process (i.e., counting complete words). However, we posit that tokenizers not necessarily impact the ability of word planning, as it is a standard practice that a subword starting with a special token will indicate the start of a new word (e.g., \u201cG\u0307\u201d in BPE tokenizer,5 which has been used by many LLMs such as GPT and RoBERTa). Nor are we aware of evidence that the subwords of a tokenizer roughly correspond to units of syllables. For example, Tian et al. (2023) shows that smaller models such as GPT-2-large fine-tuned on syllablerelated data can achieve a success rate of close to 90% on the same syllable-planning task. On the other hand, the best performance of ChatGPT is 37%.\nDecoding Methods. The reported results are based on sampling with a temperature of 0.3. Moreover, we have experiments showing that our conclusion is robust to the change of decoding mechanisms, where we try other decoding methods beyond sampling with T = 0.3.\nSpecifically, we tried 1) greedy decoding, 2) beam search with beam size 8, and 3) sampling with temperature T = {0.3, 0.7, 1.0}. For the prior two, most of the generated outputs are highly similar, plain, and lack diversity. As for sampling with T = {0.3, 0.7, 1.0}, the success rate decreases as T increases. We think T = 0.3 is a reasonable balance between diversity and quality. We believe that our results convey meaningful signals since each\n5https://huggingface.co/learn/nlp-course/ chapter6/5?fw=pt#byte-pair-encoding-tokenization\nnumber N has been averaged over 100 different evaluation samples to reduce noise. However, none of these experiments show that LLMs can do better than fine-tuned GPT-2.\nIn-Context Learning. We try to give more demonstration of NPB in our prompts and we surprisingly found that this does not help once the input number N cannot be found in the examples. Our results resonate with Yin et al. (2023); Kung and Peng (2023) that LLMs do not truly understand task definitions via in-context learning.\nHow to Improve. We encourage future work to explore from two different directions: 1) chain/tree/graph-of-thought reasoning, and 2) bridging LLMs with non-autoregressive generation abilities (e.g., NADO (Meng et al., 2022)). For the first one, one can try both simple chain/tree/graphof-thought prompting or even pretrained LLMs with chain-of-thought/scratchpad pairs, as it shows promises for mathematical reasoning (Zhou et al., 2022). However, this will not fundamentally solve the planning issue. It is straightforward that autoregressively generating the next tokens will lead to the problem of models not \u201clooking back\u201d and therefore not adhering to the fine-grained control signals. Therefore, we encourage researchers to also investigate multi-step planning and iterative revisions with LLMs, or, more fundamentally, challenge the autoregressive architecture of LLMs."
        },
        {
            "heading": "9 Conclusion",
            "text": "We test the controllability of large language models on five tasks and ten benchmarks, including a numerical planning benchmark that is easy for humans while challenging for LLMs. From there, we draw a spectrum by comparing the performance between LLMs and smaller specialized models. LLMs are able to generate human-level rationales and conform with coarse control signals, such as sentiment, topic and keyword incorporation. However, they struggle at fine-grained hard constraints, such as numerical planning and paraphrase generations. We hope that our work can inspire downstream applications on when to adopt LLMs. For example, we find that LLMs are good at generating rationales, and these automatic rationales could be used to further boost LLMs\u2019 performance through chain-of-thought reasoning."
        },
        {
            "heading": "Acknowledgement",
            "text": "The authors thank anonymous reviewers for their constructive feedback and suggestions that helped improve the draft, especially reviewer rXWW. Jiao and Yufei are supported by Amazon fellowships.\nLimitations\nThis work is subject to couple of limitations. First, all of our experiments involved heavy prompt engineering effort. Although we have attempted to choose the best performing prompts, there might be room for better prompts which could influence the reported evaluation metrics. Second, automatic evaluations are imperfect. Last, we have not proposed solutions after identifying tasks where LLMs struggle. We leave this for future work."
        },
        {
            "heading": "A SPB additional results",
            "text": "We report the additional results of ChatGPT and Alpaca on the SPB benchmark in Table 8. Recall that the suffix for the paragraph planning task is the last sentence. In practice, LLMs are unable to follow instructions and copy the requirement as prompted. Hence, when we compute the success rate for this last task, we check the token overlap between the generated sentence and our requirement, and if more than 2/3 of the tokens overlap, we will consider it as a success.\nTaking all four tasks in the SPB benchmark into account, we find out that Alpaca-7b have very little numerical planning ability. ChatGPT on the hother hand is best at sentence count planning, and worst at syllable count planning."
        },
        {
            "heading": "B Additional Information of Content Controlled Generation",
            "text": "Controlled content generation refers to the task of controlling the content of generated texts. We consider three types of content constraints:\n\u2022 Topic constraint. It requires the model to generate texts about certain topics. Traditional methods for topic constrained generation either append a special token for different topics (\u00c7ag\u0306layan and Karakaya, 2021) or use trained topic classifiers (Qin et al., 2022) to guide the generation process. \u2022 Sentiment constraint. Similar to topic constraint, this task requires the model to generate texts of\ncertain sentiments. The aforementioned methods for topic constrained generation also apply to sentiment constrained generation. \u2022 Keyword constraint. Keyword constrained, or lexical constrained text generation requires the model to generate texts that contain certain keywords or tokens. Traditional methods for keyword constrained text generation generally enforce lexical constraints on the outputs by modifying the search space according to the constraints (Anderson et al., 2017; Post and Vilar, 2018; Lu et al., 2021).\nDatasets. For topic constraints, we use a subset of the topics from the first hierarchy in the M2D2 dataset (Reid et al., 2022) which contains domains such as health, history, society, technology, arts, science, etc. The total number of topics is 10 in our experiments. We use the Amazon Review dataset (Keung et al., 2020) for sentiment constrained text generation. The sentiment is measure by 1 to 5 stars. For lexical constrained text generation, we use the CommonGEN dataset (Lin et al., 2020) which requires the model to generate a sentence using three to five keywords."
        }
    ],
    "title": "Evaluating Large Language Models on Controlled Generation Tasks",
    "year": 2023
}