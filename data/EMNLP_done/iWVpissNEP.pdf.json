{
    "abstractText": "Recently, many studies have illustrated the robustness problem of Named Entity Recognition (NER) systems: the NER models often rely on superficial entity patterns for predictions, without considering evidence from the context. Consequently, even state-of-theart NER models generalize poorly to outof-domain scenarios when out-of-distribution (OOD) entity patterns are introduced. Previous research attributes the robustness problem to the existence of NER dataset bias, where simpler and regular entity patterns induce shortcut learning. In this work, we bring new insights into this problem by comprehensively investigating the NER dataset bias from a dataset difficulty view. We quantify the entity-context difficulty distribution in existing datasets and explain their relationship with model robustness. Based on our findings, we explore three potential ways to de-bias the NER datasets by altering entity-context distribution, and we validate the feasibility with intensive experiments. Finally, we show that the de-biased datasets can transfer to different models and even benefit existing model-based robustness-improving methods, indicating that building more robust datasets is fundamental for building more robust NER systems.",
    "authors": [
        {
            "affiliations": [],
            "name": "Ruotian Ma"
        },
        {
            "affiliations": [],
            "name": "Xiaolei Wang"
        },
        {
            "affiliations": [],
            "name": "Xin Zhou"
        },
        {
            "affiliations": [],
            "name": "Qi Zhang"
        },
        {
            "affiliations": [],
            "name": "Xuanjing Huang"
        }
    ],
    "id": "SP:0fd2f4e9d7a5928a4a9f4b65888f65f766a9ffb8",
    "references": [
        {
            "authors": [
                "Oshin Agarwal",
                "Yinfei Yang",
                "Byron C Wallace",
                "Ani Nenkova."
            ],
            "title": "Entity-switched datasets: An approach to auditing the in-domain robustness of named entity recognition models",
            "venue": "arXiv preprint arXiv:2004.04123.",
            "year": 2020
        },
        {
            "authors": [
                "Piotr Bojanowski",
                "Edouard Grave",
                "Armand Joulin",
                "Tomas Mikolov."
            ],
            "title": "Enriching word vectors with subword information",
            "venue": "Transactions of the Association for Computational Linguistics, 5:135\u2013 146.",
            "year": 2017
        },
        {
            "authors": [
                "Jason PC Chiu",
                "Eric Nichols."
            ],
            "title": "Named entity recognition with bidirectional lstm-cnns",
            "venue": "Transactions of the association for computational linguistics, 4:357\u2013370.",
            "year": 2016
        },
        {
            "authors": [
                "Nigel Collier",
                "Jin-Dong Kim."
            ],
            "title": "Introduction to the bio-entity recognition task at JNLPBA",
            "venue": "Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications (NLPBA/BioNLP), pages 73\u201378,",
            "year": 2004
        },
        {
            "authors": [
                "Xiang Dai",
                "Heike Adel."
            ],
            "title": "An analysis of simple data augmentation for named entity recognition",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 3861\u20133867, Barcelona, Spain (Online). International Committee",
            "year": 2020
        },
        {
            "authors": [
                "Leon Derczynski",
                "Eric Nichols",
                "Marieke van Erp",
                "Nut Limsopatham."
            ],
            "title": "Results of the WNUT2017 shared task on novel and emerging entity recognition",
            "venue": "Proceedings of the 3rd Workshop on Noisy User-generated Text, pages",
            "year": 2017
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of the 2019 Conference of the North American Chapter of the",
            "year": 2019
        },
        {
            "authors": [
                "Kawin Ethayarajh",
                "Yejin Choi",
                "Swabha Swayamdipta."
            ],
            "title": "Understanding dataset difficulty with V-usable information",
            "venue": "Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine",
            "year": 2022
        },
        {
            "authors": [
                "Jinlan Fu",
                "Pengfei Liu",
                "Qi Zhang."
            ],
            "title": "Rethinking generalization of neural models: A named entity recognition case study",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 7732\u20137739.",
            "year": 2020
        },
        {
            "authors": [
                "Abbas Ghaddar",
                "Philippe Langlais",
                "Ahmad Rashid",
                "Mehdi Rezagholizadeh."
            ],
            "title": "Context-aware adversarial training for name regularity bias in named entity recognition",
            "venue": "Transactions of the Association for Computational Linguistics, 9:586\u2013604.",
            "year": 2021
        },
        {
            "authors": [
                "Hyunjae Kim",
                "Jaewoo Kang"
            ],
            "title": "How do your biomedical named entity recognition models generalize to novel entities",
            "venue": "Ieee Access,",
            "year": 2022
        },
        {
            "authors": [
                "Ananya Kumar",
                "Aditi Raghunathan",
                "Robbie Matthew Jones",
                "Tengyu Ma",
                "Percy Liang."
            ],
            "title": "Finetuning can distort pretrained features and underperform out-of-distribution",
            "venue": "International Conference on Learning Representations.",
            "year": 2022
        },
        {
            "authors": [
                "Guillaume Lample",
                "Miguel Ballesteros",
                "Sandeep Subramanian",
                "Kazuya Kawakami",
                "Chris Dyer."
            ],
            "title": "Neural architectures for named entity recognition",
            "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association",
            "year": 2016
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdelrahman Mohamed",
                "Omer Levy",
                "Veselin Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "BART: Denoising sequence-to-sequence pre-training for natural language",
            "year": 2020
        },
        {
            "authors": [
                "Jing Li",
                "Aixin Sun",
                "Jianglei Han",
                "Chenliang Li."
            ],
            "title": "A survey on deep learning for named entity recognition",
            "venue": "IEEE Transactions on Knowledge and Data Engineering, 34(1):50\u201370.",
            "year": 2020
        },
        {
            "authors": [
                "Hongyu Lin",
                "Yaojie Lu",
                "Jialong Tang",
                "Xianpei Han",
                "Le Sun",
                "Zhicheng Wei",
                "Nicholas Jing Yuan"
            ],
            "title": "A rigorous study on named entity recognition: Can fine-tuning pretrained model lead to the promised land",
            "year": 2020
        },
        {
            "authors": [
                "Yinhan Liu",
                "Myle Ott",
                "Naman Goyal",
                "Jingfei Du",
                "Mandar Joshi",
                "Danqi Chen",
                "Omer Levy",
                "Mike Lewis",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Roberta: A robustly optimized bert pretraining approach",
            "venue": "arXiv preprint arXiv:1907.11692.",
            "year": 2019
        },
        {
            "authors": [
                "Hao Peng",
                "Tianyu Gao",
                "Xu Han",
                "Yankai Lin",
                "Peng Li",
                "Zhiyuan Liu",
                "Maosong Sun",
                "Jie Zhou."
            ],
            "title": "Learning from Context or Names? An Empirical Study on Neural Relation Extraction",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods",
            "year": 2020
        },
        {
            "authors": [
                "Minlong Peng",
                "Qi Zhang",
                "Xiaoyu Xing",
                "Tao Gui",
                "Jinlan Fu",
                "Xuanjing Huang."
            ],
            "title": "Learning taskspecific representation for novel words in sequence labeling",
            "venue": "arXiv preprint arXiv:1905.12277.",
            "year": 2019
        },
        {
            "authors": [
                "C.E. Shannon."
            ],
            "title": "A mathematical theory of communication",
            "venue": "The Bell System Technical Journal, 27(3):379\u2013423.",
            "year": 1948
        },
        {
            "authors": [
                "Erik F. Tjong Kim Sang",
                "Fien De Meulder"
            ],
            "title": "Introduction to the CoNLL-2003",
            "year": 2003
        },
        {
            "authors": [
                "Christopher Walker",
                "Stephanie Strassel",
                "Julie Medero",
                "Kazuaki Maeda."
            ],
            "title": "Ace 2005 multilingual training corpus ldc2006t06",
            "venue": "URL https://catalog. ldc. upenn. edu/LDC2006T06.",
            "year": 2006
        },
        {
            "authors": [
                "Xiao Wang",
                "Shihan Dou",
                "Limao Xiong",
                "Yicheng Zou",
                "Qi Zhang",
                "Tao Gui",
                "Liang Qiao",
                "Zhanzhan Cheng",
                "Xuanjing Huang."
            ],
            "title": "MINER: Improving out-of-vocabulary named entity recognition from an information theoretic perspective",
            "venue": "Proceedings",
            "year": 2022
        },
        {
            "authors": [
                "Yuan Hu",
                "Qiyuan Bian",
                "Zhihua Liu",
                "Shan Qin",
                "Bolin Zhu",
                "Xiaoyu Xing",
                "Jinlan Fu",
                "Yue Zhang",
                "Minlong Peng",
                "Xiaoqing Zheng",
                "Yaqian Zhou",
                "Zhongyu Wei",
                "Xipeng Qiu",
                "Xuanjing Huang"
            ],
            "title": "TextFlint: Unified multilingual robustness evaluation toolkit",
            "year": 2021
        },
        {
            "authors": [
                "Ralph Weischedel",
                "Martha Palmer",
                "Mitchell Marcus",
                "Eduard Hovy",
                "Sameer Pradhan",
                "Lance Ramshaw",
                "Nianwen Xue",
                "Ann Taylor",
                "Jeff Kaufman",
                "Michelle Franchini"
            ],
            "title": "Linguistic Data Consortium, Philadel",
            "venue": "Ontonotes release",
            "year": 2013
        },
        {
            "authors": [
                "Yilun Xu",
                "Shengjia Zhao",
                "Jiaming Song",
                "Russell Stewart",
                "Stefano Ermon."
            ],
            "title": "A theory of usable information under computational constraints",
            "venue": "International Conference on Learning Representations.",
            "year": 2019
        },
        {
            "authors": [
                "Xiangji Zeng",
                "Yunliang Li",
                "Yuchen Zhai",
                "Yin Zhang."
            ],
            "title": "Counterfactual generator: A weaklysupervised method for named entity recognition",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
            "year": 2020
        },
        {
            "authors": [
                "Qi Zhang",
                "Jinlan Fu",
                "Xiaoyu Liu",
                "Xuanjing Huang."
            ],
            "title": "Adaptive co-attention network for named entity recognition in tweets",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, 32(1).",
            "year": 2018
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Named Entity Recognition (NER), aiming to recognize named entities from unstructured data, is widely studied by researchers as a fundamental task in Natural Language Processing (NLP) and a crucial task in practical applications (Lample et al., 2016; Chiu and Nichols, 2016; Li et al., 2020). Recently, the advances in pre-trained language models (Devlin et al., 2019; Lewis et al., 2020; Liu et al., 2019) have contributed to promising performance on standard NER benchmarks, such\n\u2217Equal contribution. \u2020Corresponding authors.\nas CoNLL03 (Tjong Kim Sang and De Meulder, 2003) and OntoNotes 5.0 (Weischedel et al., 2013).\nDespite the success, recent research has demonstrated the robustness problem in NER: the stateof-the-art NER systems often rely on superficial entity patterns for predictions, while disregarding evidence from the context. Consequently, the models show poor generalization ability in outof-domain (OOD) scenarios where out-of-domain entity patterns are introduced (Lin et al., 2020; Ghaddar et al., 2021; Wang et al., 2022). For instance, Figure 1 shows two typical OOD failures of SOTA NER models: (1) Instances with out-ofvocabulary entities (upper). The entity \"Cathay\" is unseen in the training data, however, the model fails to deduce correctly given obvious evidence \"[]\u2019s profit to grow\" in the context. (2) Instances with ambiguous entities (bottom). Fu et al. (2020) shows when an entity is labeled differently across domains, the model fails to recognize well even with supportive context, such as mistaking the person name \"Apple\" in the example.\nPrevious works have delved into the robustness problem of NER from different perspectives. (Agarwal et al., 2020; Ghaddar et al., 2021; Kim and Kang, 2022; Lin et al., 2020; Wang et al., 2021) examine the NER models by constructing challenging test sets. Their experiments reveal that NER models fail to \"learn from context information\" during training. Agarwal et al. (2020) and Kim and Kang (2022) evaluate models\non controlled entity sets and consider the poor robustness is due to the model\u2019s tendency to memorize entity patterns. Lin et al. (2020) further designs a series of randomization tests and demonstrates that the strong name regularity and high mention coverage rate in existing NER datasets might hinder model robustness. All these studies indicate that the poor robustness of NER models might be due to a hidden dataset bias of existing NER datasets: the entity pattern is \"easier\" for the model to learn, so the models are biased to learn the shortcut in entity names while paying less attention to the context.\nIn this work, we systematically locate the origin of NER dataset bias and investigate its effect on model robustness from a dataset difficulty view. We try to answer two questions:\nQ1: How does the entity-context distribution in the training data induce dataset bias? To answer this question, we borrow a recent concept \"V-information\" (Xu et al., 2019; Ethayarajh et al., 2022) to measure the difficulty of entity and context for the model to learn in each dataset. We find that (1) In all NER datasets we examine, the V-information of the entity is obviously larger than that of the context, indicating the dataset distribution induces models to learn more entity than context. (2) We further design an instancelevel metric to measure the difficulty of entity and context in every single instance. We find that the largest population of instances\u2014with equalityinformative entity and context\u2014does not lead or even harm the models to learn context.\nQ2: Based on the analysis in Q1, are we able to build more robust NER datasets by altering the entity-context distribution in existing data? Based on Q1, we consider three potential ways to de-bias the NER datasets: (1) Reducing the overall V-information of the entity in the training data. (2) Enhancing the overall V-information of the context in the training data. (3) Enlarging the proportion of the robustness-helpful instances, i.e., instances with contexts easier than entities. By conducting extensive experiments, we verify the feasibility of all three approaches. These results also in turn confirm our analysis in Q1. Furthermore, we validate the transferability of the model-specific constructed datasets to improve the robustness of other models. These de-biased data are even helpful for existing model-based robustnessimproving strategies, showing that building more\nrobust datasets is always fundamental for building more robust NER systems.\nWe hope our study can bring new insights into building more robust NER datasets, as well as developing more robust and general NER systems for real-world scenarios1."
        },
        {
            "heading": "2 Measuring the Difficulty of Entity and Context in NER datasets",
            "text": "2.1 Background of V-information Recently, Xu et al. (2019) extends the mutual information Shannon (1948) to a concept of Vusable information under computational constraints, which measures how much information about Y can be extracted from X with a certain model family V . As defined in Xu et al. (2019): Definition 1. Let X , Y be two random variables taking values in X \u00d7 Y . Let V be a predictive family that V \u2286 \u2126 = {f : X \u222a {\u2205} \u2192 P (Y)}. The V-usable information is:2\nIV(X \u2192 Y ) =HV(Y |\u2205)\u2212HV(Y |X) (1)\nwhere HV(Y |\u2205) = inf\nf\u2208V E[\u2212 log2 f [\u2205](Y )]\nHV(Y |X) = inf f\u2208V\nE[\u2212 log2 f [X](Y )] (2)\nMore intuitively, V can be a pre-trained model family like BERT. HV(Y |\u2205) can be computed with a BERT model fine-tuned with a null input \u2205 and Y , and HV(Y |X) can be computed with a BERT model fine-tuned with (X,Y ).\nEthayarajh et al. (2022) further extends Vinformation to measure dataset difficulty. Intuitively, a higher IV(X \u2192 Y ) means V is able to extract more usable information from X about Y , thus indicating an easier dataset for V to learn. They also propose to compare different attributes of X by computing IV(\u03c4(X) \u2192 Y ), where \u03c4(\u00b7) is a transformation on X to isolate an attribute a. For instance, we can transform the regular NLI (Bowman et al., 2015) inputs into hypothesisonly inputs to measure the V-information of the hypothesis attribute.\nEthayarajh et al. (2022) also propose a new measure based on V-information to measure pointwise difficulty, which refers to pointwise Vinformation (PVI):\n1Our code is available at https://github.com/rtmaww/ NERDataBias\n2We use log2 to measure the entropies in bits of information following (Ethayarajh et al., 2022).\nDefinition 2. Let X , Y be two random variables and V be a predictive family, the pointwise Vinformation (PVI) of an instance (x, y) is\nPVI(x \u2192 y) = \u2212 log2 g[\u2205](y) + log2 g \u2032[x](y) (3)\nwhere g, g\u2032 \u2208 V .\nSimilarly, we can use a BERT model fine-tuned with (X,Y ) and a BERT model fine-tuned with (\u2205, Y ) to calculate the PVI of every single instance, and a higher PVI indicates the instance is easier for V . We adopt PVI to measure instance difficulty."
        },
        {
            "heading": "2.2 Decoupling Context and Entity",
            "text": "Motivated by Ethayarajh et al. (2022), in this work, we propose to decouple the entity and context attributes in order to measure the difficulty of each part respectively. Specifically, we first transform the NER dataset into two separate entity-only and context-only datasets. As shown in Fig.2, to build the context-only dataset, we replace the entity with a \"[MASK]\". To build the entity-only dataset, we simply use the entity as input. Then, we respectively train a context-only and an entity-only classification model based on a pre-trained model family (such as BERT) to predict the entity type based on the inputs. Based on the trained models, we can thus calculate the respective PVI of context and entity in each instance, as well as calculate the V-information of context and entity of the whole training data, which indicates the difficulty of context and entity in this dataset to the used pretrained model. More implementation details are included in Appendix A.3."
        },
        {
            "heading": "2.3 Context-entity Information Margin (CEIM)",
            "text": "In order to better describe the difficulty discrepancy of context and entity in an instance, we further introduce a new measure: Context-entity Information Margin (CEIM). Formally, we refer to the context-only model as MC , and the entity-only\nmodel as ME . For each instance (x, y), we denote the context PVI (measured by MC) as PVIC(x), and the entity PVI (measured by ME) as PVIE(x). The CEIM is then calculated by:\nCEIM(x) = PVIE(x)\u2212 PVIC(x) (4)\nIntuitively, a high CEIM means the entity name in the instance is much easier to learn than the context."
        },
        {
            "heading": "3 How Does the Entity-context",
            "text": "Distribution Induce Dataset Bias?\nIn order to answer Q1, in this section, we decouple the context and entity in NER datasets and calculate the V-information of each part, so as to obtain the context-entity difficulty distribution. Based on the results, we analyze the correlation between a context-entity distribution and dataset bias in NER datasets at both the whole-data level (Sec.3.2) and the instance level (Sec.3.3)."
        },
        {
            "heading": "3.1 Experiment Setup",
            "text": "Dataset To obtain comprehensive knowledge of the entity-context distribution of different NER datasets, we first conduct experiments on 6 commonly used datasets to calculate the Vinformation of each dataset: CoNLL 2003 (Tjong Kim Sang and De Meulder, 2003), OntoNotes 5.0 (Weischedel et al., 2013), Bio-NER (Collier and Kim, 2004), ACE 2005 (Walker et al., 2006), Twitter (Zhang et al., 2018) and WNUT 2017 (Derczynski et al., 2017).\nIn Section 3.3, we include experiments to further explore the correlation between the entity-context distribution and model robustness. Following previous works on NER robustness (Lin et al., 2020; Wang et al., 2022), we experiment on CoNLL 2003 and ACE 2005 datasets. Except for evaluating standard performance on the i.i.d. test set (denoted as Test), we adopt two robustness test sets (Wang et al., 2021) for each dataset, the OOV and CrossCategory test sets, as the measure of model robustness, also following (Wang et al., 2022). These two robustness test set corresponds to the two typical failures of NER models as described in Fig.1, respectively. We include more dataset details and example cases of these test sets in the Appendix A.2.\nBase Model We conducted all experiments in this section based on the BERT-base-cased pretrained model (Devlin et al., 2019). More implementation details are included in Appendix A.3.\n3.2 V-information Comparison between Context and Entity\nIn Figure 3, we show the isolated V-information of context and entity in 6 common NER datasets. From the results, we can observe that (1) In most of the commonly-used datasets, the V-information of the entity is larger than 1.0. Such high values indicate the pre-trained model is able to learn and correctly classify most entities in the datasets without any information from the context. (2) In all datasets, the V-information of the entity is obviously higher than that of context, meaning that the entity is much easier for the pre-trained model to learn than the context. Such V-information discrepancy in existing datasets means that the difficulty distribution of existing datasets induces the model to learn more from entities instead of contexts. Corresponding to previous studies (Agarwal et al., 2020; Kim and Kang, 2022; Lin et al., 2020), this is an intrinsic bias in NER datasets that harms model robustness."
        },
        {
            "heading": "3.3 Understanding Entity-context Distribution with CEIM",
            "text": "As V-information is the difficulty measure of the whole dataset, we step further to understand the instance-level difficulty of context and entity with Context-entity Information Margin (CEIM) (Section 2.3). We calculate the CEIM of instances in each dataset and divide the instances into 3 categories: (1) High-CEIM: instances with high CEIM, i.e., the entity is easier to learn than the context; (2) Low-CEIM: instances with low CEIM, i.e., the context is easier to learn; (3) NZ-CEIM: instances with a near-zero CEIM (|CEIM(x)| < 0.5), i.e., the context and entity is equally-easy to learn.\nTable 1 shows the distribution of different CEIM instances and the average PVIE in each part. It\u2019s shown that the near-zero-CEIM instances cover the largest proportion in all datasets, and next is the high-CEIM instances. Also, the Average-PVIE shows that both the near-zero-CEIM and highCEIM instances mainly contain high-PVI (easyto-learn) entities.\nIn Table 2, we show some cases of different CEIM instances. Generally speaking, the highCEIM instances often contain low-PVI contexts that are ambiguous or misleading, while containing informative entities. The near-zero-CEIM instances often consist of equally informative\ncontexts and entities. The low-CEIM instances consist of high-PVI context and low-PVI entities, where the entities are often rare, more complicated, or ambiguous. We include more discussion on how different CEIM instances might affect model prediction in Appendix A.1.\nHow do different CEIM instances affect model robustness? To further understand the impact of entity-context distribution on the model robustness, we further conducted an experiment to compare the model behavior when trained on data with different CEIMs. We first randomly sampled 1000 instances from the whole dataset as a baseline training set, denoted as Base. Next, we randomly sampled 1000 near-zero-CEIM instances and add them to Base to construct a new 2000-instance training set, denoted as Base+NZ. Similarly, we constructed another two training sets Base+High and Base+Low by adding 1000 randomly-sampled high-CEIM and low-CEIM instances to Base, respectively. We then train a model on each training set and evaluate their performance on the test set and the robustness OOV and CrossCategory test set.\nTable 3 shows the effect of different CEIM data on the model performance. We can see that: (1) By adding 1000 extra instances to Base, the performance on the test set is improved on all training sets. Among all training sets, Base+High\nand Base+NZ show slightly larger improvement than Base+Low, which corresponds to the findings in previous studies (Lin et al., 2020; Agarwal et al., 2020; Zeng et al., 2020) that high-PVI entity names contribute more to the generalization on the i.i.d. test set. (2) Base+Low shows notable improvement on both OOV and CrossCategory test sets, while Base+High and Base+NZ are less beneficial or even harmful to the robustness performance. These results demonstrate that the low-CEIM instances, i.e., instances with contexts easier than entities, contribute most to the model robustness. (3) The limited robustness performance of Base+NZ also indicates that although the context may be informative enough for label predicting, with equally easy entity and context, the pre-trained model still tends to make use of the entity information instead of context. Unfortunately, the near-zero-CEIM data constitutes the largest proportion in all datasets (Tab.1), thus having much larger effects on the model training than the lowCEIM data (which largely improves robustness).\n4 Can We Build More Robust Datasets by Altering Entity-context Distribution?\nBased on the above analysis, in this section, we explore three potential ways to de-bias NER datasets by altering the entity-context distribution."
        },
        {
            "heading": "4.1 Experiment Setup",
            "text": "Datasets Similar to Section 3, in this section, we conduct experiments on the CoNLL2003 and ACE2005 datasets, and evaluate the i.i.d. test performance on the Test set, as well as the robustness performance on the OOV and CrossCategory test sets (denoted as \"Cate.\").\nBase Model and Baselines In this section, we conduct all experiments based on two pre-trained LM, BERT-base-cased (Devlin et al., 2019) and RoBERTa-large (Liu et al., 2019). To better verify the robustness improvement of the three de-bias methods, we include several robustness-improving baselines: (1) Base (Devlin et al., 2019; Liu et al., 2019) The base token classification model based on BERT-base-cased and RoBERTa-large, trained on the original training sets; (2) DataAug (Dai and Adel, 2020), which augments the training set by replacing entities with similar entities or typos entities; (3) MINER (Wang et al., 2022), which also creates samples with entity switching and trained with a contrastive robustness-improving loss. It is also the SOTA method in NER robustness; (4) LPFT (Kumar et al., 2022), a general OOD method that can effectively improve OOD model generalization. More implementation details can be found in Appendix A.4."
        },
        {
            "heading": "4.2 Enlarging the Low-CEIM Proportion",
            "text": "The experiments in Section 3.3 have shown that the high-CEIM data and near-zero-CEIM data contribute less to the model robustness, while the low-CEIM data do make the model learn more from context. However, the proportion of the lowCEIM data in the datasets is quite low, leading to limited influence on the model learning. In this section, we reconstruct the training sets to alter the proportion of low-CEIM data, trying to investigate: (1) If enlarging the proportion of low-CEIM data is a feasible way to improve robustness; (2) If we can achieve a good balance of robustness and generalization with a certain proportion of low-\nCEIM data."
        },
        {
            "heading": "4.2.1 Detailed Experimental Settings",
            "text": "As the number of low-CEIM instances is limited in both CoNLL2003 and ACE2005 datasets (Table 1), we decided to fix the instance number of the reconstructed training sets to 1000. We construct datasets with the proportion of low-CEIM data ranging from 0% to 90%. For example, when constructing a training set with 20% low-CEIM data, we randomly sample 200 instances from the low-CEIM data and 800 instances from the highor near-zero-CEIM data."
        },
        {
            "heading": "4.2.2 Results",
            "text": "Figure 4 shows the model performance trained on the reconstructed training sets on BERT-basecased 3. We can observe that: (1) With the proportion of low-CEIM data increasing, the performance on the test set keeps dropping, which corresponds to the discussion in Sec.3.3 that the high- and near-zero-CEIM data contribute more to i.i.d. generalization. (2) As the proportion of low-CEIM data increases, the performance on the OOV and CrossCategory test sets generally shows a trend of first rising and then falling. The rising robustness performance at low low-CEIM proportion validates the effectiveness of enlarging the low-CEIM proportion for improving model robustness. However, as the low-CEIM proportion\n3The results on RoBERTa-large are in Appendix A.5.\nkeeps increasing, the poor generalization ability will also affect robustness and lead to declining results. (3) Compared with the results on 1000 random data, the reconstructed data, with certain data proportions, achieves significant improvement on the robustness test sets and comparable performance on the Test set. We conclude that for different datasets, there exists appropriate proportions when a good balance of i.i.d. and OOD generalization can be achieved (e.g., 10%- 30% for CoNLL03, 20%-40% for ACE05).\n4.3 Reducing the V-information of Entity\nAs discussed in Section 3.2, the V-information discrepancy between entity and context is the main factor of dataset bias in NER. In order to de-bias NER datasets, the most intuitive idea is to increase the low-PVI entities or decrease the high-PVI entities in the training set. In this section, we explore potential ways to reduce the V-information of the entity of the training set by dataset reconstruction:\nA. Random2low: Increasing the low-PVI entities by randomly replacing high-PVI entities with low-PVI entities. The replaced sentences are added to the original dataset as data augmentation.\nB. HighC2low: Based on A, we further select instances with high-PVI context and high-PVI entity for entity replacement. This process\nensures that the replaced instances have informative contexts for the model to learn and predict.\nC. Redundant2low: As declared in (Lin et al., 2020), existing datasets mainly consist of regularlypatterned entities that harm model robustness. We also find in our experiments that there exists a large number of redundant high-PVI entities in the datasets. Therefore, we propose to reduce these redundant entities by replacing them with low-PVI entities. Different from A and B, this method doesn\u2019t increase the total data size.\nNote that all methods are actually trying to introduce more low-CEIM instances. In our experiments, we reconstruct the existing datasets based on the above methods and train new models on the reconstructed training sets, separately."
        },
        {
            "heading": "4.3.1 Results",
            "text": "Table 4 shows the results of the models trained on three types of reconstructed datasets. Here, m% means replacing m% of the total entities in each method. From the results, we can observe that: (1) All of the three methods show obvious improvement over Base and even DataAug on OOV and CrossCategory. As the replacement rate grows, the robustness performance generally increases, as well as the test performance decreases. This trend is similar to previously observed trends in Fig.4. (2) Compared with A.Random2Low, B.HighCLow shows relatively higher robustness performance and test performance. This is because randomly replacing high-PVI entities\nwith low-PVI entities without considering the context might create instances with both difficult entity and context, which would not benefit robustness and generalization. In contrast, B.HighC2Low ensures introducing more lowCEIM instances. In most cases, B.HighC2Low can construct a dataset that achieves both higher robustness performance and comparable test performance. (3) C.Redundant2Low is also effective in improving model robustness. Although a large proportion of high-PVI entities are replaced, the test performance is only slightly hurt and comparable to A.Random2Low and DataAug that increases data size with augmentation. It also achieves larger improvement on the robustness test sets than A.Random2Low and DataAug. These results demonstrate that the large number of redundant high-PVI entities in the NER datasets limitedly benefits model generalization yet would harm model robustness. (4) Apart from the three methods, MINER can also achieve good robustness. Nevertheless, we claim that the dataset reconstruction methods are generally orthogonal to the model-based robustness-improving methods like MINER. More details of this point are discussed in Sec.4.5.\n4.4 Enhancing the V-information of Context Aside from lowering the V-information of the entity in Sec.4.3, another intuitive approach is to enhance the V-information of the context. Similar to Sec.4.3, in this section, we design two potential ways to increase the proportion of high-PVI\ncontexts in the training sets:\nI.Random2High Randomly deleting a certain ratio of contexts and replacing them with high-PVI contexts from the retained set.\nII.Low2High Deleting a certain ratio of low-PVI contexts, and replacing the deleted contexts with high-PVI contexts.\nSimilar to Section 4.3, we reconstruct the existing datasets based on the above methods and train new models on the reconstructed data, separately."
        },
        {
            "heading": "4.4.1 Results",
            "text": "Table 5 shows the results of different methods, where m% means deleting (replacing) m% of the total context. We can observe that: (1) Randomly deleting a certain proportion of context, although decreases context diversity in the datasets, doesn\u2019t show a serious drop in the test performance. Interestingly, by replacing these contexts with highPVI contexts, the robustness performance can be improved to a certain degree. (2) As shown in Appendix A.1, low-PVI contexts are often noisy contexts and will harm performance. Therefore, it is intuitive that replacing low-PVI contexts with high-PVI contexts effectively improves robustness performance. It also outperforms I.Random2High on most replacement rates, validating that reducing context difficulty can largely improve model robustness. However, this method suffers from more decrease in the test performance, which might be because reducing the low-PVI contexts relatively reduces model attention on the entity,\nthus hindering generalization on i.i.d. distribution. Nevertheless, the results show that a good tradeoff between OOD and i.i.d. performance can be achieved with certain replacement ratios."
        },
        {
            "heading": "4.5 Transferability of the De-biased Datasets",
            "text": "As the V-information calculation is model-specific, it is intuitive to wonder if the datasets reconstructed based on one model can transfer to another model. In both Table 4 and Table 5, we further conduct experiments to investigate the transferability of the de-biased datasets. In both experiments, we trained MINER on the reconstructed datasets (MINER+HighC2Low 40% and MINER+Low2High 40%). We also use the BERT-based reconstructed datasets to train RoBERTa-large models (BERT.HighC2Low 40% and BERT.Low2High 40%). Surprisingly, the reconstructed datasets can also benefit other models to a certain degree. These results not only validate the generalizability of the de-biased datasets, but also reveal that the dataset reconstruction methods are orthogonal to the model-based robustnessimproving methods such as MINER. It also shows that building more robust datasets is fundamental for building more robust NER systems."
        },
        {
            "heading": "5 Related Work",
            "text": ""
        },
        {
            "heading": "5.1 Analyzing the Robustness Problem in NER.",
            "text": "Many works have focused on analyzing the robustness problem in NER. These works generally fall into two categories: (1) Constructing challenging sets to evaluate the model robustness (Ghaddar\net al., 2021; Lin et al., 2020) such as switching the entities in test sets (Agarwal et al., 2020), testing on out-of-dictionary entities (Lin et al., 2020; Kim and Kang, 2022) or introducing typos to create OOV entities (Wang et al., 2021); (2) Investigating the impact of possible attribute through a delicate design of experiments (Fu et al., 2020; Kim and Kang, 2022), such as conducting randomization experiments (Lin et al., 2020) or measuring the impact of attributes with specifically-designed metrics (Fu et al., 2020). Our work is totally different from the existing studies. We provide a brand new view of considering the NER robustness problem by quantifying and comprehensively analyzing the correlation between context-entity distribution and model robustness and provide new insights into the NER robustness studies.\nIt is worth mentioning that Lin et al. (2020) and Peng et al. (2020) (work on Relation Extraction) also consider the \"context or name\" problem and design experiments to disentangle the impact of context and entity name. These experiments also motivate the experiment designs in this work."
        },
        {
            "heading": "5.2 Mitigating the Robustness Problem in NER.",
            "text": "There are also many works that aim at mitigating the robustness problem in NER. These works include methods to alleviate the OOV problem (Bojanowski et al., 2017; Peng et al., 2019), leveraging data augmentation (Dai and Adel, 2020; Zeng et al., 2020) or adopting adversarial training (Ghaddar et al., 2021) or other training strategies (Wang et al., 2022) to improve model robustness. In this work, we explore a new direction of approaches: to improve model robustness through data reconstruction. We also argue that constructing robust datasets is fundamental for building more robust NER systems."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this work, we conduct an interesting study on the model robustness problem of NER. We quantify the difficulty distribution of context and entity in existing NER datasets and reveal how the entity-context distribution affects model robustness. Based on our analysis, we further explore three potential ways to de-bias the existing NER datasets by reconstructing the existing datasets and altering the entity-context distribution. With extensive experiments, we validate that the reconstructed\ndatasets can largely improve model robustness. As these datasets can also benefit model-based robustness-improving methods, we argue that building more robust datasets is fundamental for building more robust NER systems."
        },
        {
            "heading": "Acknowledgement",
            "text": "The authors wish to thank the anonymous reviewers for their helpful comments. This work was partially funded by National Natural Science Foundation of China (No.62076069, 61976056) and Shanghai Academic Research Leader Program 22XD1401100.\nLimitations\nWe summarize the limitations of this work as follows: (1) We regard our work as an exploratory study on the robustness problem of NER from the dataset view. Nevertheless, the method to measure the dataset difficulty is not quite efficient since it requires first training two individual models on an i.i.d. training set. There might be more efficient ways to measure the dataset and instance difficulty, thus further improving the efficiency and practicality of the data reconstruction methods. (2) In this work, we consider the robustness problem of NER models with only small pre-trained models (model size less than 1B). As the large language models have shown powerful ability in information extraction tasks, it is in doubt that if the same conclusion can also generalize to large language models. Nevertheless, we believe our study is worthful since building more robust datasets is always important for building a NER system required for real-world usage. We expect our work can prompt more valuable future works also on large language models."
        },
        {
            "heading": "A Appendix",
            "text": "A.1 Discussion of Different CEIM instances\nIn Section 3.3, we categorized each dataset into three categories based on the CEIM scores: high-CEIM instances, low-CEIM instances, and Near-zero-CEIM instances. Then, we conducted experiments to show the effect of different CEIM instances on model robustness. To better understand the concept of CEIM, we provide some examples of different CEIM instances in Tab.2.\nGenerally, the high-CEIM instances often contain low-PVI contexts. These contexts are often ambiguous or misleading, thus might introduce noise in model learning. On the contrary, the entities in these high-CEIM instances are often informative enough for the model to predict. As a result, the model will pay less attention to the context when trained on high-CEIM instances. Therefore, removing these low-PVI contexts is also helpful for de-bias the datasets, as shown in Sec.4.4.\nIn near-zero-CEIM instances, the context and the entity are usually equally supportive (the number of cases with equally-low context and entity is small). However, the entity pattern is easier to learn and memorize. We deduce that the model might still tend to memorize entity patterns instead of learning more context, corresponding to the results in Table 3.\nThe low-CEIM instances consist of high-PVI context and low-PVI entities. These entities are often ambiguous, more complicated or less frequent entities. Therefore, trained on low-CEIM instances, the model will tend to pay attention to the informative context for label predicting, which will benefit robustness. However, as the generalization to the i.i.d. test sets mainly relies on high-PVI entities, these low-CEIM instances, although helpful in OOD situations, might harm i.i.d. generalizations. In Section 4.2,4.3,4.4, we validate that an appropriate context-entity distribution can achieve better trade-off between i.i.d. and OOD generalization.\nA.2 Dataset Details\nIn Section 3, we examine and analyze the V-information of 6 commonly used datasets, including: CoNLL 2003 (Tjong Kim Sang and De Meulder, 2003) from the newswire domain,\nOntoNotes 5.0 (Weischedel et al., 2013)4 from the general domain, Bio-NER (Collier and Kim, 2004) from the biology domain, ACE 2005 (Walker et al., 2006)5 the general domain, Twitter (Zhang et al., 2018) from social media domain and WNUT 2017 (Derczynski et al., 2017) from social media domain. The dataset details can be found in Table 6.\nIn Section 4 and further exploration in Section 3, we conduct experiments on CoNLL 2003 and ACE 2005 to investigate the relation between the entity-context distribution and model robustness. Following (Wang et al., 2022), we adopt two robustness test sets from (Wang et al., 2021): the OOV test set and the CrossCategory test set (denoted as \"Cate.\"). The OOV test set is constructed by replacing entities with outof-vocabulary entities of the same category. The CrossCategory test set is constructed by replacing entities with entities from different categories. Therefore, these two robustness test sets respectively correspond to the two typical failures of SOTA NER models shown in Figure 1. In Table 9, we show some cases of these two robustness test sets for better understanding. We also include quantity details of these two test sets in Table 6.\nA.3 Implementation Details for V-information Experiments\nIn Section 3, we conducted experiments to calculate the V-information and PVIs of each dataset. For both context-only and entity-only models, we implemented based on the text classification model based on the Huggingface library6. To measure the PVI of the whole training set, we adopted 5-fold cross-validation. As the PVI of an instance (x, y) only depends on the distribution of (X,Y ), using 5-fold cross-validation will not affect the estimation of PVI (Ethayarajh et al., 2022). We detail the hyperparameters used for the experiments in Table 7. Other hyperparameters are the same as the default hyperparameters if not noted.\nAll experiments are conducted on NVIDIA GeForce RTX 3090 and NVIDIA Tesla V100. For each result, we report the average results of 3 repeated experiments.\n4https://catalog.ldc.upenn.edu/license/ ldc-non-members-agreement.pdf\n5https://catalog.ldc.upenn.edu/license/ ldc-non-members-agreement.pdf\n6https://github.com/huggingface/transformers/ tree/main/examples/pytorch/text-classification\nA.4 Implementation Details for Dataset Reconstruction Experiments\nWe implemented all BERT-base-cased and RoBERTalarge dataset reconstruction experiments based on the token classification model in the Huggingface library7. For DataAug, we implemented based on the implementations from (Wang et al., 2022)8. For MINER, we implemented based on the released code9. We used batch_size=32, gama=0.001, beta=0.01, lr=0.00001 for BERT-based baselines, and used batch_size=32, gama=0.0001, beta=0.0001, lr=0.00001 for RoBERTa-based baselines. For LPFT, we also implemented based on the token classification model in the Huggingface library10. We include the hyperparameters used for the experiments in Table 8. Other hyperparameters\n7https://github.com/huggingface/transformers/ tree/main/examples/pytorch/token-classification\n8https://github.com/BeyonderXX/MINER 9https://github.com/BeyonderXX/MINER\n10https://github.com/huggingface/transformers/ tree/main/examples/pytorch/token-classification\nare the same as the default hyperparameters if not noted.\nAll experiments are conducted on NVIDIA GeForce RTX 3090 and NVIDIA Tesla V100. For each result, we report the average results of 3 repeated experiments.\nA.5 Detailed Experiment Results of Data Reconstruction\nIn Section 4, we only showed a part of the experiment results due to space limitation. In this section, we include other detailed experiment results, including the results based on RoBERTalarge in Section 4.2 (Fig.5), the detailed results of different data reconstruction rates in Section 4.3 (Table 10) and Section 4.4 (Table 11)."
        }
    ],
    "title": "Towards Building More Robust NER Datasets: An Empirical Study on NER Dataset Bias from a Dataset Difficulty View",
    "year": 2023
}