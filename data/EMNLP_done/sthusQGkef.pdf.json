{
    "abstractText": "Few-shot relation extraction involves identifying the type of relationship between two specific entities within a text, using a limited number of annotated samples. A variety of solutions to this problem have emerged by applying meta-learning and neural graph techniques which typically necessitate a training process for adaptation. Recently, the strategy of incontext learning has been demonstrating notable results without training. Few studies have already utilized in-context learning for zeroshot information extraction. Unfortunately, the evidence for inference is either not considered or implicitly modeled during the construction of chain-of-thought prompts. In this paper, we propose a novel approach for few-shot relation extraction using large language models, named CoT-ER, chain-of-thought with explicit evidence reasoning. In particular, CoT-ER first induces large language models to generate evidence using task-specific and concept-level knowledge. Then this evidence is explicitly incorporated into chain-of-thought prompting for relation extraction. Experimental results demonstrate that our CoT-ER approach (with 0% training data) achieves competitive performance compared to the fully-supervised (with 100% training data) state-of-the-art approach on the FewRel1.0 and FewRel2.0 datasets.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xilai Ma"
        },
        {
            "affiliations": [],
            "name": "Jing Li"
        },
        {
            "affiliations": [],
            "name": "Min Zhang"
        }
    ],
    "id": "SP:b20a2d9d21dc9d9a6bf5d2369d708bd7047b8e9a",
    "references": [
        {
            "authors": [
                "Nguyen Bach",
                "Sameer Badaskar."
            ],
            "title": "A review of relation extraction",
            "venue": "Literature review for Language and Statistics II, 2:1\u201315.",
            "year": 2007
        },
        {
            "authors": [
                "Tom Kwiatkowski"
            ],
            "title": "Matching the blanks: Distributional similarity for relation learning",
            "venue": "In The 57th Annual Meeting of the Association for Computational Linguistics (ACL),",
            "year": 2019
        },
        {
            "authors": [
                "Sam Brody",
                "Sichao Wu",
                "Adrian Benton."
            ],
            "title": "Towards realistic few-shot relation extraction",
            "venue": "The 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5338\u20135345.",
            "year": 2021
        },
        {
            "authors": [
                "Tom Brown",
                "Benjamin Mann",
                "Nick Ryder",
                "Melanie Subbiah",
                "Jared D Kaplan",
                "Prafulla Dhariwal",
                "Arvind Neelakantan",
                "Pranav Shyam",
                "Girish Sastry",
                "Amanda Askell"
            ],
            "title": "Language models are few-shot learners. Advances in neural information processing",
            "year": 2020
        },
        {
            "authors": [
                "Claire Cardie."
            ],
            "title": "Empirical methods in information extraction",
            "venue": "AI magazine, 18(4):65\u201365.",
            "year": 1997
        },
        {
            "authors": [
                "Qingxiu Dong",
                "Lei Li",
                "Damai Dai",
                "Ce Zheng",
                "Zhiyong Wu",
                "Baobao Chang",
                "Xu Sun",
                "Jingjing Xu",
                "Zhifang Sui."
            ],
            "title": "A survey for in-context learning",
            "venue": "arXiv preprint arXiv:2301.00234.",
            "year": 2022
        },
        {
            "authors": [
                "Chunliu Dou",
                "Shaojuan Wu",
                "Xiaowang Zhang",
                "Zhiyong Feng",
                "Kewen Wang."
            ],
            "title": "Function-words enhanced attention networks for few-shot inverse relation classification",
            "venue": "arXiv preprint arXiv:2204.12111.",
            "year": 2022
        },
        {
            "authors": [
                "Liu Fangchao",
                "Xiao Xinyan",
                "Yan Lingyong",
                "Lin Hongyu",
                "Han Xianpei",
                "Dai Dai",
                "Wu Hua",
                "Sun Le."
            ],
            "title": "From learning-to-match to learning-todiscriminate:global prototype learning for few-shot relation classification",
            "venue": "The 20th Chinese National",
            "year": 2021
        },
        {
            "authors": [
                "Tianyu Gao",
                "Xu Han",
                "Zhiyuan Liu",
                "Maosong Sun."
            ],
            "title": "Hybrid attention-based prototypical networks for noisy few-shot relation classification",
            "venue": "The AAAI conference on artificial intelligence (AAAI), volume 33, pages 6407\u20136414.",
            "year": 2019
        },
        {
            "authors": [
                "Tianyu Gao",
                "Xu Han",
                "Hao Zhu",
                "Zhiyuan Liu",
                "Peng Li",
                "Maosong Sun",
                "Jie Zhou"
            ],
            "title": "2019b. FewRel 2.0: Towards more challenging few-shot relation classification",
            "venue": "In The 2019 Conference on Empirical Methods in Natural Language Processing and the 9th In-",
            "year": 2019
        },
        {
            "authors": [
                "Jiale Han",
                "Bo Cheng",
                "Wei Lu."
            ],
            "title": "Exploring task difficulty for few-shot relation extraction",
            "venue": "The 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2605\u20132616.",
            "year": 2021
        },
        {
            "authors": [
                "Xu Han",
                "Hao Zhu",
                "Pengfei Yu",
                "Ziyun Wang",
                "Yuan Yao",
                "Zhiyuan Liu",
                "Maosong Sun."
            ],
            "title": "FewRel: A large-scale supervised few-shot relation classification dataset with state-of-the-art evaluation",
            "venue": "The 2018 Conference on Empirical Methods in Natural",
            "year": 2018
        },
        {
            "authors": [
                "Junheng Hao",
                "Muhao Chen",
                "Wenchao Yu",
                "Yizhou Sun",
                "Wei Wang."
            ],
            "title": "Universal representation learning of knowledge bases by jointly embedding instances and ontological concepts",
            "venue": "The 25th ACM SIGKDD International Conference on Knowledge",
            "year": 2019
        },
        {
            "authors": [
                "Or Honovich",
                "Uri Shaham",
                "Samuel R Bowman",
                "Omer Levy."
            ],
            "title": "Instruction induction: From few examples to natural language task descriptions",
            "venue": "arXiv preprint arXiv:2205.10782.",
            "year": 2022
        },
        {
            "authors": [
                "Bernal Jimenez Gutierrez",
                "Nikolas McNeal",
                "Clayton Washington",
                "You Chen",
                "Lang Li",
                "Huan Sun",
                "Yu Su."
            ],
            "title": "Thinking about GPT-3 in-context learning for biomedical IE? think again",
            "venue": "Findings of the Association for Computational Linguistics (EMNLP),",
            "year": 2022
        },
        {
            "authors": [
                "Takeshi Kojima",
                "Shixiang Shane Gu",
                "Machel Reid",
                "Yutaka Matsuo",
                "Yusuke Iwasawa."
            ],
            "title": "Large language models are zero-shot reasoners",
            "venue": "arXiv preprint arXiv:2205.11916.",
            "year": 2022
        },
        {
            "authors": [
                "Jing Li",
                "Yequan Wang",
                "Shuai Zhang",
                "Min Zhang."
            ],
            "title": "Rethinking document-level relation extraction: A reality check",
            "venue": "Findings of the Association for Computational Linguistics (ACL), pages 5715\u20135730.",
            "year": 2023
        },
        {
            "authors": [
                "Wanli Li",
                "Tieyun Qian."
            ],
            "title": "Graph-based model generation for few-shot relation extraction",
            "venue": "The 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 62\u201371.",
            "year": 2022
        },
        {
            "authors": [
                "Jiachang Liu",
                "Dinghan Shen",
                "Yizhe Zhang",
                "Bill Dolan",
                "Lawrence Carin",
                "Weizhu Chen"
            ],
            "title": "What makes good in-context examples for GPT-3? In Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration",
            "year": 2022
        },
        {
            "authors": [
                "Yang Liu",
                "Jinpeng Hu",
                "Xiang Wan",
                "Tsung-Hui Chang."
            ],
            "title": "A simple yet effective relation information guided approach for few-shot relation extraction",
            "venue": "Findings of the Association for Computational Linguistics (ACL), pages 757\u2013763.",
            "year": 2022
        },
        {
            "authors": [
                "Robert Logan IV",
                "Ivana Balazevic",
                "Eric Wallace",
                "Fabio Petroni",
                "Sameer Singh",
                "Sebastian Riedel."
            ],
            "title": "Cutting down on prompts and parameters: Simple few-shot learning with language models",
            "venue": "Findings of the Association for Computational Linguistics",
            "year": 2022
        },
        {
            "authors": [
                "Yao Lu",
                "Max Bartolo",
                "Alastair Moore",
                "Sebastian Riedel",
                "Pontus Stenetorp."
            ],
            "title": "Fantastically ordered prompts and where to find them: Overcoming fewshot prompt order sensitivity",
            "venue": "The 60th Annual Meeting of the Association for Computational Lin-",
            "year": 2022
        },
        {
            "authors": [
                "Qinghua Hu",
                "Bingzhe Wu."
            ],
            "title": "Fairnessguided few-shot prompting for large language models",
            "venue": "arXiv preprint arXiv:2303.13217.",
            "year": 2023
        },
        {
            "authors": [
                "Sewon Min",
                "Xinxi Lyu",
                "Ari Holtzman",
                "Mikel Artetxe",
                "Mike Lewis",
                "Hannaneh Hajishirzi",
                "Luke Zettlemoyer"
            ],
            "title": "Rethinking the role of demonstrations: What makes in-context learning work",
            "venue": "In The 2022 Conference on Empirical Methods in Natural Lan-",
            "year": 2022
        },
        {
            "authors": [
                "Sachin Pawar",
                "Girish K Palshikar",
                "Pushpak Bhattacharyya."
            ],
            "title": "Relation extraction: A survey",
            "venue": "arXiv preprint arXiv:1712.05191.",
            "year": 2017
        },
        {
            "authors": [
                "Hao Peng",
                "Tianyu Gao",
                "Xu Han",
                "Yankai Lin",
                "Peng Li",
                "Zhiyuan Liu",
                "Maosong Sun",
                "Jie Zhou."
            ],
            "title": "Learning from Context or Names? An Empirical Study on Neural Relation Extraction",
            "venue": "The 2020 Conference on Empirical Methods in Natural Lan-",
            "year": 2020
        },
        {
            "authors": [
                "Ethan Perez",
                "Douwe Kiela",
                "Kyunghyun Cho."
            ],
            "title": "True few-shot learning with language models",
            "venue": "Advances in neural information processing systems (NIPS), 34:11054\u201311070.",
            "year": 2021
        },
        {
            "authors": [
                "Fabio Petroni",
                "Tim Rockt\u00e4schel",
                "Sebastian Riedel",
                "Patrick Lewis",
                "Anton Bakhtin",
                "Yuxiang Wu",
                "Alexander Miller"
            ],
            "title": "Language models as knowledge bases",
            "venue": "In The 2019 Conference on Empirical Methods in Natural Language Processing and the 9th",
            "year": 2019
        },
        {
            "authors": [
                "Meng Qu",
                "Tianyu Gao",
                "Louis-Pascal Xhonneux",
                "Jian Tang."
            ],
            "title": "Few-shot relation extraction via Bayesian meta-learning on relation graphs",
            "venue": "The 37th International Conference on Machine Learning (ICML), volume 119, pages 7867\u20137876.",
            "year": 2020
        },
        {
            "authors": [
                "Adam Roberts",
                "Colin Raffel",
                "Noam Shazeer"
            ],
            "title": "How much knowledge can you pack into the parameters of a language model",
            "venue": "In The 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
            "year": 2020
        },
        {
            "authors": [
                "Timo Schick",
                "Hinrich Sch\u00fctze."
            ],
            "title": "True few-shot learning with Prompts\u2014A real-world perspective",
            "venue": "Transactions of the Association for Computational Linguistics (TACL), 10:716\u2013731.",
            "year": 2022
        },
        {
            "authors": [
                "Karthik Valmeekam",
                "Alberto Olmo",
                "Sarath Sreedharan",
                "Subbarao Kambhampati."
            ],
            "title": "Large language models still can\u2019t plan (a benchmark for llms on planning and reasoning about change)",
            "venue": "arXiv preprint arXiv:2206.10498.",
            "year": 2022
        },
        {
            "authors": [
                "Zhen Wan",
                "Fei Cheng",
                "Zhuoyuan Mao",
                "Qianying Liu",
                "Haiyue Song",
                "Jiwei Li",
                "Sadao Kurohashi."
            ],
            "title": "Gpt-re: In-context learning for relation extraction using large language models",
            "venue": "arXiv preprint arXiv:2305.02105.",
            "year": 2023
        },
        {
            "authors": [
                "Yizhong Wang",
                "Swaroop Mishra",
                "Pegah Alipoormolabashi",
                "Yeganeh Kordi",
                "Amirreza Mirzaei",
                "Atharva Naik",
                "Arjun Ashok",
                "Arut Selvan Dhanasekaran",
                "Anjana Arunkumar",
                "David Stap"
            ],
            "title": "Supernaturalinstructions: Generalization via declarative",
            "year": 2022
        },
        {
            "authors": [
                "Jason Wei",
                "Xuezhi Wang",
                "Dale Schuurmans",
                "Maarten Bosma",
                "Ed Chi",
                "Quoc Le",
                "Denny Zhou."
            ],
            "title": "Chain of thought prompting elicits reasoning in large language models",
            "venue": "arXiv preprint arXiv:2201.11903.",
            "year": 2022
        },
        {
            "authors": [
                "Zhiyong Wu",
                "Yaoxiang Wang",
                "Jiacheng Ye",
                "Lingpeng Kong."
            ],
            "title": "Self-adaptive in-context learning",
            "venue": "arXiv preprint arXiv:2212.10375.",
            "year": 2022
        },
        {
            "authors": [
                "Shan Yang",
                "Yongfei Zhang",
                "Guanglin Niu",
                "Qinghua Zhao",
                "Shiliang Pu."
            ],
            "title": "Entity conceptenhanced few-shot relation extraction",
            "venue": "The 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Confer-",
            "year": 2021
        },
        {
            "authors": [
                "Jiawen Zhang",
                "Jiaqi Zhu",
                "Yi Yang",
                "Wandong Shi",
                "Congcong Zhang",
                "Hongan Wang."
            ],
            "title": "Knowledgeenhanced domain adaptation in few-shot relation classification",
            "venue": "The 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining (SIGKDD),",
            "year": 2021
        },
        {
            "authors": [
                "Zhuosheng Zhang",
                "Aston Zhang",
                "Mu Li",
                "Alex Smola."
            ],
            "title": "Automatic chain of thought prompting in large language models",
            "venue": "arXiv preprint arXiv:2210.03493.",
            "year": 2022
        },
        {
            "authors": [
                "Yongchao Zhou",
                "Andrei Ioan Muresanu",
                "Ziwen Han",
                "Keiran Paster",
                "Silviu Pitis",
                "Harris Chan",
                "Jimmy Ba."
            ],
            "title": "Large language models are human-level prompt engineers",
            "venue": "arXiv preprint arXiv:2211.01910.",
            "year": 2022
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Relation extraction (RE) aims at identifying the relation between two given entities based on contextual semantic information (Cardie, 1997; Bach and Badaskar, 2007; Pawar et al., 2017). However, the performance of RE models often degrades significantly when the labeled data is insufficient. The few-shot relation extraction (FSRE) task needs to be addressed with a limited amount of annotated training data (Han et al., 2018; Gao et al., 2019b; Brody et al., 2021). Recently, numerous\n\u2217 Corresponding author.\nresearchers have tackled this problem by employing meta-learning and neural graph techniques (Fangchao et al., 2021; Dou et al., 2022; Li and Qian, 2022; Zhang et al., 2021; Li et al., 2023). These methods have achieved satisfying results by meta-training the model on a large dataset or incorporating external knowledge.\nMore recently, pre-trained Large Language Models (LLMs) such as GPT-series models, have exhibited significant in-context learning capabilities (Brown et al., 2020; Min et al., 2022), achieving promising results across many NLP tasks. These findings suggest that LLMs can effectively perform various tasks without the need for parameter optimization, a concept known as In-context Learning (Dong et al., 2022). Within the paradigm of in-context learning, LLMs demonstrate competitive performance compared to standard fullysupervised methods across many NLP tasks, even with just a few examples provided as few-shot demonstrations in the prompt (Wang et al., 2022).\nFurthermore, the chain-of-thought prompting method (Wei et al., 2022; Kojima et al., 2022; Zhang et al., 2022) elicits an impressive reasoning capability from the LLM in mathematical problems and commonsense reasoning. While in the\nRE task, there may exist a reasoning process that guides the LLM in determining the relation label. However, there is a lack of research to fill this gap. Though GPT-RE (Wan et al., 2023) introduces a golden label-induced reasoning method by prompting the LLM to generate a suitable reasoning process solely based on the given golden label. The performance improvement from the auto-generated reasoning process is marginal compared to a meticulously designed approach for few-shot demonstration retrieval.\nWe argue that the one-step reasoning process generated by LLM does not fully unleash the potential of LLM: (1) Previous studies and our experiments indicate that the one-step auto-generated reasoning process by LLM does not emphasize the higher-level abstraction of entity types, specifically the concept-level entities, which has been proven to be beneficial for FSRE task (Hao et al., 2019; Zhang et al., 2021). For instance, consider the following simple example: the relation between two location entities should not be categorized under the relation type between human beings. (2) Due to the huge amount of pre-training data, the LLM has already possessed a considerable knowledge base (Petroni et al., 2019; Roberts et al., 2020), which can be beneficial when the LLM encounters an FSRE task. (3) The quality of semantic representation of the relation label is not crucial in the fully-supervised setting, but in-context learning is sensitive to the relation label. For instance, given the relation labels= {mother, child, sport} in FewRel 1.0 (Han et al., 2018), relation labels \u201cmother\u201d and \u201cchild\u201d would confuse the LLM without appropriate prompt designing, as the primary distinction between these two relations is the positioning of the parent entity as either the head or tail entity. Moreover, the word \u201csport\u201d barely contains enough relation information for the LLM to perform the RE task. We call this issue the semantic ambiguity of relation labels.\nTo this end, this paper presents a novel chainof-thought prompting method for the FSRE task: Chain-of-thought with Explicit Evidence Reasoning, achieving competitive results compared to the state-of-the-art result on FewRel 1.0 and FewRel 2.0. Our method employs a 3-step reasoning approach to address the aforementioned issues. In the first and second steps, CoT-ER requires the LLM to output the concept-level entities corresponding to the head and tail entities, which serve as the\nfoundation for RE-specific reasoning. In the third step, CoT-ER prompts the LLM to extract the relevant contextual spans as evidence that explicitly establishes a specific relationship between these two entities. By combining the head entity, tail entity, and relation label to form a coherent sentence, LLMs can determine the relation label between two given entities more semantically, addressing the issue of semantic ambiguity of relation labels in prompting methods. Figure 1 demonstrates the difference between Auto-CoT and our CoT-ER."
        },
        {
            "heading": "2 Related Work",
            "text": "Few-shot Relation Extraction. Few-shot relation extraction aims at predicting semantic relations between head and tail entities indicated in a given instance based on a limited amount of annotated data. FewRel, a large-scale dataset introduced by Han et al. (2018), was the first to explore few-shot learning in relation extraction. Many approaches (Qu et al., 2020; Yang et al., 2021; Zhang et al., 2021) incorporate external knowledge to improve performance given the scarcity of training data. Another line of FSRE research (Gao et al., 2019a; Han et al., 2021; Liu et al., 2022b) relies solely on the input text and provided relation description information, without incorporating external knowledge. Most of the previous methods usually adopt complicated designs of neural networks or introduce external knowledge, which can be labor-intensive in realistic scenarios.\nIn-context Learning. GPT-3 in-context learning (ICL) (Brown et al., 2020; Dong et al., 2022) has emerged as a novel paradigm in NLP and demonstrates competitive performance across various tasks when compared to fine-tuned models. It\u2019s much easier to introduce prior knowledge into LLMs by incorporating relevant text information into prompt (Liu et al., 2022a; Lu et al., 2022; Wei et al., 2022). Furthermore, ICL is a training-free approach by directly prompting the LLMs, which means it\u2019s a ready-to-use method and can be easily applied to various tasks with a few demonstrations in the prompt.\nRecently, most researchers focus on the demonstration designing of ICL to improve the performance in NLP tasks and gradually developed into two categories (Dong et al., 2022). The first line of demonstration designing tries to seek an optimal arrangement of the few-shot demonstrations in the\nprompt by selecting instances from the dataset (Liu et al., 2022a; Valmeekam et al., 2022; Wu et al., 2022; Wan et al., 2023) and ordering the selected demonstration examples (Lu et al., 2022; Liu et al., 2022a; Ma et al., 2023). Another line of demonstration design aims to discover an effective prompting method to unleash the potential of LLMs. Several studies (Honovich et al., 2022; Zhou et al., 2022) find that the LLMs can generate the task instruction automatically. Furthermore, Wei et al. (2022) revealed the reasoning ability of LLM by adding intermediate reasoning steps manually before giving the answer, which is called chain-of-thought (CoT). Additionally, Kojima et al. (2022) shows that by simply adding \u201cLet\u2019s think step by step\u201d before each answer, LLM can do the zero-shot reasoning without manually annotated data. Based on this discovery, Zhang et al. (2022) proposed Auto-CoT, replacing the manually written reasoning process in CoT with the automatically generated reasoning process by LLM.\nDespite the CoT prompting method achieving promising results in many NLP tasks, it still lacks relevant exploration for RE. Hence, in this paper, we propose a novel CoT prompting method called CoT-ER to fill this gap.\nTrue Few-Shot Learning. Perez et al. (2021) argues that prior research has achieved promising results by choosing prompts or tuning other hyperparameters using a large development set, such as selecting few-shot demonstrations from a large training set, which does not truly demonstrate the few-shot learning capability of LLMs. This setting has been adopted by many works (Logan IV et al., 2022; Schick and Sch\u00fctze, 2022; Lu et al., 2022; Jimenez Gutierrez et al., 2022) to get a more accurate result of few-shot performance. We will also adopt the setting in this paper."
        },
        {
            "heading": "3 CoT-ER",
            "text": ""
        },
        {
            "heading": "3.1 Problem Formulation",
            "text": "Definition of Relation Extraction. Let x denote the input sentence and esub, eobj denote the pair of subject and object entities in the given sentence. The RE task aims to identify the relation label r between the marked entities in sentence x. Here R represents a predefined set of relations, and r is an element of R.\nDefinition of Few-shot Relation Extraction. Given an N-way K-shot RE task, the goal is to solve this problem for each instance in the query set based on the support set. The relation label\nset R consists of N type of relations. For each r \u2208 R, the support set Sr includes K instances, represented as {s1r , s2r , s3r , ..., sKr }. The query set Q comprises the test input instance for each r \u2208 R.\nSince the N and K are usually quite small, predicting relations in query instances with limited labeled data presents a significant challenge. Previous studies tackled this problem by training a dataefficient network, specifically the meta-learningbased method. In the subsequent section, we will discuss a training-free method to address this problem by leveraging the reasoning ability of the LLM."
        },
        {
            "heading": "3.2 Overview",
            "text": "An overview of our proposed CoT-ER is shown in Figure 2, which consists of 3 components: (1) The Human-Instructed Reasoning Module, which aims to associate a reasoning process with each instance from the support set by prompting LLM with human-annotated data. (2) A Similarity Based KNN Retrieval Module will select instances with the reasoning process from the support set based on the similarity to query instance, which are considered as few-shot demonstrations in the ultimate prompt. (3) The Inference Module predicts the relation label of a query instance by instructing the LLM through the ultimate prompt, which concatenates the task instruction, few-shot demonstrations, and a question about the instance."
        },
        {
            "heading": "3.3 Human-Instructed Reasoning Module",
            "text": "Since the LLM has the ability of in-context learning (Brown et al., 2020), we propose a human-instructed approach to guide the LLM in performing accurate reasoning using a minimal amount of annotated data.\nCoT-ER Designing. To fully leverage the knowledge stored in LLM and facilitate step-by-step reasoning, we introduce a novel 3-step reasoning framework with concept-level knowledge and explicit evidence. In Step 1, the LLM infers concept-level knowledge related to the head entity, while Step 2 does the same for the tail entity. Through these steps, the LLM can easily exclude options with incorrect concept entities. Step 3: To figure out which relation label fits this pair of entities most within the given context, we explicitly highlight relevant text spans as evidence, and subsequently construct a coherent expression that combines the two entities and the relation label together. Table 6 shows an example with the\nrelation label \u201ccrosses\u201d. To further illustrate our 3-step reasoning process, few-shot demonstrations in Figure 3 demonstrate the template of this reasoning process.\nCoT-ER Generating. We annotated one CoT-ER reasoning example for each relation class in the dataset to be seed examples.1 Then we design an appropriate prompt2 using the annotated example as the few-shot demonstration to instruct the LLM in generating a similar reasoning step for each support instance. Each support instance with the CoTER reasoning steps will be appended to the candidate set. Figure 3 shows a similar prompt designed for the Human Instructed Reasoning Module."
        },
        {
            "heading": "3.4 Instance Retrieval Module",
            "text": "Several studies (Liu et al., 2022a; Lu et al., 2022; Wan et al., 2023) suggest that selecting few-shot demonstrations based on similarity yields strong improvements in in-context learning. Wan et al. (2023) achieved promising performance in RE by employing a task-specific fine-tuned model as the encoder, which means this approach does not fit the true few-shot setting mentioned in \u00a72. Moreover, this advantage diminishes rapidly as the number of candidates decreases.\nBecause of the limited input tokens of LLM, a single prompt may not hold all support instances given an N-Way K-Shot task. For instance, in the case of the 10-way 5-shot task, having a total of 50 candidate samples leads to the inability to append them all in one single prompt. In this paper, we follow the similarity-based method for selecting fewshot demonstrations. To obtain a relation-specific similarity representation, we first reconstruct the input text as \u201cContext: [text] Given the context, what is the relation between \u201c[head entity]\u201d and \u201c[tail entity]\u201d?\u201d by incorporating entity-level information. Then, we utilize the GPT series model \u201ctext-embedding-ada-002\u201d as the encoder to get the semantic embedding. Subsequently, we compute the Euclidean distance between each instance in the candidate set and the query instance. Finally, M instances from the candidate set are selected as few-shot demonstrations based on their lower Euclidean distance to the query instance. Intuitively, we aim to provide as much information as possible for LLM, so we follow the principle of filling the\n1All seed examples are shown in Appendix B. 2All prompts are shown in Appendix C.\ncontext window to increase M as much as possible."
        },
        {
            "heading": "3.5 Inference Module",
            "text": "To create the ultimate prompt, we simply concatenate a task instruction, few-shot demonstrations, and a question that is tailored to the query instance, using the support instances with CoT-ER reasoning as few-shot demonstrations. Figure 3 shows the framework of the ultimate prompt. It is worth noting that LLMs have a strong inclination to wrongly output NULL in a general setting (Wan et al., 2023; Jimenez Gutierrez et al., 2022). Here, we enforce the LLM to select one of the provided relation labels, as we do not consider the \u201cNone-of-theAbove\u201d scenario in the FewRel dataset (Han et al., 2018; Gao et al., 2019b)."
        },
        {
            "heading": "4 Experimental Setups",
            "text": ""
        },
        {
            "heading": "4.1 Dataset For Few-shot Relation Extraction",
            "text": "There are two standard few-shot relation extraction datasets: FewRel 1.0 (Han et al., 2018) and FewRel 2.0 (Gao et al., 2019b)3. FewRel 1.0 is constructed from Wikipedia, which consists of 70, 000 sentences annotated with 100 relation labels, these\n3https://github.com/thunlp/FewRel\n100 relation labels are divided into 64/16/20 splits for train/validation/test set. FewRel 2.0 extends FewRel 1.0 by introducing additional validation and test sets from the medical domain, which includes 10 relation labels with 1, 000 instances and 15 relation labels with 1, 500 instances, respectively. Besides, note that FewRel 1.0 provides a description of each relation label in the dataset, but FewRel 2.0 does not. This difference is a crucial factor to consider when designing the seed CoT-ER reasoning process4."
        },
        {
            "heading": "4.2 Implementation Details",
            "text": "For LLM, we select \u201ctext-davinci-003\u201d and get the response from GPT by calling the open API of the OpenAI5 with the parameter temperature = 0.\nIn a realistic scenario, it\u2019s reasonable to perform the RE task directly with fixed, manually annotated examples as few-shot demonstrations for each relation label. To this end, we evaluate the performance by selecting the few-shot demonstrations from a predetermined human-annotated CoT-ER dataset (seed examples), which is denoted as Manual-CoTER. In this setting, the few-shot demonstrations are independent of the support set, meaning that LLM will perform the RE task using a smaller amount of annotated data. In contrast, Auto-CoT-ER utilizes the auto-generated CoT-ER reasoning process as the few-shot demonstrations based on the support set which is described in \u00a73.3.\nFollowing the standard configuration of FewRel, we conducted experiments in these settings: 5-Way 1-shot, 5-Way 5-shot, 10-Way 1-Shot, and 10-Way 5-Shot. Due to the high cost of running the CoT-ER on the GPT-3 API and the golden labels of the test set are not publicly available, we evaluate all LLMbased methods by sampling 100\u00d7N test queries for each N-way K-shot task from validation sets."
        },
        {
            "heading": "4.3 Compared Methods",
            "text": "We consider two categories of methods for the FSRE task. Methods with 100%-training data: MTB (Baldini Soares et al., 2019), CP (Peng et al., 2020), HCPR (Han et al., 2021), FAEA (Dou et al., 2022), GTPN (Fangchao et al., 2021), GM_GEN (Li and Qian, 2022), KEFDA (Zhang et al., 2021). Generally, these methods train a model on FewRel 1.0 training set and evaluate their performance on FewRel 1.0, 2.0 validation and test sets.\n4More details are demonstrated in Appendix B. 5https://platform.openai.com/docs/\napi-reference\nMethods with 0%-training data: To the best of our knowledge, no relevant evaluation has been conducted under the N-Way K-Shot setting on the FSRE dataset FewRel using the in-context learning approach. Thus we applied Vanilla-ICL (Brown et al., 2020) and Auto-CoT (Zhang et al., 2022; Wan et al., 2023) as the baseline prompt formatting methods. These methods utilize a few examples as demonstrations and prompt the LLM to perform an NLP task. Vanilla-ICL designs a template that directly combines the texts and relation label, such as \u201cContext:[text], Given the context, the relation between [head entity] and [tail entity] is [relation label]\u201d. Auto-CoT extends the Vanilla-ICL with auto-generated reasoning steps. Throughout the experiment, we noticed that whether to require the LLM to perform reasoning in the final answering stage can lead to inconsistent results, thus we report both of the results in Table 1 and Table 2. Additionally, we utilize the pre-trained BERT-base model6 and the GPT series model text-embedding-ada-002 as the encoder to directly obtain a representation of the input text. For each N-way K-shot task, we obtain a prototype of each class by averaging K instances that belong to this class. Then the predicted label of the query instance is assigned to the class whose prototype has the closest Euclidean distance to the query instance. We denote these two methods as Bert-proto and GPT-proto.\n6https://github.com/huggingface/transformers"
        },
        {
            "heading": "5 Results and Discussion",
            "text": ""
        },
        {
            "heading": "5.1 Main Results",
            "text": "We present our main experiment results with previous methods in Table 1 and Table 2. From the table, we can observe that:\nFirst, Auto-CoT does not demonstrate significant improvement compared to Vanilla-ICL in the fewshot scenario. This could be attributed to the low quality of the reasoning process and the reduced number of instances in few-shot demonstrations due to the maximum tokens limitation. Furthermore, When it comes to generating a reasoning process in the ultimate answer, Auto-CoT with reasoning outperforms the version of directly generating a relation label on FewRel 1.0. However, an opposite conclusion is reached on FewRel 2.0. We try to provide an explanation for this: FewRel 1.0 draws instances from Wikipedia and often requires common sense for reasoning, whereas FewRel 2.0 necessitates medical-related expertise and constitutes a smaller portion of the pre-training corpus compared to common sense. Consequently, the LLM encounters difficulties in performing reasoning tasks in the medical domain.\nSecond, Both Manual-CoT-ER and Auto-CoTER outperform the training-free baselines with fewer instances used in the few-shot demonstrations. Indicating the necessity of designing a specific CoT prompting method tailored to the RE task in order to achieve better performance in the\nfew-shot scenario. Third, CoT-ER prompting method achieves competitive performance compared to the state-of-theart fully-supervised method and surpasses the majority of fully-supervised methods with minimal manual labor both on FewRel 1.0 and FewRel 2.0. This suggests that GPT series LLMs have the potential to beat previous fully-supervised methods when high-quality relation information and welldesigned reasoning processes are provided."
        },
        {
            "heading": "5.2 Ablation Study on CoT-ER",
            "text": "Does the incorporation of entity information significantly benefit the coT-ER? To this end, we conducted ablation experiments to demonstrate the necessity of the 3-step reasoning process. In this experiment, we removed the first and second steps and compared the performance with Auto-CoTreasoning. For fairness concerns, we implemented this experiment using Auto-CoT-ER, which also employs an auto-generated reasoning process by LLM. Due to the limitation of maximum input and output tokens, we set the number of instances in the few-shot demonstrations to 13 for the ablation experiments. The results are presented in Figure 4.\nWe find that: (1) after removing the first and second steps, the performance of Auto-CoT-ER shows a significant decline with reductions of 3.4, 2.2, 1.8, 2.9, and 5.2, 6, 5.3, 7.6 Accuracy on FewRel 1.0 and FewRel 2.0 respectively. It means higher-level\nabstraction of entity types, specifically the conceptlevel entities, are beneficial to the LLM performing RE task in the few-shot scenario. (2) Despite the third step of CoT-ER pairing the support instance with a simpler reasoning process compared to AutoCoT, it achieves superior performance in certain challenging scenarios (10-Way 1-Shot and medical domain \u00a75.1). This finding indicates that the semantic information provided by the relation label is more beneficial to the LLM than low-quality reasoning information."
        },
        {
            "heading": "5.3 The Stability of CoT-ER",
            "text": "Different Random Seeds for Task Sampling. Due to the high cost of the \u201ctext-davinci-003\u201d, we sample a relatively small number of queries for testing, specifically 100 \u00d7N for each N-Way K-Shot task. It may raise concerns that the results may not hold up when evaluated on the full test sets. To this end, we evaluated the CoT-ER and Vanilla-ICL using 8 random seeds for N-Way K-Shot task sampling. Table 3 and Table 4 show experimental results with mean \u00b1 standard deviation on FewRel2.0. Notably, CoT-ER consistently outperforms Vanilla-ICL across all N-way K-shot settings with a lower standard deviation.\nDifferent Number of Few-shot Instances. To investigate how the selected number of demonstrations contribute to the performance of CoT-ER,\nwe conducted experiments across different M under the 5-Way 5-Shot setting. A single prompt can hold 13 CoT-ER reasoning demonstrations at worst, whereas all the support instances (25) can be appended to the prompt in Vanilla-ICL. The results are presented in Table 5.\nWe observe that both CoT-ER and Vanilla-ICL can benefit from more few-shot examples, which aligns with the same conclusion in previous work (Liu et al., 2022a). However, the performance of Vanilla-ICL deteriorates rapidly as the number of examples decreases. CoT-ER can effectively leverage the information from provided instances and maintain strong performance even with a reduced number of instances. This demonstrates that CoTER exhibits greater stability compared to VanillaICL when the number of few-shot instances varies."
        },
        {
            "heading": "5.4 Case Study",
            "text": "We select one typical reasoning example generated by LLM to better demonstrate the superiority of our prompting method CoT-ER. As shown in Table 6, this instance necessitates the LLM to correctly identify the relation label \u201ccrosses\u201d between \u201cRailway Bridge\u201d and \u201cDaugava\u201d. In FewRel 1.0, the relation label \u201ccrosses\u201d is described as \u201cobstacle (body of water, road, ...) which this bridge crosses over or this tunnel goes under\u201d.\nHowever, using Auto-CoT prompting leads to a wrong prediction where the model incorrectly labels the relation with \u201clocated in or next to body of water\u201d, which pertains to the relationship between a location entity and a water-related entity (river, lake, ...). The primary reason for the failure of AutoCoT is the absence of higher-level abstraction of entities in reasoning, which is necessary to comprehend the entities involved in the relation. CoT-ER addresses this issue by incorporating concept-level information into the reasoning process through its first and second steps. Specifically, in this case, the LLM first reasons the subject entity corresponds to a bridge and the object entity corresponds to a river based on its own knowledge base and contextual information, thereby excluding the relation requiring a location entity and water-related entities (as demonstrated by other examples in prompt). With this clue, the LLM can effectively perform subsequent reasoning steps.\nFurthermore, the presence of both \u201ccrosses\u201d and \u201clocated in or next to body of water\u201d labels in an N-way K-shot task can indeed confuse the LLM due to the lack of semantic information on these two phrases. CoT-ER addresses this issue by inte-\nthis example is \u201cThe Railway Bridge is a bridge that crosses the Daugava river in Riga, the capital of Latvia.\u201d, and the relation between two highlight entities is \u201ccrosses\u201d. The key reasoning processes of CoT-ER are highlighted with green.\ngrating both entities and the relation label into a coherent expression, as exemplified by this example \u201cRailway Bridge\u201d crosses \u201cDaugava\u201d."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this paper, we explore the potential of LLM incontext learning on few-shot relation extraction. To enhance the general performance caused by lowquality auto-generated reasoning processes, we introduce CoT-ER, a prompting method tailored to few-shot relation extraction. The core idea is to prompt LLM to generate evidence using taskspecific and concept-level knowledge stored in its pre-training stage. These pieces of evidence will be utilized by LLM during the RE task, and facilitate the reasoning process. Additionally, we devise a label verbalizing technique by integrating both entities and the relation label into a coherent expression. This technique addresses the semantic ambiguity of relation labels, which is a common challenge encountered during relation extraction when utilizing in-context learning. The experimental results on FewRel 1.0 and FewRel 2.0 outperform all training-free baselines, demonstrating the effectiveness of our proposed approach. Moreover, achieving comparable results to the state-of-the-art fully-supervised method suggests that the paradigm of in-context learning holds promise as a novel solution for the few-shot relation extraction task.\nLimitations\nAlthough CoT-ER achieved decent results on FewRel 1.0 and FewRel 2.0, there is still poten-\ntial for future improvement. Our proposed method does not fully utilize all instances when handling larger support sets, such as 5-way 5-shot and 10- way 5-shot, due to the constraint of maximum length. Though we adopt a similarity-based KNN retrieval to select superior instances for few-shot demonstrations, we find it not as effective in the few-shot setting compared to other works that perform well when there is a large candidate set available. Due to the high cost of employing reasoningrequired ICL via GPT-3 API, we have not evaluated the CoT-ER on a superior LLM with longer maximum input tokens and a larger scale.\nOur limited budget also restricted the optimization for the construction of seed examples. It is possible to enhance the performance with a more informative and appropriate design.\nEthics Statement\nIt is known that pre-trained language models could capture the bias reflecting training data. Thus, our approach using LLMs can potentially generate offensive or biased content. We acknowledge this risk and suggest that practitioners should carefully examine the potential bias before deploying our models in real-world applications."
        },
        {
            "heading": "A Error Analysis",
            "text": "A.1 Error Analysis of Relation Type\nTo fully justify CoT-ER as a superior approach to the baseline, we will provide a quantitative analysis comparing CoT-ER and Vanilla-ICL across all test classes. Taking the 5-Way 1-Shot setting as an example, Table 7 and Table 8 display the accuracy of these two methods across various relation classes within FewRel. Note that different numbers represent different relation types, and their order is based on the performance ranking of Vanilla-ICL. These accuracies are the average results obtained from multiple test runs, each performed with seven different random seeds.\nTable 7 shows the experimental results on FewRel 1.0. We can observe that CoT-ER surpasses\nVanilla-ICL 10 times, with 7 of them showing a relatively high improvement. However, in the 7th and 8th relations, CoT-ER still lags behind Vanilla-ICL by a few percentage points.\nTable 8 shows the experimental results on FewRel 2.0. We can observe that CoT-ER surpasses Vanilla-ICL 6 times, with 4 of them showing a significant improvement of over 10%. However, in the 5th and 7th relations, CoT-ER still lags behind Vanilla-ICL by a few percentage points.\nA.2 Error Analysis of Reasoning Process\nCoT-ER shows significant improvements in scenarios when Vanilla-ICL performs poorly. Here, we present a few cases to illustrate the reasoning process of CoT-ER in some representative scenarios in order to facilitate future research. Table 9 shows some correct and incorrect answers produced by CoT-ER.\nRelation class gene plays role in process: In this case, CoT-ER can not only recognize what \u201ctranscriptional\u201d and \u201cmean\u201d mean in the context but also have concept-level knowledge. And the final prediction is correct.\nRelation class spouse: In this case, CoT-ER correctly recognizes the entity type and precisely extracts the crucial evidence \u201cmaternal grandparents\u201d. However, the LLM incorrectly interprets \u201cmaternal grandparents\u201d as the relationship between these two entities, when they are actually a couple of \u201cmaternal grandparents\u201d. This demonstrates that the LLM with CoT-ER may overlook contextual information sometimes.\nRelation class is primary anatomic site of disease: In this case, CoT-ER can also recognize the entity well, and the conclusion is semantically right\n(\u201closs of hair\u201d occurs in \u201cskin\u201d). However, the final prediction is incorrect, as the predicted relation label is \u201coccurs in\u201d while the ground truth label is \u201cis primary anatomic site of disease\u201d. The reason is that the label \u201coccurs in\u201d in this dataset means \u201ca condition occurs in a period of the lifetime\u201d. This particular label should be matched with entity pairs like \u201ccondition or disease\u201d and \u201ca period of a person\u2019s lifetime (such as congenital)\u201d. This issue indicates that the relation description would be a key component in such methods, but it\u2019s not included in the FewRel 2.0 dataset."
        },
        {
            "heading": "B Seed Examples",
            "text": "In this section, we will give more details about how we construct the seed examples and present all seed examples in Table 10, Table 11, Table 12, Table 13 and Table 14.\nWe first randomly select one instance from each relation class to serve as the seed example. Then we outline the three steps of CoT-ER in each instance. By considering the contextual information of the two entities involved, we manually assign the entity types and identify relevant text spans as evidence. Because FewRel 1.0 provides a description of each relation (such as \"sport: sport in which the subject participates or belongs to\") in a separate file while FewRel 2.0 does not, this has implications for the design of seed examples. However, these descriptions are not directly used in the prompts. Furthermore, we haven\u2019t optimized the seed examples, leaving room for further improvement."
        },
        {
            "heading": "C Prompts",
            "text": "All prompt templates used in this paper are presented in Table 15.\ncompetition class Context: Sasakul turned pro in 1991 and captured the WBC and lineal flyweight titles with a win over Yuri Arbachakov in 1997.\nCoT-ER: 1. Subject entity \u201cYuri Arbachakov\u201d is a personal name, which refers to the entity of events, teams, participants, or equipment\nin the context. 2. Object entity \u201cflyweight\u201d is a competition type of boxing match, which refers to the entity of competition or organization\nin the context. 3. According to the context, \u201ccaptured the WBC and lineal flyweight titles with a win over Yuri Arbachakov\u201d indicates that\nobject entity \u201cYuri Arbachakov\u201d qualifies for inclusion in \u201cflyweight\u201d. So, the relation between subject entity \u201cYuri Arbachakov\u201d and object entity \u201cflyweight\u201d is \u201ccompetition class\u201d.\npart of Context: The observatory began operation around 1984 with the Isaac Newton Telescope, which was moved to La Palma from the Royal Greenwich Observatory site at Herstmonceux Castle in Sussex, England.\nCoT-ER: 1. Subject entity \u201cIsaac Newton Telescope\u201d is a scientific instrument, which refers to the entity of components in the context. 2. Object entity \u201cRoyal Greenwich Observatory\u201d is scientific institution, which refers to the entity of entirety in the context. 3. According to the context, \u201cwhich was moved to La Palma from the Royal Greenwich Observatory\u201d indicates that\n\u201cIsaac Newton Telescope\u201d is part of \u201cRoyal Greenwich Observatory\u201d. So, the relation between subject entity \u201cIsaac Newton Telescope\u201d and object entity \u201cRoyal Greenwich Observatory\u201d is\n\u201cpart of\u201d.\nconstellation Context: Tau2 Gruis, is a double star located in the constellation Grus."
        }
    ],
    "title": "Chain of Thought with Explicit Evidence Reasoning for Few-shot Relation Extraction",
    "year": 2023
}