{
    "abstractText": "Social intelligence is essential for understanding and reasoning about human expressions, intents and interactions. One representative benchmark for its study is Social Intelligence Queries (Social-IQ), a dataset of multiplechoice questions on videos of complex social interactions. We define a comprehensive methodology to study the soundness of Social-IQ, as the soundness of such benchmark datasets is crucial to the investigation of the underlying research problem. Our analysis reveals that Social-IQ contains substantial biases, which can be exploited by a moderately strong language model to learn spurious correlations to achieve perfect performance without being given the context or even the question. We introduce DeSIQ, a new challenging dataset, constructed by applying simple perturbations to Social-IQ. Our empirical analysis shows DeSIQ significantly reduces the biases in the original Social-IQ dataset. Furthermore, we examine and shed light on the effect of model size, model style, learning settings, commonsense knowledge, and multi-modality on the new benchmark performance. Our new dataset, observations and findings open up important research questions for the study of social intelligence.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xiao-Yu Guo"
        },
        {
            "affiliations": [],
            "name": "Yuan-Fang Li"
        },
        {
            "affiliations": [],
            "name": "Gholamreza Haffari"
        }
    ],
    "id": "SP:733734940a29587ed0be4e2a282bbdb30e214f2b",
    "references": [
        {
            "authors": [
                "Huda Alamri",
                "Vincent Cartillier",
                "Abhishek Das",
                "Jue Wang",
                "Anoop Cherian",
                "Irfan Essa",
                "Dhruv Batra",
                "Tim K. Marks",
                "Chiori Hori",
                "Peter Anderson",
                "Stefan Lee",
                "Devi Parikh."
            ],
            "title": "Audio visual sceneaware dialog",
            "venue": "IEEE Conference on Computer",
            "year": 2019
        },
        {
            "authors": [
                "Eleni Andreou."
            ],
            "title": "Social preference, perceived popularity and social intelligence: Relations to overt and relational aggression",
            "venue": "School Psychology International, 27(3):339\u2013351.",
            "year": 2006
        },
        {
            "authors": [
                "Alexei Baevski",
                "Yuhao Zhou",
                "Abdelrahman Mohamed",
                "Michael Auli"
            ],
            "title": "wav2vec 2.0: A framework for self-supervised learning of speech representations",
            "venue": "In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information",
            "year": 2020
        },
        {
            "authors": [
                "Antoine Bosselut",
                "Hannah Rashkin",
                "Maarten Sap",
                "Chaitanya Malaviya",
                "Asli Celikyilmaz",
                "Yejin Choi."
            ],
            "title": "COMET: commonsense transformers for automatic knowledge graph construction",
            "venue": "Proceedings",
            "year": 2019
        },
        {
            "authors": [
                "Denis Emelin",
                "Ronan Le Bras",
                "Jena D. Hwang",
                "Maxwell Forbes",
                "Yejin Choi."
            ],
            "title": "Moral stories: Situated reasoning about norms, intents, actions, and their consequences",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,",
            "year": 2021
        },
        {
            "authors": [
                "Maxwell Forbes",
                "Jena D. Hwang",
                "Vered Shwartz",
                "Maarten Sap",
                "Yejin Choi."
            ],
            "title": "Social chemistry 101: Learning to reason about social and moral norms",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
            "year": 2020
        },
        {
            "authors": [
                "Itai Gat",
                "Idan Schwartz",
                "Alexander G. Schwing",
                "Tamir Hazan."
            ],
            "title": "Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies",
            "venue": "Advances in Neural Information Processing Systems 33: Annual Conference on Neural",
            "year": 2020
        },
        {
            "authors": [
                "Daniel Goleman."
            ],
            "title": "Social intelligence",
            "venue": "Random house.",
            "year": 2007
        },
        {
            "authors": [
                "Dan Hendrycks",
                "Collin Burns",
                "Steven Basart",
                "Andrew Critch",
                "Jerry Li",
                "Dawn Song",
                "Jacob Steinhardt."
            ],
            "title": "Aligning AI with shared human values",
            "venue": "9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7,",
            "year": 2021
        },
        {
            "authors": [
                "Yunseok Jang",
                "Yale Song",
                "Youngjae Yu",
                "Youngjin Kim",
                "Gunhee Kim."
            ],
            "title": "TGIF-QA: toward spatiotemporal reasoning in visual question answering",
            "venue": "2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA,",
            "year": 2017
        },
        {
            "authors": [
                "Robin Jia",
                "Percy Liang."
            ],
            "title": "Adversarial examples for evaluating reading comprehension systems",
            "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2021\u20132031, Copenhagen, Denmark. Association for",
            "year": 2017
        },
        {
            "authors": [
                "Liwei Jiang",
                "Jena D. Hwang",
                "Chandra Bhagavatula",
                "Ronan Le Bras",
                "Maxwell Forbes",
                "Jon Borchardt",
                "Jenny Liang",
                "Oren Etzioni",
                "Maarten Sap",
                "Yejin Choi."
            ],
            "title": "Delphi: Towards machine ethics and norms",
            "venue": "CoRR, abs/2110.07574.",
            "year": 2021
        },
        {
            "authors": [
                "Yichen Jiang",
                "Mohit Bansal."
            ],
            "title": "Avoiding reasoning shortcuts: Adversarial evaluation, training, and model development for multi-hop QA",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2726\u20132736, Flo-",
            "year": 2019
        },
        {
            "authors": [
                "Jie Lei",
                "Licheng Yu",
                "Mohit Bansal",
                "Tamara L. Berg."
            ],
            "title": "TVQA: localized, compositional video question answering",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November",
            "year": 2018
        },
        {
            "authors": [
                "Jie Lei",
                "Licheng Yu",
                "Tamara L. Berg",
                "Mohit Bansal."
            ],
            "title": "TVQA+: spatio-temporal grounding for video question answering",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020,",
            "year": 2020
        },
        {
            "authors": [
                "OpenAI."
            ],
            "title": "Chatgpt: Optimizing language models for dialogue",
            "venue": "Accessed 2023-01-13.",
            "year": 2022
        },
        {
            "authors": [
                "Colin Raffel",
                "Noam Shazeer",
                "Adam Roberts",
                "Katherine Lee",
                "Sharan Narang",
                "Michael Matena",
                "Yanqi Zhou",
                "Wei Li",
                "Peter J. Liu."
            ],
            "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "venue": "J. Mach. Learn. Res., 21:140:1\u2013140:67.",
            "year": 2020
        },
        {
            "authors": [
                "Nils Reimers",
                "Iryna Gurevych."
            ],
            "title": "Sentence-bert: Sentence embeddings using siamese bert-networks",
            "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.",
            "year": 2019
        },
        {
            "authors": [
                "Krunal Shah",
                "Nitish Gupta",
                "Dan Roth"
            ],
            "title": "What do we expect from multiple-choice QA systems? In Findings of the Association for Computational Linguistics: EMNLP 2020",
            "venue": "Online Event,",
            "year": 2020
        },
        {
            "authors": [
                "Makarand Tapaswi",
                "Yukun Zhu",
                "Rainer Stiefelhagen",
                "Antonio Torralba",
                "Raquel Urtasun",
                "Sanja Fidler."
            ],
            "title": "Movieqa: Understanding stories in movies through question-answering",
            "venue": "2016 IEEE Conference on Computer Vision and Pattern Recognition,",
            "year": 2016
        },
        {
            "authors": [
                "Edward L Thorndike."
            ],
            "title": "Intelligence and its uses",
            "venue": "Harper\u2019s magazine.",
            "year": 1920
        },
        {
            "authors": [
                "Keren Ye",
                "Adriana Kovashka."
            ],
            "title": "A case study of the shortcut effects in visual commonsense reasoning",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, 35(4):3181\u20133189.",
            "year": 2021
        },
        {
            "authors": [
                "Amir Zadeh",
                "Michael Chan",
                "Paul Pu Liang",
                "Edmund Tong",
                "Louis-Philippe Morency."
            ],
            "title": "Socialiq: A question answering benchmark for artificial social intelligence",
            "venue": "IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019,",
            "year": 2019
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Social intelligence is a long-standing research area in social science and psychology (Thorndike, 1920; Andreou, 2006; Goleman, 2007). It is the capacity to understand and navigate complex social situations. Social intelligence is more than the perception of objects and human actions, as it requires a deeper understanding of human intents and interactions behind these actions or words.\nThe study of social intelligence is an emerging area in both the NLP and computer vision communities. One representative work, Social-IQ (Social Intelligence Queries) (Zadeh et al., 2019), is a benchmark dataset measuring social intelligence of\ncurrent AI systems. It is a multiple choice question answering dataset with multi-modal inputs, including questions, answer options, videos, etc; see an example in Figure 1. Although Social-IQ contains rigorously human-annotated data, surprisingly, we find even small models like T5-small (Raffel et al., 2020) could easily achieve 100% answer option accuracy (Table 3).\nThe perfect performance of such an underpowered model prompted us to conduct further investigation to identify its source. Through employing different models and perturbation methods on the answer options, we identify significant biases in the Social-IQ dataset, in which the representations of correct and incorrect options are easily separable, regardless of the questions (Figure 3). Thus, the models are able to exploit such a shortcut (Jia and Liang, 2017; Jiang and Bansal, 2019) to answer questions with a high accuracy, without necessarily understanding social intelligence.\nTo debias the Social-IQ dataset, we propose a simple yet effective debiasing approach and present a new unbiased benchmark DeSIQ, by substituting all the incorrect answer options with correct answer options from randomly selected other questions.\nWe establish a performance baseline on DeSIQ with T5-small and Delphi (Jiang et al., 2021), a language model pretrained with commonsense and social norms knowledge. Given answer options only or question-answers, both T5-small and Delphi obtain close to random accuracy. By making use of multi-modal inputs, both T5-small and Delphi achieve an accuracy of up to 77%. These results demonstrate that DeSIQ is unbiased and challenging. Interestingly, both models also outperform GPT-3 and ChatGPT, further indicating the challenging nature of the social intelligence understanding problem.\nOur contributions are:\n\u2022 We propose six formally defined methods to identify the bias in Social-IQ. From the answer pertur-\nbation experiments, we find that the bias mainly exists in the answer options.\n\u2022 We propose DeSIQ, an unbiased, and more challenging multi-modal question answering benchmark, designed to better measure social intelligence for machine learning models.\n\u2022 We propose two effective models that outperform the baseline and GPT-3/ChatGPT on our new benchmark. We also make detailed analysis and comparison on the performance of these models."
        },
        {
            "heading": "2 Identifying Biases in Social-IQ",
            "text": ""
        },
        {
            "heading": "2.1 The Social Intelligence Datasets",
            "text": "Social-IQ (Zadeh et al., 2019) is an unconstrained multi-modal, multiple-choice question answering (MCQA) dataset designed to evaluate the social intelligence of machine learning models. It contains videos about social interactions, questions and multiple-choice answer options, in which the questions and answer options were crowdsourced. For each video, the context for all questions and answer options includes not only the original video, but also the corresponding extracted audio and au-\ntomatically generated transcripts1. Detailed dataset statistics are shown in Table 1.\nSocial-IQ provides two configurations: A2 (2- way, i.e. one correct answer option and one incorrect option for each question) and A4 (2-way, i.e. one correct option and 3 incorrect options for each question) for training and evaluation, in which\n1We don\u2019t have access to the raw transcript, video and audio data so we use extracted features downloaded from https://github.com/matsuolab/CMU-MultimodalSDK.\nmodel performance is measured using binary and 4-way accuracy respectively.\nMost recently, Social-IQ-2.0 was released online2 with the A4 configuration. Though nearly half of the videos overlap with Social-IQ, almost all questions and answers were newly annotated. Moreover, raw video and audio files have been provided instead of only features in the original Social-IQ dataset. The detailed statistics are shown in Table 2. For simplicity, v1 and v2 represent Social-IQ and Social-IQ-2.0 respectively, which are used interchangeably."
        },
        {
            "heading": "2.2 Methodology",
            "text": "In this section, we propose several experimental settings to identify biases in a MCQA dataset. Let q and q\u2032 denote two different questions, a and i denote the correct and an incorrect answer option of q respectively, and a\u2032 and i\u2032 denote the correct and an incorrect answer option of q\u2032 respectively. We define six methods to identify biases: No context and question (NCAQ): the contexts\nand questions for all answer options are removed. I.e., the model is only given all answer options.\nAn MCQA dataset should be sufficiently challenging that no model can predict a correct answer when neither the input context nor the question is not provided.\nMore Powerful Model (MPM): the model is substituted by a larger, more capable model.\nIt is plausible to induce a performance increase on the dataset when a stronger model (e.g. with more trainable parameters and/or one that is finetuned on relevant data) is employed. However, a sufficiently hard dataset should not induce a perfect model performance (i.e. near 100% accuracy score). This can be tested with models of different sizes and thus capabilities.\nRIWI: Replace i with i\u2032, (q, a, i) \u2192 (q, a, i\u2032) RIWA: Replace i with a\u2032, (q, a, i) \u2192 (q, a, a\u2032) RAWI: Replace a with i\u2032, (q, a, i) \u2192 (q, i\u2032, i) RAWA: Replace a with a\u2032, (q, a, i) \u2192 (q, a\u2032, i)\nWith the above perturbations, we expect the dataset to induce the following robustness behaviours. With RIWI or RIWA applied to the dev/test set, we should expect that a model\u2019s performance should not significantly deviate from 2https://cmu-multicomp-lab.github.io/\nsocial-iq-2.0/\nthe original dataset. With RAWI or RAWA, the model should perform significantly worse."
        },
        {
            "heading": "2.3 Biases in Social-IQ",
            "text": "We evaluate the A2 (binary choice) configuration and A4 (multiple choice) configurations of SocialIQ, and A4 configuration of Social-IQ-2.0 in the experimental settings discussed above, and surprisingly, we observe that they are both biased. Below, we describe our detailed analysis and show that Social-IQ contains substantial biases that can be exploited by moderately strong language models. Table 3 summarises the experimental results. In the fully supervised setting, we evaluate the performance of the LSTM-based model in the original Social-IQ paper (Zadeh et al., 2019) (Figure 2) as well as the more capable T5-small (Raffel et al., 2020), which we use as the encoder to replace the LSTM in Figure 2. Evidence of Dataset Bias. We start from the NCAQ settings, i.e., only the answer options (a and i) are given as model input, without the question and video, for both training and evaluation. Under this setting, we also compare models\u2019 performance with different perturbations on the answer options. Table 3 shows that the basic LSTM model outperforms the random guess by 9.45% on v1 (i.e. Social-IQ). With the unreasonable inputs (with no context nor question), these accuracy scores show that the Social-IQ dataset is biased.\nWe postulate that while a stronger model (i.e. MPM) should obtain better performance than LSTM, without being given sufficient information,\neven the stronger model should not perform unreasonably well. Thus, we experiment with T5-small, a modestly-sized yet more capable model. As it can be seen in Table 3, T5-small outperforms LSTM by a large margin on v1. Surprisingly, it also achieves a perfect 100% accuracy score on v1 and 63.35% on v2 without being given the context nor the question. These results provide strong evidence of the biases in these datasets.\nFinally, we study the other four perturbation settings by applying them to the dev sets. Below we analyse the performance on v1 in detail, followed by a discussion on v2.\n\u2022 RIWI. Similar to the performance on the original dataset, T5-small achieves an unreasonable performance of 97.37% on A2 and 99.97% in A4. It indicates that the model can easily distinguish the correct answer from the incorrect options.\n\u2022 RIWA. It leads to a large performance degradation: A2 from 100% to 50.21%, A4 from 100% to 25.03%, similar to random guess (i.e., 50% and 25%). This shows that T5-small is unable to distinguish the correct answer options, regardless of the question it is used for.\n\u2022 RAWI. This produces a dataset containing only incorrect answer options. We consider the incorrect answer option that replaces the correct answer option as the correct answer.\nIntuitively, it should lead a model to randomly guess, as none of the options is correct. In Table 3, we can observe that RAWI leads to a large performance drop: A2 from 100% to 49.93%, A4 from 100% to 23.76%, indicating that T5-small cannot distinguish incorrect answers from each other, confirming our intuition.\n\u2022 RAWA. It should lead to A2 with 50% and A4 with 25% performance since the correct answer option is replaced with an irrelevant correct answer of another question.\nContrary to our intuition, RAWA leads to a nearperfect performance of 97.25% on A2 and even better 100% on A4.\nThese unexpectedly high scores indicate that the model can easily distinguish the correct answer options from the incorrect ones of the original dataset, regardless of the question they are used for, consistent with the results of RIWI.\nFigure 3 shows the T-distributed Stochastic Neighbor Embedding (T-SNE) visualization of the embeddings of all answer options in the Social-IQ dev set. We can observe a clear boundary between correct and incorrect answer options. The above results provide compelling evidence of the unwanted bias in Social-IQ, manifested in T5-small\u2019s strong capability in distinguishing the correct and incorrect answer options.\nSimilar evidence can be found in Social-IQ-2.0, as can be seen in the v2 rows in Table 3."
        },
        {
            "heading": "3 DeSIQ: Debiased Social-IQ",
            "text": "In this section, we first describe our approach to debias Social-IQ . We then study the effectiveness of our debiasing approach and the resultant DeSIQ datasets, by comparing the performance of both LSTM and T5-small on DeSIQ in different settings."
        },
        {
            "heading": "3.1 Constructing DeSIQ",
            "text": "We propose the following perturbation-based approach to debias Social-IQ and construct a more\nmeaningful and challenging dataset on social intelligence. Specifically, we apply the RIWA perturbation on both the training and development sets of Social-IQ, ie substituting the incorrect answer options with correct answer options from the other questions. We construct two debiased datasets3: \u2022 DeSIQd. Given an original triplet (q, a, i), we\nrandomly sample another triplet (q\u2032, a\u2032, i\u2032) from another video. Thus, for each original triplet (q, a, i), we form a new triplet (q, a, a\u2032).\n\u2022 DeSIQs. We sample (q\u2032, a\u2032, i\u2032) from the same video for each (q, a, i). Similarly, we replace the incorrect answer option i with a\u2032. Since q and q\u2032\nare from the same video, their answers can have a higher chance of referring to the same entity that appears in the video. Thus, DeSIQs is a more challenging dataset of (q, a, a\u2032).\nAn example video and some associated questions and answer options for both Social-IQ and DeSIQs can be seen in Figure 1. For Social-IQ-2.0, we do the same approach to obtain DeSIQd-2.0."
        },
        {
            "heading": "3.2 Effectiveness of the Debiasing Approach",
            "text": "We set up a number of models in both fully supervised and zero/few-shot learning settings to show the effectiveness of our debiasing approach,\nSupervised Learning. We train the LSTM and T5-small on Social-IQ, DeSIQd and DeSIQs in the same architecture (Figure 2), and train T5-small on Social-IQ-2.0. Table 4, Table 5 and Table 6 show the results, where the relevant results are shaded in gray . The second column \u201cInput\u201d represents the input used in both the training and evaluation procedures, where \u201ca\u201d, \u201cq\u201d, \u201ct\u201d, and \u201cv\u201d represent answer options, the question, the transcript and the video, respectively. The third column \u201cConcat\u201d represents different model architectures. The symbol \u201c\u2717\u201d denotes that all inputs are separately encoded as in Figure 2, which is the focus of this subsection. The symbol \u201c\u2713\u201d denotes that all inputs are concatenated and encoded as one sequence as in Figure 4, which will be discussed in the next section.\nAs seen in Table 4, DeSIQd largely reduces the bias in Social-IQ, effectively reducing the performance of both LSTM and T5-small close to random guess. For LSTM, when given only answer options, we observe a performance drop of 59.45% \u2192 48.52% on A2 and 34.84% \u2192 27.23% on A4. For\n3Below we describe the dataset construction process for the A2 configuration. Similar perturbations are applied to the A4 configuration of Social-IQ.\nT5-small, it suffers a larger performance drop on both A2 and A4 of DeSIQd (to 50.16% and 34.15% respectively), although 100% A2 on Social-IQ.\nThe results in Table 5 show that DeSIQs effectively reduces the bias in Social-IQ. For LSTM, DeSIQs leads to a performance drop of 59.45% \u2192 48.24% on A2 and 34.84% \u2192 27.06%. For T5small, we can observe a performance drop of 100% \u2192 48.73% on A2 and of 100% \u2192 33.53% on A4.\nComparing results in Tables 4 and 5, we see DeSIQs is generally more challenging than DeSIQd, i.e. compare T5-small\u2019s performance under the same settings across the two datasets. For instance, with the question feature added (\u201cq+a\u201d as inputs), T5-small achieves on 60.55% on DeSIQd and 49.17% on DeSIQs in A2, and 27.57% on DeSIQd and 24.22% on DeSIQs in A4.\nIn Table 6, DeSIQd-2.0 also reduces the bias in Social-IQ-2.0, effectively reducing the performance of T5-small close to random guess. For T5-small, it suffers a larger performance drop on A4 of DeSIQd-2.0 (63.35% to 28.07%).\nZero-shot and Few-shot Learning. We employ the strong GPT-3 model (Brown et al., 2020) and ChatGPT (OpenAI, 2022) with both zero-shot and\ndevelopment sets. Results shaded in gray are relevant to Sec. 3.\nfew-shot learning to show the strength of our debiased datasets. Social-IQ experiments are performed in the A2 configuration using GPT-3, while Social-IQ-2.0 experiments in the A4 using ChatGPT. For zero-shot evaluation, we concatenate the question with correct and incorrect answer options (i.e. \u201cq+a\u201d) to form the prompt4, where the order of\n4We observe that when only given answer options but not the question, GPT-3 tends to select the first option.\nthe two answer options is randomly shuffled. The zero-shot prompt is constructed as follows:\n\u201cChoose the correct answer option corresponding to the question: \u201d + q + \u201c A: \u201d + a + \u201c B: \u201d + i\nFor the few-shot evaluation, we use the question similarity to find exemplars for in-context learning. For each question in the development set, we choose the top-3 most similar questions from the training set. We measure the semantic distance between questions based on their embeddings obtained from Sentence-Transformers (Reimers and Gurevych, 2019). The few-shot prompts leverage the same format as in the zero-shot evaluation, with the correct option appended to each exemplar:\n\u201cChoose the correct answer option corresponding to the question: \u201d + (q\u2032 + \u201c A: \u201d + a\u2032 + \u201c B: \u201d + i\u2032 + \u201cA or B\u201d)*3 + zero-shot prompt\nTable 7 shows the results. For Social-IQ, under the zero-shot setting, GPT-3 can obtain 58.26% with \u201cq+a\u201d and 64.63% with \u201cq+a+t\u201d on Social-IQ. In comparison, under either zero-shot or few-shot setting, both the DeSIQd and DeSIQs dataset lead\nto a performance drop of more than 4%. Under the few-shot setting for \u201cq+a\u201d, GPT-3 does not seem to learn shortcuts, as the performance is unchanged compared to the zero-shot setting5. These results show that DeSIQd and DeSIQs are less biased and more challenging than Social-IQ. For Social-IQ2.0, the performance does not change that much when leveraging ChatGPT under both zero-shot and few-shot learning settings, which also proves it is less biased than Social-IQ."
        },
        {
            "heading": "4 Setting Baseline Performance on DeSIQ",
            "text": "For our more challenging DeSIQ benchmark, we introduce a new baseline model to better handle multi-modal inputs. Its architecture is shown in Figure 4. Compared with the model in Figure 2, we add three more projection layers (three yellow MLPs) to map the original feature representations into the same dimensions. We then concatenate all the resulting representations as the inputs to a backbone MPM. For DeSIQd-2.0 containing raw data, we employ Vision Transformer (ViT) (Dosovitskiy et al., 2021) and Wav2Vec 2.0 (Baevski et al., 2020) to obtain the video and audio representations respectively. We note again that raw video and audio files are not available for v1, thus we develop the above architecture to uniformly handle both datasets, and leave how to best use multi-modal inputs in DeSIQ-2.0 for future work.\nAs social intelligence usually requires commonsense knowledge, we posit that injecting commonsense knowledge into the backbone language model in our architecture would improve the model\u2019s performance. Therefore, inspired by Jiang et al. (2021), we distill commonsense social knowledge from the following datasets into T5small: Social Chemistry 101 (Forbes et al., 2020), ETHICS (Hendrycks et al., 2021) and Moral Stories (Emelin et al., 2021). Specifically, we pretrain\n5We could not perform few-shot experiments with \u201cq+a+t\u201d due to GPT-3\u2019s limit of prompt length.\nT5-small on these corpora and then finetune it on the downstream Social-IQ and DeSIQ datasets. We call this variant T5-smallDelphi."
        },
        {
            "heading": "4.1 Results on DeSIQ",
            "text": "We analyze the effectiveness of our proposed architecture, and the effect of the distillation of commonsense knowledge. The results of our new model architecture are shown in the bottom portions of Tables 4 and 5, where the inputs are concatenated (\u201c\u2713\u201d for the column \u201cConcat\u201d). We can make the following observations: \u2022 Both T5-small and T5-smallDelphi outperform\nthe LSTM baseline on both DeSIQd and DeSIQs while not achieving near perfect accuracy, showing the effectiveness of our proposed architecture as well as the unbiased nature of DeSIQ.\n\u2022 When the question is given as part of the model input, T5-small and T5-smallDelphi (\u2713) significantly outperform the vanilla versions (\u2717), showing the effectiveness of our model architecture.\n\u2022 Injecting commonsense knowledge can indeed improve model performance on social intelligence. T5-smallDelphi with \u201cq+a+t\u201d inputs shows the best A2 score as 76.77% and A4 and 74.51% on DeSIQd, and 67.70% in A2 on DeSIQs. On DeSIQd, it outperforms T5-small in all but one settings (q+a+v for A2). On DeSIQs, however, T5-small shows competitive performance, and significantly outperforms T5smallDelphi on A4 for both q+a+t. We leave the investigation of this result to future work.\n\u2022 In many cases, adding the transcript can help improve model performance, and usually more effective than adding the video modality. Since T5-smallDelphi is pretrained on a textual corpus, it is reasonable that adding the video modality may decrease model performance.\n\u2022 Compared to DeSIQd, DeSIQs is a more challenging dataset, as except for \u201ca\u201d, performance of T5-small and T5-smallDelphi drops for all others.\n\u2022 Comparing the performance of q+a+t/q+a+v and q+a, we can observe that both T5-small and T5-smallDelphi can learn some shortcuts, as they achieve comparable performance when only given the question and answers as input.\nSome examples are shown in Appendix A Figure 5, illustrating the influence of different modalities. The first two examples show how the transcript and video features may provide clues for answering the\nquestion. For instance, the first example cannot be correctly answered based on \u201cq+a\u201d, since the transcript contains the required information. T5smallDelphi is the only model that predicts correct options for the last example in Figure 5, which we attribute to Delphi\u2019s commonsense knowledge."
        },
        {
            "heading": "4.2 Results on DeSIQ-2.0",
            "text": "For DeSIQ-2.0, we can apply multi-modal model using the raw videos and audios. The experimental results are in Table 6. Apart from some similar observations on DeSIQ-1.0 above, some new conclusions can be made as follows: \u2022 Adding audios or videos can help improve model\nperformance. Moreover, audios are more effective as the model achieves overall best A4 score of 74.13% under the \u201cq+a+s\u201d setting.\n\u2022 Employing raw transcripts can reduce model performance (57.23% \u2192 52.02% ) as they are usually 5 times longer than other input features in length, which can largely influence the representation learning procedure of other inputs.\n\u2022 Compared with ChatGPT in Table 7, our best result outperforms 24.52% on A4, which shows DeSIQ-2.0 to be a challenging dataset.\nWe also conduct experiments with settings \u201ca+t\u201d and \u201ca+v\u201d, but don\u2019t include them in the paper. After debiasing, both settings for the proposed model on DeSIQ2.0 are near the random guess performance: \u201ca+t\u201d 22.66% and \u201ca+v\u201d 26.46%. Thus, questions are necessary when compared with the performance of \u201cq+a+t\u201d and \u201cq+a+v\u201d inputs in Table 6."
        },
        {
            "heading": "4.3 Further Research Questions",
            "text": "The above results show the lack of biases and challenging nature of our DeSIQ datasets as well as promising performance by modestly-sized language models. These results lead to the following important research directions for further investigation: \u2022 Are there still noticeable biases in DeSIQ, and if\nso, how to further debias it?\n\u2022 What is the performance of stronger language models on DeSIQ?\n\u2022 How to effectively incorporate socio-cultural and commonsense knowledge into large language models for this task?\n\u2022 How to utilize multi-modal language models to better exploit video and audio input?"
        },
        {
            "heading": "5 Related Work",
            "text": "Debiasing. Shah et al. (2020) proposed a number of expectations to examine a model\u2019s performance on a number of multiple-choice QA datasets and observed that the model (RoBERTa) falls short of the expectations. Different from this work, we establish a systematic methodology, consisting of six novel methods, to examine a dataset. And we design some experimental settings on both SocialIQ and Social-IQ-2.0.\nLanguage Dependence/Prior is actually a MODEL side bias resulting in the model largely depending on one major modality (usually text). Reducing it can be regarded as an optimization problem. Gat et al. (2020) try to balance the influence of text and image from the MODEL side. Though the paper includes Social-IQ dataset and gets positive results, it doesn\u2019t realise the bias\u2019s existence in the original Social-IQ dataset.\nShortcut is a DATA side bias resulting in the model easily learning the pattern/repeated word in one dataset. For example, some keywords can occur both in the question and the correct answer, but not in the incorrect answers, so that the model directly gets clues from this overlap. Ye and Kovashka (2021) identify the shortcut and show its negative effects. However, they only modify the validation data and propose a masking approach to perform more robust training on the MODEL side.\nIn this paper, we start from the DATA side and also peform debiasing on the DATA side. Moreover, the bias we identify in the Social-IQ dataset is not the same kind, which is mainly in the answers and much harder to be debiased in the DATA side. Thus, though they share some similarities, we consider it a new task.\nMulti-modal Question Answering. With different multiple input modalities, such as image and video, multi-modal question answering problem is more challenging and has been rising more and more attention in the past few years. Datasets like MovieQA (Tapaswi et al., 2016), TGIF-QA (Jang et al., 2017), TVQA (Lei et al., 2018) and TVQA+ (Lei et al., 2020) provide images, GIFs or video clips in addition to text-based single-turn questions. There are some datasets like AVSD (Alamri et al., 2019) that require dialogue history to predict answers for multi-turn questions. All these datasets evaluate model capacity of perceive the contextual information contained in both text and non-text modalities.\nSocial Intelligence Learning. Understanding and reasoning about social commonsense knowledge and human interactions is essential for cognitive social intelligence learning. Bosselut et al. (2019) present a comprehensive study on automatic commonsense knowledge base construction, which mines the intents and reasons behind human behaviors. (Jiang et al., 2021) propose a commonsense moral model to better understand social norms and make reliable ethical judgments on real-world human actions. In this paper, we focus on the SocialIQ dataset (Zadeh et al., 2019), a benchmark provides a diverse annotated set of videos and questionanswer pairs. We run all the experiments on this dataset because it is much more related to social intelligence learning than other datasets."
        },
        {
            "heading": "6 Conclusion",
            "text": "Social intelligence is an essential ingredient for effective human-computer communications. In this paper, we analyze Social-IQ, a multiple-choice question answering benchmark dataset for social intelligence. Our empirical analysis reveal the severe biases present in Social-IQ, which can be easily exploited by modestly-sized language models such as T5-small to achieve perfect accuracy on its development set. We construct the DeSIQ benchmark by applying simple perturbation-based techniques on Social-IQ and show that the DeSIQ vastly reduce the biases in Social-IQ. Moreover, we propose a new model architecture on DeSIQ and set strong performance baselines for this challenging new dataset. Finally, our comprehensive analyses open up a number of important research questions for further investigation.\nLimitations\nFor the proposed model architecture designed to address the new DeSIQ benchmark, we mainly employ text-based language models and pretrain them on text-based corpora. The exploration of powerful multi-modal language models, instead of using the projection function as is done in this paper, is thus an important future research work direction. Due to resource constraints, all the experiments in this work were under conducted only once with the same random seed equals 42. Multiple runs with different random seeds would enable us to performance statistical significance tests of the results, and thus make the findings more reliable.\nEthics Statement\nAlthough the benchmark is designed for studying human behaviors and research purposes only, the resources and findings could be used unexpectedly. For example, it is possible that harmful content exists in the Social-IQ dataset, thus also in our DeSIQ datasets, based on which trainable models could turn from a positive to a negative perspective. Thus, it is prudent for researchers working on social intelligence to pledge to only make ethical use of our benchmark datasets."
        },
        {
            "heading": "Acknowledgement",
            "text": "This material is based on research partially sponsored by the DARPA Assured Neuro Symbolic Learning and Reasoning (ANSR) program under award number FA8750-23-2-1016, the DARPA Knowledge Management at Scale and Speed (KMASS) program under award number HR00112220047, and the DARPA Computational Cultural Understanding (CCU) program under the agreement number HR001122C0029. The U.S. Government is authorised to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The authors are grateful to the anonymous reviewers for their helpful comments."
        },
        {
            "heading": "A Appendix",
            "text": "A.1 Experimental Settings For all experiments, we fix our random seed at 42. We run fully supervised learning on one A40 GPU with 40GB memory, and set the learning rate as 1e-4 as well as early stopping by monitoring the loss on the development set. Typically, it takes 2-3 hours using only features to finish 100-epoch training with a batch size of 8.\nWe also employ GPT-3 (175B parameters) as it is the current state-of-the-art language model in a variety of NLP tasks for in-context learning For the few-shot evaluation, we select top-3 most similar questions from the training set. We did not test other choice of k due to both budget and time constraints, which we leave for future work.\nW hy\nis th\ne w\nom an\nup\nse t w\nhe n\nsh e\nre ce\niv es\nhe\nr s co\nre ?\nSo ca\nil Ch\nem 10\n1 cl\nue s\n(D EL\nPH I\npr et\nra in\nin g\nco rp\nus ):\ni t'\ns fu\nn to\nb e\nha pp\ny ab\nou t\nge tt\nin g\na hi\ngh s\nco re\n.\nA (c\nor re\nct ):\nIt is\nn ot\na s h\nig h\nas\nsh e\nth ou\ngh t i\nt w ou\nld b e B (i nc or re ct ): Sh e is ju\nst a\nct in g up se t t o tri ck th e op po ne nt\n-th at\n's w\nha t i\nt s ou\nnd s l\nik e\nw he\nn th ey sp lit fr om a n ev ol ut io na ry li ne ag e -y ea h yo u ge t 4 07 p oi nt s -O h\nA ns w er\nQ ue st io n\nTr an sc rip t\nVi de o\nA (i\nnc or\nre ct\n): ye\ns, he\nis b\nei ng\nse\nrio us\nB (c\nor re\nct ):\nno , h\ne is\nb ei\nng\nsa rc\nas tic\nfo r c\nom ed\nic a\nffe ct\nIs th\ne m\nan se\nrio us\nw\nhe n\nhe a\nsk s \"\nar e\nyo u\nca pt\niv at\ned y\net \"?\nLS TM T5 -s m al l D el ph i\nA A A A A A A A A A BB a q+ a q+ a+ t q+ a+ v\n-A re\ny ou\nc ap\ntiv at\ned y\net ?\nSo I\u2019\nm\ngo na\nto sh\nuf fle\nit\nLS TM T5 -s m al l D el ph i\nB B B B B B B B B A AB a q+ a q+ a+ t q+ a+ v Pr ed ic tio n\nVi de\no cl\nue s:\na no\nth er\np er\nso n\nar e\nsm il\nin g.\nLS TM T5 -s m al l D el ph i\nB B B B A B B B A A BA a q+ a q+ a+ t q+ a+ v\nW hy\nd oe\ns t he\nb lo\nnd e\nm an\nse em\nsa d?\nA (c\nor re\nct ):\nH e's\nu ps\net th e br un et te m an d oe sn 't w\nan t h\nis\nch ild\nre n\nra is\ned w\nith re\nlig io\nn.\nB (i\nnc or\nre ct\n): H\ne's sa\nd th\nat h e do es n' t g et a lo ng w ith th e br un et te m an .\n-A re\ny ou\nr p ar\nen ts\nre lig\nio us ? -T he y ar e re lig io us . ... -A nd I th in k sh e's re al ly\nso fte\nne d\nm y\nvi ew\ns o n\na lo\nt o f t\nhi ng s. I j us t d on 't w an t m y ch ild re n\nto g\nro w\nup\nw ith\nth e\nsa m\ne ex\npe rie\nnc e\nI h ad . Tr an sc ri pt c lu es : ye ll ow b ac kg ro un d wo rd s.\nFi gu\nre 5:\nPr ed\nic tio\nns of\ndi ff\ner en\ntm od\nel s\non D\neS IQ\nd be\nnc hm\nar k.\nW e\nsh ow\nth e\nan sw\ner s,\nqu es\ntio n,\ntr an\nsc ri\npt an\nd vi\nde o\nm od\nal iti\nes in\nth e\nfir st\nfo ur\nco lu\nm ns\n,a nd\npr ed\nic tio\nns of\ndi ff\ner en\ntm od\nel s\nus in\ng ou\nrs et\ntin gs\nof in\npu tf\nea tu\nre s.\nR ed\nel lip\nse s\nar e\nco rr\nec tp\nre di\nct io\nns ba\nse d\non ce\nrt ai\nn fe\nat ur\nes .S\nom e\nex pl\nai na\nbl e\ncl ue\ns ar\ne sh\nad ed\nin ye\nllo w\n."
        }
    ],
    "title": "DeSIQ: Towards an Unbiased, Challenging Benchmark for Social Intelligence Understanding",
    "year": 2023
}