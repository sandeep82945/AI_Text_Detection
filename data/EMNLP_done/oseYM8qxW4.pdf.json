{
    "abstractText": "Hallucination of text ungrounded in the input is a well-known problem in neural data-to-text generation. Many methods have been proposed to mitigate it, but they typically require altering model architecture or collecting additional data, and thus cannot be easily applied to an existing model. In this paper, we explore a new way to mitigate hallucinations by combining the probabilistic output of a generator language model (LM) with the output of a special \u201ctext critic\u201d classifier, which guides the generation by assessing the match between the input data and the text generated so far. Our method does not need any changes to the underlying LM\u2019s architecture or training procedure and can thus be combined with any model and decoding operating on word probabilities. The critic does not need any additional training data, using the base LM\u2019s training data and synthetic negative examples. Our experimental results show that our method improves over the baseline on the WebNLG and OpenDialKG benchmarks.",
    "authors": [
        {
            "affiliations": [],
            "name": "Mateusz Lango"
        }
    ],
    "id": "SP:c7a4fb73bbb4f829527c24a9c306a5a90910be47",
    "references": [
        {
            "authors": [
                "Satanjeev Banerjee",
                "Alon Lavie."
            ],
            "title": "METEOR: An automatic metric for MT evaluation with improved correlation with human judgments",
            "venue": "Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Transla-",
            "year": 2005
        },
        {
            "authors": [
                "Meng Cao",
                "Yue Dong",
                "Jiapeng Wu",
                "Jackie Chi Kit Cheung."
            ],
            "title": "Factual error correction for abstractive summarization models",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6251\u20136258,",
            "year": 2020
        },
        {
            "authors": [
                "Sihao Chen",
                "Fan Zhang",
                "Kazoo Sone",
                "Dan Roth."
            ],
            "title": "Improving faithfulness in abstractive summarization with contrast candidate generation and selection",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for",
            "year": 2021
        },
        {
            "authors": [
                "Reuben Cohn-Gordon",
                "Noah Goodman",
                "Christopher Potts."
            ],
            "title": "Pragmatically informative image captioning with character-level inference",
            "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational",
            "year": 2018
        },
        {
            "authors": [
                "Alexis Conneau",
                "Kartikay Khandelwal",
                "Naman Goyal",
                "Vishrav Chaudhary",
                "Guillaume Wenzek",
                "Francisco Guzm\u00e1n",
                "Edouard Grave",
                "Myle Ott",
                "Luke Zettlemoyer",
                "Veselin Stoyanov."
            ],
            "title": "Unsupervised cross-lingual representation learning at scale",
            "venue": "CoRR,",
            "year": 2019
        },
        {
            "authors": [
                "Javier Gonz\u00e1lez Corbelle",
                "Alberto Bugar\u00edn-Diz",
                "Jose Maria Alonso-Moral",
                "Juan Taboada"
            ],
            "title": "Dealing With Hallucination And Omission",
            "year": 2022
        },
        {
            "authors": [
                "Sumanth Dathathri",
                "Andrea Madotto",
                "Janice Lan",
                "Jane Hung",
                "Eric Frank",
                "Piero Molino",
                "Jason Yosinski",
                "Rosanne Liu."
            ],
            "title": "Plug and play language models: A simple approach to controlled text generation",
            "venue": "International Conference on Learning Representa-",
            "year": 2020
        },
        {
            "authors": [
                "Ond\u0159ej Du\u0161ek",
                "Zden\u011bk Kasner."
            ],
            "title": "Evaluating semantic accuracy of data-to-text generation with natural language inference",
            "venue": "Proceedings of the 13th International Conference on Natural Language Generation, pages 131\u2013137, Dublin, Ireland. Association",
            "year": 2020
        },
        {
            "authors": [
                "Katja Filippova."
            ],
            "title": "Controlled hallucinations: Learning to generate faithfully from noisy data",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 864\u2013870, Online. Association for Computational Linguistics.",
            "year": 2020
        },
        {
            "authors": [
                "Claire Gardent",
                "Anastasia Shimorina",
                "Shashi Narayan",
                "Laura Perez-Beltrachini."
            ],
            "title": "Creating training corpora for NLG micro-planners",
            "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
            "year": 2017
        },
        {
            "authors": [
                "Hamza Harkous",
                "Isabel Groves",
                "Amir Saffari."
            ],
            "title": "Have Your Text and Use It Too! End-to-End Neural Data-to-Text Generation with Semantic Fidelity",
            "venue": "COLING, Online. ArXiv: 2004.06577.",
            "year": 2020
        },
        {
            "authors": [
                "Or Honovich",
                "Leshem Choshen",
                "Roee Aharoni",
                "Ella Neeman",
                "Idan Szpektor",
                "Omri Abend."
            ],
            "title": "q2: Evaluating factual consistency in knowledgegrounded dialogues via question generation and question answering",
            "venue": "Proceedings of the 2021 Confer-",
            "year": 2021
        },
        {
            "authors": [
                "Ziwei Ji",
                "Nayeon Lee",
                "Rita Frieske",
                "Tiezheng Yu",
                "Dan Su",
                "Yan Xu",
                "Etsuko Ishii",
                "Ye Jin Bang",
                "Andrea Madotto",
                "Pascale Fung."
            ],
            "title": "Survey of hallucination in natural language generation",
            "venue": "ACM Computing Surveys, 55(12):1\u201338.",
            "year": 2023
        },
        {
            "authors": [
                "G\u00fcnter Klambauer",
                "Thomas Unterthiner",
                "Andreas Mayr",
                "Sepp Hochreiter."
            ],
            "title": "Self-normalizing neural networks",
            "venue": "Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS\u201917, page 972\u2013981, Red Hook, NY, USA.",
            "year": 2017
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdelrahman Mohamed",
                "Omer Levy",
                "Veselin Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "BART: Denoising sequence-to-sequence pre-training",
            "year": 2020
        },
        {
            "authors": [
                "Seungwhan Moon",
                "Pararth Shah",
                "Anuj Kumar",
                "Rajen Subba."
            ],
            "title": "OpenDialKG: Explainable conversational reasoning with attention-based walks over knowledge graphs",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational",
            "year": 2019
        },
        {
            "authors": [
                "Kishore Papineni",
                "Salim Roukos",
                "Todd Ward",
                "Wei jing Zhu."
            ],
            "title": "Bleu: a method for automatic evaluation of machine translation",
            "venue": "pages 311\u2013318.",
            "year": 2002
        },
        {
            "authors": [
                "Hannah Rashkin",
                "David Reitter",
                "Gaurav Singh Tomar",
                "Dipanjan Das."
            ],
            "title": "Increasing faithfulness in knowledge-grounded dialogue with controllable features",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics",
            "year": 2021
        },
        {
            "authors": [
                "Vikas Raunak",
                "Arul Menezes",
                "Marcin JunczysDowmunt."
            ],
            "title": "The Curious Case of Hallucinations in Neural Machine Translation",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics:",
            "year": 2021
        },
        {
            "authors": [
                "Clement Rebuffel",
                "Marco Roberti",
                "Laure Soulier",
                "Geoffrey Scoutheeten",
                "Rossella Cancelliere",
                "Patrick Gallinari."
            ],
            "title": "Controlling hallucinations at word level in data-to-text generation",
            "venue": "Data Mining and Knowledge Discovery, 36(1):318\u2013354.",
            "year": 2022
        },
        {
            "authors": [
                "Thibault Sellam",
                "Dipanjan Das",
                "Ankur P. Parikh."
            ],
            "title": "Bleurt: Learning robust metrics for text generation",
            "venue": "ACL.",
            "year": 2020
        },
        {
            "authors": [
                "Craig Thomson",
                "Ehud Reiter",
                "Somayajulu Sripada."
            ],
            "title": "SportSett:Basketball - A robust and maintainable dataset for Natural Language Generation",
            "venue": "IntelLanG - Intelligent Information Processing and Natural Language Generation, page 9, Online.",
            "year": 2020
        },
        {
            "authors": [
                "Hongmin Wang."
            ],
            "title": "Revisiting challenges in data-totext generation with fact grounding",
            "venue": "Proceedings of the 12th International Conference on Natural Language Generation, pages 311\u2013322, Tokyo, Japan. Association for Computational Linguistics.",
            "year": 2019
        },
        {
            "authors": [
                "Sean Welleck",
                "Ilia Kulikov",
                "Stephen Roller",
                "Emily Dinan",
                "Kyunghyun Cho",
                "Jason Weston."
            ],
            "title": "Neural text generation with unlikelihood training",
            "venue": "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April",
            "year": 2020
        },
        {
            "authors": [
                "Kevin Yang",
                "Dan Klein."
            ],
            "title": "FUDGE: Controlled text generation with future discriminators",
            "venue": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages",
            "year": 2021
        },
        {
            "authors": [
                "Tianyi Zhang",
                "Varsha Kishore",
                "Felix Wu",
                "Kilian Q. Weinberger",
                "Yoav Artzi."
            ],
            "title": "BERTScore: Evaluating text generation with BERT",
            "venue": "International Conference on Learning Representations.",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Hallucination, i.e., generated text lacking grounding in the input data, is a major challenge in neural data-to-text generation (Raunak et al., 2021; Rebuffel et al., 2022; Corbelle et al., 2022; Ji et al., 2023). Hallucinations can lead to inaccurate or misleading information, significantly undermining the quality and reliability of the generated output. While many approaches have been proposed to address this problem, they often involve modifying the underlying model architecture (Rebuffel et al., 2022) or acquiring additional data (Wang, 2019; Thomson et al., 2020), making them impractical for existing models. At the same time, popular metrics for evaluating hallucinations are based on text classification models, e.g. NLI-based metrics (Honovich et al., 2021; Du\u0161ek and Kasner, 2020). This indicates that text classifiers have the potential to accurately identify and assess coher-\nence problems between the data and the generated text. However, use of text classifiers in generation typically involves producing many outputs with a base model and reranking them afterwards (Harkous et al., 2020).\nIn this paper, we propose a novel critic-driven decoding approach that combines the probabilistic output of a conditional language model (LM) with the output of a specialized text critic classifier that guides the generation process by evaluating the coherence of the textual prefix generated so far with the input data. This allows us to influence the generation on-the-fly, without the need to overgenerate many outputs. Furthermore, our approach does not require modifications to the underlying LM or additional fine-tuning. This ensures compatibility with a wide range of existing models and decoding algorithms that operate on word probabilities. Finally, our method does not rely on the collection of additional data, as training data for the critic can be synthesized from the data-to-text dataset used to train the underlying conditional LM.\nWe verify the effectiveness of our critic-driven decoding in experiments on the WebNLG (Gardent et al., 2017) and OpenDialKG (Moon et al., 2019) benchmarks, with both automatic and manual evaluation of text hallucinations in the model outputs. The results show that our method is able to limit hallucinations and produce a more faithful text, yet close to the base LM\u2019s output. Our implementation of the proposed method is publicly available.1"
        },
        {
            "heading": "2 Critic-driven decoding",
            "text": "Recall that auto-regressive conditional LMs for data-to-text generation rely on the following probability factorization:\nP (y|x) = n\u220f\ni=1\nP (yi|y\u2264i\u22121, x) (1)\n1https://github.com/langus0/ critic-aware-decoding\nwhere x is the data representation and y is the generated text. We use y\u2264j to denote all the tokens y1, y2, y3, ..., yj .\nIn our approach, we introduce to this probability an additional text generation critic which evaluates the match between the generated text and the data representation. The output of the critic c can be seen as a binary variable, equal to 1 if the text matches the input data and 0 otherwise. This leads to the following probability factorization:\nP (y|x, c) = n\u220f\ni=1\nP (yi|y\u2264i\u22121, x, c) (2)\ni.e. generation of text y given the data representation x and the output of the critic c. By applying simple probability transformations (see Appendix A), we obtain the following factorization:\nP (yi|y\u2264i\u22121, x, c) \u221d P (c|y\u2264i, x)P (yi|y\u2264i\u22121, x) (3)\nThis formulation combines two probabilities: the probability of a standard conditional LM P (yi|y\u2264i\u22121, x) and the probability of the match between the text and the data as evaluated by the critic model P (c|y\u2264i, x).\nThe critic is modelled as a binary classifier, conditioned on the data, past tokens and the token currently being decoded. It is thus run at each decoding step, and it is evaluating the viability of the current prefix of the generation output (assuming future generation will be successful). The proposed formulation can be used with any auto-regressive conditional LM without modification, as the operation is identical to Eq. 1. The critic can be trained separately from the LM since our formulation implies the conditional independence of those two models.\nThe above factorization leads us to a practical proposal of a critic-driven decoding algorithm. First, an additional critic model is trained, which is able to approximate P (c|y\u2264i, x) (details are discussed in Sec. 3). We then perform standard greedy decoding with the LM, but using the updated formula for calculating probabilities of the next tokens (Eq. 3). In practice, our implementation operates on logarithms rather than raw probabilities and uses an additional weight \u03bb that adjusts the influence of the critic on the final result:\nlnP (yi|y\u2264i\u22121, x, c) \u221d \u03bb lnP (c|y\u2264i, x) + lnP (yi|y\u2264i\u22121, x)\n(4)"
        },
        {
            "heading": "3 Training a text generation critic",
            "text": "The critic model P (c|y\u2264i, x) is a binary classifier that checks the correspondence between the linearized data representation x and the so far generated prefix of the output text y\u2264i. We assume an encoder pretrained LM as the backbone of the critic. The model input contains x and y\u2264i split by a separator token.\nPositive instances for the critic\u2019s training are constructed from examples (x, y) in the underlying LM\u2019s dataset as prefixes: (x, y1), (x, y\u22642), (x, y\u22643), ..., (x, y\u2264n). Negative examples must be synthesized and are crucial for training the critic, as they teach it how to detect that the generated text starts deviating from the input data (i.e. hallucinations). Therefore, we explore five ways of generating negative examples (see Appendix G for examples):\n1. base \u2013 for each positive example, we replace the last token with a random one. To make the training set more challenging, the tokens are sampled from another text reference for the same data (if available) or another random sentence from the dataset.\n2. base with full sentences \u2013 a randomly selected sentence of the reference text y is replaced with a random sentence from the dataset. Negative examples are then generated in the same way as positive examples, but starting from the first token that deviates from the reference. In addition, instances where a random token in the reference is replaced by a wrong one are also generated in the same way.\n3. vanilla LM \u2013 for each positive example we probe an unconditional LM to get a list of the five most likely next tokens. We randomly select a token from this list and construct a negative example.\n4. fine-tuned LM \u2013 similar to the previous, but using the LM conditioned on the data.\n5. fine-tuned LM with full sentences \u2013 the LM conditioned on the data is used to generate a textual description of the data. The negative examples are constructed for each token starting from the one where the model starts deviating from the reference.\nAll critic model variants are trained by optimizing binary cross-entropy loss."
        },
        {
            "heading": "4 Experimental evaluation",
            "text": "We compare all critic variants defined in Sec. 3 with the baseline LM on both automatic and manual metrics, focusing on the number of hallucinations."
        },
        {
            "heading": "4.1 Experimental setup",
            "text": "We performed most experiments on the WebNLG benchmark (Gardent et al., 2017) containing data expressed as RDF triples and corresponding text references, which is prominent in many previous works tackling hallucination. We also evaluate our approach on the OpenDialKG dataset (Moon et al., 2019), which contains dialogues annotated with RDF triples representing the information expressed in each utterance. We use it in a similar way as WebNLG, treating the utterances as textualisations of the data, i.e. without taking dialogue history into account. The BART-base encoder-decoder model (Lewis et al., 2020), finetuned on WebNLG, is used as the base NLG system (see Appendix C for training details).\nFive different critic models were trained as discussed in Sec. 3 with classification heads on top of a XLM-RoBERTa-base model (Conneau et al., 2019), see Appendix D for details. The vanilla LM critic uses BART-base without any fine-tuning, the fine-tuned LM variants (4 & 5) use the base LM to generate training data. The critics\u2019 classification performance is given in Table 1. This shows that the critics are able to learn the synthetic data well, which is, however, not necessarily reflected in performance when used during generation.\nWe use greedy decoding by default. To speed up computation of critic-driven decoding, we first evaluate the second term of Eq. 3, i.e. the conditional LM, and we run the critic model only for k = 5 most probable tokens, modifying its probabilities accordingly. The critic weight \u03bb = 0.25 (see Eq. 4) was used for all the models for WebNLG and \u03bb = 1 for OpenDialKG. We found that the output of the critic can be noisy when evaluating the match between the data and only a few initial tokens of the text. Therefore, we add a simple linear warmup for \u03bb for the first five tokens: while decoding the i-th token, \u03bbi = min( i5 , 1) \u00b7 \u03bb (cf. Appendix B for choice of k and warmup)."
        },
        {
            "heading": "4.2 Analysis of decoding performance with automatic measures",
            "text": "The system outputs were evaluated using standard automatic metrics \u2013 BLEU (Papineni et al.,\n2002), METEOR (Banerjee and Lavie, 2005) and BERTScore (Zhang et al., 2020) \u2013 as well as measures particularly targeting hallucinations: BLEURT (Sellam et al., 2020) and the NLI-based metric proposed by Du\u0161ek and Kasner (2020).\nOverall results on WebNLG are presented in Table 2. Except for the critic trained on full LMgenerated sentences (var. 5), all the other variants of critic-driven decoding slightly improve performance according to BLEU, METEOR, and BERTScore. Higher gains, up to 2.5% absolute on the whole test set, can be observed on measures targeting hallucinations, i.e. NLI and BLEURT. Note that our approach achieves this without modifying the original LM. The base critic achieves the highest scores across most evaluation metrics.\nInterestingly, both critics trained on data generated with the fine-tuned LM (i.e. the same system as used for decoding) failed to improve the NLI measure and only one improved BLEURT. This shows that an effective critic can be trained separately from the NLG system.\nAnalysis of introduced changes We also measured to what extent the critic-based approaches change the outputs compared to the baseline, i.e. the percentage of modified outputs as well as the number of added and removed words.2 Results in Tab. 4 show that critic-based approaches preserve many outputs (30-70%) and generally only change a few words, while keeping the output lengths similar. This suggests that our critics make small changes and only where necessary.\nOut of domain generalization The test data of the WebNLG dataset contains about 46% of instances from categories not present in the training data. Therefore, we also provide the fine-grained results for both in-domain and out-domain part of the test set in Table 2. The in-domain results are naturally better, but we can observe consistent im-\n2Replacing a word counts as one addition and one deletion.\nprovements of our critic-aware approach on both in-domain and out-of-domain data.\nStatistical analysis We performed statistical hypothesis testing to compare the results of the baseline with our approach with critic (base with full sentences). As expected, the differences on text quality measures (BLEU, METEOR, BERTScore) are not statistically significant, in contrast to the differences on measures targeting hallucinations, which are statistically significant at the \u03b1 = 0.05 significance level (cf. Table 2).\nBeam search experiment To verify the consistency of our critic\u2019s improvements, we run additional experiments with a stronger baseline, i.e. beam search decoding. The results, confirming greedy decoding results, are in Appendix F.\nResults on OpenDialKG are presented in Table 3 and are mostly in line with those obtained for WebNLG. The base critic approach (var. 1) obtained a gain of 5 percentage points on NLI and of 3 points on BLEURT over the baseline. The values of basic word-overlap metrics are lower, but our qualitative assessment did not confirm any quality drop. The second critic variant (base with full sentences), which offered high performance of WebNLG, also performed well on OpenDialKG. It scored best on standard text quality metrics while offering improvements over the baseline on hallucinationfocused metrics (NLI, BLEURT)."
        },
        {
            "heading": "4.3 Manual analysis of decoding performance",
            "text": "To verify the automatic metric results, we performed a small-scale in-house human evaluation. We sampled 100 instances from the test set of the WebNLG dataset and annotated for them the output of all the systems under study (600 system outputs in total). The annotation was performed by five NLP expert annotators, who assessed the presence of minor hallucinations (mostly typos in named entity names), major hallucinations (output containing fact(s) not supported by the data), omissions (missing information), disfluencies (grammar errors or hard-to-read text) and repetitions (information mentioned twice). Finally, the annotators ranked the system outputs for each example from best to worst, with ties allowed. The annotation was blind, with system order randomly shuffled for each example. Results are summarised in Table 5 (see Appendix E for inter-annotator agreement).\nAll critic-driven approaches achieved better av-\nerage ranks than the baseline, with the base critic (var. 1) having the best rank. The rank difference compared to the baseline is not large (0.23), but increases for more complex instances: in instances with three or more triples, the difference is 0.33, for instances with file or more triples, it is 0.53. More importantly, the base critic reduced the rate of major hallucination by 10% absolute. Again, the improvements are bigger for more complex instances (15.3% for \u2265 3 triples, 20% for \u2265 5). It also performed better on all other criteria, producing a more fluent output, with fewer omissions and repetitions, as well as a slightly reduced number of minor hallucinations.\nOther critic variants were also effective in reducing hallucinations; in particular, the vanilla LM critic (var. 3) was the most effective in reducing both major and minor hallucinations. The finetuned LM approaches (vars. 4 & 5) only provided very limited benefits."
        },
        {
            "heading": "5 Related works",
            "text": "Hallucination in NLG is a widely studied problem, with many different mitigation methods proposed, including data cleaning or various model architecture modifications (see Ji et al. (2023) for a detailed review). Mitigation methods most similar to ours include the controlled generation approach by Filippova (2020), which uses special control codes to control hallucinations. This was followed by Rashkin et al. (2021), who combine control codes with resampling of several texts and selecting the best one according to the metrics. However, both approaches require training a new LM with control codes and, in the latter case, additional resampling of whole texts. Cao et al. (2020) proposed a twostep generate & refine procedure, which is modelindependent but requires training of an additional correcting LM and decoding the sequence twice. Similarly to our approach, Chen et al. (2021) use a text classifier to select the best output among the\nso-called contrast candidates but does not use it during decoding.\nOur method is closely inspired by works on classconditional LMs, which use the Bayes rule to introduce additional conditioning (Cohn-Gordon et al., 2018; Dathathri et al., 2020). In particular, a formulation similar to ours is used by FUDGE (Yang and Klein, 2021) to impose a certain requirement, such as a level of formality, on the text produced by a LM. However, these works do not address the issue of hallucinations.\nThe use of randomly generated words as negative samples to improve natural language generation has also been explored by Welleck et al. (2020). In contrast to this work, their unlikelihood training technique is mainly aimed at limiting repetitive text generation and requires training a new model, as it modifies the training objective."
        },
        {
            "heading": "6 Summary",
            "text": "Our paper introduces a novel critic-driven decoding approach to mitigate hallucinations in data-to-text generation. By using the output of a specialised text critic classifier, we guide the generation process to produce more grounded output without requiring any modifications to the underlying LM. The experimental results on the WebNLG and OpenDialKG benchmarks show that the proposed method has the potential to limit hallucinations without hindering other text quality metrics."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was supported by the European Research Council (Grant agreement No. 101039303, NG-NLG) and used resources of the LINDAT/ CLARIAH-CZ Research Infrastructure (Czech Ministry of Education, Youth, and Sports project No. LM2018101). The authors would like to thank Ondr\u030cej Pl\u00e1tek, Patr\u00edcia Schmidtov\u00e1 and Sourabrata Mukherjee, who kindly provided manual annotations for this work.\nLimitations\nWhile our approach strives to remove as many hallucinations as possible from the NLG output, a certain proportion still remains for all our setups. The performance of the approach is limited by the base LM and its proposed most likely next tokens (as a limited number of next tokens is considered at each step, cf. Sec. 4). Furthermore, the use of the critic slows down the decoding. For application to other datasets, the critic may become less effective if the underlying training data is too noisy."
        },
        {
            "heading": "A Derivation of the proposed probability factorization that incorporates a critic model",
            "text": "By applying the conditional probability formula and the product rule to Eq. 2, we obtain the following:\nP (yi|y\u2264i\u22121, x, c) =\n= P (yi, y\u2264i\u22121, x, c)\nP (y\u2264i\u22121, x, c)\n= P (c|yi, y\u2264i\u22121, x)P (yi|y\u2264i\u22121, x)P (y\u2264i\u22121, x)\nP (y\u2264i\u22121, x, c)\n= P (c|y\u2264i, x)P (yi|y\u2264i\u22121, x) P (y\u2264i\u22121, x)\nP (y\u2264i\u22121, x, c)\n= P (c|y\u2264i, x)P (yi|y\u2264i\u22121, x)P (c|y\u2264i\u22121, x)\u22121 \u221d P (c|y\u2264i, x)P (yi|y\u2264i\u22121, x)\nwhere the last line comes from the fact that when computing the probability of the next token yi, the previous tokens y\u2264i\u22121 are fixed, so the critic\u2019s score for the previous tokens P (c|y\u2264i\u22121, x) is a constant and does not affect the result."
        },
        {
            "heading": "B Sensitivity analysis of the hyperparameters of critic-aware decoding",
            "text": "B.1 The number of most probable considered tokens\nTo speed up computations of critic-driven decoding, we run the critic model only for k most probable tokens according to the LM and modify its probabilities with Eq. 3. The results in the paper are reported for k = 5, but we performed additional experiments with k = 15 to investigate how it will affect the performance. The results are given in Table 6. In general, we observe minor differences in comparison to k = 5. Some metrics has been slightly improved, but it probably does not counterbalance the additional computational cost.\nB.2 The importance of linear warm-up\nA practical motivation for using linear warm-up of the \u03bb parameter can be found in Figure 1, which shows the accuracy as a function of text prefix length for one of the critic models (base, var. 1). It can be observed that at the beginning of the generation process (i.e. for very short prefixes) the accuracy of the critic is low, but grows rapidly with the length of the prefix, reaching a high level around the length of 5 tokens.\nThe importance of linear warm-up is investigated by comparing the decoding performance with a constant \u03bb and with linear warm-up (i.e. \u03bbi = min( i5 , 1) \u00b7 \u03bb). The results of this experiment for BLEU and BLEURT measures are depicted in Figure 2 and 3, respectively. It can be observed that the linear warm-up provides better performance for almost every model."
        },
        {
            "heading": "C Hyperparameters of BART fine-tuning",
            "text": "As a conditional language model, we used BARTbase model (Lewis et al., 2020) fine-tuned with default architecture provided by HuggingFace library. AdamW with learning rate \u03b7 = 2 \u00b7 10\u22125 and parameters \u03b2 = (0.9, 0.997), \u03f5 = 10\u22129 was used\nas optimizer. Additionally, we applied polynomial scheduler of \u03b7 with a warmup equal to 10% of optimization steps. The training was scheduled for 20 epochs with early stopping on validation loss (patience of 10 epochs). We used batch size equal to 8 and label smoothing with 0.1 smoothing factor."
        },
        {
            "heading": "D Details on critic model training",
            "text": "The architecture of the critic model consisted of a pretrained XLM-RoBERTa-base model (Conneau et al., 2019) and a classification head on top of the representation of the first token. The classification head contained a fully connected layer with SELU activation function (Klambauer et al., 2017) and one additional classification layer with sigmoid activation. The number of neurons in the first layer was set to the dimensionality of the output embedding.\nThe critic models were trained as discussed in Sec. 3 by optimizing the cross-entropy loss. AdamW was used as an optimizer with a learning rate of \u03b7 = 10\u22125. The training was continued until the convergence, i.e. lack of the improvement on validation loss.\nAll the experiments with the critics (both critic training and decoding) were performed on one GPU: nVidia Quadro P5000 16 GB. During decoding the BART-based language model was loaded with bitsandbytes library (8-bit mode).\nE Inter-annotator agreement\nTo estimate the inter-annotator agreement, one of the annotators re-annotated 10 (\u00d7 6 model outputs) instances originally annotated by a different annotator. 86% of annotations were identical. In terms of Cohen\u2019s kappa, 0.19 agreement was obtained for minor hallucinations, 0.68 for major, 0.88 for omissions, 0.48 for repetitions and 0.07 for disfluencies."
        },
        {
            "heading": "F Comparison with a stronger baseline",
            "text": "One simple method which generates multiple outputs and generally tends to offer texts of higher quality is beam search. We run additional experiments with beam size equal to 5 and present the result in the Table 7. The improvements for this stronger baseline are consistent with these reported in the main paper for greedy decoding."
        },
        {
            "heading": "G Examples of negative instances generated by different approaches for critic training set construction",
            "text": "Let us consider the following data representation:\n(A-Rosa Luna | length | 125800.0 (millimetres)); (A-Rosa Luna | power type | MTU Friedrichshafen)\nand the reference:\nThe A-Rosa Luna is powered by a MTU Friedrichshafen engine and is 125.8 metres in\nlength.\nThe positive examples for the critic consist on all the possible prefixes generated from the reference, i.e. \"The\", \"The A-Rosa\", \"The A-Rosa Luna\", etc. The negative examples generated by different approaches are as follows:\n1. base \u2013 the negative examples are generated with random words\n\"The Cruises\", \"The A-Rosa operated\", \"The A-Rosa Luna located\", ...\n2. base with full sentences - a sentence or a token from the reference is replaced with random sentence/token and all possible negative examples are generated\n\"The Cruises\", \"The Cruises Luna\", \"The Cruises Luna is\", ..., \"The A-Rosa operated\",\n\"The A-Rosa operated is\", ...\n3. vanilla LM \u2013 the incorrect next words are sampled from the five most probable tokens according to (unconditioned) LM\n\"The United\", \"The A-Rosa is\", \"The A-Rosa Luna powers\", ...\n4. fine-tuned LM with full sentences \u2013 for a given data the NLG system generated the following output: \"The A-Rosa Luna is 125.8m long and is powered by MTU Friedrichsburger\", which is used to generate negative examples by comparing it against the reference\n\"The A-Rosa Luna is 125.8m\", \"The A-Rosa Luna is 125.8m long\", \"The A-Rosa Luna is 125.8m and\", \"The A-Rosa Luna is 125.8m\nand is\", ...\n5. fine-tuned LM \u2013 the incorrect next words are sampled from the five most probable tokens according to data-conditioned LM\n\"The A-Rosa Luna is 125.8m\", \"The A-Rosa Luna is supplied\", \"The A-Rosa Luna is\npowered with\", ..."
        }
    ],
    "title": "Critic-Driven Decoding for Mitigating Hallucinations in Data-to-text Generation",
    "year": 2023
}