{
    "abstractText": "Online sentiment analysis has emerged as a crucial component in numerous datadriven applications, including social media monitoring, customer feedback analysis, and online reputation management. Despite their importance, current methodologies falter in effectively managing the continuously evolving nature of data streams, largely due to their reliance on substantial, pre-existing labelled datasets. This paper presents SentiStream, a novel co-training framework specifically designed for efficient sentiment analysis within dynamic data streams. Comprising unsupervised, semi-supervised, and stream merge modules, SentiStream guarantees constant adaptability to evolving data landscapes. This research delves into the continuous adaptation of language models for online sentiment analysis, focusing on real-world applications. Experimental evaluations using data streams derived from five benchmark sentiment analysis datasets confirm that our proposed methodology surpasses existing approaches in terms of both accuracy and computational efficiency1.",
    "authors": [
        {
            "affiliations": [],
            "name": "Yuhao Wu"
        },
        {
            "affiliations": [],
            "name": "Karthick Sharma"
        },
        {
            "affiliations": [],
            "name": "Chun Wei Seah"
        },
        {
            "affiliations": [],
            "name": "Shuhao Zhang"
        }
    ],
    "id": "SP:fe5981abdc116bd50ba165f31d53bc899401ed86",
    "references": [
        {
            "authors": [
                "B. Agarwal",
                "N. Mittal."
            ],
            "title": "Machine Learning Approach for Sentiment Analysis",
            "venue": "Springer International Publishing.",
            "year": 2016
        },
        {
            "authors": [
                "Hongjoon Ahn",
                "Sungmin Cha",
                "Donggyu Lee",
                "Taesup Moon."
            ],
            "title": "Uncertainty-based continual learning with adaptive regularization",
            "venue": "Advances in neural information processing systems, 32.",
            "year": 2019
        },
        {
            "authors": [
                "Craig Atkinson",
                "Brendan McCane",
                "Lech Szymanski",
                "Anthony Robins."
            ],
            "title": "Pseudo-recursal: Solving the catastrophic forgetting problem in deep neural networks",
            "venue": "arXiv preprint arXiv:1802.03875.",
            "year": 2018
        },
        {
            "authors": [
                "S\u00e9bastien Bubeck",
                "Varun Chandrasekaran",
                "Ronen Eldan",
                "Johannes Gehrke",
                "Eric Horvitz",
                "Ece Kamar",
                "Peter Lee",
                "Yin Tat Lee",
                "Yuanzhi Li",
                "Scott Lundberg"
            ],
            "title": "Sparks of artificial general intelligence: Early experiments with gpt-4",
            "year": 2023
        },
        {
            "authors": [
                "Nicola Capuano",
                "Luca Greco",
                "Pierluigi Ritrovato",
                "Mario Vento."
            ],
            "title": "Sentiment analysis for customer relationship management: an incremental learning approach",
            "venue": "Applied Intelligence, 51(6):3339\u20133352.",
            "year": 2021
        },
        {
            "authors": [
                "Matthias De Lange",
                "Rahaf Aljundi",
                "Marc Masana",
                "Sarah Parisot",
                "Xu Jia",
                "Ale\u0161 Leonardis",
                "Gregory Slabaugh",
                "Tinne Tuytelaars."
            ],
            "title": "A continual learning survey: Defying forgetting in classification tasks",
            "venue": "IEEE transactions on pattern analysis and machine",
            "year": 2021
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "arXiv preprint arXiv:1810.04805.",
            "year": 2018
        },
        {
            "authors": [
                "Milagros Fern\u00e1ndez-Gavilanes",
                "Tamara \u00c1lvarezL\u00f3pez",
                "Jonathan Juncal-Mart\u00ednez",
                "Enrique CostaMontenegro",
                "Francisco Javier Gonz\u00e1lez-Casta\u00f1o."
            ],
            "title": "Unsupervised method for sentiment analysis in online texts",
            "venue": "Expert Systems with Applications,",
            "year": 2016
        },
        {
            "authors": [
                "Chrisantha Fernando",
                "Dylan Banarse",
                "Charles Blundell",
                "Yori Zwols",
                "David Ha",
                "Andrei A Rusu",
                "Alexander Pritzel",
                "Daan Wierstra."
            ],
            "title": "Pathnet: Evolution channels gradient descent in super neural networks",
            "venue": "arXiv preprint arXiv:1701.08734.",
            "year": 2017
        },
        {
            "authors": [
                "Lukas Galke",
                "Ansgar Scherp."
            ],
            "title": "Bag-ofwords vs",
            "venue": "graph vs. sequence in text classification: Questioning the necessity of text-graphs and the surprising strength of a wide mlp. arXiv preprint arXiv:2109.03777.",
            "year": 2021
        },
        {
            "authors": [
                "Geetika Gautam",
                "Divakar Yadav."
            ],
            "title": "Sentiment analysis of twitter data using machine learning approaches and semantic analysis",
            "venue": "2014 Seventh International Conference on Contemporary Computing (IC3), pages 437\u2013442. IEEE.",
            "year": 2014
        },
        {
            "authors": [
                "Alec Go",
                "Richa Bhayani",
                "Lei Huang."
            ],
            "title": "Twitter sentiment classification using distant supervision",
            "venue": "CS224N project report, Stanford, 1(12):2009.",
            "year": 2009
        },
        {
            "authors": [
                "Yue Han",
                "Yuhong Liu",
                "Zhigang Jin."
            ],
            "title": "Sentiment analysis via semi-supervised learning: a model based on dynamic threshold and multiclassifiers",
            "venue": "Neural Computing and Applications, 32:5117\u20135129.",
            "year": 2020
        },
        {
            "authors": [
                "Tanjim Ul Haque",
                "Nudrat Nawal Saber",
                "Faisal Muhammad Shah."
            ],
            "title": "Sentiment analysis on large scale amazon product reviews",
            "venue": "2018 IEEE international conference on innovative research and development (ICIRD), pages 1\u20136. IEEE.",
            "year": 2018
        },
        {
            "authors": [
                "Vasileios Iosifidis",
                "Eirini Ntoutsi."
            ],
            "title": "Large scale sentiment learning with limited labels",
            "venue": "KDD\u201917, pages 1823\u20131832.",
            "year": 2017
        },
        {
            "authors": [
                "Xisen Jin",
                "Dejiao Zhang",
                "Henghui Zhu",
                "Wei Xiao",
                "Shang-Wen Li",
                "Xiaokai Wei",
                "Andrew Arnold",
                "Xiang Ren."
            ],
            "title": "Lifelong pretraining: Continually adapting language models to emerging corpora",
            "venue": "arXiv preprint arXiv:2110.08534.",
            "year": 2021
        },
        {
            "authors": [
                "Zixuan Ke",
                "Bing Liu",
                "Hu Xu",
                "Lei Shu."
            ],
            "title": "Classic: Continual and contrastive learning of aspect sentiment classification tasks",
            "venue": "arXiv preprint arXiv:2112.02714.",
            "year": 2021
        },
        {
            "authors": [
                "Yoon Kim."
            ],
            "title": "Convolutional neural networks for sentence classification",
            "venue": "Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 1746\u20131751.",
            "year": 2014
        },
        {
            "authors": [
                "James Kirkpatrick",
                "Razvan Pascanu",
                "Neil Rabinowitz",
                "Joel Veness",
                "Guillaume Desjardins",
                "Andrei A Rusu",
                "Kieran Milan",
                "John Quan",
                "Tiago Ramalho",
                "Agnieszka Grabska-Barwinska"
            ],
            "title": "Overcoming catastrophic forgetting",
            "year": 2017
        },
        {
            "authors": [
                "Miaomiao Li",
                "Jiaqi Zhu",
                "Xin Yang",
                "Yi Yang",
                "Qiang Gao",
                "Hongan Wang."
            ],
            "title": "Cl-wstc: Continual learning for weakly supervised text classification on the internet",
            "venue": "Proceedings of the ACM Web Conference 2023, pages 1489\u20131499.",
            "year": 2023
        },
        {
            "authors": [
                "Ning Li",
                "Chi-Yin Chow",
                "Jia-Dong Zhang."
            ],
            "title": "Seml: A semi-supervised multi-task learning framework for aspect-based sentiment analysis",
            "venue": "IEEE Access, 8:189287\u2013189297.",
            "year": 2020
        },
        {
            "authors": [
                "Chenghua Lin",
                "Yulan He."
            ],
            "title": "Joint sentiment/topic model for sentiment analysis",
            "venue": "Proceedings of the 18th ACM conference on Information and knowledge management, pages 375\u2013 384.",
            "year": 2009
        },
        {
            "authors": [
                "Kyle Lo",
                "Lucy Lu Wang",
                "Mark Neumann",
                "Rodney Kinney",
                "Daniel Weld."
            ],
            "title": "S2ORC: The semantic scholar open research corpus",
            "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages",
            "year": 2020
        },
        {
            "authors": [
                "David Lopez-Paz",
                "Marc\u2019Aurelio Ranzato"
            ],
            "title": "Gradient episodic memory for continual learning",
            "venue": "Advances in neural information processing systems,",
            "year": 2017
        },
        {
            "authors": [
                "Kelvin Luu",
                "Daniel Khashabi",
                "Suchin Gururangan",
                "Karishma Mandyam",
                "Noah A Smith"
            ],
            "title": "Time waits for no one! analysis and challenges of temporal misalignment",
            "venue": "arXiv preprint arXiv:2111.07408",
            "year": 2021
        },
        {
            "authors": [
                "Andrew L. Maas",
                "Raymond E. Daly",
                "Peter T. Pham",
                "Dan Huang",
                "Andrew Y. Ng",
                "Christopher Potts."
            ],
            "title": "Learning word vectors for sentiment analysis",
            "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational",
            "year": 2011
        },
        {
            "authors": [
                "Tomas Mikolov",
                "Kai Chen",
                "Gregory S. Corrado",
                "Jeffrey Dean."
            ],
            "title": "Efficient estimation of word representations in vector space",
            "venue": "ICLR.",
            "year": 2013
        },
        {
            "authors": [
                "Roberto Navigli",
                "Federico Martelli."
            ],
            "title": "An overview of word and sense similarity",
            "venue": "Natural Language Engineering, 25(6):693\u2013714.",
            "year": 2019
        },
        {
            "authors": [
                "Jianmo Ni",
                "Jiacheng Li",
                "Julian McAuley."
            ],
            "title": "Justifying recommendations using distantly-labeled reviews and fine-grained aspects",
            "venue": "pages 188\u2013197.",
            "year": 2019
        },
        {
            "authors": [
                "Alvaro Ortigosa",
                "Jos\u00e9 M Mart\u00edn",
                "Rosa M Carro."
            ],
            "title": "Sentiment analysis in facebook and its application to e-learning",
            "venue": "Computers in human behavior, 31:527\u2013541.",
            "year": 2014
        },
        {
            "authors": [
                "Yassine Ouali",
                "C\u00e9line Hudelot",
                "Myriam Tami."
            ],
            "title": "An overview of deep semi-supervised learning",
            "venue": "arXiv preprint arXiv:2006.05278.",
            "year": 2020
        },
        {
            "authors": [
                "Alec Radford",
                "Karthik Narasimhan",
                "Tim Salimans",
                "Ilya Sutskever"
            ],
            "title": "Improving language understanding by generative pre-training",
            "year": 2018
        },
        {
            "authors": [
                "Amir Hossein Akhavan Rahnama."
            ],
            "title": "Distributed real-time sentiment analysis for big data social streams",
            "venue": "2014 International conference on control, decision and information technologies (CoDIT), pages 789\u2013794. IEEE.",
            "year": 2014
        },
        {
            "authors": [
                "Sylvestre-Alvise Rebuffi",
                "Alexander Kolesnikov",
                "Georg Sperl",
                "Christoph H Lampert."
            ],
            "title": "icarl: Incremental classifier and representation learning",
            "venue": "Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pages 2001\u20132010.",
            "year": 2017
        },
        {
            "authors": [
                "Nadia Felix F Da Silva",
                "Luiz FS Coletta",
                "Eduardo R Hruschka."
            ],
            "title": "A survey and comparative study of tweet sentiment analysis via semi-supervised learning",
            "venue": "ACM Computing Surveys (CSUR), 49(1):1\u2013",
            "year": 2016
        },
        {
            "authors": [
                "Vikas Sindhwani",
                "Prem Melville"
            ],
            "title": "Documentword co-regularization for semi-supervised sentiment analysis",
            "venue": "Eighth ieee international conference on data mining,",
            "year": 2008
        },
        {
            "authors": [
                "Jasmina Smailovi\u0107",
                "Miha Gr\u010dar",
                "Nada Lavra\u010d",
                "Martin \u017dnidar\u0161i\u010d."
            ],
            "title": "Stream-based active learning for sentiment analysis in the financial domain",
            "venue": "Information sciences, 285:181\u2013203.",
            "year": 2014
        },
        {
            "authors": [
                "Richard Socher",
                "Alex Perelygin",
                "Jean Wu",
                "Jason Chuang",
                "Christopher D Manning",
                "Andrew Ng",
                "Christopher Potts."
            ],
            "title": "Recursive deep models for semantic compositionality over a sentiment treebank",
            "venue": "Proceedings of the 2013 conference on empirical",
            "year": 2013
        },
        {
            "authors": [
                "Kihyuk Sohn",
                "David Berthelot",
                "Nicholas Carlini",
                "Zizhao Zhang",
                "Han Zhang",
                "Colin A Raffel",
                "Ekin Dogus Cubuk",
                "Alexey Kurakin",
                "Chun-Liang Li."
            ],
            "title": "Fixmatch: Simplifying semi-supervised learning with consistency and confidence",
            "venue": "Advances in neural",
            "year": 2020
        },
        {
            "authors": [
                "Srishti Vashishtha",
                "Seba Susan."
            ],
            "title": "Fuzzy rule based unsupervised sentiment analysis from social media posts",
            "venue": "Expert Systems with Applications, 138:112834.",
            "year": 2019
        },
        {
            "authors": [
                "M.K. Kavitha K Vijaymeena"
            ],
            "title": "A survey on similarity measures in text mining",
            "venue": "Machine Learning and Applications: An International Journal, 3(1):19\u201328.",
            "year": 2016
        },
        {
            "authors": [
                "Jiapeng Wang",
                "Yihong Dong."
            ],
            "title": "Measurement of text similarity: A survey",
            "venue": "Information, 11(9).",
            "year": 2020
        },
        {
            "authors": [
                "Yidong Wang",
                "Hao Chen",
                "Qiang Heng",
                "Wenxin Hou",
                "Marios Savvides",
                "Takahiro Shinozaki",
                "Bhiksha Raj",
                "Zhen Wu",
                "Jindong Wang."
            ],
            "title": "Freematch: Selfadaptive thresholding for semi-supervised learning",
            "venue": "arXiv preprint arXiv:2205.07246.",
            "year": 2022
        },
        {
            "authors": [
                "Geoffrey I Webb",
                "Roy Hyde",
                "Hong Cao",
                "Hai Long Nguyen",
                "Francois Petitjean."
            ],
            "title": "Characterizing concept drift",
            "venue": "Data Mining and Knowledge Discovery, 30(4):964\u2013994.",
            "year": 2016
        },
        {
            "authors": [
                "Bing Xiang",
                "Liang Zhou."
            ],
            "title": "Improving twitter sentiment analysis with topic-based mixture modeling and semi-supervised training",
            "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume",
            "year": 2014
        },
        {
            "authors": [
                "Ju Xu",
                "Zhanxing Zhu."
            ],
            "title": "Reinforced continual learning",
            "venue": "Advances in Neural Information Processing Systems, 31.",
            "year": 2018
        },
        {
            "authors": [
                "Zichao Yang",
                "Diyi Yang",
                "Chris Dyer",
                "Xiaodong He",
                "Alex Smola",
                "Eduard Hovy."
            ],
            "title": "Hierarchical attention networks for document classification",
            "venue": "Proceedings of the 2016 Conference of the North American Chapter of the",
            "year": 2016
        },
        {
            "authors": [
                "Rowan Zellers",
                "Ari Holtzman",
                "Hannah Rashkin",
                "Yonatan Bisk",
                "Ali Farhadi",
                "Franziska Roesner",
                "Yejin Choi."
            ],
            "title": "Defending against neural fake news",
            "venue": "Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.",
            "year": 2019
        },
        {
            "authors": [
                "Bowen Zhang",
                "Yidong Wang",
                "Wenxin Hou",
                "Hao Wu",
                "Jindong Wang",
                "Manabu Okumura",
                "Takahiro Shinozaki."
            ],
            "title": "Flexmatch: Boosting semisupervised learning with curriculum pseudo labeling",
            "venue": "Advances in Neural Information Processing Systems,",
            "year": 2021
        },
        {
            "authors": [
                "Lei Zhang",
                "Shuai Wang",
                "Bing Liu."
            ],
            "title": "Deep learning for sentiment analysis: A survey",
            "venue": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 8(4):e1253.",
            "year": 2018
        },
        {
            "authors": [
                "Xiang Zhang",
                "Junbo Zhao",
                "Yann LeCun."
            ],
            "title": "Character-level Convolutional Networks for Text Classification",
            "venue": "arXiv:1509.01626 [cs].",
            "year": 2015
        },
        {
            "authors": [
                "Jichang Zhao",
                "Li Dong",
                "Junjie Wu",
                "Ke Xu."
            ],
            "title": "Moodlens: an emoticon-based sentiment analysis system for chinese tweets",
            "venue": "Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1528\u2013",
            "year": 2012
        },
        {
            "authors": [
                "Yukun Zhu",
                "Ryan Kiros",
                "Rich Zemel",
                "Ruslan Salakhutdinov",
                "Raquel Urtasun",
                "Antonio Torralba",
                "Sanja Fidler."
            ],
            "title": "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books",
            "venue": "2015",
            "year": 2015
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Online Sentiment Analysis (OSA) has established its significance in the realm of sentiment analysis, with its primary objective being the identification of polarity in ceaselessly incoming data streams (Capuano et al., 2021). This task requires proficiency in two key aspects: online adaptation and sentiment classification.\nThe requirement for online adaptation arises from the ever-evolving characteristics of real-time data streams, an effect commonly known as concept drift (Webb et al., 2016).\n\u2217Work done while the second author was interning at SUTD IntelliStream Group.\n\u2020Corresponding author. 1Our code is available at https://github.com/\nintellistream/SentiStream\nThis necessitates continuous model adaptation to maintain effectiveness. Simultaneously, sentiment classification, a core task within natural language processing (NLP), has found its cruciality in a myriad of sectors such as customer feedback interpretation and public opinion monitoring (Zhang et al., 2018). However, creating an OSA approach that can simultaneously handle online adaptation and sentiment classification remains a challenging feat.\nPrevious research (Vashishtha and Susan, 2019; Rahnama, 2014; Smailovic\u0301 et al., 2014; Go et al., 2009; Gautam and Yadav, 2014; Haque et al., 2018; Ortigosa et al., 2014) has indicated that supervised learning paradigms can yield high accuracy in sentiment analysis. Despite their strengths, these methods frequently overlook the ceaseless accumulation of real-world streaming data originating from varied sources like literature (Zhu et al., 2015), news articles (Zellers et al., 2019), and scientific papers (Lo et al., 2020). The constant emergence of this dynamic streaming data often leads to the concept drift effect, which can impair the performance of traditional offline methods (Luu et al., 2021). Continuous learning attempts to tackle concept drift and adapt to the ongoing data stream, but obtaining ground truth labels for this streaming data is often arduous and costly, which consequently limits the continuous application of supervised techniques and reduces their long-term efficacy.\nIn response to these challenges, we present SentiStream, a co-training framework tailored explicitly for efficient online sentiment analysis of swift-flowing opinion data. This framework consists of three modules: unsupervised, semisupervised, and stream merge. The unsupervised module uses continuously adapted pre-trained language models (PLMs) to distill knowledge from unlabeled streaming data, coupled with lexicon-based strategies to produce preliminary\npolarity labels. SentiStream harnesses semantic and temporal information from text-based data streams to incrementally retrain the PLMs, later employing a nimble lexicon-based classification method to generate polarity labels using the updated PLMs. The semi-supervised module constructs a weakly supervised classification model with a small labeled dataset and continuously retrains this model with pseudo-labels generated by the stream merge module. The final stream merge module consolidates outputs from the preceding two modules, utilizing their confidence scores to dynamically update the lexicon for the unsupervised module, providing pseudo-labeled data for semi-supervised learning and dynamically fine-tuning the threshold for the semi-supervised module.\nWe assessed the performance of SentiStream on five benchmark sentiment analysis datasets and juxtaposing its efficacy against several unsupervised and semi-supervised benchmarks. The experimental results confirm that our methodology considerably outperforms existing methods in tackling dynamic data streams for online sentiment analysis tasks. Additionally, SentiStream uses a lightweight model, ensuring superior throughput and latency performance.\nThe major contributions of our work can be summarized as:\n\u2022 The development of SentiStream, a novel co-training framework, devised specifically for proficient online sentiment analysis within dynamic data streams; \u2022 An unsupervised module that amalgamates the merits of continuously trained PLMs with lexicon-based classification techniques; \u2022 The implementation of a semi-supervised selflearning strategy, devised to optimize the usage of limited labelled data; \u2022 The unification of outputs through a stream merge technique, promoting collaborative learning to continuously adapt to dynamic stream data from various angles; \u2022 The employment of lightweight models, complemented by a series of optimizations, to fulfill online deployment requirements."
        },
        {
            "heading": "2 Related Work",
            "text": "In this section, we provide an overview of relevant literature on online sentiment analysis, continual learning, and semi-supervised learning, thereby laying the foundation for our proposed framework."
        },
        {
            "heading": "2.1 Sentiment Analysis",
            "text": "Online sentiment analysis has gained traction with the escalating volume of user-generated content on social media platforms and online forums. MoodLens, a system developed by Zhao et al. (2012), utilizes incremental learning to navigate sentiment shifts and new terminology. In the realm of online text messages, Fern\u00e1ndez-Gavilanes et al. (2016) introduced an unsupervised methodology, leveraging sentiment features from lexicons. For a more comprehensive approach, Iosifidis and Ntoutsi (2017) employed semi-supervised learning, drawing upon both labelled and unlabeled data, via Self-Learning and Co-Training. The research in offline sentiment analysis, particularly the remarkable results attained through deep learning architectures like CNNs and RNNs (Kim, 2014; Zhang et al., 2015), and the contributions of pretrained language models such as BERT and GPT (Devlin et al., 2018; Radford et al., 2018), are also worth noting. However, these offline methodologies often falter in adapting to the dynamic nature of online data streams, thereby compromising their performance. This emphasizes the need for specialized online sentiment analysis methods that can adapt fluidly to evolving data streams while maintaining performance levels."
        },
        {
            "heading": "2.2 Continual Learning",
            "text": "In contrast to traditional neural networks, which are viewed as static knowledge entities prone to catastrophic forgetting when knowledge expansion efforts veer off the original task, continual learning envisions networks capable of accruing knowledge across different tasks without requiring comprehensive retraining (De Lange et al., 2021). Prior research has primarily sought to address continual learning challenges within the frameworks of incremental class and task scenarios. The strategies used range from replay methods (Rebuffi et al., 2017; Lopez-Paz and Ranzato, 2017; Atkinson et al., 2018) and regularization-based techniques (Kirkpatrick et al., 2017; Ahn et al., 2019) to parameter isolation methods (Xu and Zhu, 2018; Fernando et al., 2017). In a noteworthy contribution, Jin et al. (2021) deployed distillationbased techniques for the continuous incremental pre-training of language models across diverse domain corpora. In the context of sentiment analysis, Ke et al. (2021) explored aspect-based sentiment analysis tasks across different domains\nthrough contrastive continual learning. However, these approaches often fail to address the temporal influence, as observed by Luu et al. (2021), where data drift over time can negatively impact model performance."
        },
        {
            "heading": "2.3 Semi-Supervised Learning",
            "text": "Semi-supervised learning, which involves model building using both labelled and unlabeled data, is of particular relevance in real-world scenarios where unlabeled data is plentiful and readily available, while labelled instances are relatively scarce (Ouali et al., 2020). Internet tweets and comments are prime examples that can greatly benefit from semi-supervised learning techniques (Silva et al., 2016). These techniques comprise a variety of methods such as graph-based (Sindhwani and Melville, 2008), wrapper-based (Li et al., 2020), and topic-based (Xiang and Zhou, 2014). More recent studies have delved into dynamic thresholds for semi-supervised techniques (Sohn et al., 2020; Wang et al., 2022), with Han et al. (2020) applying these methods to sentiment analysis. This research suggests an iterative autolabelling process anchored in a dynamic threshold algorithm, which takes into account both the quality and quantity of auto-labelled data when setting thresholds for their selection."
        },
        {
            "heading": "3 Proposed Methodology",
            "text": "Our proposed method, SentiStream, consists of two parallel sentiment classification modules and a shared output co-trainer: an unsupervised module, a semi-supervised module, and a stream merge module. The overall structure is shown in Figure 1.\nProblem Formulation: Our focus is on effectively conducting sentiment analysis of streaming opinion data in real-time. We define the term input stream as a sequence of tuples, referred to as S = T1, ..., TN , which arrive at our system in chronological order. Each tuple, denoted as T , consists of a finite number of sentences, xi, forming T =(x1 \u223c xm). The sentiment polarity is either positive or negative. Our goal with SentiStream is to learn and identify the polarity of T (x1 \u223c xm) \u2208 S as soon as Ti arrives."
        },
        {
            "heading": "3.1 Unsupervised Module",
            "text": "Due to potential delays between training cycles, the system might not be up-to-date with events and emerging knowledge (Bubeck et al., 2023). To\ncombat this, we employ two elements: continual pre-trained language model (PLM) training and a dynamic lexicon-based classifier.\nContinuous PLM Training: In our framework, the PLMs are subject to continuous training, a distinct departure from offline methods (Agarwal and Mittal, 2016; Haque et al., 2018) where PLMs can quickly fall behind as the vocabulary and polarity models evolve. Such offline methods necessitate periodic re-training with labelled datasets, an approach that our framework sidesteps. Our continual training ensures the PLMs remain updated, and capable of labelling sentences that contain even the most novel vocabulary.\nThe continual PLM training module leverages rich semantic and temporal information from the streaming textual data to incrementally train the models. Specifically, the streaming data is used to perpetually train the model using the pre-trained loss function in an unsupervised manner. The continuous learning aspect of our model means it can learn and refine sentence representations over time, thereby keeping in step with the evolving nature of the data stream. This unique approach allows the model to adapt more effectively to the dynamic language used in current data streams, ensuring it maintains relevance and accuracy.\nDynamic Lexicon-based Classifier: After we\u2019ve obtained the learned vector representations of each word, we suggest leveraging text similarity measures (Wang and Dong, 2020; Vijaymeena M.K, 2016; Navigli and Martelli, 2019) to infer the sentiment polarity of an input sentence. This is based on a list of reference words with pre-established polarities (Lin and He, 2009), as opposed to relying on supervised training progress for polarity identification.\nOur lexicon contains various emotion representations that we vectorize using our model. Subsequently, we conduct a cosine similarity computation (CSC) between the vectorized input and the mean of either the positive or negative reference words. The computed aggregated mean is referred to as Mean(pos) or Mean(neg). Ultimately, by comparing Mean(pos) and Mean(neg), we infer the overall polarity of the input tuple.\nHowever, the reference table may become obsolete over time. To address this issue, we dynamically update the lexicon using sentences from the stream merge module, where the model\u2019s\noutput confidence is high. The lexicon update algorithm, detailed in Algorithm 1, autonomously incorporates new words into the sentiment lexicon, eliminating the need for manual annotation of new data.\nWe establish a similarity threshold that offers a balance between the need to add new words and the risk of adding false positives to the reference table. Hence, new words are only added to the reference table if the cosine similarity between the lexicon and the word surpasses the similarity threshold.\nThrough this dynamic update process, our lexicon continuously reflects the prevailing ways emotions are expressed in everyday language. Our extensive experimental results demonstrate that this approach not only significantly reduces computational effort but also consistently outperforms alternative methods in terms of prediction accuracy."
        },
        {
            "heading": "3.2 Semi-Supervised Module",
            "text": "The semi-supervised module\u2019s primary goal is to efficiently utilize a limited amount of labeled data alongside a substantial amount of unlabeled data obtained from the streaming input, thereby promoting semi-supervised learning. To accomplish this, we use labelled data collected from the stream merge module to identify instances with high confidence, which are then used as pseudo-labels for the continual training of the semisupervised classifier.\nHowever, the ever-evolving nature of streaming data environments can make the acquisition of\nAlgorithm 1 Lexicon Update Input: Sentences S = {s1, s2, . . . sn}, Initial lexicon D = {Dpos, Dneg}, Similarity threshold \u03b1 Output: Updated lexicon D\u2032 = {D\u2032pos, D\u2032neg} Compute mean embedding of positive and negative lexicon. \u00b5pos =\n1 |Dpos| \u2211 d\u2208Dpos , \u00b5neg = 1 |Dneg| \u2211 d\u2208Dneg\nfor each sentence s in S do for each word w in s do\nCalculate cosine similarity between w and \u00b5pos if cos(w, \u00b5pos) > \u03b1 then\nAdd w to D\u2032pos end if Calculate cosine similarity between w and \u00b5neg if cos(w, \u00b5neg) > \u03b1 then\nAdd w to D\u2032neg end if\nend for end for\nreturn D\u2032 = {D\u2032pos, D\u2032neg}\naccurate and consistent pseudo-labels a challenging task. If changes occur within the dataset, it may be difficult for weakly supervised models to make accurate decisions. Likewise, static thresholds may not yield an adequate number of pseudo-labelled data under these changing conditions.\nDynamic Threshold: In order to overcome these challenges, we employ a dynamic threshold approach, as proposed in the study by Zhang et al. (2021). As shown in Algorithm 2, this method adjusts the threshold for each class based on the model\u2019s current learning status. The learning efficiency of a class is assessed by counting the number of samples whose predictions surpass the hard threshold, defined as the sum of the lower and\nupper thresholds. This count is then normalized by the maximum value of either the positive or negative learning effect or the number of lowconfidence labels. This approach is especially useful in the early learning stages when the learning effect is generally minimal, and a higher number of low-confidence labels would naturally lead to a more flexible threshold.\nFollowing this, we utilize a non-linear function to adjust the learning rate. Initially, this function incrementally increases the threshold, but it quickens the rise when both learning rates are high. This method allows for a more seamless and logical integration of data, thereby improving the quality of the produced pseudo-labelled data.\nAlgorithm 2 Dynamic Threshold Input: Pseudo labels P = {p1, . . . pn}, Confidence scores\nC = {c1, . . . cn}, Learning effect \u03bb = {\u03bbpos, \u03bbneg}, Fixed lower threshold \u03b1 = {\u03b1pos, \u03b1neg}, Fixed upper threshold \u03b2 = {\u03b2pos, \u03b2neg},\nOutput: Filtered pseudo labels P \u2032 = {p\u20321, . . . p\u2032m} pos\u2190 \u2211 c>\u03b1pos+\u03b2pos 1\nneg \u2190 \u2211\nc<\u2212(\u03b1neg+\u03b2neg) 1\nif pos+ neg > 0 then \u03b4 \u2190 max(|C| \u2212 (pos+ neg), pos, neg) \u03bbpos \u2190 (pos/\u03b4)/(2\u2212 pos/\u03b4) \u03bbneg \u2190 (neg/\u03b4)/(2\u2212 neg/\u03b4) end if for c\u2190 1 to n do\nif c \u2264 \u2212(\u03b1neg + \u03b2neg \u2217 \u03bbneg) or c \u2265 (\u03b1pos + \u03b2pos \u2217 \u03bbpos) then\nP \u2032 \u2190 pc end if\nend for\nreturn P \u2032 = {p\u20321, . . . p\u2032m}"
        },
        {
            "heading": "3.3 Stream Merge Module",
            "text": "The principal aim of the stream merge module is to competently amalgamate data and yield reliable pseudo-labelled data. To achieve this, we introduce a stream merge method hinging on confidence assessment. As depicted in Algorithm 3, this method merges data streams generated by two separate parts, selecting data points accurately classified (with high confidence) by both models to form pseudo-labels.\nThe algorithm dynamically adjusts the weights for each model, basing its decision on its previous prediction performance. A model demonstrating a higher ratio of high-confidence predictions will be allocated more weight in the subsequent iteration, thereby potentially improving its prediction accuracy while adapting to the\nAlgorithm 3 Stream Merge Input: Unsupervised model\u2019s predicted labels Ul =\nUl1 , . . . Uln , Unsupervised model\u2019s predicted confidence Uc = Uc1 , . . . Ucn , Semi-supervised model\u2019s predicted labels Sl = Sl1 , . . . Sln , Semi-supervised model\u2019s predicted confidence Sc = Sc1 , . . . , Scn Fixed confidence threshold T , Adaptive weight for unsupervised prediction Wu, Adaptive weight for semi-supervised prediction Ws\nOutput: Predictions P \u2032 = p\u20321, . . . p\u2032m for i\u2190 1 to n do\nif Uci > T and Sci > T then if Uci > Sci then\nP \u2032 \u2190 Uli else\nP \u2032 \u2190 Sli end if\nelse if Uci \u2217Wu > Sci \u2217Ws then\nP \u2032 \u2190 Uli else\nP \u2032 \u2190 Sli end if\nend if end for Wu \u2190 \u2211n i=1 Uci>T\nn Ws \u2190 \u2211n i=1 Sci>T\nn\nreturn P \u2032 = {p\u20321, . . . p\u2032n}\nmodels\u2019 performance over time. For every data point, the algorithm checks whether both models show high confidence in their predictions (surpassing a threshold T). If so, the prediction associated with the highest confidence score is selected. Otherwise, the algorithm multiplies the confidence scores by the adaptive weights for each model, and the prediction with the highest weighted confidence score is chosen.\nThis approach prioritizes labels with high confidence, which generally lead to correct labels, while also addressing the issue of inaccurate low-confidence labels. By multiplying the model\u2019s weight with low-confidence predictions, the algorithm ensures that even when predictions have low confidence, the highest-performing model is given more importance. This, in turn, contributes to making the overall prediction process more consistent and logical."
        },
        {
            "heading": "4 Experimental Setup",
            "text": ""
        },
        {
            "heading": "4.1 Datasets",
            "text": "In conducting our evaluation, we employed two distinct types of datasets to thoroughly assess the adaptability of SentiStream to dynamic data streams, each labeled according to specific classification rules. These datasets are delineated as follows:"
        },
        {
            "heading": "4.1.1 Multi-domain Evolving Datasets",
            "text": "Formulated by amalgamating three well-known, large-scale datasets, this construction simulates a dynamic data stream featuring evolving characteristics, thereby reflecting real-world data fluctuations across multiple domains and temporal spans.\nYelp Review Polarity (Zhang et al., 2015) was derived from the Yelp Dataset Challenge in 2015. Reviews were labeled as either positive, if they received 3 or 4 stars, or negative, if they received 1 or 2 stars.\nLarge Movie Review (LMRD) (Maas et al., 2011) was collected by the Artificial Intelligence Laboratory at Stanford University. This dataset contains movie reviews along with their associated binary sentiment polarity labels, serving as a benchmark for sentiment classification.\nStanford Sentiment Treebank-2 (SST2) (Socher et al., 2013) collected by Stanford University researchers. It consists of movie reviews extracted from Rotten Tomatoes parsed using Stanford parser with sentiment labels.\nWe evenly sample data from the three datasets, merging them in three different orders (1,Yelp \u2192 LMRD \u2192 SST-2; 2,LMRD \u2192 SST-2 \u2192 Yelp; 3, SST-2 \u2192 Yelp \u2192 LMRD) to simulate real-world data drift, with one of these scenarios illustrated in Figure 2."
        },
        {
            "heading": "4.1.2 Longitudinal Singular Domain Datasets",
            "text": "Incorporates two datasets with a longitudinal perspective within a single, consistent domain, providing insight into how SentiStream handles changes and shifts over time within the same data source\nSentiment140 (Go et al., 2009) was compiled using the Twitter API, encompassing a balanced distribution of 1.6 million tweets, expressed sentiments, and recorded in chronological order from April 6, 2009, to June 25, 2009.\nAmazon Fashion, a subset of the Amazon Review Data (Ni et al., 2019) and consists of customer reviews for fashion products available\non Amazon. These reviews were collected in chronological order in quarterly periods from 2010 to 2018."
        },
        {
            "heading": "4.2 Language Model Set",
            "text": "In this paper, we select some lightweight language model to achieve lower latency and higher throughput, in line with the industry\u2019s deployment preference for simple and efficient models. Galke and Scherp (2021) showed that combining a bag-of-words model with WideMLP resulted in exceptional performance in text classification tasks. Characterized by a single wide hidden layer, WideMLP outperforms numerous contemporary models in inductive text categorization. Furthermore, training large language models (e.g. BERT, GPT) on streaming data involves additional complexities and constraints, which we will discuss in Section 7. Therefore, here we choose Word2Vec (Mikolov et al., 2013) and Hierarchical Attention Networks (Yang et al., 2016) as the base models for unsupervised and semi-supervised learning, respectively. We also include BERT (Devlin et al., 2018) as a large-scale model for comparative testing."
        },
        {
            "heading": "4.3 Baselines",
            "text": "We compare the performance of the proposed model with diverse types of baselines such as random, supervised and self-supervised methods.\n\u2022 Random: At first, we present a random baseline where the predictions are generated using a uniform distribution. This will provide us with a lower bound for our evaluation.\n\u2022 Supervised: We train a supervised model by using 0.5% of the entire dataset as the training set. We chose BERT and HAN as the two base models for our experiments. This will provide us with an upper bound for our evaluation.\n\u2022 Self-supervised: The self-supervised framework used by (Iosifidis and Ntoutsi, 2017) employed co-training to improve the model performance.\n\u2022 Weakly-supervised: We select a weaklysupervised framework (CL-WSTC (Li et al., 2023)) that considers the scenario of continual learning for comparison. They employ BERT as the foundational model."
        },
        {
            "heading": "5 Experimental Evaluation",
            "text": "In this section, we study the performance of the different algorithms on three datasets, compare them with different baselines, and discuss the qualitative analysis of our model\u2019s performance."
        },
        {
            "heading": "5.1 Evaluation Framework",
            "text": "We evaluate our framework within an end-toend setup for real-time sentiment classification, with throughput, latency, accuracy, and streaming data adaptation serving as primary performance indicators. The task requires processing text data within specific time intervals and assigning the appropriate emotion labels. To verify the effectiveness of our framework, we will run experiments on integrated data streams. We designate 0.5% of the ongoing data stream as training data for our semi-supervised model and other supervised model, while the remaining portion is utilized as test data. This enables us to assess the performance at each stage and the overall performance. An ablation study provides insights into the unique effects of various optimizations, but due to space constraints, this has been relocated to Appendix A.1."
        },
        {
            "heading": "5.2 Evaluation Metrics",
            "text": "We evaluate the system with five performance metrics.\nThroughput. High throughput is a necessity to manage large-volume data streams. For instance, in the event of significant happenings, opinions on social media may suddenly surge. Thus, we measure throughput as the maximum number of input tuples per second that the system can sustain.\nLatency. We measure the 95% latency as the elapsed time from when the input tuple arrives to when the corresponding classification result is produced. It is an important indicator to denote the system\u2019s responsiveness.\nAccuracy. We define prediction accuracy as the ratio of correct predictions (the sum of true positives and true negatives) to the total number of tuples processed.\nF1-score & AUC. To evaluate the accuracy of the prediction in a workload with class imbalance, we also use the F1-score and AUC, which is the harmonic mean of precision and recall."
        },
        {
            "heading": "5.3 Experimental Results and Analysis",
            "text": ""
        },
        {
            "heading": "5.3.1 End-to-end comparison",
            "text": "Latency and Throughput: In Table 1, we can see that SentiStream surpasses self-supervised and weakly-supervised methods, in terms of latency and throughput. The BERT model\u2019s latency is nearly 100 times that of SentiStream. Moreover, the difference in throughput is especially pronounced, with SentiStream outperforming the BERT model by nearly an order of magnitude. This discrepancy can be ascribed to the stark contrast in the number of model parameters utilized by SentiStream compared to those used by the BERT model. As for the weakly-supervised method, it was initially developed without considering latency and throughput. Consequently, its approach tends to prioritize future accuracy enhancements, even if it potentially compromises latency and throughput."
        },
        {
            "heading": "5.3.2 Multi-domain Evolving Datasets",
            "text": "Overall Performance: Table 2 presents a comprehensive summary of our experimental results. Our framework, SentiStream, consistently exhibits excellent performance, occasionally even matching the supervised BERT baseline. In addition, the sentistream approach is always excellent with the supervised HAN and word2vec models. In terms of the F1 score, SentiStream substantially outperforms its counterparts, thereby showcasing the power of its co-training strategy for handling unbalanced data. The performance of the unsupervised component is particularly noteworthy, underscoring the bagof-words model\u2019s ability to produce satisfactory results, even in less complicated text classification tasks. As the data suggests, SentiStream\u2019s performance improves with extended offsets.\nAdaptation to Streaming Data: Figure 3 presents the dynamic performance of accuracy across the entire datasets, assessing the continual learning capability of our method. Initially, during the Yelp dataset stage, supervised learning shows\nremarkable performance, primarily due to the powerful capabilities intrinsic to BERT. However, when concept drift occurs, supervised learning fails to adapt and learn continuously (as it requires annotated data for model fine-tuning), leading to a decline in performance. This downward trend in performance becomes significantly evident during the final task involving the SST-2 dataset.\nSurprisingly, methods expected to demonstrate substantial continual learning capabilities, such as self-supervised learning and weakly supervised learning, did not meet the anticipated performance metrics. The underlying model for self-supervised learning is Bayesian, which might be too simple to effectively mine and extract valuable information. Upon closer examination of weakly supervised learning, a major issue was identified: the model\u2019s failure to properly integrate seed words during its operation in the online sentiment classification task. This problem is critical given the significant influence these seed words have on the model\u2019s performance.\nOn the contrary, SentiStream displays exceptional performance, consistently adapting to the evolving data distribution inherent to the data stream, thus promoting continuous performance improvement. A prime example is SentiStream\u2019s progressively improving performance throughout the SST dataset. It also demonstrated notable resilience in dealing with data drift. Such adaptability is particularly important in real-world scenarios where concept drift can occur in more complex forms.\nAccuracy Across Datasets"
        },
        {
            "heading": "5.3.3 Longitudinal Singular Domain Datasets",
            "text": "Overall Performance: With regard to the aggregate performance, SentiStream exhibits outstanding proficiency on both the Sentiment140 and Amazon Fashion datasets. Notably, SentiStream outperforms its rivals in metrics such as ACC, F1-score, and AUC.\nAdaptation to Streaming Data: As illustrated in Figures 4 and 5, there are notable performance shifts over time for the self-supervised, supervised, and SentiStream methodologies. In the context of Figure 4, SentiStream markedly distinguishes itself from the other two approaches. On the other hand, in Figure 5, early self-supervised and supervised methods initially lead the pack. However, as the data distribution shifted, for instance during the 2013-Q3 quarter, SentiStream leveraged its superior adaptability and took a comprehensive lead. In summary, SentiStream showcases commendable average performance\nand robust adaptability to streaming data in Longitudinal Singular Domain Datasets."
        },
        {
            "heading": "6 Conclusion",
            "text": "This paper introduced SentiStream, an adaptive co-training framework that efficiently tackles concept drift, latency, and throughput issues in dynamic data streams for online sentiment analysis. Through its integrated unsupervised, semi-supervised, and stream merge modules, SentiStream effectively manages continuous data stream evolution, a major challenge for existing methods. Continuous training and dynamic dictionary updates enhance SentiStream\u2019s adaptability to ever-changing data streams, proving its potential applicability in real-world scenarios. Experimental results demonstrated SentiStream\u2019s promising performance in online sentiment analysis across various data-driven applications. As a highly adaptable and efficient solution, SentiStream addresses the growing demand for real-time sentiment analysis in evolving online environments and data streams. Future work can build on this foundation, extending the application of the SentiStream framework to other dynamic, data-driven domains."
        },
        {
            "heading": "7 Limitation",
            "text": "A primary limitation of our study is the lack of integration with popular large-scale language models (e.g., GPT4 (OpenAI, 2023)). However, it is worth noting that employing these models entails increased computational resources and latency. Moreover, current large-scale language models\ncannot be trained on streaming data, presenting various challenges, such as computational resource utilization, real-time updates, data instability, hyperparameter tuning, storage and management, and system stability and reliability. Bubeck et al. (2023) also emphasizes the importance of continuous learning for LLM and indicates the need for further research and improvement, while our work can be seen as an initial, yet important attempt towards such a goal. Another practical issue is the absence of publicly available corpora categorized by domain or year, along with corresponding sentiment classification test sets. Moving forward, we aim to address this limitation by working with genuine large-scale language models trained on streaming data, showcasing their effectiveness in more complex tasks."
        },
        {
            "heading": "8 Acknowledgement",
            "text": "We would like to thank the anonymous reviewers, our meta-reviewer, and senior area chairs for their insightful comments and support with this work. This project is supported by TL@SUTD seed research project grant (RTDSS2214051) and the National Research Foundation, Singapore and Infocomm Media Development Authority under its Future Communications Research & Development Programme FCP-SUTD-RG2022-006. The computational work for this article was partially performed on resources of the National Supercomputing Centre (NSCC), Singapore (https://www.nscc.sg)."
        },
        {
            "heading": "A Appendix",
            "text": "A.1 Ablation Study To assess the contribution of each proposed method in improving the performance of our semi-supervised learning model, we conducted an ablation study, as shown in Table 7. The study aimed to evaluate the contributions of dynamic lexicon update and dynamic threshold, as well as their combination, in enhancing sentiment analysis performance. The study consisted of four model variations, namely the baseline model, the model with dynamic lexicon update, the model with dynamic threshold, and the model combining both dynamic lexicon update and dynamic threshold.\nBy conducting this experiment, we sought to provide empirical evidence regarding the effectiveness of these methods and their impact on sentiment analysis performance. Understanding the contributions of dynamic lexicon update and dynamic threshold, both individually and in combination, can guide the development of more accurate and robust sentiment analysis models, especially in scenarios with limited labeled data availability.\nBaseline Model: The baseline model served as starting point for comparison. It employed a fixed threshold method with the upper threshold set to 0.8 for filtering pseudo labels and did not incorporate dynamic lexicon update or dynamic threshold.\nModel with Dynamic Lexicon Update: In this variation, we introduced dynamic lexicon update to the baseline model while maintaining fixed threshold for pseudo label filtering. It is aimed to leverage an evolving lexicon to enhance sentiment classification. Similarity threshold (\u03b1) was varied to explore its impact on the model\u2019s performance. Specifically, we experimented with three values of \u03b1: 0.7, 0.8 and 0.9.\nModel with Dynamic Threshold: This variation incorporated dynamic thresholding into the baseline model, but did not involve lexicon updates. It allowed for adaptively adjusting the threshold for pseudo label filtering based on the model\u2019s predictions. We examined the effects of different upper threshold values (T) on the model\u2019s performance. The same three values of T (0.7, 0.8, and 0.9) used in the previous variation were employed.\nModel with Combined Dynamic Lexicon Update and Dynamic Threshold: In the final variation, we combined both dynamic lexicon\nupdate and dynamic threshold in the baseline model. This comprehensive approach aimed to leverage the benefits of both techniques simultaneously. For this variation, we fixed the similarity threshold at 0.9 and the upper threshold at 0.8.\nThe results clearly demonstrate that the combined model outperforms the other variations, indicating the effectiveness of leveraging both dynamic lexicon update and dynamic thresholding for improved sentiment analysis performance.\nA.2 Device Setting This is information about the device currently used in the experiment.\nA.3 Word List Table 5 shows the initial word list, used in Algorithm 1.\nA.4 Distribution of Sentiments in Datasets\nA.5 Additional Results A.5.1 More Training Data Evaluation Results We used more as (1%) of the total training data, although this is probably the more rare case. In the\nresults, the supervised effect of BERT is better due to having more training data, but still inevitably followed by a significant drop on the SST-2 dataset as indicated in table 8.\nA.5.2 Multi-domain Evolving Datasets We conducted comprehensive experiments involving various combinations of datasets to evaluate the performance of our method compared to different baselines. Notably, our method consistently outperformed the alternative baselines in all combinations. Specifically, we examined the Yelp \u2192 LMRD \u2192 SST-2, LMRD \u2192 SST-2 \u2192 Yelp and SST-2 \u2192 Yelp \u2192 LMRD combinations, as illustrated in Table 9, Table 10, Table 11 respectively. The superior effectiveness of our method in addressing the research problem is demonstrated by its consistent performance across various dataset arrangements.\nA.5.3 Longitudinal Singular Domain Datasets Table 12 and Table 13 present the ACC, F1, AUC, throughput, and latency metrics for longitudinal singular domain datasets. Figure 4 and 5 depict the temporal trends of supervised, semi-supervised, and SentiStream performance on Longitudinal Singular Domain Datasets, specifically Sentiment\n140 and Amazon Fashion. The SentiStream demonstrates notable average performance and robust adaptability to streaming data within these datasets."
        }
    ],
    "title": "SentiStream: A Co-Training Framework for Adaptive Online Sentiment Analysis in Evolving Data Streams",
    "year": 2023
}