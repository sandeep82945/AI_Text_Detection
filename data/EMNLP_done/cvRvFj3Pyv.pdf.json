{
    "abstractText": "Empathy plays an important role in the human dialogue. Detecting the empathetic direction expressed by the user is necessary for empathetic dialogue systems because it is highly relevant to understanding the user\u2019s needs. Several studies have shown that empathy intent information improves the ability to response capacity of empathetic dialogue. However, the interaction between empathy detection and empathy intent recognition has not been explored. To this end, we invite 3 experts to manually annotate the healthy empathy detection datasets IEMPATHIZE and TwittEmp with 8 empathy intent labels, and perform joint training for the two tasks. Empirical study has shown that the introduction of empathy intent recognition task can improve the accuracy of empathy detection task, and we analyze possible reasons for this improvement. To make joint training of the two tasks more challenging, we propose a novel framework, Cascaded Label Signal Network, which uses the cascaded interactive attention module and the label signal enhancement module to capture feature exchange information between empathy and empathy intent representations. Experimental results show that our framework outperforms all baselines under both settings on the two datasets. 1",
    "authors": [
        {
            "affiliations": [],
            "name": "Liting Jiang"
        },
        {
            "affiliations": [],
            "name": "Di Wu"
        },
        {
            "affiliations": [],
            "name": "Bohui Mao"
        },
        {
            "affiliations": [],
            "name": "Yanbing Li"
        },
        {
            "affiliations": [],
            "name": "Wushour Slamu"
        }
    ],
    "id": "SP:23c7f2ee329c47f7b3910d7b6ac813f33c3a9e02",
    "references": [
        {
            "authors": [
                "Firoj Alam",
                "Morena Danieli",
                "Giuseppe Riccardi."
            ],
            "title": "Annotating and modeling empathy in spoken conversations",
            "venue": "Computer Speech and Language, 50(C):40\u201361.",
            "year": 2018
        },
        {
            "authors": [
                "MK Ayshabi",
                "Sumam Mary Idicula."
            ],
            "title": "A multiresolution mechanism with multiple decoders for empathetic dialogue generation",
            "venue": "2021 8th International Conference on Smart Computing and Communications (ICSCC), pages 240\u2013245. IEEE.",
            "year": 2021
        },
        {
            "authors": [
                "Guanqun Bi",
                "Yanan Cao",
                "Piji Li",
                "Yuqiang Xie",
                "Fang Fang",
                "Zheng Lin."
            ],
            "title": "Seri: Sketchingreasoning-integrating progressive workflow for empathetic response generation",
            "venue": "ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech",
            "year": 2023
        },
        {
            "authors": [
                "Sven Buechel",
                "Anneke Buffone",
                "Barry Slaff",
                "Lyle Ungar",
                "Jo\u00e3o Sedoc."
            ],
            "title": "Modeling empathy and distress in reaction to news stories",
            "venue": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4758\u20134765.",
            "year": 2018
        },
        {
            "authors": [
                "Hila Chefer",
                "Shir Gur",
                "Lior Wolf."
            ],
            "title": "Transformer interpretability beyond attention visualization",
            "venue": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 782\u2013791.",
            "year": 2021
        },
        {
            "authors": [
                "Mao Yan Chen",
                "Siheng Li",
                "Yujiu Yang."
            ],
            "title": "Emphi: Generating empathetic responses with humanlike intents",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
            "year": 2022
        },
        {
            "authors": [
                "Zhuohao Chen",
                "James Gibson",
                "Ming-Chang Chiu",
                "Qiaohong Hu",
                "Tara K Knight",
                "Daniella Meeker",
                "James A Tulsky",
                "Kathryn I Pollak",
                "Shrikanth Narayanan"
            ],
            "title": "Automated empathy detection for oncology",
            "year": 2020
        },
        {
            "authors": [
                "Pascale Fung",
                "Anik Dey",
                "Farhad Bin Siddique",
                "Ruixi Lin",
                "Yang Yang",
                "Yan Wan",
                "Ho Yin Ricky Chan."
            ],
            "title": "Zara the supergirl: An empathetic personality recognition system",
            "venue": "Proceedings of the 2016 Conference of the North American Chapter of the",
            "year": 2016
        },
        {
            "authors": [
                "Jun Gao",
                "Yuhan Liu",
                "Haolin Deng",
                "Wei Wang",
                "Yu Cao",
                "Jiachen Du",
                "Ruifeng Xu."
            ],
            "title": "Improving empathetic response generation by recognizing emotion cause in conversations",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021,",
            "year": 2021
        },
        {
            "authors": [
                "Soumitra Ghosh",
                "Dhirendra Maurya",
                "Asif Ekbal",
                "Pushpak Bhattacharyya."
            ],
            "title": "Team iitp-ainlpml at wassa 2022: Empathy detection, emotion classification and personality detection",
            "venue": "Proceedings of the 12th Workshop on Computational Approaches to Sub-",
            "year": 2022
        },
        {
            "authors": [
                "Mahshid Hosseini",
                "Cornelia Caragea."
            ],
            "title": "Distilling knowledge for empathy detection",
            "venue": "Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3713\u20133724.",
            "year": 2021
        },
        {
            "authors": [
                "Mahshid Hosseini",
                "Cornelia Caragea."
            ],
            "title": "It takes two to empathize: One to seek and one to provide",
            "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 13018\u201313026.",
            "year": 2021
        },
        {
            "authors": [
                "Jacob Devlin Ming-Wei Chang Kenton",
                "Lee Kristina Toutanova."
            ],
            "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "venue": "Proceedings of NAACL-HLT, pages 4171\u20134186.",
            "year": 2019
        },
        {
            "authors": [
                "Hamed Khanpour",
                "Cornelia Caragea",
                "Prakhar Biyani."
            ],
            "title": "Identifying empathetic messages in online health communities",
            "venue": "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers),",
            "year": 2017
        },
        {
            "authors": [
                "Wongyu Kim",
                "Youbin Ahn",
                "Donghyun Kim",
                "KyongHo Lee."
            ],
            "title": "Emp-rft: Empathetic response generation via recognizing feature transitions between utterances",
            "venue": "Proceedings of the 2022 Conference of the North American Chapter of the Association",
            "year": 2022
        },
        {
            "authors": [
                "Diederik P. Kingma",
                "Jimmy Ba."
            ],
            "title": "Adam: A method for stochastic optimization",
            "venue": "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.",
            "year": 2015
        },
        {
            "authors": [
                "Araya",
                "Siqi Yan"
            ],
            "title": "Captum: A unified and generic model interpretability library for pytorch",
            "venue": "arXiv preprint arXiv:2009.07896",
            "year": 2020
        },
        {
            "authors": [
                "Tsung-Yi Lin",
                "Priya Goyal",
                "Ross Girshick",
                "Kaiming He",
                "Piotr Doll\u00e1r."
            ],
            "title": "Focal loss for dense object detection",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 42(2):318\u2013327.",
            "year": 2018
        },
        {
            "authors": [
                "L Medeiros",
                "T Bosse."
            ],
            "title": "Empirical analysis of social support provided via social media",
            "venue": "Proceedings of the 8th International Conference on Social Informatics, SocInfo\u201916, pages 439\u2013453. Springer Verlag.",
            "year": 2016
        },
        {
            "authors": [
                "Ver\u00f3nica P\u00e9rez-Rosas",
                "Rada Mihalcea",
                "Kenneth Resnicow",
                "Satinder Singh",
                "Lawrence An."
            ],
            "title": "Understanding and predicting empathic behavior in counseling therapy",
            "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Lin-",
            "year": 2017
        },
        {
            "authors": [
                "Libo Qin",
                "Wanxiang Che",
                "Yangming Li",
                "Mingheng Ni",
                "Ting Liu."
            ],
            "title": "Dcr-net: A deep co-interactive relation network for joint dialog act recognition and sentiment classification",
            "venue": "Proceedings of the AAAI conference on artificial intelligence, volume 34,",
            "year": 2020
        },
        {
            "authors": [
                "Libo Qin",
                "Zhouyang Li",
                "Wanxiang Che",
                "Minheng Ni",
                "Ting Liu."
            ],
            "title": "Co-gat: A co-interactive graph attention network for joint dialog act recognition and sentiment classification",
            "venue": "Proceedings of the AAAI conference on artificial intelligence, volume 35,",
            "year": 2021
        },
        {
            "authors": [
                "Tulika Saha",
                "Sophia Ananiadou."
            ],
            "title": "Emotionaware and intent-controlled empathetic response generation using hierarchical transformer network",
            "venue": "2022 International Joint Conference on Neural Networks (IJCNN), pages 1\u20138. IEEE.",
            "year": 2022
        },
        {
            "authors": [
                "Azlaan Mustafa Samad",
                "Kshitij Mishra",
                "Mauajama Firdaus",
                "Asif Ekbal."
            ],
            "title": "Empathetic persuasion: Reinforcing empathy and persuasiveness in dialogue systems",
            "venue": "Findings of the Association for Computational Linguistics: NAACL 2022, pages 844\u2013856.",
            "year": 2022
        },
        {
            "authors": [
                "Jo\u00e3o Sedoc",
                "Sven Buechel",
                "Yehonathan Nachmany",
                "Anneke Buffone",
                "Lyle Ungar."
            ],
            "title": "Learning word ratings for empathy and distress from document-level user responses",
            "venue": "Proceedings of the 12th Language Resources and Evaluation Conference, pages 1664\u2013",
            "year": 2020
        },
        {
            "authors": [
                "Ashish Sharma",
                "Adam Miner",
                "David Atkins",
                "Tim Althoff."
            ],
            "title": "A computational approach to understanding empathy expressed in text-based mental health support",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
            "year": 2020
        },
        {
            "authors": [
                "Laurens Van der Maaten",
                "Geoffrey Hinton."
            ],
            "title": "Visualizing data using t-sne",
            "venue": "Journal of machine learning research, 9(11).",
            "year": 2008
        },
        {
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N Gomez",
                "\u0141ukasz Kaiser",
                "Illia Polosukhin."
            ],
            "title": "Attention is all you need",
            "venue": "Advances in neural information processing systems, 30.",
            "year": 2017
        },
        {
            "authors": [
                "M. Virvou",
                "G. Katsionis."
            ],
            "title": "Relating error diagnosis and performance characteristics for affect perception and empathy in an educational software application",
            "venue": "pages 22\u201327.",
            "year": 2004
        },
        {
            "authors": [
                "Anuradha Welivita",
                "Pearl Pu."
            ],
            "title": "A taxonomy of empathetic response intents in human social conversations",
            "venue": "Proceedings of the 28th International Conference on Computational Linguistics, pages 4886\u2013 4899.",
            "year": 2020
        },
        {
            "authors": [
                "Anuradha Welivita",
                "Yubo Xie",
                "Pearl Pu."
            ],
            "title": "A large-scale dataset for empathetic response generation",
            "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1251\u20131264.",
            "year": 2021
        },
        {
            "authors": [
                "Akmal Setiawan Wijaya",
                "Dhomas Hatta Fudholi",
                "Ahmad R Pratama."
            ],
            "title": "A computational approach in analyzing the empathy to online donations during covid-19",
            "venue": "MATRIK: Jurnal Manajemen, Teknik Informatika dan Rekayasa Komputer, 22(2):185\u2013194.",
            "year": 2023
        },
        {
            "authors": [
                "AC de C Williams",
                "A Cano."
            ],
            "title": "Facing others in pain: the effects of empathy",
            "venue": "Pain, 118(3):285\u2013288.",
            "year": 2005
        },
        {
            "authors": [
                "Yubo Xie",
                "Pearl Pu."
            ],
            "title": "Empathetic dialog generation with fine-grained intents",
            "venue": "Proceedings of the 25th Conference on Computational Natural Language Learning, pages 133\u2013147.",
            "year": 2021
        },
        {
            "authors": [
                "\u00d6zge Nilay Yalcin",
                "Steve DiPaola."
            ],
            "title": "A computational model of empathy for interactive agents",
            "venue": "Biologically inspired cognitive architectures, 26:20\u2013",
            "year": 2018
        },
        {
            "authors": [
                "Diyi Yang",
                "Robert E Kraut",
                "Tenbroeck Smith",
                "Elijah Mayfield",
                "Dan Jurafsky"
            ],
            "title": "Seekers, providers, welcomers, and storytellers: Modeling social roles in online health communities",
            "venue": "In Proceedings of the 2019 CHI conference on human factors",
            "year": 2019
        },
        {
            "authors": [
                "Xiaodong Zhang",
                "Houfeng Wang."
            ],
            "title": "A joint model of intent determination and slot filling for spoken language understanding",
            "venue": "Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, pages 2993\u20132999.",
            "year": 2016
        },
        {
            "authors": [
                "Naitian Zhou",
                "David Jurgens."
            ],
            "title": "Condolence and empathy in online communities",
            "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 609\u2013 626.",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Empathy is essential in human social interaction. In the process of human dialogue, empathy enables listeners to establish rapport with speakers by understanding their emotional and cognitive states, arousing their interest, and comforting them (Kim et al., 2022). Therefore, it is worthwhile to detect the empathetic direction of dialogue utterances. In recent years, researchers have studied empathy detection in various fields, such as mental health support (Sharma et al., 2020; Zhou and\n\u2217Corresponding author. 1https://github.com/JiangT7/CLSN\nJurgens, 2020), empathetic expression understanding in newswire (Buechel et al., 2018), medical and healthcare (Khanpour et al., 2017; Hosseini and Caragea, 2021a; Chen et al., 2020; Wijaya et al., 2023), human-computer interaction (Virvou and Katsionis, 2004; Xie and Pu, 2021; Gao et al., 2021; Samad et al., 2022), etc.\nCurrently, millions of people seek psychological support by expressing their emotions in online health communities and look forward to receiving support from peers who may have had similar experiences and can understand their feelings. Therefore, some researchers have performed studies on the direction of empathy expression in people\u2019s utterances. For example, the utterance: \"I lost my mom to cancer in April and just miss her so much. There are so many pieces to work on and I find it so hard to work on bc my grief is so strong\". The model needs to detect the direction of empathy expressed by the user, \u2018Seek\u2019. Hosseini and Caragea (2021a) provided an online healthy dataset and a baseline for empathy detection (ED), but their methods are monotonous, as shown in Figure 1 (a). They did not consider that humans have potential empa-\nthy intent information while expressing empathy. Chen et al. (2022) learned the distribution of potential empathy intent and then combined implicit and explicit representations of empathy intent to generate responses with empathy intent. However, they do not explore the interaction between empathy and empathy intent representations.\nIn this paper, we invite 3 experts to manually annotate the empathy intent of each utterance in two empathy detection datasets IEMPATHIZE (Hosseini and Caragea, 2021b) and TwittEmp (Hosseini and Caragea, 2021a) according to the lexicon of empathy intent example utterance provided by Welivita and Pu (2020). On this basis, we use a simple joint training method to test the feasibility of empathy intent recognition (EIC) as an auxiliary task, as shown in Figure 1 (b). The experimental results show that the joint training of ED and EIC leads to higher accuracy of ED, and we find that the categories of ED are easier to distinguish after the introduction of EIC due to the obvious correspondence between empathy and empathy intent labels. To make joint training tasks more challenging, we propose a novel framework, called Cascaded Label Signal Network (CLSN). First, it uses the BERT (Kenton and Toutanova, 2019) model to obtain the semantic features of utterances and extracts different representations through two linear layers. Then, the cascaded interactive attention module is used to implement feature interaction and control knowledge flow. Finally, the label signal enhancement module is used to further extract interactive features from the label information of the two tasks and feed them to different decoders to complete ED and EIC. We model the interaction information flow between both tasks, as shown in Figure 1(c).\nOverall, our contributions are as follows: (1) We invite 3 experts to manually annotate empathy intent labels on the ED datasets IEMPATHIZE and TwittEmp, provide the necessary datasets for the joint ED and EIC study; (2) To the best of our knowledge, we are the first to attempt joint training of the ED and EIC tasks to improve the accuracy of the ED task. We also explore the possible reasons for the accuracy improvement; (3) To make joint training of the two tasks more challenging, we propose a novel framework, CLSN, which explicitly controls the knowledge transfer between the two tasks. Experimental results show that our framework outperforms all baselines under both settings in the two datasets."
        },
        {
            "heading": "2 Related Work",
            "text": ""
        },
        {
            "heading": "2.1 Empathy Detection",
            "text": "Empathy detection, one of a series of empathy tasks, has been widely studied by many researchers (Hosseini and Caragea, 2021a; Chen et al., 2020). Currently, the task involves two types of research: analyzing empathy from text (Yang et al., 2019; Buechel et al., 2018; Sedoc et al., 2020; Ghosh et al., 2022), and from spoken dialogues (Fung et al., 2016; Kim et al., 2022; Alam et al., 2018; P\u00e9rez-Rosas et al., 2017; Ayshabi and Idicula, 2021). Empathy plays an important role in online health communities (Medeiros and Bosse, 2016) as it can facilitate the healing process by reducing psychological distress and increasing optimism through empathetic dialogue (Yalcin and DiPaola, 2018; Williams and Cano, 2005). Sharma et al. (2020) used a RoBERTa-based bi-encoder model to identify empathy in conversations on online mental health platforms. Khanpour et al. (2017) proposed a model based on Convolutional Networks and Long Short-Term Memory to identify empathetic messages in online health communities. Alam et al. (2018) proposed an Italian spoken empathetic dialogue system consisting only of paired conversations between patient and therapist in different audio. Bi et al. (2023) defined an empathy planner to capture and reason about multi-source information that considers cognition and affection. They also introduced a dynamic integrator module that allows the model dynamically select the appropriate information to generate empathetic responses."
        },
        {
            "heading": "2.2 Empathy Intent Recognition",
            "text": "Some empathetic dialogue generation studies incorporate empathy intent information, such as, Welivita and Pu (2020) have manually labeled 500 response intents. Using lexical and machine learning methods, they automatically analyzed utterances of the entire dataset with identified response intents and 32 emotion categories, and the information visualization method is used to summarize the emotional dialogue exchange model and its temporal evolution. Welivita et al. (2021) curated a novel large-scale silver dialogue dataset, EDOS (Emotional Dialogues in OpenSubtitles). It contains 1 million movie subtitles for emotional dialogue, with 32 fine-grained emotions, 8 intent categories, and a neutral category. Saha and Ananiadou (2022) proposed a fusion model of the Transformer model and the Hierarchical Encoder Decoder, called the\nHierarchical Transformer Network, to capture the speaker\u2019s emotion and dialogue context. To generate intent controlled empathetic responses, they used the results of Reinforcement Learning to implicitly optimize rewards."
        },
        {
            "heading": "3 Empirical Study",
            "text": "In this section, we introduce EIC as an auxiliary task in the ED task to verify its effectiveness. In addition, we explore the reasons for the influence of the EIC task on ED."
        },
        {
            "heading": "3.1 Problem Definition",
            "text": "Both ED and EIC can be regarded as classification tasks. Given an utterance U = (u1, u2, \u00b7 \u00b7 \u00b7 , us), the ED task detects the direction of empathy based on the U , and the EIC task identifies the potential empathy intent of the user based on the U ."
        },
        {
            "heading": "3.2 Dataset and Annotation",
            "text": "IEMPATHIZE2 containing sentences from online cancer survivors. It contains 5007 sentences, 3 empathy labels: \u2018Seek\u2019, \u2018provide\u2019 and \u2018None\u2019. In total, 1046 sentences are annotated as \u2018Seek\u2019, 966 as \u2018provide\u2019, and 2995 as \u2018None\u2019. To introduce the EIC task, we annotate the intent labels on the empathy detection dataset. Inspired by Welivita and Pu (2020); Chen et al. (2022), we identify 7 empathy intent labels: \u2018Acknowledging\u2019, \u2018Consoling\u2019, \u2018Questioning\u2019, \u2018Sympathizing\u2019, \u2018Wishing\u2019, \u2018Positive\u2019, \u2018Negative\u2019 and \u2018Neutral\u2019 (all other unmentioned intents) by observing the IEMPATHIZE dataset. We recruit 3 experts to assign an empathy intent label to each utterance in the IEMPATHIZE dataset in combination with the lexicon of intent labels example utterance provided by Welivita and Pu (2020). The first round of annotation is completed by 2 experts, and Cohen\u2019s kappa coefficient is 88.4% for the empathy intent of the IEMPATHIZE dataset. For samples with inconsistent annotation, the 3rd expert decided which category the empathy intent belonged to. The distribution of the dataset is shown in Figure 2 (a).\nFollowing previous work (Hosseini and Caragea, 2021a,b), we use both settings to create classifiers. The binary setting is used to identify utterances that seek empathy or provide empathy. For example, To create the seek-classifier, we set \u2018Seek\u2019 as positive samples, \u2018None\u2019 and \u2018Provide\u2019 as negative samples. The provide-classifiers is created in similar way as\n2https://github.com/Mahhos/Empathy\nseek-classifier. The multi-class setting considers three classes. In experiments, we split the dataset, keeping 60% of the data for the training set, 20% for the validation set, and 20% for the test set. See Appendix A for detailed statistics."
        },
        {
            "heading": "3.3 Empirical Study Results",
            "text": "Following the work of (Hosseini and Caragea, 2021b), BERT is used as a shared encoder to train the two tasks together and decode the hidden states separately to get the results of both tasks. We preexperiment with IEMPATHIZE under both settings.\nTable 1 shows a significant improvement in ED accuracy when the EIC task is introduced. The F1score of the ED improved by 1.74%, 2.79%, and 5.61% under the both settings, demonstrating that implementing joint learning between EIC and ED can improve the performance of the ED task."
        },
        {
            "heading": "3.4 Analysis of Reasons for Improvement",
            "text": "The accuracy of the ED task has improved substantially, and two questions are asked to explore the reasons for the improvement. Question (1): After the introduction of the EIC task, why did the accuracy of the ED task improve significantly? Question (2): How does the introduction of the EIC task help to improve the accuracy of ED? For Question (1): In terms of whether the introduction of the EIC task improves the performance of the model, we performed visualization on the test set of the IEMPATHIZE dataset (multi-class). The T-SNE (Van der Maaten and Hinton, 2008) results are shown in Figure 3.\nThe T-SNE results for the introduced EIC task are shown in Figure 3 (b). The categories \u2018Provides\u2019 and \u2018Seek\u2019 are more discriminable. In addition, the three categories are more aggregated. This demonstrates the ability of the model to learn a better representation of the hidden state after the introduction of the EIC task, which is one of the important reasons for the accuracy gains achieved. For Question (2): We count the frequency of cooccurrence of different labels in the IEMPATHIZE training dataset, as shown in Table 2.\nFrom Table 2 we can see that when the empathy intent label is \u2018Acknowledging\u2019, \u2018Neutral\u2019, \u2018Questioning\u2019 or \u2018Positive\u2019, the empathy label is more likely to be \u2018None\u2019, the empathy intent label is \u2018Negative\u2019, the empathy label is more likely to be \u2018Seek\u2019, the empathy intent label is \u2018Consoling\u2019, \u2018Wishing\u2019, \u2018Sympathizing\u2019, or \u2018Positive\u2019, the empathy label is more likely to be \u2018Provide\u2019. For example: \"I am sorry to hear about your mother-in-law\u2019s troubles after her diagnosis, I am sympathetic\", the word \u2018sympathetic\u2019 reflects the empathy intent of \u2018Sympathizing\u2019 and expresses the direction of empathy as \u2018Provide\u2019. The EIC channel shares the captured semantics with the ED channel which can help the ED channel to better perceive the empathy information contained in the utterance. Intuitively, since\nthere are 8 possible empathy intent labels for an utterance and only 3 possible empathy labels, it is harder to accurately identify the empathy intent label of an utterance than it is to identify the empathy label. Once the model correctly predicts the empathy intent label of the utterance, the model is able to more accurately identify the empathy label of the utterance based on the apparent correspondence of the two labels cooccurrence frequency in Table 2. Figure 4 shows some cases, and we can see that the simultaneous occurrence of the two labels is consistent with the co-occurrence frequency in Table 2. The empirical study is able to correctly predict the empathy labels of the three utterances, demonstrating that the introduction of the EIC task can help the model to improve the performance of ED tasks.\nWe use the same data annotation approach to annotate TwittEmp3. The Cohen\u2019s kappa coefficient is 80.0%, The distribution of the dataset is shown in Figure 2 (b). TwittEmp was collected from Twitter on cancer topics and there are a total of 3000 sentences. The category labels are the same as IEMPATHIZE, where 1000 sentences are annotated as \"Seek\", 1000 as \"Provide\", and 1000 as \"None\".\nAlthough the joint training method can improve the accuracy of the ED task, the modeling approach does not explicitly control the information flow between ED and EIC. To address this shortcoming and to make the joint training of the two tasks more challenging, we propose a novel framework in section 4."
        },
        {
            "heading": "4 Methodology",
            "text": "In this section, we provide a detailed description of the CLSN, which can effectively model the interaction between empathy and empathy intent representations. It consists of an encoding layer (\u00a74.1), a cascaded interactive attention module (\u00a74.2), a la-\n3https://github.com/Mahhos/KDempathy\nbel signal enhancement module (\u00a74.3), and two separate classification decoders (\u00a74.4). An overview of our framework is shown in Figure 5."
        },
        {
            "heading": "4.1 Encoding Layer",
            "text": "In our framework, ED shares an encoder with EIC. Given an utterance U , we first mark [CLS] and [SEP ] at the beginning and end of the utterance and then use the pre-trained language model BERT (bert-base-uncased) to encode the semantic utterance to capture contextual semantic information.\nH = BERT ([CLS] + U + [SEP ]) , (1)\nwhere H \u2208 Rd, and d denotes the hidden dimension. During the empirical study, we have found that the model can learn the task representation by itself, even without the additional label representation as an auxiliary feature guide. Therefore, before modeling the interaction between the two tasks of ED and EIC, we obtain different features of text encoding through two fully connected layers to allow the model to learn empathy and empathy intent representations by itself.\nH\u03b4 = FC\u03b4 (H) , (2)\nwhere \u03b4 \u2208 {I, E}, I denotes empathy intent and E denotes empathy, respectively. FC denotes a fully connected layer, HE and HI are empathy and empathy intent representations, respectively."
        },
        {
            "heading": "4.2 Cascaded Interactive Attention Module",
            "text": "The approach of simply sharing the hidden state is not sufficient to achieve explicit information transfer between two tasks. Therefore, we design a cascade of interactive attention modules. It can explicitly model the interaction between ED and EIC tasks. By this method, interactive information is continuously extracted features between tasks and finally returns to the original task to complete the cascade operation.\nTo make the two tasks learn features from each other, we use the attention mechanism (Vaswani et al., 2017) to connect the two tasks. First, we map the matrices HE and HI by linear projection to obtain the corresponding Q, K, V, respectively. Then the attention mechanism is used to obtain the corresponding empathy representation HE\u2212I with empathy intent features and empathy intent representation HI\u2212E with empathy features, respectively. At the same time, we use the empathy and empathy intent representations combined with HI\u2212E and HE\u2212I respectively to construct the attention layer to obtain the cascaded interaction features HE\u2212I\u2212E and HI\u2212E\u2212I .\nH\u03b3\u2212\u03b4 = Attention (H\u03b3 ,H\u03b4,H\u03b4) , (3)\nH\u03b4\u2212\u03b3\u2212\u03b4 = Attention (H\u03b4,H\u03b3\u2212\u03b4,H\u03b3\u2212\u03b4) , (4)\nwhere \u03b3 and \u03b4 \u2208 {I, E}, if \u03b3 denotes E, then \u03b4 denotes I, and vice versa."
        },
        {
            "heading": "4.3 Label Signal Enhancement Module",
            "text": "To make the extracted features more effective, we constructed a label signal enhancement module. It combines the empathy labels EM and the empathy intent labels IN as label signals. Specifically, concatenating all label encodings of the two tasks as the query vectors of the module with the empathy and empathy intent representations for the attention computation can effectively capture, the semantics of the two information with respect to labels. Taking the empathy detection task as an example, the computation with label encoding can not only capture the semantics about empathy, but also capture the semantics about empathy intent for assisting the decoding of empathy, and the same is true for the empathy intent recognition task.The label signal\nand the interaction features can obtain the corresponding representation of label perception. We do not explicitly use the predicted results to guide another task, as this could lead to problems with the error cascade. Formally, before decoding, we use the learnable label signal embedding LS\u03b4 as input to establish an association with the representations HE\u2212I\u2212E and HI\u2212E\u2212I , respectively, which can explicitly enhance the importance of features that are easier to classify in feature information. We also add H for enhanced capture contextual semantic information.\nLS\u03b4 = IN \u2295EM \u2295H\u03b4\u2212\u03b3\u2212\u03b4, (5)\nLH\u03b4 = Attention (LS\u03b4,H\u03b4\u2212\u03b3\u2212\u03b4,H\u03b4\u2212\u03b3\u2212\u03b4) , (6)\nH \u2032 \u03b4 = LH\u03b4 +H, (7)\nwhere LHE and LHI denote the empathy and the empathy intent representations after label signal enhancement. H\n\u2032 E and H \u2032 I denote the final empathy\nand the empathy intent representations."
        },
        {
            "heading": "4.4 Decoder",
            "text": "Finally, we apply the max-pooling operation to H\n\u2032 E and H \u2032 I to obtain the representations HEM and HIM , respectively. Two separate decoders are used for ED and EIC.\nyE = softmax ( WEHEM + b E ) , (8)\nyI = softmax ( WIHIM + b I ) , (9)\nwhere yE , yI are the predicted distributions for ED and EIC, respectively. WE and WI are trainable parameters, bE and bI are bias."
        },
        {
            "heading": "4.5 Joint Training",
            "text": "We use a joint training scheme to consider both ED and EIC and update the parameters by joint optimization. Lin et al. (2018) proposed to add a modulation factor (1\u2212 pi)\u03b7 to the cross-entropy loss to discriminate between easy/hard examples. pi represents the probability value of the t-th class from softmax output. It can alleviate the problem of unbalanced category distribution in our data. Focal loss is used for ED and EIC, respectively:\nLEmp = \u2212\u03bbEt ( 1\u2212 yEt )\u03b7 log ( yEt ) , (10)\nLIntent = \u2212\u03bbIt ( 1\u2212 yIt )\u03b7 log ( yIt ) , (11)\nwhere \u03bb\u03b4t represents the weight of the t-th class sample, y\u03b4t denotes pi, \u03b7 is hyper-parameters and \u03b7 \u2208 [0, 5].\nThe final joint objective is formulated as:\nL = \u03b1LEmp + \u03b2LIntent, (12)\nwhere \u03b1 and \u03b2 are hyper-parameters."
        },
        {
            "heading": "5 Experiments",
            "text": ""
        },
        {
            "heading": "5.1 Experimental Settings",
            "text": "We use the BERT pre-trained model to extract vectors as the initialization embedding. The batch size is 32 and 64 on IEMPATHIZE and TwittEmp, respectively. The epoch is set to 100. The learning rate is set to 0.0001 and the dropout ratio is set to 0.2. The output dimension of the cascaded interaction module and the label signal enhancement module is 128. We use Adam (Kingma and Ba, 2015) to optimize the parameters in the model. In the loss function, \u03b7 is set to 5, \u03bb is set to 1. All experiments are conducted at GeForce RTX 2080Ti."
        },
        {
            "heading": "5.2 Baselines",
            "text": "To validate the performance of our framework, we compare our framework to some baselines, including: (1) BERT (Hosseini and Caragea, 2021b): The BERT model was fine-tuned on the IEMPATHIZE dataset; (2) KD (Hosseini and Caragea, 2021a): They used the idea of knowledge distillation to combine emotions and sentiments to complete the empathy detection; (3) Empirical Study: BERT models as a shared encoder to jointly train of the empathy detection task and the empathy intent recognition task; (4) Joint ID and SF (Zhang and Wang, 2016): The model was used for the spoken language understanding task, and we use it for the joint training of ED and EIC; (5) DCRNet(Qin et al., 2020): They propose the DCR-NET to explicitly consider the cross-influence between tasks. The model captures mutual knowledge by stacking of relational layers within itself; (6) CoGAT (Qin et al., 2021): The core module of the model is the co-interactive graph interaction layer, in which cross-utterance connections and crosstask connections are constructed and iteratively updated with each other to establish information transfer between two tasks. Since this study focuses only on a single-turn dialogue task, we replace the cross-utterance connections in the model with cross-word connections."
        },
        {
            "heading": "5.3 Main Results and Analysis",
            "text": "For both ED and EIC tasks on the two datasets, we use Precision (P), Recall (R), and F1-score (F1) as evaluation metrics. The experimental results are shown in Table 3 and Appendix B. We can see that the performance of CLSN on both datasets is significantly improved compared with all baselines.\nThe Joint ID and SF uses the bi-directional GRU to extract features and classify them directly, without considering the feature interactions between empathy and empathy intent representations, therefore, the model achieves lower accuracy. The DCRNET uses the stacked co-interactive relationship layer to implement the interaction between the two tasks. Since the method models the information interaction between two tasks, the accuracy of the model is better than the joint ID and SF. However, DCR-NET has limited information interaction capabilities, resulting in lower accuracy than our framework. It can be seen that the accuracy of Co-GAT is lower, which shows that adopting cross-word connections instead of cross-utterances connections can not fully show the modeling performance of Co-GAT. Compared with all baselines, the cascaded interaction attention mechanism in\nour framework establishes a deeper information transfer between two tasks. Specifically, after the initial information interaction is completed, the current task can be used as a query to search for singlelevel interaction features, thus achieving deep feature extraction from the current task to another task. The information flow continuously interacts between two tasks, eventually bringing feature information from another task back to the current task. It not only enriches the feature information of the current task, but also avoids the lack of features due to insufficient interaction. In addition, the label signal enhancement module in our framework uses the label encoding information of the tasks to help the model automatically detect the category features in the model, while avoiding the problem of error cascades due to mutual guidance between tasks. The clear bidirectional flow of modeling information in the two modules enables our framework to achieve competitive results."
        },
        {
            "heading": "5.4 Ablation Study",
            "text": "This subsection aims to demonstrate the effectiveness of different components in our framework, including the cascaded interactive attention mod-\nule, the label signal enhancement module, and the focal loss.\n\u2022 Effectiveness of Cascaded Interactive Attention Module. We remove the cascaded interactive attention module from our framework (w/o CIA). From Table 4, we can observe that the F1-score of ED decreases by 1.87% after removing the cascaded interaction attention module under the multiclass setting in the IEMPATHIZE dataset. The F1score of EIC decreased by 0.27%. The F1-score of the two tasks also shows a decreasing trend in the binary classification setting. These results indicate that the cascaded interactive attention module is essential in the proposed CLSN due to its ability to effectively establish the information interaction between the two tasks.\n\u2022 Effectiveness of Label Signal Enhancement Module. We remove this part of the framework (w/o LSE). From Table 4, we can see that the F1-score of both settings in the IEMPATHIZE\ndataset are degraded after removing this component. Therefore, it is effective for the label signal enhancement component to guide the two task representations. Moreover, our framework achieves optimal results only when both the cascaded interactive attention module and the label signal enhancement module are applied to CLSN, proving that these two modules are complementary. \u2022 Effectiveness of Focal Loss. We verify the effectiveness of the focal loss by replacing it with the cross-entropy loss (r.p. CEL). The experimental results show that the use of the focal loss to alleviate the problem of an unbalanced distribution of category labels is effective. We can observe that the use of the cross-entropy loss function is lower than our proposed full framework under both classifier settings, and there is a significant reduction in EIC. This shows that focal loss can indeed help improve the quality of ED by improving the unbalanced samples of empathy intent during training. Furthermore, as can be seen from Tables 3 and 4, when our framework uses cross-entropy as the loss function under both settings, the F1-scores still outperform all baselines in most cases, indicating that the accuracy improvement achieved by CLSN is not only the use of the focal loss function, but the superiority of the model is also a factor."
        },
        {
            "heading": "5.5 Visualisation Analysis",
            "text": "To explore the impact of different modeling approaches on words in utterances, we use the Cap-\ntum4 to visualize the contribution of different words to empathy labels (Kokhlikyan et al., 2020; Chefer et al., 2021). As shown in Figure 6, the BERT does not accurately identify the empathy labels for two cases. The empirical study introduced the EIC task and accurately identifies the categories for the two cases, but the model could not focus well on the words associated with the correct label. In contrast, the CLSN not only accurately identifies the empathy labels in both cases, but is also able to focus more reasonably on the words associated with the empathy labels in the utterance, demonstrating the superiority of our framework."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this paper, to investigate whether the performance of the ED task can be improved by the introduction of the EIC task, we invite 3 experts to manually label the empathy intent labels on two empathy detection datasets, IEMPATHIZE and TwittEmp, as datasets for joint training of ED and EIC. The empirical study shows that the introduction of EIC task is effective in improving the accuracy of the ED task, and we also explore possible reasons for this improvement. In addition, we propose the CLSN, which explicitly models the information flow interaction between the two representations through a cascaded interactive attention module and a labeled signal enhancement module. Experimental results show that the CLSN achieves better accuracy than all baselines under both settings in the two datasets.\nLimitations\nThe limitations of this paper are mainly twofold: (1) Although the introduction of the EIC task into the ED task can significantly improve the accuracy of the ED task, this requires manual annotation and is costly, and in future studies we will explore few-shot learning approaches to mitigate this cost; (2) In exploring the reasons for this improvement, we count the frequency co-occurrence matrices of the two labels, and find that there is a clear correspondence between the empathy and empathy intent labels. Although there is an obvious correspondence between the labels, but the proposed CLSN only uses the two implicit states for interaction when modeling information transfer, without explicitly modeling information transfer based on the above label correspondence. How to use this\n4https://captum.ai/\ncorrespondence could be a direction of exploration for our future work.\nEthics Statement\nThe dataset studied in this paper does not involve ethical issues."
        },
        {
            "heading": "Acknowledgements",
            "text": "We thank the anonymous reviewers for their helpful comments and suggestions. This work was supported by the National Natural Science Foundation of China (61433012) and the National Key R & D Program of China (No. 2014CB340506) and the Excellent Doctoral Student Research Innovation Project of Xinjiang University (No. XJU2022BS077)."
        },
        {
            "heading": "A Dataset Statistics",
            "text": ""
        },
        {
            "heading": "B class-wise Performance",
            "text": "Figure 7, Figure 8, and Figure 9 show the results of the CLSN for each category in different settings in the ED and EIC tasks, respectively."
        }
    ],
    "title": "Empathy Intent Drives Empathy Detection",
    "year": 2023
}