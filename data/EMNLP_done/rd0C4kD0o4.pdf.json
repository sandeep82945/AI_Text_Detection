{
    "abstractText": "Knowledge-grounded dialogue generation requires to first retrieve appropriate external knowledge based on a conversational context and then generate a response grounded on the retrieved knowledge. In general, these two sequential modules, a knowledge retriever and a response generator, have been separately trained by supervised data for each module. However, obtaining intermediate labels of the ground-truth knowledge is expensive and difficult especially in open-domain conversation. Latent variable modeling can circumvent it and enables a joint training without the knowledge supervision. In this paper, we propose an efficient algorithm for this latent variable modeling that is able to leverage a large amount of dialogue data. In specific, rather than directly training the complex retriever, we adapt a query generator with an off-the-shelf retriever, and the query generator and response generator are simultaneously trained over the latent variable of query. Moreover, we employ the evidence lower bound as a training objective and modify it to efficiently and robustly perform the joint training. Experimental results on diverse knowledge-grounded dialogue datasets show that the proposed algorithm achieves state-ofthe-art performances even without the use of the annotated knowledge while maintaining the efficiency and scalability.",
    "authors": [
        {
            "affiliations": [],
            "name": "Gunsoo Han"
        },
        {
            "affiliations": [],
            "name": "Daejin Jo"
        },
        {
            "affiliations": [],
            "name": "Daniel Wontae Nam"
        },
        {
            "affiliations": [],
            "name": "Eunseop Yoon"
        },
        {
            "affiliations": [],
            "name": "Taehwan Kwon"
        },
        {
            "affiliations": [],
            "name": "Seungeun Rho"
        },
        {
            "affiliations": [],
            "name": "Kyoung-Woon On"
        },
        {
            "affiliations": [],
            "name": "Chang D. Yoo"
        },
        {
            "affiliations": [],
            "name": "Sungwoong Kim"
        }
    ],
    "id": "SP:1e03ea4339b3c27c8551679331824328650aac3e",
    "references": [
        {
            "authors": [
                "Leonard Adolphs",
                "Benjamin Boerschinger",
                "Christian Buck",
                "Michelle Chen Huebscher",
                "Massimiliano Ciaramita",
                "Lasse Espeholt",
                "Thomas Hofmann",
                "Yannic Kilcher",
                "Sascha Rothe",
                "Pier Giuseppe Sessa"
            ],
            "title": "Boosting search engines with interactive",
            "year": 2021
        },
        {
            "authors": [
                "Leonard Adolphs",
                "Kurt Shuster",
                "Jack Urbanek",
                "Arthur Szlam",
                "Jason Weston."
            ],
            "title": "Reason first, then respond: Modular generation for knowledge-infused dialogue",
            "venue": "arXiv preprint arXiv:2111.05204.",
            "year": 2021
        },
        {
            "authors": [
                "Raviteja Anantha",
                "Svitlana Vakulenko",
                "Zhucheng Tu",
                "Shayne Longpre",
                "Stephen Pulman",
                "Srinivas Chappidi."
            ],
            "title": "Open-domain question answering goes conversational via question rewriting",
            "venue": "Proceedings of the 2021 Conference of the North Amer-",
            "year": 2021
        },
        {
            "authors": [
                "Mingzhu Cai",
                "Siqi Bao",
                "Xin Tian",
                "Huang He",
                "Fan Wang",
                "Hua Wu."
            ],
            "title": "Query enhanced knowledgeintensive conversation via unsupervised joint modeling",
            "venue": "ACL.",
            "year": 2023
        },
        {
            "authors": [
                "Xiuyi Chen",
                "Fandong Meng",
                "Peng Li",
                "Feilong Chen",
                "Shuang Xu",
                "Bo Xu",
                "Jie Zhou."
            ],
            "title": "Bridging the gap between prior and posterior knowledge selection for knowledge-grounded dialogue generation",
            "venue": "EMNLP, pages 3426\u20133437.",
            "year": 2020
        },
        {
            "authors": [
                "Zhiyu Chen",
                "Jie Zhao",
                "Anjie Fang",
                "Besnik Fetahu",
                "Oleg Rokhlenko",
                "Shervin Malmasi."
            ],
            "title": "Reinforced question rewriting for conversational question answering",
            "venue": "arXiv preprint arXiv:2210.15777.",
            "year": 2022
        },
        {
            "authors": [
                "Emily Dinan",
                "Stephen Roller",
                "Kurt Shuster",
                "Angela Fan",
                "Michael Auli",
                "Jason Weston."
            ],
            "title": "Wizard of wikipedia: Knowledge-powered conversational agents",
            "venue": "arXiv preprint arXiv:1811.01241.",
            "year": 2018
        },
        {
            "authors": [
                "Nijkamp Erik",
                "Mitch Hill",
                "Song-Chun Zhu",
                "Ying Nian Wu."
            ],
            "title": "Learning non-convergent non-persistent short-run mcmc toward energy-based model",
            "venue": "Advances in Neural Information Processing Systems (NeurIPS).",
            "year": 2019
        },
        {
            "authors": [
                "Michael Glass",
                "Gaetano Rossiello",
                "Md Faisal Mahbub Chowdhury",
                "Ankita Rajaram Naik",
                "Pengshan Cai",
                "Alfio Gliozzo."
            ],
            "title": "Re2g: Retrieve, rerank, generate",
            "venue": "NAACL.",
            "year": 2022
        },
        {
            "authors": [
                "Kelvin Guu",
                "Kenton Lee",
                "Zora Tung",
                "Panupong Pasupat",
                "Ming-Wei Chang."
            ],
            "title": "Realm: Retrievalaugmented language model pre-training",
            "venue": "arXiv preprint arXiv:2002.08909.",
            "year": 2020
        },
        {
            "authors": [
                "Ari Holtzman",
                "Jan Buys",
                "Li Du",
                "Maxwell Forbes",
                "Yejin Choi"
            ],
            "title": "The curious case of neural text degeneration",
            "year": 2020
        },
        {
            "authors": [
                "Xinxian Huang",
                "Huang He",
                "Siqi Bao",
                "Fan Wang",
                "Hua Wu",
                "Haifeng Wang."
            ],
            "title": "PLATO-KAG: Unsupervised knowledge-grounded conversation via joint modeling",
            "venue": "Proceedings of the 3rd Workshop on Natural Language Processing for Conversational AI,",
            "year": 2021
        },
        {
            "authors": [
                "Gautier Izacard",
                "Edouard Grave."
            ],
            "title": "Leveraging passage retrieval with generative models for open domain question answering",
            "venue": "arXiv preprint arXiv:2007.01282.",
            "year": 2020
        },
        {
            "authors": [
                "Michael I Jordan",
                "Zoubin Ghahramani",
                "Tommi S Jaakkola",
                "Lawrence K Saul."
            ],
            "title": "An introduction to variational methods for graphical models",
            "venue": "Machine learning, 37:183\u2013233.",
            "year": 1999
        },
        {
            "authors": [
                "Vladimir Karpukhin",
                "Barlas O\u011fuz",
                "Sewon Min",
                "Patrick Lewis",
                "Ledell Wu",
                "Sergey Edunov",
                "Danqi Chen",
                "Wen-tau Yih."
            ],
            "title": "Dense passage retrieval for open-domain question answering",
            "venue": "arXiv preprint arXiv:2004.04906.",
            "year": 2020
        },
        {
            "authors": [
                "Byeongchang Kim",
                "Jaewoo Ahn",
                "Gunhee Kim."
            ],
            "title": "Sequential latent knowledge selection for knowledge-grounded dialogue",
            "venue": "ICLR.",
            "year": 2020
        },
        {
            "authors": [
                "Sungdong Kim",
                "Gangwoo Kim"
            ],
            "title": "Saving dense retriever from shortcut dependency in conversational search",
            "year": 2022
        },
        {
            "authors": [
                "Diederik P Kingma",
                "Max Welling."
            ],
            "title": "Autoencoding variational bayes",
            "venue": "arXiv preprint arXiv:1312.6114.",
            "year": 2013
        },
        {
            "authors": [
                "Mojtaba Komeili",
                "Kurt Shuster",
                "Jason Weston."
            ],
            "title": "Internet-augmented dialogue generation",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8460\u20138478, Dublin, Ireland. Association",
            "year": 2022
        },
        {
            "authors": [
                "Uszkoreit",
                "Quoc Le",
                "Slav Petrov."
            ],
            "title": "Natural questions: A benchmark for question answering research",
            "venue": "Transactions of the Association for Computational Linguistics, 7:452\u2013466.",
            "year": 2019
        },
        {
            "authors": [
                "Mike Lewis",
                "Yinhan Liu",
                "Naman Goyal",
                "Marjan Ghazvininejad",
                "Abdelrahman Mohamed",
                "Omer Levy",
                "Ves Stoyanov",
                "Luke Zettlemoyer"
            ],
            "title": "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
            "year": 2019
        },
        {
            "authors": [
                "Patrick Lewis",
                "Ethan Perez",
                "Aleksandra Piktus",
                "Fabio Petroni",
                "Vladimir Karpukhin",
                "Naman Goyal",
                "Heinrich K\u00fcttler",
                "Mike Lewis",
                "Wen-tau Yih",
                "Tim Rockt\u00e4schel"
            ],
            "title": "Retrieval-augmented generation for knowledge-intensive nlp tasks",
            "year": 2020
        },
        {
            "authors": [
                "Linxiao Li",
                "Can Xu",
                "Wei Wu",
                "Yufan Zhao",
                "Xueliang Zhao",
                "Chongyang Tao"
            ],
            "title": "Zero-resource knowledge-grounded dialogue generation",
            "year": 2021
        },
        {
            "authors": [
                "Zekang Li",
                "Cheng Niu",
                "Fandong Meng",
                "Yang Feng",
                "Qian Li",
                "Jie Zhou."
            ],
            "title": "Incremental transformer with deliberation decoder for document grounded conversations",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Lin-",
            "year": 2019
        },
        {
            "authors": [
                "Rongzhong Lian",
                "Min Xie",
                "Fan Wang",
                "Jinhua Peng",
                "Hua Wu."
            ],
            "title": "Learning to select knowledge for response generation in dialog systems",
            "venue": "arXiv preprint arXiv:1902.04911.",
            "year": 2019
        },
        {
            "authors": [
                "Sheng-Chieh Lin",
                "Jheng-Hong Yang",
                "Rodrigo Nogueira",
                "Ming-Feng Tsai",
                "Chuan-Ju Wang",
                "Jimmy Lin."
            ],
            "title": "Conversational question reformulation via sequence-to-sequence architectures and pretrained language models",
            "venue": "arXiv preprint arXiv:2004.01909.",
            "year": 2020
        },
        {
            "authors": [
                "Shilei Liu",
                "Xiaofeng Zhao",
                "Bochao Li",
                "Feiliang Ren",
                "Longhui Zhang",
                "Shujuan Yin."
            ],
            "title": "A Three-Stage Learning Framework for Low-Resource Knowledge-Grounded Dialogue Generation",
            "venue": "Proceedings of the 2021 Conference on Empirical Meth-",
            "year": 2021
        },
        {
            "authors": [
                "Shuman Liu",
                "Hongshen Chen",
                "Zhaochun Ren",
                "Yang Feng",
                "Qun Liu",
                "Dawei Yin."
            ],
            "title": "Knowledge diffusion for neural dialogue generation",
            "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
            "year": 2018
        },
        {
            "authors": [
                "Longxuan Ma",
                "Weinan Zhang",
                "Runxin Sun",
                "Ting Liu."
            ],
            "title": "A compare aggregate transformer for understanding document-grounded dialogue",
            "venue": "arXiv preprint arXiv:2010.00190.",
            "year": 2020
        },
        {
            "authors": [
                "Nikita Moghe",
                "Siddhartha Arora",
                "Suman Banerjee",
                "Mitesh M Khapra."
            ],
            "title": "Towards exploiting background knowledge for building conversation systems",
            "venue": "arXiv preprint arXiv:1809.08205.",
            "year": 2018
        },
        {
            "authors": [
                "Tri Nguyen",
                "Mir Rosenberg",
                "Xia Song",
                "Jianfeng Gao",
                "Saurabh Tiwary",
                "Rangan Majumder",
                "Li Deng"
            ],
            "title": "2017. MS MARCO: A human-generated MAchine reading COmprehension dataset",
            "year": 2017
        },
        {
            "authors": [
                "Rodrigo Nogueira",
                "Kyunghyun Cho."
            ],
            "title": "Taskoriented query reformulation with reinforcement learning",
            "venue": "arXiv preprint arXiv:1704.04572.",
            "year": 2017
        },
        {
            "authors": [
                "Ashwin Paranjape",
                "Omar Khattab",
                "Christopher Potts",
                "Matei Zaharia",
                "Christopher D Manning."
            ],
            "title": "Hindsight: Posterior-guided training of retrievers for improved open-ended generation",
            "venue": "ICLR.",
            "year": 2022
        },
        {
            "authors": [
                "Gon\u00e7alo Raposo",
                "Rui Ribeiro",
                "Bruno Martins",
                "Lu\u00edsa Coheur."
            ],
            "title": "Question rewriting? assessing its importance for conversational question answering",
            "venue": "Lecture Notes in Computer Science, pages 199\u2013 206. Springer International Publishing.",
            "year": 2022
        },
        {
            "authors": [
                "Hannah Rashkin",
                "David Reitter",
                "Gaurav Singh Tomar",
                "Dipanjan Das."
            ],
            "title": "Increasing faithfulness in knowledge-grounded dialogue with controllable features",
            "venue": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics",
            "year": 2021
        },
        {
            "authors": [
                "Hannah Rashkin",
                "Eric Michael Smith",
                "Margaret Li",
                "Y-Lan Boureau."
            ],
            "title": "Towards empathetic opendomain conversation models: A new benchmark and dataset",
            "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,",
            "year": 2019
        },
        {
            "authors": [
                "Stephen Robertson",
                "Hugo Zaragoza"
            ],
            "title": "The probabilistic relevance framework: Bm25 and beyond",
            "venue": "Foundations and Trends\u00ae in Information Retrieval,",
            "year": 2009
        },
        {
            "authors": [
                "Kurt Shuster",
                "Mojtaba Komeili",
                "Leonard Adolphs",
                "Stephen Roller",
                "Arthur Szlam",
                "Jason Weston."
            ],
            "title": "Language models that seek for knowledge: Modular search & generation for dialogue and prompt completion",
            "venue": "arXiv preprint",
            "year": 2022
        },
        {
            "authors": [
                "Weiwei Sun",
                "Pengjie Ren",
                "Zhaochun Ren."
            ],
            "title": "Generative knowledge selection for knowledgegrounded dialogues",
            "venue": "Findings of the Association for Computational Linguistics: EACL 2023, pages 2077\u20132088, Dubrovnik, Croatia. Association",
            "year": 2023
        },
        {
            "authors": [
                "Lamm",
                "Viktoriya Kuzmina",
                "Joe Fenton",
                "Aaron Cohen",
                "Rachel Bernstein",
                "Ray Kurzweil",
                "Blaise AgueraArcas",
                "Claire Cui",
                "Marian Croak",
                "Ed H. Chi",
                "Quoc Le."
            ],
            "title": "Lamda: Language models for dialog applications",
            "venue": "arXiv preprint arXiv:2201.08239,",
            "year": 2022
        },
        {
            "authors": [
                "David Thulke",
                "Nico Daheim",
                "Christian Dugast",
                "Hermann Ney."
            ],
            "title": "Efficient retrieval augmented generation from unstructured knowledge for taskoriented dialog",
            "venue": "arXiv preprint arXiv:2102.04643.",
            "year": 2021
        },
        {
            "authors": [
                "Megan Ung",
                "Jing Xu",
                "Y-Lan Boureau."
            ],
            "title": "SaFeRDialogues: Taking feedback gracefully after conversational safety failures",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 6462\u2013",
            "year": 2022
        },
        {
            "authors": [
                "Svitlana Vakulenko",
                "Shayne Longpre",
                "Zhucheng Tu",
                "Raviteja Anantha."
            ],
            "title": "Question rewriting for conversational question answering",
            "venue": "Proceedings of the 14th ACM international conference on web search and data mining, pages 355\u2013363.",
            "year": 2021
        },
        {
            "authors": [
                "Nikos Voskarides",
                "Dan Li",
                "Pengjie Ren",
                "Evangelos Kanoulas",
                "Maarten de Rijke."
            ],
            "title": "Query resolution for conversational search with limited supervision",
            "venue": "Proceedings of the 43rd International ACM SIGIR conference on research and development in",
            "year": 2020
        },
        {
            "authors": [
                "Zeqiu Wu",
                "Yi Luan",
                "Hannah Rashkin",
                "David Reitter",
                "Hannaneh Hajishirzi",
                "Mari Ostendorf",
                "Gaurav Singh Tomar."
            ],
            "title": "Conqrr: Conversational query rewriting for retrieval with reinforcement learning",
            "venue": "EMNLP.",
            "year": 2022
        },
        {
            "authors": [
                "Tianbao Xie",
                "Chen Henry Wu",
                "Peng Shi",
                "Ruiqi Zhong",
                "Torsten Scholak",
                "Michihiro Yasunaga",
                "Chien-Sheng Wu",
                "Ming Zhong",
                "Pengcheng Yin",
                "Sida I Wang"
            ],
            "title": "Unifiedskg: Unifying and multi-tasking structured knowledge grounding with text-to-text",
            "year": 2022
        },
        {
            "authors": [
                "Jing Xu",
                "Arthur Szlam",
                "Jason Weston."
            ],
            "title": "Beyond goldfish memory: Long-term open-domain conversation",
            "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5180\u20135197, Dublin,",
            "year": 2022
        },
        {
            "authors": [
                "Jing Xu",
                "Megan Ung",
                "Mojtaba Komeili",
                "Kushal Arora",
                "Y-Lan Boureau",
                "Jason Weston."
            ],
            "title": "Learning new skills after deployment: Improving open-domain internet-driven dialogue with human feedback",
            "venue": "arXiv preprint arXiv:2208.03270.",
            "year": 2022
        },
        {
            "authors": [
                "Yan Xu",
                "Deqian Kong",
                "Dehong Xu",
                "Ziwei Ji",
                "Bo Pang",
                "Pascale Fung",
                "Ying Nian Wu"
            ],
            "title": "Diverse and faithful knowledge-grounded dialogue generation via sequential posterior inference",
            "year": 2023
        },
        {
            "authors": [
                "Shi Yu",
                "Jiahua Liu",
                "Jingqin Yang",
                "Chenyan Xiong",
                "Paul Bennett",
                "Jianfeng Gao",
                "Zhiyuan Liu."
            ],
            "title": "Fewshot generative conversational query rewriting",
            "venue": "Proceedings of the 43rd International ACM SIGIR conference on research and development in Informa-",
            "year": 2020
        },
        {
            "authors": [
                "Haolan Zhan",
                "Lei Shen",
                "Hongshen Chen",
                "Hainan Zhang."
            ],
            "title": "Colv: A collaborative latent variable model for knowledge-grounded dialogue generation",
            "venue": "EMNLP.",
            "year": 2021
        },
        {
            "authors": [
                "Saizheng Zhang",
                "Emily Dinan",
                "Jack Urbanek",
                "Arthur Szlam",
                "Douwe Kiela",
                "Jason Weston"
            ],
            "title": "Personalizing dialogue agents: I have a dog, do you have pets too",
            "venue": "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
            "year": 2018
        },
        {
            "authors": [
                "Yizhe Zhang",
                "Siqi Sun",
                "Xiang Gao",
                "Yuwei Fang",
                "Chris Brockett",
                "Michel Galley",
                "Jianfeng Gao",
                "Bill Dolan."
            ],
            "title": "Retgen: A joint framework for retrieval and grounded text generation modeling",
            "venue": "AAAI.",
            "year": 2022
        },
        {
            "authors": [
                "Xueliang Zhao",
                "Wei Wu",
                "Can Xu",
                "Chongyang Tao",
                "Dongyan Zhao",
                "Rui Yan."
            ],
            "title": "Knowledgegrounded dialogue generation with pre-trained language models",
            "venue": "EMNLP.",
            "year": 2020
        },
        {
            "authors": [
                "Hao Zhou",
                "Tom Young",
                "Minlie Huang",
                "Haizhou Zhao",
                "Jingfang Xu",
                "Xiaoyan Zhu."
            ],
            "title": "Commonsense knowledge aware conversation generation with graph attention",
            "venue": "Proceedings of the 27th International Joint Conference on Artificial Intelligence,",
            "year": 2018
        },
        {
            "authors": [
                "Kangyan Zhou",
                "Shrimai Prabhumoye",
                "Alan W Black."
            ],
            "title": "A dataset for document grounded conversations",
            "venue": "EMNLP.",
            "year": 2018
        },
        {
            "authors": [
                "Query: Mark Spitz Speedo"
            ],
            "title": "Swimsuit ads after speedo swimming career ends mark spitz m Munich olympics 2012 GT knowledge selected: False Response: Spitz did Schick razor commercials and Speedo swimsuit ads",
            "year": 2012
        },
        {
            "authors": [
                "Query: Stephen Sonds",
                "Lapine"
            ],
            "title": "Rhapsodic passion1994 Stephen sondheim, James lapine plays 12 dreams off-broadway p Pulitzer prize for play Sunday in Park. GT knowledge selected: False Response: Stephen Sondheim and James Lapine\u2019s last work together was the rhapsodic",
            "venue": "Passion",
            "year": 1994
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Recently, knowledge-grounded dialogue generation has drawn increasing attention especially as a key ingredient for open-domain conversational agents (Dinan et al., 2018; Zhou et al., 2018b; Zhan et al., 2021; Liu et al., 2018; Zhou et al., 2018a; Lian et al., 2019; Zhao et al., 2020; Kim et al., 2020; Chen et al., 2022; kom; Shuster et al., 2022a,b; Cai et al., 2023; Wu et al., 2022; Lewis et al., 2020; Huang et al., 2021; Thulke et al., 2021; Anantha\n\u2217 Work done at Kakao Brain \u2020 Corresponding Author\net al., 2021). It usually obtains knowledge from external resources such as Wikipedia-based databases and web search engines since internal knowledge even in large-scale parametric language models (Brown et al., 2020; Thoppilan et al., 2022; Chowdhery et al., 2022) is incomplete or outdated, and moreover it can provide hallucinated information.\nIn order for a dialogue response to be grounded on such external knowledge, the conversational agent generally consists of a knowledge retriever, which retrieves knowledge corresponding to a given dialogue context, followed by a response generator that produces an informative response based on the dialogue context and the retrieved knowledge. In many previous methods, supervised learning has often been applied to independently optimize each module using the ground-truth or gold knowledge (Dinan et al., 2018; Shuster et al., 2022a,b; Glass et al., 2022; Adolphs et al., 2021a; Nogueira and Cho, 2017; Ma et al., 2020; Xie et al., 2022). However, human annotation of knowledge information is cumbersome, expensive, and often incomplete due to the existence of multiple possible knowledge candidates and the overlooking of the target response. In addition, existing automatic annotations are generally limited to a simple extractive question answering (Zhao et al., 2020; Liu et al., 2021). This difficulty in obtaining annotations of knowledge information could be severe under the open-domain conversation and hinders the use of large-scale dialogue data.\nTherefore, there have been a number of recent approaches to learn the knowledge retriever and the response generator without the knowledge supervision. In specific, they have treated the retrieved knowledge, document, or passage as an unobserved latent variable and adapt latent variable modeling based on approximated marginalization (e.g. top-k) (Lewis et al., 2020; Huang et al., 2021; Cai et al., 2023; Guu et al., 2020), reinforcement learning (Zhao et al., 2020; Zhang et al., 2022; Chen et al., 2022; Wu et al., 2022) or variational methods (Zhan\net al., 2021; Paranjape et al., 2022; Lian et al., 2019; Kim et al., 2020; Chen et al., 2020; Xu et al., 2023). However, joint training of the retriever along with the generator under this latent variable modeling has some restrictions in utilizing the retriever. For example, a retriever needs to produce a differentiable prior probability for the gradient propagation through the marginalization or to be intermittently updated to rebuild the whole passage index during training (Karpukhin et al., 2020; Lewis et al., 2020; Zhang et al., 2022). This leads to limitation in facilitating complicated or large-scale retrievers and further in leveraging large-scale data. In addition, the posterior probability used in the previous variational methods has been modeled by a separated network, which grows the training complexity and also incurs the discrepancy between the trainingtime and test-time knowledge samplings.\nTo overcome such restrictions, in this paper, we propose an efficient latent variable modeling, named ELVM, for knowledge-grounded dialogue generation. In particular, we reduce the burden for training a whole retriever by employing a query generator followed by an off-the-shelf retriever that is fixed during training. More precisely, in tandem with the response generator, the query generator rather than the retriever is jointly optimized by latent variable modeling, in which a query is taken as a latent variable, on paired observations of dialogue contexts and responses.\nTo this end, we exploit the variational method using the evidence lower bound (ELBO) (Kingma and Welling, 2013; Jordan et al., 1999) and approximate the expected conditional likelihood in the ELBO by subset sampling from the prior distribution, which acts as the training objective for the response and the query generators. This approximation gets rid of an extra modeling of a surrogate posterior distribution or online posterior inference such as Markov Chain Monte Carlo (MCMC) and also reduces the training-inference discrepancy in knowledge retrieval. Moreover, we further modify the Kullback\u2013Leibler (KL) regularization of the ELBO by constructing the approximated posterior distribution from the conditional likelihood and prior distribution and set this posterior distribution as a teacher for a distillation objective to further learn the query generator.\nExperimental results show that the proposed ELVM allows to efficiently and robustly perform training without (1) the use of the annotated knowledge, (2) an explicit training of the knowledge\nretrieval, and (3) a complex posterior sampling. Especially, it significantly outperforms previous state-of-the-art methods for knowledge-grounded dialogue generation. In addition, the proposed posterior distillation improves the performances over the baseline that solely maximizes the expectation of the conditional likelihood.\nOur main contributions can be summarized as: \u2022 An efficient latent variable modeling is proposed\nin joint training of query generator and dialogue response generator without the knowledge supervision for knowledge-intensive dialogue generation. \u2022 For realizing efficient yet robust joint training, the ELBO for the marginal likelihood is modified as the combination of the conditional likelihood objective and the posterior distillation objective, based on multiple prior samples. \u2022 The proposed ELVM demonstrates its effectiveness in performing unsupervised joint training and even significant performance improvements over previous methods, being a new state-of-theart on benchmark datasets."
        },
        {
            "heading": "2 Related Work",
            "text": ""
        },
        {
            "heading": "2.1 Knowledge-Grounded Dialogue Generation",
            "text": "Knowledge-grounded conversation has been extensively studied through recently released public datasets (Dinan et al., 2018; kom; Xu et al., 2022b; Kwiatkowski et al., 2019; Anantha et al., 2021; Moghe et al., 2018). Existing approaches for this task have mostly exploited two successive modules, the knowledge retriever and the knowledgegrounded response generator. Many previous works have used manual annotations of gold knowledge provided by some of public datasets to optimize the modules (Dinan et al., 2018; Shuster et al., 2022a,b; Glass et al., 2022; Adolphs et al., 2021a; Nogueira and Cho, 2017; Ma et al., 2020; Xie et al., 2022). Specifically, SeekeR (Shuster et al., 2022a) and BlenderBot3 (Shuster et al., 2022b) have recently proposed to build a series of modules by a single transformer with different prompts for each module, and trained its transformer on a large number of modular tasks using annotated datasets. However, this manual annotation is expensive, time-consuming, and often inaccurate, which impedes the utilization of a large-scale dialogue data that is especially necessary for open-domain conversation."
        },
        {
            "heading": "2.2 Unsupervised Joint Training",
            "text": "Recently, unsupervised training methods have been widely applied, and many of them have tries to jointly learn the modules without knowledge labels (Lewis et al., 2020; Huang et al., 2021; Zhao et al., 2020; Zhang et al., 2022; Zhan et al., 2021; Paranjape et al., 2022; Lian et al., 2019; Kim et al., 2020). For example, PLATO-KAG (Huang et al., 2021) has approximated the marginal likelihood by top-k knowledge samples while RetGen (Zhang et al., 2022) has trained to reward knowledge retrieval with the highest utilization in response generation by reinforcement learning and mixture-of-experts ensembling.\nMeanwhile, latent variable modeling based on variational methods has also been developed by several recent works. CoLV (Zhan et al., 2021) has introduced collaborative latent spaces to reflect the inherent correlation between the knowledge selection and the response generation. SKT (Kim et al., 2020) has developed a sequential latent variable model for the multi-turn knowledge-grounded dialogue generation. In order to perform the posterior sampling of knowledge selection during joint training, some works have proposed to separately train the posterior distribution model (Paranjape et al., 2022; Lian et al., 2019) or the posterior information prediction model (Chen et al., 2020). Very recently, SPI (Xu et al., 2023) has applied short-run MCMC (Erik et al., 2019) for posterior sampling on the collaborative latent spaces.\nWhile these latent variable modeling algorithms can effectively perform unsupervised joint training, the entire training of the retriever is still difficult and imposes restrictions on the selection of the retriever in terms of both a search algorithm and a knowledge resource. Furthermore, the additional posterior sampling through separate networks or multiple iterations in the previous variational methods also leads to increased training complexity as well as the training-inference discrepancy in knowledge generation. In contrast, the proposed ELVM can employ any kind of retriever in latent variable modeling since it controls a retrieval output by only changing of a generated query. Moreover, ELVM removes an extra posterior modeling or sampling by prior subset sampling and approximated posterior distillation, which leads to efficient training without the discrepancy."
        },
        {
            "heading": "2.3 Query Generation",
            "text": "When an off-the-shelf retriever is used for knowledge retrieval, how to make an input text query\nis important for obtaining appropriate documents. Especially, in knowledge-grounded dialogue, a self-contained query should be generated from the multi-turn dialogue context. A number of prior works have tried to train a supervised query rewriting model by human rewrites (Yu et al., 2020; Lin et al., 2020; Vakulenko et al., 2021; Voskarides et al., 2020). Similar to the knowledge annotation, the limitations of manual query annotation have came up with unsupervised learning of the query generator. A number of works have proposed a novel rewards for reinforcement learning of a query rewriter (Wu et al., 2022; Chen et al., 2022).\nQKConv (Cai et al., 2023) has proposed an unsupervised query enhanced method for knowledgegrounded conversation. This work is similar to ours in that it consists of a query generator, an offthe-shelf knowledge retriever, and a response generator, and unsupervised joint training is applied to the query generator and the response generator. However, their training objective is based on the approximated marginal likelihood over candidate queries, which is different from our objective that includes the posterior distillation based on the ELBO loss."
        },
        {
            "heading": "3 Efficient Latent Variable Model for Knowledge-Grounded Dialogue Generation",
            "text": ""
        },
        {
            "heading": "3.1 Setup",
            "text": "In this section, we explain an overall structure of our ELVM, as described in Figure 1a, and define notations. Unlike previous works of document (passage) retrieval (Zhang et al., 2022; Huang et al., 2021; Lewis et al., 2020) using a query of an embedded vector of a dialogue context x, we use a text query of natural language, which enables to utilize any kind of retriever for dialogue response generation. We define the probability of generating a natural language query u for a given dialogue context x, p\u03d5(u|x), as below:\np\u03d5(u|x) = \u220f t p\u03d5(ut|u0:t\u22121, x), (1)\nwhere ut is the t-th token in u and p\u03d5 is the probability obtained from the model parameterized by \u03d5. Similarly, the probability of generating a response y for a given query u and dialogue context x is defined as\np\u03b8(y|Z(u), x) = \u220f t p\u03b8(yt|y0:t\u22121, Z(u), x), (2)\nwhere yt is the t-th token in y, Z(u) = {z1, z2, ..., zk} is the set of retrieved documents (passages) by u, and \u03b8 is the model parameters to produce the response probability. Here, we use top-k result obtained by an off-the-shelf retriever such as BM25 (Robertson et al., 2009) and DPR (Karpukhin et al., 2020) and freeze the retriever. We assume that there is a deterministic mapping from u to Z. We now set a query u as a latent variable. Then, using the prior p\u03d5(u|x) associated with the query generator and the conditional likelihood p\u03b8(y|Z(u), x) corresponding to the response generator, we can define the marginal likelihood of the knowledge-grounded response y given the dialogue context x as below:\np\u03b8,\u03d5(y|x) = \u2211 u\u2208Q p\u03d5(u|x)p\u03b8(y|Z(u), x), (3)\nwhere Q is the set of all possible queries. Since it is intractable to marginalize over all queries, we sample a small subset composed of m unique queries, Qs(x) = {u1, u2, ..., um} using p\u03d5(\u00b7|x) and then marginalize over this set as below:\np\u0303\u03b8,\u03d5(y|x) = \u2211 u\u2208Qs p\u0304\u03d5(u|x)p\u03b8(y|Z(u), x), (4)\nwhere\np\u0304\u03d5(u|x) = p\u03d5(u|x)\u2211\nu\u2032\u2208Qs p\u03d5(u \u2032|x)\n. (5)\nWe construct Qs by obtaining m-unique queries sampled from p\u03d5(\u00b7|x). It is noted that our response generator takes multiple retrieved documents efficiently using FiD (Izacard and Grave, 2020), which is different from the use of a single document for response generation in previous methods. In addition, while we can utilize relative matching scores from the retriever to assign varying likelihoods to each document given a query for p(Z(u)|u), we have noticed that this approach can occasionally hinder the effective and comprehensive learning of the query generator. During the training process, that will be described in the next subsection, our objective is to amplify the impact of the generated query. Consequently, we opt for a deterministic mapping from a query to a set of retrieved documents as a unified whole, aiming to enhance the gradient flow."
        },
        {
            "heading": "3.2 Joint Training",
            "text": "Our training objective is the ELBO (Kingma and Welling, 2013; Jordan et al., 1999) of log p\u0303\u03b8,\u03d5 which can be written as below:\nlog p\u0303\u03b8,\u03d5(y|x) \u2265 Eu\u223cq(u|x,y)[log p\u03b8(y|Z(u), x)] \u2212DKL ( q(u|x, y)||p\u0304\u03d5(u|x) ) , (6)\nwhere q(u|x, y) is the variational posterior. Note that the equality holds when q(u|x, y) is identical to the true posterior distribution of it. In this work,\nwe do not parameterize q(u|x, y) and approximate the expected conditional likelihood in the ELBO by sampling u from not q(u|x, y) but p\u0304\u03d5(u|x) such as\nEu\u223cq(u|x,y)[log p\u03b8(y|Z(u), x)] \u2248 Eu\u223cp\u0304\u03d5(u|x)[log p\u03b8(y|Z(u), x)]. (7)\nThis approximation is due to that it minimizes the discrepancy between training and test time inference and it does not separately model q(u|x, y) or complicatedly sample from it during training. Then, we obtain the following two losses corresponding to the expected conditional likelihood and the KL regularization such as\nLy,u(\u03b8, \u03d5) = \u2212Eu\u223cp\u0304\u03d5(u|x)[log p\u03b8(y|Z(u), x)],(8) Lu(\u03d5) =DKL ( q(u|x, y)||p\u0304\u03d5(u|x) ) . (9)\nMoreover, we define q(u|x, y) in Lu(\u03d5) by the approximated posterior derived from the prior and the likelihood such as\nq(u|x, y) = p\u03b8(y|Z(u), x)p\u0304\u03d5(u|x)\u2211\nu\u2032\u2208Qs p\u03b8(y|Z(u\u2032), x)p\u0304\u03d5(u\u2032|x) .\n(10) We set this posterior distribution q(u|x, y) as a teacher for a distillation to update the prior associated with the query generation at test time. Namely, Lu(\u03d5) becomes the posterior distillation loss, and our prior is explicitly updated to be similar to the posterior. Here, the gradient is not propagated from q(u|x, y), and q(u|x, y) can be computed easily without additional model or approximation since we define it over the subset Qs.\nTo sum up, we obtain the conditional likelihood loss and the posterior distillation loss by multiple samples from the prior distribution that is aligned with query sampling at the inference time. We would mitigate the bias of prior sampling by multiple query samples for each input during training. In addition, our modification of ELBO is different from the expectation-maximization (EM) algorithm in that we sample a latent variable from the prior distribution rather than the posterior distribution that is used for sampling of E-step in EM. Moreover, in contrast to the M-step loss, we use the prior-weighted conditional likelihood and the gradient is also propagated to the sampled latents and the corresponding prior model. For experiments in this paper, the query generator \u03d5 and the response generator \u03b8 share parameters, with different input prompts to distinguish each module, for simplicity.\nOverall, the loss for our joint training is\nL(\u03b8, \u03d5) = Ly,u(\u03b8, \u03d5) + \u03b2Lu(\u03d5), (11)\nwhere \u03b2 is the relative weight for the posterior distillation loss."
        },
        {
            "heading": "4 Experiment",
            "text": ""
        },
        {
            "heading": "4.1 Experimental Setup",
            "text": "Dataset. Our experiments are conducted on two widely used knowledge-grounded dialogue datasets, Wizard of Wikipedia (WoW) (Dinan et al., 2018) and QReCC (Anantha et al., 2021). WoW is structured around dialogues that are grounded in knowledge sentences sourced from Wikipedia, consisting of roughly 18K, 2K, and 2K dialogues, for training, validation, and test subsets, respectively. QReCC is a comprehensive compilation of conversational data, consisting of 14K open-domain conversations comprising 80K question-answer pairs.\nTraining. We begin with publicly available R2C2 pre-trained transformer model (Shuster et al., 2022a) with 400M parameter size and fine-tune it on multiple datasets to acquire the essential skill sets for knowledge-grounded dialogue such as query generation and knowledge-grounded response generation. Detailed tasks and statistics are shown in Table 1. In line with Shuster et al. (2022b), we adopt a modular system with a single model that incorporates control tokens into the dialogue context to perform different modules. For example, appending the control token __generate-query__ to the dialogue context promotes the model to generate relevant search query. We name the initial model from this pretraining procedure as R2C2-PT. Subsequently, we apply our proposed algorithm to R2C2-PT model,\nresulting in ELVM. Furthermore, to dispel concerns that our training gains might predominantly stem from R2C2-PT\u2019s comprehensive fine-tuning across multiple datasets rather than ELVM\u2019s inherent efficacy, we opted to utilize the base R2C2 model. Upon integrating it with ELVM, the resulting configuration is denoted as ELVM-from-R2C2.\nDuring the training of ELVM, we employ a sampling-based generation method, specifically nucleus sampling (Holtzman et al., 2020), to promote diverse query generation in p\u03d5. When retrieving documents based on the generated queries, we utilize an off-the-shelf sparse retriever such as BM25 (Robertson et al., 2009), prioritizing low latency over the dense retriever (DR). We train for 3 epochs with m = 4 and k = 5 for WoW and 1 epoch with m = 8 and k = 10 for QReCC. \u03b2 is set to 1 for both tasks, unless stated otherwise. To ensure a thorough evaluation of ELVM\u2019s performance and its ability to generalize to unseen dialogues, we purposely avoid dataset overlap between training of R2C2-PT and ELVM. More detailed information on the training process can be found in Appendix A.\nInference. During inference, unlike the training phase, only a single query is generated by the query generator p\u03d5. The default number of retrieved documents k from the off-the-shelf retriever is set to 5 for WoW and 10 for QReCC. The knowledgegrounded response is generated by the response generator, p\u03b8. An illustration of the inference is depicted in Figure 1b. During the inference, both query and response generation are conducted using beam search with a beam size of 5.\nVariants of ELVM. To examine the impact of the proposed ELVM training, we explore another variant, ELVM-OK, which is trained on the response generation task with annotated oracle knowledge documents while keeping the query generator p\u03d5\nfrozen. During inference, given a dialogue context the frozen query generator p\u03d5 generates query and use the off-the-shelf retriever to bring relevant documents. Finally the response generator of ELVM-OK generates the final response.\nIn Section 3.2, we describe the difference between ELVM training and EM algorithm. In order to quantitatively compare these two methods, we perform EM-like training in ELVM where we apply the posterior-weighted conditional likelihood in Ly,u(\u03b8, \u03d5): Ly,u(\u03b8, \u03d5) = \u2212 \u2211\nu SG(q(u|x, y)) log p\u03b8(y|Z(u), x). Here, the query latents u are still sampled from the prior distribution, and SG means the stop-gradient that prevents the gradient propagation to the query generator. We name this variant as ELVM-EM-Like."
        },
        {
            "heading": "4.2 Automatic Evaluation",
            "text": "The evaluation results of WoW test seen and unseen tasks are shown in Table 2. ELVM surpasses all its variants and previous state-of-the-art (SOTA) model, achieving a new SOTA on both WoW test seen unseen tasks, across all metrics. In addition, ELVM-OK demonstrates notable improvements in BLEU and Rouge scores compared to previous models with a slight drawback in PPL. Similarly, ELVM-EM-Like also exhibits competitive performance across multiple metrics. Moreover, when comparing ELVM-from-R2C2 and ELVM, the experiment demonstrates that while R2C2-PT offers marginal benefits, the marked performance\nincrease is predominantly attributable to ELVM. We further examine the performance of query generator by assessing the recall of the ground-truth documents. The results summarized in Table 3 reveal that training with our proposed algorithm leads to an increase in recall for both ELVM-\u03b2=0 and ELVM compared to R2C2-PT while the latter yields a larger performance gain. This highlights the effectiveness of distilling the posterior distribution of the response generator into the prior distribution associated with the query generator.\nFor QReCC, as shown in Table 4, ELVM surpasses the previous SOTA, QKConv (Cai et al., 2023), the recent previous works (Raposo et al., 2022; Kim and Kim, 2022), and the variants of ELVM including R2C2-PT and ELVM-OK in terms of all metrics. The recall performance on QReCC is included in Table C."
        },
        {
            "heading": "4.3 Human Evaluation",
            "text": "To gauge performance across multiple aspects of the quality of generated responses, human evaluation is performed on the generated responses of ELVM and KnowledGPT (Zhao et al., 2020)1. Similar to (Rashkin et al., 2021) and (Xu et al., 2023), we assess the response quality in two aspects: Fluency and Relevance. Fluency measures whether the response is understandable, self-consistent without repetition, and proficient. Relevance assesses the extent to which the response aligns with the dialogue context, incorporates pertinent knowledge, and maintains appropriateness. In total, 50 data\n1We choose KnowledGPT because it is the best performing model among publicly available models.\nsamples are randomly selected from WoW tasks where 25 samples are randomly selected from each seen and unseen task. The qualities of the responses are measured by A/B testing on the two aspects. The feedback is collected from 11 human experts. Further details and annotator instructions can be found in Table G. As shown in Table 5, ELVM significantly outperforms KnowledGPT in all aspects especially on the unseen task."
        },
        {
            "heading": "4.4 Ablation Studies",
            "text": "Number of Queries. The size of sampled query set Qs, m, plays a huge role in training of ELVM, as it directly influences the bias of the marginal likelihood of the knowledge-grounded response y. To investigate the impact of m, we gradually increase m from 1 to 8 and measure the performance on WoW while keeping other hyperparameters fixed. As shown in Table 6, we observe a positive correlation where increasing m leads to improved performance. Notably, setting m = 4 yields the optimal performance for both seen and unseen tasks.\nPosterior Distillation Weight. We examine the influence of the posterior distillation loss on ELVM training by adjusting the value of \u03b2. The experimental results presented in Table 7 reveal that the optimal performance is attained when \u03b2 = 1 for both the WoW unseen and QReCC tasks, indicating the effectiveness of incorporating the posterior distillation loss. However, a substantial decline in\nperformance is observed when \u03b2 is increased to 5 or set to 0, particularly in the case of QReCC.\nVarying the Retriever. We extend our experiments by incorporating the DR in two distinct ways. For WoW, we train and evaluate using allMiniLM-L6-v22 DR. In contrast, for QReCC, due to its extensive knowledge pool, we leverage DR solely during evaluation by employing both the BM25 retriever and all-mpnet-base-v23 DR in a hybrid manner to retrieve the top-k documents. Concretely, we score each document by summing up the normalized score of each retriever and rerank to obtain top-k documents. Table 8 presents a summary of the performance results of employing DR, demonstrating a successful integration of DR in different settings of ELVM.\nScaling Up Model. We investigate the impact of increasing the model size on performance. Starting with the publicly available 2.7B R2C2 pretrained transformer, we follow exactly the same procedure outlined in Section 3.2 to obtain R2C2PTLarge, ELVM-OKLarge and ELVMLarge. Detailed hyperparameters for training 2.7B model is given in Appendix A. The results presented in Table 9 demonstrate that as the model size increases, there is an improvement in performance across all metrics, supporting the scalability of ELVM.\nBART as Base. To ensure a fair comparison and further demonstrate the robustness of our algorithm on diverse model scales, we conduct an experiment employing BART (Lewis et al., 2019) base as an initial model and then apply our proposed algorithm on WoW dataset. We choose BART base model since the previous SOTA model (Xu et al., 2023) utilized BART base as their base model. The outcome of this training is termed ELVM-from-BART. As shown in Table 10, the initial BART model shows very poor performances. However, upon training the BART-base with our ELVM algorithm, there is a great improvement in performance across both WoW Seen and Unseen tasks. Importantly, the results surpass the performance benchmarks set by the previous SOTA model (SPI).\nRetriever Switching To assess the robustness of our algorithm to the retriever mismatch between training and inference phases, we undertake an\n2https://huggingface.co/sentence-transformers/allMiniLM-L6-v2\n3https://huggingface.co/sentence-transformers/all-mpnetbase-v2\nadditional experiment, of which the results are depicted in Table 11. In this experiment, we train the WoW task utilizing either BM25 or dense retriever (utilizing all-MiniLM-L6-v2 retriever, as detailed Section 4), and subsequently evaluate using either BM25 or dense retriever. The results on the WoW unseen test indicate that utilizing a different retriever during testing doesn\u2019t necessitate model re-training, particularly given the superior performance of the dense retriever compared to BM25."
        },
        {
            "heading": "4.5 Qualitative Analysis",
            "text": "For qualitative analysis, we examine the generated samples from KnowledGPT, R2C2-PT and other variants of ELVM, whose samples are presented in Table 12. The example reveals that the queries generated by KnowledGPT, R2C2-PT and ELVM-\u03b2=0 fail to retrieve the relevant knowledge effectively while the queries generated by ELVM with BM25 and DR (all-MiniLM-L6-v2) reflects the ability to access the relevant knowledge, leading to improved responses. The results also demonstrate that the query generator trained with our algorithm effectively adapts to the chosen retriever."
        },
        {
            "heading": "5 Conclusion",
            "text": "In this paper, we propose ELVM as an efficient latent variable modeling for knowledge-intensive dialogue generation. In ELVM, the knowledge retrieval is realized by the query generation followed by document retrieval using the off-the-shelf retriever for ease of joint training of both the retriever and the response generator, without the knowledge supervision. Furthermore, the training scheme of ELVM modifies the ELBO for the marginal likelihood to effectively perform the joint training without the use of complex posterior sampling, which also eliminates the discrepancy between the training-time and test-time knowledge samplings. ELVM empirically demonstrates that it significant outperforms over previous latent variable methods with in-depth analysis on diverse dialogue datasets.\nLimitations\nThere are a number of limitations and possible directions to future works of ELVM proposed in this paper. First, as more large language models beyond the scale of hundreds of billion parameters are emerging, there are rooms for emergent behaviors in ELVM as the sizes of data and model grow that\nhas not been tested in this paper. Second, instead of the prior sampling that we use, fast posterior sampling such as short-run MCMC (Erik et al., 2019; Xu et al., 2023) is also an alternative candidate. Third, the experiments in this paper retrieve documents from confined set (e.g., Wikipedia) using light retriever such as BM25 and dense retriever. However, real-world applications often rely on the web which has much bigger pool of documents from broader open-domain. In turn, we should consider future extension of this work to utilizing larger public search engines. Last, we may consider alternative yet more effective means of query sampling during training other than a small set of random samples, as the current design. Other possible methods include imposing additional guidance for query sampling or multiple refinements of query sampling and knowledge retrieval for more diverse set.\nEthics Statement\nThis work presents no direct ethical issues. However, there is a possibility that the generated responses may inadvertently contain inadequate, biased, or discriminatory content. We do not introduce new datasets, and all experiments are conducted using publicly available datasets."
        },
        {
            "heading": "Acknowledgments",
            "text": "This work was supported by Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT)(No. 2019-0-00079, Artificial Intelligence Graduate School Program, Korea University). In addition, this work was also supported by Artificial intelligence industrial convergence cluster development project funded by the Ministry of Science and ICT(MSIT, Korea) Gwangju Metropolitan City. Finally, we would also like to thank Brain Cloud Team at Kakao Brain for their support."
        },
        {
            "heading": "A Training Details",
            "text": "Table 13 we provide hyperparameters utilized during this training process. We also report hyperparameters used for training ELVM and its variants model (ELVM-OK and ELVM-EM-Like) in Table 14. In addition, during training of QReCC, we adopt a strategy to decrease the knowledge pool size from 54M to 1M. This reduction aims to mitigate latency issues during document retrieval. Concretely, the 1M pool is constructed by initially gathering the ground-truth relevant passage for each instance in the training dataset then adding randomly sampled documents. During the evaluation stage, we utilize the original full-size knowledge pool of 54M passages."
        },
        {
            "heading": "B Upper Bound Performance",
            "text": "We believe in the value of understanding the utmost capability in an ideal scenario. To this end, we pursue an upper-bound performance analysis for both the WoW and QReCC tasks. This approach\ninvolves training our response generator under the assumption that the model has access to the groundtruth document during both training and evaluation. The performance metrics of this specific setup are designated as \"ELVM-w-GT-Doc\" in Table 15 and Table 16. From both tables, it\u2019s evident that there still remains a margin for improvement for both tasks."
        },
        {
            "heading": "C Document Recall Performance",
            "text": "We report the document recall performance on QReCC, including different types of queries, as show in Table 17. Our proposed model, ELVM, surpasses both its variants and non-model generated queries such as using dialogue context as a query. The document recall performance on QReCC, encompassing various query types, is presented in Table 17. Our proposed ELVM model outperforms its variants as well as non-model generated queries, including the use of dialogue context as a query. Moreover, incorporating the dense retriever for reranking documents (ELVMDR) leads to further improvements in recall."
        },
        {
            "heading": "D Knowledge Pool Scaling",
            "text": "In order to create a more realistic and challenging retrieval scenario, we expand the original setting of the WoW dataset by increasing the number of relevant documents per instance to 1000. This modification better reflects real-world information retrieval scenarios where a vast array of both relevant and irrelevant documents are typically encountered. We construct this extended dataset by randomly augmenting 1000 - K documents from the WoW dataset to the document pool for each instance, where K represents the number of annotated relevant documents for each instance. On average, K \u2248 20 for each instance in WoW dataset.\nResults in Table 18 show performances of ELVM models with different number of retrieved documents, k, and knowledge pool size, where models with increased knowledge pool has tailing keyword Bulk at then end of their names. Despite the increase in complexity of the retrieval task, ELVM demonstrates robust performance, with only a marginal drop in metrics compared to the original setting. Furthermore, it is important to highlight that even under these more difficult conditions with 1000 relevant documents, ELVM still outperforms SPI by a significant margin."
        },
        {
            "heading": "E Effect of Parameter Sharing",
            "text": "In our ELVM training, parameters are shared between the query and response generators. To probe this design choice, we decoupled these parameters, resulting in the ELVM-Decouple configuration, as detailed in Table 19. Upon evaluation on WoW\u2019s test seen and unseen tasks, ELVM-\nDecouple showed a slight edge over the standard ELVM. Nevertheless, the benefits of shared parameters\u2014particularly regarding computational efficiency and knowledge transfer during training and inference\u2014cannot be understated."
        },
        {
            "heading": "F Additional Metrics",
            "text": "We report the evaluation of our models on the WoW task using both F1 and knowledge F1 (KF1) metrics in Table 20. For reference, values pertaining to previous models are derived from Sun et al. (2023)."
        },
        {
            "heading": "G Human Evaluation",
            "text": "For a comprehensive evaluation, we conduct the human evaluation between ELVM and KnowledGPT on seen and unseen tasks in WoW (Dinan et al., 2018). We randomly select 50 samples (25 samples per task), and each sample is evaluated by 11 different human experts. In specific, the two generated responses from each model in the same context are assigned to the annotators. For A/B testing, we give one score to the model if it\u2019s response is received an equally good or better than the other one. Figure 2 shows the annotator instructions for the two aspects."
        },
        {
            "heading": "H Generated Samples",
            "text": "Generated samples for the WoW test unseen are presented in Table 21 and Table 22. Similarly, Table 23 and Table 24 showcase the generated samples for the QReCC test."
        }
    ],
    "title": "Efficient Latent Variable Modeling for Knowledge-Grounded Dialogue Generation",
    "year": 2023
}