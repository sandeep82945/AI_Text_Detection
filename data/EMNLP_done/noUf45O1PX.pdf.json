{
    "abstractText": "Lemmatization holds significance in both natural language processing (NLP) and linguistics, as it effectively decreases data density and aids in comprehending contextual meaning. However, due to the highly inflected nature and morphological richness, lemmatization in Bangla text poses a complex challenge. In this study, we propose linguistic rules for lemmatization and utilize a dictionary along with the rules to design a lemmatizer specifically for Bangla. Our system aims to lemmatize words based on their parts of speech class within a given sentence. Unlike previous rule-based approaches, we analyzed the suffix marker occurrence according to the morpho-syntactic values and then utilized sequences of suffix markers instead of entire suffixes. To develop our rules, we analyze a large corpus of Bangla text from various domains, sources, and time periods to observe the word formation of inflected words. The lemmatizer achieves an accuracy of 96.36% when tested against a manually annotated test dataset by trained linguists and demonstrates competitive performance on three previously published Bangla lemmatization datasets. We are making the code and datasets publicly available at https://github.com/ eblict-gigatech/BanLemma1 in order to contribute to the further advancement of Bangla NLP.",
    "authors": [
        {
            "affiliations": [],
            "name": "Sadia Afrin"
        },
        {
            "affiliations": [],
            "name": "Md. Shahad Mahmud Chowdhury"
        },
        {
            "affiliations": [],
            "name": "Md. Ekramul Islam"
        },
        {
            "affiliations": [],
            "name": "Faisal Ahamed Khan"
        },
        {
            "affiliations": [],
            "name": "Labib Imam Chowdhury"
        },
        {
            "affiliations": [],
            "name": "MD. Motahar Mahtab"
        },
        {
            "affiliations": [],
            "name": "Nazifa Nuha Chowdhury"
        },
        {
            "affiliations": [],
            "name": "Massud Forkan"
        },
        {
            "affiliations": [],
            "name": "Neelima Kundu"
        },
        {
            "affiliations": [],
            "name": "Hakim Arif"
        },
        {
            "affiliations": [],
            "name": "Mohammad Mamun"
        },
        {
            "affiliations": [],
            "name": "Or Rashid"
        },
        {
            "affiliations": [],
            "name": "Mohammad Ruhul Amin"
        },
        {
            "affiliations": [],
            "name": "Nabeel Mohammed"
        }
    ],
    "id": "SP:dc41ba4edb0d9c3eea32ac2b4454fe7d4a76ef54",
    "references": [
        {
            "authors": [
                "Accessible."
            ],
            "title": "Accessible dictionary",
            "venue": "https:// accessibledictionary.gov.bd/. (Accessed on 04/24/2023).",
            "year": 2023
        },
        {
            "authors": [
                "Anwesa Bagchi."
            ],
            "title": "Postpositions in bangla",
            "venue": "Language in India, 7(11).",
            "year": 2007
        },
        {
            "authors": [
                "Vimala Balakrishnan",
                "Ethel Lloyd-Yemoh"
            ],
            "title": "Stemming and lemmatization: A comparison of retrieval performances",
            "year": 2014
        },
        {
            "authors": [
                "Kalika Bali",
                "Choudhury Monojit",
                "Priyanka Biswas."
            ],
            "title": "Indian language part-of-speech tagset: Bengali - linguistic data consortium",
            "venue": "https: //catalog.ldc.upenn.edu/LDC2010T16. (Accessed on 06/15/2023).",
            "year": 2010
        },
        {
            "authors": [
                "Samit Bhattacharya",
                "Monojit Choudhury",
                "Sudeshna Sarkar",
                "Anupam Basu."
            ],
            "title": "Inflectional morphology synthesis for bengali noun, pronoun and verb systems",
            "venue": "InProc. of the National Conference on Computer Processing of Bangla (NCCPB 05), pages",
            "year": 2005
        },
        {
            "authors": [
                "Marine Carpuat."
            ],
            "title": "Nrc: A machine translation approach to cross-lingual word sense disambiguation (semeval-2013 task 10)",
            "venue": "Second Joint Conference on Lexical and Computational Semantics (* SEM), Volume 2: Proceedings of the Seventh International",
            "year": 2013
        },
        {
            "authors": [
                "Abhisek Chakrabarty",
                "Akshay Chaturvedi",
                "Utpal Garain."
            ],
            "title": "A neural lemmatizer for bengali",
            "venue": "Proceedings of the Tenth International Conference",
            "year": 2016
        },
        {
            "authors": [
                "Abhisek Chakrabarty",
                "Utpal Garain."
            ],
            "title": "Benlem (a bengali lemmatizer) and its role in wsd",
            "venue": "ACM Trans. Asian Low-Resour. Lang. Inf. Process., 15(3).",
            "year": 2016
        },
        {
            "authors": [
                "Abhisek Chakrabarty",
                "Onkar Arun Pandit",
                "Utpal Garain."
            ],
            "title": "Context sensitive lemmatization using two successive bidirectional gated recurrent networks",
            "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Vol-",
            "year": 2017
        },
        {
            "authors": [
                "J Choudhury."
            ],
            "title": "Bangla academy bangla banan abhidhan",
            "venue": "Pmo.gov.bd.",
            "year": 2008
        },
        {
            "authors": [
                "Jamil Chowdhury."
            ],
            "title": "Bangla akademy banan abhidhan",
            "venue": "https://nltr.itewb.gov.in/ download/Bangla_word-list.doc. (Accessed on 04/24/2023).",
            "year": 2012
        },
        {
            "authors": [
                "Thomas H. Cormen",
                "Charles E. Leiserson",
                "Ronald L. Rivest",
                "Clifford Stein."
            ],
            "title": "Introduction to Algorithms, Third Edition, 3rd edition",
            "venue": "The MIT Press.",
            "year": 2009
        },
        {
            "authors": [
                "Arijit Das",
                "Tapas Halder",
                "Diganta Saha."
            ],
            "title": "Automatic extraction of bengali root verbs using paninian grammar",
            "venue": "2017 2nd IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT),",
            "year": 2017
        },
        {
            "authors": [
                "Souvick Das",
                "Rajat Pandit",
                "Sudip Kumar Naskar."
            ],
            "title": "A rule based lightweight bengali stemmer",
            "venue": "Proceedings of the 17th International Conference on Natural Language Processing (ICON), pages 400\u2013 408.",
            "year": 2020
        },
        {
            "authors": [
                "Niladri Sekhar Dash."
            ],
            "title": "Bangla pronouns-a corpus based study",
            "venue": "Literary and linguistic computing, 15(4):433\u2013444.",
            "year": 2000
        },
        {
            "authors": [
                "Marie-Catherine de Marneffe",
                "Timothy Dozat",
                "Natalia Silveira",
                "Katri Haverinen",
                "Filip Ginter",
                "Joakim Nivre",
                "Christopher D. Manning."
            ],
            "title": "Universal Stanford dependencies: A cross-linguistic typology",
            "venue": "In",
            "year": 2014
        },
        {
            "authors": [
                "Abu Zaher Md Faridee",
                "Francis Tyers."
            ],
            "title": "Development of a morphological analyser for bengali",
            "venue": "Proceedings of the First International Workshop on Free/Open-Source Rule-Based Machine Translation.",
            "year": 2009
        },
        {
            "authors": [
                "Md Ashraful Islam",
                "Md Towhiduzzaman",
                "Md Tauhidul Islam Bhuiyan",
                "Abdullah Al Maruf",
                "Jesan Ahammed Ovi."
            ],
            "title": "Banel: an encoderdecoder based bangla neural lemmatizer",
            "venue": "SN Applied Sciences, 4(5):138.",
            "year": 2022
        },
        {
            "authors": [
                "Rafiqul Islam",
                "Pabitra Sarkar."
            ],
            "title": "Bangla Academy Pramita Bangla Bhashar Byakaran",
            "venue": "Bangla Academy.",
            "year": 2017
        },
        {
            "authors": [
                "Rafiqul Islam",
                "Pabitra Sarkar",
                "Mahbubul Haque."
            ],
            "title": "Bangla Academy Pramita Bangla Bhaboharik Byakaran",
            "venue": "Bangla Academy.",
            "year": 2014
        },
        {
            "authors": [
                "Jenna Kanerva",
                "Filip Ginter",
                "Niko Miekka",
                "Akseli Leino",
                "Tapio Salakoski."
            ],
            "title": "Turku neural parser pipeline: An end-to-end system for the CoNLL 2018 shared task",
            "venue": "Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing",
            "year": 2018
        },
        {
            "authors": [
                "Michal Karwatowski",
                "Marcin Pietron"
            ],
            "title": "Context based lemmatizer for polish language",
            "year": 2022
        },
        {
            "authors": [
                "Md Kowsher",
                "Imran Hossen",
                "Skshohorab Ahmed",
                "Seth Darren."
            ],
            "title": "Bengali information retrieval system (birs)",
            "venue": "Linguistics, 8:1\u201312.",
            "year": 2019
        },
        {
            "authors": [
                "Rochelle Lieber."
            ],
            "title": "Introducing morphology",
            "venue": "Cambridge University Press.",
            "year": 2021
        },
        {
            "authors": [
                "Md Redowan Mahmud",
                "Mahbuba Afrin",
                "Md Abdur Razzaque",
                "Ellis Miller",
                "Joel Iwashige."
            ],
            "title": "A rule based bengali stemmer",
            "venue": "2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI), pages 2750\u20132756.",
            "year": 2014
        },
        {
            "authors": [
                "Joakim Nivre",
                "Daniel Zeman",
                "Filip Ginter",
                "Francis Tyers."
            ],
            "title": "Universal Dependencies",
            "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts, Valencia, Spain. Association for",
            "year": 2017
        },
        {
            "authors": [
                "Alok Ranjan Pal",
                "Niladri Sekhar Dash",
                "Diganta Saha."
            ],
            "title": "An innovative lemmatization technique for bangla nouns by using longest suffix stripping methodology in decreasing order",
            "venue": "2015 International Conference on Computing and Network Com-",
            "year": 2015
        },
        {
            "authors": [
                "Peng Qi",
                "Timothy Dozat",
                "Yuhao Zhang",
                "Christopher D.Manning."
            ],
            "title": "Universal Dependency parsing from scratch",
            "venue": "Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, pages 160\u2013170, Brus-",
            "year": 2018
        },
        {
            "authors": [
                "Sagor Sarker."
            ],
            "title": "Bnlp: Natural language processing toolkit for bengali language",
            "venue": "arXiv preprint arXiv:2102.00405.",
            "year": 2021
        },
        {
            "authors": [
                "Kumar Saunack",
                "Kumar Saurav",
                "Pushpak Bhattacharyya."
            ],
            "title": "How low is too low? a monolingual take on lemmatisation in Indian languages",
            "venue": "Proceedings of the 2021 Conference of the North",
            "year": 2021
        },
        {
            "authors": [
                "Michal Toman",
                "Roman Tesar",
                "Karel Jezek."
            ],
            "title": "Influence of word normalization on text classification",
            "venue": "Proceedings of InSciT, 4:354\u2013358.",
            "year": 2006
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Lemmatization is a crucial task in Natural Language Processing (NLP), where the goal is to obtain the base form of a word, known as the lemma. It has widespread applications in several NLP tasks, such as information retrieval (Balakrishnan and Lloyd-Yemoh, 2014), text classification (Toman et al., 2006), machine translation\n\u2217Corresponding author (faisal.cse06@gigatechltd.com) 1The repository contains the codes, analysis dataset, list of\nmarkers, test datasets, and a sample dictionary.\n(Carpuat, 2013), etc. Lemmatization is a particularly challenging task in highly inflectional languages such as Bangla (Bhattacharya et al., 2005), due to the large number of inflectional and derivational suffixes that can be added to words. Generally, lemmatization reduces the inflectional form of a word to its dictionary form. Lemmatization in Bangla has several challenges due to various linguistic factors. Firstly, the language exhibits a wide range of morphological diversity, making it difficult for a system to cover all its aspects (Islam et al., 2022). Secondly, Bangla has approximately 50000 roots, each capable of generating a large number of inflected words based on several factors such as tense, gender, and number (Chakrabarty et al., 2016). Thirdly, Bangla words can have multiple meanings, known as polysemy, depending on their Part-of-Speech (PoS), surrounding words, context, and other factors (Chakrabarty and Garain, 2016). Additionally, the development of lemmatization systems for this complex morphological language is hindered by the lack of available resources. Prior research attempts have employed different methodologies (e.g., learning-based, rule-based, and hybrid approaches) (Pal et al., 2015\u037e Das et al., 2017\u037e Islam et al., 2022\u037e Chakrabarty and Garain, 2016). Despite the fact that some studies have shown satisfactory performance in specific scenarios, there remains a pressing need for a robust lemmatizer tailored to the Bangla language. In this study, we have taken a rule and dictionary-based approach to tackle the lemmatization problem in Bangla. Unlike other rule-based studies for lemmatization in Bangla, we have derived the stripping methods based on the suffix marker sequences considering the PoS class of a word. A suffix \u09c7\u09a6\u09b0\u0997\u09c1\u09c7\u09b2\u09be\u09c7\u09a4 (de\u032argulote\u032a) from a word \u09bf\u09b6\u09b6\u09c1\u09c7\u09a6\u09b0\u0997\u09c1\u09c7\u09b2\u09be\u09c7\u09a4 (\u0283i\u0283ude\u032argulote\u032a) is a combination of \u09c7\u09a6\u09b0 (de\u032ar), \u0997\u09c1\u09c7\u09b2\u09be (gulo), and \u09c7\u09a4 (te\u032a) markers. We strip the last to the first marker sequentially to ob-\ntain the lemma \u09bf\u09b6\u09b6\u09c1 (\u0283i\u0283u\u037e child). To derive the marker sequences, we analyzed the word formations using a large Bangla text corpus. By embracing the marker sequence striping approach, we are able to effectively address a wide range of suffixes in the Bangla language, where other studies exhibit substantial limitations. Figure 1 shows an illustration of our lemmatization process and its effectiveness in cross-dataset settings where our lemmatizer achieves higher accuracy than other lemmatizers when tested on their respective datasets (Chakrabarty and Garain, 2016\u037e Islam et al., 2022\u037e Chakrabarty et al., 2017). The key contributions of this study are as follows:\n\u2022 We introduce BanLemma, a lemmatization system specifically designed for Bangla. By leveraging a precisely crafted linguistical framework, our system demonstrates superior performance compared to existing state-ofthe-art Bangla lemmatization methods.\n\u2022 We present a set of linguistical rules interpreting the process by which inflected words in the Bangla language are derived from their respective base words or lemmas.\n\u2022 The linguistic rules are derived from rigorous analysis conducted on an extensive Bangla text corpus of 90.65M unique sentences. It encompasses a vast collection of 0.5B words, where 6.17M words are distinct. We sampled\n22675 words through a systematic approach to manually analyze the inflected words.\n\u2022 To assess the efficacy of BanLemma, we have employed both intra-dataset and cross-dataset evaluation. This evaluation framework enables us to measure the robustness of our proposed system across multiple datasets.\n\u2022 Utilizing human annotated PoS tag, we have achieved 96.36% accuracy on intra-dataset testing. Moreover, in cross-dataset testing, BanLemma surpasses recently published methodologies, exhibiting substantial performance improvements ranging from 1% to 11% (see Figure 1b), which implies our proposed BanLemma\u2019s robustness."
        },
        {
            "heading": "2 Related Work",
            "text": "Preliminary works on lemmatization mainly consisted of rule-based and statistical approaches. Pal et al. (2015) created a Bangla lemmatizer for nouns where they removed non-inflected nouns using the Bangla Academy non-inflected word list (Choudhury, 2008) and removed the suffixes via the longest match suffix stripping algorithm. Das et al. (2017) created a lemmatizer for Bangla verbs according to tense and person using Paninian grammar described in Ashtadhyayi2. Kowsher et al.\n2https://ashtadhyayi.com/\n(2019) used two novel techniques jointly: Dictionary Based Search by Removing Affix (DBSRA) and Trie (Cormen et al., 2009) to lemmatize Bangla words. Chakrabarty andGarain (2016) proposed a novel Bangla lemmatization algorithm using word-specific contextual information like part of speech and word sense. Contextual lemmatizers lemmatize a word based on the surrounding context using deep neural networks. Chakrabarty et al. (2017) employed a two-stage bidirectional gated recurrent neural network to predict lemmas without using additional features. Release of the Universal Dependencies (UD) dataset (de Marneffe et al., 2014,Nivre et al., 2017) and Sigmorphon 2019 shared task formed the basis of encoder-decoder architectures to solve the lemmatization task as a string-transduction task (Qi et al., 2018\u037e Kanerva et al., 2018). For the Bangla language, Saunack et al. (2021) employed a similar two-step attention network that took morphological tags and inflected words as input. Islam et al. (2022) used PoS tags of each word as additional features to the encoder-decoder network achieving 95.75% accuracy on validation dataset. Earlier rule-based approaches did not consider the composition of suffixes and removed them based on the highest length or trie-like data structures. In contrast, we provide specific rules on how a sequence of markers forms a suffix based on a word\u2019s PoS tag and show its efficacy on a crossdataset setup."
        },
        {
            "heading": "3 Methodology",
            "text": "In Bangla, the meaning of a word is greatly influenced by its PoS class within a given context of a sentence (see Table 1). Inflections are morphemes that convey grammatical features without chang-\ning the word class or semantic meaning (Lieber, 2021). They do not involve adding prefixes and altering the word\u2019s meaning. According to Karwatowski and Pietron (2022), for lemmatization it is crucial to determine the word\u2019s intended PoS accurately and its meaning within a sentence, considering the broader context. In this study, we have adopted a word formation-dependent rule-based approach, considering the following factors: i) The lemmatizer will operate on the inflected forms only and leave the derivational forms as they are. ii) The rules depend on the words\u2019 PoS class to use the contextual information."
        },
        {
            "heading": "3.1 Development of Lemmatization Rules",
            "text": "To analyze the behavior of inflected words, we utilized a raw text corpus of 90.65 million sentences, totaling about 0.58 billion words, where approximately 6.17 million words are unique. The corpus was crawled from 112 sources, covering ten different domains across various time periods. Figure 3 and Figure 4 in Appendix A.1 provide visual representations of the dataset\u2019s distribution across domains and time respectively. To obtain the PoS tags for each word in the dataset, we employed the automatic PoS tagger from the BNLP toolkit (Sarker, 2021). We projected each narrow PoS class to its corresponding basic PoS class: noun, pronoun, adjective, verb, adverb, conjunction, interjection, and postposition (Islam et al., 2014). For example, NC (common noun), NP (proper noun), and NV (verbal noun) were mapped to the class \u201cnoun\u201d. This allowed us to categorize the words based on their PoS classes. After categorizing the words, we selected 19591 words as the analysis dataset which was used to\nanalyze the inflection patterns of Bangla words. The analysis dataset preparation procedure is elaborated in Appendix A.2. Word distribution of the raw text corpus and analysis dataset per PoS class is depicted in Figure 2. As the majority of the words in the analysis dataset were in colloquial form, there was insufficient data available to study words in classical forms, such as \u09a4\u09be\u09b9\u09be\u09bf\u09a6\u0997\u09b0 (ta\u032ahadi\u032ag\u0254r\u037e their), \u09bf\u0997\u09df\u09be\u09bf\u099b\u09c7\u09b2\u09a8 (gi\u02b2ac\u02b0ilen\u037e went), etc. To address this limitation, we collected classical texts from specifically selected sources3. Utilizing 500 sentences comprising 5155 total words, where 3084 words were unique, we manually created clusters for the corresponding PoS classes using these classical texts. We did not employ the automatic PoS tagger here as it was trained only on colloquial text (Bali et al., 2010). Adding classical texts allowed us to include a wider range of words, with a total of 22675 words. The morphological synthesis of different PoS is highly effective in determining whether inflections are applied and helps identify the lemma. The investigations of the analysis dataset revealed interesting sequential patterns of inflected words from different PoS classes. Nouns and pronouns were found to have four inflectional suffixes, including case markers (Moravcsik, 2008), plural markers, determiners, and emphasis markers. Verb inflections, on the other hand, depend on factors like tense, person, and number. Adjectives, in comparison, have only two suffixes \u09a4\u09b0 (t\u0254\u032aro) and \u09a4\u09ae (t\u0254\u032amo) which indicate the comparative and superlative degrees respectively (Das et al., 2020). Lastly, only emphatic inflections are found in adverb and postposition word classes. It should be noted that while other PoS classes exhibit distinct patterns of inflection, conjunctions, and interjections function without undergoing any inflection."
        },
        {
            "heading": "3.1.1 Inflections of Nouns",
            "text": "Nouns in Bangla comprise both NP and NC, which contribute a significant portion to the vocabulary of Bengali phrases. Nominal inflections are observed at four levels of nouns, including inanimate, animate, human, and elite (Faridee and Tyers, 2009). These inflections are added to nouns to signify grammatical roles and incorporate morphological features.\n3Used the following sources to extract classical text: https://bankim-rachanabali.nltr.org, https://kobita.banglakosh.com, https://rabindra-rachanabali.nltr.org\nCase markers in the Bangla suffix system determine the noun\u2019s role in the sentence, indicating subject, object, possessor, or locative position. From seven Bangla cases, four case markers are used as noun suffixes e.g., nominative, objective, genitive, and locative (Mahmud et al., 2014). Determiner markers in Bangla noun suffixes provide specificity and indicate singularity, while plural markers indicate multiple entities or instances of a noun phrase. Some plural markers are specifically used with animate nouns, such as \u0997\u09a3 (g\u0254n), \u09ac\u09c3\u09a8\u09cd\u09a6 (brindo\u032a), \u09ae\u09a3\u09cd\u09a1\u09b2\u09c0 (m\u0254ndoli), \u0995\u09c1\u09b2 (kul), etc. while others are used with inanimate objects, like \u0986\u09ac\u09bf\u09b2 (abli), \u0997\u09c1\u099a\u09cd\u099b (gucc\u02b0o), \u0997\u09f0\u09cd\u09be\u09ae (gram), \u099a\u09df (c\u0254\u02b2), etc. (Islam and Sarkar, 2017). Though these suffixes are found in traditional grammar and literature, their frequency of usage is quite low. Emphasis markers \u0987 (i) and \u0993 (o) are employed to emphasize nouns. Table 9 in Appendix A.3 lists the markers used in nouns . In Bengali, the word \u09ae\u09be\u09a8\u09c1\u09b7\u0997\u09c1\u09c7\u09b2\u09be\u09c7\u0995\u0993 (manu\u0283guloke\u0361o\u032f) is formed by combining the base word \u09ae\u09be\u09a8\u09c1\u09b7 (manu\u0283; human) + \u0997\u09c1\u09c7\u09b2\u09be (gulo) + \u09c7\u0995 (ke) + \u0993 (o) where lemma is \u09ae\u09be\u09a8\u09c1\u09b7 (manu\u0283\u037e human) with \u0997\u09c1\u09c7\u09b2\u09be (gulo) plural, \u09c7\u0995 (ke) case, and \u0993 (o) emphatic markers. This inflected form expresses the meaning of \u201ceven the humans\u201d and conveys plurality, objective case, and emphasis in a single word. The order of these suffixes is crucial because altering the sequence, such as \u09ae\u09be\u09a8\u09c1\u09b7\u0993\u09c7\u0995\u0997\u09c1\u09c7\u09b2\u09be (manu\u0283okegulo), would result in a nonsensical word. The key considerations in noun morphology are selecting the appropriate suffixes, figuring out how to arrange them, and understanding the changes that take place at the border during affixation (Bhattacharya et al., 2005). From analysis, we find that the emphasis marker always takes the end position of a noun and does not occur in the middle of the suffix sequence, where the other markers can be combined in different ways. Table 10 in Appendix A.3 lists some examples of how nouns are inflected by taking different markers in a specific sequence in the marker combinations, as represented by Equation 1.\nW = L+ (PM + CM) || (CM + PM) +DM + CM + EM (1)\nHere, W , L, PM , CM , DM , and EM denote the original word, the corresponding lemma, plural marker, case marker, determiner marker, and emphasis marker, respectively. We would use these\nnotations in the following equations also. According to the equation, an inflected form of a word can consist of a lemma and up to four possible suffixes. The first suffix can be either a plural marker or a case marker, and they can alternate positions. However, it is not possible for one type of marker to occur twice consecutively. It is also possible to omit any of these suffixes from the sequence."
        },
        {
            "heading": "3.1.2 Inflections of Verbs",
            "text": "Bangla extensively utilizes verbs, which are action words comprising a verb root and an inflectional ending. The inflectional ending varies based on the tense (present, past, future), person (first, second, third), and honor (intimate, familiar, formal) (Mahmud et al., 2014). Traditional Bangla grammar divides the tense categories into ten different forms. Verbs in Bangla can be written in classical/literary form or colloquial form. Table 11 of Appendix A.4 showcases the different forms of verbal inflection in Bangla. In Bangla, verb suffixes do not break down into markers like other parts of speech. Removing the suffixes from a verb does not yield the lemma but rather the root form of the verb. For instance, \u09af\u09be\u09bf\u099a\u09cd\u099b (\u025facc\u02b0i\u037e going), \u09af\u09be\u09c7\u09ac\u09be (\u025fabo\u037e will go), and \u09bf\u0997\u09c7\u09df\u09bf\u099b\u09b2\u09be\u09ae (gi\u02b2ec\u02b0ilam\u037e went) are different forms of the verb \u09af\u09be\u0993\u09df\u09be (\u025fa\u0361o\u032f\u02b7a\u037e to go), which is the dictionary word (Das et al., 2020\u037e Dash, 2000). After stripping the suffixes from the inflected\nverbs \u09af\u09be\u09bf\u099a\u09cd\u099b (\u025facc\u02b0i\u037e going) and \u09af\u09be\u09c7\u09ac\u09be (\u025fabo\u037e will go) we would get the suffixes \u09bf\u099a\u09cd\u099b (\u09af\u09be + \u09bf\u099a\u09cd\u099b) (cc\u02b0i(\u025fa + cc\u02b0i)) and \u09c7\u09ac\u09be (\u09af\u09be + \u09c7\u09ac\u09be) (bo(\u025fa + bo)) respectively. After stripping the suffixes, we get the root \u09af\u09be (\u025fa\u037e go). This lemmatizer will map the root \u09af\u09be (\u025fa\u037e go) to the lemma \u09af\u09be\u0993\u09df\u09be (\u025fa\u0361o\u032f\u02b7a\u037e to go). However, in Bangla verbs, some exceptions are found such as \u09bf\u0997\u09c7\u09df\u09bf\u099b\u09b2\u09be\u09ae (gi\u02b2ec\u02b0ilam\u037e went),\u098f\u09c7\u09b8\u09bf\u099b (e\u0283ec\u02b0i), etc. After stripping the verbal inflections we get the suffixes \u09c7\u09df\u09bf\u099b\u09b2\u09be\u09ae (\u09bf\u0997 + \u09c7\u09df\u09bf\u099b\u09b2\u09be\u09ae) (\u02b2ec\u02b0ilam(gi + \u02b2ec\u02b0ilam)) and \u098f\u09c7\u09b8\u09bf\u099b (\u098f\u09b8 + \u098f\u09bf\u099b) (e\u0283ec\u02b0i (e\u0283 + ec\u02b0i )) and the root \u09bf\u0997 (gi) and \u098f\u09b8 (e\u0283) which does not match with the actual verb roots \u09af\u09be (\u025fa) and \u0986\u09b8 (a\u0283). In these cases, the lemmatizer will directly map the verb to the lemma using a root-form to verb-lemma mapping which is shown in Table 2. Briefly, a two-step process is followed to accu-\nrately lemmatize verbs. Firstly, the suffixes are removed from the verb to extract its root form. Then, a root-to-lemma mapping is applied to determine the final lemma form of the verb."
        },
        {
            "heading": "3.1.3 Inflections of Pronouns",
            "text": "Bangla pronouns represent specific nouns and exhibit similar inflectional patterns to noun classes. The language has nine types of pronouns, categorized into first, second, and third person based on personal distinctions (Dash, 2000). Appendix A.5 lists the singular, plural, and possessive forms of Bangla personal pronouns, offering a comprehensive understanding of their usage in the language. Many Bangla personal pronouns have inherent suffixes that are integral to thewords, and stripping these suffixes can result in meaningless strings. For example, pronouns like \u0986\u09ae\u09be\u09b0 (amar; my), \u09c7\u09a4\u09be\u09ae\u09be\u09b0 (to\u032amar; your), \u0986\u09ae\u09be\u09c7\u09a6\u09b0 (amade\u032ar; our), \u09c7\u09a4\u09be\u09ae\u09be\u09c7\u09a6\u09b0 (to\u032amade\u032ar; yours) contain case markers \u09b0 (r\u0254) and \u09c7\u09a6\u09b0 (de\u032ar) as inherent parts, which can further be inflected with other markers like the plural marker, determiner, and emphasis marker. Additionally, other pronouns are inflected with four nominal suffixes, including the plural marker, case marker, determiner, and emphasis markers. For instance, the pronoun \u09c7\u09a4\u09be\u09ae\u09be\u09c7\u09a6\u09b0\u09c7\u0995\u0987 (to\u032amade\u032arke\u0361i)\u032f is inflected with the case marker \u09c7\u0995 (ke) and the emphasis marker \u0987 (i). However, the marker \u09c7\u09a6\u09b0 (de\u032ar) is considered part of the pronoun itself, and our lemmatizer does not strip it, resulting in the lemma being \u09c7\u09a4\u09be\u09ae\u09be\u09c7\u09a6\u09b0 (to\u032amade\u032ar; yours), even though \u09c7\u09a6\u09b0 (de\u032ar) can function as a case marker. Pronoun lemmas can be inflected using the marker sequence shown in Equation 2.\nW = L+ PM +DM + CM + EM (2)"
        },
        {
            "heading": "3.1.4 Inflections of Adjectives, Adverbs and Postpositions",
            "text": "Bangla adjectives serve as modifiers for nouns expressing their features and can also modify adverbs. Suffix markers associated with adjectives indicate comparative and superlative degrees (Das et al., 2020). There are only two degree markers, \u09a4\u09b0 (t\u0254\u032aro) as comparative and \u09a4\u09ae (t\u0254\u032amo) as\nsuperlative, which inflect adjectives to indicate a degree. The lemmatizer strips the degree marker from an adjective and results in the corresponding positive adjective. For example: \u09ac\u09c3\u09b9\u09a4\u09cd\u09a4\u09b0 (brihott\u032ao\u032ar\u037e largest) is lemmatized as \u09ac\u09c3\u09b9\u09ce (brih\u0254t\u037e\u032a large) and \u0995\u09c1\u09cd\u09b7\u09a6\u09f0\u09cd\u09a4\u09ae (k\u02b0udr\u032aot\u0254\u032amo\u037e smallest) is lemmatized as \u0995\u09c1\u09cd\u09b7\u09a6\u09f0\u09cd (k\u02b0udr\u032ao\u037e small). Adjectives can also take the form of numerics when quantifying nouns. For example, \u098f\u0995\u09bf\u099f (ekti\u037e a) is an adjective inflected with a nominal suffix. In such cases, the lemmatizer will not strip the suffix, resulting in the lemma being the same as the inflected form. Moreover, because of syntactic structure, nouns can function as adjectives e.g\u0986\u09c7\u0997\u09b0 \u09bf\u09a6\u09c7\u09a8\u09b0 \u09b8\u09c3\u09cd\u09ae\u09bf\u09a4\u0997\u09c1\u09c7\u09b2\u09be (ager di\u032aner sriti\u032agulo\u037e The memories of the previous day). Here, \u0986\u09c7\u0997\u09b0 (ager\u037e previous) will be unchanged as the lemma for being an adjective in this sentence. Additionally, adjectives can be inflected with emphatic markers. Equation 3, where DgM represents the degree marker, indicates the sequence of markers that can inflect an adjective.\nW = L+DgM + EM (3)\nAdverbs modify verbs to indicate how an action takes place. Postpositions, on the other hand, serve a functional role in establishing syntactic connections between syntactic units (Bagchi, 2007). Postpositions can also undergo inflection by emphasis markers only. Adverbs and postpositions are inflected according toW = L+ EM sequence. Our analysis revealed that words belonging to conjunction and interjection PoS classes do not get inflected in the Bangla language."
        },
        {
            "heading": "3.2 BanLemma",
            "text": "BanLemma consists of two main components: PoS-dependent rules and a dictionary. When given an input sentence, BanLemma employs an automatic PoS tagger, a suffix list, and a dictionary. The PoS tagger assigns tags to eachword in the sentence, resulting in a list of word-PoS tag pairs. Subsequently, BanLemma iterates over each element of the list and applies the relevant lemmatization rule based on the PoS tag. In the case of a noun, BanLemma utilizes a method based on Equation 1 to determine the lemma. In contrast, the method utilizes the dictionary and applies sequential suffix stripping to determine the lemma as described in Algorithm 1. We discuss more detailed and implementation-oriented pseudo codes in the Appendix A.6.\nAlgorithm 1Marker stripping method Require: A word (W ), Marker list (M ), and Dictionary words (Dw) Ensure: The marker list is sorted according to length in descending order. function strip_marker(W,M,Dw)\nL\u2190 len(W ) Lmax \u2190 0 mmax \u2190 string() for allm \u2208M do\nif W endswithm then w \u2190W [0 . . . L\u2212 len(m)] if w \u2208 Dw then\nreturn Dw[w] else if len(m) > Lmax then\nLmax \u2190 len(m) mmax \u2190 m\nend if end if\nend for if Lmax > 0 then\nW \u2190W [0 . . . L\u2212 Lmax] end if returnW\nend function"
        },
        {
            "heading": "3.2.1 Development of BanLemma Dictionary",
            "text": "The dictionary used in the lemmatization process includes inflected words and their corresponding lemmas. For instance, (\u0985\u0982\u09b6\u09c0\u09a6\u09be\u09b0\u09c7\u0995 (\u0254\u014b\u0283ida\u032arke; to the partner), \u0985\u0982\u09b6\u09c0\u09a6\u09be\u09b0 (\u0254\u014b\u0283ida\u032ar; partner)) represents the mapping of an inflected word to its lemma. However, for base words, the key and value in the mapping are the same, as in (\u09c7\u0995\u09a4\u09a8 (k\u00e6to\u032an; flag), \u09c7\u0995\u09a4\u09a8 (k\u00e6to\u032an; flag)). The dictionary is organized into 6 PoS clusters (e.g., nouns, pronouns, verbs, adjectives, adverbs, and postpositions) containing a total of around 71.5k wordlemma pairs. To prepare the dictionary, we used sources including Accessible (2023)\u037e Chowdhury (2012). The dictionary format and organization are shown in Figure 6 in Appendix A.7."
        },
        {
            "heading": "4 Experimental Setup",
            "text": "We evaluate BanLemma\u2019s performance using different PoS taggers: human-annotated tags, BNLP toolkit (Sarker, 2021), and ISI4 using the Stanford Postagger5 implementation. Additionally, we\n4www.isical.ac.in/~utpal/resources.php 5nlp.stanford.edu/software/tagger.shtml\nconduct cross-dataset evaluation and compare our methodologywith existing Bangla lemmatizers, including BenLem (Chakrabarty and Garain, 2016), BaNeL (Islam et al., 2022), and Chakrabarty et al. (2017)."
        },
        {
            "heading": "4.1 Test Dataset Preparation",
            "text": "We created a test dataset using the text corpus described in Section 3.1. Instead of random selection, we employed a systematic approach to choose 1049 sentences while maintaining the same domain distribution. The detailed procedure for preparing the test dataset is discussed inAppendix A.8. This dataset had 25.16% words overlapping with the analysis dataset, enabling a reliable evaluation of our proposed rules. To ensure accuracy, we manually annotated the PoS tags and lemmas of the test dataset. We also prepare a separate test dataset containing only classical texts that contain 70 sentences totaling 607 words."
        },
        {
            "heading": "5 Results & Analysis",
            "text": ""
        },
        {
            "heading": "5.1 Performance of BanLemma",
            "text": "Table 3 summarizes the lemmatizer\u2019s performance for PoS categories. At first, we evaluate it using the whole test dataset and report the result in All column, where we achieve 96.36% overall accuracy. To measure the performance on the classical texts only, we separate the classical sentences and report the performance on the CSCL column that demonstrates 96.48% overall accuracy. After that, we tried to evaluate the performance of words we did not include during the manual analysis of inflected words, i.e., non-overlapping with the analysis dataset. Column NOAD shows we achieved an accuracy of 96.41% in this attempt. Finally, we measured the performance of the words where neither the word nor the lemma was not included in the dictionary. We report the accuracy to be 96.32% for this experiment in the NOD column. The table shows that the lemmatizer achieves a perfect accuracy of 100% for postpositions, which can be attributed to the limited number of lemmas and inflections in this category, most of which are included in the word-lemma mapping dictionary. The \u201cothers\u201d category also achieves 100% accuracy, as the lemmatization process considers the word itself as the lemma for any category not explicitly targeted for lemmatization. We further evaluated the performance of BanLemma in terms of precision, recall, and F1 score, which is dis-\ncussed in Appendix A.9."
        },
        {
            "heading": "5.2 Dependency on Automatic PoS Tagger",
            "text": "Table 4 summarizes the impact of using an automatic PoS tagger to get the tags of each word. It indicates that the lemmatizer tends to show significantly reduced performance when used with an automatic PoS tagger. It also highlights that the rules are well capable of lemmatizing Bangla text more accurately given the correct PoS. Table 5 provides examples where the lemmatizer fails to generate accurate lemmas due to incorrect PoS information. These examples highlight the dependency of the lemmatizer on the accuracy of the automatic PoS tagger. It demonstrates that the lemmatizer is capable of producing the correct lemma when provided with accurate manually annotated PoS tags."
        },
        {
            "heading": "5.3 Cross Dataset Evaluation",
            "text": "Table 6 presents the results of the cross-dataset evaluation. Our lemmatizer outperforms BenLem, achieving an 11.63% improvement in accuracy on their provided test dataset. BaNeL did not provide any separate test dataset. So, we evalu-\nated the lemmatizer on the entire BaNeL dataset. Though they reported the performance on a test split, our lemmatizer demonstrates competitive performance achieving 94.80% accuracy on the whole dataset, which is only 0.95% less than their reported accuracy. On the other hand, our system exhibits lower performance on the test dataset provided byChakrabarty et al. (2017), achieving an accuracy of 80.08%, which is 11.06% lower than the reported performance. Several factors contribute to this performance gap, including the reliance on an automatic PoS tagger, which introduced inherent errors. Further investigation reveals significant inconsistency between the dataset used in their study and our considerations during the development of the lemmatizer. These inconsistencies are discussed in detail in Appendix A.10.\nTo evaluate the performance of our proposed system on the dataset provided by Chakrabarty et al. (2017), we manually annotated and corrected PoS tags and lemmas. We focused on 52 sentences comprising a total of 695 words. Additionally, we reviewed and corrected 2000 lemmas from the BaNeL dataset. The results of our evaluation are summarized in Table 7. For the Chakrabarty et al. (2017) dataset, we\nperformed three evaluation steps. Firstly, we assessed the performance of our lemmatizer on unmodified data within the portion where manual efforts were applied. The accuracy column (Acc.) of the table presents the accuracy on this attempt to be 79.97%. Secondly, we examined the performance using an automatic PoS tagger while correcting the lemmas. The automatic PoS tags (A-PoS) and original lemma (O-Lem) column report this accuracy to be 87.09%. Finally, we measured the overall performance using manually annotated PoS tags and corrected lemmas. The correct PoS (C-PoS) and corrected lemma (C-Lem) column of the table illustrate the outcomes of the final experiment to be 94.34%. Since the BaNeL dataset already provides manually annotated PoS tags, we focused solely on evaluating the performance of our lemmatizer on the corrected lemmas. The fourth column of the table presents the performance in this scenario. In both cases, our lemmatizer demonstrated improved performance compared to the initial evaluations."
        },
        {
            "heading": "6 Conclusion and Future Works",
            "text": "This study introduces BanLemma, a Bangla lemmatization system aimed at enriching Bangla language resources. BanLemma is composed of linguistically derived rules, obtained through rigorous analysis of a large Bangla text corpus. To\novercome the challenges associated with limited resources in Bangla lemmatization, we also provide a comprehensive collection of morphological markers and rules. To demonstrate the effectiveness of BanLemma, we have conducted evaluations using a human-annotated test dataset, annotated by trained linguists and some recently published Bangla datasets. Our proposed BanLemma achieved an accuracy of 96.36% on our humanannotated test set. Furthermore, in cross-dataset evaluation, BanLemma exhibited significant performance improvements ranging from 1% to 11%. The results of our study shed light on the formation of inflected words, offering a solution to address the limitations of previous lemmatization methods. These findings contribute to the advancement of research in this field and pave the way for further investigations in the domain of Bangla lemmatization."
        },
        {
            "heading": "Limitations",
            "text": "During our analysis, we found some limitations of BanLemma. We discuss these in the following points:\n\u2022 Out of dictionary words: we identified a notable pattern in the lemmatizer\u2019s behavior regarding words that are not present in the dictionary but already are lemmas and end with a suffix substring. In this case, the lemmatizer erroneously strips the suffix from the words. For instance, the word \u09a8\u09c2\u09a8\u09af\u09cd\u09a4\u09ae (nunn\u0254t\u0254\u032am\u0254\u037e minimum) itself is a lemma, yet the lemmatizer strips the ending substring\u09a4\u09ae (t\u0254\u032amo), resulting in the lemma \u09a8\u09c2\u09a8\u09af\u09cd (nunno), which is incorrect. We also noticed that this limitation is particularly prominent with proper nouns. It also emphasizes the significance of the dictionary\u2019s richness in the lemmatization process. Words that are not present in the dictionary but end with suffix substrings will be inaccurately lemmatized.\n\u2022 Ambiguous semantic meaning: We observed that the lemmatizer struggles to comprehend the semantic meaning of certain words, resulting in incorrect lemmatization. For example, Table 8 illustrates a case where the lemma varies depending on the context although having the same PoS class. The lemmas differ based on whether they express the\naction of hanging or the state of something being hung.\n\u2022 Automatic PoS dependency: The lemmatizer heavily relies on PoS information, which introduces errors when an automatic PoS tagger is used in the workflow."
        },
        {
            "heading": "A Appendix",
            "text": ""
        },
        {
            "heading": "A.1 Raw Corpus Distribution",
            "text": "Figure 3 and Figure 4 provide representations of the raw corpus\u2019s distribution across domains and time respectively."
        },
        {
            "heading": "A.2 Analysis Dataset Preparation",
            "text": "To obtain the PoS tags for each word in the dataset, we used the PoS tagger from the BNLP toolkit. The tagger was trained on the Indian Language Part-of-Speech Tagset: Bengali LDC2010T16 (Bali et al., 2010) dataset, which comprises 30 narrow PoS classes. After projecting the narrow PoS classes, we grouped the words based on their PoS class for further analysis which formed the basis of our investigation into the behavior of inflected words in Bangla. In order to conduct a detailed analysis of the words, we employed a systematic approach to create a representative dataset. Initially, we clustered the words based on their longest common initial substring within each PoS group. For example, words like \u09b8\u09b0\u0995\u09be\u09b0 (\u0283\u0254rkar\u037e government), \u09b8\u09b0\u0995\u09be\u09b0\u0987 (\u0283\u0254rkari), \u09b8\u09b0\u0995\u09be\u09b0\u0993 (\u0283\u0254rkaro),\n\u09b8\u09b0\u0995\u09be\u09b0\u09c7\u0995 (\u0283\u0254rkarke), and so on, which share the common initial substring \u09b8\u09b0\u0995\u09be\u09b0 (\u0283\u0254rkar\u037e government), were grouped together. For the analysis, we then selected clusters that contain a minimum threshold of words. Initially, we set a minimum threshold of 10, but this resulted in an overabundance of nouns, verbs, and adjectives while filtering out clusters from pronouns, postpositions, conjunctions, and interjections due to limited words in those groups. To address this, we individually determined the minimum threshold for each PoS class. The thresholds were set as follows: 14 for nouns, 7 for adjectives, 6 for verbs, 2 for pronouns and adverbs, and 1 for postpositions, conjunctions, and interjections. These thresholds were determined through a combination of tuning and manual examination of the selected clusters. To neutralize the error of the automatic PoS tagger, we manually curated the words while removing any word if necessary. Finally, we came up with 19591 selected words for the analysis dataset. To study the classical texts rigorously, we additionally use some classical text sources and select some words. Subsequently, we selected a total of 22675 words for further analysis."
        },
        {
            "heading": "A.3 Markers and Noun Formation",
            "text": "A.4 Verb Suffixes\nTable 11 presents all suffixes that inflect the a verb root."
        },
        {
            "heading": "A.5 Personal Pronouns",
            "text": "Table 12 lists the personal pronouns in singular, plural, and possessive forms."
        },
        {
            "heading": "A.6 Lemmatization Algorithm and Methods",
            "text": "Algorithm 2 summarizes the overall lemmatization algorithm. Algorithm 3 provides a summary of the lemmatization method for noun words. The stripping process begins with the last marker, which in the case of nouns is the emphasis marker. Equation 1 illustrates that the sequence of the last three markers is fixed. However, if the first marker is a plural marker, then the second marker will be a case marker, or vice versa. After stripping the last three types of markers, the algorithm determines the next last marker and selects a second appropriate sequence for stripping the remaining markers. The marker stripping method is described in detail in Algorithm 1. This algorithm is responsible for identifying and removing markers at the end of a word. It begins by checking if a word ends with a marker. If a match is found, it determines whether to stop the matching process based on whether the remaining prefix of the word is present in the dictionary. If the remaining prefix\nis found in the dictionary, the lemma is immediately returned. However, if the remaining prefix is not found in the dictionary, the algorithm continuesmatching to determine if stripping a shorter suffix marker would result in a dictionary entry. This design choice allows for handling cases wheremultiple markers are present. For example, when stripping case markers from the inflected word \u09c7\u099b\u09c7\u09b2\u09b0 (of the boy), the algorithm would first match the marker \u098f\u09b0 (\u09c7\u25cc\u09b0). Stripping this marker would result in the word \u09c7\u099b\u09b2, which is not the correct lemma. By continuing the matching process, the algorithm would then match the marker , resulting in the correct lemma \u09c7\u099b\u09c7\u09b2 (boy). However, if any shorter marker is not found, it would strip the longest marker at the end. The lemmatization methods for other PoS classes can be achieved by modifying Algorithm 3. The details of these modifications are discussed in Algorithm 4 to Algorithm 7. Algorithm 4 to 7 presents the algorithms to lemmatize the words from the corresponding PoS class.\nAlgorithm 2 The lemmatization algorithm Require: A sentence (T ), PoS Tagger (p_tagger), Suffix and Marker list (S), and Dictionary (D) Ensure: The PoS tagger (p_tagger) returns a list of tuples where the first element is the word and the second element is the PoS tag. Suffix lists are clustered into PoS classes and sorted according to length in descending order. procedure lemmatize(T, p_tagger, S,D)\nlemmas\u2190 list() words_with_tags\u2190 p_tagger(T ) for all (W, tag) \u2208 words_with_tags do\nif tag = noun then L\u2190 noun_lemma(W,S,D) else if tag = pronoun then L\u2190 pro_lemma(W,S,D) else if tag = verb then L\u2190 verb_lemma(W,S,D) else if tag = adverb then L\u2190 adverb_lemma(W,S,D) else if tag = adjective then L\u2190 adj_lemma(W,S,D) else if tag = postposition then L\u2190 postpos_lemma(W,S,D) else L\u2190W end if lemmas.add(L) end for lemma_sent\u2190 space_join(lemmas) return lemma_sent\nend procedure"
        },
        {
            "heading": "A.7 The Dictionary Format",
            "text": "In total, the dictionary contains 6 PoS clusters such as nouns, pronouns, verbs, adverbs, adjectives, and postpositions and consist of 46, 289, 499, 5, 366, 17, 040, 860, and 1, 353word-lemma pairs, respectively. The dictionary format and organization is shown in Figure 6"
        },
        {
            "heading": "A.8 Test Dataset Preparation",
            "text": "First, we divided the sentences into their respective domains and randomly reshuffled them. Then, we selected a percentage of sentences from each domain based on its contribution to the total percentage of sentences in the entire raw text corpus. For example, we sampled 452 sentences from the Bangla news domain, which accounted for 45.18% of the entire dataset. During the selection process,\nAlgorithm 3 Noun lemmatization method Require: A nounword (W ), Clustered marker list (S), and Dictionary (D) Ensure: The word is a noun. Suffix lists are clustered into markers in a hash map where the key is themarker name and the value is a list of markers. function noun_lemma(W, S, D)\nDw \u2190 D[nouns] if W \u2208 Dw then\nreturn Dw[W ] end if StripSeq \u2190 [em, cm, dm] for allm \u2208 StripSeq do\nW \u2190 strip_marker(W,S[m], Dw) if W \u2208 Dw then\nreturn Dw[W ] end if\nend for SecondStripSeq \u2190 list() for allm \u2208 S[pm] do\nif W endswithm then SecondStripSeq \u2190 [pm, cm] break\nend if end for if len(SecondStripSeq) = 0 then\nSecondStripSeq \u2190 [cm, pm] end if for allm \u2208 SecondStripSeq do\nW \u2190 strip_marker(W,S[m], Dw) if W \u2208 Dw then\nreturn Dw[W ] end if\nend for returnW\nend function\nwe made sure to include at least 1% of sentences from each domain. This decision enabled us to incorporate sentences from domains that were underrepresented in the dataset, such as circular, which accounted for only 0.09% of the entire corpus. Additionally, we included sentences for which we could not determine a specific domain. Throughout this procedure, we maintained the uniqueness of the selected sentences. At this stage, we discovered that the test dataset had a significant overlap of 38.27%with the words used during the inflected word analysis. To ensure a more effective evaluation of our proposed\nAlgorithm 4 Pronoun lemmatization method Require: A pronoun word (W ), Clustered marker list (S), and Dictionary (D) Ensure: The word is a pronoun. Suffix lists are clustered into markers in a hash map where the key is the marker name and the value is a list of markers. function pro_lemma(W, S, D)\nDw \u2190 D[pronouns] if W \u2208 Dw then\nreturn Dw[W ] end if StripSeq \u2190 [em, cm, dm, pm] for allm \u2208 StripSeq do\nW \u2190 strip_marker(W,S[m], Dw) if W \u2208 Dw then\nreturn Dw[W ] end if\nend for returnW\nend function\nAlgorithm 5 Adjective lemmatization method Require: A adjective word (W ), Clustered marker list (S), and Dictionary (D) Ensure: The word is an adjective. Suffix lists are clustered into markers in a hash map where the key is the marker name and the value is a list of markers. function ADJ_LEMMA(W, S, D)\nDw \u2190 D[adjectives] if W \u2208 Dw then\nreturn Dw[W ] end if StripSeq \u2190 [em, dgm] for allm \u2208 StripSeq do\nW \u2190 strip_marker(W,S[m], Dw) if W \u2208 Dw then\nreturn Dw[W ] end if\nend for returnW\nend function\nrules, we aimed to reduce this overlap percentage. Figure 2 illustrates that the raw corpus consists of a large number of nouns, verbs, and adjectives. Therefore, during the selection of test sentences, we excluded any sentence that contained any noun, verb, or adjective that was already in-\nAlgorithm 6 Adverb lemmatization method Require: An adverb word (W ), Clustered marker list (S), and Dictionary (D) Ensure: The word is an adverb. Suffix lists are clustered into markers in a hash map where the key is the marker name and the value is a list of markers. function ADVERB_LEMMA(W, S, D)\nDw \u2190 D[adverb] if W \u2208 Dw then\nreturn Dw[W ] end if StripSeq \u2190 [em] for allm \u2208 StripSeq do\nW \u2190 strip_marker(W,S[m], Dw) if W \u2208 Dw then\nreturn Dw[W ] end if\nend for returnW\nend function\nAlgorithm 7 Postposition lemmatization method Require: A postposition word (W ), Clustered marker list (S), and Dictionary (D) Ensure: The word is an adverb or postposition. Suffix lists are clustered into markers in a hash map where the key is the marker name and the value is a list of markers. function POSTPOS_LEMMA(W, S, D)\nDw \u2190 D[postposition] if W \u2208 Dw then\nreturn Dw[W ] end if StripSeq \u2190 [em] for allm \u2208 StripSeq do\nW \u2190 strip_marker(W,S[m], Dw) if W \u2208 Dw then\nreturn Dw[W ] end if\nend for returnW\nend function\ncluded in the analysis dataset. However, we found that the sample sentences were not well formed as the number of verbs and adjectives is limited. So, finally, we attempt to reduce the overlap by allowing all verbs and adjectives while controlling the overlapping of nouns. As a result, the final\ntest dataset had only 25.16% overlapping words with the analysis dataset, where we found 9.68% nouns overlaps with the analysis dataset. However, this reduced overlapping dataset allows us to conduct a more robust evaluation. Finally, to complete the annotation process, we manually assigned PoS tags and lemmas to the words extracted from these sentences. We collaborated with an annotator who assigned the PoS tags and lemmas to each word. To ensure the accuracy and consistency of the annotations, the assigned tags and lemmas were validated by a validator who was a linguistic expert."
        },
        {
            "heading": "A.9 Further Performance Evaluation",
            "text": "We were interested in evaluating how the lemmatizer works on the non-inflected and inflected words. For a non-inflected word, the word itself is the lemma. Except for the proper nouns, Usually, the non-inflected words are found in a dictionary. To conduct this experiment, we first lemmatize the sentences from the test dataset. Then separate the non-inflected and inflected words along with the lemmas. In this setup, there are a total of 6906 non-inflected words and 3125 inflected words. We found that the lemmatizer achieves an F1 score of 0.9733 for non-inflected words and 0.9399 for inflected words. Table 13 summarizes the analysis."
        },
        {
            "heading": "A.10 Dataset Annotation Inconsistencies",
            "text": "From the dataset of BenLem, firstly we found that they labeled verb roots as lemmas, while we consider the dictionary form as the lemma. For example, they annotated the lemma of the word \u09b9\u09c7\u09ac (h\u0254be) as \u09b9 (h\u0254), whereas we lemmatize it as \u09b9\u0993\u09df\u09be (h\u0254\u02b7a). Secondly, they converted colloquial pronouns to their classical forms. They labeled the lemma of \u09a4\u09be\u09c7\u09a6\u09b0 (ta\u032ade\u032ar\u037e their) as the classical form \u09a4\u09be\u09b9\u09be\u09c7\u09a6\u09b0 (ta\u032ahade\u032ar\u037e their), whereas we consider the same colloquial form \u09a4\u09be\u09c7\u09a6\u09b0 (ta\u032ade\u032ar\u037e their) as the lemma. Lastly, they made spelling changes to certain words, such as transforming \u09ad\u09be\u09b2 (b\u02b1alo) to \u09ad\u09be\u09c7\u09b2\u09be (b\u02b1alo), which differs from our approach. During our analysis of the BaNeL dataset, we discovered the following inconsistencies. Firstly, certain derivational markers were removed. Secondly, pronoun forms were modified, converting \u098f\u0981\u09c7\u09a6\u09b0 (ede\u032ar\u037e their) to \u09bf\u09a4\u09bf\u09a8 (ti\u032ani\u037e he/she). Thirdly, spelling changes were made to some words, such as lemmatizing \u09c7\u09b8\u09ac\u0995\u09be\u09a7\u09c7\u09ae\u09b0 (\u0283ebokad\u02b1\u0254mer) as \u09c7\u09b8\u09ac\u0995\u0985\u09a7\u09ae (\u0283ebokod\u02b1\u0254m), whereas we consider it as \u09c7\u09b8\u09ac\u0995\u09be\u09a7\u09ae (\u0283ebokad\u02b1\u0254m). Additionally, incorrect lemmas were found in the dataset, where \u09ad\u09be\u09c7\u09b2\u09be\u09ae\u09be\u09a8\u09c1\u09c7\u09b7\u09b0 (b\u02b1alomanu\u0283er) was provided as the lemma for \u09ad\u09be\u09c7\u09b2\u09be\u09ae\u09be\u09a8\u09c1\u09c7\u09b7 (b\u02b1alomanu\u0283e). Furthermore, our lemmatizer has a limitation that produces incorrect results when the actual word ends with a suffix marker. For instance, the lemma of the word \u09c7\u099c\u09c7\u09b2\u09b0 (\u025feler) should be \u09c7\u099c\u09c7\u09b2 (\u025fele\u037e fisherman), but our system incorrectly lemmatizes it as \u09c7\u099c\u09b2 (\u025fel\u037e prison). In the dataset of Chakrabarty et al. (2017) They made changes to the gender of words, such as transforming \u09af\u09c1\u09ac\u09a4\u09c0 (\u025fuboti\u032a\u037e young girl) to \u09af\u09c1\u09ac\u0995 (\u025fubok\u037e young boy), altered negated forms to positive forms, e.g., changing \u0985\u09a6\u09c2\u09b0 (\u0254du\u032ar\u037e not so far) to \u09a6\u09c2\u09b0 (du\u032ar\u037e far), and modified pronouns, e.g., \u09c7\u09a4\u09be\u09ae\u09be\u09b0 (to\u032amar\u037e your) to \u09a4\u09c1\u09bf\u09ae (tu\u032ami\u037e you). They also made derivational changes, such as transforming \u09ac\u09be\u09bf\u09a3\u09bf\u099c\u09af\u09cd\u0995 (bani\u025f\u025fik\u037e commercial) to \u09ac\u09be\u09bf\u09a3\u099c\u09af\u09cd (bani\u025f\u025fo\u037e trade), \u09aa\u09f0\u09cd\u0995\u09c3\u09bf\u09a4 (prokriti\u032a\u037e nature) to \u09aa\u09f0\u09cd\u0995\u09c3\u09a4 (prokrito\u032a\u037e real), and so on. These discrepancies significantly impacted the performance of our lemmatizer."
        }
    ],
    "title": "BanLemma: A Word Formation Dependent Rule and Dictionary Based Bangla Lemmatizer",
    "year": 2023
}