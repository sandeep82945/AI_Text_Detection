{
    "abstractText": "Entity linking, which aligns mentions in the text to entities in knowledge bases, is essential for many natural language processing tasks. Considering the real-world scenarios, recent research hotspot of entity linking has focused on the zero-shot setting, where mentions need to link to unseen entities and only the description of each entity is provided. This task challenges the language understanding ability of models to capture the coherence evidence between the mention context and entity description. However, entity descriptions often contain rich information from multiple views, and a mention with context only relates to a small part of the information. Other irrelevant information will introduce noise, which interferes with models to make the right judgments. Furthermore, the existence of these information also makes it difficult to synthesize key information. To solve these problems, we select key views from descriptions and propose a KVZEL framework for zero-shot entity linking. Specifically, our KVZEL first adopts unsupervised clustering to form sub views. Then, it employs a mentionaware key views selection module to iteratively accumulate mention-focused views. This puts emphasis on capturing mention-related information and allows long-range key information integration. Finally, we aggregate key views to make the final decision. Experimental results show the effectiveness of our KVZEL and it achieves the new state-of-the-art on the zeroshot entity linking dataset.",
    "authors": [
        {
            "affiliations": [],
            "name": "Xuhui Sui"
        },
        {
            "affiliations": [],
            "name": "Ying Zhang"
        },
        {
            "affiliations": [],
            "name": "Kehui Song"
        },
        {
            "affiliations": [],
            "name": "Baohang Zhou"
        },
        {
            "affiliations": [],
            "name": "Xiaojie Yuan"
        },
        {
            "affiliations": [],
            "name": "Wensheng Zhang"
        }
    ],
    "id": "SP:d06a7a5b4302d41770f4ab92cd40ae5952659260",
    "references": [
        {
            "authors": [
                "Edoardo Barba",
                "Luigi Procopio",
                "Roberto Navigli."
            ],
            "title": "Extend: Extractive entity disambiguation",
            "venue": "ACL, pages 2478\u20132488.",
            "year": 2022
        },
        {
            "authors": [
                "Roi Blanco",
                "Giuseppe Ottaviano",
                "Edgar Meij."
            ],
            "title": "Fast and space-efficient entity linking for queries",
            "venue": "WSDM, pages 179\u2013188.",
            "year": 2015
        },
        {
            "authors": [
                "Yizong Cheng."
            ],
            "title": "Mean shift, mode seeking, and clustering",
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell., 17(8):790\u2013799.",
            "year": 1995
        },
        {
            "authors": [
                "Jacob Devlin",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova."
            ],
            "title": "BERT: pre-training of deep bidirectional transformers for language understanding",
            "venue": "NAACL, pages 4171\u20134186.",
            "year": 2019
        },
        {
            "authors": [
                "Octavian-Eugen Ganea",
                "Thomas Hofmann."
            ],
            "title": "Deep joint entity disambiguation with local neural attention",
            "venue": "EMNLP, pages 2619\u20132629.",
            "year": 2017
        },
        {
            "authors": [
                "Gourab Kundu",
                "Avirup Sil",
                "Radu Florian",
                "Wael Hamza."
            ],
            "title": "Neural cross-lingual coreference resolution and its application to entity linking",
            "venue": "ACL, pages 395\u2013400.",
            "year": 2018
        },
        {
            "authors": [
                "Phong Le",
                "Ivan Titov."
            ],
            "title": "Improving entity linking by modeling latent relations between mentions",
            "venue": "ACL, pages 1595\u20131604.",
            "year": 2018
        },
        {
            "authors": [
                "Belinda Z. Li",
                "Sewon Min",
                "Srinivasan Iyer",
                "Yashar Mehdad",
                "Wen-tau Yih."
            ],
            "title": "Efficient one-pass end-to-end entity linking for questions",
            "venue": "EMNLP, pages 6433\u20136441.",
            "year": 2020
        },
        {
            "authors": [
                "Stuart P. Lloyd."
            ],
            "title": "Least squares quantization in PCM",
            "venue": "IEEE Trans. Inf. Theory, 28(2):129\u2013136.",
            "year": 1982
        },
        {
            "authors": [
                "Lajanugen Logeswaran",
                "Ming-Wei Chang",
                "Kenton Lee",
                "Kristina Toutanova",
                "Jacob Devlin",
                "Honglak Lee."
            ],
            "title": "Zero-shot entity linking by reading entity descriptions",
            "venue": "ACL, pages 3449\u20133460.",
            "year": 2019
        },
        {
            "authors": [
                "Ilya Loshchilov",
                "Frank Hutter."
            ],
            "title": "Fixing weight decay regularization in adam",
            "venue": "CoRR, abs/1711.05101.",
            "year": 2017
        },
        {
            "authors": [
                "Andrew Y. Ng",
                "Michael I. Jordan",
                "Yair Weiss."
            ],
            "title": "On spectral clustering: Analysis and an algorithm",
            "venue": "NeurIPS, pages 849\u2013856.",
            "year": 2001
        },
        {
            "authors": [
                "Laurel J. Orr",
                "Megan Leszczynski",
                "Neel Guha",
                "Sen Wu",
                "Simran Arora",
                "Xiao Ling",
                "Christopher R\u00e9."
            ],
            "title": "Bootleg: Chasing the tail with self-supervised named entity disambiguation",
            "venue": "CIDR.",
            "year": 2021
        },
        {
            "authors": [
                "Jonathan Raiman",
                "Olivier Raiman."
            ],
            "title": "Deeptype: Multilingual entity linking by neural type system evolution",
            "venue": "AAAI, pages 5406\u20135413.",
            "year": 2018
        },
        {
            "authors": [
                "Stephen E. Robertson",
                "Steve Walker",
                "Susan Jones",
                "Micheline Hancock-Beaulieu",
                "Mike Gatford."
            ],
            "title": "Okapi at TREC-3",
            "venue": "TREC, pages 109\u2013126.",
            "year": 1994
        },
        {
            "authors": [
                "Xuhui Sui",
                "Ying Zhang",
                "Kehui Song",
                "Baohang Zhou",
                "Guoqing Zhao",
                "Xin Wei",
                "Xiaojie Yuan."
            ],
            "title": "Improving zero-shot entity linking candidate generation with ultra-fine entity type information",
            "venue": "COLING, pages 2429\u20132437.",
            "year": 2022
        },
        {
            "authors": [
                "Kai Sun",
                "Richong Zhang",
                "Samuel Mensah",
                "Yongyi Mao",
                "Xudong Liu."
            ],
            "title": "A transformational biencoder with in-domain negative sampling for zero-shot entity linking",
            "venue": "Findings of ACL, pages 1449\u20131458.",
            "year": 2022
        },
        {
            "authors": [
                "Yaming Sun",
                "Lei Lin",
                "Duyu Tang",
                "Nan Yang",
                "Zhenzhou Ji",
                "Xiaolong Wang."
            ],
            "title": "Modeling mention, context and entity with neural networks for entity disambiguation",
            "venue": "IJCAI, pages 1333\u20131339.",
            "year": 2015
        },
        {
            "authors": [
                "Hongyin Tang",
                "Xingwu Sun",
                "Beihong Jin",
                "Fuzheng Zhang."
            ],
            "title": "A bidirectional multi-paragraph reading model for zero-shot entity linking",
            "venue": "AAAI, pages 13889\u201313897.",
            "year": 2021
        },
        {
            "authors": [
                "Simone Tedeschi",
                "Simone Conia",
                "Francesco Cecconi",
                "Roberto Navigli."
            ],
            "title": "Named entity recognition for entity linking: What works and what\u2019s next",
            "venue": "Findings of EMNLP, pages 2584\u20132596.",
            "year": 2021
        },
        {
            "authors": [
                "Johannes Welbl",
                "Pontus Stenetorp",
                "Sebastian Riedel."
            ],
            "title": "Constructing datasets for multi-hop reading comprehension across documents",
            "venue": "Trans. Assoc. Comput. Linguistics, 6:287\u2013302.",
            "year": 2018
        },
        {
            "authors": [
                "Ledell Wu",
                "Fabio Petroni",
                "Martin Josifoski",
                "Sebastian Riedel",
                "Luke Zettlemoyer."
            ],
            "title": "Scalable zeroshot entity linking with dense entity retrieval",
            "venue": "EMNLP, pages 6397\u20136407.",
            "year": 2020
        },
        {
            "authors": [
                "Ikuya Yamada",
                "Hiroyuki Shindo",
                "Hideaki Takeda",
                "Yoshiyasu Takefuji."
            ],
            "title": "Joint learning of the embedding of words and entities for named entity disambiguation",
            "venue": "CoNLL, pages 250\u2013259.",
            "year": 2016
        },
        {
            "authors": [
                "Xiyuan Yang",
                "Xiaotao Gu",
                "Sheng Lin",
                "Siliang Tang",
                "Yueting Zhuang",
                "Fei Wu",
                "Zhigang Chen",
                "Guoping Hu",
                "Xiang Ren."
            ],
            "title": "Learning dynamic context augmentation for global entity linking",
            "venue": "EMNLP, pages 271\u2013281.",
            "year": 2019
        },
        {
            "authors": [
                "Zonghai Yao",
                "Liangliang Cao",
                "Huapu Pan."
            ],
            "title": "Zero-shot entity linking with efficient long range sequence modeling",
            "venue": "Findings of EMNLP, pages 2517\u20132522.",
            "year": 2020
        }
    ],
    "sections": [
        {
            "heading": "1 Introduction",
            "text": "Entity linking (EL) is the task of assigning ambiguous mentions in textual input to their corresponding entities in a given real-world knowledge base. EL, as a fundamental task in the information extraction area, plays an important role in many downstream natural language processing (NLP) applications,\n\u2217Corresponding author.\nsuch as semantic search (Blanco et al., 2015), content analysis (Huang et al., 2018) and question answering (Welbl et al., 2018; Li et al., 2020). Traditional EL approaches are built on the assumption that the train and test set share the same entity distributions, which means that linked entities in the test set are seen during training. However, in many real-world scenarios, the process of labeling data is labor-intensive and error-prone. More importantly, for some specialized domains such as medical and legal domains, the training data is sensitive or proprietary. Thus, it is not easy to obtain labeled data for these domains. Therefore, EL models need to\nhave the capability of generalizing to new entities of new domains.\nTo address this, the zero-shot entity linking task (Logeswaran et al., 2019) has been proposed, where mentions need to be linked to unseen entities of new domains. Moreover, considering that there is no external knowledge (e.g. frequency statistics and structured data) in many specialized domains, the textual description for each entity is the only information provided in this task. Based on the above, we can see that the entity description, as the only identification information of entities, is crucial for this task. Some previous works (Yao et al., 2020; Tang et al., 2021) have realized its importance and constructed models to circumvent the length limitation problem of BERT-based models to capture richer entity description information.\nHowever, to the best of our knowledge, all previous methods utilize the same entire entity description to match different mentions with divergent context. This seems struggling to manage entities with rich multiple views information. We argue that only part of description information is related to mentions and other irrelevant information will introduce noise and make models reduce emphasis on the corresponding details. An example shown in Figure 1a, the entity description of \u201cLeBron James\u201d contains multiple views information, such as his NBA journey, his family, etc. For the first mention, it only relates to \u201cView 1\u201d in the entity description. Other views are useless in determining whether the \u201cJames\u201d should link to the entity \u201cLeBron James\u201d. For the second mention, it is related to \u201cView 2\u201d and \u201cView 4\u201d. However, the description of \u201cLeBron James\u201d mainly concentrates on his professional journey, which will introduce noise to interfere with entity linking models matching \u201chis father\u201d and \u201cLeBron James\u201d. Furthermore, \u201cView 2\u201d and \u201cView 4\u201d may exist in different parts of the description, which makes it not trivial to synthesize the key information of the two views.\nTo address these problems, in this paper, we try to select key views from entity descriptions for different mentions with divergent context, which is shown in Figure 1b. This can also help entity linking models solve the problem of length limitation in BERT-based models, since the selected views are only a part of entity description. We propose a novel Key Views selection framework for Zero-shot Entity Linking in this paper, KVZEL in short. KVZEL first adopts unsupervised clustering\nto group the sentences, and those in each cluster compose a sub view. When judging whether a mention in text matches the entity, humans tend to read the whole description and only focus on the view that is most relevant to the mention. Considering that this mention may be related to multiple views of entity description, after finding that a single view is insufficient to make the judgment, humans will use the previously relevant views as clues and move on to find the next relevant view. With the inspiration of the human\u2019s thinking process, our KVZEL designs a mention-aware key views selection module to iteratively accumulate the most relevant views. These views are then aggregated into a new text, which serves as the mention-focused and highly-condensed version of original entity description. Finally, the text replaces the description and is utilized by our entity linking module to make the final decision.\nTo summarize, our major contributions are shown as follows:\n\u2022 To the best of our knowledge, this work is the first to select key views from entity descriptions to link different mentions with divergent context. This is very meaningful for entities with rich multiple views information.\n\u2022 We propose a novel framework KVZEL for zero-shot entity linking, which imitates the human\u2019s thinking process to iteratively accumulate mention-related views. These views are aggregated to measure the matching score between mentions and entities.\n\u2022 Experimental results on zero-shot entity linking dataset (Logeswaran et al., 2019) show that our KVZEL achieves new state-of-the-art performance. Further analysis demonstrates the effectiveness of our framework."
        },
        {
            "heading": "2 Related Work",
            "text": ""
        },
        {
            "heading": "2.1 Entity Linking",
            "text": "Entity linking, as a bridge between real-world text and standard knowledge base, has been widely explored in recent years. Many entity linking methods (Sun et al., 2015; Yamada et al., 2016; Le and Titov, 2018; Yang et al., 2019; Tedeschi et al., 2021; Barba et al., 2022) have achieved great success in both academic research and industrial applications. While these results are impressive, the models in these methods are learned under the setting where\n\u2026\nlinked entities in the test set are available during training. Furthermore, with the expansion of knowledge in knowledge bases, many state-of-the-art methods (Ganea and Hofmann, 2017; Kundu et al., 2018; Raiman and Raiman, 2018; Orr et al., 2021) have made full use of external knowledge. However, in many real-world scenarios, labeled data and external knowledge are not easily available in many specialized domains. Based on empirical evidence, the performance of models deteriorates substantially when dealing with new entities of new domains without external knowledge. This motivates many researchers to study zero-shot entity linking (Logeswaran et al., 2019)."
        },
        {
            "heading": "2.2 Zero-Shot Entity Linking",
            "text": "Zero-shot entity linking is the task where mentions must be linked to unseen entities and only the description of each entity is available. It consists of two phases: candidate generation (Wu et al., 2020; Sun et al., 2022; Sui et al., 2022) and candidate ranking (Yao et al., 2020; Tang et al., 2021). Following previous works (Logeswaran et al., 2019; Yao et al., 2020; Tang et al., 2021), we only focus on the candidate ranking phase and use the traditional Information Retrieval (IR) approach of BM25 (Robertson et al., 1994) in the candidate generation phase. Logeswaran et al. (2019) uses a cross-encoder architecture that concatenates mention context and entity description and feeds it into BERT (Devlin et al., 2019) to produce the matching score by performing cross-attention. However, BERT-based models may lose important description information due to the limitation of their input\nlength. Yao et al. (2020) solves the problem by initializing larger position embeddings to expand the effective reading length of BERT. Tang et al. (2021) proposes a bidirectional multi-paragraph reading model which segments a long description into short paragraphs to make use of more description information. However, the consideration of paragraphs that are irrelevant to the mention may introduce noise in the final representation and limit the longrange dependencies between relevant information. This motivates us to select key views from entity descriptions for different mentions with divergent context to address these problems."
        },
        {
            "heading": "3 Methodology",
            "text": "Figure 2 shows the overall architecture of our proposed KVZEL framework. We first use the sub view clustering module to generate sub views from descriptions. Then we design a mention-aware key views selection module to select relevant sub views for different mentions with divergent context. Finally, our entity linking module makes the final decision based on the selected views. In this section, we introduce these three modules in detail."
        },
        {
            "heading": "3.1 Sub View Clustering",
            "text": "The goal of our sub view clustering module is to cluster sentence chunks describing the same view together, so as to select key views later. For each given entity description, we first segment it into sentence chunks S = [s1, s2, ..., sL]. Intuitively, each individual sentence in the description is taken as a chunk. However, the understanding of short sentences is often not easy and needs the help of\ncontext. A simple solution is to segment the entire description into chunks of fixed length. However, this destroys the syntactic relationship and may lead to clustering errors. Thus, we fuse these two ways and set a fixed capacity c for each chunk. Each chunk loads as many sentences as possible. After loading sentences, the sentence sequences in chunks are padded to c with zero values.\nWe feed the sentence chunks S into BERT (Devlin et al., 2019) in the form of [CLS] si [SEP] to extract features, which are the vectors in the last hidden layer corresponding to the position of [CLS] tokens. Then, we adopt mean-shift (Cheng, 1995) clustering approach to group sentence chunks. Compared to other traditional unsupervised clustering approaches (such as k-means (Lloyd, 1982), spectral clustering (Ng et al., 2001), etc), mean-shift does not need to specify the number of clusters, which is more suitable for our application scenario. Those sentence chunks in each cluster compose a sub view:\nV = Mean-Shift(BERT(S; \u03b8BERT1))"
        },
        {
            "heading": "3.2 Mention-Aware Key Views Selection",
            "text": "The goal of our mention-aware key views selection module is to iteratively accumulate mention-related views for the final entity linking process. This is similar to human reading through the whole description view by view to measure the relevance of the mention and each view. Then they will focus on the view that is most relevant to the mention. When moving on to find the next relevant view, they will still remember previously relevant views and utilize them as clues to help this process."
        },
        {
            "heading": "3.2.1 Feature Extraction",
            "text": "For a given mention m, suppose there are P candidate entities of m and we have n sub views V = [V1, V2, ..., Vn] of the p-th candidate entity ep. In the initial stage, our clues only consist of the mention m and the entity title:\n[CLS] me [SEP] t (1)\nwhere me and t are the inputs of the mention m and the entity title. Following Wu et al. (2020), me and t are constructed as: me = cl [Ms] mention [Me] cr and t = title [ENT], where mention, cl, cr, title are the word-piece tokens of the mention, context before and after the mention and the entity title respectively. [Ms] and [Me] are special tokens to tag the mention, and\n[ENT] is the special token to separate entity title and entity description. The clues are concatenated with the n views separately and a special separator token [SEP] is added at the end. We feed them into a BERT encoder (\u03b8BERT2) to extract features. It produces a matrix representation X = [x1, x2, ..., xn] to represent the clues-view pairs, where xi \u2208 Rd is the output of the last hidden layer corresponding to the position of the [CLS] token for the i-th view and d is the dimension of hidden states of BERT."
        },
        {
            "heading": "3.2.2 Module Training",
            "text": "Since the process of labeling data is labor-intensive and error-prone, we do not have any labels about key views. Therefore, we introduce a matching task to enable our module to learn relevance scores between mentions and views. We argue that views that are more relevant to the mention can contribute more to determining whether the mention and the candidate entity are matched.\nSpecifically, we use a trainable weight parameter Wa \u2208 R1\u00d7d as one of the inputs and utilize the SoftMax function to calculate the attention scores of the matching result with regard to the views:\nG = SoftMax(WaXT )\nwhere G \u2208 R1\u00d7n. Then, we utilize the weighted aggregation with the attention scores to obtain the mention-entity representation: Z = GX , where Z \u2208 Rd. Finally, we get the binary prediction y\u0302 by feeding the representation into a feed-forward neural network FFNN: y\u0302 = FFNN(Z; \u03b8F1). The prediction measures whether the mention and the candidate entity are matched.\nWe employ cross-entropy as our loss objective, which is calculated as follows:\nLSelection = \u2212(ylogy\u0302 + (1\u2212 y)log(1\u2212 y\u0302)) (2)\nwhere y takes the value 1 if the mention and the candidate entity are matched."
        },
        {
            "heading": "3.2.3 Key Views Selection",
            "text": "During the matching task training, the vector G learns to measure the degree to which each view contributes to determining whether mentions and entities are matched. In the inference stage, we use it as the relevance scores between clues and all views of the candidate entity and utilize an Argmax function to obtain the most key view:\nk = Argmax(G) (3)\nAlgorithm 1: The key views selection process of our KVZEL. Input: The mention with context m,\ncandidate entity ep, candidate view list V of ep, number of iterations Q.\nOutput: The selected view list V\u0302 . 1 Construct initial clues by Eq. 1. 2 for each iteration q = 1 to Q do 3 Calculate LSelection by Eq. 2 and train our key views selection module. 4 Calculate the most key view Vk by Eq. 3 in the inference stage. 5 Add Vk to existing clues and the selected view list V\u0302 . 6 Remove Vk from the candidate view list V . 7 end 8 return V\u0302\nwhere k is the view marker. Then, we add this view Vk (e.g. V2) to our existing clues. And we will not consider the view Vk in the next iteration. We summarize the key views selection process of our KVZEL in Algorithm 1."
        },
        {
            "heading": "3.3 Entity Linking",
            "text": "The goal of our entity linking module is to aggregate key views into a new text \u02c6des to make the final decision. Considering that the first view sentences (view V0) are able to generally describe the entity, we first add the first view V0 to \u02c6des to enhance the overall understanding of the entity. Then we sort the selected key views to maintain the relative ordering in the original description to preserve the syntactic dependencies. The key views are then added to \u02c6des one by one. The new text \u02c6des serves as the mention m focused highly-condensed version of the entity description of ep. Finally, \u02c6des replaces the original entity description and is read by our entity linking module.\nFollowing Wu et al. (2020) and similar to Eq. 1, the input text of the mention m and the candidate entity ep is constructed as: [CLS] me [SEP] t \u02c6des [SEP]. Then the input text is entered into a BERT encoder (\u03b8BERT3) to produce the vector representation Up, which is the output of the last hidden layer corresponding to the position of the [CLS] token. Finally, the representation Up is input into a feed-forward neural network FFNN and the score sp between the mention m and its p-th candidate\nentity ep is calculated using a SoftMax function:\ns\u0302p = FFNN(Up; \u03b8F2), sp = exp(s\u0302p)\u2211P j=1 exp(s\u0302j)\nwhere P is the number of candidate entities of the mention m. We employ cross-entropy as our loss objective, which is calculated as follows: LLinking = \u2212 P\u2211\np=1\nyp log sp+(1\u2212 yp) log(1\u2212 sp)\nwhere yp \u2208 {0, 1} and yp takes the value 1 if the candidate entity ep is the gold entity of the mention m, otherwise it takes the value 0."
        },
        {
            "heading": "4 Experiments",
            "text": ""
        },
        {
            "heading": "4.1 Dataset",
            "text": "Following recent zero-shot entity linking works (Logeswaran et al., 2019; Wu et al., 2020; Yao et al., 2020; Tang et al., 2021), we evaluate our framework KVZEL under the Zeshel dataset,1 which is constructed by Logeswaran et al. (2019). Overall statistics of the dataset are shown in Table 1. The dataset was built based on the documents in Wikia.2 Wikia consists of encyclopedias, each specialized 1https://github.com/lajanugen/zeshel 2https://www.wikia.com\nin a particular subject such as sports and film series. Each particular subject can be considered as a domain. Zeshel consists of 16 specialized domains, 8 domains for training, 4 for validation, and 4 for test. Each domain has its individual entity dictionary, allowing the performance evaluation on entire unseen entities of new domains. The training set has 49,275 labeled mentions while the validation and test sets both have 10,000 unseen mentions."
        },
        {
            "heading": "4.2 Implementation Details",
            "text": "For a fair comparison, we use the BERT-baseuncased (Devlin et al., 2019) as our encoder and use the accuracy as our evaluation metric. For the sub view clustering module, the capacity c is set to 64. For the mention-aware key views selection module, following Tang et al. (2021), we set the maximum sequence length of the mention context to be 256. We train this module 1 epoch per iteration using a batch size of 8 and a learning rate of 2e-5. The number of iterations Q is set to 3, which can get the best results. We use the AdamW (Loshchilov and Hutter, 2017) optimizer to optimize our module. For the entity linking module, also following Tang et al. (2021), the max length for the mention context and entity description are both set to 256. We train this module in 5 epochs. All parameters are also optimized by AdamW, with learning rate 2e-5, and 10% warmup steps. Experiments were conducted on two NVIDIA GeForce RTX A6000 GPUs with 48 GB memory."
        },
        {
            "heading": "4.3 Comparison Methods",
            "text": "For the quantitative evaluation of our KVZEL, we use the following state-of-the-art methods (Logeswaran et al., 2019; Wu et al., 2020; Yao et al., 2020; Tang et al., 2021) for comparison. All of these methods including our KVZEL are based on\nthe cross-encoder (Logeswaran et al., 2019; Wu et al., 2020), which feeds the concatenation of mention context and entity description to BERT and outputs the [CLS] token\u2019s embeddings to produce the relevance scores. Erepeat (Yao et al., 2020) extends the effective reading length of BERT by repeating the position embedding to solve the long-range modeling problem in entity descriptions. Uni-MPR (Tang et al., 2021) segments a long description into short paragraphs to make use of more description information. Bi-MPR (Tang et al., 2021) is based on Uni-MPR, which segments mention context into short paragraphs to incorporate more mention information. Note that we do not consider any domainadaptive techniques in our KVZEL and comparison methods, which improves the final performance but outsides our work scope."
        },
        {
            "heading": "4.4 Overall Performance",
            "text": "The comparison results on the Zeshel dataset are shown in Table 2. We can observe that our KVZEL outperforms all baseline methods on average, illustrating the effectiveness of our KVZEL and the superiority of selecting key views for different mentions with divergent context. It\u2019s worth noting that all baselines perform worse on the YuGiOh domain. We conjecture that this is because the entities in this domain has more views since we find that the entities with longer descriptions contain more views. This is consistent with our claim that previous methods seem struggling to manage entities with rich multiple views information. We observe that our KVZEL makes a significant improvement on the domains (e.g. Star Trek and YuGiOh) whose descriptions have rich multiple views information. Our KVZEL avoids the noise brought by irrelevant view information and allows long-range key information integration, which is very effective for these\ndomains. In general, our KVZEL outperforms the baseline methods for 1.61% and 2.60% on Macro Acc. and Micro Acc. on the test set of Zeshel dataset, respectively."
        },
        {
            "heading": "5 Analysis",
            "text": ""
        },
        {
            "heading": "5.1 Ablation Study",
            "text": "To better understand our KVZEL framework, we investigate the contribution of some components through ablation studies, and the results are also shown in Table 2. Considering that our entity linking module is based on cross-encoder, the comparison results to cross-encoder could also be regarded as the ablation study to justify the advantage of our KVZEL. To evaluate the contribution of iteratively accumulating key views, we train the key views selection module only once and select the same number of key views for the entity linking module. We find that this leads to a significant performance drop, which demonstrates the effectiveness of utilizing the previously selected views as clues to move on to find the next key view. We then do not add the first view V0 to \u02c6des and only consider the selected views in our entity linking module. It can be observed that KVZEL w/o V0 performs worse than KVZEL. This indicates that the adding of V0 helps our entity linking module understand entities better, since we observe the first view sentences of most entities are able to generally describe the entity."
        },
        {
            "heading": "5.2 Effect of Number of Selected Views",
            "text": "We also explore the effect of different numbers of selected views on our KVZEL performance. The experimental results are shown in Figure 3. We\ncan find that the required number of selected views changes with different domains. For domains with rich views in entity descriptions (e.g. YuGiOh), the integration of more information from multiple views becomes particularly important. While for domains whose views are not as rich (e.g. Forgotten Realms, Lego), single or two views are sufficient to help our entity linking module to correctly link to gold entities. In general, we can observe that our KVZEL with 3 selected views performs best on average. If the number of selected views is too small, there will be not enough information to help our entity linking module make the correct decision. Conversely, if this number is too large, this will introduce noise from irrelevant views and cause the performance to drop."
        },
        {
            "heading": "5.3 Effect of Description Length",
            "text": "Through our observation, we find that the entities with longer descriptions contain more views. To further show the effectiveness of our proposed KVZEL framework, we evaluate the effect of crossencoder and our KVZEL on entities with different description lengths. The statistics of entities on the test set of Zeshel dataset are shown in Table 3 and\nthe experimental results are shown in Figure 4. We can find that the cross-encoder (without selecting key views) obtains passable performance on entities with few views but fails to manage those multiview entities as the length of descriptions increases. For example, the accuracy of cross-encoder is over 80% for entities with 0-500 description tokens but about 60% for entities with over 1000 description tokens. This is the limitation for zero-shot entity linking. Our KVZEL avoids the noise brought by irrelevant view information and allows long-range key information integration by iteratively accumulate key views. This helps our framework manage the entities with rich multiple views information. Our KVZEL significantly improves the accuracy to 71.66% (+10.29%) and 66.98% (+12.33%) for entities with 1000-2000 tokens and over 2000 tokens, respectively. Furthermore, considering its ability to avoid noise brought by irrelevant views information, our KVZEL also slightly improves the performance on entities with few views, which achieves the accuracy of 80.67% (+0.26%) and 83.21% (+2.12%) for entities with 0-200 tokens and 200-500 tokens respectively."
        },
        {
            "heading": "5.4 Case Study",
            "text": "To conduct a qualitative analysis, Table 4 shows two examples from the test set of Zeshel dataset. While the baseline methods tend to input the entire entity descriptions, our KVZEL only inputs the mention-focused views of entity descriptions. This indeed helps our framework avoid noise brought by irrelevant information and enhances emphasis on the corresponding details. For these two examples, our KVZEL can point to the gold entities \u201cCat (Friends)\u201d and \u201cSherry LeBlanc (manga)\u201d instead\nof \u201cCatherine Cat\u201d and \u201cSherry LeBlanc\u201d like baselines. This indicates that baseline methods can only capture the rough meaning of a description from a general view, while our KVZEL is able to dive into the descriptions and capture more fine-grained semantic information from key views. Furthermore, for the second example, the mention with context is related to multiple views. A key observation is that our KVZEL can precisely select key views to aggregate to make the final decision, which indicates that our KVZEL has the ability of long-range key information integration."
        },
        {
            "heading": "6 Conclusion",
            "text": "In this paper, we explore an issue that was overlooked when only textual descriptions are available in zero-shot entity linking scenarios, that is, only part of description information is related to mentions and other irrelevant information will introduce noise and make models reduce emphasis on the corresponding details. To overcome this issue, we propose a KVZEL framework to select key views from entity descriptions for different mentions with divergent context. Specifically, it first adopts unsupervised clustering to form sub views. Then, it imitates the human\u2019s thinking process to iteratively accumulate mention-related views, which helps our entity linking module have the ability of long-range information integration. The selected views are aggregated into a new text, which replaces the original description as the input of our entity linking module to make the final decision. Experimental results demonstrate that the proposed KVZEL framework achieves new state-of-the-art performance on the zero-shot entity linking dataset.\nLimitations\nAlthough our KVZEL achieves new state-of-the-art for zero-shot entity linking, it also poses several limitations as follows: 1) In this work, for simplicity, we only use the traditional unsupervised clustering approach mean-shift to form sub views. However, other state-of-the-art clustering approaches also can be used and may work better. We leave the selection of a more effective cluster approach to future work. 2) In this work, we only focus on the zero-shot entity linking setting, which is a low-resource scenario and only provides the textual description information for each entity. This task challenges the ability of entity linking models to understand the language consistency between mention contexts and entity descriptions. Our KVZEL improves this ability by selecting key views from entity descriptions. Therefore, when our KVZEL is extended to other entity linking settings which may have much external knowledge (e.g. frequency statistics and structure data, etc.) and not focus on the language understanding ability so much, the improvement of performance may be insignificant."
        },
        {
            "heading": "Acknowledgments",
            "text": "This research is supported by the National Natural Science Foundation of China (No. 62272250, 62002178), the Natural Science Foundation of Tianjin, China (No. 22JCJQJC00150)."
        }
    ],
    "title": "Selecting Key Views for Zero-Shot Entity Linking",
    "year": 2023
}